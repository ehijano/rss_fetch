<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>physics.comp-ph updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/physics.comp-ph</link>
    <description>physics.comp-ph updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/physics.comp-ph" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Tue, 20 May 2025 02:50:07 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Mon, 19 May 2025 00:00:00 -0400</pubDate>
    <skipDays>
      <day>Saturday</day>
      <day>Sunday</day>
    </skipDays>
    <item>
      <title>Unearthing large pseudoscalar Yukawa couplings with Machine Learning</title>
      <link>https://arxiv.org/abs/2505.10625</link>
      <description>arXiv:2505.10625v1 Announce Type: cross 
Abstract: With the Large Hadron Collider's Run 3 in progress, the 125 GeV Higgs boson couplings are being examined in greater detail, while searching for additional scalars. Multi-Higgs frameworks allow Higgs couplings to significantly deviate from Standard Model values, enabling indirect probes of extra scalars. We consider the possibility of large pseudoscalar Yukawa couplings in the softly-broken Z2xZ2' three-Higgs doublet model with CP violating coefficients. To explore the parameter space of the model, we employ a Machine Learning algorithm that significantly enhances sampling efficiency. Using it, we find new regions of parameter space and observable consequences, not found with previous techniques. This method leverages an Evolutionary Strategy to quickly converge towards valid regions with an additional Novelty Reward mechanism. We use this model as a prototype to illustrate the potential of the new techniques, applicable to any Physics Beyond the Standard Model scenario.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.10625v1</guid>
      <category>hep-ph</category>
      <category>physics.comp-ph</category>
      <pubDate>Mon, 19 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Fernando Abreu de Souza, Rafael Boto, Miguel Crispim Rom\~ao, Pedro N. Figueiredo, Jorge C. Rom\~ao, Jo\~ao P. Silva</dc:creator>
    </item>
    <item>
      <title>From noisy observables to accurate ground state energies: a quantum classical signal subspace approach with denoising</title>
      <link>https://arxiv.org/abs/2505.10735</link>
      <description>arXiv:2505.10735v1 Announce Type: cross 
Abstract: We propose a hybrid quantum-classical algorithm for ground state energy (GSE) estimation that remains robust to highly noisy data and exhibits low sensitivity to hyperparameter tuning. Our approach -- Fourier Denoising Observable Dynamic Mode Decomposition (FDODMD) -- combines Fourier-based denoising thresholding to suppress spurious noise modes with observable dynamic mode decomposition (ODMD), a quantum-classical signal subspace method. By applying ODMD to an ensemble of denoised time-domain trajectories, FDODMD reliably estimates the system's eigenfrequencies. We also provide an error analysis of FDODMD. Numerical experiments on molecular systems demonstrate that FDODMD achieves convergence in high-noise regimes inaccessible to baseline methods under a limited quantum computational budget, while accelerating spectral estimation in intermediate-noise regimes. Importantly, this performance gain is entirely classical, requiring no additional quantum overhead and significantly reducing overall quantum resource demands.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.10735v1</guid>
      <category>quant-ph</category>
      <category>cs.SY</category>
      <category>eess.SP</category>
      <category>eess.SY</category>
      <category>physics.comp-ph</category>
      <pubDate>Mon, 19 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Hardeep Bassi, Yizhi Shen, Harish S. Bhat, Roel Van Beeumen</dc:creator>
    </item>
    <item>
      <title>Beyond surfaces: quantifying internal radiative heat transport in dense materials</title>
      <link>https://arxiv.org/abs/2505.10853</link>
      <description>arXiv:2505.10853v1 Announce Type: cross 
Abstract: While phonons and electrons are well-established heat carriers in solids, photons are typically associated only with radiative transfer between surfaces. Yet for over 70 years, theorists have speculated that thermal photons could also conduct heat within dense, opaque materials -- an idea that has remained unproven and unquantified. Here, we resolve this longstanding question by developing a first-principles framework that reveals and quantifies the internal radiative contribution to thermal conductivity in solids. By analyzing 15 crystalline materials, we uncover photon mean free paths (MFPs) ranging from $\sim$100$\mu$m to over 1cm, with some materials exhibiting surprisingly large radiative thermal conductivity ($\kappa_{\text{rad}}$). Contrary to common assumptions, we show that $\kappa_{\text{rad}}$ can scale steeply with temperature (from $T^{1}$ to $T^{4}$), even as MFPs decrease (from $T^{-0.3}$ to $T^{-3}$). We also discover a robust link between photon MFP and phonon linewidths, revealing an unexpected interplay between radiative and phononic heat transport. Crucially, we establish a general formalism to calculate $\kappa_{\text{rad}}$ across arbitrary sample thicknesses and surface emissivities -- bridging ballistic and diffusive regimes. Our findings overturn long-held assumptions, uncover a missing channel of heat conduction, and provide a powerful new tool for thermal management in extreme environments.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.10853v1</guid>
      <category>cond-mat.mtrl-sci</category>
      <category>physics.comp-ph</category>
      <pubDate>Mon, 19 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Janak Tiwari, Tianli Feng</dc:creator>
    </item>
    <item>
      <title>Simulating fluid-fluid displacement in a soft capillary tube: How compliance delays interfacial instability and bubble pinch-off</title>
      <link>https://arxiv.org/abs/2505.10865</link>
      <description>arXiv:2505.10865v1 Announce Type: cross 
Abstract: The displacement of a more viscous fluid by a less viscous immiscible fluid in confined geometries is a fundamental problem in multiphase flows. Recent experiments have shown that such fluid-fluid displacement in micro-capillary tubes can lead to interfacial instabilities and, eventually, bubble pinch-off. A critical yet often overlooked aspect of this system is the effect of the tube's deformability on the onset of interfacial instability and bubble pinch-off. Here, we present a computational fluid-structure interaction model and an algorithm to simulate this fluid-fluid displacement problem in a soft capillary tube. We use a phase-field model for the fluids and a nonlinear hyperelastic model for the solid. Our fluid-structure interaction formulation uses a boundary-fitted approach and we use isogeometric analysis for the spatial discretization. Using this computational framework, we study the effects of inlet capillary number and tube stiffness on the control of interfacial instabilities in a soft capillary tube for both imbibition and drainage. We find that tube compliance delays or even suppresses interfacial instability and bubble pinch-off, a finding that has important implications for flow in soft porous media, bio-microfluidics, and manufacturing processes.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.10865v1</guid>
      <category>physics.flu-dyn</category>
      <category>physics.comp-ph</category>
      <pubDate>Mon, 19 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Sthavishtha R. Bhopalam, Ruben Juanes, Hector Gomez</dc:creator>
    </item>
    <item>
      <title>Pedestrian mobility citizen science complements expert mapping for enhancing inclusive neighborhood placemaking</title>
      <link>https://arxiv.org/abs/2505.11098</link>
      <description>arXiv:2505.11098v2 Announce Type: cross 
Abstract: Cities are complex systems that demand integrated approaches, with increasing attention focused on the neighborhood level. This study examines the interplay between expert-based mapping and citizen science in the Primer de Maig neighborhood of Granollers, Catalonia, Spain--an area marked by poor-quality public spaces and long-standing socio-economic challenges. Seventy-two residents were organized into 19 groups to record their pedestrian mobility while engaging in protocolized playful social actions. Their GPS identified opportunity units for meaningful public space activation. Although 56% of observed actions occurred within expert-defined units, the remaining 44% took place elsewhere. Clustering analysis of geo-located action stops revealed seven distinct clusters, highlighting overlooked areas with significant social potential. These findings underscore the complementarity of top-down and bottom-up approaches, demonstrating how citizen science and community science approaches enriches urban diagnostics by integrating subjective, community-based perspectives in public space placemaking and informing inclusive, adaptive sustainable urban transformation strategies.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.11098v2</guid>
      <category>physics.soc-ph</category>
      <category>cs.CY</category>
      <category>physics.comp-ph</category>
      <pubDate>Mon, 19 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <dc:creator>Ferran Larroya, Josep Perell\'o, Roger Paez, Manuela Valtchanova</dc:creator>
    </item>
    <item>
      <title>Reinforcement Learning Closures for Underresolved Partial Differential Equations using Synthetic Data</title>
      <link>https://arxiv.org/abs/2505.11308</link>
      <description>arXiv:2505.11308v1 Announce Type: cross 
Abstract: Partial Differential Equations (PDEs) describe phenomena ranging from turbulence and epidemics to quantum mechanics and financial markets. Despite recent advances in computational science, solving such PDEs for real-world applications remains prohibitively expensive because of the necessity of resolving a broad range of spatiotemporal scales. In turn, practitioners often rely on coarse-grained approximations of the original PDEs, trading off accuracy for reduced computational resources. To mitigate the loss of detail inherent in such approximations, closure models are employed to represent unresolved spatiotemporal interactions. We present a framework for developing closure models for PDEs using synthetic data acquired through the method of manufactured solutions. These data are used in conjunction with reinforcement learning to provide closures for coarse-grained PDEs. We illustrate the efficacy of our method using the one-dimensional and two-dimensional Burgers' equations and the two-dimensional advection equation. Moreover, we demonstrate that closure models trained for inhomogeneous PDEs can be effectively generalized to homogeneous PDEs. The results demonstrate the potential for developing accurate and computationally efficient closure models for systems with scarce data.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.11308v1</guid>
      <category>cs.LG</category>
      <category>physics.comp-ph</category>
      <pubDate>Mon, 19 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Lothar Heimbach, Sebastian Kaltenbach, Petr Karnakov, Francis J. Alexander, Petros Koumoutsakos</dc:creator>
    </item>
    <item>
      <title>Context parroting: A simple but tough-to-beat baseline for foundation models in scientific machine learning</title>
      <link>https://arxiv.org/abs/2505.11349</link>
      <description>arXiv:2505.11349v1 Announce Type: cross 
Abstract: Recently-developed time series foundation models for scientific machine learning exhibit emergent abilities to predict physical systems. These abilities include zero-shot forecasting, in which a model forecasts future states of a system given only a short trajectory as context. Here, we show that foundation models applied to physical systems can give accurate predictions, but that they fail to develop meaningful representations of the underlying physics. Instead, foundation models often forecast by context parroting, a simple zero-shot forecasting strategy that copies directly from the context. As a result, a naive direct context parroting model scores higher than state-of-the-art time-series foundation models on predicting a diverse range of dynamical systems, at a tiny fraction of the computational cost. We draw a parallel between context parroting and induction heads, which explains why large language models trained on text can be repurposed for time series forecasting. Our dynamical systems perspective also ties the scaling between forecast accuracy and context length to the fractal dimension of the attractor, providing insight into the previously observed in-context neural scaling laws. Context parroting thus serves as a simple but tough-to-beat baseline for future time-series foundation models and can help identify in-context learning strategies beyond parroting.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.11349v1</guid>
      <category>cs.LG</category>
      <category>nlin.CD</category>
      <category>physics.comp-ph</category>
      <pubDate>Mon, 19 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Yuanzhao Zhang, William Gilpin</dc:creator>
    </item>
    <item>
      <title>Potential failures of physics-informed machine learning in traffic flow modeling: theoretical and experimental analysis</title>
      <link>https://arxiv.org/abs/2505.11491</link>
      <description>arXiv:2505.11491v1 Announce Type: cross 
Abstract: This study critically examines the performance of physics-informed machine learning (PIML) approaches for traffic flow modeling, defining the failure of a PIML model as the scenario where it underperforms both its purely data-driven and purely physics-based counterparts. We analyze the loss landscape by perturbing trained models along the principal eigenvectors of the Hessian matrix and evaluating corresponding loss values. Our results suggest that physics residuals in PIML do not inherently hinder optimization, contrary to a commonly assumed failure cause. Instead, successful parameter updates require both ML and physics gradients to form acute angles with the quasi-true gradient and lie within a conical region. Given inaccuracies in both the physics models and the training data, satisfying this condition is often difficult. Experiments reveal that physical residuals can degrade the performance of LWR- and ARZ-based PIML models, especially under highly physics-driven settings. Moreover, sparse sampling and the use of temporally averaged traffic data can produce misleadingly small physics residuals that fail to capture actual physical dynamics, contributing to model failure. We also identify the Courant-Friedrichs-Lewy (CFL) condition as a key indicator of dataset suitability for PIML, where successful applications consistently adhere to this criterion. Lastly, we observe that higher-order models like ARZ tend to have larger error lower bounds than lower-order models like LWR, which is consistent with the experimental findings of existing studies.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.11491v1</guid>
      <category>cs.LG</category>
      <category>physics.comp-ph</category>
      <pubDate>Mon, 19 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Yuan-Zheng Lei, Yaobang Gong, Dianwei Chen, Yao Cheng, Xianfeng Terry Yang</dc:creator>
    </item>
    <item>
      <title>A robust and adaptive GenEO-type domain decomposition preconditioner for $\mathbf{H}(\mathbf{curl})$ problems in three-dimensional general topologies</title>
      <link>https://arxiv.org/abs/2311.18783</link>
      <description>arXiv:2311.18783v3 Announce Type: replace-cross 
Abstract: In this paper we design, analyse and test domain decomposition methods for linear systems of equations arising from conforming finite element discretisations of positive Maxwell-type equations, namely for $\mathbf{H}(\mathbf{curl})$ problems. It is well known that convergence of domain decomposition methods rely heavily on the efficiency of the coarse space used in the second level. We design adaptive coarse spaces that complement a near-kernel space made from the gradient of scalar functions. The new class of preconditioner is inspired by the idea of subspace decomposition, but based on spectral coarse spaces, and is specially designed for curl-conforming discretisations of Maxwell's equations in heterogeneous media on general domains which may have holes. We also address the practical robustness of various solvers in the case of non-trivial topologies and/or high aspect ratio of the domain.</description>
      <guid isPermaLink="false">oai:arXiv.org:2311.18783v3</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <category>physics.comp-ph</category>
      <pubDate>Mon, 19 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Niall Bootland, Victorita Dolean, Fr\'ed\'eric Nataf, Pierre-Henri Tournier</dc:creator>
    </item>
    <item>
      <title>chemtrain: Learning Deep Potential Models via Automatic Differentiation and Statistical Physics</title>
      <link>https://arxiv.org/abs/2408.15852</link>
      <description>arXiv:2408.15852v2 Announce Type: replace-cross 
Abstract: Neural Networks (NNs) are effective models for refining the accuracy of molecular dynamics, opening up new fields of application. Typically trained bottom-up, atomistic NN potential models can reach first-principle accuracy, while coarse-grained implicit solvent NN potentials surpass classical continuum solvent models. However, overcoming the limitations of costly generation of accurate reference data and data inefficiency of common bottom-up training demands efficient incorporation of data from many sources. This paper introduces the framework chemtrain to learn sophisticated NN potential models through customizable training routines and advanced training algorithms. These routines can combine multiple top-down and bottom-up algorithms, e.g., to incorporate both experimental and simulation data or pre-train potentials with less costly algorithms. chemtrain provides an object-oriented high-level interface to simplify the creation of custom routines. On the lower level, chemtrain relies on JAX to compute gradients and scale the computations to use available resources. We demonstrate the simplicity and importance of combining multiple algorithms in the examples of parametrizing an all-atomistic model of titanium and a coarse-grained implicit solvent model of alanine dipeptide.</description>
      <guid isPermaLink="false">oai:arXiv.org:2408.15852v2</guid>
      <category>physics.chem-ph</category>
      <category>cs.LG</category>
      <category>physics.comp-ph</category>
      <pubDate>Mon, 19 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <arxiv:DOI>10.1016/j.cpc.2025.109512</arxiv:DOI>
      <arxiv:journal_reference>Computer Physics Communications, Volume 310, 2025, 109512, ISSN 0010-4655</arxiv:journal_reference>
      <dc:creator>Paul Fuchs, Stephan Thaler, Sebastien R\"ocken, Julija Zavadlav</dc:creator>
    </item>
    <item>
      <title>Slip-dominated structural transitions</title>
      <link>https://arxiv.org/abs/2409.04066</link>
      <description>arXiv:2409.04066v3 Announce Type: replace-cross 
Abstract: We use molecular dynamics to show that plastic slip is a crucial component of the transformation mechanism of a square-to-triangular structural transition. The latter is a stylized analog of many other reconstructive phase transitions. To justify our conclusions we use a novel atomistically-informed mesoscopic representation of the field of lattice distortions in molecular dynamics simulations. Our approach reveals a hidden alternating slip distribution behind the seemingly homogeneous product phase which points to the fact that lattice invariant shears play a central role in this class of phase transformations. While the underlying pattern of anti-parallel displacements may be also interpreted as microscopic shuffling, its precise crystallographic nature strongly suggests the plasticity-centered interpretation.</description>
      <guid isPermaLink="false">oai:arXiv.org:2409.04066v3</guid>
      <category>cond-mat.mtrl-sci</category>
      <category>cond-mat.mes-hall</category>
      <category>nlin.PS</category>
      <category>physics.comp-ph</category>
      <pubDate>Mon, 19 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <arxiv:DOI>10.1103/x5fv-67xn</arxiv:DOI>
      <dc:creator>Kanka Ghosh, Oguz Umut Salman, Sylvain Queyreau, Lev Truskinovsky</dc:creator>
    </item>
    <item>
      <title>Learning Equivariant Non-Local Electron Density Functionals</title>
      <link>https://arxiv.org/abs/2410.07972</link>
      <description>arXiv:2410.07972v3 Announce Type: replace-cross 
Abstract: The accuracy of density functional theory hinges on the approximation of non-local contributions to the exchange-correlation (XC) functional. To date, machine-learned and human-designed approximations suffer from insufficient accuracy, limited scalability, or dependence on costly reference data. To address these issues, we introduce Equivariant Graph Exchange Correlation (EG-XC), a novel non-local XC functional based on equivariant graph neural networks (GNNs). Where previous works relied on semi-local functionals or fixed-size descriptors of the density, we compress the electron density into an SO(3)-equivariant nuclei-centered point cloud for efficient non-local atomic-range interactions. By applying an equivariant GNN on this point cloud, we capture molecular-range interactions in a scalable and accurate manner. To train EG-XC, we differentiate through a self-consistent field solver requiring only energy targets. In our empirical evaluation, we find EG-XC to accurately reconstruct `gold-standard' CCSD(T) energies on MD17. On out-of-distribution conformations of 3BPA, EG-XC reduces the relative MAE by 35% to 50%. Remarkably, EG-XC excels in data efficiency and molecular size extrapolation on QM9, matching force fields trained on 5 times more and larger molecules. On identical training sets, EG-XC yields on average 51% lower MAEs.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.07972v3</guid>
      <category>cs.LG</category>
      <category>physics.chem-ph</category>
      <category>physics.comp-ph</category>
      <pubDate>Mon, 19 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Nicholas Gao, Eike Eberhard, Stephan G\"unnemann</dc:creator>
    </item>
    <item>
      <title>The State of Factoring on Quantum Computers</title>
      <link>https://arxiv.org/abs/2410.14397</link>
      <description>arXiv:2410.14397v2 Announce Type: replace-cross 
Abstract: We report on the current state of factoring integers on both digital and analog quantum computers. For digital quantum computers, we study the effect of errors for which one can formally prove that Shor's factoring algorithm fails. For analog quantum computers, we experimentally test three factorisation methods and provide evidence for a scaling performance that is absolutely and asymptotically better than random guessing but still exponential. We conclude with an overview of future perspectives on factoring large integers on quantum computers.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.14397v2</guid>
      <category>quant-ph</category>
      <category>physics.comp-ph</category>
      <pubDate>Mon, 19 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <arxiv:DOI>10.34734/FZJ-2025-01965</arxiv:DOI>
      <arxiv:journal_reference>NIC Symposium 2025, Publication Series of the John von Neumann Institute for Computing (NIC) NIC Series 52, 239 - 250 (2025)</arxiv:journal_reference>
      <dc:creator>Dennis Willsch, Philipp Hanussek, Georg Hoever, Madita Willsch, Fengping Jin, Hans De Raedt, Kristel Michielsen</dc:creator>
    </item>
    <item>
      <title>The Non-Local Dual Phase Lag Model of Heat Conduction in a Silicon Metal-Oxide-Semiconductor Field-Effect Transistor</title>
      <link>https://arxiv.org/abs/2412.10962</link>
      <description>arXiv:2412.10962v3 Announce Type: replace-cross 
Abstract: As the transistors and consequently the chips are getting smaller, the accurate investigation of heat transport at micro/nanoscale, becomes an important issue of concern. This is due to an increase in the energy consumption and the leakage currents as a result of the miniaturization which requires taking care of the thermal behavior to make sure that the device is working in the threshold temperature regime. The current work deals with a two-dimensional framework, incorporating the nonlocality in space, for more accurate investigation of the nanoscale heat transport using the lower computational cost phenomenological macroscopical Dual Phase Lag (DPL) method. The non dimensional non-locality parameter {\gamma}, which indicates the strength of the non-locality, is embedded through the modified DPL model named as nonlocal DPL. It is obtained that for the two-dimensional silicon transistor, the {\gamma} parameter in x and y direction has the same value and like its behavior at one-dimension, is linearly dependent on the Knudsen number, being 1.5 for Kn=10 and 0.015 for Kn=0.1. Also, the phase lagging ratio, B, is found to be 0.08. It should be mentioned that the non-locality effect is more pronounced for smaller systems with higher Knudsen number in which the non-Fourier behavior is more evident but contemplating the non-locality parameter in systems with lower Knudsen number, makes the results more precise. In brief, it is confirmed that taking into account the {\gamma} parameter is noteworthy for accurately predicting the thermal behavior in micro/nano scale systems using the classical macroscopical methods.</description>
      <guid isPermaLink="false">oai:arXiv.org:2412.10962v3</guid>
      <category>physics.app-ph</category>
      <category>cond-mat.mes-hall</category>
      <category>physics.comp-ph</category>
      <pubDate>Mon, 19 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <arxiv:journal_reference>International Communication in Heat and Mass Transfer, 2025</arxiv:journal_reference>
      <dc:creator>Sharif A. Sulaiman, Zahra Shomali</dc:creator>
    </item>
    <item>
      <title>Efficient Monte Carlo Event Generation for Neutrino-Nucleus Exclusive Cross Sections</title>
      <link>https://arxiv.org/abs/2502.14452</link>
      <description>arXiv:2502.14452v3 Announce Type: replace-cross 
Abstract: Modern neutrino-nucleus cross section predictions need to incorporate sophisticated nuclear models to achieve greater predictive precision. However, the computational complexity of these advanced models often limits their practicality for experimental analyses. To address this challenge, we introduce a new Monte Carlo method utilizing Normalizing Flows to generate surrogate cross sections that closely approximate those of the original model while significantly reducing computational overhead. As a case study, we built a Monte Carlo event generator for the neutrino-nucleus cross section model developed by the Ghent group. This model employs a Hartree-Fock procedure to establish a quantum mechanical framework in which both the bound and scattering nucleon states are solutions to the mean-field nuclear potential. The surrogate cross sections generated by our method demonstrate excellent accuracy with a relative effective sample size of more than $98.4 \%$, providing a computationally efficient alternative to traditional Monte Carlo sampling methods for differential cross sections.</description>
      <guid isPermaLink="false">oai:arXiv.org:2502.14452v3</guid>
      <category>hep-ex</category>
      <category>nucl-th</category>
      <category>physics.comp-ph</category>
      <pubDate>Mon, 19 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Mathias El Baz, Federico S\'anchez, Natalie Jachowicz, Kajetan Niewczas, Ashish Kumar Jha, Alexis Nikolakopoulos</dc:creator>
    </item>
    <item>
      <title>MetaSym: A Symplectic Meta-learning Framework for Physical Intelligence</title>
      <link>https://arxiv.org/abs/2502.16667</link>
      <description>arXiv:2502.16667v2 Announce Type: replace-cross 
Abstract: Scalable and generalizable physics-aware deep learning has long been considered a significant challenge with various applications across diverse domains ranging from robotics to molecular dynamics. Central to almost all physical systems are symplectic forms, the geometric backbone that underpins fundamental invariants like energy and momentum. In this work, we introduce a novel deep learning framework, MetaSym. In particular, MetaSym combines a strong symplectic inductive bias obtained from a symplectic encoder, and an autoregressive decoder with meta-attention. This principled design ensures that core physical invariants remain intact, while allowing flexible, data-efficient adaptation to system heterogeneities. We benchmark MetaSym with highly varied and realistic datasets, such as a high-dimensional spring-mesh system (Otness et al., 2021), an open quantum system with dissipation and measurement backaction, and robotics-inspired quadrotor dynamics. Our results demonstrate superior performance in modeling dynamics under few-shot adaptation, outperforming state-of-the-art baselines that use larger models.</description>
      <guid isPermaLink="false">oai:arXiv.org:2502.16667v2</guid>
      <category>cs.LG</category>
      <category>cs.RO</category>
      <category>physics.comp-ph</category>
      <category>quant-ph</category>
      <pubDate>Mon, 19 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Pranav Vaidhyanathan, Aristotelis Papatheodorou, Mark T. Mitchison, Natalia Ares, Ioannis Havoutis</dc:creator>
    </item>
  </channel>
</rss>
