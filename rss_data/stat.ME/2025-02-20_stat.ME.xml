<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>stat.ME updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/stat.ME</link>
    <description>stat.ME updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/stat.ME" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Thu, 20 Feb 2025 05:00:09 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Thu, 20 Feb 2025 00:00:00 -0500</pubDate>
    <skipDays>
      <day>Sunday</day>
      <day>Saturday</day>
    </skipDays>
    <item>
      <title>Approximate Bayesian Kernel Machine Regression via Random Fourier Features for Estimating Joint Health Effects of Multiple Exposures</title>
      <link>https://arxiv.org/abs/2502.13157</link>
      <description>arXiv:2502.13157v1 Announce Type: new 
Abstract: Environmental epidemiology has traditionally focused on examining health effects of single exposures, more recently with adjustment for co-occurring exposures. Advancements in exposure assessments and statistical tools have enabled a shift towards studying multiple exposures and their combined health impacts. Bayesian Kernel Machine Regression (BKMR) is a popular approach to flexibly estimate the joint and nonlinear effects of multiple exposures. However, BKMR faces computation challenges for large datasets, as inverting the kernel repeatedly in Markov chain Monte Carlo (MCMC) algorithms can be time-consuming and often infeasible in practice. To address this issue, we propose a faster version of BKMR using supervised random Fourier features to approximate the Gaussian process. We use periodic functions as basis functions and this approximation re-frames the kernel machine regression into a linear mixed-effect model that facilitates computationally efficient estimation and prediction. Bayesian inference was conducted using MCMC with Hamiltonian Monte Carlo algorithms. Analytic code for implementing Fast BKMR was developed for R. Simulation studies demonstrated that this approximation method yields results comparable to the original Gaussian process while reducing the computation time by 29 to 99%, depending on the number of basis functions and sample sizes. Our approach is also more robust to kernel misspecification in some scenarios. Finally, we applied this approach to analyze over 270,000 birth records, examining associations between multiple ambient air pollutants and birthweight in Georgia.</description>
      <guid isPermaLink="false">oai:arXiv.org:2502.13157v1</guid>
      <category>stat.ME</category>
      <category>stat.AP</category>
      <pubDate>Thu, 20 Feb 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Danlu Zhang, Stephanie M. Eick, Howard H. Chang</dc:creator>
    </item>
    <item>
      <title>Robust Inference for the Direct Average Treatment Effect with Treatment Assignment Interference</title>
      <link>https://arxiv.org/abs/2502.13238</link>
      <description>arXiv:2502.13238v1 Announce Type: new 
Abstract: Uncertainty quantification in causal inference settings with random network interference is a challenging open problem. We study the large sample distributional properties of the classical difference-in-means Hajek treatment effect estimator, and propose a robust inference procedure for the (conditional) direct average treatment effect, allowing for cross-unit interference in both the outcome and treatment equations. Leveraging ideas from statistical physics, we introduce a novel Ising model capturing interference in the treatment assignment, and then obtain three main results. First, we establish a Berry-Esseen distributional approximation pointwise in the degree of interference generated by the Ising model. Our distributional approximation recovers known results in the literature under no-interference in treatment assignment, and also highlights a fundamental fragility of inference procedures developed using such a pointwise approximation. Second, we establish a uniform distributional approximation for the Hajek estimator, and develop robust inference procedures that remain valid regardless of the unknown degree of interference in the Ising model. Third, we propose a novel resampling method for implementation of robust inference procedure. A key technical innovation underlying our work is a new \textit{De-Finetti Machine} that facilitates conditional i.i.d. Gaussianization, a technique that may be of independent interest in other settings.</description>
      <guid isPermaLink="false">oai:arXiv.org:2502.13238v1</guid>
      <category>stat.ME</category>
      <category>econ.EM</category>
      <pubDate>Thu, 20 Feb 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Matias D. Cattaneo (Rae), Yihan He (Rae),  Ruiqi (Rae),  Yu</dc:creator>
    </item>
    <item>
      <title>Functional Network Autoregressive Models for Panel Data</title>
      <link>https://arxiv.org/abs/2502.13431</link>
      <description>arXiv:2502.13431v1 Announce Type: new 
Abstract: This study proposes a novel functional vector autoregressive framework for analyzing network interactions of functional outcomes in panel data settings. In this framework, an individual's outcome function is influenced by the outcomes of others through a simultaneous equation system. To estimate the functional parameters of interest, we need to address the endogeneity issue arising from these simultaneous interactions among outcome functions. This issue is carefully handled by developing a novel functional moment-based estimator. We establish the consistency, convergence rate, and pointwise asymptotic normality of the proposed estimator. Additionally, we discuss the estimation of marginal effects and impulse response analysis. As an empirical illustration, we analyze the demand for a bike-sharing service in the U.S. The results reveal statistically significant spatial interactions in bike availability across stations, with interaction patterns varying over the time of day.</description>
      <guid isPermaLink="false">oai:arXiv.org:2502.13431v1</guid>
      <category>stat.ME</category>
      <category>econ.EM</category>
      <pubDate>Thu, 20 Feb 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Tomohiro Ando, Tadao Hoshino</dc:creator>
    </item>
    <item>
      <title>Balancing Flexibility and Interpretability: A Conditional Linear Model Estimation via Random Forest</title>
      <link>https://arxiv.org/abs/2502.13438</link>
      <description>arXiv:2502.13438v1 Announce Type: new 
Abstract: Traditional parametric econometric models often rely on rigid functional forms, while nonparametric techniques, despite their flexibility, frequently lack interpretability. This paper proposes a parsimonious alternative by modeling the outcome $Y$ as a linear function of a vector of variables of interest $\boldsymbol{X}$, conditional on additional covariates $\boldsymbol{Z}$. Specifically, the conditional expectation is expressed as $\mathbb{E}[Y|\boldsymbol{X},\boldsymbol{Z}]=\boldsymbol{X}^{T}\boldsymbol{\beta}(\boldsymbol{Z})$, where $\boldsymbol{\beta}(\cdot)$ is an unknown Lipschitz-continuous function. We introduce an adaptation of the Random Forest (RF) algorithm to estimate this model, balancing the flexibility of machine learning methods with the interpretability of traditional linear models. This approach addresses a key challenge in applied econometrics by accommodating heterogeneity in the relationship between covariates and outcomes. Furthermore, the heterogeneous partial effects of $\boldsymbol{X}$ on $Y$ are represented by $\boldsymbol{\beta}(\cdot)$ and can be directly estimated using our proposed method. Our framework effectively unifies established parametric and nonparametric models, including varying-coefficient, switching regression, and additive models. We provide theoretical guarantees, such as pointwise and $L^p$-norm rates of convergence for the estimator, and establish a pointwise central limit theorem through subsampling, aiding inference on the function $\boldsymbol\beta(\cdot)$. We present Monte Carlo simulation results to assess the finite-sample performance of the method.</description>
      <guid isPermaLink="false">oai:arXiv.org:2502.13438v1</guid>
      <category>stat.ME</category>
      <category>econ.EM</category>
      <pubDate>Thu, 20 Feb 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Ricardo Masini, Marcelo Medeiros</dc:creator>
    </item>
    <item>
      <title>Distal Causal Excursion Effects: Modeling Long-Term Effects of Time-Varying Treatments in Micro-Randomized Trials</title>
      <link>https://arxiv.org/abs/2502.13500</link>
      <description>arXiv:2502.13500v1 Announce Type: new 
Abstract: Micro-randomized trials (MRTs) play a crucial role in optimizing digital interventions. In an MRT, each participant is sequentially randomized among treatment options hundreds of times. While the interventions tested in MRTs target short-term behavioral responses (proximal outcomes), their ultimate goal is to drive long-term behavior change (distal outcomes). However, existing causal inference methods, such as the causal excursion effect, are limited to proximal outcomes, making it challenging to quantify the long-term impact of interventions. To address this gap, we introduce the distal causal excursion effect (DCEE), a novel estimand that quantifies the long-term effect of time-varying treatments. The DCEE contrasts distal outcomes under two excursion policies while marginalizing over most treatment assignments, enabling a parsimonious and interpretable causal model even with a large number of decision points. We propose two estimators for the DCEE -- one with cross-fitting and one without -- both robust to misspecification of the outcome model. We establish their asymptotic properties and validate their performance through simulations. We apply our method to the HeartSteps MRT to assess the impact of activity prompts on long-term habit formation. Our findings suggest that prompts delivered earlier in the study have a stronger long-term effect than those delivered later, underscoring the importance of intervention timing in behavior change. This work provides the critically needed toolkit for scientists working on digital interventions to assess long-term causal effects using MRT data.</description>
      <guid isPermaLink="false">oai:arXiv.org:2502.13500v1</guid>
      <category>stat.ME</category>
      <pubDate>Thu, 20 Feb 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Tianchen Qian</dc:creator>
    </item>
    <item>
      <title>Multi-view biclustering via non-negative matrix tri-factorisation</title>
      <link>https://arxiv.org/abs/2502.13698</link>
      <description>arXiv:2502.13698v1 Announce Type: new 
Abstract: Multi-view data is ever more apparent as methods for production, collection and storage of data become more feasible both practically and fiscally. However, not all features are relevant to describe the patterns for all individuals. Multi-view biclustering aims to simultaneously cluster both rows and columns, discovering clusters of rows as well as their view-specific identifying features. A novel multi-view biclustering approach based on non-negative matrix factorisation is proposed (ResNMTF). Demonstrated through extensive experiments on both synthetic and real datasets, ResNMTF successfully identifies both overlapping and non-exhaustive biclusters, without pre-existing knowledge of the number of biclusters present, and is able to incorporate any combination of shared dimensions across views. Further, to address the lack of a suitable bicluster-specific intrinsic measure, the popular silhouette score is extended to the bisilhouette score. The bisilhouette score is demonstrated to align well with known extrinsic measures, and proves useful as a tool for hyperparameter tuning as well as visualisation.</description>
      <guid isPermaLink="false">oai:arXiv.org:2502.13698v1</guid>
      <category>stat.ME</category>
      <category>stat.AP</category>
      <pubDate>Thu, 20 Feb 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Ella S. C. Orme, Theodoulos Rodosthenous, Marina Evangelou</dc:creator>
    </item>
    <item>
      <title>D-separation for applied researchers: understanding how to interpret directed acyclic graphs</title>
      <link>https://arxiv.org/abs/2502.13736</link>
      <description>arXiv:2502.13736v1 Announce Type: new 
Abstract: The assumed causal relationships depicted in a DAG are interpreted using a set of rules called D-separation rules. Although these rules can be implemented automatically using standard software, at least a basic understanding of their principles is useful for properly using and interpreting DAGs in practice.</description>
      <guid isPermaLink="false">oai:arXiv.org:2502.13736v1</guid>
      <category>stat.ME</category>
      <pubDate>Thu, 20 Feb 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Fernando Pires Hartwig, Timothy Feeney, Neil Davies</dc:creator>
    </item>
    <item>
      <title>Causal discovery in heavy-tailed linear structural equation models via scalings</title>
      <link>https://arxiv.org/abs/2502.13762</link>
      <description>arXiv:2502.13762v1 Announce Type: new 
Abstract: Causal dependence modelling of multivariate extremes is intended to improve our understanding of the relationships amongst variables associated with rare events. Regular variation provides a standard framework in the study of extremes. This paper concerns the linear structural equation model with regularly varying noise variables. We focus on extreme observations generated from such a model and propose a causal discovery method based on the scaling parameters of its extremal angular measure. We implement the method as an algorithm, establish its consistency and evaluate it by simulation and by application to river discharge datasets. Comparison with the only alternative extremal method for such model reveals its competitive performance.</description>
      <guid isPermaLink="false">oai:arXiv.org:2502.13762v1</guid>
      <category>stat.ME</category>
      <pubDate>Thu, 20 Feb 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Mario Krali</dc:creator>
    </item>
    <item>
      <title>A Zero-Inflated Poisson Latent Position Cluster Model</title>
      <link>https://arxiv.org/abs/2502.13790</link>
      <description>arXiv:2502.13790v1 Announce Type: new 
Abstract: The latent position network model (LPM) is a popular approach for the statistical analysis of network data. A central aspect of this model is that it assigns nodes to random positions in a latent space, such that the probability of an interaction between each pair of individuals or nodes is determined by their distance in this latent space. A key feature of this model is that it allows one to visualize nuanced structures via the latent space representation. The LPM can be further extended to the Latent Position Cluster Model (LPCM), to accommodate the clustering of nodes by assuming that the latent positions are distributed following a finite mixture distribution. In this paper, we extend the LPCM to accommodate missing network data and apply this to non-negative discrete weighted social networks. By treating missing data as ``unusual'' zero interactions, we propose a combination of the LPCM with the zero-inflated Poisson distribution. Statistical inference is based on a novel partially collapsed Markov chain Monte Carlo algorithm, where a Mixture-of-Finite-Mixtures (MFM) model is adopted to automatically determine the number of clusters and optimal group partitioning. Our algorithm features a truncated absorb-eject move, which is a novel adaptation of an idea commonly used in collapsed samplers, within the context of MFMs. Another aspect of our work is that we illustrate our results on 3-dimensional latent spaces, maintaining clear visualizations while achieving more flexibility than 2-dimensional models. The performance of this approach is illustrated via two carefully designed simulation studies, as well as four different publicly available real networks, where some interesting new perspectives are uncovered.</description>
      <guid isPermaLink="false">oai:arXiv.org:2502.13790v1</guid>
      <category>stat.ME</category>
      <category>stat.AP</category>
      <category>stat.CO</category>
      <pubDate>Thu, 20 Feb 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Chaoyi Lu, Riccardo Rastelli, Nial Friel</dc:creator>
    </item>
    <item>
      <title>Methods of multi-indication meta-analysis for health technology assessment: a simulation study</title>
      <link>https://arxiv.org/abs/2502.13844</link>
      <description>arXiv:2502.13844v1 Announce Type: new 
Abstract: A growing number of oncology treatments, such as bevacizumab, are used across multiple indications. However, in health technology assessment (HTA), their clinical and cost-effectiveness are typically appraised within a single target indication. This approach excludes a broader evidence base across other indications. To address this, we explored multi-indication meta-analysis methods that share evidence across indications.
  We conducted a simulation study to evaluate alternative multi-indication synthesis models. This included univariate (mixture and non-mixture) methods synthesizing overall survival (OS) data and bivariate surrogacy models jointly modelling treatment effects on progression-free survival (PFS) and OS, pooling surrogacy parameters across indications. Simulated datasets were generated using a multistate disease progression model under various scenarios, including different levels of heterogeneity within and between indications, outlier indications, and varying data on OS for the target indication. We evaluated the performance of the synthesis models applied to the simulated datasets, in terms of their ability to predict overall survival (OS) in a target indication.
  The results showed univariate multi-indication methods could reduce uncertainty without increasing bias, particularly when OS data were available in the target indication. Compared with univariate methods, mixture models did not significantly improve performance and are not recommended for HTA. In scenarios where OS data in the target indication is absent and there were also outlier indications, bivariate surrogacy models showed promise in correcting bias relative to univariate models, though further research under realistic conditions is needed.
  Multi-indication methods are more complex than traditional approaches but can potentially reduce uncertainty in HTA decisions.</description>
      <guid isPermaLink="false">oai:arXiv.org:2502.13844v1</guid>
      <category>stat.ME</category>
      <category>stat.AP</category>
      <pubDate>Thu, 20 Feb 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-sa/4.0/</dc:rights>
      <dc:creator>David Glynn, Pedro Saramago, Janharpreet Singh, Sylwia Bujkiewicz, Sofia Dias, Stephen Palmer, Marta Soares</dc:creator>
    </item>
    <item>
      <title>Integrating Randomized Controlled Trial and External Control Data Using Balancing Weights: A Comparison of Estimands and Estimators</title>
      <link>https://arxiv.org/abs/2502.13871</link>
      <description>arXiv:2502.13871v1 Announce Type: new 
Abstract: Randomized controlled trials (RCTs) face inherent limitations, such as ethical or resource constraints, which lead to a limited number of study participants. To address these limitations, recent research endeavors have sought to incorporate external control (EC) data, such as historical trial data or real-world data, with RCT data in treatment effect evaluation. This integration introduces unique questions regarding target population specification, causal estimand, and optimality of pooled estimators. Balancing weights have emerged as valuable tools to ensure comparability in patient characteristics, but there remains a gap in implementing them with ECs. In this study, we elucidate potential estimands of interest and propose corresponding balancing-weight-based estimators. We provide statistical and clinical definitions and interpretations of the estimands. Our extensive simulations show that different causal estimands perform differently with respect to bias and efficiency, based on the level of similarity between RCT and EC.</description>
      <guid isPermaLink="false">oai:arXiv.org:2502.13871v1</guid>
      <category>stat.ME</category>
      <pubDate>Thu, 20 Feb 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Peijin Wang, Hwanhee Hong, Kyungeun Jeon, Laine Elliott Thomas</dc:creator>
    </item>
    <item>
      <title>Debiasing Functions of Private Statistics in Postprocessing</title>
      <link>https://arxiv.org/abs/2502.13314</link>
      <description>arXiv:2502.13314v1 Announce Type: cross 
Abstract: Given a differentially private unbiased estimate $\tilde{q}=q(D) +\nu$ of a statistic $q(D)$, we wish to obtain unbiased estimates of functions of $q(D)$, such as $1/q(D)$, solely through post-processing of $\tilde{q}$, with no further access to the confidential dataset $D$. To this end, we adapt the deconvolution method used for unbiased estimation in the statistical literature, deriving unbiased estimators for a broad family of twice-differentiable functions when the privacy-preserving noise $\nu$ is drawn from the Laplace distribution (Dwork et al., 2006). We further extend this technique to a more general class of functions, deriving approximately optimal estimators that are unbiased for values in a user-specified interval (possibly extending to $\pm \infty$). We use these results to derive an unbiased estimator for private means when the size $n$ of the dataset is not publicly known. In a numerical application, we find that a mechanism that uses our estimator to return an unbiased sample size and mean outperforms a mechanism that instead uses the previously known unbiased privacy mechanism for such means (Kamath et al., 2023). We also apply our estimators to develop unbiased transformation mechanisms for per-record differential privacy, a privacy concept in which the privacy guarantee is a public function of a record's value (Seeman et al., 2024). Our mechanisms provide stronger privacy guarantees than those in prior work (Finley et al., 2024) by using Laplace, rather than Gaussian, noise. Finally, using a different approach, we go beyond Laplace noise by deriving unbiased estimators for polynomials under the weak condition that the noise distribution has sufficiently many moments.</description>
      <guid isPermaLink="false">oai:arXiv.org:2502.13314v1</guid>
      <category>cs.CR</category>
      <category>stat.ME</category>
      <pubDate>Thu, 20 Feb 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-sa/4.0/</dc:rights>
      <dc:creator>Flavio Calmon, Elbert Du, Cynthia Dwork, Brian Finley, Grigory Franguridi</dc:creator>
    </item>
    <item>
      <title>Tensor dynamic conditional correlation model: A new way to pursuit "Holy Grail of investing"</title>
      <link>https://arxiv.org/abs/2502.13461</link>
      <description>arXiv:2502.13461v1 Announce Type: cross 
Abstract: Style investing creates asset classes (or the so-called "styles") with low correlations, aligning well with the principle of "Holy Grail of investing" in terms of portfolio selection. The returns of styles naturally form a tensor-valued time series, which requires new tools for studying the dynamics of the conditional correlation matrix to facilitate the aforementioned principle. Towards this goal, we introduce a new tensor dynamic conditional correlation (TDCC) model, which is based on two novel treatments: trace-normalization and dimension-normalization. These two normalizations adapt to the tensor nature of the data, and they are necessary except when the tensor data reduce to vector data. Moreover, we provide an easy-to-implement estimation procedure for the TDCC model, and examine its finite sample performance by simulations. Finally, we assess the usefulness of the TDCC model in international portfolio selection across ten global markets and in large portfolio selection for 1800 stocks from the Chinese stock market.</description>
      <guid isPermaLink="false">oai:arXiv.org:2502.13461v1</guid>
      <category>q-fin.PM</category>
      <category>econ.EM</category>
      <category>stat.ME</category>
      <pubDate>Thu, 20 Feb 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Cheng Yu, Zhoufan Zhu, Ke Zhu</dc:creator>
    </item>
    <item>
      <title>An Efficient Permutation-Based Kernel Two-Sample Test</title>
      <link>https://arxiv.org/abs/2502.13570</link>
      <description>arXiv:2502.13570v1 Announce Type: cross 
Abstract: Two-sample hypothesis testing-determining whether two sets of data are drawn from the same distribution-is a fundamental problem in statistics and machine learning with broad scientific applications. In the context of nonparametric testing, maximum mean discrepancy (MMD) has gained popularity as a test statistic due to its flexibility and strong theoretical foundations. However, its use in large-scale scenarios is plagued by high computational costs. In this work, we use a Nystr\"om approximation of the MMD to design a computationally efficient and practical testing algorithm while preserving statistical guarantees. Our main result is a finite-sample bound on the power of the proposed test for distributions that are sufficiently separated with respect to the MMD. The derived separation rate matches the known minimax optimal rate in this setting. We support our findings with a series of numerical experiments, emphasizing realistic scientific data.</description>
      <guid isPermaLink="false">oai:arXiv.org:2502.13570v1</guid>
      <category>stat.ML</category>
      <category>cs.LG</category>
      <category>math.ST</category>
      <category>stat.ME</category>
      <category>stat.TH</category>
      <pubDate>Thu, 20 Feb 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Antoine Chatalic, Marco Letizia, Nicolas Schreuder, and Lorenzo Rosasco</dc:creator>
    </item>
    <item>
      <title>Reverse Markov Learning: Multi-Step Generative Models for Complex Distributions</title>
      <link>https://arxiv.org/abs/2502.13747</link>
      <description>arXiv:2502.13747v1 Announce Type: cross 
Abstract: Learning complex distributions is a fundamental challenge in contemporary applications. Generative models, such as diffusion models, have demonstrated remarkable success in overcoming many limitations of traditional statistical methods. Shen and Meinshausen (2024) introduced engression, a generative approach based on scoring rules that maps noise (and covariates, if available) directly to data. While effective, engression struggles with highly complex distributions, such as those encountered in image data. In this work, we extend engression to improve its capability in learning complex distributions. We propose a framework that defines a general forward process transitioning from the target distribution to a known distribution (e.g., Gaussian) and then learns a reverse Markov process using multiple engression models. This reverse process reconstructs the target distribution step by step. Our approach supports general forward processes, allows for dimension reduction, and naturally discretizes the generative process. As a special case, when using a diffusion-based forward process, our framework offers a method to discretize the training and inference of diffusion models efficiently. Empirical evaluations on simulated and climate data validate our theoretical insights, demonstrating the effectiveness of our approach in capturing complex distributions.</description>
      <guid isPermaLink="false">oai:arXiv.org:2502.13747v1</guid>
      <category>cs.LG</category>
      <category>stat.ME</category>
      <category>stat.ML</category>
      <pubDate>Thu, 20 Feb 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Xinwei Shen, Nicolai Meinshausen, Tong Zhang</dc:creator>
    </item>
    <item>
      <title>Pareto optimal proxy metrics</title>
      <link>https://arxiv.org/abs/2307.01000</link>
      <description>arXiv:2307.01000v2 Announce Type: replace 
Abstract: North star metrics and online experimentation play a central role in how technology companies improve their products. In many practical settings, however, evaluating experiments based on the north star metric directly can be difficult. The two most significant issues are 1) low sensitivity of the north star metric and 2) differences between the short-term and long-term impact on the north star metric. A common solution is to rely on proxy metrics rather than the north star in experiment evaluation and launch decisions. Existing literature on proxy metrics concentrates mainly on the estimation of the long-term impact from short-term experimental data. In this paper, instead, we focus on the trade-off between the estimation of the long-term impact and the sensitivity in the short term. In particular, we propose the Pareto optimal proxy metrics method, which simultaneously optimizes prediction accuracy and sensitivity. In addition, we give an efficient multi-objective optimization algorithm that outperforms standard methods. We applied our methodology to experiments from a large industrial recommendation system, and found proxy metrics that are eight times more sensitive than the north star and consistently moved in the same direction, increasing the velocity and the quality of the decisions to launch new features.</description>
      <guid isPermaLink="false">oai:arXiv.org:2307.01000v2</guid>
      <category>stat.ME</category>
      <category>cs.LG</category>
      <pubDate>Thu, 20 Feb 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Alessandro Zito, Dylan Greaves, Jacopo Soriano, Lee Richardson</dc:creator>
    </item>
    <item>
      <title>Deep mixture of linear mixed models for complex longitudinal data</title>
      <link>https://arxiv.org/abs/2311.07156</link>
      <description>arXiv:2311.07156v2 Announce Type: replace 
Abstract: Mixtures of linear mixed models are widely used for modelling longitudinal data for which observation times differ between subjects. In typical applications, temporal trends are described using a basis expansion, with basis coefficients treated as random effects varying by subject. Additional random effects can describe variation between mixture components, or other known sources of variation in complex experimental designs. A key advantage of these models is that they provide a natural mechanism for clustering, which can be helpful for interpretation in many applications. Current versions of mixtures of linear mixed models are not specifically designed for the case where there are many observations per subject and a complex temporal trend, which requires a large number of basis functions to capture. In this case, the subject-specific basis coefficients are a high-dimensional random effects vector, for which the covariance matrix is hard to specify and estimate, especially if it varies between mixture components. To address this issue, we consider the use of recently-developed deep mixture of factor analyzers models as the prior for the random effects. The resulting deep mixture of linear mixed models is well-suited to high-dimensional settings, and we describe an efficient variational inference approach to posterior computation. The efficacy of the method is demonstrated on both real and simulated data.</description>
      <guid isPermaLink="false">oai:arXiv.org:2311.07156v2</guid>
      <category>stat.ME</category>
      <category>stat.AP</category>
      <pubDate>Thu, 20 Feb 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Lucas Kock, Nadja Klein, David J. Nott</dc:creator>
    </item>
    <item>
      <title>Statistical inference for high-dimensional convoluted rank regression</title>
      <link>https://arxiv.org/abs/2405.14652</link>
      <description>arXiv:2405.14652v2 Announce Type: replace 
Abstract: High-dimensional penalized rank regression is a powerful tool for modeling high-dimensional data due to its robustness and estimation efficiency. However, the non-smoothness of the rank loss brings great challenges to the computation. To solve this critical issue, high-dimensional convoluted rank regression has been recently proposed, introducing penalized convoluted rank regression estimators. However, these developed estimators cannot be directly used to make inference. In this paper, we investigate the statistical inference problem of high-dimensional convoluted rank regression. The use of U-statistic in convoluted rank loss function presents challenges for the analysis. We begin by establishing estimation error bounds of the penalized convoluted rank regression estimators under weaker conditions on the predictors. Building on this, we further introduce a debiased estimator and provide its Bahadur representation. Subsequently, a high-dimensional Gaussian approximation for the maximum deviation of the debiased estimator is derived, which allows us to construct simultaneous confidence intervals. For implementation, a novel bootstrap procedure is proposed and its theoretical validity is also established. Finally, simulation and real data analysis are conducted to illustrate the merits of our proposed methods.</description>
      <guid isPermaLink="false">oai:arXiv.org:2405.14652v2</guid>
      <category>stat.ME</category>
      <pubDate>Thu, 20 Feb 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Leheng Cai, Xu Guo, Heng Lian, Liping Zhu</dc:creator>
    </item>
    <item>
      <title>On estimation and order selection for multivariate extremes via clustering</title>
      <link>https://arxiv.org/abs/2406.14535</link>
      <description>arXiv:2406.14535v4 Announce Type: replace 
Abstract: We investigate the estimation of multivariate extreme models with a discrete spectral measure using spherical clustering techniques. The primary contribution involves devising a method for selecting the order, that is, the number of clusters. The method consistently identifies the true order, i.e., the number of spectral atoms, and enjoys intuitive implementation in practice. Specifically, we introduce an extra penalty term to the well-known simplified average silhouette width, which penalizes small cluster sizes and small dissimilarities between cluster centers. Consequently, we provide a consistent method for determining the order of a max-linear factor model, where a typical information-based approach is not viable. Our second contribution is a large-deviation-type analysis for estimating the discrete spectral measure through clustering methods, which serves as an assessment of the convergence quality of clustering-based estimation for multivariate extremes. Additionally, as a third contribution, we discuss how estimating the discrete measure can lead to parameter estimations of heavy-tailed factor models. We also present simulations and real-data studies that demonstrate order selection and factor model estimation.</description>
      <guid isPermaLink="false">oai:arXiv.org:2406.14535v4</guid>
      <category>stat.ME</category>
      <category>math.ST</category>
      <category>stat.TH</category>
      <pubDate>Thu, 20 Feb 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Shiyuan Deng, He Tang, Shuyang Bai</dc:creator>
    </item>
    <item>
      <title>Finite population inference for skewness measures</title>
      <link>https://arxiv.org/abs/2411.18549</link>
      <description>arXiv:2411.18549v3 Announce Type: replace 
Abstract: In this article we consider Bowley's skewness measure and the Groeneveld-Meeden $b_{3}$ index in the context of finite population sampling. We employ the functional delta method to obtain asymptotic variance formulae for plug-in estimators and propose corresponding variance estimators. We then consider plug-in estimators based on the H\'{a}jek cdf-estimator and on a Deville-S\"arndal type calibration estimator and test the performance of normal confidence intervals.</description>
      <guid isPermaLink="false">oai:arXiv.org:2411.18549v3</guid>
      <category>stat.ME</category>
      <pubDate>Thu, 20 Feb 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Leo Pasquazzi</dc:creator>
    </item>
    <item>
      <title>Univariate-Guided Sparse Regression</title>
      <link>https://arxiv.org/abs/2501.18360</link>
      <description>arXiv:2501.18360v5 Announce Type: replace 
Abstract: In this paper, we introduce ``UniLasso'' -- a novel statistical method for sparse regression. This two-stage approach preserves the signs of the univariate coefficients and leverages their magnitude. Both of these properties are attractive for stability and interpretation of the model. Through comprehensive simulations and applications to real-world datasets, we demonstrate that UniLasso outperforms Lasso in various settings, particularly in terms of sparsity and model interpretability. We prove asymptotic support recovery and mean-squared error consistency under a set of conditions different from the well-known irrepresentability conditions for the Lasso. Extensions to generalized linear models (GLMs) and Cox regression are also discussed.</description>
      <guid isPermaLink="false">oai:arXiv.org:2501.18360v5</guid>
      <category>stat.ME</category>
      <pubDate>Thu, 20 Feb 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Sourav Chatterjee, Trevor Hastie, Robert Tibshirani</dc:creator>
    </item>
    <item>
      <title>Causal Temporal Regime Structure Learning</title>
      <link>https://arxiv.org/abs/2311.01412</link>
      <description>arXiv:2311.01412v3 Announce Type: replace-cross 
Abstract: Understanding causal relationships in multivariate time series is essential for predicting and controlling dynamic systems in fields like economics, neuroscience, and climate science. However, existing causal discovery methods often assume stationarity, limiting their effectiveness when time series consist of sequential regimes, consecutive temporal segments with unknown boundaries and changing causal structures. In this work, we firstly introduce a framework to describe and model such time series. Then, we present CASTOR, a novel method that concurrently learns the Directed Acyclic Graph (DAG) for each regime while determining the number of regimes and their sequential arrangement. CASTOR optimizes the data log-likelihood using an expectation-maximization algorithm, alternating between assigning regime indices (expectation step) and inferring causal relationships in each regime (maximization step). We establish the identifiability of the regimes and DAGs within our framework. Extensive experiments show that CASTOR consistently outperforms existing causal discovery models in detecting different regimes and learning their DAGs across various settings, including linear and nonlinear causal relationships, on both synthetic and real world datasets.</description>
      <guid isPermaLink="false">oai:arXiv.org:2311.01412v3</guid>
      <category>cs.LG</category>
      <category>cs.AI</category>
      <category>stat.ME</category>
      <pubDate>Thu, 20 Feb 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <arxiv:journal_reference>Proceedings of the 28th International Conference on Artificial Intelligence and Statistics (AISTATS) 2025, Mai Khao, Thailand. PMLR: Volume 258. Copyright 2025 by the author(s)</arxiv:journal_reference>
      <dc:creator>Abdellah Rahmani, Pascal Frossard</dc:creator>
    </item>
    <item>
      <title>A Novel Constrained Sampling Method for Efficient Exploration in Materials and Chemical Mixture Design</title>
      <link>https://arxiv.org/abs/2407.16567</link>
      <description>arXiv:2407.16567v3 Announce Type: replace-cross 
Abstract: Efficient exploration of multicomponent material composition spaces is often limited by time and financial constraints, particularly when mixture and synthesis constraints exist. Traditional methods like Latin hypercube sampling (LHS) struggle with constrained problems especially in high dimensions, while emerging approaches like Bayesian optimization (BO) face challenges in early-stage exploration. This article introduces ConstrAined Sequential laTin hypeRcube sampling methOd (CASTRO), an open-source tool designed to address these challenges. CASTRO is optimized for uniform sampling in constrained small- to moderate-dimensional spaces, with scalability to higher dimensions through future adaptations. CASTRO uses a divide-and-conquer strategy to decompose problems into parallel subproblems, improving efficiency and scalability. It effectively handles equality-mixture constraints, ensuring comprehensive design space coverage and leveraging LHS and LHS with multidimensional uniformity (LHSMDU). It also integrates prior experimental knowledge, making it well-suited for efficient exploration within limited budgets. Validation through two material design case studies, a four-dimensional problem with near-uniform distributions and a nine-dimensional problem with additional synthesis constraints, demonstrates CASTRO's effectiveness in exploring constrained design spaces for materials science, pharmaceuticals and chemicals. The software and case studies are available on GitHub.</description>
      <guid isPermaLink="false">oai:arXiv.org:2407.16567v3</guid>
      <category>stat.CO</category>
      <category>cond-mat.mtrl-sci</category>
      <category>physics.data-an</category>
      <category>stat.AP</category>
      <category>stat.ME</category>
      <pubDate>Thu, 20 Feb 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Christina Schenk, Maciej Haranczyk</dc:creator>
    </item>
    <item>
      <title>Comment on "Sequential validation of treatment heterogeneity" and "Comment on generic machine learning inference on heterogeneous treatment effects in randomized experiments"</title>
      <link>https://arxiv.org/abs/2502.01548</link>
      <description>arXiv:2502.01548v2 Announce Type: replace-cross 
Abstract: We warmly thank Kosuke Imai, Michael Lingzhi Li, and Stefan Wager for their gracious and insightful comments. We are particularly encouraged that both pieces recognize the importance of the research agenda the lecture laid out, which we see as critical for applied researchers. It is also great to see that both underscore the potential of the basic approach we propose - targeting summary features of the CATE after proxy estimation with sample splitting. We are also happy that both papers push us (and the reader) to continue thinking about the inference problem associated with sample splitting. We recognize that our current paper is only scratching the surface of this interesting agenda. Our proposal is certainly not the only option, and it is exciting that both papers provide and assess alternatives. Hopefully, this will generate even more work in this area.</description>
      <guid isPermaLink="false">oai:arXiv.org:2502.01548v2</guid>
      <category>econ.EM</category>
      <category>stat.ME</category>
      <pubDate>Thu, 20 Feb 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Victor Chernozhukov, Mert Demirer, Esther Duflo, Iv\'an Fern\'andez-Val</dc:creator>
    </item>
  </channel>
</rss>
