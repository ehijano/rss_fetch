<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>cs.GT updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/cs.GT</link>
    <description>cs.GT updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/cs.GT" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Fri, 05 Sep 2025 04:01:04 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Fri, 05 Sep 2025 00:00:00 -0400</pubDate>
    <skipDays>
      <day>Sunday</day>
      <day>Saturday</day>
    </skipDays>
    <item>
      <title>The evolution of trust as a cognitive shortcut in repeated interactions</title>
      <link>https://arxiv.org/abs/2509.04143</link>
      <description>arXiv:2509.04143v1 Announce Type: new 
Abstract: Trust is often thought to increase cooperation. However, game-theoretic models often fail to distinguish between cooperative behaviour and trust. This makes it difficult to measure trust and determine its effect in different social dilemmas. We address this here by formalising trust as a cognitive shortcut in repeated games. This functions by avoiding checking a partner's actions once a threshold level of cooperativeness has been observed. We consider trust-based strategies that implement this heuristic, and systematically analyse their evolution across the space of two-player symmetric social dilemma games. We find that where it is costly to check whether another agent's actions were cooperative, as is the case in many real-world settings, then trust-based strategies can outcompete standard reciprocal strategies such as Tit-for-Tat in many social dilemmas. Moreover, the presence of trust increases the overall level of cooperation in the population, especially in cases where agents can make unintentional errors in their actions. This occurs even in the presence of strategies designed to build and then exploit trust. Overall, our results demonstrate the individual adaptive benefit to an agent of using a trust heuristic, and provide a formal theory for how trust can promote cooperation in different types of social interaction. We discuss the implications of this for interactions between humans and artificial intelligence agents.</description>
      <guid isPermaLink="false">oai:arXiv.org:2509.04143v1</guid>
      <category>cs.GT</category>
      <pubDate>Fri, 05 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Cedric Perret, The Anh Han, Elias Fern\'andez Domingos, Theodor Cimpeanu, Simon T. Powers</dc:creator>
    </item>
    <item>
      <title>Evolutionary dynamics under coordinated reciprocity</title>
      <link>https://arxiv.org/abs/2509.03524</link>
      <description>arXiv:2509.03524v1 Announce Type: cross 
Abstract: Using past behaviors to guide future actions is essential for fostering cooperation in repeated social dilemmas. Traditional memory-based strategies that focus on recent interactions have yielded valuable insights into the evolution of cooperative behavior. However, as memory length increases, the complexity of analysis grows exponentially, since these strategies need to map every possible action sequence of a given length to subsequent responses. Due to their inherent reliance on exhaustive mapping and a lack of explicit information processing, it remains unclear how individuals can handle extensive interaction histories to make decisions under cognitive constraints. To fill this gap, we introduce coordinated reciprocity strategies ($CORE$), which incrementally evaluate the entire game history by tallying instances of consistent actions between individuals without storing round-to-round details. Once this consistency index surpasses a threshold, $CORE$ prescribes cooperation. Through equilibrium analysis, we derive an analytical condition under which $CORE$ constitutes an equilibrium. Moreover, our numerical results show that $CORE$ effectively promotes cooperation between variants of itself, and it outperforms a range of existing strategies including memory-$1$, memory-$2$, and those from a documented strategy library in evolutionary dynamics. Our work thus underscores the pivotal role of cumulative action consistency in enhancing cooperation, developing robust strategies, and offering cognitively low-burden information processing mechanisms in repeated social dilemmas.</description>
      <guid isPermaLink="false">oai:arXiv.org:2509.03524v1</guid>
      <category>q-bio.PE</category>
      <category>cs.GT</category>
      <pubDate>Fri, 05 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Feipeng Zhang, Bingxin Lin, Lei Zhou, Long Wang</dc:creator>
    </item>
    <item>
      <title>From Leiden to Pleasure Island: The Constant Potts Model for Community Detection as a Hedonic Game</title>
      <link>https://arxiv.org/abs/2509.03834</link>
      <description>arXiv:2509.03834v1 Announce Type: cross 
Abstract: Community detection is one of the fundamental problems in data science which consists of partitioning nodes into disjoint communities. We present a game-theoretic perspective on the Constant Potts Model (CPM) for partitioning networks into disjoint communities, emphasizing its efficiency, robustness, and accuracy. Efficiency: We reinterpret CPM as a potential hedonic game by decomposing its global Hamiltonian into local utility functions, where the local utility gain of each agent matches the corresponding increase in global utility. Leveraging this equivalence, we prove that local optimization of the CPM objective via better-response dynamics converges in pseudo-polynomial time to an equilibrium partition. Robustness: We introduce and relate two stability criteria: a strict criterion based on a novel notion of robustness, requiring nodes to simultaneously maximize neighbors and minimize non-neighbors within communities, and a relaxed utility function based on a weighted sum of these objectives, controlled by a resolution parameter. Accuracy: In community tracking scenarios, where initial partitions are used to bootstrap the Leiden algorithm with partial ground-truth information, our experiments reveal that robust partitions yield higher accuracy in recovering ground-truth communities.</description>
      <guid isPermaLink="false">oai:arXiv.org:2509.03834v1</guid>
      <category>cs.LG</category>
      <category>cs.AI</category>
      <category>cs.GT</category>
      <pubDate>Fri, 05 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Lucas Lopes Felipe, Konstantin Avrachenkov, Daniel Sadoc Menasche</dc:creator>
    </item>
    <item>
      <title>Meta-Inverse Reinforcement Learning for Mean Field Games via Probabilistic Context Variables</title>
      <link>https://arxiv.org/abs/2509.03845</link>
      <description>arXiv:2509.03845v1 Announce Type: cross 
Abstract: Designing suitable reward functions for numerous interacting intelligent agents is challenging in real-world applications. Inverse reinforcement learning (IRL) in mean field games (MFGs) offers a practical framework to infer reward functions from expert demonstrations. While promising, the assumption of agent homogeneity limits the capability of existing methods to handle demonstrations with heterogeneous and unknown objectives, which are common in practice. To this end, we propose a deep latent variable MFG model and an associated IRL method. Critically, our method can infer rewards from different yet structurally similar tasks without prior knowledge about underlying contexts or modifying the MFG model itself. Our experiments, conducted on simulated scenarios and a real-world spatial taxi-ride pricing problem, demonstrate the superiority of our approach over state-of-the-art IRL methods in MFGs.</description>
      <guid isPermaLink="false">oai:arXiv.org:2509.03845v1</guid>
      <category>cs.LG</category>
      <category>cs.AI</category>
      <category>cs.GT</category>
      <pubDate>Fri, 05 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Yang Chen, Xiao Lin, Bo Yan, Libo Zhang, Jiamou Liu, Neset \"Ozkan Tan, Michael Witbrock</dc:creator>
    </item>
    <item>
      <title>Solving Zero-Sum Games with Fewer Matrix-Vector Products</title>
      <link>https://arxiv.org/abs/2509.04426</link>
      <description>arXiv:2509.04426v1 Announce Type: cross 
Abstract: In this paper we consider the problem of computing an $\epsilon$-approximate Nash Equilibrium of a zero-sum game in a payoff matrix $A \in \mathbb{R}^{m \times n}$ with $O(1)$-bounded entries given access to a matrix-vector product oracle for $A$ and its transpose $A^\top$. We provide a deterministic algorithm that solves the problem using $\tilde{O}(\epsilon^{-8/9})$-oracle queries, where $\tilde{O}(\cdot)$ hides factors polylogarithmic in $m$, $n$, and $\epsilon^{-1}$. Our result improves upon the state-of-the-art query complexity of $\tilde{O}(\epsilon^{-1})$ established by [Nemirovski, 2004] and [Nesterov, 2005]. We obtain this result through a general framework that yields improved deterministic query complexities for solving a broader class of minimax optimization problems which includes computing a linear classifier (hard-margin support vector machine) as well as linear regression.</description>
      <guid isPermaLink="false">oai:arXiv.org:2509.04426v1</guid>
      <category>math.OC</category>
      <category>cs.DS</category>
      <category>cs.GT</category>
      <pubDate>Fri, 05 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Ishani Karmarkar, Liam O'Carroll, Aaron Sidford</dc:creator>
    </item>
    <item>
      <title>Elastic Restaking Networks</title>
      <link>https://arxiv.org/abs/2503.00170</link>
      <description>arXiv:2503.00170v4 Announce Type: replace 
Abstract: Many blockchain-based decentralized services require their validators (operators) to deposit stake (collateral), which is forfeited (slashed) if they misbehave. Restaking networks let validators secure multiple services by reusing stake. These networks have quickly gained traction, leveraging over \$20 billion in stake. However, restaking introduces a new attack vector where validators can coordinate to misbehave across multiple services simultaneously, extracting digital assets while forfeiting their stake only once.
  Previous work focused either on preventing coordinated misbehavior or on protecting services if all other services are Byzantine and might unjustly cause slashing due to bugs or malice. The first model overlooks how a single Byzantine service can collapse the network, while the second ignores shared-stake benefits.
  To bridge the gap, we analyze the system as a strategic game of coordinated misbehavior, when a given fraction of the services are Byzantine. We introduce elastic restaking networks, where validators can allocate portions of their stake that may cumulatively exceed their total stake, and when allocations are lost, the remaining stake stretches to cover remaining allocations. We show that elastic networks exhibit superior robustness compared to previous approaches, and demonstrate a synergistic effect where an elastic restaking network enhances its blockchain's security, contrary to community concerns of an opposite effect in existing networks. We then design incentives for tuning validators' allocations.
  Our elastic restaking system and incentive design have immediate practical implications for deployed restaking networks.</description>
      <guid isPermaLink="false">oai:arXiv.org:2503.00170v4</guid>
      <category>cs.GT</category>
      <category>cs.DC</category>
      <pubDate>Fri, 05 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Roi Bar-Zur, Ittay Eyal</dc:creator>
    </item>
    <item>
      <title>A Strongly Polynomial-Time Combinatorial Algorithm for the Nucleolus in Convex Games</title>
      <link>https://arxiv.org/abs/2509.02380</link>
      <description>arXiv:2509.02380v2 Announce Type: replace 
Abstract: The nucleolus is a fundamental solution concept in cooperative game theory, yet computing it is NP-hard in general. In convex games-where players' marginal contributions grow with coalition size-the only existing polynomial-time algorithm relies on the ellipsoid method. We re-examine a reduced game approach, refuting a previously claimed polynomial-time implementation and clarifying why it fails. By developing new algorithmic ideas and exploiting the structure of least core polyhedra, we show that reduced games can in fact be used effectively. This yields the first combinatorial and strongly polynomial algorithm for computing the nucleolus in convex games.</description>
      <guid isPermaLink="false">oai:arXiv.org:2509.02380v2</guid>
      <category>cs.GT</category>
      <pubDate>Fri, 05 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Giacomo Maggiorano, Alessandro Sosso, Gautier Stauffer</dc:creator>
    </item>
    <item>
      <title>Co-Investment with Payoff-Sharing Mechanism for Cooperative Decision-Making in Network Design Games</title>
      <link>https://arxiv.org/abs/2508.12059</link>
      <description>arXiv:2508.12059v3 Announce Type: replace-cross 
Abstract: Network-based systems are inherently interconnected, with the design and performance of subnetworks being interdependent. However, the decisions of self-interested operators may lead to suboptimal outcomes for users and the overall system. This paper explores cooperative mechanisms that can simultaneously benefit both operators and users. We address this challenge using a game-theoretical framework that integrates both non-cooperative and cooperative game theory. In the non-cooperative stage, we propose a network design game in which subnetwork decision-makers strategically design local infrastructures. In the cooperative stage, co-investment with payoff-sharing mechanism is developed to enlarge collective benefits and fairly distribute them. To demonstrate the effectiveness of our framework, we conduct case studies on the Sioux Falls network and real-world public transport networks in Zurich and Winterthur, Switzerland. Our evaluation considers impacts on environmental sustainability, social welfare, and economic efficiency. The proposed framework provides a foundation for improving interdependent networked systems by enabling strategic cooperation among self-interested operators.</description>
      <guid isPermaLink="false">oai:arXiv.org:2508.12059v3</guid>
      <category>eess.SY</category>
      <category>cs.GT</category>
      <category>cs.SY</category>
      <pubDate>Fri, 05 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Mingjia He, Andrea Censi, Emilio Frazzoli, Gioele Zardini</dc:creator>
    </item>
  </channel>
</rss>
