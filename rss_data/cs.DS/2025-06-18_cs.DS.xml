<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>cs.DS updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/cs.DS</link>
    <description>cs.DS updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/cs.DS" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Wed, 18 Jun 2025 04:00:10 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Wed, 18 Jun 2025 00:00:00 -0400</pubDate>
    <skipDays>
      <day>Saturday</day>
      <day>Sunday</day>
    </skipDays>
    <item>
      <title>Spectral partitioning of graphs into compact, connected regions</title>
      <link>https://arxiv.org/abs/2506.13982</link>
      <description>arXiv:2506.13982v1 Announce Type: new 
Abstract: We define and study a spectral recombination algorithm, SpecReCom, for partitioning a graph into a given number of connected parts. It is straightforward to introduce additional constraints such as the requirement that the weight (or number of vertices) in each part is approximately balanced, and we exemplify this by stating a variant, BalSpecReCom, of the SpecReCom algorithm. We provide empirical evidence that the algorithm achieves more compact partitions than alternatives such as RevReCom by studying a $56\times 56$ grid graph and a planar graph obtained from the state of Colorado.</description>
      <guid isPermaLink="false">oai:arXiv.org:2506.13982v1</guid>
      <category>cs.DS</category>
      <category>physics.soc-ph</category>
      <pubDate>Wed, 18 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Ewan Davies, Ryan Job, Maxine Kampbell, Hannah Kim, Hyojin Seo</dc:creator>
    </item>
    <item>
      <title>glass: ordered set data structure for client-side order books</title>
      <link>https://arxiv.org/abs/2506.13991</link>
      <description>arXiv:2506.13991v1 Announce Type: new 
Abstract: The "ordered set" abstract data type with operations "insert", "erase", "find", "min", "max", "next" and "prev" is ubiquitous in computer science. It is usually implemented with red-black trees, $B$-trees, or $B^+$-trees. We present our implementation of ordered set based on a trie. It only supports integer keys (as opposed to keys of any strict weakly ordered type) and is optimized for market data, namely for what we call sequential locality. The following is the list of what we believe to be novelties:
  * Cached path to exploit sequential locality, and fast truncation thereof on erase operation;
  * A hash table (or, rather, a cache table) with hard O(1) time guarantees on any operation to speed up key lookup (up to a pre-leaf node);
  * Hardware-accelerated "find next/previous set bit" operations with BMI2 instruction set extension on x86-64;
  * Order book-specific features: the preemption principle and the tree restructure operation that prevent the tree from consuming too much memory.
  We achieve the following speedups over C++'s standard std::map container: 6x-20x on modifying operations, 30x on lookup operations, 9x-15x on real market data, and a more modest 2x-3x speedup on iteration. In this paper, we discuss our implementation.</description>
      <guid isPermaLink="false">oai:arXiv.org:2506.13991v1</guid>
      <category>cs.DS</category>
      <pubDate>Wed, 18 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Viktor Krapivensky</dc:creator>
    </item>
    <item>
      <title>An Exact and Efficient Sampler for Dynamic Discrete Distributions</title>
      <link>https://arxiv.org/abs/2506.14062</link>
      <description>arXiv:2506.14062v1 Announce Type: new 
Abstract: Sampling from a dynamic discrete distribution involves sampling from a dynamic set of weighted elements, where elements can be added or removed at any stage of the sampling process. Although efficient for static sets, the Alias method becomes impractical in dynamic settings due to the need to reconstruct the sampler after each update, which incurs a computational cost proportional to the size of the distribution, making it unsuitable for applications requiring frequent insertions, deletions, or weight adjustments. To address this limitation, different approaches have been studied, such as the Forest of Trees method and the BUcket Sampling (BUS) method. However, all previous methods suffered from numerical issues which can bias the sampling process. In this paper, we describe EBUS (Exact BUcket Sampling), the first exact algorithm with $O(1)$ sampling and update cost. The sampler can be updated by base-$b$ numbers with bounded precision and exponent, and sample the distribution of its elements exactly and efficiently. We provide also a state of the art implementation of the method using IEEE 64-bit floating point numbers which we empirically show to be more efficient than several implementations of previous inexact methods.</description>
      <guid isPermaLink="false">oai:arXiv.org:2506.14062v1</guid>
      <category>cs.DS</category>
      <category>math.PR</category>
      <category>stat.CO</category>
      <pubDate>Wed, 18 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Lilith Orion Hafner, Adriano Meligrana</dc:creator>
    </item>
    <item>
      <title>Simpler, Better, Faster, Stronger: Revisiting a Successful Reduction Rule for Dominating Set</title>
      <link>https://arxiv.org/abs/2506.14564</link>
      <description>arXiv:2506.14564v1 Announce Type: new 
Abstract: DominatingSet is a classical NP-complete problem and also known to be W[2]-hard. Thus, there is little hope for small kernels on general graphs. However, in practice, reduction rules to heuristically shrink instances are used. In this context, Rule1 by Alber et. al. is quite successful, yet at times somewhat expensive to execute. We propose a linear time algorithm implementing and surpassing the original Rule1 formulation. Our discussions and proofs yield interesting structural insights into the reduction rule and its interplay with the DominatingSet problem. For instance, while the original formulation warrants repeated invocations of an $\mathcal{O}(n^3)$ time algorithm, we recast it to allow a single search run in linear time. Then, we propose simple, but practically significant, extensions to our algorithmic framework to prune the graph even further. The algorithm is easy to implement and highly practical.</description>
      <guid isPermaLink="false">oai:arXiv.org:2506.14564v1</guid>
      <category>cs.DS</category>
      <pubDate>Wed, 18 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Lukas Geis, Alexander Leonhardt, Johannes Meintrup, Ulrich Meyer, Manuel Penschuck</dc:creator>
    </item>
    <item>
      <title>Compressing Suffix Trees by Path Decompositions</title>
      <link>https://arxiv.org/abs/2506.14734</link>
      <description>arXiv:2506.14734v1 Announce Type: new 
Abstract: In classic suffix trees, path compression works by replacing unary suffix trie paths with pairs of pointers to $T$, which must be available in the form of some random access oracle at query time. In this paper, we revisit path compression and show that a more careful choice of pointers leads to a new elegant, simple, and remarkably efficient way to compress the suffix tree. We begin by observing that an alternative way to path-compress the suffix trie of $T$ is to decompose it into a set of (disjoint) node-to-leaf paths and then represent each path as a pointer $i$ to one of the string's suffixes $T[i,n]$. At this point, we show that the array $A$ of such indices $i$, sorted by the colexicographic order of the corresponding text prefixes $T[1,i]$, possesses the following properties: (i) it supports \emph{cache-efficient} pattern matching queries via simple binary search on $A$ and random access on $T$, and (ii) it contains a number of entries being proportional to the size of the \emph{compressed text}. Of particular interest is the path decomposition given by the colexicographic rank of $T$'s prefixes. The resulting index is smaller and orders of magnitude faster than the $r$-index on the task of locating all occurrences of a query pattern.</description>
      <guid isPermaLink="false">oai:arXiv.org:2506.14734v1</guid>
      <category>cs.DS</category>
      <pubDate>Wed, 18 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Ruben Becker, Davide Cenzato, Travis Gagie, Sung-Hwan Kim, Ragnar Groot Koerkamp, Giovanni Manzini, Nicola Prezza</dc:creator>
    </item>
    <item>
      <title>Asymptotically Smaller Encodings for Graph Problems and Scheduling</title>
      <link>https://arxiv.org/abs/2506.14042</link>
      <description>arXiv:2506.14042v1 Announce Type: cross 
Abstract: We show how several graph problems (e.g., vertex-cover, independent-set, $k$-coloring) can be encoded into CNF using only $O(|V|^2 / \lg |V|)$ many clauses, as opposed to the $\Omega(|V|^2)$ constraints used by standard encodings. This somewhat surprising result is a simple consequence of a result of Erd\H{o}s, Chung, and Spencer (1983) about biclique coverings of graphs, and opens theoretical avenues to understand the success of "Bounded Variable Addition'' (Manthey, Heule, and Biere, 2012) as a preprocessing tool. Finally, we show a novel encoding for independent sets in some dense interval graphs using only $O(|V| \lg |V|)$ clauses (the direct encoding uses $\Omega(|V|^2)$), which we have successfully applied to a string-compression encoding posed by Bannai et al. (2022). As a direct byproduct, we obtain a reduction in the encoding size of a scheduling problem posed by Mayank and Modal (2020) from $O(NMT^2)$ to $O(NMT + M T^2 \lg T)$, where $N$ is the number of tasks, $T$ the total timespan, and $M$ the number of machines.</description>
      <guid isPermaLink="false">oai:arXiv.org:2506.14042v1</guid>
      <category>cs.LO</category>
      <category>cs.AI</category>
      <category>cs.DS</category>
      <pubDate>Wed, 18 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Bernardo Subercaseaux</dc:creator>
    </item>
    <item>
      <title>The Complexity of Counting Small Sub-Hypergraphs</title>
      <link>https://arxiv.org/abs/2506.14081</link>
      <description>arXiv:2506.14081v1 Announce Type: cross 
Abstract: Subgraph counting is a fundamental and well-studied problem whose computational complexity is well understood. Quite surprisingly, the hypergraph version of subgraph counting has been almost ignored. In this work, we address this gap by investigating the most basic sub-hypergraph counting problem: given a (small) hypergraph $H$ and a (large) hypergraph $G$, compute the number of sub-hypergraphs of $G$ isomorphic to $H$. Formally, for a family $\mathcal{H}$ of hypergraphs, let #Sub($\mathcal{H}$) be the restriction of the problem to $H \in \mathcal{H}$; the induced variant #IndSub($\mathcal{H}$) is defined analogously. Our main contribution is a complete classification of the complexity of these problems. Assuming the Exponential Time Hypothesis, we prove that #Sub($\mathcal{H}$) is fixed-parameter tractable if and only if $\mathcal{H}$ has bounded fractional co-independent edge-cover number, a novel graph parameter we introduce. Moreover, #IndSub($\mathcal{H}$) is fixed-parameter tractable if and only if $\mathcal{H}$ has bounded fractional edge-cover number. Both results subsume pre-existing results for graphs as special cases. We also show that the fixed-parameter tractable cases of #Sub($\mathcal{H}$) and #IndSub($\mathcal{H}$) are unlikely to be in polynomial time, unless respectively #P = P and Graph Isomorphism $\in$ P. This shows a separation with the special case of graphs, where the fixed-parameter tractable cases are known to actually be in polynomial time.</description>
      <guid isPermaLink="false">oai:arXiv.org:2506.14081v1</guid>
      <category>cs.CC</category>
      <category>cs.DS</category>
      <pubDate>Wed, 18 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Marco Bressan, Julian Brinkmann, Holger Dell, Marc Roth, Philip Wellnitz</dc:creator>
    </item>
    <item>
      <title>FLASH-TB: Integrating Arc-Flags and Trip-Based Public Transit Routing</title>
      <link>https://arxiv.org/abs/2312.13146</link>
      <description>arXiv:2312.13146v3 Announce Type: replace 
Abstract: We present FLASH-TB, a journey planning algorithm for public transit networks that combines Trip-Based Public Transit Routing (TB) with the Arc-Flags speedup technique. The basic idea is simple: The network is partitioned into a configurable number of cells. For each cell and each possible transfer between two vehicles, the algorithm precomputes a flag that indicates whether the transfer is required to reach the cell. During a query, only flagged transfers are explored. Our algorithm improves upon previous attempts to apply Arc-Flags to public transit networks, which saw limited success due to conflicting rules for pruning the search space. We show that these rules can be reconciled while still producing correct results. Because the number of cells is configurable, FLASH-TB offers a tradeoff between query time and memory consumption. It is significantly more space-efficient than existing techniques with a comparable preprocessing time, which store generalized shortest-path trees: to match their query performance, it requires up to two orders of magnitude less memory. The fastest configuration of FLASH-TB achieves a speedup of more than two orders of magnitude over TB, offering sub-millisecond query times even on large countrywide networks.</description>
      <guid isPermaLink="false">oai:arXiv.org:2312.13146v3</guid>
      <category>cs.DS</category>
      <pubDate>Wed, 18 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Ernestine Gro{\ss}mann, Jonas Sauer, Christian Schulz, Patrick Steil, Sascha Witt</dc:creator>
    </item>
    <item>
      <title>Fine-grained Analysis and Faster Algorithms for Iteratively Solving Linear Systems</title>
      <link>https://arxiv.org/abs/2405.05818</link>
      <description>arXiv:2405.05818v2 Announce Type: replace 
Abstract: Despite being a key bottleneck in many machine learning tasks, the cost of solving large linear systems has proven challenging to quantify due to problem-dependent quantities such as condition numbers. To tackle this, we consider a fine-grained notion of complexity for solving linear systems, which is motivated by applications where the data exhibits low-dimensional structure, including spiked covariance models and kernel machines, and when the linear system is explicitly regularized, such as ridge regression. Concretely, let $\kappa_\ell$ be the ratio between the $\ell$th largest and the smallest singular value of $n\times n$ matrix $A$. We give a stochastic algorithm based on the Sketch-and-Project paradigm, that solves the linear system $Ax = b$, that is, finds $\bar{x}$ such that $\|A\bar{x} - b\| \le \epsilon \|b\|$, in time $\bar O(\kappa_\ell\cdot n^2\log 1/\epsilon)$, for any $\ell = O(n^{0.729})$. This is a direct improvement over preconditioned conjugate gradient, and it provides a stronger separation between stochastic linear solvers and algorithms accessing $A$ only through matrix-vector products. Our main technical contribution is the new analysis of the first and second moments of the random projection matrix that arises in Sketch-and-Project.</description>
      <guid isPermaLink="false">oai:arXiv.org:2405.05818v2</guid>
      <category>cs.DS</category>
      <category>cs.LG</category>
      <category>cs.NA</category>
      <category>math.NA</category>
      <category>math.OC</category>
      <pubDate>Wed, 18 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Micha{\l} Derezi\'nski, Daniel LeJeune, Deanna Needell, Elizaveta Rebrova</dc:creator>
    </item>
    <item>
      <title>UNIFY: Unified Index for Range Filtered Approximate Nearest Neighbors Search</title>
      <link>https://arxiv.org/abs/2412.02448</link>
      <description>arXiv:2412.02448v2 Announce Type: replace 
Abstract: This paper presents an efficient and scalable framework for Range Filtered Approximate Nearest Neighbors Search (RF-ANNS) over high-dimensional vectors associated with attribute values. Given a query vector $q$ and a range $[l, h]$, RF-ANNS aims to find the approximate $k$ nearest neighbors of $q$ among data whose attribute values fall within $[l, h]$. Existing methods including pre-, post-, and hybrid filtering strategies that perform attribute range filtering before, after, or during the ANNS process, all suffer from significant performance degradation when query ranges shift. Though building dedicated indexes for each strategy and selecting the best one based on the query range can address this problem, it leads to index consistency and maintenance issues.
  Our framework, called UNIFY, constructs a unified Proximity Graph-based (PG-based) index that seamlessly supports all three strategies. In UNIFY, we introduce SIG, a novel Segmented Inclusive Graph, which segments the dataset by attribute values. It ensures the PG of objects from any segment combinations is a sub-graph of SIG, thereby enabling efficient hybrid filtering by reconstructing and searching a PG from relevant segments. Moreover, we present Hierarchical Segmented Inclusive Graph (HSIG), a variant of SIG which incorporates a hierarchical structure inspired by HNSW to achieve logarithmic hybrid filtering complexity. We also implement pre- and post-filtering for HSIG by fusing skip list connections and compressed HNSW edges into the hierarchical graph. Experimental results show that UNIFY delivers state-of-the-art RF-ANNS performance across small, mid, and large query ranges.</description>
      <guid isPermaLink="false">oai:arXiv.org:2412.02448v2</guid>
      <category>cs.DS</category>
      <category>cs.DB</category>
      <pubDate>Wed, 18 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Anqi Liang, Pengcheng Zhang, Bin Yao, Zhongpu Chen, Yitong Song, Guangxu Cheng</dc:creator>
    </item>
    <item>
      <title>Parallel Greedy Best-First Search with a Bound on Expansions Relative to Sequential Search</title>
      <link>https://arxiv.org/abs/2412.12221</link>
      <description>arXiv:2412.12221v2 Announce Type: replace 
Abstract: Parallelization of non-admissible search algorithms such as GBFS poses a challenge because straightforward parallelization can result in search behavior which significantly deviates from sequential search. Previous work proposed PUHF, a parallel search algorithm which is constrained to only expand states that can be expanded by some tie-breaking strategy for GBFS. We show that despite this constraint, the number of states expanded by PUHF is not bounded by a constant multiple of the number of states expanded by sequential GBFS with the worst-case tie-breaking strategy. We propose and experimentally evaluate One Bench At a Time (OBAT), a parallel greedy search which guarantees that the number of states expanded is within a constant factor of the number of states expanded by sequential GBFS with some tie-breaking policy.</description>
      <guid isPermaLink="false">oai:arXiv.org:2412.12221v2</guid>
      <category>cs.DS</category>
      <category>cs.AI</category>
      <pubDate>Wed, 18 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Takumi Shimoda, Alex Fukunaga</dc:creator>
    </item>
    <item>
      <title>Practical colinear chaining on sequences revisited</title>
      <link>https://arxiv.org/abs/2506.11750</link>
      <description>arXiv:2506.11750v2 Announce Type: replace 
Abstract: Colinear chaining is a classical heuristic for sequence alignment and is widely used in modern practical aligners. Jain et al. (J. Comput. Biol. 2022) proposed an $O(n \log^3 n)$ time algorithm to chain a set of $n$ anchors so that the chaining cost matches the edit distance of the input sequences, when anchors are all the maximal exact matches. Moreover, assuming a uniform and sparse distribution of anchors, they provided a practical solution ($\mathtt{ChainX}$) working in $O(n \cdot \mathrm{SOL} + n \log n)$ average-case time, where $\mathrm{SOL}$ is the cost of the output chain. This practical solution is not guaranteed to be optimal: we study the failing cases, introduce the anchor diagonal distance, and find and implement an optimal algorithm working in $O(n \cdot \mathrm{OPT} + n \log n)$ average-case time, where $\mathrm{OPT}$ $\le \mathrm{SOL}$ is the optimal chaining cost. We validate the results by Jain et al., show that $\mathtt{ChainX}$ can be suboptimal with a realistic long read dataset, and show minimal computational slowdown for our solution.</description>
      <guid isPermaLink="false">oai:arXiv.org:2506.11750v2</guid>
      <category>cs.DS</category>
      <pubDate>Wed, 18 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Nicola Rizzo, Manuel C\'aceres, Veli M\"akinen</dc:creator>
    </item>
    <item>
      <title>Decoupling Generation and Evaluation for Parallel Greedy Best-First Search(extended version)</title>
      <link>https://arxiv.org/abs/2408.05682</link>
      <description>arXiv:2408.05682v2 Announce Type: replace-cross 
Abstract: In order to understand and control the search behavior of parallel search, recent work has proposed a class of constrained parallel greedy best-first search algorithms which only expands states that satisfy some constraint.However, enforcing such constraints can be costly, as threads must be waiting idly until a state that satisfies the expansion constraint is available. We propose an improvement to constrained parallel search which decouples state generation and state evaluation and significantly improves state evaluation rate, resulting in better search performance.</description>
      <guid isPermaLink="false">oai:arXiv.org:2408.05682v2</guid>
      <category>cs.AI</category>
      <category>cs.DC</category>
      <category>cs.DS</category>
      <pubDate>Wed, 18 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Takumi Shimoda, Alex Fukunaga</dc:creator>
    </item>
    <item>
      <title>Mildly-Interacting Fermionic Unitaries are Efficiently Learnable</title>
      <link>https://arxiv.org/abs/2504.11318</link>
      <description>arXiv:2504.11318v2 Announce Type: replace-cross 
Abstract: Recent work has shown that one can efficiently learn fermionic Gaussian unitaries, also commonly known as nearest-neighbor matchcircuits or non-interacting fermionic unitaries. However, one could ask a similar question about unitaries that are near Gaussian: for example, unitaries prepared with a small number of non-Gaussian circuit elements. These operators find significance in quantum chemistry and many-body physics, yet no algorithm exists to learn them.
  We give the first such result by devising an algorithm which makes queries to an $n$-mode fermionic unitary $U$ prepared by at most $O(t)$ non-Gaussian gates and returns a circuit approximating $U$ to diamond distance $\varepsilon$ in time $\textrm{poly}(n,2^t,1/\varepsilon)$. This resolves a central open question of Mele and Herasymenko under the strongest distance metric. In fact, our algorithm is much more general: we define a property of unitary Gaussianity known as unitary Gaussian dimension and show that our algorithm can learn $n$-mode unitaries of Gaussian dimension at least $2n - O(t)$ in time $\textrm{poly}(n,2^t,1/\varepsilon)$. Indeed, this class subsumes unitaries prepared by at most $O(t)$ non-Gaussian gates but also includes several unitaries that require up to $2^{O(t)}$ non-Gaussian gates to construct.
  In addition, we give a $\textrm{poly}(n,1/\varepsilon)$-time algorithm to distinguish whether an $n$-mode unitary is of Gaussian dimension at least $k$ or $\varepsilon$-far from all such unitaries in Frobenius distance, promised that one is the case. Along the way, we prove structural results about near-Gaussian fermionic unitaries that are likely to be of independent interest.</description>
      <guid isPermaLink="false">oai:arXiv.org:2504.11318v2</guid>
      <category>quant-ph</category>
      <category>cs.DS</category>
      <category>cs.LG</category>
      <pubDate>Wed, 18 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Vishnu Iyer</dc:creator>
    </item>
    <item>
      <title>Information-Computation Gaps in Quantum Learning via Low-Degree Likelihood</title>
      <link>https://arxiv.org/abs/2505.22743</link>
      <description>arXiv:2505.22743v2 Announce Type: replace-cross 
Abstract: In a variety of physically relevant settings for learning from quantum data, designing protocols that can computationally efficiently extract information remains largely an art, and there are important cases where we believe this to be impossible, that is, where there is an information-computation gap. While there is a large array of tools in the classical literature for giving evidence for average-case hardness of statistical inference problems, the corresponding tools in the quantum literature are far more limited. One such framework in the classical literature, the low-degree method, makes predictions about hardness of inference problems based on the failure of estimators given by low-degree polynomials. In this work, we extend this framework to the quantum setting.
  We establish a general connection between state designs and low-degree hardness. We use this to obtain the first information-computation gaps for learning Gibbs states of random, sparse, non-local Hamiltonians. We also use it to prove hardness for learning random shallow quantum circuit states in a challenging model where states can be measured in adaptively chosen bases. To our knowledge, the ability to model adaptivity within the low-degree framework was open even in classical settings. In addition, we also obtain a low-degree hardness result for quantum error mitigation against strategies with single-qubit measurements.
  We define a new quantum generalization of the planted biclique problem and identify the threshold at which this problem becomes computationally hard for protocols that perform local measurements. Interestingly, the complexity landscape for this problem shifts when going from local measurements to more entangled single-copy measurements.
  We show average-case hardness for the "standard" variant of Learning Stabilizers with Noise and for agnostically learning product states.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.22743v2</guid>
      <category>quant-ph</category>
      <category>cs.CC</category>
      <category>cs.DS</category>
      <category>cs.LG</category>
      <pubDate>Wed, 18 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Sitan Chen, Weiyuan Gong, Jonas Haferkamp, Yihui Quek</dc:creator>
    </item>
    <item>
      <title>Towards Fair Representation: Clustering and Consensus</title>
      <link>https://arxiv.org/abs/2506.08673</link>
      <description>arXiv:2506.08673v3 Announce Type: replace-cross 
Abstract: Consensus clustering, a fundamental task in machine learning and data analysis, aims to aggregate multiple input clusterings of a dataset, potentially based on different non-sensitive attributes, into a single clustering that best represents the collective structure of the data. In this work, we study this fundamental problem through the lens of fair clustering, as introduced by Chierichetti et al. [NeurIPS'17], which incorporates the disparate impact doctrine to ensure proportional representation of each protected group in the dataset within every cluster. Our objective is to find a consensus clustering that is not only representative but also fair with respect to specific protected attributes. To the best of our knowledge, we are the first to address this problem and provide a constant-factor approximation.
  As part of our investigation, we examine how to minimally modify an existing clustering to enforce fairness -- an essential postprocessing step in many clustering applications that require fair representation. We develop an optimal algorithm for datasets with equal group representation and near-linear time constant factor approximation algorithms for more general scenarios with different proportions of two group sizes. We complement our approximation result by showing that the problem is NP-hard for two unequal-sized groups. Given the fundamental nature of this problem, we believe our results on Closest Fair Clustering could have broader implications for other clustering problems, particularly those for which no prior approximation guarantees exist for their fair variants.</description>
      <guid isPermaLink="false">oai:arXiv.org:2506.08673v3</guid>
      <category>cs.LG</category>
      <category>cs.DS</category>
      <pubDate>Wed, 18 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Diptarka Chakraborty, Kushagra Chatterjee, Debarati Das, Tien Long Nguyen, Romina Nobahari</dc:creator>
    </item>
  </channel>
</rss>
