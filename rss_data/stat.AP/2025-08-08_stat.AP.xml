<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>stat.AP updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/stat.AP</link>
    <description>stat.AP updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/stat.AP" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Fri, 08 Aug 2025 04:00:33 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Fri, 08 Aug 2025 00:00:00 -0400</pubDate>
    <skipDays>
      <day>Sunday</day>
      <day>Saturday</day>
    </skipDays>
    <item>
      <title>Introducing Powerwise (PWR): A pairwise and Power Rating method for selecting at-large teams to the NCAA Division I Men's Lacrosse Championship</title>
      <link>https://arxiv.org/abs/2508.04919</link>
      <description>arXiv:2508.04919v1 Announce Type: new 
Abstract: This document describes a new system for selecting teams for the NCAA Men's Division I Lacrosse championship tournament called "Powerwise" that was developed in discussions with the NCAA Lacrosse Selection Criteria and Ranking Committee (SCR). The method is simple, employing hierarchical pairwise comparisons that emphasize on-field performance in head-to-head and common opponent matchups, and a simple Massey/Colley/Sagarin-like statistic called the Power Rating (PR) when on-field results are not conclusive. Power Ratings are based on margin of victory and implicitly account for strength of schedule. Powerwise addresses the complexities of team selection in a way that both coaches and fans can understand while improving the fairness, objectivity, and overall quality of the selection process.</description>
      <guid isPermaLink="false">oai:arXiv.org:2508.04919v1</guid>
      <category>stat.AP</category>
      <category>stat.ME</category>
      <pubDate>Fri, 08 Aug 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Lawrence Feldman, Matthew Bomparola</dc:creator>
    </item>
    <item>
      <title>Plans for acceptance sampling by attributes when observations are destructive</title>
      <link>https://arxiv.org/abs/2508.05131</link>
      <description>arXiv:2508.05131v1 Announce Type: new 
Abstract: The international standard ISO 2859-2 provides plans for acceptance sampling by attributes, that ensure a defined quality level in isolated lots using the hypergeometric distribution. In destructive testing, the sample itself is damaged or changed such that the quality of an entire lot is less relevant than the quality of the lot that remains after removing the sample. Examples include assessing the germination of seeds and the conformity of in-service utility meters.
  This research highlights that the hypergeometric distribution cannot describe the frequentist consumer's risk of accepting a remaining lot with unsatisfactory quality. Consequently, sampling plans as those provided in ISO 2859-2 are ill-suited to assess the remaining lot when sampling destructively. In contrast, Bayesian statistics inherently infers the lot's quality after sampling. Using a reference prior, we show that sampling plans provided by ISO 2859-2 result in high specific consumer's risk for small remaining lots.
  The ISO 2859-2 being ill-suited, we design plans for destructive sampling that limit the (Bayesian) specific consumer's risk. To tabulate these plans in a similar way to ISO 2859-2, we propose a new representation that fixes the remaining lot size $N-n$ rather than the sample size $n$. This generalizable, concise and efficient representation is suitable for future standardization of destructive sampling.</description>
      <guid isPermaLink="false">oai:arXiv.org:2508.05131v1</guid>
      <category>stat.AP</category>
      <pubDate>Fri, 08 Aug 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Hugalf Bernburg, Katy Klauenberg</dc:creator>
    </item>
    <item>
      <title>Federal Reserve Communication and the COVID-19 Pandemic</title>
      <link>https://arxiv.org/abs/2508.04830</link>
      <description>arXiv:2508.04830v1 Announce Type: cross 
Abstract: In this study, we examine the Federal Reserve's communication strategies during the COVID-19 pandemic, comparing them with communication during previous periods of economic stress. Using specialized dictionaries tailored to COVID-19, unconventional monetary policy (UMP), and financial stability, combined with sentiment analysis and topic modeling techniques, we identify a distinct focus in Fed communication during the pandemic on financial stability, market volatility, social welfare, and UMP, characterized by notable contextual uncertainty. Through comparative analysis, we juxtapose the Fed's communication during the COVID-19 crisis with its responses during the dot-com and global financial crises, examining content, sentiment, and timing dimensions. Our findings reveal that Fed communication and policy actions were more reactive to the COVID-19 crisis than to previous crises. Additionally, declining sentiment related to financial stability in interest rate announcements and minutes anticipated subsequent accommodative monetary policy decisions. We further document that communicating about UMP has become the "new normal" for the Fed's Federal Open Market Committee meeting minutes and Chairman's speeches since the Global Financial Crisis, reflecting an institutional adaptation in communication strategy following periods of economic distress. These findings contribute to our understanding of how central bank communication evolves during crises and how communication strategies adapt to exceptional economic circumstances.</description>
      <guid isPermaLink="false">oai:arXiv.org:2508.04830v1</guid>
      <category>econ.GN</category>
      <category>cs.CL</category>
      <category>cs.IT</category>
      <category>math.IT</category>
      <category>q-fin.EC</category>
      <category>stat.AP</category>
      <category>stat.ML</category>
      <pubDate>Fri, 08 Aug 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <arxiv:DOI>10.1111/manc.12520</arxiv:DOI>
      <arxiv:journal_reference>Manchester School, 93(5), 2025, 464-484</arxiv:journal_reference>
      <dc:creator>Jonathan Benchimol, Sophia Kazinnik, Yossi Saadon</dc:creator>
    </item>
    <item>
      <title>Enhancing Empathic Accuracy: Penalized Functional Alignment Method to Correct Temporal Misalignment in Real-time Emotional Perception</title>
      <link>https://arxiv.org/abs/2409.05343</link>
      <description>arXiv:2409.05343v2 Announce Type: replace 
Abstract: Empathic accuracy (EA) is the ability to accurately understand another person\textquotesingle s thoughts and feelings, which is crucial for social and psychological interactions. Traditionally, EA is assessed by comparing a perceiver\textquotesingle s moment-to-moment ratings of a target\textquotesingle s emotional state with the target\textquotesingle s own self-reported ratings at corresponding time points. However, misalignments between these two sequences are common due to the complexity of emotional interpretation and individual differences in behavioral responses. Conventional methods often ignore or oversimplify these misalignments, for instance, by assuming a fixed time lag, which can introduce bias into EA estimates. To address this, we propose a novel alignment approach that captures a wide range of misalignment patterns. Our method leverages the square-root velocity framework to decompose emotional rating trajectories into amplitude and phase components. To ensure realistic alignment, we introduce a regularization constraint that limits temporal shifts to ranges consistent with human perceptual capabilities. This alignment is efficiently implemented using a constrained dynamic programming algorithm. We validate our method through simulations and real-world applications involving video and music datasets, demonstrating its superior performance over traditional techniques.</description>
      <guid isPermaLink="false">oai:arXiv.org:2409.05343v2</guid>
      <category>stat.AP</category>
      <pubDate>Fri, 08 Aug 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Linh H Nghiem, Jing Cao, Chrystyna Kouros, Chul Moon</dc:creator>
    </item>
    <item>
      <title>Unsupervised Graph Deep Learning Reveals Emergent Flood Risk Profile of Urban Areas</title>
      <link>https://arxiv.org/abs/2309.14610</link>
      <description>arXiv:2309.14610v4 Announce Type: replace-cross 
Abstract: Urban flood risk emerges from complex and nonlinear interactions among multiple features related to flood hazard, flood exposure, and social and physical vulnerabilities, along with the complex spatial flood dependence relationships. Existing approaches for characterizing urban flood risk, however, are primarily based on flood plain maps, focusing on a limited number of features, primarily hazard and exposure features, without consideration of feature interactions or the dependence relationships among spatial areas. To address this gap, this study presents an integrated urban flood-risk rating model based on a novel unsupervised graph deep learning model (called FloodRisk-Net). FloodRisk-Net is capable of capturing spatial dependence among areas and complex and nonlinear interactions among flood hazards and urban features for specifying emergent flood risk. Using data from multiple metropolitan statistical areas (MSAs) in the United States, the model characterizes their flood risk into six distinct city-specific levels. The model is interpretable and enables feature analysis of areas within each flood-risk level, allowing for the identification of the three archetypes shaping the highest flood risk within each MSA. Flood risk is found to be spatially distributed in a hierarchical structure within each MSA, where the core city disproportionately bears the highest flood risk. Multiple cities are found to have high overall flood-risk levels and low spatial inequality, indicating limited options for balancing urban development and flood-risk reduction. Relevant flood-risk reduction strategies are discussed considering ways that the highest flood risk and uneven spatial distribution of flood risk are formed.</description>
      <guid isPermaLink="false">oai:arXiv.org:2309.14610v4</guid>
      <category>cs.LG</category>
      <category>cs.AI</category>
      <category>cs.CY</category>
      <category>stat.AP</category>
      <pubDate>Fri, 08 Aug 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Kai Yin, Junwei Ma, Ali Mostafavi</dc:creator>
    </item>
  </channel>
</rss>
