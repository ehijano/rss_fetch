<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>cs.CC updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/cs.CC</link>
    <description>cs.CC updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/cs.CC" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Wed, 20 Nov 2024 02:47:49 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Tue, 19 Nov 2024 00:00:00 -0500</pubDate>
    <skipDays>
      <day>Sunday</day>
      <day>Saturday</day>
    </skipDays>
    <item>
      <title>Towards Geometry-Preserving Reductions Between Constraint Satisfaction Problems (and other problems in NP)</title>
      <link>https://arxiv.org/abs/2411.10453</link>
      <description>arXiv:2411.10453v1 Announce Type: new 
Abstract: Motivated by phase transitions in combinatorial optimization problems, we define two kinds of geometry-preserving reductions between constraint satisfaction problems and other NP-search problems. We give a couple of examples and counterexamples for these reductions.  </description>
      <guid isPermaLink="false">oai:arXiv.org:2411.10453v1</guid>
      <category>cs.CC</category>
      <category>cs.AI</category>
      <category>cs.DM</category>
      <pubDate>Tue, 19 Nov 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <arxiv:DOI>10.4204/EPTCS.410.3</arxiv:DOI>
      <arxiv:journal_reference>EPTCS 410, 2024, pp. 38-52</arxiv:journal_reference>
      <dc:creator>Gabriel Istrate</dc:creator>
    </item>
    <item>
      <title>Near-Optimal Averaging Samplers and Matrix Samplers</title>
      <link>https://arxiv.org/abs/2411.10870</link>
      <description>arXiv:2411.10870v1 Announce Type: new 
Abstract: We present the first efficient averaging sampler that achieves asymptotically optimal randomness complexity and near-optimal sample complexity. For any $\delta &lt; \varepsilon$ and any constant $\alpha &gt; 0$, our sampler uses $m + O(\log (1 / \delta))$ random bits to output $t = O((\frac{1}{\varepsilon^2} \log \frac{1}{\delta})^{1 + \alpha})$ samples $Z_1, \dots, Z_t \in \{0, 1\}^m$ such that for any function $f: \{0, 1\}^m \to [0, 1]$, \[ \Pr\left[\left|\frac{1}{t}\sum_{i=1}^t f(Z_i) - \mathbb{E}[f]\right| \leq \varepsilon\right] \geq 1 - \delta. \] The randomness complexity is optimal up to a constant factor, and the sample complexity is optimal up to the $O((\frac{1}{\varepsilon^2} \log \frac{1}{\delta})^{\alpha})$ factor.
  Our technique generalizes to matrix samplers. A matrix sampler is defined similarly, except that $f: \{0, 1\}^m \to \mathbb{C}^{d \times d}$ and the absolute value is replaced by the spectral norm. Our matrix sampler achieves randomness complexity $m + \tilde O (\log(d / \delta))$ and sample complexity $ O((\frac{1}{\varepsilon^2} \log \frac{d}{\delta})^{1 + \alpha})$ for any constant $\alpha &gt; 0$, both near-optimal with only a logarithmic factor in randomness complexity and an additional $\alpha$ exponent on the sample complexity.
  We use known connections with randomness extractors and list-decodable codes to give applications to these objects. Specifically, we give the first extractor construction with optimal seed length up to an arbitrarily small constant factor above 1, when the min-entropy $k = \beta n$ for a large enough constant $\beta &lt; 1$.</description>
      <guid isPermaLink="false">oai:arXiv.org:2411.10870v1</guid>
      <category>cs.CC</category>
      <category>cs.DS</category>
      <pubDate>Tue, 19 Nov 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Zhiyang Xun, David Zuckerman</dc:creator>
    </item>
    <item>
      <title>Gadgetless Lifting Beats Round Elimination: Improved Lower Bounds for Pointer Chasing</title>
      <link>https://arxiv.org/abs/2411.10996</link>
      <description>arXiv:2411.10996v1 Announce Type: new 
Abstract: We prove an \Omega(n/k+k) communication lower bound on (k-1)-round distributional complexity of the k-step pointer chasing problem under uniform input distribution, improving the \Omega(n/k - k log n) lower bound due to Yehudayoff (Combinatorics Probability and Computing, 2020). Our lower bound almost matches the upper bound of O(n/k + k) communication by Nisan and Wigderson (STOC 91).
  As part of our approach, we put forth gadgetless lifting, a new framework that lifts lower bounds for a family of restricted protocols into lower bounds for general protocols. A key step in gadgetless lifting is choosing the appropriate definition of restricted protocols. In this paper, our definition of restricted protocols is inspired by the structure-vs-pseudorandomness decomposition by G\"o\"os, Pitassi, and Watson (FOCS 17) and Yang and Zhang (STOC 24).
  Previously, round-communication trade-offs were mainly obtained by round elimination and information complexity. Both methods have some barriers in some situations, and we believe gadgetless lifting could potentially address these barriers.</description>
      <guid isPermaLink="false">oai:arXiv.org:2411.10996v1</guid>
      <category>cs.CC</category>
      <pubDate>Tue, 19 Nov 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Xinyu Mao, Guangxu Yang, Jiapeng Zhang</dc:creator>
    </item>
    <item>
      <title>Improved PIR Schemes using Matching Vectors and Derivatives</title>
      <link>https://arxiv.org/abs/2411.11611</link>
      <description>arXiv:2411.11611v1 Announce Type: new 
Abstract: In this paper, we construct new t-server Private Information Retrieval (PIR) schemes with communication complexity subpolynomial in the previously best known, for all but finitely many t. Our results are based on combining derivatives (in the spirit of Woodruff-Yekhanin) with the Matching Vector based PIRs of Yekhanin and Efremenko. Previously such a combination was achieved in an ingenious way by Dvir and Gopi, using polynomials and derivatives over certain exotic rings, en route to their fundamental result giving the first 2-server PIR with subpolynomial communication.
  Our improved PIRs are based on two ingredients:
  - We develop a new and direct approach to combine derivatives with Matching Vector based PIRs. This approach is much simpler than that of Dvir-Gopi: it works over the same field as the original PIRs, and only uses elementary properties of polynomials and derivatives.
  - A key subproblem that arises in the above approach is a higher-order polynomial interpolation problem. We show how "sparse S-decoding polynomials", a powerful tool from the original constructions of Matching Vector PIRs, can be used to solve this higher-order polynomial interpolation problem using surprisingly few higer-order evaluations.
  Using the known sparse S-decoding polynomials, in combination with our ideas leads to our improved PIRs. Notably, we get a 3-server PIR scheme with communication $2^{O^{\sim}( (\log n)^{1/3}) }$, improving upon the previously best known communication of $2^{O^{\sim}( \sqrt{\log n})}$ due to Efremenko.</description>
      <guid isPermaLink="false">oai:arXiv.org:2411.11611v1</guid>
      <category>cs.CC</category>
      <category>cs.IT</category>
      <category>math.IT</category>
      <pubDate>Tue, 19 Nov 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Fatemeh Ghasemi, Swastik Kopparty, Madhu Sudan</dc:creator>
    </item>
    <item>
      <title>Hardness Results on Characteristics for Elastic-Degenerated Strings</title>
      <link>https://arxiv.org/abs/2411.10653</link>
      <description>arXiv:2411.10653v1 Announce Type: cross 
Abstract: Generalizations of plain strings have been proposed as a compact way to represent a collection of nearly identical sequences or to express uncertainty at specific text positions by enumerating all possibilities. While a plain string stores a character at each of its positions, generalizations consider a set of characters (indeterminate strings), a set of strings of equal length (generalized degenerate strings, or shortly GD strings), or a set of strings of arbitrary lengths (elastic-degenerate strings, or shortly ED strings). These generalizations are of importance to compactly represent such type of data, and find applications in bioinformatics for representing and maintaining a set of genetic sequences of the same taxonomy or a multiple sequence alignment. To be of use, attention has been drawn to answering various query types such as pattern matching or measuring similarity of ED strings by generalizing techniques known to plain strings. However, for some types of queries, it has been shown that a generalization of a polynomial-time solvable query on classic strings becomes NP-hard on ED strings, e.g. [Russo et al.,2022]. In that light, we wonder about other types of queries, which are of particular interest to bioinformatics: the search for the longest repeating factor, unique substrings, absent words, anti-powers, and longest previous factors. While we obtain a polynomial time algorithm for the first problem on ED strings, we show that all others are NP-hard to compute, some of them even under the restriction that the input can be modelled as an indeterminate or GD string.</description>
      <guid isPermaLink="false">oai:arXiv.org:2411.10653v1</guid>
      <category>cs.DS</category>
      <category>cs.CC</category>
      <pubDate>Tue, 19 Nov 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Dominik K\"oppl, Jannik Olbrich</dc:creator>
    </item>
    <item>
      <title>Computational Complexity of Envy-free and Exchange-stable Seat Arrangement Problems on Grid Graphs</title>
      <link>https://arxiv.org/abs/2411.10719</link>
      <description>arXiv:2411.10719v1 Announce Type: cross 
Abstract: The Seat Arrangement Problem is a problem of finding a desirable seat arrangement for given preferences of agents and a seat graph that represents a configuration of seats. In this paper, we consider decision problems of determining if an envy-free arrangement exists and an exchange-stable arrangement exists, when a seat graph is an $\ell \times m$ grid graph. When $\ell=1$, the seat graph is a path of length $m$ and both problems have been known to be NP-complete. In this paper, we extend it and show that both problems are NP-complete for any integer $\ell \geq 2$.</description>
      <guid isPermaLink="false">oai:arXiv.org:2411.10719v1</guid>
      <category>cs.GT</category>
      <category>cs.CC</category>
      <category>cs.DS</category>
      <pubDate>Tue, 19 Nov 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Sota Kawase, Shuichi Miyazaki</dc:creator>
    </item>
    <item>
      <title>Hereditary First-Order Model Checking</title>
      <link>https://arxiv.org/abs/2411.10860</link>
      <description>arXiv:2411.10860v1 Announce Type: cross 
Abstract: Many computational problems can be modelled as the class of all finite relational structures $\mathbb A$ that satisfy a fixed first-order sentence $\phi$ hereditarily, i.e., we require that every substructure of $\mathbb A$ satisfies $\phi$. In this case, we say that the class is in HerFO. The problems in HerFO are always in coNP, and sometimes coNP-complete. HerFO also contains many interesting computational problems in P, including many constraint satisfaction problems (CSPs). We show that HerFO captures the class of complements of CSPs for reducts of finitely bounded structures, i.e., every such CSP is polynomial-time equivalent to the complement of a problem in HerFO. However, we also prove that HerFO does not have the full computational power of coNP: there are problems in coNP that are not polynomial-time equivalent to a problem in HerFO, unless E=NE. Another main result is a description of the quantifier-prefixes for $\phi$ such that hereditarily checking $\phi$ is in P; we show that for every other quantifier-prefix there exists a formula $\phi$ with this prefix such that hereditarily checking $\phi$ is coNP-complete.</description>
      <guid isPermaLink="false">oai:arXiv.org:2411.10860v1</guid>
      <category>math.LO</category>
      <category>cs.CC</category>
      <category>cs.DM</category>
      <category>cs.LO</category>
      <pubDate>Tue, 19 Nov 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Manuel Bodirsky, Santiago Guzm\'an-Pro</dc:creator>
    </item>
    <item>
      <title>Maximization of Approximately Submodular Functions</title>
      <link>https://arxiv.org/abs/2411.10949</link>
      <description>arXiv:2411.10949v1 Announce Type: cross 
Abstract: We study the problem of maximizing a function that is approximately submodular under a cardinality constraint. Approximate submodularity implicitly appears in a wide range of applications as in many cases errors in evaluation of a submodular function break submodularity. Say that $F$ is $\varepsilon$-approximately submodular if there exists a submodular function $f$ such that $(1-\varepsilon)f(S) \leq F(S)\leq (1+\varepsilon)f(S)$ for all subsets $S$. We are interested in characterizing the query-complexity of maximizing $F$ subject to a cardinality constraint $k$ as a function of the error level $\varepsilon&gt;0$. We provide both lower and upper bounds: for $\varepsilon&gt;n^{-1/2}$ we show an exponential query-complexity lower bound. In contrast, when $\varepsilon&lt; {1}/{k}$ or under a stronger bounded curvature assumption, we give constant approximation algorithms.</description>
      <guid isPermaLink="false">oai:arXiv.org:2411.10949v1</guid>
      <category>cs.DS</category>
      <category>cs.CC</category>
      <pubDate>Tue, 19 Nov 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <arxiv:journal_reference>Advances in Neural Information Processing Systems 29, NeurIPS 2016, pp. 3045-3053</arxiv:journal_reference>
      <dc:creator>Thibaut Horel, Yaron Singer</dc:creator>
    </item>
    <item>
      <title>Explicit Two-Sided Vertex Expanders Beyond the Spectral Barrier</title>
      <link>https://arxiv.org/abs/2411.11627</link>
      <description>arXiv:2411.11627v1 Announce Type: cross 
Abstract: We construct the first explicit two-sided vertex expanders that bypass the spectral barrier.
  Previously, the strongest known explicit vertex expanders were given by $d$-regular Ramanujan graphs, whose spectral properties imply that every small subset of vertices $S$ has at least $0.5d|S|$ distinct neighbors. However, it is possible to construct Ramanujan graphs containing a small set $S$ with no more than $0.5d|S|$ neighbors. In fact, no explicit construction was known to break the $0.5 d$-barrier.
  In this work, we give an explicit construction of an infinite family of $d$-regular graphs (for large enough $d$) where every small set expands by a factor of $\approx 0.6d$. More generally, for large enough $d_1,d_2$, we give an infinite family of $(d_1,d_2)$-biregular graphs where small sets on the left expand by a factor of $\approx 0.6d_1$, and small sets on the right expand by a factor of $\approx 0.6d_2$. In fact, our construction satisfies an even stronger property: small sets on the left and right have unique-neighbor expansion $0.6d_1$ and $0.6d_2$ respectively.
  Our construction follows the tripartite line product framework of Hsieh, McKenzie, Mohanty &amp; Paredes, and instantiates it using the face-vertex incidence of the $4$-dimensional Ramanujan clique complex as its base component. As a key part of our analysis, we derive new bounds on the triangle density of small sets in the Ramanujan clique complex.</description>
      <guid isPermaLink="false">oai:arXiv.org:2411.11627v1</guid>
      <category>math.CO</category>
      <category>cs.CC</category>
      <category>cs.DM</category>
      <category>cs.DS</category>
      <pubDate>Tue, 19 Nov 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Jun-Ting Hsieh, Ting-Chun Lin, Sidhanth Mohanty, Ryan O'Donnell, Rachel Yun Zhang</dc:creator>
    </item>
    <item>
      <title>Solving convex QPs with structured sparsity under indicator conditions</title>
      <link>https://arxiv.org/abs/2411.11722</link>
      <description>arXiv:2411.11722v1 Announce Type: cross 
Abstract: We study convex optimization problems where disjoint blocks of variables are controlled by binary indicator variables that are also subject to conditions, e.g., cardinality. Several classes of important examples can be formulated in such a way that both the objective and the constraints are separable convex quadratics. We describe a family of polynomial-time approximation algorithms and negative complexity results.</description>
      <guid isPermaLink="false">oai:arXiv.org:2411.11722v1</guid>
      <category>math.OC</category>
      <category>cs.CC</category>
      <category>cs.DS</category>
      <pubDate>Tue, 19 Nov 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Daniel Bienstock, Tongtong Chen</dc:creator>
    </item>
    <item>
      <title>On the hardness of cloning and connections to representation theory</title>
      <link>https://arxiv.org/abs/2411.11805</link>
      <description>arXiv:2411.11805v1 Announce Type: cross 
Abstract: The states accepted by a quantum circuit are known as the witnesses for the quantum circuit's satisfiability. The assumption BQP does not equal QMA implies that no efficient algorithm exists for constructing a witness for a quantum circuit from the circuit's classical description. However, a similar complexity-theoretic lower bound on the computational hardness of cloning a witness is not known. In this note, we derive a conjecture about cloning algorithms for maximally entangled states over hidden subspaces which would imply that no efficient algorithm exists for cloning witnesses (assuming BQP does not contain NP). The conjecture and result follow from connections between quantum computation and representation theory; specifically, the relationship between quantum state complexity and the complexity of computing Kronecker coefficients.</description>
      <guid isPermaLink="false">oai:arXiv.org:2411.11805v1</guid>
      <category>quant-ph</category>
      <category>cs.CC</category>
      <pubDate>Tue, 19 Nov 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Vojt\v{e}ch Havl\'i\v{c}ek, Chinmay Nirkhe</dc:creator>
    </item>
    <item>
      <title>Barriers for recent methods in geodesic optimization</title>
      <link>https://arxiv.org/abs/2102.06652</link>
      <description>arXiv:2102.06652v3 Announce Type: replace 
Abstract: We study a class of optimization problems including matrix scaling, matrix balancing, multidimensional array scaling, operator scaling, and tensor scaling that arise frequently in theory and in practice. Some of these problems, such as matrix and array scaling, are convex in the Euclidean sense, but others such as operator scaling and tensor scaling are geodesically convex on a different Riemannian manifold. Trust region methods, which include box-constrained Newton's method, are known to produce high precision solutions very quickly for matrix scaling and matrix balancing (Cohen et. al., FOCS 2017, Allen-Zhu et. al. FOCS 2017), and result in polynomial time algorithms for some geodesically convex problems like operator scaling (Garg et. al. STOC 2018, B\"urgisser et. al. FOCS 2019). One is led to ask whether these guarantees also hold for multidimensional array scaling and tensor scaling.
  We show that this is not the case by exhibiting instances with exponential diameter bound: we construct polynomial-size instances of 3-dimensional array scaling and 3-tensor scaling whose approximate solutions all have doubly exponential condition number. Moreover, we study convex-geometric notions of complexity known as margin and gap, which are used to bound the running times of all existing optimization algorithms for such problems. We show that margin and gap are exponentially small for several problems including array scaling, tensor scaling and polynomial scaling. Our results suggest that it is impossible to prove polynomial running time bounds for tensor scaling based on diameter bounds alone. Therefore, our work motivates the search for analogues of more sophisticated algorithms, such as interior point methods, for geodesically convex optimization that do not rely on polynomial diameter bounds.</description>
      <guid isPermaLink="false">oai:arXiv.org:2102.06652v3</guid>
      <category>cs.CC</category>
      <category>math.CO</category>
      <category>math.OC</category>
      <pubDate>Tue, 19 Nov 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <arxiv:DOI>10.4230/LIPIcs.CCC.2021.13</arxiv:DOI>
      <dc:creator>Cole Franks, Philipp Reichenbach</dc:creator>
    </item>
    <item>
      <title>Spectral Lower Bounds for Local Search</title>
      <link>https://arxiv.org/abs/2403.06248</link>
      <description>arXiv:2403.06248v3 Announce Type: replace 
Abstract: Local search is a powerful heuristic in optimization and computer science, the complexity of which has been studied in the white box and black box models. In the black box model, we are given a graph $G = (V,E)$ and oracle access to a function $f : V \to \mathbb{R}$. The local search problem is to find a vertex $v$ that is a local minimum, i.e. with $f(v) \leq f(u)$ for all $(u,v) \in E$, using as few queries to the oracle as possible.
  We show that if a graph $G$ admits a lazy, irreducible, and reversible Markov chain with stationary distribution $\pi$, then the randomized query complexity of local search on $G$ is $\Omega\left( \frac{\sqrt{n}}{t_{mix} \cdot \exp(3\sigma)}\right)$, where $t_{mix}$ is the mixing time of the chain and $\sigma = \max_{u,v \in V(G)} \frac{\pi(v)}{\pi(u)}.$ This theorem formally establishes a connection between the query complexity of local search and the mixing time of the fastest mixing Markov chain for the given graph. We also get several corollaries that lower bound the complexity as a function of the spectral gap, one of which slightly improves a lower bound based on spectral gaps from prior work.</description>
      <guid isPermaLink="false">oai:arXiv.org:2403.06248v3</guid>
      <category>cs.CC</category>
      <pubDate>Tue, 19 Nov 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Simina Br\^anzei, Nicholas J. Recker</dc:creator>
    </item>
    <item>
      <title>Assembly Theory and its Relationship with Computational Complexity</title>
      <link>https://arxiv.org/abs/2406.12176</link>
      <description>arXiv:2406.12176v2 Announce Type: replace 
Abstract: Assembly theory (AT) quantifies selection using the assembly equation and identifies complex objects that occur in abundance based on two measurements, assembly index and copy number, where the assembly index is the minimum number of joining operations necessary to construct an object from basic parts, and the copy number is how many instances of the given object(s) are observed. Together these define a quantity, called Assembly, which captures the amount of causation required to produce objects in abundance in an observed sample. This contrasts with the random generation of objects. Herein we describe how AT's focus on selection as the mechanism for generating complexity offers a distinct approach, and answers different questions, than computational complexity theory with its focus on minimum descriptions via compressibility. To explore formal differences between the two approaches, we show several simple and explicit mathematical examples demonstrating that the assembly index, itself only one piece of the theoretical framework of AT, is formally not equivalent to other commonly used complexity measures from computer science and information theory including Shannon entropy, Huffman encoding, and Lempel-Ziv-Welch compression. We also include proofs that assembly index is not in the same computational complexity class as these compression algorithms and discuss fundamental differences in the ontological basis of AT, and assembly index as a physical observable, which distinguish it from theoretical approaches to formalizing life that are unmoored from measurement.</description>
      <guid isPermaLink="false">oai:arXiv.org:2406.12176v2</guid>
      <category>cs.CC</category>
      <pubDate>Tue, 19 Nov 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <dc:creator>Christopher P. Kempes, Michael Lachmann, Andrew Iannaccone, G. Matthew Fricke, M. Redwan Chowdhury, Sara I. Walker, Leroy Cronin</dc:creator>
    </item>
    <item>
      <title>Bounded degree QBF and positional games</title>
      <link>https://arxiv.org/abs/2411.10093</link>
      <description>arXiv:2411.10093v2 Announce Type: replace 
Abstract: The study of SAT and its variants has provided numerous NP-complete problems, from which most NP-hardness results were derived. Due to the NP-hardness of SAT, adding constraints to either specify a more precise NP-complete problem or to obtain a tractable one helps better understand the complexity class of several problems. In 1984, Tovey proved that bounded-degree SAT is also NP-complete, thereby providing a tool for performing NP-hardness reductions even with bounded parameters, when the size of the reduction gadget is a function of the variable degree. In this work, we initiate a similar study for QBF, the quantified version of SAT. We prove that, like SAT, the truth value of a maximum degree two quantified formula is polynomial-time computable. However, surprisingly, while the truth value of a 3-regular 3-SAT formula can be decided in polynomial time, it is PSPACE-complete for a 3-regular QBF formula. A direct consequence of these results is that Avoider-Enforcer and Client-Waiter positional games are PSPACE-complete when restricted to bounded-degree hypergraphs. To complete the study, we also show that Maker-Breaker and Maker-Maker positional games are PSPACE-complete for bounded-degree hypergraphs.</description>
      <guid isPermaLink="false">oai:arXiv.org:2411.10093v2</guid>
      <category>cs.CC</category>
      <category>cs.DM</category>
      <category>math.CO</category>
      <pubDate>Tue, 19 Nov 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Nacim Oijid</dc:creator>
    </item>
    <item>
      <title>Bridging Classical and Quantum: Group-Theoretic Approach to Quantum Circuit Simulation</title>
      <link>https://arxiv.org/abs/2407.19575</link>
      <description>arXiv:2407.19575v2 Announce Type: replace-cross 
Abstract: Efficiently simulating quantum circuits on classical computers is a fundamental challenge in quantum computing. This paper presents a novel theoretical approach that achieves exponential speedups (polynomial runtime) over existing simulators for a wide class of quantum circuits. The technique leverages advanced group theory and symmetry considerations to map quantum circuits to equivalent forms amenable to efficient classical simulation. Several fundamental theorems are proven that establish the mathematical foundations of this approach, including a generalized Gottesman-Knill theorem. The potential of this method is demonstrated through theoretical analysis and preliminary benchmarks. This work contributes to the understanding of the boundary between classical and quantum computation, provides new tools for quantum circuit analysis and optimization, and opens up avenues for further research at the intersection of group theory and quantum computation. The findings may have implications for quantum algorithm design, error correction, and the development of more efficient quantum simulators.</description>
      <guid isPermaLink="false">oai:arXiv.org:2407.19575v2</guid>
      <category>quant-ph</category>
      <category>cs.CC</category>
      <category>cs.DS</category>
      <category>math-ph</category>
      <category>math.GR</category>
      <category>math.MP</category>
      <pubDate>Tue, 19 Nov 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Daksh Shami</dc:creator>
    </item>
  </channel>
</rss>
