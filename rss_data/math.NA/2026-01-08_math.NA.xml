<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>math.NA updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/math.NA</link>
    <description>math.NA updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/math.NA" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Thu, 08 Jan 2026 05:00:26 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Thu, 08 Jan 2026 00:00:00 -0500</pubDate>
    <skipDays>
      <day>Saturday</day>
      <day>Sunday</day>
    </skipDays>
    <item>
      <title>Discontinuous Galerkin finite element operator network for solving non-smooth PDEs</title>
      <link>https://arxiv.org/abs/2601.03668</link>
      <description>arXiv:2601.03668v1 Announce Type: new 
Abstract: We introduce Discontinuous Galerkin Finite Element Operator Network (DG--FEONet), a data-free operator learning framework that combines the strengths of the discontinuous Galerkin (DG) method with neural networks to solve parametric partial differential equations (PDEs) with discontinuous coefficients and non-smooth solutions. Unlike traditional operator learning models such as DeepONet and Fourier Neural Operator, which require large paired datasets and often struggle near sharp features, our approach minimizes the residual of a DG-based weak formulation using the Symmetric Interior Penalty Galerkin (SIPG) scheme. DG-FEONet predicts element-wise solution coefficients via a neural network, enabling data-free training without the need for precomputed input-output pairs. We provide theoretical justification through convergence analysis and validate the model's performance on a series of one- and two-dimensional PDE problems, demonstrating accurate recovery of discontinuities, strong generalization across parameter space, and reliable convergence rates. Our results highlight the potential of combining local discretization schemes with machine learning to achieve robust, singularity-aware operator approximation in challenging PDE settings.</description>
      <guid isPermaLink="false">oai:arXiv.org:2601.03668v1</guid>
      <category>math.NA</category>
      <category>cs.AI</category>
      <category>cs.LG</category>
      <category>cs.NA</category>
      <pubDate>Thu, 08 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <dc:creator>Kapil Chawla, Youngjoon Hong, Jae Yong Lee, Sanghyun Lee</dc:creator>
    </item>
    <item>
      <title>Local Interpolation via Low-Rank Tensor Trains</title>
      <link>https://arxiv.org/abs/2601.03885</link>
      <description>arXiv:2601.03885v1 Announce Type: new 
Abstract: Tensor Train (TT) decompositions provide a powerful framework to compress grid-structured data, such as sampled function values, on regular Cartesian grids. Such high compression, in turn, enables efficient high-dimensional computations. Exact TT representations are only available for simple analytic functions. Furthermore, global polynomial or Fourier expansions typically yield TT-ranks that grow proportionally with the number of basis terms. State-of-the-art methods are often prohibitively expensive or fail to recover the underlying low-rank structure. We propose a low-rank TT interpolation framework that, given a TT describing a discrete (scalar-, vector-, or tensor-valued) function on a coarse regular grid with $n$ cores, constructs a finer-scale version of the same function represented by a TT with $n+m$ cores, where the last $m$ cores maintain constant rank. Our method guarantees a $\ell^{2}$-norm error bound independent of the total number of cores, achieves exponential compression at fixed accuracy, and admits logarithmic complexity with respect of the number of grid points. We validate its performance through numerical experiments, including 1D, 2D, and 3D applications such as: 2D and 3D airfoil mask embeddings, image super-resolution, and synthetic noise fields such as 3D synthetic turbulence. In particular, we generate fractal noise fields directly in TT format with logarithmic complexity and memory. This work opens a path to scalable TT-native solvers with complex geometries and multiscale generative models, with implications from scientific simulation to imaging and real-time graphics.</description>
      <guid isPermaLink="false">oai:arXiv.org:2601.03885v1</guid>
      <category>math.NA</category>
      <category>cs.GR</category>
      <category>cs.NA</category>
      <pubDate>Thu, 08 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Siddhartha E. Guzman, Egor Tiunov, Leandro Aolita</dc:creator>
    </item>
    <item>
      <title>Constrained dynamics for searching saddle points on general Riemannian manifolds</title>
      <link>https://arxiv.org/abs/2601.03931</link>
      <description>arXiv:2601.03931v1 Announce Type: new 
Abstract: Finding constrained saddle points on Riemannian manifolds is significant for analyzing energy landscapes arising in physics and chemistry. Existing works have been limited to special manifolds that admit global regular level-set representations, excluding applications such as electronic excited-state calculations. In this paper, we develop a constrained saddle dynamics applicable to smooth functions on general Riemannian manifolds. Our dynamics is formulated compactly over the Grassmann bundle of the tangent bundle. By analyzing the Grassmann bundle geometry, we achieve universality via incorporating the second fundamental form, which captures variations of tangent spaces along the trajectory. We rigorously establish the local linear stability of the dynamics and the local linear convergence of the resulting algorithms. Remarkably, our analysis provides the first convergence guarantees for discretized saddle-search algorithms in manifold settings. Moreover, by respecting the intrinsic quotient structure, we remove unnecessary nondegeneracy assumptions on the eigenvalues of the Riemannian Hessian that are present in existing works. We also point out that locating saddle points can be more ill-conditioning than finding local minimizers, and requires using nonredundant parametrizations. Finally, numerical experiments on linear eigenvalue problems and electronic excited-state calculations showcase the effectiveness of the proposed algorithms and corroborate the established local theory.</description>
      <guid isPermaLink="false">oai:arXiv.org:2601.03931v1</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <category>math.OC</category>
      <category>physics.chem-ph</category>
      <category>physics.comp-ph</category>
      <pubDate>Thu, 08 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Yukuan Hu, Laura Grazioli</dc:creator>
    </item>
    <item>
      <title>On the importance of smoothness, interface resolution and numerical sensitivities in shape and topological sensitivity analysis</title>
      <link>https://arxiv.org/abs/2601.03967</link>
      <description>arXiv:2601.03967v1 Announce Type: new 
Abstract: In this paper we investigate the influence of the discretization of PDE constraints on shape and topological derivatives. To this end, we study a tracking-type functional and a two-material Poisson problem in one spatial dimension. We consider the discretization by a standard method and an enriched method. In the standard method we use splines of degree $p$ such that we can control the smoothness of the basis functions easily, but do not take any interface location into consideration. This includes for p=1 the usual hat basis functions. In the enriched method we additionally capture the interface locations in the ansatz space by enrichment functions. For both discretization methods shape and topological sensitivity analysis is performed. It turns out that the regularity of the shape derivative depends on the regularity of the basis functions. Furthermore, for point-wise convergence of the shape derivative the interface has to be considered in the ansatz space. For the topological derivative we show that only the enriched method converges.</description>
      <guid isPermaLink="false">oai:arXiv.org:2601.03967v1</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <category>math.OC</category>
      <pubDate>Thu, 08 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>M. H. Gfrerer, P. Gangl</dc:creator>
    </item>
    <item>
      <title>Posterior error bounds for prior-driven balancing in linear Gaussian inverse problems</title>
      <link>https://arxiv.org/abs/2601.03971</link>
      <description>arXiv:2601.03971v1 Announce Type: new 
Abstract: In large-scale Bayesian inverse problems, it is often necessary to apply approximate forward models to reduce the cost of forward model evaluations, while controlling approximation quality. In the context of Bayesian inverse problems with linear forward models, Gaussian priors, and Gaussian noise, we use perturbation theory for inverses to bound the error in the approximate posterior mean and posterior covariance resulting from a linear approximate forward model. We then focus on the smoothing problem of inferring the initial condition of linear time-invariant dynamical systems, using finitely many partial state observations. For such problems, and for a specific model order reduction method based on balanced truncation, we show that the impulse response of a certain prior-driven system is closely related to the prior-preconditioned Hessian of the inverse problem. This reveals a novel connection between systems theory and inverse problems. We exploit this connection to prove the first a priori error bounds for system-theoretic model order reduction methods applied to smoothing problems. The bounds control the approximation error of the posterior mean and covariance in terms of the truncated Hankel singular values of the underlying system.</description>
      <guid isPermaLink="false">oai:arXiv.org:2601.03971v1</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <category>cs.SY</category>
      <category>eess.SY</category>
      <pubDate>Thu, 08 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Josie K\"onig, Han Cheng Lie</dc:creator>
    </item>
    <item>
      <title>A Bivariate Spline Construction of Orthonormal Polynomials over Polygonal Domains and Its Applications to Quadrature</title>
      <link>https://arxiv.org/abs/2601.04022</link>
      <description>arXiv:2601.04022v1 Announce Type: new 
Abstract: We present computational methods for constructing orthogonal/orthonormal polynomials over arbitrary polygonal domains in $\mathbb{R}^2$
  using bivariate spline functions. Leveraging a mature MATLAB implementation which generates spline spaces of any degree, any smoothness over any triangulation, we have exact polynomial representation over the polygonal domain of interest. Two algorithms are developed: one constructs orthonormal polynomials of degree $d&gt;0$
  over a polygonal domain, and the other constructs orthonormal polynomials of degree $d+1$ in the orthogonal complement of $\mathbb{P}_d$. Numerical examples for degrees $d=1--5$ illustrate the structure and zero curves of these polynomials, providing evidence against the existence of Gauss quadrature on centrally symmetric domains. In addition, we introduce polynomial reduction strategies based on odd- and even-degree orthogonal polynomials, reducing the integration to the integration of its residual quadratic or linear polynomials. These reductions motivate new quadrature schemes, which we further extend through polynomial interpolation to obtain efficient, high-precision quadrature rules for various polygonal domains.</description>
      <guid isPermaLink="false">oai:arXiv.org:2601.04022v1</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <pubDate>Thu, 08 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Ming-Jun Lai</dc:creator>
    </item>
    <item>
      <title>A higher order sparse grid combination technique</title>
      <link>https://arxiv.org/abs/2601.04075</link>
      <description>arXiv:2601.04075v1 Announce Type: new 
Abstract: We show that a generalised sparse grid combination technique which combines multi-variate extrapolation of finite difference solutions with the standard combination formula lifts a second order accurate scheme on regular meshes to a fourth order combined sparse grid solution. In the analysis, working in a general dimension, we characterise all terms in a multivariate error expansion of the scheme as solutions of a sequence of semi-discrete problems. This is first carried out formally under suitable assumptions on the truncation error of the scheme, stability and regularity of solutions. We then verify the assumptions on the example of the Poisson problem with smooth data, and illustrate the practical convergence in up to seven dimensions.</description>
      <guid isPermaLink="false">oai:arXiv.org:2601.04075v1</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <pubDate>Thu, 08 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Julia Mu\~noz-Ech\'aniz, Christoph Reisinger</dc:creator>
    </item>
    <item>
      <title>Algebraic Multigrid with Overlapping Schwarz Smoothers and Local Spectral Coarse Grids for Least Squares Problems</title>
      <link>https://arxiv.org/abs/2601.04112</link>
      <description>arXiv:2601.04112v1 Announce Type: new 
Abstract: This paper develops a new algebraic multigrid (AMG) method for sparse least-squares systems of the form $A=G^TG$ motivated by challenging applications in scientific computing where classical AMG methods fail. First we review and relate the use of local spectral problems in distinct fields of literature on AMG, domain decomposition (DD), and multiscale finite elements. We then propose a new approach blending aggregation-based coarsening, overlapping Schwarz smoothers, and locally constructed spectral coarse spaces. By exploiting the factorized structure of $A$, we construct an inexpensive symmetric positive semidefinite splitting that yields local generalized eigenproblems whose solutions define sparse, nonoverlapping coarse basis functions. This enables a fully algebraic and naturally recursive multilevel hierarchy that can either coarsen slowly to achieve AMG-like operator complexities, or coarsen aggressively-with correspondingly larger local spectral problems-to ensure robustness on problems that cannot be solved by existing AMG methods. The method requires no geometric information, avoids global eigenvalue solves, and maintains efficient parallelizable setup through localized operations. Numerical experiments demonstrate that the proposed least-squares AMG-DD method achieves convergence rates independent of anisotropy on rotated diffusion problems and remains scalable with problem size, while for small amounts of anisotropy we obtain convergence and operator complexities comparable with classical AMG methods. Most notably, for extremely anisotropic heat conduction operators arising in magnetic confinement fusion, where AMG and smoothed aggregation fail to reduce the residual even marginally, our method provides robust and efficient convergence across many orders of magnitude in anisotropy strength.</description>
      <guid isPermaLink="false">oai:arXiv.org:2601.04112v1</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <pubDate>Thu, 08 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Ben S. Southworth, Hussam Al Daas, Golo A&gt; Wimmer, Ed Threlfall</dc:creator>
    </item>
    <item>
      <title>Quantitative Constraints for Stable Sampling on the Sphere</title>
      <link>https://arxiv.org/abs/2601.04119</link>
      <description>arXiv:2601.04119v1 Announce Type: new 
Abstract: We derive quantitative volume constraints for sampling measures $\mu_t$ on the unit sphere $\mathbb{S}^d$ that satisfy Marcinkiewicz-Zygmund inequalities of order $t$. Using precise localization estimates for Jacobi polynomials, we obtain explicit upper and lower bounds on the $\mu_t$-mass of geodesic balls at the natural scale $t^{-1}$. Whereas constants are typically left implicit in the literature, we place special emphasis on fully explicit constants, and the results are genuinely quantitative. Moreover, these bounds yield quantitative constraints for the $s$-dimensional Hausdorff volume of Marcinkiewicz-Zygmund sampling sets and, in particular, optimal lower bounds for the length of Marcinkiewicz-Zygmund curves.</description>
      <guid isPermaLink="false">oai:arXiv.org:2601.04119v1</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <pubDate>Thu, 08 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Martin Ehler, Karlheinz Gr\"ochenig</dc:creator>
    </item>
    <item>
      <title>Active subspace methods and derivative-based Shapley effects for functions with non-independent variables</title>
      <link>https://arxiv.org/abs/2601.04132</link>
      <description>arXiv:2601.04132v1 Announce Type: new 
Abstract: Lower-dimensional subspaces that impact estimates of uncertainty are often described by Linear combinations of input variables, leading to active variables. This paper extends the derivative-based active subspace methods and derivative-based Shapley effects to cope with functions with non-independent variables, and it introduces sensitivity-based active subspaces. While derivative-based subspace methods focus on directions along which the function exhibits significant variation, sensitivity-based subspace methods seek a reduced set of active variables that enables a reduction in the function's variance. We propose both theoretical results using the recent development of gradients of functions with non-independent variables and practical settings by making use of optimal computations of gradients, which admit dimension-free upper-bounds of the biases and the parametric rate of convergence. Simulations show that the relative performance of derivative-based and sensitivity-based active subspaces methods varies across different functions.</description>
      <guid isPermaLink="false">oai:arXiv.org:2601.04132v1</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <category>math.PR</category>
      <pubDate>Thu, 08 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <dc:creator>Matieyendou Lamboni, Sergei Kucherenko</dc:creator>
    </item>
    <item>
      <title>Efficient third-order iterative algorithms for computing zeros of special functions</title>
      <link>https://arxiv.org/abs/2601.04148</link>
      <description>arXiv:2601.04148v1 Announce Type: new 
Abstract: This manuscript presents a novel and reliable third-order iterative procedure for computing the zeros of solutions to second-order ordinary differential equations. By approximating the solution of the related Riccati differential equation using the trapezoidal rule, this study has derived the proposed third-order method. This work establishes sufficient conditions to ensure the theoretical non-local convergence of the proposed method. This study provides suitable initial guesses for the proposed third-order iterative procedure to compute all zeros in a given interval of the solutions to second-order ordinary differential equations. The orthogonal polynomials like Legendre and Hermite, as well as the special functions like Bessel, Coulomb wave, confluent hypergeometric, and cylinder functions, satisfy the proposed conditions for convergence. Numerical simulations demonstrate the effectiveness of the proposed theory. This work also presents a comparative analysis with recent studies.</description>
      <guid isPermaLink="false">oai:arXiv.org:2601.04148v1</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <pubDate>Thu, 08 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Dhivya Prabhu K, Sanjeev Singh, Antony Vijesh V</dc:creator>
    </item>
    <item>
      <title>From Penrose to Melrose: Computing Scattering Amplitudes at Infinity for Unbounded Media</title>
      <link>https://arxiv.org/abs/2601.04167</link>
      <description>arXiv:2601.04167v1 Announce Type: new 
Abstract: We develop a method to compute scattering amplitudes for the Helmholtz equation in variable, unbounded media with possibly long-range asymptotics. Combining Penrose's conformal compactification and Melrose's geometric scattering theory, we formulate the time-harmonic scattering problem on a compactified manifold with boundary and construct a two-step solver for scattering amplitudes at infinity. The construction is asymptotic: it treats a neighborhood of infinity, and is meant to couple to interior solvers via domain decomposition. The method provides far-field data without relying on explicit solutions or Green's function representation. Scattering in variable media is treated in a unified framework where both the incident and scattered fields solve the same background Helmholtz operator. Numerical experiments for constant, short-range, and long-range media with single-mode and Gaussian beam incidence demonstrate spectral convergence of the computed scattering amplitudes in all cases.</description>
      <guid isPermaLink="false">oai:arXiv.org:2601.04167v1</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <category>gr-qc</category>
      <pubDate>Thu, 08 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>An{\i}l Zengino\u{g}lu</dc:creator>
    </item>
    <item>
      <title>The Geometry of the Pivot: A Note on Lazy Pivoted Cholesky and Farthest Point Sampling</title>
      <link>https://arxiv.org/abs/2601.03706</link>
      <description>arXiv:2601.03706v1 Announce Type: cross 
Abstract: Low-rank approximations of large kernel matrices are ubiquitous in machine learning, particularly for scaling Gaussian Processes to massive datasets. The Pivoted Cholesky decomposition is a standard tool for this task, offering a computationally efficient, greedy low-rank approximation. While its algebraic properties are well-documented in numerical linear algebra, its geometric intuition within the context of kernel methods often remains obscure. In this note, we elucidate the geometric interpretation of the algorithm within the Reproducing Kernel Hilbert Space (RKHS). We demonstrate that the pivotal selection step is mathematically equivalent to Farthest Point Sampling (FPS) using the kernel metric, and that the Cholesky factor construction is an implicit Gram-Schmidt orthogonalization. We provide a concise derivation and a minimalist Python implementation to bridge the gap between theory and practice.</description>
      <guid isPermaLink="false">oai:arXiv.org:2601.03706v1</guid>
      <category>cs.LG</category>
      <category>cs.NA</category>
      <category>math.NA</category>
      <pubDate>Thu, 08 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Gil Shabat</dc:creator>
    </item>
    <item>
      <title>Assessing Meteo-HySEA Performance for Adriatic Meteotsunami Events</title>
      <link>https://arxiv.org/abs/2601.03856</link>
      <description>arXiv:2601.03856v1 Announce Type: cross 
Abstract: Meteotsunamis are atmospherically driven sea-level oscillations that can trigger hazardous coastal flooding, particularly in resonant bays. This study assesses the GPU-based Meteo-HySEA model for meteotsunami simulation in the Adriatic Sea, benchmarking its performance against the CPU-based AdriSC-ADCIRC system. Three documented events (2014, 2017, 2020) were simulated using WRF downscaling of ERA reanalyses and validated with tide-gauge and microbarograph observations. Both models are limited by the underestimation of mesoscale pressure disturbances in the atmospheric forcing. Meteo-HySEA generally reproduces the timing and spatial variability of sea-level oscillations and often yields larger amplitudes than ADCIRC, but it tends to overestimate dominant wave periods, particularly in enclosed basins. Differences in oscillation persistence underscore the need for further validation against high-resolution tide-gauge data to assess whether Meteo-HySEA captures harbor seiches more realistically or ADCIRC better represents physical energy dissipation. Crucially, GPU acceleration provides order-of-magnitude gains in computational efficiency, enabling rapid high-resolution, multi-grid simulations including inundation, and thus offering strong potential for operational early warning.</description>
      <guid isPermaLink="false">oai:arXiv.org:2601.03856v1</guid>
      <category>physics.geo-ph</category>
      <category>cs.NA</category>
      <category>math.NA</category>
      <pubDate>Thu, 08 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Alejandro Gonz\'alez, Cl\'ea Denamiel, Jorge Mac\'ias</dc:creator>
    </item>
    <item>
      <title>Quantum computing for multidimensional option pricing: End-to-end pipeline</title>
      <link>https://arxiv.org/abs/2601.04049</link>
      <description>arXiv:2601.04049v1 Announce Type: cross 
Abstract: This work introduces an end-to-end framework for multi-asset option pricing that combines market-consistent risk-neutral density recovery with quantum-accelerated numerical integration. We first calibrate arbitrage-free marginal distributions from European option quotes using the Normal Inverse Gaussian (NIG) model, leveraging its analytical tractability and ability to capture skewness and fat tails. Marginals are coupled via a Gaussian copula to construct joint distributions. To address the computational bottleneck of the high-dimensional integration required to solve the option pricing formula, we employ Quantum Accelerated Monte Carlo (QAMC) techniques based on Quantum Amplitude Estimation (QAE), achieving quadratic convergence improvements over classical Monte Carlo (CMC) methods. Theoretical results establish accuracy bounds and query complexity for both marginal density estimation (via cosine-series expansions) and multidimensional pricing. Empirical tests on liquid equity entities (Credit Agricole, AXA, Michelin) confirm high calibration accuracy and demonstrate that QAMC requires 10-100 times fewer queries than classical methods for comparable precision. This study provides a practical route to integrate arbitrage-aware modelling with quantum computing, highlighting implications for scalability and future extensions to complex derivatives.</description>
      <guid isPermaLink="false">oai:arXiv.org:2601.04049v1</guid>
      <category>q-fin.CP</category>
      <category>cs.NA</category>
      <category>math.NA</category>
      <category>quant-ph</category>
      <pubDate>Thu, 08 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Julien Hok, \'Alvaro Leitao</dc:creator>
    </item>
    <item>
      <title>Multi-index importance sampling for McKean--Vlasov stochastic differential equations</title>
      <link>https://arxiv.org/abs/2307.05149</link>
      <description>arXiv:2307.05149v2 Announce Type: replace 
Abstract: This work addresses the estimation of rare-event quantities expressed as expectations of smooth observables of solutions to a broad class of McKean--Vlasov stochastic differential equations (MV-SDEs). Building on the double loop Monte Carlo (DLMC) method with stochastic optimal control-based importance sampling (IS) introduced by Ben Rached et al. (2024a), this work extends this framework to the multi-index Monte Carlo (MIMC) setting. The resulting multi-index DLMC estimator mitigates the explosion of the coefficient of variation for rare event quantities. Moreover, it exploits the sampling efficiency of MIMC by leveraging the propagation of chaos to ensure mixed-difference variances vanish in the mean-field limit. The complexity analysis relies on assumptions on mixed-difference bias and variance decay, similar to standard MIMC assumptions. Although not rigorously proved, this work presents strong numerical evidence in support of these assumptions. The primary contribution of this work is the novel numerical integration of the MIMC method with IS for MV-SDEs. This approach reduces the computational complexity from $\mathcal{O}(\mathrm{TOL}_{\mathrm{r}}^{-4})$ for the DLMC estimator to $\mathcal{O}(\mathrm{TOL}_{\mathrm{r}}^{-2} (\log \mathrm{TOL}_{\mathrm{r}}^{-1})^2)$, enabling an accurate estimation of rare-event quantities within a prescribed relative error tolerance $\mathrm{TOL}_{\mathrm{r}}$. Numerical experiments on the Kuramoto model from statistical physics demonstrate computational savings of several orders of magnitude for the multi-index DLMC estimator with IS, compared with the standard Monte Carlo (MC) method.</description>
      <guid isPermaLink="false">oai:arXiv.org:2307.05149v2</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <category>stat.CO</category>
      <pubDate>Thu, 08 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Nadhir Ben Rached, Abdul-Lateef Haji-Ali, Shyam Mohan Subbiah Pillai, Ra\'ul Tempone</dc:creator>
    </item>
    <item>
      <title>Numerical approximation of McKean-Vlasov SDEs via stochastic gradient descent</title>
      <link>https://arxiv.org/abs/2310.13579</link>
      <description>arXiv:2310.13579v3 Announce Type: replace 
Abstract: We propose a novel approach to numerically approximate McKean-Vlasov stochastic differential equations (MV-SDE) using stochastic gradient descent (SGD) while avoiding the use of interacting particle systems (IPS) {and the associated simulation costs required to achieve the ``propagation of chaos'' limit}. The SGD technique is deployed to solve a Euclidean minimization problem, obtained by first representing the MV-SDE as a minimization problem over the set of continuous functions of time, and then approximating the domain with a finite-dimensional subspace. Convergence is established by proving certain intermediate stability and moment estimates of the relevant stochastic processes, including the tangent processes. Numerical experiments illustrate the competitive performance of our SGD based method compared to the IPS benchmarks. This work offers a theoretical foundation for using the SGD method in the context of numerical approximation of MV-SDEs, and provides analytical tools to study its stability and convergence.</description>
      <guid isPermaLink="false">oai:arXiv.org:2310.13579v3</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <category>math.PR</category>
      <pubDate>Thu, 08 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Ankush Agarwal, Andrea Amato, Goncalo dos Reis, Stefano Pagliarani</dc:creator>
    </item>
    <item>
      <title>A Higher Order Local Mesh Method for Approximating 1-Laplacians on Unknown Manifolds</title>
      <link>https://arxiv.org/abs/2405.15735</link>
      <description>arXiv:2405.15735v2 Announce Type: replace 
Abstract: We introduce a numerical method for approximating arbitrary differential operators on vector fields in the weak form given point cloud data sampled randomly from a $d$ dimensional manifold embedded in $\mathbb{R}^n$. This method generalizes the local linear mesh method to the local curved mesh method, thus, allowing for the estimation of differential operators with nontrivial Christoffel symbols, such as the Bochner or Hodge Laplacians. In particular, we leverage the potentially small intrinsic dimension of the manifold $(d \ll n)$ to construct local parameterizations that incorporate both local meshes and higher-order curvature information. The former is constructed using low dimensional meshes obtained from local data projected to the tangent spaces, while the latter is obtained by fitting local polynomials with the generalized moving least squares. Theoretically, we prove the spectral convergence for the proposed method for the estimation of the Bochner Laplacian. We provide numerical results supporting the theoretical convergence rates for the Bochner and Hodge Laplacians on simple manifolds.</description>
      <guid isPermaLink="false">oai:arXiv.org:2405.15735v2</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <pubDate>Thu, 08 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>John Wilson Peoples, John Harlim</dc:creator>
    </item>
    <item>
      <title>An explicit spectral decomposition of the ADRT</title>
      <link>https://arxiv.org/abs/2412.11151</link>
      <description>arXiv:2412.11151v3 Announce Type: replace 
Abstract: The approximate discrete Radon transform (ADRT) is a hierarchical multiscale approximation of the Radon transform. In this paper, we factor the ADRT into a product of linear transforms that resemble convolutions and derive an explicit spectral decomposition of each factor. We further show that this implies -- for data lying in the range of the ADRT -- that the transform of an $N \times N$ image can be formally inverted with complexity $\mathcal{O}(N^2 \log^2 N)$. We numerically test the accuracy of the inverse on images of moderate size and find that it is competitive with existing iterative algorithms in this special regime.</description>
      <guid isPermaLink="false">oai:arXiv.org:2412.11151v3</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <category>math.SP</category>
      <pubDate>Thu, 08 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Weilin Li, Karl Otness, Kui Ren, Donsub Rim</dc:creator>
    </item>
    <item>
      <title>Neural Multiscale Decomposition for Solving The Nonlinear Klein-Gordon Equation with Time Oscillation</title>
      <link>https://arxiv.org/abs/2512.00266</link>
      <description>arXiv:2512.00266v4 Announce Type: replace 
Abstract: In this paper, we propose a neural multiscale decomposition method (NeuralMD) for solving the nonlinear Klein-Gordon equation (NKGE) with a dimensionless parameter $\varepsilon\in(0,1]$ from the relativistic regime to the nonrelativistic limit regime. The solution of the NKGE propagates waves with wavelength at $O(1)$ and $O(\varepsilon^2)$ in space and time, respectively, which brings the oscillation in time. Existing collocation-based methods for solving this equation lead to spectral bias and propagation failure. To mitigate the spectral bias induced by high-frequency time oscillation, we employ a multiscale time integrator (MTI) to absorb the time oscillation into the phase. This decomposes the NKGE into a nonlinear Schr\"odinger equation with wave operator (NLSW) with well-prepared initial data and a remainder equation with small initial data. As $\varepsilon \to 0$, the NKGE converges to the NLSW at rate $O(\varepsilon^{2})$, and the contribution of the remainder equation becomes negligible. Furthermore, to alleviate propagation failure caused by medium-frequency time oscillation, we propose a gated gradient correlation correction strategy to enforce temporal coherence in collocation-based methods. As a result, the approximation of the remainder term is no longer affected by propagation failure. Comparative experiments with existing collocation-based methods demonstrate the superior performance of our method for solving the NKGE with various regularities of initial data over the whole regime.</description>
      <guid isPermaLink="false">oai:arXiv.org:2512.00266v4</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <pubDate>Thu, 08 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Zhangyong Liang, Zhiping Mao, Xiaofei Zhao</dc:creator>
    </item>
    <item>
      <title>Energy Conserving Data Driven Discretizations for Maxwells Equations</title>
      <link>https://arxiv.org/abs/2601.01902</link>
      <description>arXiv:2601.01902v2 Announce Type: replace 
Abstract: We study data-driven construction of spatial discretizations for the one-dimensional Maxwell system. Given high-fidelity training data generated by a spectral discretization, we learn a linear convolution stencil that approximates the spatial derivative operator appearing in Maxwell's equations. The stencil is obtained by solving a convex quadratic optimization problem, subject to linear constraints that enforce skew-adjointness of the discrete derivative. These constraints guarantee a semi-discrete energy identity for the resulting Maxwell system. We prove that our constraints characterize the class of skew-symmetric convolution operators and express the associated numerical wave speed and CFL restriction for the classical leapfrog scheme in terms of the learned stencil's Fourier symbol. We then compare several convex solvers for the resulting quadratic program -- projected gradient, Nesterov-accelerated gradient, ADMM, and an interior-point reference implemented in CVXPY -- and evaluate the learned schemes in time-dependent one-dimensional Maxwell simulations using a Crank--Nicolson (CN) time discretization. Our numerical experiments show that (i) energy-constrained learned stencils achieve accuracy comparable to standard central differences while exactly preserving the discrete electromagnetic energy under CN time-stepping, and (ii) ADMM and interior-point methods produce nearly identical operators, with ADMM offering a favorable tradeoff between accuracy, constraint satisfaction, and runtime.</description>
      <guid isPermaLink="false">oai:arXiv.org:2601.01902v2</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <pubDate>Thu, 08 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Victory Obieke</dc:creator>
    </item>
    <item>
      <title>An inexact infeasible arc-search interior-point method for linear optimization problems</title>
      <link>https://arxiv.org/abs/2403.18155</link>
      <description>arXiv:2403.18155v4 Announce Type: replace-cross 
Abstract: We propose an inexact infeasible arc-search interior-point method for solving linear optimization problems. The method combines an arc-search strategy with inexact solutions to Newton systems and admits a polynomial iteration complexity bound. In existing inexact infeasible interior-point methods, both the linearization error of the central path and the inexactness of the Newton system accumulate along the search direction, which forces the algorithm to take very small steps. The proposed method mitigates this effect by using an arc-search strategy: the curved search path provides a more accurate approximation of the central path, so the step size can remain larger even when the Newton system is solved inexactly. As a result, the proposed method achieves a provably tighter worst-case iteration bound than existing inexact infeasible line-search methods. Numerical experiments on NETLIB benchmark problems demonstrate that the proposed method reduces both the number of iterations and the computation time.</description>
      <guid isPermaLink="false">oai:arXiv.org:2403.18155v4</guid>
      <category>math.OC</category>
      <category>cs.NA</category>
      <category>math.NA</category>
      <pubDate>Thu, 08 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Einosuke Iida, Makoto Yamashita</dc:creator>
    </item>
    <item>
      <title>Hammersley Point Sets and Inverse of Star-Discrepancy</title>
      <link>https://arxiv.org/abs/2411.10363</link>
      <description>arXiv:2411.10363v3 Announce Type: replace-cross 
Abstract: We establish the existence of $N$-point sets in dimension $d$ whose star-discrepancy is bounded above by $2.4631832 \sqrt{\frac{d}{N}}$, where the numerical constant improves upon all previously known bounds. This improvement is obtained by combining a recent result by Gnewuch on bracketing numbers in high dimensions with discrepancy bounds for Hammersley point sets due to Atanassov in dimensions $1 \leq d \leq 4$.</description>
      <guid isPermaLink="false">oai:arXiv.org:2411.10363v3</guid>
      <category>math.NT</category>
      <category>cs.NA</category>
      <category>math.NA</category>
      <pubDate>Thu, 08 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Christian Wei{\ss}</dc:creator>
    </item>
    <item>
      <title>Full-Wave Modeling of Transcranial Ultrasound using Volume-Surface Integral Equations and CT-Derived Heterogeneous Skull Data</title>
      <link>https://arxiv.org/abs/2508.11100</link>
      <description>arXiv:2508.11100v3 Announce Type: replace-cross 
Abstract: Transcranial ultrasound therapy uses focused acoustic energy to induce therapeutic bioeffects in the brain. Ultrasound must be transmitted through the skull, which is highly attenuating and heterogeneous, causing beam distortion, reducing focal pressure, and shifting the target location. Computational models are frequently used to predict beam aberration, assess cranial heating, and correct the phase of ultrasound transducers. These models often rely on computed tomography (CT) images to build patient-specific geometries and estimate skull acoustic properties. However, the coarse voxel resolution of CT limits accuracy for differential equation solvers at ultrasound frequencies. This paper presents an efficient numerical method based on volume-surface integral equations to model full-wave acoustic propagation through heterogeneous skull bone. We show that our approach effectively simulates transcranial ultrasound, even when using the original CT voxels as the computational mesh, where the 0.5 mm voxel length is relatively coarse compared to the shortest wavelength of 3 mm. The method is validated against a high-resolution boundary element model using an averaged skull representation. Simulations using a CT-based skull model and a bowl transducer reveal significant beam distortion of 7.8 mm attributed to the skull's heterogeneous acoustical properties.</description>
      <guid isPermaLink="false">oai:arXiv.org:2508.11100v3</guid>
      <category>physics.med-ph</category>
      <category>cs.NA</category>
      <category>eess.IV</category>
      <category>math.NA</category>
      <category>physics.comp-ph</category>
      <pubDate>Thu, 08 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <arxiv:DOI>10.1016/j.ultras.2026.107954</arxiv:DOI>
      <dc:creator>Alberto Almuna-Morales, Danilo Aballay, Pierre G\'elat, Reza Haqshenas, Elwin van 't Wout</dc:creator>
    </item>
  </channel>
</rss>
