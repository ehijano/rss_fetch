<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>math.IT updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/math.IT</link>
    <description>math.IT updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/math.IT" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Fri, 06 Feb 2026 02:46:44 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Thu, 05 Feb 2026 00:00:00 -0500</pubDate>
    <skipDays>
      <day>Saturday</day>
      <day>Sunday</day>
    </skipDays>
    <item>
      <title>Semantic Rate Distortion and Posterior Design: Compute Constraints, Multimodality, and Strategic Inference</title>
      <link>https://arxiv.org/abs/2602.03949</link>
      <description>arXiv:2602.03949v1 Announce Type: new 
Abstract: We study strategic Gaussian semantic compression under rate and compute constraints, where an encoder and decoder optimize distinct quadratic objectives. A latent Gaussian state generates a task dependent semantic variable, and the decoder best responds via MMSE estimation, reducing the encoder's problem to posterior covariance design under an information rate constraint. We characterize the strategic rate distortion function in direct, remote, and full information regimes, derive semantic waterfilling and rate constrained Gaussian persuasion solutions, and establish Gaussian optimality under misaligned objectives. We further show that architectural compute limits act as implicit rate constraints, yielding exponential improvements in semantic accuracy with model depth and inference time compute, while multimodal observation eliminates the geometric mean penalty inherent to remote encoding. These results provide information theoretic foundations for data and energy efficient AI and offer a principled interpretation of modern multimodal language models as posterior design mechanisms under resource constraints.</description>
      <guid isPermaLink="false">oai:arXiv.org:2602.03949v1</guid>
      <category>cs.IT</category>
      <category>cs.AI</category>
      <category>cs.LG</category>
      <category>math.IT</category>
      <pubDate>Thu, 05 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Emrah Akyol</dc:creator>
    </item>
    <item>
      <title>Joint Sleep Mode Activation and Load Balancing with Dynamic Cell Load: A Combinatorial Bandit Approach</title>
      <link>https://arxiv.org/abs/2602.04808</link>
      <description>arXiv:2602.04808v1 Announce Type: new 
Abstract: We propose a combinatorial bandit formulation to opportunistically trigger sleep modes in gNode-B (gNB) small cells (SCs), followed by a cell range expansion (CRE)-based load balancing procedure. This is implemented by ensuring that the fifth generation (5G) quality of service identifier (5QI)-requirements of user equipments (UEs) are maintained. The key challenge is the fact that while deactivating a given SC gNB reduces its own consumption, it may increase the load on neighboring gNBs and the macro gNB (coverage cell), impacting the overall energy efficiency. This phenomenon is accurately characterized by modeling the dynamic cell load that jointly takes into account the location of the UEs, their relative locations to all the SCs, and their data demands. We experimentally show that the proposed combinatorial upper confidence bound (CUCB) followed by the load balancer outperforms not only the naive strategies like arbitrarily keeping all the SCs on, but also other state-of-the-art reinforcement learning solutions. The proposed algorithm can be implemented as open-radio access network (O-RAN) near-real-time (NRT) RAN intelligent controller (RIC) xApps.</description>
      <guid isPermaLink="false">oai:arXiv.org:2602.04808v1</guid>
      <category>cs.IT</category>
      <category>math.IT</category>
      <pubDate>Thu, 05 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Wajahat Bashir Gilkar, Gourab Ghatak</dc:creator>
    </item>
    <item>
      <title>Game of Coding for Vector-Valued Computations</title>
      <link>https://arxiv.org/abs/2602.04810</link>
      <description>arXiv:2602.04810v1 Announce Type: new 
Abstract: The game of coding is a new framework at the intersection of game theory and coding theory; designed to transcend the fundamental limitations of classical coding theory. While traditional coding theoretic schemes rely on a strict trust assumption, that honest nodes must outnumber adversarial ones to guarantee valid decoding, the game of coding leverages the economic rationality of actors to guarantee correctness and reliable decodability, even in the presence of an adversarial majority. This capability is paramount for emerging permissionless applications, particularly decentralized machine learning (DeML). However, prior investigations into the game of coding have been strictly confined to scalar computations, limiting their applicability to real world tasks where high dimensional data is the norm. In this paper, we bridge this gap by extending the framework to the general $N$-dimensional Euclidean space. We provide a rigorous problem formulation for vector valued computations and fully characterize the equilibrium strategies of the resulting high dimensional game. Our analysis demonstrates that the resilience properties established in the scalar setting are preserved in the vector regime, establishing a theoretical foundation for secure, large scale decentralized computing without honest majority assumptions.</description>
      <guid isPermaLink="false">oai:arXiv.org:2602.04810v1</guid>
      <category>cs.IT</category>
      <category>math.IT</category>
      <pubDate>Thu, 05 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Hanzaleh Akbari Nodehi, Parsa Moradi, Soheil Mohajer, Mohammad Ali Maddah-Ali</dc:creator>
    </item>
    <item>
      <title>Capacity Bounds on Doppler OFDM Channels</title>
      <link>https://arxiv.org/abs/2602.04862</link>
      <description>arXiv:2602.04862v1 Announce Type: new 
Abstract: Low Earth orbit (LEO) satellite systems experience significant Doppler effects due to high mobility. While Doppler shifts can be largely compensated, residual frequency uncertainty induces a structured form of channel uncertainty that can limit achievable rates. We model this effect using a block-fading channel of the form $ \mathbf{H} = \mathbf{F} + s \mathbf{G} $, where $s$ is an unknown scalar random parameter. We first study this model in a general $N\times N$ MIMO setting. For this channel, we derive achievable rate lower bounds based on explicit transmission schemes and capacity upper bounds using a duality approach. We study Gaussian signaling and propose a practical superposition scheme with subspace alignment (SN) and successive interference cancellation, where a coarse-layer stream serves as an implicit pilot for decoding refined-layer data. We characterize asymptotic capacity in the near-coherent and high-SNR regimes, and show via Doppler-OFDM simulations that the proposed SN scheme achieves near-optimal rates with low complexity.</description>
      <guid isPermaLink="false">oai:arXiv.org:2602.04862v1</guid>
      <category>cs.IT</category>
      <category>math.IT</category>
      <pubDate>Thu, 05 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Pablo Orellana, Zheng Li, Jean-Marc Kelif, Sheng Yang, Shlomo Shamai</dc:creator>
    </item>
    <item>
      <title>GeoIB: Geometry-Aware Information Bottleneck via Statistical-Manifold Compression</title>
      <link>https://arxiv.org/abs/2602.03906</link>
      <description>arXiv:2602.03906v1 Announce Type: cross 
Abstract: Information Bottleneck (IB) is widely used, but in deep learning, it is usually implemented through tractable surrogates, such as variational bounds or neural mutual information (MI) estimators, rather than directly controlling the MI I(X;Z) itself. The looseness and estimator-dependent bias can make IB "compression" only indirectly controlled and optimization fragile.
  We revisit the IB problem through the lens of information geometry and propose a \textbf{Geo}metric \textbf{I}nformation \textbf{B}ottleneck (\textbf{GeoIB}) that dispenses with mutual information (MI) estimation. We show that I(X;Z) and I(Z;Y) admit exact projection forms as minimal Kullback-Leibler (KL) distances from the joint distributions to their respective independence manifolds. Guided by this view, GeoIB controls information compression with two complementary terms: (i) a distribution-level Fisher-Rao (FR) discrepancy, which matches KL to second order and is reparameterization-invariant; and (ii) a geometry-level Jacobian-Frobenius (JF) term that provides a local capacity-type upper bound on I(Z;X) by penalizing pullback volume expansion of the encoder. We further derive a natural-gradient optimizer consistent with the FR metric and prove that the standard additive natural-gradient step is first-order equivalent to the geodesic update. We conducted extensive experiments and observed that the GeoIB achieves a better trade-off between prediction accuracy and compression ratio in the information plane than the mainstream IB baselines on popular datasets. GeoIB improves invariance and optimization stability by unifying distributional and geometric regularization under a single bottleneck multiplier. The source code of GeoIB is released at "https://anonymous.4open.science/r/G-IB-0569".</description>
      <guid isPermaLink="false">oai:arXiv.org:2602.03906v1</guid>
      <category>cs.LG</category>
      <category>cs.AI</category>
      <category>cs.IT</category>
      <category>math.IT</category>
      <category>stat.ML</category>
      <pubDate>Thu, 05 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <dc:creator>Weiqi Wang, Zhiyi Tian, Chenhan Zhang, Shui Yu</dc:creator>
    </item>
    <item>
      <title>Supervised Learning as Lossy Compression: Characterizing Generalization and Sample Complexity via Finite Blocklength Analysis</title>
      <link>https://arxiv.org/abs/2602.04107</link>
      <description>arXiv:2602.04107v1 Announce Type: cross 
Abstract: This paper presents a novel information-theoretic perspective on generalization in machine learning by framing the learning problem within the context of lossy compression and applying finite blocklength analysis. In our approach, the sampling of training data formally corresponds to an encoding process, and the model construction to a decoding process. By leveraging finite blocklength analysis, we derive lower bounds on sample complexity and generalization error for a fixed randomized learning algorithm and its associated optimal sampling strategy. Our bounds explicitly characterize the degree of overfitting of the learning algorithm and the mismatch between its inductive bias and the task as distinct terms. This separation provides a significant advantage over existing frameworks. Additionally, we decompose the overfitting term to show its theoretical connection to existing metrics found in information-theoretic bounds and stability theory, unifying these perspectives under our proposed framework.</description>
      <guid isPermaLink="false">oai:arXiv.org:2602.04107v1</guid>
      <category>cs.LG</category>
      <category>cs.IT</category>
      <category>math.IT</category>
      <pubDate>Thu, 05 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Kosuke Sugiyama, Masato Uchida</dc:creator>
    </item>
    <item>
      <title>An Enhanced Polar-Domain Dictionary Design for Elevated BSs in Near-Field U-MIMO</title>
      <link>https://arxiv.org/abs/2602.04331</link>
      <description>arXiv:2602.04331v1 Announce Type: cross 
Abstract: Near-field U-MIMO communications require carefully optimized sampling grids in both angular and distance domains. However, most existing grid design methods neglect the influence of base station height, assuming instead that the base station is positioned at ground level - a simplification that rarely reflects real-world deployments. To overcome this limitation, we propose a generalized grid design framework that accommodates arbitrary base station locations. Unlike conventional correlation-based approaches, our method optimizes the grid based on the minimization of the optimal normalized mean squared error, leading to more accurate channel representation. We evaluate the performance of a hybrid U-MIMO system operating at sub-THz frequencies, considering the P-SOMP algorithm for channel estimation. Analytical and numerical results show that the proposed design enhances both channel estimation accuracy and spectral efficiency compared to existing alternatives.</description>
      <guid isPermaLink="false">oai:arXiv.org:2602.04331v1</guid>
      <category>eess.SP</category>
      <category>cs.IT</category>
      <category>math.IT</category>
      <pubDate>Thu, 05 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Luca Antonelli, Antonio Alberto D'Amico, Luca Sanguinetti</dc:creator>
    </item>
    <item>
      <title>Cross-Attention Transformer for Joint Multi-Receiver Uplink Neural Decoding</title>
      <link>https://arxiv.org/abs/2602.04728</link>
      <description>arXiv:2602.04728v1 Announce Type: cross 
Abstract: We propose a cross-attention Transformer for joint decoding of uplink OFDM signals received by multiple coordinated access points. A shared per-receiver encoder learns time-frequency structure within each received grid, and a token-wise cross-attention module fuses the receivers to produce soft log-likelihood ratios for a standard channel decoder, without requiring explicit per-receiver channel estimates. Trained with a bit-metric objective, the model adapts its fusion to per-receiver reliability, tolerates missing or degraded links, and remains robust when pilots are sparse. Across realistic Wi-Fi channels, it consistently outperforms classical pipelines and strong convolutional baselines, frequently matching (and in some cases surpassing) a powerful baseline that assumes perfect channel knowledge per access point. Despite its expressiveness, the architecture is compact, has low computational cost (low GFLOPs), and achieves low latency on GPUs, making it a practical building block for next-generation Wi-Fi receivers.</description>
      <guid isPermaLink="false">oai:arXiv.org:2602.04728v1</guid>
      <category>eess.SP</category>
      <category>cs.IT</category>
      <category>cs.LG</category>
      <category>math.IT</category>
      <pubDate>Thu, 05 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Xavier Tardy, Gr\'egoire Lefebvre, Apostolos Kountouris, Ha\"ifa Fares, Amor Nafkha</dc:creator>
    </item>
    <item>
      <title>Differentially Private Sampling via Reveal-or-Obscure</title>
      <link>https://arxiv.org/abs/2504.14696</link>
      <description>arXiv:2504.14696v2 Announce Type: replace 
Abstract: We introduce a differentially private (DP) algorithm called Reveal-or-Obscure (ROO) to generate a single representative sample from a dataset of n i.i.d. observations from an unknown distribution. Unlike methods that add explicit noise to the estimated empirical distribution, ROO achieves $\epsilon$-differential privacy by choosing whether to "reveal" or "obscure" the empirical distribution with a fixed probability $q$. While our proposed mechanism is structurally identical to an algorithm proposed by Cheu and Nayak, we prove a strictly better bound on the sampling complexity than that established in their theorem. Building on this framework, we propose a novel generalized sampler called Data-Specific ROO (DS-ROO), where the obscuring probability $q$ is a function of the empirical distribution. We show that when the dataset contains enough samples from every element of the alphabet, DS-ROO can achieve $\epsilon$-DP while obscuring much less. In addition, we provide tight upper bounds on the utility of DS-ROO in terms of total variation distance. Our results show that under the same privacy budget, DS-ROO can achieve better utility than state-of-the-art private samplers and vanilla ROO, with total variation distance decaying exponentially in dataset size $n$.</description>
      <guid isPermaLink="false">oai:arXiv.org:2504.14696v2</guid>
      <category>cs.IT</category>
      <category>cs.CR</category>
      <category>cs.DS</category>
      <category>cs.LG</category>
      <category>math.IT</category>
      <pubDate>Thu, 05 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Naima Tasnim, Atefeh Gilani, Lalitha Sankar, Oliver Kosut</dc:creator>
    </item>
    <item>
      <title>On the Tail Transition of First Arrival Position Channels: From Cauchy to Exponential Decay</title>
      <link>https://arxiv.org/abs/2511.19074</link>
      <description>arXiv:2511.19074v2 Announce Type: replace 
Abstract: While the zero-drift first arrival position (FAP) channel is known to exhibit a Cauchy noise distribution, practical molecular communication systems typically operate under nonzero drift. This letter analyzes the resulting transition in FAP noise behavior from heavy-tailed algebraic decay to exponential regularization. By asymptotically examining the exact FAP distribution, we identify a characteristic propagation distance (CPD) $r_c=\sigma^2/v$ that separates diffusion-dominated and drift-dominated regimes. Numerical results show that in low-drift environments, Gaussian approximations substantially underestimate the achievable rate, whereas the zero-drift Cauchy model provides a physically grounded performance baseline.</description>
      <guid isPermaLink="false">oai:arXiv.org:2511.19074v2</guid>
      <category>cs.IT</category>
      <category>eess.SP</category>
      <category>math.IT</category>
      <category>math.PR</category>
      <pubDate>Thu, 05 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Yen-Chi Lee</dc:creator>
    </item>
    <item>
      <title>Exact 3-D Channel Impulse Response Under Uniform Drift for Absorbing Spherical Receivers</title>
      <link>https://arxiv.org/abs/2512.04858</link>
      <description>arXiv:2512.04858v2 Announce Type: replace 
Abstract: An exact channel impulse response (CIR) for the three-dimensional point-to-sphere absorbing channel under drift has remained unavailable due to symmetry breaking. This letter closes this gap by deriving an exact analytical CIR for a fully absorbing spherical receiver under uniform drift with arbitrary direction. By formulating the problem in terms of joint first-hitting time-location statistics and applying a Girsanov-based measure change, drift effects are isolated into an explicit multiplicative factor, yielding an exact series representation. The resulting CIR provides a rigorous reference model and enables efficient, noise-free evaluation of key channel metrics without relying on Monte Carlo simulations.</description>
      <guid isPermaLink="false">oai:arXiv.org:2512.04858v2</guid>
      <category>cs.IT</category>
      <category>eess.SP</category>
      <category>math.IT</category>
      <category>math.PR</category>
      <pubDate>Thu, 05 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Yen-Chi Lee, Ping-Cheng Yeh, Chia-Han Lee</dc:creator>
    </item>
    <item>
      <title>Dualities of dihedral and generalised quaternion codes and applications to quantum codes</title>
      <link>https://arxiv.org/abs/2512.07354</link>
      <description>arXiv:2512.07354v2 Announce Type: replace 
Abstract: Let $\mathbb{F}_q$ be a finite field of $q$ elements, for some prime power $q$, and let $G$ be a finite group. A (left) group code, or simply a $G$-code, is a (left) ideal of the group algebra $\mathbb{F}_q[G]$. In this paper, we provide a complete algebraic description for the hermitian dual code of any $D_n$-code over $\mathbb{F}_{q^2}$, where $D_n$ is a dihedral group of order $2n$ with $n$ not divisible by char$(\mathbb{F}_{q^2})$, through a suitable Wedderburn-Artin's decomposition of the group algebra $\mathbb{F}_{q^2}[D_n]$, and we determine all distinct hermitian self-orthogonal $D_n$-codes over $\mathbb{F}_{q^2}$. We also present a thorough representation of the euclidean dual code of any $Q_n$-code over $\mathbb{F}_q$, where $Q_n$ is a generalised quaternion group of order $4n$ not divisible by char$(\mathbb{F}_q)$, via the Wedderburn-Artin's decomposition of the group algebra $\mathbb{F}_q[Q_n]$. In particular, since the semisimple group algebras $\mathbb{F}_{q^2}[Q_n]$ and $\mathbb{F}_{q^2}[D_{2n}]$ are isomorphic, then the hermitian dual code of any $Q_n$-code has also been fully described. As application of the hermitian dualities computed, we give a systematic construction, via the structure of the group algebra, to obtain quantum error-correcting codes, and in fact we rebuild some already known optimal quantum codes with this methodical approach.</description>
      <guid isPermaLink="false">oai:arXiv.org:2512.07354v2</guid>
      <category>cs.IT</category>
      <category>math.IT</category>
      <category>math.QA</category>
      <category>math.RA</category>
      <pubDate>Thu, 05 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Miguel Sales-Cabrera, Xaro Soler-Escriv\`a, V\'ictor Sotomayor</dc:creator>
    </item>
    <item>
      <title>Spectral-Aligned Pruning for Universal Error-Correcting Code Transformers</title>
      <link>https://arxiv.org/abs/2602.01602</link>
      <description>arXiv:2602.01602v2 Announce Type: replace 
Abstract: Recently, the Foundation Error Correction Code Transformer (FECCT) has emerged as a promising universal channel decoder, achieving competitive decoding performance across diverse code families by relying on a single shared model backbone, optionally followed by code-specific retraining. Despite this flexibility, the high computational complexity and large parameter footprint of transformer-based decoders present substantial obstacles to practical deployment. To address these challenges, we investigate structured pruning for FECCT and propose Spectral-Aligned Pruning (SAP), a structure-aware framework that enables cross-code reuse of structured pruning masks across codes by leveraging the spectrum of the corresponding bipartite graph. After pruning, SAP performs per-code recovery via parameter-efficient low-rank adaptation (LoRA), enabling a shared pruned backbone while storing only small code-specific adapter parameters. Experiments across diverse codes show that SAP achieves decoding performance comparable to dedicated per-code pruning, while enabling substantial reductions in computational cost and model memory footprint through kernel-level structured pruning.</description>
      <guid isPermaLink="false">oai:arXiv.org:2602.01602v2</guid>
      <category>cs.IT</category>
      <category>math.IT</category>
      <pubDate>Thu, 05 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Sanghyeon Cho, Taewoo Park, Seong-Joon Park, Dae-Young Yun, Hee-Youl Kwak, Sang-Hyo Kim, Yongjune Kim</dc:creator>
    </item>
    <item>
      <title>The Lov\'asz Theta Function for Recovering Planted Clique Covers and Graph Colorings</title>
      <link>https://arxiv.org/abs/2310.00257</link>
      <description>arXiv:2310.00257v2 Announce Type: replace-cross 
Abstract: The problems of computing graph colorings and clique covers are central challenges in combinatorial optimization. Both of these are known to be NP-hard, and thus computationally intractable in the worst-case instance. A prominent approach for computing approximate solutions to these problems is the celebrated Lov\'asz theta function $\vartheta(G)$, which is specified as the solution of a semidefinite program (SDP), and hence tractable to compute. In this work, we move beyond the worst-case analysis and set out to understand whether the Lov\'asz theta function recovers clique covers for random instances that have a latent clique cover structure, possibly obscured by noise. We answer this question in the affirmative and show that for graphs generated from the planted clique model we introduce in this work, the SDP formulation of $\vartheta(G)$ has a unique solution that reveals the underlying clique-cover structure with high-probability. The main technical step is an intermediate result where we prove a deterministic condition of recovery based on an appropriate notion of sparsity.</description>
      <guid isPermaLink="false">oai:arXiv.org:2310.00257v2</guid>
      <category>math.OC</category>
      <category>cs.DS</category>
      <category>cs.IT</category>
      <category>math.CO</category>
      <category>math.IT</category>
      <pubDate>Thu, 05 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Jiaxin Hou, Yong Sheng Soh, Antonios Varvitsiotis</dc:creator>
    </item>
    <item>
      <title>Three results on twisted $G-$codes and skew twisted $G-$codes</title>
      <link>https://arxiv.org/abs/2601.00752</link>
      <description>arXiv:2601.00752v4 Announce Type: replace-cross 
Abstract: In this paper we solve an open question formulated in the original paper of twisted skew group codes regarding when a twisted skew group code is checkable. Also, we prove that all ideals of dimension 3 over a twisted group algebra are abelian group codes, generalising another previous result over group algebras. Finally, we prove a bound on the dimension and distance of a twisted group code, as well as when such bound is reached.</description>
      <guid isPermaLink="false">oai:arXiv.org:2601.00752v4</guid>
      <category>math.AG</category>
      <category>cs.CR</category>
      <category>cs.IT</category>
      <category>math.IT</category>
      <pubDate>Thu, 05 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Alvaro Otero Sanchez</dc:creator>
    </item>
    <item>
      <title>Hallucination is a Consequence of Space-Optimality: A Rate-Distortion Theorem for Membership Testing</title>
      <link>https://arxiv.org/abs/2602.00906</link>
      <description>arXiv:2602.00906v4 Announce Type: replace-cross 
Abstract: Large language models often hallucinate with high confidence on "random facts" that lack inferable patterns. We formalize the memorization of such facts as a membership testing problem, unifying the discrete error metrics of Bloom filters with the continuous log-loss of LLMs. By analyzing this problem in the regime where facts are sparse in the universe of plausible claims, we establish a rate-distortion theorem: the optimal memory efficiency is characterized by the minimum KL divergence between score distributions on facts and non-facts. This theoretical framework provides a distinctive explanation for hallucination: even with optimal training, perfect data, and a simplified "closed world" setting, the information-theoretically optimal strategy under limited capacity is not to abstain or forget, but to assign high confidence to some non-facts, resulting in hallucination. We validate this theory empirically on synthetic data, showing that hallucinations persist as a natural consequence of lossy compression.</description>
      <guid isPermaLink="false">oai:arXiv.org:2602.00906v4</guid>
      <category>cs.LG</category>
      <category>cs.AI</category>
      <category>cs.CL</category>
      <category>cs.DS</category>
      <category>cs.IT</category>
      <category>math.IT</category>
      <pubDate>Thu, 05 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Anxin Guo, Jingwei Li</dc:creator>
    </item>
    <item>
      <title>Statistics Approximation-Enabled Distributed Beamforming for Cell-Free Massive MIMO</title>
      <link>https://arxiv.org/abs/2602.03590</link>
      <description>arXiv:2602.03590v2 Announce Type: replace-cross 
Abstract: We study a distributed beamforming approach for cell-free massive multiple-input multiple-output networks, referred to as Global Statistics &amp; Local Instantaneous information-based minimum mean-square error (GSLI-MMSE). The scenario with multi-antenna access points (APs) is considered over three different channel models: correlated Rician fading with fixed or random line-of-sight (LoS) phase-shifts, and correlated Rayleigh fading. With the aid of matrix inversion derivations, we can construct the conventional MMSE combining from the perspective of each AP, where global instantaneous information is involved. Then, for an arbitrary AP, we apply the statistics approximation methodology to approximate instantaneous terms related to other APs by channel statistics to construct the distributed combining scheme at each AP with local instantaneous information and global statistics. With the aid of uplink-downlink duality, we derive the respective GSLI-MMSE precoding schemes. Numerical results showcase that the proposed GSLI-MMSE scheme demonstrates performance comparable to the optimal centralized MMSE scheme, under the stable LoS conditions, e.g., with static users having Rician fading with a fixed LoS path.</description>
      <guid isPermaLink="false">oai:arXiv.org:2602.03590v2</guid>
      <category>eess.SP</category>
      <category>cs.IT</category>
      <category>math.IT</category>
      <pubDate>Thu, 05 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Zhe Wang, Emil Bj\"ornson, Jiayi Zhang, Peng Zhang, Vitaly Petrov, Bo Ai</dc:creator>
    </item>
  </channel>
</rss>
