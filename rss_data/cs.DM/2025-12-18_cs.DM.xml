<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>cs.DM updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/cs.DM</link>
    <description>cs.DM updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/cs.DM" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Thu, 18 Dec 2025 05:00:13 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Thu, 18 Dec 2025 00:00:00 -0500</pubDate>
    <skipDays>
      <day>Saturday</day>
      <day>Sunday</day>
    </skipDays>
    <item>
      <title>A Constant-Factor Approximation for Directed Latency</title>
      <link>https://arxiv.org/abs/2512.15473</link>
      <description>arXiv:2512.15473v1 Announce Type: cross 
Abstract: In the Directed Latency problem, we are given an asymmetric metric on a set of vertices (or clients), and a given depot $s$. We seek a path $P$ starting at $s$ and visiting all the clients so as to minimize the sum of client waiting times (also known as latency) before being visited on the path.
  In contrast to the symmetric version of this problem (also known as the Deliveryperson problem and the Repairperson problem in the literature), there are significant gaps in our understanding of Directed Latency. The best approximation factor has remained at $O(\log n)$, where $n$ is the number of clients, for more than a decade [Friggstad, Salavatipour, and Svitkina, '13]. Only recently, [Friggstad and Swamy, '22] presented a constant-factor approximation but in quasi-polynomial time. Both results follow similar ideas: they consider buckets with geometrically-increasing distances, build paths in each bucket, and then stitch together all these paths to get a feasible solution. [Friggstad and Swamy, '22] showed if we guess a vertex from each bucket and augment a standard LP relaxation with these guesses, then one can reduce the stitching cost. Unfortunately, there are logarithmically many buckets so the running time of their algorithm is quasi-polynomial.
  In this paper, we present the first constant-factor approximation for Directed Latency in polynomial time by introducing a completely new way of bucketing which helps us strengthen a standard LP relaxation with less aggressive guessing. Although the resulting LP is no longer a relaxation of Directed Latency, it still admits a good solution. We present a rounding algorithm for fractional solutions of our LP, crucially exploiting the way we restricted the feasibility region of the LP formulation.</description>
      <guid isPermaLink="false">oai:arXiv.org:2512.15473v1</guid>
      <category>cs.DS</category>
      <category>cs.DM</category>
      <pubDate>Thu, 18 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Jannis Blauth, Ramin Mousavi</dc:creator>
    </item>
    <item>
      <title>Completely Independent Spanning Trees in Split Graphs: Structural Properties and Complexity</title>
      <link>https://arxiv.org/abs/2512.15486</link>
      <description>arXiv:2512.15486v1 Announce Type: cross 
Abstract: We study completely independent spanning trees (CIST), \textit{i.e.}, trees that are both edge-disjoint and internally vertex-disjoint, in split graphs. We establish a correspondence between the existence of CIST in a split graph and some types of hypergraph colorings (panchromatic and bipanchromatic colorings) of its associated hypergraph, allowing us to obtain lower and upper bounds on the number of CIST. Using these relations, we prove that the problem of the existence of two CIST in a split graph is NP-complete. Finally, we formulate a conjecture on the bipanchromatic number of a hypergraph related to the results obtained for the number of CIST.</description>
      <guid isPermaLink="false">oai:arXiv.org:2512.15486v1</guid>
      <category>math.CO</category>
      <category>cs.DM</category>
      <pubDate>Thu, 18 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Mohammed Lalou, Nader Mbarek, Abdallah Skender, Olivier Togni</dc:creator>
    </item>
    <item>
      <title>Algorithmizing the Multiplicity Schwartz-Zippel Lemma</title>
      <link>https://arxiv.org/abs/2111.11072</link>
      <description>arXiv:2111.11072v3 Announce Type: replace-cross 
Abstract: The multiplicity Schwartz-Zippel lemma asserts that over a field, a low-degree polynomial cannot vanish with high multiplicity very often on a sufficiently large product set. Since its discovery in a work of Dvir, Kopparty, Saraf and Sudan [SIAM J. Comput., 2013], the lemma has found numerous applications in both math and computer science; in particular, in the definition and properties of multiplicity codes by Kopparty, Saraf and Yekhanin [J. ACM, 2014].
  In this work, we show how to algorithmize the multiplicity Schwartz-Zippel lemma for arbitrary product sets over any field. In other words, we give an efficient algorithm for unique decoding of multivariate multiplicity codes from half their minimum distance on arbitrary product sets over all fields. Previously, such an algorithm was known either when the underlying product set had a nice algebraic structure: for instance, was a subfield (by Kopparty [ToC, 2015]) or when the underlying field had large (or zero) characteristic, the multiplicity parameter was sufficiently large and the multiplicity code had distance bounded away from $1$ (Bhandari, Harsha, Kumar and Sudan [STOC 2021]). In particular, even unique decoding of bivariate multiplicity codes with multiplicity two from half their minimum distance was not known over arbitrary product sets over any field.
  Our algorithm builds upon a result of Kim and Kopparty [ToC, 2017] who gave an algorithmic version of the Schwartz-Zippel lemma (without multiplicities) or equivalently, an efficient algorithm for unique decoding of Reed-Muller codes over arbitrary product sets. We introduce a refined notion of distance based on the multiplicity Schwartz-Zippel lemma and design a unique decoding algorithm for this distance measure. On the way, we give an alternate analysis of Forney's classical generalized minimum distance decoder that might be of independent interest.</description>
      <guid isPermaLink="false">oai:arXiv.org:2111.11072v3</guid>
      <category>cs.CC</category>
      <category>cs.DM</category>
      <category>cs.IT</category>
      <category>math.IT</category>
      <pubDate>Thu, 18 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <arxiv:DOI>10.46298/theoretics.25.29</arxiv:DOI>
      <arxiv:journal_reference>TheoretiCS, Volume 4 (2025), Article 29, 1-53</arxiv:journal_reference>
      <dc:creator>Siddharth Bhandari, Prahladh Harsha, Mrinal Kumar, Ashutosh Shankar</dc:creator>
    </item>
    <item>
      <title>Enigma: Application-Layer Privacy for Quantum Optimization on Untrusted Computers</title>
      <link>https://arxiv.org/abs/2311.13546</link>
      <description>arXiv:2311.13546v2 Announce Type: replace-cross 
Abstract: The Early Fault-Tolerant (EFT) era is emerging, where modest Quantum Error Correction (QEC) can enable quantum utility before full-scale fault tolerance. Quantum optimization is a leading candidate for early applications, but protecting these workloads is critical since they will run on expensive cloud services where providers could learn sensitive problem details. Experience with classical computing systems has shown that treating security as an afterthought can lead to significant vulnerabilities. Thus, we must address the security implications of quantum computing before widespread adoption. However, current Secure Quantum Computing (SQC) approaches, although theoretically promising, are impractical in the EFT era: blind quantum computing requires large-scale quantum networks, and quantum homomorphic encryption depends on full QEC.
  We propose application-specific SQC, a principle that applies obfuscation at the application layer to enable practical deployment while remaining agnostic to algorithms, computing models, and hardware architectures. We present Enigma, the first realization of this principle for quantum optimization. Enigma integrates three complementary obfuscations: ValueGuard scrambles coefficients, StructureCamouflage inserts decoys, and TopologyTrimmer prunes variables. These techniques guarantee recovery of original solutions, and their stochastic nature resists repository-matching attacks. Evaluated against seven state-of-the-art AI models across five representative graph families, even combined adversaries, under a conservatively strong attacker model, identify the correct problem within their top five guesses in only 4.4% of cases. The protections come at the cost of problem size and T-gate counts increasing by averages of 1.07x and 1.13x, respectively, with both obfuscation and decoding completing within seconds for large-scale problems.</description>
      <guid isPermaLink="false">oai:arXiv.org:2311.13546v2</guid>
      <category>quant-ph</category>
      <category>cs.AI</category>
      <category>cs.CR</category>
      <category>cs.DM</category>
      <category>cs.ET</category>
      <pubDate>Thu, 18 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Ramin Ayanzadeh, Ahmad Mousavi, Amirhossein Basareh, Narges Alavisamani, Kazem Taram</dc:creator>
    </item>
    <item>
      <title>Degree Realization by Bipartite Multigraphs</title>
      <link>https://arxiv.org/abs/2501.15515</link>
      <description>arXiv:2501.15515v4 Announce Type: replace-cross 
Abstract: The problem of realizing a given degree sequence by a multigraph can be thought of as a relaxation of the classical degree realization problem (where the realizing graph is simple). This paper concerns the case where the realizing multigraph is required to be bipartite.
  The problem of characterizing sequences that can be realized by a bipartite graph has two variants. In the simpler one, termed BDR$^P$, the partition of the sequence into two sides is given as part of the input. A complete characterization for realizability in this variant was given by Gale and Ryser over sixty years ago. However, the variant where the partition is not given, termed BDR, is still open.
  For bipartite multigraph realizations, there are also two variants. For BDR$^P$, where the partition is given as part of the input, a characterization was known for determining whether there is a multigraph realization whose underlying graph is bipartite, such that the maximum number of copies of an edge is at most $r$. We present a characterization for determining if there is a bipartite multigraph realization such that the total number of excess edges is at most $t$. We show that optimizing these two measures may lead to different realizations, and that optimizing by one measure may increase the other substantially. As for the variant BDR, where the partition is not given, we show that determining whether a given (single) sequence admits a bipartite multigraph realization is NP-hard. Moreover, we show that this hardness result extends to any graph family which is a sub-family of bipartite graphs and a super-family of paths. On the positive side, we provide an algorithm that computes optimal realizations for the case where the number of balanced partitions is polynomial, and present sufficient conditions for the existence of bipartite multigraph realizations that depend only on the largest degree of the sequence.</description>
      <guid isPermaLink="false">oai:arXiv.org:2501.15515v4</guid>
      <category>math.CO</category>
      <category>cs.DM</category>
      <pubDate>Thu, 18 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Amotz Bar-Noy, Toni Bohnlein, David Peleg, Dror Rawitz</dc:creator>
    </item>
    <item>
      <title>New constructions of free products and geodetic Cayley graphs</title>
      <link>https://arxiv.org/abs/2509.22188</link>
      <description>arXiv:2509.22188v2 Announce Type: replace-cross 
Abstract: A connected graph is called \emph{geodetic} if there is a unique shortest path between each pair of vertices. We introduce a systematic method for constructing new presentations of free products that give rise to previously unknown geodetic Cayley graphs. Our approach adapts subdivision techniques of Parthasarathy and Srinivasan (J. Combin. Theory Ser. B, 1982), which preserve geodecity at the graph level, to the setting of group presentations and rewriting systems. Specifically, given a group $G$ with geodetic Cayley graph with respect to generating set $\Sigma$ and an integer $n$, our construction produces a rewriting system presenting the free product of $G$ with a free group of rank $n|\Sigma|$ with geodetic Cayley graph with respect to a new generating set. This framework provides new infinite families of geodetic Cayley graphs and extends the toolkit for investigating long-standing conjectures on geodetic groups.</description>
      <guid isPermaLink="false">oai:arXiv.org:2509.22188v2</guid>
      <category>math.GR</category>
      <category>cs.DM</category>
      <pubDate>Thu, 18 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Joshua Abraham, Murray Elder, Adam Piggott, Kane Townsend</dc:creator>
    </item>
    <item>
      <title>Toward P != NP: An Observer-Theoretic Separation via SPDP Rank and a ZFC-Equivalent Foundation within the N-Frame Model</title>
      <link>https://arxiv.org/abs/2512.11820</link>
      <description>arXiv:2512.11820v2 Announce Type: replace-cross 
Abstract: We present a self-contained separation framework for P vs NP developed entirely within ZFC. The approach consists of: (i) a deterministic, radius-1 compilation from uniform polynomial-time Turing computation to local sum-of-squares (SoS) polynomials with polylogarithmic contextual entanglement width (CEW); (ii) a formal Width-to-Rank upper bound for the resulting SPDP matrices at matching parameters; (iii) an NP-side identity-minor lower bound in the same encoding; and (iv) a rank-monotone, instance-uniform extraction map from the compiled P-side polynomials to the NP family. Together these yield a contradiction under the assumption P = NP, establishing a separation.
  We develop a correspondence between CEW, viewed as a quantitative measure of computational contextuality, and SPDP rank, yielding a unified criterion for complexity separation. We prove that bounded-CEW observers correspond to polynomial-rank computations (the class P), while unbounded CEW characterizes the class NP. This implies that exponential SPDP rank for #3SAT and related hard families forces P != NP within the standard framework of complexity theory.
  Key technical components include: (1) constructive lower bounds on SPDP rank via Ramanujan-Tseitin expander families; (2) a non-circular reduction from Turing-machine computation to low-rank polynomial evaluation; (3) a codimension-collapse lemma ensuring that rank amplification cannot occur within polynomial resources; and (4) proofs of barrier immunity against relativization, natural proofs, and algebrization. The result is a complete ZFC proof architecture whose primitives and compositions are fully derived, with community verification and machine-checked formalization left as future work.</description>
      <guid isPermaLink="false">oai:arXiv.org:2512.11820v2</guid>
      <category>cs.CC</category>
      <category>cs.DM</category>
      <pubDate>Thu, 18 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Darren J. Edwards</dc:creator>
    </item>
  </channel>
</rss>
