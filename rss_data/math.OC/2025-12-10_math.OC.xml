<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>math.OC updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/math.OC</link>
    <description>math.OC updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/math.OC" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Wed, 10 Dec 2025 05:00:06 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Wed, 10 Dec 2025 00:00:00 -0500</pubDate>
    <skipDays>
      <day>Saturday</day>
      <day>Sunday</day>
    </skipDays>
    <item>
      <title>Dual Smoothing for Decentralized Optimization</title>
      <link>https://arxiv.org/abs/2512.08167</link>
      <description>arXiv:2512.08167v1 Announce Type: new 
Abstract: Decentralized optimization is widely used in different fields of study such as distributed learning, signal processing, and various distributed control problems. In these types of problems, nodes of the network are connected to each other and seek to optimize some objective function. In this article, we present a method for smoothing the non-smooth and non-strongly convex problems. This is done using the dual smoothing technique. We study two types of problems: consensus optimization of linear models and coupled constraints optimization. It is shown that these two problem classes are dual to each other.</description>
      <guid isPermaLink="false">oai:arXiv.org:2512.08167v1</guid>
      <category>math.OC</category>
      <pubDate>Wed, 10 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Alexander Rogozin, Nhat Trung Nguyen, Hamed Azami Zenuzagh, Alexander Gasnikov</dc:creator>
    </item>
    <item>
      <title>Primal-dual policy learning for mean-field stochastic LQR problem</title>
      <link>https://arxiv.org/abs/2512.08205</link>
      <description>arXiv:2512.08205v1 Announce Type: new 
Abstract: Integrating data-driven techniques with mechanism-driven insights has recently gained popularity as a powerful learning approach to solving traditional LQR problems for designing intelligent controllers in complex dynamic systems. However, the theoretical understanding of various reinforcement learning algorithms needs further exploration to enhance their efficiency and safety. In this article, by means of primal-dual optimization tools, we study the partially model-free design of the mean-field stochastic LQR (MF-SLQR) controller using a policy learning approach. Firstly, by designing appropriate optimizing variables, the considered MF-SLQR problem is transformed into a new static nonconvex constrained optimization problem with equivalence preserved in certain senses. After that, the equivalent formulation of the duality results is constructed via finding the solution of the generalized Lyapunov equation. Then, the strong duality is analyzed, based on which we establish a primal-dual algorithm by Karush-Kuhn-Tucker conditions. More importantly, a partially model-free implementation is also presented, which has a direct connection with the classical policy iteration algorithm. Finally, we use a high-dimensional example to validate our methods.</description>
      <guid isPermaLink="false">oai:arXiv.org:2512.08205v1</guid>
      <category>math.OC</category>
      <pubDate>Wed, 10 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Xiushan Jiang, Dong Wang, Weihai Zhang, Daniel W. C. Ho, Yuanqing Wu</dc:creator>
    </item>
    <item>
      <title>Strict Elimination of Double Traversals in Outer Subaisles and Two-Block Rectangular Warehouses</title>
      <link>https://arxiv.org/abs/2512.08235</link>
      <description>arXiv:2512.08235v1 Announce Type: new 
Abstract: The order picking problem seeks the shortest warehouse route that visits all required item locations. Strict conditions are known for single-block rectangular layouts under which optimal routes never require double traversals, while broader results show they are avoidable only when cross-aisle connectivity is present. We strengthen these findings by proving that no double traversals are needed in the upper or lower subaisles of warehouses with at least two aisles, establishing strict conditions for both single and two-block layouts.</description>
      <guid isPermaLink="false">oai:arXiv.org:2512.08235v1</guid>
      <category>math.OC</category>
      <pubDate>Wed, 10 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>George Dunn, Elizabeth Stojanovski, Bishnu Lamichhane, Hadi Charkhgard, Ali Eshragh</dc:creator>
    </item>
    <item>
      <title>Global optimization of low-rank polynomials</title>
      <link>https://arxiv.org/abs/2512.08394</link>
      <description>arXiv:2512.08394v1 Announce Type: new 
Abstract: This work considers polynomial optimization problems where the objective admits a low- rank canonical polyadic tensor decomposition. We introduce LRPOP (low-rank polynomial optimization), a new hierarchy of semidefinite programming relaxations for which the size of the semidefinite blocks is determined by the canonical polyadic rank rather than the number of variables. As a result, LRPOP can solve low-rank polynomial optimization problems that are far beyond the reach of existing sparse hierarchies. In particular, we solve problems with up to thousands of variables with total degree in the thousands. Numerical conditioning for problems of this size is improved by using the Bernstein basis. The LRPOP hierarchy converges from below to the global minimum of the polynomial under standard assumptions.</description>
      <guid isPermaLink="false">oai:arXiv.org:2512.08394v1</guid>
      <category>math.OC</category>
      <pubDate>Wed, 10 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Lloren\c{c} Balada Gaggioli, Didier Henrion, Milan Korda</dc:creator>
    </item>
    <item>
      <title>Optimal Operation and Valuation of Electricity Storages in Intraday Markets</title>
      <link>https://arxiv.org/abs/2512.08422</link>
      <description>arXiv:2512.08422v1 Announce Type: new 
Abstract: This paper applies computational techniques of convex stochastic optimization to optimal operation and valuation of electricity storages in the face of uncertain electricity prices. Our valuations are based on the indifference pricing principle, which builds on optimal trading strategies and calibrates to the user's financial position, market views and risk preferences. The underlying optimization problem is solved with the Stochastic Dual Dynamic Programming algorithm which is applicable to various specifications of storages, and it allows for e.g. hard constraints on storage capacity and charging speed. We illustrate the approach in intraday trading where the agent charges or discharges a battery over a finite number of delivery periods, and the electricity prices are subject to bid-ask spreads and significant uncertainty. Optimal strategies are found in a matter of minutes on a regular PC. We find that the corresponding trading strategies and battery valuations vary consistently with respect to the agent's risk preferences as well as the physical characteristics of the battery.</description>
      <guid isPermaLink="false">oai:arXiv.org:2512.08422v1</guid>
      <category>math.OC</category>
      <pubDate>Wed, 10 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Jean-Philippe Chancelier (CERMICS), Michel de Lara (CERMICS), Fran\c{c}ois Pacaud (LMU), Tanguy Lindegaard (LMU), Teemu Pennanen (LMU), Ari-Pekka Perkki\"o (LMU)</dc:creator>
    </item>
    <item>
      <title>Optimal coefficients for elliptic PDEs</title>
      <link>https://arxiv.org/abs/2512.08431</link>
      <description>arXiv:2512.08431v1 Announce Type: new 
Abstract: We consider an optimization problem related to elliptic PDEs of the form $-{\rm div}(a(x)\nabla u)=f$ with Dirichlet boundary condition on a given domain $\Omega$. The coefficient $a(x)$ has to be determined, in a suitable given class of admissible choices, in order to optimize a given criterion. We first deal with the case when the cost is the so-called elastic compliance, and then we discuss the more general case when the problem is written as an optimal control problem.</description>
      <guid isPermaLink="false">oai:arXiv.org:2512.08431v1</guid>
      <category>math.OC</category>
      <pubDate>Wed, 10 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Giuseppe Buttazzo, Juan Casado-D\'iaz, Faustino Maestre</dc:creator>
    </item>
    <item>
      <title>An Overview of Sensitivity-Based Distributed Optimization and Model Predictive Control</title>
      <link>https://arxiv.org/abs/2512.08446</link>
      <description>arXiv:2512.08446v1 Announce Type: new 
Abstract: This paper presents a concise overview of sensitivity-based methods for solving large-scale optimization problems in distributed fashion. The approach relies on sensitivities and primal decomposition to achieve coordination between the subsystems while requiring only local computations with neighbor-to-neighbor communication. We give a brief historical synopsis of its development and apply it to both static and dynamic optimization problems. Furthermore, a real-time capable distributed model predictive controller is proposed which is experimentally validated on a coupled watertank system.</description>
      <guid isPermaLink="false">oai:arXiv.org:2512.08446v1</guid>
      <category>math.OC</category>
      <pubDate>Wed, 10 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Maximilian Pierer von Esch, Andreas V\"olz, Knut Graichen</dc:creator>
    </item>
    <item>
      <title>Enhancing Kernel Search with Pattern Recognition: the Single-Source Capacitated Facility Location Problem</title>
      <link>https://arxiv.org/abs/2512.08576</link>
      <description>arXiv:2512.08576v1 Announce Type: new 
Abstract: We introduce Pattern-based Kernel Search (PaKS), a two-phase matheuristic for the solution of the Single-Source Capacitated Facility Location Problem (SSCFLP). In the first phase, PaKS employs a pattern recognition technique to identify an implicit spatial separation of potential locations and customers into subsets, called regions, within which location and assignment decisions are strongly interdependent. In the second phase, PaKS employs an enhanced Kernel Search (KS) heuristic that leverages the interdependencies among the decision variables identified in the first phase. On a set of 112 benchmark instances, consisting of up to 1,000 locations and 1,000 customers, computational results show that PaKS consistently outperforms both a standard KS implementation and the current state-of-the-art heuristic for solving the SSCFLP, as well as CPLEX when run with a time limit. For these instances, PaKS achieved an average gap compared to the best known solution of 0.02%. Experimental results conducted on a large set of new very large test problems, comprising up to 2,000 locations and 2,000 customers, demonstrate that PaKS outperforms both the standard KS heuristic and CPLEX in terms of quality of the solution found, finding the largest number of best solutions, and achieving the smallest average gap.</description>
      <guid isPermaLink="false">oai:arXiv.org:2512.08576v1</guid>
      <category>math.OC</category>
      <pubDate>Wed, 10 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Hannah Bakker, Gianfranco Guastaroba, Stefan Nickel, M. Grazia Speranza</dc:creator>
    </item>
    <item>
      <title>Saturation-based robustly optimal hierarchical operation control of microgrids</title>
      <link>https://arxiv.org/abs/2512.08757</link>
      <description>arXiv:2512.08757v1 Announce Type: new 
Abstract: This paper studies the problem of robustly optimal operation control of microgrids with a high share of renewable energy sources. The main goal is to ensure optimal operation under a wide range of circumstances, given the highly intermittent and uncertain nature of renewable sources and load demand. We formally state this problem, and, in order to solve it, we make effective use of the hierarchical power system control approach. We consider an enhanced primary control layer including droop control and autonomous limitation of power and energy. We prove that this enables the use of constant power setpoints to achieve optimal operation under certain conditions. In order to relax these conditions, the approach is combined with an energy management system, which solves a robust unit commitment problem within a model predictive control framework. Finally, a case study demonstrates the viability of the control design.</description>
      <guid isPermaLink="false">oai:arXiv.org:2512.08757v1</guid>
      <category>math.OC</category>
      <category>cs.SY</category>
      <category>eess.SY</category>
      <pubDate>Wed, 10 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Ujjwal Pratap, Steffen Hofmann</dc:creator>
    </item>
    <item>
      <title>Computing normalized Nash equilibria for generalized Nash games with nonconvex players</title>
      <link>https://arxiv.org/abs/2512.08770</link>
      <description>arXiv:2512.08770v1 Announce Type: new 
Abstract: Generalized Nash equilibrium (GNE) is a solution concept for complete information games, in which each player's objective function and feasible region depend on other players' actions. While numerical methods for finding GNE when players possess convex structure are relatively mature, the same cannot be said when players optimize nonconvex objective functions over nonconvex feasible regions. Drawing inspiration from the notion of a normalized (or variational) Nash equilibrium, which is a more restrictive class of solutions to generalized Nash games, we extend the ideas of Harwood et al. ("Equilibrium modeling and solution approaches inspired by nonconvex bilevel programming." Computational Optimization and Applications, 87(2):641-676, 2024) to develop an exact method that can find a normalized Nash equilibrium (NNE) of a problem, when such an NNE exists. By adapting the framework of Harwood et al., we are able to find NNE without any convexity assumptions. We demonstrate the effectiveness of our method on several nonconvex games.</description>
      <guid isPermaLink="false">oai:arXiv.org:2512.08770v1</guid>
      <category>math.OC</category>
      <pubDate>Wed, 10 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <arxiv:DOI>10.1007/s10479-025-06968-z</arxiv:DOI>
      <dc:creator>Stuart M. Harwood, Dimitri J. Papageorgiou</dc:creator>
    </item>
    <item>
      <title>Adaptive Regularized Newton Method with Inexact Hessian</title>
      <link>https://arxiv.org/abs/2512.08775</link>
      <description>arXiv:2512.08775v1 Announce Type: new 
Abstract: Newton's method is the most widespread high-order method, demanding the gradient and the Hessian of the objective function. However, one of the main disadvantages of Newtons method is its lack of global convergence and high iteration cost. Both these drawbacks are critical for modern optimization motivated primarily by current applications in machine learning. In this paper, we introduce a novel algorithm to deal with these disadvantages. Our method can be implemented with various Hessian approximations, including methods that use only the first-order information. Thus, computational costs might be drastically reduced. Also, it can be adjusted to problems' geometries via the usage of different Bregman divergences. The proposed method converges for nonconvex and convex problems globally and it has the same rates as other well-known methods that lack mentioned properties. We present experiments validating our method performs according to the theoretical bounds and shows competitive performance among other Newton-based methods.</description>
      <guid isPermaLink="false">oai:arXiv.org:2512.08775v1</guid>
      <category>math.OC</category>
      <pubDate>Wed, 10 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Aleksandr Shestakov, Nail Bashirov, Andrei Semenov, Alexander Gasnikov, Martin Tak\'a\v{c}, Aleksandr Beznosikov, Dmitry Kamzolov</dc:creator>
    </item>
    <item>
      <title>Speeding up the Goemans-Williamson randomized procedure by difference-of-convex optimization</title>
      <link>https://arxiv.org/abs/2512.08852</link>
      <description>arXiv:2512.08852v1 Announce Type: new 
Abstract: We present a novel approach to accelerate the Goemans-Williamson (GW) randomized rounding procedure for quadratic unconstrained binary optimization (QUBO) problems. Instead of solving the conventional semi-definite programming (SDP) relaxation, which is computationally expensive, we employ a difference-of-convex (DC) optimization framework to efficiently approximate the SDP solution. The DC optimization produces candidate vectors that are then used within the GW randomized rounding scheme to generate high-quality binary solutions. Furthermore, we perform direct expectation minimization over manifolds of matrices with limited rank to further enhance the solution quality. Our method is benchmarked on real-world QUBO instances, including inverse kinematics problems, and compared against state-of-the-art solvers, such as quantum-inspired algorithms, demonstrating competitive approximation guarantees alongside substantial computational gains.</description>
      <guid isPermaLink="false">oai:arXiv.org:2512.08852v1</guid>
      <category>math.OC</category>
      <pubDate>Wed, 10 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Hadi Salloum, Roland Hildebrand, Nhat Trung Nguyen, Vitali Pirau, Amer Al Badr, Mohammad Alkousa, Alexander Gasnikov</dc:creator>
    </item>
    <item>
      <title>Learning Dynamics from Infrequent Output Measurements for Uncertainty-Aware Optimal Control</title>
      <link>https://arxiv.org/abs/2512.08013</link>
      <description>arXiv:2512.08013v1 Announce Type: cross 
Abstract: Reliable optimal control is challenging when the dynamics of a nonlinear system are unknown and only infrequent, noisy output measurements are available. This work addresses this setting of limited sensing by formulating a Bayesian prior over the continuous-time dynamics and latent state trajectory in state-space form and updating it through a targeted marginal Metropolis-Hastings sampler equipped with a numerical ODE integrator. The resulting posterior samples are used to formulate a scenario-based optimal control problem that accounts for both model and measurement uncertainty and is solved using standard nonlinear programming methods. The approach is validated in a numerical case study on glucose regulation using a Type 1 diabetes model.</description>
      <guid isPermaLink="false">oai:arXiv.org:2512.08013v1</guid>
      <category>eess.SY</category>
      <category>cs.LG</category>
      <category>cs.SY</category>
      <category>math.OC</category>
      <pubDate>Wed, 10 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Robert Lefringhausen, Theodor Springer, Sandra Hirche</dc:creator>
    </item>
    <item>
      <title>Multi-agent learning under uncertainty: Recurrence vs. concentration</title>
      <link>https://arxiv.org/abs/2512.08132</link>
      <description>arXiv:2512.08132v1 Announce Type: cross 
Abstract: In this paper, we examine the convergence landscape of multi-agent learning under uncertainty. Specifically, we analyze two stochastic models of regularized learning in continuous games -- one in continuous and one in discrete time with the aim of characterizing the long-run behavior of the induced sequence of play. In stark contrast to deterministic, full-information models of learning (or models with a vanishing learning rate), we show that the resulting dynamics do not converge in general. In lieu of this, we ask instead which actions are played more often in the long run, and by how much. We show that, in strongly monotone games, the dynamics of regularized learning may wander away from equilibrium infinitely often, but they always return to its vicinity in finite time (which we estimate), and their long-run distribution is sharply concentrated around a neighborhood thereof. We quantify the degree of this concentration, and we show that these favorable properties may all break down if the underlying game is not strongly monotone -- underscoring in this way the limits of regularized learning in the presence of persistent randomness and uncertainty.</description>
      <guid isPermaLink="false">oai:arXiv.org:2512.08132v1</guid>
      <category>cs.GT</category>
      <category>cs.LG</category>
      <category>math.OC</category>
      <pubDate>Wed, 10 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Kyriakos Lotidis, Panayotis Mertikopoulos, Nicholas Bambos, Jose Blanchet</dc:creator>
    </item>
    <item>
      <title>Robust equilibria in continuous games: From strategic to dynamic robustness</title>
      <link>https://arxiv.org/abs/2512.08138</link>
      <description>arXiv:2512.08138v1 Announce Type: cross 
Abstract: In this paper, we examine the robustness of Nash equilibria in continuous games, under both strategic and dynamic uncertainty. Starting with the former, we introduce the notion of a robust equilibrium as those equilibria that remain invariant to small -- but otherwise arbitrary -- perturbations to the game's payoff structure, and we provide a crisp geometric characterization thereof. Subsequently, we turn to the question of dynamic robustness, and we examine which equilibria may arise as stable limit points of the dynamics of "follow the regularized leader" (FTRL) in the presence of randomness and uncertainty. Despite their very distinct origins, we establish a structural correspondence between these two notions of robustness: strategic robustness implies dynamic robustness, and, conversely, the requirement of strategic robustness cannot be relaxed if dynamic robustness is to be maintained. Finally, we examine the rate of convergence to robust equilibria as a function of the underlying regularizer, and we show that entropically regularized learning converges at a geometric rate in games with affinely constrained action spaces.</description>
      <guid isPermaLink="false">oai:arXiv.org:2512.08138v1</guid>
      <category>cs.GT</category>
      <category>cs.LG</category>
      <category>math.OC</category>
      <pubDate>Wed, 10 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Kyriakos Lotidis, Panayotis Mertikopoulos, Nicholas Bambos, Jose Blanchet</dc:creator>
    </item>
    <item>
      <title>Worst-case generation via minimax optimization in Wasserstein space</title>
      <link>https://arxiv.org/abs/2512.08176</link>
      <description>arXiv:2512.08176v1 Announce Type: cross 
Abstract: Worst-case generation plays a critical role in evaluating robustness and stress-testing systems under distribution shifts, in applications ranging from machine learning models to power grids and medical prediction systems. We develop a generative modeling framework for worst-case generation for a pre-specified risk, based on min-max optimization over continuous probability distributions, namely the Wasserstein space. Unlike traditional discrete distributionally robust optimization approaches, which often suffer from scalability issues, limited generalization, and costly worst-case inference, our framework exploits the Brenier theorem to characterize the least favorable (worst-case) distribution as the pushforward of a transport map from a continuous reference measure, enabling a continuous and expressive notion of risk-induced generation beyond classical discrete DRO formulations. Based on the min-max formulation, we propose a Gradient Descent Ascent (GDA)-type scheme that updates the decision model and the transport map in a single loop, establishing global convergence guarantees under mild regularity assumptions and possibly without convexity-concavity. We also propose to parameterize the transport map using a neural network that can be trained simultaneously with the GDA iterations by matching the transported training samples, thereby achieving a simulation-free approach. The efficiency of the proposed method as a risk-induced worst-case generator is validated by numerical experiments on synthetic and image data.</description>
      <guid isPermaLink="false">oai:arXiv.org:2512.08176v1</guid>
      <category>stat.ML</category>
      <category>cs.LG</category>
      <category>math.OC</category>
      <pubDate>Wed, 10 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Xiuyuan Cheng, Yao Xie, Linglingzhi Zhu, Yunqin Zhu</dc:creator>
    </item>
    <item>
      <title>Bounding the Minimal Current Harmonic Distortion in Optimal Modulation of Single-Phase Power Converters</title>
      <link>https://arxiv.org/abs/2512.08201</link>
      <description>arXiv:2512.08201v1 Announce Type: cross 
Abstract: Optimal pulse patterns (OPPs) are a modulation technique in which a switching signal is computed offline through an optimization process that accounts for selected performance criteria, such as current harmonic distortion. The optimization determines both the switching angles (i.e., switching times) and the pattern structure (i.e., the sequence of voltage levels). This optimization task is a challenging mixed-integer nonconvex problem, involving integer-valued voltage levels and trigono metric nonlinearities in both the objective and the constraints. We address this challenge by reinterpreting OPP design as a periodic mode-selecting optimal control problem of a hybrid system, where selecting angles and levels corresponds to choosing jump times in a transition graph. This time-domain formulation enables the direct use of convex-relaxation techniques from optimal control, producing a hierarchy of semidefinite programs that lower-bound the minimal achievable harmonic distortion and scale subquadratically with the number of converter levels and switching angles. Numerical results demonstrate the effectiveness of the proposed approachs</description>
      <guid isPermaLink="false">oai:arXiv.org:2512.08201v1</guid>
      <category>eess.SY</category>
      <category>cs.SY</category>
      <category>math.OC</category>
      <pubDate>Wed, 10 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Jared Miller, Petros Karamanakos, Tobias Geyer</dc:creator>
    </item>
    <item>
      <title>Low Rank Support Quaternion Matrix Machine</title>
      <link>https://arxiv.org/abs/2512.08327</link>
      <description>arXiv:2512.08327v1 Announce Type: cross 
Abstract: Input features are conventionally represented as vectors, matrices, or third order tensors in the real field, for color image classification. Inspired by the success of quaternion data modeling for color images in image recovery and denoising tasks, we propose a novel classification method for color image classification, named as the Low-rank Support Quaternion Matrix Machine (LSQMM), in which the RGB channels are treated as pure quaternions to effectively preserve the intrinsic coupling relationships among channels via the quaternion algebra. For the purpose of promoting low-rank structures resulting from strongly correlated color channels, a quaternion nuclear norm regularization term, serving as a natural extension of the conventional matrix nuclear norm to the quaternion domain, is added to the hinge loss in our LSQMM model. An Alternating Direction Method of Multipliers (ADMM)-based iterative algorithm is designed to effectively resolve the proposed quaternion optimization model. Experimental results on multiple color image classification datasets demonstrate that our proposed classification approach exhibits advantages in classification accuracy, robustness and computational efficiency, compared to several state-of-the-art methods using support vector machines, support matrix machines, and support tensor machines.</description>
      <guid isPermaLink="false">oai:arXiv.org:2512.08327v1</guid>
      <category>cs.CV</category>
      <category>cs.LG</category>
      <category>math.OC</category>
      <category>stat.ML</category>
      <pubDate>Wed, 10 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Wang Chen, Ziyan Luo, Shuangyue Wang</dc:creator>
    </item>
    <item>
      <title>A reconstructed discontinuous approximation for distributed elliptic control problems</title>
      <link>https://arxiv.org/abs/2512.08353</link>
      <description>arXiv:2512.08353v1 Announce Type: cross 
Abstract: In this paper, we present and analyze an internal penalty discontinuous Galerkin method for the distributed elliptic optimal control problems. It is based on a reconstructed discontinuous approximation which admits arbitrarily high-order approximation space with only one unknown per element. Applying this method, we develop a proper discretization scheme that approximates the state and adjoint variables in the approximation space. Our main contributions are twofold: (1) the derivation of both a priori and a posteriori error estimates of the $L^2$-norm and the energy norms, and (2) the implementation of an efficiently solvable discrete system, which is solved via a linearly convergent projected gradient descent method. Numerical experiments are provided to verify the convergence order in a priori estimate and the efficiency of a posteriori error estimate.</description>
      <guid isPermaLink="false">oai:arXiv.org:2512.08353v1</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <category>math.OC</category>
      <pubDate>Wed, 10 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/publicdomain/zero/1.0/</dc:rights>
      <dc:creator>Ruo Li, Haoyang Liu, Jun Yin</dc:creator>
    </item>
    <item>
      <title>A Grover-compatible manifold optimization algorithm for quantum search</title>
      <link>https://arxiv.org/abs/2512.08432</link>
      <description>arXiv:2512.08432v1 Announce Type: cross 
Abstract: Grover's algorithm is a fundamental quantum algorithm that offers a quadratic speedup for the unstructured search problem by alternately applying physically implementable oracle and diffusion operators. In this paper, we reformulate the unstructured search as a maximization problem on the unitary manifold and solve it via the Riemannian gradient ascent (RGA) method. To overcome the difficulty that generic RGA updates do not, in general, correspond to physically implementable quantum operators, we introduce Grover-compatible retractions to restrict RGA updates to valid oracle and diffusion operators. Theoretically, we establish a local Riemannian $\mu$-Polyak-{\L}ojasiewicz (PL) inequality with $\mu = \tfrac{1}{2}$, which yields a linear convergence rate of $1 - \kappa^{-1}$ toward the global solution. Here, the condition number $\kappa = L_{\mathrm{Rie}} / \mu$, where $L_{\mathrm{Rie}}$ denotes the Riemannian Lipschitz constant of the gradient. Taking into account both the geometry of the unitary manifold and the special structure of the cost function, we show that $L_{\mathrm{Rie}} = O(\sqrt{N})$ for problem size $N = 2^n$. Consequently, the resulting iteration complexity is $O(\sqrt{N} \log(1/\varepsilon))$ for attaining an $\varepsilon$-accurate solution, which matches the quadratic speedup of $O(\sqrt{N})$ achieved by Grover's algorithm. These results demonstrate that an optimization-based viewpoint can offer fresh conceptual insights and lead to new advances in the design of quantum algorithms.</description>
      <guid isPermaLink="false">oai:arXiv.org:2512.08432v1</guid>
      <category>quant-ph</category>
      <category>math.OC</category>
      <pubDate>Wed, 10 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Zhijian Lai, Dong An, Jiang Hu, Zaiwen Wen</dc:creator>
    </item>
    <item>
      <title>Learned iterative networks: An operator learning perspective</title>
      <link>https://arxiv.org/abs/2512.08444</link>
      <description>arXiv:2512.08444v1 Announce Type: cross 
Abstract: Learned image reconstruction has become a pillar in computational imaging and inverse problems. Among the most successful approaches are learned iterative networks, which are formulated by unrolling classical iterative optimisation algorithms for solving variational problems. While the underlying algorithm is usually formulated in the functional analytic setting, learned approaches are often viewed as purely discrete. In this chapter we present a unified operator view for learned iterative networks. Specifically, we formulate a learned reconstruction operator, defining how to compute, and separately the learning problem, which defines what to compute. In this setting we present common approaches and show that many approaches are closely related in their core. We review linear as well as nonlinear inverse problems in this framework and present a short numerical study to conclude.</description>
      <guid isPermaLink="false">oai:arXiv.org:2512.08444v1</guid>
      <category>eess.IV</category>
      <category>cs.LG</category>
      <category>cs.NA</category>
      <category>math.FA</category>
      <category>math.NA</category>
      <category>math.OC</category>
      <pubDate>Wed, 10 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Andreas Hauptmann, Ozan \"Oktem</dc:creator>
    </item>
    <item>
      <title>Heuristics for Combinatorial Optimization via Value-based Reinforcement Learning: A Unified Framework and Analysis</title>
      <link>https://arxiv.org/abs/2512.08601</link>
      <description>arXiv:2512.08601v1 Announce Type: cross 
Abstract: Since the 1990s, considerable empirical work has been carried out to train statistical models, such as neural networks (NNs), as learned heuristics for combinatorial optimization (CO) problems. When successful, such an approach eliminates the need for experts to design heuristics per problem type. Due to their structure, many hard CO problems are amenable to treatment through reinforcement learning (RL). Indeed, we find a wealth of literature training NNs using value-based, policy gradient, or actor-critic approaches, with promising results, both in terms of empirical optimality gaps and inference runtimes. Nevertheless, there has been a paucity of theoretical work undergirding the use of RL for CO problems. To this end, we introduce a unified framework to model CO problems through Markov decision processes (MDPs) and solve them using RL techniques. We provide easy-to-test assumptions under which CO problems can be formulated as equivalent undiscounted MDPs that provide optimal solutions to the original CO problems. Moreover, we establish conditions under which value-based RL techniques converge to approximate solutions of the CO problem with a guarantee on the associated optimality gap. Our convergence analysis provides: (1) a sufficient rate of increase in batch size and projected gradient descent steps at each RL iteration; (2) the resulting optimality gap in terms of problem parameters and targeted RL accuracy; and (3) the importance of a choice of state-space embedding. Together, our analysis illuminates the success (and limitations) of the celebrated deep Q-learning algorithm in this problem context.</description>
      <guid isPermaLink="false">oai:arXiv.org:2512.08601v1</guid>
      <category>stat.ML</category>
      <category>cs.LG</category>
      <category>math.OC</category>
      <pubDate>Wed, 10 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Orit Davidovich, Shimrit Shtern, Segev Wasserkrug, Nimrod Megiddo</dc:creator>
    </item>
    <item>
      <title>Gradient-Informed Monte Carlo Fine-Tuning of Diffusion Models for Low-Thrust Trajectory Design</title>
      <link>https://arxiv.org/abs/2512.08705</link>
      <description>arXiv:2512.08705v1 Announce Type: cross 
Abstract: Preliminary mission design of low-thrust spacecraft trajectories in the Circular Restricted Three-Body Problem is a global search characterized by a complex objective landscape and numerous local minima. Formulating the problem as sampling from an unnormalized distribution supported on neighborhoods of locally optimal solutions, provides the opportunity to deploy Markov chain Monte Carlo methods and generative machine learning. In this work, we extend our previous self-supervised diffusion model fine-tuning framework to employ gradient-informed Markov chain Monte Carlo. We compare two algorithms - the Metropolis-Adjusted Langevin Algorithm and Hamiltonian Monte Carlo - both initialized from a distribution learned by a diffusion model. Derivatives of an objective function that balances fuel consumption, time of flight and constraint violations are computed analytically using state transition matrices. We show that incorporating the gradient drift term accelerates mixing and improves convergence of the Markov chain for a multi-revolution transfer in the Saturn-Titan system. Among the evaluated methods, MALA provides the best trade-off between performance and computational cost. Starting from samples generated by a baseline diffusion model trained on a related transfer, MALA explicitly targets Pareto-optimal solutions. Compared to a random walk Metropolis algorithm, it increases the feasibility rate from 17.34% to 63.01% and produces a denser, more diverse coverage of the Pareto front. By fine-tuning a diffusion model on the generated samples and associated reward values with reward-weighted likelihood maximization, we learn the global solution structure of the problem and eliminate the need for a tedious separate data generation phase.</description>
      <guid isPermaLink="false">oai:arXiv.org:2512.08705v1</guid>
      <category>eess.SY</category>
      <category>cs.LG</category>
      <category>cs.SY</category>
      <category>math.OC</category>
      <pubDate>Wed, 10 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Jannik Graebner, Ryne Beeson</dc:creator>
    </item>
    <item>
      <title>Variance strikes back: sub-game--perfect Nash equilibria in time-inconsistent $N$-player games, and their mean-field sequel</title>
      <link>https://arxiv.org/abs/2512.08745</link>
      <description>arXiv:2512.08745v1 Announce Type: cross 
Abstract: We investigate a time-inconsistent, non-Markovian finite-player game in continuous time, where each player's objective functional depends non-linearly on the expected value of the state process. As a result, the classical Bellman optimality principle no longer applies. To address this, we adopt a two-layer game-theoretic framework and seek sub-game--perfect Nash equilibria both at the intra-personal level, which accounts for time inconsistency, and at the inter-personal level, which captures strategic interactions among players. We first characterise sub-game--perfect Nash equilibria and the corresponding value processes of all players through a system of coupled backward stochastic differential equations. We then analyse the mean-field counterpart and its sub-game--perfect mean-field equilibria, described by a system of McKean-Vlasov backward stochastic differential equations. Building on this representation, we finally prove the convergence of sub-game--perfect Nash equilibria and their corresponding value processes in the $N$-player game to their mean-field counterparts.</description>
      <guid isPermaLink="false">oai:arXiv.org:2512.08745v1</guid>
      <category>math.PR</category>
      <category>econ.TH</category>
      <category>math.OC</category>
      <pubDate>Wed, 10 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Dylan Possama\"i, Chiara Rossato</dc:creator>
    </item>
    <item>
      <title>Axial Symmetric Navier Stokes Equations and the Beltrami /anti Beltrami spectrum in view of Physics Informed Neural Networks</title>
      <link>https://arxiv.org/abs/2512.08846</link>
      <description>arXiv:2512.08846v1 Announce Type: cross 
Abstract: In this paper, I further continue an investigation on Beltrami Flows began in 2015 with A. Sorin and amply reprised and developed in 2022 with M. Trigiante. Instead of a compact $3$-torus $T^3=\mathbb{R}^3/\Lambda$ where $\Lambda$ is a crystallographic lattice, as done in previous work, here I considered flows confined in a cylinder with identified opposite bases. In this topology I considered axial symmetric flows and found a complete basis of axial symmetric harmonic $1$-forms that, for each energy level, decomposes into six components: two Beltrami, two anti-Beltrami and two closed forms. These objects, that are written in terms of trigonometric and Bessel functions, constitute a function basis for an $L^2$ space of axial symmetric flows. I have presented a general scheme for the search of axial symmetric solutions of Navier Stokes equation by reducing the latter to an hierachy of quadratic relations on the development coefficients of the flow in the above described functional basis. It is proposed that the coefficients can be determined by means of a Physics Informed like Neural Network optimization recursive algorithm. Indeed the present paper provides the theoretical foundations for such a algorithmic construction that is planned for a future publication.</description>
      <guid isPermaLink="false">oai:arXiv.org:2512.08846v1</guid>
      <category>physics.flu-dyn</category>
      <category>cs.IT</category>
      <category>math-ph</category>
      <category>math.IT</category>
      <category>math.MP</category>
      <category>math.OC</category>
      <pubDate>Wed, 10 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Pietro Fr\'e</dc:creator>
    </item>
    <item>
      <title>Astral Space: Convex Analysis at Infinity</title>
      <link>https://arxiv.org/abs/2205.03260</link>
      <description>arXiv:2205.03260v4 Announce Type: replace 
Abstract: Not all convex functions on $\mathbb{R}^n$ have finite minimizers; some can only be minimized by a sequence as it heads to infinity. In this work, we aim to develop a theory for understanding such minimizers at infinity. We study astral space, a compact extension of $\mathbb{R}^n$ to which such points at infinity have been added. Astral space is constructed to be as small as possible while still ensuring that all linear functions can be continuously extended to the new space. Although astral space includes all of $\mathbb{R}^n$, it is not a vector space, nor even a metric space. However, it is sufficiently well-structured to allow useful and meaningful extensions of concepts of convexity, conjugacy, and subdifferentials. We develop these concepts and analyze various properties of convex functions on astral space, including the detailed structure of their minimizers, exact characterizations of continuity, and convergence of descent algorithms.</description>
      <guid isPermaLink="false">oai:arXiv.org:2205.03260v4</guid>
      <category>math.OC</category>
      <category>cs.LG</category>
      <pubDate>Wed, 10 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Miroslav Dud\'ik, Robert E. Schapire, Matus Telgarsky</dc:creator>
    </item>
    <item>
      <title>A kernel-based method for Schr\"odinger bridges</title>
      <link>https://arxiv.org/abs/2310.14522</link>
      <description>arXiv:2310.14522v5 Announce Type: replace 
Abstract: We characterize the Schr\"odinger bridge problems by a family of Mckean-Vlasov stochastic control problems with no terminal time distribution constraint. In doing so, we use the theory of Hilbert space embeddings of probability measures and then describe the constraint as penalty terms defined by the maximum mean discrepancy in the control problems. A sequence of the probability laws of the state processes resulting from $\epsilon$-optimal controls converges to a unique solution of the Schr\"odinger's problem under mild conditions on given initial and terminal time distributions and an underlying diffusion process. We propose a neural SDE based deep learning algorithm for the Mckean-Vlasov stochastic control problems. Several numerical experiments validate our methods.</description>
      <guid isPermaLink="false">oai:arXiv.org:2310.14522v5</guid>
      <category>math.OC</category>
      <category>cs.NA</category>
      <category>math.NA</category>
      <pubDate>Wed, 10 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Yumiharu Nakano</dc:creator>
    </item>
    <item>
      <title>Duality of Hoffman constants</title>
      <link>https://arxiv.org/abs/2312.09858</link>
      <description>arXiv:2312.09858v3 Announce Type: replace 
Abstract: Suppose $A\in \mathbb{R}^{m\times n}$, and $R\subseteq \mathbb{R}^n$ and $S\subseteq \mathbb{R}^m$ are {\em reference} polyhedral cones with dual cones $R^*\subseteq \mathbb{R}^n, \; S^*\subseteq \mathbb{R}^m$. We show that a suitable Slater condition implies a {\em duality inequality} between the Hoffman constants of the feasibility problems $$ \begin{array}{r} Ax-b \in S\\ x \in R \end{array} \qquad\text{ and }\qquad \begin{array}{r} c-A^T y \in R^*\\ y \in S^*. \end{array} $$ As an interesting application, we show a striking identity between the Hoffman constants of {\em box-constrained} feasibility problems with a similar primal-dual format, but where one of the reference sets is a box and the other is a linear subspace. We also establish a surprising identity between Hoffman constants of box-constrained feasibility problems and the chi condition measures for weighted least-squares problems.</description>
      <guid isPermaLink="false">oai:arXiv.org:2312.09858v3</guid>
      <category>math.OC</category>
      <pubDate>Wed, 10 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Javier F. Pena, Juan C. Vera, Luis F. Zuluaga</dc:creator>
    </item>
    <item>
      <title>Rockafellian Relaxation for PDE-Constrained Optimization with Distributional Uncertainty</title>
      <link>https://arxiv.org/abs/2405.00176</link>
      <description>arXiv:2405.00176v2 Announce Type: replace 
Abstract: Stochastic optimization problems are generally known to be ill-conditioned to the form of the underlying uncertainty. A framework is introduced for optimal control problems with partial differential equations as constraints that is robust to inaccuracies in the precise form of the problem uncertainty. The framework is based on problem relaxation and involves optimizing a bivariate, "Rockafellian" objective functional that features both a standard control variable and an additional perturbation variable that handles the distributional ambiguity. In the presence of distributional corruption, the Rockafellian objective functionals are shown in the appropriate settings to $\Gamma$-converge to uncorrupted objective functionals in the limit of vanishing corruption. Numerical examples illustrate the framework's utility for outlier detection and removal and for variance reduction.</description>
      <guid isPermaLink="false">oai:arXiv.org:2405.00176v2</guid>
      <category>math.OC</category>
      <pubDate>Wed, 10 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Harbir Antil, Sean P. Carney, Hugo D\'iaz, Johannes O. Royset</dc:creator>
    </item>
    <item>
      <title>On Solving Minimization and Min-Max Problems by First-Order Methods with Relative Error in Gradients</title>
      <link>https://arxiv.org/abs/2503.06628</link>
      <description>arXiv:2503.06628v3 Announce Type: replace 
Abstract: First-order methods for minimization and saddle point (min-max) problems are widely used for solving large-scale problems, in particular arising in machine learning. The majority of works obtain favorable complexity guarantees of such methods, assuming that exact gradient information is available. At the same time, even the use of floating-point representation of real numbers already leads to relative error in all the computations. Relative errors also arise in such applications as bilevel optimization, inverse problems, derivative-free optimization, and inexact proximal methods. This paper answers several theoretical open questions on first-order optimization methods under relative errors in the first-order oracle. We propose an explicit single-loop accelerated gradient method that preserves optimal linear convergence rate under maximal possible relative error in the gradient, and explore the tradeoff between the relative error and deterioration in the linear convergence rate. We further explore similar questions for saddle point problems and nonlinear equations, showing, for the first time in the literature, that a variant of gradient descent-ascent and the extragradient method are robust to such errors and providing estimates for the maximum level of noise that does not break linear convergence.</description>
      <guid isPermaLink="false">oai:arXiv.org:2503.06628v3</guid>
      <category>math.OC</category>
      <pubDate>Wed, 10 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Artem Vasin, Valery Krivchenko, Dmitry Kovalev, Fedyor Stonyakin, Nazarii Tupitsa, Pavel Dvurechensky, Mohammad Alkousa, Nikita Kornilov, Alexander Gasnikov</dc:creator>
    </item>
    <item>
      <title>Sparse Tensor CCA via Manifold Optimization for Multi-View Learning</title>
      <link>https://arxiv.org/abs/2504.02339</link>
      <description>arXiv:2504.02339v5 Announce Type: replace 
Abstract: Tensor canonical correlation analysis (TCCA) has garnered significant attention due to its effectiveness in capturing high-order correlations in multi-view learning. However, existing TCCA methods often underemphasize the characterization of individual structures and lack algorithmic convergence guarantees. In order to deal with these challenges, we propose a novel sparse TCCA model called STCCA-L, which integrates sparse regularization of canonical matrices and Laplacian regularization of multi-order graphs into the TCCA framework, thereby effectively exploiting the geometric structure of individual views. To solve this non-convex model, we develop an efficient alternating manifold proximal gradient algorithm based on manifold optimization, which avoids computationally expensive full tensor decomposition and leverages a semi-smooth Newton method for resolving the subproblem. Furthermore, we rigorously prove the convergence of the algorithm and analyze its complexity. Experimental results on eight benchmark datasets demonstrate the superior classification performance of the proposed method. Notably, on the 3Sources dataset, it achieves improvements of at least 4.50\% in accuracy and 6.77\% in F1 score over competitors. Our code is available at https://github.com/zhudafa/STCCA-L.</description>
      <guid isPermaLink="false">oai:arXiv.org:2504.02339v5</guid>
      <category>math.OC</category>
      <pubDate>Wed, 10 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Yanjiao Zhu, Wanquan Liu, Xianchao Xiu, Jianqin Sun</dc:creator>
    </item>
    <item>
      <title>Universal Representation of Generalized Convex Functions and their Gradients</title>
      <link>https://arxiv.org/abs/2509.04477</link>
      <description>arXiv:2509.04477v2 Announce Type: replace 
Abstract: A wide range of optimization problems can often be written in terms of generalized convex functions (GCFs). When this structure is present, it can convert certain nested bilevel objectives into single-level problems amenable to standard first-order optimization methods. We provide a new differentiable layer with a convex parameter space and show (Theorems 5.1 and 5.2) that it and its gradient are universal approximators for GCFs and their gradients. We demonstrate how this parameterization can be leveraged in practice by (i) learning optimal transport maps with general cost functions and (ii) learning optimal auctions of multiple goods. In both these cases, we show how our layer can be used to convert the existing bilevel or min-max formulations into single-level problems that can be solved efficiently with first-order methods.</description>
      <guid isPermaLink="false">oai:arXiv.org:2509.04477v2</guid>
      <category>math.OC</category>
      <category>cs.LG</category>
      <pubDate>Wed, 10 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Moeen Nehzati</dc:creator>
    </item>
    <item>
      <title>A Unified Computational Approach for Zero-Sum Linear-Quadratic Stochastic Differential Games in Infinite Horizons</title>
      <link>https://arxiv.org/abs/2511.01538</link>
      <description>arXiv:2511.01538v2 Announce Type: replace 
Abstract: This paper proposes a new method for finding closed-loop saddle points in zero-sum linear-quadratic stochastic differential games by decoupling their inherent structure. Specifically, we develop a nested iterative scheme that constructs a monotonically increasing sequence of matrices, thereby decomposing the original problem into interconnected subproblems. By sequentially computing the stabilizing solutions to the algebraic Riccati equations within each subproblem, we obtain the stabilizing solution to the original problem and rigorously establish the convergence of the iterative sequence. A numerical example further validates the effectiveness of the proposed method. To the best of our knowledge, this work extends the classical setting and provides the first general-purpose computational approach for this class of problems.</description>
      <guid isPermaLink="false">oai:arXiv.org:2511.01538v2</guid>
      <category>math.OC</category>
      <pubDate>Wed, 10 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Yiyuan Wang</dc:creator>
    </item>
    <item>
      <title>Unifying Entropy Regularization in Optimal Control: From and Back to Classical Objectives via Iterated Soft Policies and Path Integral Solutions</title>
      <link>https://arxiv.org/abs/2512.06109</link>
      <description>arXiv:2512.06109v2 Announce Type: replace 
Abstract: This paper develops a unified perspective on several stochastic optimal control formulations through the lens of Kullback-Leibler regularization. We propose a central problem that separates the KL penalties on policies and transitions, assigning them independent weights, thereby generalizing the standard trajectory-level KL-regularization commonly used in probabilistic and KL-regularized control. This generalized formulation acts as a generative structure allowing to recover various control problems. These include the classical Stochastic Optimal Control (SOC), Risk-Sensitive Optimal Control (RSOC), and their policy-based KL-regularized counterparts. The latter we refer to as soft-policy SOC and RSOC, facilitating alternative problems with tractable solutions. Beyond serving as regularized variants, we show that these soft-policy formulations majorize the original SOC and RSOC problem. This means that the regularized solution can be iterated to retrieve the original solution. Furthermore, we identify a structurally synchronized case of the risk-seeking soft-policy RSOC formulation, wherein the policy and transition KL-regularization weights coincide. Remarkably, this specific setting gives rise to several powerful properties such as a linear Bellman equation, path integral solution, and, compositionality, thereby extending these computationally favourable properties to a broad class of control problems.</description>
      <guid isPermaLink="false">oai:arXiv.org:2512.06109v2</guid>
      <category>math.OC</category>
      <category>cs.LG</category>
      <category>cs.RO</category>
      <category>cs.SY</category>
      <category>eess.SY</category>
      <pubDate>Wed, 10 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Ajinkya Bhole, Mohammad Mahmoudi Filabadi, Guillaume Crevecoeur, Tom Lefebvre</dc:creator>
    </item>
    <item>
      <title>A note on Johnson's rule for minimizing makespan in the Two-Machine Flow Shop scheduling problem</title>
      <link>https://arxiv.org/abs/2512.06119</link>
      <description>arXiv:2512.06119v2 Announce Type: replace 
Abstract: We consider Johnson's rule for minimizing the makespan in the two-machine flow shop scheduling problem. We show that although the worst-case complexity of Johnson's rule is O(n log n), since it requires a complete sorting of the jobs, it is possible to detect in linear time whenever a full sort can be avoided and the optimal solution can be computed in linear time. Computational testing indicates that the linear time complexity always occurs in practice on standard benchmark instances with uniform distribution of the processing times.</description>
      <guid isPermaLink="false">oai:arXiv.org:2512.06119v2</guid>
      <category>math.OC</category>
      <pubDate>Wed, 10 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Federico Della Croce, Quentin Schau</dc:creator>
    </item>
    <item>
      <title>Sliced Wasserstein distance between probability measures on Hilbert spaces</title>
      <link>https://arxiv.org/abs/2307.05802</link>
      <description>arXiv:2307.05802v3 Announce Type: replace-cross 
Abstract: The sliced Wasserstein distance as well as its variants have been widely considered in comparing probability measures defined on $\mathbb R^d$. Here we derive the notion of sliced Wasserstein distance for measures on an infinite dimensional separable Hilbert spaces, depict the relation between sliced Wasserstein distance and narrow convergence of measures and quantize the approximation via empirical measures.</description>
      <guid isPermaLink="false">oai:arXiv.org:2307.05802v3</guid>
      <category>math.MG</category>
      <category>math.OC</category>
      <category>math.PR</category>
      <pubDate>Wed, 10 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Ruiyu Han</dc:creator>
    </item>
    <item>
      <title>Asynchronous Stochastic Approximation with Applications to Average-Reward Reinforcement Learning</title>
      <link>https://arxiv.org/abs/2409.03915</link>
      <description>arXiv:2409.03915v3 Announce Type: replace-cross 
Abstract: This paper investigates the stability and convergence properties of asynchronous stochastic approximation (SA) algorithms, with a focus on extensions relevant to average-reward reinforcement learning. We first extend a stability proof method of Borkar and Meyn to accommodate more general noise conditions than previously considered, thereby yielding broader convergence guarantees for asynchronous SA. To sharpen the convergence analysis, we further examine the shadowing properties of asynchronous SA, building on a dynamical systems approach of Hirsch and Bena\"{i}m. These results provide a theoretical foundation for a class of relative value iteration-based reinforcement learning algorithms -- developed and analyzed in a companion paper -- for solving average-reward Markov and semi-Markov decision processes.</description>
      <guid isPermaLink="false">oai:arXiv.org:2409.03915v3</guid>
      <category>cs.LG</category>
      <category>math.OC</category>
      <pubDate>Wed, 10 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Huizhen Yu, Yi Wan, Richard S. Sutton</dc:creator>
    </item>
    <item>
      <title>Asymptotic stability equals exponential stability -- while you twist your eyes</title>
      <link>https://arxiv.org/abs/2411.03277</link>
      <description>arXiv:2411.03277v3 Announce Type: replace-cross 
Abstract: Suppose that two vector fields on a smooth manifold render some equilibrium point globally asymptotically stable (GAS). We show that there exists a homotopy between the corresponding semiflows such that this point remains GAS along this homotopy.</description>
      <guid isPermaLink="false">oai:arXiv.org:2411.03277v3</guid>
      <category>math.DS</category>
      <category>cs.SY</category>
      <category>eess.SY</category>
      <category>math.OC</category>
      <pubDate>Wed, 10 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Wouter Jongeneel</dc:creator>
    </item>
    <item>
      <title>Fast Switching in Mixed-Integer Model Predictive Control</title>
      <link>https://arxiv.org/abs/2411.19300</link>
      <description>arXiv:2411.19300v4 Announce Type: replace-cross 
Abstract: We deduce stability results for finite control set and mixed-integer model predictive control with a downstream oversampling phase. The presentation rests upon the inherent robustness of model predictive control with stabilizing terminal conditions and techniques for solving mixed-integer optimal control problems by continuous optimization. Partial outer convexification and binary relaxation transform mixed-integer problems into common optimal control problems. We deduce nominal asymptotic stability for the resulting relaxed system formulation and implement sum-up rounding to restore efficiently integer feasibility on an oversampling time grid. If fast control switching is technically possible and inexpensive, we can approximate the relaxed system behavior in the state space arbitrarily close. We integrate input perturbed model predictive control with practical asymptotic stability. Numerical experiments illustrate practical relevance of fast control switching.</description>
      <guid isPermaLink="false">oai:arXiv.org:2411.19300v4</guid>
      <category>eess.SY</category>
      <category>cs.SY</category>
      <category>math.OC</category>
      <pubDate>Wed, 10 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Artemi Makarow, Christian Kirches</dc:creator>
    </item>
    <item>
      <title>Understanding the Implicit Regularization of Gradient Descent in Over-parameterized Models</title>
      <link>https://arxiv.org/abs/2505.17304</link>
      <description>arXiv:2505.17304v2 Announce Type: replace-cross 
Abstract: Implicit regularization refers to the tendency of local search algorithms to converge to low-dimensional solutions, even when such structures are not explicitly enforced. Despite its ubiquity, the mechanism underlying this behavior remains poorly understood, particularly in over-parameterized settings. We analyze gradient descent dynamics and identify three conditions under which it converges to second-order stationary points within an implicit low-dimensional region: (i) suitable initialization, (ii) efficient escape from saddle points, and (iii) sustained proximity to the region. We show that these can be achieved through infinitesimal perturbations and a small deviation rate. Building on this, we introduce Infinitesimally Perturbed Gradient Descent (IPGD), which satisfies these conditions under mild assumptions. We provide theoretical guarantees for IPGD in over-parameterized matrix sensing and empirical evidence of its broader applicability.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.17304v2</guid>
      <category>cs.LG</category>
      <category>math.OC</category>
      <pubDate>Wed, 10 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Jianhao Ma, Geyu Liang, Salar Fattahi</dc:creator>
    </item>
    <item>
      <title>Gaussian Approximation for Two-Timescale Linear Stochastic Approximation</title>
      <link>https://arxiv.org/abs/2508.07928</link>
      <description>arXiv:2508.07928v2 Announce Type: replace-cross 
Abstract: In this paper, we establish non-asymptotic bounds for accuracy of normal approximation for linear two-timescale stochastic approximation (TTSA) algorithms driven by martingale difference or Markov noise. Focusing on both the last iterate and Polyak-Ruppert averaging regimes, we derive bounds for normal approximation in terms of the convex distance between probability distributions. Our analysis reveals a non-trivial interaction between the fast and slow timescales: the normal approximation rate for the last iterate improves as the timescale separation increases, while it decreases in the Polyak-Ruppert averaged setting. We also provide the high-order moment bounds for the error of linear TTSA algorithm, which may be of independent interest.</description>
      <guid isPermaLink="false">oai:arXiv.org:2508.07928v2</guid>
      <category>stat.ML</category>
      <category>cs.LG</category>
      <category>math.OC</category>
      <category>math.PR</category>
      <category>math.ST</category>
      <category>stat.TH</category>
      <pubDate>Wed, 10 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Bogdan Butyrin, Artemy Rubtsov, Alexey Naumov, Vladimir Ulyanov, Sergey Samsonov</dc:creator>
    </item>
    <item>
      <title>A Unifying Framework for Global Optimization: From Theory to Formalization</title>
      <link>https://arxiv.org/abs/2508.20671</link>
      <description>arXiv:2508.20671v2 Announce Type: replace-cross 
Abstract: We introduce an abstract measure___theoretic framework that serves as a tool to rigorously study stochastic iterative global optimization algorithms as a unified class. The framework is formulated in terms of probability kernels, which, via the Ionescu--Tulcea theorem, induce probability measures on the space of sequences of algorithm iterations, endowed with two intuitive properties. This framework answers the need for a general, implementation___independent formalism in the analysis of such algorithms, providing a starting point for formalizing general results in proof-assistants. To illustrate the relevance of our tool, we show that common algorithms fit naturally in the framework, and we also use it to give a rigorous proof of a general consistency theorem for stochastic iterative global optimization algorithms (Proposition 3 of (Malherbe, et al., 2017). This proof and the entire framework are formalized in the Lean proof assistant. This formalization both ensures the correctness of the definitions and proofs, and provides a basis for future machine-assisted formalizations in the field.</description>
      <guid isPermaLink="false">oai:arXiv.org:2508.20671v2</guid>
      <category>cs.FL</category>
      <category>cs.LO</category>
      <category>math.OC</category>
      <category>math.PR</category>
      <pubDate>Wed, 10 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Ga\"etan Serr\'e (ENS Paris Saclay, CB), Argyris Kalogeratos (CB, ENS Paris Saclay), Nicolas Vayatis (CB, ENS Paris Saclay)</dc:creator>
    </item>
    <item>
      <title>Online Energy Storage Arbitrage under Imperfect Predictions: A Conformal Risk-Aware Approach</title>
      <link>https://arxiv.org/abs/2511.01032</link>
      <description>arXiv:2511.01032v2 Announce Type: replace-cross 
Abstract: This work proposes a conformal approach for energy storage arbitrage to control the downside risk arising from imperfect price forecasts. Energy storage arbitrage relies solely on predictions of future market prices, while inaccurate price predictions may lead to significant profit losses. Based on conformal decision theory, we describe a controller that dynamically adjusts decision conservativeness through prediction sets without distributional assumptions. To enable online calibration when online profit loss feedback is unobservable, we establish that a temporal difference error serves as a measurable proxy. Building on this insight, we develop two online calibration strategies: prediction error-based adaptation targeting forecast accuracy, and value error-based calibration focusing on decision quality. Analysis of the conformal controller proves bounded long-term risk with convergence guarantees in temporal difference error, which further effectively manages risk exposure in potential profit losses. Case studies demonstrate superior performance in balancing risk and opportunity compared to benchmarks under varying forecast conditions.</description>
      <guid isPermaLink="false">oai:arXiv.org:2511.01032v2</guid>
      <category>eess.SY</category>
      <category>cs.SY</category>
      <category>math.OC</category>
      <pubDate>Wed, 10 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Yiqian Wu, Ming Yi, Bolun Xu, James Anderson</dc:creator>
    </item>
    <item>
      <title>Direction-of-Arrival and Noise Covariance Matrix joint estimation for beamforming</title>
      <link>https://arxiv.org/abs/2511.10639</link>
      <description>arXiv:2511.10639v3 Announce Type: replace-cross 
Abstract: We propose a joint estimation method for the Direction-of-Arrival (DoA) and the Noise Covariance Matrix (NCM) tailored for beamforming applications. Building upon an existing NCM framework, our approach simplifies the estimation procedure by deriving an quasi-linear solution, instead of the traditional exhaustive search. Additionally, we introduce a novel DoA estimation technique that operates across all frequency bins, improving robustness in reverberant environments. Simulation results demonstrate that our method outperforms classical techniques, such as MUSIC, in mid- to high-angle scenarios, achieving lower angular errors and superior signal enhancement through beamforming. The proposed framework was also fared against other techniques for signal enhancement, having better noise rejection and interference canceling capabilities. These improvements are validated using both theoretical and empirical performance metrics.</description>
      <guid isPermaLink="false">oai:arXiv.org:2511.10639v3</guid>
      <category>eess.AS</category>
      <category>math.OC</category>
      <pubDate>Wed, 10 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Vitor Gelsleichter Probst Curtarelli, Stephan Paul, Anderson Wedderhoff Spengler</dc:creator>
    </item>
    <item>
      <title>Inverse Optimality for Fair Digital Twins: A Preference-based approach</title>
      <link>https://arxiv.org/abs/2512.01650</link>
      <description>arXiv:2512.01650v2 Announce Type: replace-cross 
Abstract: Digital Twins (DTs) are increasingly used as autonomous decision-makers in complex socio-technical systems. However, their mathematically optimal decisions often diverge from human expectations, revealing a persistent mismatch between algorithmic and bounded human rationality. This work addresses this challenge by proposing a framework that introduces fairness as a learnable objective within optimization-based Digital Twins. In this respect, a preference-driven learning workflow that infers latent fairness objectives directly from human pairwise preferences over feasible decisions is introduced. A dedicated Siamese neural network is developed to generate convex quadratic cost functions conditioned on contextual information. The resulting surrogate objectives drive the optimization procedure toward solutions that better reflect human-perceived fairness while maintaining computational efficiency. The effectiveness of the approach is demonstrated on a COVID-19 hospital resource allocation scenario. Overall, this work offers a practical solution to integrate human-centered fairness into the design of autonomous decision-making systems.</description>
      <guid isPermaLink="false">oai:arXiv.org:2512.01650v2</guid>
      <category>cs.LG</category>
      <category>cs.SE</category>
      <category>math.OC</category>
      <pubDate>Wed, 10 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Daniele Masti, Francesco Basciani, Arianna Fedeli, Girgio Gnecco, Francesco Smarra</dc:creator>
    </item>
    <item>
      <title>Symmetry-Based Formation Control on Cycle Graphs Using Dihedral Point Groups</title>
      <link>https://arxiv.org/abs/2512.06733</link>
      <description>arXiv:2512.06733v2 Announce Type: replace-cross 
Abstract: This work develops a symmetry-based framework for formation control on cycle graphs using Dihedral point-group constraints. We show that enforcing inter-agent reflection symmetries, together with anchoring a single designated agent to its prescribed mirror axis, is sufficient to realize every $\mathcal{C}_{nv}$-symmetric configuration using only $n-1$ communication links. The resulting control laws have a matrix-weighted Laplacian structure and guarantee exponential convergence to the desired symmetric configuration. Furthermore, we extend the method to enable coordinated maneuvers along a time-varying reference trajectory. Simulation results are provided to support the theoretical analysis.</description>
      <guid isPermaLink="false">oai:arXiv.org:2512.06733v2</guid>
      <category>eess.SY</category>
      <category>cs.SY</category>
      <category>math.OC</category>
      <pubDate>Wed, 10 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Zamir Martinez, Daniel Zelazo</dc:creator>
    </item>
    <item>
      <title>Copositivity, discriminants and nonseparable signed supports</title>
      <link>https://arxiv.org/abs/2512.07373</link>
      <description>arXiv:2512.07373v2 Announce Type: replace-cross 
Abstract: In this work we establish a connection between copositivity, that is, nonnegativity on the positive orthant, of sparse real Laurent polynomials and discriminants. Specifically, we consider Laurent polynomials in the positive orthant with fixed support and fixed coefficient signs. We provide a criterion to decide whether a given polynomial is copositive that is based in determining the intersection points of the signed discriminant and a path going through the coefficients of the polynomial. If the signed support satisfies a combinatorial condition termed nonseparability, we show additionally that this intersection consists of one point, and that tracking one path in homotopy continuation methods suffices to decide upon copositivity.
  Building on these results, we show that any copositive polynomial with nonseparable signed support can be decomposed into a sum of nonnegative circuit polynomials, generalising thereby previously known supports having this property.</description>
      <guid isPermaLink="false">oai:arXiv.org:2512.07373v2</guid>
      <category>math.AG</category>
      <category>math.CO</category>
      <category>math.OC</category>
      <pubDate>Wed, 10 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Elisenda Feliu, Joan Ferrer, M\'at\'e L. Telek</dc:creator>
    </item>
  </channel>
</rss>
