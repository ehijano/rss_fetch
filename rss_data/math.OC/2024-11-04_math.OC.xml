<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>math.OC updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/math.OC</link>
    <description>math.OC updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/math.OC" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Tue, 05 Nov 2024 04:10:46 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Mon, 04 Nov 2024 00:00:00 -0500</pubDate>
    <skipDays>
      <day>Saturday</day>
      <day>Sunday</day>
    </skipDays>
    <item>
      <title>Iterative Belief Propagation for Sparse Combinatorial Optimization</title>
      <link>https://arxiv.org/abs/2411.00135</link>
      <description>arXiv:2411.00135v1 Announce Type: new 
Abstract: In this note we study an iterative belief propagation (IBP) algorithm and demonstrate it's ability to solve sparse combinatorial optimization problems. Similar to simulated annealing (SA), our IBP algorithm attempts to sample from the Boltzmann distribution of the objective function but also uses belief propagation (BP) to improve convergence.</description>
      <guid isPermaLink="false">oai:arXiv.org:2411.00135v1</guid>
      <category>math.OC</category>
      <pubDate>Mon, 04 Nov 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Sam Reifenstein, Timoth\'ee Leleu</dc:creator>
    </item>
    <item>
      <title>Accurate and Efficient Cardiac Digital Twin from surface ECGs: Insights into Identifiability of Ventricular Conduction System</title>
      <link>https://arxiv.org/abs/2411.00165</link>
      <description>arXiv:2411.00165v1 Announce Type: new 
Abstract: Digital twins for cardiac electrophysiology are an enabling technology for precision cardiology. Current forward models are advanced enough to simulate the cardiac electric activity under different pathophysiological conditions and accurately replicate clinical signals like torso electrocardiograms (ECGs). In this work, we address the challenge of matching subject-specific QRS complexes using anatomically accurate, physiologically grounded cardiac digital twins. By fitting the initial conditions of a cardiac propagation model, our non-invasive method predicts activation patterns during sinus rhythm. For the first time, we demonstrate that distinct activation maps can generate identical surface ECGs. To address this non-uniqueness, we introduce a physiological prior based on the distribution of Purkinje-muscle junctions. Additionally, we develop a digital twin ensemble for probabilistic inference of cardiac activation. Our approach marks a significant advancement in the calibration of cardiac digital twins and enhances their credibility for clinical application.</description>
      <guid isPermaLink="false">oai:arXiv.org:2411.00165v1</guid>
      <category>math.OC</category>
      <category>physics.med-ph</category>
      <pubDate>Mon, 04 Nov 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-sa/4.0/</dc:rights>
      <dc:creator>Thomas Grandits, Karli Gillette, Gernot Plank, Simone Pezzuto</dc:creator>
    </item>
    <item>
      <title>A Three-Operator Splitting Scheme Derived from Three-Block ADMM</title>
      <link>https://arxiv.org/abs/2411.00166</link>
      <description>arXiv:2411.00166v1 Announce Type: new 
Abstract: In this paper, we derive a three-operator splitting scheme for solving monotone inclusion and convex optimization problems from the three-block ADMM method on the dual problem. The proposed scheme can be regarded as an extension of the Douglas-Rachford splitting to more operators. We also show an extension to multi-block models whose objective function is the sum of three or more functions. A numerical comparison with the Davis-Yin three-operator splitting method demonstrates that the new three-operator splitting scheme can still converge with a much larger step size.</description>
      <guid isPermaLink="false">oai:arXiv.org:2411.00166v1</guid>
      <category>math.OC</category>
      <pubDate>Mon, 04 Nov 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Anshika Anshika, Debdas Ghosh, Xiangxiong Zhang</dc:creator>
    </item>
    <item>
      <title>Optimal screening strategies in the control of an infectious disease: a case of the COVID-19 in a population with age structure</title>
      <link>https://arxiv.org/abs/2411.00312</link>
      <description>arXiv:2411.00312v1 Announce Type: new 
Abstract: After the COVID-19 pandemic, we saw an increase in demand for epidemiological mathematical models. The goal of this work is to study the optimal control for an age-structured model as a strategy of quarantine of infected people, which is done via Pontryagin's maximum principle. Since quarantine campaigns are not just a matter of public health, also posing economic challenges, the optimal control problem does not simply minimize the number of infected individuals. Instead, it jointly minimizes this number and the economic costs associated to the campaigns, providing data that can help authorities make decisions when dealing with epidemics. The controls are the quarantine entrance parameters, which are numerically calculated for different lengths of isolation. The best strategies gives a calendar that indicates when the isolation measures can be relaxed, and the consequences of a delay in the start of the quarantine are analyzed by presenting the reduction in the number of deaths for the strategy with optimal control compared to a no-quarantine landscape.</description>
      <guid isPermaLink="false">oai:arXiv.org:2411.00312v1</guid>
      <category>math.OC</category>
      <category>math.DS</category>
      <category>q-bio.PE</category>
      <pubDate>Mon, 04 Nov 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Nelson L. Santos Junior, Jo\~ao A. M. Gondim</dc:creator>
    </item>
    <item>
      <title>Optimal Sparse $H_\infty$ Controller Design for Networked Control Systems</title>
      <link>https://arxiv.org/abs/2411.00370</link>
      <description>arXiv:2411.00370v1 Announce Type: new 
Abstract: This paper provides a comprehensive analysis of the design of optimal sparse $H_\infty$ controllers for continuous-time linear time-invariant systems. The sparsity of a controller has received increasing attention as it represents the communication and computation efficiency of feedback networks. However, the design of optimal sparse $H_\infty$ controllers remains an open and challenging problem due to its non-convexity, and we cannot design a first-order algorithm to analyze since we lack an analytical expression for a given controller. In this paper, we consider two typical problems. First, design a sparse $H_\infty$ controller subject to a specified threshold, which minimizes the sparsity of the controller while satisfying the given performance requirement. Second, design a sparsity-promoting $H_\infty$ controller, which strikes a balance between the system performance and the controller sparsity. For both problems, we propose a relaxed convex problem and we show that any feasible solution of the relaxed problem is feasible for the original problem. Subsequently, we design an iterative linear matrix inequality (ILMI) for both problems with guaranteed convergence. We further characterize the first-order optimality using the Karush-Kuhn-Tucker (KKT) conditions and prove that any limit point of the solution sequence is a stationary point. Finally, we validate the effectiveness of our algorithms through several numerical simulations.</description>
      <guid isPermaLink="false">oai:arXiv.org:2411.00370v1</guid>
      <category>math.OC</category>
      <pubDate>Mon, 04 Nov 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Zhaohua Yang, Pengyu Wang, Haishan Zhang, Shiyue Jia, Nachuan Yang, Yuxing Zhong, Ling Shi</dc:creator>
    </item>
    <item>
      <title>Enhancing Top Efficiency by Minimizing Second-Best Scores: A Novel Perspective on Super Efficiency Models in DEA</title>
      <link>https://arxiv.org/abs/2411.00438</link>
      <description>arXiv:2411.00438v1 Announce Type: new 
Abstract: In this paper, we reveal a new characterization of the super-efficiency model for Data Envelopment Analysis (DEA). In DEA, the efficiency of each decision making unit (DMU) is measured by the ratio the weighted sum of outputs divided by the weighted sum of inputs. In order to measure efficiency of a DMU, ${\rm DMU}_j$, say, in CCR model, the weights of inputs and outputs are determined so that the effiency of ${\rm DMU}_j$ is maximized under the constraint that the efficiency of each DMU is less than or equal to one. ${\rm DMU}_j$ is called CCR-efficient if its efficiency score is equal to one. It often happens that weights making ${\rm DMU}_j$ CCR-efficient are not unique but form continuous set. This can be problematic because the weights representing CCR-efficiencty of ${\rm DMU}_j$ play an important role in making decisions on its management strategy. In order to resolve this problem, we propose to choose weights which minimize the efficency of the second best DMU enhancing the strength of ${\rm DMU}_j$, and demonstrate that this problem is reduced to a linear programming problem identical to the renowned super-efficiency model. We conduct numerical experiments using data of Japanese commercial banks to demonstrate the advantage of the supper-efficiency model.</description>
      <guid isPermaLink="false">oai:arXiv.org:2411.00438v1</guid>
      <category>math.OC</category>
      <pubDate>Mon, 04 Nov 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Tomonari Kitahara, Takashi Tsuchiya</dc:creator>
    </item>
    <item>
      <title>Adaptive Output Synchronization for a Class of Uncertain Nonlinear Multi-Agent Systems over Switching Networks</title>
      <link>https://arxiv.org/abs/2411.00455</link>
      <description>arXiv:2411.00455v1 Announce Type: new 
Abstract: In this paper, we first study the leader-following output synchronization problem for a class of uncertain nonlinear multi-agent systems over jointly connected switching networks. Our approach integrates the output-based adaptive distributed observer, the conventional adaptive control technique, and the output regulation theory. Compared with the existing results, our control law only relies on the output of the leader instead of the state of the leader and allows the followers and the leader to have different orders. Then, we further consider the rejection of a class of bounded disturbances with unknown bounds. Our problem includes the state consensus problem as a special case if the followers and the leader have the same order.</description>
      <guid isPermaLink="false">oai:arXiv.org:2411.00455v1</guid>
      <category>math.OC</category>
      <pubDate>Mon, 04 Nov 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/publicdomain/zero/1.0/</dc:rights>
      <dc:creator>Jie Huang</dc:creator>
    </item>
    <item>
      <title>On the required number of electrodes for uniqueness and convex reformulation in an inverse coefficient problem</title>
      <link>https://arxiv.org/abs/2411.00482</link>
      <description>arXiv:2411.00482v1 Announce Type: new 
Abstract: We introduce a computer-assisted proof for uniqueness and global reconstruction for the inverse Robin transmission problem, where the corrosion function on the boundary of an interior object is to be determined from current-voltage measurements on the boundary of an outer domain. We consider the shunt electrode model where, in contrast to the standard Neumann boundary condition, the applied electrical current is only partially known. The aim is to determine the corrosion coefficient with a finite number of measurements.
  In this paper, we present a numerically verifiable criterion that ensures unique solvability of the inverse problem, given a desired resolution. This allows us to explicitly determine the required number and position of the required electrodes. Furthermore, we will present an error estimate for noisy data. By rewriting the problem as a convex optimisation problem, our aim is to develop a globally convergent reconstruction algorithm.</description>
      <guid isPermaLink="false">oai:arXiv.org:2411.00482v1</guid>
      <category>math.OC</category>
      <category>cs.NA</category>
      <category>math.AP</category>
      <category>math.NA</category>
      <pubDate>Mon, 04 Nov 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Andrej Brojatsch, Bastian Harrach</dc:creator>
    </item>
    <item>
      <title>Unleashing the full potential of the North Sea -- Identifying key energy infrastructure synergies for 2030 and 2040</title>
      <link>https://arxiv.org/abs/2411.00540</link>
      <description>arXiv:2411.00540v1 Announce Type: new 
Abstract: Policy efforts have primarily focused on expanding variable renewable energy sources (vRES) to meet carbon emission reduction targets. The integration of high shares of renewables into the energy system is central to both policy making and research, focusing on the need for balancing options between vRES and demand. In this work we analyze and compare three key integration measures: grid expansions, electricity storage, and the role of production, storage and transport of low-carbon hydrogen. We focus on their potential to reduce emissions and energy system costs, individually and in combination. We take the North Sea as an exemplary region with ambitious 2030-2040 targets for offshore wind developments. The projections on installed generation and grid capacities, along with demand estimates from the Ten Year Network Development Plan (TYNDP) 2022, serve as a starting point for our energy system model. This starting model can then be further expanded with the three integration measures. Our findings show that grid expansions across the North Sea are a no-regret measure lowering costs, emissions and required renewable. The production of hydrogen and its direct use in industry has a lower cost reduction potential and emission reduction potential, while hydrogen storage and transport have little to no additional value. In the short term (2030), electricity storage can help to reduce emissions, but it is not cost competitive. In the longer term (2040), storage can help to balance investments in vRES assets by providing additional flexibility to the system. Combining the three integration measures provides additional benefits. The highest emission reductions can be achieved by combining electricity storage with an expansion of the grid. The highest economic benefits can be achieved with a combination of grid expansions and hydrogen production for direct use in industry.</description>
      <guid isPermaLink="false">oai:arXiv.org:2411.00540v1</guid>
      <category>math.OC</category>
      <category>econ.GN</category>
      <category>q-fin.EC</category>
      <pubDate>Mon, 04 Nov 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Jan F. Wiegner, Madeleine Gibescu, Matteo Gazzani</dc:creator>
    </item>
    <item>
      <title>Solving Semi-Linear Elliptic Optimal Control Problems with $L^1$-Cost via Regularization and RAS-Preconditioned Newton Methods</title>
      <link>https://arxiv.org/abs/2411.00546</link>
      <description>arXiv:2411.00546v1 Announce Type: new 
Abstract: We present a new parallel computational framework for the efficient solution of a class of $L^2$/$L^1$-regularized optimal control problems governed by semi-linear elliptic partial differential equations (PDEs). The main difficulty in solving this type of problem is the nonlinearity and non-smoothness of the $L^1$-term in the cost functional, which we address by employing a combination of several tools. First, we approximate the non-differentiable projection operator appearing in the optimality system by an appropriately chosen regularized operator and establish convergence of the resulting system's solutions. Second, we apply a continuation strategy to control the regularization parameter to improve the behavior of (damped) Newton methods. Third, we combine Newton's method with a domain-decomposition-based nonlinear preconditioning, which improves its robustness properties and allows for parallelization. The efficiency of the proposed numerical framework is demonstrated by extensive numerical experiments.</description>
      <guid isPermaLink="false">oai:arXiv.org:2411.00546v1</guid>
      <category>math.OC</category>
      <category>cs.NA</category>
      <category>math.NA</category>
      <pubDate>Mon, 04 Nov 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Gabriele Ciaramella, Michael Kartmann, Georg M\"uller</dc:creator>
    </item>
    <item>
      <title>An exact column generation algorithm for load balancing in capacity sharing networks</title>
      <link>https://arxiv.org/abs/2411.00555</link>
      <description>arXiv:2411.00555v1 Announce Type: new 
Abstract: Capacity sharing networks are typical heterogeneous communication networks widely applied in information and communications technology (ICT) field. In such networks, resources like bandwidth, spectrum, computation and storage are shared among various communication services. Meanwhile, the issue of network congestion is always a prominent challenge. To handle network congestion essentially needs to solve the load balancing of networks. In this paper, for capacity sharing networks, we formulate their load balancing problem as a maximum multi-commodity flow problem. For such a problem, always a large-scale linear programming, the column generation algorithm is a commonly used and crucial method to solve it. In each iteration, this algorithm involves solving a linear programming subproblem and determining whether to terminate or generate a new column for inclusion in the subproblem. This iterative procedure of solving and checking continues throughout the algorithm. Nevertheless, since the checking subproblem is NP-hard, its solution significantly impacts the overall efficiency of the algorithm. In this paper, we innovatively convert the checking subproblem into a single-constrained shortest path (SCSP) subproblem. By exactly solving the SCSP subproblem, we can obtain the optimal solution to the checking subproblem with same or less computing time. Experimental results demonstrate that our algorithm achieves computational efficiency comparable to heuristic algorithms while outperforming other state-of-the-art algorithms by at least an order of magnitude.</description>
      <guid isPermaLink="false">oai:arXiv.org:2411.00555v1</guid>
      <category>math.OC</category>
      <category>cs.SY</category>
      <category>eess.SY</category>
      <pubDate>Mon, 04 Nov 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Kaixiang Hu, Feilong Huang, Caixia Kou</dc:creator>
    </item>
    <item>
      <title>Pasting of Equilibria and Donsker-type Results for Mean Field Games</title>
      <link>https://arxiv.org/abs/2411.00633</link>
      <description>arXiv:2411.00633v1 Announce Type: new 
Abstract: This paper studies the relation between equilibria in single-period, discrete-time and continuous-time mean field game models. First, for single-period mean field games, we establish the existence of equilibria and then prove the propagation of the Lasry-Lions monotonicity to the optimal equilibrium value, as a function of the realization of the initial condition and its distribution. Secondly, we prove a pasting property for equilibria; that is, we construct equilibria to multi-period discrete-time mean field games by recursively pasting the equilibria of suitably initialized single-period games. Then, we show that any sequence of equilibria of discrete-time mean field games with discretized noise converges (up to a subsequence) to some equilibrium of the continuous-time mean field game as the mesh size of the discretization tends to zero. When the cost functions of the game satisfy the Lasry-Lions monotonicity property, we strengthen this convergence result by providing a sharp convergence rate.</description>
      <guid isPermaLink="false">oai:arXiv.org:2411.00633v1</guid>
      <category>math.OC</category>
      <category>math.PR</category>
      <pubDate>Mon, 04 Nov 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Jodi Dianetti, Max Nendel, Ludovic Tangpi, Shichun Wang</dc:creator>
    </item>
    <item>
      <title>A fresh look into variational analysis of $\mathcal C^2$-partly smooth functions</title>
      <link>https://arxiv.org/abs/2411.00655</link>
      <description>arXiv:2411.00655v1 Announce Type: new 
Abstract: $\mathcal C^2$-partial smoothness of functions has been an important subject of research in optimization, on both theoretical and algorithmic aspects, since it was first introduced by Lewis in 2002. Our work aims at providing a fresh variational analysis viewpoint on the class of $\mathcal C^2$-partly smooth functions. Namely, we explore the relationship between $\mathcal C^2$-partial smoothness and strict twice epi-differentiability and demonstrate that functions from the latter class are always strictly twice epi-differentiable. On the other hand, we provide two examples to show that the opposite conclusion does not hold in general. As a consequence of our analysis, we calculate the second subderivative of $\mathcal C^2$-partly smooth functions. Applications to stability analysis of related generalized equations involving a general perturbation and to asymptotic analysis of the well-known sample average approximation method for stochastic programs with $\mathcal C^2$-partly smooth regularizers are also given.</description>
      <guid isPermaLink="false">oai:arXiv.org:2411.00655v1</guid>
      <category>math.OC</category>
      <pubDate>Mon, 04 Nov 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Nguyen T. V. Hang, Ebrahim Sarabi</dc:creator>
    </item>
    <item>
      <title>IC/DC: Surpassing Heuristic Solvers in Combinatorial Optimization with Diffusion Models</title>
      <link>https://arxiv.org/abs/2411.00003</link>
      <description>arXiv:2411.00003v1 Announce Type: cross 
Abstract: Recent advancements in learning-based combinatorial optimization (CO) methods have shown promising results in solving NP-hard problems without the need for expert-crafted heuristics. However, high performance of these approaches often rely on problem-specific human-expertise-based search after generating candidate solutions, limiting their applicability to commonly solved CO problems such as Travelling Salesman Problem (TSP). In this paper, we present IC/DC, a CO framework that operates without any supervision. IC/DC is specialized in addressing problems involving two distinct sets of items, and it does not need problem-specific search processes to generate valid solutions. IC/DC employs a novel architecture capable of capturing the intricate relationships between items, and thereby enabling effective optimization in challenging CO scenarios. We train our model in a self-supervised way to minimize the cost of the solution while adhering to the problem-specific constraints. IC/DC not only achieves state-of-the-art performance compared to previous learning methods, but also surpasses well-known solvers and heuristic approaches on Asymmetric Traveling Salesman Problem (ATSP).</description>
      <guid isPermaLink="false">oai:arXiv.org:2411.00003v1</guid>
      <category>cs.AI</category>
      <category>cs.LG</category>
      <category>math.OC</category>
      <pubDate>Mon, 04 Nov 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/publicdomain/zero/1.0/</dc:rights>
      <dc:creator>Seong-Hyun Hong, Hyun-Sung Kim, Zian Jang, Byung-Jun Lee</dc:creator>
    </item>
    <item>
      <title>Derivative-Free Optimization via Finite Difference Approximation: An Experimental Study</title>
      <link>https://arxiv.org/abs/2411.00112</link>
      <description>arXiv:2411.00112v1 Announce Type: cross 
Abstract: Derivative-free optimization (DFO) is vital in solving complex optimization problems where only noisy function evaluations are available through an oracle. Within this domain, DFO via finite difference (FD) approximation has emerged as a powerful method. Two classical approaches are the Kiefer-Wolfowitz (KW) and simultaneous perturbation stochastic approximation (SPSA) algorithms, which estimate gradients using just two samples in each iteration to conserve samples. However, this approach yields imprecise gradient estimators, necessitating diminishing step sizes to ensure convergence, often resulting in slow optimization progress. In contrast, FD estimators constructed from batch samples approximate gradients more accurately. While gradient descent algorithms using batch-based FD estimators achieve more precise results in each iteration, they require more samples and permit fewer iterations. This raises a fundamental question: which approach is more effective -- KW-style methods or DFO with batch-based FD estimators? This paper conducts a comprehensive experimental comparison among these approaches, examining the fundamental trade-off between gradient estimation accuracy and iteration steps. Through extensive experiments in both low-dimensional and high-dimensional settings, we demonstrate a surprising finding: when an efficient batch-based FD estimator is applied, its corresponding gradient descent algorithm generally shows better performance compared to classical KW and SPSA algorithms in our tested scenarios.</description>
      <guid isPermaLink="false">oai:arXiv.org:2411.00112v1</guid>
      <category>cs.LG</category>
      <category>math.OC</category>
      <pubDate>Mon, 04 Nov 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Wang Du-Yi, Liang Guo, Liu Guangwu, Zhang Kun</dc:creator>
    </item>
    <item>
      <title>EARL-BO: Reinforcement Learning for Multi-Step Lookahead, High-Dimensional Bayesian Optimization</title>
      <link>https://arxiv.org/abs/2411.00171</link>
      <description>arXiv:2411.00171v1 Announce Type: cross 
Abstract: Conventional methods for Bayesian optimization (BO) primarily involve one-step optimal decisions (e.g., maximizing expected improvement of the next step). To avoid myopic behavior, multi-step lookahead BO algorithms such as rollout strategies consider the sequential decision-making nature of BO, i.e., as a stochastic dynamic programming (SDP) problem, demonstrating promising results in recent years. However, owing to the curse of dimensionality, most of these methods make significant approximations or suffer scalability issues, e.g., being limited to two-step lookahead. This paper presents a novel reinforcement learning (RL)-based framework for multi-step lookahead BO in high-dimensional black-box optimization problems. The proposed method enhances the scalability and decision-making quality of multi-step lookahead BO by efficiently solving the SDP of the BO process in a near-optimal manner using RL. We first introduce an Attention-DeepSets encoder to represent the state of knowledge to the RL agent and employ off-policy learning to accelerate its initial training. We then propose a multi-task, fine-tuning procedure based on end-to-end (encoder-RL) on-policy learning. We evaluate the proposed method, EARL-BO (Encoder Augmented RL for Bayesian Optimization), on both synthetic benchmark functions and real-world hyperparameter optimization problems, demonstrating significantly improved performance compared to existing multi-step lookahead and high-dimensional BO methods.</description>
      <guid isPermaLink="false">oai:arXiv.org:2411.00171v1</guid>
      <category>cs.LG</category>
      <category>math.OC</category>
      <pubDate>Mon, 04 Nov 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Mujin Cheon, Jay H. Lee, Dong-Yeun Koh, Calvin Tsay</dc:creator>
    </item>
    <item>
      <title>Inclusive KL Minimization: A Wasserstein-Fisher-Rao Gradient Flow Perspective</title>
      <link>https://arxiv.org/abs/2411.00214</link>
      <description>arXiv:2411.00214v1 Announce Type: cross 
Abstract: Otto's (2001) Wasserstein gradient flow of the exclusive KL divergence functional provides a powerful and mathematically principled perspective for analyzing learning and inference algorithms. In contrast, algorithms for the inclusive KL inference, i.e., minimizing $ \mathrm{KL}(\pi \| \mu) $ with respect to $ \mu $ for some target $ \pi $, are rarely analyzed using tools from mathematical analysis. This paper shows that a general-purpose approximate inclusive KL inference paradigm can be constructed using the theory of gradient flows derived from PDE analysis. We uncover that several existing learning algorithms can be viewed as particular realizations of the inclusive KL inference paradigm. For example, existing sampling algorithms such as Arbel et al. (2019) and Korba et al. (2021) can be viewed in a unified manner as inclusive-KL inference with approximate gradient estimators. Finally, we provide the theoretical foundation for the Wasserstein-Fisher-Rao gradient flows for minimizing the inclusive KL divergence.</description>
      <guid isPermaLink="false">oai:arXiv.org:2411.00214v1</guid>
      <category>stat.ML</category>
      <category>cs.LG</category>
      <category>math.OC</category>
      <pubDate>Mon, 04 Nov 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Jia-Jie Zhu</dc:creator>
    </item>
    <item>
      <title>Differential Calculus and Optimization in Persistence Module Categories</title>
      <link>https://arxiv.org/abs/2411.00493</link>
      <description>arXiv:2411.00493v1 Announce Type: cross 
Abstract: Persistence modules are representations of products of totally ordered sets in the category of vector spaces. They appear naturally in the representation theory of algebras, but in recent years they have also found applications in other areas of mathematics, including symplectic topology, complex analysis, and topological data analysis, where they arise from filtrations of topological spaces by the sublevel sets of real-valued functions. Two fundamental properties of persistence modules make them useful in such contexts: (1) the fact that they are stable under perturbations of the originating functions, and (2) the fact that they can be approximated, in the sense of relative homological algebra, by classes of indecomposable modules with an elementary structure. In this text we give an introduction to the theory of persistence modules, then we explain how the above properties can be leveraged to build a framework for differential calculus and optimization with convergence guarantees in persistence module categories.</description>
      <guid isPermaLink="false">oai:arXiv.org:2411.00493v1</guid>
      <category>math.AT</category>
      <category>math.OC</category>
      <category>math.RT</category>
      <pubDate>Mon, 04 Nov 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Steve Oudot</dc:creator>
    </item>
    <item>
      <title>Machine Learning-Accelerated Multi-Objective Design of Fractured Geothermal Systems</title>
      <link>https://arxiv.org/abs/2411.00504</link>
      <description>arXiv:2411.00504v1 Announce Type: cross 
Abstract: Multi-objective optimization has burgeoned as a potent methodology for informed decision-making in enhanced geothermal systems, aiming to concurrently maximize economic yield, ensure enduring geothermal energy provision, and curtail carbon emissions. However, addressing a multitude of design parameters inherent in computationally intensive physics-driven simulations constitutes a formidable impediment for geothermal design optimization, as well as across a broad range of scientific and engineering domains. Here we report an Active Learning enhanced Evolutionary Multi-objective Optimization algorithm, integrated with hydrothermal simulations in fractured media, to enable efficient optimization of fractured geothermal systems using few model evaluations. We introduce probabilistic neural network as classifier to learns to predict the Pareto dominance relationship between candidate samples and reference samples, thereby facilitating the identification of promising but uncertain offspring solutions. We then use active learning strategy to conduct hypervolume based attention subspace search with surrogate model by iteratively infilling informative samples within local promising parameter subspace. We demonstrate its effectiveness by conducting extensive experimental tests of the integrated framework, including multi-objective benchmark functions, a fractured geothermal model and a large-scale enhanced geothermal system. Results demonstrate that the ALEMO approach achieves a remarkable reduction in required simulations, with a speed-up of 1-2 orders of magnitude (10-100 times faster) than traditional evolutionary methods, thereby enabling accelerated decision-making. Our method is poised to advance the state-of-the-art of renewable geothermal energy system and enable widespread application to accelerate the discovery of optimal designs for complex systems.</description>
      <guid isPermaLink="false">oai:arXiv.org:2411.00504v1</guid>
      <category>cs.NE</category>
      <category>math.OC</category>
      <pubDate>Mon, 04 Nov 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Guodong Chen, Jiu Jimmy Jiao, Qiqi Liu, Zhongzheng Wang, Yaochu Jin</dc:creator>
    </item>
    <item>
      <title>Constrained Sampling with Primal-Dual Langevin Monte Carlo</title>
      <link>https://arxiv.org/abs/2411.00568</link>
      <description>arXiv:2411.00568v1 Announce Type: cross 
Abstract: This work considers the problem of sampling from a probability distribution known up to a normalization constant while satisfying a set of statistical constraints specified by the expected values of general nonlinear functions. This problem finds applications in, e.g., Bayesian inference, where it can constrain moments to evaluate counterfactual scenarios or enforce desiderata such as prediction fairness. Methods developed to handle support constraints, such as those based on mirror maps, barriers, and penalties, are not suited for this task. This work therefore relies on gradient descent-ascent dynamics in Wasserstein space to put forward a discrete-time primal-dual Langevin Monte Carlo algorithm (PD-LMC) that simultaneously constrains the target distribution and samples from it. We analyze the convergence of PD-LMC under standard assumptions on the target distribution and constraints, namely (strong) convexity and log-Sobolev inequalities. To do so, we bring classical optimization arguments for saddle-point algorithms to the geometry of Wasserstein space. We illustrate the relevance and effectiveness of PD-LMC in several applications.</description>
      <guid isPermaLink="false">oai:arXiv.org:2411.00568v1</guid>
      <category>stat.ML</category>
      <category>cs.LG</category>
      <category>math.OC</category>
      <pubDate>Mon, 04 Nov 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Luiz F. O. Chamon, Mohammad Reza Karimi, Anna Korba</dc:creator>
    </item>
    <item>
      <title>Path Integral Control for Hybrid Dynamical Systems</title>
      <link>https://arxiv.org/abs/2411.00659</link>
      <description>arXiv:2411.00659v1 Announce Type: cross 
Abstract: This work introduces a novel paradigm for solving optimal control problems for hybrid dynamical systems under uncertainties. Robotic systems having contact with the environment can be modeled as hybrid systems. Controller design for hybrid systems under disturbances is complicated by the discontinuous jump dynamics, mode changes with inconsistent state dimensions, and variations in jumping timing and states caused by noise. We formulate this problem into a stochastic control problem with hybrid transition constraints and propose the Hybrid Path Integral (H-PI) framework to obtain the optimal controller. Despite random mode changes across stochastic path samples, we show that the ratio between hybrid path distributions with varying drift terms remains analogous to the smooth path distributions. We then show that the optimal controller can be obtained by evaluating a path integral with hybrid constraints. Importance sampling for path distributions with hybrid dynamics constraints is introduced to reduce the variance of the path integral evaluation, where we leverage the recently developed Hybrid iterative-Linear-Quadratic-Regulator (H-iLQR) controller to induce a hybrid path distribution proposal with low variance. The proposed method is validated through numerical experiments on various hybrid systems and extensive ablation studies. All the sampling processes are conducted in parallel on a Graphics Processing Unit (GPU).</description>
      <guid isPermaLink="false">oai:arXiv.org:2411.00659v1</guid>
      <category>cs.RO</category>
      <category>math.OC</category>
      <pubDate>Mon, 04 Nov 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Hongzhe Yu, Diana Frias Franco, Aaron M. Johnson, Yongxin Chen</dc:creator>
    </item>
    <item>
      <title>Why do we regularise in every iteration for imaging inverse problems?</title>
      <link>https://arxiv.org/abs/2411.00688</link>
      <description>arXiv:2411.00688v1 Announce Type: cross 
Abstract: Regularisation is commonly used in iterative methods for solving imaging inverse problems. Many algorithms involve the evaluation of the proximal operator of the regularisation term in every iteration, leading to a significant computational overhead since such evaluation can be costly. In this context, the ProxSkip algorithm, recently proposed for federated learning purposes, emerges as an solution. It randomly skips regularisation steps, reducing the computational time of an iterative algorithm without affecting its convergence. Here we explore for the first time the efficacy of ProxSkip to a variety of imaging inverse problems and we also propose a novel PDHGSkip version. Extensive numerical results highlight the potential of these methods to accelerate computations while maintaining high-quality reconstructions.</description>
      <guid isPermaLink="false">oai:arXiv.org:2411.00688v1</guid>
      <category>math.NA</category>
      <category>cs.CV</category>
      <category>cs.NA</category>
      <category>math.OC</category>
      <pubDate>Mon, 04 Nov 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Evangelos Papoutsellis, Zeljko Kereta, Kostas Papafitsoros</dc:creator>
    </item>
    <item>
      <title>Aubry-Mather theory for optimal control systems with nonholonomic constraints</title>
      <link>https://arxiv.org/abs/2306.03808</link>
      <description>arXiv:2306.03808v3 Announce Type: replace 
Abstract: In this work, we extend Aubry-Mather theory to the case of control systems with nonholonomic constraints. In this framework, we consider an optimal control problem where admissible trajectories are solutions of a control-affine equation. Such an equation is associated with a family of smooth vector fields that satisfy the Hormander condition, which implies the controllability of the system. In this case, the Hamiltonian fails to be coercive, so results for Tonelli Hamiltonians cannot be applied. To overcome these obstacles, we develop an intrinsic approach based on the metric properties of the geometry induced on the state space by the sub-Riemannian structure.</description>
      <guid isPermaLink="false">oai:arXiv.org:2306.03808v3</guid>
      <category>math.OC</category>
      <pubDate>Mon, 04 Nov 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Piermarco Cannarsa, Cristian Mendico</dc:creator>
    </item>
    <item>
      <title>Optimal reinsurance from an optimal transport perspective</title>
      <link>https://arxiv.org/abs/2312.06811</link>
      <description>arXiv:2312.06811v2 Announce Type: replace 
Abstract: We use the randomization idea and proof techniques from optimal transport to study optimal reinsurance problems. We start by providing conditions for a class of problems that allow us to characterize the support of optimal treaties, and show how this can be used to deduce the shape of the optimal contract, reducing the task to an optimization problem with finitely many constraints, for which standard techniques can be applied. For a more general class of problems, we regard the optimal reinsurance problem as an iterated optimal transport problem between a (known) initial risk exposure of the insurer and an (unknown) resulting risk exposure of the reinsurer. The proposed approach provides a general framework that encompasses many reinsurance problems, which we illustrate in several concrete examples, providing alternative proofs to classical optimal reinsurance results, as well as establishing new optimality results, some of which contain optimal treaties that involve external randomness.</description>
      <guid isPermaLink="false">oai:arXiv.org:2312.06811v2</guid>
      <category>math.OC</category>
      <pubDate>Mon, 04 Nov 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Beatrice Acciaio, Hansj\"org Albrecher, Brandon Garc\'ia Flores</dc:creator>
    </item>
    <item>
      <title>Neur2BiLO: Neural Bilevel Optimization</title>
      <link>https://arxiv.org/abs/2402.02552</link>
      <description>arXiv:2402.02552v2 Announce Type: replace 
Abstract: Bilevel optimization deals with nested problems in which a leader takes the first decision to minimize their objective function while accounting for a follower's best-response reaction. Constrained bilevel problems with integer variables are particularly notorious for their hardness. While exact solvers have been proposed for mixed-integer linear bilevel optimization, they tend to scale poorly with problem size and are hard to generalize to the non-linear case. On the other hand, problem-specific algorithms (exact and heuristic) are limited in scope. Under a data-driven setting in which similar instances of a bilevel problem are solved routinely, our proposed framework, Neur2BiLO, embeds a neural network approximation of the leader's or follower's value function, trained via supervised regression, into an easy-to-solve mixed-integer program. Neur2BiLO serves as a heuristic that produces high-quality solutions extremely fast for four applications with linear and non-linear objectives and pure and mixed-integer variables.</description>
      <guid isPermaLink="false">oai:arXiv.org:2402.02552v2</guid>
      <category>math.OC</category>
      <category>cs.AI</category>
      <category>cs.LG</category>
      <pubDate>Mon, 04 Nov 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Justin Dumouchelle, Esther Julien, Jannis Kurtz, Elias B. Khalil</dc:creator>
    </item>
    <item>
      <title>Edge expansion of a graph: SDP-based computational strategies</title>
      <link>https://arxiv.org/abs/2403.04657</link>
      <description>arXiv:2403.04657v5 Announce Type: replace 
Abstract: Computing the edge expansion of a graph is a famously hard combinatorial problem for which there have been many approximation studies. We present two variants of exact algorithms using semidefinite programming (SDP) to compute this constant for any graph. The first variant uses the SDP relaxation first to reduce the search space considerably. The problem is then transformed into instances of max-cut problems, which are solved with an SDP-based state-of-the-art solver. Our second variant to compute the edge expansion uses Dinkelbach's algorithm for fractional programming. This is, we have to solve a parametrized optimization problem and again we use semidefinite programming to obtain solutions of the parametrized problems. Numerical results demonstrate that with our algorithms one can compute the edge expansion on graphs up to 400 vertices in a routine way, including instances where standard branch-and-cut solvers fail. To the best of our knowledge, these are the first SDP-based solvers for computing the edge expansion of a graph.</description>
      <guid isPermaLink="false">oai:arXiv.org:2403.04657v5</guid>
      <category>math.OC</category>
      <pubDate>Mon, 04 Nov 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Akshay Gupte, Melanie Siebenhofer, Angelika Wiegele</dc:creator>
    </item>
    <item>
      <title>From Linear to Linearizable Optimization: A Novel Framework with Applications to Stationary and Non-stationary DR-submodular Optimization</title>
      <link>https://arxiv.org/abs/2405.00065</link>
      <description>arXiv:2405.00065v3 Announce Type: replace 
Abstract: This paper introduces the notion of upper-linearizable/quadratizable functions, a class that extends concavity and DR-submodularity in various settings, including monotone and non-monotone cases over different convex sets. A general meta-algorithm is devised to convert algorithms for linear/quadratic maximization into ones that optimize upper-linearizable/quadratizable functions, offering a unified approach to tackling concave and DR-submodular optimization problems. The paper extends these results to multiple feedback settings, facilitating conversions between semi-bandit/first-order feedback and bandit/zeroth-order feedback, as well as between first/zeroth-order feedback and semi-bandit/bandit feedback. Leveraging this framework, new algorithms are derived using existing results as base algorithms for convex optimization, improving upon state-of-the-art results in various cases. Dynamic and adaptive regret guarantees are obtained for DR-submodular maximization, marking the first algorithms to achieve such guarantees in these settings. Notably, the paper achieves these advancements with fewer assumptions compared to existing state-of-the-art results, underscoring its broad applicability and theoretical contributions to non-convex optimization.</description>
      <guid isPermaLink="false">oai:arXiv.org:2405.00065v3</guid>
      <category>math.OC</category>
      <category>cs.CC</category>
      <category>cs.LG</category>
      <category>stat.ML</category>
      <pubDate>Mon, 04 Nov 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Mohammad Pedramfar, Vaneet Aggarwal</dc:creator>
    </item>
    <item>
      <title>On the integrality gap of the Complete Metric Steiner Tree Problem via a novel formulation</title>
      <link>https://arxiv.org/abs/2405.13773</link>
      <description>arXiv:2405.13773v3 Announce Type: replace 
Abstract: In this work, we study the metric Steiner Tree problem on graphs focusing on computing lower bounds for the integrality gap of the bi-directed cut (DCUT) formulation and introducing a novel formulation, the Complete Metric (CM) model, specifically designed to address the weakness of the DCUT formulation on metric instances. A key contribution of our work is extending of the Gap problem, previously explored in the context of the Traveling Salesman problems, to the metric Steiner Tree problem. To tackle the Gap problem for Steiner Tree instances, we first establish several structural properties of the CM formulation. We then classify the isomorphism classes of the vertices within the CM polytope, revealing a correspondence between the vertices of the DCUT and CM polytopes. Computationally, we exploit these structural properties to design two complementary heuristics for finding nontrivial small metric Steiner instances with a large integrality gap. We present several vertices for graphs with a number of nodes $\leq 10$, which realize the best-known lower bounds on the integrality gap for the CM and the DCUT formulations. We conclude the paper by presenting three new conjectures on the integrality gap of the DCUT and CM formulations for small graphs.</description>
      <guid isPermaLink="false">oai:arXiv.org:2405.13773v3</guid>
      <category>math.OC</category>
      <category>cs.DM</category>
      <pubDate>Mon, 04 Nov 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Ambrogio Maria Bernardelli, Eleonora Vercesi, Stefano Gualandi, Monaldo Mastrolilli, Luca Maria Gambardella</dc:creator>
    </item>
    <item>
      <title>Complexity of Adagrad and other first-order methods for nonconvex optimization problems with bounds constraints</title>
      <link>https://arxiv.org/abs/2406.15793</link>
      <description>arXiv:2406.15793v3 Announce Type: replace 
Abstract: A parametric class of trust-region algorithms for constrained nonconvex optimization is analyzed, where the objective function is never computed. By defining appropriate first-order stationarity criteria, we are able to extend the Adagrad method to the newly considered problem and retrieve the standard complexity rate of the projected gradient method that uses both the gradient and objective function values. Furthermore, we propose an additional iteration-dependent scaling with slightly inferior theoretical guarantees. In both cases, the bounds are essentially sharp, and curvature information can be used to compute the stepsize. Initial experimental results for noisy bound-constrained instances illustrate the benefits of the objective-free approach.</description>
      <guid isPermaLink="false">oai:arXiv.org:2406.15793v3</guid>
      <category>math.OC</category>
      <pubDate>Mon, 04 Nov 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Serge Gratton, Sadok Jerad, Philippe L. Toint</dc:creator>
    </item>
    <item>
      <title>Decentralized Conjugate Gradient and Memoryless BFGS Methods</title>
      <link>https://arxiv.org/abs/2409.07122</link>
      <description>arXiv:2409.07122v2 Announce Type: replace 
Abstract: This paper considers the decentralized optimization problem of minimizing a finite sum of continuously differentiable functions over a fixed-connected undirected network. Summarizing the lack of previously developed decentralized conjugate gradient methods, we propose new decentralized conjugate gradient (NDCG) and memoryless BFGS (DMBFGS) methods for nonconvex and strongly convex problems, respectively. Firstly, to the best of our knowledge, NDCG is the first decentralized conjugate gradient method to be shown to have global convergence with constant stepsizes for general nonconvex optimization problems, which profits from our designed conjugate parameter and relies only on the same mild conditions as the centralized conjugate gradient method. Secondly, considering the conjugate gradient method as a special quasi-Newton method, we apply a scaled memoryless BFGS technique and develop the DMBFGS method that requires only vector-vector products to capture the curvature information of Hessian matrices. DMBFGS ensures quasi-Newton matrices have bounded eigenvalues without introducing any regularization term or damping method. Under proper choice of stepsizes, DMBFGS has global linear convergence for solving strongly convex decentralized optimization problems. Our numerical results show both NDCG and DMBFGS are very efficient respectively compared with other state-of-the-art methods for solving nonconvex and strongly convex decentralized optimization.</description>
      <guid isPermaLink="false">oai:arXiv.org:2409.07122v2</guid>
      <category>math.OC</category>
      <pubDate>Mon, 04 Nov 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Liping Wang, Hao Wu, Hongchao Zhang</dc:creator>
    </item>
    <item>
      <title>Prevailing against Adversarial Noncentral Disturbances: Exact Recovery of Linear Systems with the $l_1$-norm Estimator</title>
      <link>https://arxiv.org/abs/2410.03218</link>
      <description>arXiv:2410.03218v2 Announce Type: replace 
Abstract: This paper studies the linear system identification problem in the general case where the disturbance is sub-Gaussian, correlated, and possibly adversarial. First, we consider the case with noncentral (nonzero-mean) disturbances for which the ordinary least-squares (OLS) method fails to correctly identify the system. We prove that the $l_1$-norm estimator accurately identifies the system under the condition that each disturbance has equal probabilities of being positive or negative. This condition restricts the sign of each disturbance but allows its magnitude to be arbitrary. Second, we consider the case where each disturbance is adversarial with the model that the attack times happen occasionally but the distributions of the attack values are completely arbitrary. We show that when the probability of having an attack at a given time is less than 0.5, the $l_1$-norm estimator prevails against any adversarial noncentral disturbances and the exact recovery is achieved within a finite time. These results pave the way to effectively defend against arbitrarily large noncentral attacks in safety-critical systems.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.03218v2</guid>
      <category>math.OC</category>
      <pubDate>Mon, 04 Nov 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Jihun Kim, Javad Lavaei</dc:creator>
    </item>
    <item>
      <title>Nesterov acceleration despite very noisy gradients</title>
      <link>https://arxiv.org/abs/2302.05515</link>
      <description>arXiv:2302.05515v3 Announce Type: replace-cross 
Abstract: We present a generalization of Nesterov's accelerated gradient descent algorithm. Our algorithm (AGNES) provably achieves acceleration for smooth convex and strongly convex minimization tasks with noisy gradient estimates if the noise intensity is proportional to the magnitude of the gradient at every point. Nesterov's method converges at an accelerated rate if the constant of proportionality is below 1, while AGNES accommodates any signal-to-noise ratio. The noise model is motivated by applications in overparametrized machine learning. AGNES requires only two parameters in convex and three in strongly convex minimization tasks, improving on existing methods. We further provide clear geometric interpretations and heuristics for the choice of parameters.</description>
      <guid isPermaLink="false">oai:arXiv.org:2302.05515v3</guid>
      <category>stat.ML</category>
      <category>cs.LG</category>
      <category>math.OC</category>
      <pubDate>Mon, 04 Nov 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Kanan Gupta, Jonathan W. Siegel, Stephan Wojtowytsch</dc:creator>
    </item>
    <item>
      <title>Continuous-time q-learning for mean-field control problems</title>
      <link>https://arxiv.org/abs/2306.16208</link>
      <description>arXiv:2306.16208v4 Announce Type: replace-cross 
Abstract: This paper studies the q-learning, recently coined as the continuous time counterpart of Q-learning by Jia and Zhou (2023), for continuous time Mckean-Vlasov control problems in the setting of entropy-regularized reinforcement learning. In contrast to the single agent's control problem in Jia and Zhou (2023), the mean-field interaction of agents renders the definition of the q-function more subtle, for which we reveal that two distinct q-functions naturally arise: (i) the integrated q-function (denoted by $q$) as the first-order approximation of the integrated Q-function introduced in Gu, Guo, Wei and Xu (2023), which can be learnt by a weak martingale condition involving test policies; and (ii) the essential q-function (denoted by $q_e$) that is employed in the policy improvement iterations. We show that two q-functions are related via an integral representation under all test policies. Based on the weak martingale condition and our proposed searching method of test policies, some model-free learning algorithms are devised. In two examples, one in LQ control framework and one beyond LQ control framework, we can obtain the exact parameterization of the optimal value function and q-functions and illustrate our algorithms with simulation experiments.</description>
      <guid isPermaLink="false">oai:arXiv.org:2306.16208v4</guid>
      <category>cs.LG</category>
      <category>math.OC</category>
      <category>q-fin.CP</category>
      <pubDate>Mon, 04 Nov 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Xiaoli Wei, Xiang Yu</dc:creator>
    </item>
    <item>
      <title>Decision-focused predictions via pessimistic bilevel optimization: a computational study</title>
      <link>https://arxiv.org/abs/2312.17640</link>
      <description>arXiv:2312.17640v3 Announce Type: replace-cross 
Abstract: Dealing with uncertainty in optimization parameters is an important and longstanding challenge. Typically, uncertain parameters are predicted accurately, and then a deterministic optimization problem is solved. However, the decisions produced by this so-called \emph{predict-then-optimize} procedure can be highly sensitive to uncertain parameters. In this work, we contribute to recent efforts in producing \emph{decision-focused} predictions, i.e., to build predictive models that are constructed with the goal of minimizing a \emph{regret} measure on the decisions taken with them. We begin by formulating the exact expected regret minimization as a pessimistic bilevel optimization model. Then, we establish NP-completeness of this problem, even in a heavily restricted case. Using duality arguments, we reformulate it as a non-convex quadratic optimization problem. Finally, we show various computational techniques to achieve tractability. We report extensive computational results on shortest-path instances with uncertain cost vectors. Our results indicate that our approach can improve training performance over the approach of Elmachtoub and Grigas (2022), a state-of-the-art method for decision-focused learning.</description>
      <guid isPermaLink="false">oai:arXiv.org:2312.17640v3</guid>
      <category>cs.LG</category>
      <category>math.OC</category>
      <pubDate>Mon, 04 Nov 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>V\'ictor Bucarey, Sophia Calder\'on, Gonzalo Mu\~noz, Frederic Semet</dc:creator>
    </item>
    <item>
      <title>Control of the Schr\"{o}dinger equation in $\mathbb{R}^3$: The critical case</title>
      <link>https://arxiv.org/abs/2404.07749</link>
      <description>arXiv:2404.07749v2 Announce Type: replace-cross 
Abstract: This article deals with the $H^{1}$--level local null controllability for the defocusing critical nonlinear Schr\"{o}dinger equation in $\mathbb{R}^3$. Firstly, we show the problem under consideration to be well-posed using Strichartz estimates. Moreover, through the Hilbert uniqueness method, we prove the linear Schr\"{o}dinger equation to be controllable. Finally, we use a perturbation argument and show local controllability for the critical nonlinear Schr\"{o}dinger equation.</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.07749v2</guid>
      <category>math.AP</category>
      <category>math.OC</category>
      <pubDate>Mon, 04 Nov 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/publicdomain/zero/1.0/</dc:rights>
      <dc:creator>Pablo Braz e Silva (UFPE), Roberto de A. Capistrano-Filho (UFPE), Jackellyny Dassy do Nascimento Carvalho (UFPE), David dos Santos Ferreira (IELC)</dc:creator>
    </item>
    <item>
      <title>Adversarial Representation Engineering: A General Model Editing Framework for Large Language Models</title>
      <link>https://arxiv.org/abs/2404.13752</link>
      <description>arXiv:2404.13752v3 Announce Type: replace-cross 
Abstract: Since the rapid development of Large Language Models (LLMs) has achieved remarkable success, understanding and rectifying their internal complex mechanisms has become an urgent issue. Recent research has attempted to interpret their behaviors through the lens of inner representation. However, developing practical and efficient methods for applying these representations for general and flexible model editing remains challenging. In this work, we explore how to leverage insights from representation engineering to guide the editing of LLMs by deploying a representation sensor as an editing oracle. We first identify the importance of a robust and reliable sensor during editing, then propose an Adversarial Representation Engineering (ARE) framework to provide a unified and interpretable approach for conceptual model editing without compromising baseline performance. Experiments on multiple tasks demonstrate the effectiveness of ARE in various model editing scenarios. Our code and data are available at https://github.com/Zhang-Yihao/Adversarial-Representation-Engineering.</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.13752v3</guid>
      <category>cs.LG</category>
      <category>cs.AI</category>
      <category>cs.CL</category>
      <category>cs.CR</category>
      <category>math.OC</category>
      <pubDate>Mon, 04 Nov 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Yihao Zhang, Zeming Wei, Jun Sun, Meng Sun</dc:creator>
    </item>
    <item>
      <title>Source Identification by Consensus-Based Optimization</title>
      <link>https://arxiv.org/abs/2405.10110</link>
      <description>arXiv:2405.10110v2 Announce Type: replace-cross 
Abstract: A consensus-based optimization (CBO) algorithm, which enables derivative and mesh-free optimization, is presented to localize a bioluminescent source. The light propagation is modeled by the radiative transfer equation approximated by spherical harmonics. The approach is investigated for a hierarchy of simplified diffusion models in simulated environments and tissue-mimicking phantoms. In simulations, the state-of-the-art diffusive approximation gives reliable results for heavily scattering media. However, higher-order models achieve better localization and more accurate source intensities for deeper sources and in the presence of artificial noise in strongly absorbing, but only moderately scattering media. In phantoms, higher-order models give lower approximation errors and the most accurate localization, even for a high scattering coefficient. These results demonstrate the potential of CBO to render higher-order models at lower computational cost while ensuring accurate localization in bioluminescence tomography.</description>
      <guid isPermaLink="false">oai:arXiv.org:2405.10110v2</guid>
      <category>q-bio.QM</category>
      <category>math.OC</category>
      <pubDate>Mon, 04 Nov 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Jan Friedrich, Sarah Schraven, Fabian Kiessling, Michael Herty</dc:creator>
    </item>
    <item>
      <title>Improving Generalization and Convergence by Enhancing Implicit Regularization</title>
      <link>https://arxiv.org/abs/2405.20763</link>
      <description>arXiv:2405.20763v4 Announce Type: replace-cross 
Abstract: In this work, we propose an Implicit Regularization Enhancement (IRE) framework to accelerate the discovery of flat solutions in deep learning, thereby improving generalization and convergence. Specifically, IRE decouples the dynamics of flat and sharp directions, which boosts the sharpness reduction along flat directions while maintaining the training stability in sharp directions. We show that IRE can be practically incorporated with {\em generic base optimizers} without introducing significant computational overload. Experiments show that IRE consistently improves the generalization performance for image classification tasks across a variety of benchmark datasets (CIFAR-10/100, ImageNet) and models (ResNets and ViTs). Surprisingly, IRE also achieves a $2\times$ {\em speed-up} compared to AdamW in the pre-training of Llama models (of sizes ranging from 60M to 229M) on datasets including Wikitext-103, Minipile, and Openwebtext. Moreover, we provide theoretical guarantees, showing that IRE can substantially accelerate the convergence towards flat minima in Sharpness-aware Minimization (SAM).</description>
      <guid isPermaLink="false">oai:arXiv.org:2405.20763v4</guid>
      <category>cs.LG</category>
      <category>math.OC</category>
      <category>stat.ML</category>
      <pubDate>Mon, 04 Nov 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Mingze Wang, Jinbo Wang, Haotian He, Zilin Wang, Guanhua Huang, Feiyu Xiong, Zhiyu Li, Weinan E, Lei Wu</dc:creator>
    </item>
    <item>
      <title>FIARSE: Model-Heterogeneous Federated Learning via Importance-Aware Submodel Extraction</title>
      <link>https://arxiv.org/abs/2407.19389</link>
      <description>arXiv:2407.19389v2 Announce Type: replace-cross 
Abstract: In federated learning (FL), accommodating clients' varied computational capacities poses a challenge, often limiting the participation of those with constrained resources in global model training. To address this issue, the concept of model heterogeneity through submodel extraction has emerged, offering a tailored solution that aligns the model's complexity with each client's computational capacity. In this work, we propose Federated Importance-Aware Submodel Extraction (FIARSE), a novel approach that dynamically adjusts submodels based on the importance of model parameters, thereby overcoming the limitations of previous static and dynamic submodel extraction methods. Compared to existing works, the proposed method offers a theoretical foundation for the submodel extraction and eliminates the need for additional information beyond the model parameters themselves to determine parameter importance, significantly reducing the overhead on clients. Extensive experiments are conducted on various datasets to showcase the superior performance of the proposed FIARSE.</description>
      <guid isPermaLink="false">oai:arXiv.org:2407.19389v2</guid>
      <category>cs.DC</category>
      <category>cs.LG</category>
      <category>math.OC</category>
      <pubDate>Mon, 04 Nov 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Feijie Wu, Xingchen Wang, Yaqing Wang, Tianci Liu, Lu Su, Jing Gao</dc:creator>
    </item>
    <item>
      <title>Bi-level regularization via iterative mesh refinement for aeroacoustics</title>
      <link>https://arxiv.org/abs/2409.06854</link>
      <description>arXiv:2409.06854v3 Announce Type: replace-cross 
Abstract: In this work, we illustrate the connection between adaptive mesh refinement for finite element discretized PDEs and the recently developed \emph{bi-level regularization algorithm}. By adaptive mesh refinement according to data noise, regularization effect and convergence are immediate consequences. We moreover demonstrate its numerical advantages to the classical Landweber algorithm in term of time and reconstruction quality for the example of the Helmholtz equation in an aeroacoustic setting.</description>
      <guid isPermaLink="false">oai:arXiv.org:2409.06854v3</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <category>math.OC</category>
      <pubDate>Mon, 04 Nov 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Christian Aarset, Tram Thi Ngoc Nguyen</dc:creator>
    </item>
    <item>
      <title>Tensor-Based Synchronization and the Low-Rankness of the Block Trifocal Tensor</title>
      <link>https://arxiv.org/abs/2409.09313</link>
      <description>arXiv:2409.09313v2 Announce Type: replace-cross 
Abstract: The block tensor of trifocal tensors provides crucial geometric information on the three-view geometry of a scene. The underlying synchronization problem seeks to recover camera poses (locations and orientations up to a global transformation) from the block trifocal tensor. We establish an explicit Tucker factorization of this tensor, revealing a low multilinear rank of $(6,4,4)$ independent of the number of cameras under appropriate scaling conditions. We prove that this rank constraint provides sufficient information for camera recovery in the noiseless case. The constraint motivates a synchronization algorithm based on the higher-order singular value decomposition of the block trifocal tensor. Experimental comparisons with state-of-the-art global synchronization methods on real datasets demonstrate the potential of this algorithm for significantly improving location estimation accuracy. Overall this work suggests that higher-order interactions in synchronization problems can be exploited to improve performance, beyond the usual pairwise-based approaches.</description>
      <guid isPermaLink="false">oai:arXiv.org:2409.09313v2</guid>
      <category>cs.CV</category>
      <category>cs.NA</category>
      <category>math.NA</category>
      <category>math.OC</category>
      <pubDate>Mon, 04 Nov 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <dc:creator>Daniel Miao, Gilad Lerman, Joe Kileel</dc:creator>
    </item>
    <item>
      <title>Strongly connected orientations and integer lattices</title>
      <link>https://arxiv.org/abs/2410.13665</link>
      <description>arXiv:2410.13665v2 Announce Type: replace-cross 
Abstract: Let $D=(V,A)$ be a digraph whose underlying graph is $2$-edge-connected, and let $P$ be the polytope whose vertices are the incidence vectors of arc sets whose reversal makes $D$ strongly connected. We study the lattice theoretic properties of the integer points contained in a proper face $F$ of $P$ not contained in $\{x:x_a=i\}$ for any $a\in A,i\in \{0,1\}$. We prove under a mild necessary condition that $F\cap \{0,1\}^A$ contains an integral basis $B$, i.e., $B$ is linearly independent, and any integral vector in the linear hull of $F$ is an integral linear combination of $B$. This result is surprising as the integer points in $F$ do not necessarily form a Hilbert basis. In proving the result, we develop a theory similar to Matching Theory for degree-constrained dijoins in bipartite digraphs. Our result has consequences for head-disjoint strong orientations in hypergraphs, and also to a famous conjecture by Woodall that the minimum size of a dicut of $D$, say $\tau$, is equal to the maximum number of disjoint dijoins. We prove a relaxation of this conjecture, by finding for any prime number $p\geq 2$, a $p$-adic packing of dijoins of value $\tau$ and of support size at most $2|A|$. We also prove that the all-ones vector belongs to the lattice generated by $F\cap \{0,1\}^A$, where $F$ is the face of $P$ satisfying $x(\delta^+(U))=1$ for every minimum dicut $\delta^+(U)$.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.13665v2</guid>
      <category>math.CO</category>
      <category>math.OC</category>
      <pubDate>Mon, 04 Nov 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Ahmad Abdi, G\'erard Cornu\'ejols, Siyue Liu, Olha Silina</dc:creator>
    </item>
    <item>
      <title>Provable optimal transport with transformers: The essence of depth and prompt engineering</title>
      <link>https://arxiv.org/abs/2410.19931</link>
      <description>arXiv:2410.19931v2 Announce Type: replace-cross 
Abstract: Can we establish provable performance guarantees for transformers? Establishing such theoretical guarantees is a milestone in developing trustworthy generative AI. In this paper, we take a step toward addressing this question by focusing on optimal transport, a fundamental problem at the intersection of combinatorial and continuous optimization. Leveraging the computational power of attention layers, we prove that a transformer with fixed parameters can effectively solve the optimal transport problem in Wasserstein-2 with entropic regularization for an arbitrary number of points. Consequently, the transformer can sort lists of arbitrary sizes up to an approximation factor. Our results rely on an engineered prompt that enables the transformer to implement gradient descent with adaptive stepsizes on the dual optimal transport. Combining the convergence analysis of gradient descent with Sinkhorn dynamics, we establish an explicit approximation bound for optimal transport with transformers, which improves as depth increases. Our findings provide novel insights into the essence of prompt engineering and depth for solving optimal transport. In particular, prompt engineering boosts the algorithmic expressivity of transformers, allowing them implement an optimization method. With increasing depth, transformers can simulate several iterations of gradient descent.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.19931v2</guid>
      <category>cs.LG</category>
      <category>math.OC</category>
      <category>stat.ML</category>
      <pubDate>Mon, 04 Nov 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Hadi Daneshmand</dc:creator>
    </item>
  </channel>
</rss>
