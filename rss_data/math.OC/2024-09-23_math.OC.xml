<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>math.OC updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/math.OC</link>
    <description>math.OC updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/math.OC" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Tue, 24 Sep 2024 03:14:42 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Mon, 23 Sep 2024 00:00:00 -0400</pubDate>
    <skipDays>
      <day>Sunday</day>
      <day>Saturday</day>
    </skipDays>
    <item>
      <title>Robustifying Model Predictive Control of Uncertain Linear Systems with Chance Constraints</title>
      <link>https://arxiv.org/abs/2409.13032</link>
      <description>arXiv:2409.13032v1 Announce Type: new 
Abstract: This paper proposes a model predictive controller for discrete-time linear systems with additive, possibly unbounded, stochastic disturbances and subject to chance constraints. By computing a polytopic probabilistic positively invariant set for constraint tightening with the help of the computation of the minimal robust positively invariant set, the chance constraints are guaranteed, assuming only the mean and covariance of the disturbance distribution are given. The resulting online optimization problem is a standard strictly quadratic programming, just like in conventional model predictive control with recursive feasibility and stability guarantees and is simple to implement. A numerical example is provided to illustrate the proposed method.</description>
      <guid isPermaLink="false">oai:arXiv.org:2409.13032v1</guid>
      <category>math.OC</category>
      <pubDate>Mon, 23 Sep 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Kai Wang, Kiet Tuan Hoang, S\'ebastien Gros</dc:creator>
    </item>
    <item>
      <title>Singularity-free Backstepping-based Adaptive Control of a Bicopter with Unknown Mass and Inertia</title>
      <link>https://arxiv.org/abs/2409.13081</link>
      <description>arXiv:2409.13081v1 Announce Type: new 
Abstract: The paper develops a singularity-free backstepping-based adaptive control for stabilizing and tracking the trajectory of a bicopter system. In the bicopter system, the inertial parameters parameterize the input map. Since the classical adaptive backstepping technique requires the inversion of the input map, which contains the estimate of parameter estimates, the stability of the closed-loop system cannot be guaranteed due to the inversion of parameter estimates. This paper proposes a novel technique to circumvent the inversion of parameter estimates in the control law. The resulting controller requires only the sign of the unknown parameters. The proposed controller is validated in simulation for a smooth and nonsmooth trajectory-tracking problem.</description>
      <guid isPermaLink="false">oai:arXiv.org:2409.13081v1</guid>
      <category>math.OC</category>
      <pubDate>Mon, 23 Sep 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <dc:creator>Jhon Manuel Portella Delgado, Ankit Goel</dc:creator>
    </item>
    <item>
      <title>Lipschitz stability of least-squares problems regularized by functions with $\mathcal{C}^2$-cone reducible conjugates</title>
      <link>https://arxiv.org/abs/2409.13118</link>
      <description>arXiv:2409.13118v1 Announce Type: new 
Abstract: In this paper, we study Lipschitz continuity of the solution mappings of regularized least-squares problems for which the convex regularizers have (Fenchel) conjugates that are $\mathcal{C}^2$-cone reducible. Our approach, by using Robinson's strong regularity on the dual problem, allows us to obtain new characterizations of Lipschitz stability that rely solely on first-order information, thus bypassing the need to explore second-order information (curvature) of the regularizer. We show that these solution mappings are automatically Lipschitz continuous around the points in question whenever they are locally single-valued. We leverage our findings to obtain new characterizations of full stability and tilt stability for a broader class of convex additive-composite problems.</description>
      <guid isPermaLink="false">oai:arXiv.org:2409.13118v1</guid>
      <category>math.OC</category>
      <pubDate>Mon, 23 Sep 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Ying Cui, Tim Hoheisel, Tran T. A. Nghia, Defeng Sun</dc:creator>
    </item>
    <item>
      <title>A Neural Network Framework for High-Dimensional Dynamic Unbalanced Optimal Transport</title>
      <link>https://arxiv.org/abs/2409.13188</link>
      <description>arXiv:2409.13188v1 Announce Type: new 
Abstract: In this paper, we introduce a neural network-based method to address the high-dimensional dynamic unbalanced optimal transport (UOT) problem. Dynamic UOT focuses on the optimal transportation between two densities with unequal total mass, however, it introduces additional complexities compared to the traditional dynamic optimal transport (OT) problem. To efficiently solve the dynamic UOT problem in high-dimensional space, we first relax the original problem by using the generalized Kullback-Leibler (GKL) divergence to constrain the terminal density. Next, we adopt the Lagrangian discretization to address the unbalanced continuity equation and apply the Monte Carlo method to approximate the high-dimensional spatial integrals. Moreover, a carefully designed neural network is introduced for modeling the velocity field and source function. Numerous experiments demonstrate that the proposed framework performs excellently in high-dimensional cases. Additionally, this method can be easily extended to more general applications, such as crowd motion problem.</description>
      <guid isPermaLink="false">oai:arXiv.org:2409.13188v1</guid>
      <category>math.OC</category>
      <pubDate>Mon, 23 Sep 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Wei Wan, Jiangong Pan, Yuejin Zhang, Chenglong Bao, Zuoqiang Shi</dc:creator>
    </item>
    <item>
      <title>A Modified Algorithm for Optimal Picker Routing in a Single Block Warehouse</title>
      <link>https://arxiv.org/abs/2409.13219</link>
      <description>arXiv:2409.13219v1 Announce Type: new 
Abstract: The order picker routing problem involves finding the optimal tour of a warehouse that collects all the required items on a given pick list. Ratliff and Rosenthal introduced a dynamic programming algorithm for solving this problem in polynomial time by sequentially adding edges inside and between each aisle to construct a tour. We provide a method where only transitions from one aisle to the next are considered, significantly reducing the number of stages in the algorithm.</description>
      <guid isPermaLink="false">oai:arXiv.org:2409.13219v1</guid>
      <category>math.OC</category>
      <pubDate>Mon, 23 Sep 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>George Dunn, Hadi Charkhgard, Ali Eshragh, Elizabeth Stojanovski</dc:creator>
    </item>
    <item>
      <title>An accelerated preconditioned proximal gradient algorithm with a generalized Nesterov momentum for PET image reconstruction</title>
      <link>https://arxiv.org/abs/2409.13344</link>
      <description>arXiv:2409.13344v1 Announce Type: new 
Abstract: This paper presents an Accelerated Preconditioned Proximal Gradient Algorithm (APPGA) for effectively solving a class of Positron Emission Tomography (PET) image reconstruction models with differentiable regularizers. We establish the convergence of APPGA with the Generalized Nesterov (GN) momentum scheme, demonstrating its ability to converge to a minimizer of the objective function with rates of $o(1/k^{2\omega})$ and $o(1/k^{\omega})$ in terms of the function value and the distance between consecutive iterates, respectively, where $\omega\in(0,1]$ is the power parameter of the GN momentum. To achieve an efficient algorithm with high-order convergence rate for the higher-order isotropic total variation (ITV) regularized PET image reconstruction model, we replace the ITV term by its smoothed version and subsequently apply APPGA to solve the smoothed model. Numerical results presented in this work indicate that as $\omega\in(0,1]$ increase, APPGA converges at a progressively faster rate. Furthermore, APPGA exhibits superior performance compared to the preconditioned proximal gradient algorithm and the preconditioned Krasnoselskii-Mann algorithm. The extension of the GN momentum technique for solving a more complex optimization model with multiple nondifferentiable terms is also discussed.</description>
      <guid isPermaLink="false">oai:arXiv.org:2409.13344v1</guid>
      <category>math.OC</category>
      <category>cs.NA</category>
      <category>math.NA</category>
      <pubDate>Mon, 23 Sep 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Yizun Lin, Yongxin He, C. Ross Schmidtlein, Deren Han</dc:creator>
    </item>
    <item>
      <title>An integrated selection and routing policy for urban waste collection</title>
      <link>https://arxiv.org/abs/2409.13386</link>
      <description>arXiv:2409.13386v1 Announce Type: new 
Abstract: We study a daily urban waste collection problem arising in the municipality of Groningen, The Netherlands, where residents bring their waste to local underground waste containers organised in clusters. The municipality plans routes for waste collection vehicles to empty the container clusters. These routes should be as short as possible to limit operational costs, but also long enough to visit sufficiently many clusters and ensure that containers do not overflow. A complicating factor is that the actual fill levels of the clusters' containers are not known, and only the number of deposits is observed. Additionally, it is unclear whether the containers should be upgraded with expensive fill level sensors so that the service level can be improved or routing costs can be reduced. We propose an efficient integrated selection and routing (ISR) policy that jointly optimises the daily cluster selection and routing decisions. The integration is achieved by first estimating prizes that express the urgency of selecting a cluster to empty, and then solving a prize-collecting vehicle routing problem with time windows and driver breaks to collect these prizes while minimising routing costs. We use a metaheuristic to solve the prize-collecting vehicle routing problem inside a realistic simulation environment that models the waste collection problem faced by the municipality. We show that solving the daily waste collection problem in this way is very effective, and can lead to substantial cost savings for the municipality in practice, with no reduction in service level. In particular, by integrating the container selection and routing problems using our ISR policy, routing costs can be reduced by more than 40% and the fleet size by 25%. We also show that more advanced measuring techniques do not significantly reduce routing costs, and the service level not at all.</description>
      <guid isPermaLink="false">oai:arXiv.org:2409.13386v1</guid>
      <category>math.OC</category>
      <category>stat.AP</category>
      <pubDate>Mon, 23 Sep 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Niels A. Wouda, Marjolein Aerts-Veenstra, Nicky van Foreest</dc:creator>
    </item>
    <item>
      <title>Methods for Solving Variational Inequalities with Markovian Stochasticity</title>
      <link>https://arxiv.org/abs/2409.13428</link>
      <description>arXiv:2409.13428v1 Announce Type: new 
Abstract: In this paper, we present a novel stochastic method for solving variational inequalities (VI) in the context of Markovian noise. By leveraging Extragradient technique, we can productively solve VI optimization problems characterized by Markovian dynamics. We demonstrate the efficacy of proposed method through rigorous theoretical analysis, proving convergence under quite mild assumptions of $L$-Lipschitzness, strong monotonicity of the operator and boundness of the noise only at the optimum. In order to gain further insight into the nature of Markov processes, we conduct the experiments to investigate the impact of the mixing time parameter on the convergence of the algorithm.</description>
      <guid isPermaLink="false">oai:arXiv.org:2409.13428v1</guid>
      <category>math.OC</category>
      <pubDate>Mon, 23 Sep 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Vladimir Solodkin, Michael Ermoshin, Roman Gavrilenko, Aleksandr Beznosikov</dc:creator>
    </item>
    <item>
      <title>Optimal control of a kinetic model describing social interactions on a graph</title>
      <link>https://arxiv.org/abs/2409.13542</link>
      <description>arXiv:2409.13542v1 Announce Type: new 
Abstract: In this paper we introduce the optimal control of a kinetic model describing agents who migrate on a graph and interact within its nodes exchanging a physical quantity. As a prototype model, we consider the spread of an infectious disease on a graph, so that the exchanged quantity is the viral-load. The control, exerted on both the mobility and on the interactions separately, aims at minimising the average macroscopic viral-load.
  We prove that minimising the average viral-load weighted by the mass in each node is the most effective and convenient strategy. We consider two different interactions: in the first one the infection (gain) and the healing (loss) processes happen within the same interaction, while in the second case the infection and healing result from two different processes. With the appropriate controls, we prove that in the first case it is possible to stop the increase of the disease, but paying a very high cost in terms of control, while in the second case it is possible to eradicate the disease. We test numerically the role of each intervention and the interplay between the mobility and the interaction control strategies in each model.</description>
      <guid isPermaLink="false">oai:arXiv.org:2409.13542v1</guid>
      <category>math.OC</category>
      <category>math.DS</category>
      <category>physics.soc-ph</category>
      <pubDate>Mon, 23 Sep 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <dc:creator>Jonathan Franceschi, Nadia Loy</dc:creator>
    </item>
    <item>
      <title>Qualitative Analysis and Adaptive Boosted DCA for Generalized Multi-Source Weber Problems</title>
      <link>https://arxiv.org/abs/2409.13635</link>
      <description>arXiv:2409.13635v1 Announce Type: new 
Abstract: This paper has two primary objectives. First, we investigate fundamental qualitative properties of the generalized multi-source Weber problem formulated using the Minkowski gauge function. This includes proving the existence of global optimal solutions, demonstrating the compactness of the solution set, and establishing optimality conditions for these solutions. Second, we apply Nesterov's smoothing and the adaptive Boosted Difference of Convex functions Algorithm (BDCA) to solve both the unconstrained and constrained versions of the generalized multi-source Weber problems. These algorithms build upon the work presented in [6,19]. We conduct a comprehensive evaluation of the adaptive BDCA, comparing its performance to the method proposed in [19], and provide insights into its efficiency.</description>
      <guid isPermaLink="false">oai:arXiv.org:2409.13635v1</guid>
      <category>math.OC</category>
      <pubDate>Mon, 23 Sep 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Vo Si Trong Long, Nguyen Mau Nam, Tuyen Tran, Nguyen Thi Thu Van</dc:creator>
    </item>
    <item>
      <title>Fast and Numerically Stable Implementation of Rate Constant Matrix Contraction Method</title>
      <link>https://arxiv.org/abs/2409.13128</link>
      <description>arXiv:2409.13128v1 Announce Type: cross 
Abstract: The rate constant matrix contraction (RCMC) method, proposed by Sumiya et al. (2015, 2017), enables fast and numerically stable simulations of chemical kinetics on large-scale reaction path networks. Later, Iwata et al. (2023) mathematically reformulated the RCMC method as a numerical algorithm to solve master equations whose coefficient matrices, known as rate constant matrices, possess the detailed balance property.
  This paper aims to accelerate the RCMC method. The bottleneck in the RCMC method lies in the greedy selection of steady states, which is actually equivalent to the greedy algorithm for the MAP inference in DPPs under cardinality constraints. Hemmi et al. (2022) introduced a fast implementation of the greedy DPP MAP inference, called LazyFastGreedy, by combining the greedy algorithm of Chen et al. (2018) with the lazy greedy algorithm by Minoux (1978), a practically efficient greedy algorithm that exploits the submodularity of the objective function. However, for instances arising from chemical kinetics, the straightforward application of LazyFastGreedy suffers from catastrophic cancellations due to the wide range of reaction time scales.
  To address this numerical instability, we propose a modification to LazyFastGreedy that avoids the subtraction of like-sign numbers by leveraging the properties of rate constant matrices and the connection of the DPP MAP inference to Cholesky decomposition. For faster implementation, we utilize a segment tree, a data structure that manages one-dimensional arrays of elements in a semigroup. We also analyze the increase in relative errors caused by like-sign subtractions and permit such subtractions when they do not lead to catastrophic cancellations, aiming to further accelerate the process. Using real instances, we confirm that the proposed algorithm is both numerically stable and significantly faster than the original RCMC method.</description>
      <guid isPermaLink="false">oai:arXiv.org:2409.13128v1</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <category>math.OC</category>
      <pubDate>Mon, 23 Sep 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Shinichi Hemmi, Satoru Iwata, Taihei Oki</dc:creator>
    </item>
    <item>
      <title>Convergence of Distributed Adaptive Optimization with Local Updates</title>
      <link>https://arxiv.org/abs/2409.13155</link>
      <description>arXiv:2409.13155v1 Announce Type: cross 
Abstract: We study distributed adaptive algorithms with local updates (intermittent communication). Despite the great empirical success of adaptive methods in distributed training of modern machine learning models, the theoretical benefits of local updates within adaptive methods, particularly in terms of reducing communication complexity, have not been fully understood yet. In this paper, we prove that \em Local SGD \em with momentum (\em Local \em SGDM) and \em Local \em Adam can outperform their minibatch counterparts in convex and weakly convex settings, respectively. Our analysis relies on a novel technique to prove contraction during local iterations, which is a crucial but challenging step to show the advantages of local updates, under generalized smoothness assumption and gradient clipping.</description>
      <guid isPermaLink="false">oai:arXiv.org:2409.13155v1</guid>
      <category>cs.LG</category>
      <category>math.OC</category>
      <pubDate>Mon, 23 Sep 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Ziheng Cheng, Margalit Glasgow</dc:creator>
    </item>
    <item>
      <title>Cooperative distributed model predictive control for embedded systems: Experiments with hovercraft formations</title>
      <link>https://arxiv.org/abs/2409.13334</link>
      <description>arXiv:2409.13334v1 Announce Type: cross 
Abstract: This paper presents experiments for embedded cooperative distributed model predictive control applied to a team of hovercraft floating on an air hockey table. The hovercraft collectively solve a centralized optimal control problem in each sampling step via a stabilizing decentralized real-time iteration scheme using the alternating direction method of multipliers. The efficient implementation does not require a central coordinator, executes onboard the hovercraft, and facilitates sampling intervals in the millisecond range. The formation control experiments showcase the flexibility of the approach on scenarios with point-to-point transitions, trajectory tracking, collision avoidance, and moving obstacles.</description>
      <guid isPermaLink="false">oai:arXiv.org:2409.13334v1</guid>
      <category>cs.RO</category>
      <category>cs.SY</category>
      <category>eess.SY</category>
      <category>math.OC</category>
      <pubDate>Mon, 23 Sep 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>G\"osta Stomberg, Roland Schwan, Andrea Grillo, Colin N. Jones, Timm Faulwasser</dc:creator>
    </item>
    <item>
      <title>Graph Similarity Regularized Softmax for Semi-Supervised Node Classification</title>
      <link>https://arxiv.org/abs/2409.13544</link>
      <description>arXiv:2409.13544v1 Announce Type: cross 
Abstract: Graph Neural Networks (GNNs) are powerful deep learning models designed for graph-structured data, demonstrating effectiveness across a wide range of applications.The softmax function is the most commonly used classifier for semi-supervised node classification. However, the softmax function lacks spatial information of the graph structure. In this paper, we propose a graph similarity regularized softmax for GNNs in semi-supervised node classification. By incorporating non-local total variation (TV) regularization into the softmax activation function, we can more effectively capture the spatial information inherent in graphs. The weights in the non-local gradient and divergence operators are determined based on the graph's adjacency matrix. We apply the proposed method into the architecture of GCN and GraphSAGE, testing them on citation and webpage linking datasets, respectively. Numerical experiments demonstrate its good performance in node classification and generalization capabilities. These results indicate that the graph similarity regularized softmax is effective on both assortative and disassortative graphs.</description>
      <guid isPermaLink="false">oai:arXiv.org:2409.13544v1</guid>
      <category>cs.LG</category>
      <category>math.OC</category>
      <pubDate>Mon, 23 Sep 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Yiming Yang, Jun Liu, Wei Wan</dc:creator>
    </item>
    <item>
      <title>Hamiltonian control to desynchronize Kuramoto oscillators with higher-order interactions</title>
      <link>https://arxiv.org/abs/2409.13578</link>
      <description>arXiv:2409.13578v1 Announce Type: cross 
Abstract: Synchronization is a ubiquitous phenomenon in nature. Although it is necessary for the functioning of many systems, too much synchronization can also be detrimental, e.g., (partially) synchronized brain patterns support high-level cognitive processes and bodily control, but hypersynchronization can lead to epileptic seizures and tremors, as in neurodegenerative conditions such as Parkinson's disease.
  Consequently, a critical research question is how to develop effective pinning control methods capable to reduce or modulate synchronization as needed.
  Although such methods exist to control pairwise-coupled oscillators, there are none for higher-order interactions, despite the increasing evidence of their relevant role in brain dynamics.
  In this work, we fill this gap by proposing a generalized control method designed to desynchronize Kuramoto oscillators connected through higher-order interactions. Our method embeds a higher-order Kuramoto model into a suitable Hamiltonian flow, and builds up on previous work in Hamiltonian control theory to analytically construct a feedback control mechanism.
  We numerically show that the proposed method effectively prevents synchronization. Although our findings indicate that pairwise contributions in the feedback loop are often sufficient, the higher-order generalization becomes crucial when pairwise coupling is weak. Finally, we explore the minimum number of controlled nodes required to fully desynchronize oscillators coupled via an all-to-all hypergraphs.</description>
      <guid isPermaLink="false">oai:arXiv.org:2409.13578v1</guid>
      <category>math.DS</category>
      <category>math.OC</category>
      <category>nlin.AO</category>
      <pubDate>Mon, 23 Sep 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Martin Moriam\'e, Maxime Lucas, Timoteo Carletti</dc:creator>
    </item>
    <item>
      <title>A Krasnoselskii-Mann Proximity Algorithm for Markowitz Portfolios with Adaptive Expected Return Level</title>
      <link>https://arxiv.org/abs/2409.13608</link>
      <description>arXiv:2409.13608v1 Announce Type: cross 
Abstract: Markowitz's criterion aims to balance expected return and risk when optimizing the portfolio. The expected return level is usually fixed according to the risk appetite of an investor, then the risk is minimized at this fixed return level. However, the investor may not know which return level is suitable for her/him and the current financial circumstance. It motivates us to find a novel approach that adaptively optimizes this return level and the portfolio at the same time. It not only relieves the trouble of deciding the return level during an investment but also gets more adaptive to the ever-changing financial market than a subjective return level. In order to solve the new model, we propose an exact, convergent, and efficient Krasnoselskii-Mann Proximity Algorithm based on the proximity operator and Krasnoselskii-Mann momentum technique. Extensive experiments show that the proposed method achieves significant improvements over state-of-the-art methods in portfolio optimization. This finding may contribute a new perspective on the relationship between return and risk in portfolio optimization.</description>
      <guid isPermaLink="false">oai:arXiv.org:2409.13608v1</guid>
      <category>q-fin.PM</category>
      <category>cs.NA</category>
      <category>math.NA</category>
      <category>math.OC</category>
      <pubDate>Mon, 23 Sep 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Yizun Lin, Yongxin He, Zhao-Rong Lai</dc:creator>
    </item>
    <item>
      <title>Recent Advances in Non-convex Smoothness Conditions and Applicability to Deep Linear Neural Networks</title>
      <link>https://arxiv.org/abs/2409.13672</link>
      <description>arXiv:2409.13672v1 Announce Type: cross 
Abstract: The presence of non-convexity in smooth optimization problems arising from deep learning have sparked new smoothness conditions in the literature and corresponding convergence analyses. We discuss these smoothness conditions, order them, provide conditions for determining whether they hold, and evaluate their applicability to training a deep linear neural network for binary classification.</description>
      <guid isPermaLink="false">oai:arXiv.org:2409.13672v1</guid>
      <category>cs.LG</category>
      <category>math.OC</category>
      <pubDate>Mon, 23 Sep 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Vivak Patel, Christian Varner</dc:creator>
    </item>
    <item>
      <title>Optimal and $H_\infty$ Control of Stochastic Reaction Networks</title>
      <link>https://arxiv.org/abs/2111.14754</link>
      <description>arXiv:2111.14754v4 Announce Type: replace 
Abstract: Stochastic reaction networks is a powerful class of models for the representation a wide variety of population models including biochemistry. The control of such networks has been recently considered due to their important implications for the control of biological systems. Their optimal control, however, has been relatively few studied until now. The continuous-time finite-horizon optimal control problem is formulated first and explicitly solved in the case of unimolecular reaction networks. The problems of the optimal sampled-data control, the continuous $H_\infty$ control, and the sampled-data $H_\infty$ control of such networks are addressed next. The results in the unimolecular case take the form of nonstandard Riccati differential equations or differential Lyapunov equations coupled with difference Riccati equations, which can all be solved numerically by backward-in-time integration.</description>
      <guid isPermaLink="false">oai:arXiv.org:2111.14754v4</guid>
      <category>math.OC</category>
      <category>cs.SY</category>
      <category>eess.SY</category>
      <category>q-bio.MN</category>
      <pubDate>Mon, 23 Sep 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Corentin Briat, Mustafa Khammash</dc:creator>
    </item>
    <item>
      <title>Strong Partitioning and a Machine Learning Approximation for Accelerating the Global Optimization of Nonconvex QCQPs</title>
      <link>https://arxiv.org/abs/2301.00306</link>
      <description>arXiv:2301.00306v3 Announce Type: replace 
Abstract: We learn optimal instance-specific heuristics for the global minimization of nonconvex quadratically-constrained quadratic programs (QCQPs). Specifically, we consider partitioning-based convex mixed-integer programming relaxations for nonconvex QCQPs and propose the novel problem of strong partitioning to optimally partition variable domains without sacrificing global optimality. Since solving this max-min strong partitioning problem exactly can be very challenging, we design a local optimization method that leverages generalized gradients of the value function of its inner-minimization problem. However, even solving the strong partitioning problem to local optimality can be time-consuming. To address this, we propose a simple and practical machine learning (ML) approximation for homogeneous families of QCQPs. We conduct a detailed computational study on randomly generated QCQP families, including instances of the pooling problem, using the open-source global solver Alpine. Numerical experiments demonstrate that our ML approximation of strong partitioning reduces Alpine's solution time by a factor of 2 to 4.5 on average, with a maximum reduction factor of 10 to 200 across the different QCQP families.</description>
      <guid isPermaLink="false">oai:arXiv.org:2301.00306v3</guid>
      <category>math.OC</category>
      <pubDate>Mon, 23 Sep 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Rohit Kannan, Harsha Nagarajan, Deepjyoti Deka</dc:creator>
    </item>
    <item>
      <title>Tomographic projection optimization for volumetric additive manufacturing with general band constraint Lp-norm minimization</title>
      <link>https://arxiv.org/abs/2312.01548</link>
      <description>arXiv:2312.01548v3 Announce Type: replace 
Abstract: Tomographic volumetric additive manufacturing is a rapidly growing fabrication technology that enables rapid production of 3D objects through a single build step. In this process, the design of projections directly impacts geometric resolution, material properties, and manufacturing yield of the final printed part. Herein, we identify the hidden equivalent operations of three major existing projection optimization schemes and reformulate them into a general loss function where the optimization behavior can be systematically studied, and unique capabilities of the individual schemes can coalesce. The loss function formulation proposed in this study unified the optimization for binary and greyscale targets and generalized problem relaxation strategies with local tolerancing and weighting. Additionally, this formulation offers control on error sparsity and consistent dose response mapping throughout initialization, optimization, and evaluation. A parameter-sweep analysis in this study guides users in tuning optimization parameters for application-specific goals.</description>
      <guid isPermaLink="false">oai:arXiv.org:2312.01548v3</guid>
      <category>math.OC</category>
      <pubDate>Mon, 23 Sep 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Chi Chung Li, Joseph Toombs, Hayden K. Taylor, Thomas J. Wallin</dc:creator>
    </item>
    <item>
      <title>An Extended ADMM for 3-Block Nonconvex Nonseparable Problems with Applications</title>
      <link>https://arxiv.org/abs/2402.02193</link>
      <description>arXiv:2402.02193v3 Announce Type: replace 
Abstract: We consider a 3-block Alternating Direction Method of Multipliers (ADMM) for solving nonconvex nonseparable problems with a linear constraint. Inspired by \cite[Sun, Toh and Yang, \textit{SIAM Journal on Optimization}, 25 (2015), pp.882-915]{wtwice}, the proposed ADMM follows the Block Coordinate Descent (BCD) cycle order $1\to 3\to 2\to 3$. We analyze its convergence based on the Kurdyka-{\L}ojasiewicz property. We also discuss two useful extensions of the proposed ADMM with $2\to 3\to 1\to 3$ Gauss-Seidel BCD cycle order, and with adding a proximal term for more general nonseparable problems, respectively. Moreover, we make numerical experiments on two nonconvex problems: robust principal component analysis and nonnegative matrix completion. Results show the efficiency and outperformance of the proposed ADMM.</description>
      <guid isPermaLink="false">oai:arXiv.org:2402.02193v3</guid>
      <category>math.OC</category>
      <category>cs.IT</category>
      <category>math.IT</category>
      <pubDate>Mon, 23 Sep 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Zekun Liu</dc:creator>
    </item>
    <item>
      <title>The Mixed Integer Trust Region Problem</title>
      <link>https://arxiv.org/abs/2402.08827</link>
      <description>arXiv:2402.08827v2 Announce Type: replace 
Abstract: In this paper we consider the problem of minimizing a general quadratic function over the mixed integer points in an ellipsoid. This problem is strongly NP-hard, NP-hard to approximate within a constant factor, and optimal solutions can be irrational. In our main result we show that an arbitrarily good solution can be found in polynomial time, if we fix the number of integer variables. This algorithm provides a natural extension to the mixed integer setting, of the polynomial solvability of the trust region problem proven by Ye, Karmarkar, Vavasis, and Zippel. Our result removes a key bottleneck in the design and analysis of model trust region methods for mixed integer nonlinear optimization problems. The techniques introduced to prove this result are of independent interest and can be used in other mixed integer programming problems involving quadratic functions. As an example we consider the problem of minimizing a general quadratic function over the mixed integer points in a polyhedron. For this problem, we show that a solution satisfying weak bounds with respect to optimality can be computed in polynomial time, provided that the number of integer variables is fixed. It is well-known that finding a solution satisfying stronger bounds cannot be done in polynomial time, unless P=NP.</description>
      <guid isPermaLink="false">oai:arXiv.org:2402.08827v2</guid>
      <category>math.OC</category>
      <category>cs.DM</category>
      <pubDate>Mon, 23 Sep 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Alberto Del Pia</dc:creator>
    </item>
    <item>
      <title>Constraint Preconditioning and Parameter Selection for a First-Order Primal-Dual Method applied to Model Predictive Control</title>
      <link>https://arxiv.org/abs/2403.15656</link>
      <description>arXiv:2403.15656v2 Announce Type: replace 
Abstract: Many techniques for real-time trajectory optimization and control require the solution of optimization problems at high frequencies. However, ill-conditioning in the optimization problem can significantly reduce the speed of first-order primal-dual optimization algorithms. We introduce a preconditioning technique and step-size heuristic for Proportional-Integral Projected Gradient (PIPG), a first-order primal-dual algorithm. The preconditioning technique, based on the QR factorization, aims to reduce the condition number of the KKT matrix associated with the optimization problem. Our step-size selection heuristic chooses step-sizes to minimize the upper bound on the convergence of the primal-dual gap for the optimization problem. These algorithms are tested on two model predictive control problem examples and show a solve-time reduction of at least 3.6x.</description>
      <guid isPermaLink="false">oai:arXiv.org:2403.15656v2</guid>
      <category>math.OC</category>
      <pubDate>Mon, 23 Sep 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Govind M. Chari, Yue Yu, Beh\c{c}et A\c{c}{\i}kme\c{s}e</dc:creator>
    </item>
    <item>
      <title>Optimal reinsurance in a dynamic contagion model: comparing self-exciting and externally-exciting risks</title>
      <link>https://arxiv.org/abs/2404.11482</link>
      <description>arXiv:2404.11482v2 Announce Type: replace 
Abstract: We investigate the optimal reinsurance problem in a risk model with jump clustering features. This modeling framework is inspired by the concept initially proposed in Dassios and Zhao (2011), combining Hawkes and Cox processes with shot noise intensity models. Specifically, these processes describe self-exciting and externally excited jumps in the claim arrival intensity, respectively. The insurer aims to maximize the expected exponential utility of terminal wealth for general reinsurance contracts and reinsurance premiums. We discuss two different methodologies: the classical stochastic control approach based on the Hamilton-Jacobi-Bellman (HJB) equation and a backward stochastic differential equation (BSDE) approach. In a Markovian setting, differently from the classical HJB-approach, the BSDE method enables us to solve the problem without imposing any requirements for regularity on the associated value function. We provide a Verification Theorem in terms of a suitable BSDE driven by a two-dimensional marked point process and we prove an existence result relaying on the theory developed in Papapantoleon et al. (2018) for stochastic Lipschitz generators. After discussing the optimal strategy for general reinsurance contracts and reinsurance premiums, we provide more explicit results in some relevant cases. Finally, we provide comparison results that highlight the heightened risk stemming from the self-exciting component in contrast to the externally-excited counterpart and discuss the the monotonicity property of the value function.</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.11482v2</guid>
      <category>math.OC</category>
      <category>q-fin.MF</category>
      <pubDate>Mon, 23 Sep 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Claudia Ceci, Alessandra Cretarola</dc:creator>
    </item>
    <item>
      <title>Task-splitting in home healthcare routing and scheduling</title>
      <link>https://arxiv.org/abs/2406.19288</link>
      <description>arXiv:2406.19288v2 Announce Type: replace 
Abstract: This paper introduces the concept of task-splitting into home healthcare (HHC) routing and scheduling. It focuses on the design of routes and timetables for caregivers providing services at patients' homes. Task-splitting is the division of a (lengthy) patient visit into separate visits that can be performed by different caregivers at different times. The resulting split parts may have reduced caregiver qualification requirements, relaxed visiting time windows, or a shorter/longer combined duration. However, additional temporal dependencies can arise between them. To incorporate task-splitting decisions into the planning process, we introduce two different mixed integer linear programming formulations, a Miller-Tucker-Zemlin and a time-indexed variant. These formulations aim to minimize operational costs while simultaneously deciding which visits to split and imposing a potentially wide range of temporal dependencies. We also propose pre-processing routines for the time-indexed formulation and two heuristic procedures. These methods are embedded into the branch-and-bound approach as primal and improvement heuristics. The results of our computational study demonstrate the additional computational difficulty introduced by task-splitting possibilities and the associated additional synchronization, and the usefulness of the proposed heuristic procedures. From a planning perspective, our results indicate that integrating task-splitting decisions into the planning process reduces staff requirements, decreases HHC operational costs, and allows caregivers to spend relatively more time on tasks aligned with their qualifications. Moreover, we observe that the potential of task-splitting is not specific to the chosen planning objective; it can also be beneficial when minimizing travel time instead.</description>
      <guid isPermaLink="false">oai:arXiv.org:2406.19288v2</guid>
      <category>math.OC</category>
      <pubDate>Mon, 23 Sep 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Loek van Montfort, Wout Dullaert, Markus Leitner</dc:creator>
    </item>
    <item>
      <title>Stochastic Monotone Inclusion with Closed Loop Distributions</title>
      <link>https://arxiv.org/abs/2407.13868</link>
      <description>arXiv:2407.13868v2 Announce Type: replace 
Abstract: In this paper, we study in a Hilbertian setting, first and second-order monotone inclusions related to stochastic optimization problems with decision dependent distributions. The studied dynamics are formulated as monotone inclusions governed by Lipschitz perturbations of maximally monotone operators where the concept of equilibrium plays a central role. We discuss the relationship between the $\mathbb{W}_1$-Wasserstein Lipschitz behavior of the distribution and the so-called coarse Ricci curvature. As an application, we consider the monotone inclusions associated with stochastic optimisation problems involving the sum of a smooth function with Lipschitz gradient, a proximable function and a composite term.</description>
      <guid isPermaLink="false">oai:arXiv.org:2407.13868v2</guid>
      <category>math.OC</category>
      <pubDate>Mon, 23 Sep 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Hamza Ennaji, Jalal Fadili, Hedy Attouch</dc:creator>
    </item>
    <item>
      <title>Data-driven distributionally robust MPC for systems with multiplicative noise: A semi-infinite semi-definite programming approach</title>
      <link>https://arxiv.org/abs/2408.15193</link>
      <description>arXiv:2408.15193v2 Announce Type: replace 
Abstract: This article introduces a novel distributionally robust model predictive control (DRMPC) algorithm for a specific class of controlled dynamical systems where the disturbance multiplies the state and control variables. These classes of systems arise in mathematical finance, where the paradigm of distributionally robust optimization (DRO) fits perfectly, and this serves as the primary motivation for this work. We recast the optimal control problem (OCP) as a semi-definite program with an infinite number of constraints, making the ensuing optimization problem a \emph{semi-infinite semi-definite program} (SI-SDP). To numerically solve the SI-SDP, we advance an approach for solving convex semi-infinite programs (SIPs) to SI-SDPs and, subsequently, solve the DRMPC problem. A numerical example is provided to show the effectiveness of the algorithm.</description>
      <guid isPermaLink="false">oai:arXiv.org:2408.15193v2</guid>
      <category>math.OC</category>
      <category>cs.SY</category>
      <category>eess.SY</category>
      <pubDate>Mon, 23 Sep 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Souvik Das, Siddhartha Ganguly, Ashwin Aravind, Debasish Chatterjee</dc:creator>
    </item>
    <item>
      <title>Two characterizations of quasiconvexity</title>
      <link>https://arxiv.org/abs/2408.15983</link>
      <description>arXiv:2408.15983v2 Announce Type: replace 
Abstract: We present two characterizations of quasiconvexity for radially semicontinuous mappings defined on a convex subset of a real linear space. As an application we obtain an extension of the Sion's minimax theorem, as well as a new characterization of quasiconvex risk measures.</description>
      <guid isPermaLink="false">oai:arXiv.org:2408.15983v2</guid>
      <category>math.OC</category>
      <category>math.CA</category>
      <pubDate>Mon, 23 Sep 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>W{\l}odzimierz Fechner</dc:creator>
    </item>
    <item>
      <title>Second-Order Constrained Dynamic Optimization</title>
      <link>https://arxiv.org/abs/2409.11649</link>
      <description>arXiv:2409.11649v2 Announce Type: replace 
Abstract: This paper provides an overview, analysis, and comparison of second-order dynamic optimization algorithms, i.e., constrained Differential Dynamic Programming (DDP) and Sequential Quadratic Programming (SQP). Although a variety of these algorithms has been proposed and used successfully, there exists a gap in understanding the key differences and advantages, which we aim to provide in this work. For constrained DDP, we choose methods that incorporate nonlinear programming techniques to handle state and control constraints, including Augmented Lagrangian (AL), Interior Point, Primal Dual Augmented Lagrangian (PDAL), and Alternating Direction Method of Multipliers. Both DDP and SQP are provided in single- and multiple-shooting formulations, where constraints that arise from dynamics are encoded implicitly and explicitly, respectively. As a byproduct of the review, we also propose a single-shooting PDAL DDP which is robust to the growth of penalty parameters and performs better than the normal AL variant. We perform extensive numerical experiments on various systems with increasing complexity to investigate the quality of the solutions, the levels of constraint violation, iterations for convergence, and the sensitivity of final solutions with respect to initialization. The results show that DDP often has the advantage of finding better local minima, while SQP tends to achieve better constraint satisfaction. For multiple-shooting formulation, both DDP and SQP can enjoy informed initial guesses, while the latter appears to be more advantageous in complex systems. It is also worth highlighting that DDP provides favorable computational complexity and feedback gains as a byproduct of optimization.</description>
      <guid isPermaLink="false">oai:arXiv.org:2409.11649v2</guid>
      <category>math.OC</category>
      <pubDate>Mon, 23 Sep 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Yuichiro Aoyama, Oswin So, Augustinos D. Saravanos, Evangelos A. Theodorou</dc:creator>
    </item>
    <item>
      <title>Stochastic Online Fisher Markets: Static Pricing Limits and Adaptive Enhancements</title>
      <link>https://arxiv.org/abs/2205.00825</link>
      <description>arXiv:2205.00825v5 Announce Type: replace-cross 
Abstract: Fisher markets are one of the most fundamental models for resource allocation. However, the problem of computing equilibrium prices in Fisher markets typically relies on complete knowledge of users' budgets and utility functions and requires transactions to happen in a static market where all users are present simultaneously. Motivated by these practical considerations, we study an online variant of Fisher markets, wherein users with privately known utility and budget parameters, drawn i.i.d. from a distribution, arrive sequentially. In this setting, we first study the limitations of static pricing algorithms, which set uniform prices for all users, along two performance metrics: (i) regret, i.e., the optimality gap in the objective of the Eisenberg-Gale program between an online algorithm and an oracle with complete information, and (ii) capacity violations, i.e., the over-consumption of goods relative to their capacities. Given the limitations of static pricing, we design adaptive posted-pricing algorithms, one with knowledge of the distribution of users' budget and utility parameters and another that adjusts prices solely based on past observations of user consumption, i.e., revealed preference feedback, with improved performance guarantees. Finally, we present numerical experiments to compare our revealed preference algorithm's performance to several benchmarks.</description>
      <guid isPermaLink="false">oai:arXiv.org:2205.00825v5</guid>
      <category>cs.GT</category>
      <category>cs.LG</category>
      <category>econ.TH</category>
      <category>math.OC</category>
      <pubDate>Mon, 23 Sep 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Devansh Jalota, Yinyu Ye</dc:creator>
    </item>
    <item>
      <title>Interpolatory $\mathcal{H}_2$-optimality Conditions for Structured Linear Time-invariant Systems</title>
      <link>https://arxiv.org/abs/2310.10618</link>
      <description>arXiv:2310.10618v4 Announce Type: replace-cross 
Abstract: Interpolatory necessary optimality conditions for $\mathcal{H}_2$-optimal reduced-order modeling of unstructured linear time-invariant (LTI) systems are well-known. Based on previous work on $\mathcal{L}_2$-optimal reduced-order modeling of stationary parametric problems, in this paper we develop and investigate optimality conditions for $\mathcal{H}_2$-optimal reduced-order modeling of structured LTI systems, in particular, for second-order, port-Hamiltonian, and time-delay systems. Under certain diagonalizability assumptions, we show that across all these different structured settings, bitangential Hermite interpolation is the common form for optimality, thus proving a unifying optimality framework for structured reduced-order modeling.</description>
      <guid isPermaLink="false">oai:arXiv.org:2310.10618v4</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <category>cs.SY</category>
      <category>eess.SY</category>
      <category>math.OC</category>
      <pubDate>Mon, 23 Sep 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Petar Mlinari\'c, Peter Benner, Serkan Gugercin</dc:creator>
    </item>
    <item>
      <title>Randomization Inference When N Equals One</title>
      <link>https://arxiv.org/abs/2310.16989</link>
      <description>arXiv:2310.16989v2 Announce Type: replace-cross 
Abstract: N-of-1 experiments, where a unit serves as its own control and treatment in different time windows, have been used in certain medical contexts for decades. However, due to effects that accumulate over long time windows and interventions that have complex evolution, a lack of robust inference tools has limited the widespread applicability of such N-of-1 designs. This work combines techniques from experiment design in causal inference and system identification from control theory to provide such an inference framework. We derive a model of the dynamic interference effect that arises in linear time-invariant dynamical systems. We show that a family of causal estimands analogous to those studied in potential outcomes are estimable via a standard estimator derived from the method of moments. We derive formulae for higher moments of this estimator and describe conditions under which N-of-1 designs may provide faster ways to estimate the effects of interventions in dynamical systems. We also provide conditions under which our estimator is asymptotically normal and derive valid confidence intervals for this setting.</description>
      <guid isPermaLink="false">oai:arXiv.org:2310.16989v2</guid>
      <category>stat.ME</category>
      <category>math.OC</category>
      <category>math.ST</category>
      <category>stat.TH</category>
      <pubDate>Mon, 23 Sep 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Tengyuan Liang, Benjamin Recht</dc:creator>
    </item>
    <item>
      <title>Towards Efficient Risk-Sensitive Policy Gradient: An Iteration Complexity Analysis</title>
      <link>https://arxiv.org/abs/2403.08955</link>
      <description>arXiv:2403.08955v2 Announce Type: replace-cross 
Abstract: Reinforcement Learning (RL) has shown exceptional performance across various applications, enabling autonomous agents to learn optimal policies through interaction with their environments. However, traditional RL frameworks often face challenges in terms of iteration complexity and robustness. Risk-sensitive RL, which balances expected return and risk, has been explored for its potential to yield probabilistically robust policies, yet its iteration complexity analysis remains underexplored. In this study, we conduct a thorough iteration complexity analysis for the risk-sensitive policy gradient method, focusing on the REINFORCE algorithm and employing the exponential utility function. We obtain an iteration complexity of $\cO(\epsilon^{-2})$ to reach an $\epsilon$-approximate first-order stationary point (FOSP). We investigate whether risk-sensitive algorithms can potentially achieve better iteration complexity compared to their risk-neutral counterparts. Our theoretical analysis demonstrates that risk-sensitive REINFORCE can potentially have a reduced number of iterations required for convergence. This leads to improved iteration complexity, as employing the exponential utility does not entail additional computation per iteration. We characterize the conditions under which risk-sensitive algorithms can potentially achieve better iteration complexity. Our simulation results also validate that risk-averse cases can converge and stabilize more quickly after $41\%$ of the episodes compared to their risk-neutral counterparts.</description>
      <guid isPermaLink="false">oai:arXiv.org:2403.08955v2</guid>
      <category>cs.LG</category>
      <category>cs.AI</category>
      <category>math.OC</category>
      <pubDate>Mon, 23 Sep 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <dc:creator>Rui Liu, Erfaun Noorani, Pratap Tokekar</dc:creator>
    </item>
    <item>
      <title>Performance of NPG in Countable State-Space Average-Cost RL</title>
      <link>https://arxiv.org/abs/2405.20467</link>
      <description>arXiv:2405.20467v2 Announce Type: replace-cross 
Abstract: We consider policy optimization methods in reinforcement learning settings where the state space is arbitrarily large, or even countably infinite. The motivation arises from control problems in communication networks, matching markets, and other queueing systems. Specifically, we consider the popular Natural Policy Gradient (NPG) algorithm, which has been studied in the past only under the assumption that the cost is bounded and the state space is finite, neither of which holds for the aforementioned control problems. Assuming a Lyapunov drift condition, which is naturally satisfied in some cases and can be satisfied in other cases at a small cost in performance, we design a state-dependent step-size rule which dramatically improves the performance of NPG for our intended applications. In addition to experimentally verifying the performance improvement, we also theoretically show that the iteration complexity of NPG can be made independent of the size of the state space. The key analytical tool we use is the connection between NPG step-sizes and the solution to Poisson's equation. In particular, we provide policy-independent bounds on the solution to Poisson's equation, which are then used to guide the choice of NPG step-sizes.</description>
      <guid isPermaLink="false">oai:arXiv.org:2405.20467v2</guid>
      <category>cs.LG</category>
      <category>math.OC</category>
      <pubDate>Mon, 23 Sep 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Yashaswini Murthy, Isaac Grosof, Siva Theja Maguluri, R. Srikant</dc:creator>
    </item>
  </channel>
</rss>
