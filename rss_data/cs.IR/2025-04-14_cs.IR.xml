<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>cs.IR updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/cs.IR</link>
    <description>cs.IR updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/cs.IR" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Tue, 15 Apr 2025 03:10:10 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Mon, 14 Apr 2025 00:00:00 -0400</pubDate>
    <skipDays>
      <day>Saturday</day>
      <day>Sunday</day>
    </skipDays>
    <item>
      <title>How Good Are Large Language Models for Course Recommendation in MOOCs?</title>
      <link>https://arxiv.org/abs/2504.08208</link>
      <description>arXiv:2504.08208v1 Announce Type: new 
Abstract: Large Language Models (LLMs) have made significant strides in natural language processing and are increasingly being integrated into recommendation systems. However, their potential in educational recommendation systems has yet to be fully explored. This paper investigates the use of LLMs as a general-purpose recommendation model, leveraging their vast knowledge derived from large-scale corpora for course recommendation tasks. We explore a variety of approaches, ranging from prompt-based methods to more advanced fine-tuning techniques, and compare their performance against traditional recommendation models. Extensive experiments were conducted on a real-world MOOC dataset, evaluating using LLMs as course recommendation systems across key dimensions such as accuracy, diversity, and novelty. Our results demonstrate that LLMs can achieve good performance comparable to traditional models, highlighting their potential to enhance educational recommendation systems. These findings pave the way for further exploration and development of LLM-based approaches in the context of educational recommendations.</description>
      <guid isPermaLink="false">oai:arXiv.org:2504.08208v1</guid>
      <category>cs.IR</category>
      <category>cs.AI</category>
      <pubDate>Mon, 14 Apr 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Boxuan Ma, Md Akib Zabed Khan, Tianyuan Yang, Agoritsa Polyzou, Shin'ichi Konomi</dc:creator>
    </item>
    <item>
      <title>RAG-VR: Leveraging Retrieval-Augmented Generation for 3D Question Answering in VR Environments</title>
      <link>https://arxiv.org/abs/2504.08256</link>
      <description>arXiv:2504.08256v2 Announce Type: new 
Abstract: Recent advances in large language models (LLMs) provide new opportunities for context understanding in virtual reality (VR). However, VR contexts are often highly localized and personalized, limiting the effectiveness of general-purpose LLMs. To address this challenge, we present RAG-VR, the first 3D question-answering system for VR that incorporates retrieval-augmented generation (RAG), which augments an LLM with external knowledge retrieved from a localized knowledge database to improve the answer quality. RAG-VR includes a pipeline for extracting comprehensive knowledge about virtual environments and user conditions for accurate answer generation. To ensure efficient retrieval, RAG-VR offloads the retrieval process to a nearby edge server and uses only essential information during retrieval. Moreover, we train the retriever to effectively distinguish among relevant, irrelevant, and hard-to-differentiate information in relation to questions. RAG-VR improves answer accuracy by 17.9%-41.8% and reduces end-to-end latency by 34.5%-47.3% compared with two baseline systems.</description>
      <guid isPermaLink="false">oai:arXiv.org:2504.08256v2</guid>
      <category>cs.IR</category>
      <category>cs.AI</category>
      <category>cs.HC</category>
      <pubDate>Mon, 14 Apr 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Shiyi Ding, Ying Chen</dc:creator>
    </item>
    <item>
      <title>OnSET: Ontology and Semantic Exploration Toolkit</title>
      <link>https://arxiv.org/abs/2504.08373</link>
      <description>arXiv:2504.08373v1 Announce Type: new 
Abstract: Retrieval over knowledge graphs is usually performed using dedicated, complex query languages like SPARQL. We propose a novel system, Ontology and Semantic Exploration Toolkit (OnSET) that allows non-expert users to easily build queries with visual user guidance provided by topic modelling and semantic search throughout the application. OnSET allows users without any prior information about the ontology or networked knowledge to start exploring topics of interest over knowledge graphs, including the retrieval and detailed exploration of prototypical sub-graphs and their instances. Existing systems either focus on direct graph explorations or do not foster further exploration of the result set. We, however, provide a node-based editor that can extend on these missing properties of existing systems to support the search over big ontologies with sub-graph instances. Furthermore, OnSET combines efficient and open platforms to deploy the system on commodity hardware.</description>
      <guid isPermaLink="false">oai:arXiv.org:2504.08373v1</guid>
      <category>cs.IR</category>
      <pubDate>Mon, 14 Apr 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-sa/4.0/</dc:rights>
      <dc:creator>Benedikt Kantz, Kevin Innerebner, Peter Waldert, Stefan Lengauer, Elisabeth Lex, Tobias Schreck</dc:creator>
    </item>
    <item>
      <title>A Reproducibility Study of Graph-Based Legal Case Retrieval</title>
      <link>https://arxiv.org/abs/2504.08400</link>
      <description>arXiv:2504.08400v1 Announce Type: new 
Abstract: Legal retrieval is a widely studied area in Information Retrieval (IR) and a key task in this domain is retrieving relevant cases based on a given query case, often done by applying language models as encoders to model case similarity. Recently, Tang et al. proposed CaseLink, a novel graph-based method for legal case retrieval, which models both cases and legal charges as nodes in a network, with edges representing relationships such as references and shared semantics. This approach offers a new perspective on the task by capturing higher-order relationships of cases going beyond the stand-alone level of documents. However, while this shift in approaching legal case retrieval is a promising direction in an understudied area of graph-based legal IR, challenges in reproducing novel results have recently been highlighted, with multiple studies reporting difficulties in reproducing previous findings. Thus, in this work we reproduce CaseLink, a graph-based legal case retrieval method, to support future research in this area of IR. In particular, we aim to assess its reliability and generalizability by (i) first reproducing the original study setup and (ii) applying the approach to an additional dataset. We then build upon the original implementations by (iii) evaluating the approach's performance when using a more sophisticated graph data representation and (iv) using an open large language model (LLM) in the pipeline to address limitations that are known to result from using closed models accessed via an API. Our findings aim to improve the understanding of graph-based approaches in legal IR and contribute to improving reproducibility in the field. To achieve this, we share all our implementations and experimental artifacts with the community.</description>
      <guid isPermaLink="false">oai:arXiv.org:2504.08400v1</guid>
      <category>cs.IR</category>
      <pubDate>Mon, 14 Apr 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Gregor Donabauer, Udo Kruschwitz</dc:creator>
    </item>
    <item>
      <title>A Comparative Study of Recommender Systems under Big Data Constraints</title>
      <link>https://arxiv.org/abs/2504.08457</link>
      <description>arXiv:2504.08457v1 Announce Type: new 
Abstract: Recommender Systems (RS) have become essential tools in a wide range of digital services, from e-commerce and streaming platforms to news and social media. As the volume of user-item interactions grows exponentially, especially in Big Data environments, selecting the most appropriate RS model becomes a critical task. This paper presents a comparative study of several state-of-the-art recommender algorithms, including EASE-R, SLIM, SLIM with ElasticNet regularization, Matrix Factorization (FunkSVD and ALS), P3Alpha, and RP3Beta. We evaluate these models according to key criteria such as scalability, computational complexity, predictive accuracy, and interpretability. The analysis considers both their theoretical underpinnings and practical applicability in large-scale scenarios. Our results highlight that while models like SLIM and SLIM-ElasticNet offer high accuracy and interpretability, they suffer from high computational costs, making them less suitable for real-time applications. In contrast, algorithms such as EASE-R and RP3Beta achieve a favorable balance between performance and scalability, proving more effective in large-scale environments. This study aims to provide guidelines for selecting the most appropriate recommender approach based on specific Big Data constraints and system requirements.</description>
      <guid isPermaLink="false">oai:arXiv.org:2504.08457v1</guid>
      <category>cs.IR</category>
      <pubDate>Mon, 14 Apr 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Arimondo Scrivano</dc:creator>
    </item>
    <item>
      <title>Topic mining based on fine-tuning Sentence-BERT and LDA</title>
      <link>https://arxiv.org/abs/2504.07984</link>
      <description>arXiv:2504.07984v1 Announce Type: cross 
Abstract: Research background: With the continuous development of society, consumers pay more attention to the key information of product fine-grained attributes when shopping. Research purposes: This study will fine tune the Sentence-BERT word embedding model and LDA model, mine the subject characteristics in online reviews of goods, and show consumers the details of various aspects of goods. Research methods: First, the Sentence-BERT model was fine tuned in the field of e-commerce online reviews, and the online review text was converted into a word vector set with richer semantic information; Secondly, the vectorized word set is input into the LDA model for topic feature extraction; Finally, focus on the key functions of the product through keyword analysis under the theme. Results: This study compared this model with other word embedding models and LDA models, and compared it with common topic extraction methods. The theme consistency of this model is 0.5 higher than that of other models, which improves the accuracy of theme extraction</description>
      <guid isPermaLink="false">oai:arXiv.org:2504.07984v1</guid>
      <category>cs.CL</category>
      <category>cs.IR</category>
      <pubDate>Mon, 14 Apr 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Jianheng Li, Lirong Chen</dc:creator>
    </item>
    <item>
      <title>eST$^2$ Miner -- Process Discovery Based on Firing Partial Orders</title>
      <link>https://arxiv.org/abs/2504.08372</link>
      <description>arXiv:2504.08372v1 Announce Type: cross 
Abstract: Process discovery generates process models from event logs. Traditionally, an event log is defined as a multiset of traces, where each trace is a sequence of events. The total order of the events in a sequential trace is typically based on their temporal occurrence. However, real-life processes are partially ordered by nature. Different activities can occur in different parts of the process and, thus, independently of each other. Therefore, the temporal total order of events does not necessarily reflect their causal order, as also causally unrelated events may be ordered in time. Only partial orders allow to express concurrency, duration, overlap, and uncertainty of events. Consequently, there is a growing need for process mining algorithms that can directly handle partially ordered input. In this paper, we combine two well-established and efficient algorithms, the eST Miner from the process mining community and the Firing LPO algorithm from the Petri net community, to introduce the eST$^2$ Miner. The eST$^2$ Miner is a process discovery algorithm that can directly handle partially ordered input, gives strong formal guarantees, offers good runtime and excellent space complexity, and can, thus, be used in real-life applications.</description>
      <guid isPermaLink="false">oai:arXiv.org:2504.08372v1</guid>
      <category>cs.DB</category>
      <category>cs.IR</category>
      <pubDate>Mon, 14 Apr 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Sabine Folz-Weinstein, Christian Rennert, Lisa Luise Mannel, Robin Bergenthum, Wil van der Aalst</dc:creator>
    </item>
    <item>
      <title>Scholar Inbox: Personalized Paper Recommendations for Scientists</title>
      <link>https://arxiv.org/abs/2504.08385</link>
      <description>arXiv:2504.08385v1 Announce Type: cross 
Abstract: Scholar Inbox is a new open-access platform designed to address the challenges researchers face in staying current with the rapidly expanding volume of scientific literature. We provide personalized recommendations, continuous updates from open-access archives (arXiv, bioRxiv, etc.), visual paper summaries, semantic search, and a range of tools to streamline research workflows and promote open research access. The platform's personalized recommendation system is trained on user ratings, ensuring that recommendations are tailored to individual researchers' interests. To further enhance the user experience, Scholar Inbox also offers a map of science that provides an overview of research across domains, enabling users to easily explore specific topics. We use this map to address the cold start problem common in recommender systems, as well as an active learning strategy that iteratively prompts users to rate a selection of papers, allowing the system to learn user preferences quickly. We evaluate the quality of our recommendation system on a novel dataset of 800k user ratings, which we make publicly available, as well as via an extensive user study. https://www.scholar-inbox.com/</description>
      <guid isPermaLink="false">oai:arXiv.org:2504.08385v1</guid>
      <category>cs.CL</category>
      <category>cs.AI</category>
      <category>cs.IR</category>
      <pubDate>Mon, 14 Apr 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Markus Flicke, Glenn Angrabeit, Madhav Iyengar, Vitalii Protsenko, Illia Shakun, Jovan Cicvaric, Bora Kargi, Haoyu He, Lukas Schuler, Lewin Scholz, Kavyanjali Agnihotri, Yong Cao, Andreas Geiger</dc:creator>
    </item>
    <item>
      <title>PCA-RAG: Principal Component Analysis for Efficient Retrieval-Augmented Generation</title>
      <link>https://arxiv.org/abs/2504.08386</link>
      <description>arXiv:2504.08386v1 Announce Type: cross 
Abstract: Retrieval-Augmented Generation (RAG) has emerged as a powerful paradigm for grounding large language models in external knowledge sources, improving the precision of agents responses. However, high-dimensional language model embeddings, often in the range of hundreds to thousands of dimensions, can present scalability challenges in terms of storage and latency, especially when processing massive financial text corpora. This paper investigates the use of Principal Component Analysis (PCA) to reduce embedding dimensionality, thereby mitigating computational bottlenecks without incurring large accuracy losses. We experiment with a real-world dataset and compare different similarity and distance metrics under both full-dimensional and PCA-compressed embeddings. Our results show that reducing vectors from 3,072 to 110 dimensions provides a sizeable (up to $60\times$) speedup in retrieval operations and a $\sim 28.6\times$ reduction in index size, with only moderate declines in correlation metrics relative to human-annotated similarity scores. These findings demonstrate that PCA-based compression offers a viable balance between retrieval fidelity and resource efficiency, essential for real-time systems such as Zanista AI's \textit{Newswitch} platform. Ultimately, our study underscores the practicality of leveraging classical dimensionality reduction techniques to scale RAG architectures for knowledge-intensive applications in finance and trading, where speed, memory efficiency, and accuracy must jointly be optimized.</description>
      <guid isPermaLink="false">oai:arXiv.org:2504.08386v1</guid>
      <category>cs.LG</category>
      <category>cs.AI</category>
      <category>cs.IR</category>
      <category>stat.ML</category>
      <pubDate>Mon, 14 Apr 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Arman Khaledian, Amirreza Ghadiridehkordi, Nariman Khaledian</dc:creator>
    </item>
    <item>
      <title>A Parametrizable Algorithm for Distributed Approximate Similarity Search with Arbitrary Distances</title>
      <link>https://arxiv.org/abs/2405.13795</link>
      <description>arXiv:2405.13795v3 Announce Type: replace 
Abstract: Recent studies have explored alternative distance measures for similarity search in spaces with diverse topologies, emphasizing the importance of selecting an appropriate distance function to improve the performance of k-Nearest Neighbour search algorithms. However, a critical gap remains in accommodating such diverse similarity measures, as most existing methods for exact or approximate similarity search are explicitly designed for metric spaces.
  To address this need, we propose PDASC (Parametrizable Distributed Approximate Similarity Search with Clustering), a novel Approximate Nearest Neighbour search algorithm. PDASC combines an innovative multilevel indexing structure particularly adept at managing outliers, highly imbalanced datasets, and sparse data distributions, with the flexibility to support arbitrary distance functions achieved through the integration of clustering algorithms that inherently accommodate them.
  Experimental results show that PDASC constitutes a reliable ANN search method, suitable for operating in distributed data environments and for handling datasets defined in different topologies, where the selection of the most appropriate distance function is often non-trivial.</description>
      <guid isPermaLink="false">oai:arXiv.org:2405.13795v3</guid>
      <category>cs.IR</category>
      <category>cs.DB</category>
      <pubDate>Mon, 14 Apr 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Elena Garcia-Morato, Maria Jesus Algar, Cesar Alfaro, Felipe Ortega, Javier Gomez, Javier M. Moguerza</dc:creator>
    </item>
    <item>
      <title>Navigating the Future of Federated Recommendation Systems with Foundation Models</title>
      <link>https://arxiv.org/abs/2406.00004</link>
      <description>arXiv:2406.00004v4 Announce Type: replace 
Abstract: Federated Recommendation Systems (FRSs) offer a privacy-preserving alternative to traditional centralized approaches by decentralizing data storage. However, they face persistent challenges such as data sparsity and heterogeneity, largely due to isolated client environments. Recent advances in Foundation Models (FMs), particularly large language models like ChatGPT, present an opportunity to surmount these issues through powerful, cross-task knowledge transfer. In this position paper, we systematically examine the convergence of FRSs and FMs, illustrating how FM-enhanced frameworks can substantially improve client-side personalization, communication efficiency, and server-side aggregation. We also delve into pivotal challenges introduced by this integration, including privacy-security trade-offs, non-IID data, and resource constraints in federated setups, and propose prospective research directions in areas such as multimodal recommendation, real-time FM adaptation, and explainable federated reasoning. By unifying FRSs with FMs, our position paper provides a forward-looking roadmap for advancing privacy-preserving, high-performance recommendation systems that fully leverage large-scale pre-trained knowledge to enhance local performance.</description>
      <guid isPermaLink="false">oai:arXiv.org:2406.00004v4</guid>
      <category>cs.IR</category>
      <category>cs.AI</category>
      <category>cs.LG</category>
      <pubDate>Mon, 14 Apr 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Zhiwei Li, Guodong Long, Chunxu Zhang, Honglei Zhang, Jing Jiang, Chengqi Zhang</dc:creator>
    </item>
    <item>
      <title>Mitigating Propensity Bias of Large Language Models for Recommender Systems</title>
      <link>https://arxiv.org/abs/2409.20052</link>
      <description>arXiv:2409.20052v2 Announce Type: replace 
Abstract: The rapid development of Large Language Models (LLMs) creates new opportunities for recommender systems, especially by exploiting the side information (e.g., descriptions and analyses of items) generated by these models. However, aligning this side information with collaborative information from historical interactions poses significant challenges. The inherent biases within LLMs can skew recommendations, resulting in distorted and potentially unfair user experiences. On the other hand, propensity bias causes side information to be aligned in such a way that it often tends to represent all inputs in a low-dimensional subspace, leading to a phenomenon known as dimensional collapse, which severely restricts the recommender system's ability to capture user preferences and behaviours. To address these issues, we introduce a novel framework named Counterfactual LLM Recommendation (CLLMR). Specifically, we propose a spectrum-based side information encoder that implicitly embeds structural information from historical interactions into the side information representation, thereby circumventing the risk of dimension collapse. Furthermore, our CLLMR approach explores the causal relationships inherent in LLM-based recommender systems. By leveraging counterfactual inference, we counteract the biases introduced by LLMs. Extensive experiments demonstrate that our CLLMR approach consistently enhances the performance of various recommender models.</description>
      <guid isPermaLink="false">oai:arXiv.org:2409.20052v2</guid>
      <category>cs.IR</category>
      <category>cs.AI</category>
      <pubDate>Mon, 14 Apr 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Guixian Zhang, Guan Yuan, Debo Cheng, Lin Liu, Jiuyong Li, Shichao Zhang</dc:creator>
    </item>
    <item>
      <title>Efficient and Responsible Adaptation of Large Language Models for Robust and Equitable Top-k Recommendations</title>
      <link>https://arxiv.org/abs/2501.04762</link>
      <description>arXiv:2501.04762v2 Announce Type: replace 
Abstract: Conventional recommendation systems (RSs) are typically optimized to enhance performance metrics uniformly across all training samples, inadvertently overlooking the needs of diverse user populations. The performance disparity among various populations can harm the model's robustness to sub-populations due to the varying user properties. While large language models (LLMs) show promise in enhancing RS performance, their practical applicability is hindered by high costs, inference latency, and degraded performance on long user queries. To address these challenges, we propose a hybrid task allocation framework designed to promote social good by equitably serving all user groups. By adopting a two-phase approach, we promote a strategic assignment of tasks for efficient and responsible adaptation of LLMs. Our strategy works by first identifying the weak and inactive users that receive a suboptimal ranking performance by RSs. Next, we use an in-context learning approach for such users, wherein each user interaction history is contextualized as a distinct ranking task. We evaluate our hybrid framework by incorporating eight different recommendation algorithms and three different LLMs -- both open and close-sourced. Our results on three real-world datasets show a significant reduction in weak users and improved robustness to subpopulations without disproportionately escalating costs.</description>
      <guid isPermaLink="false">oai:arXiv.org:2501.04762v2</guid>
      <category>cs.IR</category>
      <category>cs.LG</category>
      <pubDate>Mon, 14 Apr 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Kirandeep Kaur, Manya Chadha, Vinayak Gupta, Chirag Shah</dc:creator>
    </item>
    <item>
      <title>Context-Aware Lifelong Sequential Modeling for Online Click-Through Rate Prediction</title>
      <link>https://arxiv.org/abs/2502.12634</link>
      <description>arXiv:2502.12634v2 Announce Type: replace 
Abstract: Lifelong sequential modeling (LSM) is becoming increasingly critical in social media recommendation systems for predicting the click-through rate (CTR) of items presented to users. Central to this process is the attention mechanism, which extracts interest representations with respect to candidate items from the user sequence. Typically, attention mechanisms operate in a point-wise manner, focusing solely on the relevance of individual items in the sequence to the candidate item. In contrast, context-aware LSM aims to also consider adjacent items in the user behavior sequence to better assess the importance of each item. In this paper, we propose the Context-Aware Interest Network (CAIN), which utilizes the Temporal Convolutional Network (TCN) to create context-aware representations for each item throughout the lifelong sequence. These enhanced representations are then used in the attention mechanism instead of the original item representations to derive context-aware interest representations. Building upon this TCN framework, we propose the Multi-Scope Interest Aggregator (MSIA) module, which incorporates multiple TCN layers and their corresponding attention modules to capture interest representations across varying context scopes. Furthermore, we introduce the Personalized Extractor Generation (PEG) module, which generates convolution filters based on users' basic profile features. These personalized filters are then used in the TCN layers instead of the original global filters to generate more user-specific representations. We conducted extensive experiments on both a public dataset and an industrial dataset from the WeChat Channels platform. The results demonstrate that CAIN outperforms existing methods in terms of prediction accuracy and online performance metrics.</description>
      <guid isPermaLink="false">oai:arXiv.org:2502.12634v2</guid>
      <category>cs.IR</category>
      <pubDate>Mon, 14 Apr 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Ting Guo, Zhaoyang Yang, Qinsong Zeng, Ming Chen</dc:creator>
    </item>
    <item>
      <title>A Survey of Large Language Model Empowered Agents for Recommendation and Search: Towards Next-Generation Information Retrieval</title>
      <link>https://arxiv.org/abs/2503.05659</link>
      <description>arXiv:2503.05659v2 Announce Type: replace 
Abstract: Information technology has profoundly altered the way humans interact with information. The vast amount of content created, shared, and disseminated online has made it increasingly difficult to access relevant information. Over the past two decades, recommender systems and search (collectively referred to as information retrieval systems) have evolved significantly to address these challenges. Recent advances in large language models (LLMs) have demonstrated capabilities that surpass human performance in various language-related tasks and exhibit general understanding, reasoning, and decision-making abilities. This paper explores the transformative potential of LLM agents in enhancing recommender and search systems. We discuss the motivations and roles of LLM agents, and establish a classification framework to elaborate on the existing research. We highlight the immense potential of LLM agents in addressing current challenges in recommendation and search, providing insights into future research directions. This paper is the first to systematically review and classify the research on LLM agents in these domains, offering a novel perspective on leveraging this advanced AI technology for information retrieval. To help understand the existing works, we list the existing papers on LLM agent based recommendation and search at this link: https://github.com/tsinghua-fib-lab/LLM-Agent-for-Recommendation-and-Search.</description>
      <guid isPermaLink="false">oai:arXiv.org:2503.05659v2</guid>
      <category>cs.IR</category>
      <pubDate>Mon, 14 Apr 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Yu Zhang, Shutong Qiao, Jiaqi Zhang, Tzu-Heng Lin, Chen Gao, Yong Li</dc:creator>
    </item>
    <item>
      <title>Attribution in Scientific Literature: New Benchmark and Methods</title>
      <link>https://arxiv.org/abs/2405.02228</link>
      <description>arXiv:2405.02228v3 Announce Type: replace-cross 
Abstract: Large language models (LLMs) present a promising yet challenging frontier for automated source citation in scientific communication. Previous approaches to citation generation have been limited by citation ambiguity and LLM overgeneralization. We introduce REASONS, a novel dataset with sentence-level annotations across 12 scientific domains from arXiv. Our evaluation framework covers two key citation scenarios: indirect queries (matching sentences to paper titles) and direct queries (author attribution), both enhanced with contextual metadata. We conduct extensive experiments with models such as GPT-O1, GPT-4O, GPT-3.5, DeepSeek, and other smaller models like Perplexity AI (7B). While top-tier LLMs achieve high performance in sentence attribution, they struggle with high hallucination rates, a key metric for scientific reliability. Our metadata-augmented approach reduces hallucination rates across all tasks, offering a promising direction for improvement. Retrieval-augmented generation (RAG) with Mistral improves performance in indirect queries, reducing hallucination rates by 42% and maintaining competitive precision with larger models. However, adversarial testing highlights challenges in linking paper titles to abstracts, revealing fundamental limitations in current LLMs. REASONS provides a challenging benchmark for developing reliable and trustworthy LLMs in scientific applications</description>
      <guid isPermaLink="false">oai:arXiv.org:2405.02228v3</guid>
      <category>cs.CL</category>
      <category>cs.AI</category>
      <category>cs.IR</category>
      <pubDate>Mon, 14 Apr 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Yash Saxena, Deepa Tilwani, Ali Mohammadi, Edward Raff, Amit Sheth, Srinivasan Parthasarathy, Manas Gaur</dc:creator>
    </item>
    <item>
      <title>CoSQA+: Pioneering the Multi-Choice Code Search Benchmark with Test-Driven Agents</title>
      <link>https://arxiv.org/abs/2406.11589</link>
      <description>arXiv:2406.11589v5 Announce Type: replace-cross 
Abstract: Semantic code search, retrieving code that matches a given natural language query, is an important task to improve productivity in software engineering. Existing code search datasets face limitations: they rely on human annotators who assess code primarily through semantic understanding rather than functional verification, leading to potential inaccuracies and scalability issues. Additionally, current evaluation metrics often overlook the multi-choice nature of code search. This paper introduces CoSQA+, pairing high-quality queries from CoSQA with multiple suitable codes. We develop an automated pipeline featuring multiple model-based candidate selections and the novel test-driven agent annotation system. Among a single Large Language Model (LLM) annotator and Python expert annotators (without test-based verification), agents leverage test-based verification and achieve the highest accuracy of 92.0%. Through extensive experiments, CoSQA+ has demonstrated superior quality over CoSQA. Models trained on CoSQA+ exhibit improved performance. We provide the code and data at https://github.com/DeepSoftwareAnalytics/CoSQA_Plus.</description>
      <guid isPermaLink="false">oai:arXiv.org:2406.11589v5</guid>
      <category>cs.SE</category>
      <category>cs.AI</category>
      <category>cs.IR</category>
      <pubDate>Mon, 14 Apr 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/publicdomain/zero/1.0/</dc:rights>
      <dc:creator>Jing Gong, Yanghui Wu, Linxi Liang, Yanlin Wang, Jiachi Chen, Mingwei Liu, Zibin Zheng</dc:creator>
    </item>
  </channel>
</rss>
