<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>cs.DS updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/cs.DS</link>
    <description>cs.DS updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/cs.DS" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Fri, 05 Sep 2025 01:26:27 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Thu, 04 Sep 2025 00:00:00 -0400</pubDate>
    <skipDays>
      <day>Sunday</day>
      <day>Saturday</day>
    </skipDays>
    <item>
      <title>Sorting with constraints</title>
      <link>https://arxiv.org/abs/2509.02616</link>
      <description>arXiv:2509.02616v1 Announce Type: new 
Abstract: In this work, we study the generalized sorting problem, where we are given a set of $n$ elements to be sorted, but only a subset of all possible pairwise element comparisons is allowed. We look at the problem from the perspective of the graph formed by the ``forbidden'' pairs, and we parameterize algorithms using the clique number and the chromatic number of this graph. We also extend these results to the class of problems where the input graph is not necessarily sortable, and one is only interested in discovering the partial order. We use our results to develop a simple algorithm that always determines the underlying partial order in $O(n^{3/2} \log n)$ probes, when the input graph is an Erd\H{o}s--R\'enyi graph.</description>
      <guid isPermaLink="false">oai:arXiv.org:2509.02616v1</guid>
      <category>cs.DS</category>
      <category>cs.DM</category>
      <pubDate>Thu, 04 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>A. Manas</dc:creator>
    </item>
    <item>
      <title>Efficient Dynamic Rank Aggregation</title>
      <link>https://arxiv.org/abs/2509.02885</link>
      <description>arXiv:2509.02885v1 Announce Type: new 
Abstract: The rank aggregation problem, which has many real-world applications, refers to the process of combining multiple input rankings into a single aggregated ranking. In dynamic settings, where new rankings arrive over time, efficiently updating the aggregated ranking is essential. This paper develops a fast, theoretically and practically efficient dynamic rank aggregation algorithm. First, we develop the LR-Aggregation algorithm, built on top of the LR-tree data structure, which is itself modeled on the LR-distance, a novel and equivalent take on the classical Spearman's footrule distance. We then analyze the theoretical efficiency of the Pick-A-Perm algorithm, and show how it can be combined with the LR-aggregation algorithm using another data structure that we develop. We demonstrate through experimental evaluations that LR-Aggregation produces close to optimal solutions in practice. We show that Pick-A-Perm has a theoretical worst case approximation guarantee of 2. We also show that both the LR-Aggregation and Pick-A-Perm algorithms, as well as the methodology for combining them can be run in $O(n \log n)$ time. To the best of our knowledge, this is the first fast, near linear time rank aggregation algorithm in the dynamic setting, having both a theoretical approximation guarantee, and excellent practical performance (much better than the theoretical guarantee).</description>
      <guid isPermaLink="false">oai:arXiv.org:2509.02885v1</guid>
      <category>cs.DS</category>
      <pubDate>Thu, 04 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Morteza Alimi, Hourie Mehrabiun, Alireza Zarei</dc:creator>
    </item>
    <item>
      <title>Fast approximation algorithms for the 1-median problem on real-world large graphs</title>
      <link>https://arxiv.org/abs/2509.03052</link>
      <description>arXiv:2509.03052v1 Announce Type: new 
Abstract: The 1-median problem (1MP) on undirected weighted graphs seeks to find a facility location minimizing the total weighted distance to all customer nodes. Although the 1MP can be solved exactly by computing the single-source shortest paths from each customer node, such approaches become computationally expensive on large-scale graphs with millions of nodes. In many real-world applications, such as recommendation systems based on large-scale knowledge graphs, the number of nodes (i.e., potential facility locations) is enormous, whereas the number of customer nodes is relatively small and spatially concentrated. In such cases, exhaustive graph exploration is not only inefficient but also unnecessary. Leveraging this observation, we propose three approximation algorithms that reduce computation by terminating Dijkstra's algorithm early. We provide theoretical analysis showing that one of the proposed algorithms guarantees an approximation ratio of 2, whereas the other two improve this ratio to 1.618. We demonstrate that the lower bound of the approximation ratio is 1.2 by presenting a specific instance. Moreover, we show that all proposed algorithms return optimal solutions when the number of customer nodes is less than or equal to three. Extensive experiments demonstrate that our algorithms significantly outperform baseline exact methods in runtime while maintaining near-optimal accuracy across all tested graph types. Notably, on grid graphs with 10 million nodes, our algorithms obtains all optimal solutions within 1 millisecond, whereas the baseline exact method requires over 70 seconds on average.</description>
      <guid isPermaLink="false">oai:arXiv.org:2509.03052v1</guid>
      <category>cs.DS</category>
      <category>cs.DM</category>
      <pubDate>Thu, 04 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Keisuke Ueta, Wei Wu, Mutsunori Yagiura</dc:creator>
    </item>
    <item>
      <title>Triangle Detection in Worst-Case Sparse Graphs via Local Sketching</title>
      <link>https://arxiv.org/abs/2509.03215</link>
      <description>arXiv:2509.03215v1 Announce Type: new 
Abstract: We present a non-algebraic, locality-preserving framework for triangle detection in worst-case sparse graphs. Our algorithm processes the graph in $O(\log n)$ independent layers and partitions incident edges into prefix-based classes where each class maintains a 1-sparse triple over a prime field. Potential witnesses are surfaced by pair-key (PK) alignment, and every candidate is verified by a three-stage, zero-false-positive pipeline: a class-level 1-sparse consistency check, two slot-level decodings, and a final adjacency confirmation. \textbf{To obtain single-run high-probability coverage, we further instantiate $R=c_G\log n$ independent PK groups per class (each probing a constant number of complementary buckets), which amplifies the per-layer hit rate from $\Theta(1/\log n)$ to $1-n^{-\Omega(1)}$ without changing the accounting.} A one-shot pairing discipline and class-term triggering yield a per-(layer,level) accounting bound of $O(m)$, while keep-coin concentration ensures that each vertex retains only $O(d^+(x))$ keys with high probability. Consequently, the total running time is $O(m\log^2 n)$ and the peak space is $O(m\log n)$, both with high probability. The algorithm emits a succinct Seeds+Logs artifact that enables a third party to replay all necessary checks and certify a NO-instance in $\tilde O(m\log n)$ time. We also prove a $\Theta(1/\log n)$ hit-rate lower bound for any single PK family under a constant-probe local model (via Yao)--motivating the use of $\Theta(\log n)$ independent groups--and discuss why global algebraic convolutions would break near-linear accounting or run into fine-grained barriers. We outline measured paths toward Las Vegas $O(m\log n)$ and deterministic near-linear variants.</description>
      <guid isPermaLink="false">oai:arXiv.org:2509.03215v1</guid>
      <category>cs.DS</category>
      <category>cs.CG</category>
      <pubDate>Thu, 04 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Hongyi Duan, Jian'an Zhang</dc:creator>
    </item>
    <item>
      <title>Compressed Dictionary Matching on Run-Length Encoded Strings</title>
      <link>https://arxiv.org/abs/2509.03265</link>
      <description>arXiv:2509.03265v1 Announce Type: new 
Abstract: Given a set of pattern strings $\mathcal{P}=\{P_1, P_2,\ldots P_k\}$ and a text string $S$, the classic dictionary matching problem is to report all occurrences of each pattern in $S$. We study the dictionary problem in the compressed setting, where the pattern strings and the text string are compressed using run-length encoding, and the goal is to solve the problem without decompression and achieve efficient time and space in the size of the compressed strings. Let $m$ and $n$ be the total length of the patterns $\mathcal{P}$ and the length of the text string $S$, respectively, and let $\overline{m}$ and $\overline{n}$ be the total number of runs in the run-length encoding of the patterns in $\mathcal{P}$ and $S$, respectively. Our main result is an algorithm that achieves $O( (\overline{m} + \overline{n})\log \log m + \mathrm{occ})$ expected time, and $O(\overline{m})$ space, where $\mathrm{occ}$ is the total number of occurrences of patterns in $S$. This is the first non-trivial solution to the problem. Since any solution must read the input, our time bound is optimal within an $\log \log m$ factor. We introduce several new techniques to achieve our bounds, including a new compressed representation of the classic Aho-Corasick automaton and a new efficient string index that supports fast queries in run-length encoded strings.</description>
      <guid isPermaLink="false">oai:arXiv.org:2509.03265v1</guid>
      <category>cs.DS</category>
      <pubDate>Thu, 04 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <arxiv:DOI>10.4230/LIPIcs.CPM.2025.21</arxiv:DOI>
      <arxiv:journal_reference>36th Annual Symposium on Combinatorial Pattern Matching (CPM 2025). Leibniz International Proceedings in Informatics (LIPIcs), Volume 331, pp. 21:1-21:16, Schloss Dagstuhl - Leibniz-Zentrum f\"ur Informatik (2025)</arxiv:journal_reference>
      <dc:creator>Philip Bille, Inge Li G{\o}rtz, Simon J. Puglisi, Simon R. Tarnow</dc:creator>
    </item>
    <item>
      <title>Lower Bounds for Linear Operators</title>
      <link>https://arxiv.org/abs/2509.02730</link>
      <description>arXiv:2509.02730v1 Announce Type: cross 
Abstract: We consider a static data structure problem of computing a linear operator under cell-probe model. Given a linear operator $M \in \mathbb{F}_2^{m \times n}$, the goal is to pre-process a vector $X \in \mathbb{F}_2^n$ into a data structure of size $s$ to answer any query $\langle M_i , X \rangle$ in time $t$. We prove that for a random operator $M$, any such data structure requires:
  $$ t \geq \Omega ( \min \{ \log (m/s) , n / \log s \} ).$$ This result overcomes the well-known logarithmic barrier in static data structures [MNSW98, Sie04, PD06, PTW08, Pat11, DGW19] by using a random linear operator. Furthermore, it provides the first significant progress toward confirming a decades-old folklore conjecture: that non-linear pre-processing does not substantially help in computing most linear operators.
  A straightforward modification of our proof also yields a wire lower bound of $\Omega(n \cdot \log^{1/d}(n))$ for depth-$d$ circuits with arbitrary gates that compute a specific linear operator $M \in \mathbb{F}_2^{O(n) \times n}$, even against some small constant advantage over random guessing. This bound holds even for circuits with only a small constant advantage over random guessing, improving upon longstanding results [RS03, Che08a, Che08b, GHK+13] for a random operator.
  Finally, our work partially resolves the communication form of the Multiphase Conjecture [Pat10] and makes progress on Jukna-Schnitger's Conjecture [JS11, Juk12]. We address the former by considering the Inner Product (mod 2) problem (instead of Set Disjointness) when the number of queries $m$ is super-polynomial (e.g., $2^{n^{1/3}}$), and the total update time is $m^{0.99}$. Our result for the latter also applies to cases with super-polynomial $m$.</description>
      <guid isPermaLink="false">oai:arXiv.org:2509.02730v1</guid>
      <category>cs.CC</category>
      <category>cs.DM</category>
      <category>cs.DS</category>
      <pubDate>Thu, 04 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Young Kun Ko</dc:creator>
    </item>
    <item>
      <title>Treasure Hunt in Anonymous Graphs with Quantum Pebbles by Oblivious Agents</title>
      <link>https://arxiv.org/abs/2509.02909</link>
      <description>arXiv:2509.02909v1 Announce Type: cross 
Abstract: We investigate the problem of finding a static treasure in anonymous graphs using oblivious agents and introduce a novel approach that leverages quantum information. In anonymous graphs, vertices are unlabelled, indistinguishable, and edges are locally labelled with port numbers. Agents typically rely on stationary classical pebbles placed by an oracle to guide their search. However, this classical approach is constrained by limited information transmission and high traversal complexity. Classical pebbles are not sufficient for search if the agents are oblivious. We propose the first use of quantum pebbles for search in anonymous graphs. Quantum pebbles periodically emit qubits in a fixed quantum state. Each pebble encodes the port number to the next node using a unique quantum state. The agent determines the correct path by performing measurements in multiple bases, exploiting the probabilistic nature of quantum measurement to distinguish states. We show that this strategy enables an oblivious agent to locate the treasure in $D$ steps using $D$ quantum pebbles, where $D$ is the length of the shortest path between the starting point and the treasure. Moreover, only $O((\log D + \log \Delta)/(\log 1/\delta))$ measurements per node are required to ensure high success probability in a graph with maximum degree $\Delta$ where $\delta = \cos^2(\frac{\pi}{2\Delta})$. We propose the use of quantum information as a guidance mechanism in anonymous graph search. We demonstrate that quantum pebbles can not only emulate the functionality of classical pebbles but can do so with improved efficiency, offering a promising direction for future quantum-enhanced distributed algorithms.</description>
      <guid isPermaLink="false">oai:arXiv.org:2509.02909v1</guid>
      <category>quant-ph</category>
      <category>cs.DC</category>
      <category>cs.DS</category>
      <category>cs.ET</category>
      <pubDate>Thu, 04 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Gaurav Gaur, Barun Gorain, Rishi Ranjan Singh, Daya Gaur</dc:creator>
    </item>
    <item>
      <title>Online Resource Allocation with Cancellations</title>
      <link>https://arxiv.org/abs/2210.11570</link>
      <description>arXiv:2210.11570v3 Announce Type: replace 
Abstract: We initiate the study of two-sided online resource allocation with costly cancellations. Our focus is on edge-weighted online bipartite matching (and several of its extensions), where nodes arrive online and request offline resources. In contrast to the classic literature, any fraction of an offline resource that was preallocated to an earlier online node can be reclaimed, resulting in the loss of the previously allocated edge-weight plus an additional penalty equal to a non-negative constant factor $f$ times the edge-weight. Parameterizing the problem by the buyback factor $f$, our main result is the development of optimal competitive algorithms for \emph{all possible values} of $f$ through a novel primal-dual family of algorithms in the fractional (or equivalently, large capacity) setting, and establishing their optimality by deriving matching lower bounds. Interestingly, our results reveal a phase transition: for the small buyback regime ($f &lt; \frac{e-2}{2}$), the optimal competitive ratio is $\frac{e}{e-(1+f)}$, and for the large buyback regime ($f \geq \frac{e-2}{2}$), the competitive ratio is $-W_{-1}\left(\frac{-1}{e(1+f)}\right)$, where $W_{-1}$ is the non-principal branch of the Lambert $W$ function. We also study variants of this model, such as matching with deterministic integral allocations. We again show a phase transition: for the small buyback regime ($f &lt; \frac{1}{3}$), the optimal competitive ratio is $\frac{2}{1-f}$, while for the large buyback regime ($f \geq \frac{1}{3}$), the competitive ratio is $1 + 2f + 2\sqrt{f(1+f)}$. We further consider various extensions, including to configuration allocations and submodular welfare maximization, as well as negative values of $f$, modeling a secondary supply channels or overflow capacities available at discounted rates. Our unifying primal-dual framework achieves the exact optimal competitive ratio across all these variants</description>
      <guid isPermaLink="false">oai:arXiv.org:2210.11570v3</guid>
      <category>cs.DS</category>
      <category>cs.GT</category>
      <pubDate>Thu, 04 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Farbod Ekbatani, Yiding Feng, Rad Niazadeh</dc:creator>
    </item>
    <item>
      <title>A Lock-free Binary Trie</title>
      <link>https://arxiv.org/abs/2405.06208</link>
      <description>arXiv:2405.06208v2 Announce Type: replace 
Abstract: A binary trie is a sequential data structure for a dynamic set on the universe $\{0,\dots,u-1\}$ supporting Search with $O(1)$ worst-case step complexity, and Insert, Delete, and Predecessor operations with $O(\log u)$ worst-case step complexity.
  We give a wait-free implementation of a relaxed binary trie, using read, write, CAS, and ($\log u$)-bit AND operations. It supports all operations with the same worst-case step complexity as the sequential binary trie. However, Predecessor operations may not return a key when there are concurrent update operations. We use this as a component of a lock-free, linearizable implementation of a binary trie. It supports Search with $O(1)$ worst-case step complexity and Insert, Delete and Predecessor with $O(c^2 + \log u)$ amortized step complexity, where $c$ is a measure of the contention.
  A lock-free binary trie is challenging to implement as compared to many other lock-free data structures because Insert and Delete operations perform a non-constant number of modifications to the binary trie in the worst-case to ensure the correctness of Predecessor operations.</description>
      <guid isPermaLink="false">oai:arXiv.org:2405.06208v2</guid>
      <category>cs.DS</category>
      <pubDate>Thu, 04 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Jeremy Ko</dc:creator>
    </item>
    <item>
      <title>Safe Sequences via Dominators in DAGs for Path-Covering Problems</title>
      <link>https://arxiv.org/abs/2411.03871</link>
      <description>arXiv:2411.03871v4 Announce Type: replace 
Abstract: A path-covering problem on a directed acyclic graph (DAG) requires finding a set of source-to-sink paths that cover all the nodes, all the arcs, or subsets thereof, and additionally they are optimal with respect to some function. In this paper we study safe sequences of nodes or arcs, namely sequences that appear in some path of every path cover of a DAG.
  We show that safe sequences admit a simple characterization via cutnodes. Moreover, we establish a connection between maximal safe sequences and leaf-to-root paths in the source- and sink-dominator trees of the DAG, which may be of independent interest in the extensive literature on dominators. With dominator trees, safe sequences admit an O(n)-size representation and a linear-time output-sensitive enumeration algorithm running in time O(m + o), where n and m are the number of nodes and arcs, respectively, and o is the total length of the maximal safe sequences.
  We then apply maximal safe sequences to simplify Integer Linear Programs (ILPs) for two path-covering problems, LeastSquares and MinPathError, which are at the core of RNA transcript assembly problems from bioinformatics. On various datasets, maximal safe sequences can be computed in under 0.1 seconds per graph, on average, and ILP solvers whose search space is reduced in this manner exhibit significant speed-ups. For example on graphs with a large width, average speed-ups are in the range 50-250x for MinPathError and in the range 80-350x for LeastSquares. Optimizing ILPs using safe sequences can thus become a fast building block of practical RNA transcript assembly tools, and more generally, of path-covering problems.</description>
      <guid isPermaLink="false">oai:arXiv.org:2411.03871v4</guid>
      <category>cs.DS</category>
      <category>math.OC</category>
      <category>q-bio.GN</category>
      <pubDate>Thu, 04 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Francisco Sena, Romeo Rizzi, Alexandru I. Tomescu</dc:creator>
    </item>
    <item>
      <title>Covering a Few Submodular Constraints and Applications</title>
      <link>https://arxiv.org/abs/2507.09879</link>
      <description>arXiv:2507.09879v2 Announce Type: replace 
Abstract: We consider the problem of covering multiple submodular constraints. Given a finite ground set $N$, a cost function $c: N \rightarrow \mathbb{R}_+$, $r$ monotone submodular functions $f_1,f_2,\ldots,f_r$ over $N$ and requirements $b_1,b_2,\ldots,b_r$ the goal is to find a minimum cost subset $S \subseteq N$ such that $f_i(S) \ge b_i$ for $1 \le i \le r$. When $r=1$ this is the well-known Submodular Set Cover problem. Previous work \cite{chekuri2022covering} considered the setting when $r$ is large and developed bi-criteria approximation algorithms, and approximation algorithms for the important special case when each $f_i$ is a weighted coverage function. These are fairly general models and capture several concrete and interesting problems as special cases. The approximation ratios for these problem are at least $\Omega(\log r)$ which is unavoidable when $r$ is part of the input. In this paper, motivated by some recent applications, we consider the problem when $r$ is a \emph{fixed constant} and obtain two main results. For covering multiple submodular constraints we obtain a randomized bi-criteria approximation algorithm that for any given integer $\alpha \ge 1$ outputs a set $S$ such that $f_i(S) \ge$ $(1-1/e^\alpha -\epsilon)b_i$ for each $i \in [r]$ and $\mathbb{E}[c(S)] \le (1+\epsilon)\alpha \cdot \sf{OPT}$. Second, when the $f_i$ are weighted coverage functions from a deletion-closed set system we obtain a $(1+\epsilon)$ $(\frac{e}{e-1})$ $(1+\beta)$-approximation where $\beta$ is the approximation ratio for the underlying set cover instances via the natural LP. These results show that one can obtain nearly as good an approximation for any fixed $r$ as what one would achieve for $r=1$. We mention some applications that follow easily from these general results and anticipate more in the future.</description>
      <guid isPermaLink="false">oai:arXiv.org:2507.09879v2</guid>
      <category>cs.DS</category>
      <category>cs.AI</category>
      <category>cs.GT</category>
      <pubDate>Thu, 04 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Tanvi Bajpai, Chandra Chekuri, Pooja Kulkarni</dc:creator>
    </item>
    <item>
      <title>The Broader Landscape of Robustness in Algorithmic Statistics</title>
      <link>https://arxiv.org/abs/2412.02670</link>
      <description>arXiv:2412.02670v2 Announce Type: replace-cross 
Abstract: The last decade has seen a number of advances in computationally efficient algorithms for statistical methods subject to robustness constraints. An estimator may be robust in a number of different ways: to contamination of the dataset, to heavy-tailed data, or in the sense that it preserves privacy of the dataset. We survey recent results in these areas with a focus on the problem of mean estimation, drawing technical and conceptual connections between the various forms of robustness, showing that the same underlying algorithmic ideas lead to computationally efficient estimators in all these settings.</description>
      <guid isPermaLink="false">oai:arXiv.org:2412.02670v2</guid>
      <category>stat.ML</category>
      <category>cs.CR</category>
      <category>cs.DS</category>
      <category>cs.IT</category>
      <category>math.IT</category>
      <category>math.ST</category>
      <category>stat.TH</category>
      <pubDate>Thu, 04 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Gautam Kamath</dc:creator>
    </item>
    <item>
      <title>Learning sparse generalized linear models with binary outcomes via iterative hard thresholding</title>
      <link>https://arxiv.org/abs/2502.18393</link>
      <description>arXiv:2502.18393v2 Announce Type: replace-cross 
Abstract: In statistics, generalized linear models (GLMs) are widely used for modeling data and can expressively capture potential nonlinear dependence of the model's outcomes on its covariates. Within the broad family of GLMs, those with binary outcomes, which include logistic and probit regressions, are motivated by common tasks such as binary classification with (possibly) non-separable data. In addition, in modern machine learning and statistics, data is often high-dimensional yet has a low intrinsic dimension, making sparsity constraints in models another reasonable consideration. In this work, we propose to use and analyze an iterative hard thresholding (projected gradient descent on the ReLU loss) algorithm, called binary iterative hard thresholding (BIHT), for parameter estimation in sparse GLMs with binary outcomes. We establish that BIHT is statistically efficient and converges to the correct solution for parameter estimation in a general class of sparse binary GLMs. Unlike many other methods for learning GLMs, including maximum likelihood estimation, generalized approximate message passing, and GLM-tron (Kakade et al. 2011; Bahmani et al. 2016), BIHT does not require knowledge of the GLM's link function, offering flexibility and generality in allowing the algorithm to learn arbitrary binary GLMs. As two applications, logistic and probit regression are additionally studied. In this regard, it is shown that in logistic regression, the algorithm is in fact statistically optimal in the sense that the order-wise sample complexity matches (up to logarithmic factors) the lower bound obtained previously. To the best of our knowledge, this is the first work achieving statistical optimality for logistic regression in all noise regimes with a computationally efficient algorithm. Moreover, for probit regression, our sample complexity is on the same order as that obtained for logistic regression.</description>
      <guid isPermaLink="false">oai:arXiv.org:2502.18393v2</guid>
      <category>math.ST</category>
      <category>cs.DS</category>
      <category>cs.IT</category>
      <category>cs.LG</category>
      <category>math.IT</category>
      <category>stat.ML</category>
      <category>stat.TH</category>
      <pubDate>Thu, 04 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Namiko Matsumoto, Arya Mazumdar</dc:creator>
    </item>
    <item>
      <title>Quantum singular value transformation without block encodings: Near-optimal complexity with minimal ancilla</title>
      <link>https://arxiv.org/abs/2504.02385</link>
      <description>arXiv:2504.02385v2 Announce Type: replace-cross 
Abstract: We develop new algorithms for Quantum Singular Value Transformation (QSVT), a unifying framework that encapsulates most known quantum algorithms and serves as the foundation for new ones. Existing implementations of QSVT rely on block encoding, incurring an intrinsic $O(\log L)$ ancilla overhead and circuit depth $\widetilde{O}(L d\lambda )$ for polynomial transformations of a Hamiltonian $H=\sum_{k=1}^L H_k$, where $d$ is the polynomial degree and $\lambda=\sum_{k}\|H_k\|$.
  We introduce a simple yet powerful approach that utilizes only basic Hamiltonian simulation techniques, namely, Trotter methods, to: (i) eliminate the need for block encoding, (ii) reduce the ancilla overhead to only a single qubit, and (iii) still maintain near-optimal complexity. Our method achieves a circuit depth of $\widetilde{O}(L(d\lambda_{\mathrm{comm}})^{1+o(1)})$, without requiring any complicated multi-qubit controlled gates. Moreover, $\lambda_{\mathrm{comm}}$ depends on the nested commutators of the terms of $H$ and can be substantially smaller than $\lambda$ for many physically relevant Hamiltonians, a feature absent in standard QSVT. To achieve these results, we make use of Richardson extrapolation in a novel way, systematically eliminating errors in any interleaved sequence of arbitrary unitaries and Hamiltonian evolution operators, thereby establishing a general framework that encompasses QSVT but is more broadly applicable.
  As applications, we develop end-to-end quantum algorithms for solving linear systems and estimating ground state properties of Hamiltonians, both achieving near-optimal complexity without relying on oracular access. Overall, our results establish a new framework for quantum algorithms, significantly reducing hardware overhead while maintaining near-optimal performance, with implications for both near-term and fault-tolerant quantum computing.</description>
      <guid isPermaLink="false">oai:arXiv.org:2504.02385v2</guid>
      <category>quant-ph</category>
      <category>cs.DS</category>
      <pubDate>Thu, 04 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Shantanav Chakraborty, Soumyabrata Hazra, Tongyang Li, Changpeng Shao, Xinzhao Wang, Yuxin Zhang</dc:creator>
    </item>
    <item>
      <title>Even Faster Algorithm for the Chamfer Distance</title>
      <link>https://arxiv.org/abs/2505.08957</link>
      <description>arXiv:2505.08957v2 Announce Type: replace-cross 
Abstract: For two d-dimensional point sets A, B of size up to n, the Chamfer distance from A to B is defined as CH(A,B) = \sum_{a \in A} \min_{b \in B} \|a-b\|. The Chamfer distance is a widely used measure for quantifying dissimilarity between sets of points, used in many machine learning and computer vision applications. A recent work of Bakshi et al, NeuriPS'23, gave the first near-linear time (1+eps)-approximate algorithm, with a running time of O(ndlog(n)/eps^2). In this paper we improve the running time further, to O(nd(loglog(n)+log(1/eps))/eps^2). When eps is a constant, this reduces the gap between the upper bound and the trivial Omega(dn) lower bound significantly, from O(log n) to O(loglog n).</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.08957v2</guid>
      <category>cs.CG</category>
      <category>cs.DS</category>
      <pubDate>Thu, 04 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Ying Feng, Piotr Indyk</dc:creator>
    </item>
  </channel>
</rss>
