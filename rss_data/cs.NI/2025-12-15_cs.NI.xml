<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>cs.NI updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/cs.NI</link>
    <description>cs.NI updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/cs.NI" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Mon, 15 Dec 2025 05:00:14 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Mon, 15 Dec 2025 00:00:00 -0500</pubDate>
    <skipDays>
      <day>Saturday</day>
      <day>Sunday</day>
    </skipDays>
    <item>
      <title>SHIFT: An RDMA Failure-Resilient Layer for Distributed Training</title>
      <link>https://arxiv.org/abs/2512.11094</link>
      <description>arXiv:2512.11094v1 Announce Type: new 
Abstract: With gang scheduling in large-scale distributed Large Language Model training, a single network anomaly can propagate and cause complete task failure. The frequency of such anomalies increases with network scale. However, existing fault-tolerance mechanisms, such as checkpointing and runtime resilience methods, primarily operate at the application layer and inevitably cause disruptions in training progress.
  We propose to address this challenge by introducing fault tolerance at the Remote Direct Memory Access (RDMA) layer and integrating it with existing application-layer techniques. We present SHIFT, a fault-resilient layer over RDMA that enables seamless redirection of RDMA traffic across different intra-host NICs. By allowing applications to continue execution in the presence of network anomalies until the next checkpoint, SHIFT effectively minimizes training progress loss. SHIFT is designed to be application-agnostic, transparent to applications, and low-overhead.
  Through a carefully designed failure state machine and control flow, unmodified applications such as PyTorch with NCCL can run with RDMA-level fault tolerance. Experimental results demonstrate that SHIFT introduces minimal data path overhead while ensuring application continuity under network failures.</description>
      <guid isPermaLink="false">oai:arXiv.org:2512.11094v1</guid>
      <category>cs.NI</category>
      <pubDate>Mon, 15 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Shengkai Lin, Kairui Zhou, Yibo Wu, Hongtao Zhang, Qinwei Yang, Wei Zhang, Arvind Krishnamurthy, Shizhen Zhao</dc:creator>
    </item>
    <item>
      <title>BIER-Star: Stateless Geographic Multicast for Scalable Satellite-Terrestrial Integration</title>
      <link>https://arxiv.org/abs/2512.11156</link>
      <description>arXiv:2512.11156v1 Announce Type: new 
Abstract: The rapid expansion of LEO satellite constellations has enabled an integrated terrestrial network and non-terrestrial network (TN-NTN), connecting diverse users such as aircraft, ships, and remote communities. These networks increasingly need a scalable and efficient multicast protocol for critical applications like emergency alerts, large-scale software updates, and real-time broadcasting. However, traditional multicast protocols, such as IP-based multicast and software-defined multicast approaches, introduce significant control overhead and struggle to adapt to the dynamic and mobile nature of satellite topologies. This paper presents BIER-Star, a stateless multicast protocol designed for the integrated TN-NTN. BIER-Star uses a two-layer geospatial gridding scheme (i.e., H3) to encode destinations as Earth- and space-cell identifiers rather than per-terminal addresses. This cell-based abstraction shortens the header bitstring, simplifies forwarding, and eliminates per-flow state and complex signaling. Our simulations indicate that BIER-Star reduces header size versus BIER and avoids geographic path-finding failures seen in greedy methods.</description>
      <guid isPermaLink="false">oai:arXiv.org:2512.11156v1</guid>
      <category>cs.NI</category>
      <pubDate>Mon, 15 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Mostafa Abdollahi, Wenjun Yang, Jianping Pan</dc:creator>
    </item>
    <item>
      <title>Distributed Resource Allocation and Application Deployment in Mesh Edge Networks</title>
      <link>https://arxiv.org/abs/2512.11230</link>
      <description>arXiv:2512.11230v1 Announce Type: new 
Abstract: Virtual Network Embedding (VNE) approaches typically assume static or slowly-changing network topologies, but emerging applications require deployment in mobile environments where traditional methods become insufficient. This work extends VNE to constrained mesh networks of mobile edge devices, addressing the unique challenges of rapid topology changes and limited resources. We develop models incorporating device capabilities, connectivity, mobility and energy constraints to evaluate optimal deployment strategies for mobile edge environments. Our approach handles the dynamic nature of mobile networks through three allocation strategies: an integer linear program for optimal allocation, a greedy heuristic for immediate deployment, and a multi-objective genetic algorithm for balanced optimization. Our initial evaluation analyzes application acceptance rates, resource utilization, and latency performance under resource limitations. Results demonstrate improvements over traditional approaches, providing a foundation for VNE deployment in highly mobile environments.</description>
      <guid isPermaLink="false">oai:arXiv.org:2512.11230v1</guid>
      <category>cs.NI</category>
      <pubDate>Mon, 15 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <arxiv:DOI>10.1109/WiMob66857.2025.11257493</arxiv:DOI>
      <dc:creator>Antoine Bernard, Antoine Legrain, Maroua Ben Attia, Abdo Shabah</dc:creator>
    </item>
    <item>
      <title>Toward Scalable VR-Cloud Gaming: An Attention-aware Adaptive Resource Allocation Framework for 6G Networks</title>
      <link>https://arxiv.org/abs/2512.11667</link>
      <description>arXiv:2512.11667v1 Announce Type: new 
Abstract: Virtual Reality Cloud Gaming (VR-CG) represents a demanding class of immersive applications, requiring high bandwidth, ultra-low latency, and intelligent resource management to ensure optimal user experience. In this paper, we propose a scalable and QoE-aware multi-stage optimization framework for resource allocation in VR-CG over 6G networks. Our solution decomposes the joint resource allocation problem into three interdependent stages: (i) user association and communication resource allocation; (ii) VR-CG game engine placement with adaptive multipath routing; and (iii) attention-aware scheduling and wireless resource allocation based on motion-to-photon latency. For each stage, we design specialized heuristic algorithms that achieve near-optimal performance while significantly reducing computational time. We introduce a novel user-centric QoE model based on visual attention to virtual objects, guiding adaptive resolution and frame rate selection. A dataset-driven evaluation demonstrates that, when compared against state-of-the-art approaches, our framework improves QoE by up to 50\%, reduces communication resource usage by 75\%, and achieves up to 35\% cost savings, while maintaining an average optimality gap of 5\%. Our proposed heuristics solve large-scale scenarios in under 0.1 seconds, highlighting their potential for real-time deployment in next-generation mobile networks.</description>
      <guid isPermaLink="false">oai:arXiv.org:2512.11667v1</guid>
      <category>cs.NI</category>
      <pubDate>Mon, 15 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Gabriel Almeida, Jo\~ao Paulo Esper, Cleverson Nahum, Audebaro Klautau, Kleber Vieira Cardoso</dc:creator>
    </item>
    <item>
      <title>Proving DNSSEC Correctness: A Formal Approach to Secure Domain Name Resolution</title>
      <link>https://arxiv.org/abs/2512.11431</link>
      <description>arXiv:2512.11431v1 Announce Type: cross 
Abstract: The Domain Name System Security Extensions (DNSSEC) are critical for preventing DNS spoofing, yet its specifications contain ambiguities and vulnerabilities that elude traditional "break-and-fix" approaches. A holistic, foundational security analysis of the protocol has thus remained an open problem. This paper introduces DNSSECVerif, the first framework for comprehensive, automated formal security analysis of the DNSSEC protocol suite. Built on the SAPIC+ symbolic verifier, our high-fidelity model captures protocol-level interactions, including cryptographic operations and stateful caching with fine-grained concurrency control. Using DNSSECVerif, we formally prove four of DNSSEC's core security guarantees and uncover critical ambiguities in the standards--notably, the insecure coexistence of NSEC and NSEC3. Our model also automatically rediscovers three classes of known attacks, demonstrating fundamental weaknesses in the protocol design. To bridge the model-to-reality gap, we validate our findings through targeted testing of mainstream DNS software and a large-scale measurement study of over 2.2 million open resolvers, confirming the real-world impact of these flaws. Our work provides crucial, evidence-based recommendations for hardening DNSSEC specifications and implementations.</description>
      <guid isPermaLink="false">oai:arXiv.org:2512.11431v1</guid>
      <category>cs.CR</category>
      <category>cs.FL</category>
      <category>cs.NI</category>
      <pubDate>Mon, 15 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Qifan Zhang, Zilin Shen, Imtiaz Karim, Elisa Bertino, Zhou Li</dc:creator>
    </item>
    <item>
      <title>ECCO: Leveraging Cross-Camera Correlations for Efficient Live Video Continuous Learning</title>
      <link>https://arxiv.org/abs/2512.11727</link>
      <description>arXiv:2512.11727v1 Announce Type: cross 
Abstract: Recent advances in video analytics address real-time data drift by continuously retraining specialized, lightweight DNN models for individual cameras. However, the current practice of retraining a separate model for each camera suffers from high compute and communication costs, making it unscalable. We present ECCO, a new video analytics framework designed for resource-efficient continuous learning. The key insight is that the data drift, which necessitates model retraining, often shows temporal and spatial correlations across nearby cameras. By identifying cameras that experience similar drift and retraining a shared model for them, ECCO can substantially reduce the associated compute and communication costs. Specifically, ECCO introduces: (i) a lightweight grouping algorithm that dynamically forms and updates camera groups; (ii) a GPU allocator that dynamically assigns GPU resources across different groups to improve retraining accuracy and ensure fairness; and (iii) a transmission controller at each camera that configures frame sampling and coordinates bandwidth sharing with other cameras based on its assigned GPU resources. We conducted extensive evaluations on three distinctive datasets for two vision tasks. Compared to leading baselines, ECCO improves retraining accuracy by 6.7%-18.1% using the same compute and communication resources, or supports 3.3 times more concurrent cameras at the same accuracy.</description>
      <guid isPermaLink="false">oai:arXiv.org:2512.11727v1</guid>
      <category>cs.DC</category>
      <category>cs.LG</category>
      <category>cs.NI</category>
      <pubDate>Mon, 15 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Yuze He, Ferdi Kossmann, Srinivasan Seshan, Peter Steenkiste</dc:creator>
    </item>
    <item>
      <title>Hypergraph based Multi-Party Payment Channel</title>
      <link>https://arxiv.org/abs/2512.11775</link>
      <description>arXiv:2512.11775v1 Announce Type: cross 
Abstract: Public blockchains inherently offer low throughput and high latency, motivating off-chain scalability solutions such as Payment Channel Networks (PCNs). However, existing PCNs suffer from liquidity fragmentation-funds locked in one channel cannot be reused elsewhere-and channel depletion, both of which limit routing efficiency and reduce transaction success rates. Multi-party channel (MPC) constructions mitigate these issues, but they typically rely on leaders or coordinators, creating single points of failure and providing only limited flexibility for inter-channel payments.
  We introduce Hypergraph-based Multi-Party Payment Channels (H-MPCs), a new off-chain construction that replaces bilateral channels with collectively funded hyperedges. These hyperedges enable fully concurrent, leaderless intra- and inter-hyperedge payments through verifiable, proposer-ordered DAG updates, offering significantly greater flexibility and concurrency than prior designs.
  Our implementation on a 150-node network demonstrates a transaction success rate of approximately 94% without HTLC expiry or routing failures, highlighting the robustness of H-MPCs.</description>
      <guid isPermaLink="false">oai:arXiv.org:2512.11775v1</guid>
      <category>cs.DC</category>
      <category>cs.CR</category>
      <category>cs.NI</category>
      <pubDate>Mon, 15 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Ayush Nainwal, Atharva Kamble, Nitin Awathare</dc:creator>
    </item>
  </channel>
</rss>
