<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>math.OC updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/math.OC</link>
    <description>math.OC updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/math.OC" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Wed, 18 Dec 2024 05:00:04 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Wed, 18 Dec 2024 00:00:00 -0500</pubDate>
    <skipDays>
      <day>Sunday</day>
      <day>Saturday</day>
    </skipDays>
    <item>
      <title>Controllability of a Class of Nonlinear Networked Systems</title>
      <link>https://arxiv.org/abs/2412.12135</link>
      <description>arXiv:2412.12135v1 Announce Type: new 
Abstract: Various controllability conditions have been obtained by researchers for heterogeneous networked systems with linear dynamics. However, the literature for nonlinear, heterogeneous networked systems is comparatively less. In this paper we analyse the controllabiity aspect of a nonlinearly perturbed linear networked system. The basic assumption is that the linear system is controllable and the nonlinear perturbation functions satisfy Holder continuity condition and in particular Lipschitz condition. The Boyd-Wong fixed point theorem is employed to prove controllability of the nonlinear system. The result is illustrated with numerical examples.</description>
      <guid isPermaLink="false">oai:arXiv.org:2412.12135v1</guid>
      <category>math.OC</category>
      <pubDate>Wed, 18 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Aleena Thomas, Abhijith Ajayakumar, Raju K. George</dc:creator>
    </item>
    <item>
      <title>Deep Distributed Optimization for Large-Scale Quadratic Programming</title>
      <link>https://arxiv.org/abs/2412.12156</link>
      <description>arXiv:2412.12156v1 Announce Type: new 
Abstract: Quadratic programming (QP) forms a crucial foundation in optimization, encompassing a broad spectrum of domains and serving as the basis for more advanced algorithms. Consequently, as the scale and complexity of modern applications continue to grow, the development of efficient and reliable QP algorithms is becoming increasingly vital. In this context, this paper introduces a novel deep learning-aided distributed optimization architecture designed for tackling large-scale QP problems. First, we combine the state-of-the-art Operator Splitting QP (OSQP) method with a consensus approach to derive DistributedQP, a new method tailored for network-structured problems, with convergence guarantees to optimality. Subsequently, we unfold this optimizer into a deep learning framework, leading to DeepDistributedQP, which leverages learned policies to accelerate reaching to desired accuracy within a restricted amount of iterations. Our approach is also theoretically grounded through Probably Approximately Correct (PAC)-Bayes theory, providing generalization bounds on the expected optimality gap for unseen problems. The proposed framework, as well as its centralized version DeepQP, significantly outperform their standard optimization counterparts on a variety of tasks such as randomly generated problems, optimal control, linear regression, transportation networks and others. Notably, DeepDistributedQP demonstrates strong generalization by training on small problems and scaling to solve much larger ones (up to 50K variables and 150K constraints) using the same policy. Moreover, it achieves orders-of-magnitude improvements in wall-clock time compared to OSQP. The certifiable performance guarantees of our approach are also demonstrated, ensuring higher-quality solutions over traditional optimizers.</description>
      <guid isPermaLink="false">oai:arXiv.org:2412.12156v1</guid>
      <category>math.OC</category>
      <category>cs.LG</category>
      <category>cs.MA</category>
      <pubDate>Wed, 18 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <dc:creator>Augustinos D. Saravanos, Hunter Kuperman, Alex Oshin, Arshiya Taj Abdul, Vincent Pacelli, Evangelos A. Theodorou</dc:creator>
    </item>
    <item>
      <title>Fully stochastic trust-region methods with Barzilai-Borwein steplengths</title>
      <link>https://arxiv.org/abs/2412.12180</link>
      <description>arXiv:2412.12180v1 Announce Type: new 
Abstract: We investigate stochastic gradient methods and stochastic counterparts of the Barzilai-Borwein steplengths and their application to finite-sum minimization problems. Our proposal is based on the Trust-Region-ish (TRish) framework introduced in [F. E. Curtis, K. Scheinberg, R. Shi, A stochastic trust region algorithm based on careful step normalization, Informs Journal on Optimization, 1, 2019]. The new framework, named TRishBB, aims at enhancing the performance of TRish and at reducing the computational cost of the second-order TRish variant. We propose three different methods belonging to the TRishBB framework and present the convergence analysis for possibly nonconvex objective functions, considering biased and unbiased gradient approximations. Our analysis requires neither diminishing step-sizes nor full gradient evaluation. The numerical experiments in machine learning applications demonstrate the effectiveness of applying the Barzilai-Borwein steplength with stochastic gradients and show improved testing accuracy compared to the TRish method.</description>
      <guid isPermaLink="false">oai:arXiv.org:2412.12180v1</guid>
      <category>math.OC</category>
      <category>cs.NA</category>
      <category>math.NA</category>
      <pubDate>Wed, 18 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Stefania Bellavia, Benedetta Morini, Mahsa Yousefi</dc:creator>
    </item>
    <item>
      <title>Target-Following Online Resource Allocation Using Proxy Assignments</title>
      <link>https://arxiv.org/abs/2412.12321</link>
      <description>arXiv:2412.12321v1 Announce Type: new 
Abstract: We study a target-following variation of online resource allocation. As in classical resource allocation, the decision-maker must assign sequentially arriving jobs to one of multiple available resources. However, in addition to the assignment costs incurred from these decisions, the decision-maker is also penalized for deviating from exogenously given, nonstationary target allocations throughout the horizon. The goal is to minimize the total expected assignment and deviation penalty costs incurred throughout the horizon when the distribution of assignment costs is unknown. In contrast to traditional online resource allocation, in our setting the timing of allocation decisions is critical due to the nonstationarity of allocation targets. Examples of practical problems that fit this framework include many physical resource settings where capacity is time-varying, such as manual warehouse processes where staffing levels change over time, and assignment of packages to outbound trucks whose departure times are scheduled throughout the day. We first show that naive extensions of state-of-the-art algorithms for classical resource allocation problems can fail dramatically when applied to target-following resource allocation. We then propose a novel ``proxy assignment" primal-dual algorithm for the target-following online resource allocation problem that uses current arrivals to simulate the effect of future arrivals. We prove that our algorithm incurs the optimal $O(\sqrt{T})$ regret bound when the assignment costs of the arriving jobs are drawn i.i.d. from a fixed distribution. We demonstrate the practical performance of our approach by conducting numerical experiments on synthetic datasets, as well as real-world datasets from retail fulfillment operations.</description>
      <guid isPermaLink="false">oai:arXiv.org:2412.12321v1</guid>
      <category>math.OC</category>
      <pubDate>Wed, 18 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Chamsi Hssaine, Huseyin Topaloglu, Garrett van Ryzin</dc:creator>
    </item>
    <item>
      <title>Linear Convergence of Resolvent Splitting with Minimal Lifting and its Application to a Primal-Dual Algorithm</title>
      <link>https://arxiv.org/abs/2412.12607</link>
      <description>arXiv:2412.12607v1 Announce Type: new 
Abstract: We consider resolvent splitting algorithms for finding a zero of the sum of finitely many maximally monotone operators. The standard approach to solving this type of problem involves reformulating as a two-operator problem in the product-space and applying the Douglas-Rachford algorithm. However, existing results for linear convergence cannot be applied in the product-space formulation due to a lack of appropriate Lipschitz continuity and strong monotonicity. In this work, we investigate a different approach that does not rely on the Douglas-Rachford algorithm or the product-space directly. We establish linear convergence of the "resolvent splitting with minimal lifting" algorithm due to Malitsky and Tam for monotone inclusions with finitely many operators. Our results are then used to derive linear convergence of a primal-dual algorithm for convex minimization problems involving infimal convolutions. The theoretical results are demonstrated on numerical experiments in image denoising.</description>
      <guid isPermaLink="false">oai:arXiv.org:2412.12607v1</guid>
      <category>math.OC</category>
      <pubDate>Wed, 18 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Farhana A. Simi, Matthew K. Tam</dc:creator>
    </item>
    <item>
      <title>Mean field game problem for the optimal control of neuronal spiking activity</title>
      <link>https://arxiv.org/abs/2412.12682</link>
      <description>arXiv:2412.12682v1 Announce Type: new 
Abstract: We study the mean field game problem for a nervous system consisting of a large number of neurons with mean-field interaction. In this system, each neuron can modulate its spiking activity by controlling its membrane potential to synchronize with others, thereby giving rise to a finite-player game problem. To address this, we first examine the corresponding mean field game problem and characterize the mean field equilibrium by solving a fixed point problem. Subsequently, leveraging the obtained mean field equilibrium, we construct an approximate Nash equilibrium for the finite-player game as the number of neurons is large.</description>
      <guid isPermaLink="false">oai:arXiv.org:2412.12682v1</guid>
      <category>math.OC</category>
      <pubDate>Wed, 18 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <dc:creator>Lijun Bo, Dongfang Yang, Shihua Wang</dc:creator>
    </item>
    <item>
      <title>Preference Robust Ordinal Priority Approach and its Satisficing Extension for Multi-Attribute Decision-Making with Incomplete Information</title>
      <link>https://arxiv.org/abs/2412.12690</link>
      <description>arXiv:2412.12690v1 Announce Type: new 
Abstract: Ordinal Priority Approach (OPA) has recently been proposed to deal with multi-attribute decision-making (MADM) for determining the weights of experts, attributes, and alternatives under incomplete preference information. This study presents an equivalent reformulation of OPA related to rank order centroid weights, further providing its closed-form solution and decomposability. Building on these properties, we propose a Preference Robust Ordinal Priority Approach (OPA-PR) utilizing a two-stage optimization framework to generalize the utility structure and counter the ambiguity within the ranking parameters and utility preferences. In the first stage, OPA-PR elicits the worst-case utility functions across all experts and attributes from utility preference ambiguity sets characterized by monotonicity, normalization, concavity, Lipschitz continuity, and moment-type preference elicitation. In the second stage, OPA-PR optimizes decision weights based on the elicited utility functions, considering the worst-case ranking parameters indicated by support functions. We suggest a piecewise linear approximation for the utility preference ambiguity sets to derive the tractable reformulation of OPA-PR, verified by the error bounds for optimal outcomes in both stages. Critical properties of OPA-PR are provided, including closed-form solution, invariance of optimal weight disparity, and risk preference independence. Moreover, considering the potential ranking parameter misspecification, we develop a robust satisficing extension of OPA-PR based on its closed-form solution, OPA-PRS, with a novel decision criterion-fragility measure of weight disparity. The effectiveness of OPA-PR and OPA-PRS is validated through a numerical experiment of the emergency supplier selection problem.</description>
      <guid isPermaLink="false">oai:arXiv.org:2412.12690v1</guid>
      <category>math.OC</category>
      <pubDate>Wed, 18 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Renlong Wang</dc:creator>
    </item>
    <item>
      <title>Complex extension of optical flow and its practical evaluation for undersampled dynamic MRI</title>
      <link>https://arxiv.org/abs/2412.12711</link>
      <description>arXiv:2412.12711v1 Announce Type: new 
Abstract: Reconstructing high-quality images from undersampled dynamic MRI data is a challenging task and important for the success of this imaging modality. To remedy the naturally occurring artifacts due to measurement undersampling, one can incorporate a motion model into the reconstruction so that information can propagate across time frames. Current models for MRI imaging are using the optical flow equation. However, they are based on real-valued images. Here, we generalise the optical flow equation to complex-valued images and demonstrate, based on two real cardiac MRI datasets, that the new model is capable of improving image quality.</description>
      <guid isPermaLink="false">oai:arXiv.org:2412.12711v1</guid>
      <category>math.OC</category>
      <pubDate>Wed, 18 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Matthias J. Ehrhardt, Marco Mauritz</dc:creator>
    </item>
    <item>
      <title>Robust Deterministic Policies for Markov Decision Processes under Budgeted Uncertainty</title>
      <link>https://arxiv.org/abs/2412.12879</link>
      <description>arXiv:2412.12879v1 Announce Type: new 
Abstract: This paper studies the computation of robust deterministic policies for Markov Decision Processes (MDPs) in the Lightning Does Not Strike Twice (LDST) model of Mannor, Mebel and Xu (ICML '12). In this model, designed to provide robustness in the face of uncertain input data while not being overly conservative, transition probabilities and rewards are uncertain and the uncertainty set is constrained by a budget that limits the number of states whose parameters can deviate from their nominal values.
  Mannor et al. (ICML '12) showed that optimal randomized policies for MDPs in the LDST regime can be efficiently computed when only the rewards are affected by uncertainty. In contrast to these findings, we observe that the computation of optimal deterministic policies is $N\!P$-hard even when only a single terminal reward may deviate from its nominal value and the MDP consists of $2$ time periods. For this hard special case, we then derive a constant-factor approximation algorithm by combining two relaxations based on the Knapsack Cover and Generalized Assignment problem, respectively. For the general problem with possibly a large number of deviations and a longer time horizon, we derive strong inapproximability results for computing robust deterministic policies as well as $\Sigma_2^p$-hardness, indicating that the general problem does not even admit a compact mixed integer programming formulation.</description>
      <guid isPermaLink="false">oai:arXiv.org:2412.12879v1</guid>
      <category>math.OC</category>
      <category>cs.DM</category>
      <pubDate>Wed, 18 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Fei Wu, Erik Demeulemeester, Jannik Matuschke</dc:creator>
    </item>
    <item>
      <title>Image Space Analysis to the generalized optimization problem on a local sphere</title>
      <link>https://arxiv.org/abs/2412.12895</link>
      <description>arXiv:2412.12895v1 Announce Type: new 
Abstract: This paper introduces and studies the generalized optimization problem (for short, GOP) defined by the conic order relation on a local sphere. The existence of solution to this problem is studied by using image space analysis (for short, ISA), and a class of regular weak separation functions on the local sphere is established. Moreover, a Lagrangian-type sufficient optimality condition and a saddle-point-type necessary optimality condition for GOP is obtained by a second class of weak separation functions, which are based on the Gerstewitz function and the directional distance function. The problem is transformed into a solvable real-valued optimization problem using scalarization methods.</description>
      <guid isPermaLink="false">oai:arXiv.org:2412.12895v1</guid>
      <category>math.OC</category>
      <pubDate>Wed, 18 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Li-wen Zhou, Min Tang, Ya-ling Yi, Yao-Jia Zhang</dc:creator>
    </item>
    <item>
      <title>Improved conditional gradient method for the generalized cone order optimization problem on the local sphere</title>
      <link>https://arxiv.org/abs/2412.12899</link>
      <description>arXiv:2412.12899v1 Announce Type: new 
Abstract: In this paper, a generalized optimization problem on the local sphere is established by the cone order relation on the tangent space, and solved by an improved conditional gradient method (for short, ICGM). The auxiliary subproblems are constructed by the directed distance function on the tangent space, the iteration step size is updated by the Armijo rule, and the convergence of the ICGM is proved without the convexity of the objective function. Under the assumption of convexity, the clusters of the sequence generated by the ICGM are proved to be the spherical weakly Pareto solutions (also known as weakly efficient solutions) of this problem .</description>
      <guid isPermaLink="false">oai:arXiv.org:2412.12899v1</guid>
      <category>math.OC</category>
      <pubDate>Wed, 18 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Li-wen Zhou, Min Tang, Ya-ling Yi, Yao-Jia Zhang</dc:creator>
    </item>
    <item>
      <title>Certified Model Predictive Control for Switched Evolution Equations using Model Order Reduction</title>
      <link>https://arxiv.org/abs/2412.12930</link>
      <description>arXiv:2412.12930v1 Announce Type: new 
Abstract: We present a model predictive control (MPC) framework for linear switched evolution equations arising from a parabolic partial differential equation (PDE). First-order optimality conditions for the resulting finite-horizon optimal control problems are derived. The analysis allows for the incorporation of convex control constraints and sparse regularization. Then, to mitigate the computational burden of the MPC procedure, we employ Galerkin reduced-order modeling (ROM) techniques to obtain a low-dimensional surrogate for the state-adjoint systems. We derive recursive a-posteriori estimates for the ROM feedback law and the ROM-MPC closed-loop state and show that the ROM-MPC trajectory evolves within a neighborhood of the true MPC trajectory, whose size can be explicitly computed and is controlled by the quality of the ROM. Such estimates are then used to formulate two ROM-MPC algorithms with closed-loop certification.</description>
      <guid isPermaLink="false">oai:arXiv.org:2412.12930v1</guid>
      <category>math.OC</category>
      <category>cs.NA</category>
      <category>math.NA</category>
      <pubDate>Wed, 18 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Michael Kartmann, Mattia Manucci, Benjamin Unger, Stefan Volkwein</dc:creator>
    </item>
    <item>
      <title>Online optimisation for dynamic electrical impedance tomography</title>
      <link>https://arxiv.org/abs/2412.12944</link>
      <description>arXiv:2412.12944v1 Announce Type: new 
Abstract: Online optimisation studies the convergence of optimisation methods as the data embedded in the problem changes. Based on this idea, we propose a primal dual online method for nonlinear time-discrete inverse problems. We analyse the method through regret theory and demonstrate its performance in real-time monitoring of moving bodies in a fluid with Electrical Impedance Tomography (EIT). To do so, we also prove the second-order differentiability of the Complete Electrode Model (CEM) solution operator on $L^\infty$.</description>
      <guid isPermaLink="false">oai:arXiv.org:2412.12944v1</guid>
      <category>math.OC</category>
      <category>cs.CV</category>
      <pubDate>Wed, 18 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Neil Dizon, Jyrki Jauhiainen, Tuomo Valkonen</dc:creator>
    </item>
    <item>
      <title>The exact subgraph hierarchy and its local variant for the stable set problem for Paley graphs</title>
      <link>https://arxiv.org/abs/2412.12958</link>
      <description>arXiv:2412.12958v1 Announce Type: new 
Abstract: The stability number of a graph, defined as the cardinality of the largest set of pairwise non-adjacent vertices, is NP-hard to compute. The exact subgraph hierarchy (ESH) provides a sequence of increasingly tighter upper bounds on the stability number, starting with the Lov\'asz theta function at the first level and including all exact subgraph constraints of subgraphs of order $k$ into the semidefinite program to compute the Lov\'asz theta function at level $k$.
  In this paper, we investigate the ESH for Paley graphs, a class of strongly regular, vertex-transitive graphs. We show that for Paley graphs, the bounds obtained from the ESH remain the Lov\'asz theta function up to a certain threshold level, i.e., the bounds of the ESH do not improve up to a certain level.
  To overcome this limitation, we introduce the local ESH for the stable set problem for vertex-transitive graphs such as Paley graphs. We prove that this new hierarchy provides upper bounds on the stability number of vertex-transitive graphs that are at least as tight as those obtained from the ESH. Additionally, our computational experiments reveal that the local ESH produces superior bounds compared to the ESH for Paley graphs.</description>
      <guid isPermaLink="false">oai:arXiv.org:2412.12958v1</guid>
      <category>math.OC</category>
      <pubDate>Wed, 18 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Elisabeth Gaar, Dunja Pucher</dc:creator>
    </item>
    <item>
      <title>Stochastic interior-point methods for smooth conic optimization with applications</title>
      <link>https://arxiv.org/abs/2412.12987</link>
      <description>arXiv:2412.12987v1 Announce Type: new 
Abstract: Conic optimization plays a crucial role in many machine learning (ML) problems. However, practical algorithms for conic constrained ML problems with large datasets are often limited to specific use cases, as stochastic algorithms for general conic optimization remain underdeveloped. To fill this gap, we introduce a stochastic interior-point method (SIPM) framework for general conic optimization, along with four novel SIPM variants leveraging distinct stochastic gradient estimators. Under mild assumptions, we establish the global convergence rates of our proposed SIPMs, which, up to a logarithmic factor, match the best-known rates in stochastic unconstrained optimization. Finally, our numerical experiments on robust linear regression, multi-task relationship learning, and clustering data streams demonstrate the effectiveness and efficiency of our approach.</description>
      <guid isPermaLink="false">oai:arXiv.org:2412.12987v1</guid>
      <category>math.OC</category>
      <category>cs.AI</category>
      <category>cs.LG</category>
      <pubDate>Wed, 18 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Chuan He, Zhanwang Deng</dc:creator>
    </item>
    <item>
      <title>Strengthened and Faster Linear Approximation to Joint Chance Constraints with Wasserstein Ambiguity</title>
      <link>https://arxiv.org/abs/2412.12992</link>
      <description>arXiv:2412.12992v1 Announce Type: new 
Abstract: Many real-world decision-making problems in energy systems, transportation, and finance have uncertain parameters in their constraints. Wasserstein distributionally robust joint chance constraints (WDRJCC) offer a promising solution by explicitly guaranteeing the probability of the simultaneous satisfaction of multiple constraints. WDRJCC are computationally demanding, and although manageable for small problems, practical applications often demand more tractable approaches -- especially for large-scale and complex problems, such as power system unit commitment problems and multilevel problems with chance-constrained lower levels. To address this, this paper proposes a novel inner-approximation for a specific type of WDRJCC, namely WDRJCC with right-hand-side uncertainties (RHS-WDRJCC). We propose a Strengthened and Faster Linear Approximation (SFLA) by strengthening an existing convex inner-approximation that is equivalent to the worst-case conditional value-at-risk (W-CVaR) method under specific hyperparameters. This strengthening process reduces the number of constraints and tightens the feasible region for ancillary variables, leading to significant computational speedup. Despite the tightening, we prove that the proposed SFLA does not introduce additional conservativeness and can even lead to less conservativeness. The significance and superiority of the proposed SFLA are validated in two important real-world problems. In a power system unit commitment problem, the proposed SFLA achieves up to 10x and on average 3.8x computational speedup compared to the strengthened and exact mixed-integer reformulation in finding comparable high-quality feasible solutions. In a bilevel strategic bidding problem where the exact reformulation is not applicable due to non-convexity, we show that the proposed SFLA can lead to 90x speedup compared to existing convex approximation methods such as W-CVaR.</description>
      <guid isPermaLink="false">oai:arXiv.org:2412.12992v1</guid>
      <category>math.OC</category>
      <pubDate>Wed, 18 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Yihong Zhou, Yuxin Xia, Hanbin Yang, Thomas Morstyn</dc:creator>
    </item>
    <item>
      <title>Distributed Normal Map-based Stochastic Proximal Gradient Methods over Networks</title>
      <link>https://arxiv.org/abs/2412.13054</link>
      <description>arXiv:2412.13054v1 Announce Type: new 
Abstract: Consider $n$ agents connected over a network collaborate to minimize the average of their local cost functions combined with a common nonsmooth function. This paper introduces a unified algorithmic framework for solving such a problem through distributed stochastic proximal gradient methods, leveraging the normal map update scheme. Within this framework, we propose two new algorithms, termed Normal Map-based Distributed Stochastic Gradient Tracking (norM-DSGT) and Normal Map-based Exact Diffusion (norM-ED), to solve the distributed composite optimization problem over a connected network. We demonstrate that both methods can asymptotically achieve comparable convergence rates to the centralized stochastic proximal gradient descent method under a general variance condition on the stochastic gradients. Additionally, the number of iterations required for norM-ED to achieve such a rate (i.e., the transient time) behaves as $\mathcal{O}(n^{3}/(1-\lambda)^2)$ for minimizing composite objective functions, matching the performance of the non-proximal ED algorithm. Here $1-\lambda$ denotes the spectral gap of the mixing matrix related to the underlying network topology. To our knowledge, such a convergence result is state-of-the-art for the considered composite problem. Under the same condition, norM-DSGT enjoys a transient time of $\mathcal{O}(\max\{n^3/(1-\lambda)^2, n/(1-\lambda)^4\})$ and behaves more stable than norM-ED under decaying stepsizes for solving the tested problems.</description>
      <guid isPermaLink="false">oai:arXiv.org:2412.13054v1</guid>
      <category>math.OC</category>
      <pubDate>Wed, 18 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Kun Huang, Shi Pu, Angelia Nedi\'c</dc:creator>
    </item>
    <item>
      <title>Polyhedral Control Design: Theory and Methods</title>
      <link>https://arxiv.org/abs/2412.13082</link>
      <description>arXiv:2412.13082v1 Announce Type: new 
Abstract: In this article, we survey the primary research on polyhedral computing methods for constrained linear control systems. Our focus is on the modeling power of convex optimization, featured to design set-based robust and optimal controllers. In detail, we review the state-of-the-art techniques for computing geometric structures such as robust control invariant polytopes. Moreover, we survey recent methods for constructing control Lyapunov functions with polyhedral epigraphs as well as the extensive literature on robust model predictive control. The article concludes with a discussion of both the complexity and potential of polyhedral computing methods that rely on large-scale convex optimization.</description>
      <guid isPermaLink="false">oai:arXiv.org:2412.13082v1</guid>
      <category>math.OC</category>
      <category>cs.SY</category>
      <category>eess.SY</category>
      <pubDate>Wed, 18 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Boris Houska, Matthias A. M\"uller, Mario E. Villanueva</dc:creator>
    </item>
    <item>
      <title>A Pontryagin-Guided Neural Policy Optimization Framework for Merton's Portfolio Problem</title>
      <link>https://arxiv.org/abs/2412.13101</link>
      <description>arXiv:2412.13101v1 Announce Type: new 
Abstract: We present a neural policy optimization framework for Merton's portfolio optimization problem that is rigorously aligned with Pontryagin's Maximum Principle (PMP). Our approach employs a discrete-time, backpropagation-through-time (BPTT)-based gradient method, but unlike conventional data-driven methods, we establish a direct connection to the underlying continuous-time optimality conditions. By approximating adjoint variables from a policy-fixed backward stochastic differential equation (BSDE), we obtain parameter gradients consistent with the PMP framework, all without explicitly solving the PMP-derived BSDE. As the policy parameters are iteratively updated, both the suboptimal adjoint variables and the neural network policies converge almost surely to their PMP-optimal counterparts. This ensures that the final learned policy is not only numerically robust but also provably optimal in the continuous-time sense. Hence, our method provides a theoretically grounded and practically implementable solution that bridges modern deep learning techniques and classical optimal control theory in stochastic settings.</description>
      <guid isPermaLink="false">oai:arXiv.org:2412.13101v1</guid>
      <category>math.OC</category>
      <category>q-fin.MF</category>
      <pubDate>Wed, 18 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Jeonggyu Huh</dc:creator>
    </item>
    <item>
      <title>Acceptable area of optimal control for a multidimensional system</title>
      <link>https://arxiv.org/abs/2412.13125</link>
      <description>arXiv:2412.13125v1 Announce Type: new 
Abstract: A research shows the phase space of the system. The phase space of such a system is determined by the development structure of four subsystems with different objective functions. The control loop of such a system is formed. Using the control loop, optimal control is generated. The dynamic control region is calculated on the basis of a matrix determining the structure of the development of a multidimensional dynamic system. It was established that the optimal distribution by R. Bellman's method allows increasing the increase in the value of the objective function over 5 years by 85% from the initial value with a decrease in the distributed resource by 20%. It is believed that the construction of railways leads to an increase in gross regional product by 2%, but the authors proved that it is possible to increase this figure to 7-8%</description>
      <guid isPermaLink="false">oai:arXiv.org:2412.13125v1</guid>
      <category>math.OC</category>
      <pubDate>Wed, 18 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <arxiv:DOI>10.1088/1742-6596/1679/2/022091</arxiv:DOI>
      <arxiv:journal_reference>J. Phys.: Conf. Ser. 1679 022091 (2020)</arxiv:journal_reference>
      <dc:creator>Sergey Masaev, Georgiy Dorrer, Vladimir Cyganov</dc:creator>
    </item>
    <item>
      <title>Moment-sos and spectral hierarchies for polynomial optimization on the sphere and quantum de Finetti theorems</title>
      <link>https://arxiv.org/abs/2412.13191</link>
      <description>arXiv:2412.13191v1 Announce Type: new 
Abstract: We revisit the convergence analysis of two approximation hierarchies for polynomial optimization on the unit sphere. The first one is based on the moment-sos approach and gives semidefinite bounds for which Fang and Fawzi (2021) showed an analysis in $O(1/r^2)$ for the r-th level bound, using the polynomial kernel method. The second hierarchy was recently proposed by Lovitz and Johnston (2023) and gives spectral bounds for which they show a convergence rate in $O(1/r)$, using a quantum de Finetti theorem of Christandl et al. (2007) that applies to complex Hermitian matrices with a "double" symmetry. We investigate links between these approaches, in particular, via duality of moments and sums of squares. We also propose another proof for the analysis of the spectral bounds, via a "banded" real de Finetti theorem, and show that the spectral bounds cannot have a convergence rate better than $O(1/r^2)$. In addition, we show how to use the polynomial kernel method to obtain a de Finetti type result for real maximally symmetric matrices, improving an earlier result of Doherty and Wehner (2012).</description>
      <guid isPermaLink="false">oai:arXiv.org:2412.13191v1</guid>
      <category>math.OC</category>
      <pubDate>Wed, 18 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Alexander Taveira Blomenhofer, Monique Laurent</dc:creator>
    </item>
    <item>
      <title>Linear Equations with Min and Max Operators: Computational Complexity</title>
      <link>https://arxiv.org/abs/2412.12228</link>
      <description>arXiv:2412.12228v1 Announce Type: cross 
Abstract: We consider a class of optimization problems defined by a system of linear equations with min and max operators. This class of optimization problems has been studied under restrictive conditions, such as, (C1) the halting or stability condition; (C2) the non-negative coefficients condition; (C3) the sum up to 1 condition; and (C4) the only min or only max oerator condition. Several seminal results in the literature focus on special cases. For example, turn-based stochastic games correspond to conditions C2 and C3; and Markov decision process to conditions C2, C3, and C4. However, the systematic computational complexity study of all the cases has not been explored, which we address in this work. Some highlights of our results are: with conditions C2 and C4, and with conditions C3 and C4, the problem is NP-complete, whereas with condition C1 only, the problem is in UP intersects coUP. Finally, we establish the computational complexity of the decision problem of checking the respective conditions.</description>
      <guid isPermaLink="false">oai:arXiv.org:2412.12228v1</guid>
      <category>cs.CC</category>
      <category>cs.AI</category>
      <category>math.OC</category>
      <pubDate>Wed, 18 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Krishnendu Chatterjee, Ruichen Luo, Raimundo Saona, Jakub Svoboda</dc:creator>
    </item>
    <item>
      <title>Positivity of state, trace, and moment polynomials, and applications in quantum information</title>
      <link>https://arxiv.org/abs/2412.12342</link>
      <description>arXiv:2412.12342v1 Announce Type: cross 
Abstract: State, trace, and moment polynomials are polynomial expressions in several operator or random variables and positive functionals on their products (states, traces or expectations). While these concepts, and in particular their positivity and optimization, arose from problems in quantum information theory, yet they naturally fit under the umbrella of multivariate operator theory. This survey presents state, trace, and moment polynomials in a concise and unified way, and highlights their similarities and differences. The focal point is their positivity and optimization. Sums of squares certificates for unconstrained and constrained positivity (Positivstellens\"atze) are given, and parallels with their commutative and freely noncommutative analogs are discussed. They are used to design a convergent hierarchy of semidefinite programs for optimization of state, trace, and moment polynomials. Finally, circling back to the original motivation behind the derived theory, multiple applications in quantum information theory are outlined.</description>
      <guid isPermaLink="false">oai:arXiv.org:2412.12342v1</guid>
      <category>quant-ph</category>
      <category>math.FA</category>
      <category>math.OC</category>
      <pubDate>Wed, 18 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Felix Huber, Victor Magron, Jurij Vol\v{c}i\v{c}</dc:creator>
    </item>
    <item>
      <title>The suboptimality ratio of projective measurements restricted to low-rank subspaces</title>
      <link>https://arxiv.org/abs/2412.12413</link>
      <description>arXiv:2412.12413v1 Announce Type: cross 
Abstract: Limitations in measurement instruments can hinder the implementation of some quantum algorithms. Understanding the suboptimality of such measurements with restrictions may then lead to more efficient measurement policies. In this paper, we theoretically examine the suboptimality arising from a Procrustes problem for minimizing the average distance between two fixed quantum states when one of the states has been measured by a Projective Measurement (PM). Specifically, we compare optima when we can only use PMs that are aligned with a low-rank subspace where the quantum states are supported, and when we can measure with the full set of PMs. For this problem, we show that the suboptimality ratio is independent of the dimension of the full space, and is at most polylogarithmic in the dimension of the low-rank subspace. In the proof of this result, we use a probabilistic approach and the main techniques include trace inequalities related to projective measurements, and operator norm bounds for equipartitions of Parseval frames, which are of independent interest.</description>
      <guid isPermaLink="false">oai:arXiv.org:2412.12413v1</guid>
      <category>quant-ph</category>
      <category>math.OC</category>
      <category>math.PR</category>
      <pubDate>Wed, 18 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Albert Senen-Cerda</dc:creator>
    </item>
    <item>
      <title>SOR-like iteration and FPI are consistent when they are equipped with certain optimal iterative parameters</title>
      <link>https://arxiv.org/abs/2412.12608</link>
      <description>arXiv:2412.12608v1 Announce Type: cross 
Abstract: Two common methods for solving absolute value equations (AVE) are SOR-like iteration method and fixed point iteration (FPI) method. In this paper, novel convergence analysis, which result wider convergence range, of the SOR-like iteration and the FPI are given. Based on the new analysis, a new optimal iterative parameter with a analytical form is obtained for the SOR-like iteration. In addition, an optimal iterative parameter with a analytical form is also obtained for FPI. Surprisingly, the SOR-like iteration and the FPI are the same whenever they are equipped with our optimal iterative parameters. As a by product, we give two new constructive proof for a well known sufficient condition such that AVE has a unique solution for any right hand side. Numerical results demonstrate our claims.</description>
      <guid isPermaLink="false">oai:arXiv.org:2412.12608v1</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <category>math.OC</category>
      <pubDate>Wed, 18 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Jiayu Liu, Tingting Luo, Cairong Chen, Deren Han</dc:creator>
    </item>
    <item>
      <title>Lagrangian Index Policy for Restless Bandits with Average Reward</title>
      <link>https://arxiv.org/abs/2412.12641</link>
      <description>arXiv:2412.12641v1 Announce Type: cross 
Abstract: We study the Lagrangian Index Policy (LIP) for restless multi-armed bandits with long-run average reward. In particular, we compare the performance of LIP with the performance of the Whittle Index Policy (WIP), both heuristic policies known to be asymptotically optimal under certain natural conditions. Even though in most cases their performances are very similar, in the cases when WIP shows bad performance, LIP continues to perform very well. We then propose reinforcement learning algorithms, both tabular and NN-based, to obtain online learning schemes for LIP in the model-free setting. The proposed reinforcement learning schemes for LIP requires significantly less memory than the analogous scheme for WIP. We calculate analytically the Lagrangian index for the restart model, which describes the optimal web crawling and the minimization of the weighted age of information. We also give a new proof of asymptotic optimality in case of homogeneous bandits as the number of arms goes to infinity, based on exchangeability and de Finetti's theorem.</description>
      <guid isPermaLink="false">oai:arXiv.org:2412.12641v1</guid>
      <category>cs.LG</category>
      <category>cs.AI</category>
      <category>math.OC</category>
      <category>math.PR</category>
      <pubDate>Wed, 18 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Konstantin Avrachenkov, Vivek S. Borkar, Pratik Shah</dc:creator>
    </item>
    <item>
      <title>Differential Games for a Mixed ODE-PDE System</title>
      <link>https://arxiv.org/abs/2412.12712</link>
      <description>arXiv:2412.12712v1 Announce Type: cross 
Abstract: Motivated by a vaccination coverage problem, we consider here a zero-sum differential game governed by a differential system consisting of a hyperbolic partial differential equation (PDE) and an ordinary differential equation (ODE). Two players act through their respective controls to influence the evolution of the system with the aim of minimizing their objective functionals $\mathcal F_1$ and $\mathcal F_2$, under the assumption that $\mathcal F_1 +\mathcal F_2 = 0$. First we prove a well posedness and a stability result for the differential system, once the control functions are fixed. Then we introduce the concept of non-anticipating strategies for both players and we consider the associated value functions, which solve two infinite-dimensional Hamilton-Jacobi-Isaacs equations in the viscosity sense.</description>
      <guid isPermaLink="false">oai:arXiv.org:2412.12712v1</guid>
      <category>math.AP</category>
      <category>math.OC</category>
      <pubDate>Wed, 18 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Mauro Garavello, Elena Rossi, Abraham Sylla</dc:creator>
    </item>
    <item>
      <title>Subdifferentials and penalty approximations of the obstacle problem</title>
      <link>https://arxiv.org/abs/2412.13029</link>
      <description>arXiv:2412.13029v1 Announce Type: cross 
Abstract: We consider a framework for approximating the obstacle problem through a penalty approach by nonlinear PDEs. By using tools from capacity theory, we show that derivatives of the solution maps of the penalised problems converge in the weak operator topology to an element of the strong-weak Bouligand subdifferential. We are able to treat smooth penalty terms as well as nonsmooth ones involving for example the positive part function $\max(0,\cdot)$. Our abstract framework applies to several specific choices of penalty functions which are omnipresent in the literature. We conclude with consequences to the theory of optimal control of the obstacle problem.</description>
      <guid isPermaLink="false">oai:arXiv.org:2412.13029v1</guid>
      <category>math.AP</category>
      <category>math.OC</category>
      <pubDate>Wed, 18 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Amal Alphonse, Gerd Wachsmuth</dc:creator>
    </item>
    <item>
      <title>Adaptive Economic Model Predictive Control: Performance Guarantees for Nonlinear Systems</title>
      <link>https://arxiv.org/abs/2412.13046</link>
      <description>arXiv:2412.13046v1 Announce Type: cross 
Abstract: We consider the problem of optimizing the economic performance of nonlinear constrained systems subject to uncertain time-varying parameters and bounded disturbances. In particular, we propose an adaptive economic model predictive control (MPC) framework that: (i) directly minimizes transient economic costs, (ii) addresses parametric uncertainty through online model adaptation, (iii) determines optimal setpoints online, and (iv) ensures robustness by using a tube-based approach. The proposed design ensures recursive feasibility, robust constraint satisfaction, and a transient performance bound. In case the disturbances have a finite energy and the parameter variations have a finite path length, the asymptotic average performance is (approximately) not worse than the performance obtained when operating at the best reachable steady-state. We highlight performance benefits in a numerical example involving a chemical reactor with unknown time-invariant and time-varying parameters.</description>
      <guid isPermaLink="false">oai:arXiv.org:2412.13046v1</guid>
      <category>eess.SY</category>
      <category>cs.SY</category>
      <category>math.OC</category>
      <pubDate>Wed, 18 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Maximilian Degner, Raffaele Soloperto, Melanie N. Zeilinger, John Lygeros, Johannes K\"ohler</dc:creator>
    </item>
    <item>
      <title>Regularity lost: the fundamental limitations and constraint qualifications in the problems of elastoplasticity</title>
      <link>https://arxiv.org/abs/2412.13068</link>
      <description>arXiv:2412.13068v1 Announce Type: cross 
Abstract: We investigate the existence and non-existence of a function-valued strain solution in various models of elastoplasticity from the perspective of the constraint-based ``dual'' formulations. We describe abstract frameworks for linear elasticity, elasticity-perfect plasticity and elasticity-hardening plasticity in terms of adjoint linear operators and convert them to equivalent formulations in terms of differential inclusions (the sweeping process in particular). Within such frameworks we consider several manually solvable examples of discrete and continuous models. Despite their simplicity, the examples show how for discrete models with perfect plasticity it is possible to find the evolution of stress and strain (elongation), yet continuum models within the same framework may not possess a function-valued strain. Although some examples with such phenomenon are already known, we demonstrate that it may appear due to displacement loading. The central idea of the paper is to explain the loss of strain regularity in the dual formulation by the lack of additivity of the normal cones and the failure of Slater's constraint qualification.
  In contrast to perfect plasticity, models with hardening are known to be well-solvable for strains. We show that more advanced constraint qualifications can help to distinguish between those cases and, in the case of hardening, ensure the additivity of the normal cones, which means the existence of a function-valued strain rate.</description>
      <guid isPermaLink="false">oai:arXiv.org:2412.13068v1</guid>
      <category>math.AP</category>
      <category>math-ph</category>
      <category>math.DS</category>
      <category>math.FA</category>
      <category>math.MP</category>
      <category>math.OC</category>
      <pubDate>Wed, 18 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Ivan Gudoshnikov</dc:creator>
    </item>
    <item>
      <title>Active learning for anti-disturbance dual control of unknown nonlinear systems</title>
      <link>https://arxiv.org/abs/2212.08934</link>
      <description>arXiv:2212.08934v2 Announce Type: replace 
Abstract: This work concerns the control of unknown nonlinear systems corrupted by disturbances. For such systems, we propose an anti-disturbance dual control approach with active learning of the disturbances. Our approach holds the dual property of handling the two tasks simultaneously and iteratively: (i) learn the disturbances affecting the system and (ii) drive the system output towards a reference trajectory. Particularly, we model nonlinear system dynamics using a specialized neural network (SNN). This SNN formulates the disturbances via the designed additive and multiplicative disturbance components. We consider both additive and multiplicative disturbances for precise description and recognition of disturbance profile. We achieve the disturbance recognition in the SNN via the design of a Bayesian-based active learning approach, which allows the disturbance learning to be decoupled from the control law derivation. Such a decoupling contributes to the control robustness in the existence of varying and abrupt disturbances. We derive the dual control law based on the active learning of the SNN, and validate our approach via one-time and Monte Carlo simulations. The results demonstrate a fast disturbance recognition by our method in real-time and the robustness of control of unknown systems with abrupt disturbances. We evaluate our approach on the speed control of high-speed train, and the results manifest efficient control of the train speed with disturbance resilience, without prior knowledge about the train dynamics and the disturbances imposed on the train. We openly released the code for this work for reproduction purpose.</description>
      <guid isPermaLink="false">oai:arXiv.org:2212.08934v2</guid>
      <category>math.OC</category>
      <pubDate>Wed, 18 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Xuehui Ma, Shiliang Zhang, Fucai Qian, Jinbao Wang, Yushuai Li</dc:creator>
    </item>
    <item>
      <title>Temporal Parallelisation of the HJB Equation and Continuous-Time Linear Quadratic Control</title>
      <link>https://arxiv.org/abs/2212.11744</link>
      <description>arXiv:2212.11744v2 Announce Type: replace 
Abstract: This paper presents a mathematical formulation to perform temporal parallelisation of continuous-time optimal control problems, which can be solved via the Hamilton--Jacobi--Bellman (HJB) equation. We divide the time interval of the control problem into sub-intervals, and define a control problem in each sub-interval, conditioned on the start and end states, leading to conditional value functions for the sub-intervals. By defining an associative operator as the minimisation of the sum of conditional value functions, we obtain the elements and associative operators for a parallel associative scan operation. This allows for solving the optimal control problem on the whole time interval in parallel in logarithmic time complexity in the number of sub-intervals. We derive the HJB-type of backward and forward equations for the conditional value functions and solve them in closed form for linear quadratic problems. We also discuss numerical methods for computing the conditional value functions. The computational advantages of the proposed parallel methods are demonstrated via simulations run on a multi-core central processing unit and a graphics processing unit.</description>
      <guid isPermaLink="false">oai:arXiv.org:2212.11744v2</guid>
      <category>math.OC</category>
      <category>cs.DC</category>
      <pubDate>Wed, 18 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Simo S\"arkk\"a, \'Angel F. Garc\'ia-Fern\'andez</dc:creator>
    </item>
    <item>
      <title>A Constrained Optimisation Framework for Parameter Identification of the SIRD Model</title>
      <link>https://arxiv.org/abs/2310.11162</link>
      <description>arXiv:2310.11162v3 Announce Type: replace 
Abstract: We consider a numerical framework tailored to identifying optimal parameters in the context of modelling disease propagation. Our focus is on understanding the behaviour of optimisation algorithms for such problems, where the dynamics are described by a system of ordinary differential equations associated with the epidemiological SIRD model. Applying an optimise-then-discretise approach, we examine properties of the solution operator and determine existence of optimal parameters for the problem considered. Further, first-order optimality conditions are derived, the solution of which provides a certificate of goodness of fit, which is not always guaranteed with parameter tuning techniques. We then propose strategies for the numerical solution of such problems, based on projected gradient descent, Fast Iterative Shrinkage-Thresholding Algorithm (FISTA), nonmonotone Accelerated Proximal Gradient (nmAPG), and limited memory BFGS trust region approaches. We carry out a thorough computational study for a range of problems of interest, determining the relative performance of these numerical methods. Our results provide insights into the effectiveness of these strategies, contributing to ongoing research into optimising parameters for accurate and reliable disease spread modelling. Moreover, our approach paves the way for calibration of more intricate compartmental models.</description>
      <guid isPermaLink="false">oai:arXiv.org:2310.11162v3</guid>
      <category>math.OC</category>
      <pubDate>Wed, 18 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Andr\'es Miniguano-Trujillo, John W. Pearson, Benjamin D. Goddard</dc:creator>
    </item>
    <item>
      <title>Second-order conditions for spatio-temporally sparse optimal control via second subderivatives</title>
      <link>https://arxiv.org/abs/2311.14538</link>
      <description>arXiv:2311.14538v3 Announce Type: replace 
Abstract: We address second-order optimality conditions for optimal control problems involving sparsity functionals which induce spatio-temporal sparsity patterns. We employ the notion of (weak) second subderivatives. With this approach, we are able to reproduce the results from Casas, Herzog, and Wachsmuth (ESAIM COCV, 23, 2017, p. 263-295). Our analysis yields a slight improvement of one of these results and also opens the door for the sensitivity analysis of this class of problems.</description>
      <guid isPermaLink="false">oai:arXiv.org:2311.14538v3</guid>
      <category>math.OC</category>
      <pubDate>Wed, 18 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <arxiv:DOI>10.46298/jnsao-2024-12604</arxiv:DOI>
      <arxiv:journal_reference>Journal of Nonsmooth Analysis and Optimization, Vol 5, 2024</arxiv:journal_reference>
      <dc:creator>Nicolas Borchard, Gerd Wachsmuth</dc:creator>
    </item>
    <item>
      <title>Risk-Aware Control of Discrete-Time Stochastic Systems: Integrating Kalman Filter and Worst-case CVaR in Control Barrier Functions</title>
      <link>https://arxiv.org/abs/2312.15638</link>
      <description>arXiv:2312.15638v3 Announce Type: replace 
Abstract: This paper proposes control approaches for discrete-time linear systems subject to stochastic disturbances. It employs Kalman filter to estimate the mean and covariance of the state propagation, and the worst-case conditional value-at-risk (CVaR) to quantify the tail risk using the estimated mean and covariance. The quantified risk is then integrated into a control barrier function (CBF) to derive constraints for controller synthesis, addressing tail risks near safe set boundaries. Two optimization-based control methods are presented using the obtained constraints for half-space and ellipsoidal safe sets, respectively. The effectiveness of the obtained results is demonstrated using numerical simulations.</description>
      <guid isPermaLink="false">oai:arXiv.org:2312.15638v3</guid>
      <category>math.OC</category>
      <category>cs.SY</category>
      <category>eess.SY</category>
      <pubDate>Wed, 18 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Masako Kishida</dc:creator>
    </item>
    <item>
      <title>Transport maps as flows of control-affine systems</title>
      <link>https://arxiv.org/abs/2404.12793</link>
      <description>arXiv:2404.12793v3 Announce Type: replace 
Abstract: We consider the problem of transporting two probability measures with the flow of a driftless control-affine system. Under suitable regularity conditions, the controllability of the system by means of open-loop controls is a sufficient condition for the existence of time-varying feedback controls such that the flow of the system is the optimal transport map, for the $2$-Wasserstein distance, between the two given probability measures. The main ingredient is a controllability result of the continuity equation.</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.12793v3</guid>
      <category>math.OC</category>
      <pubDate>Wed, 18 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Marco Caponigro, Arianna Vicari</dc:creator>
    </item>
    <item>
      <title>Global optimality conditions for sensor placement, with extensions to binary A-optimal experimental designs</title>
      <link>https://arxiv.org/abs/2410.16590</link>
      <description>arXiv:2410.16590v4 Announce Type: replace 
Abstract: We investigate optimality conditions for the sensor placement problem within optimal experimental design, wherein one must decide on the optimal manner in which a fixed number of sensors can be arranged over a large number of candidate locations. By a subgradient argument, we obtain sufficient and necessary conditions for global optimality of the relaxed problem, and demonstrate how one can take advantage of this optimality criterion to approximate optimal binary designs, i.e.~designs where no fractions of sensors are placed. To demonstrate our optimality criteria-based results, we derive a trace-free, efficient formulation of the gradient of the A-optimal objective for finite element-discretised function space settings, and study globally optimal designs for a Helmholtz-type source problem and extensions towards optimal binary designs.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.16590v4</guid>
      <category>math.OC</category>
      <pubDate>Wed, 18 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Christian Aarset</dc:creator>
    </item>
    <item>
      <title>Optimal two-parameter portfolio management strategy with transaction costs</title>
      <link>https://arxiv.org/abs/2411.07949</link>
      <description>arXiv:2411.07949v2 Announce Type: replace 
Abstract: We consider a simplified model for optimizing a single-asset portfolio in the presence of transaction costs given a signal with a certain autocorrelation and cross-correlation structure. In our setup, the portfolio manager is given two one-parameter controls to influence the construction of the portfolio. The first is a linear filtering parameter that may increase or decrease the level of autocorrelation in the signal. The second is a numerical threshold that determines a symmetric "no-trade" zone. Portfolio positions are constrained to a single unit long or a single unit short. These constraints allow us to focus on the interplay between the signal filtering mechanism and the hysteresis introduced by the "no-trade" zone. We then formulate an optimization problem where we aim to minimize the frequency of trades subject to a fixed return level of the portfolio. We show that maintaining a no-trade zone while removing autocorrelation entirely from the signal yields a locally optimal solution. For any given "no-trade" zone threshold, this locally optimal solution also achieves the maximum attainable return level, and we derive a quantitative lower bound for the amount of improvement in terms of the given threshold and the amount of autocorrelation removed.</description>
      <guid isPermaLink="false">oai:arXiv.org:2411.07949v2</guid>
      <category>math.OC</category>
      <category>math.PR</category>
      <category>q-fin.PM</category>
      <pubDate>Wed, 18 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Chutian Ma, Paul Smith</dc:creator>
    </item>
    <item>
      <title>SPARKLE: A Unified Single-Loop Primal-Dual Framework for Decentralized Bilevel Optimization</title>
      <link>https://arxiv.org/abs/2411.14166</link>
      <description>arXiv:2411.14166v3 Announce Type: replace 
Abstract: This paper studies decentralized bilevel optimization, in which multiple agents collaborate to solve problems involving nested optimization structures with neighborhood communications. Most existing literature primarily utilizes gradient tracking to mitigate the influence of data heterogeneity, without exploring other well-known heterogeneity-correction techniques such as EXTRA or Exact Diffusion. Additionally, these studies often employ identical decentralized strategies for both upper- and lower-level problems, neglecting to leverage distinct mechanisms across different levels. To address these limitations, this paper proposes SPARKLE, a unified Single-loop Primal-dual AlgoRithm frameworK for decentraLized bilEvel optimization. SPARKLE offers the flexibility to incorporate various heterogeneitycorrection strategies into the algorithm. Moreover, SPARKLE allows for different strategies to solve upper- and lower-level problems. We present a unified convergence analysis for SPARKLE, applicable to all its variants, with state-of-the-art convergence rates compared to existing decentralized bilevel algorithms. Our results further reveal that EXTRA and Exact Diffusion are more suitable for decentralized bilevel optimization, and using mixed strategies in bilevel algorithms brings more benefits than relying solely on gradient tracking.</description>
      <guid isPermaLink="false">oai:arXiv.org:2411.14166v3</guid>
      <category>math.OC</category>
      <category>cs.LG</category>
      <category>stat.ML</category>
      <pubDate>Wed, 18 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Shuchen Zhu, Boao Kong, Songtao Lu, Xinmeng Huang, Kun Yuan</dc:creator>
    </item>
    <item>
      <title>Inexact Proximal Point Algorithms for Zeroth-Order Global Optimization</title>
      <link>https://arxiv.org/abs/2412.11485</link>
      <description>arXiv:2412.11485v2 Announce Type: replace 
Abstract: This work concerns the zeroth-order global minimization of continuous nonconvex functions with a unique global minimizer and possibly multiple local minimizers. We formulate a theoretical framework for inexact proximal point (IPP) methods for global optimization, establishing convergence guarantees under mild assumptions when either deterministic or stochastic estimates of proximal operators are used. The quadratic regularization in the proximal operator and the scaling effect of a parameter $\delta&gt;0$ create a concentrated landscape of an associated Gibbs measure that is practically effective for sampling. The convergence of the expectation under the Gibbs measure as $\delta\to 0^+$ is established, and the convergence rate of $\mathcal O(\delta)$ is derived under additional assumptions. These results provide a theoretical foundation for evaluating proximal operators inexactly using sampling-based methods such as Monte Carlo (MC) integration. In addition, we propose a new approach based on tensor train (TT) approximation. This approach employs a randomized TT cross algorithm to efficiently construct a low-rank TT approximation of a discretized function using a small number of function evaluations, and we provide an error analysis for the TT-based estimation. We then propose two practical IPP algorithms, TT-IPP and MC-IPP. The TT-IPP algorithm leverages TT estimates of the proximal operators, while the MC-IPP algorithm employs MC integration to estimate the proximal operators. Both algorithms are designed to adaptively balance efficiency and accuracy in inexact evaluations of proximal operators. The effectiveness of the two algorithms is demonstrated through experiments on diverse benchmark functions and various applications.</description>
      <guid isPermaLink="false">oai:arXiv.org:2412.11485v2</guid>
      <category>math.OC</category>
      <pubDate>Wed, 18 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Minxin Zhang, Fuqun Han, Yat Tin Chow, Stanley Osher, Hayden Schaeffer</dc:creator>
    </item>
    <item>
      <title>Accelerating nuclear-norm regularized low-rank matrix optimization through Burer-Monteiro decomposition</title>
      <link>https://arxiv.org/abs/2204.14067</link>
      <description>arXiv:2204.14067v3 Announce Type: replace-cross 
Abstract: This work proposes a rapid algorithm, BM-Global, for nuclear-norm-regularized convex and low-rank matrix optimization problems. BM-Global efficiently decreases the objective value via low-cost steps leveraging the nonconvex but smooth Burer-Monteiro (BM) decomposition, while effectively escapes saddle points and spurious local minima ubiquitous in the BM form to obtain guarantees of fast convergence rates to the global optima of the original nuclear-norm-regularized problem through aperiodic inexact proximal gradient steps on it. The proposed approach adaptively adjusts the rank for the BM decomposition and can provably identify an optimal rank for the BM decomposition problem automatically in the course of optimization through tools of manifold identification. BM-Global hence also spends significantly less time on parameter tuning than existing matrix-factorization methods, which require an exhaustive search for finding this optimal rank. Extensive experiments on real-world large-scale problems of recommendation systems, regularized kernel estimation, and molecular conformation confirm that BM-Global can indeed effectively escapes spurious local minima at which existing BM approaches are stuck, and is a magnitude faster than state-of-the-art algorithms for low-rank matrix optimization problems involving a nuclear-norm regularizer. Based on this research, we have released an open-source package of the proposed BM-Global at https://www.github.com/leepei/BM-Global/.</description>
      <guid isPermaLink="false">oai:arXiv.org:2204.14067v3</guid>
      <category>cs.LG</category>
      <category>math.OC</category>
      <pubDate>Wed, 18 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <arxiv:journal_reference>Journal of Machine Learning Research 2024</arxiv:journal_reference>
      <dc:creator>Ching-pei Lee, Ling Liang, Tianyun Tang, Kim-Chuan Toh</dc:creator>
    </item>
    <item>
      <title>Differential Privacy via Distributionally Robust Optimization</title>
      <link>https://arxiv.org/abs/2304.12681</link>
      <description>arXiv:2304.12681v3 Announce Type: replace-cross 
Abstract: In recent years, differential privacy has emerged as the de facto standard for sharing statistics of datasets while limiting the disclosure of private information about the involved individuals. This is achieved by randomly perturbing the statistics to be published, which in turn leads to a privacy-accuracy trade-off: larger perturbations provide stronger privacy guarantees, but they result in less accurate statistics that offer lower utility to the recipients. Of particular interest are therefore optimal mechanisms that provide the highest accuracy for a pre-selected level of privacy. To date, work in this area has focused on specifying families of perturbations a priori and subsequently proving their asymptotic and/or best-in-class optimality. In this paper, we develop a class of mechanisms that enjoy non-asymptotic and unconditional optimality guarantees. To this end, we formulate the mechanism design problem as an infinite-dimensional distributionally robust optimization problem. We show that the problem affords a strong dual, and we exploit this duality to develop converging hierarchies of finite-dimensional upper and lower bounding problems. Our upper (primal) bounds correspond to implementable perturbations whose suboptimality can be bounded by our lower (dual) bounds. Both bounding problems can be solved within seconds via cutting plane techniques that exploit the inherent problem structure. Our numerical experiments demonstrate that our perturbations can outperform the previously best results from the literature on artificial as well as standard benchmark problems.</description>
      <guid isPermaLink="false">oai:arXiv.org:2304.12681v3</guid>
      <category>cs.CR</category>
      <category>cs.LG</category>
      <category>math.OC</category>
      <pubDate>Wed, 18 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Aras Selvi, Huikang Liu, Wolfram Wiesemann</dc:creator>
    </item>
    <item>
      <title>Notes on data-driven output-feedback control of linear MIMO systems</title>
      <link>https://arxiv.org/abs/2311.17484</link>
      <description>arXiv:2311.17484v2 Announce Type: replace-cross 
Abstract: Recent works have approached the data-driven design of dynamic output-feedback controllers for discrete-time LTI systems by constructing non-minimal state vectors composed of past inputs and outputs. Depending on the system's complexity (order $n$, lag $\ell$ and number of outputs $p$), it was observed in several works that such an approach presents significant limitations. In particular, many works require to restrict the class of LTI systems to those satisfying the relation $p\ell=n$. In this note, we show how to address the general MIMO case (for which $p\ell\geq n$ in general) by constructing an alternative non-minimal state vector from data. Different from the existing literature, our method guarantees the satisfaction of certain rank conditions when the system is persistently excited, thereby facilitating the direct data-driven dynamic output-feedback control of MIMO systems by applying methods that were originally developed for the input-state data setting.</description>
      <guid isPermaLink="false">oai:arXiv.org:2311.17484v2</guid>
      <category>eess.SY</category>
      <category>cs.SY</category>
      <category>math.OC</category>
      <pubDate>Wed, 18 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Mohammad Alsalti, Victor G. Lopez, Matthias A. M\"uller</dc:creator>
    </item>
    <item>
      <title>Data Collaboration Analysis with Orthogonal Basis Alignment</title>
      <link>https://arxiv.org/abs/2403.02780</link>
      <description>arXiv:2403.02780v3 Announce Type: replace-cross 
Abstract: The Data Collaboration (DC) framework provides a privacy-preserving solution for multi-source data fusion, enabling the joint analysis of data from multiple sources to achieve enhanced insights. It utilizes linear transformations with secretly selected bases to ensure privacy guarantees through non-iterative communication. Despite its strengths, the DC framework often encounters performance instability due to theoretical challenges in aligning the bases used for mapping raw data. This study addresses these challenges by establishing a rigorous theoretical foundation for basis alignment within the DC framework, formulating it as an optimization problem over orthogonal matrices. Under specific assumptions, we demonstrate that this problem can be reduced to the Orthogonal Procrustes Problem, which has a well-known analytical solution. Extensive empirical evaluations across diverse datasets reveal that the proposed alignment method significantly enhances model performance and computational efficiency, outperforming existing approaches. Additionally, it demonstrates robustness across varying levels of differential privacy, thus enabling practical and reliable implementations of the DC framework.</description>
      <guid isPermaLink="false">oai:arXiv.org:2403.02780v3</guid>
      <category>cs.LG</category>
      <category>math.OC</category>
      <pubDate>Wed, 18 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Keiyu Nosaka, Yuichi Takano, Akiko Yoshise</dc:creator>
    </item>
    <item>
      <title>A Bilevel Optimization Framework for Imbalanced Data Classification</title>
      <link>https://arxiv.org/abs/2410.11171</link>
      <description>arXiv:2410.11171v2 Announce Type: replace-cross 
Abstract: Data rebalancing techniques, including oversampling and undersampling, are a common approach to addressing the challenges of imbalanced data. To tackle unresolved problems related to both oversampling and undersampling, we propose a new undersampling approach that: (i) avoids the pitfalls of noise and overlap caused by synthetic data and (ii) avoids the pitfall of under-fitting caused by random undersampling. Instead of undersampling majority data randomly, our method undersamples datapoints based on their ability to improve model loss. Using improved model loss as a proxy measurement for classification performance, our technique assesses a datapoint's impact on loss and rejects those unable to improve it. In so doing, our approach rejects majority datapoints redundant to datapoints already accepted and, thereby, finds an optimal subset of majority training data for classification. The accept/reject component of our algorithm is motivated by a bilevel optimization problem uniquely formulated to identify the optimal training set we seek. Experimental results show our proposed technique with F1 scores up to 10% higher than state-of-the-art methods.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.11171v2</guid>
      <category>cs.LG</category>
      <category>math.OC</category>
      <category>stat.ML</category>
      <pubDate>Wed, 18 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Karen Medlin, Sven Leyffer, Krishnan Raghavan</dc:creator>
    </item>
  </channel>
</rss>
