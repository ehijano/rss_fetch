<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>cs.DB updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/cs.DB</link>
    <description>cs.DB updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/cs.DB" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Fri, 21 Feb 2025 05:00:02 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Fri, 21 Feb 2025 00:00:00 -0500</pubDate>
    <skipDays>
      <day>Sunday</day>
      <day>Saturday</day>
    </skipDays>
    <item>
      <title>Enhancing Pavement Sensor Data Acquisition for AI-Driven Transportation Research</title>
      <link>https://arxiv.org/abs/2502.14222</link>
      <description>arXiv:2502.14222v1 Announce Type: new 
Abstract: Effective strategies for sensor data management are essential for advancing transportation research, especially in the current data-driven era, due to the advent of novel applications in artificial intelligence. This paper presents comprehensive guidelines for managing transportation sensor data, encompassing both archived static data and real-time data streams. The real-time system architecture integrates various applications with data acquisition systems (DAQ). By deploying the in-house designed, open-source Avena software platform alongside the NATS messaging system as a secure communication broker, reliable data exchange is ensured. While robust databases like TimescaleDB facilitate organized storage, visualization platforms like Grafana provide real-time monitoring capabilities.
  In contrast, static data standards address the challenges in handling unstructured, voluminous datasets. The standards advocate for a combination of cost-effective bulk cloud storage for unprocessed sensor data and relational databases for recording summarized analyses. They highlight the role of cloud data transfer tools like FME for efficient migration of sensor data from local storages onto the cloud. Further, integration of robust visualization tools into the framework helps in deriving patterns and trends from these complex datasets.
  The proposals were applied to INDOT's real-world case studies involving the I-65 and I-69 Greenfield districts. For real-time data collection, Campbell Scientific DAQ systems were used, enabling continuous generation and monitoring of sensor metrics. In the case of the archived I-69 database, summary data was compiled in Oracle, while the unprocessed data was stored in SharePoint. The results underline the effectiveness of the proposed guidelines and motivate their adoption in research projects.</description>
      <guid isPermaLink="false">oai:arXiv.org:2502.14222v1</guid>
      <category>cs.DB</category>
      <category>cs.AI</category>
      <category>eess.SP</category>
      <pubDate>Fri, 21 Feb 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Manish Kumar Krishne Gowda, Andrew Balmos, Shin Boonam, James V. Krogmeier</dc:creator>
    </item>
    <item>
      <title>Optimize Cardinality Estimation Model Pretraining by Simplifying the Training Datasets</title>
      <link>https://arxiv.org/abs/2502.14350</link>
      <description>arXiv:2502.14350v1 Announce Type: new 
Abstract: The cardinality estimation is a key aspect of query optimization research, and its performance has significantly improved with the integration of machine learning. To overcome the "cold start" problem or the lack of model transferability in learned cardinality estimators, some pre-training cardinality estimation models have been proposed that use learning across multiple datasets and corresponding workloads. These models typically train on a dataset created by uniformly sampling from many datasets, but this approach may not be optimal. By applying the Group Distributionally Robust Optimization (Group DRO) algorithm to training datasets, we find that some specific training datasets contribute more significantly to model performance than others. Based on this observation, we conduct extensive experiments to delve deeper into pre-training cardinality estimators. Our results show how the performance of these models can be influenced by the datasets and corresponding workloads. Finally, we introduce a simplified training dataset, which has been reduced to a fraction of the size of existing pretraining datasets. Sufficient experimental results demonstrate that the pre-trained cardinality estimator based on this simplified dataset can still achieve comparable performance to existing models in zero-shot setups.</description>
      <guid isPermaLink="false">oai:arXiv.org:2502.14350v1</guid>
      <category>cs.DB</category>
      <category>cs.LG</category>
      <pubDate>Fri, 21 Feb 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Boyang Fang</dc:creator>
    </item>
    <item>
      <title>SQL4NN: Validation and expressive querying of models as data</title>
      <link>https://arxiv.org/abs/2502.14745</link>
      <description>arXiv:2502.14745v1 Announce Type: new 
Abstract: We consider machine learning models, learned from data, to be an important, intensional, kind of data in themselves. As such, various analysis tasks on models can be thought of as queries over this intensional data, often combined with extensional data such as data for training or validation. We demonstrate that relational database systems and SQL can actually be well suited for many such tasks.</description>
      <guid isPermaLink="false">oai:arXiv.org:2502.14745v1</guid>
      <category>cs.DB</category>
      <category>cs.LG</category>
      <pubDate>Fri, 21 Feb 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Mark Gerarts, Juno Steegmans, Jan Van den Bussche</dc:creator>
    </item>
    <item>
      <title>Real-Time Device Reach Forecasting Using HLL and MinHash Data Sketches</title>
      <link>https://arxiv.org/abs/2502.14785</link>
      <description>arXiv:2502.14785v1 Announce Type: new 
Abstract: Predicting the right number of TVs (Device Reach) in real-time based on a user-specified targeting attributes is imperative for running multi-million dollar ADs business. The traditional approach of SQL queries to join billions of records across multiple targeting dimensions is extremely slow. As a workaround, many applications will have an offline process to crunch these numbers and present the results after many hours. In our case, the solution was an offline process taking 24 hours to onboard a customer resulting in a potential loss of business. To solve this problem, we have built a new real-time prediction system using MinHash and HyperLogLog (HLL) data sketches to compute the device reach at runtime when a user makes a request. However, existing MinHash implementations do not solve the complex problem of multilevel aggregation and intersection. This work will show how we have solved this problem, in addition, we have improved MinHash algorithm to run 4 times faster using Single Instruction Multiple Data (SIMD) vectorized operations for high speed and accuracy with constant space to process billions of records. Finally, by experiments, we prove that the results are as accurate as traditional offline prediction system with an acceptable error rate of 5%.</description>
      <guid isPermaLink="false">oai:arXiv.org:2502.14785v1</guid>
      <category>cs.DB</category>
      <category>cs.AI</category>
      <category>cs.LG</category>
      <pubDate>Fri, 21 Feb 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <arxiv:DOI>10.1109/ISCMI51676.2020.9311573</arxiv:DOI>
      <arxiv:journal_reference>2020 7th Intl. Conference on Soft Computing &amp; Machine Intelligence</arxiv:journal_reference>
      <dc:creator>Chandrashekar Muniyappa, Kendall Willets, Sriraman Krishnamoorthy</dc:creator>
    </item>
    <item>
      <title>dtaianomaly: A Python library for time series anomaly detection</title>
      <link>https://arxiv.org/abs/2502.14381</link>
      <description>arXiv:2502.14381v1 Announce Type: cross 
Abstract: dtaianomaly is an open-source Python library for time series anomaly detection, designed to bridge the gap between academic research and real-world applications. Our goal is to (1) accelerate the development of novel state-of-the-art anomaly detection techniques through simple extensibility; (2) offer functionality for large-scale experimental validation; and thereby (3) bring cutting-edge research to business and industry through a standardized API, similar to scikit-learn to lower the entry barrier for both new and experienced users. Besides these key features, dtaianomaly offers (1) a broad range of built-in anomaly detectors, (2) support for time series preprocessing, (3) tools for visual analysis, (4) confidence prediction of anomaly scores, (5) runtime and memory profiling, (6) comprehensive documentation, and (7) cross-platform unit testing.
  The source code of dtaianomaly, documentation, code examples and installation guides are publicly available at https://github.com/ML-KULeuven/dtaianomaly.</description>
      <guid isPermaLink="false">oai:arXiv.org:2502.14381v1</guid>
      <category>cs.LG</category>
      <category>cs.DB</category>
      <pubDate>Fri, 21 Feb 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Louis Carpentier, Nick Seeuws, Wannes Meert, Mathias Verbeke</dc:creator>
    </item>
    <item>
      <title>eC-Tab2Text: Aspect-Based Text Generation from e-Commerce Product Tables</title>
      <link>https://arxiv.org/abs/2502.14820</link>
      <description>arXiv:2502.14820v1 Announce Type: cross 
Abstract: Large Language Models (LLMs) have demonstrated exceptional versatility across diverse domains, yet their application in e-commerce remains underexplored due to a lack of domain-specific datasets. To address this gap, we introduce eC-Tab2Text, a novel dataset designed to capture the intricacies of e-commerce, including detailed product attributes and user-specific queries. Leveraging eC-Tab2Text, we focus on text generation from product tables, enabling LLMs to produce high-quality, attribute-specific product reviews from structured tabular data. Fine-tuned models were rigorously evaluated using standard Table2Text metrics, alongside correctness, faithfulness, and fluency assessments. Our results demonstrate substantial improvements in generating contextually accurate reviews, highlighting the transformative potential of tailored datasets and fine-tuning methodologies in optimizing e-commerce workflows. This work highlights the potential of LLMs in e-commerce workflows and the essential role of domain-specific datasets in tailoring them to industry-specific challenges.</description>
      <guid isPermaLink="false">oai:arXiv.org:2502.14820v1</guid>
      <category>cs.CL</category>
      <category>cs.AI</category>
      <category>cs.DB</category>
      <category>cs.HC</category>
      <pubDate>Fri, 21 Feb 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Luis Antonio Guti\'errez Guanilo, Mir Tafseer Nayeem, Cristian L\'opez, Davood Rafiei</dc:creator>
    </item>
    <item>
      <title>Dimensionality-Reduction Techniques for Approximate Nearest Neighbor Search: A Survey and Evaluation</title>
      <link>https://arxiv.org/abs/2403.13491</link>
      <description>arXiv:2403.13491v2 Announce Type: replace 
Abstract: Approximate Nearest Neighbor Search (ANNS) on high-dimensional vectors has become a fundamental and essential component in various machine learning tasks. Recently, with the rapid development of deep learning models and the applications of Large Language Models (LLMs), the dimensionality of the vectors keeps growing in order to accommodate a richer semantic representation. This poses a major challenge to the ANNS solutions since distance calculation cost in ANNS grows linearly with the dimensionality of vectors. To overcome this challenge, dimensionality-reduction techniques can be leveraged to accelerate the distance calculation in the search process. In this paper, we investigate six dimensionality-reduction techniques that have the potential to improve ANNS solutions, including classical algorithms such as PCA and vector quantization, as well as algorithms based on deep learning approaches. We further describe two frameworks to apply these techniques in the ANNS workflow, and theoretically analyze the time and space costs, as well as the beneficial threshold for the pruning ratio of these techniques. The surveyed techniques are evaluated on six public datasets. The analysis of the results reveals the characteristics of the different families of techniques and provides insights into the promising future research directions.</description>
      <guid isPermaLink="false">oai:arXiv.org:2403.13491v2</guid>
      <category>cs.DB</category>
      <pubDate>Fri, 21 Feb 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <dc:creator>Zeyu Wang, Haoran Xiong, Qitong Wang, Zhenying He, Peng Wang, Themis Palpanas, Wei Wang</dc:creator>
    </item>
    <item>
      <title>The KnowWhereGraph: A Large-Scale Geo-Knowledge Graph for Interdisciplinary Knowledge Discovery and Geo-Enrichment</title>
      <link>https://arxiv.org/abs/2502.13874</link>
      <description>arXiv:2502.13874v2 Announce Type: replace 
Abstract: Global challenges such as food supply chain disruptions, public health crises, and natural hazard responses require access to and integration of diverse datasets, many of which are geospatial. Over the past few years, a growing number of (geo)portals have been developed to address this need. However, most existing (geo)portals are stacked by separated or sparsely connected data "silos" impeding effective data consolidation. A new way of sharing and reusing geospatial data is therefore urgently needed. In this work, we introduce KnowWhereGraph, a knowledge graph-based data integration, enrichment, and synthesis framework that not only includes schemas and data related to human and environmental systems but also provides a suite of supporting tools for accessing this information. The KnowWhereGraph aims to address the challenge of data integration by building a large-scale, cross-domain, pre-integrated, FAIR-principles-based, and AI-ready data warehouse rooted in knowledge graphs. We highlight the design principles of KnowWhereGraph, emphasizing the roles of space, place, and time in bridging various data "silos". Additionally, we demonstrate multiple use cases where the proposed geospatial knowledge graph and its associated tools empower decision-makers to uncover insights that are often hidden within complex and poorly interoperable datasets.</description>
      <guid isPermaLink="false">oai:arXiv.org:2502.13874v2</guid>
      <category>cs.DB</category>
      <pubDate>Fri, 21 Feb 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Rui Zhu, Cogan Shimizu, Shirly Stephen, Colby K. Fisher, Thomas Thelen, Kitty Currier, Krzysztof Janowicz, Pascal Hitzler, Mark Schildhauer, Wenwen Li, Dean Rehberger, Adrita Barua, Antrea Christou, Ling Cai, Abhilekha Dalal, Anthony D'Onofrio, Andrew Eells, Mitchell Faulk, Zilong Liu, Gengchen Mai, Mohammad Saeid Mahdavinejad, Bryce Mecum, Sanaz Saki Norouzi, Meilin Shi, Yuanyuan Tian, Sizhe Wang, Zhangyu Wang, Joseph Zalewski</dc:creator>
    </item>
  </channel>
</rss>
