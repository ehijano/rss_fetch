<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>cs.MA updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/cs.MA</link>
    <description>cs.MA updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/cs.MA" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Fri, 14 Feb 2025 02:47:32 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Thu, 13 Feb 2025 00:00:00 -0500</pubDate>
    <skipDays>
      <day>Sunday</day>
      <day>Saturday</day>
    </skipDays>
    <item>
      <title>Fresh2comm: Information Freshness Optimized Collaborative Perception</title>
      <link>https://arxiv.org/abs/2502.07852</link>
      <description>arXiv:2502.07852v1 Announce Type: new 
Abstract: Collaborative perception is a cornerstone of intelligent connected vehicles, enabling them to share and integrate sensory data to enhance situational awareness. However, measuring the impact of high transmission delay and inconsistent delay on collaborative perception in real communication scenarios, as well as improving the effectiveness of collaborative perception under such conditions, remain significant challenges in the field. To address these challenges, we incorporate the key factor of information freshness into the collaborative perception mechanism and develop a model that systematically measures and analyzes the impacts of real-world communication on collaborative perception performance. This provides a new perspective for accurately evaluating and optimizing collaborative perception performance. We propose and validate an Age of Information (AoI)-based optimization framework that strategically allocates communication resources to effectively control the system's AoI, thereby significantly enhancing the freshness of information transmission and the accuracy of perception. Additionally, we introduce a novel experimental approach that comprehensively assesses the varying impacts of different types of delay on perception results, offering valuable insights for perception performance optimization under real-world communication scenarios.</description>
      <guid isPermaLink="false">oai:arXiv.org:2502.07852v1</guid>
      <category>cs.MA</category>
      <pubDate>Thu, 13 Feb 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Ziyong Wu (Sino-French Engineer School, Beihang University, Beijing, China), Zhilin Peng (Sino-French Engineer School, Beihang University, Beijing, China), Lei Yu (Sino-French Engineer School, Beihang University, Beijing, China)</dc:creator>
    </item>
    <item>
      <title>PolicySimEval: A Benchmark for Evaluating Policy Outcomes through Agent-Based Simulation</title>
      <link>https://arxiv.org/abs/2502.07853</link>
      <description>arXiv:2502.07853v1 Announce Type: new 
Abstract: With the growing adoption of agent-based models in policy evaluation, a pressing question arises: Can such systems effectively simulate and analyze complex social scenarios to inform policy decisions? Addressing this challenge could significantly enhance the policy-making process, offering researchers and practitioners a systematic way to validate, explore, and refine policy outcomes. To advance this goal, we introduce PolicySimEval, the first benchmark designed to evaluate the capability of agent-based simulations in policy assessment tasks. PolicySimEval aims to reflect the real-world complexities faced by social scientists and policymakers. The benchmark is composed of three categories of evaluation tasks: (1) 20 comprehensive scenarios that replicate end-to-end policy modeling challenges, complete with annotated expert solutions; (2) 65 targeted sub-tasks that address specific aspects of agent-based simulation (e.g., agent behavior calibration); and (3) 200 auto-generated tasks to enable large-scale evaluation and method development. Experiments show that current state-of-the-art frameworks struggle to tackle these tasks effectively, with the highest-performing system achieving only 24.5\% coverage rate on comprehensive scenarios, 15.04\% on sub-tasks, and 14.5\% on auto-generated tasks. These results highlight the difficulty of the task and the gap between current capabilities and the requirements for real-world policy evaluation.</description>
      <guid isPermaLink="false">oai:arXiv.org:2502.07853v1</guid>
      <category>cs.MA</category>
      <category>cs.CY</category>
      <pubDate>Thu, 13 Feb 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Jiaju Kang, Puyu Han, Tian Zhang, Luqi Gong</dc:creator>
    </item>
    <item>
      <title>Symbiotic Cooperation for Web Agents: Harnessing Complementary Strengths of Large and Small LLMs</title>
      <link>https://arxiv.org/abs/2502.07942</link>
      <description>arXiv:2502.07942v1 Announce Type: new 
Abstract: Web browsing agents powered by large language models (LLMs) have shown tremendous potential in automating complex web-based tasks. Existing approaches typically rely on large LLMs (e.g., GPT-4o) to explore web environments and generate trajectory data, which is then used either for demonstration retrieval (for large LLMs) or to distill small LLMs (e.g., Llama3) in a process that remains decoupled from the exploration. In this paper, we propose AgentSymbiotic, an iterative framework that couples data synthesis with task-performance, yielding a "symbiotic improvement" for both large and small LLMs. Our study uncovers a complementary dynamic between LLM types: while large LLMs excel at generating high-quality trajectories for distillation, the distilled small LLMs-owing to their distinct reasoning capabilities-often choose actions that diverge from those of their larger counterparts. This divergence drives the exploration of novel trajectories, thereby enriching the synthesized data. However, we also observe that the performance of small LLMs becomes a bottleneck in this iterative enhancement process. To address this, we propose two innovations in LLM distillation: a speculative data synthesis strategy that mitigates off-policy bias, and a multi-task learning approach designed to boost the reasoning capabilities of the student LLM. Furthermore, we introduce a Hybrid Mode for Privacy Preservation to address user privacy concerns. Evaluated on the WEBARENA benchmark, AgentSymbiotic achieves SOTA performance with both LLM types. Our best Large LLM agent reaches 52%, surpassing the previous best of 45%, while our 8B distilled model demonstrates a competitive 49%, exceeding the prior best of 28%. Code will be released upon acceptance.</description>
      <guid isPermaLink="false">oai:arXiv.org:2502.07942v1</guid>
      <category>cs.MA</category>
      <category>cs.LG</category>
      <pubDate>Thu, 13 Feb 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Ruichen Zhang, Mufan Qiu, Zhen Tan, Mohan Zhang, Vincent Lu, Jie Peng, Kaidi Xu, Leandro Z. Agudelo, Peter Qian, Tianlong Chen</dc:creator>
    </item>
    <item>
      <title>Decentralised multi-agent coordination for real-time railway traffic management</title>
      <link>https://arxiv.org/abs/2502.08324</link>
      <description>arXiv:2502.08324v1 Announce Type: new 
Abstract: The real-time Railway Traffic Management Problem (rtRTMP) is a challenging optimisation problem in railway transportation. It involves the efficient management of train movements while minimising delay propagation caused by unforeseen perturbations due to, e.g, temporary speed limitations or signal failures. This paper re-frames the rtRTMP as a multi-agent coordination problem and formalises it as a Distributed Constraint Optimisation Problem (DCOP) to explore its potential for decentralised solutions. We propose a novel coordination algorithm that extends the widely known Distributed Stochastic Algorithm (DSA), allowing trains to self-organise and resolve scheduling conflicts. The performance of our algorithm is compared to a classical DSA through extensive simulations on a synthetic dataset reproducing diverse problem configurations. Results show that our approach achieves significant improvements in solution quality and convergence speed, demonstrating its effectiveness and scalability in managing large-scale railway networks. Beyond the railway domain, this framework can have broader applicability in autonomous systems, such as self-driving vehicles or inter-satellite coordination.</description>
      <guid isPermaLink="false">oai:arXiv.org:2502.08324v1</guid>
      <category>cs.MA</category>
      <pubDate>Thu, 13 Feb 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Leo D'Amato, Paola Pellegrini, Vito Trianni</dc:creator>
    </item>
    <item>
      <title>Resilient Quantized Consensus in Multi-Hop Relay Networks</title>
      <link>https://arxiv.org/abs/2502.08455</link>
      <description>arXiv:2502.08455v1 Announce Type: new 
Abstract: We study resilient quantized consensus in multi-agent systems, where some agents may malfunction. The network consists of agents taking integer-valued states, and the agents' communication is subject to asynchronous updates and time delays. We utilize the quantized weighted mean subsequence reduced algorithm where agents communicate with others through multi-hop relays. We prove necessary and sufficient conditions for our algorithm to achieve the objective under the malicious and Byzantine attack models. Our approach has tighter graph conditions compared to the one-hop algorithm and the flooding-based algorithms for binary consensus. Numerical examples verify the efficacy of our algorithm.</description>
      <guid isPermaLink="false">oai:arXiv.org:2502.08455v1</guid>
      <category>cs.MA</category>
      <category>cs.SY</category>
      <category>eess.SY</category>
      <pubDate>Thu, 13 Feb 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Liwei Yuan, Hideaki Ishii</dc:creator>
    </item>
    <item>
      <title>WorldGUI: Dynamic Testing for Comprehensive Desktop GUI Automation</title>
      <link>https://arxiv.org/abs/2502.08047</link>
      <description>arXiv:2502.08047v1 Announce Type: cross 
Abstract: Current GUI agents have achieved outstanding performance in GUI element grounding. However, planning remains highly challenging, especially due to sensitivity to the initial state of the environment. Specifically, slight differences in the initial state-such as the target software not being open or the interface not being in its default state-often lead to planning errors. This issue is widespread in real user scenarios, but existing benchmarks fail to evaluate it. In this paper, we present WorldGUI, a novel GUI benchmark that designs GUI tasks with various initial states to simulate real computer-user interactions. The benchmark spans a wide range of tasks across 10 popular software applications, including PowerPoint, VSCode, and Adobe Acrobat. In addition, to address the challenges of dynamic GUI automation tasks, we propose GUI-Thinker, a holistic framework, leveraging a critique mechanism, that effectively manages the unpredictability and complexity of GUI interactions. Experimental results demonstrate that GUI-Thinker significantly outperforms Claude-3.5 (Computer Use) by 14.9% in success rate on WorldGUI tasks. This improvement underscores the effectiveness of our critical-thinking-based framework in enhancing GUI automation.</description>
      <guid isPermaLink="false">oai:arXiv.org:2502.08047v1</guid>
      <category>cs.AI</category>
      <category>cs.MA</category>
      <pubDate>Thu, 13 Feb 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Henry Hengyuan Zhao, Difei Gao, Mike Zheng Shou</dc:creator>
    </item>
    <item>
      <title>Cognify: Supercharging Gen-AI Workflows With Hierarchical Autotuning</title>
      <link>https://arxiv.org/abs/2502.08056</link>
      <description>arXiv:2502.08056v1 Announce Type: cross 
Abstract: Today's gen-AI workflows that involve multiple ML model calls, tool/API calls, data retrieval, or generic code execution are often tuned manually in an ad-hoc way that is both time-consuming and error-prone. In this paper, we propose a systematic approach for automatically tuning gen-AI workflows. Our key insight is that gen-AI workflows can benefit from structure, operator, and prompt changes, but unique properties of gen-AI workflows require new optimization techniques. We propose AdaSeek, an adaptive hierarchical search algorithm for autotuning gen-AI workflows. AdaSeek organizes workflow tuning methods into different layers based on the user-specified total search budget and distributes the budget across different layers based on the complexity of each layer. During its hierarchical search, AdaSeek redistributes the search budget from less useful to more promising tuning configurations based on workflow-level evaluation results. We implement AdaSeek in a workflow autotuning framework called Cognify and evaluate Cognify using six types of workflows such as RAG-based QA and text-to-SQL transformation. Overall, Cognify improves these workflows' generation quality by up to 2.8x, reduces execution monetary cost by up to 10x, and reduces end-to-end latency by 2.7x.</description>
      <guid isPermaLink="false">oai:arXiv.org:2502.08056v1</guid>
      <category>cs.LG</category>
      <category>cs.AI</category>
      <category>cs.MA</category>
      <pubDate>Thu, 13 Feb 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Zijian He, Reyna Abhyankar, Vikranth Srivatsa, Yiying Zhang</dc:creator>
    </item>
    <item>
      <title>Beyond Predictions: A Participatory Framework for Multi-Stakeholder Decision-Making</title>
      <link>https://arxiv.org/abs/2502.08542</link>
      <description>arXiv:2502.08542v1 Announce Type: cross 
Abstract: Conventional decision-support systems, primarily based on supervised learning, focus on outcome prediction models to recommend actions. However, they often fail to account for the complexities of multi-actor environments, where diverse and potentially conflicting stakeholder preferences must be balanced. In this paper, we propose a novel participatory framework that redefines decision-making as a multi-stakeholder optimization problem, capturing each actor's preferences through context-dependent reward functions. Our framework leverages $k$-fold cross-validation to fine-tune user-provided outcome prediction models and evaluate decision strategies, including compromise functions mediating stakeholder trade-offs. We introduce a synthetic scoring mechanism that exploits user-defined preferences across multiple metrics to rank decision-making strategies and identify the optimal decision-maker. The selected decision-maker can then be used to generate actionable recommendations for new data. We validate our framework using two real-world use cases, demonstrating its ability to deliver recommendations that effectively balance multiple metrics, achieving results that are often beyond the scope of purely prediction-based methods. Ablation studies demonstrate that our framework, with its modular, model-agnostic, and inherently transparent design, integrates seamlessly with various predictive models, reward structures, evaluation metrics, and sample sizes, making it particularly suited for complex, high-stakes decision-making contexts.</description>
      <guid isPermaLink="false">oai:arXiv.org:2502.08542v1</guid>
      <category>cs.LG</category>
      <category>cs.MA</category>
      <pubDate>Thu, 13 Feb 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Vittoria Vineis, Giuseppe Perelli, Gabriele Tolomei</dc:creator>
    </item>
    <item>
      <title>QA-Expand: Multi-Question Answer Generation for Enhanced Query Expansion in Information Retrieval</title>
      <link>https://arxiv.org/abs/2502.08557</link>
      <description>arXiv:2502.08557v1 Announce Type: cross 
Abstract: Query expansion is widely used in Information Retrieval (IR) to improve search outcomes by enriching queries with additional contextual information. Although recent Large Language Model (LLM) based methods generate pseudo-relevant content and expanded terms via multiple prompts, they often yield repetitive, narrow expansions that lack the diverse context needed to retrieve all relevant information. In this paper, we introduce QA-Expand, a novel and effective framework for query expansion. It first generates multiple relevant questions from the initial query and subsequently produces corresponding pseudo-answers as surrogate documents. A feedback model further rewrites and filters these answers to ensure only the most informative augmentations are incorporated. Extensive experiments on benchmarks such as BEIR and TREC demonstrate that QA-Expand enhances retrieval performance by up to 13% over state-of-the-art methods, offering a robust solution for modern retrieval challenges.</description>
      <guid isPermaLink="false">oai:arXiv.org:2502.08557v1</guid>
      <category>cs.IR</category>
      <category>cs.CL</category>
      <category>cs.LG</category>
      <category>cs.MA</category>
      <pubDate>Thu, 13 Feb 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <dc:creator>Wonduk Seo, Seunghyun Lee</dc:creator>
    </item>
    <item>
      <title>Learning in Markets with Heterogeneous Agents: Dynamics and Survival of Bayesian vs. No-Regret Learners</title>
      <link>https://arxiv.org/abs/2502.08597</link>
      <description>arXiv:2502.08597v1 Announce Type: cross 
Abstract: We analyze the performance of heterogeneous learning agents in asset markets with stochastic payoffs. Our agents aim to maximize the expected growth rate of their wealth but have different theories on how to learn this best. We focus on comparing Bayesian and no-regret learners in market dynamics. Bayesian learners with a prior over a finite set of models that assign positive prior probability to the correct model have posterior probabilities that converge exponentially to the correct model. Consequently, they survive even in the presence of agents who invest according to the correct model of the stochastic process. Bayesians with a continuum prior converge to the correct model at a rate of $O((\log T)/T)$. Online learning theory provides no-regret algorithms for maximizing the log of wealth in this setting, achieving a worst-case regret bound of $O(\log T)$ without assuming a steady underlying stochastic process but comparing to the best fixed investment rule. This regret, as we observe, is of the same order of magnitude as that of a Bayesian learner with a continuum prior. However, we show that even such low regret may not be sufficient for survival in asset markets: an agent can have regret as low as $O(\log T)$, but still vanish in market dynamics when competing against agents who invest according to the correct model or even against a perfect Bayesian with a finite prior. On the other hand, we show that Bayesian learning is fragile, while no-regret learning requires less knowledge of the environment and is therefore more robust. Any no-regret learner will drive out of the market an imperfect Bayesian whose finite prior or update rule has even small errors. We formally establish the relationship between notions of survival, vanishing, and market domination studied in economics and the framework of regret minimization, thus bridging these theories.</description>
      <guid isPermaLink="false">oai:arXiv.org:2502.08597v1</guid>
      <category>cs.GT</category>
      <category>cs.AI</category>
      <category>cs.MA</category>
      <category>econ.TH</category>
      <pubDate>Thu, 13 Feb 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>David Easley, Yoav Kolumbus, Eva Tardos</dc:creator>
    </item>
    <item>
      <title>Multi-Agent Digital Twinning for Collaborative Logistics: Framework and Implementation</title>
      <link>https://arxiv.org/abs/2309.12781</link>
      <description>arXiv:2309.12781v3 Announce Type: replace 
Abstract: Collaborative logistics has been widely recognised as an effective avenue to reduce carbon emissions by enhanced truck utilisation and reduced travel distance. However, stakeholders' participation in collaborations is hindered by information-sharing barriers and the absence of integrated systems. We, thus, in this paper addresses these barriers by investigating an integrated platform that foster collaboration through the integration of agents with digital twins. Specifically, we employ a multi-agent system approach to integrate stakeholders and physical mobile assets in collaborative logistics, representing them as agents. We introduce a loosely-coupled system architecture that facilitates the connection between physical and digital systems, enabling the integration of agents with digital twins. Using this architecture, we implement the platform (or testbed). The resulting testbed, comprising a physical environment and a digital replica, is a digital twin that integrates distributed entities involved in collaborative logistics. The effectiveness of the testbed is demonstrated through a carrier collaboration scenario. This paper is among the earliest few efforts to investigate the integration of agents and digital twin concepts and goes beyond the conceptual discussion of existing studies to the technical implementation of such integration.</description>
      <guid isPermaLink="false">oai:arXiv.org:2309.12781v3</guid>
      <category>cs.MA</category>
      <pubDate>Thu, 13 Feb 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <dc:creator>Liming Xu, Stephen Mak, Stefan Schoepf, Michael Ostroumov, Alexandra Brintrup</dc:creator>
    </item>
    <item>
      <title>Enhancing Clinical Trial Patient Matching through Knowledge Augmentation and Reasoning with Multi-Agents</title>
      <link>https://arxiv.org/abs/2411.14637</link>
      <description>arXiv:2411.14637v2 Announce Type: replace 
Abstract: Matching patients effectively and efficiently for clinical trials is a significant challenge due to the complexity and variability of patient profiles and trial criteria. This paper introduces Multi-Agents for Knowledge Augmentation and Reasoning (MAKAR), a novel framework that enhances patient-trial matching by integrating domain-specific knowledge with structured reasoning. MAKAR consists of two key modules: the Augmentation Module and the Reasoning Module. The Augmentation Module enriches trial criteria by incorporating detailed explanations of relevant concepts to ensure clarity and completeness. The Reasoning Module then evaluates each health condition, following a structured, step-wise approach to determine eligibility and make the final matching decision. This paper enhances patient-trial matching by leveraging the agency and reasoning capabilities of large language models (LLMs) through automated agent interactions, including collaboration, critique, and navigation. Experimental results on a public dataset demonstrate that our framework surpasses existing benchmarks, achieving up to an 8% improvement in accuracy for specific criteria. Furthermore, in a real-world offline test, MAKAR achieved a 100% accuracy. These findings show MAKAR's potential as a scalable and robust solution for clinical trial patient matching.</description>
      <guid isPermaLink="false">oai:arXiv.org:2411.14637v2</guid>
      <category>cs.MA</category>
      <pubDate>Thu, 13 Feb 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Hanwen Shi, Jin Zhang, Kunpeng Zhang</dc:creator>
    </item>
    <item>
      <title>Towards CausalGPT: A Multi-Agent Approach for Faithful Knowledge Reasoning via Promoting Causal Consistency in LLMs</title>
      <link>https://arxiv.org/abs/2308.11914</link>
      <description>arXiv:2308.11914v4 Announce Type: replace-cross 
Abstract: Despite the progress of foundation models, knowledge-based reasoning remains a persistent challenge due to their limited capacity for knowledge recall and inference. Existing methods primarily focus on encouraging these models to plan and solve problems or extensively sample reasoning chains independently. However, these methods often overlook conceptual errors and inferential fallacies, inevitably leading to a series of notorious issues such as misleading conclusions, cognitive biases, and reduced decision quality. While explicit modeling of causality is argued to hold promise in addressing these issues, contemporary research efforts have thus far fallen short in achieving causality-based foundation models. Drawing inspiration from the orchestration of diverse specialized agents collaborating to tackle intricate tasks, we propose a framework named Causal-Consistency Chain-of-Thought (CaCo-CoT) that harnesses multi-agent collaboration to bolster the faithfulness and causality of foundation models, involving a set of reasoners and evaluators. These agents collaboratively work within a reasoning-and-consensus paradigm to improve faithfulness. The reasoners are tasked with generating reasoning chains for knowledge-intensive problems by mimicking human causal reasoning. Meanwhile, the evaluator scrutinizes the causal consistency of a reasoner's reasoning chain from a non-causal and a counterfactual perspective. Our framework demonstrates significant superiority over state-of-the-art methods through extensive and comprehensive evaluations across text-based and multi-modal knowledge reasoning tasks (e.g., science question answering and commonsense reasoning).</description>
      <guid isPermaLink="false">oai:arXiv.org:2308.11914v4</guid>
      <category>cs.AI</category>
      <category>cs.MA</category>
      <pubDate>Thu, 13 Feb 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Ziyi Tang, Ruilin Wang, Weixing Chen, Yongsen Zheng, Zechuan Chen, Yang Liu, Keze Wang, Tianshui Chen, Liang Lin</dc:creator>
    </item>
    <item>
      <title>Closure Discovery for Coarse-Grained Partial Differential Equations Using Grid-based Reinforcement Learning</title>
      <link>https://arxiv.org/abs/2402.00972</link>
      <description>arXiv:2402.00972v3 Announce Type: replace-cross 
Abstract: Reliable predictions of critical phenomena, such as weather, wildfires and epidemics often rely on models described by Partial Differential Equations (PDEs). However, simulations that capture the full range of spatio-temporal scales described by such PDEs are often prohibitively expensive. Consequently, coarse-grained simulations are usually deployed that adopt various heuristics and empirical closure terms to account for the missing information. We propose a novel and systematic approach for identifying closures in under-resolved PDEs using grid-based Reinforcement Learning. This formulation incorporates inductive bias and exploits locality by deploying a central policy represented efficiently by a Fully Convolutional Network (FCN). We demonstrate the capabilities and limitations of our framework through numerical solutions of the advection equation and the Burgers' equation. Our results show accurate predictions for in- and out-of-distribution test cases as well as a significant speedup compared to resolving all scales.</description>
      <guid isPermaLink="false">oai:arXiv.org:2402.00972v3</guid>
      <category>cs.LG</category>
      <category>cs.MA</category>
      <category>physics.comp-ph</category>
      <pubDate>Thu, 13 Feb 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Jan-Philipp von Bassewitz, Sebastian Kaltenbach, Petros Koumoutsakos</dc:creator>
    </item>
    <item>
      <title>MedAgentBench: A Realistic Virtual EHR Environment to Benchmark Medical LLM Agents</title>
      <link>https://arxiv.org/abs/2501.14654</link>
      <description>arXiv:2501.14654v2 Announce Type: replace-cross 
Abstract: Recent large language models (LLMs) have demonstrated significant advancements, particularly in their ability to serve as agents thereby surpassing their traditional role as chatbots. These agents can leverage their planning and tool utilization capabilities to address tasks specified at a high level. However, a standardized dataset to benchmark the agent capabilities of LLMs in medical applications is currently lacking, making the evaluation of LLMs on complex tasks in interactive healthcare environments challenging. To address this gap, we introduce MedAgentBench, a broad evaluation suite designed to assess the agent capabilities of large language models within medical records contexts. MedAgentBench encompasses 300 patient-specific clinically-derived tasks from 10 categories written by human physicians, realistic profiles of 100 patients with over 700,000 data elements, a FHIR-compliant interactive environment, and an accompanying codebase. The environment uses the standard APIs and communication infrastructure used in modern EMR systems, so it can be easily migrated into live EMR systems. MedAgentBench presents an unsaturated agent-oriented benchmark that current state-of-the-art LLMs exhibit some ability to succeed at. The best model (Claude 3.5 Sonnet v2) achieves a success rate of 69.67%. However, there is still substantial space for improvement which gives the community a next direction to optimize. Furthermore, there is significant variation in performance across task categories. MedAgentBench establishes this and is publicly available at https://github.com/stanfordmlgroup/MedAgentBench , offering a valuable framework for model developers to track progress and drive continuous improvements in the agent capabilities of large language models within the medical domain.</description>
      <guid isPermaLink="false">oai:arXiv.org:2501.14654v2</guid>
      <category>cs.LG</category>
      <category>cs.AI</category>
      <category>cs.MA</category>
      <pubDate>Thu, 13 Feb 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Yixing Jiang, Kameron C. Black, Gloria Geng, Danny Park, James Zou, Andrew Y. Ng, Jonathan H. Chen</dc:creator>
    </item>
  </channel>
</rss>
