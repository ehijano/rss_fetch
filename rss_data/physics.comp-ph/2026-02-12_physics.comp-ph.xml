<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>physics.comp-ph updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/physics.comp-ph</link>
    <description>physics.comp-ph updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/physics.comp-ph" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Thu, 12 Feb 2026 05:00:12 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Thu, 12 Feb 2026 00:00:00 -0500</pubDate>
    <skipDays>
      <day>Saturday</day>
      <day>Sunday</day>
    </skipDays>
    <item>
      <title>Noise-balanced multilevel on-the-fly sparse grid surrogates for coupling Monte Carlo models into continuum models with application to heterogeneous catalysis</title>
      <link>https://arxiv.org/abs/2602.11006</link>
      <description>arXiv:2602.11006v1 Announce Type: new 
Abstract: Multiscale simulations utilizing high-fidelity, microscopic Monte Carlo models to provide the nonlinear response for continuum models can easily become computationally intractable. Surrogate models for the high-fidelity Monte Carlo models can overcome this but come with some challenges. One such challenges arise by the sampling noise in the underlying Monte Carlo data, which leads to uncontrolled errors possibly corrupting the surrogate even though it would be highly accurate in the case of noise-free data. Another challenge arises by the 'curse of dimensionality' when the response depends on many macro-variables. These points are addressed by a novel noise-balanced sparse grids interpolation approach which, in a quasi-optimal fashion, controls the amount of Monte Carlo sampling for each data point. The approach is complemented by a multilevel on-the-fly construction during the multiscale simulation. Besides its efficiency, a particularly appealing feature is the ease of use of the approach with only a single hyperparameter controlling the whole surrogate construction - from the surrogate's accuracy with guaranteed convergence to which data needs to be created with which accuracy. The approach is demonstrated on challenging examples from heterogeneous catalysis, coupling microscopic kinetic Monte Carlo models into macroscopic reactor simulations.</description>
      <guid isPermaLink="false">oai:arXiv.org:2602.11006v1</guid>
      <category>physics.comp-ph</category>
      <category>cond-mat.stat-mech</category>
      <category>cs.NA</category>
      <category>math.NA</category>
      <pubDate>Thu, 12 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Tobias H\"ulser, Sebastian Matera</dc:creator>
    </item>
    <item>
      <title>Benchmarking of Massively Parallel Phase-Field Codes for Directional Solidification</title>
      <link>https://arxiv.org/abs/2602.10316</link>
      <description>arXiv:2602.10316v1 Announce Type: cross 
Abstract: We present a detailed benchmark comparing two state-of-the-art phase-field implementations for simulating alloy solidification under experimentally relevant conditions. The study investigates the directional solidification of Al-3wt%Cu under additive manufacturing conditions and SCN-0.46wt% camphor under microgravity conditions from National Aeronautics and Space Administration (NASA) DECLIC-DSI-R experiments. Both codes, one employing finite-difference discretization with uniform mesh and GPU-acceleration and the other one employing finite-element discretization with adaptive-mesh and CPU-parallelization, solve the same quantitative phase-field formulation that incorporates an anti-trapping current for the solidification of dilute alloys. We evaluate the predictions of each code for dendritic morphology, primary spacing, and tip dynamics in both 2D and 3D, as well as their numerical convergence and computational performance. While existing benchmark problems have primarily focused on simplified or small-scale simulations, they do not reflect the computational and modeling challenges posed by employing experimentally relevant time and length scales. Our results provide a practical framework for assessing phase-field code performance as well as validating and facilitating their application in integrated computational materials engineering (ICME) workflows that require integration with realistic experimental data.</description>
      <guid isPermaLink="false">oai:arXiv.org:2602.10316v1</guid>
      <category>cond-mat.mtrl-sci</category>
      <category>physics.comp-ph</category>
      <pubDate>Thu, 12 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Jiefu Tian, David Montiel, Kaihua Ji, Trevor Lyons, Jason Landini, Katsuyo Thornton, Alain Karma</dc:creator>
    </item>
    <item>
      <title>A Multimodal Conditional Mixture Model with Distribution-Level Physics Priors</title>
      <link>https://arxiv.org/abs/2602.10451</link>
      <description>arXiv:2602.10451v1 Announce Type: cross 
Abstract: Many scientific and engineering systems exhibit intrinsically multimodal behavior arising from latent regime switching and non-unique physical mechanisms. In such settings, learning the full conditional distribution of admissible outcomes in a physically consistent and interpretable manner remains a challenge. While recent advances in machine learning have enabled powerful multimodal generative modeling, their integration with physics-constrained scientific modeling remains nontrivial, particularly when physical structure must be preserved or data are limited. This work develops a physics-informed multimodal conditional modeling framework based on mixture density representations. Mixture density networks (MDNs) provide an explicit and interpretable parameterization of multimodal conditional distributions. Physical knowledge is embedded through component-specific regularization terms that penalize violations of governing equations or physical laws. This formulation naturally accommodates non-uniqueness and stochasticity while remaining computationally efficient and amenable to conditioning on contextual inputs. The proposed framework is evaluated across a range of scientific problems in which multimodality arises from intrinsic physical mechanisms rather than observational noise, including bifurcation phenomena in nonlinear dynamical systems, stochastic partial differential equations, and atomistic-scale shock dynamics. In addition, the proposed method is compared with a conditional flow matching (CFM) model, a representative state-of-the-art generative modeling approach, demonstrating that MDNs can achieve competitive performance while offering a simpler and more interpretable formulation.</description>
      <guid isPermaLink="false">oai:arXiv.org:2602.10451v1</guid>
      <category>cs.LG</category>
      <category>physics.comp-ph</category>
      <pubDate>Thu, 12 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Jinkyo Han, Bahador Bahmani</dc:creator>
    </item>
    <item>
      <title>On the Role of Consistency Between Physics and Data in Physics-Informed Neural Networks</title>
      <link>https://arxiv.org/abs/2602.10611</link>
      <description>arXiv:2602.10611v1 Announce Type: cross 
Abstract: Physics-informed neural networks (PINNs) have gained significant attention as a surrogate modeling strategy for partial differential equations (PDEs), particularly in regimes where labeled data are scarce and physical constraints can be leveraged to regularize the learning process. In practice, however, PINNs are frequently trained using experimental or numerical data that are not fully consistent with the governing equations due to measurement noise, discretization errors, or modeling assumptions. The implications of such data-to-PDE inconsistencies on the accuracy and convergence of PINNs remain insufficiently understood. In this work, we systematically analyze how data inconsistency fundamentally limits the attainable accuracy of PINNs. We introduce the concept of a consistency barrier, defined as an intrinsic lower bound on the error that arises from mismatches between the fidelity of the data and the exact enforcement of the PDE residual. To isolate and quantify this effect, we consider the 1D viscous Burgers equation with a manufactured analytical solution, which enables full control over data fidelity and residual errors. PINNs are trained using datasets of progressively increasing numerical accuracy, as well as perfectly consistent analytical data. Results show that while the inclusion of the PDE residual allows PINNs to partially mitigate low-fidelity data and recover the dominant physical structure, the training process ultimately saturates at an error level dictated by the data inconsistency. When high-fidelity numerical data are employed, PINN solutions become indistinguishable from those trained on analytical data, indicating that the consistency barrier is effectively removed. These findings clarify the interplay between data quality and physics enforcement in PINNs providing practical guidance for the construction and interpretation of physics-informed surrogate models.</description>
      <guid isPermaLink="false">oai:arXiv.org:2602.10611v1</guid>
      <category>cs.LG</category>
      <category>physics.comp-ph</category>
      <category>stat.ML</category>
      <pubDate>Thu, 12 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Nicol\'as Becerra-Zuniga, Lucas Lacasa, Eusebio Valero, Gonzalo Rubio</dc:creator>
    </item>
    <item>
      <title>Statistical Learning Analysis of Physics-Informed Neural Networks</title>
      <link>https://arxiv.org/abs/2602.11097</link>
      <description>arXiv:2602.11097v1 Announce Type: cross 
Abstract: We study the training and performance of physics-informed learning for initial and boundary value problems (IBVP) with physics-informed neural networks (PINNs) from a statistical learning perspective. Specifically, we restrict ourselves to parameterizations with hard initial and boundary condition constraints and reformulate the problem of estimating PINN parameters as a statistical learning problem. From this perspective, the physics penalty on the IBVP residuals can be better understood not as a regularizing term bus as an infinite source of indirect data, and the learning process as fitting the PINN distribution of residuals $p(y \mid x, t, w) q(x, t) $ to the true data-generating distribution $\delta(0) q(x, t)$ by minimizing the Kullback-Leibler divergence between the true and PINN distributions. Furthermore, this analysis show that physics-informed learning with PINNs is a singular learning problem, and we employ singular learning theory tools, namely the so-called Local Learning Coefficient (Lau et al., 2025) to analyze the estimates of PINN parameters obtained via stochastic optimization for a heat equation IBVP. Finally, we discuss implications of this analysis on the quantification of predictive uncertainty of PINNs and the extrapolation capacity of PINNs.</description>
      <guid isPermaLink="false">oai:arXiv.org:2602.11097v1</guid>
      <category>cs.LG</category>
      <category>physics.comp-ph</category>
      <pubDate>Thu, 12 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>David A. Barajas-Solano</dc:creator>
    </item>
    <item>
      <title>Linear Analysis of Stochastic Verlet-Type Integrators for Langevin Equations</title>
      <link>https://arxiv.org/abs/2505.04100</link>
      <description>arXiv:2505.04100v3 Announce Type: replace 
Abstract: We provide an analytical framework for analyzing the quality of stochastic Verlet-type integrators for simulating the Langevin equation. Focusing only on basic objective measures, we consider the ability of an integrator to correctly simulate two characteristic configurational quantities of transport, a) diffusion on a flat surface and b) drift on a tilted planar surface, as well as c) statistical sampling of a harmonic potential. For any stochastic Verlet-type integrator expressed in its configurational form, we develop closed form expressions to directly assess these three most basic quantities as a function of the applied time step. The applicability of the analysis is exemplified through twelve representative integrators developed over the past five decades, and algorithm performance is conveniently visualized through the three characteristic measures for each integrator. The GJ set of integrators stands out as the only option for correctly simulating diffusion, drift, and Boltzmann distribution in linear systems, and we therefore suggest that this general method is the one best suited for high quality thermodynamic simulations of nonlinear and complex systems, including for relatively high time steps compared to simulations with other integrators.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.04100v3</guid>
      <category>physics.comp-ph</category>
      <category>cond-mat.stat-mech</category>
      <category>physics.chem-ph</category>
      <pubDate>Thu, 12 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <arxiv:DOI>10.1007/s10955-025-03553-3</arxiv:DOI>
      <arxiv:journal_reference>Journal of Statistical Physics Vol.193, 12 (2026)</arxiv:journal_reference>
      <dc:creator>Niels Gr{\o}nbech-Jensen</dc:creator>
    </item>
    <item>
      <title>Discovery of Hyperelastic Constitutive Laws from Experimental Data with EUCLID</title>
      <link>https://arxiv.org/abs/2510.24747</link>
      <description>arXiv:2510.24747v2 Announce Type: replace 
Abstract: We assess the performance of EUCLID, Efficient Unsupervised Constitutive Law Identification and Discovery, a recently proposed framework for automated discovery of constitutive laws, on experimental data. Mechanical tests are performed on natural rubber specimens spanning simple to complex geometries, from which we collect both global, force elongation, and local, full-field displacement, measurements. Using these data, we obtain constitutive laws via two routes, the conventional identification of unknown parameters in a priori selected material models, and EUCLID, which automates model selection and parameter identification within a unified model-discovery pipeline. We compare the two methodologies using global versus local data, analyze predictive accuracy, and examine generalization to unseen geometries. Moreover, we quantify the experimental noise, investigate the coverage of the material state space achieved by each approach and discuss the relative performance of different datasets and different a priori chosen models versus EUCLID.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.24747v2</guid>
      <category>physics.comp-ph</category>
      <category>cond-mat.mtrl-sci</category>
      <pubDate>Thu, 12 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Arefeh Abbasi, Maurizio Ricci, Pietro Carrara, Moritz Flaschel, Siddhant Kumar, Sonia Marfia, Laura De Lorenzis</dc:creator>
    </item>
    <item>
      <title>diffpy.morph: Python tools for model independent comparisons between sets of 1D functions</title>
      <link>https://arxiv.org/abs/2602.06987</link>
      <description>arXiv:2602.06987v3 Announce Type: replace 
Abstract: diffpy.morph addresses a need to gain scientific insights from 1D scientific spectra in model independent ways. A powerful approach for this is to take differences between pairs of spectra and look for meaningful changes that might indicate underlying chemical, structural, or other modifications. The challenge is that the difference curve may contain uninteresting differences such as experimental inconsistencies and benign physical changes such as the effects of thermal expansion. diffpy.morph allows researchers to apply simple transformations, or "morphs", to one of the datasets to remove the unwanted differences revealing, when they are present, non-trivial differences. diffpy.morph is an open-source Python package available on the Python Package Index and conda-forge. Here, we describe its functionality and apply it to solve a range of experimental challenges on diffraction and PDF data from x-rays and neutrons, though we note that it may be applied to any 1D function in principle.</description>
      <guid isPermaLink="false">oai:arXiv.org:2602.06987v3</guid>
      <category>physics.comp-ph</category>
      <category>cond-mat.mtrl-sci</category>
      <pubDate>Thu, 12 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Andrew Yang, Christopher L. Farrow, Pavol Juh\'as, Luis Kitsu Iglesias, Chia-Hao Liu, Samuel D. Marks, Vivian R. K. Wall, Joshua Safin, Sean M. Drewry, Caden Myers, Dillon F. Hanlon, Nicholas Leonard, Cedomir Petrovic, Ahhyun Jeong, Dmitri V. Talapin, Linda F. Nazar, Haidong Zhou, Samuel W. Teitelbaum, Tim B. van Driel, Soham Banerjee, Emil S. Bozin, Michael F. Toney, Katharine Page, Naomi S. Ginsberg, Simon J. L. Billinge</dc:creator>
    </item>
    <item>
      <title>Nonpertubative Many-Body Theory for the Two-Dimensional Hubbard Model at Low Temperature: From Weak to Strong Coupling Regimes</title>
      <link>https://arxiv.org/abs/2503.12468</link>
      <description>arXiv:2503.12468v3 Announce Type: replace-cross 
Abstract: In theoretical studies of two-dimensional (2D) systems, the Mermin-Wagner theorem prevents continuous symmetry breaking at any finite temperature, thus forbidding a Landau phase transition at a critical temperature $T_c$. The difficulty arises when many-body theoretical studies predict a Landau phase transition at finite temperatures, which contradicts the Mermin-Wagner theorem and is termed a pseudo phase transition. To tackle this problem, we systematically develop a symmetrization scheme, defined as averaging physical quantities over all symmetry-breaking states, thus ensuring that it preserves the Mermin-Wagner theorem. We apply the symmetrization scheme to the GW-covariance calculation for the 2D repulsive Hubbard model at half-filling in the intermediate-to-strong coupling regime and at low temperatures, obtaining the one-body Green's function and spin-spin correlation function, and benchmark them against Determinant Quantum Monte Carlo (DQMC) with good agreement.The spin-spin correlation functions are approached within the covariance theory, a general method for calculating two-body correlation functions from a one-particle starting point, such as the GW formalism used here, which ensures the preservation of the fundamental fluctuation-dissipation relation (FDR) and Ward-Takahashi identities (WTI). With the FDR and WTI satisfied, we conjecture that the $\chi$-sum rule, a fundamental relation from the Pauli exclusion principle, can be used to probe the reliability of many-body methods, and demonstrate this by comparing the GW-covariance and mean-field-covariance approaches. This work provides a novel framework to investigate the strong-coupling and doped regime of the 2D Hubbard model, which is believed to be applicable to real high-$T_c$ cuprate superconductors.</description>
      <guid isPermaLink="false">oai:arXiv.org:2503.12468v3</guid>
      <category>cond-mat.str-el</category>
      <category>physics.atom-ph</category>
      <category>physics.comp-ph</category>
      <pubDate>Thu, 12 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Ruitao Xiao, Yingze Su, Junnian Xiong, Hui Li, Huaqing Huang, Dingping Li</dc:creator>
    </item>
    <item>
      <title>Spatiotemporal Field Generation Based on Hybrid Mamba-Transformer with Physics-informed Fine-tuning</title>
      <link>https://arxiv.org/abs/2505.11578</link>
      <description>arXiv:2505.11578v5 Announce Type: replace-cross 
Abstract: This research confronts the challenge of substantial physical equation discrepancies encountered in the generation of spatiotemporal physical fields through data-driven trained models. A spatiotemporal physical field generation model, named HMT-PF, is developed based on the hybrid Mamba-Transformer architecture, incorporating unstructured grid information as input. A fine-tuning block, enhanced with physical information, is introduced to effectively reduce the physical equation discrepancies. The physical equation residuals are computed through a point query mechanism for efficient gradient evaluation, then encoded into latent space for refinement. The fine-tuning process employs a self-supervised learning approach to achieve physical consistency while maintaining essential field characteristics. Results show that the hybrid Mamba-Transformer model achieves good performance in generating spatiotemporal fields, while the physics-informed fine-tuning mechanism further reduces significant physical errors effectively. A MSE-R evaluation method is developed to assess the accuracy and realism of physical field generation.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.11578v5</guid>
      <category>cs.LG</category>
      <category>cs.AI</category>
      <category>physics.comp-ph</category>
      <pubDate>Thu, 12 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Peimian Du, Jiabin Liu, Xiaowei Jin, Wangmeng Zuo, Hui Li</dc:creator>
    </item>
    <item>
      <title>evortran: a modern Fortran package for genetic algorithms with applications from LHC data fitting to LISA signal reconstruction</title>
      <link>https://arxiv.org/abs/2507.06082</link>
      <description>arXiv:2507.06082v3 Announce Type: replace-cross 
Abstract: evortran is a modern Fortran library designed for high-performance genetic algorithms and evolutionary optimization. evortran can be used to tackle a wide range of problems in high-energy physics and beyond, such as derivative-free parameter optimization, complex search taks, parameter scans and fitting experimental data under the presence of instrumental noise. The library is built as an fpm package with flexibility and efficiency in mind, while also offering a simple installation process, user interface and integration into existing Fortran (or Python) programs. evortran offers a variety of selection, crossover, mutation and elitism strategies, with which users can tailor an evolutionary algorithm to their specific needs. evortran supports different abstraction levels: from operating directly on individuals and populations, to running full evolutionary cycles, and even enabling migration between independently evolving populations to enhance convergence and maintain diversity. In this paper, we present the functionality of the evortran library, demonstrate its capabilities with example benchmark applications, and compare its performance with existing genetic algorithm frameworks. As physics-motivated applications, we use evortran to confront extended Higgs sectors with LHC data and to reconstruct gravitational wave spectra and the underlying physical parameters from LISA mock data, demonstrating its effectiveness in realistic, data-driven scenarios.</description>
      <guid isPermaLink="false">oai:arXiv.org:2507.06082v3</guid>
      <category>hep-ph</category>
      <category>cs.NE</category>
      <category>physics.comp-ph</category>
      <pubDate>Thu, 12 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <arxiv:DOI>10.21468/SciPostPhysCodeb.64</arxiv:DOI>
      <arxiv:journal_reference>SciPost Phys. Codebases 64 (2026)</arxiv:journal_reference>
      <dc:creator>Thomas Biek\"otter</dc:creator>
    </item>
  </channel>
</rss>
