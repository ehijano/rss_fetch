<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>econ.EM updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/econ.EM</link>
    <description>econ.EM updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/econ.EM" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Thu, 04 Jul 2024 04:02:44 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Thu, 04 Jul 2024 00:00:00 -0400</pubDate>
    <skipDays>
      <day>Saturday</day>
      <day>Sunday</day>
    </skipDays>
    <item>
      <title>Policymaker meetings as heteroscedasticity shifters: Identification and simultaneous inference in unstable SVARs</title>
      <link>https://arxiv.org/abs/2407.03265</link>
      <description>arXiv:2407.03265v1 Announce Type: new 
Abstract: We propose a novel approach to identification in structural vector autoregressions (SVARs) that uses external instruments for heteroscedasticiy of a structural shock of interest. This approach does not require lead/lag exogeneity for identification, does not require heteroskedasticity to be persistent, and facilitates interpretation of the structural shocks. To implement this identification approach in applications, we develop a new method for simultaneous inference of structural impulse responses and other parameters, employing a dependent wild-bootstrap of local projection estimators. This method is robust to an arbitrary number of unit roots and cointegration relationships, time-varying local means and drifts, and conditional heteroskedasticity of unknown form and can be used with other identification schemes, including Cholesky and the conventional external IV. We show how to construct pointwise and simultaneous confidence bounds for structural impulse responses and how to compute smoothed local projections with the corresponding confidence bounds. Using simulated data from a standard log-linearized DSGE model, we show that the method can reliably recover the true impulse responses in realistic datasets. As an empirical application, we adopt the proposed method in order to identify monetary policy shock using the dates of FOMC meetings in a standard six-variable VAR. The robustness of our identification and inference methods allows us to construct an instrumental variable for monetary policy shock that dates back to 1965. The resulting impulse response functions for all variables align with the classical Cholesky identification scheme and are different from the narrative sign restricted Bayesian VAR estimates. In particular, the response to inflation manifests a price puzzle that is indicative of the cost channel of the interest rates.</description>
      <guid isPermaLink="false">oai:arXiv.org:2407.03265v1</guid>
      <category>econ.EM</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Bulat Gafarov, Madina Karamysheva, Andrey Polbin, Anton Skrobotov</dc:creator>
    </item>
    <item>
      <title>Finely Stratified Rerandomization Designs</title>
      <link>https://arxiv.org/abs/2407.03279</link>
      <description>arXiv:2407.03279v1 Announce Type: new 
Abstract: We study estimation and inference on causal parameters under finely stratified rerandomization designs, which use baseline covariates to match units into groups (e.g. matched pairs), then rerandomize within-group treatment assignments until a balance criterion is satisfied. We show that finely stratified rerandomization does partially linear regression adjustment by design, providing nonparametric control over the covariates used for stratification, and linear control over the rerandomization covariates. We also introduce novel rerandomization criteria, allowing for nonlinear imbalance metrics and proposing a minimax scheme that optimizes the balance criterion using pilot data or prior information provided by the researcher. While the asymptotic distribution of generalized method of moments (GMM) estimators under stratified rerandomization is generically non-Gaussian, we show how to restore asymptotic normality using optimal ex-post linear adjustment. This allows us to provide simple asymptotically exact inference methods for superpopulation parameters, as well as efficient conservative inference methods for finite population parameters.</description>
      <guid isPermaLink="false">oai:arXiv.org:2407.03279v1</guid>
      <category>econ.EM</category>
      <category>math.ST</category>
      <category>stat.TH</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Max Cytrynbaum</dc:creator>
    </item>
    <item>
      <title>Evidence Aggregation for Treatment Choice</title>
      <link>https://arxiv.org/abs/2108.06473</link>
      <description>arXiv:2108.06473v2 Announce Type: replace 
Abstract: Consider a planner who has limited knowledge of the policy's causal impact on a certain local population of interest due to a lack of data, but does have access to the publicized intervention studies performed for similar policies on different populations. How should the planner make use of and aggregate this existing evidence to make her policy decision? Following Manski (2020; Towards Credible Patient-Centered Meta-Analysis, \textit{Epidemiology}), we formulate the planner's problem as a statistical decision problem with a social welfare objective, and solve for an optimal aggregation rule under the minimax-regret criterion. We investigate the analytical properties, computational feasibility, and welfare regret performance of this rule. We apply the minimax regret decision rule to two settings: whether to enact an active labor market policy based on 14 randomized control trial studies; and whether to approve a drug (Remdesivir) for COVID-19 treatment using a meta-database of clinical trials.</description>
      <guid isPermaLink="false">oai:arXiv.org:2108.06473v2</guid>
      <category>econ.EM</category>
      <category>math.ST</category>
      <category>stat.TH</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Takuya Ishihara, Toru Kitagawa</dc:creator>
    </item>
    <item>
      <title>Semiparametric Efficiency Gains From Parametric Restrictions on Propensity Scores</title>
      <link>https://arxiv.org/abs/2306.04177</link>
      <description>arXiv:2306.04177v3 Announce Type: replace 
Abstract: We explore how much knowing a parametric restriction on propensity scores improves semiparametric efficiency bounds in the potential outcome framework. For stratified propensity scores, considered as a parametric model, we derive explicit formulas for the efficiency gain from knowing how the covariate space is split. Based on these, we find that the efficiency gain decreases as the partition of the stratification becomes finer. For general parametric models, where it is hard to obtain explicit representations of efficiency bounds, we propose a novel framework that enables us to see whether knowing a parametric model is valuable in terms of efficiency even when it is high-dimensional. In addition to the intuitive fact that knowing the parametric model does not help much if it is sufficiently flexible, we discover that the efficiency gain can be nearly zero even though the parametric assumption significantly restricts the space of possible propensity scores.</description>
      <guid isPermaLink="false">oai:arXiv.org:2306.04177v3</guid>
      <category>econ.EM</category>
      <category>math.ST</category>
      <category>stat.TH</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <arxiv:DOI>10.1093/biomet/asae034</arxiv:DOI>
      <dc:creator>Haruki Kono</dc:creator>
    </item>
    <item>
      <title>Dyadic Regression with Sample Selection</title>
      <link>https://arxiv.org/abs/2405.17787</link>
      <description>arXiv:2405.17787v2 Announce Type: replace 
Abstract: This paper addresses the sample selection problem in panel dyadic regression analysis. Dyadic data often include many zeros in the main outcomes due to the underlying network formation process. This not only contaminates popular estimators used in practice but also complicates the inference due to the dyadic dependence structure. We extend Kyriazidou (1997)'s approach to dyadic data and characterize the asymptotic distribution of our proposed estimator. The convergence rates are $\sqrt{n}$ or $\sqrt{n^{2}h_{n}}$, depending on the degeneracy of the H\'{a}jek projection part of the estimator, where $n$ is the number of nodes and $h_{n}$ is a bandwidth. We propose a bias-corrected confidence interval and a variance estimator that adapts to the degeneracy. A Monte Carlo simulation shows the good finite sample performance of our estimator and highlights the importance of bias correction in both asymptotic regimes when the fraction of zeros in outcomes varies. We illustrate our procedure using data from Moretti and Wilson (2017)'s paper on migration.</description>
      <guid isPermaLink="false">oai:arXiv.org:2405.17787v2</guid>
      <category>econ.EM</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Kensuke Sakamoto</dc:creator>
    </item>
    <item>
      <title>Estimating Treatment Effects under Recommender Interference: A Structured Neural Networks Approach</title>
      <link>https://arxiv.org/abs/2406.14380</link>
      <description>arXiv:2406.14380v2 Announce Type: replace 
Abstract: Recommender systems are essential for content-sharing platforms by curating personalized content. To evaluate updates to recommender systems targeting content creators, platforms frequently rely on creator-side randomized experiments. The treatment effect measures the change in outcomes when a new algorithm is implemented compared to the status quo. We show that the standard difference-in-means estimator can lead to biased estimates due to recommender interference that arises when treated and control creators compete for exposure. We propose a "recommender choice model" that describes which item gets exposed from a pool containing both treated and control items. By combining a structural choice model with neural networks, this framework directly models the interference pathway while accounting for rich viewer-content heterogeneity. We construct a debiased estimator of the treatment effect and prove it is $\sqrt n$-consistent and asymptotically normal with potentially correlated samples. We validate our estimator's empirical performance with a field experiment on Weixin short-video platform. In addition to the standard creator-side experiment, we conduct a costly double-sided randomization design to obtain a benchmark estimate free from interference bias. We show that the proposed estimator yields results comparable to the benchmark, whereas the standard difference-in-means estimator can exhibit significant bias and even produce reversed signs.</description>
      <guid isPermaLink="false">oai:arXiv.org:2406.14380v2</guid>
      <category>econ.EM</category>
      <category>cs.LG</category>
      <category>stat.ME</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Ruohan Zhan, Shichao Han, Yuchen Hu, Zhenling Jiang</dc:creator>
    </item>
    <item>
      <title>Frequentist properties of Bayesian inequality tests</title>
      <link>https://arxiv.org/abs/1607.00393</link>
      <description>arXiv:1607.00393v4 Announce Type: replace-cross 
Abstract: Bayesian and frequentist criteria fundamentally differ, but often posterior and sampling distributions agree asymptotically (e.g., Gaussian with same covariance). For the corresponding single-draw experiment, we characterize the frequentist size of a certain Bayesian hypothesis test of (possibly nonlinear) inequalities. If the null hypothesis is that the (possibly infinite-dimensional) parameter lies in a certain half-space, then the Bayesian test's size is $\alpha$; if the null hypothesis is a subset of a half-space, then size is above $\alpha$; and in other cases, size may be above, below, or equal to $\alpha$. Rejection probabilities at certain points in the parameter space are also characterized. Two examples illustrate our results: translog cost function curvature and ordinal distribution relationships.</description>
      <guid isPermaLink="false">oai:arXiv.org:1607.00393v4</guid>
      <category>math.ST</category>
      <category>econ.EM</category>
      <category>stat.ME</category>
      <category>stat.TH</category>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <arxiv:DOI>10.1016/j.jeconom.2020.05.015</arxiv:DOI>
      <arxiv:journal_reference>Journal of Econometrics 221 (2021) 312-336</arxiv:journal_reference>
      <dc:creator>David M. Kaplan, Longhao Zhuo</dc:creator>
    </item>
    <item>
      <title>Multiply-Robust Causal Change Attribution</title>
      <link>https://arxiv.org/abs/2404.08839</link>
      <description>arXiv:2404.08839v3 Announce Type: replace-cross 
Abstract: Comparing two samples of data, we observe a change in the distribution of an outcome variable. In the presence of multiple explanatory variables, how much of the change can be explained by each possible cause? We develop a new estimation strategy that, given a causal model, combines regression and re-weighting methods to quantify the contribution of each causal mechanism. Our proposed methodology is multiply robust, meaning that it still recovers the target parameter under partial misspecification. We prove that our estimator is consistent and asymptotically normal. Moreover, it can be incorporated into existing frameworks for causal attribution, such as Shapley values, which will inherit the consistency and large-sample distribution properties. Our method demonstrates excellent performance in Monte Carlo simulations, and we show its usefulness in an empirical application. Our method is implemented as part of the Python library DoWhy (arXiv:2011.04216, arXiv:2206.06821).</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.08839v3</guid>
      <category>stat.ME</category>
      <category>cs.LG</category>
      <category>econ.EM</category>
      <category>stat.ML</category>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <arxiv:journal_reference>Proceedings of the 41st International Conference on Machine Learning, Vienna, Austria. PMLR 235, 2024</arxiv:journal_reference>
      <dc:creator>Victor Quintas-Martinez, Mohammad Taha Bahadori, Eduardo Santiago, Jeff Mu, Dominik Janzing, David Heckerman</dc:creator>
    </item>
  </channel>
</rss>
