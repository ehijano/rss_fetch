<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>cs.DS updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/cs.DS</link>
    <description>cs.DS updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/cs.DS" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Wed, 12 Feb 2025 02:55:47 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Tue, 11 Feb 2025 00:00:00 -0500</pubDate>
    <skipDays>
      <day>Sunday</day>
      <day>Saturday</day>
    </skipDays>
    <item>
      <title>Algorithmic Problems in Categories of Partitions</title>
      <link>https://arxiv.org/abs/2502.05373</link>
      <description>arXiv:2502.05373v1 Announce Type: new 
Abstract: Categories of partitions are combinatorial structures arising from the representation theory of certain compact quantum groups and are linked to classical diagram algebras such as the Temperley-Lieb algebra. In this paper, we present efficient algorithms and data-structures for partitions of sets and their corresponding category operations, including a concrete implementation in the computer algebra system OSCAR. Moreover, we show that there exists a category of partitions for which the natural computational problems of deciding membership of a given partition as well as counting partitions of a given size are algorithmically undecidable.</description>
      <guid isPermaLink="false">oai:arXiv.org:2502.05373v1</guid>
      <category>cs.DS</category>
      <category>math.QA</category>
      <pubDate>Tue, 11 Feb 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Nicolas Faro{\ss}, Sebastian Volz</dc:creator>
    </item>
    <item>
      <title>Approximating the total variation distance between spin systems</title>
      <link>https://arxiv.org/abs/2502.05437</link>
      <description>arXiv:2502.05437v1 Announce Type: new 
Abstract: Spin systems form an important class of undirected graphical models. For two Gibbs distributions $\mu$ and $\nu$ induced by two spin systems on the same graph $G = (V, E)$, we study the problem of approximating the total variation distance $d_{TV}(\mu,\nu)$ with an $\epsilon$-relative error. We propose a new reduction that connects the problem of approximating the TV-distance to sampling and approximate counting. Our applications include the hardcore model and the antiferromagnetic Ising model in the uniqueness regime, the ferromagnetic Ising model, and the general Ising model satisfying the spectral condition.
  Additionally, we explore the computational complexity of approximating the total variation distance $d_{TV}(\mu_S,\nu_S)$ between two marginal distributions on an arbitrary subset $S \subseteq V$. We prove that this problem remains hard even when both $\mu$ and $\nu$ admit polynomial-time sampling and approximate counting algorithms.</description>
      <guid isPermaLink="false">oai:arXiv.org:2502.05437v1</guid>
      <category>cs.DS</category>
      <category>cs.LG</category>
      <category>math.PR</category>
      <pubDate>Tue, 11 Feb 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Weiming Feng, Hongyang Liu, Minji Yang</dc:creator>
    </item>
    <item>
      <title>New and Improved Bounds for Markov Paging</title>
      <link>https://arxiv.org/abs/2502.05511</link>
      <description>arXiv:2502.05511v1 Announce Type: new 
Abstract: In the Markov paging model, one assumes that page requests are drawn from a Markov chain over the pages in memory, and the goal is to maintain a fast cache that suffers few page faults in expectation. While computing the optimal online algorithm $(\mathrm{OPT})$ for this problem naively takes time exponential in the size of the cache, the best-known polynomial-time approximation algorithm is the dominating distribution algorithm due to Lund, Phillips and Reingold (FOCS 1994), who showed that the algorithm is $4$-competitive against $\mathrm{OPT}$. We substantially improve their analysis and show that the dominating distribution algorithm is in fact $2$-competitive against $\mathrm{OPT}$. We also show a lower bound of $1.5907$-competitiveness for this algorithm -- to the best of our knowledge, no such lower bound was previously known.</description>
      <guid isPermaLink="false">oai:arXiv.org:2502.05511v1</guid>
      <category>cs.DS</category>
      <pubDate>Tue, 11 Feb 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Chirag Pabbaraju, Ali Vakilian</dc:creator>
    </item>
    <item>
      <title>Combined Search and Encoding for Seeds, with an Application to Minimal Perfect Hashing</title>
      <link>https://arxiv.org/abs/2502.05613</link>
      <description>arXiv:2502.05613v1 Announce Type: new 
Abstract: Randomised algorithms often employ methods that can fail and that are retried with independent randomness until they succeed. Randomised data structures therefore often store indices of successful attempts, called seeds. If $n$ such seeds are required (e.g., for independent substructures) the standard approach is to compute for each $i \in [n]$ the smallest successful seed $S_i$ and store $\vec{S} = (S_1, \ldots, S_n)$.
  The central observation of this paper is that this is not space-optimal. We present a different algorithm that computes a sequence $\vec{S}' = (S_1', \ldots, S_n')$ of successful seeds such that the entropy of $\vec{S'}$ undercuts the entropy of $\vec{S}$ by $\Omega(n)$ bits in most cases. To achieve a memory consumption of $\mathrm{OPT}+\varepsilon n$, the expected number of inspected seeds increases by a factor of $O(1/\varepsilon)$.
  We demonstrate the usefulness of our findings with a novel construction for minimal perfect hash functions with space requirement $(1+\varepsilon)\mathrm{OPT}$. The construction time is $O(n/\varepsilon)$ while all previous approaches have construction times that increase exponentially with $1/\varepsilon$. Our implementation beats the construction throughput of the state of the art by up to two orders of magnitude.</description>
      <guid isPermaLink="false">oai:arXiv.org:2502.05613v1</guid>
      <category>cs.DS</category>
      <pubDate>Tue, 11 Feb 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Hans-Peter Lehmann, Peter Sanders, Stefan Walzer, Jonatan Ziegler</dc:creator>
    </item>
    <item>
      <title>Near-Optimal Directed Low-Diameter Decompositions</title>
      <link>https://arxiv.org/abs/2502.05687</link>
      <description>arXiv:2502.05687v1 Announce Type: new 
Abstract: Low Diameter Decompositions (LDDs) are invaluable tools in the design of combinatorial graph algorithms. While historically they have been applied mainly to undirected graphs, in the recent breakthrough for the negative-length Single Source Shortest Path problem, Bernstein, Nanongkai, and Wulff-Nilsen [FOCS '22] extended the use of LDDs to directed graphs for the first time. Specifically, their LDD deletes each edge with probability at most $O(\frac{1}{D} \cdot \log^2 n)$, while ensuring that each strongly connected component in the remaining graph has a (weak) diameter of at most $D$.
  In this work, we make further advancements in the study of directed LDDs. We reveal a natural and intuitive (in hindsight) connection to Expander Decompositions, and leveraging this connection along with additional techniques, we establish the existence of an LDD with an edge-cutting probability of $O(\frac{1}{D} \cdot \log n \log\log n)$. This improves the previous bound by nearly a logarithmic factor and closely approaches the lower bound of $\Omega(\frac{1}{D} \cdot \log n)$. With significantly more technical effort, we also develop two efficient algorithms for computing our LDDs: a deterministic algorithm that runs in time $\tilde O(m \cdot poly(D))$ and a randomized algorithm that runs in near-linear time $\tilde O(m)$.
  We believe that our work provides a solid conceptual and technical foundation for future research relying on directed LDDs, which will undoubtedly follow soon.</description>
      <guid isPermaLink="false">oai:arXiv.org:2502.05687v1</guid>
      <category>cs.DS</category>
      <pubDate>Tue, 11 Feb 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Karl Bringmann, Nick Fischer, Bernhard Haeupler, Rustam Latypov</dc:creator>
    </item>
    <item>
      <title>Pareto-Optimality, Smoothness, and Stochasticity in Learning-Augmented One-Max-Search</title>
      <link>https://arxiv.org/abs/2502.05720</link>
      <description>arXiv:2502.05720v1 Announce Type: new 
Abstract: One-max search is a classic problem in online decision-making, in which a trader acts on a sequence of revealed prices and accepts one of them irrevocably to maximise its profit. The problem has been studied both in probabilistic and in worst-case settings, notably through competitive analysis, and more recently in learning-augmented settings in which the trader has access to a prediction on the sequence. However, existing approaches either lack smoothness, or do not achieve optimal worst-case guarantees: they do not attain the best possible trade-off between the consistency and the robustness of the algorithm. We close this gap by presenting the first algorithm that simultaneously achieves both of these important objectives. Furthermore, we show how to leverage the obtained smoothness to provide an analysis of one-max search in stochastic learning-augmented settings which capture randomness in both the observed prices and the prediction.</description>
      <guid isPermaLink="false">oai:arXiv.org:2502.05720v1</guid>
      <category>cs.DS</category>
      <category>cs.AI</category>
      <pubDate>Tue, 11 Feb 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Ziyad Benomar, Lorenzo Croissant, Vianney Perchet, Spyros Angelopoulos</dc:creator>
    </item>
    <item>
      <title>Breaking the Quadratic Barrier: Robust Cardinality Sketches for Adaptive Queries</title>
      <link>https://arxiv.org/abs/2502.05723</link>
      <description>arXiv:2502.05723v1 Announce Type: new 
Abstract: Cardinality sketches are compact data structures that efficiently estimate the number of distinct elements across multiple queries while minimizing storage, communication, and computational costs. However, recent research has shown that these sketches can fail under {\em adaptively chosen queries}, breaking down after approximately $\tilde{O}(k^2)$ queries, where $k$ is the sketch size.
  In this work, we overcome this \emph{quadratic barrier} by designing robust estimators with fine-grained guarantees. Specifically, our constructions can handle an {\em exponential number of adaptive queries}, provided that each element participates in at most $\tilde{O}(k^2)$ queries. This effectively shifts the quadratic barrier from the total number of queries to the number of queries {\em sharing the same element}, which can be significantly smaller. Beyond cardinality sketches, our approach expands the toolkit for robust algorithm design.</description>
      <guid isPermaLink="false">oai:arXiv.org:2502.05723v1</guid>
      <category>cs.DS</category>
      <pubDate>Tue, 11 Feb 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Edith Cohen, Mihir Singhal, Uri Stemmer</dc:creator>
    </item>
    <item>
      <title>Sink-free orientations: a local sampler with applications</title>
      <link>https://arxiv.org/abs/2502.05877</link>
      <description>arXiv:2502.05877v1 Announce Type: new 
Abstract: For sink-free orientations in graphs of minimum degree at least $3$, we show that there is a deterministic approximate counting algorithm that runs in time $O((n^{73}/\varepsilon^{72})\log(n/\varepsilon))$, a near-linear time sampling algorithm, and a randomised approximate counting algorithm that runs in time $O((n/\varepsilon)^2\log(n/\varepsilon))$, where $n$ denotes the number of vertices of the input graph and $0&lt;\varepsilon&lt;1$ is the desired accuracy. All three algorithms are based on a local implementation of the sink popping method (Cohn, Pemantle, Propp, 2002) under the partial rejection sampling framework (Guo, Jerrum, Liu, 2019).</description>
      <guid isPermaLink="false">oai:arXiv.org:2502.05877v1</guid>
      <category>cs.DS</category>
      <category>cs.DM</category>
      <category>math.PR</category>
      <pubDate>Tue, 11 Feb 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Konrad Anand, Graham Freifeld, Heng Guo, Chunyang Wang, Jiaheng Wang</dc:creator>
    </item>
    <item>
      <title>Faster Approximation Algorithms for k-Center via Data Reduction</title>
      <link>https://arxiv.org/abs/2502.05888</link>
      <description>arXiv:2502.05888v1 Announce Type: new 
Abstract: We study efficient algorithms for the Euclidean $k$-Center problem, focusing on the regime of large $k$. We take the approach of data reduction by considering $\alpha$-coreset, which is a small subset $S$ of the dataset $P$ such that any $\beta$-approximation on $S$ is an $(\alpha + \beta)$-approximation on $P$. We give efficient algorithms to construct coresets whose size is $k \cdot o(n)$, which immediately speeds up existing approximation algorithms. Notably, we obtain a near-linear time $O(1)$-approximation when $k = n^c$ for any $0 &lt; c &lt; 1$. We validate the performance of our coresets on real-world datasets with large $k$, and we observe that the coreset speeds up the well-known Gonzalez algorithm by up to $4$ times, while still achieving similar clustering cost. Technically, one of our coreset results is based on a new efficient construction of consistent hashing with competitive parameters. This general tool may be of independent interest for algorithm design in high dimensional Euclidean spaces.</description>
      <guid isPermaLink="false">oai:arXiv.org:2502.05888v1</guid>
      <category>cs.DS</category>
      <pubDate>Tue, 11 Feb 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Arnold Filtser, Shaofeng H. -C. Jiang, Yi Li, Anurag Murty Naredla, Ioannis Psarros, Qiaoyuan Yang, Qin Zhang</dc:creator>
    </item>
    <item>
      <title>Constant sensitivity on the CDAWGs</title>
      <link>https://arxiv.org/abs/2502.05915</link>
      <description>arXiv:2502.05915v1 Announce Type: new 
Abstract: Compact directed acyclic word graphs (CDAWGs) [Blumer et al. 1987] are a fundamental data structure on strings with applications in text pattern searching, data compression, and pattern discovery. Intuitively, the CDAWG of a string $T$ is obtained by merging isomorphic subtrees of the suffix tree [Weiner 1973] of the same string $T$, and thus CDAWGs are a compact indexing structure. In this paper, we investigate the sensitivity of CDAWGs when a single character edit operation is performed at an arbitrary position in $T$. We show that the size of the CDAWG after an edit operation on $T$ is asymptotically at most 8 times larger than the original CDAWG before the edit.</description>
      <guid isPermaLink="false">oai:arXiv.org:2502.05915v1</guid>
      <category>cs.DS</category>
      <pubDate>Tue, 11 Feb 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Rikuya Hamai, Hiroto Fujimaru, Shunsuke Inenaga</dc:creator>
    </item>
    <item>
      <title>Improved Sublinear Algorithms for Classical and Quantum Graph Coloring</title>
      <link>https://arxiv.org/abs/2502.06024</link>
      <description>arXiv:2502.06024v1 Announce Type: new 
Abstract: We present three sublinear randomized algorithms for vertex-coloring of graphs with maximum degree $\Delta$. The first is a simple algorithm that extends the idea of Morris and Song to color graphs with maximum degree $\Delta$ using $\Delta+1$ colors. Combined with the greedy algorithm, it achieves an expected runtime of $O(n^{3/2}\sqrt{\log n})$ in the query model, improving on Assadi, Chen, and Khanna's algorithm by a $\sqrt{\log n}$ factor in expectation. When we allow quantum queries to the graph, we can accelerate the first algorithm using Grover's famous algorithm, resulting in a runtime of $\tilde{O}(n^{4/3})$ quantum queries. Finally, we introduce a quantum algorithm for $(1+\epsilon)\Delta$-coloring, achieving $O(\epsilon^{-1}n^{5/4}\log^{3/2}n)$ quantum queries, offering a polynomial improvement over the previous best bound by Morris and Song.</description>
      <guid isPermaLink="false">oai:arXiv.org:2502.06024v1</guid>
      <category>cs.DS</category>
      <pubDate>Tue, 11 Feb 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Asaf Ferber, Liam Hardiman, Xiaonan Chen</dc:creator>
    </item>
    <item>
      <title>On the query complexity of sampling from non-log-concave distributions</title>
      <link>https://arxiv.org/abs/2502.06200</link>
      <description>arXiv:2502.06200v1 Announce Type: new 
Abstract: We study the problem of sampling from a $d$-dimensional distribution with density $p(x)\propto e^{-f(x)}$, which does not necessarily satisfy good isoperimetric conditions.
  Specifically, we show that for any $L,M$ satisfying $LM\ge d\ge 5$, $\epsilon\in \left\{0,\frac{1}{32}\right\}$, and any algorithm with query accesses to the value of $f(x)$ and $\nabla f(x)$, there exists an $L$-log-smooth distribution with second moment at most $M$ such that the algorithm requires $\left\{\frac{LM}{d\epsilon}\right\}^{\Omega(d)}$ queries to compute a sample whose distribution is within $\epsilon$ in total variation distance to the target distribution. We complement the lower bound with an algorithm requiring $\left\{\frac{LM}{d\epsilon}\right\}^{\mathcal O(d)}$ queries, thereby characterizing the tight (up to the constant in the exponent) query complexity for sampling from the family of non-log-concave distributions.
  Our results are in sharp contrast with the recent work of Huang et al. (COLT'24), where an algorithm with quasi-polynomial query complexity was proposed for sampling from a non-log-concave distribution when $M=\mathtt{poly}(d)$. Their algorithm works under the stronger condition that all distributions along the trajectory of the Ornstein-Uhlenbeck process, starting from the target distribution, are $\mathcal O(1)$-log-smooth. We investigate this condition and prove that it is strictly stronger than requiring the target distribution to be $\mathcal O(1)$-log-smooth. Additionally, we study this condition in the context of mixtures of Gaussians.
  Finally, we place our results within the broader theme of ``sampling versus optimization'', as studied in Ma et al. (PNAS'19). We show that for a wide range of parameters, sampling is strictly easier than optimization by a super-exponential factor in the dimension $d$.</description>
      <guid isPermaLink="false">oai:arXiv.org:2502.06200v1</guid>
      <category>cs.DS</category>
      <category>cs.LG</category>
      <category>stat.ML</category>
      <pubDate>Tue, 11 Feb 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Yuchen He, Chihao Zhang</dc:creator>
    </item>
    <item>
      <title>Maximum Coverage $k$-Antichains and Chains: A Greedy Approach</title>
      <link>https://arxiv.org/abs/2502.06459</link>
      <description>arXiv:2502.06459v1 Announce Type: new 
Abstract: Given an input acyclic digraph $G = (V,E)$ and a positive integer $k$, the problem of Maximum Coverage $k$-Antichains (resp., Chains) denoted as MA-$k$ (resp., MC-$k$) asks to find $k$ sets of pairwise unreachable vertices, known as antichains (resp., $k$ subsequences of paths, known as chains), maximizing the number of vertices covered by these antichains (resp. chains). While MC-$k$ has been recently solved in (almost) optimal $O(|E|^{1+o(1)})$ time [Kogan and Parter, ICALP 2022], the fastest known algorithm for MA-$k$ is a recent $(k|E|)^{1+o(1)}$-time solution [Kogan and Parter, ESA 2024] as well as a $1/2$ approximation running in $|E|^{1+o(1)}$ time in the same paper. In this paper, we leverage a paths-based proof of the Greene-Kleitmann (GK) theorem with the help of the greedy algorithm for set cover and recent advances on fast algorithms for flows and shortest paths to obtain the following results for MA-$k$:
  - The first (exact) algorithm running in $|E|^{1+o(1)}$ time, hence independent in $k$.
  - A randomized algorithm running in $\tilde{O}(\alpha_k|E|)$ time, where $\alpha_k$ is the size of the optimal solution. That is, a near-linear parameterized running time, generalizing the result of [M\"akinen et al., ACM TALG] obtained for $k=1$.
  - An approximation algorithm running in time $O(\alpha_1^2|V| + (\alpha_1+k)|E|)$ with approximation ratio of $(1-1/e) &gt; 0.63 &gt; 1/2$.
  Our last two solutions rely on the use of greedy set cover, first exploited in [Felsner et al., Order 2003] for chains, which we now apply to antichains. We complement these results with two examples (one for chains and one for antichains) showing that, for every $k \ge 2$, greedy misses a $1/4$ portion of the optimal coverage. We also show that greedy is a $\Omega(\log{|V|})$ factor away from minimality when required to cover all vertices: previously unknown for sets of chains or antichains.</description>
      <guid isPermaLink="false">oai:arXiv.org:2502.06459v1</guid>
      <category>cs.DS</category>
      <pubDate>Tue, 11 Feb 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Manuel C\'aceres, Andreas Grigorjew, Wanchote Po Jiamjitrak, Alexandru I. Tomescu</dc:creator>
    </item>
    <item>
      <title>New simple and fastest quicksort algorithm for equal keys</title>
      <link>https://arxiv.org/abs/2502.06461</link>
      <description>arXiv:2502.06461v1 Announce Type: new 
Abstract: This paper introduces a novel and efficient partitioning technique for quicksort, specifically designed for real-world data with duplicate elements (50-year-old problem). The method is referred to as "equal quicksort" or "eqsort". Based on the experimental findings, it has been determined that the newly developed algorithm, eqsort, is competitive with the best current implementations,such as fat partitioning algorithms and dual-pivot quicksort. This method offers several advantages over the commonly used dual-pivot method and pdqsort partitioning, making it a potential replacement.</description>
      <guid isPermaLink="false">oai:arXiv.org:2502.06461v1</guid>
      <category>cs.DS</category>
      <pubDate>Tue, 11 Feb 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Parviz Afereidoon</dc:creator>
    </item>
    <item>
      <title>ARRIVAL: Recursive Framework &amp; $\ell_1$-Contraction</title>
      <link>https://arxiv.org/abs/2502.06477</link>
      <description>arXiv:2502.06477v1 Announce Type: new 
Abstract: ARRIVAL is the problem of deciding which out of two possible destinations will be reached first by a token that moves deterministically along the edges of a directed graph, according to so-called switching rules. It is known to lie in NP $\cap$ CoNP, but not known to lie in P. The state-of-the-art algorithm due to G\"artner et al. (ICALP `21) runs in time $2^{\mathcal{O}(\sqrt{n} \log n)}$ on an $n$-vertex graph.
  We prove that ARRIVAL can be solved in time $2^{\mathcal{O}(k \log^2 n)}$ on $n$-vertex graphs of treewidth $k$. Our algorithm is derived by adapting a simple recursive algorithm for a generalization of ARRIVAL called G-ARRIVAL. This simple recursive algorithm acts as a framework from which we can also rederive the subexponential upper bound of G\"artner et al.
  Our second result is a reduction from G-ARRIVAL to the problem of finding an approximate fixed point of an $\ell_1$-contracting function $f : [0, 1]^n \rightarrow [0, 1]^n$. Finding such fixed points is a well-studied problem in the case of the $\ell_2$-metric and the $\ell_\infty$-metric, but little is known about the $\ell_1$-case.
  Both of our results highlight parallels between ARRIVAL and the Simple Stochastic Games (SSG) problem. Concretely, Chatterjee et al. (SODA `23) gave an algorithm for SSG parameterized by treewidth that achieves a similar bound as we do for ARRIVAL, and SSG is known to reduce to $\ell_\infty$-contraction.</description>
      <guid isPermaLink="false">oai:arXiv.org:2502.06477v1</guid>
      <category>cs.DS</category>
      <pubDate>Tue, 11 Feb 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Sebastian Haslebacher</dc:creator>
    </item>
    <item>
      <title>Approximation Algorithms for Optimal Hopsets</title>
      <link>https://arxiv.org/abs/2502.06522</link>
      <description>arXiv:2502.06522v1 Announce Type: new 
Abstract: For a given graph $G$, a "hopset" $H$ with hopbound $\beta$ and stretch $\alpha$ is a set of edges such that between every pair of vertices $u$ and $v$, there is a path with at most $\beta$ hops in $G \cup H$ that approximates the distance between $u$ and $v$ up to a multiplicative stretch of $\alpha$. Hopsets have found a wide range of applications for distance-based problems in various computational models since the 90s. More recently, there has been significant interest in understanding these fundamental objects from an existential and structural perspective. But all of this work takes a worst-case (or existential) point of view: How many edges do we need to add to satisfy a given hopbound and stretch requirement for any input graph?
  We initiate the study of the natural optimization variant of this problem: given a specific graph instance, what is the minimum number of edges that satisfy the hopbound and stretch requirements? We give approximation algorithms for a generalized hopset problem which, when combined with known existential bounds, lead to different approximation guarantees for various regimes depending on hopbound, stretch, and directed vs. undirected inputs. We complement our upper bounds with a lower bound that implies Label Cover hardness for directed hopsets and shortcut sets with hopbound at least $3$.</description>
      <guid isPermaLink="false">oai:arXiv.org:2502.06522v1</guid>
      <category>cs.DS</category>
      <category>cs.DM</category>
      <pubDate>Tue, 11 Feb 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Michael Dinitz, Ama Koranteng, Yasamin Nazari</dc:creator>
    </item>
    <item>
      <title>On the FirstFit Algorithm for Online Unit-Interval Coloring</title>
      <link>https://arxiv.org/abs/2502.06558</link>
      <description>arXiv:2502.06558v1 Announce Type: new 
Abstract: In this paper, we study the performance of the FirstFit algorithm for the online unit-length intervals coloring problem where the intervals can be either open or closed, which serves a further investigation towards the actual performance of FirstFit. We develop a sophisticated counting method by generalizing the classic neighborhood bound, which limits the color FirstFit can assign an interval by counting the potential intersections. In the generalization, we show that for any interval, there is a critical interval intersecting it that can help reduce the overestimation of the number of intersections, and it further helps bound the color an interval can be assigned. The technical challenge then falls on identifying these critical intervals that guarantee the effectiveness of counting. Using this new mechanism for bounding the color that FirstFit can assign an interval, we provide a tight analysis of $2\omega$ colors when all intervals have integral endpoints and an upper bound of $\lceil\frac{7}{3}\omega\rceil-2$ colors for the general case, where $\omega$ is the optimal number of colors needed for the input set of intervals.</description>
      <guid isPermaLink="false">oai:arXiv.org:2502.06558v1</guid>
      <category>cs.DS</category>
      <pubDate>Tue, 11 Feb 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Bob Krekelberg, Alison Hsiang-Hsuan Liu</dc:creator>
    </item>
    <item>
      <title>Robust Scatter Matrix Estimation for Elliptical Distributions in Polynomial Time</title>
      <link>https://arxiv.org/abs/2502.06564</link>
      <description>arXiv:2502.06564v1 Announce Type: new 
Abstract: We study the problem of computationally efficient robust estimation of scatter matrices of elliptical distributions under the strong contamination model. We design polynomial time algorithms that achieve dimension-independent error in Frobenius norm.
  Our first result is a sequence of efficient algorithms that approaches nearly optimal error. Specifically, under a mild assumption on the eigenvalues of the scatter matrix $\Sigma$, for every $t \in \mathbb{N}$, we design an estimator that, given $n = d^{O(t)}$ samples, in time $n^{O(t)}$ finds $\hat{\Sigma}$ such that $ \Vert{\Sigma^{-1/2}\, ({\hat{\Sigma} - \Sigma})\, \Sigma^{-1/2}}\Vert_{\text{F}} \le O(t \cdot \varepsilon^{1-\frac{1}{t}})$, where $\varepsilon$ is the fraction of corruption. We do not require any assumptions on the moments of the distribution, while all previously known computationally efficient algorithms for robust covariance/scatter estimation with dimension-independent error rely on strong assumptions on the moments, such as sub-Gaussianity or (certifiable) hypercontractivity.
  Furthermore, under a stronger assumption on the eigenvalues of $\Sigma$ (that, in particular, is satisfied by all matrices with constant condition number),
  we provide a fast (sub-quadratic in the input size) algorithm that, given nearly optimal number of samples $n = \tilde{O}(d^2/\varepsilon)$, in time $\tilde{O}({nd^2 poly(1/\varepsilon)})$ finds $\hat{\Sigma}$ such that $\Vert\hat{\Sigma} - \Sigma\Vert_{\text{F}} \le O(\Vert{\Sigma}\Vert \cdot \sqrt{\varepsilon})$.
  Our approach is based on robust covariance estimation of the spatial sign (the projection onto the sphere of radius $\sqrt{d}$) of elliptical distributions.</description>
      <guid isPermaLink="false">oai:arXiv.org:2502.06564v1</guid>
      <category>cs.DS</category>
      <category>cs.LG</category>
      <category>math.ST</category>
      <category>stat.ML</category>
      <category>stat.TH</category>
      <pubDate>Tue, 11 Feb 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Gleb Novikov</dc:creator>
    </item>
    <item>
      <title>Decay of correlation for edge colorings when $q&gt;3\Delta$</title>
      <link>https://arxiv.org/abs/2502.06586</link>
      <description>arXiv:2502.06586v1 Announce Type: new 
Abstract: We examine various perspectives on the decay of correlation for the uniform distribution over proper $q$-edge colorings of graphs with maximum degree $\Delta$.
  First, we establish the coupling independence property when $q\ge 3\Delta$ for general graphs. Together with the work of Chen et al. (2024), this result implies a fully polynomial-time approximation scheme (FPTAS) for counting the number of proper $q$-edge colorings.
  Next, we prove the strong spatial mixing property on trees, provided that $q&gt; (3+o(1))\Delta$. The strong spatial mixing property is derived from the spectral independence property of a version of the weighted edge coloring distribution, which is established using the matrix trickle-down method developed in Abdolazimi, Liu and Oveis Gharan (FOCS, 2021) and Wang, Zhang and Zhang (STOC, 2024).
  Finally, we show that the weak spatial mixing property holds on trees with maximum degree $\Delta$ if and only if $q\ge 2\Delta-1$.</description>
      <guid isPermaLink="false">oai:arXiv.org:2502.06586v1</guid>
      <category>cs.DS</category>
      <category>math.PR</category>
      <pubDate>Tue, 11 Feb 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Zejia Chen, Yulin Wang, Chihao Zhang, Zihan Zhang</dc:creator>
    </item>
    <item>
      <title>Engineering Insights into Biclique Partitions and Fractional Binary Ranks of Matrices</title>
      <link>https://arxiv.org/abs/2502.06730</link>
      <description>arXiv:2502.06730v1 Announce Type: new 
Abstract: We investigate structural properties of the binary rank of Kronecker powers of binary matrices, equivalently, the biclique partition numbers of the corresponding bipartite graphs. To this end, we engineer a Column Generation approach to solve linear optimization problems for the fractional biclique partition number of bipartite graphs, specifically examining the Domino graph and its Kronecker powers. We address the challenges posed by the double exponential growth of the number of bicliques in increasing Kronecker powers. We discuss various strategies to generate suitable initial sets of bicliques, including an inductive method for increasing Kronecker powers. We show how to manage the number of active bicliques to improve running time and to stay within memory limits. Our computational results reveal that the fractional binary rank is not multiplicative with respect to the Kronecker product. Hence, there are binary matrices, and bipartite graphs, respectively, such as the Domino, where the asymptotic fractional binary rank is strictly smaller than the fractional binary rank. While we used our algorithm to reduce the upper bound, we formally prove that the fractional biclique cover number is a lower bound, which is at least as good as the widely used isolating (or fooling set) bound. For the Domino, we obtain that the asymptotic fractional binary rank lies in the interval $[2,2.373]$. Since our computational resources are not sufficient to further reduce the upper bound, we encourage further exploration using more substantial computing resources or further mathematical engineering techniques to narrow the gap and advance our understanding of biclique partitions, particularly, to settle the open question whether binary rank and biclique partition number are multiplicative with respect to the Kronecker product.</description>
      <guid isPermaLink="false">oai:arXiv.org:2502.06730v1</guid>
      <category>cs.DS</category>
      <pubDate>Tue, 11 Feb 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Angikar Ghosal, Andreas Karrenbauer</dc:creator>
    </item>
    <item>
      <title>$O(\sqrt{T})$ Static Regret and Instance Dependent Constraint Violation for Constrained Online Convex Optimization</title>
      <link>https://arxiv.org/abs/2502.05019</link>
      <description>arXiv:2502.05019v1 Announce Type: cross 
Abstract: The constrained version of the standard online convex optimization (OCO) framework, called COCO is considered, where on every round, a convex cost function and a convex constraint function are revealed to the learner after it chooses the action for that round. The objective is to simultaneously minimize the static regret and cumulative constraint violation (CCV). An algorithm is proposed that guarantees a static regret of $O(\sqrt{T})$ and a CCV of $\min\{\cV, O(\sqrt{T}\log T) \}$, where $\cV$ depends on the distance between the consecutively revealed constraint sets, the shape of constraint sets, dimension of action space and the diameter of the action space. For special cases of constraint sets, $\cV=O(1)$. Compared to the state of the art results, static regret of $O(\sqrt{T})$ and CCV of $O(\sqrt{T}\log T)$, that were universal, the new result on CCV is instance dependent, which is derived by exploiting the geometric properties of the constraint sets.</description>
      <guid isPermaLink="false">oai:arXiv.org:2502.05019v1</guid>
      <category>cs.LG</category>
      <category>cs.DS</category>
      <pubDate>Tue, 11 Feb 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Rahul Vaze, Abhishek Sinha</dc:creator>
    </item>
    <item>
      <title>Online Bidding Algorithms with Strict Return on Spend (ROS) Constraint</title>
      <link>https://arxiv.org/abs/2502.05599</link>
      <description>arXiv:2502.05599v1 Announce Type: cross 
Abstract: Auto-bidding problem under a strict return-on-spend constraint (ROSC) is considered, where an algorithm has to make decisions about how much to bid for an ad slot depending on the revealed value, and the hidden allocation and payment function that describes the probability of winning the ad-slot depending on its bid. The objective of an algorithm is to maximize the expected utility (product of ad value and probability of winning the ad slot) summed across all time slots subject to the total expected payment being less than the total expected utility, called the ROSC. A (surprising) impossibility result is derived that shows that no online algorithm can achieve a sub-linear regret even when the value, allocation and payment function are drawn i.i.d. from an unknown distribution. The problem is non-trivial even when the revealed value remains constant across time slots, and an algorithm with regret guarantee that is optimal up to logarithmic factor is derived.</description>
      <guid isPermaLink="false">oai:arXiv.org:2502.05599v1</guid>
      <category>cs.GT</category>
      <category>cs.DS</category>
      <category>cs.LG</category>
      <pubDate>Tue, 11 Feb 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Rahul Vaze, Abhishek Sinha</dc:creator>
    </item>
    <item>
      <title>Attainability of Two-Point Testing Rates for Finite-Sample Location Estimation</title>
      <link>https://arxiv.org/abs/2502.05730</link>
      <description>arXiv:2502.05730v1 Announce Type: cross 
Abstract: LeCam's two-point testing method yields perhaps the simplest lower bound for estimating the mean of a distribution: roughly, if it is impossible to well-distinguish a distribution centered at $\mu$ from the same distribution centered at $\mu+\Delta$, then it is impossible to estimate the mean by better than $\Delta/2$. It is setting-dependent whether or not a nearly matching upper bound is attainable. We study the conditions under which the two-point testing lower bound can be attained for univariate mean estimation; both in the setting of location estimation (where the distribution is known up to translation) and adaptive location estimation (unknown distribution). Roughly, we will say an estimate nearly attains the two-point testing lower bound if it incurs error that is at most polylogarithmically larger than the Hellinger modulus of continuity for $\tilde{\Omega}(n)$ samples.
  Adaptive location estimation is particularly interesting as some distributions admit much better guarantees than sub-Gaussian rates (e.g. $\operatorname{Unif}(\mu-1,\mu+1)$ permits error $\Theta(\frac{1}{n})$, while the sub-Gaussian rate is $\Theta(\frac{1}{\sqrt{n}})$), yet it is not obvious whether these rates may be adaptively attained by one unified approach. Our main result designs an algorithm that nearly attains the two-point testing rate for mixtures of symmetric, log-concave distributions with a common mean. Moreover, this algorithm runs in near-linear time and is parameter-free. In contrast, we show the two-point testing rate is not nearly attainable even for symmetric, unimodal distributions.
  We complement this with results for location estimation, showing the two-point testing rate is nearly attainable for unimodal distributions, but unattainable for symmetric distributions.</description>
      <guid isPermaLink="false">oai:arXiv.org:2502.05730v1</guid>
      <category>math.ST</category>
      <category>cs.DS</category>
      <category>stat.ML</category>
      <category>stat.TH</category>
      <pubDate>Tue, 11 Feb 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Spencer Compton, Gregory Valiant</dc:creator>
    </item>
    <item>
      <title>Amnesiac Flooding: Easy to break, hard to escape</title>
      <link>https://arxiv.org/abs/2502.06001</link>
      <description>arXiv:2502.06001v1 Announce Type: cross 
Abstract: Broadcast is a central problem in distributed computing. Recently, Hussak and Trehan [PODC'19/DC'23] proposed a stateless broadcasting protocol (Amnesiac Flooding), which was surprisingly proven to terminate in asymptotically optimal time (linear in the diameter of the network). However, it remains unclear: (i) Are there other stateless terminating broadcast algorithms with the desirable properties of Amnesiac Flooding, (ii) How robust is Amnesiac Flooding with respect to \emph{faults}?
  In this paper we make progress on both of these fronts. Under a reasonable restriction (obliviousness to message content) additional to the fault-free synchronous model, we prove that Amnesiac Flooding is the \emph{only} strictly stateless deterministic protocol that can achieve terminating broadcast. We identify four natural properties of a terminating broadcast protocol that Amnesiac Flooding uniquely satisfies. In contrast, we prove that even minor relaxations of \textit{any} of these four criteria allow the construction of other terminating broadcast protocols.
  On the other hand, we prove that Amnesiac Flooding can become non-terminating or non-broadcasting, even if we allow just one node to drop a single message on a single edge in a single round. As a tool for proving this, we focus on the set of all \textit{configurations} of transmissions between nodes in the network, and obtain a \textit{dichotomy} characterizing the configurations, starting from which, Amnesiac Flooding terminates.
  Additionally, we characterise the structure of sets of Byzantine agents capable of forcing non-termination or non-broadcast of the protocol on arbitrary networks.</description>
      <guid isPermaLink="false">oai:arXiv.org:2502.06001v1</guid>
      <category>cs.DC</category>
      <category>cs.DM</category>
      <category>cs.DS</category>
      <pubDate>Tue, 11 Feb 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Henry Austin, Maximilien Gadouleau, George B. Mertzios, Amitabh Trehan</dc:creator>
    </item>
    <item>
      <title>Pcodec: Better Compression for Numerical Sequences</title>
      <link>https://arxiv.org/abs/2502.06112</link>
      <description>arXiv:2502.06112v1 Announce Type: cross 
Abstract: We present Pcodec (Pco), a format and algorithm for losslessly compressing numerical sequences. Pco's core and most novel component is a binning algorithm that quickly converges to the true entropy of smoothly, independently, and identically distributed (SIID) data. To automatically handle more general data, Pco has two opinionated preprocessing steps. The first step, Pco's mode, decomposes the data into more smoothly distributed latent variables. The second step, delta encoding, makes the latents more independently and identically distributed. We prove that, given $k$ bins, binning uses only $\mathcal{O}(1/k)$ bits more than the SIID data's entropy. Additionally, we demonstrate that Pco achieves 29-94% higher compression ratio than other approaches on six real-world datasets while using less compression time.</description>
      <guid isPermaLink="false">oai:arXiv.org:2502.06112v1</guid>
      <category>cs.IT</category>
      <category>cs.DS</category>
      <category>math.IT</category>
      <pubDate>Tue, 11 Feb 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Martin Loncaric, Niels Jeppesen, Ben Zinberg</dc:creator>
    </item>
    <item>
      <title>A Quadratic Lower Bound for Stable Roommates Solvability</title>
      <link>https://arxiv.org/abs/2502.06464</link>
      <description>arXiv:2502.06464v2 Announce Type: cross 
Abstract: In their seminal work on the Stable Marriage Problem (SM), Gale and Shapley introduced a generalization of SM referred to as the Stable Roommates Problem (SR). An instance of SR consists of a set of $2n$ agents, and each agent has preferences in the form of a ranked list of all other agents. The goal is to find a one-to-one matching between the agents that is stable in the sense that no pair of agents have a mutual incentive to deviate from the matching. Unlike the (bipartite) stable marriage problem, in SR, stable matchings need not exist. Irving devised an algorithm that finds a stable matching or reports that none exists in $O(n^2)$ time. In their influential 1989 text, Gusfield and Irving posed the question of whether $\Omega(n^2)$ time is required for SR solvability -- the task of deciding if an SR instance admits a stable matching.
  In this paper we provide an affirmative answer to Gusfield and Irving's question. We show that any (randomized) algorithm that decides SR solvability requires $\Omega(n^2)$ adaptive Boolean queries to the agents' preferences (in expectation). Our argument follows from a reduction from the communication complexity of the set disjointness function. The query lower bound implies quadratic time lower bounds for Turing machines, and memory access lower bounds for random access machines. Thus, we establish that Irving's algorithm is optimal (up to a logarithmic factor) in a very strong sense.</description>
      <guid isPermaLink="false">oai:arXiv.org:2502.06464v2</guid>
      <category>cs.CC</category>
      <category>cs.DS</category>
      <category>cs.GT</category>
      <pubDate>Tue, 11 Feb 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Will Rosenbaum</dc:creator>
    </item>
    <item>
      <title>Improved Hardness of Approximation for Geometric Bin Packing</title>
      <link>https://arxiv.org/abs/2301.09272</link>
      <description>arXiv:2301.09272v3 Announce Type: replace 
Abstract: The Geometric Bin Packing (GBP) problem is a generalization of Bin Packing where the input is a set of $d$-dimensional rectangles, and the goal is to pack them into unit $d$-dimensional cubes efficiently. It is NP-Hard to obtain a PTAS for the problem, even when $d=2$. For general $d$, the best-known approximation algorithm has an approximation guarantee exponential in $d$, while the best hardness of approximation is still a small constant inapproximability from the case when $d=2$. In this paper, we show that the problem cannot be approximated within $d^{1-\epsilon}$ factor unless NP=P.
  Recently, $d$-dimensional Vector Bin Packing, a closely related problem to the GBP, was shown to be hard to approximate within $\Omega(\log d)$ when $d$ is a fixed constant, using a notion of Packing Dimension of set families. In this paper, we introduce a geometric analog of it, the Geometric Packing Dimension of set families. While we fall short of obtaining similar inapproximability results for the Geometric Bin Packing problem when $d$ is fixed, we prove a couple of key properties of the Geometric Packing Dimension which highlight fundamental differences between Geometric Bin Packing and Vector Bin Packing.</description>
      <guid isPermaLink="false">oai:arXiv.org:2301.09272v3</guid>
      <category>cs.DS</category>
      <category>cs.CC</category>
      <category>cs.CG</category>
      <pubDate>Tue, 11 Feb 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <arxiv:DOI>10.1016/j.ipl.2024.106552</arxiv:DOI>
      <arxiv:journal_reference>Information Processing Letters, Volume 189, March 2025, 106552</arxiv:journal_reference>
      <dc:creator>Arka Ray, Sai Sandeep</dc:creator>
    </item>
    <item>
      <title>Optimality of Non-Adaptive Algorithms in Online Submodular Welfare Maximization with Stochastic Outcomes</title>
      <link>https://arxiv.org/abs/2403.18059</link>
      <description>arXiv:2403.18059v3 Announce Type: replace 
Abstract: We generalize the problem of online submodular welfare maximization to incorporate various stochastic elements that have gained significant attention in recent years. We show that a non-adaptive Greedy algorithm, which is oblivious to the realization of these stochastic elements, achieves the best possible competitive ratio among all polynomial-time algorithms, including adaptive ones. This result holds even when the objective function is not submodular but instead satisfies the weaker submodular order property. Our results unify and strengthen existing competitive ratio bounds across well-studied settings and diverse arrival models, showing that, in general, adaptivity to stochastic elements offers no advantage in terms of competitive ratio.
  To establish these results, we introduce a technique that lifts known results from the deterministic setting to the generalized stochastic setting. The technique has broad applicability, enabling us to show that, in certain special cases, non-adaptive Greedy-like algorithms outperform the Greedy algorithm and achieve the optimal competitive ratio. We also apply the technique in reverse to derive new upper bounds on the performance of Greedy-like algorithms in deterministic settings by leveraging upper bounds on the performance of non-adaptive algorithms in stochastic settings.</description>
      <guid isPermaLink="false">oai:arXiv.org:2403.18059v3</guid>
      <category>cs.DS</category>
      <pubDate>Tue, 11 Feb 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Rajan Udwani</dc:creator>
    </item>
    <item>
      <title>Small Space Encoding and Recognition of $k$-Palindromic Prefixes</title>
      <link>https://arxiv.org/abs/2410.03309</link>
      <description>arXiv:2410.03309v3 Announce Type: replace 
Abstract: Palindromes are non-empty strings that read the same forward and backward. The problem of recognizing strings that can be represented as the concatenation of even-length palindromes, the concatenation of palindromes of length at least two, and the concatenation of exactly $k$ palindromes was introduced in the seminal paper of Knuth, Morris, and Pratt [SIAM J. Comput., 1977].
  In this work, we study the problem of recognizing so-called $k$-palindromic strings, which can be represented as the concatenation of exactly $k$ palindromes. We show the following results:
  1. First, we show a structural characterization of the set of all $k$-palindromic prefixes of a string by representing it as a union of a small number of highly structured string sets, called affine prefix sets. Representing the lengths of the $k$-palindromic prefixes in this way requires $O(6^{k^2} \cdot \log^k n)$ space. By constructing a lower bound, we show that the space complexity is optimal up to polylogarithmic factors for reasonably small values of $k$.
  2. Secondly, we derive a read-only algorithm that, given a string $T$ of length $n$ and an integer $k$, computes a compact representation of $i$-palindromic prefixes of $T$, for all $1 \le i \le k$. The algorithm uses $O(n \cdot 6^{k^2} \cdot \log^k n)$ time and $O(6^{k^2} \cdot \log^k n)$ space.
  3. Finally, we also give a read-only algorithm for computing the palindromic length of $T$, which is the smallest $\ell$ such that $T$ is $\ell$-palindromic. Here, we achieve $O(n \cdot 6^{\ell^2} \cdot \log^{\lceil{\ell/2 \rceil}} n)$ time and $O(6^{\ell^2} \cdot \log^{\lceil{\ell/2\rceil}} n)$ space. For some values of $\ell$, this is the first algorithm for palindromic length that uses $o(n)$ additional working space on top of the input.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.03309v3</guid>
      <category>cs.DS</category>
      <pubDate>Tue, 11 Feb 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Gabriel Bathie, Jonas Ellert, Tatiana Starikovskaya</dc:creator>
    </item>
    <item>
      <title>Counterexamples to a Weitz-Style Reduction for Multispin Systems</title>
      <link>https://arxiv.org/abs/2411.06541</link>
      <description>arXiv:2411.06541v2 Announce Type: replace 
Abstract: In a seminal paper, Weitz showed that for two-state spin systems, such as the Ising and hardcore models from statistical physics, correlation decay on trees implies correlation decay on arbitrary graphs. The key gadget in Weitz's reduction has been instrumental in recent advances in approximate counting and sampling, from analysis of local Markov chains like Glauber dynamics to the design of deterministic algorithms for estimating the partition function. A longstanding open problem in the field has been to find such a reduction for more general multispin systems like the uniform distribution over proper colorings of a graph.
  In this paper, we show that for a rich class of multispin systems, including the ferromagnetic Potts model, there are fundamental obstacles to extending Weitz's reduction to the multispin setting. A central component of our investigation is establishing nonconvexity of the image of the belief propagation functional, the standard tool for analyzing spin systems on trees. On the other hand, we provide evidence of convexity for the antiferromagnetic Potts model.</description>
      <guid isPermaLink="false">oai:arXiv.org:2411.06541v2</guid>
      <category>cs.DS</category>
      <category>math.PR</category>
      <pubDate>Tue, 11 Feb 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Kuikui Liu, Nitya Mani, Francisco Pernice</dc:creator>
    </item>
    <item>
      <title>Complexity of Minimal Faithful Permutation Degree for Fitting-free Groups</title>
      <link>https://arxiv.org/abs/2501.16039</link>
      <description>arXiv:2501.16039v2 Announce Type: replace 
Abstract: In this paper, we investigate the complexity of computing the minimal faithful permutation degree for groups without abelian normal subgroups. When our groups are given as quotients of permutation groups, we establish that this problem is in $\textsf{P}$. Furthermore, in the setting of permutation groups, we obtain an upper bound of $\textsf{NC}$ for this problem. This improves upon the work of Das and Thakkar (STOC 2024), who established a Las Vegas polynomial-time algorithm for this class in the setting of permutation groups.</description>
      <guid isPermaLink="false">oai:arXiv.org:2501.16039v2</guid>
      <category>cs.DS</category>
      <category>cs.CC</category>
      <category>math.GR</category>
      <pubDate>Tue, 11 Feb 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Michael Levet, Pranjal Srivastava, Dhara Thakkar</dc:creator>
    </item>
    <item>
      <title>Minimum Riesz s-Energy Subset Selection in Ordered Point Sets via Dynamic Programming</title>
      <link>https://arxiv.org/abs/2502.01163</link>
      <description>arXiv:2502.01163v3 Announce Type: replace 
Abstract: We present a dynamic programming algorithm for selecting a representative subset of size $k$ from a given set with $n$ points such that the Riesz $s$-energy is near minimized. While NP-hard in general dimensions, the one-dimensional case can use the natural data ordering for efficient dynamic programming as an effective heuristic solution approach. This approach is then extended to problems related to two-dimensional Pareto front representations arising in biobjective optimization problems. Under the assumption of sorted (or non-dominated) input, the method typically yields near-optimal solutions in most cases. We also show that the approach avoids mistakes of greedy subset-selection by means of example. However, as we demonstrate, there are exceptions where DP does not identify the global minimum; for example, in one of our examples, the DP solution slightly deviates from the configuration found by a brute-force search. This is because the DP scheme's recurrence is approximate. The total time complexity of our algorithm is shown to be $O(n^2 k)$. We provide computational examples with discontinuous Pareto fronts and an open-source Python implementation, demonstrating the approximate DP algorithm's effectiveness across various problems with large point sets.</description>
      <guid isPermaLink="false">oai:arXiv.org:2502.01163v3</guid>
      <category>cs.DS</category>
      <pubDate>Tue, 11 Feb 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Michael Emmerich</dc:creator>
    </item>
    <item>
      <title>From Zero-Freeness to Strong Spatial Mixing via a Christoffel-Darboux Type Identity</title>
      <link>https://arxiv.org/abs/2401.09317</link>
      <description>arXiv:2401.09317v3 Announce Type: replace-cross 
Abstract: We present a unifying proof to derive the strong spatial mixing (SSM) property for the general 2-spin system from zero-free regions of its partition function. Our proof works for the multivariate partition function over all three complex parameters $(\beta, \gamma, \lambda)$, and we allow the zero-free regions of $\beta, \gamma$ or $\lambda$ to be of arbitrary shapes. Our main technical contribution is to establish a Christoffel-Darboux type identity for the 2-spin system on trees so that we are able to handle zero-free regions of the three different parameters $\beta, \gamma$ or $\lambda$ in a unified way. We use Riemann mapping theorem to deal with zere-free regions of arbitrary shapes.
  Our result comprehensively turns all existing zero-free regions (to our best knowledge) of the partition function of the 2-spin system where pinned vertices are allowed into the SSM property. As a consequence, we obtain novel SSM properties for the 2-spin system beyond the direct argument for SSM based on tree recurrence. Moreover, we extend our result to handle the 2-spin system with non-uniform external fields. As an application, we obtain a new SSM property and two new forms of spatial mixing property, namely plus and minus spatial mixing for the non-uniform ferromagnetic Ising model from the celebrated Lee-Yang circle theorem.</description>
      <guid isPermaLink="false">oai:arXiv.org:2401.09317v3</guid>
      <category>math-ph</category>
      <category>cs.DS</category>
      <category>math.CO</category>
      <category>math.MP</category>
      <category>math.PR</category>
      <pubDate>Tue, 11 Feb 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Shuai Shao, Xiaowei Ye</dc:creator>
    </item>
    <item>
      <title>Communication-efficient Vertical Federated Learning via Compressed Error Feedback</title>
      <link>https://arxiv.org/abs/2406.14420</link>
      <description>arXiv:2406.14420v2 Announce Type: replace-cross 
Abstract: Communication overhead is a known bottleneck in federated learning (FL). To address this, lossy compression is commonly used on the information communicated between the server and clients during training. In horizontal FL, where each client holds a subset of the samples, such communication-compressed training methods have recently seen significant progress. However, in their vertical FL counterparts, where each client holds a subset of the features, our understanding remains limited. To address this, we propose an error feedback compressed vertical federated learning (EF-VFL) method to train split neural networks. In contrast to previous communication-compressed methods for vertical FL, EF-VFL does not require a vanishing compression error for the gradient norm to converge to zero for smooth nonconvex problems. By leveraging error feedback, our method can achieve a $\mathcal{O}(1/T)$ convergence rate for a sufficiently large batch size, improving over the state-of-the-art $\mathcal{O}(1/\sqrt{T})$ rate under $\mathcal{O}(1/\sqrt{T})$ compression error, and matching the rate of uncompressed methods. Further, when the objective function satisfies the Polyak-{\L}ojasiewicz inequality, our method converges linearly. In addition to improving convergence, our method also supports the use of private labels. Numerical experiments show that EF-VFL significantly improves over the prior art, confirming our theoretical results. The code for this work can be found at https://github.com/Valdeira/EF-VFL.</description>
      <guid isPermaLink="false">oai:arXiv.org:2406.14420v2</guid>
      <category>cs.LG</category>
      <category>cs.DC</category>
      <category>cs.DS</category>
      <category>math.OC</category>
      <pubDate>Tue, 11 Feb 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Pedro Valdeira, Jo\~ao Xavier, Cl\'audia Soares, Yuejie Chi</dc:creator>
    </item>
    <item>
      <title>Privacy of the last iterate in cyclically-sampled DP-SGD on nonconvex composite losses</title>
      <link>https://arxiv.org/abs/2407.05237</link>
      <description>arXiv:2407.05237v3 Announce Type: replace-cross 
Abstract: Differentially-private stochastic gradient descent (DP-SGD) is a family of iterative machine learning training algorithms that privatize gradients to generate a sequence of differentially-private (DP) model parameters. It is also the standard tool used to train DP models in practice, even though most users are only interested in protecting the privacy of the final model. Tight DP accounting for the last iterate would minimize the amount of noise required while maintaining the same privacy guarantee and potentially increasing model utility. However, last-iterate accounting is challenging, and existing works require strong assumptions not satisfied by most implementations. These include assuming (i) the global sensitivity constant is known - to avoid gradient clipping; (ii) the loss function is Lipschitz or convex; and (iii) input batches are sampled randomly.
  In this work, we forego any unrealistic assumptions and provide privacy bounds for the most commonly used variant of DP-SGD, in which data is traversed cyclically, gradients are clipped, and only the last model is released. More specifically, we establish new Renyi differential privacy (RDP) upper bounds for the last iterate under realistic assumptions of small stepsize and Lipschitz smoothness of the loss function. Our general bounds also recover the special-case convex bounds when the weak-convexity parameter of the objective function approaches zero and no clipping is performed. The approach itself leverages optimal transport techniques for last iterate bounds, which is a nontrivial task when the data is traversed cyclically and the loss function is nonconvex.</description>
      <guid isPermaLink="false">oai:arXiv.org:2407.05237v3</guid>
      <category>cs.LG</category>
      <category>cs.CR</category>
      <category>cs.DS</category>
      <category>math.OC</category>
      <category>stat.ML</category>
      <pubDate>Tue, 11 Feb 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Weiwei Kong, M\'onica Ribero</dc:creator>
    </item>
    <item>
      <title>Quantum Approximate Optimization Algorithms for Maximum Cut on Low-Girth Graphs</title>
      <link>https://arxiv.org/abs/2410.04409</link>
      <description>arXiv:2410.04409v2 Announce Type: replace-cross 
Abstract: Maximum cut (MaxCut) on graphs is a classic NP-hard problem. In quantum computing, Farhi, Gutmann, and Goldstone proposed the Quantum Approximate Optimization Algorithm (QAOA) for solving the MaxCut problem. Its guarantee on cut fraction (the fraction of edges in the output cut over all edges) was mainly studied for high-girth graphs, i.e., graphs with only long cycles. On the other hand, low-girth graphs are ubiquitous in theoretical computer science, including expander graphs being outstanding examples with wide applications in theory and beyond. In this paper, we apply QAOA to MaxCut on a set of expander graphs proposed by Mohanty and O'Donnell known as additive product graphs. Additionally, we apply multi-angle QAOA (ma-QAOA) to better utilize the graph structure of additive product graphs in ansatz design. In theory, we derive an iterative formula to calculate the expected cut fraction of such graphs. This formula also extends to the quantum MaxCut problem. On the other hand, we conduct numerical experiments to compare between best-known classical local algorithms and QAOA with constant depth. Our results demonstrate that QAOA outperforms the best-known classical algorithms by 0.3% to 5.2% on several additive product graphs, while ma-QAOA further enhances this advantage by an additional 0.6% to 2.5%. In particular, we observe cases that ma-QAOA exhibits superiority over best-known classical algorithms but QAOA does not. Furthermore, we extend our experiments to planar graphs such as tiling grid graphs, where QAOA also demonstrates an advantage.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.04409v2</guid>
      <category>quant-ph</category>
      <category>cs.DS</category>
      <category>math.OC</category>
      <pubDate>Tue, 11 Feb 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Tongyang Li, Yuexin Su, Ziyi Yang, Shengyu Zhang</dc:creator>
    </item>
  </channel>
</rss>
