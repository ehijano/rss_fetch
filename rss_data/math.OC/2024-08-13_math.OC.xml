<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>math.OC updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/math.OC</link>
    <description>math.OC updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/math.OC" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Wed, 14 Aug 2024 04:00:36 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Wed, 14 Aug 2024 00:00:00 -0400</pubDate>
    <skipDays>
      <day>Sunday</day>
      <day>Saturday</day>
    </skipDays>
    <item>
      <title>Fast Explicit Machine Learning-Based Model Predictive Control of Nonlinear Processes Using Input Convex Neural Networks</title>
      <link>https://arxiv.org/abs/2408.06580</link>
      <description>arXiv:2408.06580v1 Announce Type: new 
Abstract: Explicit machine learning-based model predictive control (explicit ML-MPC) has been developed to reduce the real-time computational demands of traditional ML-MPC. However, the evaluation of candidate control actions in explicit ML-MPC can be time-consuming due to the non-convex nature of machine learning models. To address this issue, we leverage Input Convex Neural Networks (ICNN) to develop explicit ICNN-MPC, which is formulated as a convex optimization problem. Specifically, ICNN is employed to capture nonlinear system dynamics and incorporated into MPC, with sufficient conditions provided to ensure the convexity of ICNN-based MPC. We then formulate mixed-integer quadratic programming (MIQP) problems based on the candidate control actions derived from the solutions of multi-parametric quadratic programming (mpQP) problems within the explicit ML-MPC framework. Optimal control actions are obtained by solving real-time convex MIQP problems. The effectiveness of the proposed method is demonstrated through two case studies, including a chemical reactor example, and a chemical process network simulated by Aspen Plus Dynamics, where explicit ML-MPC written in Python is integrated with Aspen dynamic simulation through a programmable interface.</description>
      <guid isPermaLink="false">oai:arXiv.org:2408.06580v1</guid>
      <category>math.OC</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Wenlong Wang, Haohao Zhang, Yujia Wang, Yuhe Tian, Zhe Wu</dc:creator>
    </item>
    <item>
      <title>An extra gradient Anderson-accelerated algorithm for pseudomonotone variational inequalities</title>
      <link>https://arxiv.org/abs/2408.06606</link>
      <description>arXiv:2408.06606v1 Announce Type: new 
Abstract: This paper proposes an extra gradient Anderson-accelerated algorithm for solving pseudomonotone variational inequalities, which uses the extra gradient scheme with line search to guarantee the global convergence and Anderson acceleration to have fast convergent rate. We prove that the sequence generated by the proposed algorithm from any initial point converges to a solution of the pseudomonotone variational inequality problem without assuming the Lipschitz continuity and contractive condition, which are used for convergence analysis of the extra gradient method and Anderson-accelerated method, respectively in existing literatures. Numerical experiments, particular emphasis on Harker-Pang problem, fractional programming, nonlinear complementarity problem and PDE problem with free boundary, are conducted to validate the effectiveness and good performance of the proposed algorithm comparing with the extra gradient method and Anderson-accelerated method.</description>
      <guid isPermaLink="false">oai:arXiv.org:2408.06606v1</guid>
      <category>math.OC</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Xin Qu, Wei Bian, Xiaojun Chen</dc:creator>
    </item>
    <item>
      <title>Method with Batching for Stochastic Finite-Sum Variational Inequalities in Non-Euclidean Setting</title>
      <link>https://arxiv.org/abs/2408.06728</link>
      <description>arXiv:2408.06728v1 Announce Type: new 
Abstract: Variational inequalities are a universal optimization paradigm that incorporate classical minimization and saddle point problems. Nowadays more and more tasks require to consider stochastic formulations of optimization problems. In this paper, we present an analysis of a method that gives optimal convergence estimates for monotone stochastic finite-sum variational inequalities. In contrast to the previous works, our method supports batching, does not lose the oracle complexity optimality and uses an arbitrary Bregman distance to take into account geometry of the problem. Paper provides experimental confirmation to algorithm's effectiveness.</description>
      <guid isPermaLink="false">oai:arXiv.org:2408.06728v1</guid>
      <category>math.OC</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Alexander Pichugin, Maksim Pechin, Aleksandr Beznosikov, Vasilii Novitskii, Alexander Gasnikov</dc:creator>
    </item>
    <item>
      <title>Extended mean field control problems with constraints: The generalized Fritz-John conditions and Lagrangian method</title>
      <link>https://arxiv.org/abs/2408.06865</link>
      <description>arXiv:2408.06865v1 Announce Type: new 
Abstract: This paper studies the extended mean field control problems under dynamic expectation constraints and/or dynamic state-control constraints. We aim to pioneer the establishment of the stochastic maximum principle (SMP) and the derivation of the backward SDE (BSDE) from the perspective of the constrained optimization using the method of Lagrangian multipliers. To this end, we first propose to embed the constrained extended mean-field control (C-(E)MFC) problems into some abstract optimization problems with constraints on Banach spaces, for which we develop the generalized Fritz-John (FJ) optimality conditions. We then prove the stochastic maximum principle (SMP) for C-(E)MFC problems by transforming the FJ type conditions into an equivalent stochastic first-order condition associated with a general type of constrained forward-backward SDEs (FBSDEs). Contrary to the existing literature, we recast the controlled Mckean-Vlasov SDE as an infinite-dimensional equality constraint such that the BSDE induced by the FJ first-order optimality condition can be interpreted as the generalized Lagrange multiplier to cope with the SDE constraint. Finally, we also present the SMP for constrained stochastic control problems and constrained mean field game problems as consequences of our main result for C-(E)MFC problems.</description>
      <guid isPermaLink="false">oai:arXiv.org:2408.06865v1</guid>
      <category>math.OC</category>
      <category>math.PR</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Lijun Bo, Jingfei Wang, Xiang Yu</dc:creator>
    </item>
    <item>
      <title>Tikhonov regularization of second-order plus first-order primal-dual dynamical systems for separable convex optimization</title>
      <link>https://arxiv.org/abs/2408.06884</link>
      <description>arXiv:2408.06884v1 Announce Type: new 
Abstract: This paper deals with a Tikhonov regularized second-order plus first-order primal-dual dynamical system with time scaling for separable convex optimization problems with linear equality constraints. This system consists of two second-order ordinary differential equations for the primal variables and one first-order ordinary differential equation for the dual variable.By utilizing the Lyapunov analysis approach, we obtain the convergence properties of the primal-dual gap, the objective function error, the feasibility measure and the gradient norm of the objective function along the trajectory. We also establish the strong convergence of the primal trajectory generated by the dynamical system towards the minimal norm solution of the separable convex optimization problem. Furthermore, we give numerical experiments to illustrate the theoretical results, showing that our dynamical system performs better than those in the literature in terms of convergence rates.</description>
      <guid isPermaLink="false">oai:arXiv.org:2408.06884v1</guid>
      <category>math.OC</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Xiangkai Sun, Lijuan Zheng, Kok Lay Teo</dc:creator>
    </item>
    <item>
      <title>Local geometry of feasible regions via smooth paths</title>
      <link>https://arxiv.org/abs/2408.06984</link>
      <description>arXiv:2408.06984v1 Announce Type: new 
Abstract: Variational analysis presents a unified theory encompassing in particular both smoothness and convexity. In a Euclidean space, convex sets and smooth manifolds both have straightforward local geometry. However, in the most basic hybrid case of feasible regions consisting of pre-images of convex sets under maps that are once (but not necessarily twice) continuously differentiable, the geometry is less transparent. We define a new approximate convexity property, that holds both for such feasible regions and also for all prox-regular sets. This new property requires that nearby points can always be joined by smooth feasible paths that are almost straight. In particular, in the terminology of real algebraic geometry, such feasible regions are locally normally embedded in the Euclidean space.</description>
      <guid isPermaLink="false">oai:arXiv.org:2408.06984v1</guid>
      <category>math.OC</category>
      <category>math.MG</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Adrian S. Lewis, Adriana Nicolae, Tonghua Tian</dc:creator>
    </item>
    <item>
      <title>Kernel Sum of Squares for Data Adapted Kernel Learning of Dynamical Systems from Data: A global optimization approach</title>
      <link>https://arxiv.org/abs/2408.06465</link>
      <description>arXiv:2408.06465v1 Announce Type: cross 
Abstract: This paper examines the application of the Kernel Sum of Squares (KSOS) method for enhancing kernel learning from data, particularly in the context of dynamical systems. Traditional kernel-based methods, despite their theoretical soundness and numerical efficiency, frequently struggle with selecting optimal base kernels and parameter tuning, especially with gradient-based methods prone to local optima. KSOS mitigates these issues by leveraging a global optimization framework with kernel-based surrogate functions, thereby achieving more reliable and precise learning of dynamical systems. Through comprehensive numerical experiments on the Logistic Map, Henon Map, and Lorentz System, KSOS is shown to consistently outperform gradient descent in minimizing the relative-$\rho$ metric and improving kernel accuracy. These results highlight KSOS's effectiveness in predicting the behavior of chaotic dynamical systems, demonstrating its capability to adapt kernels to underlying dynamics and enhance the robustness and predictive power of kernel-based approaches, making it a valuable asset for time series analysis in various scientific fields.</description>
      <guid isPermaLink="false">oai:arXiv.org:2408.06465v1</guid>
      <category>cs.LG</category>
      <category>math.DS</category>
      <category>math.OC</category>
      <category>stat.ML</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Daniel Lengyel, Panos Parpas, Boumediene Hamzi, Houman Owhadi</dc:creator>
    </item>
    <item>
      <title>Variance-Reduced Cascade Q-learning: Algorithms and Sample Complexity</title>
      <link>https://arxiv.org/abs/2408.06544</link>
      <description>arXiv:2408.06544v1 Announce Type: cross 
Abstract: We study the problem of estimating the optimal Q-function of $\gamma$-discounted Markov decision processes (MDPs) under the synchronous setting, where independent samples for all state-action pairs are drawn from a generative model at each iteration. We introduce and analyze a novel model-free algorithm called Variance-Reduced Cascade Q-learning (VRCQ). VRCQ comprises two key building blocks: (i) the established direct variance reduction technique and (ii) our proposed variance reduction scheme, Cascade Q-learning. By leveraging these techniques, VRCQ provides superior guarantees in the $\ell_\infty$-norm compared with the existing model-free stochastic approximation-type algorithms. Specifically, we demonstrate that VRCQ is minimax optimal. Additionally, when the action set is a singleton (so that the Q-learning problem reduces to policy evaluation), it achieves non-asymptotic instance optimality while requiring the minimum number of samples theoretically possible. Our theoretical results and their practical implications are supported by numerical experiments.</description>
      <guid isPermaLink="false">oai:arXiv.org:2408.06544v1</guid>
      <category>stat.ML</category>
      <category>cs.LG</category>
      <category>cs.SY</category>
      <category>eess.SY</category>
      <category>math.OC</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Mohammad Boveiri, Peyman Mohajerin Esfahani</dc:creator>
    </item>
    <item>
      <title>From Maximum Cut to Maximum Independent Set</title>
      <link>https://arxiv.org/abs/2408.06758</link>
      <description>arXiv:2408.06758v1 Announce Type: cross 
Abstract: The Maximum Cut (Max-Cut) problem could be naturally expressed either in a Quadratic Unconstrained Binary Optimization (QUBO) formulation, or as an Ising model. It has long been known that the Maximum Independent Set (MIS) problem could also be related to a specific Ising model. Therefore, it would be natural to attack MIS with various Max-Cut/Ising solvers. It turns out that this strategy greatly improves the approximation for the independence number of random Erd\H{o}s-R\'{e}nyi graphs. It also exhibits perfect performance on a benchmark arising from coding theory. These results pave the way for further development of approximate quantum algorithms on MIS, and specifically on the corresponding coding problems.</description>
      <guid isPermaLink="false">oai:arXiv.org:2408.06758v1</guid>
      <category>quant-ph</category>
      <category>math.CO</category>
      <category>math.OC</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-sa/4.0/</dc:rights>
      <dc:creator>Chuixiong Wu, Jianan Wang, Fen Zuo</dc:creator>
    </item>
    <item>
      <title>Robustness of optimal quantum annealing protocols</title>
      <link>https://arxiv.org/abs/2408.06782</link>
      <description>arXiv:2408.06782v1 Announce Type: cross 
Abstract: Noise in quantum computing devices poses a key challenge in their realization. In this paper, we study the robustness of optimal quantum annealing protocols against coherent control errors, which are multiplicative Hamlitonian errors causing detrimental effects on current quantum devices. We show that the norm of the Hamiltonian quantifies the robustness against these errors, motivating the introduction of an additional regularization term in the cost function. We analyze the optimality conditions of the resulting robust quantum optimal control problem based on Pontryagin's maximum principle, showing that robust protocols admit larger smooth annealing sections. This suggests that quantum annealing admits improved robustness in comparison to bang-bang solutions such as the quantum approximate optimization algorithm. Finally, we perform numerical simulations to verify our analytical results and demonstrate the improved robustness of the proposed approach.</description>
      <guid isPermaLink="false">oai:arXiv.org:2408.06782v1</guid>
      <category>quant-ph</category>
      <category>cs.SY</category>
      <category>eess.SY</category>
      <category>math.OC</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Niklas Funcke, Julian Berberich</dc:creator>
    </item>
    <item>
      <title>Robust Model Predictive Control for Aircraft Intent-Aware Collision Avoidance</title>
      <link>https://arxiv.org/abs/2408.06999</link>
      <description>arXiv:2408.06999v1 Announce Type: cross 
Abstract: This paper presents the use of robust model predictive control for the design of an intent-aware collision avoidance system for multi-agent aircraft engaged in horizontal maneuvering scenarios. We assume that information from other agents is accessible in the form of waypoints or destinations. Consequently, we consider that other agents follow their optimal Dubin's path--a trajectory that connects their current state to their intended state--while accounting for potential uncertainties. We propose using scenario tree model predictive control as a robust approach that offers computational efficiency. We demonstrate that the proposed method can easily integrate intent information and offer a robust scheme that handles different uncertainties. The method is illustrated through simulation results.</description>
      <guid isPermaLink="false">oai:arXiv.org:2408.06999v1</guid>
      <category>eess.SY</category>
      <category>cs.SY</category>
      <category>math.OC</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Arash Bahari Kordabad, Andrea Da Col, Arabinda Ghosh, Sybert Stroeve, Sadegh Soudjani</dc:creator>
    </item>
    <item>
      <title>Nonconvex Factorization and Manifold Formulations are Almost Equivalent in Low-rank Matrix Optimization</title>
      <link>https://arxiv.org/abs/2108.01772</link>
      <description>arXiv:2108.01772v3 Announce Type: replace 
Abstract: In this paper, we consider the geometric landscape connection of the widely studied manifold and factorization formulations in low-rank positive semidefinite (PSD) and general matrix optimization. We establish a sandwich relation on the spectrum of Riemannian and Euclidean Hessians at first-order stationary points (FOSPs). As a result of that, we obtain an equivalence on the set of FOSPs, second-order stationary points (SOSPs) and strict saddles between the manifold and the factorization formulations. In addition, we show the sandwich relation can be used to transfer more quantitative geometric properties from one formulation to another. Similarities and differences in the landscape connection under the PSD case and the general case are discussed. To the best of our knowledge, this is the first geometric landscape connection between the manifold and the factorization formulations for handling rank constraints, and it provides a geometric explanation for the similar empirical performance of factorization and manifold approaches in low-rank matrix optimization observed in the literature. In the general low-rank matrix optimization, the landscape connection of two factorization formulations (unregularized and regularized ones) is also provided. By applying these geometric landscape connections, in particular, the sandwich relation, we are able to solve unanswered questions in literature and establish stronger results in the applications on geometric analysis of phase retrieval, well-conditioned low-rank matrix optimization, and the role of regularization in factorization arising from machine learning and signal processing.</description>
      <guid isPermaLink="false">oai:arXiv.org:2108.01772v3</guid>
      <category>math.OC</category>
      <category>cs.IT</category>
      <category>cs.LG</category>
      <category>eess.SP</category>
      <category>math.IT</category>
      <category>stat.ML</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-sa/4.0/</dc:rights>
      <dc:creator>Yuetian Luo, Xudong Li, Anru R. Zhang</dc:creator>
    </item>
    <item>
      <title>The Principle of Optimality in Dynamic Programming: A Pedagogical Note</title>
      <link>https://arxiv.org/abs/2302.08467</link>
      <description>arXiv:2302.08467v5 Announce Type: replace 
Abstract: The principle of optimality is a fundamental aspect of dynamic programming, which states that the optimal solution to a dynamic optimization problem can be found by combining the optimal solutions to its sub-problems. While this principle is generally applicable, it is often only taught for problems with finite or countable state spaces in order to sidestep measure-theoretic complexities. Therefore, it cannot be applied to classic models such as inventory management and dynamic pricing models that have continuous state spaces, and students may not be aware of the possible challenges involved in studying dynamic programming models with general state spaces. To address this, we provide conditions and a self-contained simple proof that establish when the principle of optimality for discounted dynamic programming is valid. These conditions shed light on the difficulties that may arise in the general state space case. We provide examples from the literature that include the relatively involved case of universally measurable dynamic programming and the simple case of finite dynamic programming where our main result can be applied to show that the principle of optimality holds.</description>
      <guid isPermaLink="false">oai:arXiv.org:2302.08467v5</guid>
      <category>math.OC</category>
      <category>math.PR</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Bar Light</dc:creator>
    </item>
    <item>
      <title>A Decentralized Primal-Dual Method with Quasi-Newton Tracking</title>
      <link>https://arxiv.org/abs/2304.01614</link>
      <description>arXiv:2304.01614v3 Announce Type: replace 
Abstract: This paper considers the decentralized optimization problem of minimizing a finite sum of strongly convex and twice continuously differentiable functions over a fixed-connected undirected network. A fully decentralized primal-dual method(DPDM) and its generalization(GDPDM), which allows for multiple primal steps per iteration, are proposed. In our methods, both primal and dual updates use second-order information obtained by quasi-Newton techniques which only involve matrix-vector multiplication. Specifically, the primal update applies a Jacobi relaxation step using the BFGS approximation for both computation and communication efficiency. The dual update employs a new second-order correction step. We show that the decentralized local primal updating direction on each node asymptotically approaches the centralized quasi-Newton direction. Under proper choice of parameters, GDPDM including DPDM has global linear convergence for solving strongly convex decentralized optimization problems. Our numerical results show both GDPDM and DPDM are very efficient compared with other state-of-the-art methods for solving decentralized optimization.</description>
      <guid isPermaLink="false">oai:arXiv.org:2304.01614v3</guid>
      <category>math.OC</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Hao Wu, Liping Wang, Hongchao Zhang</dc:creator>
    </item>
    <item>
      <title>On indication, strict monotonicity, and efficiency of projections in a general class of path-based data envelopment models</title>
      <link>https://arxiv.org/abs/2311.16382</link>
      <description>arXiv:2311.16382v2 Announce Type: replace 
Abstract: Data envelopment analysis (DEA) theory formulates a number of desirable properties that DEA models should satisfy. Among these, indication, strict monotonicity, and strong efficiency of projections tend to be grouped together in the sense that, in individual models, typically, either all three are satisfied or all three fail at the same time. Specifically, in slacks-based graph models, the three properties are always met; in path-based models, such as radial models, directional distance function models, and the hyperbolic function model, the three properties, with some minor exceptions, typically all fail.
  Motivated by this observation, the article examines relationships among indication, strict monotonicity, and strong efficiency of projections in the class of path-based models over variable returns-to-scale technology sets. Under mild assumptions, it is shown that the property of strict monotonicity and strong efficiency of projections are equivalent, and that both properties imply indication. This paper also characterises a narrow class of technology sets and path directions for which the three properties hold in path-based models.</description>
      <guid isPermaLink="false">oai:arXiv.org:2311.16382v2</guid>
      <category>math.OC</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <arxiv:DOI>10.1016/j.ejor.2024.08.009</arxiv:DOI>
      <dc:creator>Margar\'eta Halick\'a, M\'aria Trnovsk\'a, Ale\v{s} \v{C}ern\'y</dc:creator>
    </item>
    <item>
      <title>The Robust Bilevel Selection Problem</title>
      <link>https://arxiv.org/abs/2401.03951</link>
      <description>arXiv:2401.03951v2 Announce Type: replace 
Abstract: In bilevel optimization problems, a leader and a follower make their decisions in a hierarchy, and both decisions may influence each other. Usually one assumes that both players have full knowledge also of the other player's data. In a more realistic model, uncertainty can be quantified, e.g., using the robust optimization approach: We assume that the leader does not know the follower's objective precisely, but only up to some uncertainty set, and her aim is to optimize the worst case of the corresponding scenarios. Now the question arises how the complexity of bilevel optimization changes under the additional complications of this uncertainty.
  We make a further step towards answering this question by examining an easy bilevel problem. In the Bilevel Selection Problem (BSP), the leader and the follower each select some items from their own item set, while a common number of items to select in total is given, and each player minimizes the total costs of the selected items, according to different sets of item costs. We show that the BSP can be solved in polynomial time and then investigate its robust version. If the two players' item sets are disjoint, it can still be solved in polynomial time for several types of uncertainty sets. Otherwise, we show that the Robust BSP is NP-hard and present a 2-approximation algorithm and exact exponential-time approaches.
  Furthermore, we investigate variants of the BSP where one or both of the two players take a continuous decision. One variant leads to an example of a bilevel optimization problem whose optimal value may not be attained. For the Robust Continuous BSP, where all variables are continuous, we also develop a new approach for the setting of discrete uncorrelated uncertainty, which gives a polynomial-time algorithm for the Robust Continuous BSP and a pseudopolynomial-time algorithm for the Robust Bilevel Continuous Knapsack Problem.</description>
      <guid isPermaLink="false">oai:arXiv.org:2401.03951v2</guid>
      <category>math.OC</category>
      <category>cs.DS</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Dorothee Henke</dc:creator>
    </item>
    <item>
      <title>Revisiting Inexact Fixed-Point Iterations for Min-Max Problems: Stochasticity and Structured Nonconvexity</title>
      <link>https://arxiv.org/abs/2402.05071</link>
      <description>arXiv:2402.05071v2 Announce Type: replace 
Abstract: We focus on constrained, $L$-smooth, potentially stochastic and nonconvex-nonconcave min-max problems either satisfying $\rho$-cohypomonotonicity or admitting a solution to the $\rho$-weakly Minty Variational Inequality (MVI), where larger values of the parameter $\rho&gt;0$ correspond to a greater degree of nonconvexity. These problem classes include examples in two player reinforcement learning, interaction dominant min-max problems, and certain synthetic test problems on which classical min-max algorithms fail. It has been conjectured that first-order methods can tolerate a value of $\rho$ no larger than $\frac{1}{L}$, but existing results in the literature have stagnated at the tighter requirement $\rho &lt; \frac{1}{2L}$. With a simple argument, we obtain optimal or best-known complexity guarantees with cohypomonotonicity or weak MVI conditions for $\rho &lt; \frac{1}{L}$. First main insight for the improvements in the convergence analyses is to harness the recently proposed $\textit{conic nonexpansiveness}$ property of operators. Second, we provide a refined analysis for inexact Halpern iteration that relaxes the required inexactness level to improve some state-of-the-art complexity results even for constrained stochastic convex-concave min-max problems. Third, we analyze a stochastic inexact Krasnosel'ski\u{\i}-Mann iteration with a multilevel Monte Carlo estimator when the assumptions only hold with respect to a solution.</description>
      <guid isPermaLink="false">oai:arXiv.org:2402.05071v2</guid>
      <category>math.OC</category>
      <category>cs.LG</category>
      <category>stat.ML</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <arxiv:journal_reference>Proceedings of the International Conference on Machine Learning (ICML) 2024</arxiv:journal_reference>
      <dc:creator>Ahmet Alacaoglu, Donghwan Kim, Stephen J. Wright</dc:creator>
    </item>
    <item>
      <title>Stochastic linear quadratic optimal control problems with regime-switching jumps in infinite horizon</title>
      <link>https://arxiv.org/abs/2403.00288</link>
      <description>arXiv:2403.00288v2 Announce Type: replace 
Abstract: This paper investigates a stochastic linear-quadratic (SLQ, for short) control problem regulated by a time-invariant Markov chain in infinite horizon. Under the $L^2$-stability framework, we study a class of linear backward stochastic differential equations (BSDE, for short) in infinite horizon and discuss the open-loop and closed-loop solvabilities of the SLQ problem. The open-loop solvability is characterized by the solvability of a system of coupled forward-backward stochastic differential equations (FBSDEs, for short) in infinite horizon and the convexity of the cost functional, and the closed-loop solvability is shown to be equivalent to the open-loop solvability, which in turn is equivalent to the existence of a static stabilizing solution to the associated constrained coupled algebra Riccati equations (CAREs, for short). Under the uniform convexity assumption, we obtain the unique solvability of associated CAREs and construct the corresponding closed-loop optimal control. Finally, we also solve a class of discounted SLQ problems and give two concrete examples to illustrate the results developed in the earlier sections.</description>
      <guid isPermaLink="false">oai:arXiv.org:2403.00288v2</guid>
      <category>math.OC</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Fan Wu, Xun Li, Xin Zhang</dc:creator>
    </item>
    <item>
      <title>Forced Symmetric Formation Control</title>
      <link>https://arxiv.org/abs/2403.02836</link>
      <description>arXiv:2403.02836v2 Announce Type: replace 
Abstract: This work considers the distance constrained formation control problem with an additional constraint requiring that the formation exhibits a specified spatial symmetry. We employ recent results from the theory of symmetry-forced rigidity to construct an appropriate potential function that leads to a gradient dynamical system driving the agents to the desired formation. We show that only $(1+1/|\Gamma|)n$ edges are sufficient to implement the control strategy when there are $n$ agents and the underlying symmetry group is $\Gamma$. This number is considerably smaller than what is typically required from classic rigidity-theory based strategies ($2n-3$ edges). We also provide an augmented control strategy that ensures the agents can converge to a formation with respect to an arbitrary centroid. Numerous numerical examples are provided to illustrate the main results.</description>
      <guid isPermaLink="false">oai:arXiv.org:2403.02836v2</guid>
      <category>math.OC</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-sa/4.0/</dc:rights>
      <dc:creator>Daniel Zelazo, Shin-ichi Tanigawa, Bernd Schulze</dc:creator>
    </item>
    <item>
      <title>Efficient Online Prediction for High-Dimensional Time Series via Joint Tensor Tucker Decomposition</title>
      <link>https://arxiv.org/abs/2403.18320</link>
      <description>arXiv:2403.18320v2 Announce Type: replace 
Abstract: Real-time prediction plays a vital role in various control systems, such as traffic congestion control and wireless channel resource allocation. In these scenarios, the predictor usually needs to track the evolution of the latent statistical patterns in the modern high-dimensional streaming time series continuously and quickly, which presents new challenges for traditional prediction methods. This paper is the first to propose a novel online algorithm (TOPA) based on tensor factorization to predict streaming tensor time series. The proposed algorithm TOPA updates the predictor in a low-complexity online manner to adapt to the time-evolving data. Additionally, an automatically adaptive version of the algorithm (TOPA-AAW) is presented to mitigate the negative impact of stale data. Simulation results demonstrate that our proposed methods achieve prediction accuracy similar to that of conventional offline tensor prediction methods, while being much faster than them during long-term online prediction. Therefore, TOPA-AAW is an effective and efficient solution method for the online prediction of streaming tensor time series.</description>
      <guid isPermaLink="false">oai:arXiv.org:2403.18320v2</guid>
      <category>math.OC</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Zhenting Luan, Defeng Sun, Haoning Wang, Liping Zhang</dc:creator>
    </item>
    <item>
      <title>Non-convex Pose Graph Optimization in SLAM via Proximal Linearized Riemannian ADMM</title>
      <link>https://arxiv.org/abs/2404.18560</link>
      <description>arXiv:2404.18560v2 Announce Type: replace 
Abstract: Pose graph optimization (PGO) is a well-known technique for solving the pose-based simultaneous localization and mapping (SLAM) problem. In this paper, we represent the rotation and translation by a unit quaternion and a three-dimensional vector, and propose a new PGO model based on the von Mises-Fisher distribution. The constraints derived from the unit quaternions are spherical manifolds, and the projection onto the constraints can be calculated by normalization. Then a proximal linearized Riemannian alternating direction method of multipliers (PieADMM) is developed to solve the proposed model, which not only has low memory requirements, but also can update the poses in parallel. Furthermore, we establish the iteration complexity of $O(1/\epsilon^{2})$ of PieADMM for finding an $\epsilon$-stationary solution of our model. The efficiency of our proposed algorithm is demonstrated by numerical experiments on two synthetic and four 3D SLAM benchmark datasets.</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.18560v2</guid>
      <category>math.OC</category>
      <category>cs.RO</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Xin Chen, Chunfeng Cui, Deren Han, Liqun Qi</dc:creator>
    </item>
    <item>
      <title>Decentralized Optimization with Coupled Constraints</title>
      <link>https://arxiv.org/abs/2407.02020</link>
      <description>arXiv:2407.02020v3 Announce Type: replace 
Abstract: We consider the decentralized minimization of a separable objective $\sum_{i=1}^{n} f_i(x_i)$, where the variables are coupled through an affine constraint $\sum_{i=1}^n\left(\mathbf{A}_i x_i - b_i\right) = 0$. We assume that the functions $f_i$, matrices $\mathbf{A}_i$, and vectors $b_i$ are stored locally by the nodes of a computational network, and that the functions $f_i$ are smooth and strongly convex.
  This problem has significant applications in resource allocation and systems control and can also arise in distributed machine learning. We propose lower complexity bounds for decentralized optimization problems with coupled constraints and a first-order algorithm achieving the lower bounds. To the best of our knowledge, our method is also the first linearly convergent first-order decentralized algorithm for problems with general affine coupled constraints.</description>
      <guid isPermaLink="false">oai:arXiv.org:2407.02020v3</guid>
      <category>math.OC</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Demyan Yarmoshik, Alexander Rogozin, Nikita Kiselev, Daniil Dorin, Alexander Gasnikov, Dmitry Kovalev</dc:creator>
    </item>
    <item>
      <title>Weyl Calculus and Exactly Solvable Schr\"{o}dinger Bridges with Quadratic State Cost</title>
      <link>https://arxiv.org/abs/2407.15245</link>
      <description>arXiv:2407.15245v3 Announce Type: replace 
Abstract: Schr\"{o}dinger bridge--a stochastic dynamical generalization of optimal mass transport--exhibits a learning-control duality. Viewed as a stochastic control problem, the Schr\"{o}dinger bridge finds an optimal control policy that steers a given joint state statistics to another while minimizing the total control effort subject to controlled diffusion and deadline constraints. Viewed as a stochastic learning problem, the Schr\"{o}dinger bridge finds the most-likely distribution-valued trajectory connecting endpoint distributional observations, i.e., solves the two point boundary-constrained maximum likelihood problem over the manifold of probability distributions. Recent works have shown that solving the Schr\"{o}dinger bridge problem with state cost requires finding the Markov kernel associated with a reaction-diffusion PDE where the state cost appears as a state-dependent reaction rate. We explain how ideas from Weyl calculus in quantum mechanics, specifically the Weyl operator and the Weyl symbol, can help determine such Markov kernels. We illustrate these ideas by explicitly finding the Markov kernel for the case of quadratic state cost via Weyl calculus, recovering our earlier results but avoiding tedious computation with Hermite polynomials.</description>
      <guid isPermaLink="false">oai:arXiv.org:2407.15245v3</guid>
      <category>math.OC</category>
      <category>cs.LG</category>
      <category>cs.SY</category>
      <category>eess.SY</category>
      <category>math-ph</category>
      <category>math.MP</category>
      <category>stat.ML</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Alexis M. H. Teter, Wenqing Wang, Abhishek Halder</dc:creator>
    </item>
    <item>
      <title>The Binary Linearization Complexity of Pseudo-Boolean Functions</title>
      <link>https://arxiv.org/abs/2301.06207</link>
      <description>arXiv:2301.06207v3 Announce Type: replace-cross 
Abstract: We consider the problem of linearizing a pseudo-Boolean function $f : \{0,1\}^n \to \mathbb{R}$ by means of $k$ Boolean functions. Such a linearization yields an integer linear programming formulation with only $k$ auxiliary variables. This motivates the definition of the linarization complexity of $f$ as the minimum such $k$. Our theoretical contributions are the proof that random polynomials almost surely have a high linearization complexity and characterizations of its value in case we do or do not restrict the set of admissible Boolean functions. The practical relevance is shown by devising and evaluating integer linear programming models of two such linearizations for the low auto-correlation binary sequences problem. Still, many problems around this new concept remain open.</description>
      <guid isPermaLink="false">oai:arXiv.org:2301.06207v3</guid>
      <category>cs.DM</category>
      <category>math.OC</category>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Matthias Walter</dc:creator>
    </item>
    <item>
      <title>Neural networks can detect model-free static arbitrage strategies</title>
      <link>https://arxiv.org/abs/2306.16422</link>
      <description>arXiv:2306.16422v2 Announce Type: replace-cross 
Abstract: In this paper we demonstrate both theoretically as well as numerically that neural networks can detect model-free static arbitrage opportunities whenever the market admits some. Due to the use of neural networks, our method can be applied to financial markets with a high number of traded securities and ensures almost immediate execution of the corresponding trading strategies. To demonstrate its tractability, effectiveness, and robustness we provide examples using real financial data. From a technical point of view, we prove that a single neural network can approximately solve a class of convex semi-infinite programs, which is the key result in order to derive our theoretical results that neural networks can detect model-free static arbitrage strategies whenever the financial market admits such opportunities.</description>
      <guid isPermaLink="false">oai:arXiv.org:2306.16422v2</guid>
      <category>q-fin.CP</category>
      <category>cs.LG</category>
      <category>math.OC</category>
      <category>q-fin.MF</category>
      <category>stat.ML</category>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Ariel Neufeld, Julian Sester</dc:creator>
    </item>
    <item>
      <title>A Network-Constrained Demand Response Game for Procuring Energy Balancing Services</title>
      <link>https://arxiv.org/abs/2306.17475</link>
      <description>arXiv:2306.17475v2 Announce Type: replace-cross 
Abstract: Securely and efficiently procuring energy balancing services in distribution networks remains challenging, especially within a privacy-preserving environment. This paper proposes a network-constrained demand response game, i.e., a Generalized Nash Game (GNG), to incentivize energy consumers to offer balancing services. Specifically, we adopt a supply function-based bidding method for our demand response problem, where a requisite load adjustment must be met. To ensure the secure operation of distribution networks, we incorporate physical network constraints, including line capacity and bus voltage limits, into the game formulation. In addition, we analytically evaluate the efficiency loss of this game. Previous approaches to steer energy consumers toward the Generalized Nash Equilibrium (GNE) of the game often necessitated sharing some private information, which might not be practically feasible or desired. To overcome this limitation, we propose a decentralized market clearing algorithm with analytical convergence guarantees, which only requires the participants to share limited, non-sensitive information with others. Numerical analyses illustrate that the proposed market mechanism exhibits a low market efficiency loss. Moreover, these analyses highlight the critical role of integrating physical network constraints. Finally, we demonstrate the scalability of our proposed algorithm by conducting simulations on the IEEE 33-bus and 69-bus test systems.</description>
      <guid isPermaLink="false">oai:arXiv.org:2306.17475v2</guid>
      <category>eess.SY</category>
      <category>cs.SY</category>
      <category>math.OC</category>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Xiupeng Chen, Koorosh Shomalzadeh, Jacquelien M. A. Scherpen, Nima Monshizadeh</dc:creator>
    </item>
    <item>
      <title>An Ensemble Score Filter for Tracking High-Dimensional Nonlinear Dynamical Systems</title>
      <link>https://arxiv.org/abs/2309.00983</link>
      <description>arXiv:2309.00983v2 Announce Type: replace-cross 
Abstract: We propose an ensemble score filter (EnSF) for solving high-dimensional nonlinear filtering problems with superior accuracy. A major drawback of existing filtering methods, e.g., particle filters or ensemble Kalman filters, is the low accuracy in handling high-dimensional and highly nonlinear problems. EnSF attacks this challenge by exploiting the score-based diffusion model, defined in a pseudo-temporal domain, to characterizing the evolution of the filtering density. EnSF stores the information of the recursively updated filtering density function in the score function, instead of storing the information in a set of finite Monte Carlo samples (used in particle filters and ensemble Kalman filters). Unlike existing diffusion models that train neural networks to approximate the score function, we develop a training-free score estimation that uses a mini-batch-based Monte Carlo estimator to directly approximate the score function at any pseudo-spatial-temporal location, which provides sufficient accuracy in solving high-dimensional nonlinear problems as well as saves a tremendous amount of time spent on training neural networks. High-dimensional Lorenz-96 systems are used to demonstrate the performance of our method. EnSF provides surprising performance, compared with the state-of-the-art Local Ensemble Transform Kalman Filter method, in reliably and efficiently tracking extremely high-dimensional Lorenz systems (up to 1,000,000 dimensions) with highly nonlinear observation processes.</description>
      <guid isPermaLink="false">oai:arXiv.org:2309.00983v2</guid>
      <category>stat.ML</category>
      <category>cs.LG</category>
      <category>math.OC</category>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Feng Bao, Zezhong Zhang, Guannan Zhang</dc:creator>
    </item>
    <item>
      <title>There is No Silver Bullet: Benchmarking Methods in Predictive Combinatorial Optimization</title>
      <link>https://arxiv.org/abs/2311.07633</link>
      <description>arXiv:2311.07633v3 Announce Type: replace-cross 
Abstract: Predictive combinatorial optimization, where the parameters of combinatorial optimization (CO) are unknown at the decision-making time, is the precise modeling of many real-world applications, including energy cost-aware scheduling and budget allocation on advertising. Tackling such a problem usually involves a prediction model and a CO solver. These two modules are integrated into the predictive CO pipeline following two design principles: ``Predict-then-Optimize (PtO)'', which learns predictions by supervised training and subsequently solves CO using predicted coefficients, while the other, named ``Predict-and-Optimize (PnO)'', directly optimizes towards the ultimate decision quality and claims to yield better decisions than traditional PtO approaches. However, there lacks a systematic benchmark of both approaches, including the specific design choices at the module level, as well as an evaluation dataset that covers representative real-world scenarios. To this end, we develop a modular framework to benchmark 11 existing PtO/PnO methods on 8 problems, including a new industrial dataset for combinatorial advertising that will be released. Our study shows that PnO approaches are better than PtO on 7 out of 8 benchmarks, but there is no silver bullet found for the specific design choices of PnO. A comprehensive categorization of current approaches and integration of typical scenarios are provided under a unified benchmark. Therefore, this paper could serve as a comprehensive benchmark for future PnO approach development and also offer fast prototyping for application-focused development.</description>
      <guid isPermaLink="false">oai:arXiv.org:2311.07633v3</guid>
      <category>cs.LG</category>
      <category>cs.AI</category>
      <category>math.OC</category>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Haoyu Geng, Hang Ruan, Runzhong Wang, Yang Li, Yang Wang, Lei Chen, Junchi Yan</dc:creator>
    </item>
    <item>
      <title>DPO: Differential reinforcement learning with application to optimal configuration search</title>
      <link>https://arxiv.org/abs/2404.15617</link>
      <description>arXiv:2404.15617v2 Announce Type: replace-cross 
Abstract: Reinforcement learning (RL) with continuous state and action spaces remains one of the most challenging problems within the field. Most current learning methods focus on integral identities such as value functions to derive an optimal strategy for the learning agent. In this paper, we instead study the dual form of the original RL formulation to propose the first differential RL framework that can handle settings with limited training samples and short-length episodes. Our approach introduces Differential Policy Optimization (DPO), a pointwise and stage-wise iteration method that optimizes policies encoded by local-movement operators. We prove a pointwise convergence estimate for DPO and provide a regret bound comparable with the best current theoretical derivation. Such pointwise estimate ensures that the learned policy matches the optimal path uniformly across different steps. We then apply DPO to a class of practical RL problems with continuous state and action spaces, and which search for optimal configurations with Lagrangian rewards. DPO is easy to implement, scalable, and shows competitive results on benchmarking experiments against several popular RL methods.</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.15617v2</guid>
      <category>cs.LG</category>
      <category>cs.AI</category>
      <category>math.OC</category>
      <category>math.ST</category>
      <category>stat.TH</category>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Chandrajit Bajaj, Minh Nguyen</dc:creator>
    </item>
    <item>
      <title>Biomarker Selection for Adaptive Systems</title>
      <link>https://arxiv.org/abs/2405.09809</link>
      <description>arXiv:2405.09809v3 Announce Type: replace-cross 
Abstract: Biomarkers enable objective monitoring of a given cell or state in a biological system and are widely used in research, biomanufacturing, and clinical practice. However, identifying appropriate biomarkers that are both robustly measurable and capture a state accurately remains challenging. We present a framework for biomarker identification based upon observability guided sensor selection. Our methods, Dynamic Sensor Selection (DSS) and Structure-Guided Sensor Selection (SGSS), utilize temporal models and experimental data, offering a template for applying observability theory to data from biological systems. Unlike conventional methods that assume well-known, fixed dynamics, DSS adaptively select biomarkers or sensors that maximize observability while accounting for the time-varying nature of biological systems. Additionally, SGSS incorporates structural information and diverse data to identify sensors which are resilient against inaccuracies in our model of the underlying system. We validate our approaches by performing estimation on high dimensional systems derived from temporal gene expression data from partial observations. Our algorithms reliably identify known biomarkers and uncover new ones within our datasets. Additionally, integrating chromosome conformation and gene expression data addresses noise and uncertainty, enhancing the reliability of our biomarker selection approach for the genome.</description>
      <guid isPermaLink="false">oai:arXiv.org:2405.09809v3</guid>
      <category>q-bio.MN</category>
      <category>math.OC</category>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Joshua Pickard, Cooper Stansbury, Amit Surana, Lindsey Muir, Anthony Bloch, Indika Rajapakse</dc:creator>
    </item>
  </channel>
</rss>
