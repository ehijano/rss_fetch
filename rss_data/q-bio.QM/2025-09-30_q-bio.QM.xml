<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>q-bio.QM updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/q-bio.QM</link>
    <description>q-bio.QM updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/q-bio.QM" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Wed, 01 Oct 2025 04:00:25 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Wed, 01 Oct 2025 00:00:00 -0400</pubDate>
    <skipDays>
      <day>Sunday</day>
      <day>Saturday</day>
    </skipDays>
    <item>
      <title>Marginal Girsanov Reweighting: Stable Variance Reduction via Neural Ratio Estimation</title>
      <link>https://arxiv.org/abs/2509.25872</link>
      <description>arXiv:2509.25872v1 Announce Type: new 
Abstract: Recovering unbiased properties from biased or perturbed simulations is a central challenge in rare-event sampling. Classical Girsanov Reweighting (GR) offers a principled solution by yielding exact pathwise probability ratios between perturbed and reference processes. However, the variance of GR weights grows rapidly with time, rendering it impractical for long-horizon reweighting. We introduce Marginal Girsanov Reweighting (MGR), which mitigates variance explosion by marginalizing over intermediate paths, producing stable and scalable weights for long-timescale dynamics. Experiments demonstrate that MGR (i) accurately recovers kinetic properties from umbrella-sampling trajectories in molecular dynamics, and (ii) enables efficient Bayesian parameter inference for stochastic differential equations with temporally sparse observations.</description>
      <guid isPermaLink="false">oai:arXiv.org:2509.25872v1</guid>
      <category>q-bio.QM</category>
      <category>q-bio.BM</category>
      <pubDate>Wed, 01 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Yan Wang, Hao Wu, Simon Olsson</dc:creator>
    </item>
    <item>
      <title>Commutative algebra neural network reveals genetic origins of diseases</title>
      <link>https://arxiv.org/abs/2509.26566</link>
      <description>arXiv:2509.26566v1 Announce Type: new 
Abstract: Genetic mutations can disrupt protein structure, stability, and solubility, contributing to a wide range of diseases. Existing predictive models often lack interpretability and fail to integrate physical and chemical interactions critical to molecular mechanisms. Moreover, current approaches treat disease association, stability changes, and solubility alterations as separate tasks, limiting model generalizability. In this study, we introduce a unified framework based on multiscale commutative algebra to capture intrinsic physical and chemical interactions for the first time. Leveraging Persistent Stanley-Reisner Theory, we extract multiscale algebraic invariants to build a Commutative Algebra neural Network (CANet). Integrated with transformer features and auxiliary physical features, we apply CANet to tackle three key domains for the first time: disease-associated mutations, mutation-induced protein stability changes, and solubility changes upon mutations. Across six benchmark tasks, CANet and its gradient boosting tree counterpart, CATree, consistently attain state-of-the-art performance, achieving up to 7.5% improvement in predictive accuracy. Our approach offers multiscale, mechanistic, interpretable,and generalizable models for predicting disease-mutation associations.</description>
      <guid isPermaLink="false">oai:arXiv.org:2509.26566v1</guid>
      <category>q-bio.QM</category>
      <category>math.AC</category>
      <category>q-bio.BM</category>
      <pubDate>Wed, 01 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>JunJie Wee, Faisal Suwayyid, Mushal Zia, Hongsong Feng, Yuta Hozumi, Guo-Wei Wei</dc:creator>
    </item>
    <item>
      <title>Can Molecular Foundation Models Know What They Don't Know? A Simple Remedy with Preference Optimization</title>
      <link>https://arxiv.org/abs/2509.25509</link>
      <description>arXiv:2509.25509v1 Announce Type: cross 
Abstract: Molecular foundation models are rapidly advancing scientific discovery, but their unreliability on out-of-distribution (OOD) samples severely limits their application in high-stakes domains such as drug discovery and protein design. A critical failure mode is chemical hallucination, where models make high-confidence yet entirely incorrect predictions for unknown molecules. To address this challenge, we introduce Molecular Preference-Aligned Instance Ranking (Mole-PAIR), a simple, plug-and-play module that can be flexibly integrated with existing foundation models to improve their reliability on OOD data through cost-effective post-training. Specifically, our method formulates the OOD detection problem as a preference optimization over the estimated OOD affinity between in-distribution (ID) and OOD samples, achieving this goal through a pairwise learning objective. We show that this objective essentially optimizes AUROC, which measures how consistently ID and OOD samples are ranked by the model. Extensive experiments across five real-world molecular datasets demonstrate that our approach significantly improves the OOD detection capabilities of existing molecular foundation models, achieving up to 45.8%, 43.9%, and 24.3% improvements in AUROC under distribution shifts of size, scaffold, and assay, respectively.</description>
      <guid isPermaLink="false">oai:arXiv.org:2509.25509v1</guid>
      <category>cs.LG</category>
      <category>q-bio.QM</category>
      <pubDate>Wed, 01 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Langzhou He, Junyou Zhu, Fangxin Wang, Junhua Liu, Haoyan Xu, Yue Zhao, Philip S. Yu, Qitian Wu</dc:creator>
    </item>
    <item>
      <title>Stochasticity and Practical Identifiability in Epidemic Models: A Monte Carlo Perspective</title>
      <link>https://arxiv.org/abs/2509.26577</link>
      <description>arXiv:2509.26577v1 Announce Type: cross 
Abstract: Assessing the practical identifiability of epidemic models is essential for determining whether parameters can be meaningfully estimated from observed data. Monte Carlo (MC) methods provide an accessible and intuitive framework; however, their standard implementation - perturbing deterministic trajectories with independent Gaussian noise - rests on assumptions poorly suited to epidemic processes, which are inherently stochastic, temporally correlated, and highly variable, especially in small populations or under slow transmission. In this study, we investigate the structure of stochastic variability in the classic Susceptible-Infected-Recovered (SIR) model across a range of epidemiological regimes, and assess whether it can be represented within the independent Gaussian noise framework. We show that continuous-time Markov chain (CTMC) trajectories consistently exhibit super-Poissonian variability and strong temporal dependence. Through coverage analysis, we further demonstrate that independent Gaussian noise systematically underestimates the variability of the underlying stochastic process, leading to overly optimistic conclusions about parameter identifiability. In addition, we propose a hybrid simulation approach that introduces time- and amplitude-dependent variability into deterministic ODE trajectories, preserving computational efficiency while capturing key features of epidemic stochasticity. Our findings highlight the limitations of the standard MC algorithm and provide a pathway for incorporating more realistic noise structures into epidemic inference.</description>
      <guid isPermaLink="false">oai:arXiv.org:2509.26577v1</guid>
      <category>stat.ME</category>
      <category>q-bio.QM</category>
      <pubDate>Wed, 01 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Chiara Mattamira, Olivia Prosper Feldman</dc:creator>
    </item>
    <item>
      <title>De novo peptide sequencing rescoring and FDR estimation with Winnow</title>
      <link>https://arxiv.org/abs/2509.24952</link>
      <description>arXiv:2509.24952v2 Announce Type: replace 
Abstract: Machine learning has markedly advanced de novo peptide sequencing (DNS) for mass spectrometry-based proteomics. DNS tools offer a reliable way to identify peptides without relying on reference databases, extending proteomic analysis and unlocking applications into less-charted regions of the proteome. However, they still face a key limitation. DNS tools lack principled methods for estimating false discovery rates (FDR) and instead rely on model-specific confidence scores that are often miscalibrated. This limits trust in results, hinders cross-model comparisons and reduces validation success. Here we present Winnow, a model-agnostic framework for estimating FDR from calibrated DNS outputs. Winnow maps raw model scores to calibrated confidences using a neural network trained on peptide-spectrum match (PSM)-derived features. From these calibrated scores, Winnow computes PSM-specific error metrics and an experiment-wide FDR estimate using a novel decoy-free FDR estimator. It supports both zero-shot and dataset-specific calibration, enabling flexible application via direct inference, fine-tuning, or training a custom model. We demonstrate that, when applied to InstaNovo predictions, Winnow's calibrator improves recall at fixed FDR thresholds, and its FDR estimator tracks true error rates when benchmarked against reference proteomes and database search. Winnow ensures accurate FDR control across datasets, helping unlock the full potential of DNS.</description>
      <guid isPermaLink="false">oai:arXiv.org:2509.24952v2</guid>
      <category>q-bio.QM</category>
      <pubDate>Wed, 01 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Amandla Mabona, Jemma Daniel, Henrik Servais Janssen Knudsen, Rachel Catzel, Kevin Michael Eloff, Erwin M. Schoof, Nicolas Lopez Carranza, Timothy P. Jenkins, Jeroen Van Goey, Konstantinos Kalogeropoulos</dc:creator>
    </item>
    <item>
      <title>Brain Tumor Classification on MRI in Light of Molecular Markers</title>
      <link>https://arxiv.org/abs/2409.19583</link>
      <description>arXiv:2409.19583v4 Announce Type: replace-cross 
Abstract: In research findings, co-deletion of the 1p/19q gene is associated with clinical outcomes in low-grade gliomas. The ability to predict 1p19q status is critical for treatment planning and patient follow-up. This study aims to utilize a specially MRI-based convolutional neural network for brain cancer detection. Although public networks such as RestNet and AlexNet can effectively diagnose brain cancers using transfer learning, the model includes quite a few weights that have nothing to do with medical images. As a result, the diagnostic results are unreliable by the transfer learning model. To deal with the problem of trustworthiness, we create the model from the ground up, rather than depending on a pre-trained model. To enable flexibility, we combined convolution stacking with a dropout and full connect operation, it improved performance by reducing overfitting. During model training, we also supplement the given dataset and inject Gaussian noise. We use three--fold cross-validation to train the best selection model. Comparing InceptionV3, VGG16, and MobileNetV2 fine-tuned with pre-trained models, our model produces better results. On an validation set of 125 codeletion vs. 31 not codeletion images, the proposed network achieves 96.37\% percent F1-score, 97.46\% percent precision, and 96.34\% percent recall when classifying 1p/19q codeletion and not codeletion images.</description>
      <guid isPermaLink="false">oai:arXiv.org:2409.19583v4</guid>
      <category>eess.IV</category>
      <category>cs.CV</category>
      <category>cs.LG</category>
      <category>q-bio.QM</category>
      <pubDate>Wed, 01 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <arxiv:journal_reference>Springer Nature - Book Series: Transactions on Computational Science &amp; Computational Intelligence, 2022</arxiv:journal_reference>
      <dc:creator>Jun Liu, Geng Yuan, Weihao Zeng, Hao Tang, Wenbin Zhang, Xue Lin, XiaoLin Xu, Dong Huang, Yanzhi Wang</dc:creator>
    </item>
    <item>
      <title>A Statistical Framework for Co-Mediators of Zero-Inflated Single-Cell RNA-Seq Data</title>
      <link>https://arxiv.org/abs/2507.06113</link>
      <description>arXiv:2507.06113v3 Announce Type: replace-cross 
Abstract: Single-cell RNA sequencing (scRNA-seq) has revolutionized the study of cellular heterogeneity, enabling detailed molecular profiling at the individual cell level. However, integrating high-dimensional single-cell data into causal mediation analysis remains challenging due to zero inflation and complex mediator structures. We propose a novel mediation framework leveraging zero-inflated negative binomial models to characterize cell-level mediator distributions and beta regression for zero-inflation proportions. The model can identify expression level as well as expressed proportion that could mediate disease-leading causal pathway. Extensive simulation studies demonstrate improved power and controlled false discovery rates. We further illustrate the utility of this approach through application to ROSMAP single-cell transcriptomic data, uncovering biologically meaningful mediation effects that enhance understanding of disease mechanisms.</description>
      <guid isPermaLink="false">oai:arXiv.org:2507.06113v3</guid>
      <category>stat.ME</category>
      <category>q-bio.GN</category>
      <category>q-bio.QM</category>
      <category>stat.AP</category>
      <pubDate>Wed, 01 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Seungjun Ahn, Li Chen, Maaike van Gerwen, Panos Roussos, Zhigang Li</dc:creator>
    </item>
    <item>
      <title>K-Dense Analyst: Towards Fully Automated Scientific Analysis</title>
      <link>https://arxiv.org/abs/2508.07043</link>
      <description>arXiv:2508.07043v2 Announce Type: replace-cross 
Abstract: The complexity of modern bioinformatics analysis has created a critical gap between data generation and developing scientific insights. While large language models (LLMs) have shown promise in scientific reasoning, they remain fundamentally limited when dealing with real-world analytical workflows that demand iterative computation, tool integration and rigorous validation. We introduce K-Dense Analyst, a hierarchical multi-agent system that achieves autonomous bioinformatics analysis through a dual-loop architecture. K-Dense Analyst, part of the broader K-Dense platform, couples planning with validated execution using specialized agents to decompose complex objectives into executable, verifiable tasks within secure computational environments. On BixBench, a comprehensive benchmark for open-ended biological analysis, K-Dense Analyst achieves 29.2% accuracy, surpassing the best-performing language model (GPT-5) by 6.3 percentage points, representing nearly 27% improvement over what is widely considered the most powerful LLM available. Remarkably, K-Dense Analyst achieves this performance using Gemini 2.5 Pro, which attains only 18.3% accuracy when used directly, demonstrating that our architectural innovations unlock capabilities far beyond the underlying model's baseline performance. Our insights demonstrate that autonomous scientific reasoning requires more than enhanced language models, it demands purpose-built systems that can bridge the gap between high-level scientific objectives and low-level computational execution. These results represent a significant advance toward fully autonomous computational biologists capable of accelerating discovery across the life sciences.</description>
      <guid isPermaLink="false">oai:arXiv.org:2508.07043v2</guid>
      <category>cs.AI</category>
      <category>cs.MA</category>
      <category>q-bio.GN</category>
      <category>q-bio.QM</category>
      <pubDate>Wed, 01 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Orion Li, Vinayak Agarwal, Summer Zhou, Ashwin Gopinath, Timothy Kassis</dc:creator>
    </item>
    <item>
      <title>A decision-theoretic framework for uncertainty quantification in epidemiological modelling</title>
      <link>https://arxiv.org/abs/2509.20013</link>
      <description>arXiv:2509.20013v2 Announce Type: replace-cross 
Abstract: Estimating, understanding, and communicating uncertainty is fundamental to statistical epidemiology, where model-based estimates regularly inform real-world decisions. However, sources of uncertainty are rarely formalised, and existing classifications are often defined inconsistently. This lack of structure hampers interpretation, model comparison, and targeted data collection. Connecting ideas from machine learning, information theory, experimental design, and health economics, we present a first-principles decision-theoretic framework that defines uncertainty as the expected loss incurred by making an estimate based on incomplete information, arguing that this is a highly useful and practically relevant definition for epidemiology. We show how reasoning about future data leads to a notion of expected uncertainty reduction, which induces formal definitions of reducible and irreducible uncertainty. We demonstrate our approach using a case study of SARS-CoV-2 wastewater surveillance in Aotearoa New Zealand, estimating the uncertainty reduction if wastewater surveillance were expanded to the full population. We then connect our framework to relevant literature from adjacent fields, showing how it unifies and extends many of these ideas and how it allows these ideas to be applied to a wider range of models. Altogether, our framework provides a foundation for more reliable, consistent, and policy-relevant uncertainty quantification in infectious disease epidemiology.</description>
      <guid isPermaLink="false">oai:arXiv.org:2509.20013v2</guid>
      <category>stat.ME</category>
      <category>q-bio.QM</category>
      <pubDate>Wed, 01 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <dc:creator>Nicholas Steyn, Freddie Bickford Smith, Cathal Mills, Vik Shirvaikar, Christl A Donnelly, Kris V Parag</dc:creator>
    </item>
  </channel>
</rss>
