<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>stat.ME updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/stat.ME</link>
    <description>stat.ME updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/stat.ME" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Fri, 13 Jun 2025 04:00:16 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Fri, 13 Jun 2025 00:00:00 -0400</pubDate>
    <skipDays>
      <day>Sunday</day>
      <day>Saturday</day>
    </skipDays>
    <item>
      <title>Limiting the Shrinkage for the Exceptional by Objective Robust Bayesian Analysis: the `Clemente Problem'</title>
      <link>https://arxiv.org/abs/2506.10114</link>
      <description>arXiv:2506.10114v1 Announce Type: new 
Abstract: In `borrowing strength' an important problem of Statistics is to treat exceptional cases in a fundamentally different. This is what has been coined as `the Clemente problem' in honor of R. Clemente (Efron 2010). In this article, we propose to use robust penalties, in the form of losses that penalize more severely huge errors, or (equivalently) priors of heavy tails which make more probable the exceptional. Using heavy tailed priors, we can reproduce in a Bayesian way Efron and Morris `limited translated estimators' (with Double Exponential Priors) and `discarding priors estimators' (with Cauchy like priors), which discard the prior in the presence of conflict. Both Empirical Bayes and Full Bayes approaches are able to alleviate the Clemente Problem and furthermore beat the James-Stein estimator in terms of smaller square errors, for sensible Robust Bayes priors. We model in parallel Empirical Bayes and Fully Bayesian hierarchical models, illustrating that the differences among sensible versions of both are relatively small, as compared with the effect due to the robust assumptions.</description>
      <guid isPermaLink="false">oai:arXiv.org:2506.10114v1</guid>
      <category>stat.ME</category>
      <pubDate>Fri, 13 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Luis R. Pericchi, Maria-Eglee Perez</dc:creator>
    </item>
    <item>
      <title>Classification of multiple segmented profiles, application to the study of the neuronal protein Tau</title>
      <link>https://arxiv.org/abs/2506.10126</link>
      <description>arXiv:2506.10126v1 Announce Type: new 
Abstract: This work is motivated by an application in neuroscience, in particular by the study of the (dys)functioning of a protein called Tau. The objective is to establish a classification of intensity profiles, according to the presence or absence of the protein and its monomer or dimer proportion. For this, we propose a Gaussian mixture model with a fixed number of clusters whose mean parameters are constrained and shared by the clusters. The inference of this model is done via the classical EM algorithm. The performance of the method is evaluated via simulation studies and an application on real data is done.</description>
      <guid isPermaLink="false">oai:arXiv.org:2506.10126v1</guid>
      <category>stat.ME</category>
      <category>stat.AP</category>
      <pubDate>Fri, 13 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Vincent Brault, Emilie Lebarbier, Am\'elie Rosier, Virginie Stoppin-Mellet</dc:creator>
    </item>
    <item>
      <title>Comparing name generator designs in rural panel studies: analyzing alter retention and change</title>
      <link>https://arxiv.org/abs/2506.10136</link>
      <description>arXiv:2506.10136v1 Announce Type: new 
Abstract: We conducted a two-wave personal network study in a rural Romanian community, interviewing the same participants (n = 68) using two name generators. Wave 1 employed a fixed-choice generator (n = 25) focused on emotional closeness; Wave 2 used a free-choice generator based on frequent interaction. We compared tie characteristics and assessed retention across waves. Alters who were kin, co-residents, or emotionally close were more likely to be retained, regardless of generator type. These findings underscore the role of relational attributes in personal network stability and highlight design considerations for network studies in resource-limited, culturally distinct settings.</description>
      <guid isPermaLink="false">oai:arXiv.org:2506.10136v1</guid>
      <category>stat.ME</category>
      <category>cs.SI</category>
      <category>physics.soc-ph</category>
      <category>stat.AP</category>
      <pubDate>Fri, 13 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Marian-Gabriel H\^ancean, J\"urgen Lerner, Christopher McCarty</dc:creator>
    </item>
    <item>
      <title>Robust copula estimation for one-shot devices with correlated failure modes</title>
      <link>https://arxiv.org/abs/2506.10152</link>
      <description>arXiv:2506.10152v1 Announce Type: new 
Abstract: This paper presents a robust method for estimating copula models to evaluate dependence between failure modes in one-shot devices-systems designed for single use and destroyed upon activation. Traditional approaches, such as maximum likelihood estimation (MLE), often produce unreliable results when faced with outliers or model misspecification. To overcome these limitations, we introduce a divergence-based estimation technique that enhances robustness and provides a more reliable characterization of the joint failure-time distribution. Extensive simulation studies confirm the robustness of the proposed method. Additionally, we illustrate its practical utility through the analysis of a real-world dataset.</description>
      <guid isPermaLink="false">oai:arXiv.org:2506.10152v1</guid>
      <category>stat.ME</category>
      <pubDate>Fri, 13 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>E. Castilla, P. J. Chocano</dc:creator>
    </item>
    <item>
      <title>A Bayesian Multisource Fusion Model for Spatiotemporal PM2.5 in an Urban Setting</title>
      <link>https://arxiv.org/abs/2506.10688</link>
      <description>arXiv:2506.10688v1 Announce Type: new 
Abstract: Airborne particulate matter (PM2.5) is a major public health concern in urban environments, where population density and emission sources exacerbate exposure risks. We present a novel Bayesian spatiotemporal fusion model to estimate monthly PM2.5 concentrations over Greater London (2014-2019) at 1km resolution. The model integrates multiple PM2.5 data sources, including outputs from two atmospheric air quality dispersion models and predictive variables, such as vegetation and satellite aerosol optical depth, while explicitly modelling a latent spatiotemporal field. Spatial misalignment of the data is addressed through an upscaling approach to predict across the entire area. Building on stochastic partial differential equations (SPDE) within the integrated nested Laplace approximations (INLA) framework, our method introduces spatially- and temporally-varying coefficients to flexibly calibrate datasets and capture fine-scale variability. Model performance and complexity are balanced using predictive metrics such as the predictive model choice criterion and thorough cross-validation. The best performing model shows excellent fit and solid predictive performance, enabling reliable high-resolution spatiotemporal mapping of PM2.5 concentrations with the associated uncertainty. Furthermore, the model outputs, including full posterior predictive distributions, can be used to map exceedance probabilities of regulatory thresholds, supporting air quality management and targeted interventions in vulnerable urban areas, as well as providing refined exposure estimates of PM2.5 for epidemiological applications.</description>
      <guid isPermaLink="false">oai:arXiv.org:2506.10688v1</guid>
      <category>stat.ME</category>
      <category>stat.AP</category>
      <pubDate>Fri, 13 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Abi I. Riley, Marta Blangiardo, Fr\'ed\'eric B. Piel, Andrew Beddows, Sean Beevers, Gary W. Fuller, Paul Agnew</dc:creator>
    </item>
    <item>
      <title>On feature selection in double-imbalanced data settings: a Random Forest approach</title>
      <link>https://arxiv.org/abs/2506.10929</link>
      <description>arXiv:2506.10929v1 Announce Type: new 
Abstract: Feature selection is a critical step in high-dimensional classification tasks, particularly under challenging conditions of double imbalance, namely settings characterized by both class imbalance in the response variable and dimensional asymmetry in the data $(n \gg p)$. In such scenarios, traditional feature selection methods applied to Random Forests (RF) often yield unstable or misleading importance rankings. This paper proposes a novel thresholding scheme for feature selection based on minimal depth, which exploits the tree topology to assess variable relevance. Extensive experiments on simulated and real-world datasets demonstrate that the proposed approach produces more parsimonious and accurate subsets of variables compared to conventional minimal depth-based selection. The method provides a practical and interpretable solution for variable selection in RF under double imbalance conditions.</description>
      <guid isPermaLink="false">oai:arXiv.org:2506.10929v1</guid>
      <category>stat.ME</category>
      <category>cs.LG</category>
      <pubDate>Fri, 13 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Fabio Demaria</dc:creator>
    </item>
    <item>
      <title>Estimating Signal-to-Noise Ratios for Multivariate High-dimensional Linear Models</title>
      <link>https://arxiv.org/abs/2506.10370</link>
      <description>arXiv:2506.10370v1 Announce Type: cross 
Abstract: Signal-to-noise ratios (SNR) play a crucial role in various statistical models, with important applications in tasks such as estimating heritability in genomics. The method-of-moments estimator is a widely used approach for estimating SNR, primarily explored in single-response settings. In this study, we extend the method-of-moments SNR estimation framework to encompass both fixed effects and random effects linear models with multivariate responses. In particular, we establish and compare the asymptotic distributions of the proposed estimators. Furthermore, we extend our approach to accommodate cases with residual heteroskedasticity and derive asymptotic inference procedures based on standard error estimation. The effectiveness of our methods is demonstrated through extensive numerical experiments.</description>
      <guid isPermaLink="false">oai:arXiv.org:2506.10370v1</guid>
      <category>math.ST</category>
      <category>stat.ME</category>
      <category>stat.TH</category>
      <pubDate>Fri, 13 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Xiaohan Hu, Zhentao Li, Xiaodong Li</dc:creator>
    </item>
    <item>
      <title>A note on the properties of the confidence set for the local average treatment effect obtained by inverting the score test</title>
      <link>https://arxiv.org/abs/2506.10449</link>
      <description>arXiv:2506.10449v1 Announce Type: cross 
Abstract: We study the properties of the score confidence set for the local average treatment effect in non and semiparametric instrumental variable models. This confidence set is constructed by inverting a score test based on an estimate of the nonparametric influence function for the estimand, and is known to be uniformly valid in models that allow for arbitrarily weak instruments; because of this, the confidence set can have infinite diameter at some laws. We characterize the six possible forms the score confidence set can take: a finite interval, an infinite interval (or a union of them), the whole real line, an empty set, or a single point. Moreover, we show that, at any fixed law, the score confidence set asymptotically coincides, up to a term of order 1/n, with the Wald confidence interval based on the doubly robust estimator which solves the estimating equation associated with the nonparametric influence function. This result implies that, in models where the efficient influence function coincides with the nonparametric influence function, the score confidence set is, in a sense, optimal in terms of its diameter. We also show that under weak instrument asymptotics, where the strength of the instrument is modelled as local to zero, the doubly robust estimator is asymptotically biased and does not follow a normal distribution. A simulation study confirms that, as expected, the doubly robust estimator performs poorly when instruments are weak, whereas the score confidence set retains good finite-sample properties in both strong and weak instrument settings. Finally, we provide an algorithm to compute the score confidence set, which is now available in the DoubleML package for double machine learning.</description>
      <guid isPermaLink="false">oai:arXiv.org:2506.10449v1</guid>
      <category>math.ST</category>
      <category>stat.ME</category>
      <category>stat.TH</category>
      <pubDate>Fri, 13 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Ezequiel Smucler, Ludovico Lanni, David Masip</dc:creator>
    </item>
    <item>
      <title>Nonparametric estimation of an optimal treatment rule with fused randomized trials and missing effect modifiers</title>
      <link>https://arxiv.org/abs/2506.10863</link>
      <description>arXiv:2506.10863v1 Announce Type: cross 
Abstract: A fundamental principle of clinical medicine is that a treatment should only be administered to those patients who would benefit from it. Treatment strategies that assign treatment to patients as a function of their individual characteristics are known as dynamic treatment rules. The dynamic treatment rule that optimizes the outcome in the population is called the optimal dynamic treatment rule. Randomized clinical trials are considered the gold standard for estimating the marginal causal effect of a treatment on an outcome; they are often not powered to detect heterogeneous treatment effects, and thus, may rarely inform more personalized treatment decisions. The availability of multiple trials studying a common set of treatments presents an opportunity for combining data, often called data-fusion, to better estimate dynamic treatment rules. However, there may be a mismatch in the set of patient covariates measured across trials. We address this problem here; we propose a nonparametric estimator for the optimal dynamic treatment rule that leverages information across the set of randomized trials. We apply the estimator to fused randomized trials of medications for the treatment of opioid use disorder to estimate a treatment rule that would match patient subgroups with the medication that would minimize risk of return to regular opioid use.</description>
      <guid isPermaLink="false">oai:arXiv.org:2506.10863v1</guid>
      <category>stat.AP</category>
      <category>stat.ME</category>
      <pubDate>Fri, 13 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Nicholas Williams, Kara Rudolph, Iv\'an D\'iaz</dc:creator>
    </item>
    <item>
      <title>Demystifying Spectral Feature Learning for Instrumental Variable Regression</title>
      <link>https://arxiv.org/abs/2506.10899</link>
      <description>arXiv:2506.10899v1 Announce Type: cross 
Abstract: We address the problem of causal effect estimation in the presence of hidden confounders, using nonparametric instrumental variable (IV) regression. A leading strategy employs spectral features - that is, learned features spanning the top eigensubspaces of the operator linking treatments to instruments. We derive a generalization error bound for a two-stage least squares estimator based on spectral features, and gain insights into the method's performance and failure modes. We show that performance depends on two key factors, leading to a clear taxonomy of outcomes. In a good scenario, the approach is optimal. This occurs with strong spectral alignment, meaning the structural function is well-represented by the top eigenfunctions of the conditional operator, coupled with this operator's slow eigenvalue decay, indicating a strong instrument. Performance degrades in a bad scenario: spectral alignment remains strong, but rapid eigenvalue decay (indicating a weaker instrument) demands significantly more samples for effective feature learning. Finally, in the ugly scenario, weak spectral alignment causes the method to fail, regardless of the eigenvalues' characteristics. Our synthetic experiments empirically validate this taxonomy.</description>
      <guid isPermaLink="false">oai:arXiv.org:2506.10899v1</guid>
      <category>stat.ML</category>
      <category>cs.LG</category>
      <category>stat.ME</category>
      <pubDate>Fri, 13 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Dimitri Meunier, Antoine Moulin, Jakub Wornbard, Vladimir R. Kostic, Arthur Gretton</dc:creator>
    </item>
    <item>
      <title>A More Robust Approach to Multivariable Mendelian Randomization</title>
      <link>https://arxiv.org/abs/2402.00307</link>
      <description>arXiv:2402.00307v4 Announce Type: replace 
Abstract: Multivariable Mendelian randomization (MVMR) uses genetic variants as instrumental variables to infer the direct effects of multiple exposures on an outcome. However, unlike univariable Mendelian randomization, MVMR often faces greater challenges with many weak instruments, which can lead to bias not necessarily toward zero and inflation of type I errors. In this work, we introduce a new asymptotic regime that allows exposures to have varying degrees of instrument strength, providing a more accurate theoretical framework for studying MVMR estimators. Under this regime, our analysis of the widely used multivariable inverse-variance weighted method shows that it is often biased and tends to produce misleadingly narrow confidence intervals in the presence of many weak instruments. To address this, we propose a simple, closed-form modification to the multivariable inverse-variance weighted estimator to reduce bias from weak instruments, and additionally introduce a novel spectral regularization technique to improve finite-sample performance. We show that the resulting spectral-regularized estimator remains consistent and asymptotically normal under many weak instruments. Through simulations and real data applications, we demonstrate that our proposed estimator and asymptotic framework can enhance the robustness of MVMR analyses.</description>
      <guid isPermaLink="false">oai:arXiv.org:2402.00307v4</guid>
      <category>stat.ME</category>
      <pubDate>Fri, 13 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Yinxiang Wu, Hyunseung Kang, Ting Ye</dc:creator>
    </item>
    <item>
      <title>A Graph-based Approach to Estimating the Number of Clusters in High-dimensional Settings</title>
      <link>https://arxiv.org/abs/2402.15600</link>
      <description>arXiv:2402.15600v3 Announce Type: replace 
Abstract: We consider the problem of estimating the number of clusters (k) in a dataset. We propose a non-parametric approach to the problem that utilizes similarity graphs to construct a robust statistic that effectively captures similarity information among observations. This graph-based statistic is applicable to datasets of any dimension, is computationally efficient to obtain, and can be paired with any kind of clustering technique. Asymptotic theory is developed to establish the selection consistency of the proposed approach. Simulation studies demonstrate that the graph-based statistic outperforms existing methods for estimating k, especially in the high-dimensional setting. We illustrate its utility on an imaging dataset and an RNA-seq dataset.</description>
      <guid isPermaLink="false">oai:arXiv.org:2402.15600v3</guid>
      <category>stat.ME</category>
      <pubDate>Fri, 13 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Yichuan Bai, Lynna Chu</dc:creator>
    </item>
    <item>
      <title>Robust Distance Covariance</title>
      <link>https://arxiv.org/abs/2403.03722</link>
      <description>arXiv:2403.03722v2 Announce Type: replace 
Abstract: Distance covariance is a popular measure of dependence between random variables. It has some robustness properties, but not all. We prove that the influence function of the usual distance covariance is bounded, but that its breakdown value is zero. Moreover, it has an unbounded sensitivity function, converging to the bounded influence function for increasing sample size. To address this sensitivity to outliers we construct a more robust version of distance correlation, which is based on a new data transformation. Simulations indicate that the resulting method is quite robust, and has good power in the presence of outliers. We illustrate the method on genetic data. Comparing the classical distance correlation with its more robust version provides additional insight.</description>
      <guid isPermaLink="false">oai:arXiv.org:2403.03722v2</guid>
      <category>stat.ME</category>
      <pubDate>Fri, 13 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Sarah Leyder, Jakob Raymaekers, Peter J. Rousseeuw</dc:creator>
    </item>
    <item>
      <title>Sharp Bounds for Continuous-Valued Treatment Effects with Unobserved Confounders</title>
      <link>https://arxiv.org/abs/2411.02231</link>
      <description>arXiv:2411.02231v3 Announce Type: replace 
Abstract: In causal inference, treatment effects are typically estimated under the ignorability, or unconfoundedness, assumption, which is often unrealistic in observational data. By relaxing this assumption and conducting a sensitivity analysis, we introduce novel bounds and derive confidence intervals for the Average Potential Outcome (APO) - a standard metric for evaluating continuous-valued treatment or exposure effects. We demonstrate that these bounds are sharp under a continuous sensitivity model, in the sense that they give the smallest possible interval under this model, and propose a doubly robust version of our estimators. In a comparative analysis with the method of Jesson et al. (2022) (arXiv:2204.10022), using both simulated and real datasets, we show that our approach not only yields sharper bounds but also achieves good coverage of the true APO, with significantly reduced computation times.</description>
      <guid isPermaLink="false">oai:arXiv.org:2411.02231v3</guid>
      <category>stat.ME</category>
      <pubDate>Fri, 13 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Jean-Baptiste Baitairian, Bernard Sebastien, Rana Jreich, Sandrine Katsahian, Agathe Guilloux</dc:creator>
    </item>
    <item>
      <title>Are you doing better than random guessing? A call for using negative controls when evaluating causal discovery algorithms</title>
      <link>https://arxiv.org/abs/2412.10039</link>
      <description>arXiv:2412.10039v2 Announce Type: replace 
Abstract: New proposals for causal discovery algorithms are typically evaluated using simulations and a few selected real data examples with known data generating mechanisms. However, there does not exist a general guideline for how such evaluation studies should be designed, and therefore, comparing results across different studies can be difficult. In this article, we propose to use negative controls as a common evaluation baseline by posing the question: Are we doing better than random guessing? For the task of graph skeleton estimation, we derive exact distributional results under random guessing for the expected behavior of a range of typical causal discovery evaluation metrics, including precision and recall. We show that these metrics can achieve very favorable values under random guessing in certain scenarios, and hence warn against using them without also reporting negative control results, i.e., performance under random guessing. We also propose an exact test of overall skeleton fit, and showcase its use on a real data application. Finally, we propose a general pipeline for using negative controls beyond the skeleton estimation task, and apply it both in a simulated example and a real data application.</description>
      <guid isPermaLink="false">oai:arXiv.org:2412.10039v2</guid>
      <category>stat.ME</category>
      <category>stat.ML</category>
      <pubDate>Fri, 13 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <dc:creator>Anne Helby Petersen</dc:creator>
    </item>
    <item>
      <title>Nonparametric Smoothing of Directional and Axial Data</title>
      <link>https://arxiv.org/abs/2501.17463</link>
      <description>arXiv:2501.17463v3 Announce Type: replace 
Abstract: We discuss generalized linear models for directional data where the conditional distribution of the response is a von Mises-Fisher distribution in arbitrary dimension or a Bingham distribution on the unit circle. To do this properly, we parametrize von Mises-Fisher distributions by Euclidean parameters and investigate computational aspects of this parametrization. Then we modify this approach for local polynomial regression as a means of nonparametric smoothing of distributional data. The methods are illustrated with simulated data and a data set from planetary sciences involving covariate vectors on a sphere with axial response.</description>
      <guid isPermaLink="false">oai:arXiv.org:2501.17463v3</guid>
      <category>stat.ME</category>
      <category>astro-ph.EP</category>
      <category>stat.CO</category>
      <pubDate>Fri, 13 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Lutz Duembgen, Caroline Haslebacher</dc:creator>
    </item>
    <item>
      <title>Improving exponential-family random graph models for bipartite networks</title>
      <link>https://arxiv.org/abs/2502.01892</link>
      <description>arXiv:2502.01892v3 Announce Type: replace 
Abstract: Bipartite graphs, representing two-mode networks, arise in many research fields. These networks have two disjoint node sets representing distinct entity types, for example persons and groups, with edges representing associations between the two entity types. In bipartite graphs, the smallest possible cycle is a cycle of length four, and hence four-cycles are the smallest structure to model closure in such networks. Exponential-family random graph models (ERGMs) are a widely used model for social, and other, networks, including specifically bipartite networks. Existing ERGM terms to model four-cycles in bipartite networks, however, are relatively rarely used. In this work we demonstrate some problems with these existing terms to model four-cycles, and define new ERGM terms to help overcome these problems. The position of the new terms in the ERGM dependence hierarchy, and their interpretation, is discussed. The new terms are demonstrated in simulation experiments, and their application illustrated on a canonical example of an empirical two-mode network.</description>
      <guid isPermaLink="false">oai:arXiv.org:2502.01892v3</guid>
      <category>stat.ME</category>
      <category>stat.AP</category>
      <pubDate>Fri, 13 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Alex Stivala, Peng Wang, Alessandro Lomi</dc:creator>
    </item>
    <item>
      <title>Graphical Transformation Models</title>
      <link>https://arxiv.org/abs/2503.17845</link>
      <description>arXiv:2503.17845v3 Announce Type: replace 
Abstract: Graphical Transformation Models (GTMs) are introduced as a novel approach to effectively model multivariate data with intricate marginals and complex dependency structures non-parametrically, while maintaining interpretability through the identification of varying conditional independencies. GTMs extend multivariate transformation models by replacing the Gaussian copula with a custom-designed multivariate transformation, offering two major advantages. Firstly, GTMs can capture more complex interdependencies using penalized splines, which also provide an efficient regularization scheme. Secondly, we demonstrate how to approximately regularize GTMs using a lasso penalty towards pairwise conditional independencies, akin to Gaussian graphical models. The model's robustness and effectiveness are validated through simulations, showcasing its ability to accurately learn parametric vine copulas and identify conditional independencies. Additionally, the model is applied to a benchmark astrophysics dataset, where the GTM demonstrates favorable performance compared to non-parametric vine copulas in learning complex multivariate distributions.</description>
      <guid isPermaLink="false">oai:arXiv.org:2503.17845v3</guid>
      <category>stat.ME</category>
      <category>cs.LG</category>
      <category>stat.ML</category>
      <pubDate>Fri, 13 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Matthias Herp, Johannes Brachem, Michael Altenbuchinger, Thomas Kneib</dc:creator>
    </item>
    <item>
      <title>Multi-object Data Integration in the Study of Primary Progressive Aphasia</title>
      <link>https://arxiv.org/abs/2407.09542</link>
      <description>arXiv:2407.09542v2 Announce Type: replace-cross 
Abstract: This article focuses on a multi-modal imaging data application where structural/anatomical information from gray matter (GM) and brain connectivity information in the form of a brain connectome network from functional magnetic resonance imaging (fMRI) are available for a number of subjects with different degrees of primary progressive aphasia (PPA), a neurodegenerative disorder (ND) measured through a speech rate measure on motor speech loss. The clinical/scientific goal in this study becomes the identification of brain regions of interest significantly related to the speech rate measure to gain insight into ND patterns. Viewing the brain connectome network and GM images as objects, we develop an integrated object response regression framework of network and GM images on the speech rate measure. A novel integrated prior formulation is proposed on network and structural image coefficients in order to exploit network information of the brain connectome while leveraging the interconnections among the two objects. The principled Bayesian framework allows the characterization of uncertainty in ascertaining a region being actively related to the speech rate measure. Our framework yields new insights into the relationship of brain regions associated with PPA, offering a deeper understanding of neuro-degenerative patterns of PPA. The supplementary file adds details about posterior computation and additional empirical results.</description>
      <guid isPermaLink="false">oai:arXiv.org:2407.09542v2</guid>
      <category>q-bio.NC</category>
      <category>stat.ME</category>
      <pubDate>Fri, 13 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Rene Gutierrez, Rajarshi Guhaniyogi, Aaron Scheffler, Maria Luisa Gorno-Tempini, Maria Luisa Mandelli, Giovanni Battistella</dc:creator>
    </item>
    <item>
      <title>Testing Generalizability in Causal Inference</title>
      <link>https://arxiv.org/abs/2411.03021</link>
      <description>arXiv:2411.03021v2 Announce Type: replace-cross 
Abstract: Ensuring robust model performance in diverse real-world scenarios requires addressing generalizability across domains with covariate shifts. However, no formal procedure exists for statistically evaluating generalizability in machine learning algorithms. Existing predictive metrics like mean squared error (MSE) help to quantify the relative performance between models, but do not directly answer whether a model can or cannot generalize. To address this gap in the domain of causal inference, we propose a systematic framework for statistically evaluating the generalizability of high-dimensional causal inference models. Our approach uses the frugal parameterization to flexibly simulate from fully and semi-synthetic causal benchmarks, offering a comprehensive evaluation for both mean and distributional regression methods. Grounded in real-world data, our method ensures more realistic evaluations, which is often missing in current work relying on simplified datasets. Furthermore, using simulations and statistical testing, our framework is robust and avoids over-reliance on conventional metrics, providing statistical safeguards for decision making.</description>
      <guid isPermaLink="false">oai:arXiv.org:2411.03021v2</guid>
      <category>cs.LG</category>
      <category>stat.AP</category>
      <category>stat.ME</category>
      <category>stat.ML</category>
      <pubDate>Fri, 13 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Daniel de Vassimon Manela, Linying Yang, Robin J. Evans</dc:creator>
    </item>
    <item>
      <title>Debiasing Watermarks for Large Language Models via Maximal Coupling</title>
      <link>https://arxiv.org/abs/2411.11203</link>
      <description>arXiv:2411.11203v2 Announce Type: replace-cross 
Abstract: Watermarking language models is essential for distinguishing between human and machine-generated text and thus maintaining the integrity and trustworthiness of digital communication. We present a novel green/red list watermarking approach that partitions the token set into ``green'' and ``red'' lists, subtly increasing the generation probability for green tokens. To correct token distribution bias, our method employs maximal coupling, using a uniform coin flip to decide whether to apply bias correction, with the result embedded as a pseudorandom watermark signal. Theoretical analysis confirms this approach's unbiased nature and robust detection capabilities. Experimental results show that it outperforms prior techniques by preserving text quality while maintaining high detectability, and it demonstrates resilience to targeted modifications aimed at improving text quality. This research provides a promising watermarking solution for language models, balancing effective detection with minimal impact on text quality.</description>
      <guid isPermaLink="false">oai:arXiv.org:2411.11203v2</guid>
      <category>stat.ML</category>
      <category>cs.CL</category>
      <category>cs.CR</category>
      <category>cs.LG</category>
      <category>stat.ME</category>
      <pubDate>Fri, 13 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Yangxinyu Xie, Xiang Li, Tanwi Mallick, Weijie J. Su, Ruixun Zhang</dc:creator>
    </item>
    <item>
      <title>Spectrally Robust Covariance Shrinkage for Hotelling's $T^2$ in High Dimensions</title>
      <link>https://arxiv.org/abs/2502.02006</link>
      <description>arXiv:2502.02006v3 Announce Type: replace-cross 
Abstract: We investigate covariance shrinkage for Hotelling's $T^2$ in the regime where the data dimension $p$ and the sample size $n$ grow in a fixed ratio -- without assuming that the population covariance matrix is spiked or well-conditioned. When $p/n\to\phi \in (0,1)$, we propose a practical finite-sample shrinker that, for any maximum-entropy signal prior and any fixed significance level, (a) asymptotically maximizes power under Gaussian data, and (b) asymptotically saturates the Hanson--Wright lower bound on power in the more general sub-Gaussian case. Our approach is to formulate and solve a variational problem characterizing the optimal limiting shrinker, and to show that our finite-sample method consistently approximates this limit by extending recent local random matrix laws. Empirical studies on simulated and real-world data, including the Crawdad UMich/RSS data set, demonstrate up to a $50\%$ gain in power over leading linear and nonlinear competitors at a significance level of $10^{-4}$.</description>
      <guid isPermaLink="false">oai:arXiv.org:2502.02006v3</guid>
      <category>math.ST</category>
      <category>math.PR</category>
      <category>stat.ME</category>
      <category>stat.TH</category>
      <pubDate>Fri, 13 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Benjamin D. Robinson, Van Latimer</dc:creator>
    </item>
    <item>
      <title>Locally minimax optimal and dimension-agnostic discrete argmin inference</title>
      <link>https://arxiv.org/abs/2503.21639</link>
      <description>arXiv:2503.21639v3 Announce Type: replace-cross 
Abstract: This paper tackles a fundamental inference problem: given $n$ observations from a $d$ dimensional vector with unknown mean $\boldsymbol{\mu}$, we must form a confidence set for the index (or indices) corresponding to the smallest component of $\boldsymbol{\mu}$. By duality, we reduce this to testing, for each $r$ in $1,\ldots,d$, whether $\mu_r$ is the smallest. Based on the sample splitting and self-normalization approach of Kim and Ramdas (2024), we propose "dimension-agnostic" tests that maintain validity regardless of how $d$ scales with $n$, and regardless of arbitrary ties in $\boldsymbol{\mu}$. Notably, our validity holds under mild moment conditions, requiring little more than finiteness of a second moment, and permitting possibly strong dependence between coordinates. In addition, we establish the local minimax separation rate for this problem, which adapts to the cardinality of a confusion set, and show that the proposed tests attain this rate. Furthermore, we develop robust variants that continue to achieve the same minimax rate under heavy-tailed distributions with only finite second moments. Empirical results on simulated and real data illustrate the strong performance of our approach in terms of type I error control and power compared to existing methods.</description>
      <guid isPermaLink="false">oai:arXiv.org:2503.21639v3</guid>
      <category>math.ST</category>
      <category>stat.ME</category>
      <category>stat.ML</category>
      <category>stat.TH</category>
      <pubDate>Fri, 13 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Ilmun Kim, Aaditya Ramdas</dc:creator>
    </item>
    <item>
      <title>Finite Population Identification and Design-Based Sensitivity Analysis</title>
      <link>https://arxiv.org/abs/2504.14127</link>
      <description>arXiv:2504.14127v2 Announce Type: replace-cross 
Abstract: We develop a new approach for quantifying uncertainty in finite populations, by using design distributions to calibrate sensitivity parameters in finite population identified sets. This yields uncertainty intervals that can be interpreted as identified sets, Bayesian credible sets, or frequentist design-based confidence sets. We focus on quantifying uncertainty about the average treatment effect (ATE) due to missing potential outcomes in a randomized experiment, where our approach (1) yields design-based confidence intervals for ATE which allow for heterogeneous treatment effects but do not rely on asymptotics, (2) provides a new motivation for examining covariate balance, and (3) gives a new formal analysis of the role of randomized treatment assignment. We illustrate our approach in three empirical applications.</description>
      <guid isPermaLink="false">oai:arXiv.org:2504.14127v2</guid>
      <category>econ.EM</category>
      <category>stat.ME</category>
      <pubDate>Fri, 13 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Brendan Kline, Matthew A. Masten</dc:creator>
    </item>
    <item>
      <title>Hybrid Bernstein Normalizing Flows for Flexible Multivariate Density Regression with Interpretable Marginals</title>
      <link>https://arxiv.org/abs/2505.14164</link>
      <description>arXiv:2505.14164v2 Announce Type: replace-cross 
Abstract: Density regression models allow a comprehensive understanding of data by modeling the complete conditional probability distribution. While flexible estimation approaches such as normalizing flows (NF) work particularly well in multiple dimensions, interpreting the input-output relationship of such models is often difficult, due to the black-box character of deep learning models. In contrast, existing statistical methods for multivariate outcomes such as multivariate conditional transformation models (MCTM) are restricted in flexibility and are often not expressive enough to represent complex multivariate probability distributions. In this paper, we combine MCTM with state-of-the-art and autoregressive NF to leverage the transparency of MCTM for modeling interpretable feature effects on the marginal distributions in the first step and the flexibility of neural-network-based NF techniques to account for complex and non-linear relationships in the joint data distribution. We demonstrate our method's versatility in various numerical experiments and compare it with MCTM and other NF models on both simulated and real-world data.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.14164v2</guid>
      <category>stat.ML</category>
      <category>cs.LG</category>
      <category>stat.AP</category>
      <category>stat.ME</category>
      <pubDate>Fri, 13 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Marcel Arpogaus, Thomas Kneib, Thomas Nagler, David R\"ugamer</dc:creator>
    </item>
  </channel>
</rss>
