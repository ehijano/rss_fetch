<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>cs.SE updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/cs.SE</link>
    <description>cs.SE updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/cs.SE" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Tue, 08 Apr 2025 04:00:00 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Tue, 08 Apr 2025 00:00:00 -0400</pubDate>
    <skipDays>
      <day>Saturday</day>
      <day>Sunday</day>
    </skipDays>
    <item>
      <title>Agentic Business Process Management: The Past 30 Years And Practitioners' Future Perspectives</title>
      <link>https://arxiv.org/abs/2504.03693</link>
      <description>arXiv:2504.03693v1 Announce Type: new 
Abstract: With the advent of generative Artificial Intelligence (genAI), the notion of an agent has seen a resurgence in popularity. This has also led to speculation about the extent to which business process management, as a discipline and research field, may impact and be impacted by the deployment of genAI-based agents. To better ground such speculations into the state-of-the-art, we draw from the past 30 years of research on agents and business process management to establish the concept of Agentic Business Process Management (agentic BPM) that is only loosely coupled to the genAI hype. We conduct a series of interviews with BPM practitioners to explore their understanding, expectations, and concerns related to agent autonomy, adaptability, human collaboration, and governance in processes. The findings reflect both challenges with respect to data inconsistencies, manual interventions, identification of process bottlenecks, actionability of process improvements, as well as the opportunities of enhanced efficiency, predictive process insights and proactive decision-making support. While the technology offers potential benefits, practitioners also anticipate risks such as biases, over-reliance, lack of transparency, and job displacement within organizations. These concerns underscore the need for a robust methodological framework for managing agents in organizations.</description>
      <guid isPermaLink="false">oai:arXiv.org:2504.03693v1</guid>
      <category>cs.SE</category>
      <category>cs.MA</category>
      <pubDate>Tue, 08 Apr 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Hoang Vu, Nataliia Klievtsova, Henrik Leopold, Stefanie Rinderle-Ma, Timotheus Kampik</dc:creator>
    </item>
    <item>
      <title>Improving Front-end Performance through Modular Rendering and Adaptive Hydration (MRAH) in React Applications</title>
      <link>https://arxiv.org/abs/2504.03884</link>
      <description>arXiv:2504.03884v1 Announce Type: new 
Abstract: Modern web applications increasingly leverage server-side rendering (SSR) to improve initial load times and search engine optimization. However, the subsequent hydration process-where client-side JavaScript attaches interactivity to SSR-delivered HTML-can introduce performance bottlenecks. We propose a novel architectural pattern combining a modular rendering pipeline with an adaptive hydration strategy to optimize frontend performance in React and Next.js applications. The approach breaks the interface into distinct modules that can be rendered and hydrated independently (inspired by the "islands" paradigm), and it adaptively prioritizes or defers hydration of these modules based on device capabilities, network conditions, and component importance. We integrate techniques such as code-splitting with dynamic import(), conditional hydration triggers (e.g., on visibility or idle time) using libraries like react-lazy-hydration, and adaptive loading hooks to tailor the hydration process to the user's context. By reducing the amount of JavaScript executed on page load and by scheduling hydration work intelligently, this architecture aims to improve key performance metrics-including First Input Delay (FID) and Time to Interactive (TTI)-without sacrificing rich interactivity. We describe the architecture and implementation in a Next.js environment, discuss how components can be conditionally hydrated or entirely skipped when not needed, and compare our approach to related work in progressive hydration, partial hydration, and React Server Components. Evaluation of the approach is left for future work. This pattern offers a pathway to building highly interactive yet performant React applications through careful orchestration of rendering and hydration.</description>
      <guid isPermaLink="false">oai:arXiv.org:2504.03884v1</guid>
      <category>cs.SE</category>
      <pubDate>Tue, 08 Apr 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Kaitao Chen</dc:creator>
    </item>
    <item>
      <title>OpenCodeInstruct: A Large-scale Instruction Tuning Dataset for Code LLMs</title>
      <link>https://arxiv.org/abs/2504.04030</link>
      <description>arXiv:2504.04030v1 Announce Type: new 
Abstract: Large Language Models (LLMs) have transformed software development by enabling code generation, automated debugging, and complex reasoning. However, their continued advancement is constrained by the scarcity of high-quality, publicly available supervised fine-tuning (SFT) datasets tailored for coding tasks. To bridge this gap, we introduce OpenCodeInstruct, the largest open-access instruction tuning dataset, comprising 5 million diverse samples. Each sample includes a programming question, solution, test cases, execution feedback, and LLM-generated quality assessments. We fine-tune various base models, including LLaMA and Qwen, across multiple scales (1B+, 3B+, and 7B+) using our dataset. Comprehensive evaluations on popular benchmarks (HumanEval, MBPP, LiveCodeBench, and BigCodeBench) demonstrate substantial performance improvements achieved by SFT with OpenCodeInstruct. We also present a detailed methodology encompassing seed data curation, synthetic instruction and solution generation, and filtering.</description>
      <guid isPermaLink="false">oai:arXiv.org:2504.04030v1</guid>
      <category>cs.SE</category>
      <category>cs.CL</category>
      <pubDate>Tue, 08 Apr 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Wasi Uddin Ahmad, Aleksander Ficek, Mehrzad Samadi, Jocelyn Huang, Vahid Noroozi, Somshubra Majumdar, Boris Ginsburg</dc:creator>
    </item>
    <item>
      <title>The Ripple Effect of Vulnerabilities in Maven Central: Prevalence, Propagation, and Mitigation Challenges</title>
      <link>https://arxiv.org/abs/2504.04175</link>
      <description>arXiv:2504.04175v1 Announce Type: new 
Abstract: The widespread use of package managers like Maven has accelerated software development but has also introduced significant security risks due to vulnerabilities in dependencies. In this study, we analyze the prevalence and impact of vulnerabilities within the Maven Central ecosystem, using Common Vulnerabilities and Exposures (CVE) data from OSV.dev and a subsample enriched with aggregated CVE data (CVE_AGGREGATED), which captures both direct and transitive vulnerabilities. In our subsample of around 4 million releases, we found that while only about 1% of releases have direct vulnerabilities, approximately 46.8% are affected by transitive vulnerabilities. This highlights how a small number of vulnerable yet influential artifacts can impact a vast portion of the ecosystem. Moreover, our analysis shows that vulnerabilities propagate rapidly through dependency networks and that more central artifacts (those with a high number of dependents) are not necessarily less vulnerable. We also observed that the time taken to patch vulnerabilities, including those of high or critical severity, often spans several years. Additionally, we found that dependents of artifacts tend to prefer presumably non-vulnerable versions; however, some continue to use vulnerable versions, indicating challenges in adopting patched releases. These findings highlight the critical need for improved dependency management practices and timely vulnerability remediation to enhance the security of software ecosystems.</description>
      <guid isPermaLink="false">oai:arXiv.org:2504.04175v1</guid>
      <category>cs.SE</category>
      <pubDate>Tue, 08 Apr 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Ehtisham Ul Haq, Song Wang, Robert S. Allison</dc:creator>
    </item>
    <item>
      <title>AdaCoder: An Adaptive Planning and Multi-Agent Framework for Function-Level Code Generation</title>
      <link>https://arxiv.org/abs/2504.04220</link>
      <description>arXiv:2504.04220v1 Announce Type: new 
Abstract: Recently, researchers have proposed many multi-agent frameworks for function-level code generation, which aim to improve software development productivity by automatically generating function-level source code based on task descriptions. A typical multi-agent framework consists of Large Language Model (LLM)-based agents that are responsible for task planning, code generation, testing, debugging, etc. Studies have shown that existing multi-agent code generation frameworks perform well on ChatGPT. However, their generalizability across other foundation LLMs remains unexplored systematically. In this paper, we report an empirical study on the generalizability of four state-of-the-art multi-agent code generation frameworks across six open-source LLMs with varying parameter sizes, architectures, and performance levels. Our study reveals the unstable generalizability of existing frameworks on diverse foundation LLMs. Based on the findings obtained from the empirical study, we propose AdaCoder, a novel adaptive planning, multi-agent framework for function-level code generation. AdaCoder has two phases. Phase-1 is an initial code generation step without planning, which uses an LLM-based coding agent and a script-based testing agent to unleash LLM's native power, identify cases beyond LLM's power, and determine the errors hindering execution. Phase-2 adds a rule-based debugging agent and an LLM-based planning agent for iterative code generation with planning. Our evaluation shows that AdaCoder achieves higher generalizability on diverse LLMs. Compared to the best baseline MapCoder, AdaCoder is on average 27.69% higher in Pass@1, 16 times faster in inference, and 12 times lower in token consumption.</description>
      <guid isPermaLink="false">oai:arXiv.org:2504.04220v1</guid>
      <category>cs.SE</category>
      <pubDate>Tue, 08 Apr 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Yueheng Zhu, Chao Liu, Xuan He, Xiaoxue Ren, Zhongxin Liu, Ruwei Pan, Hongyu Zhang</dc:creator>
    </item>
    <item>
      <title>Exploration of Approaches for Robustness and Safety in a Low Code Open Environment for Factory Automation</title>
      <link>https://arxiv.org/abs/2504.04224</link>
      <description>arXiv:2504.04224v1 Announce Type: new 
Abstract: This report is a compilation of technical knowledge and concepts that were produced by the authors and additional contributors in the context of the collaboration projects "Abstraction Requirements for Language of Choice in Industrial Automation" (FY21-22) and "Approaches for Robust and Safe Low-Code" (FY23-24) from Siemens Technology and the University of California, Berkeley. The primary objective of these projects was to assess Siemens Open Industrial Edge (OIE) engineering capabilities by defining a concept that ensures the satisfaction of coordination and safety requirements when using disparate OIE modules. The objective was to use the Lingua Franca (LF) coordination language to demonstrate how to address challenges in: 1. engineering modular, distributed, and flexible automation solutions that ensure, by design, robust and safe operation1; 2. the use of IEC 61499, the event driven execution model for specifying the execution order of OIE modules (defined as function blocks); 3. support large-scale distributed OIE automation solutions, and eventually 4. define optimal solutions with synchronization and time-optimal mechanisms.</description>
      <guid isPermaLink="false">oai:arXiv.org:2504.04224v1</guid>
      <category>cs.SE</category>
      <category>cs.SY</category>
      <category>eess.SY</category>
      <pubDate>Tue, 08 Apr 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Gustavo Quiros A., Yi Peng Zhu, Tao Cui, Shaokai Lin, Marten Lohstroh, Edward A. Lee</dc:creator>
    </item>
    <item>
      <title>Automated Assessment in Mobile Programming Courses: Leveraging GitHub Classroom and Flutter for Enhanced Student Outcomes</title>
      <link>https://arxiv.org/abs/2504.04230</link>
      <description>arXiv:2504.04230v1 Announce Type: new 
Abstract: The growing demand for skilled mobile developers has made mobile programming courses an essential component of computer science curricula. However, these courses face unique challenges due to the complexity of mobile development environments and the graphical, interactive nature of mobile applications. This paper explores the potential of using GitHub Classroom, combined with the Flutter framework, for the automated assessment of mobile programming assignments. By leveraging GitHub Actions for continuous integration and Flutter's robust support for test automation, the proposed approach enables an auto-grading cost-effective solution. We evaluate the feasibility of integrating these tools through an experiment in a Mobile Programming course and present findings from a student survey that assesses their perceptions of the proposed evaluation model. The results are encouraging, showing that the approach is well-received by students.</description>
      <guid isPermaLink="false">oai:arXiv.org:2504.04230v1</guid>
      <category>cs.SE</category>
      <pubDate>Tue, 08 Apr 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Pedro Alves, Bruno Pereira Cipriano</dc:creator>
    </item>
    <item>
      <title>Tratto: A Neuro-Symbolic Approach to Deriving Axiomatic Test Oracles</title>
      <link>https://arxiv.org/abs/2504.04251</link>
      <description>arXiv:2504.04251v1 Announce Type: new 
Abstract: This paper presents Tratto, a neuro-symbolic approach that generates assertions (boolean expressions) that can serve as axiomatic oracles, from source code and documentation. The symbolic module of Tratto takes advantage of the grammar of the programming language, the unit under test, and the context of the unit (its class and available APIs) to restrict the search space of the tokens that can be successfully used to generate valid oracles. The neural module of Tratto uses transformers fine-tuned for both deciding whether to output an oracle or not and selecting the next lexical token to incrementally build the oracle from the set of tokens returned by the symbolic module. Our experiments show that Tratto outperforms the state-of-the-art axiomatic oracle generation approaches, with 73% accuracy, 72% precision, and 61% F1-score, largely higher than the best results of the symbolic and neural approaches considered in our study (61%, 62%, and 37%, respectively). Tratto can generate three times more axiomatic oracles than current symbolic approaches, while generating 10 times less false positives than GPT4 complemented with few-shot learning and Chain-of-Thought prompting.</description>
      <guid isPermaLink="false">oai:arXiv.org:2504.04251v1</guid>
      <category>cs.SE</category>
      <pubDate>Tue, 08 Apr 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Davide Molinelli, Alberto Martin-Lopez, Elliott Zackrone, Beyza Eken, Michael D. Ernst, Mauro Pezz\`e</dc:creator>
    </item>
    <item>
      <title>Compiler Optimization Testing Based on Optimization-Guided Equivalence Transformations</title>
      <link>https://arxiv.org/abs/2504.04321</link>
      <description>arXiv:2504.04321v1 Announce Type: new 
Abstract: Compiler optimization techniques are inherently complex, and rigorous testing of compiler optimization implementation is critical. Recent years have witnessed the emergence of testing approaches for uncovering incorrect optimization bugs, but these approaches rely heavily on the differential testing mechanism, which requires comparing outputs across multiple compilers. This dependency gives rise to important limitations, including that (1) the tested functionality must be consistently implemented across all compilers and (2) shared bugs remain undetected. Thus, false alarms can be produced and significant manual efforts will be required. To overcome the limitations, we propose a metamorphic testing approach inspired by compiler optimizations. The approach is driven by how to maximize compiler optimization opportunities while effectively judging optimization correctness. Specifically, our approach first employs tailored code construction strategies to generate input programs that satisfy optimization conditions, and then applies various compiler optimization transformations to create semantically equivalent test programs. By comparing the outputs of pre- and post-transformation programs, this approach effectively identifies incorrect optimization bugs. We conducted a preliminary evaluation of this approach on GCC and LLVM, and we have successfully detected five incorrect optimization bugs at the time of writing. This result demonstrates the effectiveness and potential of our approach.</description>
      <guid isPermaLink="false">oai:arXiv.org:2504.04321v1</guid>
      <category>cs.SE</category>
      <pubDate>Tue, 08 Apr 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Jingwen Wu, Jiajing Zheng, Zhenyu Yang, Zhongxing Yu</dc:creator>
    </item>
    <item>
      <title>Towards Source Mapping for Zero-Knowledge Smart Contracts: Design and Preliminary Evaluation</title>
      <link>https://arxiv.org/abs/2504.04322</link>
      <description>arXiv:2504.04322v1 Announce Type: new 
Abstract: Debugging and auditing zero-knowledge-compatible smart contracts remains a significant challenge due to the lack of source mapping in compilers such as zkSolc. In this work, we present a preliminary source mapping framework that establishes traceability between Solidity source code, LLVM IR, and zkEVM bytecode within the zkSolc compilation pipeline. Our approach addresses the traceability challenges introduced by non-linear transformations and proof-friendly optimizations in zero-knowledge compilation. To improve the reliability of mappings, we incorporate lightweight consistency checks based on static analysis and structural validation. We evaluate the framework on a dataset of 50 benchmark contracts and 500 real-world zkSync contracts, observing a mapping accuracy of approximately 97.2% for standard Solidity constructs. Expected limitations arise in complex scenarios such as inline assembly and deep inheritance hierarchies. The measured compilation overhead remains modest, at approximately 8.6%. Our initial results suggest that source mapping support in zero-knowledge compilation pipelines is feasible and can benefit debugging, auditing, and development workflows. We hope that this work serves as a foundation for further research and tool development aimed at improving developer experience in zk-Rollup environments.</description>
      <guid isPermaLink="false">oai:arXiv.org:2504.04322v1</guid>
      <category>cs.SE</category>
      <pubDate>Tue, 08 Apr 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Pei Xu</dc:creator>
    </item>
    <item>
      <title>Artificial Intelligence for Software Architecture: Literature Review and the Road Ahead</title>
      <link>https://arxiv.org/abs/2504.04334</link>
      <description>arXiv:2504.04334v1 Announce Type: new 
Abstract: This paper presents a forward-looking vision for artificial intelligence-driven software architecture that addresses longstanding challenges in design and evolution. Although artificial intelligence has achieved notable success in software engineering, its explicit application to software architecture remains under-explored. Traditional practices, heavily reliant on expert knowledge and complex trade-off reasoning, tend to be manual and error-prone, thereby compromising system quality and maintainability. Building on recent advances, we examine how artificial intelligence can automate architectural design, support quantitative trade-off analyses, and continuously update architectural documentation. Our approach combines a systematic review of state-of-the-art applications with insights from industry practitioners. The resulting roadmap outlines 14 current artificial intelligence contributions to software architecture, identifies six artificial intelligence-specific challenges in supporting architectural tasks, and reveals six avenues for future improvement, charting a course for future research and practical implementations.</description>
      <guid isPermaLink="false">oai:arXiv.org:2504.04334v1</guid>
      <category>cs.SE</category>
      <pubDate>Tue, 08 Apr 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Alessio Bucaioni, Martin Weyssow, Junda He, Yunbo Lyu, David Lo</dc:creator>
    </item>
    <item>
      <title>DDPT: Diffusion-Driven Prompt Tuning for Large Language Model Code Generation</title>
      <link>https://arxiv.org/abs/2504.04351</link>
      <description>arXiv:2504.04351v1 Announce Type: new 
Abstract: Large Language Models (LLMs) have demonstrated remarkable capabilities in code generation. However, the quality of the generated code is heavily dependent on the structure and composition of the prompts used. Crafting high-quality prompts is a challenging task that requires significant knowledge and skills of prompt engineering. To advance the automation support for the prompt engineering for LLM-based code generation, we propose a novel solution Diffusion-Driven Prompt Tuning (DDPT) that learns how to generate optimal prompt embedding from Gaussian Noise to automate the prompt engineering for code generation. We evaluate the feasibility of diffusion-based optimization and abstract the optimal prompt embedding as a directional vector toward the optimal embedding. We use the code generation loss given by the LLMs to help the diffusion model capture the distribution of optimal prompt embedding during training. The trained diffusion model can build a path from the noise distribution to the optimal distribution at the sampling phrase, the evaluation result demonstrates that DDPT helps improve the prompt optimization for code generation.</description>
      <guid isPermaLink="false">oai:arXiv.org:2504.04351v1</guid>
      <category>cs.SE</category>
      <category>cs.AI</category>
      <category>cs.CL</category>
      <category>cs.LG</category>
      <pubDate>Tue, 08 Apr 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Jinyang Li, Sangwon Hyun, M. Ali Babar</dc:creator>
    </item>
    <item>
      <title>How Accurately Do Large Language Models Understand Code?</title>
      <link>https://arxiv.org/abs/2504.04372</link>
      <description>arXiv:2504.04372v1 Announce Type: new 
Abstract: Large Language Models (LLMs) are increasingly used in post-development tasks such as code repair and testing. A key factor in these tasks' success is the model's deep understanding of code. However, the extent to which LLMs truly understand code remains largely unevaluated. Quantifying code comprehension is challenging due to its abstract nature and the lack of a standardized metric. Previously, this was assessed through developer surveys, which are not feasible for evaluating LLMs. Existing LLM benchmarks focus primarily on code generation, fundamentally different from code comprehension. Additionally, fixed benchmarks quickly become obsolete as they become part of the training data. This paper presents the first large-scale empirical investigation into LLMs' ability to understand code. Inspired by mutation testing, we use an LLM's fault-finding ability as a proxy for its deep code understanding. This approach is based on the insight that a model capable of identifying subtle functional discrepancies must understand the code well. We inject faults in real-world programs and ask the LLM to localize them, ensuring the specifications suffice for fault localization. Next, we apply semantic-preserving code mutations (SPMs) to the faulty programs and test whether the LLMs still locate the faults, verifying their confidence in code understanding. We evaluate nine popular LLMs on 575000 debugging tasks from 670 Java and 637 Python programs. We find that LLMs lose the ability to debug the same bug in 81% of faulty programs when SPMs are applied, indicating a shallow understanding of code and reliance on features irrelevant to semantics. We also find that LLMs understand code earlier in the program better than later. This suggests that LLMs' code comprehension remains tied to lexical and syntactic features due to tokenization designed for natural languages, which overlooks code semantics.</description>
      <guid isPermaLink="false">oai:arXiv.org:2504.04372v1</guid>
      <category>cs.SE</category>
      <category>cs.AI</category>
      <category>cs.LG</category>
      <pubDate>Tue, 08 Apr 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Sabaat Haroon, Ahmad Faraz Khan, Ahmad Humayun, Waris Gill, Abdul Haddi Amjad, Ali R. Butt, Mohammad Taha Khan, Muhammad Ali Gulzar</dc:creator>
    </item>
    <item>
      <title>ICCheck: A Portable, Language-Agnostic Tool for Synchronizing Code Clones</title>
      <link>https://arxiv.org/abs/2504.04537</link>
      <description>arXiv:2504.04537v1 Announce Type: new 
Abstract: Inconsistent modifications to code clones can lead to software defects. Many approaches exist to support consistent modifications based on clone detection and/or change pattern extraction. However, no tool currently supports synchronization of code clones across diverse programming languages and development environments. We propose ICCheck, a tool designed to be language-agnostic and portable across various environments. By leveraging an existing language-agnostic clone search technique and limiting the tool's external dependency to an existing Git repository, we developed a tool that can assist in synchronizing code clones in diverse environments. We validated the tool's functionality in multiple open-source repositories, demonstrating its language independence. Furthermore, by supporting the Language Server Protocol, we confirmed that ICCheck can be integrated into multiple development environments with minimal effort. ICCheck is available at https://github.com/salab/iccheck</description>
      <guid isPermaLink="false">oai:arXiv.org:2504.04537v1</guid>
      <category>cs.SE</category>
      <pubDate>Tue, 08 Apr 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Motoki Abe, Shinpei Hayashi</dc:creator>
    </item>
    <item>
      <title>Studying the Impact of Early Test Termination Due to Assertion Failure on Code Coverage and Spectrum-based Fault Localization</title>
      <link>https://arxiv.org/abs/2504.04557</link>
      <description>arXiv:2504.04557v1 Announce Type: new 
Abstract: An assertion is commonly used to validate the expected programs behavior (e.g., if the returned value of a method equals an expected value) in software testing. Although it is a recommended practice to use only one assertion in a single test to avoid code smells (e.g., Assertion Roulette), it is common to have multiple assertions in a single test. One issue with tests that have multiple assertions is that when the test fails at an early assertion (not the last one), the test will terminate at that point, and the remaining testing code will not be executed. This, in turn, can potentially reduce the code coverage and the performance of techniques that rely on code coverage information (e.g., spectrum-based fault localization). We refer to such a scenario as early test termination. Understanding the impact of early test termination on test coverage is important for software testing and debugging, particularly for the techniques that rely on coverage information obtained from the testing. We conducted the first empirical study on early test termination due to assertion failure (i.e., early test termination) by investigating 207 versions of 6 open-source projects. We found that a nonnegligible portion of the failed tests (19.1%) is early terminated due to assertion failure. Our findings indicate that early test termination harms both code coverage and the effectiveness of spectrum-based fault localization. For instance, after eliminating early test termination, the line/branch coverage is improved in 55% of the studied versions, and improves the performance of two popular SBFL techniques Ochiai and Tarantula by 15.1% and 10.7% compared to the original setting (without eliminating early test termination) in terms of MFR, respectively.</description>
      <guid isPermaLink="false">oai:arXiv.org:2504.04557v1</guid>
      <category>cs.SE</category>
      <pubDate>Tue, 08 Apr 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Md. Ashraf Uddin (Peter), Shaowei Wang (Peter), An Ran Chen (Peter),  Tse-Hsun (Peter),  Chen</dc:creator>
    </item>
    <item>
      <title>Foundation Models for Software Engineering of Cyber-Physical Systems: the Road Ahead</title>
      <link>https://arxiv.org/abs/2504.04630</link>
      <description>arXiv:2504.04630v1 Announce Type: new 
Abstract: Foundation Models (FMs), particularly Large Language Models (LLMs), are increasingly used to support various software engineering activities (e.g., coding and testing). Their applications in the software engineering of Cyber-Physical Systems (CPSs) are also growing. However, research in this area remains limited. Moreover, existing studies have primarily focused on LLMs-only one type of FM-leaving ample opportunities to explore others, such as vision-language models. We argue that, in addition to LLMs, other FMs utilizing different data modalities (e.g., images, audio) and multimodal models (which integrate multiple modalities) hold great potential for supporting CPS software engineering, given that these systems process diverse data types. To address this, we present a research roadmap for integrating FMs into various phases of CPS software engineering, highlighting key research opportunities and challenges for the software engineering community.</description>
      <guid isPermaLink="false">oai:arXiv.org:2504.04630v1</guid>
      <category>cs.SE</category>
      <pubDate>Tue, 08 Apr 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Chengjie Lu, Pablo Valle, Jiahui Wu, Erblin Isaku, Hassan Sartaj, Aitor Arrieta, Shaukat Ali</dc:creator>
    </item>
    <item>
      <title>R2Vul: Learning to Reason about Software Vulnerabilities with Reinforcement Learning and Structured Reasoning Distillation</title>
      <link>https://arxiv.org/abs/2504.04699</link>
      <description>arXiv:2504.04699v1 Announce Type: new 
Abstract: Large language models (LLMs) have shown promising performance in software vulnerability detection (SVD), yet their reasoning capabilities remain unreliable. Existing approaches relying on chain-of-thought (CoT) struggle to provide relevant and actionable security assessments. Additionally, effective SVD requires not only generating coherent reasoning but also differentiating between well-founded and misleading yet plausible security assessments, an aspect overlooked in prior work. To this end, we introduce R2Vul, a novel approach that distills structured reasoning into small LLMs using reinforcement learning from AI feedback (RLAIF). Through RLAIF, R2Vul enables LLMs to produce structured, security-aware reasoning that is actionable and reliable while explicitly learning to distinguish valid assessments from misleading ones. We evaluate R2Vul across five languages against SAST tools, CoT, instruction tuning, and classification-based baselines. Our results show that R2Vul with structured reasoning distillation enables a 1.5B student LLM to rival larger models while improving generalization to out-of-distribution vulnerabilities. Beyond model improvements, we contribute a large-scale, multilingual preference dataset featuring structured reasoning to support future research in SVD.</description>
      <guid isPermaLink="false">oai:arXiv.org:2504.04699v1</guid>
      <category>cs.SE</category>
      <category>cs.AI</category>
      <category>cs.CL</category>
      <pubDate>Tue, 08 Apr 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Martin Weyssow, Chengran Yang, Junkai Chen, Yikun Li, Huihui Huang, Ratnadira Widyasari, Han Wei Ang, Frank Liauw, Eng Lieh Ouh, Lwin Khin Shar, David Lo</dc:creator>
    </item>
    <item>
      <title>Out of Sight, Still at Risk: The Lifecycle of Transitive Vulnerabilities in Maven</title>
      <link>https://arxiv.org/abs/2504.04803</link>
      <description>arXiv:2504.04803v1 Announce Type: new 
Abstract: The modern software development landscape heavily relies on transitive dependencies. They enable seamless integration of third-party libraries. However, they also introduce security challenges. Transitive vulnerabilities that arise from indirect dependencies expose projects to risks associated with Common Vulnerabilities and Exposures (CVEs). It happens even when direct dependencies remain secure. This paper examines the lifecycle of transitive vulnerabilities in the Maven ecosystem. We employ survival analysis to measure the time projects remain exposed after a CVE is introduced. Using a large dataset of Maven projects, we identify factors that influence the resolution of these vulnerabilities. Our findings offer practical advice on improving dependency management.</description>
      <guid isPermaLink="false">oai:arXiv.org:2504.04803v1</guid>
      <category>cs.SE</category>
      <category>cs.CR</category>
      <pubDate>Tue, 08 Apr 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Piotr Przymus, Miko{\l}aj Fejzer, Jakub Nar\k{e}bski, Krzysztof Rykaczewski, Krzysztof Stencel</dc:creator>
    </item>
    <item>
      <title>HaPy-Bug -- Human Annotated Python Bug Resolution Dataset</title>
      <link>https://arxiv.org/abs/2504.04810</link>
      <description>arXiv:2504.04810v1 Announce Type: new 
Abstract: We present HaPy-Bug, a curated dataset of 793 Python source code commits associated with bug fixes, with each line of code annotated by three domain experts. The annotations offer insights into the purpose of modified files, changes at the line level, and reviewers' confidence levels. We analyze HaPy-Bug to examine the distribution of file purposes, types of modifications, and tangled changes. Additionally, we explore its potential applications in bug tracking, the analysis of bug-fixing practices, and the development of repository analysis tools. HaPy-Bug serves as a valuable resource for advancing research in software maintenance and security.</description>
      <guid isPermaLink="false">oai:arXiv.org:2504.04810v1</guid>
      <category>cs.SE</category>
      <pubDate>Tue, 08 Apr 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Piotr Przymus, Miko{\l}aj Fejzer, Jakub Nar\k{e}bski, Rados{\l}aw Wo\'zniak, {\L}ukasz Halada, Aleksander Kazecki, Mykhailo Molchanov, Krzysztof Stencel</dc:creator>
    </item>
    <item>
      <title>AlgOS: Algorithm Operating System</title>
      <link>https://arxiv.org/abs/2504.04909</link>
      <description>arXiv:2504.04909v1 Announce Type: new 
Abstract: Algorithm Operating System (AlgOS) is an unopinionated, extensible, modular framework for algorithmic implementations. AlgOS offers numerous features: integration with Optuna for automated hyperparameter tuning; automated argument parsing for generic command-line interfaces; automated registration of new classes; and a centralised database for logging experiments and studies. These features are designed to reduce the overhead of implementing new algorithms and to standardise the comparison of algorithms. The standardisation of algorithmic implementations is crucial for reproducibility and reliability in research. AlgOS combines Abstract Syntax Trees with a novel implementation of the Observer pattern to control the logical flow of algorithmic segments.</description>
      <guid isPermaLink="false">oai:arXiv.org:2504.04909v1</guid>
      <category>cs.SE</category>
      <category>cs.AI</category>
      <category>cs.LG</category>
      <pubDate>Tue, 08 Apr 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Llewyn Salt, Marcus Gallagher</dc:creator>
    </item>
    <item>
      <title>Expectations vs Reality -- A Secondary Study on AI Adoption in Software Testing</title>
      <link>https://arxiv.org/abs/2504.04921</link>
      <description>arXiv:2504.04921v1 Announce Type: new 
Abstract: In the software industry, artificial intelligence (AI) has been utilized more and more in software development activities. In some activities, such as coding, AI has already been an everyday tool, but in software testing activities AI it has not yet made a significant breakthrough. In this paper, the objective was to identify what kind of empirical research with industry context has been conducted on AI in software testing, as well as how AI has been adopted in software testing practice. To achieve this, we performed a systematic mapping study of recent (2020 and later) studies on AI adoption in software testing in the industry, and applied thematic analysis to identify common themes and categories, such as the real-world use cases and benefits, in the found papers. The observations suggest that AI is not yet heavily utilized in software testing, and still relatively few studies on AI adoption in software testing have been conducted in the industry context to solve real-world problems. Earlier studies indicated there was a noticeable gap between the actual use cases and actual benefits versus the expectations, which we analyzed further. While there were numerous potential use cases for AI in software testing, such as test case generation, code analysis, and intelligent test automation, the reported actual implementations and observed benefits were limited. In addition, the systematic mapping study revealed a potential problem with false positive search results in online databases when using the search string "artificial intelligence".</description>
      <guid isPermaLink="false">oai:arXiv.org:2504.04921v1</guid>
      <category>cs.SE</category>
      <category>cs.AI</category>
      <pubDate>Tue, 08 Apr 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-sa/4.0/</dc:rights>
      <dc:creator>Katja Karhu, Jussi Kasurinen, Kari Smolander</dc:creator>
    </item>
    <item>
      <title>Quantum Program Linting with LLMs: Emerging Results from a Comparative Study</title>
      <link>https://arxiv.org/abs/2504.05204</link>
      <description>arXiv:2504.05204v1 Announce Type: new 
Abstract: Ensuring the quality of quantum programs is increasingly important; however, traditional static analysis techniques are insufficient due to the unique characteristics of quantum computing. Quantum-specific linting tools, such as LintQ, have been developed to detect quantum-specific programming problems; however, they typically rely on manually crafted analysis queries. The manual effort required to update these tools limits their adaptability to evolving quantum programming practices.
  To address this challenge, this study investigates the feasibility of employing Large Language Models (LLMs) to develop a novel linting technique for quantum software development and explores potential avenues to advance linting approaches. We introduce LintQ-LLM, an LLM-based linting tool designed to detect quantum-specific problems comparable to those identified by LintQ. Through an empirical comparative study using real-world Qiskit programs, our results show that LintQ-LLM is a viable solution that complements LintQ, with particular strengths in problem localization, explanation clarity, and adaptability potential for emerging quantum programming frameworks, thus providing a basis for further research. Furthermore, this study discusses several research opportunities for developing more advanced, adaptable, and feedback-aware quantum software quality assurance methods by leveraging LLMs.</description>
      <guid isPermaLink="false">oai:arXiv.org:2504.05204v1</guid>
      <category>cs.SE</category>
      <pubDate>Tue, 08 Apr 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Seung Yeob Shin, Fabrizio Pastore, Domenico Bianculli</dc:creator>
    </item>
    <item>
      <title>The Secret Life of CVEs</title>
      <link>https://arxiv.org/abs/2504.03863</link>
      <description>arXiv:2504.03863v1 Announce Type: cross 
Abstract: The Common Vulnerabilities and Exposures (CVEs) system is a reference method for documenting publicly known information security weaknesses and exposures. This paper presents a study of the lifetime of CVEs in software projects and the risk factors affecting their existence. The study uses survival analysis to examine how features of programming languages, projects, and CVEs themselves impact the lifetime of CVEs. We suggest avenues for future research to investigate the effect of various factors on the resolution of vulnerabilities.</description>
      <guid isPermaLink="false">oai:arXiv.org:2504.03863v1</guid>
      <category>cs.CR</category>
      <category>cs.SE</category>
      <pubDate>Tue, 08 Apr 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <arxiv:DOI>10.1109/MSR59073.2023.00056</arxiv:DOI>
      <arxiv:journal_reference>2023 IEEE/ACM 20th International Conference on Mining Software Repositories (MSR), Melbourne, Australia, 2023, pp. 362-366</arxiv:journal_reference>
      <dc:creator>Piotr Przymus, Miko{\l}aj Fejzer, Jakub Nar\k{e}bski, Krzysztof Stencel</dc:creator>
    </item>
    <item>
      <title>Bridging LMS and Generative AI: Dynamic Course Content Integration (DCCI) for Connecting LLMs to Course Content -- The Ask ME Assistant</title>
      <link>https://arxiv.org/abs/2504.03966</link>
      <description>arXiv:2504.03966v1 Announce Type: cross 
Abstract: The integration of Large Language Models (LLMs) with Learning Management Systems (LMSs) has the potential to enhance task automation and accessibility in education. However, hallucination where LLMs generate inaccurate or misleading information remains a significant challenge. This study introduces the Dynamic Course Content Integration (DCCI) mechanism, which dynamically retrieves and integrates course content and curriculum from Canvas LMS into the LLM-powered assistant, Ask ME. By employing prompt engineering to structure retrieved content within the LLM's context window, DCCI ensures accuracy, relevance, and contextual alignment, mitigating hallucination. To evaluate DCCI's effectiveness, Ask ME's usability, and broader student perceptions of AI in education, a mixed-methods approach was employed, incorporating user satisfaction ratings and a structured survey. Results from a pilot study indicate high user satisfaction (4.614/5), with students recognizing Ask ME's ability to provide timely and contextually relevant responses for both administrative and course-related inquiries. Additionally, a majority of students agreed that Ask ME's integration with course content in Canvas LMS reduced platform-switching, improving usability, engagement, and comprehension. AI's role in reducing classroom hesitation and fostering self-directed learning and intellectual curiosity was also highlighted. Despite these benefits and positive perception of AI tools, concerns emerged regarding over-reliance on AI, accuracy limitations, and ethical issues such as plagiarism and reduced student-teacher interaction. These findings emphasize the need for strategic AI implementation, ethical safeguards, and a pedagogical framework that prioritizes human-AI collaboration over substitution.</description>
      <guid isPermaLink="false">oai:arXiv.org:2504.03966v1</guid>
      <category>cs.CY</category>
      <category>cs.AI</category>
      <category>cs.ET</category>
      <category>cs.HC</category>
      <category>cs.SE</category>
      <pubDate>Tue, 08 Apr 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <arxiv:DOI>10.21203/rs.3.rs-6256444/v1</arxiv:DOI>
      <dc:creator>Kovan Mzwri (Doctoral School of Informatics, E\"otv\"os Lor\'and University, Budapest, Hungary), M\'arta Turcs\'anyi-Szabo (Department of Media &amp; Educational Technology, Faculty of Informatics, E\"otv\"os Lor\'and University, Budapest, Hungary)</dc:creator>
    </item>
    <item>
      <title>LeakGuard: Detecting Memory Leaks Accurately and Scalably</title>
      <link>https://arxiv.org/abs/2504.04422</link>
      <description>arXiv:2504.04422v1 Announce Type: cross 
Abstract: Memory leaks are prevalent in various real-world software projects, thereby leading to serious attacks like denial-of-service. Though prior methods for detecting memory leaks made significant advance, they often suffer from low accuracy and weak scalability for testing large and complex programs. In this paper we present LeakGuard, a memory leak detection tool which provides satisfactory balance of accuracy and scalability. For accuracy, LeakGuard analyzes the behaviors of library and developer-defined memory allocation and deallocation functions in a path-sensitive manner and generates function summaries for them in a bottom-up approach. Additionally, we develop a pointer escape analysis technique to model the transfer of pointer ownership. For scalability, LeakGuard examines each function of interest independently by using its function summary and under-constrained symbolic execution technique, which effectively mitigates path explosion problem. Our extensive evaluation on 18 real-world software projects and standard benchmark datasets demonstrates that LeakGuard achieves significant advancements in multiple aspects: it exhibits superior MAD function identification capability compared to Goshawk, outperforms five state-of-the-art methods in defect detection accuracy, and successfully identifies 129 previously undetected memory leak bugs, all of which have been independently verified and confirmed by the respective development teams.</description>
      <guid isPermaLink="false">oai:arXiv.org:2504.04422v1</guid>
      <category>cs.CR</category>
      <category>cs.SE</category>
      <pubDate>Tue, 08 Apr 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Hongliang Liang, Luming Yin, Guohao Wu, Yuxiang Li, Qiuping Yi, Lei Wang</dc:creator>
    </item>
    <item>
      <title>On the Impact of Black-box Deployment Strategies for Edge AI on Latency and Model Performance</title>
      <link>https://arxiv.org/abs/2403.17154</link>
      <description>arXiv:2403.17154v2 Announce Type: replace 
Abstract: Deciding what combination of operators to use across the Edge AI tiers to achieve specific latency and model performance requirements is an open question for MLOps engineers. This study aims to empirically assess the accuracy vs inference time trade-off of different black-box Edge AI deployment strategies, i.e., combinations of deployment operators and deployment tiers. In this paper, we conduct inference experiments involving 3 deployment operators (i.e., Partitioning, Quantization, Early Exit), 3 deployment tiers (i.e., Mobile, Edge, Cloud) and their combinations on four widely used Computer-Vision models to investigate the optimal strategies from the point of view of MLOps developers. Our findings suggest that Edge deployment using the hybrid Quantization + Early Exit operator could be preferred over non-hybrid operators (Quantization/Early Exit on Edge, Partition on Mobile-Edge) when faster latency is a concern at medium accuracy loss. However, when minimizing accuracy loss is a concern, MLOps engineers should prefer using only a Quantization operator on edge at a latency reduction or increase, respectively over the Early Exit/Partition (on edge/mobile-edge) and Quantized Early Exit (on edge) operators. In scenarios constrained by Mobile CPU/RAM resources, a preference for Partitioning across mobile and edge tiers is observed over mobile deployment. For models with smaller input data samples (such as FCN), a network-constrained cloud deployment can also be a better alternative than Mobile/Edge deployment and Partitioning strategies. For models with large input data samples (ResNet, ResNext, DUC), an edge tier having higher network/computational capabilities than Cloud/Mobile can be a more viable option than Partitioning and Mobile/Cloud deployment strategies.</description>
      <guid isPermaLink="false">oai:arXiv.org:2403.17154v2</guid>
      <category>cs.SE</category>
      <category>cs.AI</category>
      <category>cs.LG</category>
      <pubDate>Tue, 08 Apr 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Jaskirat Singh, Emad Fallahzadeh, Bram Adams, Ahmed E. Hassan</dc:creator>
    </item>
    <item>
      <title>Demystifying Issues, Causes and Solutions in LLM Open-Source Projects</title>
      <link>https://arxiv.org/abs/2409.16559</link>
      <description>arXiv:2409.16559v2 Announce Type: replace 
Abstract: With the advancements of Large Language Models (LLMs), an increasing number of open-source software projects are using LLMs as their core functional component. Although research and practice on LLMs are capturing considerable interest, no dedicated studies explored the challenges faced by practitioners of LLM open-source projects, the causes of these challenges, and potential solutions. To fill this research gap, we conducted an empirical study to understand the issues that practitioners encounter when developing and using LLM open-source software, the possible causes of these issues, and potential solutions. We collected all closed issues from 15 LLM open-source projects and labelled issues that met our requirements. We then randomly selected 994 issues from the labelled issues as the sample for data extraction and analysis to understand the prevalent issues, their underlying causes, and potential solutions. Our study results show that (1) Model Issue is the most common issue faced by practitioners, (2) Model Problem, Configuration and Connection Problem, and Feature and Method Problem are identified as the most frequent causes of the issues, and (3) Optimize Model is the predominant solution to the issues. Based on the study results, we provide implications for practitioners and researchers of LLM open-source projects.</description>
      <guid isPermaLink="false">oai:arXiv.org:2409.16559v2</guid>
      <category>cs.SE</category>
      <category>cs.AI</category>
      <pubDate>Tue, 08 Apr 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Yangxiao Cai, Peng Liang, Yifei Wang, Zengyang Li, Mojtaba Shahin</dc:creator>
    </item>
    <item>
      <title>VeCoGen: Automating Generation of Formally Verified C Code with Large Language Models</title>
      <link>https://arxiv.org/abs/2411.19275</link>
      <description>arXiv:2411.19275v3 Announce Type: replace 
Abstract: Large language models have demonstrated impressive capabilities in generating code, yet they often produce programs with flaws or deviations from intended behavior, limiting their suitability for safety-critical applications. To address this limitation, this paper introduces VECOGEN, a novel tool that combines large language models with formal verification to automate the generation of formally verified C programs. VECOGEN takes a formal specification in ANSI/ISO C Specification Language, a natural language specification, and a set of test cases to attempt to generate a verified program. This program-generation process consists of two steps. First, VECOGEN generates an initial set of candidate programs. Secondly, the tool iteratively improves on previously generated candidates. If a candidate program meets the formal specification, then we are sure the program is correct. We evaluate VECOGEN on 15 problems presented in Codeforces competitions. On these problems, VECOGEN solves 13 problems. This work shows the potential of combining large language models with formal verification to automate program generation.</description>
      <guid isPermaLink="false">oai:arXiv.org:2411.19275v3</guid>
      <category>cs.SE</category>
      <pubDate>Tue, 08 Apr 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Merlijn Sevenhuijsen, Khashayar Etemadi, Mattias Nyberg</dc:creator>
    </item>
    <item>
      <title>Consolidating TinyML Lifecycle with Large Language Models: Reality, Illusion, or Opportunity?</title>
      <link>https://arxiv.org/abs/2501.12420</link>
      <description>arXiv:2501.12420v2 Announce Type: replace 
Abstract: The evolving requirements of Internet of Things (IoT) applications are driving an increasing shift toward bringing intelligence to the edge, enabling real-time insights and decision-making within resource-constrained environments. Tiny Machine Learning (TinyML) has emerged as a key enabler of this evolution, facilitating the deployment of ML models on devices such as microcontrollers and embedded systems. However, the complexity of managing the TinyML lifecycle, including stages such as data processing, model optimization and conversion, and device deployment, presents significant challenges and often requires substantial human intervention. Motivated by these challenges, we began exploring whether Large Language Models (LLMs) could help automate and streamline the TinyML lifecycle. We developed a framework that leverages the natural language processing (NLP) and code generation capabilities of LLMs to reduce development time and lower the barriers to entry for TinyML deployment. Through a case study involving a computer vision classification model, we demonstrate the framework's ability to automate key stages of the TinyML lifecycle. Our findings suggest that LLM-powered automation holds potential for improving the lifecycle development process and adapting to diverse requirements. However, while this approach shows promise, there remain obstacles and limitations, particularly in achieving fully automated solutions. This paper sheds light on both the challenges and opportunities of integrating LLMs into TinyML workflows, providing insights into the path forward for efficient, AI-assisted embedded system development.</description>
      <guid isPermaLink="false">oai:arXiv.org:2501.12420v2</guid>
      <category>cs.SE</category>
      <category>cs.AI</category>
      <category>cs.LG</category>
      <pubDate>Tue, 08 Apr 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Guanghan Wu, Sasu Tarkoma, Roberto Morabito</dc:creator>
    </item>
    <item>
      <title>How Users Employ Workarounds in Software Forms</title>
      <link>https://arxiv.org/abs/2503.17624</link>
      <description>arXiv:2503.17624v2 Announce Type: replace 
Abstract: Workarounds enable users to achieve goals despite system limitations but expose design flaws, reduce productivity, risk compromising data quality, and cause inconsistencies. This study investigates how users employ workarounds when the data they want to enter does not align with software form constraints. Through a descriptive user study, we analyzed how workarounds originate and impact system design and data integrity. Understanding workarounds is essential for software designers to identify unmet user needs.</description>
      <guid isPermaLink="false">oai:arXiv.org:2503.17624v2</guid>
      <category>cs.SE</category>
      <pubDate>Tue, 08 Apr 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>MohammadAmin Zaheri, Michalis Famelis, Eugene Syriani</dc:creator>
    </item>
    <item>
      <title>From Code Generation to Software Testing: AI Copilot with Context-Based RAG</title>
      <link>https://arxiv.org/abs/2504.01866</link>
      <description>arXiv:2504.01866v2 Announce Type: replace 
Abstract: The rapid pace of large-scale software development places increasing demands on traditional testing methodologies, often leading to bottlenecks in efficiency, accuracy, and coverage. We propose a novel perspective on software testing by positing bug detection and coding with fewer bugs as two interconnected problems that share a common goal, which is reducing bugs with limited resources. We extend our previous work on AI-assisted programming, which supports code auto-completion and chatbot-powered Q&amp;A, to the realm of software testing. We introduce Copilot for Testing, an automated testing system that synchronizes bug detection with codebase updates, leveraging context-based Retrieval Augmented Generation (RAG) to enhance the capabilities of large language models (LLMs). Our evaluation demonstrates a 31.2% improvement in bug detection accuracy, a 12.6% increase in critical test coverage, and a 10.5% higher user acceptance rate, highlighting the transformative potential of AI-driven technologies in modern software development practices.</description>
      <guid isPermaLink="false">oai:arXiv.org:2504.01866v2</guid>
      <category>cs.SE</category>
      <category>cs.AI</category>
      <category>cs.PL</category>
      <pubDate>Tue, 08 Apr 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <arxiv:DOI>10.1109/MS.2025.3549628</arxiv:DOI>
      <dc:creator>Yuchen Wang, Shangxin Guo, Chee Wei Tan</dc:creator>
    </item>
    <item>
      <title>From Prompts to Templates: A Systematic Prompt Template Analysis for Real-world LLMapps</title>
      <link>https://arxiv.org/abs/2504.02052</link>
      <description>arXiv:2504.02052v2 Announce Type: replace 
Abstract: Large Language Models (LLMs) have revolutionized human-AI interaction by enabling intuitive task execution through natural language prompts. Despite their potential, designing effective prompts remains a significant challenge, as small variations in structure or wording can result in substantial differences in output. To address these challenges, LLM-powered applications (LLMapps) rely on prompt templates to simplify interactions, enhance usability, and support specialized tasks such as document analysis, creative content generation, and code synthesis. However, current practices heavily depend on individual expertise and iterative trial-and-error processes, underscoring the need for systematic methods to optimize prompt template design in LLMapps. This paper presents a comprehensive analysis of prompt templates in practical LLMapps. We construct a dataset of real-world templates from open-source LLMapps, including those from leading companies like Uber and Microsoft. Through a combination of LLM-driven analysis and human review, we categorize template components and placeholders, analyze their distributions, and identify frequent co-occurrence patterns. Additionally, we evaluate the impact of identified patterns on LLMs' instruction-following performance through sample testing. Our findings provide practical insights on prompt template design for developers, supporting the broader adoption and optimization of LLMapps in industrial settings.</description>
      <guid isPermaLink="false">oai:arXiv.org:2504.02052v2</guid>
      <category>cs.SE</category>
      <pubDate>Tue, 08 Apr 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Yuetian Mao, Junjie He, Chunyang Chen</dc:creator>
    </item>
    <item>
      <title>IRIS: LLM-Assisted Static Analysis for Detecting Security Vulnerabilities</title>
      <link>https://arxiv.org/abs/2405.17238</link>
      <description>arXiv:2405.17238v3 Announce Type: replace-cross 
Abstract: Software is prone to security vulnerabilities. Program analysis tools to detect them have limited effectiveness in practice due to their reliance on human labeled specifications. Large language models (or LLMs) have shown impressive code generation capabilities but they cannot do complex reasoning over code to detect such vulnerabilities especially since this task requires whole-repository analysis. We propose IRIS, a neuro-symbolic approach that systematically combines LLMs with static analysis to perform whole-repository reasoning for security vulnerability detection. Specifically, IRIS leverages LLMs to infer taint specifications and perform contextual analysis, alleviating needs for human specifications and inspection. For evaluation, we curate a new dataset, CWE-Bench-Java, comprising 120 manually validated security vulnerabilities in real-world Java projects. A state-of-the-art static analysis tool CodeQL detects only 27 of these vulnerabilities whereas IRIS with GPT-4 detects 55 (+28) and improves upon CodeQL's average false discovery rate by 5% points. Furthermore, IRIS identifies 4 previously unknown vulnerabilities which cannot be found by existing tools. IRIS is available publicly at https://github.com/iris-sast/iris.</description>
      <guid isPermaLink="false">oai:arXiv.org:2405.17238v3</guid>
      <category>cs.CR</category>
      <category>cs.PL</category>
      <category>cs.SE</category>
      <pubDate>Tue, 08 Apr 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Ziyang Li, Saikat Dutta, Mayur Naik</dc:creator>
    </item>
    <item>
      <title>Continuous reasoning for adaptive container image distribution in the cloud-edge continuum</title>
      <link>https://arxiv.org/abs/2407.12605</link>
      <description>arXiv:2407.12605v2 Announce Type: replace-cross 
Abstract: Cloud-edge computing requires applications to operate across diverse infrastructures, often triggered by cyber-physical events. Containers offer a lightweight deployment option but pulling images from central repositories can cause delays. This article presents a novel declarative approach and open-source prototype for replicating container images across the cloud-edge continuum. Considering resource availability, network QoS, and storage costs, we leverage logic programming to (i) determine optimal initial placements via Answer Set Programming (ASP) and (ii) adapt placements using Prolog-based continuous reasoning. We evaluate our solution through simulations, showcasing how combining ASP and Prolog continuous reasoning can balance cost optimisation and prompt decision-making in placement adaptation at increasing infrastructure sizes.</description>
      <guid isPermaLink="false">oai:arXiv.org:2407.12605v2</guid>
      <category>cs.DC</category>
      <category>cs.AI</category>
      <category>cs.LO</category>
      <category>cs.SE</category>
      <pubDate>Tue, 08 Apr 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/publicdomain/zero/1.0/</dc:rights>
      <arxiv:DOI>10.1007/s10586-025-05253-9</arxiv:DOI>
      <arxiv:journal_reference>Cluster Computing, 2025</arxiv:journal_reference>
      <dc:creator>Damiano Azzolini, Stefano Forti, Antonio Ielo</dc:creator>
    </item>
    <item>
      <title>MCP-Solver: Integrating Language Models with Constraint Programming Systems</title>
      <link>https://arxiv.org/abs/2501.00539</link>
      <description>arXiv:2501.00539v2 Announce Type: replace-cross 
Abstract: The MCP Solver bridges Large Language Models (LLMs) with symbolic solvers through the Model Context Protocol (MCP), an open-source standard for AI system integration. Providing LLMs access to formal solving and reasoning capabilities addresses their key deficiency while leveraging their strengths. Our implementation offers interfaces for constraint programming (Minizinc), propositional satisfiability (PySAT), and SAT modulo Theories (Python Z3). The system employs an editing approach with iterated validation to ensure model consistency during modifications and enable structured refinement.</description>
      <guid isPermaLink="false">oai:arXiv.org:2501.00539v2</guid>
      <category>cs.AI</category>
      <category>cs.CL</category>
      <category>cs.LG</category>
      <category>cs.SE</category>
      <pubDate>Tue, 08 Apr 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Stefan Szeider</dc:creator>
    </item>
    <item>
      <title>Data Spatial Programming</title>
      <link>https://arxiv.org/abs/2503.15812</link>
      <description>arXiv:2503.15812v4 Announce Type: replace-cross 
Abstract: We introduce a novel programming model, Data Spatial Programming, which extends the semantics of Object-Oriented Programming (OOP) by introducing new class-like constructs called archetypes. These archetypes encapsulate the topological relationships between data entities and the execution flow in a structured manner, enabling more expressive and semantically rich computations over interconnected data structures or finite states. By formalizing the relationships between data elements in this topological space, our approach allows for more intuitive modeling of complex systems where a topology of connections is formed for the underlying computational model. This paradigm addresses limitations in traditional OOP when representing a wide range of problems in computer science such as agent-based systems, social networks, processing on relational data, neural networks, distributed systems, finite state machines, and other spatially-oriented computational problems.</description>
      <guid isPermaLink="false">oai:arXiv.org:2503.15812v4</guid>
      <category>cs.PL</category>
      <category>cs.MA</category>
      <category>cs.SE</category>
      <pubDate>Tue, 08 Apr 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Jason Mars</dc:creator>
    </item>
    <item>
      <title>Multi-agent Application System in Office Collaboration Scenarios</title>
      <link>https://arxiv.org/abs/2503.19584</link>
      <description>arXiv:2503.19584v3 Announce Type: replace-cross 
Abstract: This paper introduces a multi-agent application system designed to enhance office collaboration efficiency and work quality. The system integrates artificial intelligence, machine learning, and natural language processing technologies, achieving functionalities such as task allocation, progress monitoring, and information sharing. The agents within the system are capable of providing personalized collaboration support based on team members' needs and incorporate data analysis tools to improve decision-making quality. The paper also proposes an intelligent agent architecture that separates Plan and Solver, and through techniques such as multi-turn query rewriting and business tool retrieval, it enhances the agent's multi-intent and multi-turn dialogue capabilities. Furthermore, the paper details the design of tools and multi-turn dialogue in the context of office collaboration scenarios, and validates the system's effectiveness through experiments and evaluations. Ultimately, the system has demonstrated outstanding performance in real business applications, particularly in query understanding, task planning, and tool calling. Looking forward, the system is expected to play a more significant role in addressing complex interaction issues within dynamic environments and large-scale multi-agent systems.</description>
      <guid isPermaLink="false">oai:arXiv.org:2503.19584v3</guid>
      <category>cs.AI</category>
      <category>cs.CL</category>
      <category>cs.SE</category>
      <pubDate>Tue, 08 Apr 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Songtao Sun, Jingyi Li, Yuanfei Dong, Haoguang Liu, Chenxin Xu, Fuyang Li, Qiang Liu</dc:creator>
    </item>
    <item>
      <title>GIScience in the Era of Artificial Intelligence: A Research Agenda Towards Autonomous GIS</title>
      <link>https://arxiv.org/abs/2503.23633</link>
      <description>arXiv:2503.23633v3 Announce Type: replace-cross 
Abstract: The advent of generative AI exemplified by large language models (LLMs) opens new ways to represent and compute geographic information and transcends the process of geographic knowledge production, driving geographic information systems (GIS) towards autonomous GIS. Leveraging LLMs as the decision core, autonomous GIS can independently generate and execute geoprocessing workflows to perform spatial analysis. In this vision paper, we further elaborate on the concept of autonomous GIS and present a conceptual framework that defines its five autonomous goals, five autonomous levels, five core functions, and three operational scales. We demonstrate how autonomous GIS could perform geospatial data retrieval, spatial analysis, and map making with four proof-of-concept GIS agents. We conclude by identifying critical challenges and future research directions, including fine-tuning and self-growing decision-cores, autonomous modeling, and examining the societal and practical implications of autonomous GIS. By establishing the groundwork for a paradigm shift in GIScience, this paper envisions a future where GIS moves beyond traditional workflows to autonomously reason, derive, innovate, and advance geospatial solutions to pressing global challenges. As we design and deploy increasingly intelligent geospatial systems, we have a responsibility to ensure they are developed in socially responsible ways, serve the public good, and support the continued value of human geographic insight in an AI-augmented future.</description>
      <guid isPermaLink="false">oai:arXiv.org:2503.23633v3</guid>
      <category>cs.AI</category>
      <category>cs.ET</category>
      <category>cs.SE</category>
      <pubDate>Tue, 08 Apr 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Zhenlong Li, Huan Ning, Song Gao, Krzysztof Janowicz, Wenwen Li, Samantha T. Arundel, Chaowei Yang, Budhendra Bhaduri, Shaowen Wang, A-Xing Zhu, Mark Gahegan, Shashi Shekhar, Xinyue Ye, Grant McKenzie, Guido Cervone, Michael E. Hodgson</dc:creator>
    </item>
  </channel>
</rss>
