<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>cs.DB updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/cs.DB</link>
    <description>cs.DB updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/cs.DB" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Thu, 20 Mar 2025 01:52:50 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Wed, 19 Mar 2025 00:00:00 -0400</pubDate>
    <skipDays>
      <day>Sunday</day>
      <day>Saturday</day>
    </skipDays>
    <item>
      <title>CARDS: A collection of package, revision, and miscellaneous dependency graphs</title>
      <link>https://arxiv.org/abs/2503.13461</link>
      <description>arXiv:2503.13461v1 Announce Type: new 
Abstract: CARDS (Corpus of Acyclic Repositories and Dependency Systems) is a collection of directed graphs which express dependency relations, extracted from diverse real-world sources such as package managers, version control systems, and event graphs. Each graph contains anywhere from thousands to hundreds of millions of nodes and edges, which are normalized into a simple, unified format. Both cyclic and acyclic variants are included (as some graphs, such as citation networks, are not entirely acyclic). The dataset is suitable for studying the structure of different kinds of dependencies, enabling the characterization and distinction of various dependency graph types. It has been utilized for developing and testing efficient algorithms which leverage the specificities of source version control graphs. The collection is publicly available at doi.org/10.5281/zenodo.14245890.</description>
      <guid isPermaLink="false">oai:arXiv.org:2503.13461v1</guid>
      <category>cs.DB</category>
      <category>cs.DL</category>
      <category>cs.SI</category>
      <pubDate>Wed, 19 Mar 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Euxane Tran-Girard (LIGM, CNRS), Laurent Bulteau (LIGM, CNRS), Pierre-Yves David</dc:creator>
    </item>
    <item>
      <title>Foundation Models for Spatio-Temporal Data Science: A Tutorial and Survey</title>
      <link>https://arxiv.org/abs/2503.13502</link>
      <description>arXiv:2503.13502v1 Announce Type: new 
Abstract: Spatio-Temporal (ST) data science, which includes sensing, managing, and mining large-scale data across space and time, is fundamental to understanding complex systems in domains such as urban computing, climate science, and intelligent transportation. Traditional deep learning approaches have significantly advanced this field, particularly in the stage of ST data mining. However, these models remain task-specific and often require extensive labeled data. Inspired by the success of Foundation Models (FM), especially large language models, researchers have begun exploring the concept of Spatio-Temporal Foundation Models (STFMs) to enhance adaptability and generalization across diverse ST tasks. Unlike prior architectures, STFMs empower the entire workflow of ST data science, ranging from data sensing, management, to mining, thereby offering a more holistic and scalable approach. Despite rapid progress, a systematic study of STFMs for ST data science remains lacking. This survey aims to provide a comprehensive review of STFMs, categorizing existing methodologies and identifying key research directions to advance ST general intelligence.</description>
      <guid isPermaLink="false">oai:arXiv.org:2503.13502v1</guid>
      <category>cs.DB</category>
      <category>cs.LG</category>
      <pubDate>Wed, 19 Mar 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/publicdomain/zero/1.0/</dc:rights>
      <dc:creator>Yuxuan Liang, Haomin Wen, Yutong Xia, Ming Jin, Bin Yang, Flora Salim, Qingsong Wen, Shirui Pan, Gao Cong</dc:creator>
    </item>
    <item>
      <title>States of Disarray: Cleaning Data for Gerrymandering Analysis</title>
      <link>https://arxiv.org/abs/2503.13521</link>
      <description>arXiv:2503.13521v1 Announce Type: new 
Abstract: The mathematics of redistricting is an area of study that has exploded in recent years. In particular, many different research groups and expert witnesses in court cases have used outlier analysis to argue that a proposed map is a gerrymander. This outlier analysis relies on having an ensemble of potential redistricting maps against which the proposed map is compared. Arguably the most widely-accepted method of creating such an ensemble is to use a Markov Chain Monte Carlo (MCMC) process. This process requires that various pieces of data be gathered, cleaned, and coalesced into a single file that can be used as the seed of the MCMC process.
  In this article, we describe how we have begun this cleaning process for each state, and made the resulting data available for the public at https://github.com/eveomett-states . At the time of submission, we have data for 22 states available for researchers, students, and the general public to easily access and analyze. We will continue the data cleaning process for each state, and we hope that the availability of these datasets will both further research in this area, and increase the public's interest in and understanding of modern techniques to detect gerrymandering.</description>
      <guid isPermaLink="false">oai:arXiv.org:2503.13521v1</guid>
      <category>cs.DB</category>
      <category>cs.CY</category>
      <category>physics.soc-ph</category>
      <category>stat.AP</category>
      <pubDate>Wed, 19 Mar 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <dc:creator>Ananya Agarwal, Fnu Alusi, Arbie Hsu, Arif Syraj, Ellen Veomett</dc:creator>
    </item>
    <item>
      <title>NeurBench: Benchmarking Learned Database Components with Data and Workload Drift Modeling</title>
      <link>https://arxiv.org/abs/2503.13822</link>
      <description>arXiv:2503.13822v1 Announce Type: new 
Abstract: Learned database components, which deeply integrate machine learning into their design, have been extensively studied in recent years. Given the dynamism of databases, where data and workloads continuously drift, it is crucial for learned database components to remain effective and efficient in the face of data and workload drift. Adaptability, therefore, is a key factor in assessing their practical applicability. However, existing benchmarks for learned database components either overlook or oversimplify the treatment of data and workload drift, failing to evaluate learned database components across a broad range of drift scenarios. This paper presents NeurBench, a new benchmark suite that applies measurable and controllable data and workload drift to enable systematic performance evaluations of learned database components. We quantify diverse types of drift by introducing a key concept called the drift factor. Building on this formulation, we propose a drift-aware data and workload generation framework that effectively simulates real-world drift while preserving inherent correlations. We employ NeurBench to evaluate state-of-the-art learned query optimizers, learned indexes, and learned concurrency control within a consistent experimental process, providing insights into their performance under diverse data and workload drift scenarios.</description>
      <guid isPermaLink="false">oai:arXiv.org:2503.13822v1</guid>
      <category>cs.DB</category>
      <pubDate>Wed, 19 Mar 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Zhanhao Zhao, Gang Chen, Haotian Gao, Manuel Rigger, Beng Chin Ooi, Naili Xing, Lingze Zeng, Meihui Zhang</dc:creator>
    </item>
    <item>
      <title>Mapping Urban Villages in China: Progress and Challenges</title>
      <link>https://arxiv.org/abs/2503.14195</link>
      <description>arXiv:2503.14195v1 Announce Type: new 
Abstract: The shift toward high-quality urbanization has brought increased attention to the issue of "urban villages", which has become a prominent social problem in China. However, there is a lack of available geospatial data on urban villages, making it crucial to prioritize urban village mapping. In order to assess the current progress in urban village mapping and identify challenges and future directions, we have conducted a comprehensive review, which to the best of our knowledge is the first of its kind in this field. Our review begins by providing a clear context for urban villages and elaborating the method for literature review, then summarizes the study areas, data sources, and approaches used for urban village mapping in China. We also address the challenges and future directions for further research. Through thorough investigation, we find that current studies only cover very limited study areas and periods and lack sufficient investigation into the scalability, transferability, and interpretability of identification approaches due to the challenges in concept fuzziness and variances, spatial heterogeneity and variances of urban villages, and data availability. Future research can complement and further the current research in the following potential directions in order to achieve large-area mapping across the whole nation...</description>
      <guid isPermaLink="false">oai:arXiv.org:2503.14195v1</guid>
      <category>cs.DB</category>
      <category>cs.CV</category>
      <pubDate>Wed, 19 Mar 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <arxiv:DOI>10.1016/j.compenvurbsys.2025.102282</arxiv:DOI>
      <arxiv:journal_reference>Computers, Environment and Urban Systems, 119, 102282 (2025)</arxiv:journal_reference>
      <dc:creator>Rui Cao, Wei Tu, Dongsheng Chen, Wenyu Zhang</dc:creator>
    </item>
    <item>
      <title>Attribution Score Alignment in Explainable Data Management</title>
      <link>https://arxiv.org/abs/2503.14469</link>
      <description>arXiv:2503.14469v1 Announce Type: new 
Abstract: Different attribution-scores have been proposed to quantify the relevance of database tuples for a query answer from a database. Among them, we find Causal Responsibility, the Shapley Value, the Banzhaf Power-Index, and the Causal Effect. They have been analyzed in isolation, mainly in terms of computational properties. In this work, we start an investigation into the alignment of these scores on the basis of the queries at hand; that is, on whether they induce compatible rankings of tuples. We are able to identify vast classes of queries for which some pairs of scores are always aligned, and others for which they are not. It turns out that the presence of exogenous tuples makes a crucial difference in this regard.</description>
      <guid isPermaLink="false">oai:arXiv.org:2503.14469v1</guid>
      <category>cs.DB</category>
      <category>cs.AI</category>
      <pubDate>Wed, 19 Mar 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Felipe Azua, Leopoldo Bertossi</dc:creator>
    </item>
    <item>
      <title>A Circular Construction Product Ontology for End-of-Life Decision-Making</title>
      <link>https://arxiv.org/abs/2503.13708</link>
      <description>arXiv:2503.13708v1 Announce Type: cross 
Abstract: Efficient management of end-of-life (EoL) products is critical for advancing circularity in supply chains, particularly within the construction industry where EoL strategies are hindered by heterogenous lifecycle data and data silos. Current tools like Environmental Product Declarations (EPDs) and Digital Product Passports (DPPs) are limited by their dependency on seamless data integration and interoperability which remain significant challenges. To address these, we present the Circular Construction Product Ontology (CCPO), an applied framework designed to overcome semantic and data heterogeneity challenges in EoL decision-making for construction products. CCPO standardises vocabulary and facilitates data integration across supply chain stakeholders enabling lifecycle assessments (LCA) and robust decision-making. By aggregating disparate data into a unified product provenance, CCPO enables automated EoL recommendations through customisable SWRL rules aligned with European standards and stakeholder-specific circularity SLAs, demonstrating its scalability and integration capabilities. The adopted circular product scenario depicts CCPO's application while competency question evaluations show its superior performance in generating accurate EoL suggestions highlighting its potential to greatly improve decision-making in circular supply chains and its applicability in real-world construction environments.</description>
      <guid isPermaLink="false">oai:arXiv.org:2503.13708v1</guid>
      <category>cs.AI</category>
      <category>cs.DB</category>
      <pubDate>Wed, 19 Mar 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Kwabena Adu-Duodu, Stanly Wilson, Yinhao Li, Aanuoluwapo Oladimeji, Talea Huraysi, Masoud Barati, Charith Perera, Ellis Solaiman, Omer Rana, Rajiv Ranjan, Tejal Shah</dc:creator>
    </item>
    <item>
      <title>Query Rewriting via LLMs</title>
      <link>https://arxiv.org/abs/2502.12918</link>
      <description>arXiv:2502.12918v2 Announce Type: replace 
Abstract: When complex SQL queries suffer slow executions despite query optimization, DBAs typically invoke automated query rewriting tools to recommend ``lean'' equivalents that are conducive to faster execution. The rewritings are usually achieved via transformation rules, but these rules are limited in scope and difficult to update in a production system. Recently, LLM-based techniques have also been suggested, but they are prone to semantic and syntactic errors.
  We investigate here how the remarkable cognitive capabilities of LLMs can be leveraged for performant query rewriting while incorporating safeguards and optimizations to ensure correctness and efficiency. Our study shows that these goals can be progressively achieved through incorporation of (a) an ensemble suite of basic prompts, (b) database-sensitive prompts via redundancy removal and selectivity-based rewriting rules, and (c) LLM token probability-guided rewrite paths. Further, a suite of logic-based and statistical tools can be used to check for semantic violations in the rewrites prior to DBA consideration.
  We have implemented the above LLM-infused techniques in the LITHE system, and evaluated complex analytic queries from standard benchmarks on contemporary database platforms. The results show significant performance improvements for slow queries, with regard to both abstract costing and actual execution, over both SOTA techniques and the native query optimizer. For instance, with TPC-DS on PostgreSQL, the geometric mean of the runtime speedups for slow queries was as high as 18.4 over the native optimizer, whereas SOTA delivered 6 in comparison.
  Overall, LITHE is a promising step toward viable LLM-based advisory tools for ameliorating enterprise query performance.</description>
      <guid isPermaLink="false">oai:arXiv.org:2502.12918v2</guid>
      <category>cs.DB</category>
      <pubDate>Wed, 19 Mar 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Sriram Dharwada, Himanshu Devrani, Jayant Haritsa, Harish Doraiswamy</dc:creator>
    </item>
    <item>
      <title>A Topology-Aware Localized Update Strategy for Graph-Based ANN Index</title>
      <link>https://arxiv.org/abs/2503.00402</link>
      <description>arXiv:2503.00402v2 Announce Type: replace 
Abstract: The graph-based index has been widely adopted to meet the demand for approximate nearest neighbor search (ANNS) for high-dimensional vectors. However, in dynamic scenarios involving frequent vector insertions and deletions, existing systems improve update throughput by adopting a batch update method. However, a large batch size leads to significant degradation in search accuracy.
  This work aims to improve the performance of graph-based ANNS systems in small-batch update scenarios, while maintaining high search efficiency and accuracy. We identify two key issues in existing batch update systems for small-batch updates. First, the system needs to scan the entire index file to identify and update the affected vertices, resulting in excessive unnecessary I/O. Second, updating the affected vertices introduces many new neighbors, frequently triggering neighbor pruning. To address these issues, we propose a topology-aware localized update strategy for graph-based ANN index. We introduce a lightweight index topology to identify affected vertices efficiently and employ a localized update strategy that modifies only the affected vertices in the index file. To mitigate frequent heavy neighbor pruning, we propose a similar neighbor replacement strategy, which connects the affected vertices to only a small number (typically one) of the most similar outgoing neighbors of the deleted vertex during repair. Based on extensive experiments on real-world datasets, our update strategy achieves 2.47X-6.45X higher update throughput than the state-of-the-art system FreshDiskANN while maintaining high search efficiency and accuracy.</description>
      <guid isPermaLink="false">oai:arXiv.org:2503.00402v2</guid>
      <category>cs.DB</category>
      <pubDate>Wed, 19 Mar 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Song Yu, Shengyuan Lin, Shufeng Gong, Yongqing Xie, Ruicheng Liu, Yijie Zhou, Ji Sun, Yanfeng Zhang, Guoliang Li, Ge Yu</dc:creator>
    </item>
    <item>
      <title>Resolvi: A Reference Architecture for Extensible, Scalable and Interoperable Entity Resolution</title>
      <link>https://arxiv.org/abs/2503.08087</link>
      <description>arXiv:2503.08087v3 Announce Type: replace 
Abstract: Context: Entity resolution (ER) plays a pivotal role in data management by determining whether multiple records correspond to the same real-world entity. Because of its critical importance across domains such as healthcare, finance, and machine learning and its long research history designing and implementing ER systems remains challenging in practice due to the wide array of methodologies and tools available. This diversity results in a paradox of choice for practitioners, which is further compounded by the various ER variants (record linkage, entity alignment, merge/purge, a.s.o).
  Objective: This paper introduces Resolvi, a reference architecture for facilitating the design of ER systems. The goal is to facilitate creating extensible, interoperable and scalable ER systems and to reduce architectural decision-making duration.
  Methods: Software design techniques such as the 4+1 view model or visual communication tools such as UML are used to present the reference architecture in a structured way. Source code analysis and literature review are used to derive the main elements of the reference architecture.
  Results: This paper identifies generic requirements and architectural qualities of ER systems. It provides design guidelines, patterns, and recommendations for creating extensible, scalable, and interoperable ER systems. Furthermore, it highlights implementation best practices and deployment strategies based on insights from existing systems.
  Conclusion: The proposed reference architecture offers a foundational blueprint for researchers and practitioners in developing extensible, interoperable, and scalable ER systems. Resolvi provides clear abstractions and design recommendations which simplify architecture decision making, whether designing new ER systems or improving existing designs.</description>
      <guid isPermaLink="false">oai:arXiv.org:2503.08087v3</guid>
      <category>cs.DB</category>
      <pubDate>Wed, 19 Mar 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Andrei Olar</dc:creator>
    </item>
  </channel>
</rss>
