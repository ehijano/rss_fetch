<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>cs.CY updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/cs.CY</link>
    <description>cs.CY updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/cs.CY" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Fri, 22 Nov 2024 05:00:11 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Fri, 22 Nov 2024 00:00:00 -0500</pubDate>
    <skipDays>
      <day>Sunday</day>
      <day>Saturday</day>
    </skipDays>
    <item>
      <title>Deciphering Urban Morphogenesis: A Morphospace Approach</title>
      <link>https://arxiv.org/abs/2411.13771</link>
      <description>arXiv:2411.13771v1 Announce Type: new 
Abstract: Cities emerged independently across different world regions and historical periods, raising fundamental questions: How did the first urban settlements develop? What social and spatial conditions enabled their emergence? Are these processes universal or context-dependent? Moreover, what distinguishes cities from other human settlements? This paper investigates the drivers of city creation through a hybrid approach that integrates urban theory with the biological concept of morphospace (the space of all possible configurations) and archaeological evidence. It examines the transition from sedentary hunter-gatherer communities to urban societies, identifying key forces such as defence, social hierarchy formation, population scale, and work specialization, culminating in increasingly complex divisions of labour as a central driver of urbanization. Morphogenesis is conceptualised as a trajectory across morphospace, shaped by structure-seeking selection processes that balance density, permeability, and information as critical dimensions. The study highlights the non-ergodic nature of urban morphogenesis, where configurations are progressively selected based on their fitness to support the diversifying interactions between mutually dependent agents. The morphospace framework effectively distinguishes between theoretical spatial configurations, non-urban and proto-urban settlements, and contemporary cities. This analysis supports the proposition that cities emerge and evolve as solutions balancing density, permeability, and informational organization, enabling them to support increasingly complex societal functions.</description>
      <guid isPermaLink="false">oai:arXiv.org:2411.13771v1</guid>
      <category>cs.CY</category>
      <category>cs.SI</category>
      <category>physics.soc-ph</category>
      <pubDate>Fri, 22 Nov 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Vini Netto, Caio Cacholas, Dries Daems, Fabiano Ribeiro, Howard Davis, Daniel Lenz</dc:creator>
    </item>
    <item>
      <title>GPAI Evaluations Standards Taskforce: Towards Effective AI Governance</title>
      <link>https://arxiv.org/abs/2411.13808</link>
      <description>arXiv:2411.13808v1 Announce Type: new 
Abstract: General-purpose AI evaluations have been proposed as a promising way of identifying and mitigating systemic risks posed by AI development and deployment. While GPAI evaluations play an increasingly central role in institutional decision- and policy-making -- including by way of the European Union AI Act's mandate to conduct evaluations on GPAI models presenting systemic risk -- no standards exist to date to promote their quality or legitimacy. To strengthen GPAI evaluations in the EU, which currently constitutes the first and only jurisdiction that mandates GPAI evaluations, we outline four desiderata for GPAI evaluations: internal validity, external validity, reproducibility, and portability. To uphold these desiderata in a dynamic environment of continuously evolving risks, we propose a dedicated EU GPAI Evaluation Standards Taskforce, to be housed within the bodies established by the EU AI Act. We outline the responsibilities of the Taskforce, specify the GPAI provider commitments that would facilitate Taskforce success, discuss the potential impact of the Taskforce on global AI governance, and address potential sources of failure that policymakers should heed.</description>
      <guid isPermaLink="false">oai:arXiv.org:2411.13808v1</guid>
      <category>cs.CY</category>
      <pubDate>Fri, 22 Nov 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Patricia Paskov, Lukas Berglund, Everett Smith, Lisa Soder</dc:creator>
    </item>
    <item>
      <title>Exploring the Impact of Quizzes Interleaved with Write-Code Tasks in Elementary-Level Visual Programming</title>
      <link>https://arxiv.org/abs/2411.14275</link>
      <description>arXiv:2411.14275v1 Announce Type: new 
Abstract: We explore the role of quizzes in elementary visual programming domains popularly used for K-8 computing education. Prior work has studied various quiz types, such as fill-in-the-gap write-code questions. However, the overall impact of these quizzes is unclear: studies often show utility in the learning phase when enhanced with quizzes, though limited transfer of utility in the post-learning phase. In this paper, we aim to better understand the impact of different quiz types and whether quizzes focusing on diverse skills (e.g., code debugging and task design) would have higher utility. We design a study with Hour of Code: Maze Challenge by code.org as the base curriculum, interleaved with different quiz types. Specifically, we examine two learning groups: (i) HoC-ACE with diverse quizzes including solution tracing, code debugging, code equivalence, and task design; (ii) HoC-Fill with simple quizzes on solution finding. We conducted a large-scale study with 405 students in grades 6--7. Our results highlight that the curriculum enhanced with richer quizzes led to higher utility during the post-learning phase.</description>
      <guid isPermaLink="false">oai:arXiv.org:2411.14275v1</guid>
      <category>cs.CY</category>
      <pubDate>Fri, 22 Nov 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Ahana Ghosh, Liina Malva, Alkis Gotovos, Danial Hooshyar, Adish Singla</dc:creator>
    </item>
    <item>
      <title>Sustainability concepts for digital research infrastructures developed through ground-level stakeholder empowerment</title>
      <link>https://arxiv.org/abs/2411.14301</link>
      <description>arXiv:2411.14301v1 Announce Type: new 
Abstract: The UK Research and Innovation Digital Research Infrastructure (DRI) needs to operate sustainably in the future, encompassing its use of energy and resources, and embedded computer hardware carbon emissions. Transition concepts towards less unsustainable operations will inform the future design and operations of DRI. A problem remains that, while the skills and knowledge for solving net zero challenges already exist within the UK's DRI community, the mechanisms for sharing them and enabling behavior change are missing. Without adopting community-driven approaches, individual stakeholders may feel isolated and uncertain about how to play their role in the transition. A research programme was funded to give voice to the ground-level stakeholders of the DRI ecosystem for the co-creation of carbon downshift concepts. This article presents the results of the programme, with the goal to inform a fair and just transition from the ground-level, complementing the top-down interventions of energy efficiency policies and renewable energies integration. A workshop-based innovation method was developed for researching stakeholder recommendations and perspectives on the sustainable transition of the UK's DRI. We find that giving a purposeful voice to the stakeholders for shaping their own future sustainable DRI environment can be achieved by a guided, expert-integrated, interactive and problem-focused workshop series. The chosen workshop design is impactful on creating bottom-up agency for climate action by first defining the high-level problems of unsustainability in energy and fossil-fuel consumption, and then connecting them to the ground-level circumstances of DRI stakeholders. This approach to stakeholder management should initiate a sustainable transition that promises to kick-start impactful changes from within communities, adding to high-level efforts from economics, policy, and governance.</description>
      <guid isPermaLink="false">oai:arXiv.org:2411.14301v1</guid>
      <category>cs.CY</category>
      <pubDate>Fri, 22 Nov 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Florian Ahrens, Dawn Geatches, Niall McCarroll, Justin Buck, Alvaro Lorenzo-Lopez, Hossein Keshtkar, Nadine Fayyad, Hamidreza Hassanloo, Danae Manika</dc:creator>
    </item>
    <item>
      <title>Whack-a-Chip: The Futility of Hardware-Centric Export Controls</title>
      <link>https://arxiv.org/abs/2411.14425</link>
      <description>arXiv:2411.14425v1 Announce Type: new 
Abstract: U.S. export controls on semiconductors are widely known to be permeable, with the People's Republic of China (PRC) steadily creating state-of-the-art artificial intelligence (AI) models with exfiltrated chips. This paper presents the first concrete, public evidence of how leading PRC AI labs evade and circumvent U.S. export controls. We examine how Chinese companies, notably Tencent, are not only using chips that are restricted under U.S. export controls but are also finding ways to circumvent these regulations by using software and modeling techniques that maximize less capable hardware. Specifically, we argue that Tencent's ability to power its Hunyuan-Large model with non-export controlled NVIDIA H20s exemplifies broader gains in efficiency in machine learning that have eroded the moat that the United States initially built via its existing export controls. Finally, we examine the implications of this finding for the future of the United States' export control strategy.</description>
      <guid isPermaLink="false">oai:arXiv.org:2411.14425v1</guid>
      <category>cs.CY</category>
      <category>cs.AI</category>
      <pubDate>Fri, 22 Nov 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Ritwik Gupta, Leah Walker, Andrew W. Reddie</dc:creator>
    </item>
    <item>
      <title>When Online Algorithms Influence the Environment: A Dynamical Systems Analysis of the Unintended Consequences</title>
      <link>https://arxiv.org/abs/2411.13883</link>
      <description>arXiv:2411.13883v1 Announce Type: cross 
Abstract: We analyze the effect that online algorithms have on the environment that they are learning. As a motivation, consider recommendation systems that use online algorithms to learn optimal product recommendations based on user and product attributes. It is well known that the sequence of recommendations affects user preferences. However, typical learning algorithms treat the user attributes as static and disregard the impact of their recommendations on user preferences. Our interest is to analyze the effect of this mismatch between the model assumption of a static environment, and the reality of an evolving environment affected by the recommendations. To perform this analysis, we first introduce a model for a generic coupled evolution of the parameters that are being learned, and the environment that is affected by it. We then frame a linear bandit recommendation system (RS) into this generic model where the users are characterized by a state variable that evolves based on the sequence of recommendations. The learning algorithm of the RS does not explicitly account for this evolution and assumes that the users are static. A dynamical system model that captures the coupled evolution of the population state and the learning algorithm is described, and its equilibrium behavior is analyzed. We show that when the recommendation algorithm is able to learn the population preferences in the presence of this mismatch, the algorithm induces similarity in the preferences of the user population. In particular, we present results on how different properties of the recommendation algorithm, namely the user attribute space and the exploration-exploitation tradeoff, effect the population preferences when they are learned by the algorithm. We demonstrate these results using model simulations.</description>
      <guid isPermaLink="false">oai:arXiv.org:2411.13883v1</guid>
      <category>cs.LG</category>
      <category>cs.AI</category>
      <category>cs.CY</category>
      <pubDate>Fri, 22 Nov 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-sa/4.0/</dc:rights>
      <dc:creator>Prabhat Lankireddy, Jayakrishnan Nair, D Manjunath</dc:creator>
    </item>
    <item>
      <title>Sentiment Analysis of Economic Text: A Lexicon-Based Approach</title>
      <link>https://arxiv.org/abs/2411.13958</link>
      <description>arXiv:2411.13958v1 Announce Type: cross 
Abstract: We propose an Economic Lexicon (EL) specifically designed for textual applications in economics. We construct the dictionary with two important characteristics: 1) to have a wide coverage of terms used in documents discussing economic concepts, and 2) to provide a human-annotated sentiment score in the range [-1,1]. We illustrate the use of the EL in the context of a simple sentiment measure and consider several applications in economics. The comparison to other lexicons shows that the EL is superior due to its wider coverage of domain relevant terms and its more accurate categorization of the word sentiment.</description>
      <guid isPermaLink="false">oai:arXiv.org:2411.13958v1</guid>
      <category>cs.CE</category>
      <category>cs.CL</category>
      <category>cs.CY</category>
      <pubDate>Fri, 22 Nov 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <arxiv:DOI>10.1111/ecin.13264</arxiv:DOI>
      <arxiv:journal_reference>Economic Inquiry, 1-19 (2024)</arxiv:journal_reference>
      <dc:creator>Luca Barbaglia, Sergio Consoli, Sebastiano Manzan, Luca Tiozzo Pezzoli, Elisa Tosetti</dc:creator>
    </item>
    <item>
      <title>Public sentiments on the fourth industrial revolution: An unsolicited public opinion poll from Twitter</title>
      <link>https://arxiv.org/abs/2411.14230</link>
      <description>arXiv:2411.14230v1 Announce Type: cross 
Abstract: This article explores public perceptions on the Fourth Industrial Revolution (4IR) through an analysis of social media discourse across six European countries. Using sentiment analysis and machine learning techniques on a dataset of tweets and media articles, we assess how the public reacts to the integration of technologies such as artificial intelligence, robotics, and blockchain into society. The results highlight a significant polarization of opinions, with a shift from neutral to more definitive stances either embracing or resisting technological impacts. Positive sentiments are often associated with technological enhancements in quality of life and economic opportunities, whereas concerns focus on issues of privacy, data security, and ethical implications. This polarization underscores the need for policymakers to engage proactively with the public to address fears and harness the benefits of 4IR technologies. The findings also advocate for digital literacy and public awareness programs to mitigate misinformation and foster an informed public discourse on future technological integration. This study contributes to the ongoing debate on aligning technological advances with societal values and needs, emphasizing the role of informed public opinion in shaping effective policy.</description>
      <guid isPermaLink="false">oai:arXiv.org:2411.14230v1</guid>
      <category>econ.GN</category>
      <category>cs.CY</category>
      <category>cs.SI</category>
      <category>q-fin.EC</category>
      <pubDate>Fri, 22 Nov 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Diletta Abbonato</dc:creator>
    </item>
    <item>
      <title>Confronting Conflicts to Yes: Untangling Wicked Problems with Open Design Systems</title>
      <link>https://arxiv.org/abs/2409.10549</link>
      <description>arXiv:2409.10549v3 Announce Type: replace 
Abstract: Current project development practices often fail to engage stakeholders early and effectively. Decision support is often non-inclusive, single-sided, and lacking in transparency, while complexity goes beyond human's comprehension. Additionally, many approaches focus primarily on technical system aspects, neglecting the integration of stakeholders' individual preferences. This often results in project impasses, leaving stakeholders unable to collaboratively achieve a "yes." There is a need for a purely associative, a-priori design approach that integrates system realities and stakeholder ideals within a joint socio-technical solution space. The state-of-the-art Preferendus, embedded in the proven Open Design Systems (Odesys) methodology, is a neutral tool for transforming complexity into success. Aiming for synthesis, Odesys' robust IMAP optimization method generates a single best-fit design solution. Here, Odesys is applied for a Dutch wind farm stalemate development, balancing multiple stakeholder preferences, wind farm performances, and project constraints. The success of this approach hinges on stakeholder trust and input. This article introduces a structured stakeholder assessment method using choice-based conjunctive analysis (CBCA), facilitating transparent determination of global and local stakeholder weights and preference functions. Modelling 'disputable' exogenous factors as endogenous design parameters, the application demonstrates how one can shift toward a collaborative "yes." For this, it is concluded that a zoomed-out solution space would enable the energy transition to be tackled with multiple options rather than a prescribed one. The Odesys approach fosters decision-making that aligns with the social threefold principles of freedom, equality, and fraternity, guiding projects toward genuine democratic outcomes rather than selecting from curated options.</description>
      <guid isPermaLink="false">oai:arXiv.org:2409.10549v3</guid>
      <category>cs.CY</category>
      <category>math.OC</category>
      <pubDate>Fri, 22 Nov 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>L. G. Teuber, A. R. M. Wolfert</dc:creator>
    </item>
    <item>
      <title>Comprehensive Monitoring of Air Pollution Hotspots Using Sparse Sensor Networks</title>
      <link>https://arxiv.org/abs/2410.04309</link>
      <description>arXiv:2410.04309v2 Announce Type: replace 
Abstract: Urban air pollution hotspots pose significant health risks, yet their detection and analysis remain limited by the sparsity of public sensor networks. This paper addresses this challenge by combining predictive modeling and mechanistic approaches to comprehensively monitor pollution hotspots. We enhanced New Delhi's existing sensor network with 28 low-cost sensors, collecting PM2.5 data over 30 months from May 1, 2018, to Nov 1, 2020. Applying established definitions of hotspots to this data, we found the existence of additional 189 hidden hotspots apart from confirming 660 hotspots detected by the public network. Using predictive techniques like Space-Time Kriging, we identified hidden hotspots with 95% precision and 88% recall with 50% sensor failure rate, and with 98% precision and 95% recall with 50% missing sensors. The projected results of our predictive models were further compiled into policy recommendations for public authorities. Additionally, we developed a Gaussian Plume Dispersion Model to understand the mechanistic underpinnings of hotspot formation, incorporating an emissions inventory derived from local sources. Our mechanistic model is able to explain 65% of observed transient hotspots. Our findings underscore the importance of integrating data-driven predictive models with physics-based mechanistic models for scalable and robust air pollution management in resource-constrained settings.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.04309v2</guid>
      <category>cs.CY</category>
      <category>cs.LG</category>
      <pubDate>Fri, 22 Nov 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Ankit Bhardwaj, Ananth Balashankar, Shiva Iyer, Nita Soans, Anant Sudarshan, Rohini Pande, Lakshminarayanan Subramanian</dc:creator>
    </item>
    <item>
      <title>Transforming Teacher Education in Developing Countries: The Role of Generative AI in Bridging Theory and Practice</title>
      <link>https://arxiv.org/abs/2411.10718</link>
      <description>arXiv:2411.10718v3 Announce Type: replace 
Abstract: This study examines the transformative potential of Generative AI (GenAI) in teacher education within developing countries, focusing on Ghana, where challenges such as limited pedagogical modeling, performance-based assessments, and practitioner-expertise gaps hinder progress. GenAI has the capacity to address these issues by supporting content knowledge acquisition, a role that currently dominates teacher education programs. By taking on this foundational role, GenAI allows teacher educators to redirect their focus to other critical areas, including pedagogical modeling, authentic assessments, and fostering digital literacy and critical thinking. These roles are interconnected, creating a ripple effect where pre-service teachers (PSTs) are better equipped to enhance K-12 learning outcomes and align education with workforce needs. The study emphasizes that GenAI's roles are multifaceted, directly addressing resistance to change, improving resource accessibility, and supporting teacher professional development. However, it cautions against misuse, which could undermine critical thinking and creativity, essential skills nurtured through traditional teaching methods. To ensure responsible and effective integration, the study advocates a scaffolding approach to GenAI literacy. This includes educating PSTs on its supportive role, training them in ethical use and prompt engineering, and equipping them to critically assess AI-generated content for biases and validity. The study concludes by recommending empirical research to explore these roles further and develop practical steps for integrating GenAI into teacher education systems responsibly and effectively.</description>
      <guid isPermaLink="false">oai:arXiv.org:2411.10718v3</guid>
      <category>cs.CY</category>
      <pubDate>Fri, 22 Nov 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Matthew Nyaaba</dc:creator>
    </item>
    <item>
      <title>Chat Bankman-Fried: an Exploration of LLM Alignment in Finance</title>
      <link>https://arxiv.org/abs/2411.11853</link>
      <description>arXiv:2411.11853v2 Announce Type: replace 
Abstract: Advancements in large language models (LLMs) have renewed concerns about AI alignment - the consistency between human and AI goals and values. As various jurisdictions enact legislation on AI safety, the concept of alignment must be defined and measured across different domains. This paper proposes an experimental framework to assess whether LLMs adhere to ethical and legal standards in the relatively unexplored context of finance. We prompt nine LLMs to impersonate the CEO of a financial institution and test their willingness to misuse customer assets to repay outstanding corporate debt. Beginning with a baseline configuration, we adjust preferences, incentives and constraints, analyzing the impact of each adjustment with logistic regression. Our findings reveal significant heterogeneity in the baseline propensity for unethical behavior of LLMs. Factors such as risk aversion, profit expectations, and regulatory environment consistently influence misalignment in ways predicted by economic theory, although the magnitude of these effects varies across LLMs. This paper highlights both the benefits and limitations of simulation-based, ex post safety testing. While it can inform financial authorities and institutions aiming to ensure LLM safety, there is a clear trade-off between generality and cost.</description>
      <guid isPermaLink="false">oai:arXiv.org:2411.11853v2</guid>
      <category>cs.CY</category>
      <category>cs.AI</category>
      <category>cs.CL</category>
      <category>q-fin.GN</category>
      <pubDate>Fri, 22 Nov 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <dc:creator>Claudia Biancotti, Carolina Camassa, Andrea Coletta, Oliver Giudice, Aldo Glielmo</dc:creator>
    </item>
    <item>
      <title>ChaosBench: A Multi-Channel, Physics-Based Benchmark for Subseasonal-to-Seasonal Climate Prediction</title>
      <link>https://arxiv.org/abs/2402.00712</link>
      <description>arXiv:2402.00712v5 Announce Type: replace-cross 
Abstract: Accurate prediction of climate in the subseasonal-to-seasonal scale is crucial for disaster preparedness and robust decision making amidst climate change. Yet, forecasting beyond the weather timescale is challenging because it deals with problems other than initial condition, including boundary interaction, butterfly effect, and our inherent lack of physical understanding. At present, existing benchmarks tend to have shorter forecasting range of up-to 15 days, do not include a wide range of operational baselines, and lack physics-based constraints for explainability. Thus, we propose ChaosBench, a challenging benchmark to extend the predictability range of data-driven weather emulators to S2S timescale. First, ChaosBench is comprised of variables beyond the typical surface-atmospheric ERA5 to also include ocean, ice, and land reanalysis products that span over 45 years to allow for full Earth system emulation that respects boundary conditions. We also propose physics-based, in addition to deterministic and probabilistic metrics, to ensure a physically-consistent ensemble that accounts for butterfly effect. Furthermore, we evaluate on a diverse set of physics-based forecasts from four national weather agencies as baselines to our data-driven counterpart such as ViT/ClimaX, PanguWeather, GraphCast, and FourCastNetV2. Overall, we find methods originally developed for weather-scale applications fail on S2S task: their performance simply collapse to an unskilled climatology. Nonetheless, we outline and demonstrate several strategies that can extend the predictability range of existing weather emulators, including the use of ensembles, robust control of error propagation, and the use of physics-informed models. Our benchmark, datasets, and instructions are available at https://leap-stc.github.io/ChaosBench.</description>
      <guid isPermaLink="false">oai:arXiv.org:2402.00712v5</guid>
      <category>cs.CV</category>
      <category>cs.CY</category>
      <pubDate>Fri, 22 Nov 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Juan Nathaniel, Yongquan Qu, Tung Nguyen, Sungduk Yu, Julius Busecke, Aditya Grover, Pierre Gentine</dc:creator>
    </item>
    <item>
      <title>Investigating Human Values in Online Communities</title>
      <link>https://arxiv.org/abs/2402.14177</link>
      <description>arXiv:2402.14177v3 Announce Type: replace-cross 
Abstract: Studying human values is instrumental for cross-cultural research, enabling a better understanding of preferences and behaviour of society at large and communities therein. To study the dynamics of communities online, we propose a method to computationally analyse values present on Reddit. Our method allows analysis at scale, complementing survey based approaches. We train a value relevance and a value polarity classifier, which we thoroughly evaluate using in-domain and out-of-domain human annotations. Using these, we automatically annotate over six million posts across 12k subreddits with Schwartz values. Our analysis unveils both previously recorded and novel insights into the values prevalent within various online communities. For instance, we discover a very negative stance towards conformity in the Vegan and AbolishTheMonarchy subreddits. Additionally, our study of geographically specific subreddits highlights the correlation between traditional values and conservative U.S. states. Through our work, we demonstrate how our dataset and method can be used as a complementary tool for qualitative study of online communication.</description>
      <guid isPermaLink="false">oai:arXiv.org:2402.14177v3</guid>
      <category>cs.SI</category>
      <category>cs.CY</category>
      <pubDate>Fri, 22 Nov 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Nadav Borenstein, Arnav Arora, Lucie-Aim\'ee Kaffee, Isabelle Augenstein</dc:creator>
    </item>
    <item>
      <title>Design2Code: Benchmarking Multimodal Code Generation for Automated Front-End Engineering</title>
      <link>https://arxiv.org/abs/2403.03163</link>
      <description>arXiv:2403.03163v2 Announce Type: replace-cross 
Abstract: Generative AI has made rapid advancements in recent years, achieving unprecedented capabilities in multimodal understanding and code generation. This can enable a new paradigm of front-end development in which multimodal large language models (MLLMs) directly convert visual designs into code implementations. In this work, we construct Design2Code - the first real-world benchmark for this task. Specifically, we manually curate 484 diverse real-world webpages as test cases and develop a set of automatic evaluation metrics to assess how well current multimodal LLMs can generate the code implementations that directly render into the given reference webpages, given the screenshots as input. We also complement automatic metrics with comprehensive human evaluations to validate the performance ranking. To rigorously benchmark MLLMs, we test various multimodal prompting methods on frontier models such as GPT-4o, GPT-4V, Gemini, and Claude. Our fine-grained break-down metrics indicate that models mostly lag in recalling visual elements from the input webpages and generating correct layout designs.</description>
      <guid isPermaLink="false">oai:arXiv.org:2403.03163v2</guid>
      <category>cs.CL</category>
      <category>cs.CV</category>
      <category>cs.CY</category>
      <pubDate>Fri, 22 Nov 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Chenglei Si, Yanzhe Zhang, Ryan Li, Zhengyuan Yang, Ruibo Liu, Diyi Yang</dc:creator>
    </item>
    <item>
      <title>The Peripatetic Hater: Predicting Movement Among Hate Subreddits</title>
      <link>https://arxiv.org/abs/2405.17410</link>
      <description>arXiv:2405.17410v2 Announce Type: replace-cross 
Abstract: Many online hate groups exist to disparage others based on race, gender identity, sex, or other characteristics. The accessibility of these communities allows users to join multiple types of hate groups (e.g., a racist community and a misogynistic community), raising the question of whether users who join additional types of hate communities could be further radicalized compared to users who stay in one type of hate group. However, little is known about the dynamics of joining multiple types of hate groups, nor the effect of these groups on peripatetic users. We develop a new method to classify hate subreddits and the identities they disparage, then apply it to understand better how users come to join different types of hate subreddits. The hate classification technique utilizes human-validated deep learning models to extract the protected identities attacked, if any, across 168 subreddits. We find distinct clusters of subreddits targeting various identities, such as racist subreddits, xenophobic subreddits, and transphobic subreddits. We show that when users become active in their first hate subreddit, they have a high likelihood of becoming active in additional hate subreddits of a different category. We also find that users who join additional hate subreddits, especially those of a different category develop a wider hate group lexicon. These results then lead us to train a deep learning model that, as we demonstrate, usefully predicts the hate categories in which users will become active based on post text replied to and written. The accuracy of this model may be partly driven by peripatetic users often using the language of hate subreddits they eventually join. Overall, these results highlight the unique risks associated with hate communities on a social media platform, as discussion of alternative targets of hate may lead users to target more protected identities.</description>
      <guid isPermaLink="false">oai:arXiv.org:2405.17410v2</guid>
      <category>cs.SI</category>
      <category>cs.CY</category>
      <category>cs.HC</category>
      <pubDate>Fri, 22 Nov 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Daniel Hickey, Daniel M. T. Fessler, Kristina Lerman, Keith Burghardt</dc:creator>
    </item>
    <item>
      <title>A Sociotechnical Lens for Evaluating Computer Vision Models: A Case Study on Detecting and Reasoning about Gender and Emotion</title>
      <link>https://arxiv.org/abs/2406.08222</link>
      <description>arXiv:2406.08222v2 Announce Type: replace-cross 
Abstract: In the evolving landscape of computer vision (CV) technologies, the automatic detection and interpretation of gender and emotion in images is a critical area of study. This paper investigates social biases in CV models, emphasizing the limitations of traditional evaluation metrics such as precision, recall, and accuracy. These metrics often fall short in capturing the complexities of gender and emotion, which are fluid and culturally nuanced constructs. Our study proposes a sociotechnical framework for evaluating CV models, incorporating both technical performance measures and considerations of social fairness. Using a dataset of 5,570 images related to vaccination and climate change, we empirically compared the performance of various CV models, including traditional models like DeepFace and FER, and generative models like GPT-4 Vision. Our analysis involved manually validating the gender and emotional expressions in a subset of images to serve as benchmarks. Our findings reveal that while GPT-4 Vision outperforms other models in technical accuracy for gender classification, it exhibits discriminatory biases, particularly in response to transgender and non-binary personas. Furthermore, the model's emotion detection skew heavily towards positive emotions, with a notable bias towards associating female images with happiness, especially when prompted by male personas. These findings underscore the necessity of developing more comprehensive evaluation criteria that address both validity and discriminatory biases in CV models. Our proposed framework provides guidelines for researchers to critically assess CV tools, ensuring their application in communication research is both ethical and effective. The significant contribution of this study lies in its emphasis on a sociotechnical approach, advocating for CV technologies that support social good and mitigate biases rather than perpetuate them.</description>
      <guid isPermaLink="false">oai:arXiv.org:2406.08222v2</guid>
      <category>cs.CV</category>
      <category>cs.AI</category>
      <category>cs.CY</category>
      <category>cs.HC</category>
      <pubDate>Fri, 22 Nov 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Sha Luo, Sang Jung Kim, Zening Duan, Kaiping Chen</dc:creator>
    </item>
    <item>
      <title>The Digital Transformation in Health: How AI Can Improve the Performance of Health Systems</title>
      <link>https://arxiv.org/abs/2409.16098</link>
      <description>arXiv:2409.16098v2 Announce Type: replace-cross 
Abstract: Mobile health has the potential to revolutionize health care delivery and patient engagement. In this work, we discuss how integrating Artificial Intelligence into digital health applications-focused on supply chain, patient management, and capacity building, among other use cases-can improve the health system and public health performance. We present an Artificial Intelligence and Reinforcement Learning platform that allows the delivery of adaptive interventions whose impact can be optimized through experimentation and real-time monitoring. The system can integrate multiple data sources and digital health applications. The flexibility of this platform to connect to various mobile health applications and digital devices and send personalized recommendations based on past data and predictions can significantly improve the impact of digital tools on health system outcomes. The potential for resource-poor settings, where the impact of this approach on health outcomes could be more decisive, is discussed specifically. This framework is, however, similarly applicable to improving efficiency in health systems where scarcity is not an issue.</description>
      <guid isPermaLink="false">oai:arXiv.org:2409.16098v2</guid>
      <category>cs.LG</category>
      <category>cs.AI</category>
      <category>cs.CY</category>
      <category>cs.HC</category>
      <pubDate>Fri, 22 Nov 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <arxiv:DOI>10.1080/23288604.2024.2387138</arxiv:DOI>
      <arxiv:journal_reference>Health Systems &amp; Reform, 10(2), 2024</arxiv:journal_reference>
      <dc:creator>\'Africa Peri\'a\~nez, Ana Fern\'andez del R\'io, Ivan Nazarov, Enric Jan\'e, Moiz Hassan, Aditya Rastogi, Dexian Tang</dc:creator>
    </item>
    <item>
      <title>Systematic Mapping Study on Requirements Engineering for Regulatory Compliance of Software Systems</title>
      <link>https://arxiv.org/abs/2411.01940</link>
      <description>arXiv:2411.01940v2 Announce Type: replace-cross 
Abstract: Context: As the diversity and complexity of regulations affecting Software-Intensive Products and Services (SIPS) is increasing, software engineers need to address the growing regulatory scrutiny. As with any other non-negotiable requirements, SIPS compliance should be addressed early in SIPS engineering - i.e., during requirements engineering (RE). Objectives: In the conditions of the expanding regulatory landscape, existing research offers scattered insights into regulatory compliance of SIPS. This study addresses the pressing need for a structured overview of the state of the art in software RE and its contribution to regulatory compliance of SIPS. Method: We conducted a systematic mapping study to provide an overview of the current state of research regarding challenges, principles and practices for regulatory compliance of SIPS related to RE. We focused on the role of RE and its contribution to other SIPS lifecycle phases. We retrieved 6914 studies published from 2017 until 2023 from four academic databases, which we filtered down to 280 relevant primary studies. Results: We identified and categorized the RE-related challenges in regulatory compliance of SIPS and their potential connection to six types of principles and practices. We found that about 13.6% of the primary studies considered the involvement of both software engineers and legal experts. About 20.7% of primary studies considered RE in connection to other process areas. Most primary studies focused on a few popular regulation fields and application domains. Our results suggest that there can be differences in terms of challenges and involvement of stakeholders across different fields of regulation. Conclusion: Our findings highlight the need for an in-depth investigation of stakeholders' roles, relationships between process areas, and specific challenges for distinct regulatory fields to guide research and practice.</description>
      <guid isPermaLink="false">oai:arXiv.org:2411.01940v2</guid>
      <category>cs.SE</category>
      <category>cs.CY</category>
      <pubDate>Fri, 22 Nov 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Oleksandr Kosenkov, Parisa Elahidoost, Tony Gorschek, Jannik Fischbach, Daniel Mendez, Michael Unterkalmsteiner, Davide Fucci, Rahul Mohanani</dc:creator>
    </item>
  </channel>
</rss>
