<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>math.IT updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/math.IT</link>
    <description>math.IT updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/math.IT" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Wed, 14 Jan 2026 02:37:14 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Tue, 13 Jan 2026 00:00:00 -0500</pubDate>
    <skipDays>
      <day>Saturday</day>
      <day>Sunday</day>
    </skipDays>
    <item>
      <title>Context Video Semantic Transmission with Variable Length and Rate Coding over MIMO Channels</title>
      <link>https://arxiv.org/abs/2601.06059</link>
      <description>arXiv:2601.06059v1 Announce Type: new 
Abstract: The evolution of semantic communications has profoundly impacted wireless video transmission, whose applications dominate driver of modern bandwidth consumption. However, most existing schemes are predominantly optimized for simple additive white Gaussian noise or Rayleigh fading channels, neglecting the ubiquitous multiple-input multiple-output (MIMO) environments that critically hinder practical deployment. To bridge this gap, we propose the context video semantic transmission (CVST) framework under MIMO channels. Building upon an efficient contextual video transmission backbone, CVST effectively learns a context-channel correlation map to explicitly formulate the relationships between feature groups and MIMO subchannels. Leveraging these channel-aware features, we design a multi-reference entropy coding mechanism, enabling channel state-aware variable length coding. Furthermore, CVST incorporates a checkerboard-based feature modulation strategy to achieve multiple rate points within a single trained model, thereby enhancing deployment flexibility. These innovations constitute our multi-reference variable length and rate coding (MR-VLRC) scheme. By integrating contextual transmission with MR-VLRC, CVST demonstrates substantial performance gains over various standardized separated coding methods and recent wireless video semantic communication approaches. The code is available at https://github.com/xie233333/CVST.</description>
      <guid isPermaLink="false">oai:arXiv.org:2601.06059v1</guid>
      <category>cs.IT</category>
      <category>cs.AI</category>
      <category>math.IT</category>
      <pubDate>Tue, 13 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Bingyan Xie, Yongpeng Wu, Wenjun Zhang, Derrick Wing Kwan Ng, Merouane Debbah</dc:creator>
    </item>
    <item>
      <title>Jamming Detection in Cell-Free MIMO with Dynamic Graphs</title>
      <link>https://arxiv.org/abs/2601.06075</link>
      <description>arXiv:2601.06075v1 Announce Type: new 
Abstract: Jamming attacks pose a critical threat to wireless networks, particularly in cell-free massive MIMO systems, where distributed access points and user equipment (UE) create complex, time-varying topologies. This paper proposes a novel jamming detection framework leveraging dynamic graphs and graph convolutional neural networks (GCN) to address this challenge. By modeling the network as a dynamic graph, we capture evolving communication links and detect jamming attacks as anomalies in the graph evolution. A GCN-Transformer-based model, trained with supervised learning, learns graph embeddings to identify malicious interference. Performance evaluation in simulated scenarios with moving UEs, varying jamming conditions and channel fadings, demonstrates the method's effectiveness, which is assessed through accuracy and F1 score metrics, achieving promising results for effective jamming detection.</description>
      <guid isPermaLink="false">oai:arXiv.org:2601.06075v1</guid>
      <category>cs.IT</category>
      <category>cs.AI</category>
      <category>math.IT</category>
      <pubDate>Tue, 13 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <arxiv:DOI>10.1109/PIMRC62392.2025.11275123</arxiv:DOI>
      <dc:creator>Ali Hossary, Laura Crosara, Stefano Tomasin</dc:creator>
    </item>
    <item>
      <title>One if by Land, Two if by Sea, Three if by Four Seas, and More to Come -- Values of Perception, Prediction, Communication, and Common Sense in Decision Making</title>
      <link>https://arxiv.org/abs/2601.06077</link>
      <description>arXiv:2601.06077v1 Announce Type: new 
Abstract: This work aims to rigorously define the values of perception, prediction, communication, and common sense in decision making. The defined quantities are decision-theoretic, but have information-theoretic analogues, e.g., they share some simple but key mathematical properties with Shannon entropy and mutual information, and can reduce to these quantities in particular settings. One interesting observation is that, the value of perception without prediction can be negative, while the value of perception together with prediction and the value of prediction alone are always nonnegative. The defined quantities suggest answers to practical questions arising in the design of autonomous decision-making systems. Example questions include: Do we need to observe and predict the behavior of a particular agent? How important is it? What is the best order to observe and predict the agents? The defined quantities may also provide insights to cognitive science and neural science, toward the understanding of how natural decision makers make use of information gained from different sources and operations.</description>
      <guid isPermaLink="false">oai:arXiv.org:2601.06077v1</guid>
      <category>cs.IT</category>
      <category>cs.AI</category>
      <category>cs.LG</category>
      <category>math.IT</category>
      <category>math.OC</category>
      <pubDate>Tue, 13 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Aolin Xu</dc:creator>
    </item>
    <item>
      <title>Deep Q-Network Based Resilient Drone Communication:Neutralizing First-Order Markov Jammers</title>
      <link>https://arxiv.org/abs/2601.06095</link>
      <description>arXiv:2601.06095v1 Announce Type: new 
Abstract: Deep Reinforcement Learning based solution for jamming communications using Frequency Hopping Spread Spectrum technology in a 16 channel radio environment is presented. Deep Q Network based transmitter continuously selects the next frequency hopping channel while facing first order reactive jamming, which uses observed transition statistics to predict and interrupt transmissions. Through self training, the proposed agent learns a uniform random frequency hopping policy that effectively neutralizes the predictive advantage of the jamming. In the presence of Rayleigh fading and additive noise, the impact of forward error correction Bose Chaudhuri Hocquenghem type codes is systematically evaluated, demonstrating that even moderate redundancy significantly reduces packet loss. Extensive visualization of the learning dynamics, channel utilization distribution, epsilon greedy decay, cumulative reward, BER and SNR evolution, and detailed packet loss tables confirms convergence to a near optimal jamming strategy. The results provide a practical framework for autonomous resilient communications in modern electronic warfare scenarios.</description>
      <guid isPermaLink="false">oai:arXiv.org:2601.06095v1</guid>
      <category>cs.IT</category>
      <category>cs.AI</category>
      <category>math.IT</category>
      <pubDate>Tue, 13 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Andrii Grekhov, Volodymyr Kharchenko, Vasyl Kondratiuk</dc:creator>
    </item>
    <item>
      <title>Optimal Beamforming for Uplink Covert Communication in MIMO GEO Satellite-Terrestrial Systems</title>
      <link>https://arxiv.org/abs/2601.06110</link>
      <description>arXiv:2601.06110v1 Announce Type: new 
Abstract: This paper investigates the uplink covert communication in a multiple-input multiple-output (MIMO) satellite-terrestrial system consisting of an Earth station transmitter Alice, a geosynchronous Earth orbit (GEO) satellite receiver Bob, and multiple GEO satellite wardens around Bob, where each node in the system is equipped with an array of directional antennas. Based on beamforming and the default antenna orientation setting, we first propose a scheme for covert Alice-Bob uplink transmission. Under the perfect channel estimation scenario, we provide theoretical modeling for the system performance in terms of detection error probability (DEP), transmission outage probability (TOP) and covert rate (CR), and then explore the optimal beamforming (OB) design as well as the joint optimal beamforming and antenna orientation (JO-BA) design for CR maximization. We then extend our study to the imperfect channel estimation scenario, and conduct related performance modeling and OB/JO-BA designs for CR maximization. We also apply the techniques of semidefinite relaxation, alternating optimization, Rodrigues' rotation formula and 1-D search algorithm to develop efficient algorithms to solve the above optimization problems. Finally, extensive numerical results are presented to verify our theoretical results and to illustrate the efficiency of beamforming and antenna orientation design for supporting the uplink covert communication in MIMO GEO satellite-terrestrial systems.</description>
      <guid isPermaLink="false">oai:arXiv.org:2601.06110v1</guid>
      <category>cs.IT</category>
      <category>math.IT</category>
      <pubDate>Tue, 13 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Zewei Guo, Ranran Sun, Yulong Shen, Xiaohong Jiang</dc:creator>
    </item>
    <item>
      <title>Range-Coder with fast Adaptation and Table-Based Decoding</title>
      <link>https://arxiv.org/abs/2601.06120</link>
      <description>arXiv:2601.06120v1 Announce Type: new 
Abstract: The transmission or storage of signals typically involves data compression. The final processing step in compression systems is generally an entropy coding stage, which converts symbols into a bit stream based on their probability distribution. A distinct class of entropy coding methods operates not by mapping input symbols to discrete codewords but by operating on intervals or ranges. This approach enables a more accurate approximation of the source entropy, particularly for sources with highly skewed or varying symbol distributions. Representative techniques in this category include traditional arithmetic coding, range coding, and methods based on asymmetric numeral systems (ANS). The complexity of these methods depends mainly on three processing steps: the core routines of encoding and decoding doing the calculations, the interval-based determination of the correct symbol at decoder, and the efforts of keeping updated with respect to the varying symbol distribution.
  The interval-based symbol determination at decoder typically demands for a searching procedure. In previous literature, it could be shown that the search can be replaced by a table-based approach with only O(1)-complexity but having the side-effect that the adaptation of the symbols statistic becomes infeasible because of the high time-consumption of adapting the table.
  We propose an adaptation process using a ring-buffer technique enabling the adaptive table-based decoding procedure as well as the replacement of a division by a bit-shift operation at encoder and decoder core routines. This accelerates the coding process significantly. In static (non-adaptive) mode, the coding time can be reduced by about 40 percent. In adaptive mode, the proposed technique is faster than alternative approaches for alphabets from about 12 to 64 different symbol when comparing the overall encoder+decoder time.</description>
      <guid isPermaLink="false">oai:arXiv.org:2601.06120v1</guid>
      <category>cs.IT</category>
      <category>math.IT</category>
      <pubDate>Tue, 13 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Tilo Strutz, Roman Rischke</dc:creator>
    </item>
    <item>
      <title>Extended Target Adaptive Beamforming for ISAC:A Perspective of Predictive Error Ellipse</title>
      <link>https://arxiv.org/abs/2601.06125</link>
      <description>arXiv:2601.06125v1 Announce Type: new 
Abstract: Utilizing communication signals to extract motion parameters has emerged as a key direction in Vehicle-to- Everything (V2X) networks. Accurately modeling the relationship between communication signals and sensing performance is critical for the advancement of such systems. Unlike prior work that relies primarily on qualitative analysis, this paper derives the Cram\'er-Rao Bound (CRB) for radar parameter estimation in the context of Orthogonal Frequency Division Multiplexing (OFDM) waveforms and Uniform Planar Array (UPA) configurations. Recognizing that vehicles may act as extended targets, we propose two New Radio (NR)-V2X-compatible beamforming schemes tailored to different phases of the communication process. During the initial beam establishment phase, we develop a beamforming approach based on the union of predictive error ellipses, which enhances scatterer localization through temporally assisted beam training. In the beam adjustment phase, we introduce an adaptive narrowest-beam strategy that leverages the positions of scatterers and the communication receiver (CR), enabling effective tracking with reduced complexity. The beam design problem is addressed using the minimum enclosing ellipse algorithm and tailored antenna control methods. Simulation results validate the proposed approach, showing up to a 32.4% improvement in achievable rate with a 32*32 transmit antenna array and a 5.2% gain with an 8*8 array, compared to conventional beam sweeping under identical SNR conditions.</description>
      <guid isPermaLink="false">oai:arXiv.org:2601.06125v1</guid>
      <category>cs.IT</category>
      <category>math.IT</category>
      <pubDate>Tue, 13 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Shengcai Zhou, Luping Xiang, Yi Wang, Kun Yang, Kai Kit Wong, Chan-Byoung Chae</dc:creator>
    </item>
    <item>
      <title>Channel Knowledge Map Construction via Guided Flow Matching</title>
      <link>https://arxiv.org/abs/2601.06156</link>
      <description>arXiv:2601.06156v1 Announce Type: new 
Abstract: The efficient construction of accurate channel knowledge maps (CKMs) is crucial for unleashing the full potential of environment-aware wireless networks, yet it remains a difficult ill-posed problem due to the sparsity of available location-specific channel knowledge data. Although diffusion-based methods such as denoising diffusion probabilistic models (DDPMs) have been exploited for CKM construction, they rely on iterative stochastic sampling, rendering them too slow for real-time wireless applications. To bridge the gap between high fidelity and efficient CKM construction, this letter introduces a novel framework based on linear transport guided flow matching (LT-GFM). Deviating from the noise-removal paradigm of diffusion models, our approach models the CKM generation process as a deterministic ordinary differential equation (ODE) that follows linear optimal transport paths, thereby drastically reducing the number of required inference steps. We propose a unified architecture that is applicable to not only the conventional channel gain map (CGM) construction, but also the more challenging spatial correlation map (SCM) construction. To achieve physics-informed CKM constructions, we integrate environmental semantics (e.g., building masks) for edge recovery and enforce Hermitian symmetry for property of the SCM. Simulation results verify that LT-GFM achieves superior distributional fidelity with significantly lower Fr\'echet Inception Distance (FID) and accelerates inference speed by a factor of 25 compared to DDPMs.</description>
      <guid isPermaLink="false">oai:arXiv.org:2601.06156v1</guid>
      <category>cs.IT</category>
      <category>cs.AI</category>
      <category>math.IT</category>
      <pubDate>Tue, 13 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Ziyu Huang, Yong Zeng, Shen Fu, Xiaoli Xu, Hongyang Du</dc:creator>
    </item>
    <item>
      <title>Large Multimodal Model-Aided Scheduling for 6G Autonomous Communications</title>
      <link>https://arxiv.org/abs/2601.06211</link>
      <description>arXiv:2601.06211v1 Announce Type: new 
Abstract: Recently, large language models (LLMs) have gained significant attention for their ability to generate fast and accurate answer to the given query. These models have evolved into large multimodal models (LMMs), which can interpret and analyze multimodal inputs such as images and text. With the exponential growth of AI functionalities in autonomous devices, the central unit (CU), a digital processing unit performing AI inference, needs to handle LMMs to effectively control these devices. To ensure seamless command delivery to devices, the CU must perform the scheduling, which involves resource block (RB) allocation for data transmission and modulation and coding scheme (MCS) index selection based on the channel conditions. This task is challenging in many practical environments in 6G, where even small user movement can cause abrupt channel changes. In this paper, we propose a novel LMM-based scheduling technique to address this challenge. Our key idea is to leverage LMM to predict future channel parameters (e.g., distance, angles, and path gain) by analyzing the visual sensing information as well as pilot signals. By exploiting LMMs to predict the presence of reliable path and geometric information of users from the visual sensing information, and then combining these with past channel states from pilot signals, we can accurately predict future channel parameters. Using these predictions, we can preemptively make channel-aware scheduling decisions. From the numerical evaluations, we show that the proposed technique achieves more than 30% throughput gain over the conventional scheduling techniques.</description>
      <guid isPermaLink="false">oai:arXiv.org:2601.06211v1</guid>
      <category>cs.IT</category>
      <category>math.IT</category>
      <pubDate>Tue, 13 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <arxiv:DOI>10.1109/TCCN.2025.3633741</arxiv:DOI>
      <arxiv:journal_reference>IEEE Transactions on Cognitive Communications and Networking, vol. 12, pp. 3732-3747, 2026</arxiv:journal_reference>
      <dc:creator>Sunwoo Kim, Byonghyo Shim</dc:creator>
    </item>
    <item>
      <title>Robust and Secure Blockage-Aware Pinching Antenna-assisted Wireless Communication</title>
      <link>https://arxiv.org/abs/2601.06430</link>
      <description>arXiv:2601.06430v1 Announce Type: new 
Abstract: In this work, we investigate a blockage-aware pinching antenna (PA) system designed for secure and robust wireless communication. The considered system comprises a base station equipped with multiple waveguides, each hosting multiple PAs, and serves multiple single-antenna legitimate users in the presence of multi-antenna eavesdroppers under imperfect channel state information (CSI). To safeguard confidential transmissions, artificial noise (AN) is deliberately injected to degrade the eavesdropping channels. Recognizing that conventional linear CSI-error bounds become overly conservative for spatially distributed PA architectures, we develop new geometry-aware uncertainty sets that jointly characterize eavesdroppers position and array-orientation errors. Building upon these sets, we formulate a robust joint optimization problem that determines per-waveguide beamforming and AN covariance, individual PA power-ratio allocation, and PA positions to maximize the system sum rate subject to secrecy constraints. The highly non-convex design problem is efficiently addressed via a low computational complexity iterative algorithm that capitalizes on block coordinate descent, penalty-based methods, majorization-minimization, the S-procedure, and Lipschitz-based surrogate functions. Simulation results demonstrate that sum rates for the proposed algorithm outperforms conventional fixed antenna systems by 4.7 dB, offering substantially improved rate and secrecy performance. In particular, (i) adaptive PA positioning preserves LoS to legitimate users while effectively exploiting waveguide geometry to disrupt eavesdropper channels, and (ii) neglecting blockage effects in the PA system significantly impacts the system design, leading to performance degradation and inadequate secrecy guarantees.</description>
      <guid isPermaLink="false">oai:arXiv.org:2601.06430v1</guid>
      <category>cs.IT</category>
      <category>eess.SP</category>
      <category>math.IT</category>
      <pubDate>Tue, 13 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Ruotong Zhao, Shaokang Hu, Deepak Mishra, Derrick Wing Kwan Ng</dc:creator>
    </item>
    <item>
      <title>Error correction methods based on two-faced processes</title>
      <link>https://arxiv.org/abs/2601.06447</link>
      <description>arXiv:2601.06447v1 Announce Type: new 
Abstract: A new approach to the problem of error correction in communication channels is proposed, in which the input sequence is transformed in such a way that the interdependence of symbols is significantly increased. Then, after the sequence is transmitted over the channel, this property is used for error correction so that the remaining error rate is significantly reduced. The complexity of encoding and decoding is linear.</description>
      <guid isPermaLink="false">oai:arXiv.org:2601.06447v1</guid>
      <category>cs.IT</category>
      <category>math.IT</category>
      <pubDate>Tue, 13 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Boris Ryabko</dc:creator>
    </item>
    <item>
      <title>Function-Correcting Partition codes</title>
      <link>https://arxiv.org/abs/2601.06450</link>
      <description>arXiv:2601.06450v1 Announce Type: new 
Abstract: We introduce function-correcting partition codes (FCPCs) that are a natural generalization of function-correcting codes (FCCs). A $t$-error function-correcting partition code is an $(\mathcal{P},t)$-encoding defined directly on a partition $\mathcal{P}$ of $\mathbb{F}_q^k$. For a partition $\mathcal{P}=\{P_1,P_2,\ldots,P_E\}$ a systematic mapping $\mathcal{C}_{\mathcal{P}} : \mathbb{F}_q^k \rightarrow \mathbb{F}_q^{k+r}$ is called a \emph{$(\mathcal{P},t)$-encoding} if for all $u\in P_i$ and $v\in P_j$ with $i\neq j$, $d\big(\mathcal{C}_{\mathcal{P}}(u), \mathcal{C}_{\mathcal{P}}(v)\big)\ge 2t+1.$ We show that any $t$-error correcting code for a function $f$, denoted by $(f,t)$-FCC is exactly an FCPC with respect to the domain partition induced by $f$, which makes these codes a natural generalization of FCCs. We use the join of domain partitions to construct a single code that protects multiple functions simultaneously. We define the notion of partition redundancy gain and partition rate gain to measure the bandwidth saved by using a single FCPC for multiple functions instead of constructing separate FCCs for each function. We specialize this to linear functions via coset partition of the intersection of their kernels. Then, we associate a partition graph to any given partition of $\mathbb{F}_q^k$, and show that the existence of a suitable clique in this graph yields a set of representative information vectors that achieves the optimal redundancy. We showed the existence of a full-size clique in the partition graphs of weight partition and support partition. Finally, we introduce the notion of a block-preserving contraction for a partition, which helps reduce the problem of finding optimal redundancy for an FCPC. We observe that FCPCs naturally provide a form of partial privacy, in the sense that only the domain partition of the function needs to be revealed to the transmitter.</description>
      <guid isPermaLink="false">oai:arXiv.org:2601.06450v1</guid>
      <category>cs.IT</category>
      <category>math.IT</category>
      <pubDate>Tue, 13 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Charul Rajput, B. Sundar Rajan, Ragnar Freij-Hollanti, Camilla Hollanti</dc:creator>
    </item>
    <item>
      <title>Algorithms for Computing the Petz-Augustin Capacity</title>
      <link>https://arxiv.org/abs/2601.06492</link>
      <description>arXiv:2601.06492v1 Announce Type: new 
Abstract: We propose the first algorithms with non-asymptotic convergence guarantees for computing the Petz-Augustin capacity, which generalizes the channel capacity and characterizes the optimal error exponent in classical-quantum channel coding. This capacity can be equivalently expressed as the maximization of two generalizations of mutual information: the Petz-R\'{e}nyi information and the Petz-Augustin information. To maximize the Petz-R\'{e}nyi information, we show that it corresponds to a convex H\"{o}lder-smooth optimization problem, and hence the universal fast gradient method of Nesterov (2015), along with its convergence guarantees, readily applies. Regarding the maximization of the Petz-Augustin information, we adopt a two-layered approach: we show that the objective function is smooth relative to the negative Shannon entropy and can be efficiently optimized by entropic mirror descent; each iteration of entropic mirror descent requires computing the Petz-Augustin information, for which we propose a novel fixed-point algorithm and establish its contractivity with respect to the Thompson metric. Notably, this two-layered approach can be viewed as a generalization of the mirror-descent interpretation of the Blahut-Arimoto algorithm due to He et al. (2024).</description>
      <guid isPermaLink="false">oai:arXiv.org:2601.06492v1</guid>
      <category>cs.IT</category>
      <category>math.IT</category>
      <category>math.OC</category>
      <category>quant-ph</category>
      <pubDate>Tue, 13 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Chun-Neng Chu, Wei-Fu Tseng, Yen-Huan Li</dc:creator>
    </item>
    <item>
      <title>On the Number of Subsequences in the Nonbinary Deletion Channel</title>
      <link>https://arxiv.org/abs/2601.06493</link>
      <description>arXiv:2601.06493v1 Announce Type: new 
Abstract: In the deletion channel, an important problem is to determine the number of subsequences derived from a string $U$ of length $n$ when subjected to $t$ deletions. It is well-known that the number of subsequences in the setting exhibits a strong dependence on the number of runs in the string $U$, where a run is defined as a maximal substring of identical characters. In this paper we study the number of subsequences of a non-binary string in this scenario, and propose some improved bounds on the number of subsequences of $r$-run non-binary strings. Specifically, we characterize a family of $r$-run non-binary strings with the maximum number of subsequences under any $t$ deletions, and show that this number can be computed in polynomial time.</description>
      <guid isPermaLink="false">oai:arXiv.org:2601.06493v1</guid>
      <category>cs.IT</category>
      <category>math.CO</category>
      <category>math.IT</category>
      <pubDate>Tue, 13 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Han Li, Xiang Wang, Fang-Wei Fu</dc:creator>
    </item>
    <item>
      <title>Coding for Fading Channels with Imperfect CSI at the Transmitter and Quantized Feedback</title>
      <link>https://arxiv.org/abs/2601.06501</link>
      <description>arXiv:2601.06501v1 Announce Type: new 
Abstract: The classical Schalkwijk-Kailath (SK) scheme for the additive Gaussian noise channel with noiseless feedback is highly efficient since its coding complexity is extremely low and the decoding error doubly exponentially decays as the coding blocklength tends to infinity. However, how to extend the SK scheme to channel models with memory has yet to be solved. In this paper, we first investigate how to design SK-type scheme for the 2-path quasi-static fading channel with noiseless feedback. By viewing the signal of the second path as a relay and adopting an amplify-and-forward (AF) relay strategy, we show that the interference path signal can help to enhance the transmission rate. Besides this, for arbitrary multi-path fading channel with feedback, we also present an SK-type scheme for such a model, which
  transforms the time domain channel into a frequency domain MIMO channel.</description>
      <guid isPermaLink="false">oai:arXiv.org:2601.06501v1</guid>
      <category>cs.IT</category>
      <category>math.IT</category>
      <pubDate>Tue, 13 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Yuhan Yang, Haoheng Yuan, Chao Qi, Fan Cheng, Bin Dai</dc:creator>
    </item>
    <item>
      <title>Some New Results on Sequence Reconstruction Problem for Deletion Channels</title>
      <link>https://arxiv.org/abs/2601.06503</link>
      <description>arXiv:2601.06503v1 Announce Type: new 
Abstract: Levenshtein first introduced the sequence reconstruction problem in $2001$. In the realm of combinatorics, the sequence reconstruction problem is equivalent to determining the value of $N(n,d,t)$, which represents the maximum size of the intersection of two metric balls of radius $t$, given that the distance between their centers is at least $d$ and the sequence length is $n$. In this paper, We present a lower bound on $N(n,3,t)$ for $n\geq 13$ and $t \geq 4$. For $t=4$, we prove that this lower bound is tight. This settles an open question posed by Pham, Goyal, and Kiah, confirming that $N(n,3,4)=20n-166$ for all $n \geq 13$.</description>
      <guid isPermaLink="false">oai:arXiv.org:2601.06503v1</guid>
      <category>cs.IT</category>
      <category>math.IT</category>
      <pubDate>Tue, 13 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Xiang Wang, Weijun Fang, Han Li, Fang-Wei Fu</dc:creator>
    </item>
    <item>
      <title>Visible Light Communication using Led-Based AR Markers for Robot Localization</title>
      <link>https://arxiv.org/abs/2601.06527</link>
      <description>arXiv:2601.06527v1 Announce Type: new 
Abstract: A method of information transmission using visual markers has been widely studied. In this approach, information or identifiers (IDs) are encoded in the black-and-white pattern of each marker. By analyzing the geometric properties of the marker frame - such as its size, distortion, and coordinates - the relative position and orientation between the camera and the marker can be estimated. Furthermore, by associating the positional information of each marker with its corresponding ID, the position of the camera that takes the image picture can be calculated. In the field of mobile robotics, such markers are commonly utilized for robot localization. As mobile robots become more widely used in everyday environments, such visual markers are expected to be utilized across various contexts. In environments where robots collaborate with humans - such as in cell-based manufacturing systems in factories or in domestic settings with partner robots - it is desirable for such markers to be designed in a manner that appears natural and unobtrusive to humans. In this paper, we propose a method for implementing an ArUco marker in the form of illumination. In the proposed method, LEDs are arranged in accordance with the grid pattern of the marker, and the blinking frequency of each LED is determined based on the corresponding black or white cell. As a result, the illumination appears uniformly bright to the human eye, while the camera can capture variations in the blinking frequency. From these differences, the black-and-white pattern can be reconstructed, enabling the identification of the marker's tag information. We develop a prototype system, and conduct experiments which are conducted to evaluate its performance in terms of recognition accuracy under varying distances and viewing angles with respect to the ArUco marker.</description>
      <guid isPermaLink="false">oai:arXiv.org:2601.06527v1</guid>
      <category>cs.IT</category>
      <category>cs.RO</category>
      <category>eess.IV</category>
      <category>math.IT</category>
      <pubDate>Tue, 13 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <arxiv:DOI>10.5121/ijmnct.2025.15602</arxiv:DOI>
      <dc:creator>Wataru Uemura, Shogo Kawasaki</dc:creator>
    </item>
    <item>
      <title>Hard Thresholding Pursuit Algorithms for Least Absolute Deviations Problem</title>
      <link>https://arxiv.org/abs/2601.06558</link>
      <description>arXiv:2601.06558v1 Announce Type: new 
Abstract: Least absolute deviations (LAD) is a statistical optimality criterion widely utilized in scenarios where a minority of measurements are contaminated by outliers of arbitrary magnitudes. In this paper, we delve into the robustness of the variant of adaptive iterative hard thresholding to outliers, known as graded fast hard thresholding pursuit (GFHTP$_1$) algorithm. Unlike the majority of the state-of-the-art algorithms in this field, GFHTP$_1$ does not require prior information about the signal's sparsity. Moreover, its design is parameterless, which not only simplifies the implementation process but also removes the intricacies of parameter optimization. Numerical experiments reveal that the GFHTP$_1$ algorithm consistently outperforms competing algorithms in terms of both robustness and computational efficiency.</description>
      <guid isPermaLink="false">oai:arXiv.org:2601.06558v1</guid>
      <category>cs.IT</category>
      <category>cs.CV</category>
      <category>math.IT</category>
      <pubDate>Tue, 13 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Jiao Xu, Peng Li, Bing Zheng</dc:creator>
    </item>
    <item>
      <title>TCLNet: A Hybrid Transformer-CNN Framework Leveraging Language Models as Lossless Compressors for CSI Feedback</title>
      <link>https://arxiv.org/abs/2601.06588</link>
      <description>arXiv:2601.06588v1 Announce Type: new 
Abstract: In frequency division duplexing (FDD) massive multiple-input multiple-output (MIMO) systems, downlink channel state information (CSI) plays a crucial role in achieving high spectrum and energy efficiency. However, the CSI feedback overhead becomes a major bottleneck as the number of antennas increases. Although existing deep learning-based CSI compression methods have shown great potential, they still face limitations in capturing both local and global features of CSI, thereby limiting achievable compression efficiency. To address these issues, we propose TCLNet, a unified CSI compression framework that integrates a hybrid Transformer-CNN architecture for lossy compression with a hybrid language model (LM) and factorized model (FM) design for lossless compression. The lossy module jointly exploits local features and global context, while the lossless module adaptively switches between context-aware coding and parallel coding to optimize the rate-distortion-complexity (RDC) trade-off. Extensive experiments on both real-world and simulated datasets demonstrate that the proposed TCLNet outperforms existing approaches in terms of reconstruction accuracy and transmission efficiency, achieving up to a 5 dB performance gain across diverse scenarios. Moreover, we show that large language models (LLMs) can be leveraged as zero-shot CSI lossless compressors via carefully designed prompts.</description>
      <guid isPermaLink="false">oai:arXiv.org:2601.06588v1</guid>
      <category>cs.IT</category>
      <category>math.IT</category>
      <category>physics.comp-ph</category>
      <pubDate>Tue, 13 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Zijiu Yang, Qianqian Yang, Shunpu Tang, Tingting Yang, Zhiguo Shi</dc:creator>
    </item>
    <item>
      <title>Symplectic Hulls over a Non-Unital Ring</title>
      <link>https://arxiv.org/abs/2601.06609</link>
      <description>arXiv:2601.06609v1 Announce Type: new 
Abstract: This paper presents the study of the symplectic hulls over a non-unital ring $ E= \langle \kappa,\tau \mid 2 \kappa =2 \tau=0,~ \kappa^2=\kappa,~ \tau^2=\tau,~ \kappa \tau=\kappa,~ \tau \kappa=\tau \rangle$. We first identify the residue and torsion codes of the left, right, and two-sided symplectic hulls, and characterize the generator matrix of the two-sided symplectic hull of a free $E$-linear code. Then, we explore the symplectic hull of the sum of two free $E$-linear codes. Subsequently, we provide two build-up techniques that extend a free $E$-linear code of smaller length and symplectic hull-rank to one of larger length and symplectic hull-rank. Further, for free $E$-linear codes, we discuss the permutation equivalence and investigate the symplectic hull-variation problem. An application of this study is given by classifying the free $E$-linear optimal codes for smaller lengths.</description>
      <guid isPermaLink="false">oai:arXiv.org:2601.06609v1</guid>
      <category>cs.IT</category>
      <category>math.IT</category>
      <pubDate>Tue, 13 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Anup Kushwaha, Om Prakash</dc:creator>
    </item>
    <item>
      <title>The Sample Complexity of Lossless Data Compression</title>
      <link>https://arxiv.org/abs/2601.06688</link>
      <description>arXiv:2601.06688v1 Announce Type: new 
Abstract: A new framework is introduced for examining and evaluating the fundamental limits of lossless data compression, that emphasizes genuinely non-asymptotic results. The {\em sample complexity} of compressing a given source is defined as the smallest blocklength at which it is possible to compress that source at a specified rate and to within a specified excess-rate probability. This formulation parallels corresponding developments in statistics and computer science, and it facilitates the use of existing results on the sample complexity of various hypothesis testing problems. For arbitrary sources, the sample complexity of general variable-length compressors is shown to be tightly coupled with the sample complexity of prefix-free codes and fixed-length codes. For memoryless sources, it is shown that the sample complexity is characterized not by the source entropy, but by its R\'{e}nyi entropy of order~$1/2$. Nonasymptotic bounds on the sample complexity are obtained, with explicit constants. Generalizations to Markov sources are established, showing that the sample complexity is determined by the source's R\'{e}nyi entropy rate of order~$1/2$. Finally, bounds on the sample complexity of universal data compression are developed for arbitrary families of memoryless sources. There, the sample complexity is characterized by the minimum R\'{e}nyi divergence of order~$1/2$ between elements of the family and the uniform distribution. The connection of this problem with identity testing and with the associated separation rates is explored and discussed.</description>
      <guid isPermaLink="false">oai:arXiv.org:2601.06688v1</guid>
      <category>cs.IT</category>
      <category>math.IT</category>
      <category>math.ST</category>
      <category>stat.TH</category>
      <pubDate>Tue, 13 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Terence Viaud, Ioannis Kontoyiannis</dc:creator>
    </item>
    <item>
      <title>Study of Adaptive Reliability-Driven Conditional Innovation Decoding for LDPC Codes</title>
      <link>https://arxiv.org/abs/2601.06732</link>
      <description>arXiv:2601.06732v1 Announce Type: new 
Abstract: In this work, we present an adaptive reliability-driven conditional innovation (AR-CID) decoding algorithm for low-density parity check (LDPC) codes. The proposed AR-CID decoding algorithm consists of one stage of message quality checking and another stage of message passing refinement, which are incorporated into a residual belief propagation decoding strategy. An analysis of the AR-CID decoding algorithm is carried out along with a study of its computational complexity and latency characteristics. Simulation results for several examples of LDPC codes, including short and medium-length codes over an extended range of channel conditions, indicate that the proposed AR-CID decoding algorithm outperforms competing decoding techniques and has an extremely fast convergence, making it particularly suitable for low-delay applications.</description>
      <guid isPermaLink="false">oai:arXiv.org:2601.06732v1</guid>
      <category>cs.IT</category>
      <category>math.IT</category>
      <pubDate>Tue, 13 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Hassan Touati, Rodrigo C. de Lamare</dc:creator>
    </item>
    <item>
      <title>Optimal Rate Region for Multi-server Secure Aggregation with User Collusion</title>
      <link>https://arxiv.org/abs/2601.06836</link>
      <description>arXiv:2601.06836v1 Announce Type: new 
Abstract: Secure aggregation is a fundamental primitive in privacy-preserving distributed learning systems, where an aggregator aims to compute the sum of users' inputs without revealing individual data. In this paper, we study a multi-server secure aggregation problem in a two-hop network consisting of multiple aggregation servers and multiple users per server, under the presence of user collusion. Each user communicates only with its associated server, while the servers exchange messages to jointly recover the global sum. We adopt an information-theoretic security framework, allowing up to $T$ users to collude with any server.
  We characterize the complete optimal rate region in terms of user-to-server communication rate, server-to-server communication rate, individual key rate, and source key rate. Our main result shows that the minimum communication and individual key rates are all one symbol per input symbol, while the optimal source key rate is given by $\min\{U+V+T-2,\, UV-1\}$, where $U$ denotes the number of servers and $V$ the number of users per server. The achievability is established via a linear key construction that ensures correctness and security against colluding users, while the converse proof relies on tight entropy bounds derived from correctness and security constraints.
  The results reveal a fundamental tradeoff between security and key efficiency and demonstrate that the multi-server architecture can significantly reduce the required key randomness compared to single-server secure aggregation. Our findings provide a complete information-theoretic characterization of secure aggregation in multi-server systems with user collusion.</description>
      <guid isPermaLink="false">oai:arXiv.org:2601.06836v1</guid>
      <category>cs.IT</category>
      <category>math.IT</category>
      <pubDate>Tue, 13 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Zhou Li, Xiang Zhang, Kai Wan, Hua Sun, Mingyue Ji, Giuseppe Caire</dc:creator>
    </item>
    <item>
      <title>Large Artificial Intelligence Models for Future Wireless Communications</title>
      <link>https://arxiv.org/abs/2601.06906</link>
      <description>arXiv:2601.06906v1 Announce Type: new 
Abstract: The anticipated integration of large artificial intelligence (AI) models with wireless communications is estimated to usher a transformative wave in the forthcoming information age. As wireless networks grow in complexity, the traditional methodologies employed for optimization and management face increasingly challenges. Large AI models have extensive parameter spaces and enhanced learning capabilities and can offer innovative solutions to these challenges. They are also capable of learning, adapting and optimizing in real-time. We introduce the potential and challenges of integrating large AI models into wireless communications, highlighting existing AIdriven applications and inherent challenges for future large AI models. In this paper, we propose the architecture of large AI models for future wireless communications, introduce their advantages in data analysis, resource allocation and real-time adaptation, discuss the potential challenges and corresponding solutions of energy, architecture design, privacy, security, ethical and regulatory. In addition, we explore the potential future directions of large AI models in wireless communications, laying the groundwork for forthcoming research in this area.</description>
      <guid isPermaLink="false">oai:arXiv.org:2601.06906v1</guid>
      <category>cs.IT</category>
      <category>eess.SP</category>
      <category>math.IT</category>
      <pubDate>Tue, 13 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Chong Huang, Gaojie Chen, Pei Xiao, Zhu Han, Rahim Tafazolli</dc:creator>
    </item>
    <item>
      <title>Caching Yields up to 5x Spectral Efficiency in Multi-Beam Satellite Communications</title>
      <link>https://arxiv.org/abs/2601.06925</link>
      <description>arXiv:2601.06925v1 Announce Type: new 
Abstract: This paper examines the integration of vector coded caching (VCC) into multi-beam satellite communications (SATCOM) systems and demonstrates that even limited receiver-side caching can substantially enhance spectral efficiency. By leveraging cached content to suppress interference, VCC enables the concurrent transmission of multiple precoded signal vectors that would otherwise require separate transmission resources. This leads to a multiplicative improvement in resource utilization in SATCOM. To characterize this performance, we model the satellite-to-ground channel using Rician-shadowed fading and after incorporating practical considerations such as matched-filter precoding, channel state information (CSI) acquisition overhead as well as CSI imperfections at the transmitter, we here derive closed-form expressions for the average sum rate and spectral efficiency gain of VCC in SATCOM. Our analysis, tightly validated through numerical simulations, reveals that VCC can yield spectral efficiency gains of 300% to 550% over traditional multi-user MISO SATCOM with the same resources. These gains -- which have nothing to do with multicasting, prefetching gains nor file popularity -- highlight VCC as a pure physical-layer solution for future high-throughput SATCOM systems, significantly narrowing the performance gap between satellite and wired networks.</description>
      <guid isPermaLink="false">oai:arXiv.org:2601.06925v1</guid>
      <category>cs.IT</category>
      <category>math.IT</category>
      <pubDate>Tue, 13 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Hui Zhao, Dirk Slock, Petros Elia</dc:creator>
    </item>
    <item>
      <title>Generalization Bounds for Transformer Channel Decoders</title>
      <link>https://arxiv.org/abs/2601.06969</link>
      <description>arXiv:2601.06969v1 Announce Type: new 
Abstract: Transformer channel decoders, such as the Error Correction Code Transformer (ECCT), have shown strong empirical performance in channel decoding, yet their generalization behavior remains theoretically unclear. This paper studies the generalization performance of ECCT from a learning-theoretic perspective. By establishing a connection between multiplicative noise estimation errors and bit-error-rate (BER), we derive an upper bound on the generalization gap via bit-wise Rademacher complexity. The resulting bound characterizes the dependence on code length, model parameters, and training set size, and applies to both single-layer and multi-layer ECCTs. We further show that parity-check-based masked attention induces sparsity that reduces the covering number, leading to a tighter generalization bound. To the best of our knowledge, this work provides the first theoretical generalization guarantees for this class of decoders.</description>
      <guid isPermaLink="false">oai:arXiv.org:2601.06969v1</guid>
      <category>cs.IT</category>
      <category>cs.LG</category>
      <category>math.IT</category>
      <pubDate>Tue, 13 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Qinshan Zhang, Bin Chen, Yong Jiang, Shu-Tao Xia</dc:creator>
    </item>
    <item>
      <title>Quantum Optical Integrated Sensing and Communication with Homodyne BPSK Detection</title>
      <link>https://arxiv.org/abs/2601.07034</link>
      <description>arXiv:2601.07034v1 Announce Type: new 
Abstract: In this letter, we propose a quantum integrated sensing and communication scheme for a quantum optical link using binary phase-shift keying modulation and homodyne detection. The link operates over a phase-insensitive Gaussian channel with an unknown deterministic phase rotation, where the homodyne receiver jointly carries out symbol detection and phase estimation. We formulate a design problem that minimizes the bit-error rate subject to a Fisher information-based constraint on estimation accuracy. To solve it, we develop an iterative algorithm composed of an inner expectation-maximization loop for joint detection and estimation and an outer loop that adaptively retunes the local oscillator phase. Numerical results confirm the effectiveness of the proposed approach and demonstrate a fundamental trade-off between communication reliability and sensing accuracy.</description>
      <guid isPermaLink="false">oai:arXiv.org:2601.07034v1</guid>
      <category>cs.IT</category>
      <category>math.IT</category>
      <pubDate>Tue, 13 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Ioannis Krikidis</dc:creator>
    </item>
    <item>
      <title>Random Access in DNA Storage: Algorithms, Constructions, and Bounds</title>
      <link>https://arxiv.org/abs/2601.07053</link>
      <description>arXiv:2601.07053v1 Announce Type: new 
Abstract: As DNA data storage moves closer to practical deployment, minimizing sequencing coverage depth is essential to reduce both operational costs and retrieval latency. This paper addresses the recently studied Random Access Problem, which evaluates the expected number of read samples required to recover a specific information strand from $n$ encoded strands. We propose a novel algorithm to compute the exact expected number of reads, achieving a computational complexity of $O(n)$ for fixed field size $q$ and information length $k$. Furthermore, we derive explicit formulas for the average and maximum expected number of reads, enabling an efficient search for optimal generator matrices under small parameters. Beyond theoretical analysis, we present new code constructions that improve the best-known upper bound from $0.8815k$ to $0.8811k$ for $k=3$, and achieve an upper bound of $0.8629k$ for $k=4$ for sufficiently large $q$. We also establish a tighter theoretical lower bound on the expected number of reads that improves upon state-of-the-art bounds. In particular, this bound establishes the optimality of the simple parity code for the case of $n=k+1$ across any alphabet $q$.</description>
      <guid isPermaLink="false">oai:arXiv.org:2601.07053v1</guid>
      <category>cs.IT</category>
      <category>math.IT</category>
      <pubDate>Tue, 13 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Chen Wang, Eitan Yaakobi</dc:creator>
    </item>
    <item>
      <title>Score-Based VAMP with Fisher-Information-Based Onsager Correction</title>
      <link>https://arxiv.org/abs/2601.07095</link>
      <description>arXiv:2601.07095v1 Announce Type: new 
Abstract: We propose score-based VAMP (SC-VAMP), a variant of vector approximate message passing (VAMP) in which the Onsager correction is expressed and computed via conditional Fisher information, thereby enabling a Jacobian-free implementation. Using learned score functions, SC-VAMP constructs nonlinear MMSE estimators through Tweedie's formula and derives the corresponding Onsager terms from the score-norm statistics, avoiding the need for analytical derivatives of the prior or likelihood. When combined with random orthogonal/unitary mixing to mitigate non-ideal, structured or correlated sensing settings, the proposed framework extends VAMP to complex black-box inference problems where explicit modeling is intractable. Finally, by leveraging the entropic CLT, we provide an information-theoretic perspective on the Gaussian approximation underlying SE, offering insight into the decoupling principle beyond idealized i.i.d. settings, including nonlinear regimes.</description>
      <guid isPermaLink="false">oai:arXiv.org:2601.07095v1</guid>
      <category>cs.IT</category>
      <category>math.IT</category>
      <pubDate>Tue, 13 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Tadashi Wadayama, Takumi Takahashi</dc:creator>
    </item>
    <item>
      <title>PASS-Enabled Covert Communications With Distributed Cooperative Wardens</title>
      <link>https://arxiv.org/abs/2601.07147</link>
      <description>arXiv:2601.07147v1 Announce Type: new 
Abstract: This paper investigates PASS-enabled downlink covert communication in the presence of distributed surveillance, where multiple wardens perform signal detection and fuse their local binary decisions via majority-voting rule. We consider a dual-waveguide architecture that simultaneously delivers covert information and randomized jamming to hide the transmission footprint, incorporating three representative PASS power-radiation laws-general, proportional, and equal. To characterize the system-level detectability, we derive closed-form expressions for local false-alarm and miss-detection probabilities. By leveraging a probability-generating-function (PGF) and elementary-symmetric-polynomial (ESP) framework, combined with a breakpoint-based partition of the threshold domain, we obtain explicit closed-form characterizations of the system-level detection error probability (DEP) under non-i.i.d. majority-voting fusion. Building on this analytical framework, we formulate a robust optimization problem to maximize the average covert rate subject to covertness constraint. To solve the resulting nonconvex design, we develop an MM-BCD-SCA algorithm that produces tractable alternating updates for power/radiation variables and PA positions via convex surrogates and inner approximations of the DEP value function. Numerical results validate the theoretical analysis and demonstrate the impact of cooperative monitoring and PASS radiation laws on the covertness-rate tradeoff.</description>
      <guid isPermaLink="false">oai:arXiv.org:2601.07147v1</guid>
      <category>cs.IT</category>
      <category>cs.CR</category>
      <category>math.IT</category>
      <pubDate>Tue, 13 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Ji He</dc:creator>
    </item>
    <item>
      <title>Sentiment Analysis on Movie Reviews: A Deep Dive into Modern Techniques and Open Challenges</title>
      <link>https://arxiv.org/abs/2601.07235</link>
      <description>arXiv:2601.07235v1 Announce Type: new 
Abstract: This paper presents a comprehensive survey of sentiment analysis methods for movie reviews, a benchmark task that has played a central role in advancing natural language processing. We review the evolution of techniques from early lexicon-based and classical machine learning approaches to modern deep learning architectures and large language models, covering widely used datasets such as IMDb, Rotten Tomatoes, and SST-2, and models ranging from Naive Bayes and support vector machines to LSTM networks, BERT, and attention-based transformers. Beyond summarizing prior work, this survey differentiates itself by offering a comparative, challenge-driven analysis of how these modeling paradigms address domain-specific issues such as sarcasm, negation, contextual ambiguity, and domain shift, which remain open problems in existing literature. Unlike earlier reviews that focus primarily on text-only pipelines, we also synthesize recent advances in multimodal sentiment analysis that integrate textual, audio, and visual cues from movie trailers and clips. In addition, we examine emerging concerns related to interpretability, fairness, and robustness that are often underexplored in prior surveys, and we outline future research directions including zero-shot and few-shot learning, hybrid symbolic--neural models, and real-time deployment considerations. Overall, this abstract provides a domain-focused roadmap that highlights both established solutions and unresolved challenges toward building more accurate, generalizable, and explainable sentiment analysis systems for movie review data.</description>
      <guid isPermaLink="false">oai:arXiv.org:2601.07235v1</guid>
      <category>cs.IT</category>
      <category>math.IT</category>
      <pubDate>Tue, 13 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Agnivo Gosai, Shuvodeep De, Karun Thankachan</dc:creator>
    </item>
    <item>
      <title>Bias-Aware BP Decoding of Quantum Codes via Directional Degeneracy</title>
      <link>https://arxiv.org/abs/2601.07240</link>
      <description>arXiv:2601.07240v1 Announce Type: new 
Abstract: We study directionally informed belief propagation (BP) decoding for quantum CSS codes, where anisotropic Tanner-graph structure and biased noise concentrate degeneracy along preferred directions. We formalize this by placing orientation weights on Tanner-graph edges, aggregating them into per-qubit directional weights, and defining a \emph{directional degeneracy enumerator} that summarizes how degeneracy concentrates along those directions. A single bias parameter~$\beta$ maps these weights into site-dependent log-likelihood ratios (LLRs), yielding anisotropic priors that plug directly into standard BP$\rightarrow$OSD decoders without changing the code construction. We derive bounds relating directional and Hamming distances, upper bound the number of degenerate error classes per syndrome as a function of distance, rate, and directional bias, and give a MacWilliams-type expression for the directional enumerator. Finite-length simulations under code-capacity noise show significant logical error-rate reductions -- often an order of magnitude at moderate physical error rates -- confirming that modest anisotropy is a simple and effective route to hardware-aware decoding gains.</description>
      <guid isPermaLink="false">oai:arXiv.org:2601.07240v1</guid>
      <category>cs.IT</category>
      <category>math.IT</category>
      <pubDate>Tue, 13 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Mohammad Rowshan</dc:creator>
    </item>
    <item>
      <title>Rate-distortion Theory on Non-compact Spaces: A Concentration-compactness Approach</title>
      <link>https://arxiv.org/abs/2601.07246</link>
      <description>arXiv:2601.07246v1 Announce Type: new 
Abstract: In this paper, we study rate-distortion theory for general sources with an emphasis on the existence of optimal reconstruction distributions. Classical existence results rely on compactness assumptions that are often violated in non-compact settings. By introducing the concentration-compactness principle into the analysis of the rate-distortion functional, we establish the existence of optimal reconstructions under mild coercivity conditions on the distortion function. Our results provide a unified and transparent existence theorem for rate-distortion problems on general non-compact spaces.</description>
      <guid isPermaLink="false">oai:arXiv.org:2601.07246v1</guid>
      <category>cs.IT</category>
      <category>math.IT</category>
      <pubDate>Tue, 13 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Jiayang Zou, Luyao Fan, Jiayang Gao, Jia Wang</dc:creator>
    </item>
    <item>
      <title>Engineering Favorable Propagation: Near-Field IRS Deployment for Spatial Multiplexing</title>
      <link>https://arxiv.org/abs/2601.07317</link>
      <description>arXiv:2601.07317v1 Announce Type: new 
Abstract: In intelligent reflecting surface IRS assisted multiple input multiple output MIMO systems, a strong line of sight LoS link is required to compensate for the severe cascaded path loss. However, such a link renders the effective channel highly rank deficient and fundamentally limits spatial multiplexing. To overcome this limitation, this paper leverages the large aperture of sparse arrays to harness near field spherical wavefronts, and establishes a deterministic deployment criterion that strategically positions the IRS in the near field of a base station BS. This placement exploits the spherical wavefronts of the BS IRS link to engineer decorrelated channels, thereby fundamentally overcoming the rank deficiency issue in far field cascaded channels. Based on a physical channel model for the sparse BS array and the IRS, we characterize the rank properties and inter user correlation of the cascaded BS IRS user channel. We further derive a closed form favorable propagation metric that reveals how the sparse array geometry and the IRS position can be tuned to reduce inter user channel correlation. The resulting geometry driven deployment rule provides a simple guideline for creating a favorable propagation environment with enhanced effective degrees of freedom. The favorable channel statistics induced by our deployment criterion enable a low complexity maximum ratio transmission MRT precoding scheme. This serves as the foundation for an efficient algorithm that jointly optimizes the IRS phase shifts and power allocation based solely on long term statistical channel state information CSI. Simulation results validate the effectiveness of our deployment criterion and demonstrate that our optimization framework achieves significant performance gains over benchmark schemes.</description>
      <guid isPermaLink="false">oai:arXiv.org:2601.07317v1</guid>
      <category>cs.IT</category>
      <category>math.IT</category>
      <pubDate>Tue, 13 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Yuxuan Chen, Qingqing Wu, Guangji Chen, Qiaoyan Peng, Wen Chen</dc:creator>
    </item>
    <item>
      <title>Performance Bounds of Joint Detection with Kalman Filtering and Channel Decoding for Wireless Networked Control Systems</title>
      <link>https://arxiv.org/abs/2601.07322</link>
      <description>arXiv:2601.07322v1 Announce Type: new 
Abstract: The joint detection uses Kalman filtering (KF) to estimate the prior probability of control outputs to assist channel decoding. In this paper, we regard the joint detection as maximum a posteriori (MAP) decoding and derive the lower and upper bounds based on the pairwise error probability considering system interference, quantization interval, and weight distribution. We first derive the limiting bounds as the signal-to-noise ratio (SNR) goes to infinity and the system interference goes to zero. Then, we construct an infinite-state Markov chain to describe the consecutive packet losses of the control systems to derive the MAP bounds. Finally, the MAP bounds are approximated as the bounds of the transition probability from the state with no packet loss to the state with consecutive single packet loss. The simulation results show that the MAP performance of $\left(64,16\right)$ polar code and 16-bit CRC coincides with the limiting upper bound as the SNR increases and has $3.0$dB performance gain compared with the normal approximation of the finite block rate at block error rate $10^{-3}$.</description>
      <guid isPermaLink="false">oai:arXiv.org:2601.07322v1</guid>
      <category>cs.IT</category>
      <category>math.IT</category>
      <pubDate>Tue, 13 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Jinnan Piao, Dong Li, Zhibo Li, Ming Yang, Xueting Yu, Jincheng Dai</dc:creator>
    </item>
    <item>
      <title>On the Extremal Source Key Rates for Secure Storage over Graphs</title>
      <link>https://arxiv.org/abs/2601.07340</link>
      <description>arXiv:2601.07340v1 Announce Type: new 
Abstract: This paper investigates secure storage codes over graphs, where multiple independent source symbols are encoded and stored at graph nodes subject to edge-wise correctness and security constraints. For each edge, a specified subset of source symbols must be recoverable from its two incident nodes, while no information about the remaining sources is revealed. To meet the security requirement, a shared source key may be employed. The ratio between the source symbol size and the source key size defines the source key rate, and the supremum of all achievable rates is referred to as the source key capacity.
  We study extremal values of the source key capacity in secure storage systems and provide complete graph characterizations for several fundamental settings. For the case where each edge is associated with a single source symbol, we characterize all graphs whose source key capacity equals one. We then generalize this result to the case where each edge is associated with multiple source symbols and identify a broad class of graphs that achieve the corresponding extremal capacity under a mild structural condition. In addition, we characterize all graphs for which secure storage can be achieved without using any source key.</description>
      <guid isPermaLink="false">oai:arXiv.org:2601.07340v1</guid>
      <category>cs.IT</category>
      <category>math.IT</category>
      <pubDate>Tue, 13 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Zhou Li</dc:creator>
    </item>
    <item>
      <title>Fast and Provable Nonconvex Robust Matrix Completion</title>
      <link>https://arxiv.org/abs/2601.07355</link>
      <description>arXiv:2601.07355v1 Announce Type: new 
Abstract: This paper studies the robust matrix completion problem and a computationally efficient non-convex method called ARMC has been proposed. This method is developed by introducing subspace projection to a singular value thresholding based method when updating the low rank part. Numerical experiments on synthetic and real data show that ARMC is superior to existing non-convex RMC methods. Through a refined analysis based on the leave-one-out technique, we have established the theoretical guarantee for ARMC subject to both sparse outliers and stochastic noise. The established bounds for the sample complexity and outlier sparsity are better than those established for a convex approach that also considers both outliers and stochastic noise.</description>
      <guid isPermaLink="false">oai:arXiv.org:2601.07355v1</guid>
      <category>cs.IT</category>
      <category>math.IT</category>
      <pubDate>Tue, 13 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Yichen Fu, Tianming Wang, Ke Wei</dc:creator>
    </item>
    <item>
      <title>Novel Decoding Algorithm for Noiseless Non-Adaptive Group Testing</title>
      <link>https://arxiv.org/abs/2601.07388</link>
      <description>arXiv:2601.07388v1 Announce Type: new 
Abstract: Group testing enables the identification of a small subset of defective items within a larger population by performing tests on pools of items rather than on each item individually. Over the years, it has not only attracted attention from the academic community, but has also demonstrated its potential in addressing real-world problems such as infectious disease screening, drug discovery and manufacturing quality control. With the emergence of the COVID-19 pandemic, interest in group testing has grown further, particularly in non-adaptive testing, due to its time efficiency compared to adaptive approaches. This highlights the importance of improving the performance currently achievable in such a scheme. This article focuses on advancing the field of noiseless non-adaptive group testing. The main objective of this work is to study and maximize the probability of successfully identifying the subset of defective items while performing as few tests as possible. To this end, we first note current well-known decoding algorithms, as well as established test design strategies for assigning items to pools. From this review, we identify key opportunities for improvement that inform the development of new decoding algorithms. Specifically, we propose a novel method, Weighted Sequential Combinatorial Orthogonal Matching Pursuit (W-SCOMP), to enhance the efficiency of existing detection procedures. Theoretical results demonstrate that W-SCOMP outperforms other algorithms in noiseless non-adaptive group testing. Furthermore, we develop a simulation framework to model the group testing process and conduct comparative evaluations between the proposed and existing algorithms. The empirical results are consistent with the theoretical findings. Overall, our work expands the range of available decoding algorithms and contributes to the broader understanding of noiseless non-adaptive group testing.</description>
      <guid isPermaLink="false">oai:arXiv.org:2601.07388v1</guid>
      <category>cs.IT</category>
      <category>math.IT</category>
      <category>math.PR</category>
      <pubDate>Tue, 13 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Manuel Franco-Vivo</dc:creator>
    </item>
    <item>
      <title>Center-Fed Pinching Antenna System (C-PASS) Aided Wireless Communications</title>
      <link>https://arxiv.org/abs/2601.07424</link>
      <description>arXiv:2601.07424v1 Announce Type: new 
Abstract: The novel architecture of the center-fed pinching antenna system (C-PASS) is investigated, where the waveguide-fed signal is divided into two propagation directions through controllable power splitting. By doing so, a doubled degree of freedom (DoF) is achieved compared to conventional PASS. Based on the new designed basic signal model of C-PASS, three practical operating protocols for C-PASS are proposed, namely power splitting (PS), direction switching (DS), and time switching (TS). Then, the sum-rate maximization problem for the joint optimization of transmit and pinching beamforming is formulated for each of the proposed protocols. 1) For PS, the highly coupled non-convex problem is first transformed into a tractable form via the weighted minimum mean square error reformulation and solved using the alternating optimization framework; 2) For DS, the above approach is subsequently extended to solve the mixed-integer constraints inherent for DS via the penalty-based algorithm; 3) For TS, the optimization problem can be decomposed into two subproblems and solved using the similar iterative techniques, while its optimal time allocation ratio is derived in closed form. Finally, numerical results reveal that TS is superior in the low-power regime, while PS and DS achieve significantly higher rates in the high-power regime due to the enhanced DoF.</description>
      <guid isPermaLink="false">oai:arXiv.org:2601.07424v1</guid>
      <category>cs.IT</category>
      <category>math.IT</category>
      <pubDate>Tue, 13 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Xu Gan, Yuanwei Liu</dc:creator>
    </item>
    <item>
      <title>Secure Joint Source-Channel Coding for the AWGN Channel with Feedback: A Finite Blocklength Analysis</title>
      <link>https://arxiv.org/abs/2601.07472</link>
      <description>arXiv:2601.07472v1 Announce Type: new 
Abstract: In the literature, it has been shown that the secrecy capacity of the additive white Gaussian noise (AWGN) wiretap channel with noise-free feedback equals the capacity of the same model without secrecy constraint, and the classical Schalkwijk-Kailath (SK) scheme achieves the secrecy capacity. In this paper, we show that in finite blocklength regime, the SK scheme is not optimal, and propose a modified SK scheme which may perform better than the classical one. Besides this, this paper establishes a finite blocklength converse for the AWGN wiretap channel with feedback, which can also be viewed as a converse for the same model without secrecy constraint. To the best of the authors' knowledge, this is the first paper to address such a problem, and the results of this paper are further explained via numerical examples.</description>
      <guid isPermaLink="false">oai:arXiv.org:2601.07472v1</guid>
      <category>cs.IT</category>
      <category>math.IT</category>
      <pubDate>Tue, 13 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Sheng Su, Yuhan Yang, Chao Qi, Xuan He, Bin Dai, Xiaohu Tang</dc:creator>
    </item>
    <item>
      <title>Frequency-Adaptive Multi-Band Architecture for Upper Mid-Band MIMO Systems</title>
      <link>https://arxiv.org/abs/2601.07489</link>
      <description>arXiv:2601.07489v1 Announce Type: new 
Abstract: FR3 ($\approx$7-24 GHz), also referred to as the upper mid-band, has recently emerged as promising spectrum for 6G; however, its propagation and MIMO characteristics vary significantly with frequency and environment, and spectrum availability may be intermittent due to incumbents. Using site-specific ray tracing (Sionna RT) in representative indoor and outdoor scenarios, we evaluate 7, 10, 14, 20, and 24 GHz under SISO and MIMO configurations. The results show that FR3 exhibits propagation characteristics intermediate between sub-6 GHz and mmWave bands while supporting meaningful spatial multiplexing, albeit with strong site dependence. Motivated by these findings, we propose a fully digital frequency-adaptive multi-band MIMO architecture that repurposes ADCs/DACs and baseband processing resources across FR3 subbands via switching, enabling dynamic trade-offs between bandwidth (spectrum gain) and antenna consolidation (MIMO gain) under availability and channel constraints. Simulation results demonstrate that exploiting additional spectrum is often optimal, while adaptive resource repurposing becomes beneficial when subbands are unavailable or when multiplexing gains are concentrated at specific frequencies.</description>
      <guid isPermaLink="false">oai:arXiv.org:2601.07489v1</guid>
      <category>cs.IT</category>
      <category>cs.SY</category>
      <category>eess.SY</category>
      <category>math.IT</category>
      <pubDate>Tue, 13 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Emiel Vanspranghels, Zhuangzhuang Cui, Sofie Pollin</dc:creator>
    </item>
    <item>
      <title>A Parity-Consistent Decomposition Method for the Weight Distribution of Pre-Transformed Polar Codes</title>
      <link>https://arxiv.org/abs/2601.07515</link>
      <description>arXiv:2601.07515v1 Announce Type: new 
Abstract: This paper introduces an efficient algorithm based on the Parity-Consistent Decomposition (PCD) method to determine the WD of pre-transformed polar codes. First, to address the bit dependencies introduced by the pre-transformation matrix, we propose an iterative algorithm to construct an \emph{Expanded Information Set}. By expanding the information bits within this set into 0s and 1s, we eliminate the correlations among information bits, thereby enabling the recursive calculation of the Hamming weight distribution using the \emph{PCD method}. Second, to further reduce computational complexity, we establish the theory of equivalence classes for pre-transformed polar codes. Codes within the same equivalence class share an identical weight distribution but correspond to different \emph{Expanded Information Set} sizes. By selecting the pre-transformation matrix that minimizes the \emph{Expanded Information Set} size within an equivalence class, we optimize the computation process. Numerical results demonstrate that the proposed method significantly reduces computational complexity compared to existing deterministic algorithms.</description>
      <guid isPermaLink="false">oai:arXiv.org:2601.07515v1</guid>
      <category>cs.IT</category>
      <category>math.IT</category>
      <pubDate>Tue, 13 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Yang Liu, Bolin Wu, Yuxin Han, Kai Niu</dc:creator>
    </item>
    <item>
      <title>Sparse Point-wise Privacy Leakage: Mechanism Design and Fundamental Limits</title>
      <link>https://arxiv.org/abs/2601.07523</link>
      <description>arXiv:2601.07523v1 Announce Type: new 
Abstract: We study an information-theoretic privacy mechanism design problem, where an agent observes useful data $Y$ that is arbitrarily correlated with sensitive data $X$, and design disclosed data $U$ generated from $Y$ (the agent has no direct access to $X$). We introduce \emph{sparse point-wise privacy leakage}, a worst-case privacy criterion that enforces two simultaneous constraints for every disclosed symbol $u\in\mathcal{U}$: (i) $u$ may be correlated with at most $N$ realizations of $X$, and (ii) the total leakage toward those realizations is bounded. In the high-privacy regime, we use concepts from information geometry to obtain a local quadratic approximation of mutual information which measures utility between $U$ and $Y$. When the leakage matrix $P_{X|Y}$ is invertible, this approximation reduces the design problem to a sparse quadratic maximization, known as the Rayleigh-quotient problem, with an $\ell_0$ constraint. We further show that, for the approximated problem, one can without loss of optimality restrict attention to a binary released variable $U$ with a uniform distribution. For small alphabet sizes, the exact sparsity-constrained optimum can be computed via combinatorial support enumeration, which quickly becomes intractable as the dimension grows. For general dimensions, the resulting sparse Rayleigh-quotient maximization is NP-hard and closely related to sparse principal component analysis (PCA). We propose a convex semidefinite programming (SDP) relaxation that is solvable in polynomial time and provides a tractable surrogate for the NP-hard design, together with a simple rounding procedure to recover a feasible leakage direction. We also identify a sparsity threshold beyond which the sparse optimum saturates at the unconstrained spectral value and the SDP relaxation becomes tight.</description>
      <guid isPermaLink="false">oai:arXiv.org:2601.07523v1</guid>
      <category>cs.IT</category>
      <category>math.IT</category>
      <pubDate>Tue, 13 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Amirreza Zamani, Sajad Daei, Parastoo Sadeghi, Mikael Skoglund</dc:creator>
    </item>
    <item>
      <title>Estimators for Substitution Rates in Genomes from Read Data</title>
      <link>https://arxiv.org/abs/2601.07546</link>
      <description>arXiv:2601.07546v1 Announce Type: new 
Abstract: We study the problem of estimating the mutation rate between two sequences from noisy sequencing reads. Existing alignment-free methods typically assume direct access to the full sequences. We extend these methods to the sequencing framework, where only noisy reads from the sequences are observed. We use a simple model in which both mutations and sequencing errors are substitutions. We propose multiple estimators, provide theoretical guarantees for one of them, and evaluate the others through simulations.</description>
      <guid isPermaLink="false">oai:arXiv.org:2601.07546v1</guid>
      <category>cs.IT</category>
      <category>math.IT</category>
      <category>q-bio.GN</category>
      <pubDate>Tue, 13 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Shiv Pratap Singh Rathore, Navin Kashyap</dc:creator>
    </item>
    <item>
      <title>On the Sequence Reconstruction Problem for the Single-Deletion Two-Substitution Channel</title>
      <link>https://arxiv.org/abs/2601.07547</link>
      <description>arXiv:2601.07547v1 Announce Type: new 
Abstract: The Levenshtein sequence reconstruction problem studies the reconstruction of a transmitted sequence from multiple erroneous copies of it. A fundamental question in this field is to determine the minimum number of erroneous copies required to guarantee correct reconstruction of the original sequence. This problem is equivalent to determining the maximum possible intersection size of two error balls associated with the underlying channel. Existing research on the sequence reconstruction problem has largely focused on channels with a single type of error, such as insertions, deletions, or substitutions alone. However, relatively little is known for channels that involve a mixture of error types, for instance, channels allowing both deletions and substitutions. In this work, we study the sequence reconstruction problem for the single-deletion two-substitution channel, which allows one deletion and at most two substitutions applied to the transmitted sequence. Specifically, we prove that if two $q$-ary length-$n$ sequences have the Hamming distance $d\geq 2$, where $q\geq 2$ is any fixed integer, then the intersection size of their error balls under the single-deletion two-substitution channel is upper bounded by $(q^2-1)n^2-(3q^2+5q-5)n+O_q(1)$, where $O_q(1)$ is a constant independent from $n$ but dependent on $q$. Moreover, we show that this upper bound is tight up to an additive constant.</description>
      <guid isPermaLink="false">oai:arXiv.org:2601.07547v1</guid>
      <category>cs.IT</category>
      <category>math.IT</category>
      <pubDate>Tue, 13 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Wentu Song, Kui Cai, Tony Q. S. Quek</dc:creator>
    </item>
    <item>
      <title>A $q$-Polymatroid Framework for Information Leakage in Secure Linear Network Coding</title>
      <link>https://arxiv.org/abs/2601.07567</link>
      <description>arXiv:2601.07567v1 Announce Type: new 
Abstract: We study information leakage in secure linear network coding schemes based on nested rank-metric codes. We show that the amount of information leaked to an adversary that observes a subset of network links is characterized by the conditional rank function of a representable $q$-polymatroid associated with the underlying rank-metric code pair. Building on this connection, we introduce the notions of $q$-polymatroid ports and $q$-access structures and describe their structural properties. Moreover, we extend Massey's correspondence between minimal codewords and minimal access sets to the rank-metric setting and prove a $q$-analogue of the Brickell--Davenport theorem.</description>
      <guid isPermaLink="false">oai:arXiv.org:2601.07567v1</guid>
      <category>cs.IT</category>
      <category>math.IT</category>
      <pubDate>Tue, 13 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Eimear Byrne, Johan Vester Dinesen, Ragnar Freij-Hollanti, Camilla Hollanti</dc:creator>
    </item>
    <item>
      <title>Clipped Affine Policy: Low-Complexity Near-Optimal Online Power Control for Energy Harvesting Communications over Fading Channels</title>
      <link>https://arxiv.org/abs/2601.07622</link>
      <description>arXiv:2601.07622v1 Announce Type: new 
Abstract: This paper investigates online power control for point-to-point energy harvesting communications over wireless fading channels. A linear-policy-based approximation is derived for the relative-value function in the Bellman equation of the power control problem. This approximation leads to two fundamental power control policies: optimistic and robust clipped affine policies, both taking the form of a clipped affine function of the battery level and the reciprocal of channel signal-to-noise ratio coefficient. They are essentially battery-limited weighted directional waterfilling policies operating between adjacent time slots. By leveraging the relative-value approximation and derived policies, a domain-knowledge-enhanced reinforcement learning (RL) algorithm is proposed for online power control. The proposed approach is further extended to scenarios with energy and/or channel lookahead. Comprehensive simulation results demonstrate that the proposed methods achieve a good balance between computational complexity and optimality. In particular, the robust clipped affine policy (combined with RL, using at most five parameters) outperforms all existing approaches across various scenarios, with less than 2\% performance loss relative to the optimal policy.</description>
      <guid isPermaLink="false">oai:arXiv.org:2601.07622v1</guid>
      <category>cs.IT</category>
      <category>cs.SY</category>
      <category>eess.SY</category>
      <category>math.IT</category>
      <pubDate>Tue, 13 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Hao Wu, Shengtian Yang, Huiguo Gao, Diao Wang, Jun Chen, Guanding Yu</dc:creator>
    </item>
    <item>
      <title>New $X$-Secure $T$-Private Information Retrieval Schemes via Rational Curves and Hermitian Curves</title>
      <link>https://arxiv.org/abs/2601.07676</link>
      <description>arXiv:2601.07676v1 Announce Type: new 
Abstract: $X$-secure and $T$-private information retrieval (XSTPIR) is a variant of private information retrieval where data security is guaranteed against collusion among up to $X$ servers and the user's retrieval privacy is guaranteed against collusion among up to $T$ servers. Recently, researchers have constructed XSTPIR schemes through the theory of algebraic geometry codes and algebraic curves, with the aim of obtaining XSTPIR schemes that have higher maximum PIR rates for fixed field size and $X,T$ (the number of servers $N$ is not restricted). The mainstream approach is to employ curves of higher genus that have more rational points, evolving from rational curves to elliptic curves to hyperelliptic curves and, most recently, to Hermitian curves.
  In this paper, we propose a different perspective: with the shared goal of constructing XSTPIR schemes with higher maximum PIR rates, we move beyond the mainstream approach of seeking curves with higher genus and more rational points. Instead, we aim to achieve this goal by enhancing the utilization efficiency of rational points on curves that have already been considered in previous work. By introducing a family of bases for the polynomial space $\text{span}_{\mathbb{F}_q}\{1,x,\dots,x^{k-1}\}$ as an alternative to the Lagrange interpolation basis, we develop two new families of XSTPIR schemes based on rational curves and Hermitian curves, respectively. Parameter comparisons demonstrate that our schemes achieve superior performance. Specifically, our Hermitian-curve-based XSTPIR scheme provides the largest known maximum PIR rates when the field size $q^2\geq 14^2$ and $X+T\geq 4q$. Moreover, for any field size $q^2\geq 28^2$ and $X+T\geq 4$, our two XSTPIR schemes collectively provide the largest known maximum PIR rates.</description>
      <guid isPermaLink="false">oai:arXiv.org:2601.07676v1</guid>
      <category>cs.IT</category>
      <category>math.IT</category>
      <pubDate>Tue, 13 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Yuan Gao, Weijun Fang, Jingke Xu, Jiejing Wen</dc:creator>
    </item>
    <item>
      <title>Weak Composition Lattices and Ring-Linear Anticodes</title>
      <link>https://arxiv.org/abs/2601.07725</link>
      <description>arXiv:2601.07725v1 Announce Type: new 
Abstract: Lattices and partially ordered sets have played an increasingly important role in coding theory, providing combinatorial frameworks for studying structural and algebraic properties of error-correcting codes. Motivated by recent works connecting lattice theory, anticodes, and coding-theoretic invariants, we investigate ring-linear codes endowed with the Lee metric. We introduce and characterize optimal Lee-metric anticodes over the ring $\mathbb{Z}/p^s\mathbb{Z}$. We show that the family of such anticodes admits a natural partition into subtypes and forms a lattice under inclusion. We establish a bijection between this lattice and a lattice of weak compositions ordered by dominance. As an application, we use this correspondence to introduce new invariants for Lee-metric codes via an anticode approach.</description>
      <guid isPermaLink="false">oai:arXiv.org:2601.07725v1</guid>
      <category>cs.IT</category>
      <category>math.IT</category>
      <pubDate>Tue, 13 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Jessica Bariffi, Drisana Bhatia, Giuseppe Cotardo, Violetta Weger</dc:creator>
    </item>
    <item>
      <title>Lossy Source Coding with Broadcast Side Information</title>
      <link>https://arxiv.org/abs/2601.07797</link>
      <description>arXiv:2601.07797v1 Announce Type: new 
Abstract: This paper considers the source coding problem with broadcast side information. The side information is sent to two receivers through a noisy broadcast channel. We provide an outer bound of the rate--distortion--bandwidth (RDB) quadruples and achievable RDB quadruples when the helper uses a separation-based scheme. Some special cases with full characterization are also provided. We then compare the separation-based scheme with the uncoded scheme in the quadratic Gaussian case.</description>
      <guid isPermaLink="false">oai:arXiv.org:2601.07797v1</guid>
      <category>cs.IT</category>
      <category>math.IT</category>
      <pubDate>Tue, 13 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Yiqi Chen, Holger Boche, Marc Geitz</dc:creator>
    </item>
    <item>
      <title>Filtering Beats Fine Tuning: A Bayesian Kalman View of In Context Learning in LLMs</title>
      <link>https://arxiv.org/abs/2601.06100</link>
      <description>arXiv:2601.06100v1 Announce Type: cross 
Abstract: We present a theory-first framework that interprets inference-time adaptation in large language models (LLMs) as online Bayesian state estimation. Rather than modeling rapid adaptation as implicit optimization or meta-learning, we formulate task- and context-specific learning as the sequential inference of a low-dimensional latent adaptation state governed by a linearized state-space model. Under Gaussian assumptions, adaptation follows a Kalman recursion with closed-form updates for both the posterior mean and covariance.
  This perspective elevates epistemic uncertainty to an explicit dynamical variable. We show that inference-time learning is driven by covariance collapse, i.e., rapid contraction of posterior uncertainty induced by informative tokens, which typically precedes convergence of the posterior mean. Using observability conditions on token-level Jacobians, we establish stability of the Bayesian filter, prove exponential covariance contraction rates, and derive mean-square error bounds. Gradient descent, natural-gradient methods, and meta-learning updates arise as singular, noise-free limits of the filtering dynamics, positioning optimization-based adaptation as a degenerate approximation of Bayesian inference.
  The resulting theory provides a unified probabilistic account of in-context learning, parameter-efficient adaptation, and test-time learning without parameter updates. It yields explicit guarantees on stability and sample efficiency, offers a principled interpretation of prompt informativeness via information accumulation, and clarifies the role of uncertainty dynamics absent from existing accounts. Minimal illustrative experiments corroborate the qualitative predictions of the theory.</description>
      <guid isPermaLink="false">oai:arXiv.org:2601.06100v1</guid>
      <category>cs.LG</category>
      <category>cs.CL</category>
      <category>cs.IT</category>
      <category>math.IT</category>
      <pubDate>Tue, 13 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Andrew Kiruluta</dc:creator>
    </item>
    <item>
      <title>Joint Impact of ADC and Fronthaul Quantization in Cell-Free Massive MIMO-OFDM Uplink</title>
      <link>https://arxiv.org/abs/2601.06483</link>
      <description>arXiv:2601.06483v1 Announce Type: cross 
Abstract: In the uplink of a cell-free massive MIMO system, quantization affects performance in two key domains: the time-domain distortion introduced by finite-resolution analog-to-digital converters (ADCs) at the access points (APs), and the fronthaul quantization of signals sent to the central processing unit (CPU). Although quantizing twice may seem redundant, the ADC quantization in orthogonal frequency-division duplex (OFDM) systems appears in the time domain, and one must then convert to the frequency domain, where quantization can be applied only to the signals at active subcarriers. This reduces fronthaul load and avoids unnecessary distortion, since the ADC output spans all OFDM samples while only a subset of subcarriers carries useful information.
  While both quantization effects have been extensively studied in narrowband systems, their joint impact in practical wideband OFDM-based cell-free massive MIMO remains largely unexplored. This paper addresses the gap by modeling the joint distortion and proposing a fronthaul strategy in which each AP processes the received signal to reduce quantization artifacts before transmission. We develop an efficient estimation algorithm that reconstructs the unquantized time-domain signal prior to fronthaul transmission and evaluate its effectiveness. The proposed design offers new insights for implementing efficient, quantization-aware uplink transmission in wideband cell-free architectures.</description>
      <guid isPermaLink="false">oai:arXiv.org:2601.06483v1</guid>
      <category>eess.SP</category>
      <category>cs.IT</category>
      <category>math.IT</category>
      <pubDate>Tue, 13 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>\"Ozlem Tu\u{g}fe Demir, Emil Bj\"ornson</dc:creator>
    </item>
    <item>
      <title>Cell-Free Massive MIMO with Hardware-Impaired Wireless Fronthaul</title>
      <link>https://arxiv.org/abs/2601.06486</link>
      <description>arXiv:2601.06486v1 Announce Type: cross 
Abstract: Cell-free massive MIMO (multiple-input multiple-output) enhances spectral and energy efficiency compared to conventional cellular networks by enabling joint transmission and reception across a large number of distributed access points (APs). Since these APs are envisioned to be low-cost and densely deployed, hardware impairments, stemming from non-ideal radio-frequency (RF) chains, are unavoidable. While existing studies primarily address hardware impairments on the access side, the impact of hardware impairments on the wireless fronthaul link has remained largely unexplored. In this work, we fill this important gap by introducing a novel amplify-and-forward (AF) based wireless fronthauling scheme tailored for cell-free massive MIMO. Focusing on the uplink, we develop an analytical framework that jointly models the hardware impairments at both the APs and the fronthaul transceivers, derives the resulting end-to-end distorted signal expression, and quantifies the individual contribution of each impairment to the spectral efficiency. Furthermore, we design distortion-aware linear combiners that optimally mitigate these effects. Numerical results demonstrate significant performance gains from distortion-aware processing and illustrate the potential of the proposed AF fronthauling scheme as a cost-effective enabler for future cell-free architectures.</description>
      <guid isPermaLink="false">oai:arXiv.org:2601.06486v1</guid>
      <category>eess.SP</category>
      <category>cs.IT</category>
      <category>math.IT</category>
      <pubDate>Tue, 13 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>\"Ozlem Tu\u{g}fe Demir, Emil Bj\"ornson</dc:creator>
    </item>
    <item>
      <title>Non-Abelian qLDPC: TQFT Formalism, Addressable Gauging Measurement and Application to Magic State Fountain on 2D Product Codes</title>
      <link>https://arxiv.org/abs/2601.06736</link>
      <description>arXiv:2601.06736v1 Announce Type: cross 
Abstract: A fundamental problem of fault-tolerant quantum computation with quantum low-density parity-check (qLDPC) codes is the tradeoff between connectivity and universality. It is widely believed that in order to perform native logical non-Clifford gates, one needs to resort to 3D product-code constructions. In this work, we extend Kitaev's framework of non-Abelian topological codes on manifolds to non-Abelian qLDPC codes (realized as Clifford-stabilizer codes) and the corresponding combinatorial topological quantum field theories (TQFT) defined on Poincar\'e CW complexes and certain types of general chain complexes. We also construct the spacetime path integrals as topological invariants on these complexes. Remarkably, we show that native non-Clifford logical gates can be realized using constant-rate 2D hypergraph-product codes and their Clifford-stabilizer variants. This is achieved by a spacetime path integral effectively implementing the addressable gauging measurement of a new type of 0-form subcomplex symmetries, which correspond to addressable transversal Clifford gates and become higher-form symmetries when lifted to higher-dimensional CW complexes or manifolds. Building on this structure, we apply the gauging protocol to the magic state fountain scheme for parallel preparation of $O(\sqrt{n})$ disjoint CZ magic states with code distance of $O(\sqrt{n})$, using a total number of $n$ qubits.</description>
      <guid isPermaLink="false">oai:arXiv.org:2601.06736v1</guid>
      <category>quant-ph</category>
      <category>cond-mat.str-el</category>
      <category>cs.IT</category>
      <category>hep-th</category>
      <category>math-ph</category>
      <category>math.IT</category>
      <category>math.MP</category>
      <pubDate>Tue, 13 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Guanyu Zhu, Ryohei Kobayashi, Po-Shen Hsin</dc:creator>
    </item>
    <item>
      <title>Recovering polynomials over finite fields from noisy character values</title>
      <link>https://arxiv.org/abs/2601.07137</link>
      <description>arXiv:2601.07137v1 Announce Type: cross 
Abstract: Let $g(X)$ be a polynomial over a finite field ${\mathbb F}_q$ with degree $o(q^{1/2})$, and let $\chi$ be the quadratic residue character. We give a polynomial time algorithm to recover $g(X)$ (up to perfect square factors) given the values of $\chi \circ g$ on ${\mathbb F}_q$, with up to a constant fraction of the values having errors. This was previously unknown even for the case of no errors.
  We give a similar algorithm for additive characters of polynomials over fields of characteristic $2$. This gives the first polynomial time algorithm for decoding dual-BCH codes of polynomial dimension from a constant fraction of errors.
  Our algorithms use ideas from Stepanov's polynomial method proof of the classical Weil bounds on character sums, as well as from the Berlekamp-Welch decoding algorithm for Reed-Solomon codes. A crucial role is played by what we call *pseudopolynomials*: high degree polynomials, all of whose derivatives behave like low degree polynomials on ${\mathbb F}_q$.
  Both these results can be viewed as algorithmic versions of the Weil bounds for this setting.</description>
      <guid isPermaLink="false">oai:arXiv.org:2601.07137v1</guid>
      <category>cs.CC</category>
      <category>cs.IT</category>
      <category>math.IT</category>
      <category>math.NT</category>
      <pubDate>Tue, 13 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Swastik Kopparty</dc:creator>
    </item>
    <item>
      <title>Innovation Capacity of Dynamical Learning Systems</title>
      <link>https://arxiv.org/abs/2601.07257</link>
      <description>arXiv:2601.07257v1 Announce Type: cross 
Abstract: In noisy physical reservoirs, the classical information-processing capacity $C_{\mathrm{ip}}$ quantifies how well a linear readout can realize tasks measurable from the input history, yet $C_{\mathrm{ip}}$ can be far smaller than the observed rank of the readout covariance. We explain this ``missing capacity'' by introducing the innovation capacity $C_{\mathrm{i}}$, the total capacity allocated to readout components orthogonal to the input filtration (Doob innovations, including input-noise mixing). Using a basis-free Hilbert-space formulation of the predictable/innovation decomposition, we prove the conservation law $C_{\mathrm{ip}}+C_{\mathrm{i}}=\mathrm{rank}(\Sigma_{XX})\le d$, so predictable and innovation capacities exactly partition the rank of the observable readout dimension covariance $\Sigma_{XX}\in \mathbb{R}^{\rm d\times d}$. In linear-Gaussian Johnson-Nyquist regimes, $\Sigma_{XX}(T)=S+T N_0$, the split becomes a generalized-eigenvalue shrinkage rule and gives an explicit monotone tradeoff between temperature and predictable capacity. Geometrically, in whitened coordinates the predictable and innovation components correspond to complementary covariance ellipsoids, making $C_{\mathrm{i}}$ a trace-controlled innovation budget. A large $C_{\mathrm{i}}$ forces a high-dimensional innovation subspace with a variance floor and under mild mixing and anti-concentration assumptions this yields extensive innovation-block differential entropy and exponentially many distinguishable histories. Finally, we give an information-theoretic lower bound showing that learning the induced innovation-block law in total variation requires a number of samples that scales with the effective innovation dimension, supporting the generative utility of noisy physical reservoirs.</description>
      <guid isPermaLink="false">oai:arXiv.org:2601.07257v1</guid>
      <category>cs.LG</category>
      <category>cs.IT</category>
      <category>math.IT</category>
      <pubDate>Tue, 13 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Anthony M. Polloreno</dc:creator>
    </item>
    <item>
      <title>On the Non-decoupling of Supervised Fine-tuning and Reinforcement Learning in Post-training</title>
      <link>https://arxiv.org/abs/2601.07389</link>
      <description>arXiv:2601.07389v1 Announce Type: cross 
Abstract: Post-training of large language models routinely interleaves supervised fine-tuning (SFT) with reinforcement learning (RL). These two methods have different objectives: SFT minimizes the cross-entropy loss between model outputs and expert responses, while RL maximizes reward signals derived from human preferences or rule-based verifiers. Modern reasoning models have widely adopted the practice of alternating SFT and RL training. However, there is no theoretical account of whether they can be decoupled. We prove that decoupling is impossible in either order: (1) SFT-then-RL coupling: RL increases SFT loss under SFT optimality and (2) RL-then-SFT coupling: SFT lowers the reward achieved by RL. Experiments on Qwen3-0.6B confirm the predicted degradation, verifying that SFT and RL cannot be separated without loss of prior performance in the post-training</description>
      <guid isPermaLink="false">oai:arXiv.org:2601.07389v1</guid>
      <category>cs.LG</category>
      <category>cs.AI</category>
      <category>cs.IT</category>
      <category>math.IT</category>
      <pubDate>Tue, 13 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <dc:creator>Xueyan Niu, Bo Bai, Wei Han, Weixi Zhang</dc:creator>
    </item>
    <item>
      <title>Multiperiodic Processes: Ergodic Sources with a Sublinear Entropy</title>
      <link>https://arxiv.org/abs/2302.09049</link>
      <description>arXiv:2302.09049v4 Announce Type: replace 
Abstract: We construct multiperiodic processes -- a simple example of stationary ergodic (but not mixing) processes over natural numbers that enjoy the vanishing entropy rate under a mild condition. Multiperiodic processes are supported on randomly shifted deterministic sequences called multiperiodic sequences, which can be efficiently generated using an algorithm called the Infinite Clock. Under a suitable parameterization, multiperiodic sequences exhibit relative frequencies of particular numbers given by Zipf's law. Exactly in the same setting, the respective multiperiodic processes satisfy an asymptotic power-law growth of block entropy, called Hilberg's law. Hilberg's law is deemed to hold for statistical language models, in particular.</description>
      <guid isPermaLink="false">oai:arXiv.org:2302.09049v4</guid>
      <category>cs.IT</category>
      <category>cs.LG</category>
      <category>math.IT</category>
      <category>math.ST</category>
      <category>stat.TH</category>
      <pubDate>Tue, 13 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>{\L}ukasz D\k{e}bowski</dc:creator>
    </item>
    <item>
      <title>Faster List Decoding of AG Codes</title>
      <link>https://arxiv.org/abs/2304.07083</link>
      <description>arXiv:2304.07083v2 Announce Type: replace 
Abstract: In this article, we present a fast algorithm performing an instance of the Guruswami-Sudan list decoder for algebraic geometry codes. We show that any such code can be decoded in $\tilde{O}(s^2\ell^{\omega-1}\mu^{\omega-1}(n+g) + \ell^\omega \mu^\omega)$ operations in the underlying finite field, where $n$ is the code length, $g$ is the genus of the function field used to construct the code, $s$ is the multiplicity parameter, $\ell$ is the designed list size and $\mu$ is the smallest positive element in the Weierstrass semigroup of some chosen place.</description>
      <guid isPermaLink="false">oai:arXiv.org:2304.07083v2</guid>
      <category>cs.IT</category>
      <category>cs.SC</category>
      <category>math.IT</category>
      <pubDate>Tue, 13 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <arxiv:DOI>10.1109/TIT.2025.3550750</arxiv:DOI>
      <dc:creator>Peter Beelen, Vincent Neiger</dc:creator>
    </item>
    <item>
      <title>Novel Constructions for Computation and Communication Trade-offs in Private Coded Distributed Computing</title>
      <link>https://arxiv.org/abs/2502.17195</link>
      <description>arXiv:2502.17195v2 Announce Type: replace 
Abstract: Distributed computing enables scalable machine learning by distributing tasks across multiple nodes, but ensuring privacy in such systems remains a challenge. This paper introduces a novel private coded distributed computing model that integrates privacy constraints to keep task assignments hidden. By leveraging placement delivery arrays (PDAs), we design an extended PDA framework to characterize achievable computation and communication loads under privacy constraints. By constructing two classes of extended PDAs, we explore the trade-offs between computation and communication, showing that although privacy increases communication overhead, it can be significantly alleviated through optimized PDA-based coded strategies.</description>
      <guid isPermaLink="false">oai:arXiv.org:2502.17195v2</guid>
      <category>cs.IT</category>
      <category>math.IT</category>
      <pubDate>Tue, 13 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Shanuja Sasi, Onur G\"unl\"u</dc:creator>
    </item>
    <item>
      <title>The LZ78 Source</title>
      <link>https://arxiv.org/abs/2503.10574</link>
      <description>arXiv:2503.10574v3 Announce Type: replace 
Abstract: We study a family of processes generated according to sequential probability assignments induced by the LZ78 universal compressor. We characterize entropic and distributional properties such as their entropy and relative entropy rates, finite-state compressibility and log loss of their realizations, and the empirical distributions that they induce. Though not quite stationary, these sources are "almost stationary and ergodic;" similar to stationary and ergodic processes, they satisfy a Shannon-McMillan-Breiman-type property: the normalized log probability of their realizations converges almost surely to their entropy rate. Further, they are locally "almost i.i.d." in the sense that the finite-dimensional empirical distributions of their realizations converge almost surely to a deterministic i.i.d. law. However, unlike stationary ergodic sources, the finite-state compressibility of their realizations is almost surely strictly larger than their entropy rate by a "Jensen gap". We present simulations demonstrating the theoretical results. These sources allow to gauge the performance of sequential probability models, both classical and deep learning-based, on non-Markovian non-stationary data. As such, we apply realizations of the LZ78 source to the study of in-context learning in transformer models.</description>
      <guid isPermaLink="false">oai:arXiv.org:2503.10574v3</guid>
      <category>cs.IT</category>
      <category>math.IT</category>
      <pubDate>Tue, 13 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Naomi Sagan, Amir Dembo, Matthew Ho, Tsachy Weissman</dc:creator>
    </item>
    <item>
      <title>Secret Sharing in the Rank Metric</title>
      <link>https://arxiv.org/abs/2504.18294</link>
      <description>arXiv:2504.18294v2 Announce Type: replace 
Abstract: The connection between secret sharing and matroid theory is well established. In this paper, we generalize the concepts of secret sharing and matroid ports to $q$-polymatroids. Specifically, we introduce the notion of an access structure on a vector space, and consider properties related to duality, minors, and the relationship to $q$-polymatroids. Finally, we show how rank-metric codes give rise to secret sharing schemes within this framework.</description>
      <guid isPermaLink="false">oai:arXiv.org:2504.18294v2</guid>
      <category>cs.IT</category>
      <category>math.IT</category>
      <pubDate>Tue, 13 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <arxiv:DOI>10.1109/ISIT63088.2025.11195478</arxiv:DOI>
      <arxiv:journal_reference>2025 IEEE International Symposium on Information Theory (ISIT), Ann Arbor, MI, USA, 2025, pp. 1-6</arxiv:journal_reference>
      <dc:creator>Johan Vester Dinesen, Eimear Byrne, Ragnar Freij-Hollanti, Camilla Hollanti</dc:creator>
    </item>
    <item>
      <title>Hierarchical Secure Aggregation with Heterogeneous Security Constraints and Arbitrary User Collusion</title>
      <link>https://arxiv.org/abs/2507.14768</link>
      <description>arXiv:2507.14768v2 Announce Type: replace 
Abstract: In hierarchical secure aggregation (HSA), a server communicates with clustered users through an intermediate layer of relays to compute the sum of users' inputs under two security requirements -- server security and relay security. Server security requires that the server learns nothing beyond the desired sum even when colluding with a subset of users, while relay security requires that each relay remains oblivious to the users' inputs under collusion. Existing work on HSA enforces homogeneous security where \tit{all} inputs must be protected against \tit{any} subset of potential colluding users with sizes up to a predefined threshold. Such a \homo formulation cannot capture scenarios with \tit{\het} \secty \reqs where \diff users may demand various levels of protection.
  In this paper, we study hierarchical secure aggregation (HSA) with heterogeneous security requirements and arbitrary user collusion. Specifically, we consider scenarios where the inputs of certain groups of users must remain information-theoretically secure against inference by the server or any relay, even if the server or any relay colludes with an arbitrary subset of other users. Under server security, the server learns nothing about these protected inputs beyond the prescribed aggregate sum, despite any such collusion. Under relay security, each relay similarly obtains no information about the protected inputs under the same collusion model.
  We characterize the optimal communication rates achievable across all layers for all parameter regimes. Furthermore, we study the minimum source keys required at the users to ensure security. For this source key requirement, we provide tight characterizations in two broad regimes determined by the security and collusion constraints, and establish a general information-theoretic lower bound together with a bounded-gap achievable scheme for the remaining regime.</description>
      <guid isPermaLink="false">oai:arXiv.org:2507.14768v2</guid>
      <category>cs.IT</category>
      <category>cs.CR</category>
      <category>cs.DC</category>
      <category>cs.LG</category>
      <category>math.IT</category>
      <pubDate>Tue, 13 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Zhou Li, Xiang Zhang, Jiawen Lv, Jihao Fan, Haiqiang Chen, Giuseppe Caire</dc:creator>
    </item>
    <item>
      <title>Forget BIT, It is All about TOKEN: Towards Semantic Information Theory for LLMs</title>
      <link>https://arxiv.org/abs/2511.01202</link>
      <description>arXiv:2511.01202v2 Announce Type: replace 
Abstract: Large language models (LLMs) have demonstrated remarkable capabilities in numerous real-world applications. While the vast majority of research conducted from an experimental perspective is progressing rapidly, it demands substantial computational power, data, and other resources. Therefore, how to open the black-box of LLMs from a theoretical standpoint has become a critical challenge. This paper takes the theory of rate-distortion function, directed information, and Granger causality as its starting point to investigate the information-theoretic principles behind LLMs, leading to the development of semantic information theory for LLMs, where the fundamental unit is token, rather than bits that lacks any semantic meaning. By defining the probabilistic model of LLMs, we discuss structure-agnostic information-theoretic measures, such as the directed rate-distortion function in pre-training, the directed rate-reward function in post-training, and the semantic information flow in inference phase. This paper also delves deeply into the theory of token-level semantic embedding and the information-theoretically optimal vectorization method. Thereafter, we propose a general definition of autoregression LLM, where the Transformer architecture and its performance such as ELBO, generalization error bound, memory capacity, and semantic information measures can be derived theoretically. Other architectures, such as Mamba/Mamba2 and LLaDA, are also discussed in our framework. Consequently, this paper provides a theoretical framework for understanding LLMs from the perspective of semantic information theory, which also offers the necessary theoretical tools for further in-depth research.</description>
      <guid isPermaLink="false">oai:arXiv.org:2511.01202v2</guid>
      <category>cs.IT</category>
      <category>cs.AI</category>
      <category>math.IT</category>
      <pubDate>Tue, 13 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Bo Bai</dc:creator>
    </item>
    <item>
      <title>Information-Theoretic Limits on Exact Subgraph Alignment Problem</title>
      <link>https://arxiv.org/abs/2601.05173</link>
      <description>arXiv:2601.05173v2 Announce Type: replace 
Abstract: The graph alignment problem aims to identify the vertex correspondence between two correlated graphs. Most existing studies focus on the scenario in which the two graphs share the same vertex set. However, in many real-world applications, such as computer vision, social network analysis, and bioinformatics, the task often involves locating a small graph pattern within a larger graph. Existing graph alignment algorithms and analysis cannot directly address these scenarios because they are not designed to identify the specific subset of vertices where the small graph pattern resides within the larger graph. Motivated by this limitation, we introduce the subgraph alignment problem, which seeks to recover both the vertex set and/or the vertex correspondence of a small graph pattern embedded in a larger graph. In the special case where the small graph pattern is an induced subgraph of the larger graph and both the vertex set and correspondence are to be recovered, the problem reduces to the subgraph isomorphism problem, which is NP-complete in the worst case. In this paper, we formally formulate the subgraph alignment problem by proposing the Erdos-Renyi subgraph pair model together with some appropriate recovery criterion. We then establish almost-tight information-theoretic results for the subgraph alignment problem and present some novel approaches for the analysis.</description>
      <guid isPermaLink="false">oai:arXiv.org:2601.05173v2</guid>
      <category>cs.IT</category>
      <category>math.IT</category>
      <pubDate>Tue, 13 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Chun Hei Michael Shiu, Hei Victor Cheng, Lele Wang</dc:creator>
    </item>
    <item>
      <title>Coverage and Spectral Efficiency of NOMA-Enabled LEO Satellite Networks with Ordering Schemes</title>
      <link>https://arxiv.org/abs/2501.05946</link>
      <description>arXiv:2501.05946v2 Announce Type: replace-cross 
Abstract: This paper investigates an analytical model for low-earth orbit (LEO) multi-satellite downlink non-orthogonal multiple access (NOMA) networks. The satellites transmit data to multiple NOMA user terminals (UTs), each employing successive interference cancellation (SIC) for decoding. Two ordering schemes are adopted for NOMA-enabled LEO satellite networks, i.e., mean signal power (MSP)-based ordering and instantaneous signal-to-inter-satellite-interference-plus-noise ratio (ISINR)-based ordering. For each ordering scheme, we derive the analytical expression for the coverage probability of each typical UT. Moreover, we discuss how coverage is influenced by SIC, main-lobe gain, and tradeoffs between the number of satellites and their altitudes. Additionally, two user fairness-based power allocation (PA) schemes are considered, and PA coefficients with the optimal number of UTs that maximize their sum spectral efficiency (SE) are studied. Simulation results show that there exists a maximum effective signal-to-inter-satellite-interference-plus-noise ratio (SINR) threshold for each PA scheme that ensures the operation of NOMA in LEO satellite networks, and NOMA provides performance gains only when the target SINR is below a certain threshold. Compared with orthogonal multiple access (OMA), NOMA increases UTs' sum SE by as much as 35%. Furthermore, for most SINR thresholds, the sum SE increases with the number of UTs to the highest value, whilst the maximum sum SE is obtained when there are two UTs.</description>
      <guid isPermaLink="false">oai:arXiv.org:2501.05946v2</guid>
      <category>eess.SP</category>
      <category>cs.IT</category>
      <category>cs.SY</category>
      <category>eess.SY</category>
      <category>math.IT</category>
      <pubDate>Tue, 13 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Xiangyu Li, Bodong Shang, Qingqing Wu, Chao Ren</dc:creator>
    </item>
    <item>
      <title>A new measure of dependence: Integrated $R^2$</title>
      <link>https://arxiv.org/abs/2505.18146</link>
      <description>arXiv:2505.18146v5 Announce Type: replace-cross 
Abstract: We introduce a novel measure of dependence that captures the extent to which a random variable $Y$ is determined by a random vector $X$. The measure equals zero precisely when $Y$ and $X$ are independent, and it attains one exactly when $Y$ is almost surely a measurable function of $X$. We further extend this framework to define a measure of conditional dependence between $Y$ and $X$ given $Z$. We propose a simple and interpretable estimator with computational complexity comparable to classical correlation coefficients, including those of Pearson, Spearman, and Chatterjee. Leveraging this dependence measure, we develop a tuning-free, model-agnostic variable selection procedure and establish its consistency under appropriate sparsity conditions. Extensive experiments on synthetic and real datasets highlight the strong empirical performance of our methodology and demonstrate substantial gains over existing approaches.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.18146v5</guid>
      <category>math.ST</category>
      <category>cs.IT</category>
      <category>math.IT</category>
      <category>math.PR</category>
      <category>stat.ME</category>
      <category>stat.TH</category>
      <pubDate>Tue, 13 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Mona Azadkia, Pouya Roudaki</dc:creator>
    </item>
    <item>
      <title>Efficient Online Random Sampling via Randomness Recycling</title>
      <link>https://arxiv.org/abs/2505.18879</link>
      <description>arXiv:2505.18879v3 Announce Type: replace-cross 
Abstract: This article studies the fundamental problem of using i.i.d. coin tosses from an entropy source to efficiently generate random variables $X_i \sim P_i$ $(i \ge 1)$, where $(P_1, P_2, \dots)$ is a random sequence of rational discrete probability distributions subject to an \textit{arbitrary} stochastic process. Our method achieves an amortized expected entropy cost within $\varepsilon &gt; 0$ bits of the information-theoretically optimal Shannon lower bound using $O(\log(1/\varepsilon))$ space. This result holds both pointwise in terms of the Shannon information content conditioned on $X_i$ and $P_i$, and in expectation to obtain a rate of $\mathbb{E}[H(P_1) + \dots + H(P_n)]/n + \varepsilon$ bits per sample as $n \to \infty$ (where $H$ is the Shannon entropy). The combination of space, time, and entropy properties of our method improves upon the Knuth and Yao (1976) entropy-optimal algorithm and Han and Hoshi (1997) interval algorithm for online sampling, which require unbounded space. It also uses exponentially less space than the more specialized methods of Kozen and Soloviev (2022) and Shao and Wang (2025) that generate i.i.d. samples from a fixed distribution. Our online sampling algorithm rests on a powerful algorithmic technique called \textit{randomness recycling}, which reuses a fraction of the random information consumed by a probabilistic algorithm to reduce its amortized entropy cost.
  On the practical side, we develop randomness recycling techniques to accelerate a variety of prominent sampling algorithms. We show that randomness recycling enables state-of-the-art runtime performance on the Fisher-Yates shuffle when using a cryptographically secure pseudorandom number generator, and that it reduces the entropy cost of discrete Gaussian sampling. Accompanying the manuscript is a performant software library in the C programming language.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.18879v3</guid>
      <category>cs.DS</category>
      <category>cs.DM</category>
      <category>cs.IT</category>
      <category>math.IT</category>
      <category>math.PR</category>
      <category>stat.CO</category>
      <pubDate>Tue, 13 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <arxiv:DOI>10.1137/1.9781611978971.89</arxiv:DOI>
      <arxiv:journal_reference>Proceedings of the 2026 Annual ACM-SIAM Symposium on Discrete Algorithms (SODA), pp. 2473-2511. Society for Industrial and Applied Mathematics, 2026</arxiv:journal_reference>
      <dc:creator>Thomas L. Draper, Feras A. Saad</dc:creator>
    </item>
    <item>
      <title>Advances in the Shannon Capacity of Graphs</title>
      <link>https://arxiv.org/abs/2509.24600</link>
      <description>arXiv:2509.24600v2 Announce Type: replace-cross 
Abstract: We derive exact values and new bounds for the Shannon capacity of two families of graphs: the $q$-Kneser graphs and the tadpole graphs. We also construct a countably infinite family of connected graphs whose Shannon capacity is not attained by the independence number of any finite strong power. Building on recent work of Schrijver, we establish sufficient conditions under which the Shannon capacity of a polynomial in graphs, formed via disjoint unions and strong products, equals the corresponding polynomial of the individual capacities, thereby reducing the evaluation of such capacities to that of their components. Finally, we prove an inequality relating the Shannon capacities of the strong product of graphs and their disjoint union, which yields streamlined proofs of several known bounds. In addition to contributing to the computation of the Shannon capacity of graphs, this paper is intended to serve as an accessible entry point to those wishing to work in this area.</description>
      <guid isPermaLink="false">oai:arXiv.org:2509.24600v2</guid>
      <category>math.CO</category>
      <category>cs.IT</category>
      <category>math.IT</category>
      <pubDate>Tue, 13 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Nitay Lavi, Igal Sason</dc:creator>
    </item>
    <item>
      <title>Characterizing Agent-Based Model Dynamics via $\epsilon$-Machines and Kolmogorov-Style Complexity</title>
      <link>https://arxiv.org/abs/2510.12729</link>
      <description>arXiv:2510.12729v3 Announce Type: replace-cross 
Abstract: We propose a two-level information-theoretic framework for characterizing the informational organization of Agent-Based Model (ABM) dynamics within the broader paradigm of Complex Adaptive Systems (CAS). At the macro level, a pooled $\varepsilon$-machine is reconstructed as a reference model summarizing the system-wide informational regime. At the micro level, $\varepsilon$-machines are reconstructed for each caregiver--elder dyad and variable, complemented by algorithm-agnostic Kolmogorov-style measures, including normalized LZ78 complexity and bits per symbol from lossless compression. The resulting feature set, $\{h_{\mu}, C_{\mu}, E, \mathrm{LZ78}, \mathrm{bps}\}$, enables distributional analysis, stratified comparisons, and unsupervised clustering across agents and scenarios. Empirical results show that coupling $\varepsilon$-machines with compression diagnostics yields a coherent picture of where predictive information resides in the caregiving ABM. Global reconstructions provide a memoryless baseline ($L{=}0$ under coarse symbolizations), whereas per-dyad models reveal localized structure, particularly for walkability under ordinal encodings ($m{=}3$). Compression metrics corroborate these patterns: dictionary compressors agree on algorithmic redundancy, while normalized LZ78 captures statistical novelty. Socioeconomic variables display cross-sectional heterogeneity and near-memoryless dynamics, whereas spatial interaction induces bounded temporal memory and recurrent regimes. The framework thus distinguishes semantic organization (predictive causation and memory) from syntactic simplicity (description length) and clarifies how emergence manifests at different system layers. It is demonstrated on a caregiver--elder case study with dyad-level $\varepsilon$-machine reconstructions and compression-based diagnostics.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.12729v3</guid>
      <category>cs.MA</category>
      <category>cs.IT</category>
      <category>math.IT</category>
      <pubDate>Tue, 13 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Roberto Garrone (University of Milano-Bicocca)</dc:creator>
    </item>
    <item>
      <title>Low-Complexity Monitoring and Compensation of Transceiver IQ Imbalance by Multi-dimensional Architecture for Dual-Polarization 16 Quadrature Amplitude Modulation</title>
      <link>https://arxiv.org/abs/2512.13266</link>
      <description>arXiv:2512.13266v2 Announce Type: replace-cross 
Abstract: In this paper, a low-complexity multi-dimensional architecture for IQ imbalance compensation is proposed, which reduces the effects of in-phase (I) and quadrature (Q) imbalance. The architecture use a transceiver IQ skew estimation structure to compensate for IQ skew, and then use a low-complexity MIMO equalizer to compensate for IQ amplitude/phase imbalance. In the transceiver IQ skew estimation structure, the receiver(RX) IQ skew is estimated by Gardner's phase detector, and the transmitter TX skew is estimated by finding the value that yields the lowest equalizer error. The low-complexity MIMO equalizer consists of a complex-valued MIMO (CV-MIMO) and a two-layer multimodulus algorithm real-valued MIMO (TMMA-RV-MIMO), which employ a butterfly and a non-butterfly structure, respectively. The CV-MIMO is used to perform polarization demultiplexing and the TMMA-RV-MIMO equalizes each of the two polarizations. In addition, the TMMA-RV-MIMO can recovery the carrier phase. A 100 km transmission simulation and experiment with 36 Gbaud dual-polarization 16 quadrature amplitude modulation (DP-16QAM) signals showed that, with the TX/RX IQ skew estimation, the estimation error is less than 0.9/0.25 ps. The low-complexity MIMO equalizer can tolerate 0.1 TX IQ amplitude imbalance and 5 degrees at a 0.3 dB Q-factor penalty. The number of real multiplications is reduced by 55% compared with conventional cases in total.</description>
      <guid isPermaLink="false">oai:arXiv.org:2512.13266v2</guid>
      <category>cs.NI</category>
      <category>cs.IT</category>
      <category>math.IT</category>
      <pubDate>Tue, 13 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Yukun Zhang, Xiaoxue Gong, Xu Zhang, Lei Guo</dc:creator>
    </item>
    <item>
      <title>Modern Neuromorphic AI: From Intra-Token to Inter-Token Processing</title>
      <link>https://arxiv.org/abs/2601.00245</link>
      <description>arXiv:2601.00245v3 Announce Type: replace-cross 
Abstract: The rapid growth of artificial intelligence (AI) has brought novel data processing and generative capabilities but also escalating energy requirements. This challenge motivates renewed interest in neuromorphic computing principles, which promise brain-like efficiency through discrete and sparse activations, recurrent dynamics, and non-linear feedback. In fact, modern AI architectures increasingly embody neuromorphic principles through heavily quantized activations, state-space dynamics, and sparse attention mechanisms. This paper elaborates on the connections between neuromorphic models, state-space models, and transformer architectures through the lens of the distinction between intra-token processing and inter-token processing. Most early work on neuromorphic AI was based on spiking neural networks (SNNs) for intra-token processing, i.e., for transformations involving multiple channels, or features, of the same vector input, such as the pixels of an image. In contrast, more recent research has explored how neuromorphic principles can be leveraged to design efficient inter-token processing methods, which selectively combine different information elements depending on their contextual relevance. Implementing associative memorization mechanisms, these approaches leverage state-space dynamics or sparse self-attention. Along with a systematic presentation of modern neuromorphic AI models through the lens of intra-token and inter-token processing, training methodologies for neuromorphic AI models are also reviewed. These range from surrogate gradients leveraging parallel convolutional processing to local learning rules based on reinforcement learning mechanisms.</description>
      <guid isPermaLink="false">oai:arXiv.org:2601.00245v3</guid>
      <category>cs.NE</category>
      <category>cs.IT</category>
      <category>cs.LG</category>
      <category>math.IT</category>
      <pubDate>Tue, 13 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Osvaldo Simeone</dc:creator>
    </item>
  </channel>
</rss>
