<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>math.NA updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/math.NA</link>
    <description>math.NA updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/math.NA" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Fri, 24 Oct 2025 04:01:00 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Fri, 24 Oct 2025 00:00:00 -0400</pubDate>
    <skipDays>
      <day>Saturday</day>
      <day>Sunday</day>
    </skipDays>
    <item>
      <title>Computing excited states with isometric tensor networks in two-dimensions</title>
      <link>https://arxiv.org/abs/2510.20063</link>
      <description>arXiv:2510.20063v1 Announce Type: new 
Abstract: We present a new subspace iteration method for computing low-lying eigenpairs (excited states) of high-dimensional quantum many-body Hamiltonians with nearest neighbor interactions on two-dimensional lattices. The method is based on a new block isometric projected entangled pair state (block-isoPEPS) ansatz that generalizes the block matrix product state (MPS) framework, widely used for Hamiltonians defined on one-dimensional chains, to two-dimensions. The proposed block-isoPEPS ansatz offers several attractive features for PEPS-based algorithms, including exact block orthogonalization, controlled local truncation via singular value decompositions, and efficient evaluation of observables. We demonstrate the proposed inexact subspace iteration for block-isoPEPS by computing excitations of the two-dimensional transverse-field Ising and Heisenberg models and compare our results with existing PEPS methods. Our results demonstrate that block isometric tensor networks provide a scalable framework for studying excitations in quantum many-body systems beyond one dimension.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.20063v1</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <pubDate>Fri, 24 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Alec Dektor, Runze Chi, Roel Van Beeumen, Chao Yang</dc:creator>
    </item>
    <item>
      <title>Minimizing Residuals in ODE Integration Using Optimal Control</title>
      <link>https://arxiv.org/abs/2510.20117</link>
      <description>arXiv:2510.20117v1 Announce Type: new 
Abstract: Given the set of discrete solution points or nodes, called the skeleton, generated by an ODE solver, we study the problem of fitting a curve passing through the nodes in the skeleton minimizing a norm of the residual vector of the ODE. We reformulate this interpolation problem as a multi-stage optimal control problem and, for the minimization of two different norms, we apply the associated maximum principle to obtain the necessary conditions of optimality. We solve the problem analytically for the Dahlquist test problem and a variant of the leaky bucket problem, in terms of the given skeleton. We also consider the Van der Pol equation, for which we obtain interpolating curves with minimal residual norms by numerically solving a direct discretization of the problem through optimization software. With the skeletons obtained by various ODE solvers of MATLAB, we make comparisons between the residuals obtained by our approach and those obtained by the MATLAB function deval.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.20117v1</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <pubDate>Fri, 24 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-sa/4.0/</dc:rights>
      <dc:creator>Robert M. Corless, C. Yal\c{c}{\i}n Kaya</dc:creator>
    </item>
    <item>
      <title>Joint Signal Recovery and Uncertainty Quantification via the Residual Prior Transform</title>
      <link>https://arxiv.org/abs/2510.20136</link>
      <description>arXiv:2510.20136v1 Announce Type: new 
Abstract: Conventional priors used for signal recovery are often limited by the assumption that the type of a signal's variability, such as piecewise constant or linear behavior, is known and fixed. This assumption is problematic for complex signals that exhibit different behaviors across the domain. The recently developed {\em residual transform operator} effectively reduces such variability-dependent error within the LASSO regression framework. Importantly, it does not require prior information regarding structure of the underlying signal. This paper reformulates the residual transform operator into a new prior within a hierarchical Bayesian framework. In so doing, it unlocks two powerful new capabilities. First, it enables principled uncertainty quantification, providing robust credible intervals for the recovered signal, and second, it provides a natural framework for the joint recovery of signals from multimodal measurements by coherently fusing information from disparate data sources. Numerical experiments demonstrate that the residual prior yields high-fidelity signal and image recovery from multimodal data while providing robust uncertainty quantification.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.20136v1</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <pubDate>Fri, 24 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Yao Xiao, Anne Gelb</dc:creator>
    </item>
    <item>
      <title>General transformation neural networks: A class of parametrized functions for high-dimensional function approximation</title>
      <link>https://arxiv.org/abs/2510.20142</link>
      <description>arXiv:2510.20142v1 Announce Type: new 
Abstract: We propose a novel class of neural network-like parametrized functions, i.e., general transformation neural networks (GTNNs), for high-dimensional approximation. Conventional deep neural networks sometimes perform less accurately in approximation problems under gradient descent training, especially when the target function is oscillatory. To improve accuracy, we generalize the affine transformation of the abstract neuron to more general functions, which act as complex shape functions and have larger capacities. Specifically, we introduce two types of GTNNs: the cubic and quadratic transformation neural networks (CTNNs and QTNNs). We perform approximation error analysis for CTNNs and QTNNs, presenting their universal approximation properties for continuous functions and error bounds for smooth functions and Barron-type functions. Several numerical examples of regression problems and partial differential equations are presented, demonstrating that CTNNs/QTNNs have advantages in accuracy and robustness over conventional fully connected neural networks.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.20142v1</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <pubDate>Fri, 24 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Xiaoyang Wang, Yiqi Gu</dc:creator>
    </item>
    <item>
      <title>IEnSF: Iterative Ensemble Score Filter for Reducing Error in Posterior Score Estimation in Nonlinear Data Assimilation</title>
      <link>https://arxiv.org/abs/2510.20159</link>
      <description>arXiv:2510.20159v1 Announce Type: new 
Abstract: The Ensemble Score Filter (EnSF) has emerged as a promising approach to leverage score-based diffusion models for solving high-dimensional and nonlinear data assimilation problems. While initial applications of EnSF to the Lorenz-96 model and the quasi-geostrophic system showed potential, the current method employs a heuristic weighted sum to combine the prior and the likelihood score functions. This introduces a structural error into the estimation of the posterior score function in the nonlinear setting. This work addresses this challenge by developing an iterative ensemble score filter (IEnSF) that applies an iterative algorithm as an outer loop around the reverse-time stochastic differential equation solver. When the state dynamics or the observation operator is nonlinear, the iterative algorithm can gradually reduce the posterior score estimation error by improving the accuracy of approximating the conditional expectation of the likelihood score function. The number of iterations required depends on the distance between the prior and posterior distributions and the nonlinearity of the observation operator. Numerical experiments demonstrate that the IEnSF algorithm substantially reduces the error in posterior score estimation in the nonlinear setting and thus improves the accuracy of tracking high-dimensional dynamical systems.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.20159v1</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <pubDate>Fri, 24 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Zezhong Zhang, Feng Bao, Guannan Zhang</dc:creator>
    </item>
    <item>
      <title>Anderson-type acceleration method for Deep Neural Network optimization</title>
      <link>https://arxiv.org/abs/2510.20254</link>
      <description>arXiv:2510.20254v1 Announce Type: new 
Abstract: In this paper we consider the neural network optimization for DNN. We develop Anderson-type acceleration method for the stochastic gradient decent method and it improves the network permanence very much. We demonstrate the applicability of the method for DNN and CNN. We discuss the application of the general class of the neural network design for computer tomography and inverse medium problems.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.20254v1</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <category>math.OC</category>
      <pubDate>Fri, 24 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Kazufumi Ito, Tiancheng Xue</dc:creator>
    </item>
    <item>
      <title>Unique continuation for the wave equation: the stability landscape</title>
      <link>https://arxiv.org/abs/2510.20359</link>
      <description>arXiv:2510.20359v1 Announce Type: new 
Abstract: We consider a unique continuation problem for the wave equation given data in a volumetric subset of the space time domain. In the absence of data on the lateral boundary of the space-time cylinder we prove that the solution can be continued with H\"older stability into a certain proper subset of the space-time domain. Additionally, we show that unique continuation of the solution to the entire space-time cylinder with Lipschitz stability is possible given the knowledge of a suitable finite dimensional space in which the trace of the solution on the lateral boundary is contained. These results allow us to design a finite element method that provably converges to the exact solution at a rate that mirrors the stability properties of the continuous problem.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.20359v1</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <category>math.AP</category>
      <pubDate>Fri, 24 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Erik Burman, Lauri Oksanen, Janosch Preuss, Ziyao Zhao</dc:creator>
    </item>
    <item>
      <title>Improving the accuracy of meshless methods via resolving power optimisation using multiple kernels</title>
      <link>https://arxiv.org/abs/2510.20365</link>
      <description>arXiv:2510.20365v1 Announce Type: new 
Abstract: Meshless methods are commonly used to determine numerical solutions to partial differential equations (PDEs) for problems involving free surfaces and/or complex geometries, approximating spatial derivatives at collocation points via local kernels with a finite size. Despite their common use in turbulent flow simulations, the accuracy of meshless methods has typically been assessed using their convergence characteristics resulting from the polynomial consistency of approximations to operators, with little to no attention paid to the resolving power of the approximation. Here we provide a framework for the optimisation of resolving power by exploiting the non-uniqueness of kernels to provide improvements to numerical approximations of spatial derivatives. We first demonstrate that, unlike in finite-difference approximations, the resolving power of meshless methods is dependent not only on the magnitude of the wavenumber, but also its orientation, before using linear combinations of kernels to maximise resolving power over a range of wavenumbers. The new approach shows improved accuracy in convergence tests and has little impact on stability of time-dependent problems for a range of Eulerian meshless methods. Solutions to a variety of PDE systems are computed, with significant gains in accuracy for no extra computational cost per timestep in Eulerian frameworks. The improved resolution characteristics provided by the optimisation procedure presented herein enable accurate simulation of systems of PDEs whose solution contains short spatial scales such as flow fields with homogeneous isotropic turbulence.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.20365v1</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <category>physics.flu-dyn</category>
      <pubDate>Fri, 24 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>H. Broadley, J. R. C. King, S. J. Lind</dc:creator>
    </item>
    <item>
      <title>Projecting onto the Unit Dual Quaternion Set</title>
      <link>https://arxiv.org/abs/2510.20425</link>
      <description>arXiv:2510.20425v1 Announce Type: new 
Abstract: Dual quaternions have gained significant attention due to their wide applications in areas such as multi-agent formation control, 3D motion modeling, and robotics. A fundamental aspect in dual quaternion research involves the projection onto unit dual quaternion sets. In this paper, we systematically study such projections under the $2^R$-norm, which is commonly used in practical applications. We identify several distinct cases based on the relationship between the standard and dual parts in vector form, and demonstrate the effectiveness of the proposed algorithm through numerical experiments.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.20425v1</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <pubDate>Fri, 24 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Ziyang Li, Chunfeng Cui, Jiaxin Xie</dc:creator>
    </item>
    <item>
      <title>Preconditioning of a pollution-free discretization of the Helmholtz equation</title>
      <link>https://arxiv.org/abs/2510.20564</link>
      <description>arXiv:2510.20564v1 Announce Type: new 
Abstract: We present a pollution-free first order system least squares (FOSLS) formulation for the Helmholtz equation, solved iteratively using a block preconditioner. This preconditioner consists of two components: one for the Schur complement, which corresponds to a preconditioner on $L_2(\Omega)$, and another defined on the test space, which we ensure remains Hermitian positive definite using subspace correction techniques. The proposed method is easy to implement and is directly applicable to general domains, including scattering problems. Numerical experiments demonstrate a linear dependence of the number of MINRES iterations on the wave number $\kappa$. We also introduce an approach to estimate algebraic errors which prevents unnecessary iterations.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.20564v1</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <pubDate>Fri, 24 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Harald Monsuur</dc:creator>
    </item>
    <item>
      <title>Advancing Offshore Renewable Energy: Techno-Economic and Dynamic Performance of Hybrid Wind-Wave Systems</title>
      <link>https://arxiv.org/abs/2510.20601</link>
      <description>arXiv:2510.20601v1 Announce Type: new 
Abstract: Offshore wind and wave energy offer high energy density and availability. While offshore wind has matured significantly, wave energy remains costly and under development. Integrating both technologies into a hybrid system can enhance power generation, stabilize output, and reduce costs. This study explores the benefits of combining an offshore floating wind turbine with the two-body heaving point absorber wave energy converter, Reference Model 3 (RM3). Six configurations are analyzed: RM3 integrated with the National Renewable Energy Laboratory 5 MW and the International Energy Agency 15 MW wind turbines, each tested on both spar and semi-submersible platforms. The analysis examines dynamic response, mooring loads, and power production under varying environmental conditions, considering the influence of the wave energy converter float motion and an optional reaction plate. Results indicate that the reaction plate improves damping for the spar platform, enhancing wave energy absorption and power output. A comparative analysis indicates that integrating the wave energy converter reduces its levelized cost of energy by 15-83%, while leaving the wind turbine levelized cost of energy unaffected. Hybridization significantly reduces power fluctuations by 50%, reduces the levelized cost of energy with the 5 MW wind turbine, and slightly increases it with the 15 MW wind turbine. The results highlight a mutualistic relationship between the wave energy converter and the offshore wind turbine, where the former benefits substantially while the latter experiences slight improvements or negligible effects. Additional findings quantify hydrodynamic interactions, mooring performance, and economic feasibility. This research provides insights into optimizing hybrid offshore renewable systems, demonstrating their potential to lower costs and support sustainable energy solutions.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.20601v1</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <pubDate>Fri, 24 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Alaa Ahmed, Maha N. Haji</dc:creator>
    </item>
    <item>
      <title>Well-Posedness and Approximation of Weak Solutions to Time Dependent Maxwell's Equations with $L^2$-Data</title>
      <link>https://arxiv.org/abs/2510.20752</link>
      <description>arXiv:2510.20752v1 Announce Type: new 
Abstract: We study Maxwell's equations in conducting media with perfectly conducting boundary conditions on Lipschitz domains, allowing rough material coefficients and $L^2$-data. Our first contribution is a direct proof of well-posedness of the first-order weak formulation, including solution existence and uniqueness, an energy identity, and continuous dependence on the data. The argument uses interior-in-time mollification to show uniqueness while avoiding reflection techniques. Existence is via the well-known Galerkin method (cf.~Duvaut and Lions \cite[Eqns.~(4.31)--(4.32), p.~346; Thm.~4.1]{GDuvaut_JLLions_1976a}). For completeness, and to make the paper self-contained, a complete proof has been provided.
  Our second contribution is a structure-preserving semi-discrete finite element method based on the N\'ed\'elec/Raviart--Thomas de Rham complex. The scheme preserves a discrete Gauss law for all times and satisfies a continuous-in-time energy identity with stability for nonnegative conductivity. With a divergence-free initialization of the magnetic field (via potential reconstruction or constrained $L^2$ projection), we prove convergence of the semi-discrete solutions to the unique weak solution as the mesh is refined. The analysis mostly relies on projector consistency, weak-* compactness in time-bounded $L^2$ spaces, and identification of time derivatives in dual spaces.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.20752v1</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <category>math.AP</category>
      <category>physics.comp-ph</category>
      <pubDate>Fri, 24 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Harbir Antil</dc:creator>
    </item>
    <item>
      <title>FINDER: Feature Inference on Noisy Datasets using Eigenspace Residuals</title>
      <link>https://arxiv.org/abs/2510.19917</link>
      <description>arXiv:2510.19917v1 Announce Type: cross 
Abstract: ''Noisy'' datasets (regimes with low signal to noise ratios, small sample sizes, faulty data collection, etc) remain a key research frontier for classification methods with both theoretical and practical implications. We introduce FINDER, a rigorous framework for analyzing generic classification problems, with tailored algorithms for noisy datasets. FINDER incorporates fundamental stochastic analysis ideas into the feature learning and inference stages to optimally account for the randomness inherent to all empirical datasets. We construct ''stochastic features'' by first viewing empirical datasets as realizations from an underlying random field (without assumptions on its exact distribution) and then mapping them to appropriate Hilbert spaces. The Kosambi-Karhunen-Lo\'eve expansion (KLE) breaks these stochastic features into computable irreducible components, which allow classification over noisy datasets via an eigen-decomposition: data from different classes resides in distinct regions, identified by analyzing the spectrum of the associated operators. We validate FINDER on several challenging, data-deficient scientific domains, producing state of the art breakthroughs in: (i) Alzheimer's Disease stage classification, (ii) Remote sensing detection of deforestation. We end with a discussion on when FINDER is expected to outperform existing methods, its failure modes, and other limitations.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.19917v1</guid>
      <category>cs.LG</category>
      <category>cs.CV</category>
      <category>cs.NA</category>
      <category>math.NA</category>
      <pubDate>Fri, 24 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-sa/4.0/</dc:rights>
      <dc:creator>Trajan Murphy, Akshunna S. Dogra, Hanfeng Gu, Caleb Meredith, Mark Kon, Julio Enrique Castrillion-Candas</dc:creator>
    </item>
    <item>
      <title>Enhanced Cyclic Coordinate Descent Methods for Elastic Net Penalized Linear Models</title>
      <link>https://arxiv.org/abs/2510.19999</link>
      <description>arXiv:2510.19999v1 Announce Type: cross 
Abstract: We present a novel enhanced cyclic coordinate descent (ECCD) framework for solving generalized linear models with elastic net constraints that reduces training time in comparison to existing state-of-the-art methods. We redesign the CD method by performing a Taylor expansion around the current iterate to avoid nonlinear operations arising in the gradient computation. By introducing this approximation, we are able to unroll the vector recurrences occurring in the CD method and reformulate the resulting computations into more efficient batched computations. We show empirically that the recurrence can be unrolled by a tunable integer parameter, $s$, such that $s &gt; 1$ yields performance improvements without affecting convergence, whereas $s = 1$ yields the original CD method. A key advantage of ECCD is that it avoids the convergence delay and numerical instability exhibited by block coordinate descent. Finally, we implement our proposed method in C++ using Eigen to accelerate linear algebra computations. Comparison of our method against existing state-of-the-art solvers shows consistent performance improvements of $3\times$ in average for regularization path variant on diverse benchmark datasets. Our implementation is available at https://github.com/Yixiao-Wang-Stats/ECCD.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.19999v1</guid>
      <category>stat.ML</category>
      <category>cs.LG</category>
      <category>cs.MS</category>
      <category>cs.NA</category>
      <category>math.NA</category>
      <category>stat.AP</category>
      <pubDate>Fri, 24 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Yixiao Wang, Zishan Shao, Ting Jiang, Aditya Devarakonda</dc:creator>
    </item>
    <item>
      <title>Simultaneously Solving Infinitely Many LQ Mean Field Games In Hilbert Spaces: The Power of Neural Operators</title>
      <link>https://arxiv.org/abs/2510.20017</link>
      <description>arXiv:2510.20017v1 Announce Type: cross 
Abstract: Traditional mean-field game (MFG) solvers operate on an instance-by-instance basis, which becomes infeasible when many related problems must be solved (e.g., for seeking a robust description of the solution under perturbations of the dynamics or utilities, or in settings involving continuum-parameterized agents.). We overcome this by training neural operators (NOs) to learn the rules-to-equilibrium map from the problem data (``rules'': dynamics and cost functionals) of LQ MFGs defined on separable Hilbert spaces to the corresponding equilibrium strategy. Our main result is a statistical guarantee: an NO trained on a small number of randomly sampled rules reliably solves unseen LQ MFG variants, even in infinite-dimensional settings. The number of NO parameters needed remains controlled under appropriate rule sampling during training.
  Our guarantee follows from three results: (i) local-Lipschitz estimates for the highly nonlinear rules-to-equilibrium map; (ii) a universal approximation theorem using NOs with a prespecified Lipschitz regularity (unlike traditional NO results where the NO's Lipschitz constant can diverge as the approximation error vanishes); and (iii) new sample-complexity bounds for $L$-Lipschitz learners in infinite dimensions, directly applicable as the Lipschitz constants of our approximating NOs are controlled in (ii).</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.20017v1</guid>
      <category>math.OC</category>
      <category>cs.LG</category>
      <category>cs.NA</category>
      <category>math.NA</category>
      <category>math.PR</category>
      <category>q-fin.MF</category>
      <pubDate>Fri, 24 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Dena Firoozi, Anastasis Kratsios, Xuwei Yang</dc:creator>
    </item>
    <item>
      <title>On Encoding Matrices using Quantum Circuits</title>
      <link>https://arxiv.org/abs/2510.20030</link>
      <description>arXiv:2510.20030v1 Announce Type: cross 
Abstract: Over a decade ago, it was demonstrated that quantum computing has the potential to revolutionize numerical linear algebra by enabling algorithms with complexity superior to what is classically achievable, e.g., the seminal HHL algorithm for solving linear systems. Efficient execution of such algorithms critically depends on representing inputs (matrices and vectors) as quantum circuits that encode or implement these inputs. For that task, two common circuit representations emerged in the literature: block encodings and state preparation circuits. In this paper, we systematically study encodings matrices in the form of block encodings and state preparation circuits. We examine methods for constructing these representations from matrices given in classical form, as well as quantum two-way conversions between circuit representations. Two key results we establish (among others) are: (a) a general method for efficiently constructing a block encoding of an arbitrary matrix given in classical form (entries stored in classical random access memory); and (b) low-overhead, bidirectional conversion algorithms between block encodings and state preparation circuits, showing that these models are essentially equivalent. From a technical perspective, two central components of our constructions are: (i) a special constant-depth multiplexer that simultaneously multiplexes all higher-order Pauli matrices of a given size, and (ii) an algorithm for performing a quantum conversion between a matrix's expansion in the standard basis and its expansion in the basis of higher-order Pauli matrices.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.20030v1</guid>
      <category>quant-ph</category>
      <category>cs.LG</category>
      <category>cs.NA</category>
      <category>math.NA</category>
      <pubDate>Fri, 24 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Liron Mor Yosef, Haim Avron</dc:creator>
    </item>
    <item>
      <title>Interpolatory Approximations of PMU Data: Dimension Reduction and Pilot Selection</title>
      <link>https://arxiv.org/abs/2510.20116</link>
      <description>arXiv:2510.20116v1 Announce Type: cross 
Abstract: This work investigates the reduction of phasor measurement unit (PMU) data through low-rank matrix approximations. To reconstruct a PMU data matrix from fewer measurements, we propose the framework of interpolatory matrix decompositions (IDs). In contrast to methods relying on principal component analysis or singular value decomposition, IDs recover the complete data matrix using only a few of its rows (PMU datastreams) and/or a few of its columns (snapshots in time). This compression enables the real-time monitoring of power transmission systems using a limited number of measurements, thereby minimizing communication bandwidth. The ID perspective gives a rigorous error bound on the quality of the data compression. We propose selecting rows and columns used in an ID via the discrete empirical interpolation method (DEIM), a greedy algorithm that aims to control the error bound. This bound leads to a computable estimate for the reconstruction error during online operations. A violation of this estimate suggests a change in the system's operating conditions, and thus serves as a tool for fault detection. Numerical tests using synthetic PMU data illustrate DEIM's excellent performance for data compression, and validate the proposed DEIM-based fault-detection method.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.20116v1</guid>
      <category>eess.SY</category>
      <category>cs.NA</category>
      <category>cs.SY</category>
      <category>eess.SP</category>
      <category>math.NA</category>
      <pubDate>Fri, 24 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Sean Reiter, Mark Embree, Serkan Gugercin, Vassilis Kekatos</dc:creator>
    </item>
    <item>
      <title>Alternatives to the Laplacian for Scalable Spectral Clustering with Group Fairness Constraints</title>
      <link>https://arxiv.org/abs/2510.20220</link>
      <description>arXiv:2510.20220v1 Announce Type: cross 
Abstract: Recent research has focused on mitigating algorithmic bias in clustering by incorporating fairness constraints into algorithmic design. Notions such as disparate impact, community cohesion, and cost per population have been implemented to enforce equitable outcomes. Among these, group fairness (balance) ensures that each protected group is proportionally represented within every cluster. However, incorporating balance as a metric of fairness into spectral clustering algorithms has led to computational times that can be improved. This study aims to enhance the efficiency of spectral clustering algorithms by reformulating the constrained optimization problem using a new formulation derived from the Lagrangian method and the Sherman-Morrison-Woodbury (SMW) identity, resulting in the Fair-SMW algorithm. Fair-SMW employs three alternatives to the Laplacian matrix with different spectral gaps to generate multiple variations of Fair-SMW, achieving clustering solutions with comparable balance to existing algorithms while offering improved runtime performance. We present the results of Fair-SMW, evaluated using the Stochastic Block Model (SBM) to measure both runtime efficiency and balance across real-world network datasets, including LastFM, FacebookNet, Deezer, and German. We achieve an improvement in computation time that is twice as fast as the state-of-the-art, and also flexible enough to achieve twice as much balance.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.20220v1</guid>
      <category>cs.LG</category>
      <category>cs.NA</category>
      <category>math.NA</category>
      <pubDate>Fri, 24 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Iv\'an Ojeda-Ruiz, Young Ju-Lee, Malcolm Dickens, Leonardo Cambisaca</dc:creator>
    </item>
    <item>
      <title>Stochastic evolution equations with nonlinear diffusivity, recent progress and critical cases</title>
      <link>https://arxiv.org/abs/2510.20471</link>
      <description>arXiv:2510.20471v1 Announce Type: cross 
Abstract: This short survey article stems from recent progress on critical cases of stochastic evolution equations in variational formulation with additive, multiplicative or gradient noises. Typical examples appear as the limit cases of the stochastic porous medium equation, stochastic fast- and super fast-diffusion equations, self-organized criticality, stochastic singular $p$-Laplace equations, and the stochastic total variation flow, among others. We present several different notions of solutions, results on convergence of solutions depending on a parameter, and homogenization. Furthermore, we provide some references hinting at the recent progress in regularity results, long-time behavior, ergodicity, and numerical analysis.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.20471v1</guid>
      <category>math.PR</category>
      <category>cs.NA</category>
      <category>math.AP</category>
      <category>math.DS</category>
      <category>math.FA</category>
      <category>math.NA</category>
      <pubDate>Fri, 24 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Ioana Ciotir, Dan Goreac, Jonas M. T\"olle</dc:creator>
    </item>
    <item>
      <title>Rothe's method in direct and time-dependent inverse source problems for a semilinear pseudo-parabolic equation</title>
      <link>https://arxiv.org/abs/2510.20642</link>
      <description>arXiv:2510.20642v1 Announce Type: cross 
Abstract: In this paper, we investigate the inverse problem of determining an unknown time-dependent source term in a semilinear pseudo-parabolic equation with variable coefficients and a Dirichlet boundary condition. The unknown source term is recovered from additional measurement data expressed as a weighted spatial average of the solution. By employing Rothe's time-discretisation method, we prove the existence and uniqueness of a weak solution under a smallness condition on the problem data. We also present a numerical scheme for computations.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.20642v1</guid>
      <category>math.AP</category>
      <category>cs.NA</category>
      <category>math.NA</category>
      <pubDate>Fri, 24 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Karel Van Bockstal, Khonatbek Khompysh, Arshyn Altybay</dc:creator>
    </item>
    <item>
      <title>Efficient Shallow Ritz Method For 1D Diffusion Problems</title>
      <link>https://arxiv.org/abs/2404.17750</link>
      <description>arXiv:2404.17750v4 Announce Type: replace 
Abstract: This paper studies the shallow Ritz method for solving the one-dimensional diffusion problem. It is shown that the shallow Ritz method improves the order of approximation dramatically for non-smooth problems. To realize this optimal or nearly optimal order of the shallow Ritz approximation, we develop a damped block Newton (dBN) method that alternates between updates of the linear and non-linear parameters. Per each iteration, the linear and the non-linear parameters are updated by exact inversion and one step of a modified, damped Newton method applied to a reduced non-linear system, respectively. The computational cost of each dBN iteration is $O(n)$.
  Starting with the non-linear parameters as a uniform partition of the interval, numerical experiments show that the dBN is capable of efficiently moving mesh points to nearly optimal locations. To improve efficiency of the dBN further, we propose an adaptive damped block Newton (AdBN) method by combining the dBN with the adaptive neuron enhancement (ANE) method [26].</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.17750v4</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <pubDate>Fri, 24 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Zhiqiang Cai, Anastassia Doktorova, Robert D. Falgout, C\'esar Herrera</dc:creator>
    </item>
    <item>
      <title>Generalized Moving Least-Squares Methods for Solving Vector-valued PDEs on Unknown Manifolds</title>
      <link>https://arxiv.org/abs/2406.12210</link>
      <description>arXiv:2406.12210v3 Announce Type: replace 
Abstract: In this paper, we extend the Generalized Moving Least-Squares (GMLS) method in two different ways to solve the vector-valued PDEs on unknown smooth 2D manifolds without boundaries embedded in $\mathbb{R}^{3}$, identified with randomly sampled point cloud data. The two approaches are referred to as the intrinsic method and the extrinsic method. For the intrinsic method which relies on local approximations of metric tensors, we simplify the formula of Laplacians and covariant derivatives acting on vector fields at the base point by calculating them in a local Monge coordinate system. On the other hand, the extrinsic method formulates tangential derivatives on a submanifold as the projection of the directional derivative in the ambient Euclidean space onto the tangent space of the submanifold. One challenge of this method is that the discretization of vector Laplacians yields a matrix whose size relies on the ambient dimension. To overcome this issue, we reduce the dimension of vector Laplacian matrices by employing a coordinate transformation. The complexity of both methods scales well with the dimension of manifolds rather than the ambient dimension. We also present supporting numerical examples, including eigenvalue problems, linear Poisson equations, and nonlinear Burgers' equations, to examine the numerical accuracy of proposed methods on various smooth manifolds.</description>
      <guid isPermaLink="false">oai:arXiv.org:2406.12210v3</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <pubDate>Fri, 24 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Rongji Li, Qile Yan, Shixiao W. Jiang</dc:creator>
    </item>
    <item>
      <title>A multiscale approach to the stationary Ginzburg-Landau equations of superconductivity</title>
      <link>https://arxiv.org/abs/2409.12023</link>
      <description>arXiv:2409.12023v2 Announce Type: replace 
Abstract: In this work, we study the numerical approximation of minimizers of the Ginzburg-Landau free energy, a common model to describe the behavior of superconductors under magnetic fields. The unknowns are the order parameter, which characterizes the density of superconducting charge carriers, and the magnetic vector potential, which allows to deduce the magnetic field that penetrates the superconductor. Physically important and numerically challenging are especially settings which involve lattices of quantized vortices which can be formed in materials with a large Ginzburg-Landau parameter $\kappa$. In particular, $\kappa$ introduces a severe mesh resolution condition for numerical approximations. In order to reduce these computational restrictions, we investigate a particular discretization which is based on mixed meshes where we apply a Lagrange finite element approach for the vector potential and a localized orthogonal decomposition (LOD) approach for the order parameter. We justify the proposed method by a rigorous a-priori error analysis (in $L^2$ and $H^1$) in which we keep track of the influence of $\kappa$ in all error contributions. This allows us to conclude $\kappa$-dependent resolution conditions for the various meshes and which only impose moderate practical constraints compared to a conventional finite element discretization. Finally, our theoretical findings are illustrated by numerical experiments.</description>
      <guid isPermaLink="false">oai:arXiv.org:2409.12023v2</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <pubDate>Fri, 24 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Christian D\"oding, Benjamin D\"orich, Patrick Henning</dc:creator>
    </item>
    <item>
      <title>A function approximation algorithm using multilevel active subspaces</title>
      <link>https://arxiv.org/abs/2501.12867</link>
      <description>arXiv:2501.12867v2 Announce Type: replace 
Abstract: The Active Subspace (AS) method is a widely used technique for identifying the most influential directions in high-dimensional input spaces that affect the output of a computational model. The standard AS algorithm requires a sufficient number of gradient evaluations (samples) of the input output map to achieve quasi-optimal reconstruction of the active subspace, which can lead to a significant computational cost if the samples include numerical discretization errors which have to be kept sufficiently small. To address this issue, we propose a multilevel version of the Active Subspace method (MLAS) that utilizes samples computed with different accuracies and yields different active subspaces across accuracy levels, which can match the accuracy of single-level AS with reduced computational cost, making it suitable for downstream tasks such as function approximation. In particular, we propose to perform the latter via optimally-weighted least-squares polynomial approximation in the different active subspaces, and we present an adaptive algorithm to choose dynamically the dimensions of the active subspaces and polynomial spaces. We demonstrate the practical viability of the MLAS method with polynomial approximation through numerical experiments based on random partial differential equations (PDEs).</description>
      <guid isPermaLink="false">oai:arXiv.org:2501.12867v2</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <pubDate>Fri, 24 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Fabio Nobile, Matteo Raviola, Raul Tempone</dc:creator>
    </item>
    <item>
      <title>Modal analysis of a domain decomposition method for Maxwell's equations in a waveguide</title>
      <link>https://arxiv.org/abs/2502.15548</link>
      <description>arXiv:2502.15548v2 Announce Type: replace 
Abstract: Time-harmonic wave propagation problems, especially those governed by Maxwell's equations, pose significant computational challenges due to the non-self-adjoint nature of the operators and the large, non-Hermitian linear systems resulting from discretization. Domain decomposition methods, particularly one-level Schwarz methods, offer a promising framework to tackle these challenges, with recent advancements showing the potential for weak scalability under certain conditions. In this paper, we analyze the weak scalability of one-level Schwarz methods for Maxwell's equations in strip-wise domain decompositions, focusing on waveguides with general cross sections and different types of transmission conditions such as impedance or perfectly matched layers (PMLs). By combining techniques from the limiting spectrum analysis of Toeplitz matrices and the modal decomposition of Maxwell's solutions, we provide a novel theoretical framework that extends previous work to more complex geometries and transmission conditions. Numerical experiments confirm that the limiting spectrum effectively predicts practical behavior even with a modest number of subdomains. Furthermore, we demonstrate that the one-level Schwarz method can achieve robustness with respect to the wave number under specific domain decomposition parameters, offering new insights into its applicability for large-scale electromagnetic wave problems.</description>
      <guid isPermaLink="false">oai:arXiv.org:2502.15548v2</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <category>physics.comp-ph</category>
      <pubDate>Fri, 24 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Victorita Dolean, Antoine Tonnoir, Pierre-Henri Tournier</dc:creator>
    </item>
    <item>
      <title>A decomposition-based robust training of physics-informed neural networks for nearly incompressible linear elasticity</title>
      <link>https://arxiv.org/abs/2505.21994</link>
      <description>arXiv:2505.21994v2 Announce Type: replace 
Abstract: Due to divergence instability, the accuracy of low-order conforming finite element methods for nearly incompressible elasticity equations deteriorates as the Lam\'e coefficient $\lambda\to\infty$, or equivalently as the Poisson ratio $\nu\to1/2$. This phenomenon, known as locking or non-robustness, remains not fully understood despite extensive investigation. In this work, we illustrate first that an analogous instability arises when applying the popular Physics-Informed Neural Networks (PINNs) to nearly incompressible elasticity problems, leading to significant loss of accuracy and convergence difficulties. Then, to overcome this challenge, we propose a robust decomposition-based PINN framework that reformulates the elasticity equations into balanced subsystems, thereby eliminating the ill-conditioning that causes locking. Our approach simultaneously solves the forward and inverse problems to recover both the decomposed field variables and the associated external conditions. We will also perform a convergence analysis to further enhance the reliability of the proposed approach. Moreover, through various numerical experiments, including constant, variable and parametric Lam\'e coefficients, we illustrate the efficiency of the proposed methodology.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.21994v2</guid>
      <category>math.NA</category>
      <category>cs.LG</category>
      <category>cs.NA</category>
      <pubDate>Fri, 24 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Josef Dick, Seungchan Ko, Quoc Thong Le Gia, Kassem Mustapha, Sanghyeon Park</dc:creator>
    </item>
    <item>
      <title>Inverse source problem with a posteriori interior measurements for space-time fractional diffusion equations</title>
      <link>https://arxiv.org/abs/2506.21070</link>
      <description>arXiv:2506.21070v2 Announce Type: replace 
Abstract: This paper investigates an inverse source problem for space-time fractional diffusion equations from a posteriori interior measurements. The uniqueness result is established by the memory effect of fractional derivatives and the unique continuation property. For the numerical reconstruction, the inverse problem is reformulated as an optimization problem with the Tikhonov regularization. We use the Levenberg-Marquardt method to identity the unknown source from noisy measurements. Finally, we give some numerical examples to illustrate the efficiency and accuracy of the proposed algorithm.</description>
      <guid isPermaLink="false">oai:arXiv.org:2506.21070v2</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <pubDate>Fri, 24 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <arxiv:DOI>10.1016/j.camwa.2025.10.011</arxiv:DOI>
      <arxiv:journal_reference>Computers &amp; Mathematics with Applications, 200 (2025), 305-314</arxiv:journal_reference>
      <dc:creator>Kai Yu, Zhiyuan Li, Yikan Liu</dc:creator>
    </item>
    <item>
      <title>The inverse initial data problem for anisotropic Navier-Stokes equations via Legendre time reduction method</title>
      <link>https://arxiv.org/abs/2507.16810</link>
      <description>arXiv:2507.16810v2 Announce Type: replace 
Abstract: We consider the inverse initial data problem for the compressible anisotropic Navier-Stokes equations, where the goal is to reconstruct the initial velocity field from lateral boundary observations. This problem arises in applications where direct measurements of internal fluid states are unavailable. We introduce a novel computational framework based on Legendre time reduction, which projects the velocity field onto an exponentially weighted Legendre basis in time. This transformation reduces the original time-dependent inverse problem to a coupled, time-independent elliptic system. The resulting reduced model is solved iteratively using a Picard iteration and a stabilized least-squares formulation under noisy boundary data. Numerical experiments in two dimensions confirm that the method accurately and robustly reconstructs initial velocity fields, even in the presence of significant measurement noise and complex anisotropic structures. This approach offers a flexible and computationally tractable alternative for inverse modeling in fluid dynamics with anisotropic media.</description>
      <guid isPermaLink="false">oai:arXiv.org:2507.16810v2</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <pubDate>Fri, 24 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/publicdomain/zero/1.0/</dc:rights>
      <dc:creator>Cong B. Van, Thuy T. Le, Loc H. Nguyen</dc:creator>
    </item>
    <item>
      <title>Parameter-related strong convergence rate of an Euler's type method for time-changed stochastic differential equations</title>
      <link>https://arxiv.org/abs/2510.16405</link>
      <description>arXiv:2510.16405v2 Announce Type: replace 
Abstract: An Euler's type method with the equidistant step size is proposed for a class of time-changed stochastic differential equations driven by the multiplicative noise and the strong convergence rate that is related to the parameter of the time changing process is obtained. Such a observation of the convergence rate is significantly different from those existing results that employ methods with the random step size. Numerical simulations are provided to demonstrate the theoretical results.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.16405v2</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <category>math.PR</category>
      <pubDate>Fri, 24 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Ruchun Zuo</dc:creator>
    </item>
    <item>
      <title>Newton's method for nonlinear mappings into vector bundles</title>
      <link>https://arxiv.org/abs/2404.04073</link>
      <description>arXiv:2404.04073v3 Announce Type: replace-cross 
Abstract: We consider Newton's method for finding zeros of mappings from a manifold $\mathcal X$ into a vector bundle $\mathcal E$. In this setting a connection on $\mathcal E$ is required to render the Newton equation well defined, and a retraction on $\mathcal X$ is needed to compute a Newton update. We discuss local convergence in terms of suitable differentiability concepts, using a Banach space variant of a Riemannian distance. We also carry over an affine covariant damping strategy to our setting. Finally, we will illustrate our results by applying them to generalized non-symmetric eigenvalue problems and providing a numerical example.</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.04073v3</guid>
      <category>math.DG</category>
      <category>cs.NA</category>
      <category>math.NA</category>
      <pubDate>Fri, 24 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Laura Weigl, Anton Schiela</dc:creator>
    </item>
    <item>
      <title>A primal-dual algorithm for image reconstruction with input-convex neural network regularizers</title>
      <link>https://arxiv.org/abs/2410.12441</link>
      <description>arXiv:2410.12441v2 Announce Type: replace-cross 
Abstract: We address the optimization problem in a data-driven variational reconstruction framework, where the regularizer is parameterized by an input-convex neural network (ICNN). While gradient-based methods are commonly used to solve such problems, they struggle to effectively handle non-smooth problems which often leads to slow convergence. Moreover, the nested structure of the neural network complicates the application of standard non-smooth optimization techniques, such as proximal algorithms. To overcome these challenges, we reformulate the problem and eliminate the network's nested structure. By relating this reformulation to epigraphical projections of the activation functions, we transform the problem into a convex optimization problem that can be efficiently solved using a primal-dual algorithm. We also prove that this reformulation is equivalent to the original variational problem. Through experiments on several imaging tasks, we show that the proposed approach not only outperforms subgradient methods and even accelerated methods in the smooth setting, but also facilitates the training of the regularizer itself.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.12441v2</guid>
      <category>math.OC</category>
      <category>cs.CV</category>
      <category>cs.NA</category>
      <category>math.NA</category>
      <pubDate>Fri, 24 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Matthias J. Ehrhardt, Subhadip Mukherjee, Hok Shing Wong</dc:creator>
    </item>
    <item>
      <title>Quantum speedup of non-linear Monte Carlo problems</title>
      <link>https://arxiv.org/abs/2502.05094</link>
      <description>arXiv:2502.05094v2 Announce Type: replace-cross 
Abstract: The mean of a random variable can be understood as a linear functional on the space of probability distributions. Quantum computing is known to provide a quadratic speedup over classical Monte Carlo methods for mean estimation. In this paper, we investigate whether a similar quadratic speedup is achievable for estimating non-linear functionals of probability distributions. We propose a quantum-inside-quantum Monte Carlo algorithm that achieves such a speedup for a broad class of non-linear estimation problems, including nested conditional expectations and stochastic optimization. Our algorithm improves upon the direct application of the quantum multilevel Monte Carlo algorithm introduced by An et al. (2021). The existing lower bound indicates that our algorithm is optimal up polylogarithmic factors. A key innovation of our approach is a new sequence of multilevel Monte Carlo approximations specifically designed for quantum computing, which is central to the algorithm's improved performance.</description>
      <guid isPermaLink="false">oai:arXiv.org:2502.05094v2</guid>
      <category>quant-ph</category>
      <category>cs.LG</category>
      <category>cs.NA</category>
      <category>math.NA</category>
      <category>stat.CO</category>
      <category>stat.ML</category>
      <pubDate>Fri, 24 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <arxiv:journal_reference>Proceedings of the 39th Conference on Neural Information Processing Systems (NeurIPS), 2025</arxiv:journal_reference>
      <dc:creator>Jose Blanchet, Yassine Hamoudi, Mario Szegedy, Guanyang Wang</dc:creator>
    </item>
  </channel>
</rss>
