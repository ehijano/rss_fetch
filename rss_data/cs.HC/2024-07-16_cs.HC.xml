<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>cs.HC updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/cs.HC</link>
    <description>cs.HC updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/cs.HC" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Wed, 17 Jul 2024 01:51:31 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Tue, 16 Jul 2024 00:00:00 -0400</pubDate>
    <skipDays>
      <day>Sunday</day>
      <day>Saturday</day>
    </skipDays>
    <item>
      <title>GPTutor: Great Personalized Tutor with Large Language Models for Personalized Learning Content Generation</title>
      <link>https://arxiv.org/abs/2407.09484</link>
      <description>arXiv:2407.09484v1 Announce Type: new 
Abstract: We developed GPTutor, a pioneering web application designed to revolutionize personalized learning by leveraging the capabilities of Generative AI at scale. GPTutor adapts educational content and practice exercises to align with individual students' interests and career goals, enhancing their engagement and understanding of critical academic concepts. The system uses a serverless architecture to deliver personalized and scalable learning experiences. By integrating advanced Chain-of-Thoughts prompting methods, GPTutor provides a personalized educational journey that not only addresses the unique interests of each student but also prepares them for future professional success. This demo paper presents the design, functionality, and potential of GPTutor to foster a more engaging and effective educational environment.</description>
      <guid isPermaLink="false">oai:arXiv.org:2407.09484v1</guid>
      <category>cs.HC</category>
      <category>cs.CY</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Eason Chen, Jia-En Lee, Jionghao Lin, Kenneth Koedinger</dc:creator>
    </item>
    <item>
      <title>Representation Debiasing of Generated Data Involving Domain Experts</title>
      <link>https://arxiv.org/abs/2407.09485</link>
      <description>arXiv:2407.09485v1 Announce Type: new 
Abstract: Biases in Artificial Intelligence (AI) or Machine Learning (ML) systems due to skewed datasets problematise the application of prediction models in practice. Representation bias is a prevalent form of bias found in the majority of datasets. This bias arises when training data inadequately represents certain segments of the data space, resulting in poor generalisation of prediction models. Despite AI practitioners employing various methods to mitigate representation bias, their effectiveness is often limited due to a lack of thorough domain knowledge. To address this limitation, this paper introduces human-in-the-loop interaction approaches for representation debiasing of generated data involving domain experts. Our work advocates for a controlled data generation process involving domain experts to effectively mitigate the effects of representation bias. We argue that domain experts can leverage their expertise to assess how representation bias affects prediction models. Moreover, our interaction approaches can facilitate domain experts in steering data augmentation algorithms to produce debiased augmented data and validate or refine the generated samples to reduce representation bias. We also discuss how these approaches can be leveraged for designing and developing user-centred AI systems to mitigate the impact of representation bias through effective collaboration between domain experts and AI.</description>
      <guid isPermaLink="false">oai:arXiv.org:2407.09485v1</guid>
      <category>cs.HC</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <arxiv:DOI>10.1145/3631700.3664910</arxiv:DOI>
      <arxiv:journal_reference>Adjunct Proceedings of the 32nd ACM Conference on User Modeling, Adaptation and Personalization (UMAP Adjunct '24), July 1--4, 2024, Cagliari, Italy</arxiv:journal_reference>
      <dc:creator>Aditya Bhattacharya, Simone Stumpf, Katrien Verbert</dc:creator>
    </item>
    <item>
      <title>A Systematic Review on the Potential of AI and ChatGPT for Parental Support and Child Well-Being</title>
      <link>https://arxiv.org/abs/2407.09492</link>
      <description>arXiv:2407.09492v1 Announce Type: new 
Abstract: This research article explores the potential of Artificial Intelligence (AI) and Chat Generative Pre-trained Transformers (ChatGPT) in revolutionizing the landscape of parental support and child care. With the advancement of generative AI, conversational agent technology, and Large Language Models, these tools can be a great support for parents to guide and assist their children. Recognizing the challenges faced by parents in navigating the complexities of child-rearing, this study seeks to explore the applications of AI, particularly leveraging the capabilities of ChatGPT, to provide valuable assistance and guidance. For this purpose, we perform a comprehensive examination of the existing 27 literature studies to investigate the potential of AI-driven platforms for offering advice tailored to the individual needs of the parents. We break down these research works into three domains based on their research criteria, and categorize each domain into two subgroups: pre-chatGPT era, and post-chatGPT era. At last, we investigate the significant dimensions of these literatures and present some valuable findings and future research directions.</description>
      <guid isPermaLink="false">oai:arXiv.org:2407.09492v1</guid>
      <category>cs.HC</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Mohsena Ashraf</dc:creator>
    </item>
    <item>
      <title>Social AI and The Equation of Wittgenstein's Language User With Calvino's Literature Machine</title>
      <link>https://arxiv.org/abs/2407.09493</link>
      <description>arXiv:2407.09493v1 Announce Type: new 
Abstract: Is it sensical to ascribe psychological predicates to AI systems like chatbots based on large language models (LLMs)? People have intuitively started ascribing emotions or consciousness to social AI ('affective artificial agents'), with consequences that range from love to suicide. The philosophical question of whether such ascriptions are warranted is thus very relevant. This paper advances the argument that LLMs instantiate language users in Ludwig Wittgenstein's sense but that ascribing psychological predicates to these systems remains a functionalist temptation. Social AIs are not full-blown language users, but rather more like Italo Calvino's literature machines. The ideas of LLMs as Wittgensteinian language users and Calvino's literature-producing writing machine are combined. This sheds light on the misguided functionalist temptation inherent in moving from equating the two to the ascription of psychological predicates to social AI. Finally, the framework of mortal computation is used to show that social AIs lack the basic autopoiesis needed for narrative fa\c{c}ons de parler and their role in the sensemaking of human (inter)action. Such psychological predicate ascriptions could make sense: the transition 'from quantity to quality' can take place, but its route lies somewhere between life and death, not between affective artifacts and emotion approximation by literature machines.</description>
      <guid isPermaLink="false">oai:arXiv.org:2407.09493v1</guid>
      <category>cs.HC</category>
      <category>cs.AI</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <arxiv:DOI>10.53057/irls/2024.6.1.4</arxiv:DOI>
      <arxiv:journal_reference>International Review of Literary Studies, 6, no.1 (2024): 39-55</arxiv:journal_reference>
      <dc:creator>W. J. T. Mollema</dc:creator>
    </item>
    <item>
      <title>Learning Outcomes, Assessment, and Evaluation in Educational Recommender Systems: A Systematic Review</title>
      <link>https://arxiv.org/abs/2407.09500</link>
      <description>arXiv:2407.09500v1 Announce Type: new 
Abstract: In this paper, we analyse how learning is measured and optimized in Educational Recommender Systems (ERS). In particular, we examine the target metrics and evaluation methods used in the existing ERS research, with a particular focus on the pedagogical effect of recommendations. While conducting this systematic literature review (SLR), we identified 1395 potentially relevant papers, then filtered them through the inclusion and exclusion criteria, and finally selected and analyzed 28 relevant papers. Rating-based relevance is the most popular target metric, while less than a half of papers optimize learning-based metrics. Only a third of the papers used outcome-based assessment to measure the pedagogical effect of recommendations, mostly within a formal university course. This indicates a gap in ERS research with respect to assessing the pedagogical effect of recommendations at scale and in informal education settings.</description>
      <guid isPermaLink="false">oai:arXiv.org:2407.09500v1</guid>
      <category>cs.HC</category>
      <category>cs.IR</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Nursultan Askarbekuly, Ivan Lukovi\'c</dc:creator>
    </item>
    <item>
      <title>Focused State Recognition Using EEG with Eye Movement-Assisted Annotation</title>
      <link>https://arxiv.org/abs/2407.09508</link>
      <description>arXiv:2407.09508v1 Announce Type: new 
Abstract: With the rapid advancement in machine learning, the recognition and analysis of brain activity based on EEG and eye movement signals have attained a high level of sophistication. Utilizing deep learning models for learning EEG and eye movement features proves effective in classifying brain activities. A focused state indicates intense concentration on a task or thought. Distinguishing focused and unfocused states can be achieved through eye movement behaviors, reflecting variations in brain activities. By calculating binocular focusing point disparity in eye movement signals and integrating relevant EEG features, we propose an annotation method for focused states. The resulting comprehensive dataset, derived from raw data processed through a bio-acquisition device, includes both EEG features and focused labels annotated by eye movements. Extensive training and testing on several deep learning models, particularly the Transformer, yielded a 90.16% accuracy on the subject-dependent experiments. The validity of this approach was demonstrated, with cross-subject experiments, key frequency band and brain region analyses confirming its generalizability and providing physiological explanations.</description>
      <guid isPermaLink="false">oai:arXiv.org:2407.09508v1</guid>
      <category>cs.HC</category>
      <category>cs.LG</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Tian-Hua Li, Tian-Fang Ma, Dan Peng, Wei-Long Zheng, Bao-Liang Lu</dc:creator>
    </item>
    <item>
      <title>Design and evaluation of AI copilots -- case studies of retail copilot templates</title>
      <link>https://arxiv.org/abs/2407.09512</link>
      <description>arXiv:2407.09512v1 Announce Type: new 
Abstract: Building a successful AI copilot requires a systematic approach. This paper is divided into two sections, covering the design and evaluation of a copilot respectively. A case study of developing copilot templates for the retail domain by Microsoft is used to illustrate the role and importance of each aspect. The first section explores the key technical components of a copilot's architecture, including the LLM, plugins for knowledge retrieval and actions, orchestration, system prompts, and responsible AI guardrails. The second section discusses testing and evaluation as a principled way to promote desired outcomes and manage unintended consequences when using AI in a business context. We discuss how to measure and improve its quality and safety, through the lens of an end-to-end human-AI decision loop framework. By providing insights into the anatomy of a copilot and the critical aspects of testing and evaluation, this paper provides concrete evidence of how good design and evaluation practices are essential for building effective, human-centered AI assistants.</description>
      <guid isPermaLink="false">oai:arXiv.org:2407.09512v1</guid>
      <category>cs.HC</category>
      <category>cs.AI</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Michal Furmakiewicz, Chang Liu, Angus Taylor, Ilya Venger</dc:creator>
    </item>
    <item>
      <title>An Actionability Assessment Tool for Explainable AI</title>
      <link>https://arxiv.org/abs/2407.09516</link>
      <description>arXiv:2407.09516v1 Announce Type: new 
Abstract: In this paper, we introduce and evaluate a tool for researchers and practitioners to assess the actionability of information provided to users to support algorithmic recourse. While there are clear benefits of recourse from the user's perspective, the notion of actionability in explainable AI research remains vague, and claims of `actionable' explainability techniques are based on the researchers' intuition. Inspired by definitions and instruments for assessing actionability in other domains, we construct a seven-question tool and evaluate its effectiveness through two user studies. We show that the tool discriminates actionability across explanation types and that the distinctions align with human judgements. We show the impact of context on actionability assessments, suggesting that domain-specific tool adaptations may foster more human-centred algorithmic systems. This is a significant step forward for research and practices into actionable explainability and algorithmic recourse, providing the first clear human-centred definition and tool for assessing actionability in explainable AI.</description>
      <guid isPermaLink="false">oai:arXiv.org:2407.09516v1</guid>
      <category>cs.HC</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Ronal Singh, Tim Miller, Liz Sonenberg, Eduardo Velloso, Frank Vetere, Piers Howe, Paul Dourish</dc:creator>
    </item>
    <item>
      <title>Prism XR -- A Curated Exhibition Experience in Virtual Reality with Peer Annotation Features and Virtual Guides for Art and Archaeology Classes</title>
      <link>https://arxiv.org/abs/2407.09528</link>
      <description>arXiv:2407.09528v2 Announce Type: new 
Abstract: The Prism XR project is a curated exhibition experience in virtual reality (VR) for art and archaeology education with features designed for the enhancement of interactivity and collaborative learning. The project integrates peer annotations and a virtual exhibition guide to augment educational experiences. The peer annotation features are intended for facilitating visitor critiques and comments pivotal in fostering a dialog between the curator and the audience and a dialogue between the visitors in art and archaeology education, which are demonstrated to have positive impacts on the learning motivations and learning outcomes. The virtual exhibition guide is intended to address the issue of isolation in the virtual exhibition space and to increase interactivity in the virtual curatorial experiences.</description>
      <guid isPermaLink="false">oai:arXiv.org:2407.09528v2</guid>
      <category>cs.HC</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Huopu Zhang</dc:creator>
    </item>
    <item>
      <title>Info Overload: A Cooperative Evacuation Game</title>
      <link>https://arxiv.org/abs/2407.09559</link>
      <description>arXiv:2407.09559v1 Announce Type: new 
Abstract: Info Overload is a minigame within a larger collection aimed at increasing awareness and preparation for an evacuation in the event of a wildfire. The game relies on experiential two-player cooperative gameplay and is played on a mobile device (a phone or tablet).</description>
      <guid isPermaLink="false">oai:arXiv.org:2407.09559v1</guid>
      <category>cs.HC</category>
      <category>cs.GT</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>MJ Johns, Rita Tesfay, M\'ario Escarce Junior, Emmanuel Ezenwa Jr., Thomas Maiorana, Magy Seif El-Nasr, Edward Melcer, Katherine Isbister</dc:creator>
    </item>
    <item>
      <title>Bridging Dictionary: AI-Generated Dictionary of Partisan Language Use</title>
      <link>https://arxiv.org/abs/2407.09661</link>
      <description>arXiv:2407.09661v1 Announce Type: new 
Abstract: Words often carry different meanings for people from diverse backgrounds. Today's era of social polarization demands that we choose words carefully to prevent miscommunication, especially in political communication and journalism. To address this issue, we introduce the Bridging Dictionary, an interactive tool designed to illuminate how words are perceived by people with different political views. The Bridging Dictionary includes a static, printable document featuring 796 terms with summaries generated by a large language model. These summaries highlight how the terms are used distinctively by Republicans and Democrats. Additionally, the Bridging Dictionary offers an interactive interface that lets users explore selected words, visualizing their frequency, sentiment, summaries, and examples across political divides. We present a use case for journalists and emphasize the importance of human agency and trust in further enhancing this tool. The deployed version of Bridging Dictionary is available at https://dictionary.ccc-mit.org/.</description>
      <guid isPermaLink="false">oai:arXiv.org:2407.09661v1</guid>
      <category>cs.HC</category>
      <category>cs.CL</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Hang Jiang, Doug Beeferman, William Brannon, Andrew Heyward, Deb Roy</dc:creator>
    </item>
    <item>
      <title>Purrfect Pitch: Exploring Musical Interval Learning through Multisensory Interfaces</title>
      <link>https://arxiv.org/abs/2407.09721</link>
      <description>arXiv:2407.09721v1 Announce Type: new 
Abstract: We introduce Purrfect Pitch, a system consisting of a wearable haptic device and a custom-designed learning interface for musical ear training. We focus on the ability to identify musical intervals (sequences of two musical notes), which is a perceptually ambiguous task that usually requires strenuous rote training. With our system, the user would hear a sequence of two tones while simultaneously receiving two corresponding vibrotactile stimuli on the back. Providing haptic feedback along the back makes the auditory distance between the two tones more salient, and the back-worn design is comfortable and unobtrusive. During training, the user receives multi-sensory feedback from our system and inputs their guessed interval value on our web-based learning interface. They see a green (otherwise red) screen for a correct guess with the correct interval value. Our study with 18 participants shows that our system enables novice learners to identify intervals more accurately and consistently than those who only received audio feedback, even after the haptic feedback is removed. We also share further insights on how to design a multisensory learning system.</description>
      <guid isPermaLink="false">oai:arXiv.org:2407.09721v1</guid>
      <category>cs.HC</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Sam Chin, Cathy Mengying Fang, Nikhil Singh, Ibrahim Ibrahim, Joe Paradiso, Pattie Maes</dc:creator>
    </item>
    <item>
      <title>Uncovering the Effect of Toxicity on Player Engagement and its Propagation in Competitive Online Video Games</title>
      <link>https://arxiv.org/abs/2407.09736</link>
      <description>arXiv:2407.09736v1 Announce Type: new 
Abstract: This article seeks to provide accurate estimates of the causal effect of exposure to toxic language on player engagement and the proliferation of toxic language. To this end, we analyze proprietary data from the first-person action video game Call of Duty: Modern Warfare III, published by Activision. To overcome causal identification problems, we implement an instrumental variables estimation strategy. Our findings confirm that exposure to toxic language significantly affects player engagement and the probability that players use similar language. Accordingly, video game publishers have a vested interest in addressing toxic language. Further, we demonstrate that this effect varies significantly depending on whether toxic language originates from opponents or teammates, whether it originates from teammates in the same party or a different party, and the match's outcome. This has meaningful implications regarding how resources for addressing toxicity should be allocated.</description>
      <guid isPermaLink="false">oai:arXiv.org:2407.09736v1</guid>
      <category>cs.HC</category>
      <category>econ.GN</category>
      <category>q-fin.EC</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Jacob Morrier, Amine Mahmassani, R. Michael Alvarez</dc:creator>
    </item>
    <item>
      <title>SensEmo: Enabling Affective Learning through Real-time Emotion Recognition with Smartwatches</title>
      <link>https://arxiv.org/abs/2407.09911</link>
      <description>arXiv:2407.09911v1 Announce Type: new 
Abstract: Recent research has demonstrated the capability of physiological signals to infer both user emotional and attention responses. This presents an opportunity for leveraging widely available physiological sensors in smartwatches, to detect real-time emotional cues in users, such as stress and excitement. In this paper, we introduce SensEmo, a smartwatch-based system designed for affective learning. SensEmo utilizes multiple physiological sensor data, including heart rate and galvanic skin response, to recognize a student's motivation and concentration levels during class. This recognition is facilitated by a personalized emotion recognition model that predicts emotional states based on degrees of valence and arousal. With real-time emotion and attention feedback from students, we design a Markov decision process-based algorithm to enhance student learning effectiveness and experience by by offering suggestions to the teacher regarding teaching content and pacing. We evaluate SensEmo with 22 participants in real-world classroom environments. Evaluation results show that SensEmo recognizes student emotion with an average of 88.9% accuracy. More importantly, SensEmo assists students to achieve better online learning outcomes, e.g., an average of 40.0% higher grades in quizzes, over the traditional learning without student emotional feedback.</description>
      <guid isPermaLink="false">oai:arXiv.org:2407.09911v1</guid>
      <category>cs.HC</category>
      <category>cs.CV</category>
      <category>cs.LG</category>
      <category>eess.SP</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Kushan Choksi, Hongkai Chen, Karan Joshi, Sukrutha Jade, Shahriar Nirjon, Shan Lin</dc:creator>
    </item>
    <item>
      <title>The Jade Gateway to Exergaming: How Socio-Cultural Factors Shape Exergaming Among East Asian Older Adults</title>
      <link>https://arxiv.org/abs/2407.10053</link>
      <description>arXiv:2407.10053v1 Announce Type: new 
Abstract: Exergaming, blending exercise and gaming, improves the physical and mental health of older adults. We currently do not fully know the factors that drive older adults to either engage in or abstain from exergaming. Large-scale studies investigating this are still scarce, particularly those studying East Asian older adults. To address this, we interviewed 64 older adults from China, Japan, and South Korea about their attitudes toward exergames. Most participants viewed exergames with a positive inquisitiveness. However, socio-cultural factors can obstruct this curiosity. Our study shows that perceptions of aging, lifestyle, the presence of support networks, and the cultural relevance of game mechanics are the crucial factors influencing their exergame engagement. Thus, we stress the value of socio-cultural sensitivity in game design and urge the HCI community to adopt more diverse design practices. We provide several design suggestions for creating more culturally approachable exergames.</description>
      <guid isPermaLink="false">oai:arXiv.org:2407.10053v1</guid>
      <category>cs.HC</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <arxiv:DOI>10.1145/3677106</arxiv:DOI>
      <dc:creator>Reza Hadi Mogavi, Juhyung Son, Simin Yang, Derrick M. Wang, Lydia Choong, Ahmad Alhilal, Peng Yuan Zhou, Pan Hui, Lennart E. Nacke</dc:creator>
    </item>
    <item>
      <title>Work-From-Home and Privacy: What Do Workers Face and What are They Doing About it?</title>
      <link>https://arxiv.org/abs/2407.10094</link>
      <description>arXiv:2407.10094v1 Announce Type: new 
Abstract: The COVID-19 pandemic has reshaped the way people work, normalizing the practice of working from home (WFH). However, WFH can cause a blurring of personal and professional boundaries, surfacing new privacy issues, especially when workers take work meetings from their homes. As WFH arrangements are now standard practice in many organizations, addressing the associated privacy concerns should be a key part of creating healthy work environments for workers. To this end, we conducted a scenario-based survey with 214 US-based workers who currently work from home regularly. Our results suggest that privacy invasions are commonly experienced while working from home and cause discomfort to many workers. However, only a minority said that the discomfort escalated to cause harm to them or others, and the harm was almost always psychological. While scenarios that restrict worker autonomy (prohibit turning off camera or microphone) are the least experienced scenarios, they are associated with the highest reported discomfort. In addition, participants reported measures that violated or would violate their employer's autonomy-restricting rules to protect their privacy. We also find that conference tool settings that can prevent privacy invasions are not widely used compared to manual privacy-protective measures. Our findings provide better understanding of the privacy challenges landscape that WFH workers face and how they address them. Furthermore, our discussion raised open questions that can inspire future work.</description>
      <guid isPermaLink="false">oai:arXiv.org:2407.10094v1</guid>
      <category>cs.HC</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Eman Alashwali, Joanne Peca, Mandy Lanyon, Lorrie Cranor</dc:creator>
    </item>
    <item>
      <title>Beyond Meditation: Understanding Everyday Mindfulness Practices and Technology Use Among Experienced Practitioners</title>
      <link>https://arxiv.org/abs/2407.10334</link>
      <description>arXiv:2407.10334v1 Announce Type: new 
Abstract: Mindfulness, a practice of bringing attention to the present non-judgmentally, has many mental and physical well-being benefits, especially when practiced consistently. Many technologies have been invented to support solo or group mindfulness practice such as mobile apps, live streams, virtual reality environments, and wearables. In this paper, we present findings from an interview study with 20 experienced mindfulness practitioners about their everyday mindfulness practices and technology use. Participants identify the benefits and challenges of developing long-term commitment to mindfulness practice. They employ various strategies, such as brief mindfulness exercises, social accountability, and guidance from teachers, to sustain their practice. While conflicted about technology, they adopt and appropriate a range of technologies in their practice for reminders, emotion tracking, connecting with others, and attending online sessions. They also carefully consider when to use technology, when and how to limit its use, and ways to incorporate technology as an object for mindfulness. Based on our findings, we discuss expanding the definition of mindfulness and the tension between supporting short- and long-term mindfulness practice. We also propose a set of design recommendations to support everyday mindfulness including such as through the lens of metaphor, reappropriating non-mindfulness technology, and bringing community support into personal practice.</description>
      <guid isPermaLink="false">oai:arXiv.org:2407.10334v1</guid>
      <category>cs.HC</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Jingjin Li, Karen Anne Cochrane, Gilly Leshed</dc:creator>
    </item>
    <item>
      <title>Cultural Reflections in Virtual Reality: The Effects of User Ethnicity in Avatar Matching Experiences on Sense of Embodiment</title>
      <link>https://arxiv.org/abs/2407.10412</link>
      <description>arXiv:2407.10412v1 Announce Type: new 
Abstract: Matching avatar characteristics to a user can impact sense of embodiment (SoE) in VR. However, few studies have examined how participant demographics may interact with these matching effects. We recruited a diverse and racially balanced sample of 78 participants to investigate the differences among participant groups when embodying both demographically matched and unmatched avatars. We found that participant ethnicity emerged as a significant factor, with Asian and Black participants reporting lower total SoE compared to Hispanic participants. Furthermore, we found that user ethnicity significantly influences ownership (a subscale of SoE), with Asian and Black participants exhibiting stronger effects of matched avatar ethnicity compared to White participants. Additionally, Hispanic participants showed no significant differences, suggesting complex dynamics in ethnic-racial identity. Our results also reveal significant main effects of matched avatar ethnicity and gender on SoE, indicating the importance of considering these factors in VR experiences. These findings contribute valuable insights into understanding the complex dynamics shaping VR experiences across different demographic groups.</description>
      <guid isPermaLink="false">oai:arXiv.org:2407.10412v1</guid>
      <category>cs.HC</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Tiffany D. Do, Juanita Benjamin, Camille Isabella Protko, Ryan P. McMahan</dc:creator>
    </item>
    <item>
      <title>Interactive Public Transport Infrastructure Analysis through Mobility Profiles: Making the Mobility Transition Transparent</title>
      <link>https://arxiv.org/abs/2407.10791</link>
      <description>arXiv:2407.10791v1 Announce Type: new 
Abstract: Efficient public transport systems are crucial for sustainable urban development as cities face increasing mobility demands. Yet, many public transport networks struggle to meet diverse user needs due to historical development, urban constraints, and financial limitations. Traditionally, planning of transport network structure is often based on limited surveys, expert opinions, or partial usage statistics. This provides an incomplete basis for decision-making. We introduce an data-driven approach to public transport planning and optimization, calculating detailed accessibility measures at the individual housing level. Our visual analytics workflow combines population-group-based simulations with dynamic infrastructure analysis, utilizing a scenario-based model to simulate daily travel patterns of varied demographic groups, including schoolchildren, students, workers, and pensioners. These population groups, each with unique mobility requirements and routines, interact with the transport system under different scenarios traveling to and from Points of Interest (POI), assessed through travel time calculations. Results are visualized through heatmaps, density maps, and network overlays, as well as detailed statistics. Our system allows us to analyze both the underlying data and simulation results on multiple levels of granularity, delivering both broad insights and granular details. Case studies with the city of Konstanz, Germany reveal key areas where public transport does not meet specific needs, confirmed through a formative user study. Due to the high cost of changing legacy networks, our analysis facilitates the identification of strategic enhancements, such as optimized schedules or rerouting, and few targeted stop relocations, highlighting consequential variations in accessibility to pinpointing critical service gaps.</description>
      <guid isPermaLink="false">oai:arXiv.org:2407.10791v1</guid>
      <category>cs.HC</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Yannick Metz, Dennis Ackermann, Daniel A. Keim, Maximilian T. Fischer</dc:creator>
    </item>
    <item>
      <title>Random Channel Ablation for Robust Hand Gesture Classification with Multimodal Biosignals</title>
      <link>https://arxiv.org/abs/2407.10874</link>
      <description>arXiv:2407.10874v1 Announce Type: new 
Abstract: Biosignal-based hand gesture classification is an important component of effective human-machine interaction. For multimodal biosignal sensing, the modalities often face data loss due to missing channels in the data which can adversely affect the gesture classification performance. To make the classifiers robust to missing channels in the data, this paper proposes using Random Channel Ablation (RChA) during the training process. Ultrasound and force myography (FMG) data were acquired from the forearm for 12 hand gestures over 2 subjects. The resulting multimodal data had 16 total channels, 8 for each modality. The proposed method was applied to convolutional neural network architecture, and compared with baseline, imputation, and oracle methods. Using 5-fold cross-validation for the two subjects, on average, 12.2% and 24.5% improvement was observed for gesture classification with up to 4 and 8 missing channels respectively compared to the baseline. Notably, the proposed method is also robust to an increase in the number of missing channels compared to other methods. These results show the efficacy of using random channel ablation to improve classifier robustness for multimodal and multi-channel biosignal-based hand gesture classification.</description>
      <guid isPermaLink="false">oai:arXiv.org:2407.10874v1</guid>
      <category>cs.HC</category>
      <category>cs.CV</category>
      <category>cs.LG</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Keshav Bimbraw, Jing Liu, Ye Wang, Toshiaki Koike-Akino</dc:creator>
    </item>
    <item>
      <title>ChatGPT and Vaccine Hesitancy: A Comparison of English, Spanish, and French Responses Using a Validated Scale</title>
      <link>https://arxiv.org/abs/2407.09481</link>
      <description>arXiv:2407.09481v1 Announce Type: cross 
Abstract: ChatGPT is a popular information system (over 1 billion visits in August 2023) that can generate natural language responses to user queries. It is important to study the quality and equity of its responses on health-related topics, such as vaccination, as they may influence public health decision-making. We use the Vaccine Hesitancy Scale (VHS) proposed by Shapiro et al.1 to measure the hesitancy of ChatGPT responses in English, Spanish, and French. We find that: (a) ChatGPT responses indicate less hesitancy than those reported for human respondents in past literature; (b) ChatGPT responses vary significantly across languages, with English responses being the most hesitant on average and Spanish being the least; (c) ChatGPT responses are largely consistent across different model parameters but show some variations across the scale factors (vaccine competency, risk). Results have implications for researchers interested in evaluating and improving the quality and equity of health-related web information.</description>
      <guid isPermaLink="false">oai:arXiv.org:2407.09481v1</guid>
      <category>cs.CY</category>
      <category>cs.HC</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Saubhagya Joshi, Eunbin Ha, Yonaira Rivera, Vivek K. Singh</dc:creator>
    </item>
    <item>
      <title>Exploring Thermography Technology: A Comprehensive Facial Dataset for Face Detection, Recognition, and Emotion</title>
      <link>https://arxiv.org/abs/2407.09494</link>
      <description>arXiv:2407.09494v1 Announce Type: cross 
Abstract: This dataset includes 6823 thermal images captured using a UNI-T UTi165A camera for face detection, recognition, and emotion analysis. It consists of 2485 facial recognition images depicting emotions (happy, sad, angry, natural, surprised), 2054 images for face recognition, and 2284 images for face detection. The dataset covers various conditions, color palettes, shooting angles, and zoom levels, with a temperature range of -10{\deg}C to 400{\deg}C and a resolution of 19,200 pixels. It serves as a valuable resource for advancing thermal imaging technology, aiding in algorithm development, and benchmarking for facial recognition across different palettes. Additionally, it contributes to facial motion recognition, fostering interdisciplinary collaboration in computer vision, psychology, and neuroscience. The dataset promotes transparency in thermal face detection and recognition research, with applications in security, healthcare, and human-computer interaction.</description>
      <guid isPermaLink="false">oai:arXiv.org:2407.09494v1</guid>
      <category>cs.CV</category>
      <category>cs.HC</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Mohamed Fawzi Abdelshafie Abuhussein, Ashraf Darwish, Aboul Ella Hassanien</dc:creator>
    </item>
    <item>
      <title>PARSE-Ego4D: Personal Action Recommendation Suggestions for Egocentric Videos</title>
      <link>https://arxiv.org/abs/2407.09503</link>
      <description>arXiv:2407.09503v1 Announce Type: cross 
Abstract: Intelligent assistance involves not only understanding but also action. Existing ego-centric video datasets contain rich annotations of the videos, but not of actions that an intelligent assistant could perform in the moment. To address this gap, we release PARSE-Ego4D, a new set of personal action recommendation annotations for the Ego4D dataset. We take a multi-stage approach to generating and evaluating these annotations. First, we used a prompt-engineered large language model (LLM) to generate context-aware action suggestions and identified over 18,000 action suggestions. While these synthetic action suggestions are valuable, the inherent limitations of LLMs necessitate human evaluation. To ensure high-quality and user-centered recommendations, we conducted a large-scale human annotation study that provides grounding in human preferences for all of PARSE-Ego4D. We analyze the inter-rater agreement and evaluate subjective preferences of participants. Based on our synthetic dataset and complete human annotations, we propose several new tasks for action suggestions based on ego-centric videos. We encourage novel solutions that improve latency and energy requirements. The annotations in PARSE-Ego4D will support researchers and developers who are working on building action recommendation systems for augmented and virtual reality systems.</description>
      <guid isPermaLink="false">oai:arXiv.org:2407.09503v1</guid>
      <category>cs.CV</category>
      <category>cs.HC</category>
      <category>cs.NE</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Steven Abreu, Tiffany D. Do, Karan Ahuja, Eric J. Gonzalez, Lee Payne, Daniel McDuff, Mar Gonzalez-Franco</dc:creator>
    </item>
    <item>
      <title>Brain Dialogue Interface (BDI): A User-Friendly fMRI Model for Interactive Brain Decoding</title>
      <link>https://arxiv.org/abs/2407.09509</link>
      <description>arXiv:2407.09509v1 Announce Type: cross 
Abstract: Brain decoding techniques are essential for understanding the neurocognitive system. Although numerous methods have been introduced in this field, accurately aligning complex external stimuli with brain activities remains a formidable challenge. To alleviate alignment difficulties, many studies have simplified their models by employing single-task paradigms and establishing direct links between brain/world through classification strategies. Despite improvements in decoding accuracy, this strategy frequently encounters issues with generality when adapting these models to various task paradigms. To address this issue, this study introduces a user-friendly decoding model that enables dynamic communication with the brain, as opposed to the static decoding approaches utilized by traditional studies. The model functions as a brain simulator, allowing for interactive engagement with the brain and enabling the decoding of a subject's experiences through dialogue-like queries. Uniquely, our model is trained in a completely unsupervised and task-free manner. Our experiments demonstrate the feasibility and versatility of our proposed method. Notably, our model demonstrates exceptional capabilities in signal compression, successfully representing the entire brain signal of approximately 185,751 voxels with just 32 signals. Furthermore, we show how our model can integrate seamlessly with multimodal models, thus enhancing the potential for controlling brain decoding through textual or image inputs.</description>
      <guid isPermaLink="false">oai:arXiv.org:2407.09509v1</guid>
      <category>q-bio.NC</category>
      <category>cs.HC</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Heng Huang, Lin Zhao, Zihao Wu, Xiaowei Yu, Jing Zhang, Xintao Hu, Dajiang Zhu, Tianming Liu</dc:creator>
    </item>
    <item>
      <title>A Dynamic Systems Approach to Modelling Human-Machine Rhythm Interaction</title>
      <link>https://arxiv.org/abs/2407.09538</link>
      <description>arXiv:2407.09538v1 Announce Type: cross 
Abstract: In exploring the simulation of human rhythmic perception and synchronization capabilities, this study introduces a computational model inspired by the physical and biological processes underlying rhythm processing. Utilizing a reservoir computing framework that simulates the function of cerebellum, the model features a dual-neuron classification and incorporates parameters to modulate information transfer, reflecting biological neural network characteristics. Our findings demonstrate the model's ability to accurately perceive and adapt to rhythmic patterns within the human perceptible range, exhibiting behavior closely aligned with human rhythm interaction. By incorporating fine-tuning mechanisms and delay-feedback, the model enables continuous learning and precise rhythm prediction. The introduction of customized settings further enhances its capacity to stimulate diverse human rhythmic behaviors, underscoring the potential of this architecture in temporal cognitive task modeling and the study of rhythm synchronization and prediction in artificial and biological systems. Therefore, our model is capable of transparently modelling cognitive theories that elucidate the dynamic processes by which the brain generates rhythm-related behavior.</description>
      <guid isPermaLink="false">oai:arXiv.org:2407.09538v1</guid>
      <category>q-bio.NC</category>
      <category>cs.AI</category>
      <category>cs.HC</category>
      <category>cs.NE</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Zhongju Yuan, Wannes Van Ransbeeck, Geraint Wiggins, Dick Botteldooren</dc:creator>
    </item>
    <item>
      <title>The Ballad of the Bots: Sonification Using Cognitive Metaphor to Support Immersed Teleoperation of Robot Teams</title>
      <link>https://arxiv.org/abs/2407.09673</link>
      <description>arXiv:2407.09673v1 Announce Type: cross 
Abstract: As an embodied and spatial medium, virtual reality is proving an attractive proposition for robot teleoperation in hazardous environments. This paper examines a nuclear decommissioning scenario in which a simulated team of semi-autonomous robots are used to characterise a chamber within a virtual nuclear facility. This study examines the potential utility and impact of sonification as a means of communicating salient operator data in such an environment. However, the question of what sound should be used and how it can be applied in different applications is far from resolved. This paper explores and compares two sonification design approaches. The first is inspired by the theory of cognitive metaphor to create sonifications that align with socially acquired contextual and ecological understanding of the application domain. The second adopts a computationalist approach using auditory mappings that are commonplace in the literature. The results suggest that the computationalist approach outperforms the cognitive metaphor approach in terms of predictability and mental workload. However, qualitative data analysis demonstrates that the cognitive metaphor approach resulted in sounds that were more intuitive, and were better implemented for spatialisation of data sources and data legibility when there was more than one sound source.</description>
      <guid isPermaLink="false">oai:arXiv.org:2407.09673v1</guid>
      <category>cs.RO</category>
      <category>cs.HC</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <arxiv:DOI>10.3389/frvir.2024.1404865</arxiv:DOI>
      <dc:creator>Joe Simmons, Paul Bremner, Thomas J Mitchell, Alison Bown, Verity McIntosh</dc:creator>
    </item>
    <item>
      <title>CellAgent: An LLM-driven Multi-Agent Framework for Automated Single-cell Data Analysis</title>
      <link>https://arxiv.org/abs/2407.09811</link>
      <description>arXiv:2407.09811v1 Announce Type: cross 
Abstract: Single-cell RNA sequencing (scRNA-seq) data analysis is crucial for biological research, as it enables the precise characterization of cellular heterogeneity. However, manual manipulation of various tools to achieve desired outcomes can be labor-intensive for researchers. To address this, we introduce CellAgent (http://cell.agent4science.cn/), an LLM-driven multi-agent framework, specifically designed for the automatic processing and execution of scRNA-seq data analysis tasks, providing high-quality results with no human intervention. Firstly, to adapt general LLMs to the biological field, CellAgent constructs LLM-driven biological expert roles - planner, executor, and evaluator - each with specific responsibilities. Then, CellAgent introduces a hierarchical decision-making mechanism to coordinate these biological experts, effectively driving the planning and step-by-step execution of complex data analysis tasks. Furthermore, we propose a self-iterative optimization mechanism, enabling CellAgent to autonomously evaluate and optimize solutions, thereby guaranteeing output quality. We evaluate CellAgent on a comprehensive benchmark dataset encompassing dozens of tissues and hundreds of distinct cell types. Evaluation results consistently show that CellAgent effectively identifies the most suitable tools and hyperparameters for single-cell analysis tasks, achieving optimal performance. This automated framework dramatically reduces the workload for science data analyses, bringing us into the "Agent for Science" era.</description>
      <guid isPermaLink="false">oai:arXiv.org:2407.09811v1</guid>
      <category>cs.AI</category>
      <category>cs.HC</category>
      <category>q-bio.GN</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Yihang Xiao, Jinyi Liu, Yan Zheng, Xiaohan Xie, Jianye Hao, Mingzhi Li, Ruitao Wang, Fei Ni, Yuxiao Li, Jintian Luo, Shaoqing Jiao, Jiajie Peng</dc:creator>
    </item>
    <item>
      <title>To what extent is ChatGPT useful for language teacher lesson plan creation?</title>
      <link>https://arxiv.org/abs/2407.09974</link>
      <description>arXiv:2407.09974v1 Announce Type: cross 
Abstract: The advent of generative AI models holds tremendous potential for aiding teachers in the generation of pedagogical materials. However, numerous knowledge gaps concerning the behavior of these models obfuscate the generation of research-informed guidance for their effective usage. Here we assess trends in prompt specificity, variability, and weaknesses in foreign language teacher lesson plans generated by zero-shot prompting in ChatGPT. Iterating a series of prompts that increased in complexity, we found that output lesson plans were generally high quality, though additional context and specificity to a prompt did not guarantee a concomitant increase in quality. Additionally, we observed extreme cases of variability in outputs generated by the same prompt. In many cases, this variability reflected a conflict between 20th century versus 21st century pedagogical practices. These results suggest that the training of generative AI models on classic texts concerning pedagogical practices may represent a currently underexplored topic with the potential to bias generated content towards teaching practices that have been long refuted by research. Collectively, our results offer immediate translational implications for practicing and training foreign language teachers on the use of AI tools. More broadly, these findings reveal the existence of generative AI output trends that have implications for the generation of pedagogical materials across a diversity of content areas.</description>
      <guid isPermaLink="false">oai:arXiv.org:2407.09974v1</guid>
      <category>cs.CY</category>
      <category>cs.AI</category>
      <category>cs.CL</category>
      <category>cs.HC</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Alex Dornburg, Kristin Davin</dc:creator>
    </item>
    <item>
      <title>CourseAssist: Pedagogically Appropriate Question Answering System for Computer Science Education</title>
      <link>https://arxiv.org/abs/2407.10246</link>
      <description>arXiv:2407.10246v1 Announce Type: cross 
Abstract: The growing enrollments in computer science courses and increase in class sizes necessitate scalable, automated tutoring solutions to adequately support student learning. While Large Language Models (LLMs) like GPT-3.5 have demonstrated potential in assisting students through question-answering, educators have significant concerns about students misusing LLMs or LLMs misleading students with inaccurate answers. This paper introduces CourseAssist, a novel LLM-based tutoring system tailored for computer science education. Unlike generic LLM systems, CourseAssist leverages retrieval-augmented generation along with user intent classification and post-processing to ensure that responses align with specific course learning goals, thereby addressing the pedagogical appropriateness of LLMs in educational settings. I evaluate CourseAssist against a baseline of GPT 3.5 using a dataset of 50 question-answer pairs from a programming languages course, focusing on the criteria of usefulness, accuracy, and pedagogical appropriateness. Evaluation results show that CourseAssist significantly outperforms the baseline, demonstrating its potential to serve as an effective learning assistant. This work not only highlights the importance of deliberate design considerations in LLM-based educational tools but also opens up avenues for future research, particularly in understanding user interactions with such systems in real-world scenarios and integrating human educators into LLM-based tutoring systems.</description>
      <guid isPermaLink="false">oai:arXiv.org:2407.10246v1</guid>
      <category>cs.CY</category>
      <category>cs.AI</category>
      <category>cs.HC</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <dc:creator>Ty Feng</dc:creator>
    </item>
    <item>
      <title>Mapping the Scholarship of Dark Pattern Regulation: A Systematic Review of Concepts, Regulatory Paradigms, and Solutions from an Interdisciplinary Perspective</title>
      <link>https://arxiv.org/abs/2407.10340</link>
      <description>arXiv:2407.10340v1 Announce Type: cross 
Abstract: Dark patterns, design tricks used on online interfaces to manipulate users decision-making process, have raised public concerns. However, research on regulation of dark pattern remains underdeveloped and scattered, particularly regarding scholars views on the concept, regulatory paradigms, and solutions. Following PRISMA guidelines, this paper systematically reviews the formats and content of regulatory discussions on dark patterns from the interdisciplinary scholarship of Law and Human-Computer Interaction. A total of 65 studies were analysed through content and thematic analysis. This study synthesises the unique trends and characteristics of legal scholarship on dark patterns, identifying five root problems and triple layered harms. It critiques current regulations in terms of legal theories and sectoral legislations, highlighting their inadequacies in addressing dark patterns. The paper also critically examines existing proposed solutions, including paradigmatic shifts in legal doctrines, refinements to existing frameworks, technical design-embedded solutions, and accountability measures for design practices. This research critically discusses the current barriers to effective dark pattern regulations and explores promising regulatory solutions. The difficulty in identifying the normative nature of various forms of dark patterns, in identifying evident and actionable harm, and the expanding scope of dark patterns connotation inherently hinders effective regulation. However, technical design-embedded solutions, accountability frameworks, and practical design guidelines offer potential routes for more proactive regulation, while legal pluralism stands as a promising macro-level change in regulatory paradigms for dark pattern regulation.</description>
      <guid isPermaLink="false">oai:arXiv.org:2407.10340v1</guid>
      <category>cs.CY</category>
      <category>cs.AI</category>
      <category>cs.HC</category>
      <category>cs.IT</category>
      <category>cs.SI</category>
      <category>math.IT</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Weiwei Yi, Zihao Li</dc:creator>
    </item>
    <item>
      <title>The Perceived Learning Behaviors and Assessment Techniques of First-Year Students in Computer Science: An Empirical Study</title>
      <link>https://arxiv.org/abs/2407.10368</link>
      <description>arXiv:2407.10368v1 Announce Type: cross 
Abstract: The objective of our study is to ascertain the present learning behaviors, driving forces, and assessment techniques as perceived by first-year students, and to examine them through the lens of the most recent developments (pandemic, shift to remote instruction, return to in-person instruction). Educators and educational institutions can create a more accommodating learning environment that takes into account the varied needs and preferences of students by recognizing and implementing these findings, which will ultimately improve the quality of education as a whole. Students believe that in-person instruction is the most effective way to learn, with exercise-based learning, group instruction, and pair programming. Our research indicates that, for evaluation methods, there is a preference for practical and written examinations. Our findings also underscore the importance of incorporating real-world scenarios, encouraging interactive learning approaches, and creating engaging educational environments.</description>
      <guid isPermaLink="false">oai:arXiv.org:2407.10368v1</guid>
      <category>cs.CY</category>
      <category>cs.HC</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <arxiv:DOI>10.5220/0012674000003693</arxiv:DOI>
      <dc:creator>Manuela Andreea Petrescu, Tudor Dan Mihoc</dc:creator>
    </item>
    <item>
      <title>Laypeople's Egocentric Perceptions of Copyright for AI-Generated Art</title>
      <link>https://arxiv.org/abs/2407.10546</link>
      <description>arXiv:2407.10546v1 Announce Type: cross 
Abstract: Recent breakthroughs in generative AI (GenAI) have fueled debates concerning the status of AI-generated creations under copyright law. This research investigates laypeople's perceptions ($N$ = 424) of AI-generated art concerning factors associated with copyright protection. Inspired by prior work suggesting that people show egocentric biases when evaluating their own creative outputs, we also test if the same holds for AI-generated art. Namely, we study the differences between the perceptions of those who have something to gain from copyright protection -- creators of AI-generated art -- and uninvested third parties.
  To answer our research questions, we held an incentivized AI art competition, in which some participants used a GenAI model to generate images for consideration while others evaluated these submissions. We find that participants are most likely to attribute authorship and copyright over AI-generated images to the users who prompted the AI system to generate the image and the artists whose creations were used for training the AI model. We also find that participants egocentrically favored their own art over other participants' art and rated their own creations higher than other people evaluated them. Moreover, our results suggest that people judge their own AI-generated art more favorably with respect to some factors (creativity and effort) but not others (skills). Our findings have implications for future debates concerning the potential copyright protection of AI-generated outputs.</description>
      <guid isPermaLink="false">oai:arXiv.org:2407.10546v1</guid>
      <category>cs.CY</category>
      <category>cs.HC</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Gabriel Lima, Nina Grgi\'c-Hla\v{c}a, Elissa Redmiles</dc:creator>
    </item>
    <item>
      <title>Cutting Through the Clutter: The Potential of LLMs for Efficient Filtration in Systematic Literature Reviews</title>
      <link>https://arxiv.org/abs/2407.10652</link>
      <description>arXiv:2407.10652v1 Announce Type: cross 
Abstract: In academic research, systematic literature reviews are foundational and highly relevant, yet tedious to create due to the high volume of publications and labor-intensive processes involved. Systematic selection of relevant papers through conventional means like keyword-based filtering techniques can sometimes be inadequate, plagued by semantic ambiguities and inconsistent terminology, which can lead to sub-optimal outcomes. To mitigate the required extensive manual filtering, we explore and evaluate the potential of using Large Language Models (LLMs) to enhance the efficiency, speed, and precision of literature review filtering, reducing the amount of manual screening required. By using models as classification agents acting on a structured database only, we prevent common problems inherent in LLMs, such as hallucinations. We evaluate the real-world performance of such a setup during the construction of a recent literature survey paper with initially more than 8.3k potentially relevant articles under consideration and compare this with human performance on the same dataset. Our findings indicate that employing advanced LLMs like GPT-4o, Claude 3.5 Sonnet, Gemini 1.5 Flash, or Llama3 with simple prompting can significantly reduce the time required for literature filtering - from usually weeks of manual research to only a few minutes. Simultaneously, we crucially show that false negatives can indeed be controlled through a consensus scheme, achieving recalls &gt;98.8% at or even beyond the typical human error threshold, thereby also providing for more accurate and relevant articles selected. Our research not only demonstrates a substantial improvement in the methodology of literature reviews but also sets the stage for further integration and extensive future applications of responsible AI in academic research practices.</description>
      <guid isPermaLink="false">oai:arXiv.org:2407.10652v1</guid>
      <category>cs.LG</category>
      <category>cs.DL</category>
      <category>cs.HC</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Lucas Joos, Daniel A. Keim, Maximilian T. Fischer</dc:creator>
    </item>
    <item>
      <title>XEQ Scale for Evaluating XAI Experience Quality Grounded in Psychometric Theory</title>
      <link>https://arxiv.org/abs/2407.10662</link>
      <description>arXiv:2407.10662v1 Announce Type: cross 
Abstract: Explainable Artificial Intelligence (XAI) aims to improve the transparency of autonomous decision-making through explanations. Recent literature has emphasised users' need for holistic "multi-shot" explanations and the ability to personalise their engagement with XAI systems. We refer to this user-centred interaction as an XAI Experience. Despite advances in creating XAI experiences, evaluating them in a user-centred manner has remained challenging. To address this, we introduce the XAI Experience Quality (XEQ) Scale (pronounced "Seek" Scale), for evaluating the user-centred quality of XAI experiences. Furthermore, XEQ quantifies the quality of experiences across four evaluation dimensions: learning, utility, fulfilment and engagement. These contributions extend the state-of-the-art of XAI evaluation, moving beyond the one-dimensional metrics frequently developed to assess single-shot explanations. In this paper, we present the XEQ scale development and validation process, including content validation with XAI experts as well as discriminant and construct validation through a large-scale pilot study. Out pilot study results offer strong evidence that establishes the XEQ Scale as a comprehensive framework for evaluating user-centred XAI experiences.</description>
      <guid isPermaLink="false">oai:arXiv.org:2407.10662v1</guid>
      <category>cs.AI</category>
      <category>cs.HC</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Anjana Wijekoon, Nirmalie Wiratunga, David Corsar, Kyle Martin, Ikechukwu Nkisi-Orji, Belen D\'iaz-Agudo, Derek Bridge</dc:creator>
    </item>
    <item>
      <title>GPT Sonograpy: Hand Gesture Decoding from Forearm Ultrasound Images via VLM</title>
      <link>https://arxiv.org/abs/2407.10870</link>
      <description>arXiv:2407.10870v1 Announce Type: cross 
Abstract: Large vision-language models (LVLMs), such as the Generative Pre-trained Transformer 4-omni (GPT-4o), are emerging multi-modal foundation models which have great potential as powerful artificial-intelligence (AI) assistance tools for a myriad of applications, including healthcare, industrial, and academic sectors. Although such foundation models perform well in a wide range of general tasks, their capability without fine-tuning is often limited in specialized tasks. However, full fine-tuning of large foundation models is challenging due to enormous computation/memory/dataset requirements. We show that GPT-4o can decode hand gestures from forearm ultrasound data even with no fine-tuning, and improves with few-shot, in-context learning.</description>
      <guid isPermaLink="false">oai:arXiv.org:2407.10870v1</guid>
      <category>cs.CV</category>
      <category>cs.AI</category>
      <category>cs.HC</category>
      <category>cs.LG</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Keshav Bimbraw, Ye Wang, Jing Liu, Toshiaki Koike-Akino</dc:creator>
    </item>
    <item>
      <title>Innovation Resistance Theory in Action: Unveiling Barriers to Open Government Data Adoption by Public Organizations to Unlock Open Data Innovation</title>
      <link>https://arxiv.org/abs/2407.10883</link>
      <description>arXiv:2407.10883v1 Announce Type: cross 
Abstract: Open Government Data (OGD) plays a pivotal role in fostering data-driven innovation and sustainability across various sectors. Despite its potential, many public organizations are reluctant to share their data openly. While existing research has explored factors impacting the public organizations intention to share OGD, there is a paucity of research applying theoretical models to investigate the resistance by public organizations to making government data publicly available. This study addresses the gap by developing an Innovation Resistance Theory (IRT) model tailored to OGD that allows identifying predictors of resistance among public agencies. We develop an initial model based on literature and refine it through interviews with 21 public agencies across six countries. The final model describes 39 barriers related to usage, value, risks, tradition, and image. The findings contribute to the literature by adapting IRT to the context of OGD, an area where its application has been notably limited. As such, this study addresses the growing demand for novel theoretical frameworks to examine OGD adoption barriers. Practical insights are provided to support policymakers in creating data ecosystems that encourage data openness and address challenges in OGD adoption.</description>
      <guid isPermaLink="false">oai:arXiv.org:2407.10883v1</guid>
      <category>cs.CY</category>
      <category>cs.DB</category>
      <category>cs.HC</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Anastasija Nikiforova, Antoine Clarinval, Anneke Zuiderwijk, Daniel Rudmark, Petar Milic, Katrin Rajam\"ae-Soosaar</dc:creator>
    </item>
    <item>
      <title>'One Style Does Not Regulate All': Moderation Practices in Public and Private WhatsApp Groups</title>
      <link>https://arxiv.org/abs/2401.08091</link>
      <description>arXiv:2401.08091v2 Announce Type: replace 
Abstract: WhatsApp is the largest social media platform in the Global South and is a virulent force in global misinformation and political propaganda. Due to end-to-end encryption WhatsApp can barely review any content and mostly rely on volunteer moderation by group admins. Yet, little is known about how WhatsApp group admins manage their groups, what factors and values influence moderation decisions, and what challenges they face while managing their groups. To fill this gap, we interviewed admins of 32 diverse groups and reviewed content from 30 public groups in India and Bangladesh. We observed notable differences in the formation, members' behavior, and moderation of public versus private groups, as well as in how WhatsApp admins operate compared to those on other platforms. We used Baumrind's typology of 'parenting styles' as a lens to examine how admins enact care and control during volunteer moderation. We identified four styles based on how caring and controlling the admins are and discuss design recommendations to help them better manage problematic content in WhatsApp groups.</description>
      <guid isPermaLink="false">oai:arXiv.org:2401.08091v2</guid>
      <category>cs.HC</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Farhana Shahid, Dhruv Agarwal, Aditya Vashistha</dc:creator>
    </item>
    <item>
      <title>Stepping into the Right Shoes: The Effects of User-Matched Avatar Ethnicity and Gender on Sense of Embodiment in Virtual Reality</title>
      <link>https://arxiv.org/abs/2402.03279</link>
      <description>arXiv:2402.03279v4 Announce Type: replace 
Abstract: In many consumer virtual reality (VR) applications, users embody predefined characters that offer minimal customization options, frequently emphasizing storytelling over user choice. We explore whether matching a user's physical characteristics, specifically ethnicity and gender, with their virtual self-avatar affects their sense of embodiment in VR. We conducted a 2 x 2 within-subjects experiment (n=32) with a diverse user population to explore the impact of matching or not matching a user's self-avatar to their ethnicity and gender on their sense of embodiment. Our results indicate that matching the ethnicity of the user and their self-avatar significantly enhances sense of embodiment regardless of gender, extending across various aspects, including appearance, response, and ownership. We also found that matching gender significantly enhanced ownership, suggesting that this aspect is influenced by matching both ethnicity and gender. Interestingly, we found that matching ethnicity specifically affects self-location while matching gender specifically affects one's body ownership.</description>
      <guid isPermaLink="false">oai:arXiv.org:2402.03279v4</guid>
      <category>cs.HC</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <arxiv:DOI>10.1109/TVCG.2024.3372067</arxiv:DOI>
      <arxiv:journal_reference>In IEEE Transactions on Visualization and Computer Graphics, vol. 30, no. 5, pp. 2434-2443, May 2024</arxiv:journal_reference>
      <dc:creator>Tiffany D. Do, Camille Isabella Protko, Ryan P. McMahan</dc:creator>
    </item>
    <item>
      <title>Towards a Quality Approach to Hierarchical Color Maps</title>
      <link>https://arxiv.org/abs/2407.08287</link>
      <description>arXiv:2407.08287v2 Announce Type: replace 
Abstract: To improve the perception of hierarchical structures in data sets, several color map generation algorithms have been proposed to take this structure into account. But the design of hierarchical color maps elicits different requirements to those of color maps for tabular data. Within this paper, we make an initial effort to put design rules from the color map literature into the context of hierarchical color maps. We investigate the impact of several design decisions and provide recommendations for various analysis scenarios. Thus, we lay the foundation for objective quality criteria to evaluate hierarchical color maps.</description>
      <guid isPermaLink="false">oai:arXiv.org:2407.08287v2</guid>
      <category>cs.HC</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Tobias Mertz (Fraunhofer IGD), J\"orn Kohlhammer (Fraunhofer IGD, TU Darmstadt)</dc:creator>
    </item>
    <item>
      <title>Large Language Models and Games: A Survey and Roadmap</title>
      <link>https://arxiv.org/abs/2402.18659</link>
      <description>arXiv:2402.18659v2 Announce Type: replace-cross 
Abstract: Recent years have seen an explosive increase in research on large language models (LLMs), and accompanying public engagement on the topic. While starting as a niche area within natural language processing, LLMs have shown remarkable potential across a broad range of applications and domains, including games. This paper surveys the current state of the art across the various applications of LLMs in and for games, and identifies the different roles LLMs can take within a game. Importantly, we discuss underexplored areas and promising directions for future uses of LLMs in games and we reconcile the potential and limitations of LLMs within the games domain. As the first comprehensive survey and roadmap at the intersection of LLMs and games, we are hopeful that this paper will serve as the basis for groundbreaking research and innovation in this exciting new field.</description>
      <guid isPermaLink="false">oai:arXiv.org:2402.18659v2</guid>
      <category>cs.CL</category>
      <category>cs.AI</category>
      <category>cs.HC</category>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Roberto Gallotta, Graham Todd, Marvin Zammit, Sam Earle, Antonios Liapis, Julian Togelius, Georgios N. Yannakakis</dc:creator>
    </item>
    <item>
      <title>Android in the Zoo: Chain-of-Action-Thought for GUI Agents</title>
      <link>https://arxiv.org/abs/2403.02713</link>
      <description>arXiv:2403.02713v2 Announce Type: replace-cross 
Abstract: Large language model (LLM) leads to a surge of autonomous GUI agents for smartphone, which completes a task triggered by natural language through predicting a sequence of actions of API. Even though the task highly relies on past actions and visual observations, existing studies typically consider little semantic information carried out by intermediate screenshots and screen operations. To address this, this work presents Chain-of-Action-Thought (dubbed CoAT), which takes the description of the previous actions, the current screen, and more importantly the action thinking of what actions should be performed and the outcomes led by the chosen action. We demonstrate that, in a zero-shot setting upon three off-the-shelf LMMs, CoAT significantly improves the action prediction compared to previous proposed context modeling. To further facilitate the research in this line, we construct a dataset Android-In-The-Zoo (AitZ), which contains 18,643 screen-action pairs together with chain-of-action-thought annotations. Experiments show that fine-tuning a 1B model (i.e. AUTO-UI-base) on our AitZ dataset achieves on-par performance with CogAgent-Chat-18B.</description>
      <guid isPermaLink="false">oai:arXiv.org:2403.02713v2</guid>
      <category>cs.CL</category>
      <category>cs.CV</category>
      <category>cs.HC</category>
      <category>cs.LG</category>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-sa/4.0/</dc:rights>
      <dc:creator>Jiwen Zhang, Jihao Wu, Yihua Teng, Minghui Liao, Nuo Xu, Xiao Xiao, Zhongyu Wei, Duyu Tang</dc:creator>
    </item>
    <item>
      <title>Stop! In the Name of Flaws: Disentangling Personal Names and Sociodemographic Attributes in NLP</title>
      <link>https://arxiv.org/abs/2405.17159</link>
      <description>arXiv:2405.17159v2 Announce Type: replace-cross 
Abstract: Personal names simultaneously differentiate individuals and categorize them in ways that are important in a given society. While the natural language processing community has thus associated personal names with sociodemographic characteristics in a variety of tasks, researchers have engaged to varying degrees with the established methodological problems in doing so. To guide future work that uses names and sociodemographic characteristics, we provide an overview of relevant research: first, we present an interdisciplinary background on names and naming. We then survey the issues inherent to associating names with sociodemographic attributes, covering problems of validity (e.g., systematic error, construct validity), as well as ethical concerns (e.g., harms, differential impact, cultural insensitivity). Finally, we provide guiding questions along with normative recommendations to avoid validity and ethical pitfalls when dealing with names and sociodemographic characteristics in natural language processing.</description>
      <guid isPermaLink="false">oai:arXiv.org:2405.17159v2</guid>
      <category>cs.CL</category>
      <category>cs.CY</category>
      <category>cs.HC</category>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-sa/4.0/</dc:rights>
      <dc:creator>Vagrant Gautam, Arjun Subramonian, Anne Lauscher, Os Keyes</dc:creator>
    </item>
    <item>
      <title>Open-Source Conversational AI with SpeechBrain 1.0</title>
      <link>https://arxiv.org/abs/2407.00463</link>
      <description>arXiv:2407.00463v3 Announce Type: replace-cross 
Abstract: SpeechBrain is an open-source Conversational AI toolkit based on PyTorch, focused particularly on speech processing tasks such as speech recognition, speech enhancement, speaker recognition, text-to-speech, and much more. It promotes transparency and replicability by releasing both the pre-trained models and the complete "recipes" of code and algorithms required for training them. This paper presents SpeechBrain 1.0, a significant milestone in the evolution of the toolkit, which now has over 200 recipes for speech, audio, and language processing tasks, and more than 100 models available on Hugging Face. SpeechBrain 1.0 introduces new technologies to support diverse learning modalities, Large Language Model (LLM) integration, and advanced decoding strategies, along with novel models, tasks, and modalities. It also includes a new benchmark repository, offering researchers a unified platform for evaluating models across diverse tasks</description>
      <guid isPermaLink="false">oai:arXiv.org:2407.00463v3</guid>
      <category>cs.LG</category>
      <category>cs.AI</category>
      <category>cs.CL</category>
      <category>cs.HC</category>
      <category>eess.AS</category>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Mirco Ravanelli, Titouan Parcollet, Adel Moumen, Sylvain de Langen, Cem Subakan, Peter Plantinga, Yingzhi Wang, Pooneh Mousavi, Luca Della Libera, Artem Ploujnikov, Francesco Paissan, Davide Borra, Salah Zaiem, Zeyu Zhao, Shucong Zhang, Georgios Karakasidis, Sung-Lin Yeh, Aku Rouhe, Rudolf Braun, Florian Mai, Juan Zuluaga-Gomez, Seyed Mahed Mousavi, Andreas Nautsch, Xuechen Liu, Sangeet Sagar, Jarod Duret, Salima Mdhaffar, Gaelle Laperriere, Renato De Mori, Yannick Esteve</dc:creator>
    </item>
    <item>
      <title>Roleplay-doh: Enabling Domain-Experts to Create LLM-simulated Patients via Eliciting and Adhering to Principles</title>
      <link>https://arxiv.org/abs/2407.00870</link>
      <description>arXiv:2407.00870v2 Announce Type: replace-cross 
Abstract: Recent works leverage LLMs to roleplay realistic social scenarios, aiding novices in practicing their social skills. However, simulating sensitive interactions, such as in mental health, is challenging. Privacy concerns restrict data access, and collecting expert feedback, although vital, is laborious. To address this, we develop Roleplay-doh, a novel human-LLM collaboration pipeline that elicits qualitative feedback from a domain-expert, which is transformed into a set of principles, or natural language rules, that govern an LLM-prompted roleplay. We apply this pipeline to enable senior mental health supporters to create customized AI patients for simulated practice partners for novice counselors. After uncovering issues in GPT-4 simulations not adhering to expert-defined principles, we also introduce a novel principle-adherence prompting pipeline which shows 30% improvements in response quality and principle following for the downstream task. Via a user study with 25 counseling experts, we demonstrate that the pipeline makes it easy and effective to create AI patients that more faithfully resemble real patients, as judged by creators and third-party counselors. See our project website at https://roleplay-doh.github.io/ for code and data.</description>
      <guid isPermaLink="false">oai:arXiv.org:2407.00870v2</guid>
      <category>cs.CL</category>
      <category>cs.HC</category>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Ryan Louie, Ananjan Nandi, William Fang, Cheng Chang, Emma Brunskill, Diyi Yang</dc:creator>
    </item>
    <item>
      <title>What Do People Think about Sentient AI?</title>
      <link>https://arxiv.org/abs/2407.08867</link>
      <description>arXiv:2407.08867v2 Announce Type: replace-cross 
Abstract: With rapid advances in machine learning, many people in the field have been discussing the rise of digital minds and the possibility of artificial sentience. Future developments in AI capabilities and safety will depend on public opinion and human-AI interaction. To begin to fill this research gap, we present the first nationally representative survey data on the topic of sentient AI: initial results from the Artificial Intelligence, Morality, and Sentience (AIMS) survey, a preregistered and longitudinal study of U.S. public opinion that began in 2021. Across one wave of data collection in 2021 and two in 2023 (total N = 3,500), we found mind perception and moral concern for AI well-being in 2021 were higher than predicted and significantly increased in 2023: for example, 71% agree sentient AI deserve to be treated with respect, and 38% support legal rights. People have become more threatened by AI, and there is widespread opposition to new technologies: 63% support a ban on smarter-than-human AI, and 69% support a ban on sentient AI. Expected timelines are surprisingly short and shortening with a median forecast of sentient AI in only five years and artificial general intelligence in only two years. We argue that, whether or not AIs become sentient, the discussion itself may overhaul human-computer interaction and shape the future trajectory of AI technologies, including existential risks and opportunities.</description>
      <guid isPermaLink="false">oai:arXiv.org:2407.08867v2</guid>
      <category>cs.AI</category>
      <category>cs.CY</category>
      <category>cs.ET</category>
      <category>cs.HC</category>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Jacy Reese Anthis, Janet V. T. Pauketat, Ali Ladak, Aikaterina Manoli</dc:creator>
    </item>
  </channel>
</rss>
