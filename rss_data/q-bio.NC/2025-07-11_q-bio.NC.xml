<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>q-bio.NC updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/q-bio.NC</link>
    <description>q-bio.NC updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/q-bio.NC" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Fri, 11 Jul 2025 04:00:05 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Fri, 11 Jul 2025 00:00:00 -0400</pubDate>
    <skipDays>
      <day>Sunday</day>
      <day>Saturday</day>
    </skipDays>
    <item>
      <title>Astrocyte-Mediated Higher-Order Control of Synaptic Plasticity</title>
      <link>https://arxiv.org/abs/2507.07693</link>
      <description>arXiv:2507.07693v1 Announce Type: new 
Abstract: The dynamics of higher-order topological signals are increasingly recognized as a key aspect of the activity of complex systems. A paradigmatic example are synaptic dynamics: synaptic efficacy changes over time driven by different mechanisms. Beyond traditional node-driven short-term plasticity mechanisms, the role of astrocyte modulation through higher-order interactions, in the so-called tripartite synapse, is increasingly recognized. However, the competition and interplay between node-driven and higher-order mechanisms have yet to be considered. Here, we introduce a simple higher-order model of the tripartite synapse accounting for astrocyte-synapse-neuron interactions in short-term plasticity. In the model, astrocyte gliotransmission and pre-synaptic intrinsic facilitation mechanisms jointly modulate the probability of neurotransmitter release at the synapse, generalizing previous short-term plasticity models. We investigate the implications of such mechanisms in a minimal recurrent motif -- a directed ring of three excitatory leaky integrate-and-fire neurons -- where one neuron receives external stimulation that propagates through the circuit. Due to its strong recurrence, the circuit is highly prone to self-sustained activity, which can make it insensitive to external input. By introducing higher-order interactions among different synapses through astrocyte modulation, we show that higher-order modulation robustly stabilizes circuit dynamics and expands the parameter space that supports stimulus-driven activity. Our findings highlight a plausible mechanism by which astrocytes can reshape effective connectivity and enhance information processing through higher-order structural interactions -- even in the simplest recurrent circuits.</description>
      <guid isPermaLink="false">oai:arXiv.org:2507.07693v1</guid>
      <category>q-bio.NC</category>
      <category>cond-mat.dis-nn</category>
      <pubDate>Fri, 11 Jul 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Gustavo Menesse, Ana P. Mill\'an, Joaqu\'in J. Torres</dc:creator>
    </item>
    <item>
      <title>OMiSO: Adaptive optimization of state-dependent brain stimulation to shape neural population states</title>
      <link>https://arxiv.org/abs/2507.07858</link>
      <description>arXiv:2507.07858v1 Announce Type: new 
Abstract: The coordinated activity of neural populations underlies myriad brain functions. Manipulating this activity using brain stimulation techniques has great potential for scientific and clinical applications, as it provides a tool to causally influence brain function. The state of the brain affects how neural populations respond to incoming sensory stimuli. Thus, taking into account pre-stimulation neural population activity may be crucial to achieve a desired causal manipulation using stimulation. In this work, we propose Online MicroStimulation Optimization (OMiSO), a brain stimulation framework that leverages brain state information to find stimulation parameters that can drive neural population activity toward specified states. OMiSO includes two key advances: i) it leverages the pre-stimulation brain state to choose optimal stimulation parameters, and ii) it adaptively refines the choice of those parameters by considering newly-observed stimulation responses. We tested OMiSO by applying intracortical electrical microstimulation in a monkey and found that it outperformed competing methods that do not incorporate these advances. Taken together, OMiSO provides greater accuracy in achieving specified activity states, thereby advancing neuromodulation technologies for understanding the brain and for treating brain disorders.</description>
      <guid isPermaLink="false">oai:arXiv.org:2507.07858v1</guid>
      <category>q-bio.NC</category>
      <pubDate>Fri, 11 Jul 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <dc:creator>Yuki Minai, Joana Soldado-Magraner, Byron M. Yu, Matthew A. Smith</dc:creator>
    </item>
    <item>
      <title>A novel approach for classifying Monoamine Neurotransmitters by applying Machine Learning on UV plasmonic-engineered Auto Fluorescence Time Decay Series (AFTDS)</title>
      <link>https://arxiv.org/abs/2507.07227</link>
      <description>arXiv:2507.07227v1 Announce Type: cross 
Abstract: This study introduces a hybrid approach integrating advanced plasmonic nanomaterials and machine learning (ML) for high-precision biomolecule detection. We leverage aluminum concave nanocubes (AlCNCs) as an innovative plasmonic substrate to enhance the native fluorescence of neurotransmitters, including dopamine (DA), norepinephrine (NE), and 3,4-Dihydroxyphenylacetic acid (DOPAC). AlCNCs amplify weak fluorescence signals, enabling probe-free, label-free detection and differentiation of these molecules with great sensitivity and specificity. To further improve classification accuracy, we employ ML algorithms, with Long Short-Term Memory (LSTM) networks playing a central role in analyzing time-dependent fluorescence data. Comparative evaluations with k-Nearest Neighbors (KNN) and Random Forest (RF) demonstrate the superior performance of LSTM in distinguishing neurotransmitters. The results reveal that AlCNC substrates provide up to a 12-fold enhancement in fluorescence intensity for DA, 9-fold for NE, and 7-fold for DOPAC compared to silicon substrates. At the same time, ML algorithms achieve classification accuracy exceeding 89%. This interdisciplinary methodology bridges the gap between nanotechnology and ML, showcasing the synergistic potential of AlCNC-enhanced native fluorescence and ML in biosensing. The framework paves the way for probe-free, label-free biomolecule profiling, offering transformative implications for biomedical diagnostics and neuroscience research.</description>
      <guid isPermaLink="false">oai:arXiv.org:2507.07227v1</guid>
      <category>q-bio.BM</category>
      <category>q-bio.NC</category>
      <pubDate>Fri, 11 Jul 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Mohammad Mohammadi, Sima Najafzadehkhoei, George Vega Yon, Yunshan Wang</dc:creator>
    </item>
    <item>
      <title>A statistical physics framework for optimal learning</title>
      <link>https://arxiv.org/abs/2507.07907</link>
      <description>arXiv:2507.07907v1 Announce Type: cross 
Abstract: Learning is a complex dynamical process shaped by a range of interconnected decisions. Careful design of hyperparameter schedules for artificial neural networks or efficient allocation of cognitive resources by biological learners can dramatically affect performance. Yet, theoretical understanding of optimal learning strategies remains sparse, especially due to the intricate interplay between evolving meta-parameters and nonlinear learning dynamics. The search for optimal protocols is further hindered by the high dimensionality of the learning space, often resulting in predominantly heuristic, difficult to interpret, and computationally demanding solutions. Here, we combine statistical physics with control theory in a unified theoretical framework to identify optimal protocols in prototypical neural network models. In the high-dimensional limit, we derive closed-form ordinary differential equations that track online stochastic gradient descent through low-dimensional order parameters. We formulate the design of learning protocols as an optimal control problem directly on the dynamics of the order parameters with the goal of minimizing the generalization error at the end of training. This framework encompasses a variety of learning scenarios, optimization constraints, and control budgets. We apply it to representative cases, including optimal curricula, adaptive dropout regularization and noise schedules in denoising autoencoders. We find nontrivial yet interpretable strategies highlighting how optimal protocols mediate crucial learning tradeoffs, such as maximizing alignment with informative input directions while minimizing noise fitting. Finally, we show how to apply our framework to real datasets. Our results establish a principled foundation for understanding and designing optimal learning protocols and suggest a path toward a theory of meta-learning grounded in statistical physics.</description>
      <guid isPermaLink="false">oai:arXiv.org:2507.07907v1</guid>
      <category>cond-mat.dis-nn</category>
      <category>cond-mat.stat-mech</category>
      <category>cs.LG</category>
      <category>q-bio.NC</category>
      <pubDate>Fri, 11 Jul 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Francesca Mignacco, Francesco Mori</dc:creator>
    </item>
    <item>
      <title>Multigranular Evaluation for Brain Visual Decoding</title>
      <link>https://arxiv.org/abs/2507.07993</link>
      <description>arXiv:2507.07993v1 Announce Type: cross 
Abstract: Existing evaluation protocols for brain visual decoding predominantly rely on coarse metrics that obscure inter-model differences, lack neuroscientific foundation, and fail to capture fine-grained visual distinctions. To address these limitations, we introduce BASIC, a unified, multigranular evaluation framework that jointly quantifies structural fidelity, inferential alignment, and contextual coherence between decoded and ground truth images. For the structural level, we introduce a hierarchical suite of segmentation-based metrics, including foreground, semantic, instance, and component masks, anchored in granularity-aware correspondence across mask structures. For the semantic level, we extract structured scene representations encompassing objects, attributes, and relationships using multimodal large language models, enabling detailed, scalable, and context-rich comparisons with ground-truth stimuli. We benchmark a diverse set of visual decoding methods across multiple stimulus-neuroimaging datasets within this unified evaluation framework. Together, these criteria provide a more discriminative, interpretable, and comprehensive foundation for measuring brain visual decoding methods.</description>
      <guid isPermaLink="false">oai:arXiv.org:2507.07993v1</guid>
      <category>cs.CV</category>
      <category>cs.AI</category>
      <category>eess.IV</category>
      <category>q-bio.NC</category>
      <pubDate>Fri, 11 Jul 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Weihao Xia, Cengiz Oztireli</dc:creator>
    </item>
    <item>
      <title>Clarifying the conceptual dimensions of representation in neuroscience</title>
      <link>https://arxiv.org/abs/2403.14046</link>
      <description>arXiv:2403.14046v2 Announce Type: replace 
Abstract: Despite the centrality of the notion of representation to its explanations, neuroscience lacks a unified framework for the concepts used to characterize representation, leading to disparate use of terminology and measures associated with representation. To offer clarification, we propose a core set of conceptual dimensions that characterize representations in neuroscience. These dimensions describe relations between a neural response, features that may be represented, and downstream effects of the neural response. A neural response may be shown to be sensitive and specific to a feature, invariant to other features, and functional, which means that it is used downstream in the brain. We use information-theoretic measures to introduce these conceptual dimensions unambiguously and explain how data analysis methods such as correlational analyses, decoding and encoding models, representational similarity analysis, and tests of statistical dependence or adaptation relate to our framework. We consider several canonical examples, including the representation of orientation, numerosity, and spatial location, which illustrate how the evidence put forth in support or criticism of representational conclusions is systematized by our framework. By offering a unified conceptual framework we hope to aid the comparison and integration of results across studies and research groups and to help determine when evidence for a representational conclusion is strong.</description>
      <guid isPermaLink="false">oai:arXiv.org:2403.14046v2</guid>
      <category>q-bio.NC</category>
      <pubDate>Fri, 11 Jul 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Stephan Pohl, Edgar Y. Walker, David L. Barack, Jennifer Lee, Rachel N. Denison, Ned Block, Florent Meyniel, Wei Ji Ma</dc:creator>
    </item>
    <item>
      <title>Time Makes Space: Emergence of Place Fields in Networks Encoding Temporally Continuous Sensory Experiences</title>
      <link>https://arxiv.org/abs/2408.05798</link>
      <description>arXiv:2408.05798v3 Announce Type: replace 
Abstract: The vertebrate hippocampus is believed to use recurrent connectivity in area CA3 to support episodic memory recall from partial cues. This brain area also contains place cells, whose location-selective firing fields implement maps supporting spatial memory. Here we show that place cells emerge in networks trained to remember temporally continuous sensory episodes. We model CA3 as a recurrent autoencoder that recalls and reconstructs sensory experiences from noisy and partially occluded observations by agents traversing simulated rooms. The agents move in realistic trajectories modeled from rodents and environments are modeled as high-dimensional sensory experience maps. Training our autoencoder to pattern-complete and reconstruct experiences with a constraint on total activity causes spatially localized firing fields, i.e., place cells, to emerge in the encoding layer. The emergent place fields reproduce key aspects of hippocampal phenomenology: a) remapping (maintenance of and reversion to distinct learned maps in different environments), implemented via repositioning of experience manifolds in the network's hidden layer, b) orthogonality of spatial representations in different arenas, c) robust place field emergence in differently shaped rooms, with single units showing multiple place fields in large or complex spaces, and d) slow representational drift of place fields. We argue that these results arise because continuous traversal of space makes sensory experience temporally continuous. We make testable predictions: a) rapidly changing sensory context will disrupt place fields, b) place fields will form even if recurrent connections are blocked, but reversion to previously learned representations upon remapping will be abolished, c) the dimension of temporally smooth experience sets the dimensionality of place fields, including during virtual navigation of abstract spaces.</description>
      <guid isPermaLink="false">oai:arXiv.org:2408.05798v3</guid>
      <category>q-bio.NC</category>
      <category>cs.AI</category>
      <category>cs.LG</category>
      <category>cs.NE</category>
      <pubDate>Fri, 11 Jul 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Zhaoze Wang, Ronald W. Di Tullio, Spencer Rooke, Vijay Balasubramanian</dc:creator>
    </item>
    <item>
      <title>Multi-Site rs-fMRI Domain Alignment for Autism Spectrum Disorder Auxiliary Diagnosis Based on Hyperbolic Space</title>
      <link>https://arxiv.org/abs/2502.05493</link>
      <description>arXiv:2502.05493v4 Announce Type: replace 
Abstract: Increasing the volume of training data can enable the auxiliary diagnostic algorithms for Autism Spectrum Disorder (ASD) to learn more accurate and stable models. However, due to the significant heterogeneity and domain shift in rs-fMRI data across different sites, the accuracy of auxiliary diagnosis remains unsatisfactory. Moreover, there has been limited exploration of multi-source domain adaptation models on ASD recognition, and many existing models lack inherent interpretability, as they do not explicitly incorporate prior neurobiological knowledge such as the hierarchical structure of functional brain networks. To address these challenges, we proposed a domain-adaptive algorithm based on hyperbolic space embedding. Hyperbolic space is naturally suited for representing the topology of complex networks such as brain functional networks. Therefore, we embedded the brain functional network into hyperbolic space and constructed the corresponding hyperbolic space community network to effectively extract latent representations. To address the heterogeneity of data across different sites and the issue of domain shift, we introduce a constraint loss function, Hyperbolic Maximum Mean Discrepancy (HMMD), to align the marginal distributions in the hyperbolic space. Additionally, we employ class prototype alignment to mitigate discrepancies in conditional distributions across domains. Experimental results indicate that the proposed algorithm achieves superior classification performance for ASD compared to baseline models, with improved robustness to multi-site heterogeneity. Specifically, our method achieves an average accuracy improvement of 4.03%. Moreover, its generalization capability is further validated through experiments conducted on extra Major Depressive Disorder (MDD) datasets. The code is available at https://github.com/LYQbyte/H2MSDA.</description>
      <guid isPermaLink="false">oai:arXiv.org:2502.05493v4</guid>
      <category>q-bio.NC</category>
      <pubDate>Fri, 11 Jul 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Yiqian Luo, Qiurong Chen, Fali Li, Peng Xu, Yangsong Zhang</dc:creator>
    </item>
  </channel>
</rss>
