<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>q-bio.NC updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/q-bio.NC</link>
    <description>q-bio.NC updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/q-bio.NC" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Tue, 24 Dec 2024 05:00:20 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Tue, 24 Dec 2024 00:00:00 -0500</pubDate>
    <skipDays>
      <day>Sunday</day>
      <day>Saturday</day>
    </skipDays>
    <item>
      <title>A unified model for the origins of spongiform degeneration and other neuropathological features in prion diseases</title>
      <link>https://arxiv.org/abs/2412.16678</link>
      <description>arXiv:2412.16678v1 Announce Type: new 
Abstract: Decades after their initial observation in prion-infected brain tissues, the identities of virus-like dense particles, varicose tubules, and oval bodies containing parallel bands and fibrils have remained elusive. Our recent work revealed that a phenotype of dilation of the endoplasmic reticulum (ER), most notable for the perinuclear space (PNS), contributes to spongiform degeneration. To assess the significance of this phenotype for the etiology of prion diseases, we explored whether it can be functionally linked to other neuropathological hallmarks observed in these diseases, as this would indicate it to be a central event. Having surveyed the neuropathological record and other distant literature niches, we propose a model in which pathogenic forms of the prion protein poison raft domains, including essential Na+, K+-ATPases (NKAs) embedded within them, thereby triggering an ER-centered cellular rescue program coordinated by the unfolded protein response (UPR). The execution of this program stalls general protein synthesis, causing the deterioration of synaptic spines. As the disease progresses, cells selectively increase sterol biosynthesis, along with ribosome and ER biogenesis. These adaptive rescue attempts cause morphological changes to the ER which manifest as ER dilation or ER hypertrophy in a manner that is influenced by Ca2+ influx into the cell. The nuclear-to-cytoplasmic transport of mRNAs and tRNAs interrupts in late stage disease, thereby depriving ribosomes of supplies and inducing them to aggregate into a paracrystalline form. In support of this model, we share previously reported data, whose features are consistent with the interpretation that 1) the phenotype of ER dilation is observed in major prion diseases, 2) varicose tubules and oval bodies represent ER hypertrophy, and 3) virus-like dense particles are paracrystalline aggregates of inactive ribosomes.</description>
      <guid isPermaLink="false">oai:arXiv.org:2412.16678v1</guid>
      <category>q-bio.NC</category>
      <category>q-bio.MN</category>
      <pubDate>Tue, 24 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Gerold Schmitt-Ulms, Xinzhu Wang, Joel Watts, Stephanie Booth, Wenda Zhao</dc:creator>
    </item>
    <item>
      <title>Three mechanistically different variability and noise sources in the trial-to-trial fluctuations of responses to brain stimulation</title>
      <link>https://arxiv.org/abs/2412.16997</link>
      <description>arXiv:2412.16997v1 Announce Type: new 
Abstract: Motor-evoked potentials (MEPs) are among the few directly observable responses to external brain stimulation and serve a variety of applications, often in the form of input-output (IO) curves. Previous statistical models with two variability sources inherently consider the small MEPs at the low-side plateau as part of the neural recruitment properties. However, recent studies demonstrated that small MEP responses under resting conditions are contaminated and over-shadowed by background noise of mostly technical quality, e.g., caused by the amplifier, and suggested that the neural recruitment curve should continue below this noise level. This work intends to separate physiological variability from background noise and improve the description of recruitment behaviour. We developed a triple-variability-source model around a logarithmic logistic function without a lower plateau and incorporated an additional source for background noise. Compared to models with two or fewer variability sources, our approach better described IO characteristics, evidenced by lower Bayesian Information Criterion scores across all subjects and pulse shapes. The model independently extracted hidden variability information across the stimulated neural system and isolated it from background noise, which led to an accurate estimation of the IO curve parameters. This new model offers a robust tool to analyse brain stimulation IO curves in clinical and experimental neuroscience and reduces the risk of spurious results from inappropriate statistical methods. The presented model together with the corresponding calibration method provides a more accurate representation of MEP responses and variability sources, advances our understanding of cortical excitability, and may improve the assessment of neuromodulation effects.</description>
      <guid isPermaLink="false">oai:arXiv.org:2412.16997v1</guid>
      <category>q-bio.NC</category>
      <category>eess.SP</category>
      <category>q-bio.QM</category>
      <category>stat.AP</category>
      <pubDate>Tue, 24 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Ke Ma, Siwei Liu, Mengjie Qin, Stefan Goetz</dc:creator>
    </item>
    <item>
      <title>Optimal signal transmission and timescale diversity in a model of human brain operating near criticality</title>
      <link>https://arxiv.org/abs/2412.17043</link>
      <description>arXiv:2412.17043v1 Announce Type: new 
Abstract: Cortical neurons exhibit a hierarchy of timescales across brain regions in response to input stimuli, which is thought to be crucial for information processing of different temporal scales. Modeling studies suggest that both intra-regional circuit dynamics as well as cross-regional connectome may contribute to this timescale diversity. Equally important to diverse timescales is the ability to transmit sensory signals reliably across the whole brain. Therefore, the brain must be able to generate diverse timescales while simultaneously minimizing signal attenuation. To understand the dynamical mechanism behind these phenomena, we develop a second-order mean field model of the human brain by applying moment closure and coarse-graining to a digital twin brain model endowed with whole brain structural connectome. Cross-regional coupling strength is found to induced a phase transition from asynchronous activity to synchronous oscillation. By analyzing the input-response properties of the model, we reveal criticality as a unifying mechanism for enabling simultaneously optimal signal transmission and timescales diversity. We show how structural connectome and criticality jointly shape intrinsic timescale hierarchy across the brain.</description>
      <guid isPermaLink="false">oai:arXiv.org:2412.17043v1</guid>
      <category>q-bio.NC</category>
      <category>physics.bio-ph</category>
      <pubDate>Tue, 24 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Yang Qi, Jiexiang Wang, Weiyang Ding, Gustavo Deco, Viktor Jirsa, Wenlian Lu, Jianfeng Feng</dc:creator>
    </item>
    <item>
      <title>Comparison of Spatiotemporal Characteristics of Eye Movements in Non-experts and the Skill Transfer Effects of Gaze Guidance and Annotation Guidance</title>
      <link>https://arxiv.org/abs/2412.17296</link>
      <description>arXiv:2412.17296v1 Announce Type: new 
Abstract: Methods for converting the tacit knowledge of experts into explicit knowledge have drawn increasing attention. Gaze data has emerged as a valuable approach in this effort. However, the effective transfer of tacit knowledge remains a challenge. No studies have directly compared the effects of gaze-based and annotation-based guidance or adequately examined their impacts on skill improvement after instruction. This study examined the effects of gaze and annotation guidance on the spatiotemporal characteristics of eye movements and the skill transfer of expert evaluation techniques in karate kata performances. 28 non-expert participants were assigned to three groups: a gaze guidance group, an annotation guidance group, and a control group. Participants were presented with instructional slideshows based on the expert's gaze data and annotations. Before and after instruction, participants were asked to evaluate karate kata performance videos performed by practitioners with different skill levels. The results showed that the annotation guidance group exhibited an effect of directing gaze toward the presented areas of focus, with a trend of increased total number of fixation areas. On the other hand, while the gaze guidance group was not encouraged to make fixations on multiple areas, the possibility of promoting peripheral vision was inferred based on measurements from the eye-tracking system. Regarding ranking results, 71.4% of participants in the gaze guidance group showed an improvement in ranking skills, with a trend toward better scoring ability compared to the other groups. This demonstrates the necessity of selecting appropriate methods based on instructional goals to transfer tacit knowledge effectively. Gaze-based instructional methods are expected to be versatile and applicable to karate kata and fields such as industry, medicine, and other sports.</description>
      <guid isPermaLink="false">oai:arXiv.org:2412.17296v1</guid>
      <category>q-bio.NC</category>
      <pubDate>Tue, 24 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <dc:creator>Shota Nishijima, Asuka Takai</dc:creator>
    </item>
    <item>
      <title>Asymmetric coupling of non-chaotic Rulkov neurons: fractal attractors, quasi-multistability, and final state sensitivity</title>
      <link>https://arxiv.org/abs/2412.16189</link>
      <description>arXiv:2412.16189v1 Announce Type: cross 
Abstract: Although neuron models have been well-studied for their rich dynamics and biological properties, limited research has been done on the complex geometries that emerge from the basins of attraction and basin boundaries of multistable neuron systems. In this paper, we investigate the geometrical properties of the strange attractors, four-dimensional basins, and fractal basin boundaries of an asymmetrically electrically coupled system of two identical non-chaotic Rulkov neurons. We discover a quasi-multistability in the system emerging from the existence of a chaotic spiking-bursting pseudo-attractor, and we classify and quantify the system's basins of attraction, which are found to have complex fractal geometries. Using the method of uncertainty exponents, we also find that the system exhibits extreme final state sensitivity.</description>
      <guid isPermaLink="false">oai:arXiv.org:2412.16189v1</guid>
      <category>nlin.CD</category>
      <category>math.DS</category>
      <category>q-bio.NC</category>
      <pubDate>Tue, 24 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Brandon B. Le</dc:creator>
    </item>
    <item>
      <title>A Proposal for Extending the Common Model of Cognition to Emotion</title>
      <link>https://arxiv.org/abs/2412.16231</link>
      <description>arXiv:2412.16231v1 Announce Type: cross 
Abstract: Cognition and emotion must be partnered in any complete model of a humanlike mind. This article proposes an extension to the Common Model of Cognition -- a developing consensus concerning what is required in such a mind -- for emotion that includes a linked pair of modules for emotion and metacognitive assessment, plus pervasive connections between these two new modules and the Common Model's existing modules and links.</description>
      <guid isPermaLink="false">oai:arXiv.org:2412.16231v1</guid>
      <category>cs.AI</category>
      <category>q-bio.NC</category>
      <pubDate>Tue, 24 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Paul S. Rosenbloom, John E. Laird, Christian Lebiere, Andrea Stocco, Richard H. Granger, Christian Huyck</dc:creator>
    </item>
    <item>
      <title>Fast Multi-Group Gaussian Process Factor Models</title>
      <link>https://arxiv.org/abs/2412.16773</link>
      <description>arXiv:2412.16773v1 Announce Type: cross 
Abstract: Gaussian processes are now commonly used in dimensionality reduction approaches tailored to neuroscience, especially to describe changes in high-dimensional neural activity over time. As recording capabilities expand to include neuronal populations across multiple brain areas, cortical layers, and cell types, interest in extending Gaussian process factor models to characterize multi-population interactions has grown. However, the cubic runtime scaling of current methods with the length of experimental trials and the number of recorded populations (groups) precludes their application to large-scale multi-population recordings. Here, we improve this scaling from cubic to linear in both trial length and group number. We present two approximate approaches to fitting multi-group Gaussian process factor models based on (1) inducing variables and (2) the frequency domain. Empirically, both methods achieved orders of magnitude speed-up with minimal impact on statistical performance, in simulation and on neural recordings of hundreds of neurons across three brain areas. The frequency domain approach, in particular, consistently provided the greatest runtime benefits with the fewest trade-offs in statistical performance. We further characterize the estimation biases introduced by the frequency domain approach and demonstrate effective strategies to mitigate them. This work enables a powerful class of analysis techniques to keep pace with the growing scale of multi-population recordings, opening new avenues for exploring brain function.</description>
      <guid isPermaLink="false">oai:arXiv.org:2412.16773v1</guid>
      <category>stat.ML</category>
      <category>cs.LG</category>
      <category>eess.SP</category>
      <category>q-bio.NC</category>
      <pubDate>Tue, 24 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Evren Gokcen, Anna I. Jasper, Adam Kohn, Christian K. Machens, Byron M. Yu</dc:creator>
    </item>
    <item>
      <title>Brain-to-Text Benchmark '24: Lessons Learned</title>
      <link>https://arxiv.org/abs/2412.17227</link>
      <description>arXiv:2412.17227v1 Announce Type: cross 
Abstract: Speech brain-computer interfaces aim to decipher what a person is trying to say from neural activity alone, restoring communication to people with paralysis who have lost the ability to speak intelligibly. The Brain-to-Text Benchmark '24 and associated competition was created to foster the advancement of decoding algorithms that convert neural activity to text. Here, we summarize the lessons learned from the competition ending on June 1, 2024 (the top 4 entrants also presented their experiences in a recorded webinar). The largest improvements in accuracy were achieved using an ensembling approach, where the output of multiple independent decoders was merged using a fine-tuned large language model (an approach used by all 3 top entrants). Performance gains were also found by improving how the baseline recurrent neural network (RNN) model was trained, including by optimizing learning rate scheduling and by using a diphone training objective. Improving upon the model architecture itself proved more difficult, however, with attempts to use deep state space models or transformers not yet appearing to offer a benefit over the RNN baseline. The benchmark will remain open indefinitely to support further work towards increasing the accuracy of brain-to-text algorithms.</description>
      <guid isPermaLink="false">oai:arXiv.org:2412.17227v1</guid>
      <category>cs.CL</category>
      <category>cs.LG</category>
      <category>q-bio.NC</category>
      <pubDate>Tue, 24 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Francis R. Willett, Jingyuan Li, Trung Le, Chaofei Fan, Mingfei Chen, Eli Shlizerman, Yue Chen, Xin Zheng, Tatsuo S. Okubo, Tyler Benster, Hyun Dong Lee, Maxwell Kounga, E. Kelly Buchanan, David Zoltowski, Scott W. Linderman, Jaimie M. Henderson</dc:creator>
    </item>
    <item>
      <title>The Hydrodynamic Limit of Neural Networks with Balanced Excitation and Inhibition</title>
      <link>https://arxiv.org/abs/2412.17273</link>
      <description>arXiv:2412.17273v1 Announce Type: cross 
Abstract: The theory of `Balanced Neural Networks' is a very popular explanation for the high degree of variability and stochasticity in the brain's activity. We determine equations for the hydrodynamic limit of a balanced all-to-all network of 2n neurons for asymptotically large n. The neurons are divided into two classes (excitatory and inhibitory). Each excitatory neuron excites every other neuron, and each inhibitory neuron inhibits all of the other neurons. The model is of a stochastic hybrid nature, such that the synaptic response of each neuron is governed by an ordinary differential equation. The effect of neuron j on neuron k is dictated by a spiking Poisson Process, with intensity given by a sigmoidal function of the synaptic potentiation of neuron j. The interactions are scaled by n^{-1/2} , which is much stronger than the n^{-1} scaling of classical interacting particle systems. We demonstrate that, under suitable conditions, the system does not blow up as n asymptotes to infinity because the network activity is balanced between excitatory and inhibitory inputs. The limiting population dynamics is proved to be Gaussian: with the mean determined by the balanced between excitation and inhibition, and the variance determined by the Central Limit Theorem for inhomogeneous Poisson Processes. The limiting equations can thus be expressed as autonomous Ordinary Differential Equations for the means and variances.</description>
      <guid isPermaLink="false">oai:arXiv.org:2412.17273v1</guid>
      <category>math-ph</category>
      <category>math.MP</category>
      <category>math.PR</category>
      <category>q-bio.NC</category>
      <pubDate>Tue, 24 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>James MacLaurin, Pedro Vilanova</dc:creator>
    </item>
    <item>
      <title>Perceived community alignment increases information sharing</title>
      <link>https://arxiv.org/abs/2304.13796</link>
      <description>arXiv:2304.13796v2 Announce Type: replace 
Abstract: It has been proposed that information sharing, which is a ubiquitous and consequential behavior, plays a critical role in cultivating and maintaining a sense of shared reality. Across three studies, we tested this theory by investigating whether or not people are especially likely to share information that they believe will be interpreted similarly by others in their social circles. Using neuroimaging while members of the same community viewed brief film clips, we found that more similar neural responding of participants was associated with a greater likelihood to share content. We then tested this relationship using two behavioral studies and found (1) that people were particularly likely to share content that they believed others in their social circles would interpret similarly and (2) that perceived similarity with others leads to increased sharing likelihood. In concert, our findings support the idea that people are driven to share information to create and reinforce shared understanding, which is critical to social connection.</description>
      <guid isPermaLink="false">oai:arXiv.org:2304.13796v2</guid>
      <category>q-bio.NC</category>
      <category>cs.SI</category>
      <category>physics.soc-ph</category>
      <pubDate>Tue, 24 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Elisa C. Baek, Ryan Hyon, Karina L\'opez, Mason A. Porter, Carolyn Parkinson</dc:creator>
    </item>
    <item>
      <title>Anti-seizure medication tapering correlates with daytime delta band power reduction in the cortex</title>
      <link>https://arxiv.org/abs/2405.01385</link>
      <description>arXiv:2405.01385v4 Announce Type: replace 
Abstract: Anti-seizure medications (ASMs) are the primary treatment for epilepsy, yet medication tapering effects have not been investigated in a dose, region, and time-dependent manner, despite their potential impact on research and clinical practice.
  We examined over 3000 hours of intracranial EEG recordings in 32 subjects during long-term monitoring, of which 22 underwent concurrent ASM tapering. We estimated ASM plasma levels based on known pharmaco-kinetics of all the major ASM types.
  We found an overall decrease in the power of delta band activity around the period of maximum medication withdrawal in most (80%) subjects, independent of their epilepsy type or medication combination. The degree of withdrawal correlated positively with the magnitude of delta power decrease. This dose-dependent effect was evident across all recorded cortical regions during daytime; but not in sub-cortical regions, or during night time. We found no evidence of a differential effect in seizure onset, spiking, or pathological brain regions.
  The finding of decreased delta band power during ASM tapering agrees with previous literature. Our observed dose-dependent effect indicates that monitoring ASM levels in cortical regions may be feasible for applications such as medication reminder systems, or closed-loop ASM delivery systems. ASMs are also used in other neurological and psychiatric conditions, making our findings relevant to a general neuroscience and neurology audience.</description>
      <guid isPermaLink="false">oai:arXiv.org:2405.01385v4</guid>
      <category>q-bio.NC</category>
      <pubDate>Tue, 24 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Guillermo M. Besne, Nathan Evans, Mariella Panagiotopoulou, Billy Smith, Fahmida A Chowdhury, Beate Diehl, John S Duncan, Andrew W McEvoy, Anna Miserocchi, Jane de Tisi, Mathew Walker, Peter N. Taylor, Chris Thornton, Yujiang Wang</dc:creator>
    </item>
    <item>
      <title>Does the brain behave like a (complex) network? I. Dynamics</title>
      <link>https://arxiv.org/abs/2412.15711</link>
      <description>arXiv:2412.15711v2 Announce Type: replace 
Abstract: Graph theory is now becoming a standard tool in system-level neuroscience. However, endowing observed brain anatomy and dynamics with a complex network structure does not entail that the brain actually works as a network. Asking whether the brain behaves as a network means asking whether network properties count. From the viewpoint of neurophysiology and, possibly, of brain physics, the most substantial issues a network structure may be instrumental in addressing relate to the influence of network properties on brain dynamics and to whether these properties ultimately explain some aspects of brain function. Here, we address the dynamical implications of complex network, examining which aspects and scales of brain activity may be understood to genuinely behave as a network. To do so, we first define the meaning of networkness, and analyse some of its implications. We then examine ways in which brain anatomy and dynamics can be endowed with a network structure and discuss possible ways in which network structure may be shown to represent a genuine organisational principle of brain activity, rather than just a convenient description of its anatomy and dynamics.</description>
      <guid isPermaLink="false">oai:arXiv.org:2412.15711v2</guid>
      <category>q-bio.NC</category>
      <category>cond-mat.dis-nn</category>
      <category>nlin.AO</category>
      <pubDate>Tue, 24 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <arxiv:DOI>10.1016/j.plrev.2023.12.006</arxiv:DOI>
      <arxiv:journal_reference>Physics of Life Reviews 48 (2024) 47-98</arxiv:journal_reference>
      <dc:creator>D. Papo, J. M. Buld\'u</dc:creator>
    </item>
    <item>
      <title>Vision Language Models Know Law of Conservation without Understanding More-or-Less</title>
      <link>https://arxiv.org/abs/2410.00332</link>
      <description>arXiv:2410.00332v3 Announce Type: replace-cross 
Abstract: Conservation is a critical milestone of cognitive development considered to be supported by both the understanding of quantitative concepts and the reversibility of mental operations. To assess whether this critical component of human intelligence has emerged in Vision Language Models, we have curated the ConserveBench, a battery of 365 cognitive experiments across four dimensions of physical quantities: volume, solid quantity, length, and number. The former two involve only transformational tasks, whereas the latter two involve non-transformational tasks assessing the understanding of quantitative concepts alone. Surprisingly, we find that while Vision Language Models are generally capable of conserving, they tend to fail at non-transformational tasks whose successes are typically considered to be evidence of the ability to conserve. This implies that the law of conservation, at least in concrete domains, may exist without corresponding conceptual understanding of quantity. $\href{https://growing-ai-like-a-child.github.io/pages/Conservation/}{Website}$</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.00332v3</guid>
      <category>cs.AI</category>
      <category>q-bio.NC</category>
      <pubDate>Tue, 24 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Dezhi Luo, Haiyun Lyu, Qingying Gao, Haoran Sun, Yijiang Li, Hokin Deng</dc:creator>
    </item>
    <item>
      <title>Dynamical similarity analysis can identify compositional dynamics developing in RNNs</title>
      <link>https://arxiv.org/abs/2410.24070</link>
      <description>arXiv:2410.24070v4 Announce Type: replace-cross 
Abstract: Methods for analyzing representations in neural systems have become a popular tool in both neuroscience and mechanistic interpretability. Having measures to compare how similar activations of neurons are across conditions, architectures, and species, gives us a scalable way of learning how information is transformed within different neural networks. In contrast to this trend, recent investigations have revealed how some metrics can respond to spurious signals and hence give misleading results. To identify the most reliable metric and understand how measures could be improved, it is going to be important to identify specific test cases which can serve as benchmarks. Here we propose that the phenomena of compositional learning in recurrent neural networks (RNNs) allows us to build a test case for dynamical representation alignment metrics. By implementing this case, we show it enables us to test whether metrics can identify representations which gradually develop throughout learning and probe whether representations identified by metrics are relevant to computations executed by networks. By building both an attractor- and RNN-based test case, we show that the new Dynamical Similarity Analysis (DSA) is more noise robust and identifies behaviorally relevant representations more reliably than prior metrics (Procrustes, CKA). We also show how test cases can be used beyond evaluating metrics to study new architectures. Specifically, results from applying DSA to modern (Mamba) state space models, suggest that, in contrast to RNNs, these models may not exhibit changes to their recurrent dynamics due to their expressiveness. Overall, by developing test cases, we show DSA's exceptional ability to detect compositional dynamical motifs, thereby enhancing our understanding of how computations unfold in RNNs.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.24070v4</guid>
      <category>cs.LG</category>
      <category>cs.AI</category>
      <category>cs.NE</category>
      <category>q-bio.NC</category>
      <pubDate>Tue, 24 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Quentin Guilhot, Micha{\l} W\'ojcik, Jascha Achterberg, Rui Ponte Costa</dc:creator>
    </item>
    <item>
      <title>Simplified derivations for high-dimensional convex learning problems</title>
      <link>https://arxiv.org/abs/2412.01110</link>
      <description>arXiv:2412.01110v3 Announce Type: replace-cross 
Abstract: Statistical physics provides tools for analyzing high-dimensional problems in machine learning and theoretical neuroscience. These calculations, particularly those using the replica method, often involve lengthy derivations that can obscure physical interpretation. We give concise, non-replica derivations of several key results and highlight their underlying similarities. Specifically, we introduce a cavity approach to analyzing high-dimensional learning problems and apply it to three cases: perceptron classification of points, perceptron classification of manifolds, and kernel ridge regression. These problems share a common structure -- a bipartite system of interacting feature and datum variables -- enabling a unified analysis. For perceptron-capacity problems, we identify a symmetry that allows derivation of correct capacities through a na\"ive method. These results match those obtained through the replica method.</description>
      <guid isPermaLink="false">oai:arXiv.org:2412.01110v3</guid>
      <category>cond-mat.dis-nn</category>
      <category>cs.NE</category>
      <category>q-bio.NC</category>
      <pubDate>Tue, 24 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>David G. Clark, Haim Sompolinsky</dc:creator>
    </item>
    <item>
      <title>A Simple Channel Compression Method for Brain Signal Decoding on Classification Task</title>
      <link>https://arxiv.org/abs/2412.02078</link>
      <description>arXiv:2412.02078v2 Announce Type: replace-cross 
Abstract: In the application of brain-computer interface (BCI), while pursuing accurate decoding of brain signals, we also need consider the computational efficiency of BCI devices. ECoG signals are multi-channel temporal signals which is collected using a high-density electrode array at a high sampling frequency. The data between channels has a high similarity or redundancy in the temporal domain. The redundancy of data not only reduces the computational efficiency of the model, but also overwhelms the extraction of effective features, resulting in a decrease in performance. How to efficiently utilize ECoG multi-channel signals is one of the research topics. Effective channel screening or compression can greatly reduce the model size, thereby improving computational efficiency, this would be a good direction to solve the problem. Based on previous work [1], this paper proposes a very simple channel compression method, which uses a learnable matrix to perform matrix multiplication on the original channels, that is, assigning weights to the channels and then linearly add them up. This effectively reduces the number of final channels. In the experiment, we used the vision-based ECoG multi-classification dataset owned by our laboratory to test the proposed channel selection (compression) method. We found that the new method can compress the original 128-channel ECoG signal to 32 channels (of which subject MonJ is compressed to 8 channels), greatly reducing the size of the model. The demand for GPU memory resources during model training is reduced by about 68.57%, 84.33% for each subject respectively; the model training speed also increased up around 3.82, 4.65 times of the original speed for each subject respectively. More importantly, the performance of the model has improved by about 1.10% compared with our previous work, reached the SOTA level of our unique visual based ECoG dataset</description>
      <guid isPermaLink="false">oai:arXiv.org:2412.02078v2</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <category>q-bio.NC</category>
      <pubDate>Tue, 24 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Changqing Ji, Keisuke Kawasaki, Isao Hasegawa, Takayuki Okatani</dc:creator>
    </item>
  </channel>
</rss>
