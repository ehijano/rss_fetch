<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>cs.NI updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/cs.NI</link>
    <description>cs.NI updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/cs.NI" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Mon, 27 Oct 2025 04:00:08 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Mon, 27 Oct 2025 00:00:00 -0400</pubDate>
    <skipDays>
      <day>Sunday</day>
      <day>Saturday</day>
    </skipDays>
    <item>
      <title>Sensing and Storing Less: A MARL-based Solution for Energy Saving in Edge Internet of Things</title>
      <link>https://arxiv.org/abs/2510.21103</link>
      <description>arXiv:2510.21103v1 Announce Type: new 
Abstract: As the number of Internet of Things (IoT) devices continuously grows and application scenarios constantly enrich, the volume of sensor data experiences an explosive increase. However, substantial data demands considerable energy during computation and transmission. Redundant deployment or mobile assistance is essential to cover the target area reliably with fault-prone sensors. Consequently, the ``butterfly effect" may appear during the IoT operation, since unreasonable data overlap could result in many duplicate data. To this end, we propose Senses, a novel online energy saving solution for edge IoT networks, with the insight of sensing and storing less at the network edge by adopting Muti-Agent Reinforcement Learning (MARL). Senses achieves data de-duplication by dynamically adjusting sensor coverage at the sensor level. For exceptional cases where sensor coverage cannot be altered, Senses conducts data partitioning and eliminates redundant data at the controller level. Furthermore, at the global level, considering the heterogeneity of IoT devices, Senses balances the operational duration among the devices to prolong the overall operational duration of edge IoT networks. We evaluate the performance of Senses through testbed experiments and simulations. The results show that Senses saves 11.37% of energy consumption on control devices and prolongs 20% overall operational duration of the IoT device network.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.21103v1</guid>
      <category>cs.NI</category>
      <category>cs.DC</category>
      <pubDate>Mon, 27 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Zongyang Yuan, Lailong Luo, Qianzhen Zhang, Bangbang Ren, Deke Guo, Richard T. B. Ma</dc:creator>
    </item>
    <item>
      <title>Enhanced Evolutionary Multi-Objective Deep Reinforcement Learning for Reliable and Efficient Wireless Rechargeable Sensor Networks</title>
      <link>https://arxiv.org/abs/2510.21127</link>
      <description>arXiv:2510.21127v1 Announce Type: new 
Abstract: Despite rapid advancements in sensor networks, conventional battery-powered sensor networks suffer from limited operational lifespans and frequent maintenance requirements that severely constrain their deployment in remote and inaccessible environments. As such, wireless rechargeable sensor networks (WRSNs) with mobile charging capabilities offer a promising solution to extend network lifetime. However, WRSNs face critical challenges from the inherent trade-off between maximizing the node survival rates and maximizing charging energy efficiency under dynamic operational conditions. In this paper, we investigate a typical scenario where mobile chargers move and charge the sensor, thereby maintaining the network connectivity while minimizing the energy waste. Specifically, we formulate a multi-objective optimization problem that simultaneously maximizes the network node survival rate and mobile charger energy usage efficiency across multiple time slots, which presents NP-hard computational complexity with long-term temporal dependencies that make traditional optimization approaches ineffective. To address these challenges, we propose an enhanced evolutionary multi-objective deep reinforcement learning algorithm, which integrates a long short-term memory (LSTM)-based policy network for temporal pattern recognition, a multilayer perceptron-based prospective increment model for future state prediction, and a time-varying Pareto policy evaluation method for dynamic preference adaptation. Extensive simulation results demonstrate that the proposed algorithm significantly outperforms existing approaches in balancing node survival rate and energy efficiency while generating diverse Pareto-optimal solutions. Moreover, the LSTM-enhanced policy network converges 25% faster than conventional networks, with the time-varying evaluation method effectively adapting to dynamic conditions.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.21127v1</guid>
      <category>cs.NI</category>
      <category>cs.AI</category>
      <pubDate>Mon, 27 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Bowei Tong, Hui Kang, Jiahui Li, Geng Sun, Jiacheng Wang, Yaoqi Yang, Bo Xu, Dusit Niyato</dc:creator>
    </item>
    <item>
      <title>A Confidence-Constrained Cloud-Edge Collaborative Framework for Autism Spectrum Disorder Diagnosis</title>
      <link>https://arxiv.org/abs/2510.21130</link>
      <description>arXiv:2510.21130v1 Announce Type: new 
Abstract: Autism Spectrum Disorder (ASD) diagnosis systems in school environments increasingly relies on IoT-enabled cameras, yet pure cloud processing raises privacy and latency concerns while pure edge inference suffers from limited accuracy. We propose Confidence-Constrained Cloud-Edge Knowledge Distillation (C3EKD), a hierarchical framework that performs most inference at the edge and selectively uploads only low-confidence samples to the cloud. The cloud produces temperature-scaled soft labels and distils them back to edge models via a global loss aggregated across participating schools, improving generalization without centralizing raw data. On two public ASD facial-image datasets, the proposed framework achieves a superior accuracy of 87.4\%, demonstrating its potential for scalable deployment in real-world applications.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.21130v1</guid>
      <category>cs.NI</category>
      <pubDate>Mon, 27 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Qi Deng, Yinghao Zhang, Yalin Liu, Bishenghui Tao</dc:creator>
    </item>
    <item>
      <title>TURBOTEST: Learning When Less is Enough through Early Termination of Internet Speed Tests</title>
      <link>https://arxiv.org/abs/2510.21141</link>
      <description>arXiv:2510.21141v1 Announce Type: new 
Abstract: Internet speed tests are indispensable for users, ISPs, and policymakers, but their static flooding-based design imposes growing costs: a single high-speed test can transfer hundreds of megabytes, and collectively, platforms like Ookla, M-Lab, and Fast.com generate petabytes of traffic each month. Reducing this burden requires deciding when a test can be stopped early without sacrificing accuracy. We frame this as an optimal stopping problem and show that existing heuristics-static thresholds, BBR pipe-full signals, or throughput stability rules from Fast.com and FastBTS-capture only a narrow portion of the achievable accuracy-savings trade-off. This paper introduces TURBOTEST, a systematic framework for speed test termination that sits atop existing platforms. The key idea is to decouple throughput prediction (Stage 1) from test termination (Stage 2): Stage 1 trains a regressor to estimate final throughput from partial measurements, while Stage 2 trains a classifier to decide when sufficient evidence has accumulated to stop. Leveraging richer transport-level features (RTT, retransmissions, congestion window) alongside throughput, TURBOTEST exposes a single tunable parameter for accuracy tolerance and includes a fallback mechanism for high-variability cases. Evaluation on 173,000 M-Lab NDT speed tests (2024-2025) shows that TURBOTEST achieves nearly 2-4x higher data savings than an approach based on BBR signals while reducing median error. These results demonstrate that adaptive ML-based termination can deliver accurate, efficient, and deployable speed tests at scale.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.21141v1</guid>
      <category>cs.NI</category>
      <category>cs.LG</category>
      <pubDate>Mon, 27 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-sa/4.0/</dc:rights>
      <dc:creator>Haarika Manda, Manshi Sagar,  Yogesh, Kartikay Singh, Cindy Zhao, Tarun Mangla, Phillipa Gill, Elizabeth Belding, Arpit Gupta</dc:creator>
    </item>
    <item>
      <title>Quality of Coverage (QoC): A New Paradigm for Quantifying Cellular Network Coverage Quality, Usability and Stability</title>
      <link>https://arxiv.org/abs/2510.21162</link>
      <description>arXiv:2510.21162v1 Announce Type: new 
Abstract: Current representations of cellular coverage are overly simplistic; they state only the minimal level of available bandwidth (i.e., 35/3Mbps download/upload speed for 5G) and fail to incorporate a critical component of usability: network stability over space and time. Cellular coverage quality is complex given wireless propagation characteristics and relationships between network load and (often limited) network capacity. A more fine-grained characterization is essential. We introduce Quality of Coverage (QoC), a novel multi-dimensional set of key performance indicators (KPIs) that reflect actual measured performance quality, usability and stability. This representation of the coverage of the cellular network more fully captures temporal and spatial usability and resilience. We motivate and define a set of QoC KPIs and use three distinct datasets to analyze the ability of the KPIs to characterize network behavior, demonstrating the ability of QoC to offer a more fine-grained and useful representation of cellular coverage than possible with current metrics.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.21162v1</guid>
      <category>cs.NI</category>
      <category>cs.CY</category>
      <pubDate>Mon, 27 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-sa/4.0/</dc:rights>
      <dc:creator>Varshika Srinivasavaradhan, Morgan Vigil-Hayes, Ellen Zegura, Elizabeth Belding</dc:creator>
    </item>
    <item>
      <title>Source-Coded Online Algorithm for Multicast Subgraph Construction</title>
      <link>https://arxiv.org/abs/2510.21580</link>
      <description>arXiv:2510.21580v1 Announce Type: new 
Abstract: Multicast remains a fundamental mechanism for scalable content distribution, yet existing approaches face critical limitations. Traditional multicast trees suffer from path redundancy and inefficient utilization of network resources, while network coding, although capacity-achieving, incurs significant computational overhead and deployment challenges. In this paper, we introduce a source-coded multicast framework that exploits maximum-flow decomposition to construct multiple disjoint or partially overlapping paths from the source to all receivers. Our scheme incorporates a novel path redirection mechanism: when multiple overlaps occur between receiver flows, downstream paths are realigned at the first intersection, ensuring loop-free delivery while maximizing overall throughput. We develop algorithms for path construction, overlap detection, and iterative refinement of multicast subgraphs, and analyze their computational complexity. Through extensive evaluation on synthetic and real network topologies, we demonstrate that the proposed method consistently approaches the throughput of network coding with substantially lower encoding and decoding complexity, while significantly outperforming multicast tree constructions in terms of fairness, robustness to link failures, and delivery efficiency. These results position source-coded multicast as a practical and scalable solution for next-generation networks requiring high-throughput and adaptive group communication.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.21580v1</guid>
      <category>cs.NI</category>
      <pubDate>Mon, 27 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Tomas Lestayo Martinez, Manuel Fernandez Veiega Veiga</dc:creator>
    </item>
    <item>
      <title>LIDC: A Location Independent Multi-Cluster Computing Framework for Data Intensive Science</title>
      <link>https://arxiv.org/abs/2510.21373</link>
      <description>arXiv:2510.21373v1 Announce Type: cross 
Abstract: Scientific communities are increasingly using geographically distributed computing platforms. The current methods of compute placement predominantly use logically centralized controllers such as Kubernetes (K8s) to match tasks to available resources. However, this centralized approach is unsuitable in multi-organizational collaborations. Furthermore, workflows often need to use manual configurations tailored for a single platform and cannot adapt to dynamic changes across infrastructure. Our work introduces a decentralized control plane for placing computations on geographically dispersed compute clusters using semantic names. We assign semantic names to computations to match requests with named Kubernetes (K8s) service endpoints. We show that this approach provides multiple benefits. First, it allows placement of computational jobs to be independent of location, enabling any cluster with sufficient resources to execute the computation. Second, it facilitates dynamic compute placement without requiring prior knowledge of cluster locations or predefined configurations.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.21373v1</guid>
      <category>cs.DC</category>
      <category>cs.NI</category>
      <pubDate>Mon, 27 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <arxiv:DOI>10.1109/SCW63240.2024.00108</arxiv:DOI>
      <dc:creator>Sankalpa Timilsina, Susmit Shannigrahi</dc:creator>
    </item>
    <item>
      <title>AutoRAN: Automated and Zero-Touch Open RAN Systems</title>
      <link>https://arxiv.org/abs/2504.11233</link>
      <description>arXiv:2504.11233v3 Announce Type: replace 
Abstract: [...] This paper presents AutoRAN, an automated, intent-driven framework for zero-touch provisioning of open, programmable cellular networks. Leveraging cloud-native principles, AutoRAN employs virtualization, declarative infrastructure-as-code templates, and disaggregated micro-services to abstract physical resources and protocol stacks. Its orchestration engine integrates Language Models (LLMs) to translate high-level intents into machine-readable configurations, enabling closed-loop control via telemetry-driven observability. Implemented on a multi-architecture OpenShift cluster with heterogeneous compute (x86/ARM CPUs, NVIDIA GPUs) and multi-vendor Radio Access Network (RAN) hardware (Foxconn, NI), AutoRAN automates deployment of O-RAN-compliant stacks-including OpenAirInterface, NVIDIA ARC RAN, Open5GS core, and O-RAN Software Community (OSC) RIC components-using CI/CD pipelines. Experimental results demonstrate that AutoRAN is capable of deploying an end-to-end Private 5G network in less than 60 seconds with 1.6 Gbps throughput, validating its ability to streamline configuration, accelerate testing, and reduce manual intervention with similar performance than non cloud-based implementations. With its novel LLM-assisted intent translation mechanism, and performance-optimized automation workflow for multi-vendor environments, AutoRAN has the potential of advancing the robustness of next-generation cellular supply chains through reproducible, intent-based provisioning across public and private deployments.</description>
      <guid isPermaLink="false">oai:arXiv.org:2504.11233v3</guid>
      <category>cs.NI</category>
      <pubDate>Mon, 27 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Stefano Maxenti, Ravis Shirkhani, Maxime Elkael, Leonardo Bonati, Salvatore D'Oro, Tommaso Melodia, Michele Polese</dc:creator>
    </item>
    <item>
      <title>Iris RESTful Server and IrisTileSource: An Iris implementation for existing OpenSeaDragon viewers</title>
      <link>https://arxiv.org/abs/2508.06615</link>
      <description>arXiv:2508.06615v3 Announce Type: replace 
Abstract: The Iris File Extension (IFE) is a low overhead performance-oriented whole slide image (WSI) file format designed to improve the image rendering experience for pathologists and simplify image management for system administrators. However, static hypertext transfer protocol (HTTP) file servers cannot natively stream subregions of high-resolution image files, such as the IFE. The majority of contemporary WSI viewer systems are designed as browser-based web applications and leverage OpenSeaDragon as the tile-based rendering framework. These systems convert WSI files to Deep Zoom Images (DZI) for compatibility with simple static HTTP file servers. To address this limitation, we have developed the Iris RESTful Server, a low-overhead HTTP server with a RESTful API that is natively compatible with the DICOMweb WADO-RS API. Written in C++ with Boost Beast HTTP and Asio networking libraries atop the public IFE libraries, the server offers both security and high performance. Testing shows that a single Raspberry Pi equivalent system can handle a peak of 5,061 req/s (average 3,883 req/s) with a median latency of 21 ms on a private (i.e. hospital) network. We also developed and merged a new OpenSeaDragon TileSource, compatible with the Iris RESTful API, into the next OpenSeaDragon release, enabling simple and immediate drop-in replacement of DZI images within WSI viewer stacks. Designed as a secure cross-origin resource sharing microservice, this architecture includes detailed deployment instructions for new or existing WSI workflows, and the public examples.restful.irisdigitalpathology.org subdomain is provided as a development tool to accelerate WSI web viewer development. All relevant Iris software is available under the open-source MIT software license.</description>
      <guid isPermaLink="false">oai:arXiv.org:2508.06615v3</guid>
      <category>cs.NI</category>
      <pubDate>Mon, 27 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Ryan Erik Landvater MD, Navin Kathawa, Mustafa Yousif MD, Ulysses Balis MD</dc:creator>
    </item>
    <item>
      <title>Better Together: Leveraging Multiple Digital Twins for Deployment Optimization of Airborne Base Stations</title>
      <link>https://arxiv.org/abs/2508.15816</link>
      <description>arXiv:2508.15816v3 Announce Type: replace 
Abstract: Airborne Base Stations (ABSs) allow for flexible geographical allocation of network resources with dynamically changing load as well as rapid deployment of alternate connectivity solutions during natural disasters. Since the radio infrastructure is carried by unmanned aerial vehicles (UAVs) with limited flight time, it is important to establish the best location for the ABS without exhaustive field trials. This paper proposes a digital twin (DT)-guided approach to achieve this through the following key contributions: (i) Implementation of an interactive software bridge between two open-source DTs such that the same scene is evaluated with high fidelity across NVIDIA's Sionna and Aerial Omniverse Digital Twin (AODT), highlighting the unique features of each of these platforms for this allocation problem, (ii) Design of a back-propagation-based algorithm in Sionna for rapidly converging on the physical location of the UAVs, orientation of the antennas and transmit power to ensure efficient coverage across the swarm of the UAVs, and (iii) numerical evaluation in AODT for large network scenarios (50 UEs, 10 ABS) that identifies the environmental conditions in which there is agreement or divergence of performance results between these twins. Finally, (iv) we propose a resilience mechanism to provide consistent coverage to mission-critical devices and demonstrate a use case for bi-directional flow of information between the two DTs.</description>
      <guid isPermaLink="false">oai:arXiv.org:2508.15816v3</guid>
      <category>cs.NI</category>
      <category>cs.LG</category>
      <pubDate>Mon, 27 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <arxiv:DOI>10.1109/TMC.2025.3621186</arxiv:DOI>
      <dc:creator>Mauro Belgiovine, Chris Dick, Kaushik Chowdhury</dc:creator>
    </item>
    <item>
      <title>Hybrid MAC Protocol with Integrated Multi-Layered Security for Resource-Constrained UAV Swarm Communications</title>
      <link>https://arxiv.org/abs/2510.10236</link>
      <description>arXiv:2510.10236v2 Announce Type: replace 
Abstract: Flying Ad Hoc Networks (FANETs) present unique challenges due to high node mobility, dynamic topologies, and strict resource constraints. Existing routing protocols often optimize for a single metric, such as path length or energy, while neglecting the complex dependencies between network performance, security, and MAC layer efficiency. This paper introduces a novel hardware software co design framework for secure and adaptive UAV swarm communications, featuring an energy aware protocol stack. The architecture employs a multicast, clustered organization where routing decisions integrate dynamic trust scores, historical link quality, and internodal distance. A hybrid MAC protocol combines contention based and scheduled channel access for optimized throughput. Security is ensured through a zero trust model that fuses cryptographic authentication with a behavioral reputation system, alongside hardware accelerated AES GCM encryption. Comparative analysis in an NS 3 simulation environment demonstrates the framework's superiority in packet delivery ratio, latency, resilience, and overhead, providing a scalable foundation for high performance swarm operations.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.10236v2</guid>
      <category>cs.NI</category>
      <category>cs.SY</category>
      <category>eess.SY</category>
      <pubDate>Mon, 27 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Dhrumil Bhatt, Siddharth Penumatsa, Vidushi Kumar</dc:creator>
    </item>
    <item>
      <title>Pilot Assignment for Distributed Massive MIMO Based on Channel Estimation Error Minimization</title>
      <link>https://arxiv.org/abs/2510.13732</link>
      <description>arXiv:2510.13732v2 Announce Type: replace 
Abstract: Pilot contamination remains a major bottleneck in realizing the full potential of distributed massive MIMO systems. We propose two dynamic and scalable pilot assignment schemes designed for practical deployment in such networks. First, we present a low-complexity centralized scheme that sequentially assigns pilots to user equipments (UEs) to minimize the global channel estimation errors across serving access points (APs). This improves the channel estimation quality and reduces interference among UEs, enhancing the spectral efficiency. Second, we develop a fully distributed scheme that uses a priority-based pilot selection approach. In this scheme, each selected AP minimizes the channel estimation error using only local information and offers candidate pilots to the UEs. Every UE then selects a suitable pilot based on its AP priority. This approach ensures consistency and minimizes interference while significantly reducing pilot contamination. The method requires no global coordination, maintains low signaling overhead, and adapts dynamically to the UE deployment. Numerical simulations demonstrate the superiority of the proposed schemes in terms of network throughput when compared to the existing state-of-the-art schemes.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.13732v2</guid>
      <category>cs.NI</category>
      <category>cs.IT</category>
      <category>math.IT</category>
      <pubDate>Mon, 27 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Mohd Saif Ali Khan, Karthik RM, Samar Agnihotri</dc:creator>
    </item>
    <item>
      <title>A Survey on Heterogeneous Computing Using SmartNICs and Emerging Data Processing Units</title>
      <link>https://arxiv.org/abs/2504.03653</link>
      <description>arXiv:2504.03653v2 Announce Type: replace-cross 
Abstract: The emergence of new, off-path smart network cards (SmartNICs), known generally as Data Processing Units (DPU), has opened a wide range of research opportunities. Of particular interest is the use of these and related devices in tandem with their host's CPU, creating a heterogeneous computing system with new properties and strengths to be explored, capable of accelerating a wide variety of workloads. This survey begins by providing the motivation and relevant background information for this new field, including its origins, a few current hardware offerings, major programming languages and frameworks for using them, and associated challenges. We then review and categorize a number of recent works in the field, covering a wide variety of studies, benchmarks, and application areas, such as data center infrastructure, commercial uses, and AI and ML acceleration. We conclude with a few observations.</description>
      <guid isPermaLink="false">oai:arXiv.org:2504.03653v2</guid>
      <category>cs.DC</category>
      <category>cs.NI</category>
      <pubDate>Mon, 27 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Nathan Tibbetts, Sifat Ibtisum, Satish Puri</dc:creator>
    </item>
    <item>
      <title>Collective Communication for 100k+ GPUs</title>
      <link>https://arxiv.org/abs/2510.20171</link>
      <description>arXiv:2510.20171v2 Announce Type: replace-cross 
Abstract: The increasing scale of large language models (LLMs) necessitates highly efficient collective communication frameworks, particularly as training workloads extend to hundreds of thousands of GPUs. Traditional communication methods face significant throughput and latency limitations at this scale, hindering both the development and deployment of state-of-the-art models. This paper presents the NCCLX collective communication framework, developed at Meta, engineered to optimize performance across the full LLM lifecycle, from the synchronous demands of large-scale training to the low-latency requirements of inference. The framework is designed to support complex workloads on clusters exceeding 100,000 GPUs, ensuring reliable, high-throughput, and low-latency data exchange. Empirical evaluation on the Llama4 model demonstrates substantial improvements in communication efficiency. This research contributes a robust solution for enabling the next generation of LLMs to operate at unprecedented scales.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.20171v2</guid>
      <category>cs.DC</category>
      <category>cs.AI</category>
      <category>cs.NI</category>
      <pubDate>Mon, 27 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Min Si, Pavan Balaji, Yongzhou Chen, Ching-Hsiang Chu, Adi Gangidi, Saif Hasan, Subodh Iyengar, Dan Johnson, Bingzhe Liu, Regina Ren, Ashmitha Jeevaraj Shetty, Greg Steinbrecher, Yulun Wang, Bruce Wu, Xinfeng Xie, Jingyi Yang, Mingran Yang, Kenny Yu, Minlan Yu, Cen Zhao, Wes Bland, Denis Boyda, Suman Gumudavelli, Prashanth Kannan, Cristian Lumezanu, Rui Miao, Zhe Qu, Venkat Ramesh, Maxim Samoylov, Jan Seidel, Srikanth Sundaresan, Feng Tian, Qiye Tan, Shuqiang Zhang, Yimeng Zhao, Shengbao Zheng, Art Zhu, Hongyi Zeng</dc:creator>
    </item>
  </channel>
</rss>
