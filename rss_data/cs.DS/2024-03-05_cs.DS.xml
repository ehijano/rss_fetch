<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>cs.DS updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/cs.DS</link>
    <description>cs.DS updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/cs.DS" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Tue, 05 Mar 2024 14:39:24 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Tue, 05 Mar 2024 00:00:00 -0500</pubDate>
    <skipDays>
      <day>Sunday</day>
      <day>Saturday</day>
    </skipDays>
    <item>
      <title>A Strongly Subcubic Combinatorial Algorithm for Triangle Detection with Applications</title>
      <link>https://arxiv.org/abs/2403.01085</link>
      <description>arXiv:2403.01085v1 Announce Type: new 
Abstract: We revisit the algorithmic problem of finding a triangle in a graph: We give a randomized combinatorial algorithm for triangle detection in a given $n$-vertex graph with $m$ edges running in $O(n^{7/3})$ time, or alternatively in $O(m^{4/3})$ time. This may come as a surprise since it invalidates several conjectures in the literature. In particular,
  - the $O(n^{7/3})$ runtime surpasses the long-standing fastest algorithm for triangle detection based on matrix multiplication running in $O(n^\omega) = O(n^{2.372})$ time, due to Itai and Rodeh (1978).
  - the $O(m^{4/3})$ runtime surpasses the long-standing fastest algorithm for triangle detection in sparse graphs based on matrix multiplication running in $O(m^{2\omega/(\omega+1)})= O(m^{1.407})$ time due to Alon, Yuster, and Zwick (1997).
  - the $O(n^{7/3})$ time algorithm for triangle detection leads to a $O(n^{25/9} \log{n})$ time combinatorial algorithm for $n \times n$ Boolean matrix multiplication, by a reduction of V. V. Williams and R.~R.~Williams (2018).This invalidates a conjecture of A.~Abboud and V. V. Williams (FOCS 2014).
  - the $O(m^{4/3})$ runtime invalidates a conjecture of A.~Abboud and V. V. Williams (FOCS 2014) that any combinatorial algorithm for triangle detection requires $m^{3/2 -o(1)}$ time.
  - as a direct application of the triangle detection algorithm, we obtain a faster exact algorithm for the $k$-clique problem, surpassing an almost $40$ years old algorithm of Ne{\v{s}}et{\v{r}}il and Poljak (1985). This result strongly disproves the combinatorial $k$-clique conjecture.
  - as another direct application of the triangle detection algorithm, we obtain a faster exact algorithm for the \textsc{Max-Cut} problem, surpassing an almost $20$ years old algorithm of R.~R.~Williams (2005).</description>
      <guid isPermaLink="false">oai:arXiv.org:2403.01085v1</guid>
      <category>cs.DS</category>
      <category>math.CO</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Adrian Dumitrescu</dc:creator>
    </item>
    <item>
      <title>Approximations and Hardness of Packing Partially Ordered Items</title>
      <link>https://arxiv.org/abs/2403.01568</link>
      <description>arXiv:2403.01568v1 Announce Type: new 
Abstract: Motivated by applications in production planning and storage allocation in hierarchical databases, we initiate the study of covering partially ordered items (CPO). Given a capacity $k \in \mathbb{Z}^+$, and a directed graph $G=(V,E)$ where each vertex has a size in $\{0,1, \ldots,k\}$, we seek a collection of subsets of vertices $S_1, \ldots, S_m$ that cover all the vertices, such that for any $1 \leq j \leq m$, the total size of vertices in $S_j$ is bounded by $k$, and there are no edges from $V \setminus S_j$ to $S_j$. The objective is to minimize the number of subsets $m$. CPO is closely related to the rule caching problem (RCP) that is of wide interest in the networking area. The input for RCP is a directed graph $G=(V,E)$, a profit function $p:V \rightarrow \mathbb{Z}_{0}^+$, and $k \in \mathbb{Z}^+$. The output is a subset $S \subseteq V$ of maximum profit such that $|S| \leq k$ and there are no edges from $V \setminus S$ to $S$.
  Our main result is a $2$-approximation algorithm for CPO on out-trees, complemented by an asymptotic $1.5$-hardness of approximation result. We also give a two-way reduction between RCP and the densest $k$-subhypergraph problem, surprisingly showing that the problems are equivalent w.r.t. polynomial-time approximation within any factor $\rho \geq 1$. This implies that RCP cannot be approximated within factor $|V|^{1-\eps}$ for any fixed $\eps&gt;0$, under standard complexity assumptions. Prior to this work, RCP was just known to be strongly NP-hard. We further show that there is no EPTAS for the special case of RCP where the profits are uniform, assuming Gap-ETH. Since this variant admits a PTAS, we essentially resolve the complexity status of this problem.</description>
      <guid isPermaLink="false">oai:arXiv.org:2403.01568v1</guid>
      <category>cs.DS</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Ilan Doron-Arad, Guy Kortsarz, Joseph Naor, Baruch Schieber, Hadas Shachnai</dc:creator>
    </item>
    <item>
      <title>Unleashing Graph Partitioning for Large-Scale Nearest Neighbor Search</title>
      <link>https://arxiv.org/abs/2403.01797</link>
      <description>arXiv:2403.01797v1 Announce Type: new 
Abstract: We consider the fundamental problem of decomposing a large-scale approximate nearest neighbor search (ANNS) problem into smaller sub-problems. The goal is to partition the input points into neighborhood-preserving shards, so that the nearest neighbors of any point are contained in only a few shards. When a query arrives, a routing algorithm is used to identify the shards which should be searched for its nearest neighbors. This approach forms the backbone of distributed ANNS, where the dataset is so large that it must be split across multiple machines.
  In this paper, we design simple and highly efficient routing methods, and prove strong theoretical guarantees on their performance. A crucial characteristic of our routing algorithms is that they are inherently modular, and can be used with any partitioning method. This addresses a key drawback of prior approaches, where the routing algorithms are inextricably linked to their associated partitioning method. In particular, our new routing methods enable the use of balanced graph partitioning, which is a high-quality partitioning method without a naturally associated routing algorithm. Thus, we provide the first methods for routing using balanced graph partitioning that are extremely fast to train, admit low latency, and achieve high recall. We provide a comprehensive evaluation of our full partitioning and routing pipeline on billion-scale datasets, where it outperforms existing scalable partitioning methods by significant margins, achieving up to 2.14x higher QPS at 90% recall$@10$ than the best competitor.</description>
      <guid isPermaLink="false">oai:arXiv.org:2403.01797v1</guid>
      <category>cs.DS</category>
      <category>cs.IR</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Lars Gottesb\"uren, Laxman Dhulipala, Rajesh Jayaram, Jakub Lacki</dc:creator>
    </item>
    <item>
      <title>Fully Polynomial-time Algorithms Parameterized by Vertex Integrity Using Fast Matrix Multiplication</title>
      <link>https://arxiv.org/abs/2403.01839</link>
      <description>arXiv:2403.01839v1 Announce Type: new 
Abstract: We study the computational complexity of several polynomial-time-solvable graph problems parameterized by vertex integrity, a measure of a graph's vulnerability to vertex removal in terms of connectivity. Vertex integrity is the smallest number $\iota$ such that there is a set $S$ of $\iota' \le \iota$ vertices such that every connected component of $G-S$ contains at most $\iota-\iota'$ vertices. It is known that the vertex integrity lies between the well-studied parameters vertex cover number and tree-depth.
  Alon and Yuster [ESA 2007] designed algorithms for graphs with small vertex cover number using fast matrix multiplications. We demonstrate that fast matrix multiplication can also be effectively used when parameterizing by vertex integrity $\iota$ by developing efficient algorithms for problems including an $O(\iota^{\omega-1}n)$-time algorithm for computing the girth of a graph, randomized $O(\iota^{\omega - 1}n)$-time algorithms for Maximum Matching and for finding any induced four-vertex subgraph except for a clique or an independent set, and an $O(\iota^{(\omega-1)/2}n^2) \subseteq O(\iota^{0.687} n^2)$-time algorithm for All-Pairs Shortest Paths. These algorithms can be faster than previous algorithms parameterized by tree-depth, for which fast matrix multiplication is not known to be effective.</description>
      <guid isPermaLink="false">oai:arXiv.org:2403.01839v1</guid>
      <category>cs.DS</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Matthias Bentert, Klaus Heeger, Tomohiro Koana</dc:creator>
    </item>
    <item>
      <title>The Canadian Traveller Problem on outerplanar graphs</title>
      <link>https://arxiv.org/abs/2403.01872</link>
      <description>arXiv:2403.01872v1 Announce Type: new 
Abstract: We study the PSPACE-complete $k$-Canadian Traveller Problem, where a weighted graph $G=(V,E,\omega)$ with a source $s\in V$ and a target $t\in V$ are given. This problem also has a hidden input $E_* \subsetneq E$ of cardinality at most $k$ representing blocked edges. The objective is to travel from $s$ to $t$ with the minimum distance. At the beginning of the walk, the blockages $E_*$ are unknown: the traveller discovers that an edge is blocked when visiting one of its endpoints. Online algorithms, also called strategies, have been proposed for this problem and assessed with the competitive ratio, i.e. the ratio between the distance actually traversed by the traveller divided by the distance we would have traversed knowing the blockages in advance.
  Even though the optimal competitive ratio is $2k+1$ even on unit-weighted planar graphs of treewidth 2, we design a polynomial-time strategy achieving competitive ratio $9$ on unit-weighted outerplanar graphs. This value $9$ also stands as a lower bound for this family of graphs as we prove that, for any $\varepsilon &gt; 0$, no strategy can achieve a competitive ratio $9-\varepsilon$. Finally, we show that it is not possible to achieve a constant competitive ratio (independent of $G$ and $k$) on weighted outerplanar graphs.</description>
      <guid isPermaLink="false">oai:arXiv.org:2403.01872v1</guid>
      <category>cs.DS</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-sa/4.0/</dc:rights>
      <dc:creator>Laurent Beaudou, Pierre Berg\'e, Vsevolod Chernyshev, Antoine Dailly, Yan Gerard, Aur\'elie Lagoutte, Vincent Limouzy, Lucas Pastor</dc:creator>
    </item>
    <item>
      <title>Random Generation of Git Graphs</title>
      <link>https://arxiv.org/abs/2403.01902</link>
      <description>arXiv:2403.01902v1 Announce Type: new 
Abstract: Version Control Systems, such as Git and Mercurial, manage the history of a project as a Directed Acyclic Graph encoding the various divergences and synchronizations happening in its life cycle. A popular workflow in the industry, called the feature branch workflow, constrains these graphs to be of a particular shape: a unique main branch, and non-interfering feature branches. Here we focus on the uniform random generation of those graphs with n vertices, including k on the main branch, for which we provide three algorithms, for three different use-cases. The first, based on rejection, is efficient when aiming for small values of k (more precisely whenever k = O($\sqrt$ n)). The second takes as input any number k of commits in the main branch, but requires costly precalculation. The last one is a Boltzmann generator and enables us to generate very large graphs while targeting a constant k/n ratio. All these algorithms are linear in the size of their outputs.</description>
      <guid isPermaLink="false">oai:arXiv.org:2403.01902v1</guid>
      <category>cs.DS</category>
      <category>math.CO</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Julien CourtielGREYC, Martin P\'epinGREYC</dc:creator>
    </item>
    <item>
      <title>Faster MEM-finding in $O (r + \bar{r} + g)$ space</title>
      <link>https://arxiv.org/abs/2403.02008</link>
      <description>arXiv:2403.02008v1 Announce Type: new 
Abstract: Suppose we are given a text $T [1..n]$, a straight-line program with $g$ rules for $T$ and an assignment of tags to the characters in $T$ such that the Burrows-Wheeler Transform of $T$ has $r$ runs, the Burrows-Wheeler Transform of the reverse of $T$ has $\bar{r}$ runs and the tag array -- the list of tags in the lexicographic order of the suffixes starting at the characters the tags are assigned to -- has $t$ runs. If the alphabet size is at most polylogarithmic in $n$ then there is an $O (r + \bar{r} + g + t)$-space index for $T$ such that when we are given a pattern $P [1..m]$ we can compute the maximal exact matches (MEMs) of $P$ with respect to $T$ in $O (m)$ time plus $O (\log n)$ time per MEM and then list the distinct tags assigned to the first characters of occurrences of that MEM in constant time per tag listed, all correctly with high probability.</description>
      <guid isPermaLink="false">oai:arXiv.org:2403.02008v1</guid>
      <category>cs.DS</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Travis Gagie</dc:creator>
    </item>
    <item>
      <title>Matching Algorithms in the Sparse Stochastic Block Model</title>
      <link>https://arxiv.org/abs/2403.02140</link>
      <description>arXiv:2403.02140v1 Announce Type: new 
Abstract: The stochastic block model (SBM) is a generalization of the Erd\H{o}s--R\'enyi model of random graphs that describes the interaction of a finite number of distinct communities. In sparse Erd\H{o}s--R\'enyi graphs, it is known that a linear-time algorithm of Karp and Sipser achieves near-optimal matching sizes asymptotically almost surely, giving a law-of-large numbers for the matching sizes of such graphs in terms of solutions to an ODE. We provide an extension of this analysis, identifying broad ranges of stochastic block model parameters for which the Karp--Sipser algorithm achieves near-optimal matching sizes, but demonstrating that it cannot perform optimally on general SBM instances.
  We also consider the problem of constructing a matching online, in which the vertices of one half of a bipartite stochastic block model arrive one-at-a-time, and must be matched as they arrive. We show that the competitive ratio lower bound of 0.837 found by Mastin and Jaillet for the Erd\H{o}s--R\'enyi case is tight whenever the expected degrees in all communities are equal. We propose several linear-time algorithms for online matching in the general stochastic block model, but prove that despite very good experimental performance, none of these achieve online asymptotic optimality.</description>
      <guid isPermaLink="false">oai:arXiv.org:2403.02140v1</guid>
      <category>cs.DS</category>
      <category>cs.DM</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Anna Brandenberger, Byron Chin, Nathan S. Sheffield, Divya Shyamal</dc:creator>
    </item>
    <item>
      <title>Constraint Satisfaction Problems with Advice</title>
      <link>https://arxiv.org/abs/2403.02212</link>
      <description>arXiv:2403.02212v1 Announce Type: new 
Abstract: We initiate the study of algorithms for constraint satisfaction problems with ML oracle advice. We introduce two models of advice and then design an approximation algorithm for Max Cut and Max 2-Lin in these models.</description>
      <guid isPermaLink="false">oai:arXiv.org:2403.02212v1</guid>
      <category>cs.DS</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Suprovat Ghoshal, Konstantin Makarychev, Yury Makarychev</dc:creator>
    </item>
    <item>
      <title>Statistical Query Lower Bounds for Learning Truncated Gaussians</title>
      <link>https://arxiv.org/abs/2403.02300</link>
      <description>arXiv:2403.02300v1 Announce Type: new 
Abstract: We study the problem of estimating the mean of an identity covariance Gaussian in the truncated setting, in the regime when the truncation set comes from a low-complexity family $\mathcal{C}$ of sets. Specifically, for a fixed but unknown truncation set $S \subseteq \mathbb{R}^d$, we are given access to samples from the distribution $\mathcal{N}(\boldsymbol{ \mu}, \mathbf{ I})$ truncated to the set $S$. The goal is to estimate $\boldsymbol\mu$ within accuracy $\epsilon&gt;0$ in $\ell_2$-norm. Our main result is a Statistical Query (SQ) lower bound suggesting a super-polynomial information-computation gap for this task. In more detail, we show that the complexity of any SQ algorithm for this problem is $d^{\mathrm{poly}(1/\epsilon)}$, even when the class $\mathcal{C}$ is simple so that $\mathrm{poly}(d/\epsilon)$ samples information-theoretically suffice. Concretely, our SQ lower bound applies when $\mathcal{C}$ is a union of a bounded number of rectangles whose VC dimension and Gaussian surface are small. As a corollary of our construction, it also follows that the complexity of the previously known algorithm for this task is qualitatively best possible.</description>
      <guid isPermaLink="false">oai:arXiv.org:2403.02300v1</guid>
      <category>cs.DS</category>
      <category>cs.LG</category>
      <category>math.ST</category>
      <category>stat.ML</category>
      <category>stat.TH</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Ilias Diakonikolas, Daniel M. Kane, Thanasis Pittas, Nikos Zarifis</dc:creator>
    </item>
    <item>
      <title>Euclidean distance compression via deep random features</title>
      <link>https://arxiv.org/abs/2403.01327</link>
      <description>arXiv:2403.01327v1 Announce Type: cross 
Abstract: Motivated by the problem of compressing point sets into as few bits as possible while maintaining information about approximate distances between points, we construct random nonlinear maps $\varphi_\ell$ that compress point sets in the following way. For a point set $S$, the map $\varphi_\ell:\mathbb{R}^d \to N^{-1/2}\{-1,1\}^N$ has the property that storing $\varphi_\ell(S)$ (a \emph{sketch} of $S$) allows one to report pairwise squared distances between points in $S$ up to some multiplicative $(1\pm \epsilon)$ error with high probability as long as the minimum distance is not too small compared to $\epsilon$. The maps $\varphi_\ell$ are the $\ell$-fold composition of a certain type of random feature mapping. Moreover, we determine how large $N$ needs to be as a function of $\epsilon$ and other parameters of the point set.
  Compared to existing techniques, our maps offer several advantages. The standard method for compressing point sets by random mappings relies on the Johnson-Lindenstrauss lemma which implies that if a set of $n$ points is mapped by a Gaussian random matrix to $\mathbb{R}^k$ with $k =\Theta(\epsilon^{-2}\log n)$, then pairwise distances between points are preserved up to a multiplicative $(1\pm \epsilon)$ error with high probability. The main advantage of our maps $\varphi_\ell$ over random linear maps is that ours map point sets directly into the discrete cube $N^{-1/2}\{-1,1\}^N$ and so there is no additional step needed to convert the sketch to bits. For some range of parameters, our maps $\varphi_\ell$ produce sketches which require fewer bits of storage space.</description>
      <guid isPermaLink="false">oai:arXiv.org:2403.01327v1</guid>
      <category>cs.CG</category>
      <category>cs.DS</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Brett Leroux, Luis Rademacher</dc:creator>
    </item>
    <item>
      <title>K-stars LDP: A Novel Framework for (p, q)-clique Enumeration under Local Differential Privacy</title>
      <link>https://arxiv.org/abs/2403.01788</link>
      <description>arXiv:2403.01788v1 Announce Type: cross 
Abstract: (p,q)-clique enumeration on a bipartite graph is critical for calculating clustering coefficient and detecting densest subgraph. It is necessary to carry out subgraph enumeration while protecting users' privacy from any potential attacker as the count of subgraph may contain sensitive information. Most recent studies focus on the privacy protection algorithms based on edge LDP (Local Differential Privacy). However, these algorithms suffer a large estimation error due to the great amount of required noise. In this paper, we propose a novel idea of k-stars LDP and a novel k-stars LDP algorithm for (p, q)-clique enumeration with a small estimation error, where a k-stars is a star-shaped graph with k nodes connecting to one node. The effectiveness of edge LDP relies on its capacity to obfuscate the existence of an edge between the user and his one-hop neighbors. This is based on the premise that a user should be aware of the existence of his one-hop neighbors. Similarly, we can apply this premise to k-stars as well, where an edge is a specific genre of 1-stars. Based on this fact, we first propose the k-stars neighboring list to enable our algorithm to obfuscate the existence of k-stars with Warner' s RR. Then, we propose the absolute value correction technique and the k-stars sampling technique to further reduce the estimation error. Finally, with the two-round user-collector interaction mechanism, we propose our k-stars LDP algorithm to count the number of (p, q)-clique while successfully protecting users' privacy. Both the theoretical analysis and experiments have showed the superiority of our algorithm over the algorithms based on edge LDP.</description>
      <guid isPermaLink="false">oai:arXiv.org:2403.01788v1</guid>
      <category>cs.CR</category>
      <category>cs.CY</category>
      <category>cs.DS</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Henan Sun, Zhengyu Wu, Rong-Hua Li, Guoren Wang, Zening Li</dc:creator>
    </item>
    <item>
      <title>Towards Deterministic Algorithms for Constant-Depth Factors of Constant-Depth Circuits</title>
      <link>https://arxiv.org/abs/2403.01965</link>
      <description>arXiv:2403.01965v1 Announce Type: cross 
Abstract: We design a deterministic subexponential time algorithm that takes as input a multivariate polynomial $f$ computed by a constant-depth circuit over rational numbers, and outputs a list $L$ of circuits (of unbounded depth and possibly with division gates) that contains all irreducible factors of $f$ computable by constant-depth circuits. This list $L$ might also include circuits that are spurious: they either do not correspond to factors of $f$ or are not even well-defined, e.g. the input to a division gate is a sub-circuit that computes the identically zero polynomial.
  The key technical ingredient of our algorithm is a notion of the pseudo-resultant of $f$ and a factor $g$, which serves as a proxy for the resultant of $g$ and $f/g$, with the advantage that the circuit complexity of the pseudo-resultant is comparable to that of the circuit complexity of $f$ and $g$. This notion, which might be of independent interest, together with the recent results of Limaye, Srinivasan and Tavenas, helps us derandomize one key step of multivariate polynomial factorization algorithms - that of deterministically finding a good starting point for Newton Iteration for the case when the input polynomial as well as the irreducible factor of interest have small constant-depth circuits.</description>
      <guid isPermaLink="false">oai:arXiv.org:2403.01965v1</guid>
      <category>cs.CC</category>
      <category>cs.DS</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Mrinal Kumar, Varun Ramanathan, Ramprasad Saptharishi, Ben Lee Volk</dc:creator>
    </item>
    <item>
      <title>Contract Design for Pandora's Box</title>
      <link>https://arxiv.org/abs/2403.02317</link>
      <description>arXiv:2403.02317v1 Announce Type: cross 
Abstract: We study a natural application of contract design to search problems with probabilistic prior and exploration costs. These problems have a plethora of applications and are expressed concisely within the Pandora's Box model. Its optimal solution is the ingenious index policy proposed originally by Weitzman in 1979.
  In our principal-agent setting, the search task is delegated to an agent. The agent performs a sequential exploration of $n$ boxes, suffers the exploration cost for each inspected box, and selects the content (called the prize) of one inspected box as outcome. Agent and principal obtain an individual value based on the selected prize. To influence the search, the principal a-priori designs a contract with a non-negative payment to the agent for each potential prize. The goal of the principal to maximize her expected reward, i.e., value minus payment. We show how to compute optimal contracts for the principal in several scenarios.
  A popular and important subclass are linear contracts, and we show how to compute optimal linear contracts in polynomial time. For general contracts, we consider the standard assumption that the agent suffers cost but obtains value only from the transfers by the principal. Interestingly, a suitable adaptation of the index policy results in an optimal contract here. More generally, for general contracts with non-zero agent values for outcomes we show how to compute an optimal contract in two cases: (1) when each box has only one prize with non-zero value for principal and agent, (2) for i.i.d. boxes with a single prize with positive value for the principal. These results show that optimal contracts can be highly non-trivial, and their design goes significantly beyond the application or re-interpretation of the index policy.</description>
      <guid isPermaLink="false">oai:arXiv.org:2403.02317v1</guid>
      <category>cs.GT</category>
      <category>cs.DS</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Martin Hoefer, Conrad Schecker, Kevin Schewior</dc:creator>
    </item>
    <item>
      <title>A Tight Max-Flow Min-Cut Duality Theorem for Non-Linear Multicommodity Flows</title>
      <link>https://arxiv.org/abs/2107.04252</link>
      <description>arXiv:2107.04252v2 Announce Type: replace 
Abstract: The Max-Flow Min-Cut theorem is the classical duality result for the Max-Flow problem, which considers flow of a single commodity. We study a multiple commodity generalization of Max-Flow in which flows are composed of real-valued k-vectors through networks with arc capacities formed by regions in \R^k. Given the absence of a clear notion of ordering in the multicommodity case, we define the generalized max flow as the feasible region of all flow values.
  We define a collection of concepts and operations on flows and cuts in the multicommodity setting. We study the mutual capacity of a set of cuts, defined as the set of flows that can pass through all cuts in the set. We present a method to calculate the mutual capacity of pairs of cuts, and then generalize the same to a method of calculation for arbitrary sets of cuts. We show that the mutual capacity is exactly the set of feasible flows in the network, and hence is equal to the max flow. Furthermore, we present a simple class of the multicommodity max flow problem where computations using this tight duality result could run significantly faster than default brute force computations.
  We also study more tractable special cases of the multicommodity max flow problem where the objective is to transport a maximum real or integer multiple of a given vector through the network. We devise an augmenting cycle search algorithm that reduces the optimization problem to one with m constraints in at most \R^{(m-n+1)k} space from one that requires mn constraints in \R^{mk} space for a network with n nodes and m edges. We present efficient algorithms that compute eps-approximations to both the ratio and the integer ratio maximum flow problems.</description>
      <guid isPermaLink="false">oai:arXiv.org:2107.04252v2</guid>
      <category>cs.DS</category>
      <category>math.AT</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Matthew Broussard, Bala Krishnamoorthy</dc:creator>
    </item>
    <item>
      <title>Almost Tight Bounds for Differentially Private Densest Subgraph</title>
      <link>https://arxiv.org/abs/2308.10316</link>
      <description>arXiv:2308.10316v2 Announce Type: replace 
Abstract: We study the Densest Subgraph (DSG) problem under the additional constraint of differential privacy. DSG is a fundamental theoretical question which plays a central role in graph analytics, and so privacy is a natural requirement. But all known private algorithms for Densest Subgraph lose constant multiplicative factors as well as relative large (at least $\log^2 n$) additive factors, despite the existence of non-private exact algorithms. We show that, perhaps surprisingly, these losses are not necessary: in both the classic differential privacy model and the LEDP model (local edge differential privacy, introduced recently by Dhulipala et al. [FOCS 2022]), we give $(\epsilon, \delta)$-differentially private algorithms with no multiplicative loss whatsoever. In other words, the loss is purely additive. Moreover, our additive losses improve the best-known previous additive loss (in any version of differential privacy) when $1/\delta$ is at least polynomial in $n$, and are almost tight: in the centralized setting, our additive loss is $O(\log n /\epsilon)$ while there is a known lower bound of $\Omega(\sqrt{\log n / \epsilon})$. Additionally, we give a different algorithm that is $\epsilon$-differentially private in the LEDP model which achieves a multiplicative ratio arbitrarily close to $2$, along with an additional additive factor. This improves over the previous multiplicative $4$-approximation in the LEDP model. Finally, we conclude with extensions of our techniques to both the node-weighted and the directed versions of the problem.</description>
      <guid isPermaLink="false">oai:arXiv.org:2308.10316v2</guid>
      <category>cs.DS</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Michael Dinitz, Satyen Kale, Silvio Lattanzi, Sergei Vassilvitskii</dc:creator>
    </item>
    <item>
      <title>Analysis of Phylogeny Tracking Algorithms for Serial and Multiprocess Applications</title>
      <link>https://arxiv.org/abs/2403.00246</link>
      <description>arXiv:2403.00246v2 Announce Type: replace 
Abstract: Since the advent of modern bioinformatics, the challenging, multifaceted problem of reconstructing phylogenetic history from biological sequences has hatched perennial statistical and algorithmic innovation. Studies of the phylogenetic dynamics of digital, agent-based evolutionary models motivate a peculiar converse question: how to best engineer tracking to facilitate fast, accurate, and memory-efficient lineage reconstructions? Here, we formally describe procedures for phylogenetic analysis in both serial and distributed computing scenarios. With respect to the former, we demonstrate reference-counting-based pruning of extinct lineages. For the latter, we introduce a trie-based phylogenetic reconstruction approach for "hereditary stratigraphy" genome annotations. This process allows phylogenetic relationships between genomes to be inferred by comparing their similarities, akin to reconstruction of natural history from biological DNA sequences. Phylogenetic analysis capabilities significantly advance distributed agent-based simulations as a tool for evolutionary research, and also benefit application-oriented evolutionary computing. Such tracing could extend also to other digital artifacts that proliferate through replication, like digital media and computer viruses.</description>
      <guid isPermaLink="false">oai:arXiv.org:2403.00246v2</guid>
      <category>cs.DS</category>
      <category>q-bio.PE</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Matthew Andres Moreno, Santiago Rodriguez Papa, Emily Dolson</dc:creator>
    </item>
    <item>
      <title>A new near-linear time algorithm for k-nearest neighbor search using a compressed cover tree</title>
      <link>https://arxiv.org/abs/2111.15478</link>
      <description>arXiv:2111.15478v5 Announce Type: replace-cross 
Abstract: Given a reference set $R$ of $n$ points and a query set $Q$ of $m$ points in a metric space, this paper studies an important problem of finding $k$-nearest neighbors of every point $q \in Q$ in the set $R$ in a near-linear time. In the paper at ICML 2006, Beygelzimer, Kakade, and Langford introduced a cover tree on $R$ and attempted to prove that this tree can be built in $O(n\log n)$ time while the nearest neighbor search can be done in $O(n\log m)$ time with a hidden dimensionality factor. This paper fills a substantial gap in the past proofs of time complexity by defining a simpler compressed cover tree on the reference set $R$. The first new algorithm constructs a compressed cover tree in $O(n \log n)$ time. The second new algorithm finds all $k$-nearest neighbors of all points from $Q$ using a compressed cover tree in time $O(m(k+\log n)\log k)$ with a hidden dimensionality factor depending on point distributions of the given sets $R,Q$ but not on their sizes.</description>
      <guid isPermaLink="false">oai:arXiv.org:2111.15478v5</guid>
      <category>cs.CG</category>
      <category>cs.DS</category>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Yury Elkin, Vitaliy Kurlin</dc:creator>
    </item>
    <item>
      <title>Moser-Tardos Algorithm with small number of random bits</title>
      <link>https://arxiv.org/abs/2203.05888</link>
      <description>arXiv:2203.05888v2 Announce Type: replace-cross 
Abstract: We study a variant of the parallel Moser-Tardos Algorithm. We prove that if we restrict attention to a class of problems whose dependency graphs have subexponential growth, then the expected total number of random bits used by the algorithm is constant; in particular, it is independent from the number of variables. This is achieved by using the same random bits to resample variables which are far enough in the dependency graph.
  There are two corollaries. First, we obtain a deterministic algorithm for finding a satisfying assignment, which for any class of problems as in the previous paragraph runs in time O(n), where n is the number of variables. Second, we present a Borel version of the Lov\'asz Local Lemma.</description>
      <guid isPermaLink="false">oai:arXiv.org:2203.05888v2</guid>
      <category>math.CO</category>
      <category>cs.DC</category>
      <category>cs.DS</category>
      <category>math.LO</category>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Endre Cs\'oka, {\L}ukasz Grabowski, Andr\'as M\'ath\'e, Oleg Pikhurko, Konstantinos Tyros</dc:creator>
    </item>
    <item>
      <title>Accelerated first-order methods for a class of semidefinite programs</title>
      <link>https://arxiv.org/abs/2206.00224</link>
      <description>arXiv:2206.00224v2 Announce Type: replace-cross 
Abstract: This paper introduces a new storage-optimal first-order method (FOM), CertSDP, for solving a special class of semidefinite programs (SDPs) to high accuracy. The class of SDPs that we consider, the exact QMP-like SDPs, is characterized by low-rank solutions, a priori knowledge of the restriction of the SDP solution to a small subspace, and standard regularity assumptions such as strict complementarity. Crucially, we show how to use a certificate of strict complementarity to construct a low-dimensional strongly convex minimax problem whose optimizer coincides with a factorization of the SDP optimizer. From an algorithmic standpoint, we show how to construct the necessary certificate and how to solve the minimax problem efficiently. We accompany our theoretical results with preliminary numerical experiments suggesting that CertSDP significantly outperforms current state-of-the-art methods on large sparse exact QMP-like SDPs.</description>
      <guid isPermaLink="false">oai:arXiv.org:2206.00224v2</guid>
      <category>math.OC</category>
      <category>cs.DS</category>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Alex L. Wang, Fatma Kilinc-Karzan</dc:creator>
    </item>
    <item>
      <title>Polynomial Logical Zonotopes: A Set Representation for Reachability Analysis of Logical Systems</title>
      <link>https://arxiv.org/abs/2306.12508</link>
      <description>arXiv:2306.12508v2 Announce Type: replace-cross 
Abstract: In this paper, we introduce a set representation called polynomial logical zonotopes for performing exact and computationally efficient reachability analysis on logical systems. Polynomial logical zonotopes are a generalization of logical zonotopes, which are able to represent up to 2^n binary vectors using only n generators. Due to their construction, logical zonotopes are only able to support exact computations of some logical operations (XOR, NOT, XNOR), while other operations (AND, NAND, OR, NOR) result in over-approximations in the reduced space, i.e., generator space. In order to perform all fundamental logical operations exactly, we formulate a generalization of logical zonotopes that is constructed by dependent generators and exponent matrices. We prove that through this polynomial-like construction, we are able to perform all of the fundamental logical operations (XOR, NOT, XNOR, AND, NAND, OR, NOR) exactly in the generator space. While we are able to perform all of the logical operations exactly, this comes with a slight increase in computational complexity compared to logical zonotopes. We show that we can use polynomial logical zonotopes to perform exact reachability analysis while retaining a low computational complexity. To illustrate and showcase the computational benefits of polynomial logical zonotopes, we present the results of performing reachability analysis on two use cases: (1) safety verification of an intersection crossing protocol and (2) reachability analysis on a high-dimensional Boolean function. Moreover, to highlight the extensibility of logical zonotopes, we include an additional use case where we perform a computationally tractable exhaustive search for the key of a linear feedback shift register.</description>
      <guid isPermaLink="false">oai:arXiv.org:2306.12508v2</guid>
      <category>cs.LO</category>
      <category>cs.CC</category>
      <category>cs.DS</category>
      <category>cs.SY</category>
      <category>eess.SY</category>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Amr Alanwar, Frank J. Jiang, Karl H. Johansson</dc:creator>
    </item>
    <item>
      <title>Counting occurrences of patterns in permutations</title>
      <link>https://arxiv.org/abs/2306.12682</link>
      <description>arXiv:2306.12682v2 Announce Type: replace-cross 
Abstract: We develop a new, powerful method for counting elements in a multiset. As a first application, we use this algorithm to study the number of occurrences of patterns in a permutation. For patterns of length 3 there are two Wilf classes, and the general behaviour of these is reasonably well-known. We slightly extend some of the known results in that case, and exhaustively study the case of patterns of length 4, about which there is little previous knowledge. For such patterns, there are seven Wilf classes, and based on extensive enumerations and careful series analysis, we have conjectured the asymptotic behaviour for all classes.</description>
      <guid isPermaLink="false">oai:arXiv.org:2306.12682v2</guid>
      <category>math.CO</category>
      <category>cs.DS</category>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Andrew R Conway, Anthony J Guttmann</dc:creator>
    </item>
  </channel>
</rss>
