<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>econ.EM updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/econ.EM</link>
    <description>econ.EM updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/econ.EM" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Fri, 13 Dec 2024 02:47:41 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Thu, 12 Dec 2024 00:00:00 -0500</pubDate>
    <skipDays>
      <day>Sunday</day>
      <day>Saturday</day>
    </skipDays>
    <item>
      <title>Anomaly Detection in California Electricity Price Forecasting: Enhancing Accuracy and Reliability Using Principal Component Analysis</title>
      <link>https://arxiv.org/abs/2412.07787</link>
      <description>arXiv:2412.07787v1 Announce Type: new 
Abstract: Accurate and reliable electricity price forecasting has significant practical implications for grid management, renewable energy integration, power system planning, and price volatility management. This study focuses on enhancing electricity price forecasting in California's grid, addressing challenges from complex generation data and heteroskedasticity. Utilizing principal component analysis (PCA), we analyze CAISO's hourly electricity prices and demand from 2016-2021 to improve day-ahead forecasting accuracy. Initially, we apply traditional outlier analysis with the interquartile range method, followed by robust PCA (RPCA) for more effective outlier elimination. This approach improves data symmetry and reduces skewness. We then construct multiple linear regression models using both raw and PCA-transformed features. The model with transformed features, refined through traditional and SAS Sparse Matrix outlier removal methods, shows superior forecasting performance. The SAS Sparse Matrix method, in particular, significantly enhances model accuracy. Our findings demonstrate that PCA-based methods are key in advancing electricity price forecasting, supporting renewable integration and grid management in day-ahead markets.
  Keywords: Electricity price forecasting, principal component analysis (PCA), power system planning, heteroskedasticity, renewable energy integration.</description>
      <guid isPermaLink="false">oai:arXiv.org:2412.07787v1</guid>
      <category>econ.EM</category>
      <category>cs.AI</category>
      <category>cs.ET</category>
      <category>cs.LG</category>
      <category>cs.SY</category>
      <category>eess.SY</category>
      <pubDate>Thu, 12 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <arxiv:DOI>10.1002/wene.504</arxiv:DOI>
      <arxiv:journal_reference>WIREs Energy &amp; Environment, 2024</arxiv:journal_reference>
      <dc:creator>Joseph Nyangon, Ruth Akintunde</dc:creator>
    </item>
    <item>
      <title>Robust Estimation and Inference in Panels with Interactive Fixed Effects</title>
      <link>https://arxiv.org/abs/2210.06639</link>
      <description>arXiv:2210.06639v3 Announce Type: replace 
Abstract: We consider estimation and inference for a regression coefficient in panels with interactive fixed effects (i.e., with a factor structure). We demonstrate that existing estimators and confidence intervals (CIs) can be heavily biased and size-distorted when some of the factors are weak. We propose estimators with improved rates of convergence and bias-aware CIs that remain valid uniformly, regardless of factor strength. Our approach applies the theory of minimax linear estimation to form a debiased estimate, using a nuclear norm bound on the error of an initial estimate of the interactive fixed effects. Our resulting bias-aware CIs take into account the remaining bias caused by weak factors. Monte Carlo experiments show substantial improvements over conventional methods when factors are weak, with minimal costs to estimation accuracy when factors are strong.</description>
      <guid isPermaLink="false">oai:arXiv.org:2210.06639v3</guid>
      <category>econ.EM</category>
      <category>stat.ME</category>
      <pubDate>Thu, 12 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Timothy B. Armstrong, Martin Weidner, Andrei Zeleneev</dc:creator>
    </item>
    <item>
      <title>Empirical Bayes When Estimation Precision Predicts Parameters</title>
      <link>https://arxiv.org/abs/2212.14444</link>
      <description>arXiv:2212.14444v5 Announce Type: replace 
Abstract: Gaussian empirical Bayes methods usually maintain a precision independence assumption: The unknown parameters of interest are independent from the known standard errors of the estimates. This assumption is often theoretically questionable and empirically rejected. This paper proposes to model the conditional distribution of the parameter given the standard errors as a flexibly parametrized location-scale family of distributions, leading to a family of methods that we call CLOSE. The CLOSE framework unifies and generalizes several proposals under precision dependence. We argue that the most flexible member of the CLOSE family is a minimalist and computationally efficient default for accounting for precision dependence. We analyze this method and show that it is competitive in terms of the regret of subsequent decisions rules. Empirically, using CLOSE leads to sizable gains for selecting high-mobility Census tracts.</description>
      <guid isPermaLink="false">oai:arXiv.org:2212.14444v5</guid>
      <category>econ.EM</category>
      <category>math.ST</category>
      <category>stat.ME</category>
      <category>stat.TH</category>
      <pubDate>Thu, 12 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Jiafeng Chen</dc:creator>
    </item>
    <item>
      <title>Interacting Treatments with Endogenous Takeup</title>
      <link>https://arxiv.org/abs/2301.04876</link>
      <description>arXiv:2301.04876v2 Announce Type: replace 
Abstract: We study causal inference in randomized experiments (or quasi-experiments) following a $2\times 2$ factorial design. There are two treatments, denoted $A$ and $B$, and units are randomly assigned to one of four categories: treatment $A$ alone, treatment $B$ alone, joint treatment, or none. Allowing for endogenous non-compliance with the two binary instruments representing the intended assignment, as well as unrestricted interference across the two treatments, we derive the causal interpretation of various instrumental variable estimands under more general compliance conditions than in the literature. In general, if treatment takeup is driven by both instruments for some units, it becomes difficult to separate treatment interaction from treatment effect heterogeneity. We provide auxiliary conditions and various bounding strategies that may help zero in on causally interesting parameters. As an empirical illustration, we apply our results to a program randomly offering two different treatments, namely tutoring and financial incentives, to first year college students, in order to assess the treatments' effects on academic performance.</description>
      <guid isPermaLink="false">oai:arXiv.org:2301.04876v2</guid>
      <category>econ.EM</category>
      <pubDate>Thu, 12 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Mate Kormos, Robert P. Lieli, Martin Huber</dc:creator>
    </item>
    <item>
      <title>Estimating treatment-effect heterogeneity across sites, in multi-site randomized experiments with few units per site</title>
      <link>https://arxiv.org/abs/2405.17254</link>
      <description>arXiv:2405.17254v3 Announce Type: replace 
Abstract: In multi-site randomized trials with many sites and few randomization units per site, an Empirical-Bayes estimator can be used to estimate the variance of the treatment effect across sites. When this estimator indicates that treatment effects do vary, we propose estimators of the coefficients from regressions of site-level effects on site-level characteristics that are unobserved but can be unbiasedly estimated, such as sites' average outcome without treatment, or site-specific treatment effects on mediator variables. In experiments with imperfect compliance, we show that the sign of the correlation between local average treatment effects (LATEs) and site-level characteristics is identified, and we propose a partly testable assumption under which the variance of LATEs is identified. We use our results to revisit Behaghel et al (2014), who study the effect of counseling programs on job seekers' job-finding rate, in 200 job placement agencies in France. We find considerable treatment-effect heterogeneity, both for intention to treat and LATE effects, and the treatment effect is negatively correlated with sites' job-finding rate without treatment.</description>
      <guid isPermaLink="false">oai:arXiv.org:2405.17254v3</guid>
      <category>econ.EM</category>
      <pubDate>Thu, 12 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Cl\'ement de Chaisemartin, Antoine Deeb</dc:creator>
    </item>
    <item>
      <title>Warfare Ignited Price Contagion Dynamics in Early Modern Europe</title>
      <link>https://arxiv.org/abs/2411.18978</link>
      <description>arXiv:2411.18978v3 Announce Type: replace 
Abstract: Economic historians have long studied market integration and contagion dynamics during periods of warfare and global stress, but there is a lack of model-based evidence on these phenomena. This paper uses an econometric contagion model, the Diebold-Yilmaz framework, to examine the dynamics of economic shocks across European markets in the early modern period. Our findings suggest that key periods of violent conflicts significantly increased food price spillover across cities, causing widespread disruptions across Europe. We also demonstrate the ability of this framework to capture relevant historical dynamics between the main trade centers of the period.</description>
      <guid isPermaLink="false">oai:arXiv.org:2411.18978v3</guid>
      <category>econ.EM</category>
      <pubDate>Thu, 12 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Emile Esmaili, Michael J. Puma, Francis Ludlow, Poul Holm, Eva Jobbova</dc:creator>
    </item>
    <item>
      <title>On the robustness of posterior means</title>
      <link>https://arxiv.org/abs/2303.08653</link>
      <description>arXiv:2303.08653v2 Announce Type: replace-cross 
Abstract: Consider a normal location model $X \mid \theta \sim N(\theta, \sigma^2)$ with known $\sigma^2$. Suppose $\theta \sim G_0$, where the prior $G_0$ has zero mean and variance bounded by $V$. Let $G_1$ be a possibly misspecified prior with zero mean and variance bounded by $V$. We show that the squared error Bayes risk of the posterior mean under $G_1$ is bounded, subjected to an additional tail condition on $G_1$, uniformly over $G_0, G_1, \sigma^2 &gt; 0$.</description>
      <guid isPermaLink="false">oai:arXiv.org:2303.08653v2</guid>
      <category>math.ST</category>
      <category>econ.EM</category>
      <category>econ.TH</category>
      <category>stat.TH</category>
      <pubDate>Thu, 12 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Jiafeng Chen</dc:creator>
    </item>
    <item>
      <title>LABOR-LLM: Language-Based Occupational Representations with Large Language Models</title>
      <link>https://arxiv.org/abs/2406.17972</link>
      <description>arXiv:2406.17972v2 Announce Type: replace-cross 
Abstract: Vafa et al. (2024) introduced a transformer-based econometric model, CAREER, that predicts a worker's next job as a function of career history (an "occupation model"). CAREER was initially estimated ("pre-trained") using a large, unrepresentative resume dataset, which served as a "foundation model," and parameter estimation was continued ("fine-tuned") using data from a representative survey. CAREER had better predictive performance than benchmarks. This paper considers an alternative where the resume-based foundation model is replaced by a large language model (LLM). We convert tabular data from the survey into text files that resemble resumes and fine-tune the LLMs using these text files with the objective to predict the next token (word). The resulting fine-tuned LLM is used as an input to an occupation model. Its predictive performance surpasses all prior models. We demonstrate the value of fine-tuning and further show that by adding more career data from a different population, fine-tuning smaller LLMs surpasses the performance of fine-tuning larger models.</description>
      <guid isPermaLink="false">oai:arXiv.org:2406.17972v2</guid>
      <category>cs.LG</category>
      <category>cs.CL</category>
      <category>econ.EM</category>
      <pubDate>Thu, 12 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Susan Athey, Herman Brunborg, Tianyu Du, Ayush Kanodia, Keyon Vafa</dc:creator>
    </item>
    <item>
      <title>Covariate Adjustment in Randomized Experiments Motivated by Higher-Order Influence Functions</title>
      <link>https://arxiv.org/abs/2411.08491</link>
      <description>arXiv:2411.08491v2 Announce Type: replace-cross 
Abstract: Higher-Order Influence Functions (HOIF), developed in a series of papers over the past twenty years, is a fundamental theoretical device for constructing rate-optimal causal-effect estimators from observational studies. However, the value of HOIF for analyzing well-conducted randomized controlled trials (RCTs) has not been explicitly explored. In the recent U.S. Food and Drug Administration (FDA) and European Medicines Agency (EMA) guidelines on the practice of covariate adjustment in analyzing RCTs, in addition to the simple, unadjusted difference-in-mean estimator, it was also recommended to report the estimator adjusting for baseline covariates via a simple parametric working model, such as a linear model. In this paper, we show that a HOIF-motivated estimator for the treatment-specific mean has significantly improved statistical properties compared to popular adjusted estimators in practice when the number of baseline covariates $p$ is relatively large compared to the sample size $n$. We also characterize the conditions under which the HOIF-motivated estimator improves upon the unadjusted one. Furthermore, we demonstrate that a novel debiased adjusted estimator proposed recently by Lu et al. is, in fact, another HOIF-motivated estimator in disguise. Numerical and empirical studies are conducted to corroborate our theoretical findings.</description>
      <guid isPermaLink="false">oai:arXiv.org:2411.08491v2</guid>
      <category>stat.ME</category>
      <category>econ.EM</category>
      <category>math.ST</category>
      <category>stat.TH</category>
      <pubDate>Thu, 12 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Sihui Zhao, Xinbo Wang, Lin Liu, Xin Zhang</dc:creator>
    </item>
  </channel>
</rss>
