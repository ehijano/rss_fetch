<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>cs.NA updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/cs.NA</link>
    <description>cs.NA updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/cs.NA" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Tue, 23 Sep 2025 02:47:08 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Mon, 22 Sep 2025 00:00:00 -0400</pubDate>
    <skipDays>
      <day>Sunday</day>
      <day>Saturday</day>
    </skipDays>
    <item>
      <title>Variable-preconditioned transformed primal-dual method for generalized Wasserstein Gradient Flows</title>
      <link>https://arxiv.org/abs/2509.15385</link>
      <description>arXiv:2509.15385v1 Announce Type: new 
Abstract: We propose a Variable-Preconditioned Transformed Primal-Dual (VPTPD) method for solving generalized Wasserstein gradient flows via a structure-preserving JKO scheme. This is a nontrivial extension of the TPD method [Chen et al. (2023) arXiv:2312.12355] incorporating proximal splitting techniques to address the challenges arising from the nonsmoothness of the objective function. Our key contributions include: (i) a semi-implicit-explicit iteration that combines proximal steps for the nonsmooth part with explicit gradient steps for the smooth part, and variable preconditioners constructed from the Hessian of a regularized objective to balance iteration count and per-iteration cost; (ii) a proof of existence and uniqueness of bounded solutions for the resulting generalized proximal operator, along with a convergent and bound-preserving Newton solver; and (iii) an adaptive step-size strategy to improve robustness and accelerate convergence under poor Lipschitz conditions of the energy derivative. Comprehensive numerical experiments spanning from 1D to 3D settings demonstrate that our method achieves superior computational efficiency compared to existing methods, highlighting its broad applicability through several challenging simulations.</description>
      <guid isPermaLink="false">oai:arXiv.org:2509.15385v1</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <pubDate>Mon, 22 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Jin Zeng, Dawei Zhan, Ruchi Guo, Chaozhen Wei</dc:creator>
    </item>
    <item>
      <title>Numerical Discretization Methods for Seismic Response Analysis of SDOF Systems: A Unified Perspective</title>
      <link>https://arxiv.org/abs/2509.15474</link>
      <description>arXiv:2509.15474v1 Announce Type: new 
Abstract: This paper reviews the most commonly used numerical methods for solving the differential equation governing the dynamic response of linear elastic Single-Degree-of-Freedom (SDOF) systems. For more than 80 years since its introduction, the response spectrum has remained the cornerstone of every seismic design code. The second-order differential equation that governs the dynamic response of a linear elastic SDOF system must be solved numerically to generate such response spectra. Although only one or two well-accepted time-discretization methods have been predominantly used by the earthquake engineering community over the past decades, these methods are directly or indirectly related to a broader family of methods for solving Linear Time-Invariant (LTI) systems, which have been extensively applied in other branches of engineering, particularly electrical engineering. It has recently come to my attention that a portion of our community, particularly students, may not be fully familiar with these methods. In this paper, I review these methods and describe their mathematical background, with a focus on the relative displacement of the SDOF system under ground acceleration-an essential quantity for various types of response spectra. I also briefly review some of the numerical methods traditionally used within our community, highlighting their similarities and differences. I evaluate the accuracy of all numerical methods introduced in this paper through several examples with available analytical solutions. This study focuses on time-domain solutions that can be employed for real- or near-real-time response prediction, which is particularly important for applications such as earthquake early warning and post-earthquake assessment. The paper is written to enable readers to implement these methods with minimal effort; however, MATLAB codes for all methods discussed are also provided.</description>
      <guid isPermaLink="false">oai:arXiv.org:2509.15474v1</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <pubDate>Mon, 22 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Farid Ghahari</dc:creator>
    </item>
    <item>
      <title>Spotlight inversion by orthogonal projections</title>
      <link>https://arxiv.org/abs/2509.15512</link>
      <description>arXiv:2509.15512v1 Announce Type: new 
Abstract: In inverse problems, the goal is to estimate unknown parameters from indirect noisy observations. It is not uncommon that the forward model assigning the observed variables to given values of the unknowns depend on variables that are not of primary interest, often referred to as nuisance parameters. In this article, we consider linear inverse problems, and propose a novel technique, based on linear algebra and orthogonal projections, to eliminate, or at least mitigate, the contribution of the nuisance parameters on the data. The approach is referred to as spotlight inversion, as it allows to focus on the part of primary interest of the unknown parameter, leaving the uninteresting part in the shadow. The viability of the approach is demonstrated by a computed example of local fanbeam X-ray tomography: the spotlight is on the region of interest that is part of the full target.</description>
      <guid isPermaLink="false">oai:arXiv.org:2509.15512v1</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <pubDate>Mon, 22 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Daniela Calvetti, Nuutti Hyv\"onen, Ville Kolehmainen, Erkki Somersalo</dc:creator>
    </item>
    <item>
      <title>Numerical Analysis of Simultaneous Reconstruction of Initial Condition and Potential in Subdiffusion</title>
      <link>https://arxiv.org/abs/2509.15633</link>
      <description>arXiv:2509.15633v1 Announce Type: new 
Abstract: This paper investigates the simultaneous identification of a spatially dependent potential and the initial condition in a subdiffusion model based on two terminal observations. The existence, uniqueness, and conditional stability of the inverse problem are established under weak regularity assumptions through a constructive fixed-point iteration approach. The theoretical analysis further inspires the development of an easy-to-implement iterative algorithm. A fully discrete scheme is then proposed, combining the finite element method for spatial discretization, convolution quadrature for temporal discretization, and the quasi-boundary value method to handle the ill-posedness of recovering the initial condition. Inspired by the conditional stability estimate, we demonstrate the linear convergence of the iterative algorithm and provide a detailed error analysis for the reconstructed initial condition and potential. The derived \textsl{a priori} error estimate offers a practical guide for selecting regularization parameters and discretization mesh sizes based on the noise level. Numerical experiments are provided to illustrate and support our theoretical findings.</description>
      <guid isPermaLink="false">oai:arXiv.org:2509.15633v1</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <pubDate>Mon, 22 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Xu Wu, Jiang Yang, Zhi Zhou</dc:creator>
    </item>
    <item>
      <title>Weak Error Estimates of Ergodic Approximations for Monotone Jump-diffusion SODEs</title>
      <link>https://arxiv.org/abs/2509.15698</link>
      <description>arXiv:2509.15698v1 Announce Type: new 
Abstract: We first derive the exponential ergodicity of the stochastic theta method (STM) with $\theta \in (1/2,1]$ for monotone jump-diffusion stochastic ordinary differential equations (SODEs) under a dissipative condition. Then we establish the weak error estimates of the backward Euler method (BEM), corresponding to the STM with $\theta=1$. In particular, the time-independent estimate for the BEM in the jump-free case yields a one-order convergence rate between the exact and numerical invariant measures, answering a question left in {\it Z. Liu and Z. Liu, J. Sci. Comput. (2025) 103:87}.</description>
      <guid isPermaLink="false">oai:arXiv.org:2509.15698v1</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <category>math.PR</category>
      <pubDate>Mon, 22 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Zhihui Liu, Xiaoming Wu</dc:creator>
    </item>
    <item>
      <title>Polynomial approximation from diffused data: unisolvence and stability</title>
      <link>https://arxiv.org/abs/2509.15813</link>
      <description>arXiv:2509.15813v1 Announce Type: new 
Abstract: In this work, we address the problem of polynomial interpolation of non-pointwise data. More specifically, we assume that our input information comes from measurements obtained on diffuse compact domains. Although the nodal and the diffused problems are related by the mean value theorem, such an approach does not provide any concrete insights in terms of well-posedness and stability. We hence develop a different framework in which {\it unisolvence} can be again recovered from nodal results, for which a wide literature is available. To analyze the stability of the so-obtained diffused interpolation procedure, we characterize the norm of the interpolation operator in terms of a Lebesgue constant-like quantity. After analyzing some of its features, such as invariance properties and sensitivity to support overlapping, we numerically verify the theoretical findings.</description>
      <guid isPermaLink="false">oai:arXiv.org:2509.15813v1</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <pubDate>Mon, 22 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <dc:creator>Ludovico Bruni Bruno, Stefano De Marchi, Giacomo Elefante</dc:creator>
    </item>
    <item>
      <title>The inverse of the star discrepancy of a union of randomly digitally shifted Korobov polynomial lattice point sets depends polynomially on the dimension</title>
      <link>https://arxiv.org/abs/2509.15877</link>
      <description>arXiv:2509.15877v1 Announce Type: new 
Abstract: The star discrepancy is a quantitative measure of the uniformity of a point set in the unit cube. A central quantity of interest is the inverse of the star discrepancy, $N(\varepsilon, s)$, defined as the minimum number of points required to achieve a star discrepancy of at most~$\varepsilon$ in dimension~$s$. It is known that $N(\varepsilon, s)$ depends only linearly on the dimension~$s$. All known proofs of this result are non-constructive. Finding explicit point set constructions that achieve this optimal linear dependence on the dimension remains a major open problem.
  In this paper, we make progress on this question by analyzing point sets constructed from a multiset union of digitally shifted Korobov polynomial lattice point sets. Specifically, we show the following two results. A union of randomly generated Korobov polynomial lattice point sets shifted by a random digital shift of depth $m$ can achieve a star discrepancy whose inverse depends only linearly on $s$. The second result shows that a union of all Korobov polynomial lattice point sets, each shifted by a different random digital shift, achieves the same star discrepancy bound. While our proof relies on a concentration result (Bennett's inequality) and is therefore non-constructive, it significantly reduces the search space for such point sets from a continuum of possibilities to a finite set of candidates, marking a step towards a fully explicit construction.</description>
      <guid isPermaLink="false">oai:arXiv.org:2509.15877v1</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <category>math.NT</category>
      <pubDate>Mon, 22 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Josef Dick, Friedrich Pillichshammer</dc:creator>
    </item>
    <item>
      <title>A Multidimensional Self-Adaptive Numerical Simulation Framework for Semiconductor Boltzmann Transport Equation</title>
      <link>https://arxiv.org/abs/2509.15879</link>
      <description>arXiv:2509.15879v1 Announce Type: new 
Abstract: This research addresses the numerical simulation of the Boltzmann transport equation for semiconductor devices by proposing a multidimensional self-adaptive numerical simulation framework. This framework is applied to two important generalized forms of the equation: a parabolic equation with singular properties on the unit disk and a continuity equation. The study enhances the alignment of numerical simulations with physical characteristics through polar coordinate transformation and variable drift-diffusion coefficients. Innovatively, a multidimensional adaptive mesh partitioning strategy for radius-angle-time is designed and combined with an adjustable finite difference scheme to construct a highly adaptive numerical simulation method. In the construction of discrete schemes, the Swartztrauber-Sweet method and the control volume method are employed to effectively eliminate the origin singularity caused by polar coordinate transformation. On the programming front, a parallelized MATLAB algorithm is developed to optimize code execution efficiency. Numerical comparative experiments demonstrate that the adaptive method improves the accuracy of the parabolic equation by 1 to 7 times and that of the continuity equation by 10% to 70% while maintaining computational efficiency, significantly enhancing numerical simulation accuracy with high stability. Furthermore, this study systematically verifies the algorithm's convergence, stability, and parameter sensitivity using error visualization and other means. It also explores optimal parameters and establishes tuning optimization criteria. The research provides theoretical support for high-precision and highly adaptive methods in semiconductor device simulation, demonstrating outstanding advantages in handling singular regions.</description>
      <guid isPermaLink="false">oai:arXiv.org:2509.15879v1</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <pubDate>Mon, 22 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Zeyu Zhang, Xiaoyu Zhang, Zhigang Song, Qing Fang</dc:creator>
    </item>
    <item>
      <title>A Flow-rate-conserving CNN-based Domain Decomposition Method for Blood Flow Simulations</title>
      <link>https://arxiv.org/abs/2509.15900</link>
      <description>arXiv:2509.15900v1 Announce Type: new 
Abstract: This work aims to predict blood flow with non-Newtonian viscosity in stenosed arteries using convolutional neural network (CNN) surrogate models. An alternating Schwarz domain decomposition method is proposed which uses CNN-based subdomain solvers. A universal subdomain solver (USDS) is trained on a single, fixed geometry and then applied for each subdomain solve in the Schwarz method. Results for two-dimensional stenotic arteries of varying shape and length for different inflow conditions are presented and statistically evaluated. One key finding, when using a limited amount of training data, is the need to implement a USDS which preserves some of the physics, as, in our case, flow rate conservation. A physics-aware approach outperforms purely data-driven USDS, delivering improved subdomain solutions and preventing overshooting or undershooting of the global solution during the Schwarz iterations, thereby leading to more reliable convergence.</description>
      <guid isPermaLink="false">oai:arXiv.org:2509.15900v1</guid>
      <category>math.NA</category>
      <category>cs.LG</category>
      <category>cs.NA</category>
      <pubDate>Mon, 22 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Simon Klaes, Axel Klawonn, Natalie Kubicki, Martin Lanser, Kengo Nakajima, Takashi Shimokawabe, Janine Weber</dc:creator>
    </item>
    <item>
      <title>Computing the Zeros of a Holomorphic Function Using Quadrature-Based Subdivision and Rational Approximation of the Logarithmic Derivative</title>
      <link>https://arxiv.org/abs/2509.15936</link>
      <description>arXiv:2509.15936v2 Announce Type: new 
Abstract: We introduce a new method that uses AAA approximation to reliably compute all the zeros of a holomorphic function in a specified search region in the complex plane. Specifically, the method is based on rational approximation of the logarithmic derivative in combination with subdivision of the search region based on Cauchy's argument principle. This is motivated by the fact that, while it is straightforward to compute the zeros of a AAA rational approximation, there is no guarantee that all of the zeros of the function being approximated will be found. Many of the ideas presented are also applicable to computing both the zeros and the poles of a meromorphic function. A implementation of the method is provided by the Python package skzeros.</description>
      <guid isPermaLink="false">oai:arXiv.org:2509.15936v2</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <pubDate>Mon, 22 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Jake Bowhay, Yuji Nakatsukasa, Irwin Zaid</dc:creator>
    </item>
    <item>
      <title>In Ratio Section Method and Algorithms for Minimizing Unimodal Functions</title>
      <link>https://arxiv.org/abs/2509.15972</link>
      <description>arXiv:2509.15972v1 Announce Type: new 
Abstract: This paper proposes a new method for section an interval in a given ratio intended for minimizing unimodal functions. The ratio section search is capable of quickly recognizing monotone functions and functions with a flat bottom, which contributes to increasing its performance, as measured by the number of minimized function evaluations. The method is implemented as passive and active algorithms. A comparison of the performance of the developed method with that of the classical methods of bisection search and the golden section search was performed on the basis of the data used to minimize twenty unimodal functions of various types. For all types of functions, the passive algorithm is 2.26 times faster than the bisection search and 1.72 times faster than the golden section method. Thus, the proposed method turned out to be the fastest of the known methods of cutting off segments intended for minimizing unimodal functions. The active algorithm is faster: for all types of functions, these indicators are 3.31 and 2.52, respectively. The fastest combined Brent method was also modernized. After the golden section procedure is replaced with a procedure for dividing a segment in a given ratio, a numerical experiment is conducted. The modernized method is 1.69 times faster than its prototype. Moreover, the performance of the active algorithm for dividing a segment at a given ratio exceeds that of the Brent method by 1.48 times for all types of functions. The modernized Brent method is approximately 4 times faster than the bisection search and 3 times faster than the golden section method.</description>
      <guid isPermaLink="false">oai:arXiv.org:2509.15972v1</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <pubDate>Mon, 22 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Vladimir Kodnyanko</dc:creator>
    </item>
    <item>
      <title>An Isogeometric Tearing and Interconnecting (IETI) method for solving high order partial differential equations over planar multi-patch geometries</title>
      <link>https://arxiv.org/abs/2509.15997</link>
      <description>arXiv:2509.15997v1 Announce Type: new 
Abstract: We present a novel method for solving high-order partial differential equations (PDEs) over planar multi-patch geometries demonstrated on the basis of the polyharmonic equation of order $m$, $m \geq 1$, which is a particular linear elliptic PDE of order $2m$. Our approach is based on the concept of Isogeometric Tearing and Interconnecting (IETI) [43] and allows to couple the numerical solution of the PDE with $C^s$-smoothness, $s \geq m-1$, across the edges of the multi-patch geometry. The proposed technique relies on the use of a particular class of multi-patch geometries, called bilinear-like $G^s$ multi-patch parameterizations [37], to represent the multi-patch domain. The coupling between the neighboring patches is done via the use of Lagrange multipliers and leads to a saddle point problem, which can be solved efficiently first by a small dual problem for a subset of the Lagrange multipliers followed by local, parallelizable problems on the single patches for the coefficients of the numerical solution. Several numerical examples of solving the polyharmonic equation of order $m=2$ and $m=3$, i.e. the biharmonic and triharmonic equation, respectively, over different multi-patch geometries are shown to demonstrate the potential of our IETI method for high-order problems.</description>
      <guid isPermaLink="false">oai:arXiv.org:2509.15997v1</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <pubDate>Mon, 22 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Mario Kapl, Alja\v{z} Kosma\v{c}, Vito Vitrih</dc:creator>
    </item>
    <item>
      <title>Discrete Empirical Interpolation Method with Upper and Lower Bound Constraints</title>
      <link>https://arxiv.org/abs/2509.16018</link>
      <description>arXiv:2509.16018v1 Announce Type: new 
Abstract: Discrete Empirical Interpolation Method (DEIM) is a simple and effective method for reconstructing a function from its incomplete pointwise observations. However, applying DEIM to functions with physically constrained ranges can produce reconstructions with values outside the prescribed physical bounds. Such physically constrained quantities occur routinely in applications, e.g., mass density whose range is nonnegative. The DEIM reconstructions which violate these physical constraints are not usable in downstream tasks such as forecasting and control. To address this issue, we develop Constrained DEIM (C-DEIM) whose reconstructions are guaranteed to respect the physical bounds of the quantity of interest. C-DEIM enforces the bounds as soft constraints, in the form of a carefully designed penalty term, added to the underlying least squares problem. We prove that the C-DEIM reconstructions satisfy the physical constraints asymptotically, i.e., as the penalty parameter increases towards infinity. We also derive a quantitative upper bound for the observation residual of C-DEIM. Based on these theoretical results, we devise an efficient algorithm for practical implementation of C-DEIM. The efficacy of the method and the accompanying algorithm are demonstrated on several examples, including a heat transfer problem from fluid dynamics and a cellular automaton model of wildfire spread.</description>
      <guid isPermaLink="false">oai:arXiv.org:2509.16018v1</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <pubDate>Mon, 22 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Louisa B. Ebby, Mohammad Farazmand</dc:creator>
    </item>
    <item>
      <title>Sensitivity of Perron and Fiedler eigenpairs to structural perturbations of a network</title>
      <link>https://arxiv.org/abs/2509.16024</link>
      <description>arXiv:2509.16024v1 Announce Type: new 
Abstract: One can estimate the change of the Perron and Fiedler values for a connected network when the weight of an edge is perturbed by analyzing relevant entries of the Perron and Fiedler vectors. This is helpful for identifying edges whose weight perturbation causes the largest change in the Perron and Fiedler values. It also is important to investigate the sensitivity of the Perron and Fiedler vectors to perturbations. Applications of the perturbation analysis include the identification of edges that are critical for the structural robustness of the network.</description>
      <guid isPermaLink="false">oai:arXiv.org:2509.16024v1</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <pubDate>Mon, 22 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Silvia Noschese, Lothar Reichel</dc:creator>
    </item>
    <item>
      <title>Fast subdivision of B\'{e}zier curves</title>
      <link>https://arxiv.org/abs/2509.15691</link>
      <description>arXiv:2509.15691v1 Announce Type: cross 
Abstract: It is well-known that a $d$-dimensional polynomial B\'{e}zier curve of degree $n$ can be subdivided into two segments using the famous de Casteljau algorithm in $O(dn^2)$ time. Can this problem be solved more efficiently? In this paper, we show that it is possible to do this in $O(dn\log{n})$ time using the fast Fourier transform and its inverse. Experiments show that the direct application of the new method performs well only for small values of $n$, as the algorithm is numerically unstable. However, a slightly modified version -- which still has $O(dn\log{n})$ computational complexity -- offers good numerical quality, which is confirmed by numerical experiments conducted in \textsf{Python}. Moreover, the new method has a nice property: if a B\'{e}zier curve is extended by an additional control point, the subdivision can be updated in $O(d)$ time.
  A similar idea can be applied to speed up the subdivision of rational B\'{e}zier curves and rectangular B\'{e}zier surfaces, as well as to compute the derivatives of B\'{e}zier curves more efficiently.</description>
      <guid isPermaLink="false">oai:arXiv.org:2509.15691v1</guid>
      <category>cs.GR</category>
      <category>cs.NA</category>
      <category>math.NA</category>
      <pubDate>Mon, 22 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Pawe{\l} Wo\'zny, Filip Chudy</dc:creator>
    </item>
    <item>
      <title>Optimal Experimental Design of a Moving Sensor for Linear Bayesian Inverse Problems</title>
      <link>https://arxiv.org/abs/2509.15961</link>
      <description>arXiv:2509.15961v1 Announce Type: cross 
Abstract: We optimize the path of a mobile sensor to minimize the posterior uncertainty of a Bayesian inverse problem. Along its path, the sensor continuously takes measurements of the state, which is a physical quantity modeled as the solution of a partial differential equation (PDE) with uncertain parameters. Considering linear PDEs specifically, we derive the closed-form expression of the posterior covariance matrix of the model parameters as a function of the path, and formulate the optimal experimental design problem for minimizing the posterior's uncertainty. We discretize the problem such that the cost function remains consistent under temporal refinement. Additional constraints ensure that the path avoids obstacles and remains physically interpretable through a control parameterization. The constrained optimization problem is solved using an interior-point method. We present computational results for a convection-diffusion equation with unknown initial condition.</description>
      <guid isPermaLink="false">oai:arXiv.org:2509.15961v1</guid>
      <category>cs.CE</category>
      <category>cs.NA</category>
      <category>math.NA</category>
      <pubDate>Mon, 22 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Nicole Aretz, Thomas Lynn, Karen Willcox, Sven Leyffer</dc:creator>
    </item>
    <item>
      <title>Solvability Complexity Index Classification For Koopman Operator Spectra In $L^p$ For $1&lt;p&lt;\infty$</title>
      <link>https://arxiv.org/abs/2509.16016</link>
      <description>arXiv:2509.16016v1 Announce Type: cross 
Abstract: We study the computation of the approximate point spectrum and the approximate point $\varepsilon$-pseudospectrum of bounded Koopman operators acting on $L^p(\mathcal{X},\omega)$ for $1&lt;p&lt;\infty$ and a compact metric space $(\mathcal{X}, d_{\mathcal{X}})$ with finite Borel measure $\omega$. Building on finite sections in a computable unconditional Schauder basis of $L^p(\mathcal{X},\omega)$, we design residual tests that use only finitely many evaluations of the underlying map and produce compact sets on a planar grid, that converge in the Hausdorff metric to the target spectral sets, without spectral pollution. From these constructions we obtain a complete classification, in the sense of the Solvability Complexity Index, of how many limiting procedures are inherently necessary. Also we analyze the sufficiency and existence of a Wold-von Neumann decomposition analog, that was used in the special $L^2$-case.
  The main difficulty in extending from the already analyzed Hilbert setting $(p=2)$ to general $L^p$ is the loss of orthogonality and Hilbertian structure: there is no orthonormal basis with orthogonal coordinate projections in general, the canonical truncations $E_n$ in a computable Schauder dictionary need not be contractive (and may oscillate) and the Wold-von Neumann reduction has no directly computable analog in $L^p$. We overcome these obstacles by working with computable unconditional dictionaries adapted to dyadic/Lipschitz filtrations and proving stability of residual tests under non-orthogonal truncations.</description>
      <guid isPermaLink="false">oai:arXiv.org:2509.16016v1</guid>
      <category>math.SP</category>
      <category>cs.CC</category>
      <category>cs.NA</category>
      <category>math.DS</category>
      <category>math.NA</category>
      <pubDate>Mon, 22 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Christopher Sorg</dc:creator>
    </item>
    <item>
      <title>Estimating systematic errors in Bayesian inversion using transport maps</title>
      <link>https://arxiv.org/abs/2509.16116</link>
      <description>arXiv:2509.16116v1 Announce Type: cross 
Abstract: In indirect measurements, the measurand is determined by solving an inverse problem which requires a model of the measurement process. Such models are often approximations and introduce systematic errors leading to a bias of the posterior distribution in Bayesian inversion. We propose a unified framework that combines transport maps from a reference distribution to the posterior distribution with the model error approach. This leads to an adaptive algorithm that jointly estimates the posterior distribution of the measurand and the model error. The efficiency and accuracy of the method are demonstrated on two model problems, showing that the approach effectively corrects biases while enabling fast sampling.</description>
      <guid isPermaLink="false">oai:arXiv.org:2509.16116v1</guid>
      <category>stat.ME</category>
      <category>cs.NA</category>
      <category>math.NA</category>
      <category>math.PR</category>
      <pubDate>Mon, 22 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Maren Casfor, Philipp Trunschke, Sebastian Heidenreich, Nando Hegemann</dc:creator>
    </item>
    <item>
      <title>Fast OTSU Thresholding Using Bisection Method</title>
      <link>https://arxiv.org/abs/2509.16179</link>
      <description>arXiv:2509.16179v1 Announce Type: cross 
Abstract: The Otsu thresholding algorithm represents a fundamental technique in image segmentation, yet its computational efficiency is severely limited by exhaustive search requirements across all possible threshold values. This work presents an optimized implementation that leverages the bisection method to exploit the unimodal characteristics of the between-class variance function. Our approach reduces the computational complexity from O(L) to O(log L) evaluations while preserving segmentation accuracy. Experimental validation on 48 standard test images demonstrates a 91.63% reduction in variance computations and 97.21% reduction in algorithmic iterations compared to conventional exhaustive search. The bisection method achieves exact threshold matches in 66.67% of test cases, with 95.83% exhibiting deviations within 5 gray levels. The algorithm maintains universal convergence within theoretical logarithmic bounds while providing deterministic performance guarantees suitable for real-time applications. This optimization addresses critical computational bottlenecks in large-scale image processing systems without compromising the theoretical foundations or segmentation quality of the original Otsu method.</description>
      <guid isPermaLink="false">oai:arXiv.org:2509.16179v1</guid>
      <category>cs.CV</category>
      <category>cs.AI</category>
      <category>cs.NA</category>
      <category>math.NA</category>
      <pubDate>Mon, 22 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Sai Varun Kodathala</dc:creator>
    </item>
    <item>
      <title>Multi-phase-field elasticity model based on partial rank-one energy relaxation on pairwise interfaces</title>
      <link>https://arxiv.org/abs/2304.02406</link>
      <description>arXiv:2304.02406v2 Announce Type: replace 
Abstract: To model mechanically-driven phase transformations using the phase-field theory, suitable models are needed for describing the mechanical fields related to individual phase-fields in the interfacial regions. They play a crucial role in obtaining the mechanical driving forces of phase-field evolution. Quantitative modeling requires satisfying the interfacial static equilibrium and kinematic compatibility conditions. To the best of our knowledge, no existing multi-phase-field elasticity model has been able to satisfy the jump conditions between all the locally-active phase-fields associated to their pairwise normals, except in the dual-phase-field regions. In this work, we introduce a novel multi-phase-field elasticity model based on the partial rank-one relaxation of the elastic energy density defined on the pairwise interfaces as a function of pairwise strains. These ad hoc pairwise definitions enable us to satisfy the static equilibrium and kinematic compatibility conditions between all the locally-active phase-fields. Different numerical examples are presented, which compare the developed model against the equal-strain and equal-stress limiting cases.</description>
      <guid isPermaLink="false">oai:arXiv.org:2304.02406v2</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <pubDate>Mon, 22 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Mohammad Sarhil, Oleg Shchyglo, Hesham Salama, Dominik Brands, Ingo Steinbach, J\"org Schr\"oder</dc:creator>
    </item>
    <item>
      <title>Recovery of rational functions via Hankel pencil method and sensitivities of the poles</title>
      <link>https://arxiv.org/abs/2406.13192</link>
      <description>arXiv:2406.13192v3 Announce Type: replace 
Abstract: In this paper, we introduce a new approach for the recovery of rational functions. The concept we propose is based on using the exponential structure of the Fourier coefficients of rational functions and the reconstruction of this exponential structure in the frequency domain. We choose ESPRIT as a method for the exponential recovery. The matrix pencil structure of this approach is the reason for its selection, as it makes our method suitable for the sensitivity analysis. According to our method, poles located inside and outside the unit circle are reconstructed independently as eigenvalues of some special Hankel matrix pencils. Furthermore, we derived formulas for sensitivities of poles of rational functions in case of unstructured and structured perturbations. Finally, we consider several numerical experiments and, using sensitivities, explain the recovery errors for poles.</description>
      <guid isPermaLink="false">oai:arXiv.org:2406.13192v3</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <pubDate>Mon, 22 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Nadiia Derevianko</dc:creator>
    </item>
    <item>
      <title>Measurability and continuity of parametric low-rank approximation in Hilbert spaces: linear operators and random variables</title>
      <link>https://arxiv.org/abs/2409.09102</link>
      <description>arXiv:2409.09102v2 Announce Type: replace 
Abstract: We present a unified theoretical framework for parametric low-rank approximation, a research area devoted to the development of efficient algorithms that act as adaptive alternatives of traditional methods such as Singular Value Decomposition (SVD), Proper Orthogonal Decomposition (POD), and Principal Component Analysis (PCA). Applications include, e.g., the numerical treatment of parameter-dependent partial differential equations, where operators vary with parameters, and the statistical analysis of longitudinal data, where complex measurements, like audio signals and images, are collected over time. Recently, several adaptive algorithms have emerged, but a common mathematical foundation is still lacking, and existing solutions remain constrained to specific applications. As a result, key theoretical questions -- such as the existence and regularity of optimal parametric low-rank approximants -- remain inadequately addressed. Our goal is to bridge this gap between theory and practice by establishing a rigorous framework for parametric low-rank approximation under minimal assumptions, specifically focusing on cases where parameterizations are either measurable or continuous. The analysis is carried out within the context of separable Hilbert spaces, ensuring applicability to both finite and infinite-dimensional settings. Finally, connections to recently emerging trends in the Deep Learning literature, relevant for engineering and data science, are also discussed.</description>
      <guid isPermaLink="false">oai:arXiv.org:2409.09102v2</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <pubDate>Mon, 22 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Nicola Rares Franco</dc:creator>
    </item>
    <item>
      <title>Adaptive and non-adaptive randomized approximation of high-dimensional vectors</title>
      <link>https://arxiv.org/abs/2410.23067</link>
      <description>arXiv:2410.23067v2 Announce Type: replace 
Abstract: We study approximation of the embedding $\ell_p^m \hookrightarrow \ell_q^m$, $1 \leq p &lt; q \leq \infty$, based on randomized algorithms that use up to $n$ arbitrary linear functionals as information on a problem instance where $n \ll m$. By analysing adaptive methods we show upper bounds for which the information-based complexity $n$ exhibits only a $(\log\log m)$-dependence. In the case $q &lt; \infty$ we use a multi-sensitivity approach in order to reach optimal polynomial order in $n$ for the Monte Carlo error. We also improve on non-adaptive methods for $q &lt; \infty$ by denoising known algorithms for uniform approximation.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.23067v2</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <pubDate>Mon, 22 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Robert J. Kunsch, Marcin Wnuk</dc:creator>
    </item>
    <item>
      <title>GridapROMs.jl: Efficient reduced order modelling in the Julia programming language</title>
      <link>https://arxiv.org/abs/2503.15994</link>
      <description>arXiv:2503.15994v3 Announce Type: replace 
Abstract: In this paper, we introduce GridapROMs, a Julia-based library for the numerical approximation of parameterized partial differential equations (PDEs) using a comprehensive suite of linear reduced order models (ROMs). The library is designed to be extendable and productive, leveraging an expressive high-level API built on the Gridap PDE solver backend, while achieving high performance through Julia's just-in-time compiler and advanced lazy evaluation techniques. GridapROMs is PDE-agnostic, enabling its application to a wide range of problems, including linear, nonlinear, single-field, multi-field, steady, and unsteady equations. This work details the library's key innovations, implementation principles, and core components, providing usage examples and demonstrating its capabilities by solving a fluid dynamics problem modeled by the Navier-Stokes equations in a 3D geometry.</description>
      <guid isPermaLink="false">oai:arXiv.org:2503.15994v3</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <pubDate>Mon, 22 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Nicholas Mueller, Santiago Badia</dc:creator>
    </item>
    <item>
      <title>Error estimates of fully semi-Lagrangian schemes for diffusive conservation laws</title>
      <link>https://arxiv.org/abs/2508.03455</link>
      <description>arXiv:2508.03455v2 Announce Type: replace 
Abstract: We present error estimates of the fully semi-Lagrangian scheme with high-order interpolation operators, solving the initial value problems for the one-dimensional nonlinear diffusive conservation laws, including the Burgers equations. We impose certain assumptions on the interpolation operator, which are satisfied by both spline and Hermite interpolations. We establish the convergence rates of $ O(\Delta t + h^{2 s} / \Delta t) $ in the $ L^2 $-norm and $ O(\Delta t + h^{s} / (\Delta t)^{1/2} + h^{2s} / \Delta t) $ in the $ H^s $-norm for the spatial mesh size $ h $ and the temporal step size $ \Delta t $, where the spline or Hermite interpolation operator of degree $ (2s - 1) $ is employed. The numerical results are in agreement with the theoretical analysis.</description>
      <guid isPermaLink="false">oai:arXiv.org:2508.03455v2</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <pubDate>Mon, 22 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Haruki Takemura</dc:creator>
    </item>
    <item>
      <title>A Universal Birkhoff Theory for Fast Trajectory Optimization</title>
      <link>https://arxiv.org/abs/2308.01400</link>
      <description>arXiv:2308.01400v3 Announce Type: replace-cross 
Abstract: Over the last two decades, pseudospectral methods based on Lagrange interpolants have flourished in solving trajectory optimization problems and their flight implementations. In a seemingly unjustified departure from these highly successful methods, a new starting point for trajectory optimization is proposed. This starting point is based on the recently-developed concept of universal Birkhoff interpolants. The new approach offers a substantial computational upgrade to the Lagrange theory in completely flattening the rapid growth of the condition numbers from O(N2) to O(1), where N is the number of grid points. In addition, the Birkhoff-specific primal-dual computations are isolated to a well-conditioned linear system even for nonlinear, nonconvex problems. This is part I of a two-part paper. In part I, a new theory is developed on the basis of two hypotheses. Other than these hypotheses, the theoretical development makes no assumptions on the choices of basis functions or the selection of grid points. Several covector mapping theorems are proved to establish the mathematical equivalence between direct and indirect Birkhoff methods. In part II of this paper (with Proulx), it is shown that a select family of Gegenbauer grids satisfy the two hypotheses required for the theory to hold. Numerical examples in part II illustrate the power and utility of the new theory.</description>
      <guid isPermaLink="false">oai:arXiv.org:2308.01400v3</guid>
      <category>math.OC</category>
      <category>cs.NA</category>
      <category>math.NA</category>
      <pubDate>Mon, 22 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <arxiv:DOI>10.2514/1.G007737</arxiv:DOI>
      <arxiv:journal_reference>journal = {Journal of Guidance, Control, and Dynamics}, volume = {47}, number = {12}, pages = {2468-2481}, year = {2024}</arxiv:journal_reference>
      <dc:creator>I. M. Ross</dc:creator>
    </item>
    <item>
      <title>A comparative analysis for different finite element types in strain-gradient elasticity simulations performed on Firedrake and FEniCS</title>
      <link>https://arxiv.org/abs/2411.12043</link>
      <description>arXiv:2411.12043v3 Announce Type: replace-cross 
Abstract: The layer-upon-layer approach in additive manufacturing, open or closed cells in polymeric or metallic foams involve an intrinsic microstructure tailored to the underlying applications. Homogenization of such architectured materials creates metamaterials modeled by higher-gradient models, specifically when the microstructure's characteristic length is comparable to the length scale of the structure. In this study, we conduct a comparative analysis of various finite elements methods for solving problems in strain-gradient elasticity. We employ open-source packages from Firedrake and FEniCS. Different finite element formulations are tested: we implement Lagrange, Argyris, Hermite elements, a Hu--Washizu type (mixed) formulation, as well as isogeometric analysis with Non-Uniform Rational B-Splines (NURBS). For the numerical study, we investigate one- and two-dimensional problems discussed in the literature of strain-gradient modeling. All developed codes are open-access to encourage research in Finite Element Method (FEM) based computation of generalized continua.</description>
      <guid isPermaLink="false">oai:arXiv.org:2411.12043v3</guid>
      <category>cs.CE</category>
      <category>cs.NA</category>
      <category>math-ph</category>
      <category>math.MP</category>
      <category>math.NA</category>
      <pubDate>Mon, 22 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <arxiv:DOI>10.2140/memocs.2025.13.237</arxiv:DOI>
      <arxiv:journal_reference>Mathematics and Mechanics of Complex Systems, 13(3), pp. 237-252, 2025</arxiv:journal_reference>
      <dc:creator>B. Cagri Sarar, M. Erden Yildizdag, Francesco Fabbrocino, B. Emek Abali</dc:creator>
    </item>
    <item>
      <title>Gradient-Free Sequential Bayesian Experimental Design via Interacting Particle Systems</title>
      <link>https://arxiv.org/abs/2504.13320</link>
      <description>arXiv:2504.13320v3 Announce Type: replace-cross 
Abstract: We introduce a gradient-free framework for Bayesian Optimal Experimental Design (BOED) in sequential settings, aimed at complex systems where gradient information is unavailable. Our method combines Ensemble Kalman Inversion (EKI) for design optimization with the Affine-Invariant Langevin Dynamics (ALDI) sampler for efficient posterior sampling-both of which are derivative-free and ensemble-based. To address the computational challenges posed by nested expectations in BOED, we propose variational Gaussian and parametrized Laplace approximations that provide tractable upper and lower bounds on the Expected Information Gain (EIG). These approximations enable scalable utility estimation in high-dimensional spaces and PDE-constrained inverse problems. We demonstrate the performance of our framework through numerical experiments ranging from linear Gaussian models to PDE-based inference tasks, highlighting the method's robustness, accuracy, and efficiency in information-driven experimental design.</description>
      <guid isPermaLink="false">oai:arXiv.org:2504.13320v3</guid>
      <category>stat.ML</category>
      <category>cs.LG</category>
      <category>cs.NA</category>
      <category>math.NA</category>
      <category>stat.CO</category>
      <pubDate>Mon, 22 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Robert Gruhlke, Matei Hanu, Claudia Schillings, Philipp Wacker</dc:creator>
    </item>
    <item>
      <title>Near-field-free super-potential FFT method for the three-dimensional free-space Poisson equation</title>
      <link>https://arxiv.org/abs/2506.04489</link>
      <description>arXiv:2506.04489v2 Announce Type: replace-cross 
Abstract: We present a spectrally accurate, efficient FFT-based method for the three-dimensional free-space Poisson equation with smooth, compactly supported sources. The method adopts a super-potential formulation: we first compute the convolution with the biharmonic Green's function, then recover the potential by spectral differentiation, applying the Laplacian in Fourier space. A separable Gaussian-sum (GS) approximation enables efficient precomputation and quasi-linear, FFT-based convolution. Owing to the biharmonic kernel's improved regularity, the GS cutoff error is fourth-order, uniform for all target points, eliminating the near-field corrections and Taylor expansions required in standard GS/Ewald-type methods. Benchmarks on Gaussian, oscillatory, and compactly supported densities reach the double-precision limit and, at matched accuracy on the same hardware, reduce both error and per-solve runtime relative to our original GS-based scheme. The resulting method is simple, reproducible, and efficient for three-dimensional free-space Poisson problems with smooth sources on uniform grids.</description>
      <guid isPermaLink="false">oai:arXiv.org:2506.04489v2</guid>
      <category>physics.comp-ph</category>
      <category>cs.NA</category>
      <category>math.NA</category>
      <pubDate>Mon, 22 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Lukas Exl, Sebastian Schaffer</dc:creator>
    </item>
    <item>
      <title>Block Encoding of Sparse Matrices via Coherent Permutation</title>
      <link>https://arxiv.org/abs/2508.21667</link>
      <description>arXiv:2508.21667v2 Announce Type: replace-cross 
Abstract: Block encoding of sparse matrices underpins powerful quantum algorithms such as quantum singular value transformation, Hamiltonian simulation, and quantum linear solvers, but its efficient gate-level implementation for arbitrary sparse matrices remains a major challenge. We introduce a unified framework that overcomes the key obstacles of multi-controlled X gates overhead, amplitude reordering, and hardware connectivity, enabling efficient block encoding for arbitrary sparse matrices with explicit gate-level constructions. Central to our approach are a novel connection with combinatorial optimization, which enables systematic assignment of control qubits to achieve nearest-neighbor connectivity, and coherent permutation operators that preserve superposition while enabling amplitude reordering. We demonstrate our methods on structured sparse matrices, showing significant reductions in circuit depth and control overhead, thereby bridging the gap between theoretical formulations and practical circuit implementations for quantum algorithms.</description>
      <guid isPermaLink="false">oai:arXiv.org:2508.21667v2</guid>
      <category>quant-ph</category>
      <category>cs.DS</category>
      <category>cs.NA</category>
      <category>math.NA</category>
      <pubDate>Mon, 22 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Abhishek Setty</dc:creator>
    </item>
    <item>
      <title>Tensor Forms of Derivatives of Matrices and their applications in the Solutions to Differential Equations</title>
      <link>https://arxiv.org/abs/2509.08429</link>
      <description>arXiv:2509.08429v2 Announce Type: replace-cross 
Abstract: We introduce and extend the outer product and contractive product of tensors and matrices, and present some identities in terms of these products. We offer tensor expressions of derivatives of tensors, focus on the tensor forms of derivatives of a matrix w.r.t. another matrix. This tensor form makes possible for us to unify ordinary differential equations (ODEs) with partial differential equations (PDEs), and facilitates solution to them in some cases. For our purpose, we also extend the outer product and contractive product of tensors (matrices) to a more general case through any partition of the modes, present some identities in terms of these products, initialize the definition of partial Tucker decompositions (TuckD) of a tensor, and use the partial TuckD to simplify the PDEs. We also present a tensor form for the Lyapunov function. Our results in the products of tensors and matrices help us to establish some important equalities on the derivatives of matrices and tensors. An algorithm based on the partial Tucker decompositions (TuckD) to solve the PDEs is given, and a numerical example is presented to illustrate the efficiency of the algorithm.</description>
      <guid isPermaLink="false">oai:arXiv.org:2509.08429v2</guid>
      <category>math.CA</category>
      <category>cs.NA</category>
      <category>math.AG</category>
      <category>math.NA</category>
      <pubDate>Mon, 22 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Yiran Xu, Guangbin Wang, Changqing Xu</dc:creator>
    </item>
    <item>
      <title>PBPK-iPINNs: Inverse Physics-Informed Neural Networks for Physiologically Based Pharmacokinetic Brain Models</title>
      <link>https://arxiv.org/abs/2509.12666</link>
      <description>arXiv:2509.12666v2 Announce Type: replace-cross 
Abstract: Physics-Informed Neural Networks (PINNs) leverage machine learning with differential equations to solve direct and inverse problems, ensuring predictions follow physical laws. Physiologically based pharmacokinetic (PBPK) modeling advances beyond classical compartmental approaches by using a mechanistic, physiology focused framework. A PBPK model is based on a system of ODEs, with each equation representing the mass balance of a drug in a compartment, such as an organ or tissue. These ODEs include parameters that reflect physiological, biochemical, and drug-specific characteristics to simulate how the drug moves through the body. In this paper, we introduce PBPK-iPINN, a method to estimate drug-specific or patient-specific parameters and drug concentration profiles in PBPK brain compartment models using inverse PINNs. We demonstrate that, for the inverse problem to converge to the correct solution, the loss function components (data loss, initial conditions loss, and residual loss) must be appropriately weighted, and parameters (including number of layers, number of neurons, activation functions, learning rate, optimizer, and collocation points) must be carefully tuned. The performance of the PBPK-iPINN approach is then compared with established traditional numerical and statistical methods.</description>
      <guid isPermaLink="false">oai:arXiv.org:2509.12666v2</guid>
      <category>stat.ML</category>
      <category>cs.LG</category>
      <category>cs.NA</category>
      <category>math.NA</category>
      <pubDate>Mon, 22 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/publicdomain/zero/1.0/</dc:rights>
      <dc:creator>Charuka D. Wickramasinghe, Krishanthi C. Weerasinghe, Pradeep K. Ranaweera</dc:creator>
    </item>
  </channel>
</rss>
