<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>stat.AP updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/stat.AP</link>
    <description>stat.AP updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/stat.AP" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Fri, 25 Oct 2024 01:45:55 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Thu, 24 Oct 2024 00:00:00 -0400</pubDate>
    <skipDays>
      <day>Sunday</day>
      <day>Saturday</day>
    </skipDays>
    <item>
      <title>Experimental Designs for Optimizing Last-Mile Delivery</title>
      <link>https://arxiv.org/abs/2410.17392</link>
      <description>arXiv:2410.17392v1 Announce Type: new 
Abstract: Companies like Amazon and UPS are heavily invested in last-mile delivery problems. Optimizing last-delivery operations not only creates tremendous cost savings for these companies but also generate broader societal and environmental benefits in terms of better delivery service and reduced air pollutants and greenhouse gas emissions. Last-mile delivery is readily formulated as the Travelling Salesman Problem (TSP), where a salesperson must visit several cities and return to the origin with the least cost. A solution to this problem is a Hamiltonian circuit in an undirected graph. Many methods exist for solving the TSP, but they often assume the travel costs are fixed. In practice, travel costs between delivery zones are random quantities, as they are subject to variation from traffic, weather, and other factors. Innovations such as truck-drone last-mile delivery creates even more uncertainties due to scarce data. A Bayesian D-optimal experimental design in conjunction with a regression model are proposed to estimate these unknown travel costs, and subsequently search for a highly efficient solution to the TSP. This framework can naturally be extended to incorporate the use of drones and any other emerging technology that has use in last-mile delivery.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.17392v1</guid>
      <category>stat.AP</category>
      <category>math.OC</category>
      <pubDate>Thu, 24 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Nicholas Rios, Jie Xu</dc:creator>
    </item>
    <item>
      <title>Improving Insurance Catastrophic Data with Resampling and GAN Methods</title>
      <link>https://arxiv.org/abs/2410.17294</link>
      <description>arXiv:2410.17294v1 Announce Type: cross 
Abstract: The precise and large dataset concerning catastrophic events is very important for insurers. To improve the quality of such data three methods based on the bootstrap, bootknife, and GAN algorithms are proposed. Using numerical experiments and real-life data, simulated outputs for these approaches are compared based on the mean squared (MSE) and mean absolute errors (MAE). Then, a direct algorithm to construct a fuzzy expert's opinion concerning such outputs is also considered.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.17294v1</guid>
      <category>cs.LG</category>
      <category>stat.AP</category>
      <category>stat.CO</category>
      <category>stat.ML</category>
      <pubDate>Thu, 24 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Norbert Dzadz, Maciej Romaniuk</dc:creator>
    </item>
    <item>
      <title>Formal Privacy Guarantees with Invariant Statistics</title>
      <link>https://arxiv.org/abs/2410.17468</link>
      <description>arXiv:2410.17468v1 Announce Type: cross 
Abstract: Motivated by the 2020 US Census products, this paper extends differential privacy (DP) to address the joint release of DP outputs and nonprivate statistics, referred to as invariant. Our framework, Semi-DP, redefines adjacency by focusing on datasets that conform to the given invariant, ensuring indistinguishability between adjacent datasets within invariant-conforming datasets. We further develop customized mechanisms that satisfy Semi-DP, including the Gaussian mechanism and the optimal $K$-norm mechanism for rank-deficient sensitivity spaces. Our framework is applied to contingency table analysis which is relevant to the 2020 US Census, illustrating how Semi-DP enables the release of private outputs given the one-way margins as the invariant. Additionally, we provide a privacy analysis of the 2020 US Decennial Census using the Semi-DP framework, revealing that the effective privacy guarantees are weaker than advertised.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.17468v1</guid>
      <category>cs.CR</category>
      <category>stat.AP</category>
      <pubDate>Thu, 24 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Young Hyun Cho, Jordan Awan</dc:creator>
    </item>
    <item>
      <title>Rare Event Classification with Weighted Logistic Regression for Identifying Repeating Fast Radio Bursts</title>
      <link>https://arxiv.org/abs/2410.17474</link>
      <description>arXiv:2410.17474v1 Announce Type: cross 
Abstract: An important task in the study of fast radio bursts (FRBs) remains the automatic classification of repeating and non-repeating sources based on their morphological properties. We propose a statistical model that considers a modified logistic regression to classify FRB sources. The classical logistic regression model is modified to accommodate the small proportion of repeaters in the data, a feature that is likely due to the sampling procedure and duration and is not a characteristic of the population of FRB sources. The weighted logistic regression hinges on the choice of a tuning parameter that represents the true proportion $\tau$ of repeating FRB sources in the entire population. The proposed method has a sound statistical foundation, direct interpretability, and operates with only 5 parameters, enabling quicker retraining with added data. Using the CHIME/FRB Collaboration sample of repeating and non-repeating FRBs and numerical experiments, we achieve a classification accuracy for repeaters of nearly 75\% or higher when $\tau$ is set in the range of $50$ to $60$\%. This implies a tentative high proportion of repeaters, which is surprising, but is also in agreement with recent estimates of $\tau$ that are obtained using other methods.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.17474v1</guid>
      <category>astro-ph.HE</category>
      <category>astro-ph.IM</category>
      <category>stat.AP</category>
      <pubDate>Thu, 24 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Antonio Herrera-Martin, Radu V. Craiu, Gwendolyn M. Eadie, David C. Stenning, Derek Bingham, Bryan M. Gaensler, Ziggy Pleunis, Paul Scholz, Ryan Mckinven, Bikash Kharel, Kiyoshi W. Masui</dc:creator>
    </item>
    <item>
      <title>Measuring Network Dynamics of Opioid Overdose Deaths in the United States</title>
      <link>https://arxiv.org/abs/2410.17496</link>
      <description>arXiv:2410.17496v1 Announce Type: cross 
Abstract: The US opioid overdose epidemic has been a major public health concern in recent decades. There has been increasing recognition that its etiology is rooted in part in the social contexts that mediate substance use and access; however, reliable statistical measures of social influence are lacking in the literature. We use Facebook's social connectedness index (SCI) as a proxy for real-life social networks across diverse spatial regions that help quantify social connectivity across different spatial units. This is a measure of the relative probability of connections between localities that offers a unique lens to understand the effects of social networks on health outcomes. We use SCI to develop a variable, called "deaths in social proximity", to measure the influence of social networks on opioid overdose deaths (OODs) in US counties. Our results show a statistically significant effect size for deaths in social proximity on OODs in counties in the United States, controlling for spatial proximity, as well as demographic and clinical covariates. The effect size of standardized deaths in social proximity in our cluster-robust linear regression model indicates that a one-standard-deviation increase, equal to 11.70 more deaths per 100,000 population in the social proximity of ego counties in the contiguous United States, is associated with thirteen more deaths per 100,000 population in ego counties. To further validate our findings, we performed a series of robustness checks using a network autocorrelation model to account for social network effects, a spatial autocorrelation model to capture spatial dependencies, and a two-way fixed-effect model to control for unobserved spatial and time-invariant characteristics. These checks consistently provide statistically robust evidence of positive social influence on OODs in US counties.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.17496v1</guid>
      <category>cs.SI</category>
      <category>stat.AP</category>
      <pubDate>Thu, 24 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Kushagra Tiwari, M. Amin Rahimian, Mark S. Roberts, Praveen Kumar, Jeannine M. Buchanich</dc:creator>
    </item>
    <item>
      <title>Flexible Approach for Statistical Disclosure Control in Geospatial Data</title>
      <link>https://arxiv.org/abs/2410.17601</link>
      <description>arXiv:2410.17601v1 Announce Type: cross 
Abstract: We develop a flexible approach by combining the Quadtree-based method with suppression to maximize the utility of the grid data and simultaneously to reduce the risk of disclosing private information from individual units. To protect data confidentiality, we produce a high resolution grid from geo-reference data with a minimum size of 1 km nested in grids with increasingly larger resolution on the basis of statistical disclosure control methods (i.e threshold and concentration rule). While our implementation overcomes certain weaknesses of Quadtree-based method by accounting for irregularly distributed and relatively isolated marginal units, it also allows creating joint aggregation of several variables. The method is illustrated by relying on synthetic data of the Danish agricultural census 2020 for a set of key agricultural indicators, such as the number of agricultural holdings, the utilized agricultural area and the number of organic farms. We demonstrate the need to assess the reliability of indicators when using a sub-sample of synthetic data followed by an example that presents the same approach for generating a ratio (i.e., the share of organic farming). The methodology is provided as the open-source \textit{R}-package \textit{MRG} that is adaptable to use with other geo-referenced survey data underlying confidentiality or other privacy restrictions.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.17601v1</guid>
      <category>stat.ME</category>
      <category>stat.AP</category>
      <pubDate>Thu, 24 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Jon Olav Sk{\o}ien, Nicolas Lampach, Helena Ramos, Rudolf Seljak, Renate Koeble, Linda See, Marijn van der Velde</dc:creator>
    </item>
    <item>
      <title>Longitudinal Causal Inference with Selective Eligibility</title>
      <link>https://arxiv.org/abs/2410.17864</link>
      <description>arXiv:2410.17864v1 Announce Type: cross 
Abstract: Dropout often threatens the validity of causal inference in longitudinal studies. While existing studies have focused on the problem of missing outcomes caused by treatment, we study an important but overlooked source of dropout, selective eligibility. For example, patients may become ineligible for subsequent treatments due to severe side effects or complete recovery. Selective eligibility differs from the problem of ``truncation by death'' because dropout occurs after observing the outcome but before receiving the subsequent treatment. This difference makes the standard approach to dropout inapplicable. We propose a general methodological framework for longitudinal causal inference with selective eligibility. By focusing on subgroups of units who would become eligible for treatment given a specific treatment history, we define the time-specific eligible treatment effect (ETE) and expected number of outcome events (EOE) under a treatment sequence of interest. Assuming a generalized version of sequential ignorability, we derive two nonparametric identification formulae, each leveraging different parts of the observed data distribution. We then derive the efficient influence function of each causal estimand, yielding the corresponding doubly robust estimator. Finally, we apply the proposed methodology to an impact evaluation of a pre-trial risk assessment instrument in the criminal justice system, in which selective eligibility arises due to recidivism.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.17864v1</guid>
      <category>stat.ME</category>
      <category>stat.AP</category>
      <pubDate>Thu, 24 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Zhichao Jiang, Eli Ben-Michael, D. James Greiner, Ryan Halen, Kosuke Imai</dc:creator>
    </item>
    <item>
      <title>POMDP-Driven Cognitive Massive MIMO Radar: Joint Target Detection-Tracking In Unknown Disturbances</title>
      <link>https://arxiv.org/abs/2410.17967</link>
      <description>arXiv:2410.17967v1 Announce Type: cross 
Abstract: The joint detection and tracking of a moving target embedded in an unknown disturbance represents a key feature that motivates the development of the cognitive radar paradigm. Building upon recent advancements in robust target detection with multiple-input multiple-output (MIMO) radars, this work explores the application of a Partially Observable Markov Decision Process (POMDP) framework to enhance the tracking and detection tasks in a statistically unknown environment. In the POMDP setup, the radar system is considered as an intelligent agent that continuously senses the surrounding environment, optimizing its actions to maximize the probability of detection $(P_D)$ and improve the target position and velocity estimation, all this while keeping a constant probability of false alarm $(P_{FA})$. The proposed approach employs an online algorithm that does not require any apriori knowledge of the noise statistics, and it relies on a much more general observation model than the traditional range-azimuth-elevation model employed by conventional tracking algorithms. Simulation results clearly show substantial performance improvement of the POMDP-based algorithm compared to the State-Action-Reward-State-Action (SARSA)-based one that has been recently investigated in the context of massive MIMO (MMIMO) radar systems.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.17967v1</guid>
      <category>cs.LG</category>
      <category>eess.SP</category>
      <category>stat.AP</category>
      <pubDate>Thu, 24 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Imad Bouhou, Stefano Fortunati, Leila Gharsalli, Alexandre Renaux</dc:creator>
    </item>
    <item>
      <title>MR.RGM: An R Package for Fitting Bayesian Multivariate Bidirectional Mendelian Randomization Networks</title>
      <link>https://arxiv.org/abs/2403.03944</link>
      <description>arXiv:2403.03944v2 Announce Type: replace 
Abstract: Motivation: Mendelian randomization (MR) infers causal relationships between exposures and outcomes using genetic variants as instrumental variables. Typically, MR considers only a pair of exposure and outcome at a time, limiting its capability of capturing the entire causal network. We overcome this limitation by developing 'MR.RGM' (Mendelian randomization via reciprocal graphical model), a fast R-package that implements the Bayesian reciprocal graphical model and enables practitioners to construct holistic causal networks with possibly cyclic/reciprocal causation and proper uncertainty quantifications, offering a comprehensive understanding of complex biological systems and their interconnections. We developed 'MR.RGM', an open-source R package that applies bidirectional MR using a network-based strategy, enabling the exploration of causal relationships among multiple variables in complex biological systems. 'MR.RGM' holds the promise of unveiling intricate interactions and advancing our understanding of genetic networks, disease risks, and phenotypic complexities.</description>
      <guid isPermaLink="false">oai:arXiv.org:2403.03944v2</guid>
      <category>stat.AP</category>
      <pubDate>Thu, 24 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Bitan Sarkar, Yang Ni</dc:creator>
    </item>
    <item>
      <title>A Physics-Informed, Deep Double Reservoir Network for Forecasting Boundary Layer Velocity</title>
      <link>https://arxiv.org/abs/2311.05728</link>
      <description>arXiv:2311.05728v3 Announce Type: replace-cross 
Abstract: When a fluid flows over a solid surface, it creates a thin boundary layer where the flow velocity is influenced by the surface through viscosity, and can transition from laminar to turbulent at sufficiently high speeds. Understanding and forecasting the fluid dynamics under these conditions is one of the most challenging scientific problems in fluid dynamics. It is therefore of high interest to formulate models able to capture the nonlinear spatio-temporal velocity structure as well as produce forecasts in a computationally efficient manner. Traditional statistical approaches are limited in their ability to produce timely forecasts of complex, nonlinear spatio-temporal structures which are at the same time able to incorporate the underlying flow physics. In this work, we propose a model to accurately forecast boundary layer velocities with a deep double reservoir computing network which is capable of capturing the complex, nonlinear dynamics of the boundary layer while at the same time incorporating physical constraints via a penalty obtained by a Partial Differential Equation (PDE). Simulation studies on a one-dimensional viscous fluid demonstrate how the proposed model is able to produce accurate forecasts while simultaneously accounting for energy loss. The application focuses on boundary layer data in a water tunnel with a PDE penalty derived from an appropriate simplification of the Navier-Stokes equations, showing improved forecasting by the proposed approach in terms of mass conservation and variability of velocity fluctuation against non-physics-informed methods.</description>
      <guid isPermaLink="false">oai:arXiv.org:2311.05728v3</guid>
      <category>physics.flu-dyn</category>
      <category>stat.AP</category>
      <pubDate>Thu, 24 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Matthew Bonas, David H. Richter, Stefano Castruccio</dc:creator>
    </item>
    <item>
      <title>Acquiring Better Load Estimates by Combining Anomaly and Change Point Detection in Power Grid Time-series Measurements</title>
      <link>https://arxiv.org/abs/2405.16164</link>
      <description>arXiv:2405.16164v3 Announce Type: replace-cross 
Abstract: In this paper we present novel methodology for automatic anomaly and switch event filtering to improve load estimation in power grid systems. By leveraging unsupervised methods with supervised optimization, our approach prioritizes interpretability while ensuring robust and generalizable performance on unseen data. Through experimentation, a combination of binary segmentation for change point detection and statistical process control for anomaly detection emerges as the most effective strategy, specifically when ensembled in a novel sequential manner. Results indicate the clear wasted potential when filtering is not applied. The automatic load estimation is also fairly accurate, with approximately 90% of estimates falling within a 10% error margin, with only a single significant failure in both the minimum and maximum load estimates across 60 measurements in the test set. Our methodology's interpretability makes it particularly suitable for critical infrastructure planning, thereby enhancing decision-making processes.</description>
      <guid isPermaLink="false">oai:arXiv.org:2405.16164v3</guid>
      <category>cs.LG</category>
      <category>cs.AI</category>
      <category>stat.AP</category>
      <category>stat.ML</category>
      <pubDate>Thu, 24 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <arxiv:DOI>10.1016/j.segan.2024.101540</arxiv:DOI>
      <dc:creator>Roel Bouman, Linda Schmeitz, Luco Buise, Jacco Heres, Yuliya Shapovalova, Tom Heskes</dc:creator>
    </item>
    <item>
      <title>MM Algorithms for Statistical Estimation in Quantile Regression</title>
      <link>https://arxiv.org/abs/2407.12348</link>
      <description>arXiv:2407.12348v2 Announce Type: replace-cross 
Abstract: Quantile regression is a robust and practically useful way to efficiently model quantile varying correlation and predict varied response quantiles of interest. This article constructs and tests MM algorithms, which are simple to code and have been suggested superior to some other prominent quantile regression methods in nonregularized problems, in an array of quantile regression settings including linear (modeling different quantile coefficients both separately and simultaneously), nonparametric, regularized, and monotone quantile regression. Applications to various real data sets and two simulation studies comparing MM to existing tested methods have corroborated our algorithms' effectiveness. We have made one key advance by generalizing our MM algorithm to efficiently fit easy-to-predict-and-interpret parametric quantile regression models for data sets exhibiting manifest complicated nonlinear correlation patterns, which has not yet been covered by current literature to the best of our knowledge.</description>
      <guid isPermaLink="false">oai:arXiv.org:2407.12348v2</guid>
      <category>stat.ME</category>
      <category>stat.AP</category>
      <category>stat.CO</category>
      <pubDate>Thu, 24 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Yifan Cheng, Anthony Yung Cheung Kuk</dc:creator>
    </item>
  </channel>
</rss>
