<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>math.OC updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/math.OC</link>
    <description>math.OC updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/math.OC" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Tue, 29 Oct 2024 04:00:18 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Tue, 29 Oct 2024 00:00:00 -0400</pubDate>
    <skipDays>
      <day>Saturday</day>
      <day>Sunday</day>
    </skipDays>
    <item>
      <title>The Distance Between the Perturbation of a Convex Function and its $\Gamma$-regularization</title>
      <link>https://arxiv.org/abs/2410.19805</link>
      <description>arXiv:2410.19805v1 Announce Type: new 
Abstract: In the study of a non-convex minimization problem by Lachand-Robert and Peletier, they found that the difference between the compactly supported perturbation $u+\epsilon h$ of a strictly convex function $u$, and the $\Gamma$-regularization of $u+\epsilon h$, is at most $o(\epsilon)$. Here we find that this result is optimal, albeit they expected a much stronger estimate.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.19805v1</guid>
      <category>math.OC</category>
      <category>math.AP</category>
      <category>math.CA</category>
      <category>math.DG</category>
      <pubDate>Tue, 29 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Zichang Liu</dc:creator>
    </item>
    <item>
      <title>A practical, fast method for solving sum-of-squares problems for very large polynomials</title>
      <link>https://arxiv.org/abs/2410.19844</link>
      <description>arXiv:2410.19844v1 Announce Type: new 
Abstract: Sum of squares (SOS) optimization is a powerful technique for solving problems where the positivity of a polynomials must be enforced. The common approach to solve an SOS problem is by relaxation to a Semidefinite Program (SDP). The main advantage of this transormation is that SDP is a convex problem for which efficient solvers are readily available. However, while considerable progress has been made in recent years, the standard approaches for solving SDPs are still known to scale poorly. Our goal is to devise an approach that can handle larger, more complex problems than is currently possible. The challenge indeed lies in how SDPs are commonly solved. State-Of-The-Art approaches rely on the interior point method, which requires the factorization of large matrices. We instead propose an approach inspired by polynomial neural networks, which exhibit excellent performance when optimized using techniques from the deep learning toolbox. In a somewhat counter-intuitive manner, we replace the convex SDP formulation with a non-convex, unconstrained, and \emph{over parameterized} formulation, and solve it using a first order optimization method. It turns out that this approach can handle very large problems, with polynomials having over four million coefficients, well beyond the range of current SDP-based approaches. Furthermore, we highlight theoretical and practical results supporting the experimental success of our approach in avoiding spurious local minima, which makes it amenable to simple and fast solutions based on gradient descent. In all the experiments, our approach had always converged to a correct global minimum, on general (non-sparse) polynomials, with running time only slightly higher than linear in the number of polynomial coefficients, compared to higher than quadratic in the number of coefficients for SDP-based methods.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.19844v1</guid>
      <category>math.OC</category>
      <category>cs.LG</category>
      <pubDate>Tue, 29 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Daniel Keren, Margarita Osadchy, Roi Poranne</dc:creator>
    </item>
    <item>
      <title>A mathematical model describing the trajectory of the bearing in an internal gear pump</title>
      <link>https://arxiv.org/abs/2410.19871</link>
      <description>arXiv:2410.19871v1 Announce Type: new 
Abstract: This paper presents a mathematical model for determining the movement of the bearing in an internal gear pump. The paper also performs simulation calculations to find the movement trajectory of the shaft with the given input data.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.19871v1</guid>
      <category>math.OC</category>
      <category>cs.NA</category>
      <category>math.NA</category>
      <pubDate>Tue, 29 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Hung Manh Nguyen, Trong Hoa Pham</dc:creator>
    </item>
    <item>
      <title>High-order Moreau envelope beyond convexity: An inexact two-level smoothing framework</title>
      <link>https://arxiv.org/abs/2410.19928</link>
      <description>arXiv:2410.19928v1 Announce Type: new 
Abstract: This paper introduces an inexact two-level smoothing optimization framework (ItsOPT) for finding first-order critical points of nonsmooth and nonconvex functions. The framework involves two levels of methodologies: at the upper level, a first- or second-order method will be tailored to minimize a smooth approximation of the cost function; at the lower level, the high-order proximal auxiliary problems will be solved inexactly. As a smoothing technique, in particular, we here introduce the high-order Moreau envelope (HOME) and study its fundamental features under standard assumptions and its differential properties under a variant of prox-regularity. Next, introducing a high-order proximal-point algorithm (HiPPA) and its boosted variant (Boosted HiPPA) at the upper level and solving the proximal subproblem inexactly at the lower level lead to an instance method of the ItsOPT framework. Global and linear convergence results are established under the Kurdyka-{\L}ojasiewicz (KL) property of the cost and envelope functions, along with some reasonable conditions for the accuracy of the proximal terms. Preliminary numerical experiments on a robust low-rank matrix recovery problem indicate a promising performance of the proposed algorithm, validating our theoretical foundations.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.19928v1</guid>
      <category>math.OC</category>
      <pubDate>Tue, 29 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Alireza Kabgani, Masoud Ahookhosh</dc:creator>
    </item>
    <item>
      <title>Generic Solutions to Controlled Balance Laws</title>
      <link>https://arxiv.org/abs/2410.20032</link>
      <description>arXiv:2410.20032v1 Announce Type: new 
Abstract: The paper is concerned with a scalar balance law, where the source term depends on a control function $\alpha(t)$. Given a control $\alpha\in \mathbf{L}^\infty\bigl([0,T]\bigr)$, it is proved that, for generic initial data $\bar u \in \mathcal{C}^3(\mathbb{R})$, the solution has finitely many shocks, interacting at most two at a time. Moreover, at the terminal time $T$ no shock interaction occurs, and no new shock is formed.
  In addition, a family of optimal control problems is considered, including a running cost and a terminal cost. An example is constructed where the optimal solution contains two shocks merging exactly at the terminal time $T$. Such behavior persists under any suitably small perturbation of the flux, source, and cost functions, and of the initial data. This shows that generic solutions of optimization problems have different qualitative properties, compared with generic solutions to Cauchy problems.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.20032v1</guid>
      <category>math.OC</category>
      <category>math.AP</category>
      <pubDate>Tue, 29 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Alberto Bressan, Khai T. Nguyen</dc:creator>
    </item>
    <item>
      <title>The inexact power augmented Lagrangian method for constrained nonconvex optimization</title>
      <link>https://arxiv.org/abs/2410.20153</link>
      <description>arXiv:2410.20153v1 Announce Type: new 
Abstract: This work introduces an unconventional inexact augmented Lagrangian method, where the augmenting term is a Euclidean norm raised to a power between one and two. The proposed algorithm is applicable to a broad class of constrained nonconvex minimization problems, that involve nonlinear equality constraints over a convex set under a mild regularity condition. First, we conduct a full complexity analysis of the method, leveraging an accelerated first-order algorithm for solving the H\"older-smooth subproblems. Next, we present an inexact proximal point method to tackle these subproblems, demonstrating that it achieves an improved convergence rate. Notably, this rate reduces to the best-known convergence rate for first-order methods when the augmenting term is a squared Euclidean norm. Our worst-case complexity results further show that using lower powers for the augmenting term leads to faster constraint satisfaction, albeit with a slower decrease in the dual residual. Numerical experiments support our theoretical findings, illustrating that this trade-off between constraint satisfaction and cost minimization is advantageous for certain practical problems.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.20153v1</guid>
      <category>math.OC</category>
      <category>cs.LG</category>
      <pubDate>Tue, 29 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Alexander Bodard, Konstantinos Oikonomidis, Emanuel Laude, Panagiotis Patrinos</dc:creator>
    </item>
    <item>
      <title>Bayesian Distributionally Robust Nash Equilibrium and Its Application</title>
      <link>https://arxiv.org/abs/2410.20364</link>
      <description>arXiv:2410.20364v1 Announce Type: new 
Abstract: Inspired by the recent work by Shapiro et al. [45], we propose a Bayesian distributionally robust Nash equilibrium (BDRNE) model where each player lacks complete information on the true probability distribution of the underlying uncertainty represented by a random variable and subsequently determines the optimal decision by solving a Bayesian distributionally robust optimization (BDRO) problem under the Nash conjecture. Unlike most of the DRO models in the literature, the BDRO model assumes (a) the true unknown distribution of the random variable can be approximated by a randomized parametric family of distributions, (b) the average of the worst-case expected value of the objective function with respect to the posterior distribution of the parameter, instead of the worst-case expected value of the objective function is considered in each player's decision making, and (c) the posterior distribution of the parameter is updated as more and more sampling information of the random variable is gathered. Under some moderate conditions, we demonstrate the existence of a BDRNE and derive asymptotic convergence of the equilibrium as the sample size increases. Moreover, we propose to solve the BDRNE problem by Gauss-Seidel-type iterative method in the case when the ambiguity set of each player is constructed via Kullback-Leibler (KL) divergence. Finally, we apply the BDRNE model to a price competition problem under multinomial logit demand. The preliminary numerical test results show that the proposed model and computational scheme perform well.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.20364v1</guid>
      <category>math.OC</category>
      <pubDate>Tue, 29 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Jian Liu, Ziheng Su, Huifu Xu</dc:creator>
    </item>
    <item>
      <title>New results related to cutters and to an extrapolated block-iterative method for finding a common fixed point of a collection of them</title>
      <link>https://arxiv.org/abs/2410.20448</link>
      <description>arXiv:2410.20448v1 Announce Type: new 
Abstract: Given a Hilbert space and a finite family of operators defined on the space, the common fixed point problem (CFPP) is the problem of finding a point in the intersection of the fixed point sets of these operators. A particular case of the problem, when the operators are orthogonal projections, is the convex feasibility problem which has numerous applications in science and engineering. In a previous work [Censor, Reem, and Zaknoon, A generalized block-iterative projection method for the common fixed point problem induced by cutters, J. Global Optim. 84 (2022), 967--987] we studied a block-iterative method with dynamic weights for solving the CFPP assuming the operators belong to a wide class of operators called cutters. In this work we continue the study of this algorithm by allowing extrapolation, namely we weaken the assumption on the relaxation parameters. We prove the convergence of this algorithm when the space is finite dimensional in two different scenarios, one of them is under a seems to be new condition on the weights which is less restrictive than a condition suggested in previous works. Along the way we obtain various new results of independent interest related to cutters, some of them extend, generalize and clarify previously published results.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.20448v1</guid>
      <category>math.OC</category>
      <category>math.FA</category>
      <pubDate>Tue, 29 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Yair Censor, Daniel Reem, Maroun Zaknoon</dc:creator>
    </item>
    <item>
      <title>A Cournot-Nash Model for a Coupled Hydrogen and Electricity Market</title>
      <link>https://arxiv.org/abs/2410.20534</link>
      <description>arXiv:2410.20534v1 Announce Type: new 
Abstract: We present a novel model of a coupled hydrogen and electricity market on the intraday time scale, where hydrogen gas is used as a storage device for the electric grid. Electricity is produced by renewable energy sources or by extracting hydrogen from a pipeline that is shared by non-cooperative agents. The resulting model is a generalized Nash equilibrium problem. Under certain mild assumptions, we prove that an equilibrium exists. Perspectives for future work are presented.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.20534v1</guid>
      <category>math.OC</category>
      <pubDate>Tue, 29 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Pavel Dvurechensky, Caroline Geiersbach, Michael Hinterm\"uller, Aswin Kannan, Stefan Kater, Gregor Z\"ottl</dc:creator>
    </item>
    <item>
      <title>Time-delay Induced Stochastic Optimization and Extremum Seeking</title>
      <link>https://arxiv.org/abs/2410.20572</link>
      <description>arXiv:2410.20572v1 Announce Type: new 
Abstract: In this paper a novel stochastic optimization and extremum seeking algorithm is presented, one which is based on time-delayed random perturbations and step size adaptation. For the case of a one-dimensional quadratic unconstrained optimization problem, global exponential convergence in expectation and global exponential practical convergence of the variance of the trajectories are proven. The theoretical results are complemented by numerical simulations for one- and multi-dimensional quadratic and non-quadratic objective functions.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.20572v1</guid>
      <category>math.OC</category>
      <pubDate>Tue, 29 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Naum Dimitrieski, Michael Reyer, Mohamed-Ali Belabbas, Christian Ebenbauer</dc:creator>
    </item>
    <item>
      <title>A successive approximation method in functional spaces for hierarchical optimal control problems and its application to learning</title>
      <link>https://arxiv.org/abs/2410.20617</link>
      <description>arXiv:2410.20617v1 Announce Type: new 
Abstract: We consider a class of learning problem of point estimation for modeling high-dimensional nonlinear functions, whose learning dynamics is guided by model training dataset, while the estimated parameter in due course provides an acceptable prediction accuracy on a different model validation dataset. Here, we establish an evidential connection between such a learning problem and a hierarchical optimal control problem that provides a framework how to account appropriately for both generalization and regularization at the optimization stage. In particular, we consider the following two objectives: (i) The first one is a controllability-type problem, i.e., generalization, which consists of guaranteeing the estimated parameter to reach a certain target set at some fixed final time, where such a target set is associated with model validation dataset. (ii) The second one is a regularization-type problem ensuring the estimated parameter trajectory to satisfy some regularization property over a certain finite time interval. First, we partition the control into two control strategies that are compatible with two abstract agents, namely, a leader, which is responsible for the controllability-type problem and that of a follower, which is associated with the regularization-type problem. Using the notion of Stackelberg's optimization, we provide conditions on the existence of admissible optimal controls for such a hierarchical optimal control problem under which the follower is required to respond optimally to the strategy of the leader, so as to achieve the overall objectives that ultimately leading to an optimal parameter estimate. Moreover, we provide a nested algorithm, arranged in a hierarchical structure-based on successive approximation methods, for solving the corresponding optimal control problem. Finally, we present some numerical results for a typical nonlinear regression problem.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.20617v1</guid>
      <category>math.OC</category>
      <category>stat.ML</category>
      <pubDate>Tue, 29 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Getachew K. Befekadu</dc:creator>
    </item>
    <item>
      <title>A New Approach to Reducing Vector Delay Nonlinear Systems: Boundedness and Stability Analysis</title>
      <link>https://arxiv.org/abs/2410.20674</link>
      <description>arXiv:2410.20674v1 Announce Type: new 
Abstract: This paper introduces a new method for assessing the boundedness and stability of certain vector nonlinear systems with delays and variable coefficients. The approach is based on developing scalar counterparts to the given vector systems. We prove that the solutions to these scalar nonlinear equations, which also include delays and variable coefficients, provide upper bounds for the norms of solutions to the original vector equations if the history functions for both equations are properly matched. This enables the evaluation of the boundedness and stability characteristics of a vector system by analyzing the abridged dynamics of its scalar counterparts. This assessment can be carried out through straightforward simulations or by applying simplified analytical methods. As a result, we introduce new criteria for boundedness and stability and estimate the radii of the balls that contain history functions stemming bounded or stable solutions for the original vector systems. Finally, we validate our inferences through representative simulations that also assess the accuracy of our approach.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.20674v1</guid>
      <category>math.OC</category>
      <pubDate>Tue, 29 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Mark A. Pinsky</dc:creator>
    </item>
    <item>
      <title>Neural Operators for Adaptive Control of Freeway Traffic</title>
      <link>https://arxiv.org/abs/2410.20708</link>
      <description>arXiv:2410.20708v1 Announce Type: new 
Abstract: Uncertainty and delayed reactions in human driving behavior lead to stop-and-go traffic congestion on freeways. The freeway traffic dynamics are governed by the Aw-Rascle-Zhang (ARZ) traffic Partial Differential Equation (PDE) models with unknown relaxation time. Motivated by the adaptive traffic control problem, this paper presents a neural operator (NO) based adaptive boundary control design for the coupled 2$\times$2 hyperbolic systems with uncertain spatially varying in-domain coefficients and boundary parameter. In traditional adaptive control for PDEs, solving backstepping kernel online is computationally intensive, as it requires significant resources at each time step to update the estimation of coefficients. To address this challenge, we use operator learning, i.e. DeepONet, to learn the mapping from system parameters to the kernels functions. DeepONet, a class of deep neural networks designed for approximating operators, has shown strong potential for approximating PDE backstepping designs in recent studies. Unlike previous works that focus on approximating single kernel equation associated with the scalar PDE system, we extend this framework to approximate PDE kernels for a class of the first-order coupled 2$\times$2 hyperbolic kernel equations. Our approach demonstrates that DeepONet is nearly two orders of magnitude faster than traditional PDE solvers for generating kernel functions, while maintaining a loss on the order of $10^{-3}$.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.20708v1</guid>
      <category>math.OC</category>
      <pubDate>Tue, 29 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Kaijing Lv, Junmin Wang, Yihuai Zhang, Huan Yu</dc:creator>
    </item>
    <item>
      <title>Parameter-free proximal bundle methods with adaptive stepsizes for hybrid convex composite optimization problems</title>
      <link>https://arxiv.org/abs/2410.20751</link>
      <description>arXiv:2410.20751v1 Announce Type: new 
Abstract: This paper develops a parameter-free adaptive proximal bundle method with two important features: 1) adaptive choice of variable prox stepsizes that "closely fits" the instance under consideration; and 2) adaptive criterion for making the occurrence of serious steps easier. Computational experiments show that our method performs substantially fewer consecutive null steps (i.e., a shorter cycle) while maintaining the number of serious steps under control. As a result, our method performs significantly less number of iterations than its counterparts based on a constant prox stepsize choice and a non-adaptive cycle termination criterion. Moreover, our method is very robust relative to the user-provided initial stepsize.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.20751v1</guid>
      <category>math.OC</category>
      <pubDate>Tue, 29 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Renato D. C. Monteiro, Honghao Zhang</dc:creator>
    </item>
    <item>
      <title>Numerical methods for solving minimum-time problem for linear systems</title>
      <link>https://arxiv.org/abs/2410.20963</link>
      <description>arXiv:2410.20963v1 Announce Type: new 
Abstract: This paper offers a contemporary and comprehensive perspective on the classical algorithms utilized for the solution of minimum-time problem for linear systems (MTPLS). The use of unified notations supported by visual geometric representations serves to highlight the differences between the Neustadt-Eaton and Barr-Gilbert algorithms. Furthermore, these notations assist in the interpretation of the distance-finding algorithms utilized in the Barr-Gilbert algorithm. Additionally, we present a novel algorithm for solving MTPLS and provide a constructive proof of its convergence. Similar to the Barr-Gilbert algorithm, the novel algorithm employs distance search algorithms. The design of the novel algorithm is oriented towards solving such MTPLS for which the analytic description of the reachable set is available. To illustrate the advantages of the novel algorithm, we utilize the isotropic rocket benchmark. Numerical experiments demonstrate that, for high-precision computations, the novel algorithm outperforms others by factors of tens or hundreds and exhibits the lowest failure rate.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.20963v1</guid>
      <category>math.OC</category>
      <category>cs.NA</category>
      <category>math.NA</category>
      <pubDate>Tue, 29 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>M E Buzikov, A M Mayer</dc:creator>
    </item>
    <item>
      <title>Primal-dual algorithm for weakly convex functions under sharpness conditions</title>
      <link>https://arxiv.org/abs/2410.20977</link>
      <description>arXiv:2410.20977v1 Announce Type: new 
Abstract: We investigate the convergence of the primal-dual algorithm for composite optimization problems when the objective functions are weakly convex. We introduce a modified duality gap function, which is a lower bound of the standard duality gap function. Under the sharpness condition of this new function, we identify the area around the set of saddle points where we obtain the convergence of the primal-dual algorithm. We give numerical examples and applications in image denoising and deblurring to demonstrate our results.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.20977v1</guid>
      <category>math.OC</category>
      <category>cs.NA</category>
      <category>math.NA</category>
      <pubDate>Tue, 29 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Ewa Bednarczuk, The Hung Tran, Monika Syga</dc:creator>
    </item>
    <item>
      <title>An adaptive cubic regularisation algorithm based on interior point methods for solving nonlinear inequality constrained optimization</title>
      <link>https://arxiv.org/abs/2410.21070</link>
      <description>arXiv:2410.21070v1 Announce Type: new 
Abstract: Nonlinear constrained optimization has a wide range of practical applications. In this paper, we consider nonlinear optimization with inequality constraints. The interior point method is considered to be one of the most powerful algorithms for solving large-scale nonlinear inequality constrained optimization. We propose an adaptive regularisation algorithm using cubics based on interior point methods (ARCBIP) for solving nonlinear inequality constrained optimization. For solving the barrier problem, we construct ARC subproblem with linearized constraints and the well-known fraction to the boundary rule that prevents slack variables from approaching their lower bounds prematurely. The ARC subproblem in ARCBIP can avoid incompatibility of the intersection of linearized constraints with trust-region bounds in trust-region methods. We employ composite-step approach and reduced Hessian methods to deal with linearized constraints, where the trial step is decomposed into a normal step and a tangential step. They are obtained by solving two standard ARC subproblems approximately with the fraction to the boundary rule. Requirements on normal steps and tangential steps are given to ensure global convergence. To determine whether the trial step is accepted, we use exact penalty function as the merit function in ARC framework. The updating of the barrier parameter is implemented by adaptive strategies. Global convergence is analyzed under mild assumptions. Preliminary numerical experiments and some comparison results are reported.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.21070v1</guid>
      <category>math.OC</category>
      <pubDate>Tue, 29 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Yonggang Pei, Jingyi Guo, Detong Zhu</dc:creator>
    </item>
    <item>
      <title>Transforming optimization problems into a QUBO form: A tutorial</title>
      <link>https://arxiv.org/abs/2410.21074</link>
      <description>arXiv:2410.21074v1 Announce Type: new 
Abstract: Practically relevant problems of quadratic optimization often contain multidimensional arrays of variables interconnected by linear constraints, such as equalities and inequalities. The values of each variable depend on its specific meaning and can be binary, integer, discrete, and continuous. These circumstances make it technically difficult to reduce the original problem statement to the QUBO form. The paper identifies and considers three main transformations of the original problem statement, namely, the transition from a multidimensional to a one-dimensional array of variables, the transition in mixed problems to binary variables, and the inclusion of linear constraints in the objective function in the form of quadratic penalties. Convenient formulas for calculations are presented and proven, simplifying the implementation of these transformations. In particular, the formulas for the transition in the problem statement from a multidimensional to a one-dimensional array of variables are based on the use of the Kronecker product of matrices. The considered transformations are illustrated by numerous examples.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.21074v1</guid>
      <category>math.OC</category>
      <category>quant-ph</category>
      <pubDate>Tue, 29 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Alexander M. Semenov, Sergey R. Usmanov, Aleksey K. Fedorov</dc:creator>
    </item>
    <item>
      <title>The Competive Spectral Radius of Families of Nonexpansive Mappings</title>
      <link>https://arxiv.org/abs/2410.21097</link>
      <description>arXiv:2410.21097v1 Announce Type: new 
Abstract: We consider a new class of repeated zero-sum games in which the payoff is the escape rate of a switched dynamical system, where at every stage, the transition is given by a nonexpansive operator depending on the actions of both players. This generalizes to the two-player (and non-linear) case the notion of joint spectral radius of a family of matrices. We show that the value of this game does exist, and we characterize it in terms of an infinite dimensional non-linear eigenproblem. This provides a two-player analogue of Ma\~ne's lemma from ergodic control. This also extends to the two-player case results of Kohlberg and Neyman (1981), Karlsson (2001), and Vigeral and the second author (2012), concerning the asymptotic behavior of nonexpansive mappings. We discuss two special cases of this game: order preserving and positively homogeneous self-maps of a cone equipped with Funk's and Thompson's metrics, and groups of translations.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.21097v1</guid>
      <category>math.OC</category>
      <category>math.DS</category>
      <pubDate>Tue, 29 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Marianne Akian, St\'ephane Gaubert, Lo\"ic Marchesini</dc:creator>
    </item>
    <item>
      <title>A Globally Optimal Portfolio for m-Sparse Sharpe Ratio Maximization</title>
      <link>https://arxiv.org/abs/2410.21100</link>
      <description>arXiv:2410.21100v1 Announce Type: new 
Abstract: The Sharpe ratio is an important and widely-used risk-adjusted return in financial engineering. In modern portfolio management, one may require an m-sparse (no more than m active assets) portfolio to save managerial and financial costs. However, few existing methods can optimize the Sharpe ratio with the m-sparse constraint, due to the nonconvexity and the complexity of this constraint. We propose to convert the m-sparse fractional optimization problem into an equivalent m-sparse quadratic programming problem. The semi-algebraic property of the resulting objective function allows us to exploit the Kurdyka-Lojasiewicz property to develop an efficient Proximal Gradient Algorithm (PGA) that leads to a portfolio which achieves the globally optimal m-sparse Sharpe ratio under certain conditions. The convergence rates of PGA are also provided. To the best of our knowledge, this is the first proposal that achieves a globally optimal m-sparse Sharpe ratio with a theoretically-sound guarantee.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.21100v1</guid>
      <category>math.OC</category>
      <pubDate>Tue, 29 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Yizun Lin, Zhao-Rong Lai, Cheng Li</dc:creator>
    </item>
    <item>
      <title>A robust optimization approach to flow decomposition</title>
      <link>https://arxiv.org/abs/2410.21140</link>
      <description>arXiv:2410.21140v1 Announce Type: new 
Abstract: In this paper, we consider a variant of the so-called minimum flow decomposition (MFD) problem in which uncertainty regarding edge capacities is taken into account from a robustness perspective. In the classical flow decomposition problem, a network flow is decomposed into a set of weighted paths from a fixed source node to a fixed sink node that precisely represents the flow distribution across all edges. While MFDs are often used in bioinformatics applications, they are also applicable in other fields, such as flows of goods or passengers in distribution networks, where the decomposition represents the vehicles and corresponding capacities needed to cover these flows. We generalize this problem to the weighted inexact case with lower and upper bounds on the flow values, provide a detailed analysis, and explore different variants that are solvable in polynomial time. Moreover, we introduce the concept of robust flow decomposition by incorporating uncertain flows and applying different robustness concepts to handle the uncertainty. Finally, we present two different adjustable problem formulations and perform computational experiments illustrating the benefit of adjustability in the uncertain case in a subsequent computational study.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.21140v1</guid>
      <category>math.OC</category>
      <pubDate>Tue, 29 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Moritz Stinzend\"orfer, Philine Schiewe, Fabricio Oliveira</dc:creator>
    </item>
    <item>
      <title>ControlAgent: Automating Control System Design via Novel Integration of LLM Agents and Domain Expertise</title>
      <link>https://arxiv.org/abs/2410.19811</link>
      <description>arXiv:2410.19811v1 Announce Type: cross 
Abstract: Control system design is a crucial aspect of modern engineering with far-reaching applications across diverse sectors including aerospace, automotive systems, power grids, and robotics. Despite advances made by Large Language Models (LLMs) in various domains, their application in control system design remains limited due to the complexity and specificity of control theory. To bridge this gap, we introduce ControlAgent, a new paradigm that automates control system design via novel integration of LLM agents and control-oriented domain expertise. ControlAgent encodes expert control knowledge and emulates human iterative design processes by gradually tuning controller parameters to meet user-specified requirements for stability, performance, and robustness. ControlAgent integrates multiple collaborative LLM agents, including a central agent responsible for task distribution and task-specific agents dedicated to detailed controller design for various types of systems and requirements. ControlAgent also employs a Python computation agent that performs complex calculations and controller evaluations based on standard design information provided by task-specified LLM agents. Combined with a history and feedback module, the task-specific LLM agents iteratively refine controller parameters based on real-time feedback from prior designs. Overall, ControlAgent mimics the design processes used by (human) practicing engineers, but removes all the human efforts and can be run in a fully automated way to give end-to-end solutions for control system design with user-specified requirements. To validate ControlAgent's effectiveness, we develop ControlEval, an evaluation dataset that comprises 500 control tasks with various specific design goals. The effectiveness of ControlAgent is demonstrated via extensive comparative evaluations between LLM-based and traditional human-involved toolbox-based baselines.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.19811v1</guid>
      <category>eess.SY</category>
      <category>cs.AI</category>
      <category>cs.CL</category>
      <category>cs.LG</category>
      <category>cs.SY</category>
      <category>math.OC</category>
      <pubDate>Tue, 29 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Xingang Guo, Darioush Keivan, Usman Syed, Lianhui Qin, Huan Zhang, Geir Dullerud, Peter Seiler, Bin Hu</dc:creator>
    </item>
    <item>
      <title>Hierarchical Network Partitioning for Solution of Potential-Driven, Steady-State Nonlinear Network Flow Equations</title>
      <link>https://arxiv.org/abs/2410.19850</link>
      <description>arXiv:2410.19850v1 Announce Type: cross 
Abstract: Potential-driven steady-state flow in networks is an abstract problem which manifests in various engineering applications, such as transport of natural gas, water, electric power through infrastructure networks or flow through fractured rocks modelled as discrete fracture networks. In general, while the problem is simple when restricted to a single edge of a network, it ceases to be so for a large network.
  The resultant system of nonlinear equations depends on the network topology and in general there is no numerical algorithm that offers guaranteed convergence to the solution (assuming a solution exists). Some methods offer guarantees in cases where the network topology satisfies certain assumptions but these methods fail for larger networks. On the other hand, the Newton-Raphson algorithm offers a convergence guarantee if the starting point lies close to the (unknown) solution.
  It would be advantageous to compute the solution of the large nonlinear system through the solution of smaller nonlinear sub-systems wherein the solution algorithms (Newton-Raphson or otherwise) are more likely to succeed. This article proposes and describes such a procedure, an hierarchical network partitioning algorithm that enables the solution of large nonlinear systems corresponding to potential-driven steady-state network flow equations.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.19850v1</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <category>math.OC</category>
      <pubDate>Tue, 29 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Shriram Srinivasan, Kaarthik Sundar</dc:creator>
    </item>
    <item>
      <title>Provable optimal transport with transformers: The essence of depth and prompt engineering</title>
      <link>https://arxiv.org/abs/2410.19931</link>
      <description>arXiv:2410.19931v1 Announce Type: cross 
Abstract: Can we establish provable performance guarantees for transformers? Establishing such theoretical guarantees is a milestone in developing trustworthy generative AI. In this paper, we take a step toward addressing this question by focusing on optimal transport, a fundamental problem at the intersection of combinatorial and continuous optimization. Leveraging the computational power of attention layers, we prove that a transformer with fixed parameters can effectively solve the optimal transport problem in Wasserstein-2 with entropic regularization for an arbitrary number of points. Consequently, the transformer can sort lists of arbitrary sizes up to an approximation factor. Our results rely on an engineered prompt that enables the transformer to implement gradient descent with adaptive stepsizes on the dual optimal transport. Combining the convergence analysis of gradient descent with Sinkhorn dynamics, we establish an explicit approximation bound for optimal transport with transformers, which improves as depth increases. Our findings provide novel insights into the essence of prompt engineering and depth for solving optimal transport. In particular, prompt engineering boosts the algorithmic expressivity of transformers, allowing them implement an optimization method. With increasing depth, transformers can simulate several iterations of gradient descent.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.19931v1</guid>
      <category>cs.LG</category>
      <category>math.OC</category>
      <category>stat.ML</category>
      <pubDate>Tue, 29 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Hadi Daneshmand</dc:creator>
    </item>
    <item>
      <title>Duality of Stochastic Observability and Constructability and Their Relation to the Fisher Information</title>
      <link>https://arxiv.org/abs/2410.19975</link>
      <description>arXiv:2410.19975v1 Announce Type: cross 
Abstract: Given a set of measurements, observability characterizes the distinguishability of a system's initial state, whereas constructability focuses on the final state in a trajectory. In the presence of process and/or measurement noise, the Fisher information matrices with respect to the initial and final states$\unicode{x2013}$equivalent to the stochastic observability and constructability Gramians$\unicode{x2013}$bound the performance of corresponding estimators through the Cram\'er-Rao inequality. This letter establishes a connection between stochastic observability and constructability of discrete-time linear systems and provides a more numerically stable way for calculating the stochastic observability Gramian. We define a dual system and show that the dual system's stochastic constructability is equivalent to the original system's stochastic observability, and vice versa. This duality enables the interchange of theorems and tools for observability and constructability. For example, we use this result to translate an existing recursive formula for the stochastic constructability Gramian into a formula for recursively calculating the stochastic observability Gramian for both time-varying and time-invariant systems, and we show the convergence of this sequence for the latter. Finally, we illustrate the robustness of our formula compared to existing (non-recursive) formulas through a numerical example.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.19975v1</guid>
      <category>eess.SY</category>
      <category>cs.SY</category>
      <category>math.OC</category>
      <pubDate>Tue, 29 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Burak Boyac{\i}o\u{g}lu, Floris van Breugel</dc:creator>
    </item>
    <item>
      <title>Almost Sure Convergence of Networked Policy Gradient over Time-Varying Networks in Markov Potential Games</title>
      <link>https://arxiv.org/abs/2410.20075</link>
      <description>arXiv:2410.20075v1 Announce Type: cross 
Abstract: We propose networked policy gradient play for solving Markov potential games including continuous action and state spaces. In the decentralized algorithm, agents sample their actions from parametrized and differentiable policies that depend on the current state and other agents' policy parameters. During training, agents estimate their gradient information through two consecutive episodes, generating unbiased estimators of reward and policy score functions. Using this information, agents compute the stochastic gradients of their policy functions and update their parameters accordingly. Additionally, they update their estimates of other agents' policy parameters based on the local estimates received through a time-varying communication network. In Markov potential games, there exists a potential value function among agents with gradients corresponding to the gradients of local value functions. Using this structure, we prove the almost sure convergence of joint policy parameters to stationary points of the potential value function. We also show that the convergence rate of the networked policy gradient algorithm is $\mathcal{O}(1/\epsilon^2)$. Numerical experiments on a dynamic multi-agent newsvendor problem verify the convergence of local beliefs and gradients. It further shows that networked policy gradient play converges as fast as independent policy gradient updates, while collecting higher rewards.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.20075v1</guid>
      <category>eess.SY</category>
      <category>cs.SY</category>
      <category>math.OC</category>
      <pubDate>Tue, 29 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <dc:creator>Sarper Aydin, Ceyhun Eksin</dc:creator>
    </item>
    <item>
      <title>Efficient Frequency Allocation for Superconducting Quantum Processors Using Improved Optimization Techniques</title>
      <link>https://arxiv.org/abs/2410.20283</link>
      <description>arXiv:2410.20283v1 Announce Type: cross 
Abstract: Building on previous research on frequency allocation optimization for superconducting circuit quantum processors, this work incorporates several new techniques to improve overall solution quality. New features include tightening constraints, imposing edgewise differences, including edge orientation in the optimization, and integrating multimodule designs with various boundary conditions. These enhancements allow for greater flexibility in processor design by eliminating the need for handpicked orientations. We support the efficient assembly of large processors with dense connectivity by choosing the best boundary conditions. Examples demonstrate that, at low computational cost, the new optimization approach finds a frequency configuration for a square chip with over 1,000 qubits and over 10% yield at much larger dispersion levels than required by previous approaches.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.20283v1</guid>
      <category>quant-ph</category>
      <category>math.OC</category>
      <pubDate>Tue, 29 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Zewen Zhang, Pranav Gokhale, Jeffrey M. Larson</dc:creator>
    </item>
    <item>
      <title>Classification under strategic adversary manipulation using pessimistic bilevel optimisation</title>
      <link>https://arxiv.org/abs/2410.20284</link>
      <description>arXiv:2410.20284v1 Announce Type: cross 
Abstract: Adversarial machine learning concerns situations in which learners face attacks from active adversaries. Such scenarios arise in applications such as spam email filtering, malware detection and fake-image generation, where security methods must be actively updated to keep up with the ever improving generation of malicious data.We model these interactions between the learner and the adversary as a game and formulate the problem as a pessimistic bilevel optimisation problem with the learner taking the role of the leader. The adversary, modelled as a stochastic data generator, takes the role of the follower, generating data in response to the classifier. While existing models rely on the assumption that the adversary will choose the least costly solution leading to a convex lower-level problem with a unique solution, we present a novel model and solution method which do not make such assumptions. We compare these to the existing approach and see significant improvements in performance suggesting that relaxing these assumptions leads to a more realistic model.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.20284v1</guid>
      <category>cs.LG</category>
      <category>math.OC</category>
      <pubDate>Tue, 29 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>David Benfield, Stefano Coniglio, Martin Kunc, Phan Tu Vuong, Alain Zemkoho</dc:creator>
    </item>
    <item>
      <title>Logarithmically Quantized Distributed Optimization over Dynamic Multi-Agent Networks</title>
      <link>https://arxiv.org/abs/2410.20345</link>
      <description>arXiv:2410.20345v1 Announce Type: cross 
Abstract: Distributed optimization finds many applications in machine learning, signal processing, and control systems. In these real-world applications, the constraints of communication networks, particularly limited bandwidth, necessitate implementing quantization techniques. In this paper, we propose distributed optimization dynamics over multi-agent networks subject to logarithmically quantized data transmission. Under this condition, data exchange benefits from representing smaller values with more bits and larger values with fewer bits. As compared to uniform quantization, this allows for higher precision in representing near-optimal values and more accuracy of the distributed optimization algorithm. The proposed optimization dynamics comprise a primary state variable converging to the optimizer and an auxiliary variable tracking the objective function's gradient. Our setting accommodates dynamic network topologies, resulting in a hybrid system requiring convergence analysis using matrix perturbation theory and eigenspectrum analysis.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.20345v1</guid>
      <category>eess.SY</category>
      <category>cs.LG</category>
      <category>cs.MA</category>
      <category>cs.SY</category>
      <category>math.OC</category>
      <pubDate>Tue, 29 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <arxiv:journal_reference>LCSS Journal 2024</arxiv:journal_reference>
      <dc:creator>Mohammadreza Doostmohammadian, S\'ergio Pequito</dc:creator>
    </item>
    <item>
      <title>Data-driven Analysis of T-Product-based Dynamical Systems</title>
      <link>https://arxiv.org/abs/2410.20541</link>
      <description>arXiv:2410.20541v1 Announce Type: cross 
Abstract: A wide variety of data can be represented using third-order tensors, spanning applications in chemometrics, psychometrics, and image processing. However, traditional data-driven frameworks are not naturally equipped to process tensors without first unfolding or flattening the data, which can result in a loss of crucial higher-order structural information. In this article, we introduce a novel framework for the data-driven analysis of T-product-based dynamical systems (TPDSs), where the system evolution is governed by the T-product between a third-order dynamic tensor and a third-order state tensor. In particular, we examine the data informativity of TPDSs concerning system identification, stability, controllability, and stabilizability and illustrate significant computational improvements over traditional approaches by leveraging the unique properties of the T-product. The effectiveness of our framework is demonstrated through numerical examples.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.20541v1</guid>
      <category>eess.SY</category>
      <category>cs.SY</category>
      <category>math.DS</category>
      <category>math.OC</category>
      <pubDate>Tue, 29 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Xin Mao, Anqi Dong, Ziqin He, Yidan Mei, Can Chen</dc:creator>
    </item>
    <item>
      <title>Practical Bayesian Algorithm Execution via Posterior Sampling</title>
      <link>https://arxiv.org/abs/2410.20596</link>
      <description>arXiv:2410.20596v1 Announce Type: cross 
Abstract: We consider Bayesian algorithm execution (BAX), a framework for efficiently selecting evaluation points of an expensive function to infer a property of interest encoded as the output of a base algorithm. Since the base algorithm typically requires more evaluations than are feasible, it cannot be directly applied. Instead, BAX methods sequentially select evaluation points using a probabilistic numerical approach. Current BAX methods use expected information gain to guide this selection. However, this approach is computationally intensive. Observing that, in many tasks, the property of interest corresponds to a target set of points defined by the function, we introduce PS-BAX, a simple, effective, and scalable BAX method based on posterior sampling. PS-BAX is applicable to a wide range of problems, including many optimization variants and level set estimation. Experiments across diverse tasks demonstrate that PS-BAX performs competitively with existing baselines while being significantly faster, simpler to implement, and easily parallelizable, setting a strong baseline for future research. Additionally, we establish conditions under which PS-BAX is asymptotically convergent, offering new insights into posterior sampling as an algorithm design paradigm.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.20596v1</guid>
      <category>cs.LG</category>
      <category>math.OC</category>
      <category>stat.ML</category>
      <pubDate>Tue, 29 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Chu Xin Cheng, Raul Astudillo, Thomas Desautels, Yisong Yue</dc:creator>
    </item>
    <item>
      <title>Learning Variational Inequalities from Data: Fast Generalization Rates under Strong Monotonicity</title>
      <link>https://arxiv.org/abs/2410.20649</link>
      <description>arXiv:2410.20649v1 Announce Type: cross 
Abstract: Variational inequalities (VIs) are a broad class of optimization problems encompassing machine learning problems ranging from standard convex minimization to more complex scenarios like min-max optimization and computing the equilibria of multi-player games. In convex optimization, strong convexity allows for fast statistical learning rates requiring only $\Theta(1/\epsilon)$ stochastic first-order oracle calls to find an $\epsilon$-optimal solution, rather than the standard $\Theta(1/\epsilon^2)$ calls. In this paper, we explain how one can similarly obtain fast $\Theta(1/\epsilon)$ rates for learning VIs that satisfy strong monotonicity, a generalization of strong convexity. Specifically, we demonstrate that standard stability-based generalization arguments for convex minimization extend directly to VIs when the domain admits a small covering, or when the operator is integrable and suboptimality is measured by potential functions; such as when finding equilibria in multi-player games.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.20649v1</guid>
      <category>cs.LG</category>
      <category>math.OC</category>
      <category>stat.ML</category>
      <pubDate>Tue, 29 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Eric Zhao, Tatjana Chavdarova, Michael Jordan</dc:creator>
    </item>
    <item>
      <title>Projection-based Reduced Order Modelling for Unsteady Parametrized Optimal Control Problems in 3D Cardiovascular Flows</title>
      <link>https://arxiv.org/abs/2410.20828</link>
      <description>arXiv:2410.20828v1 Announce Type: cross 
Abstract: This paper presents a projection-based reduced order modelling (ROM) framework for unsteady parametrized optimal control problems (OCP$_{(\mu)}$s) arising from cardiovascular (CV) applications. In real-life scenarios, accurately defining outflow boundary conditions in patient-specific models poses significant challenges due to complex vascular morphologies, physiological conditions, and high computational demands. These challenges make it difficult to compute realistic and reliable CV hemodynamics by incorporating clinical data such as 4D magnetic resonance imaging. To address these challenges, we focus on controlling the outflow boundary conditions to optimize CV flow dynamics and minimize the discrepancy between target and computed flow velocity profiles. The fluid flow is governed by unsteady Navier--Stokes equations with physical parametric dependence, i.e. the Reynolds number. Numerical solutions of OCP$_{(\mu)}$s require substantial computational resources, highlighting the need for robust and efficient ROMs to perform real-time and many-query simulations. Here, we aim at investigating the performance of a projection-based reduction technique that relies on the offline-online paradigm, enabling significant computational cost savings. The Galerkin finite element method is used to compute the high-fidelity solutions in the offline phase. We implemented a nested-proper orthogonal decomposition (nested-POD) for fast simulation of OCP$_{(\mu)}$s that encompasses two stages: temporal compression for reducing dimensionality in time, followed by parametric-space compression on the precomputed POD modes. We tested the efficacy of the methodology on vascular models, namely an idealized bifurcation geometry and a patient-specific coronary artery bypass graft, incorporating stress control at the outflow boundary, observing consistent speed-up with respect to high-fidelity strategies.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.20828v1</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <category>math.OC</category>
      <category>physics.comp-ph</category>
      <category>physics.flu-dyn</category>
      <category>physics.med-ph</category>
      <pubDate>Tue, 29 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Surabhi Rathore, Pasquale Claudio Africa, Francesco Ballarin, Federico Pichi, Michele Girfoglio, Gianluigi Rozza</dc:creator>
    </item>
    <item>
      <title>Long time behaviour of generalised gradient flows via occupational measures</title>
      <link>https://arxiv.org/abs/2410.20943</link>
      <description>arXiv:2410.20943v1 Announce Type: cross 
Abstract: This paper introduces new methods to study the long time behaviour of the generalised gradient flow associated with a solution of the critical equation for mechanical Hamiltonian system posed on the flat torus $\mathbb{T}^d$. For this analysis it is necessary to look at the critical set of $u$ consisting of all the points on $\mathbb{T}^d$ such that zero belongs to the super-differential of such a solution. Indeed, such a set turns out to be an attractor for the generalised gradient flow. Moreover, being the critical set the union of two subsets of rather different nature, namely the regular critical set and the singular set, we are interested in establishing whether the generalised gradient flow approaches the former or the latter as $t\to \infty$. One crucial tool of our analysis is provided by limiting occupational measures, a family of measures that are invariant under the generalized flow. Indeed, we show that by integrating the potential with respect to such measures, one can deduce whether the generalised gradient flow enters the singular set in finite time, or it approaches the regular critical set as time tends to infinity.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.20943v1</guid>
      <category>math.AP</category>
      <category>math.OC</category>
      <pubDate>Tue, 29 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Piermarco Cannarsa, Wei Cheng, Cristian Mendico</dc:creator>
    </item>
    <item>
      <title>Identification of source terms in the Schr\"odinger equation with dynamic boundary conditions from final data</title>
      <link>https://arxiv.org/abs/2410.21123</link>
      <description>arXiv:2410.21123v1 Announce Type: cross 
Abstract: In this paper, we study an inverse problem of identifying two spatial-temporal source terms in the Schr\"odinger equation with dynamic boundary conditions from the final time overdetermination. We adopt a weak solution approach to solve the inverse source problem. By analyzing the associated Tikhonov functional, we prove a gradient formula of the functional in terms of the solution to a suitable adjoint system, allowing us to obtain the Lipschitz continuity of the gradient. Next, the existence and uniqueness of a quasi-solution are also investigated. Finally, our theoretical results are validated by numerical experiments in one dimension using the Landweber iteration method.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.21123v1</guid>
      <category>math.AP</category>
      <category>math.OC</category>
      <pubDate>Tue, 29 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Salah-Eddine Chorfi, Alemdar Hasanov, Roberto Morales</dc:creator>
    </item>
    <item>
      <title>$\texttt{skwdro}$: a library for Wasserstein distributionally robust machine learning</title>
      <link>https://arxiv.org/abs/2410.21231</link>
      <description>arXiv:2410.21231v1 Announce Type: cross 
Abstract: We present skwdro, a Python library for training robust machine learning models. The library is based on distributionally robust optimization using optimal transport distances. For ease of use, it features both scikit-learn compatible estimators for popular objectives, as well as a wrapper for PyTorch modules, enabling researchers and practitioners to use it in a wide range of models with minimal code changes. Its implementation relies on an entropic smoothing of the original robust objective in order to ensure maximal model flexibility. The library is available at https://github.com/iutzeler/skwdro</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.21231v1</guid>
      <category>cs.LG</category>
      <category>cs.MS</category>
      <category>math.OC</category>
      <pubDate>Tue, 29 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <dc:creator>Florian Vincent, Wa\"iss Azizian, Franck Iutzeler, J\'er\^ome Malick</dc:creator>
    </item>
    <item>
      <title>High-level hybridization of heuristics and metaheuristics to solve symmetric TSP: a comparative study</title>
      <link>https://arxiv.org/abs/2410.21274</link>
      <description>arXiv:2410.21274v1 Announce Type: cross 
Abstract: The Travelling Salesman Problem - TSP is one of the most explored problems in the scientific literature to solve real problems regarding the economy, transportation, and logistics, to cite a few cases. Adapting TSP to solve different problems has originated several variants of the optimization problem with more complex objectives and different restrictions. Metaheuristics have been used to solve the problem in polynomial time. Several studies have tried hybridising metaheuristics with specialised heuristics to improve the quality of the solutions. However, we have found no study to evaluate whether the searching mechanism of a particular metaheuristic is more adequate for exploring hybridization. This paper focuses on the solution of the classical TSP using high-level hybridisations, experimenting with eight metaheuristics and heuristics derived from k-OPT, SISR, and segment intersection search, resulting in twenty-four combinations. Some combinations allow more than one set of searching parameters. Problems with 50 to 280 cities are solved. Parameter tuning of the metaheuristics is not carried out, exploiting the different searching patterns of the eight metaheuristics instead. The solutions' quality is compared to those presented in the literature.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.21274v1</guid>
      <category>cs.NE</category>
      <category>cs.DM</category>
      <category>math.OC</category>
      <pubDate>Tue, 29 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Carlos Alberto da Silva Junior, Roberto Yuji Tanaka, Luiz Carlos Farias da Silva, Angelo Passaro</dc:creator>
    </item>
    <item>
      <title>A first-order augmented Lagrangian method for constrained minimax optimization</title>
      <link>https://arxiv.org/abs/2301.02060</link>
      <description>arXiv:2301.02060v3 Announce Type: replace 
Abstract: In this paper we study a class of constrained minimax problems. In particular, we propose a first-order augmented Lagrangian method for solving them, whose subproblems turn out to be a much simpler structured minimax problem and are suitably solved by a first-order method developed in this paper. Under some suitable assumptions, an \emph{operation complexity} of $O(\varepsilon^{-4}\log\varepsilon^{-1})$, measured by its fundamental operations, is established for the first-order augmented Lagrangian method for finding an $\varepsilon$-KKT solution of the constrained minimax problems.</description>
      <guid isPermaLink="false">oai:arXiv.org:2301.02060v3</guid>
      <category>math.OC</category>
      <category>cs.LG</category>
      <category>cs.NA</category>
      <category>math.NA</category>
      <category>stat.ML</category>
      <pubDate>Tue, 29 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Zhaosong Lu, Sanyou Mei</dc:creator>
    </item>
    <item>
      <title>Nonconvex Stochastic Bregman Proximal Gradient Method for Nonconvex Composite Problems</title>
      <link>https://arxiv.org/abs/2306.14522</link>
      <description>arXiv:2306.14522v4 Announce Type: replace 
Abstract: Stochastic gradient methods for minimizing nonconvex composite objective functions typically rely on the Lipschitz smoothness of the differentiable part, but this assumption fails in many important problem classes, leading to instability of the algorithms in both theory and practice. To address this, we propose a family of stochastic Bregman proximal gradient (SBPG) methods that only require smooth adaptivity. SBPG replaces the quadratic approximation in SGD with a Bregman proximity measure, offering a better approximation model that handles non-Lipschitz gradients in nonconvex objectives. We establish the convergence properties of vanilla SBPG and show it achieves optimal sample complexity in the nonconvex setting. Experimental results on quadratic inverse problems demonstrate SBPG's robustness in terms of stepsize selection and sensitivity to the initial point. Furthermore, we introduce a momentum-based variant, MSBPG, which enhances convergence by relaxing the mini-batch size requirement while preserving the optimal oracle complexity. We apply a polynomial kernel function based MBPG to the loss function with polynomial growth. Experimental results on benchmark datasets confirm the effectiveness and robustness of MSBPG. Given its negligible additional computational cost compared to SGD in large-scale optimization, MSBPG shows promise as a universal optimizer for future applications.</description>
      <guid isPermaLink="false">oai:arXiv.org:2306.14522v4</guid>
      <category>math.OC</category>
      <category>cs.LG</category>
      <pubDate>Tue, 29 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/publicdomain/zero/1.0/</dc:rights>
      <dc:creator>Kuangyu Ding, Jingyang Li, Kim-Chuan Toh</dc:creator>
    </item>
    <item>
      <title>On Linear Convergence of PI Consensus Algorithm under the Restricted Secant Inequality</title>
      <link>https://arxiv.org/abs/2310.00419</link>
      <description>arXiv:2310.00419v2 Announce Type: replace 
Abstract: This paper considers solving distributed optimization problems in peer-to-peer multi-agent networks. The network is synchronous and connected. By using the proportional-integral (PI) control strategy, various algorithms with fixed stepsize have been developed. Two notable among them are the PI algorithm and the PI consensus algorithm. Although the PI algorithm has provable linear or exponential convergence without the standard requirement of (strong) convexity, a similar guarantee for the PI consensus algorithm is unavailable. In this paper, using Lyapunov theory, we guarantee exponential convergence of the PI consensus algorithm for global cost functions that satisfy the restricted secant inequality, with rate-matching discretization, without requiring convexity. To accelerate the PI consensus algorithm, we incorporate local pre-conditioning in the form of constant positive definite matrices and numerically validate its efficiency compared to the prominent distributed convex optimization algorithms. Unlike classical pre-conditioning, where only the gradients are multiplied by a pre-conditioner, the proposed pre-conditioning modifies both the gradients and the consensus terms, thereby controlling the effect of the communication graph on the algorithm.</description>
      <guid isPermaLink="false">oai:arXiv.org:2310.00419v2</guid>
      <category>math.OC</category>
      <category>cs.LG</category>
      <category>cs.SY</category>
      <category>eess.SY</category>
      <category>stat.ML</category>
      <pubDate>Tue, 29 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Kushal Chakrabarti, Mayank Baranwal</dc:creator>
    </item>
    <item>
      <title>qPOTS: Efficient batch multiobjective Bayesian optimization via Pareto optimal Thompson sampling</title>
      <link>https://arxiv.org/abs/2310.15788</link>
      <description>arXiv:2310.15788v2 Announce Type: replace 
Abstract: Classical evolutionary approaches for multiobjective optimization are quite accurate but incur a lot of queries to the objectives; this can be prohibitive when objectives are expensive oracles. A sample-efficient approach to solving multiobjective optimization is via Gaussian process (GP) surrogates and Bayesian optimization (BO). Multiobjective Bayesian optimization (MOBO) involves the construction of an acquisition function which is optimized to acquire new observation candidates sequentially. This ``inner'' optimization can be hard due to various reasons: acquisition functions being nonconvex, nondifferentiable and/or unavailable in analytical form; batch sampling usually exacerbates these problems and the success of MOBO heavily relies on this inner optimization. This, ultimately, affects their sample efficiency. To overcome these challenges, we propose a Thompson sampling (TS) based approach ($q\texttt{POTS}$). Whereas TS chooses candidates according to the probability that they are optimal, $q\texttt{POTS}$ chooses candidates according to the probability that they are Pareto optimal. Instead of a hard acquisition function optimization, $q\texttt{POTS}~$ solves a cheap multiobjective optimization on the GP posteriors with evolutionary approaches. This way we get the best of both worlds: accuracy of evolutionary approaches and sample-efficiency of MOBO. New candidates are chosen on the posterior GP Pareto frontier according to a maximin distance criterion. $q\texttt{POTS}~$ is endowed with theoretical guarantees, a natural exploration-exploitation trade-off and, superior accuracy and sample efficiency than its competitors based on synthetic as well as real-world experiments.</description>
      <guid isPermaLink="false">oai:arXiv.org:2310.15788v2</guid>
      <category>math.OC</category>
      <category>stat.ML</category>
      <pubDate>Tue, 29 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>S. Ashwin Renganathan, Kade E. Carlson</dc:creator>
    </item>
    <item>
      <title>Compressed Gradient Tracking Algorithms for Distributed Nonconvex Optimization</title>
      <link>https://arxiv.org/abs/2310.18871</link>
      <description>arXiv:2310.18871v3 Announce Type: replace 
Abstract: In this paper, we study the distributed nonconvex optimization problem, which aims to minimize the average value of the local nonconvex cost functions using local information exchange. To reduce the communication overhead, we introduce three general classes of compressors, i.e., compressors with bounded relative compression error, compressors with globally bounded absolute compression error, and compressors with locally bounded absolute compression error. By integrating them with distributed gradient tracking algorithm, we then propose three compressed distributed nonconvex optimization algorithms. For each algorithm, we design a novel Lyapunov function to demonstrate its sublinear convergence to a stationary point if the local cost functions are smooth. Furthermore, when the global cost function satisfies the Polyak--{\L}ojasiewicz (P--{\L}) condition, we show that our proposed algorithms linearly converge to a global optimal point. It is worth noting that, for compressors with bounded relative compression error and globally bounded absolute compression error, our proposed algorithms' parameters do not require prior knowledge of the P--{\L} constant. The theoretical results are illustrated by numerical examples, which demonstrate the effectiveness of the proposed algorithms in significantly reducing the communication burden while maintaining the convergence performance. Moreover, simulation results show that the proposed algorithms outperform state-of-the-art compressed distributed nonconvex optimization algorithms.</description>
      <guid isPermaLink="false">oai:arXiv.org:2310.18871v3</guid>
      <category>math.OC</category>
      <pubDate>Tue, 29 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Lei Xu, Xinlei Yi, Guanghui Wen, Yang Shi, Karl H. Johansson, Tao Yang</dc:creator>
    </item>
    <item>
      <title>A Proximal Gradient Method With Probabilistic Multi-Gossip Communications for Decentralized Composite Optimization</title>
      <link>https://arxiv.org/abs/2312.11861</link>
      <description>arXiv:2312.11861v2 Announce Type: replace 
Abstract: Decentralized optimization methods with local updates have recently gained attention for their provable ability to communication acceleration. In these methods, nodes perform several iterations of local computations between the communication rounds. Nevertheless, this capability is effective only when the loss function is smooth and the network is sufficiently well-connected. In this paper, we propose a communication-efficient method MG-Skip with probabilistic local updates and multi-gossip communications for decentralized composite (smooth + nonsmooth) optimization, whose stepsize is independent of the number of local updates and the network topology. Without any additional condition for network connectivity, MG-Skip allows for the multi-gossip communications to be skipped in most iterations in the strongly convex setting, while its iteration complexity is $\mathcal{O}\left(\kappa \log \frac{1}{\epsilon}\right)$ and communication complexity is only $\mathcal{O}\left(\sqrt{\frac{\kappa}{(1-\rho)}} \log \frac{1}{\epsilon}\right)$, where $\kappa$ is the condition number of the loss function, $\rho$ reflects the connectivity of the network topology, and $\epsilon$ is the target accuracy. The theoretical results demonstrate that MG-Skip achieves the optimal communication complexity and confirm the benefits of local updates in the nonsmooth setup.</description>
      <guid isPermaLink="false">oai:arXiv.org:2312.11861v2</guid>
      <category>math.OC</category>
      <category>cs.LG</category>
      <pubDate>Tue, 29 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Luyao Guo, Luqing Wang, Xinli Shi, Jinde Cao</dc:creator>
    </item>
    <item>
      <title>Stabilization of linear Port-Hamiltonian Descriptor Systems via Output Feedback</title>
      <link>https://arxiv.org/abs/2403.18967</link>
      <description>arXiv:2403.18967v2 Announce Type: replace 
Abstract: The structure preserving stabilization of (possibly non-regular) linear port-Hamiltonian descriptor (pHDAE) systems by output feedback is discussed. For general descriptor systems the characterization when there exist output feedbacks that lead to an asymptotically stable closed loop system is a very hard and partially an open problem. In contrast to this it is shown that for systems in pHDAE representation this problem can be completely solved. Necessary and sufficient conditions are presented that guarantee that there exist a proportional and/or derivative output feedback such that the resulting closed-loop port-Hamiltonian descriptor system is asymptotically stable. For this it is also necessary that the output feedback also makes the problem regular and of index at most one. A complete characterization when this is possible is presented as well.</description>
      <guid isPermaLink="false">oai:arXiv.org:2403.18967v2</guid>
      <category>math.OC</category>
      <category>cs.NA</category>
      <category>math.NA</category>
      <pubDate>Tue, 29 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Delin Chu, Volker Mehrmann</dc:creator>
    </item>
    <item>
      <title>Quadratically Regularized Optimal Transport: Existence and Multiplicity of Potentials</title>
      <link>https://arxiv.org/abs/2404.06847</link>
      <description>arXiv:2404.06847v2 Announce Type: replace 
Abstract: The optimal transport problem with quadratic regularization is useful when sparse couplings are desired. The density of the optimal coupling is described by two functions called potentials; equivalently, potentials can be defined as a solution of the dual problem. We prove the existence of potentials for a general square-integrable cost. Potentials are not necessarily unique, a phenomenon directly related to sparsity of the optimal support. For discrete problems, we describe the family of all potentials based on the connected components of the support, for a graph-theoretic notion of connectedness. On the other hand, we show that continuous problems have unique potentials under standard regularity assumptions, regardless of sparsity. Using potentials, we prove that the optimal support is indeed sparse for small regularization parameter in a continuous setting with quadratic cost, which seems to be the first theoretical guarantee for sparsity in this context.</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.06847v2</guid>
      <category>math.OC</category>
      <category>math.PR</category>
      <pubDate>Tue, 29 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Marcel Nutz</dc:creator>
    </item>
    <item>
      <title>Optimization-Aided Construction of Multivariate Chebyshev Polynomials</title>
      <link>https://arxiv.org/abs/2405.10438</link>
      <description>arXiv:2405.10438v3 Announce Type: replace 
Abstract: This article is concerned with an extension of univariate Chebyshev polynomials of the first kind to the multivariate setting, where one chases best approximants to specific monomials by polynomials of lower degree relative to the uniform norm. Exploiting the Moment-SOS hierarchy, we devise a versatile semidefinite-programming-based procedure to compute such best approximants, as well as associated signatures. Applying this procedure in three variables leads to the values of best approximation errors for all monomials up to degree six on the euclidean ball, the simplex, and the cross-polytope. Furthermore, inspired by numerical experiments, we obtain explicit expressions for Chebyshev polynomials in two cases unresolved before, namely for the monomial $x_1^2 x_2^2 x_3$ on the euclidean ball and for the monomial $x_1^2 x_2 x_3$ on the simplex.</description>
      <guid isPermaLink="false">oai:arXiv.org:2405.10438v3</guid>
      <category>math.OC</category>
      <category>cs.NA</category>
      <category>math.NA</category>
      <pubDate>Tue, 29 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Mareike Dressler, Simon Foucart, Mioara Joldes, Etienne de Klerk, Jean Bernard Lasserre, Yuan Xu</dc:creator>
    </item>
    <item>
      <title>Stochastic Optimization Schemes for Performative Prediction with Nonconvex Loss</title>
      <link>https://arxiv.org/abs/2405.17922</link>
      <description>arXiv:2405.17922v2 Announce Type: replace 
Abstract: This paper studies a risk minimization problem with decision dependent data distribution. The problem pertains to the performative prediction setting in which a trained model can affect the outcome estimated by the model. Such dependency creates a feedback loop that influences the stability of optimization algorithms such as stochastic gradient descent (SGD). We present the first study on performative prediction with smooth but possibly non-convex loss. We analyze a greedy deployment scheme with SGD (SGD-GD). Note that in the literature, SGD-GD is often studied with strongly convex loss. We first propose the definition of stationary performative stable (SPS) solutions through relaxing the popular performative stable condition. We then prove that SGD-GD converges to a biased SPS solution in expectation. We consider two conditions of sensitivity on the distribution shifts: (i) the sensitivity is characterized by Wasserstein-1 distance and the loss is Lipschitz w.r.t. data samples, or (ii) the sensitivity is characterized by total variation (TV) divergence and the loss is bounded. In both conditions, the bias levels are proportional to the stochastic gradient's variance and sensitivity level. Our analysis is extended to a lazy deployment scheme where models are deployed once per several SGD updates, and we show that it converges to a bias-free SPS solution. Numerical experiments corroborate our theories.</description>
      <guid isPermaLink="false">oai:arXiv.org:2405.17922v2</guid>
      <category>math.OC</category>
      <pubDate>Tue, 29 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Qiang Li, Hoi-To Wai</dc:creator>
    </item>
    <item>
      <title>Non-geodesically-convex optimization in the Wasserstein space</title>
      <link>https://arxiv.org/abs/2406.00502</link>
      <description>arXiv:2406.00502v2 Announce Type: replace 
Abstract: We study a class of optimization problems in the Wasserstein space (the space of probability measures) where the objective function is nonconvex along generalized geodesics. Specifically, the objective exhibits some difference-of-convex structure along these geodesics. The setting also encompasses sampling problems where the logarithm of the target distribution is difference-of-convex. We derive multiple convergence insights for a novel semi Forward-Backward Euler scheme under several nonconvex (and possibly nonsmooth) regimes. Notably, the semi Forward-Backward Euler is just a slight modification of the Forward-Backward Euler whose convergence is -- to our knowledge -- still unknown in our very general non-geodesically-convex setting.</description>
      <guid isPermaLink="false">oai:arXiv.org:2406.00502v2</guid>
      <category>math.OC</category>
      <category>cs.LG</category>
      <pubDate>Tue, 29 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Hoang Phuc Hau Luu, Hanlin Yu, Bernardo Williams, Petrus Mikkola, Marcelo Hartmann, Kai Puolam\"aki, Arto Klami</dc:creator>
    </item>
    <item>
      <title>Schr\"{o}dinger Bridge with Quadratic State Cost is Exactly Solvable</title>
      <link>https://arxiv.org/abs/2406.00503</link>
      <description>arXiv:2406.00503v4 Announce Type: replace 
Abstract: Schr\"{o}dinger bridge is a diffusion process that steers a given distribution to another in a prescribed time while minimizing the effort to do so. It can be seen as the stochastic dynamical version of the optimal mass transport, and has growing applications in generative diffusion models and stochastic optimal control. {\black{We say a Schr\"{o}dinger bridge is ``exactly solvable'' if the associated uncontrolled Markov kernel is available in closed form, since then the bridge can be numerically computed using dynamic Sinkhorn recursion for arbitrary endpoint distributions with finite second moments.}} In this work, we propose a regularized variant of the Schr\"{o}dinger bridge with a quadratic state cost-to-go that incentivizes the optimal sample paths to stay close to a nominal level.
  Unlike the conventional Schr\"{o}dinger bridge, the regularization induces a state-dependent rate of killing and creation of probability mass, and its solution requires determining the Markov kernel of a reaction-diffusion partial differential equation. We derive this Markov kernel in closed form, {\black{showing that the regularized Schr\"{o}dinger bridge is exactly solvable, even for non-Gaussian endpoints. This advances the state-of-the-art because closed form Markov kernel for the regularized Schr\"{o}dinger bridge is available in existing literature only for Gaussian endpoints}}. Our solution recovers the heat kernel in the vanishing regularization (i.e., diffusion without reaction) limit, thereby recovering the solution of the conventional Schr\"{o}dinger bridge {\black{as a special case}}. We deduce properties of the new kernel and explain its connections with certain exactly solvable models in quantum mechanics.</description>
      <guid isPermaLink="false">oai:arXiv.org:2406.00503v4</guid>
      <category>math.OC</category>
      <category>cs.LG</category>
      <category>cs.SY</category>
      <category>eess.SY</category>
      <category>math-ph</category>
      <category>math.MP</category>
      <category>stat.ML</category>
      <pubDate>Tue, 29 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Alexis M. H. Teter, Wenqing Wang, Abhishek Halder</dc:creator>
    </item>
    <item>
      <title>Shape differentiation for Poincare maps of harmonic fields in toroidal domains</title>
      <link>https://arxiv.org/abs/2406.08178</link>
      <description>arXiv:2406.08178v2 Announce Type: replace 
Abstract: In this article, we study Poincare maps of harmonic fields in toroidal domains using a shape variational approach. Given a bounded domain of $\mathbb{R}^3$, we define its harmonic fields as the set of magnetic fields which are curl free and tangent to the boundary. For toroidal domains, this space is one dimensional, and one may thus single out a harmonic field by specifying a degree of freedom, such as the circulation along a toroidal loop. We are then interested in the Poincare maps of such fields restricted to the boundary, which produce diffeomorphisms of the circle. We begin by proving a general shape differentiability result of such Poincare maps in the smooth category, and obtain a general formula for the shape derivative. We then investigate two specific examples of interest; axisymmetric domains, and domains for which the harmonic field has a diophantine rotation number on the boundary. We prove that, in the first case, the shape derivative of the Poincare map is always identically zero, whereas in the second case, assuming an additional condition on the geometry of the domain, the shape derivative of the Poincare map may be any smooth function of the circle by choosing an appropriate perturbation of the domain.</description>
      <guid isPermaLink="false">oai:arXiv.org:2406.08178v2</guid>
      <category>math.OC</category>
      <category>math.DS</category>
      <pubDate>Tue, 29 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Robin Roussel</dc:creator>
    </item>
    <item>
      <title>On the growth of nonconvex functionals at strict local minimizers</title>
      <link>https://arxiv.org/abs/2409.01833</link>
      <description>arXiv:2409.01833v3 Announce Type: replace 
Abstract: In this paper, we present new equivalent conditions for the growth of proper lower semicontinuous functionals at strict local minimizers. The main conditions are a variant of the so-called tilt stability property of local minimizers and an analog of the classic Polyak-{\L}ojasiewicz condition, where the gradient is replaced by linear perturbations. We derive the following tilting principle: stability of minimizers under linear perturbations can infer their stability under nonlinear ones. We show how growth conditions can be used to give convergence rates for the proximal point algorithm. Finally, we give an application to elliptic tracking problems, establishing a novel equivalence between second-order conditions and the sensitivity of solutions with respect to uncertainty in data.</description>
      <guid isPermaLink="false">oai:arXiv.org:2409.01833v3</guid>
      <category>math.OC</category>
      <pubDate>Tue, 29 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Alberto Dom\'inguez Corella, Tr\'i Minh L\^e</dc:creator>
    </item>
    <item>
      <title>Gradient-adjusted underdamped Langevin dynamics for sampling</title>
      <link>https://arxiv.org/abs/2410.08987</link>
      <description>arXiv:2410.08987v2 Announce Type: replace 
Abstract: Sampling from a target distribution is a fundamental problem. Traditional Markov chain Monte Carlo (MCMC) algorithms, such as the unadjusted Langevin algorithm (ULA), derived from the overdamped Langevin dynamics, have been extensively studied. From an optimization perspective, the Kolmogorov forward equation of the overdamped Langevin dynamics can be treated as the gradient flow of the relative entropy in the space of probability densities embedded with Wassrstein-2 metrics. Several efforts have also been devoted to including momentum-based methods, such as underdamped Langevin dynamics for faster convergence of sampling algorithms. Recent advances in optimizations have demonstrated the effectiveness of primal-dual damping and Hessian-driven damping dynamics for achieving faster convergence in solving optimization problems. Motivated by these developments, we introduce a class of stochastic differential equations (SDEs) called gradient-adjusted underdamped Langevin dynamics (GAUL), which add stochastic perturbations in primal-dual damping dynamics and Hessian-driven damping dynamics from optimization. We prove that GAUL admits the correct stationary distribution, whose marginal is the target distribution. The proposed method outperforms overdamped and underdamped Langevin dynamics regarding convergence speed in the total variation distance for Gaussian target distributions. Moreover, using the Euler-Maruyama discretization, we show that the mixing time towards a biased target distribution only depends on the square root of the condition number of the target covariance matrix. Numerical experiments for non-Gaussian target distributions, such as Bayesian regression problems and Bayesian neural networks, further illustrate the advantages of our approach.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.08987v2</guid>
      <category>math.OC</category>
      <category>cs.NA</category>
      <category>math.NA</category>
      <pubDate>Tue, 29 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Xinzhe Zuo, Stanley Osher, Wuchen Li</dc:creator>
    </item>
    <item>
      <title>Convex monotone semigroups and their generators with respect to $\Gamma$-convergence</title>
      <link>https://arxiv.org/abs/2202.08653</link>
      <description>arXiv:2202.08653v4 Announce Type: replace-cross 
Abstract: We study semigroups of convex monotone operators on spaces of continuous functions and their behaviour with respect to $\Gamma$-convergence. In contrast to the linear theory, the domain of the generator is, in general, not invariant under the semigroup. To overcome this issue, we consider different versions of invariant Lipschitz sets which turn out to be suitable domains for weaker notions of the generator. The so-called $\Gamma$-generator is defined as the time derivative with respect to $\Gamma$-convergence in the space of upper semicontinuous functions. Under suitable assumptions, we show that the $\Gamma$-generator uniquely characterizes the semigroup and is determined by its evaluation at smooth functions. Furthermore, we provide Chernoff approximation results for convex monotone semigroups and show that approximation schemes based on the same infinitesimal behaviour lead to the same semigroup. Our results are applied to semigroups related to stochastic optimal control problems in finite and infinite-dimensional settings as well as Wasserstein perturbations of transition semigroups.</description>
      <guid isPermaLink="false">oai:arXiv.org:2202.08653v4</guid>
      <category>math.AP</category>
      <category>math.OC</category>
      <pubDate>Tue, 29 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Jonas Blessing, Robert Denk, Michael Kupper, Max Nendel</dc:creator>
    </item>
    <item>
      <title>Conditional Euclidean distance optimization via relative tangency</title>
      <link>https://arxiv.org/abs/2310.16766</link>
      <description>arXiv:2310.16766v2 Announce Type: replace-cross 
Abstract: We introduce a theory of relative tangency for projective algebraic varieties. The dual variety $X_Z^\vee$ of a variety $X$ relative to a subvariety $Z$ is the set of hyperplanes tangent to $X$ at a point of $Z$. We also introduce the concept of polar classes of $X$ relative to $Z$. We explore the duality of varieties of low rank matrices relative to special linear sections. In this framework, we study the critical points of the Euclidean Distance function from a data point to $X$, lying on $Z$. The locus where the number of such conditional critical points is positive is called the ED data locus of $X$ given $Z$. The generic number of such critical points defines the conditional ED degree of $X$ given $Z$. We show the irreducibility of ED data loci, and we compute their dimensions and degrees in terms of relative characteristic classes.</description>
      <guid isPermaLink="false">oai:arXiv.org:2310.16766v2</guid>
      <category>math.AG</category>
      <category>math.OC</category>
      <pubDate>Tue, 29 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Sandra Di Rocco, Lukas Gustafsson, Luca Sodomaco</dc:creator>
    </item>
    <item>
      <title>Optimal Algorithms for Online Convex Optimization with Adversarial Constraints</title>
      <link>https://arxiv.org/abs/2310.18955</link>
      <description>arXiv:2310.18955v3 Announce Type: replace-cross 
Abstract: A well-studied generalization of the standard online convex optimization (OCO) framework is constrained online convex optimization (COCO). In COCO, on every round, a convex cost function and a convex constraint function are revealed to the learner after it chooses the action for that round. The objective is to design an online learning policy that simultaneously achieves a small regret while ensuring a small cumulative constraint violation (CCV) against an adaptive adversary interacting over a horizon of length $T$. A long-standing open question in COCO is whether an online policy can simultaneously achieve $O(\sqrt{T})$ regret and $\tilde{O}(\sqrt{T})$ CCV without any restrictive assumptions. For the first time, we answer this in the affirmative and show that a simple first-order policy can simultaneously achieve these bounds. Furthermore, in the case of strongly convex cost and convex constraint functions, the regret guarantee can be improved to $O(\log T)$ while keeping the CCV bound the same as above. We establish these results by effectively combining adaptive OCO policies as a blackbox with Lyapunov optimization - a classic tool from control theory. Surprisingly, the analysis is short and elegant.</description>
      <guid isPermaLink="false">oai:arXiv.org:2310.18955v3</guid>
      <category>cs.LG</category>
      <category>math.OC</category>
      <pubDate>Tue, 29 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Abhishek Sinha, Rahul Vaze</dc:creator>
    </item>
    <item>
      <title>Connection-Aware P2P Trading: Simultaneous Trading and Peer Selection</title>
      <link>https://arxiv.org/abs/2402.11769</link>
      <description>arXiv:2402.11769v2 Announce Type: replace-cross 
Abstract: Peer-to-peer (P2P) trading is seen as a viable solution to handle the growing number of distributed energy resources in distribution networks. However, when dealing with large-scale consumers, there are several challenges that must be addressed. One of these challenges is limited communication capabilities. Additionally, prosumers may have specific preferences when it comes to trading. Both can result in serious asynchrony in peer-to-peer trading, potentially impacting the effectiveness of negotiations and hindering convergence before the market closes. This paper introduces a connection-aware P2P trading algorithm designed for extensive prosumer trading. The algorithm facilitates asynchronous trading while respecting prosumer's autonomy in trading peer selection, an often overlooked aspect in traditional models. In addition, to optimize the use of limited connection opportunities, a smart trading peer connection selection strategy is developed to guide consumers to communicate strategically to accelerate convergence. A theoretical convergence guarantee is provided for the connection-aware P2P trading algorithm, which further details how smart selection strategies enhance convergence efficiency. Numerical studies are carried out to validate the effectiveness of the connection-aware algorithm and the performance of smart selection strategies in reducing the overall convergence time.</description>
      <guid isPermaLink="false">oai:arXiv.org:2402.11769v2</guid>
      <category>eess.SY</category>
      <category>cs.GT</category>
      <category>cs.SY</category>
      <category>math.OC</category>
      <pubDate>Tue, 29 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <arxiv:DOI>10.1016/j.apenergy.2024.124658</arxiv:DOI>
      <arxiv:journal_reference>Applied Energy, Volume 377, Part D, 2025, 124658, ISSN 0306-2619,</arxiv:journal_reference>
      <dc:creator>Cheng Feng, Kedi Zheng, Lanqing Shan, Hani Alers, Qixin Chen, Lampros Stergioulas, Hongye Guo</dc:creator>
    </item>
    <item>
      <title>Distributional MIPLIB: a Multi-Domain Library for Advancing ML-Guided MILP Methods</title>
      <link>https://arxiv.org/abs/2406.06954</link>
      <description>arXiv:2406.06954v2 Announce Type: replace-cross 
Abstract: Mixed Integer Linear Programming (MILP) is a fundamental tool for modeling combinatorial optimization problems. Recently, a growing body of research has used machine learning to accelerate MILP solving. Despite the increasing popularity of this approach, there is a lack of a common repository that provides distributions of similar MILP instances across different domains, at different hardness levels, with standardized test sets. In this paper, we introduce Distributional MIPLIB, a multi-domain library of problem distributions for advancing ML-guided MILP methods. We curate MILP distributions from existing work in this area as well as real-world problems that have not been used, and classify them into different hardness levels. It will facilitate research in this area by enabling comprehensive evaluation on diverse and realistic domains. We empirically illustrate the benefits of using Distributional MIPLIB as a research vehicle in two ways. We evaluate the performance of ML-guided variable branching on previously unused distributions to identify potential areas for improvement. Moreover, we propose to learn branching policies from a mix of distributions, demonstrating that mixed distributions achieve better performance compared to homogeneous distributions when there is limited data and generalize well to larger instances. The dataset is publicly available at https://sites.google.com/usc.edu/distributional-miplib/home.</description>
      <guid isPermaLink="false">oai:arXiv.org:2406.06954v2</guid>
      <category>cs.LG</category>
      <category>math.OC</category>
      <pubDate>Tue, 29 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Weimin Huang, Taoan Huang, Aaron M Ferber, Bistra Dilkina</dc:creator>
    </item>
    <item>
      <title>Evaluating the design space of diffusion-based generative models</title>
      <link>https://arxiv.org/abs/2406.12839</link>
      <description>arXiv:2406.12839v4 Announce Type: replace-cross 
Abstract: Most existing theoretical investigations of the accuracy of diffusion models, albeit significant, assume the score function has been approximated to a certain accuracy, and then use this a priori bound to control the error of generation. This article instead provides a first quantitative understanding of the whole generation process, i.e., both training and sampling. More precisely, it conducts a non-asymptotic convergence analysis of denoising score matching under gradient descent. In addition, a refined sampling error analysis for variance exploding models is also provided. The combination of these two results yields a full error analysis, which elucidates (again, but this time theoretically) how to design the training and sampling processes for effective generation. For instance, our theory implies a preference toward noise distribution and loss weighting in training that qualitatively agree with the ones used in [Karras et al., 2022]. It also provides perspectives on the choices of time and variance schedules in sampling: when the score is well trained, the design in [Song et al., 2021] is more preferable, but when it is less trained, the design in [Karras et al., 2022] becomes more preferable.</description>
      <guid isPermaLink="false">oai:arXiv.org:2406.12839v4</guid>
      <category>cs.LG</category>
      <category>math.DS</category>
      <category>math.OC</category>
      <category>math.PR</category>
      <category>stat.ML</category>
      <pubDate>Tue, 29 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Yuqing Wang, Ye He, Molei Tao</dc:creator>
    </item>
    <item>
      <title>Sub-Riemannian geodesics on the Heisenberg 3D nil-manifold</title>
      <link>https://arxiv.org/abs/2406.16065</link>
      <description>arXiv:2406.16065v2 Announce Type: replace-cross 
Abstract: We study the projection of the left-invariant sub-Riemannian structure on the 3D Heisenberg group $G$ to the Heisenberg 3D nil-manifold $M$ -- the compact homogeneous space of $G$ by the discrete Heisenberg group.
  First we describe dynamical properties of the geodesic flow for $M$: periodic and dense orbits, and a dynamical characterization of the normal Hamiltonian flow of Pontryagin maximum principle. Then we obtain sharp twoside bounds of sub-Riemannian balls and distance in $G$, and on this basis we estimate the cut time for sub-Riemannian geodesics in $M$.</description>
      <guid isPermaLink="false">oai:arXiv.org:2406.16065v2</guid>
      <category>math.DG</category>
      <category>math.DS</category>
      <category>math.OC</category>
      <pubDate>Tue, 29 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>A. Glutsyuk, Yu. Sachkov</dc:creator>
    </item>
    <item>
      <title>CONGO: Compressive Online Gradient Optimization</title>
      <link>https://arxiv.org/abs/2407.06325</link>
      <description>arXiv:2407.06325v2 Announce Type: replace-cross 
Abstract: We address the challenge of zeroth-order online convex optimization where the objective function's gradient exhibits sparsity, indicating that only a small number of dimensions possess non-zero gradients. Our aim is to leverage this sparsity to obtain useful estimates of the objective function's gradient even when the only information available is a limited number of function samples. Our motivation stems from the optimization of large-scale queueing networks that process time-sensitive jobs. Here, a job must be processed by potentially many queues in sequence to produce an output, and the service time at any queue is a function of the resources allocated to that queue. Since resources are costly, the end-to-end latency for jobs must be balanced with the overall cost of the resources used. While the number of queues is substantial, the latency function primarily reacts to resource changes in only a few, rendering the gradient sparse. We tackle this problem by introducing the Compressive Online Gradient Optimization framework which allows compressive sensing methods previously applied to stochastic optimization to achieve regret bounds with an optimal dependence on the time horizon without the full problem dimension appearing in the bound. For specific algorithms, we reduce the samples required per gradient estimate to scale with the gradient's sparsity factor rather than its full dimensionality. Numerical simulations and real-world microservices benchmarks demonstrate CONGO's superiority over gradient descent approaches that do not account for sparsity.</description>
      <guid isPermaLink="false">oai:arXiv.org:2407.06325v2</guid>
      <category>cs.LG</category>
      <category>cs.DC</category>
      <category>math.OC</category>
      <pubDate>Tue, 29 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Jeremy Carleton, Prathik Vijaykumar, Divyanshu Saxena, Dheeraj Narasimha, Srinivas Shakkottai, Aditya Akella</dc:creator>
    </item>
    <item>
      <title>Optimization Hyper-parameter Laws for Large Language Models</title>
      <link>https://arxiv.org/abs/2409.04777</link>
      <description>arXiv:2409.04777v2 Announce Type: replace-cross 
Abstract: Large Language Models have driven significant AI advancements, yet their training is resource-intensive and highly sensitive to hyper-parameter selection. While scaling laws provide valuable guidance on model size and data requirements, they fall short in choosing dynamic hyper-parameters, such as learning-rate (LR) schedules, that evolve during training. To bridge this gap, we present Optimization Hyper-parameter Laws (Opt-Laws), a framework that effectively captures the relationship between hyper-parameters and training outcomes, enabling the pre-selection of potential optimal schedules. Grounded in stochastic differential equations, Opt-Laws introduce novel mathematical interpretability and offer a robust theoretical foundation for some popular LR schedules. Our extensive validation across diverse model sizes and data scales demonstrates Opt-Laws' ability to accurately predict training loss and identify optimal LR schedule candidates in pre-training, continual training, and fine-tuning scenarios. This approach significantly reduces computational costs while enhancing overall model performance.</description>
      <guid isPermaLink="false">oai:arXiv.org:2409.04777v2</guid>
      <category>cs.LG</category>
      <category>math.OC</category>
      <pubDate>Tue, 29 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Xingyu Xie, Shuicheng Yan, Kim-Chuan Toh, Tianwen Wei</dc:creator>
    </item>
    <item>
      <title>Adjoint Matching: Fine-tuning Flow and Diffusion Generative Models with Memoryless Stochastic Optimal Control</title>
      <link>https://arxiv.org/abs/2409.08861</link>
      <description>arXiv:2409.08861v4 Announce Type: replace-cross 
Abstract: Dynamical generative models that produce samples through an iterative process, such as Flow Matching and denoising diffusion models, have seen widespread use, but there have not been many theoretically-sound methods for improving these models with reward fine-tuning. In this work, we cast reward fine-tuning as stochastic optimal control (SOC). Critically, we prove that a very specific memoryless noise schedule must be enforced during fine-tuning, in order to account for the dependency between the noise variable and the generated samples. We also propose a new algorithm named Adjoint Matching which outperforms existing SOC algorithms, by casting SOC problems as a regression problem. We find that our approach significantly improves over existing methods for reward fine-tuning, achieving better consistency, realism, and generalization to unseen human preference reward models, while retaining sample diversity.</description>
      <guid isPermaLink="false">oai:arXiv.org:2409.08861v4</guid>
      <category>cs.LG</category>
      <category>math.OC</category>
      <category>stat.ML</category>
      <pubDate>Tue, 29 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Carles Domingo-Enrich, Michal Drozdzal, Brian Karrer, Ricky T. Q. Chen</dc:creator>
    </item>
    <item>
      <title>Direct Data-Driven Discounted Infinite Horizon Linear Quadratic Regulator with Robustness Guarantees</title>
      <link>https://arxiv.org/abs/2409.10703</link>
      <description>arXiv:2409.10703v2 Announce Type: replace-cross 
Abstract: This paper presents a one-shot learning approach with performance and robustness guarantees for the linear quadratic regulator (LQR) control of stochastic linear systems. Even though data-based LQR control has been widely considered, existing results suffer either from data hungriness due to the inherently iterative nature of the optimization formulation (e.g., value learning or policy gradient reinforcement learning algorithms) or from a lack of robustness guarantees in one-shot non-iterative algorithms. To avoid data hungriness while ensuing robustness guarantees, an adaptive dynamic programming formalization of the LQR is presented that relies on solving a Bellman inequality. The control gain and the value function are directly learned by using a control-oriented approach that characterizes the closed-loop system using data and a decision variable from which the control is obtained. This closed-loop characterization is noise-dependent. The effect of the closed-loop system noise on the Bellman inequality is considered to ensure both robust stability and suboptimal performance despite ignoring the measurement noise. To ensure robust stability, it is shown that this system characterization leads to a closed-loop system with multiplicative and additive noise, enabling the application of distributional robust control techniques. The analysis of the suboptimality gap reveals that robustness can be achieved without the need for regularization or parameter tuning. The simulation results on the active car suspension problem demonstrate the superiority of the proposed method in terms of robustness and performance gap compared to existing methods.</description>
      <guid isPermaLink="false">oai:arXiv.org:2409.10703v2</guid>
      <category>eess.SY</category>
      <category>cs.SY</category>
      <category>math.OC</category>
      <pubDate>Tue, 29 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Ramin Esmzad, Hamidreza Modares</dc:creator>
    </item>
    <item>
      <title>A Taxonomy of Loss Functions for Stochastic Optimal Control</title>
      <link>https://arxiv.org/abs/2410.00345</link>
      <description>arXiv:2410.00345v2 Announce Type: replace-cross 
Abstract: Stochastic optimal control (SOC) aims to direct the behavior of noisy systems and has widespread applications in science, engineering, and artificial intelligence. In particular, reward fine-tuning of diffusion and flow matching models and sampling from unnormalized methods can be recast as SOC problems. A recent work has introduced Adjoint Matching (Domingo-Enrich et al., 2024), a loss function for SOC problems that vastly outperforms existing loss functions in the reward fine-tuning setup. The goal of this work is to clarify the connections between all the existing (and some new) SOC loss functions. Namely, we show that SOC loss functions can be grouped into classes that share the same gradient in expectation, which means that their optimization landscape is the same; they only differ in their gradient variance. We perform simple SOC experiments to understand the strengths and weaknesses of different loss functions.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.00345v2</guid>
      <category>cs.LG</category>
      <category>math.OC</category>
      <category>stat.ML</category>
      <pubDate>Tue, 29 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Carles Domingo-Enrich</dc:creator>
    </item>
    <item>
      <title>Learning to Walk from Three Minutes of Real-World Data with Semi-structured Dynamics Models</title>
      <link>https://arxiv.org/abs/2410.09163</link>
      <description>arXiv:2410.09163v2 Announce Type: replace-cross 
Abstract: Traditionally, model-based reinforcement learning (MBRL) methods exploit neural networks as flexible function approximators to represent $\textit{a priori}$ unknown environment dynamics. However, training data are typically scarce in practice, and these black-box models often fail to generalize. Modeling architectures that leverage known physics can substantially reduce the complexity of system-identification, but break down in the face of complex phenomena such as contact. We introduce a novel framework for learning semi-structured dynamics models for contact-rich systems which seamlessly integrates structured first principles modeling techniques with black-box auto-regressive models. Specifically, we develop an ensemble of probabilistic models to estimate external forces, conditioned on historical observations and actions, and integrate these predictions using known Lagrangian dynamics. With this semi-structured approach, we can make accurate long-horizon predictions with substantially less data than prior methods. We leverage this capability and propose Semi-Structured Reinforcement Learning ($\texttt{SSRL}$) a simple model-based learning framework which pushes the sample complexity boundary for real-world learning. We validate our approach on a real-world Unitree Go1 quadruped robot, learning dynamic gaits -- from scratch -- on both hard and soft surfaces with just a few minutes of real-world data. Video and code are available at: https://sites.google.com/utexas.edu/ssrl</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.09163v2</guid>
      <category>cs.RO</category>
      <category>cs.LG</category>
      <category>math.OC</category>
      <pubDate>Tue, 29 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Jacob Levy, Tyler Westenbroek, David Fridovich-Keil</dc:creator>
    </item>
    <item>
      <title>Learning to Optimize for Mixed-Integer Non-linear Programming</title>
      <link>https://arxiv.org/abs/2410.11061</link>
      <description>arXiv:2410.11061v2 Announce Type: replace-cross 
Abstract: Mixed-integer non-linear programs (MINLPs) arise in various domains, such as energy systems and transportation, but are notoriously difficult to solve. Recent advances in machine learning have led to remarkable successes in optimization tasks, an area broadly known as learning to optimize. This approach includes using predictive models to generate solutions for optimization problems with continuous decision variables, thereby avoiding the need for computationally expensive optimization algorithms. However, applying learning to MINLPs remains challenging primarily due to the presence of integer decision variables, which complicate gradient-based learning. To address this limitation, we propose two differentiable correction layers that generate integer outputs while preserving gradient information. Combined with a soft penalty for constraint violation, our framework can tackle both the integrality and non-linear constraints in a MINLP. Experiments on three problem classes with convex/non-convex objective/constraints and integer/mixed-integer variables show that the proposed learning-based approach consistently produces high-quality solutions for parametric MINLPs extremely quickly. As problem size increases, traditional exact solvers and heuristic methods struggle to find feasible solutions, whereas our approach continues to deliver reliable results. Our work extends the scope of learning-to-optimize to MINLP, paving the way for integrating integer constraints into deep learning models. Our code is available at https://github.com/pnnl/L2O-pMINLP.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.11061v2</guid>
      <category>cs.LG</category>
      <category>math.OC</category>
      <pubDate>Tue, 29 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Bo Tang, Elias B. Khalil, J\'an Drgo\v{n}a</dc:creator>
    </item>
    <item>
      <title>Marine spatial planning techniques with a case study on wave-powered offshore aquaculture farms</title>
      <link>https://arxiv.org/abs/2410.11926</link>
      <description>arXiv:2410.11926v2 Announce Type: replace-cross 
Abstract: As emerging marine technologies lead to the development of new infrastructure across the ocean, they enter an environment that existing ecosystems and industries already rely on. Although necessary to provide sustainable sources of energy and food, careful planning will be important to make informed decisions and avoid conflicts. This paper examines several techniques used for marine spatial planning, an approach for analyzing and planning the use of marine resources. Using open source software including QGIS and Python, the potential for developing wave-powered offshore aquaculture farms using the RM3 wave energy converter along the Northeast coast of the United States is assessed and several feasible sites are identified. The optimal site, located at 43.7{\deg}N, 68.9{\deg}W along the coast of Maine, has a total cost for a 5-pen farm of \$56.8M, annual fish yield of 676 tonnes, and a levelized cost of fish of \$9.23 per kilogram. Overall trends indicate that the cost greatly decreases with distance to shore due to the greater availability of wave energy and that conflicts and environmental constraints significantly limit the number of feasible sites in this region.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.11926v2</guid>
      <category>physics.ao-ph</category>
      <category>cs.SY</category>
      <category>eess.SY</category>
      <category>math.OC</category>
      <category>physics.data-an</category>
      <pubDate>Tue, 29 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Gabriel Ewig, Arezoo Hasankhani, Eugene Won, Maha Haji</dc:creator>
    </item>
  </channel>
</rss>
