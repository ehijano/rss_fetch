<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>stat.CO updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/stat.CO</link>
    <description>stat.CO updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/stat.CO" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Mon, 04 Nov 2024 05:00:48 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Mon, 04 Nov 2024 00:00:00 -0500</pubDate>
    <skipDays>
      <day>Sunday</day>
      <day>Saturday</day>
    </skipDays>
    <item>
      <title>Solving the 2D Advection-Diffusion Equation using Fixed-Depth Symbolic Regression and Symbolic Differentiation without Expression Trees</title>
      <link>https://arxiv.org/abs/2411.00011</link>
      <description>arXiv:2411.00011v1 Announce Type: new 
Abstract: This paper presents a novel method for solving the 2D advection-diffusion equation using fixed-depth symbolic regression and symbolic differentiation without expression trees. The method is applied to two cases with distinct initial and boundary conditions, demonstrating its accuracy and ability to find approximate solutions efficiently. This framework offers a promising, scalable solution for finding approximate solutions to differential equations, with the potential for future improvements in computational performance and applicability to more complex systems involving vector-valued objectives.</description>
      <guid isPermaLink="false">oai:arXiv.org:2411.00011v1</guid>
      <category>stat.CO</category>
      <category>cs.LG</category>
      <category>cs.NA</category>
      <category>math.NA</category>
      <pubDate>Mon, 04 Nov 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Edward Finkelstein</dc:creator>
    </item>
    <item>
      <title>Nudging state-space models for Bayesian filtering under misspecified dynamics</title>
      <link>https://arxiv.org/abs/2411.00218</link>
      <description>arXiv:2411.00218v1 Announce Type: new 
Abstract: Nudging is a popular algorithmic strategy in numerical filtering to deal with the problem of inference in high-dimensional dynamical systems. We demonstrate in this paper that general nudging techniques can also tackle another crucial statistical problem in filtering, namely the misspecification of the transition model. Specifically, we rely on the formulation of nudging as a general operation increasing the likelihood and prove analytically that, when applied carefully, nudging techniques implicitly define state-space models (SSMs) that have higher marginal likelihoods for a given (fixed) sequence of observations. This provides a theoretical justification of nudging techniques as data-informed algorithmic modifications of SSMs to obtain robust models under misspecified dynamics. To demonstrate the use of nudging, we provide numerical experiments on linear Gaussian SSMs and a stochastic Lorenz 63 model with misspecified dynamics and show that nudging offers a robust filtering strategy for these cases.</description>
      <guid isPermaLink="false">oai:arXiv.org:2411.00218v1</guid>
      <category>stat.CO</category>
      <category>math.PR</category>
      <pubDate>Mon, 04 Nov 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-sa/4.0/</dc:rights>
      <dc:creator>Fabian Gonzalez, O. Deniz Akyildiz, Dan Crisan, Joaquin Miguez</dc:creator>
    </item>
    <item>
      <title>The Sensitivity of Bayesian Kernel Machine Regression (BKMR) to Data Distribution: A Comprehensive Simulation Analysis</title>
      <link>https://arxiv.org/abs/2411.00286</link>
      <description>arXiv:2411.00286v1 Announce Type: new 
Abstract: Bayesian Kernel Machine Regression (BKMR) has emerged as a powerful tool to detect negative health effects from exposure to complex multi-pollutant mixtures. However, its performance is degraded when data deviate from normality. In this comprehensive simulation analysis, we show that BKMR's power and test size vary under different distributions and covariance matrix structures. Our results demonstrate specifically that BKMR's robustness is influenced by the response's coefficient of variation (CV), resulting in reduced accuracy to detect true effects when data are skewed. Test sizes become uncontrolled (&gt; 0.05) as CV values increase, leading to inflated false detection rates. However, we find that BKMR effectively utilizes off-diagonal covariance information corresponding to predictor interdependencies, increasing statistical power and accuracy. To achieve reliable and accurate results, we advocate for scrutiny of data skewness and covariance before applying BKMR, particularly when used to predict cognitive decline from blood/urine heavy metal concentrations in environmental health contexts.</description>
      <guid isPermaLink="false">oai:arXiv.org:2411.00286v1</guid>
      <category>stat.CO</category>
      <category>stat.AP</category>
      <pubDate>Mon, 04 Nov 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Kazi Tanvir Hasan, Gabriel Odom, Zoran Bursac, Boubakari Ibrahimou</dc:creator>
    </item>
    <item>
      <title>Blocked Gibbs Sampling for Improved Convergence in Finite Mixture Models</title>
      <link>https://arxiv.org/abs/2411.00371</link>
      <description>arXiv:2411.00371v1 Announce Type: cross 
Abstract: Gibbs sampling is a common procedure used to fit finite mixture models. However, it is known to be slow to converge when exploring correlated regions of a parameter space and so blocking correlated parameters is sometimes implemented in practice. This is straightforward to visualize in contexts like low-dimensional multivariate Gaussian distributions, but more difficult for mixture models because of the way latent variable assignment and cluster-specific parameters influence one another. Here we analyze correlation in the space of latent variables and show that latent variables of outlier observations equidistant between component distributions can exhibit significant correlation that is not bounded away from one, suggesting they can converge very slowly to their stationary distribution. We provide bounds on convergence rates to a modification of the stationary distribution and propose a blocked sampling procedure that significantly reduces autocorrelation in the latent variable Markov chain, which we demonstrate in simulation.</description>
      <guid isPermaLink="false">oai:arXiv.org:2411.00371v1</guid>
      <category>math.ST</category>
      <category>stat.CO</category>
      <category>stat.TH</category>
      <pubDate>Mon, 04 Nov 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>David Michael Swanson</dc:creator>
    </item>
    <item>
      <title>Distributed Community Detection in Large Networks</title>
      <link>https://arxiv.org/abs/2203.06509</link>
      <description>arXiv:2203.06509v2 Announce Type: replace 
Abstract: Community detection for large networks poses challenges due to the high computational cost as well as heterogeneous community structures.
  In this paper, we consider widely existing real-world networks with ``grouped communities'' (or ``the group structure''), where nodes within grouped communities are densely connected and nodes across grouped communities are relatively loosely connected.
  We propose a two-step community detection approach for such networks.
  Firstly, we leverage modularity optimization methods to partition the network into groups, where between-group connectivity is low.
  Secondly, we employ the stochastic block model (SBM) or degree-corrected SBM (DCSBM) to further partition the groups into communities, allowing for varying levels of between-community connectivity.
  By incorporating this two-step structure, we introduce a novel divide-and-conquer algorithm that asymptotically recovers both the group structure and the community structure.
  Numerical studies confirm that our approach significantly reduces computational costs while achieving competitive performance.
  This framework provides a comprehensive solution for detecting community structures in networks with grouped communities, offering a valuable tool for various applications.</description>
      <guid isPermaLink="false">oai:arXiv.org:2203.06509v2</guid>
      <category>stat.CO</category>
      <pubDate>Mon, 04 Nov 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Sheng Zhang, Rui Song, Wenbin Lu, Ji Zhu</dc:creator>
    </item>
    <item>
      <title>Evaluating Forecasts with scoringutils in R</title>
      <link>https://arxiv.org/abs/2205.07090</link>
      <description>arXiv:2205.07090v2 Announce Type: replace-cross 
Abstract: Evaluating forecasts is essential to understand and improve forecasting and make forecasts useful to decision makers. A variety of R packages provide a broad variety of scoring rules, visualisations and diagnostic tools. One particular challenge, which scoringutils aims to address, is handling the complexity of evaluating and comparing forecasts from several forecasters across multiple dimensions such as time, space, and different types of targets. scoringutils extends the existing landscape by offering a convenient and flexible data.table-based framework for evaluating and comparing probabilistic forecasts (forecasts represented by a full predictive distribution). Notably, scoringutils is the first package to offer extensive support for probabilistic forecasts in the form of predictive quantiles, a format that is currently used by several infectious disease Forecast Hubs. The package is easily extendable, meaning that users can supply their own scoring rules or extend existing classes to handle new types of forecasts. scoringutils provides broad functionality to check the data and diagnose issues, to visualise forecasts and missing data, to transform data before scoring, to handle missing forecasts, to aggregate scores, and to visualise the results of the evaluation. The paper presents the package and its core functionality and illustrates common workflows using example data of forecasts for COVID-19 cases and deaths submitted to the European COVID-19 Forecast Hub.</description>
      <guid isPermaLink="false">oai:arXiv.org:2205.07090v2</guid>
      <category>stat.ME</category>
      <category>stat.AP</category>
      <category>stat.CO</category>
      <pubDate>Mon, 04 Nov 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Nikos I. Bosse, Hugo Gruson, Anne Cori, Edwin van Leeuwen, Sebastian Funk, Sam Abbott</dc:creator>
    </item>
    <item>
      <title>Parallel-in-time quantum simulation via Page and Wootters quantum time</title>
      <link>https://arxiv.org/abs/2308.12944</link>
      <description>arXiv:2308.12944v2 Announce Type: replace-cross 
Abstract: In the past few decades, researchers have created a veritable zoo of quantum algorithm by drawing inspiration from classical computing, information theory, and even from physical phenomena. Here we present quantum algorithms for parallel-in-time simulations that are inspired by the Page and Wooters formalism. In this framework, and thus in our algorithms, the classical time-variable of quantum mechanics is promoted to the quantum realm by introducing a Hilbert space of "clock" qubits which are then entangled with the "system" qubits. We show that our algorithms can compute temporal properties over $N$ different times of many-body systems by only using $\log(N)$ clock qubits. As such, we achieve an exponential trade-off between time and spatial complexities. In addition, we rigorously prove that the entanglement created between the system qubits and the clock qubits has operational meaning, as it encodes valuable information about the system's dynamics. We also provide a circuit depth estimation of all the protocols, showing an exponential advantage in computation times over traditional sequential in time algorithms. In particular, for the case when the dynamics are determined by the Aubry-Andre model, we present a hybrid method for which our algorithms have a depth that only scales as $\mathcal{O}(\log(N)n)$. As a by product we can relate the previous schemes to the problem of equilibration of an isolated quantum system, thus indicating that our framework enable a new dimension for studying dynamical properties of many-body systems.</description>
      <guid isPermaLink="false">oai:arXiv.org:2308.12944v2</guid>
      <category>quant-ph</category>
      <category>stat.CO</category>
      <pubDate>Mon, 04 Nov 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>N. L. Diaz, Paolo Braccia, Martin Larocca, J. M. Matera, R. Rossignoli, M. Cerezo</dc:creator>
    </item>
    <item>
      <title>Monte-Carlo/Moments micro-macro Parareal method for unimodal and bimodal scalar McKean-Vlasov SDEs</title>
      <link>https://arxiv.org/abs/2310.11365</link>
      <description>arXiv:2310.11365v2 Announce Type: replace-cross 
Abstract: We propose a micro-macro parallel-in-time Parareal method for scalar McKean-Vlasov stochastic differential equations (SDEs). In the algorithm, the fine Parareal propagator is a Monte Carlo simulation of an ensemble of particles, while an approximate ordinary differential equation (ODE) description of the mean and the variance of the particle distribution is used as a coarse Parareal propagator to achieve speedup. We analyse the convergence behaviour of our method for a linear problem and provide numerical experiments indicating the parallel weak scaling of the algorithm on a set of examples. We show, with numerical experiments, that convergence typically takes place in a low number of iterations, depending on the quality of the ODE predictor. For bimodal SDEs, we avoid quality deterioration of the coarse predictor (compared to unimodal SDEs) through the usage of multiple ODEs, each describing the mean and variance of the particle distribution in locally unimodal regions of the phase space. The benefit of the proposed algorithm can be viewed through two lenses: (i) through the parallel-in-time lens, speedup is obtained through the use of a very cheap coarse integrator (an ODE moment model), and (ii) through the moment models lens, accuracy is iteratively gained through the use of parallel machinery as a corrector. In contrast to the isolated use of a moment model, the proposed method (iteratively) converges to the true distribution generated by the SDE.</description>
      <guid isPermaLink="false">oai:arXiv.org:2310.11365v2</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <category>physics.comp-ph</category>
      <category>stat.CO</category>
      <pubDate>Mon, 04 Nov 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Ignace Bossuyt, Stefan Vandewalle, Giovanni Samaey</dc:creator>
    </item>
    <item>
      <title>Micro-macro Parareal, from ODEs to SDEs and back again</title>
      <link>https://arxiv.org/abs/2401.01798</link>
      <description>arXiv:2401.01798v2 Announce Type: replace-cross 
Abstract: In this paper, we are concerned with the micro-macro Parareal algorithm for the simulation of initial-value problems. In this algorithm, a coarse (fast) solver is applied sequentially over the time domain, and a fine (time-consuming) solver is applied as a corrector in parallel over smaller chunks of the time interval. Moreover, the coarse solver acts on a reduced state variable, which is coupled to the fine state variable through appropriate coupling operators. We first provide a contribution to the convergence analysis of the micro-macro Parareal method for multiscale linear ordinary differential equations (ODEs). Then, we extend a variant of the micro-macro Parareal algorithm for scalar stochastic differential equations (SDEs) to higher-dimensional SDEs.</description>
      <guid isPermaLink="false">oai:arXiv.org:2401.01798v2</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <category>stat.CO</category>
      <pubDate>Mon, 04 Nov 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Ignace Bossuyt, Stefan Vandewalle, Giovanni Samaey</dc:creator>
    </item>
    <item>
      <title>Pochhammer Priors for Sparse Count Models</title>
      <link>https://arxiv.org/abs/2402.09583</link>
      <description>arXiv:2402.09583v3 Announce Type: replace-cross 
Abstract: Bayesian hierarchical models are commonly employed for inference in count datasets, as they account for multiple levels of variation by incorporating prior distributions for parameters at different levels. Examples include Beta-Binomial, Negative-Binomial (NB), Dirichlet-Multinomial (DM) distributions. In this paper, we address two crucial challenges that arise in various Bayesian count models: inference for the concentration parameter in the ratio of Gamma functions and the inability of these models to effectively handle excessive zeros and small nonzero counts. We propose a novel class of prior distributions that facilitates conjugate updating of the concentration parameter in Gamma ratios, enabling full Bayesian inference for the aforementioned count distributions. We use DM models as our running examples. Our methodology leverages fast residue computation and admits closed-form posterior moments. Additionally, we recommend a default horseshoe type prior which has a heavy tail and substantial mass around zero. It admits continuous shrinkage, making the posterior highly adaptable to sparsity or quasi-sparsity in the data. Furthermore, we offer insights and potential generalizations to other count models facing the two challenges. We demonstrate the usefulness of our approach on both simulated examples and on real-world applications. Finally, we conclude with directions for future research.</description>
      <guid isPermaLink="false">oai:arXiv.org:2402.09583v3</guid>
      <category>stat.ME</category>
      <category>stat.CO</category>
      <pubDate>Mon, 04 Nov 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Yuexi Wang, Nicholas G. Polson</dc:creator>
    </item>
  </channel>
</rss>
