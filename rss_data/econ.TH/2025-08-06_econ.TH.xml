<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>econ.TH updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/econ.TH</link>
    <description>econ.TH updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/econ.TH" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Thu, 07 Aug 2025 01:31:27 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Wed, 06 Aug 2025 00:00:00 -0400</pubDate>
    <skipDays>
      <day>Sunday</day>
      <day>Saturday</day>
    </skipDays>
    <item>
      <title>An Evolutionary Analysis of Narrative Selection</title>
      <link>https://arxiv.org/abs/2508.03540</link>
      <description>arXiv:2508.03540v1 Announce Type: new 
Abstract: We study the performance of different methods for processing information, incorporating narrative selection within an evolutionary model. All agents update their beliefs according to Bayes' Rule, but some strategically choose the narrative they use in updating according to heterogeneous criteria. We simulate the endogenous composition of the population, considering different laws of motion for the underlying state of the world. We find that conformists -- that is, agents that choose the narrative to conform to the average belief in the population -- have an evolutionary advantage over other agents across all specifications. The survival chances of the remaining types depend on the uncertainty regarding the state of the world. Agents who tend to develop mild beliefs perform better when the uncertainty is high, whereas agents who tend to develop extreme beliefs perform better when the uncertainty is low.</description>
      <guid isPermaLink="false">oai:arXiv.org:2508.03540v1</guid>
      <category>econ.TH</category>
      <pubDate>Wed, 06 Aug 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Federico Innocenti, Roberto Rozzi</dc:creator>
    </item>
    <item>
      <title>Approximate Equilibria in Nonconvex Markets: Theory and Evidence from European Electricity Auctions</title>
      <link>https://arxiv.org/abs/2503.02464</link>
      <description>arXiv:2503.02464v2 Announce Type: replace 
Abstract: A fundamental challenge in the design of nonconvex markets is the absence of existence guarantees for Walrasian equilibria. Despite this lack of guarantees, we observed that the European day-ahead electricity auction attained equilibrium on approximately 80% of days during 2023 in some countries, while in others, it occurred on about 10% of days. By analysing auction microdata, we attribute these differences to varying ratios of divisible (convex) bids versus indivisible (nonconvex) ones. To provide a theoretical foundation for this empirical observation, we refine classical approximate equilibrium theorems to establish a link between the market share of nonconvex participants and the existence of (approximate) equilibria. These findings offer new insights into the conditions under which equilibria can emerge in practice and contribute to current policy discussions on the reform of the European electricity auction.</description>
      <guid isPermaLink="false">oai:arXiv.org:2503.02464v2</guid>
      <category>econ.TH</category>
      <pubDate>Wed, 06 Aug 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Thomas H\"ubner</dc:creator>
    </item>
    <item>
      <title>Data-Driven Persuasion</title>
      <link>https://arxiv.org/abs/2507.03203</link>
      <description>arXiv:2507.03203v2 Announce Type: replace 
Abstract: This paper develops a data-driven approach to Bayesian persuasion. The receiver is privately informed about the prior distribution of the state of the world, the sender knows the receiver's preferences but does not know the distribution of the state variable, and the sender's payoffs depend on the receiver's action but not on the state. Prior to interacting with the receiver, the sender observes the distribution of actions taken by a population of decision makers who share the receiver's preferences in best response to an unobserved distribution of messages generated by an unknown and potentially heterogeneous signal. The sender views any prior that rationalizes this data as plausible and seeks a signal that maximizes her worst-case payoff against the set of all such distributions. We show positively that the two-state many-action problem has a saddle point and negatively that the two-action many-state problem does not. In the former case, we identify adversarial priors and optimal signals. In the latter, we characterize the set of robustly optimal Blackwell experiments.</description>
      <guid isPermaLink="false">oai:arXiv.org:2507.03203v2</guid>
      <category>econ.TH</category>
      <category>cs.GT</category>
      <pubDate>Wed, 06 Aug 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Maxwell Rosenthal</dc:creator>
    </item>
    <item>
      <title>Digital Goods Monopoly: A Folk Theorem</title>
      <link>https://arxiv.org/abs/2507.13137</link>
      <description>arXiv:2507.13137v5 Announce Type: replace 
Abstract: We study a dynamic durable-goods monopoly model of differentiated digital goods. We establish a folk theorem: when both parties are sufficiently patient, any seller payoff ranging from the lowest buyer valuation up to approximately the static commitment monopoly payoff can be sustained in equilibrium. This result emerges from two fundamental characteristics unique to digital goods: free disposability on the buyer side and zero marginal cost on the seller side. Our analysis provides economic intuition consistent with empirical evidence documenting substantially higher markups in digital-intensive industries compared to traditional manufacturing sectors.</description>
      <guid isPermaLink="false">oai:arXiv.org:2507.13137v5</guid>
      <category>econ.TH</category>
      <pubDate>Wed, 06 Aug 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Zihao Li</dc:creator>
    </item>
    <item>
      <title>Model-Based Soft Maximization of Suitable Metrics of Long-Term Human Power</title>
      <link>https://arxiv.org/abs/2508.00159</link>
      <description>arXiv:2508.00159v2 Announce Type: replace-cross 
Abstract: Power is a key concept in AI safety: power-seeking as an instrumental goal, sudden or gradual disempowerment of humans, power balance in human-AI interaction and international AI governance. At the same time, power as the ability to pursue diverse goals is essential for wellbeing.
  This paper explores the idea of promoting both safety and wellbeing by forcing AI agents explicitly to empower humans and to manage the power balance between humans and AI agents in a desirable way. Using a principled, partially axiomatic approach, we design a parametrizable and decomposable objective function that represents an inequality- and risk-averse long-term aggregate of human power. It takes into account humans' bounded rationality and social norms, and, crucially, considers a wide variety of possible human goals.
  We derive algorithms for computing that metric by backward induction or approximating it via a form of multi-agent reinforcement learning from a given world model. We exemplify the consequences of (softly) maximizing this metric in a variety of paradigmatic situations and describe what instrumental sub-goals it will likely imply. Our cautious assessment is that softly maximizing suitable aggregate metrics of human power might constitute a beneficial objective for agentic AI systems that is safer than direct utility-based objectives.</description>
      <guid isPermaLink="false">oai:arXiv.org:2508.00159v2</guid>
      <category>cs.AI</category>
      <category>cs.CY</category>
      <category>cs.LG</category>
      <category>econ.TH</category>
      <category>math.OC</category>
      <pubDate>Wed, 06 Aug 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Jobst Heitzig, Ram Potham</dc:creator>
    </item>
  </channel>
</rss>
