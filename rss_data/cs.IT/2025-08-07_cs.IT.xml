<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>cs.IT updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/cs.IT</link>
    <description>cs.IT updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/cs.IT" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Fri, 08 Aug 2025 04:03:04 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Fri, 08 Aug 2025 00:00:00 -0400</pubDate>
    <skipDays>
      <day>Sunday</day>
      <day>Saturday</day>
    </skipDays>
    <item>
      <title>Energy Efficient Transmitter Creation by Consuming Free Energy in Molecular Communication</title>
      <link>https://arxiv.org/abs/2508.04805</link>
      <description>arXiv:2508.04805v1 Announce Type: new 
Abstract: Information molecules play a crucial role in molecular communication (MC), acting as carriers for information transfer. A common approach to get information molecules in MC involves harvesting them from the environment; however, the harvested molecules are often a mixture of various environmental molecules, and the initial concentration ratios in the reservoirs are identical, which hampers high-fidelity transmission techniques such as molecular shift keying (MoSK). This paper presents a transmitter design that harvests molecules from the surrounding environment and stores them in two reservoirs. To separate the mixed molecules, energy is consumed to transfer them between reservoirs. Given limited energy resources, this work explores energy-efficient strategies to optimize transmitter performance. Through theoretical analysis and simulations, we investigate different methods for moving molecules between reservoirs. The results demonstrate that transferring higher initial concentration molecules enhances transmitter performance, while using fewer molecules per transfer further improves efficiency. These findings provide valuable insights for optimizing MC systems through energy-efficient molecule transfer techniques.</description>
      <guid isPermaLink="false">oai:arXiv.org:2508.04805v1</guid>
      <category>cs.IT</category>
      <category>math.IT</category>
      <pubDate>Fri, 08 Aug 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Dongliang Jing, Linjuan Li, Zhen Cheng, Lin Lin, Andrew W. Eckford</dc:creator>
    </item>
    <item>
      <title>Energy Efficiency Optimization for Movable Antenna-Aided Communication Systems</title>
      <link>https://arxiv.org/abs/2508.05033</link>
      <description>arXiv:2508.05033v1 Announce Type: new 
Abstract: This paper investigates the energy efficiency optimization for movable antenna (MA) systems by considering the time delay and energy consumption introduced by MA movement. We first derive the upper bound on energy efficiency for a single-user downlink communication system, where the user is equipped with a single MA. Then, the energy efficiency maximization problem is formulated to optimize the MA position, and an efficient algorithm based on successive convex approximation is proposed to solve this non-convex optimization problem. Simulation results show that, despite the overhead caused by MA movement, the MA system can still improve the energy efficiency compared to the conventional fixed-position antenna (FPA) system.</description>
      <guid isPermaLink="false">oai:arXiv.org:2508.05033v1</guid>
      <category>cs.IT</category>
      <category>eess.SP</category>
      <category>math.IT</category>
      <pubDate>Fri, 08 Aug 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Jingze Ding, Zijian Zhou, Yuping Zhao, Bingli Jiao</dc:creator>
    </item>
    <item>
      <title>Two tales for a geometric Jensen--Shannon divergence</title>
      <link>https://arxiv.org/abs/2508.05066</link>
      <description>arXiv:2508.05066v1 Announce Type: new 
Abstract: The geometric Jensen--Shannon divergence (G-JSD) gained popularity in machine learning and information sciences thanks to its closed-form expression between Gaussian distributions. In this work, we introduce an alternative definition of the geometric Jensen--Shannon divergence tailored to positive densities which does not normalize geometric mixtures. This novel divergence is termed the extended G-JSD as it extends to more general positive measures. We give explicitly the gap between the extended G-JSD and G-JSD when considering probability densities, and report both lower and upper bounds in terms of other statistical divergences. We derive corresponding closed-form expressions when considering the case of multivariate Gaussian distributions often met in applications. Finally, we show that these two types of geometric JSDs, the G-JSD and the extended G-JSD, can be interpreted as regularizations of the ordinary JSD by additive terms.</description>
      <guid isPermaLink="false">oai:arXiv.org:2508.05066v1</guid>
      <category>cs.IT</category>
      <category>cs.LG</category>
      <category>math.IT</category>
      <pubDate>Fri, 08 Aug 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Frank Nielsen</dc:creator>
    </item>
    <item>
      <title>Necessity of Block Designs for Optimal Locally Private Distribution Estimation</title>
      <link>https://arxiv.org/abs/2508.05110</link>
      <description>arXiv:2508.05110v1 Announce Type: new 
Abstract: Local differential privacy represents the gold standard for preserving the privacy of data before it leaves the device, and distribution estimation under this model has been well studied. Recently, protocols built upon balanced incomplete block designs were shown to achieve optimal error for this problem. However, it remained unknown whether other constructions could also be optimal. We resolve this question by proving that any protocol achieving optimal error must correspond to some balanced incomplete block design. This result, combined with prior work, completely characterises the set of optimal protocols for this problem. As a consequence, the protocols that achieve optimal error and optimal communication are only those based on symmetrical balanced incomplete block designs.</description>
      <guid isPermaLink="false">oai:arXiv.org:2508.05110v1</guid>
      <category>cs.IT</category>
      <category>cs.CR</category>
      <category>cs.DS</category>
      <category>math.IT</category>
      <pubDate>Fri, 08 Aug 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Abigail Gentle</dc:creator>
    </item>
    <item>
      <title>Neural Estimation of Information Leakage for Secure Communication System Design</title>
      <link>https://arxiv.org/abs/2508.05176</link>
      <description>arXiv:2508.05176v1 Announce Type: new 
Abstract: Underestimating the leakage can compromise secrecy, while overestimating it may lead to inefficient system design. Therefore, a reliable leakage estimator is essential. Neural network-based estimators provide a data-driven way to estimate mutual information without requiring full knowledge of the channel or source distributions. In this work, we aim to scale the blocklength of a wiretap code such that the estimator can still feasibly operate. We propose an improved mutual information estimator based on the variational contrastive log-ration upper bound framework, tailored for both discrete and continuous variables. By using a mixture of Bernoulli experts parameterized by neural networks, the estimator is able to quantify information leakage in communication systems, which employ complex data processing like universal hash family. We further propose a method to utilize the proposed estimator to design the universal hash family for a wiretap code or secret key generation design. Simulation results show thatprior methods significantly underestimate the mutual information, particularly when using universal hash family for higher blocklengths ($n\gg$16). The proposed method can scale the blocklength up to 255, and we conjecture that the design can scale well to even higher blocklengths given adequate training data and model size. Additionally, we contend that our proposed estimator and adaptive hash design framework offer a practical approach for extending physical layer security considerations for wiretap channels into the finite blocklength regime.</description>
      <guid isPermaLink="false">oai:arXiv.org:2508.05176v1</guid>
      <category>cs.IT</category>
      <category>math.IT</category>
      <pubDate>Fri, 08 Aug 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Darius S. Heerklotz, Ingo Schroeder, Pin-Hsun Lin, Christian Deppe, Eduard A. Jorswieck</dc:creator>
    </item>
    <item>
      <title>Simultaneous Rational Function Codes: Improved Analysis Beyond Half the Minimum Distance with Multiplicities and Poles</title>
      <link>https://arxiv.org/abs/2508.05284</link>
      <description>arXiv:2508.05284v1 Announce Type: new 
Abstract: In this paper, we extend the work of Abbondati et al. (2024) on decoding simultaneous rational function codes by addressing two important scenarios: multiplicities and poles (zeros of denominators). First, we generalize previous results to rational codes with multiplicities by considering evaluations with multi-precision. Then, using the hybrid model from Guerrini et al. (2023), we extend our approach to vectors of rational functions that may present poles. Our contributions include: a rigorous analysis of the decoding algorithm's failure probability that generalizes and improves several previous results, an extension to a hybrid model handling situations where not all errors can be assumed random, and a new improved analysis in the more general context handling poles within multiplicities. The theoretical results provide a comprehensive probabilistic analysis of reconstruction failure in these more complex scenarios, advancing the state of the art in error correction for rational function codes.</description>
      <guid isPermaLink="false">oai:arXiv.org:2508.05284v1</guid>
      <category>cs.IT</category>
      <category>cs.SC</category>
      <category>math.IT</category>
      <pubDate>Fri, 08 Aug 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Matteo Abbondati, Eleonora Guerrini, Romain Lebreton</dc:creator>
    </item>
    <item>
      <title>Fundamental limit of Sum Capacity in Pinching Antenna Assisted Multiple Access Channel</title>
      <link>https://arxiv.org/abs/2508.05309</link>
      <description>arXiv:2508.05309v1 Announce Type: new 
Abstract: Pinching antenna systems (PASSs) have recently shown their promising ability to flexibly reconfigure wireless channels via dynamically adjusting the positions of pinching antennas over a dielectric waveguide, termed as pinching beamforming. This paper studies the fundamental limit of the sum capacity for a PASSassisted multiple access channel, in which multiple users transmit individual messages to a BS under the average power constraint. To this end, we consider a dynamic pinching beamforming setup, where multiple pinching beamforming vectors are employed in a transmission period and the capacity-achieving non-orthogonal multiple access (NOMA) based transmission scheme is considered. For the ideal case with an asymptotically large number of pinching beamforming vectors, we unveil that the optimal transmission scheme is alternating transmission among each user with its channel power gain maximized by dynamic pinching beamforming, which implies that the NOMA-based transmission scheme is not needed. The corresponding sum-rate is derived in closed-form expression, which serves as the upper bound of the sum-capacity. Inspired by this result, a lower bound of the sum-rate under an arbitrarily finite number of pinching beamforming vectors is obtained. Numerical results validate our theoretical findings and illustrate the practical significance of using dynamic pinching beamforming to improve the sum capacity.</description>
      <guid isPermaLink="false">oai:arXiv.org:2508.05309v1</guid>
      <category>cs.IT</category>
      <category>math.IT</category>
      <pubDate>Fri, 08 Aug 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Guangji Chen, Qingqing Wu, Kangda Zhi</dc:creator>
    </item>
    <item>
      <title>$\mathbb{F}_{2}\mathbb{F}_{4}$-Additive Complementary Dual Codes</title>
      <link>https://arxiv.org/abs/2508.05317</link>
      <description>arXiv:2508.05317v1 Announce Type: new 
Abstract: In this paper, we investigate the structure and properties of additive complementary dual (ACD) codes over the mixed alphabet $\mathbb{F}_2\mathbb{F}_4$ relative to a certain inner product defined over $\mathbb{F}_2\mathbb{F}_4$. We establish sufficient conditions under which such codes are additive complementary dual (ACD) codes. We also show that ACD codes over $\mathbb{F}_{2}\mathbb{F}_{4}$ can be applied to construct binary linear complementary dual codes as their images under the linear map $W$. Notably, we prove that if the binary image of a code is LCD, then the original code is necessarily ACD. An example is given where the image is a distance-optimal binary LCD code.</description>
      <guid isPermaLink="false">oai:arXiv.org:2508.05317v1</guid>
      <category>cs.IT</category>
      <category>math.IT</category>
      <pubDate>Fri, 08 Aug 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>S. Ouagagui, N. Benbelkacem, A. Batoul, T. Abualrub</dc:creator>
    </item>
    <item>
      <title>On the entropy growth of sums of iid discrete random variables</title>
      <link>https://arxiv.org/abs/2508.05348</link>
      <description>arXiv:2508.05348v1 Announce Type: new 
Abstract: We derive an asymptotic lower bound on the Shannon entropy $H$ of sums of $N$ arbitrary iid discrete random variables. The derived bound $H \geq \frac{r(X)}{2}\log(N) + {\it cst}$ is given in terms of the incommensurability rank $r(X)$ of the random variable -- a positive integer quantity that we introduce. The derivation does not rely on central limit theorems, but builds upon the known expressions of the asymptotic entropy of the multinomial distribution and sums of iid lattice random variables, which correspond to the case $r(X)=1$.</description>
      <guid isPermaLink="false">oai:arXiv.org:2508.05348v1</guid>
      <category>cs.IT</category>
      <category>math.IT</category>
      <pubDate>Fri, 08 Aug 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Riccardo Castellano, Pavel Sekatski</dc:creator>
    </item>
    <item>
      <title>Communication-Efficient Distributed Computing Through Combinatorial Multi-Access Models</title>
      <link>https://arxiv.org/abs/2508.05426</link>
      <description>arXiv:2508.05426v1 Announce Type: new 
Abstract: This paper explores the multi-access distributed computing (MADC) model, a novel distributed computing framework where mapper and reducer nodes are distinct entities. Unlike traditional MapReduce frameworks, MADC leverages coding-theoretic techniques to minimize communication overhead without necessitating file replication across mapper nodes. We introduce a new approach utilizing combinatorial designs, specifically t-designs, to construct efficient coding schemes that achieve a computation load of 1. By establishing a connection between t-designs and MapReduce Arrays, we characterize the achievable communication loads and demonstrate the flexibility of our method in selecting the number of reducer nodes. The proposed scheme significantly reduces the number of reducer nodes relative to existing combinatorial topology schemes, at the expense of increased communication cost.</description>
      <guid isPermaLink="false">oai:arXiv.org:2508.05426v1</guid>
      <category>cs.IT</category>
      <category>math.IT</category>
      <pubDate>Fri, 08 Aug 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Shanuja Sasi, Onur G\"unl\"u</dc:creator>
    </item>
    <item>
      <title>Long Polar vs. LDPC Codes under Complexity-Constrained Decoding</title>
      <link>https://arxiv.org/abs/2508.05485</link>
      <description>arXiv:2508.05485v1 Announce Type: new 
Abstract: The prevailing opinion in industry and academia is that polar codes are competitive for short code lengths, but can no longer keep up with low-density parity-check (LDPC) codes as block length increases. This view is typically based on the assumption that LDPC codes can be decoded with a large number of belief propagation (BP) iterations. However, in practice, the number of iterations may be rather limited due to latency and complexity constraints. In this paper, we show that for a similar number of fixed-point log-likelihood ratio (LLR) operations, long polar codes under successive cancellation (SC) decoding outperform their LDPC counterparts. In particular, simplified successive cancellation (SSC) decoding of polar codes exhibits a better complexity scaling than $N \log{N}$ and requires fewer operations than a single BP iteration of an LDPC code with the same parameters.</description>
      <guid isPermaLink="false">oai:arXiv.org:2508.05485v1</guid>
      <category>cs.IT</category>
      <category>math.IT</category>
      <pubDate>Fri, 08 Aug 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Felix Krieg, Marvin R\"ubenacke, Andreas Zunker, Stephan ten Brink</dc:creator>
    </item>
    <item>
      <title>Multivariate Partial Information Decomposition: Constructions, Inconsistencies, and Alternative Measures</title>
      <link>https://arxiv.org/abs/2508.05530</link>
      <description>arXiv:2508.05530v1 Announce Type: new 
Abstract: While mutual information effectively quantifies dependence between two variables, it cannot capture complex, fine-grained interactions that emerge in multivariate systems.The Partial Information Decomposition (PID) framework was introduced to address this by decomposing the mutual information between a set of source variables and a target variable into fine-grained information atoms such as redundant, unique, and synergistic components. In this work, we review the axiomatic system and desired properties of the PID framework and make three main contributions. First, we resolve the two-source PID case by providing explicit closed-form formulas for all information atoms that satisfy the full set of axioms and desirable properties. Second, we prove that for three or more sources, PID suffers from fundamental inconsistencies: we present a three-variable counterexample where the sum of atoms exceeds the total information, and prove an impossibility theorem showing that no lattice-based decomposition can be consistent for all subsets when the number of sources exceeds three. Finally, we deviate from the PID lattice approach to avoid its inconsistencies, and present explicit measures of multivariate unique and synergistic information. Our proposed measures, which rely on new systems of random variables that eliminate higher-order dependencies, satisfy key axioms such as additivity and continuity, provide a robust theoretical explanation of high-order relations, and show strong numerical performance in comprehensive experiments on the Ising model. Our findings highlight the need for a new framework for studying multivariate information decomposition.</description>
      <guid isPermaLink="false">oai:arXiv.org:2508.05530v1</guid>
      <category>cs.IT</category>
      <category>math.IT</category>
      <pubDate>Fri, 08 Aug 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Aobo Lyu, Andrew Clark, Netanel Raviv</dc:creator>
    </item>
    <item>
      <title>Latency Minimization for Multi-AAV-Enabled ISCC Systems with Movable Antenna</title>
      <link>https://arxiv.org/abs/2508.05574</link>
      <description>arXiv:2508.05574v1 Announce Type: new 
Abstract: This paper investigates an autonomous aerial vehicle (AAV)-enabled integrated sensing, communication, and computation system, with a particular focus on integrating movable antennas (MAs) into the system for enhancing overall system performance. Specifically, multiple MA-enabled AVVs perform sensing tasks and simultaneously transmit the generated computational tasks to the base station for processing. To minimize the maximum latency under the sensing and resource constraints, we formulate an optimization problem that jointly coordinates the position of the MAs, the computation resource allocation, and the transmit beamforming. Due to the non-convexity of the objective function and strong coupling among variables, we propose a two-layer iterative algorithm leveraging particle swarm optimization and convex optimization to address it. The simulation results demonstrate that the proposed scheme achieves significant latency improvements compared to the baseline schemes.</description>
      <guid isPermaLink="false">oai:arXiv.org:2508.05574v1</guid>
      <category>cs.IT</category>
      <category>eess.SP</category>
      <category>math.IT</category>
      <pubDate>Fri, 08 Aug 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Yiyang Chen, Wenchao Liu, Chunjie Wang, Yinyu Wu, Xuhui Zhang, Yanyan Shen</dc:creator>
    </item>
    <item>
      <title>Power and Limitations of Linear Programming Decoder for Quantum LDPC Codes</title>
      <link>https://arxiv.org/abs/2508.04769</link>
      <description>arXiv:2508.04769v1 Announce Type: cross 
Abstract: Decoding quantum error-correcting codes is a key challenge in enabling fault-tolerant quantum computation. In the classical setting, linear programming (LP) decoders offer provable performance guarantees and can leverage fast practical optimization algorithms. Although LP decoders have been proposed for quantum codes, their performance and limitations remain relatively underexplored. In this work, we uncover a key limitation of LP decoding for quantum low-density parity-check (LDPC) codes: certain constant-weight error patterns lead to ambiguous fractional solutions that cannot be resolved through independent rounding. To address this issue, we incorporate a post-processing technique known as ordered statistics decoding (OSD), which significantly enhances LP decoding performance in practice. Our results show that LP decoding, when augmented with OSD, can outperform belief propagation with the same post-processing for intermediate code sizes of up to hundreds of qubits. These findings suggest that LP-based decoders, equipped with effective post-processing, offer a promising approach for decoding near-term quantum LDPC codes.</description>
      <guid isPermaLink="false">oai:arXiv.org:2508.04769v1</guid>
      <category>quant-ph</category>
      <category>cs.IT</category>
      <category>math.IT</category>
      <pubDate>Fri, 08 Aug 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Shouzhen Gu, Mehdi Soleimanifar</dc:creator>
    </item>
    <item>
      <title>Hybrid oscillator-qudit quantum processors: stabilizer states and symplectic operations</title>
      <link>https://arxiv.org/abs/2508.04819</link>
      <description>arXiv:2508.04819v1 Announce Type: cross 
Abstract: We construct stabilizer states and error-correcting codes on combinations of discrete- and continuous-variable systems, generalizing the Gottesman-Kitaev-Preskill (GKP) quantum lattice formalism. Our framework absorbs the discrete phase space of a qudit into a hybrid phase space parameterizable entirely by the continuous variables of a harmonic oscillator. The unit cell of a hybrid quantum lattice grows with the qudit dimension, yielding a way to simultaneously measure an arbitrarily large range of non-commuting position and momentum displacements. Simple hybrid states can be obtained by applying a conditional displacement to a Gottesman-Kitaev-Preskill (GKP) state and a Pauli eigenstate, or by encoding some of the physical qudits of a stabilizer state into a GKP code. The states' oscillator-qudit entanglement cannot be generated using symplectic (i.e., Gaussian-Clifford) operations, distinguishing them as a resource from tensor products of oscillator and qudit stabilizer states. We construct general hybrid error-correcting codes by relating stabilizer codes to non-commutative tori and obtaining logical operators via Morita equivalence. We provide examples using commutation matrices, integer symplectic matrices, and binary codes.</description>
      <guid isPermaLink="false">oai:arXiv.org:2508.04819v1</guid>
      <category>quant-ph</category>
      <category>cs.IT</category>
      <category>math-ph</category>
      <category>math.IT</category>
      <category>math.MP</category>
      <category>math.OA</category>
      <pubDate>Fri, 08 Aug 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Sayan Chakraborty, Victor V. Albert</dc:creator>
    </item>
    <item>
      <title>Federal Reserve Communication and the COVID-19 Pandemic</title>
      <link>https://arxiv.org/abs/2508.04830</link>
      <description>arXiv:2508.04830v1 Announce Type: cross 
Abstract: In this study, we examine the Federal Reserve's communication strategies during the COVID-19 pandemic, comparing them with communication during previous periods of economic stress. Using specialized dictionaries tailored to COVID-19, unconventional monetary policy (UMP), and financial stability, combined with sentiment analysis and topic modeling techniques, we identify a distinct focus in Fed communication during the pandemic on financial stability, market volatility, social welfare, and UMP, characterized by notable contextual uncertainty. Through comparative analysis, we juxtapose the Fed's communication during the COVID-19 crisis with its responses during the dot-com and global financial crises, examining content, sentiment, and timing dimensions. Our findings reveal that Fed communication and policy actions were more reactive to the COVID-19 crisis than to previous crises. Additionally, declining sentiment related to financial stability in interest rate announcements and minutes anticipated subsequent accommodative monetary policy decisions. We further document that communicating about UMP has become the "new normal" for the Fed's Federal Open Market Committee meeting minutes and Chairman's speeches since the Global Financial Crisis, reflecting an institutional adaptation in communication strategy following periods of economic distress. These findings contribute to our understanding of how central bank communication evolves during crises and how communication strategies adapt to exceptional economic circumstances.</description>
      <guid isPermaLink="false">oai:arXiv.org:2508.04830v1</guid>
      <category>econ.GN</category>
      <category>cs.CL</category>
      <category>cs.IT</category>
      <category>math.IT</category>
      <category>q-fin.EC</category>
      <category>stat.AP</category>
      <category>stat.ML</category>
      <pubDate>Fri, 08 Aug 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <arxiv:DOI>10.1111/manc.12520</arxiv:DOI>
      <arxiv:journal_reference>Manchester School, 93(5), 2025, 464-484</arxiv:journal_reference>
      <dc:creator>Jonathan Benchimol, Sophia Kazinnik, Yossi Saadon</dc:creator>
    </item>
    <item>
      <title>Provable Post-Training Quantization: Theoretical Analysis of OPTQ and Qronos</title>
      <link>https://arxiv.org/abs/2508.04853</link>
      <description>arXiv:2508.04853v1 Announce Type: cross 
Abstract: Post-training quantization (PTQ) has become a crucial tool for reducing the memory and compute costs of modern deep neural networks, including large language models (LLMs). Among PTQ algorithms, the OPTQ framework-also known as GPTQ-has emerged as a leading method due to its computational efficiency and strong empirical performance. Despite its widespread adoption, however, OPTQ lacks rigorous quantitative theoretical guarantees. This paper presents the first quantitative error bounds for both deterministic and stochastic variants of OPTQ, as well as for Qronos, a recent related state-of-the-art PTQ algorithm. We analyze how OPTQ's iterative procedure induces quantization error and derive non-asymptotic 2-norm error bounds that depend explicitly on the calibration data and a regularization parameter that OPTQ uses. Our analysis provides theoretical justification for several practical design choices, including the widely used heuristic of ordering features by decreasing norm, as well as guidance for selecting the regularization parameter. For the stochastic variant, we establish stronger infinity-norm error bounds, which enable control over the required quantization alphabet and are particularly useful for downstream layers and nonlinearities. Finally, we extend our analysis to Qronos, providing new theoretical bounds, for both its deterministic and stochastic variants, that help explain its empirical advantages.</description>
      <guid isPermaLink="false">oai:arXiv.org:2508.04853v1</guid>
      <category>cs.LG</category>
      <category>cs.AI</category>
      <category>cs.IT</category>
      <category>cs.NA</category>
      <category>math.IT</category>
      <category>math.NA</category>
      <pubDate>Fri, 08 Aug 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Haoyu Zhang, Shihao Zhang, Ian Colbert, Rayan Saab</dc:creator>
    </item>
    <item>
      <title>Anti-Jamming Sensing with Distributed Reconfigurable Intelligent Metasurface Antennas</title>
      <link>https://arxiv.org/abs/2508.04964</link>
      <description>arXiv:2508.04964v1 Announce Type: cross 
Abstract: The utilization of radio frequency (RF) signals for wireless sensing has garnered increasing attention. However, the radio environment is unpredictable and often unfavorable, the sensing accuracy of traditional RF sensing methods is often affected by adverse propagation channels from the transmitter to the receiver, such as fading and noise. In this paper, we propose employing distributed Reconfigurable Intelligent Metasurface Antennas (RIMSA) to detect the presence and location of objects where multiple RIMSA receivers (RIMSA Rxs) are deployed on different places. By programming their beamforming patterns, RIMSA Rxs can enhance the quality of received signals. The RF sensing problem is modeled as a joint optimization problem of beamforming pattern and mapping of received signals to sensing outcomes. To address this challenge, we introduce a deep reinforcement learning (DRL) algorithm aimed at calculating the optimal beamforming patterns and a neural network aimed at converting received signals into sensing outcomes. In addition, the malicious attacker may potentially launch jamming attack to disrupt sensing process. To enable effective sensing in interferenceprone environment, we devise a combined loss function that takes into account the Signal to Interference plus Noise Ratio (SINR) of the received signals. The simulation results show that the proposed distributed RIMSA system can achieve more efficient sensing performance and better overcome environmental influences than centralized implementation. Furthermore, the introduced method ensures high-accuracy sensing performance even under jamming attack.</description>
      <guid isPermaLink="false">oai:arXiv.org:2508.04964v1</guid>
      <category>eess.SP</category>
      <category>cs.IT</category>
      <category>cs.LG</category>
      <category>math.IT</category>
      <pubDate>Fri, 08 Aug 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Zhaowei Wang, Yunsong Huang, Weicheng Liu, Hui-Ming Wang</dc:creator>
    </item>
    <item>
      <title>A Novel Image Similarity Metric for Scene Composition Structure</title>
      <link>https://arxiv.org/abs/2508.05037</link>
      <description>arXiv:2508.05037v1 Announce Type: cross 
Abstract: The rapid advancement of generative AI models necessitates novel methods for evaluating image quality that extend beyond human perception. A critical concern for these models is the preservation of an image's underlying Scene Composition Structure (SCS), which defines the geometric relationships among objects and the background, their relative positions, sizes, orientations, etc. Maintaining SCS integrity is paramount for ensuring faithful and structurally accurate GenAI outputs. Traditional image similarity metrics often fall short in assessing SCS. Pixel-level approaches are overly sensitive to minor visual noise, while perception-based metrics prioritize human aesthetic appeal, neither adequately capturing structural fidelity. Furthermore, recent neural-network-based metrics introduce training overheads and potential generalization issues. We introduce the SCS Similarity Index Measure (SCSSIM), a novel, analytical, and training-free metric that quantifies SCS preservation by exploiting statistical measures derived from the Cuboidal hierarchical partitioning of images, robustly capturing non-object-based structural relationships. Our experiments demonstrate SCSSIM's high invariance to non-compositional distortions, accurately reflecting unchanged SCS. Conversely, it shows a strong monotonic decrease for compositional distortions, precisely indicating when SCS has been altered. Compared to existing metrics, SCSSIM exhibits superior properties for structural evaluation, making it an invaluable tool for developing and evaluating generative models, ensuring the integrity of scene composition.</description>
      <guid isPermaLink="false">oai:arXiv.org:2508.05037v1</guid>
      <category>cs.CV</category>
      <category>cs.IT</category>
      <category>math.IT</category>
      <pubDate>Fri, 08 Aug 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Md Redwanul Haque, Manzur Murshed, Manoranjan Paul, Tsz-Kwan Lee</dc:creator>
    </item>
    <item>
      <title>Let's Measure Information Step-by-Step: LLM-Based Evaluation Beyond Vibes</title>
      <link>https://arxiv.org/abs/2508.05469</link>
      <description>arXiv:2508.05469v1 Announce Type: cross 
Abstract: We develop mechanisms for evaluating AI systems without ground truth by exploiting a connection between gaming resistance and output quality. The data processing inequality ensures post-hoc attempts to game a metric degrades both information content and task performance. We prove that f-mutual information measures are the unique gaming resistant mechanisms under natural conditions, with the overseer acting as an agent. While Shannon mutual information faces exponential sample complexity, bounded measures like total variation distance remain tractable. Empirically, across ten domains from translation to peer review, all information-theoretic mechanisms achieve perfect discrimination (d &gt; 0.5) between faithful and strategic agents. In contrast, LLM judges exhibit systematic evaluation inversion, preferring fabricated content over accurate summaries. Our mechanisms show 10-100x better robustness to adversarial manipulation than current practices. We also find performance follows an inverted-U curve with compression ratio, peaking at 10:1 where agent responses exhibit optimal information diversity (3 effective dimensions), giving a bias-variance perspective on when our approach is expected to be most effective.</description>
      <guid isPermaLink="false">oai:arXiv.org:2508.05469v1</guid>
      <category>cs.LG</category>
      <category>cs.IT</category>
      <category>math.IT</category>
      <pubDate>Fri, 08 Aug 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Zachary Robertson, Sanmi Koyejo</dc:creator>
    </item>
    <item>
      <title>Linearity of $\mathbb{Z}_{2^L}$-Linear Codes via Schur Product</title>
      <link>https://arxiv.org/abs/2309.12291</link>
      <description>arXiv:2309.12291v4 Announce Type: replace 
Abstract: We propose an innovative approach to investigating the linearity of $\mathbb{Z}_{2^L}$-linear codes derived from $\mathbb{Z}_{2^L}$-additive codes using the generalized Gray map. To achieve this, we define two related binary codes: the associated and the decomposition codes. By considering the Schur product between codewords, we can determine the linearity of the respective $\mathbb{Z}_{2^L}$-linear code. As a result, we establish a connection between the linearity of the $\mathbb{Z}_{2^L}$-linear codes with the linearity of the decomposition code for $\mathbb{Z}_4$ and $\mathbb{Z}_8$-additive codes. Furthermore, we construct $\mathbb{Z}_{2^L}$-additive codes from nested binary codes, resulting in linear $\mathbb{Z}_{2^L}$-linear codes. This construction involves multiple layers of binary codes, where a code in one layer is the square of the code in the previous layer. We also present a sufficient condition that allows checking nonlinearity of the $\mathbb{Z}_{2^L}$-linear codes by simple binary operations in their respective associated codes. Finally, we employ our arguments to verify the linearity of well-known $\mathbb{Z}_{2^L}$-linear code constructions, including the Hadamard, simplex, and MacDonald codes.</description>
      <guid isPermaLink="false">oai:arXiv.org:2309.12291v4</guid>
      <category>cs.IT</category>
      <category>math.IT</category>
      <pubDate>Fri, 08 Aug 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Gustavo T. Bastos, Maiara F. Bollauf, Agnaldo J. Ferrari, {\O}yvind Ytrehus</dc:creator>
    </item>
    <item>
      <title>Modelling and Performance Analysis of Non-Primary Channel Access in Wi-Fi Networks</title>
      <link>https://arxiv.org/abs/2504.15774</link>
      <description>arXiv:2504.15774v2 Announce Type: replace-cross 
Abstract: This paper aims to improve our understanding of the performance of the Non-Primary Channel Access (NPCA) mechanism, a new feature introduced in IEEE 802.11bn to enhance spectrum utilization in Wi-Fi networks. NPCA enables devices to contend for and transmit on the secondary channel when the primary channel is occupied by transmissions from an Overlapping Basic Service Set (OBSS). We develop a Continuous-Time Markov Chain (CTMC) model that captures the interactions among OBSSs in dense Wireless Local Area Network (WLAN) environments when NPCA is enabled, incorporating new NPCA-specific states and transitions. In addition to the analytical insights offered by the model, we conduct numerical evaluations and simulations to quantify NPCA's impact on throughput and channel access delay across various scenarios. Our results show that NPCA can significantly improve throughput and reduce access delays in favorable conditions for BSSs that support the mechanism. Moreover, NPCA helps mitigate the OBSS performance anomaly, where low-rate OBSS transmissions degrade network performance for all nearby devices. However, we also observe trade-offs: NPCA may increase contention on secondary channels, potentially reducing transmission opportunities for BSSs operating there. Overall, the proposed modeling approach offers a foundation for analyzing, optimizing, and guiding the development of NPCA in next-generation Wi-Fi networks.</description>
      <guid isPermaLink="false">oai:arXiv.org:2504.15774v2</guid>
      <category>cs.NI</category>
      <category>cs.IT</category>
      <category>eess.SP</category>
      <category>math.IT</category>
      <pubDate>Fri, 08 Aug 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Boris Bellalta, Francesc Wilhelmi, Lorenzo Galati-Giordano, Giovanni Geraci</dc:creator>
    </item>
    <item>
      <title>CB-cPIR: Code-Based Computational Private Information Retrieval</title>
      <link>https://arxiv.org/abs/2505.03407</link>
      <description>arXiv:2505.03407v2 Announce Type: replace-cross 
Abstract: A private information retrieval (PIR) scheme is a protocol that allows a user to retrieve a file from a database without revealing the identity of the desired file to a curious database. Given a distributed data storage system, efficient PIR can be achieved by making assumptions about the colluding capabilities of the storage servers holding the database. If these assumptions turn out to be incorrect, privacy is lost. In this work, we focus on the worst-case assumption: full collusion or, equivalently, viewing the storage system virtually as a single honest-but-curious server. We present CB-cPIR, a single-server code-based computational private information retrieval (cPIR) scheme that derives security from code-based cryptography. Specifically, the queries are protected by the hardness of decoding a random linear code. The scheme is heavily inspired by the pioneering code-based cPIR scheme proposed by Holzbaur, Hollanti, and Wachter-Zeh in [Holzbaur et al., "Computational Code-Based Single-Server Private Information Retrieval", 2020 IEEE ISIT] and fixes the vulnerabilities of the original scheme arising from highly probable rank differences in submatrices of the user's query. Recently, a new vulnerability was observed in [Lage, Bartz, "On the Security of a Code-Based PIR Scheme"], a simple modification to the scheme now fixes this vulnerability. For further validation of our scheme, we draw comparisons to the state-of-the-art lattice-based cPIR schemes.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.03407v2</guid>
      <category>cs.IR</category>
      <category>cs.IT</category>
      <category>math.IT</category>
      <pubDate>Fri, 08 Aug 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Camilla Hollanti, Neehar Verma</dc:creator>
    </item>
  </channel>
</rss>
