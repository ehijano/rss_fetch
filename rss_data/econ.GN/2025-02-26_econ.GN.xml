<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>econ.GN updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/econ.GN</link>
    <description>econ.GN updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/econ.GN" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Thu, 27 Feb 2025 02:53:28 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Wed, 26 Feb 2025 00:00:00 -0500</pubDate>
    <skipDays>
      <day>Saturday</day>
      <day>Sunday</day>
    </skipDays>
    <item>
      <title>Enhancing External Validity of Experiments with Ongoing Sampling</title>
      <link>https://arxiv.org/abs/2502.18253</link>
      <description>arXiv:2502.18253v1 Announce Type: new 
Abstract: Participants in online experiments often enroll over time, which can compromise sample representativeness due to temporal shifts in covariates. This issue is particularly critical in A/B tests, online controlled experiments extensively used to evaluate product updates, since these tests are cost-sensitive and typically short in duration. We propose a novel framework that dynamically assesses sample representativeness by dividing the ongoing sampling process into three stages. We then develop stage-specific estimators for Population Average Treatment Effects (PATE), ensuring that experimental results remain generalizable across varying experiment durations. Leveraging survival analysis, we develop a heuristic function that identifies these stages without requiring prior knowledge of population or sample characteristics, thereby keeping implementation costs low. Our approach bridges the gap between experimental findings and real-world applicability, enabling product decisions to be based on evidence that accurately represents the broader target population. We validate the effectiveness of our framework on three levels: (1) through a real-world online experiment conducted on WeChat; (2) via a synthetic experiment; and (3) by applying it to 600 A/B tests on WeChat in a platform-wide application. Additionally, we provide practical guidelines for practitioners to implement our method in real-world settings.</description>
      <guid isPermaLink="false">oai:arXiv.org:2502.18253v1</guid>
      <category>econ.GN</category>
      <category>q-fin.EC</category>
      <category>stat.AP</category>
      <pubDate>Wed, 26 Feb 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-sa/4.0/</dc:rights>
      <dc:creator>Chen Wang, Shichao Han, Shan Huang</dc:creator>
    </item>
    <item>
      <title>The effect of minimum wages on employment in the presence of productivity fluctuations</title>
      <link>https://arxiv.org/abs/2502.18261</link>
      <description>arXiv:2502.18261v2 Announce Type: new 
Abstract: Traditionally, the impact of minimum wages on employment has been studied, and it is generally believed to have a negative effect. Yet, some recent studies have shown that the impact of minimum wages on employment can sometimes be positive. In addition, certain recent proposals set a higher minimum wage than the wage earned by some high-productivity workers. However, the impact of minimum wages on employment has been primarily studied on low-skilled workers, whereas there is limited research on high-skilled workers. To address this gap and examine the effects of minimum wages on high-productivity workers' employment, I construct a macroeconomic model incorporating productivity fluctuations, incomplete markets, directed search, and on-the-job search and compare the steady-state distributions between the baseline model and the model with a minimum wage. As a result, binding minimum wages increase the unemployment rate of both low and high-productivity workers.</description>
      <guid isPermaLink="false">oai:arXiv.org:2502.18261v2</guid>
      <category>econ.GN</category>
      <category>q-fin.EC</category>
      <pubDate>Wed, 26 Feb 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Asahi Sato</dc:creator>
    </item>
    <item>
      <title>Escaping the Subprime Trap in Algorithmic Lending</title>
      <link>https://arxiv.org/abs/2502.17816</link>
      <description>arXiv:2502.17816v1 Announce Type: cross 
Abstract: Disparities in lending to minority applicants persist even as algorithmic lending practices proliferate. Further, disparities in interest rates charged can remain large even when loan applicants from different groups are equally creditworthy. We study the role of risk-management constraints, specifically Value-at-Risk (VaR) constraints, in the persistence of segregation in loan approval decisions. We develop a formal model in which a mainstream (low-interest) bank is more sensitive to variance risk than a subprime (high-interest) bank. If the mainstream bank has an inflated prior belief about the variance of the minority group, it may deny that group credit indefinitely, thus never learning the true risk of lending to that group, while the subprime lender serves this population at higher rates. We formalize this as a "subprime trap" equilibrium. Finally, we show that a small, finite subsidy (or partial guarantee) can help minority groups escape the trap by covering enough of the mainstream bank's downside so that it can afford to lend and learn the minority group's true risk. Once it has sufficiently many data points, it meets its VaR requirement with no further assistance, minority groups are approved for loans by the mainstream bank, and competition drives down the interest rates of subprime lenders.</description>
      <guid isPermaLink="false">oai:arXiv.org:2502.17816v1</guid>
      <category>cs.CY</category>
      <category>econ.GN</category>
      <category>q-fin.EC</category>
      <pubDate>Wed, 26 Feb 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Adam Bouyamourn, Alexander Williams Tolbert</dc:creator>
    </item>
    <item>
      <title>Exactly solvable model of the square-root price impact dynamics under the long-range market-order correlation</title>
      <link>https://arxiv.org/abs/2502.17906</link>
      <description>arXiv:2502.17906v1 Announce Type: cross 
Abstract: In econophysics, there are two enigmatic empirical laws: (i) Due to the order-splitting behavior by institutional traders, the market-order flow has strong and predictable persistence (called the long-range order-sign correlation $C_\tau\propto \tau^{-\alpha-1}$ with $1&lt;\alpha&lt;2$), well formulated as the Lillo-Mike-Farmer model. This phenomenon seems contradictory against the diffusive and unpredictable price dynamics. (ii) The price impact $I(Q)$ by a large metaorder $Q$ has strong nonlinearlity called the the square-root law, $I(Q)\propto \sqrt{Q}$. In this Letter, we propose an exactly solvable model of the price impact dynamics unifying these two empirical laws. We generalize the Lillo-Mike-Farmer model naturally toward the nonliner price impact dynamics: All traders are assumed to be order splitters and their price impact obeys the nonlinear scaling $I(Q)\propto Q^{\delta}$. This model is mapped to the exactly solvable L\'evy-walk model with nonlinear walking speed. Our exact solution shows that the price dynamics is shown always diffusive for $\delta=1/2$ even in the presence of order splitters. Our results suggest that the square-root law plays a crucial role in mitigating large price movements in the presence of order splitters, thereby leading to normal diffusive price dynamics, which aligns with the efficient market hypothesis over long timescales.</description>
      <guid isPermaLink="false">oai:arXiv.org:2502.17906v1</guid>
      <category>q-fin.TR</category>
      <category>cond-mat.stat-mech</category>
      <category>econ.GN</category>
      <category>q-fin.EC</category>
      <category>q-fin.MF</category>
      <category>q-fin.PR</category>
      <pubDate>Wed, 26 Feb 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Yuki Sato, Kiyoshi Kanazawa</dc:creator>
    </item>
    <item>
      <title>Parallel Execution Fee Mechanisms</title>
      <link>https://arxiv.org/abs/2410.09555</link>
      <description>arXiv:2410.09555v2 Announce Type: replace 
Abstract: This paper investigates how pricing schemes can achieve efficient allocations in blockchain systems featuring multiple transaction queues under a global capacity constraint. I model a capacity-constrained blockchain where users submit transactions to different queues -- each representing a submarket with unique demand characteristics -- and decide to participate based on posted prices and expected delays. I find that revenue maximization tends to allocate capacity to the highest-paying queue, whereas welfare maximization generally serves all queues. Optimal relative pricing of different queues depends on factors such as market size, demand elasticity, and the balance between local and global congestion. My results have implications for the implementation of local congestion pricing for evolving blockchain architectures, including parallel transaction execution, directed acyclic graph (DAG)-based systems, and multiple concurrent proposers.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.09555v2</guid>
      <category>econ.GN</category>
      <category>math.OC</category>
      <category>q-fin.EC</category>
      <pubDate>Wed, 26 Feb 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Abdoulaye Ndiaye</dc:creator>
    </item>
    <item>
      <title>Complement or substitute? How AI increases the demand for human skills</title>
      <link>https://arxiv.org/abs/2412.19754</link>
      <description>arXiv:2412.19754v3 Announce Type: replace 
Abstract: This paper examines whether artificial intelligence (AI) acts as a substitute or complement to human labour, drawing on 12 million online job vacancies from the United States spanning 2018-2023. We adopt a two-pronged approach: first, analysing "internal effects" within roles explicitly requiring AI, and second, investigating "external effects" that arise when industries, occupations, and regions experience increases in AI demand. Our focus centres on whether complementary skills-such as digital literacy, teamwork, resilience, agility, or analytical thinking-become more prevalent and valuable as AI adoption grows. Results show that AI-focused roles are nearly twice as likely to require skills like resilience, agility, or analytical thinking compared to non-AI roles. Furthermore, these skills command a significant wage premium; data scientists, for instance, are offered 5-10% higher salaries if they also possess resilience or ethics capabilities. We observe positive spillover effects: a doubling of AI-specific demand across industries correlates with a 5% increase in demand for complementary skills, even outside AI-related roles. Conversely, tasks vulnerable to AI substitution, such as basic data skills or translation, exhibit modest declines in demand. However, the external effect is clearly net positive: Complementary effects are up to 1.7x larger than substitution effects. These results are consistent across economies, including the United Kingdom and Australia. Our findings highlight the necessity of reskilling workers in areas where human expertise remains increasingly valuable and ensuring workers can effectively complement and leverage emerging AI technologies.</description>
      <guid isPermaLink="false">oai:arXiv.org:2412.19754v3</guid>
      <category>econ.GN</category>
      <category>cs.AI</category>
      <category>q-fin.EC</category>
      <pubDate>Wed, 26 Feb 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Elina M\"akel\"a, Fabian Stephany</dc:creator>
    </item>
    <item>
      <title>Utility-inspired Reward Transformations Improve Reinforcement Learning Training of Language Models</title>
      <link>https://arxiv.org/abs/2501.06248</link>
      <description>arXiv:2501.06248v2 Announce Type: replace-cross 
Abstract: Current methods that train large language models (LLMs) with reinforcement learning feedback, often resort to averaging outputs of multiple rewards functions during training. This overlooks crucial aspects of individual reward dimensions and inter-reward dependencies that can lead to sub-optimal outcomes in generations. In this work, we show how linear aggregation of rewards exhibits some vulnerabilities that can lead to undesired properties of generated text. We then propose a transformation of reward functions inspired by economic theory of utility functions (specifically Inada conditions), that enhances sensitivity to low reward values while diminishing sensitivity to already high values. We compare our approach to the existing baseline methods that linearly aggregate rewards and show how the Inada-inspired reward feedback is superior to traditional weighted averaging. We quantitatively and qualitatively analyse the difference in the methods, and see that models trained with Inada-transformations score as more helpful while being less harmful.</description>
      <guid isPermaLink="false">oai:arXiv.org:2501.06248v2</guid>
      <category>cs.LG</category>
      <category>cs.AI</category>
      <category>cs.CL</category>
      <category>econ.GN</category>
      <category>q-fin.EC</category>
      <pubDate>Wed, 26 Feb 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Roberto-Rafael Maura-Rivero, Chirag Nagpal, Roma Patel, Francesco Visin</dc:creator>
    </item>
  </channel>
</rss>
