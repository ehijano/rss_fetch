<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>cs.CG updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/cs.CG</link>
    <description>cs.CG updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/cs.CG" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Thu, 30 May 2024 04:00:11 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Thu, 30 May 2024 00:00:00 -0400</pubDate>
    <skipDays>
      <day>Saturday</day>
      <day>Sunday</day>
    </skipDays>
    <item>
      <title>Minimum Strict Consistent Subset in Paths, Spiders, Combs and Trees</title>
      <link>https://arxiv.org/abs/2405.18569</link>
      <description>arXiv:2405.18569v1 Announce Type: new 
Abstract: In a connected simple graph G = (V,E), each vertex of V is colored by a color from the set of colors C={c_1, c_2,..., c_{\alpha}}. We take a subset S of V, such that for every vertex v in V\S, at least one vertex of the same color is present in its set of nearest neighbors in S. We refer to such a S as a consistent subset (CS) The Minimum Consistent Subset (MCS) problem is the computation of a consistent subset of the minimum size. It is established that MCS is NP-complete for general graphs, including planar graphs. We expand our study to interval graphs and circle graphs in an attempt to gain a complete understanding of the computational complexity of the MCS problem across various graph classes. The strict consistent subset is a variant of consistent subset problems. We take a subset S^{\prime} of V, such that for every vertex v in V\S^{\prime}, all the vertices in its set of nearest neighbors in S have the same color as v. We refer to such a S^{\prime} as a strict consistent subset (SCS). The Minimum Strict Consistent Subset (MSCS) problem is the computation of a consistent subset of the minimum size.
  We demonstrate that MSCS is NP-hard in general graphs. We show a 2-approximation in trees. Later, we show polynomial-time algorithms in trees. Later, we demonstrate faster polynomial-time algorithms in paths, spiders, and combs.</description>
      <guid isPermaLink="false">oai:arXiv.org:2405.18569v1</guid>
      <category>cs.CG</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Bubai Manna</dc:creator>
    </item>
    <item>
      <title>Geometric Bipartite Matching is in NC</title>
      <link>https://arxiv.org/abs/2405.18833</link>
      <description>arXiv:2405.18833v1 Announce Type: new 
Abstract: In this work, we study the parallel complexity of the Euclidean minimum-weight perfect matching (EWPM) problem. Here our graph is the complete bipartite graph $G$ on two sets of points $A$ and $B$ in $\mathbb{R}^2$ and the weight of each edge is the Euclidean distance between the corresponding points. The weighted perfect matching problem on general bipartite graphs is known to be in RNC [Mulmuley, Vazirani, and Vazirani, 1987], and Quasi-NC [Fenner, Gurjar, and Thierauf, 2016]. Both of these results work only when the weights are of $O(\log n)$ bits. It is a long-standing open question to show the problem to be in NC.
  First, we show that for EWPM, a linear number of bits of approximation is required to distinguish between the minimum-weight perfect matching and other perfect matchings. Next, we show that the EWPM problem that allows up to $\frac{1}{poly(n)}$ additive error, is in NC.</description>
      <guid isPermaLink="false">oai:arXiv.org:2405.18833v1</guid>
      <category>cs.CG</category>
      <category>cs.CC</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Sujoy Bhore, Sarfaraz Equbal, Rohit Gurjar</dc:creator>
    </item>
    <item>
      <title>Navigable Graphs for High-Dimensional Nearest Neighbor Search: Constructions and Limits</title>
      <link>https://arxiv.org/abs/2405.18680</link>
      <description>arXiv:2405.18680v1 Announce Type: cross 
Abstract: There has been significant recent interest in graph-based nearest neighbor search methods, many of which are centered on the construction of navigable graphs over high-dimensional point sets. A graph is navigable if we can successfully move from any starting node to any target node using a greedy routing strategy where we always move to the neighbor that is closest to the destination according to a given distance function. The complete graph is navigable for any point set, but the important question for applications is if sparser graphs can be constructed. While this question is fairly well understood in low-dimensions, we establish some of the first upper and lower bounds for high-dimensional point sets. First, we give a simple and efficient way to construct a navigable graph with average degree $O(\sqrt{n \log n })$ for any set of $n$ points, in any dimension, for any distance function. We compliment this result with a nearly matching lower bound: even under the Euclidean metric in $O(\log n)$ dimensions, a random point set has no navigable graph with average degree $O(n^{\alpha})$ for any $\alpha &lt; 1/2$. Our lower bound relies on sharp anti-concentration bounds for binomial random variables, which we use to show that the near-neighborhoods of a set of random points do not overlap significantly, forcing any navigable graph to have many edges.</description>
      <guid isPermaLink="false">oai:arXiv.org:2405.18680v1</guid>
      <category>cs.DS</category>
      <category>cs.CG</category>
      <category>cs.DB</category>
      <category>cs.LG</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Haya Diwan, Jinrui Gou, Cameron Musco, Christopher Musco, Torsten Suel</dc:creator>
    </item>
    <item>
      <title>Diffeomorphic interpolation for efficient persistence-based topological optimization</title>
      <link>https://arxiv.org/abs/2405.18820</link>
      <description>arXiv:2405.18820v1 Announce Type: cross 
Abstract: Topological Data Analysis (TDA) provides a pipeline to extract quantitative topological descriptors from structured objects. This enables the definition of topological loss functions, which assert to what extent a given object exhibits some topological properties. These losses can then be used to perform topological optimizationvia gradient descent routines. While theoretically sounded, topological optimization faces an important challenge: gradients tend to be extremely sparse, in the sense that the loss function typically depends on only very few coordinates of the input object, yielding dramatically slow optimization schemes in practice.Focusing on the central case of topological optimization for point clouds, we propose in this work to overcome this limitation using diffeomorphic interpolation, turning sparse gradients into smooth vector fields defined on the whole space, with quantifiable Lipschitz constants. In particular, we show that our approach combines efficiently with subsampling techniques routinely used in TDA, as the diffeomorphism derived from the gradient computed on a subsample can be used to update the coordinates of the full input object, allowing us to perform topological optimization on point clouds at an unprecedented scale. Finally, we also showcase the relevance of our approach for black-box autoencoder (AE) regularization, where we aim at enforcing topological priors on the latent spaces associated to fixed, pre-trained, black-box AE models, and where we show thatlearning a diffeomorphic flow can be done once and then re-applied to new data in linear time (while vanilla topological optimization has to be re-run from scratch). Moreover, reverting the flow allows us to generate data by sampling the topologically-optimized latent space directly, yielding better interpretability of the model.</description>
      <guid isPermaLink="false">oai:arXiv.org:2405.18820v1</guid>
      <category>cs.AI</category>
      <category>cs.CG</category>
      <category>math.OC</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Mathieu Carriere (CRISAM), Marc Theveneau (LIGM), Th\'eo Lacombe (LIGM)</dc:creator>
    </item>
  </channel>
</rss>
