<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>cs.DB updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/cs.DB</link>
    <description>cs.DB updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/cs.DB" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Tue, 15 Oct 2024 04:00:33 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Tue, 15 Oct 2024 00:00:00 -0400</pubDate>
    <skipDays>
      <day>Sunday</day>
      <day>Saturday</day>
    </skipDays>
    <item>
      <title>Using off-the-shelf LLMs to query enterprise data by progressively revealing ontologies</title>
      <link>https://arxiv.org/abs/2410.09244</link>
      <description>arXiv:2410.09244v1 Announce Type: new 
Abstract: Ontologies are known to improve the accuracy of Large Language Models (LLMs) when translating natural language queries into a formal query language like SQL or SPARQL. There are two ways to leverage ontologies when working with LLMs. One is to fine-tune the model, i.e., to enhance it with specific domain knowledge. Another is the zero-shot prompting approach, where the ontology is provided as part of the input question. Unfortunately, modern enterprises typically have ontologies that are too large to fit in a prompt due to LLM's token size limitations. We present a solution that incrementally reveals "just enough" of an ontology that is needed to answer a given question.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.09244v1</guid>
      <category>cs.DB</category>
      <category>cs.AI</category>
      <pubDate>Tue, 15 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>C. Civili, E. Sherkhonov, R. E. K. Stirewalt</dc:creator>
    </item>
    <item>
      <title>From Text to Databases: attribute grammar as database meta-model</title>
      <link>https://arxiv.org/abs/2410.09441</link>
      <description>arXiv:2410.09441v1 Announce Type: new 
Abstract: We present a general methodology for structuring textual data, represented as syntax trees enriched with semantic information, guided by a meta-model G defined as an attribute grammar. The method involves an evolution process where both the instance and its grammar evolve, with instance transformations guided by rewriting rules and a similarity measure. Each new instance generates a corresponding grammar, culminating in a target grammar GT that satisfies G.
  This methodology is applied to build a database populated from textual data. The process generates both a database schema and its instance, independent of specific database models. We demonstrate the approach using clinical medical cases, where trees represent database instances and grammars act as database schemas. Key contributions include the proposal of a general attribute grammar G, a formalization of grammar evolution, and a proof-of-concept implementation for database structuring.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.09441v1</guid>
      <category>cs.DB</category>
      <pubDate>Tue, 15 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Jacques Chabin, Mirian Halfeld-Ferrari, Nicolas Hiot</dc:creator>
    </item>
    <item>
      <title>The Case for DBMS Live Patching [Extended Version]</title>
      <link>https://arxiv.org/abs/2410.09925</link>
      <description>arXiv:2410.09925v1 Announce Type: new 
Abstract: Traditionally, when the code of a database management system (DBMS) needs to be updated, the system is restarted and database clients suffer downtime, or the provider instantiates hot-standby instances and rolls over the workload. We investigate a third option, live patching of the DBMS binary. For certain code changes, live patching allows to modify the application code in memory, without restart. The memory state and all client connections can be maintained. Although live patching has been explored in the operating systems research community, it remains a blind spot in DBMS research. In this Experiment, Analysis &amp; Benchmark article, we systematically explore this field from the DBMS perspective. We discuss what distinguishes database management systems from generic multi-threaded applications when it comes to live patching. We then propose domain-specific strategies for injecting quiescence points into the DBMS source code, so that threads can safely migrate to the patched process version. We experimentally investigate the interplay between the query workload and different quiescence methods, monitoring both transaction throughput and tail latencies. We show that live patching can be a viable option for updating database management systems, since database providers can make informed decisions w.r.t. the latency overhead on the client side.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.09925v1</guid>
      <category>cs.DB</category>
      <pubDate>Tue, 15 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Michael Fruth, Stefanie Scherzinger</dc:creator>
    </item>
    <item>
      <title>Data Modeling for Connected Data -- A systematic literature review</title>
      <link>https://arxiv.org/abs/2410.10081</link>
      <description>arXiv:2410.10081v1 Announce Type: new 
Abstract: A data model specifies how real-world entities and their relationships are represented and operated. In the NoSQL world data modeling usually begins from identifying application queries and designing the data model to efficiently answer them so each database is designed to meet requirements of just one or more applications. But this practice causes a strong coupling between the data model and application queries and promotes data silos. Newly developed applications that manipulate connected data, usually stored in NoSQL Graph Databases, suffer from this type of problem, which is a challenge for data integration projects in Big Data scenarios. This systematic literature review (SLR) was carried out to identify the known approaches for data modeling of connected data. The main contribution of this SLR is an analysis of sixteen works, from 2013 to 2020, in terms of three dimensions: type of contribution, bibliometrics, and data modeling characteristics. Through this analysis, it was possible to identify that reverse engineering of connected data is still a research opportunity since few and incomplete works were found.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.10081v1</guid>
      <category>cs.DB</category>
      <pubDate>Tue, 15 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Veronica Santos</dc:creator>
    </item>
    <item>
      <title>Evaluating SQL Understanding in Large Language Models</title>
      <link>https://arxiv.org/abs/2410.10680</link>
      <description>arXiv:2410.10680v1 Announce Type: new 
Abstract: The rise of large language models (LLMs) has significantly impacted various domains, including natural language processing (NLP) and image generation, by making complex computational tasks more accessible. While LLMs demonstrate impressive generative capabilities, there is an ongoing debate about their level of "understanding," particularly in structured domains like SQL. In this paper, we evaluate the extent to which LLMs "understand" SQL by testing them on a series of key SQL tasks. These tasks, such as syntax error detection, missing token identification, query performance prediction, query equivalence checking, and query explanation, assess the models' proficiency in recognition, context awareness, semantics, and coherence, which are essential skills for SQL understanding. We generate labeled datasets from well-known workloads, and evaluate the latest LLMs, focusing on how query complexity and syntactic features influence performance. Our results indicate that while GPT4 excels at tasks requiring recognition and context, all models struggle with deeper semantic understanding and coherence, especially in query equivalence and performance estimation, revealing the limitations of current LLMs in achieving full SQL comprehension.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.10680v1</guid>
      <category>cs.DB</category>
      <pubDate>Tue, 15 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Ananya Rahaman, Anny Zheng, Mostafa Milani, Fei Chiang, Rachel Pottinger</dc:creator>
    </item>
    <item>
      <title>QUIS: Question-guided Insights Generation for Automated Exploratory Data Analysis</title>
      <link>https://arxiv.org/abs/2410.10270</link>
      <description>arXiv:2410.10270v1 Announce Type: cross 
Abstract: Discovering meaningful insights from a large dataset, known as Exploratory Data Analysis (EDA), is a challenging task that requires thorough exploration and analysis of the data. Automated Data Exploration (ADE) systems use goal-oriented methods with Large Language Models and Reinforcement Learning towards full automation. However, these methods require human involvement to anticipate goals that may limit insight extraction, while fully automated systems demand significant computational resources and retraining for new datasets. We introduce QUIS, a fully automated EDA system that operates in two stages: insight generation (ISGen) driven by question generation (QUGen). The QUGen module generates questions in iterations, refining them from previous iterations to enhance coverage without human intervention or manually curated examples. The ISGen module analyzes data to produce multiple relevant insights in response to each question, requiring no prior training and enabling QUIS to adapt to new datasets.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.10270v1</guid>
      <category>cs.AI</category>
      <category>cs.CL</category>
      <category>cs.DB</category>
      <category>cs.LG</category>
      <pubDate>Tue, 15 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Abhijit Manatkar, Ashlesha Akella, Parthivi Gupta, Krishnasuri Narayanam</dc:creator>
    </item>
    <item>
      <title>Benchmarking Analytical Query Processing in Intel SGXv2</title>
      <link>https://arxiv.org/abs/2403.11874</link>
      <description>arXiv:2403.11874v3 Announce Type: replace 
Abstract: Trusted Execution Environments (TEEs), such as Intel's Software Guard Extensions (SGX), are increasingly being adopted to address trust and compliance issues in the public cloud. Intel SGX's second generation (SGXv2) addresses many limitations of its predecessor (SGXv1), offering the potential for secure and efficient analytical cloud DBMSs. We assess this potential and conduct the first in-depth evaluation study of analytical query processing algorithms inside SGXv2. Our study reveals that, unlike SGXv1, state-of-the-art algorithms like radix joins and SIMD-based scans are a good starting point for achieving high-performance query processing inside SGXv2. However, subtle hardware and software differences still influence code execution inside SGX enclaves and cause substantial overheads. We investigate these differences and propose new optimizations to bring the performance inside enclaves on par with native code execution outside enclaves.</description>
      <guid isPermaLink="false">oai:arXiv.org:2403.11874v3</guid>
      <category>cs.DB</category>
      <pubDate>Tue, 15 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Adrian Lutsch (Technical University of Darmstadt), Muhammad El-Hindi (Technical University of Darmstadt), Matthias Heinrich (Technical University of Darmstadt), Daniel Ritter (SAP SE), Zsolt Istv\'an (Technical University of Darmstadt), Carsten Binnig (Technical University of Darmstadt, DFKI)</dc:creator>
    </item>
    <item>
      <title>EdgeMiner: Distributed Process Mining at the Data Sources</title>
      <link>https://arxiv.org/abs/2405.03426</link>
      <description>arXiv:2405.03426v4 Announce Type: replace 
Abstract: Process mining is moving beyond mining traditional event logs and nowadays includes, for example, data sourced from sensors in the Internet of Things (IoT). The volume and velocity of data generated by such sensors makes it increasingly challenging to efficiently process the data by traditional process discovery algorithms, which operate on a centralized event log. This paper presents EdgeMiner, an algorithm for distributed process mining operating directly on sensor nodes on a stream of real-time event data. In contrast to centralized algorithms, EdgeMiner tracks each event and its predecessor and successor events directly on the sensor node where the event is sensed and recorded. As EdgeMiner aggregates direct successions on the individual nodes, the raw data does not need to be stored centrally, thus improving both scalability and privacy. We analytically and experimentally show the correctness of EdgeMiner. In addition, our evaluation results show that EdgeMiner determines predecessors for each event efficiently, reducing the communication overhead by up to 96% compared to querying all nodes. Further, we show that the number of queried nodes stabilizes after relatively few events, and batching predecessor queries in groups reduces the average queried nodes per event to less than 2.5%.</description>
      <guid isPermaLink="false">oai:arXiv.org:2405.03426v4</guid>
      <category>cs.DB</category>
      <category>cs.DC</category>
      <pubDate>Tue, 15 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Julia Andersen, Patrick Rathje, Christian Imenkamp, Agnes Koschmider, Olaf Landsiedel</dc:creator>
    </item>
    <item>
      <title>Path-based Algebraic Foundations of Graph Query Languages</title>
      <link>https://arxiv.org/abs/2407.04823</link>
      <description>arXiv:2407.04823v2 Announce Type: replace 
Abstract: Graph databases are gaining momentum thanks to the flexibility and expressiveness of their data models and query languages. A standardization activity driven by the ISO/IEC standardization body is also ongoing and has already conducted to the specification of the first versions of two standard graph query languages, namely SQL/PGQ and GQL, respectively in 2023 and 2024. Apart from the standards, there exists a panoply of concrete graph query languages provided by current graph database systems, each offering different query features. A common limitation of current graph query engines is the absence of an algebraic approach for evaluating path queries. To address this, we introduce an abstract algebra for evaluating path queries, allowing paths to be treated as first-class entities within the query processing pipeline. We demonstrate that our algebra can express a core fragment of path queries defined in GQL and SQL/PGQ, thereby serving as a formal framework for studying both standards and supporting their implementation in current graph database systems. We also show that evaluation trees for path algebra expressions can function as logical plans for evaluating path queries and enable the application of query optimization techniques. Our algebraic framework has the potential to act as a lingua franca for path query evaluation, enabling different implementations to be expressed and compared.</description>
      <guid isPermaLink="false">oai:arXiv.org:2407.04823v2</guid>
      <category>cs.DB</category>
      <pubDate>Tue, 15 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Renzo Angles, Angela Bonifati, Roberto Garc\'ia, Domagoj Vrgo\v{c}</dc:creator>
    </item>
  </channel>
</rss>
