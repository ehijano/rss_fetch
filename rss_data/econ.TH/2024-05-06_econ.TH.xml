<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>econ.TH updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/econ.TH</link>
    <description>econ.TH updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/econ.TH" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Mon, 06 May 2024 04:00:08 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Mon, 06 May 2024 00:00:00 -0400</pubDate>
    <skipDays>
      <day>Saturday</day>
      <day>Sunday</day>
    </skipDays>
    <item>
      <title>Manipulation of Belief Aggregation Rules</title>
      <link>https://arxiv.org/abs/2405.01655</link>
      <description>arXiv:2405.01655v1 Announce Type: new 
Abstract: This paper studies manipulation of belief aggregation rules in the setting where the society first collects individual's probabilistic opinions and then solves a public portfolio choice problem with common utility based on the aggregate belief.
  First, we show that belief reporting in Nash equilibrium under the linear opinion pool and log utility is identified as the profile of state-contingent wealth shares in parimutuel equilibrium with risk-neutral preference.
  Then we characterize belief aggregation rules which are Nash-implementable. We provide a necessary and essentially sufficient condition for implementability, which is independent of the common risk attitude.</description>
      <guid isPermaLink="false">oai:arXiv.org:2405.01655v1</guid>
      <category>econ.TH</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Christopher P. Chambers, Federico Echenique, Takashi Hayashi</dc:creator>
    </item>
    <item>
      <title>Learning to Persuade on the Fly: Robustness Against Ignorance</title>
      <link>https://arxiv.org/abs/2102.10156</link>
      <description>arXiv:2102.10156v2 Announce Type: replace-cross 
Abstract: Motivated by information sharing in online platforms, we study repeated persuasion between a sender and a stream of receivers where at each time, the sender observes a payoff-relevant state drawn independently and identically from an unknown distribution, and shares state information with the receivers who each choose an action. The sender seeks to persuade the receivers into taking actions aligned with the sender's preference by selectively sharing state information. However, in contrast to the standard models, neither the sender nor the receivers know the distribution, and the sender has to persuade while learning the distribution on the fly.
  We study the sender's learning problem of making persuasive action recommendations to achieve low regret against the optimal persuasion mechanism with the knowledge of the distribution. To do this, we first propose and motivate a persuasiveness criterion for the unknown distribution setting that centers robustness as a requirement in the face of uncertainty. Our main result is an algorithm that, with high probability, is robustly-persuasive and achieves $O(\sqrt{T\log T})$ regret, where $T$ is the horizon length. Intuitively, at each time our algorithm maintains a set of candidate distributions, and chooses a signaling mechanism that is simultaneously persuasive for all of them. Core to our proof is a tight analysis about the cost of robust persuasion, which may be of independent interest. We further prove that this regret order is optimal (up to logarithmic terms) by showing that no algorithm can achieve regret better than $\Omega(\sqrt{T})$.</description>
      <guid isPermaLink="false">oai:arXiv.org:2102.10156v2</guid>
      <category>cs.GT</category>
      <category>cs.LG</category>
      <category>econ.TH</category>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>You Zu, Krishnamurthy Iyer, Haifeng Xu</dc:creator>
    </item>
    <item>
      <title>Causal Effects in Matching Mechanisms with Strategically Reported Preferences</title>
      <link>https://arxiv.org/abs/2307.14282</link>
      <description>arXiv:2307.14282v2 Announce Type: replace-cross 
Abstract: A growing number of central authorities use assignment mechanisms to allocate students to schools in a way that reflects student preferences and school priorities. However, most real-world mechanisms incentivize students to strategically misreport their preferences. In this paper, we provide an approach for identifying the causal effects of school assignment on future outcomes that accounts for strategic misreporting. Misreporting may invalidate existing point-identification approaches, and we derive sharp bounds for causal effects that are robust to strategic behavior. Our approach applies to any mechanism as long as there exist placement scores and cutoffs that characterize that mechanism's allocation rule. We use data from a deferred acceptance mechanism that assigns students to more than 1,000 university-major combinations in Chile. Matching theory predicts that students' behavior in Chile should be strategic because they can list only up to eight options, and we find empirical evidence consistent with such behavior. Our bounds are informative enough to reveal significant heterogeneity in graduation success with respect to preferences and school assignment.</description>
      <guid isPermaLink="false">oai:arXiv.org:2307.14282v2</guid>
      <category>econ.EM</category>
      <category>econ.TH</category>
      <category>stat.ME</category>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Marinho Bertanha, Margaux Luflade, Ismael Mourifi\'e</dc:creator>
    </item>
  </channel>
</rss>
