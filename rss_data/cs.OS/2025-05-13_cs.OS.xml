<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>cs.OS updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/cs.OS</link>
    <description>cs.OS updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/cs.OS" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Tue, 13 May 2025 04:00:17 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Tue, 13 May 2025 00:00:00 -0400</pubDate>
    <skipDays>
      <day>Sunday</day>
      <day>Saturday</day>
    </skipDays>
    <item>
      <title>Work in Progress: Middleware-Transparent Callback Enforcement in Commoditized Component-Oriented Real-time Systems</title>
      <link>https://arxiv.org/abs/2505.06546</link>
      <description>arXiv:2505.06546v1 Announce Type: new 
Abstract: Real-time scheduling in commoditized component-oriented real-time systems, such as ROS 2 systems on Linux, has been studied under nested scheduling: OS thread scheduling and middleware layer scheduling (e.g., ROS 2 Executor). However, by establishing a persistent one-to-one correspondence between callbacks and OS threads, we can ignore the middleware layer and directly apply OS scheduling parameters (e.g., scheduling policy, priority, and affinity) to individual callbacks. We propose a middleware model that enables this idea and implements CallbackIsolatedExecutor as a novel ROS 2 Executor. We demonstrate that the costs (user-kernel switches, context switches, and memory usage) of CallbackIsolatedExecutor remain lower than those of the MultiThreadedExecutor, regardless of the number of callbacks. Additionally, the cost of CallbackIsolatedExecutor relative to SingleThreadedExecutor stays within a fixed ratio (1.4x for inter-process and 5x for intra-process communication). Future ROS 2 real-time scheduling research can avoid nested scheduling, ignoring the existence of the middleware layer.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.06546v1</guid>
      <category>cs.OS</category>
      <category>cs.RO</category>
      <pubDate>Tue, 13 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <arxiv:DOI>10.1109/RTAS65571.2025.00017</arxiv:DOI>
      <arxiv:journal_reference>Proc. IEEE Real-Time and Embedded Technology and Applications Symposium (RTAS), 2025, pp. 78--81</arxiv:journal_reference>
      <dc:creator>Takahiro Ishikawa-Aso, Atsushi Yano, Takuya Azumi, Shinpei Kato</dc:creator>
    </item>
    <item>
      <title>RTOS Architectures that Solve the Diminishing Bandwidth Problem</title>
      <link>https://arxiv.org/abs/2505.06645</link>
      <description>arXiv:2505.06645v1 Announce Type: new 
Abstract: The Diminishing Bandwidth Problem is a long standing, previously unidentified, extensibility problem of current real-time operating systems characterized by a superficial dependency between the number of tasks in a system and the maximum bandwidth associated with a peripheral device. In the worst case, this diabolical deficiency will continue to decrease the maximum bandwidth of a peripheral device as more tasks are added to the application. If this is not taken into account, a previously functional application may experience data loss if more tasks are added to it in order to, for example, implement new features. Three novel RTOS architectures that solve the Diminishing Bandwidth Problem are specified and discussed: the Defer Structure RTOS Architecture, the Barriers and Requests RTOS Architecture, and the Strictly Atomic RTOS Architecture. Finally, two hardware solutions to the Diminishing Bandwidth Problem are also presented.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.06645v1</guid>
      <category>cs.OS</category>
      <pubDate>Tue, 13 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Mazen Arakji</dc:creator>
    </item>
    <item>
      <title>Work-in-Progress: Multi-Deadline DAG Scheduling Model for Autonomous Driving Systems</title>
      <link>https://arxiv.org/abs/2505.06780</link>
      <description>arXiv:2505.06780v1 Announce Type: new 
Abstract: Autoware is an autonomous driving system implemented on Robot Operation System (ROS) 2, where an end-to-end timing guarantee is crucial to ensure safety. However, existing ROS 2 cause-effect chain models for analyzing end-to-end latency struggle to accurately represent the complexities of Autoware, particularly regarding sync callbacks, queue consumption patterns, and feedback loops. To address these problems, we propose a new scheduling model that decomposes the end-to-end timing constraints of Autoware into local relative deadlines for each sub-DAG. This multi-deadline DAG scheduling model avoids the need for complex analysis of data flows through queues and loops, while ensuring that all callbacks receive data within correct intervals. Furthermore, we extend the Global Earliest Deadline First (GEDF) algorithm for the proposed model and evaluate its effectiveness using a synthetic workload derived from Autoware.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.06780v1</guid>
      <category>cs.OS</category>
      <pubDate>Tue, 13 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <arxiv:DOI>10.1109/RTSS62706.2024.00049</arxiv:DOI>
      <dc:creator>Atsushi Yano, Takuya Azumi</dc:creator>
    </item>
    <item>
      <title>Online Job Scheduler for Fault-tolerant Quantum Multiprogramming</title>
      <link>https://arxiv.org/abs/2505.06741</link>
      <description>arXiv:2505.06741v1 Announce Type: cross 
Abstract: Fault-tolerant quantum computers are expected to be offered as cloud services due to their significant resource and infrastructure requirements. Quantum multiprogramming, which runs multiple quantum jobs in parallel, is a promising approach to maximize the utilization of such systems. A key challenge in this setting is the need for an online scheduler capable of handling jobs submitted dynamically while other programs are already running. In this study, we formulate the online job scheduling problem for fault-tolerant quantum computing systems based on lattice surgery and propose an efficient scheduler to address it. To meet the responsiveness required in an online environment, our scheduler approximates lattice surgery programs, originally represented as polycubes, by using simpler cuboid representations. This approximation enables efficient scheduling while improving overall throughput. In addition, we incorporate a defragmentation mechanism into the scheduling process, demonstrating that it can further enhance QPU utilization.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.06741v1</guid>
      <category>quant-ph</category>
      <category>cs.DC</category>
      <category>cs.OS</category>
      <pubDate>Tue, 13 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Shin Nishio, Ryo Wakizaka, Daisuke Sakuma, Yosuke Ueno, Yasunari Suzuki</dc:creator>
    </item>
    <item>
      <title>AIOS: LLM Agent Operating System</title>
      <link>https://arxiv.org/abs/2403.16971</link>
      <description>arXiv:2403.16971v4 Announce Type: replace 
Abstract: LLM-based intelligent agents face significant deployment challenges, particularly related to resource management. Allowing unrestricted access to LLM or tool resources can lead to inefficient or even potentially harmful resource allocation and utilization for agents. Furthermore, the absence of proper scheduling and resource management mechanisms in current agent designs hinders concurrent processing and limits overall system efficiency. As the diversity and complexity of agents continue to grow, addressing these resource management issues becomes increasingly critical to LLM-based agent systems. To address these challenges, this paper proposes the architecture of AIOS (LLM-based AI Agent Operating System) under the context of managing LLM-based agents. It introduces a novel architecture for serving LLM-based agents by isolating resources and LLM-specific services from agent applications into an AIOS kernel. This AIOS kernel provides fundamental services (e.g., scheduling, context management, memory management, storage management, access control) and efficient management of resources (e.g., LLM and external tools) for runtime agents. To enhance usability, AIOS also includes an AIOS-Agent SDK, a comprehensive suite of APIs designed for utilizing functionalities provided by the AIOS kernel. Experimental results demonstrate that using AIOS can achieve up to 2.1x faster execution for serving agents built by various agent frameworks. The source code is available at https://github.com/agiresearch/AIOS.</description>
      <guid isPermaLink="false">oai:arXiv.org:2403.16971v4</guid>
      <category>cs.OS</category>
      <category>cs.AI</category>
      <category>cs.CL</category>
      <pubDate>Tue, 13 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Kai Mei, Xi Zhu, Wujiang Xu, Wenyue Hua, Mingyu Jin, Zelong Li, Shuyuan Xu, Ruosong Ye, Yingqiang Ge, Yongfeng Zhang</dc:creator>
    </item>
  </channel>
</rss>
