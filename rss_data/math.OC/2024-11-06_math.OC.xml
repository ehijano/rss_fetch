<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>math.OC updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/math.OC</link>
    <description>math.OC updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/math.OC" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Wed, 06 Nov 2024 05:00:02 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Wed, 06 Nov 2024 00:00:00 -0500</pubDate>
    <skipDays>
      <day>Saturday</day>
      <day>Sunday</day>
    </skipDays>
    <item>
      <title>Distributionally Robust Optimization</title>
      <link>https://arxiv.org/abs/2411.02549</link>
      <description>arXiv:2411.02549v1 Announce Type: new 
Abstract: Distributionally robust optimization (DRO) studies decision problems under uncertainty where the probability distribution governing the uncertain problem parameters is itself uncertain. A key component of any DRO model is its ambiguity set, that is, a family of probability distributions consistent with any available structural or statistical information. DRO seeks decisions that perform best under the worst distribution in the ambiguity set. This worst case criterion is supported by findings in psychology and neuroscience, which indicate that many decision-makers have a low tolerance for distributional ambiguity. DRO is rooted in statistics, operations research and control theory, and recent research has uncovered its deep connections to regularization techniques and adversarial training in machine learning. This survey presents the key findings of the field in a unified and self-contained manner.</description>
      <guid isPermaLink="false">oai:arXiv.org:2411.02549v1</guid>
      <category>math.OC</category>
      <category>cs.LG</category>
      <category>stat.ML</category>
      <pubDate>Wed, 06 Nov 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Daniel Kuhn, Soroosh Shafiee, Wolfram Wiesemann</dc:creator>
    </item>
    <item>
      <title>Optimization Algorithm Design via Electric Circuits</title>
      <link>https://arxiv.org/abs/2411.02573</link>
      <description>arXiv:2411.02573v1 Announce Type: new 
Abstract: We present a novel methodology for convex optimization algorithm design using ideas from electric RLC circuits. Given an optimization problem, the first stage of the methodology is to design an appropriate electric circuit whose continuous-time dynamics converge to the solution of the optimization problem at hand. Then, the second stage is an automated, computer-assisted discretization of the continuous-time dynamics, yielding a provably convergent discrete-time algorithm. Our methodology recovers many classical (distributed) optimization algorithms and enables users to quickly design and explore a wide range of new algorithms with convergence guarantees.</description>
      <guid isPermaLink="false">oai:arXiv.org:2411.02573v1</guid>
      <category>math.OC</category>
      <category>cs.LG</category>
      <pubDate>Wed, 06 Nov 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Stephen P. Boyd, Tetiana Parshakova, Ernest K. Ryu, Jaewook J. Suh</dc:creator>
    </item>
    <item>
      <title>A Trust-Region Algorithm for Noisy Equality Constrained Optimization</title>
      <link>https://arxiv.org/abs/2411.02665</link>
      <description>arXiv:2411.02665v1 Announce Type: new 
Abstract: This paper introduces a modified Byrd-Omojokun (BO) trust region algorithm to address the challenges posed by noisy function and gradient evaluations. The original BO method was designed to solve equality constrained problems and it forms the backbone of some interior point methods for general large-scale constrained optimization. A key strength of the BO method is its robustness in handling problems with rank-deficient constraint Jacobians. The algorithm proposed in this paper introduces a new criterion for accepting a step and for updating the trust region that makes use of an estimate in the noise in the problem. The analysis presented here gives conditions under which the iterates converge to regions of stationary points of the problem, determined by the level of noise. This analysis is more complex than for line search methods because the trust region carries (noisy) information from previous iterates. Numerical tests illustrate the practical performance of the algorithm.</description>
      <guid isPermaLink="false">oai:arXiv.org:2411.02665v1</guid>
      <category>math.OC</category>
      <category>cs.LG</category>
      <pubDate>Wed, 06 Nov 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Shigeng Sun, Jorge Nocedal</dc:creator>
    </item>
    <item>
      <title>Fully Distributed Adaptive Nash Equilibrium Seeking Algorithm for Constrained Noncooperative Games with Prescribed Performance</title>
      <link>https://arxiv.org/abs/2411.02719</link>
      <description>arXiv:2411.02719v1 Announce Type: new 
Abstract: This paper investigates a fully distributed adaptive Nash equilibrium (NE) seeking algorithm for constrained noncooperative games with prescribed-time stability. On the one hand, prescribed-time stability for the proposed NE seeking algorithm is obtained by using an adaptive penalty technique, a time-varying control gain and a cosine-related time conversion function, which extends the prior asymptotic stability result. On the other hand, uncoordinated integral adaptive gains are incorporated in order to achieve the fully distribution of the algorithm. Finally, the theoretical result is validated through a numerical simulation based on a standard power market scenario.</description>
      <guid isPermaLink="false">oai:arXiv.org:2411.02719v1</guid>
      <category>math.OC</category>
      <pubDate>Wed, 06 Nov 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Sichen Qian</dc:creator>
    </item>
    <item>
      <title>Differentiability and Approximation of Probability Functions under Gaussian Mixture Models: A Bayesian Approach</title>
      <link>https://arxiv.org/abs/2411.02721</link>
      <description>arXiv:2411.02721v1 Announce Type: new 
Abstract: In this work, we study probability functions associated with Gaussian mixture models. Our primary focus is on extending the use of spherical radial decomposition for multivariate Gaussian random vectors to the context of Gaussian mixture models, which are not inherently spherical but only conditionally so. Specifically, the conditional probability distribution, given a random parameter of the random vector, follows a Gaussian distribution, allowing us to apply Bayesian analysis tools to the probability function. This assumption, together with spherical radial decomposition for Gaussian random vectors, enables us to represent the probability function as an integral over the Euclidean sphere. Using this representation, we establish sufficient conditions to ensure the differentiability of the probability function and provide and integral representation of its gradient. Furthermore, leveraging the Bayesian decomposition, we approximate the probability function using random sampling over the parameter space and the Euclidean sphere. Finally, we present numerical examples that illustrate the advantages of this approach over classical approximations based on random vector sampling.</description>
      <guid isPermaLink="false">oai:arXiv.org:2411.02721v1</guid>
      <category>math.OC</category>
      <category>math.PR</category>
      <category>stat.ML</category>
      <pubDate>Wed, 06 Nov 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Gonzalo Contador, Pedro P\'erez-Aros, Emilio Vilches</dc:creator>
    </item>
    <item>
      <title>Approximate controllability of impulsive semilinear evolution equations in Hilbert spaces</title>
      <link>https://arxiv.org/abs/2411.02766</link>
      <description>arXiv:2411.02766v1 Announce Type: new 
Abstract: Many dynamical systems in fields such as physics, chemistry, biology, and engineering show impulsive behavior due to abrupt changes at specific times. These behaviors are described by differential systems with impulse effects. This paper examines approximate controllability for certain types of semi-linear impulsive control differential and neutral differential equations in Hilbert spaces, including control within the impulses. By applying semigroup theory and a fixed-point approach, sufficient conditions for approximate controllability of impulsive and neutral differential equations are established. To illustrate the usefulness of the proposed results, three examples are presented, offering improvements over some recent results</description>
      <guid isPermaLink="false">oai:arXiv.org:2411.02766v1</guid>
      <category>math.OC</category>
      <pubDate>Wed, 06 Nov 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Javad A. Asadzade, Nazim I. Mahmudov</dc:creator>
    </item>
    <item>
      <title>Applications of Automatic Differentiation in Image Registration</title>
      <link>https://arxiv.org/abs/2411.02806</link>
      <description>arXiv:2411.02806v1 Announce Type: new 
Abstract: We demonstrate that automatic differentiation, which has become commonly available in machine learning frameworks, is an efficient way to explore ideas that lead to algorithmic improvement in multi-scale affine image registration and affine super-resolution problems. In our first experiment on multi-scale registration, we implement an ODE predictor-corrector method involving a derivative with respect to the scale parameter and the Hessian of an image registration objective function, both of which would be difficult to compute without AD. Our findings indicate that exact Hessians are necessary for the method to provide any benefits over a traditional multi-scale method; a Gauss-Newton Hessian approximation fails to provide such benefits. In our second experiment, we implement a variable projected Gauss-Newton method for super-resolution and use AD to differentiate through the iteratively computed projection, a method previously unaddressed in the literature. We show that Jacobians obtained without differentiating through the projection are poor approximations to the true Jacobians of the variable projected forward map and explore the performance of some other approximations. By addressing these problems, this work contributes to the application of AD in image registration and sets a precedent for further use of machine learning tools in this field.</description>
      <guid isPermaLink="false">oai:arXiv.org:2411.02806v1</guid>
      <category>math.OC</category>
      <pubDate>Wed, 06 Nov 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Warin Watson, Cash Cherry, Rachelle Lang</dc:creator>
    </item>
    <item>
      <title>Polyhedral study of a temporal rural postman problem: application in inspection of railway track without disturbing train schedules</title>
      <link>https://arxiv.org/abs/2411.02822</link>
      <description>arXiv:2411.02822v1 Announce Type: new 
Abstract: The Rural Postman Problem with Temporal Unavailability (RPP-TU) is a variant of the Rural Postman Problem (RPP) specified for multi-agent planning over directed graphs with temporal constraints. These temporal constraints represent the unavailable time intervals for each arc during which agents cannot traverse the arc. Such arc unavailability scenarios occur in routing and scheduling of the instrumented wagons for inspection of railway tracks without disturbing the train schedules, i.e. the scheduled trains prohibit access to the signal blocks (sections of railway track separated by signals) for some finite interval of time.
  A three-index formulation for the RPP-TU is adopted from the literature. The three-index formulation has binary variables for describing the route information of the agents, and continuous non-negative variables to describe the schedules at pre-defined locations. A relaxation of the three-index formulation for RPP-TRU, referred to as Cascaded Graph Formulation (CGF), is investigated in this work. The CGF has attributes that simplify the polyhedral study of time-dependent arc routing problems like RPP-TRU. A novel branch-and-cut algorithm is proposed to solve the RPP-TU, where branching is performed over the service arcs. A family of facet-defining inequalities, derived from the polyhedral study, is used as cutting planes in the proposed branch-and-cut algorithm to reduce the computation time by up to $48\%$. Finally, an application of this work is showcased using a simulation case study of a railway inspection scheduling problem based on Kurla-Vashi-Thane suburban network in Mumbai, India. An improvement of $93\%$ is observed when compared to a Benders' decomposition based MILP solver from the literature.</description>
      <guid isPermaLink="false">oai:arXiv.org:2411.02822v1</guid>
      <category>math.OC</category>
      <category>math.CO</category>
      <pubDate>Wed, 06 Nov 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Somnath Buriuly, Leena Vachhani, Sivapragasam Ravitharan, Arpita Sinha, Sunita Chauhan</dc:creator>
    </item>
    <item>
      <title>Fast and robust consensus-based optimization via optimal feedback control</title>
      <link>https://arxiv.org/abs/2411.03051</link>
      <description>arXiv:2411.03051v1 Announce Type: new 
Abstract: We propose a variant of consensus-based optimization (CBO) algorithms, controlled-CBO, which introduces a feedback control term to improve convergence towards global minimizers of non-convex functions in multiple dimensions. The feedback law is a gradient of a numerical approximation to the Hamilton-Jacobi-Bellman (HJB) equation, which serves as a proxy of the original objective function. Thus, the associated control signal furnishes gradient-like information to facilitate the identification of the global minimum without requiring derivative computation from the objective function itself. The proposed method exhibits significantly improved performance over standard CBO methods in numerical experiments, particularly in scenarios involving a limited number of particles, or where the initial particle ensemble is not well positioned with respect to the global minimum. At the same time, the modification keeps the algorithm amenable to theoretical analysis in the mean-field sense. The superior convergence rates are assessed experimentally.</description>
      <guid isPermaLink="false">oai:arXiv.org:2411.03051v1</guid>
      <category>math.OC</category>
      <pubDate>Wed, 06 Nov 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Yuyang Huang, Michael Herty, Dante Kalise, Nikolas Kantas</dc:creator>
    </item>
    <item>
      <title>Benign landscape for Burer-Monteiro factorizations of MaxCut-type semidefinite programs</title>
      <link>https://arxiv.org/abs/2411.03103</link>
      <description>arXiv:2411.03103v1 Announce Type: new 
Abstract: We consider MaxCut-type semidefinite programs (SDP) which admit a low rank solution. To numerically leverage the low rank hypothesis, a standard algorithmic approach is the Burer-Monteiro factorization, which allows to significantly reduce the dimensionality of the problem at the cost of its convexity. We give a sharp condition on the conditioning of the Laplacian matrix associated with the SDP under which any second-order critical point of the non-convex problem is a global minimizer. By applying our theorem, we improve on recent results about the correctness of the Burer-Monteiro approach on $\mathbb{Z}_2$-synchronization problems.</description>
      <guid isPermaLink="false">oai:arXiv.org:2411.03103v1</guid>
      <category>math.OC</category>
      <category>cs.CC</category>
      <category>stat.ML</category>
      <pubDate>Wed, 06 Nov 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Faniriana Rakoto Endor, Ir\`ene Waldspurger</dc:creator>
    </item>
    <item>
      <title>Predict-and-Optimize Robust Unit Commitment with Statistical Guarantees via Weight Combination</title>
      <link>https://arxiv.org/abs/2411.03138</link>
      <description>arXiv:2411.03138v1 Announce Type: new 
Abstract: The growing uncertainty from renewable power and electricity demand brings significant challenges to unit commitment (UC). While various advanced forecasting and optimization methods have been developed to predict better and address this uncertainty, most previous studies treat forecasting and optimization as separate tasks. This separation can lead to suboptimal results due to misalignment between the objectives of the two tasks. To overcome this challenge, we propose a robust UC framework that integrates the forecasting and optimization processes while ensuring statistical guarantees. In the forecasting stage, we combine multiple predictions derived from diverse data sources and methodologies for an improved prediction, aiming to optimize the UC performance. In the optimization stage, the combined prediction is used to construct an uncertainty set with statistical guarantees, based on which the robust UC model is formulated. The optimal robust UC solution provides feedback to refine the forecasting process, forming a closed loop. To solve the proposed integrated forecasting-optimization framework efficiently and effectively, we develop a neural network-based surrogate model for acceleration and introduce a reshaping method for the uncertainty set based on the optimization result to reduce conservativeness. Case studies on modified IEEE 30-bus and 118-bus systems demonstrate the advantages of the proposed approach.</description>
      <guid isPermaLink="false">oai:arXiv.org:2411.03138v1</guid>
      <category>math.OC</category>
      <pubDate>Wed, 06 Nov 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Rui Xie, Yue Chen, Pierre Pinson</dc:creator>
    </item>
    <item>
      <title>On the Hardness of the $L_1-L_2$ Regularization Problem</title>
      <link>https://arxiv.org/abs/2411.03216</link>
      <description>arXiv:2411.03216v1 Announce Type: new 
Abstract: The sparse linear reconstruction problem is a core problem in signal processing which aims to recover sparse solutions to linear systems. The original problem regularized by the total number of nonzero components (also know as $L_0$ regularization) is well-known to be NP-hard. The relaxation of the $L_0$ regularization by using the $L_1$ norm offers a convex reformulation, but is only exact under contain conditions (e.g., restricted isometry property) which might be NP-hard to verify. To overcome the computational hardness of the $L_0$ regularization problem while providing tighter results than the $L_1$ relaxation, several alternate optimization problems have been proposed to find sparse solutions. One such problem is the $L_1-L_2$ minimization problem, which is to minimize the difference of the $L_1$ and $L_2$ norms subject to linear constraints. This paper proves that solving the $L_1-L_2$ minimization problem is NP-hard. Specifically, we prove that it is NP-hard to minimize the $L_1-L_2$ regularization function subject to linear constraints. Moreover, it is also NP-hard to solve the unconstrained formulation that minimizes the sum of a least squares term and the $L_1-L_2$ regularization function. Furthermore, restricting the feasible set to a smaller one by adding nonnegative constraints does not change the NP-hardness nature of the problems.</description>
      <guid isPermaLink="false">oai:arXiv.org:2411.03216v1</guid>
      <category>math.OC</category>
      <pubDate>Wed, 06 Nov 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Yuyuan Ouyang, Kyle Yates</dc:creator>
    </item>
    <item>
      <title>Mitigating Forgetting in LLM Supervised Fine-Tuning and Preference Learning</title>
      <link>https://arxiv.org/abs/2410.15483</link>
      <description>arXiv:2410.15483v2 Announce Type: cross 
Abstract: Post-training of pre-trained LLMs, which typically consists of the supervised fine-tuning (SFT) stage and the preference learning (RLHF or DPO) stage, is crucial to effective and safe LLM applications. The widely adopted approach in post-training popular open-source LLMs is to sequentially perform SFT and RLHF/DPO. However, sequential training is sub-optimal in terms of SFT and RLHF/DPO trade-off: the LLM gradually forgets about the first stage's training when undergoing the second stage's training. We theoretically prove the sub-optimality of sequential post-training. Furthermore, we propose a practical joint post-training framework with theoretical convergence guarantees and empirically outperforms sequential post-training framework, while having similar computational cost. Our code is available at https://github.com/heshandevaka/XRIGHT.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.15483v2</guid>
      <category>cs.LG</category>
      <category>cs.AI</category>
      <category>cs.CL</category>
      <category>math.OC</category>
      <category>stat.ML</category>
      <pubDate>Wed, 06 Nov 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Heshan Fernando, Han Shen, Parikshit Ram, Yi Zhou, Horst Samulowitz, Nathalie Baracaldo, Tianyi Chen</dc:creator>
    </item>
    <item>
      <title>A Systematic Study on Solving Aerospace Problems Using Metaheuristics</title>
      <link>https://arxiv.org/abs/2411.02574</link>
      <description>arXiv:2411.02574v1 Announce Type: cross 
Abstract: Complex engineering problems can be modelled as optimisation problems. For instance, optimising engines, materials, components, structure, aerodynamics, navigation, control, logistics, and planning is essential in aerospace. Metaheuristics are applied to solve these optimisation problems. The present paper presents a systematic study on applying metaheuristics in aerospace based on the literature. Relevant scientific repositories were consulted, and a structured methodology was used to filter the papers. Articles published until March 2022 associating metaheuristics and aerospace applications were selected. The most used algorithms and the most relevant hybridizations were identified. This work also analyses the main types of problems addressed in the aerospace context and which classes of algorithms are most used in each problem.</description>
      <guid isPermaLink="false">oai:arXiv.org:2411.02574v1</guid>
      <category>cs.NE</category>
      <category>math.OC</category>
      <pubDate>Wed, 06 Nov 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Carlos Alberto da Silva Junior, Marconi de Arruda Pereira, Angelo Passaro</dc:creator>
    </item>
    <item>
      <title>Comparison of two mean-field approaches to modeling an epidemic spread</title>
      <link>https://arxiv.org/abs/2411.02800</link>
      <description>arXiv:2411.02800v1 Announce Type: cross 
Abstract: The paper describes and compares three approaches to modeling an epidemic spread. The first approach is a well-known system of SIR ordinary differential equations. The second is a mean-field model, in which an isolation strategy for each epidemiological group (Susceptible, Infected, and Removed) is chosen as an optimal control. The third is another meanfield model, in which isolation strategy is common for the entire population. The considered models have been compared analytically, their sensitivity analysis has been carried out and their predictive capabilities have been estimated using sets of synthetic and real data. For one of the meanfield models, its finite-difference analogue has been devised. The models have also been assessed in terms of their applicability for predicting a viral epidemic spread.</description>
      <guid isPermaLink="false">oai:arXiv.org:2411.02800v1</guid>
      <category>q-bio.PE</category>
      <category>math.OC</category>
      <pubDate>Wed, 06 Nov 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Viktoriya Petrakova, Olga Krivorotko</dc:creator>
    </item>
    <item>
      <title>Neural Networks and (Virtual) Extended Formulations</title>
      <link>https://arxiv.org/abs/2411.03006</link>
      <description>arXiv:2411.03006v1 Announce Type: cross 
Abstract: Neural networks with piecewise linear activation functions, such as rectified linear units (ReLU) or maxout, are among the most fundamental models in modern machine learning. We make a step towards proving lower bounds on the size of such neural networks by linking their representative capabilities to the notion of the extension complexity $\mathrm{xc}(P)$ of a polytope $P$, a well-studied quantity in combinatorial optimization and polyhedral geometry. To this end, we propose the notion of virtual extension complexity $\mathrm{vxc}(P)=\min\{\mathrm{xc}(Q)+\mathrm{xc}(R)\mid P+Q=R\}$. This generalizes $\mathrm{xc}(P)$ and describes the number of inequalities needed to represent the linear optimization problem over $P$ as a difference of two linear programs. We prove that $\mathrm{vxc}(P)$ is a lower bound on the size of a neural network that optimizes over $P$. While it remains open to derive strong lower bounds on virtual extension complexity, we show that powerful results on the ordinary extension complexity can be converted into lower bounds for monotone neural networks, that is, neural networks with only nonnegative weights. Furthermore, we show that one can efficiently optimize over a polytope $P$ using a small virtual extended formulation. We therefore believe that virtual extension complexity deserves to be studied independently from neural networks, just like the ordinary extension complexity. As a first step in this direction, we derive an example showing that extension complexity can go down under Minkowski sum.</description>
      <guid isPermaLink="false">oai:arXiv.org:2411.03006v1</guid>
      <category>math.CO</category>
      <category>cs.CC</category>
      <category>cs.DM</category>
      <category>cs.LG</category>
      <category>math.OC</category>
      <pubDate>Wed, 06 Nov 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Christoph Hertrich, Georg Loho</dc:creator>
    </item>
    <item>
      <title>Adjoint lattice kinetic scheme for topology optimization in fluid problems</title>
      <link>https://arxiv.org/abs/2411.03090</link>
      <description>arXiv:2411.03090v1 Announce Type: cross 
Abstract: This paper proposes a topology optimization method for non-thermal and thermal fluid problems using the Lattice Kinetic Scheme (LKS).LKS, which is derived from the Lattice Boltzmann Method (LBM), requires only macroscopic values, such as fluid velocity and pressure, whereas LBM requires velocity distribution functions, thereby reducing memory requirements. The proposed method computes design sensitivities based on the adjoint variable method, and the adjoint equation is solved in the same manner as LKS; thus, we refer to it as the Adjoint Lattice Kinetic Scheme (ALKS). A key contribution of this method is the proposed approximate treatment of boundary conditions for the adjoint equation, which is challenging to apply directly due to the characteristics of LKS boundary conditions. We demonstrate numerical examples for steady and unsteady problems involving non-thermal and thermal fluids, and the results are physically meaningful and consistent with previous research, exhibiting similar trends in parameter dependencies, such as the Reynolds number. Furthermore, the proposed method reduces memory usage by up to 75% compared to the conventional LBM in an unsteady thermal fluid problem.</description>
      <guid isPermaLink="false">oai:arXiv.org:2411.03090v1</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <category>math.OC</category>
      <pubDate>Wed, 06 Nov 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Yuta Tanabe, Kentaro Yaji, Kuniharu Ushijima</dc:creator>
    </item>
    <item>
      <title>Asymptotic stability equals exponential stability -- while you twist your eyes</title>
      <link>https://arxiv.org/abs/2411.03277</link>
      <description>arXiv:2411.03277v1 Announce Type: cross 
Abstract: Suppose that two vector fields on a smooth manifold render some equilibrium point globally asymptotically stable (GAS). We show that there exists a homotopy between the corresponding semiflows such that this point remains GAS along this homotopy.</description>
      <guid isPermaLink="false">oai:arXiv.org:2411.03277v1</guid>
      <category>math.DS</category>
      <category>cs.SY</category>
      <category>eess.SY</category>
      <category>math.OC</category>
      <pubDate>Wed, 06 Nov 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Wouter Jongeneel</dc:creator>
    </item>
    <item>
      <title>Temporal Recurring Unavailabilities in Multi-agent Rural Postman Problem: Navigating railway tracks during availability time intervals</title>
      <link>https://arxiv.org/abs/2101.04950</link>
      <description>arXiv:2101.04950v2 Announce Type: replace 
Abstract: Time-dependent (or temporal) properties may arise in many network-based planning problems, particularly in the routing and scheduling of railway track inspection problems. The availability of tracks depends on the train schedules, maintenance possessions, etc. In the absence of side constraints, this routing and scheduling problem is formulated as a multi-agent rural postman problem on a temporal-directed network; where a given set of rail track sections must be visited while respecting the temporal attributes due to railway track unavailabilities. In this work, we adopt a three-index formulation for the multi-agent Rural Postman Problem with Temporal Recurring Unavailabilities (RPP-TRU) and frame it as a Mixed Integer Linear Programming (MILP) problem. In addition, we propose relevant theoretical studies for RPP-TRU to ensure the feasibility of the proposed optimization problem. Two approaches of an exact algorithm are proposed, based on Benders' decomposition framework, to address the disjunctive unavailability constraints occurring in its scheduling sub-problems, alongside the NP-Hard routing (master) problem. A polynomial-time algorithm is designed to address the scheduling sub-problem, while the NP-Hard master problem is solved using MILP toolbox. Comparison results with RPP (without temporal constraints) show a minor compromise with the spatial cost solution with significantly less delay, hence suitable for real-world routing and scheduling applications occurring in a shared network like railways. A simulation study on a part of the Mumbai suburban railway network demonstrates the working of the proposed methodology under a realistic setting.</description>
      <guid isPermaLink="false">oai:arXiv.org:2101.04950v2</guid>
      <category>math.OC</category>
      <pubDate>Wed, 06 Nov 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Somnath Buriuly, Leena Vachhani, Arpita Sinha, Sivapragasam Ravitharan, Sunita Chauhan</dc:creator>
    </item>
    <item>
      <title>Losing momentum in continuous-time stochastic optimisation</title>
      <link>https://arxiv.org/abs/2209.03705</link>
      <description>arXiv:2209.03705v2 Announce Type: replace 
Abstract: The training of modern machine learning models often consists in solving high-dimensional non-convex optimisation problems that are subject to large-scale data. In this context, momentum-based stochastic optimisation algorithms have become particularly widespread. The stochasticity arises from data subsampling which reduces computational cost. Both, momentum and stochasticity help the algorithm to converge globally. In this work, we propose and analyse a continuous-time model for stochastic gradient descent with momentum. This model is a piecewise-deterministic Markov process that represents the optimiser by an underdamped dynamical system and the data subsampling through a stochastic switching. We investigate longtime limits, the subsampling-to-no-subsampling limit, and the momentum-to-no-momentum limit. We are particularly interested in the case of reducing the momentum over time. Under convexity assumptions, we show convergence of our dynamical system to the global minimiser when reducing momentum over time and letting the subsampling rate go to infinity. We then propose a stable, symplectic discretisation scheme to construct an algorithm from our continuous-time dynamical system. In experiments, we study our scheme in convex and non-convex test problems. Additionally, we train a convolutional neural network in an image classification problem. Our algorithm {attains} competitive results compared to stochastic gradient descent with momentum.</description>
      <guid isPermaLink="false">oai:arXiv.org:2209.03705v2</guid>
      <category>math.OC</category>
      <category>cs.LG</category>
      <category>cs.NA</category>
      <category>math.NA</category>
      <pubDate>Wed, 06 Nov 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Kexin Jin, Jonas Latz, Chenguang Liu, Alessandro Scagliotti</dc:creator>
    </item>
    <item>
      <title>Carath\'eodory Theory and A Priori Estimates for Continuity Inclusions in the Space of Probability Measures</title>
      <link>https://arxiv.org/abs/2302.00963</link>
      <description>arXiv:2302.00963v3 Announce Type: replace 
Abstract: In this article, we extend the foundations of the theory of differential inclusions in the space of compactly supported probability measures, introduced recently by the authors, to the setting of general Wasserstein spaces. In this context, we prove a novel existence result \`a la Peano for this class of dynamics under mere Carath\'eodory regularity assumptions. The latter is based on a natural, yet previously unexplored set-valued adaptation of the semi-discrete Euler scheme proposed by Filippov to study ordinary differential equations whose right-hand sides are measurable in the time variable. By leveraging some of the underlying methods along with new estimates for solutions of continuity equations, we also bring substantial improvements to the earlier versions of the Filippov estimates, compactness and relaxation properties of the solution sets of continuity inclusions, which are derived in the Cauchy-Lipschitz framework.</description>
      <guid isPermaLink="false">oai:arXiv.org:2302.00963v3</guid>
      <category>math.OC</category>
      <category>math.PR</category>
      <pubDate>Wed, 06 Nov 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <arxiv:DOI>10.1016/j.na.2024.113595</arxiv:DOI>
      <arxiv:journal_reference>Nonlinear Analysis, Theory, Methods and Applications, 247:113595 (2024)</arxiv:journal_reference>
      <dc:creator>Beno\^it Bonnet-Weill, H\'el\`ene Frankowska</dc:creator>
    </item>
    <item>
      <title>Optimal Transport for Mixtures of Radial Functions</title>
      <link>https://arxiv.org/abs/2404.08383</link>
      <description>arXiv:2404.08383v2 Announce Type: replace 
Abstract: The optimal transport and Wasserstein barycenter of Gaussian distributions have been solved. In literature, the closed form formulas of the Monge map, the Wasserstein distance and the Wasserstein barycenter have been given. Moreover, when Gaussian distributions extend more generally to elliptical contoured distributions, similar results also hold true. In this case, Gaussian distributions are regarded as elliptical contoured distribution with generator function $e^{-x/2}$. However, there are few results about optimal transport for elliptical contoured distributions with different generator functions. In this paper, we degenerate elliptical contoured distributions to radial contoured distributions and study their optimal transport and prove their Wasserstein barycenter is still radial contoured. For general elliptical contoured distributions, we give two numerical counterexamples to show that the Wasserstein barycenter of elliptical contoured distributions does not have to be elliptical contoured.</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.08383v2</guid>
      <category>math.OC</category>
      <pubDate>Wed, 06 Nov 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Keyu Chen, Yunxin Zhang</dc:creator>
    </item>
    <item>
      <title>Analysis of Primal-Dual Langevin Algorithms</title>
      <link>https://arxiv.org/abs/2405.18098</link>
      <description>arXiv:2405.18098v3 Announce Type: replace 
Abstract: We analyze a recently proposed class of algorithms for the problem of sampling from probability distributions $\mu^\ast$ in $\mathbb{R}^d$ with a Lebesgue density of the form $\mu^\ast(x) \propto \exp(-f(Kx)-g(x))$, where $K$ is a linear operator and $f,g$ convex and non-smooth. The method is a generalization of the primal-dual hybrid gradient optimization algorithm to a sampling scheme. We give the iteration's continuous time limit, a stochastic differential equation in the joint primal-dual variable, and its mean field limit Fokker-Planck equation. Under mild conditions, the scheme converges to a unique stationary state in continuous and discrete time. Contrary to purely primal overdamped Langevin diffusion, the stationary state in continuous time does not have $\mu^\ast$ as its primal marginal. Thus, further analysis is carried out to bound the bias induced by the partial dualization, and potentially correct for it in the diffusion. Time discretizations of the diffusion lead to implementable algorithms, but, as is typical in Langevin Monte Carlo methods, introduce further bias. We prove bounds for these discretization errors, which allow to give convergence results relating the produced samples to the target. We demonstrate our findings numerically first on small-scale examples in which we can exactly verify the theoretical results, and subsequently on typical examples of larger scale from Bayesian imaging inverse problems.</description>
      <guid isPermaLink="false">oai:arXiv.org:2405.18098v3</guid>
      <category>math.OC</category>
      <pubDate>Wed, 06 Nov 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Martin Burger, Matthias J. Ehrhardt, Lorenz Kuger, Lukas Weigand</dc:creator>
    </item>
    <item>
      <title>Averaging principle for multiscale controlled jump diffusions and associated nonlocal HJB equations</title>
      <link>https://arxiv.org/abs/2410.22141</link>
      <description>arXiv:2410.22141v2 Announce Type: replace 
Abstract: This paper studies the averaging principle of a class of two-time scale stochastic control systems with $\alpha$-stable noise. The associated singular perturbations problem for nonlocal Hamilton-Jacobi-Bellman (HJB) equations is also considered. We construct the effective stochastic control problem and the associated effective HJB equation for the original multiscale stochastic control problem by averaging over the ergodic measure of the fast component. We prove the convergence of the value function using two methods. With the probabilistic method, we show that the value function of the original multiscale stochastic control system converges to the value function of the effective stochastic control system by proving the weak averaging principle of the controlled jump diffusions. Using the PDE method, we study the value function as the viscosity solution of the associated nonlocal HJB equation with singular perturbations. We then prove the convergence using the perturbed test function method.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.22141v2</guid>
      <category>math.OC</category>
      <pubDate>Wed, 06 Nov 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Qi Zhang, Yanjie Zhang, Ao Zhang</dc:creator>
    </item>
    <item>
      <title>Online Bipartite Matching with Advice: Tight Robustness-Consistency Tradeoffs for the Two-Stage Model</title>
      <link>https://arxiv.org/abs/2206.11397</link>
      <description>arXiv:2206.11397v3 Announce Type: replace-cross 
Abstract: Two-stage bipartite matching is a fundamental problem of optimization under uncertainty introduced by Feng, Niazadeh, and Saberi (2021), who study it under the stochastic and adversarial paradigms of uncertainty. We propose a method to interpolate between these paradigms, using the Algorithms with Predictions (ALPS) framework. To elaborate, given some form of information (e.g. a distributional prediction) about the uncertainty, we consider the optimal decision assuming that information is correct to be some "advice", whose accuracy is unknown. In the ALPS framework, we define Consistency to be an algorithm's performance relative to the advice, and Robustness to be an algorithm's performance relative to the hindsight-optimal decision. We characterize the tight tradeoff between Consistency and Robustness for four settings of two-stage matching: unweighted, vertex-weighted, edge-weighted, and fractional budgeted allocation. Additionally, we show our algorithm achieves state-of-the-art performance in both synthetic and real-data simulations.</description>
      <guid isPermaLink="false">oai:arXiv.org:2206.11397v3</guid>
      <category>cs.DS</category>
      <category>math.OC</category>
      <pubDate>Wed, 06 Nov 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Billy Jin, Will Ma</dc:creator>
    </item>
    <item>
      <title>A Nonparametric Approach with Marginals for Modeling Consumer Choice</title>
      <link>https://arxiv.org/abs/2208.06115</link>
      <description>arXiv:2208.06115v5 Announce Type: replace-cross 
Abstract: Given data on the choices made by consumers for different offer sets, a key challenge is to develop parsimonious models that describe and predict consumer choice behavior while being amenable to prescriptive tasks such as pricing and assortment optimization. The marginal distribution model (MDM) is one such model, which requires only the specification of marginal distributions of the random utilities. This paper aims to establish necessary and sufficient conditions for given choice data to be consistent with the MDM hypothesis, inspired by the usefulness of similar characterizations for the random utility model (RUM). This endeavor leads to an exact characterization of the set of choice probabilities that the MDM can represent. Verifying the consistency of choice data with this characterization is equivalent to solving a polynomial-sized linear program. Since the analogous verification task for RUM is computationally intractable and neither of these models subsumes the other, MDM is helpful in striking a balance between tractability and representational power. The characterization is then used with robust optimization for making data-driven sales and revenue predictions for new unseen assortments. When the choice data lacks consistency with the MDM hypothesis, finding the best-fitting MDM choice probabilities reduces to solving a mixed integer convex program. Numerical results using real world data and synthetic data demonstrate that MDM exhibits competitive representational power and prediction performance compared to RUM and parametric models while being significantly faster in computation than RUM.</description>
      <guid isPermaLink="false">oai:arXiv.org:2208.06115v5</guid>
      <category>stat.ML</category>
      <category>econ.EM</category>
      <category>math.OC</category>
      <pubDate>Wed, 06 Nov 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Yanqiu Ruan, Xiaobo Li, Karthyek Murthy, Karthik Natarajan</dc:creator>
    </item>
    <item>
      <title>Provably Learning Diverse Features in Multi-View Data with Midpoint Mixup</title>
      <link>https://arxiv.org/abs/2210.13512</link>
      <description>arXiv:2210.13512v4 Announce Type: replace-cross 
Abstract: Mixup is a data augmentation technique that relies on training using random convex combinations of data points and their labels. In recent years, Mixup has become a standard primitive used in the training of state-of-the-art image classification models due to its demonstrated benefits over empirical risk minimization with regards to generalization and robustness. In this work, we try to explain some of this success from a feature learning perspective. We focus our attention on classification problems in which each class may have multiple associated features (or views) that can be used to predict the class correctly. Our main theoretical results demonstrate that, for a non-trivial class of data distributions with two features per class, training a 2-layer convolutional network using empirical risk minimization can lead to learning only one feature for almost all classes while training with a specific instantiation of Mixup succeeds in learning both features for every class. We also show empirically that these theoretical insights extend to the practical settings of image benchmarks modified to have multiple features.</description>
      <guid isPermaLink="false">oai:arXiv.org:2210.13512v4</guid>
      <category>cs.LG</category>
      <category>cs.AI</category>
      <category>cs.CV</category>
      <category>math.OC</category>
      <category>stat.ML</category>
      <pubDate>Wed, 06 Nov 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Muthu Chidambaram, Xiang Wang, Chenwei Wu, Rong Ge</dc:creator>
    </item>
    <item>
      <title>On Data-Driven Stochastic Output-Feedback Predictive Control</title>
      <link>https://arxiv.org/abs/2211.17074</link>
      <description>arXiv:2211.17074v3 Announce Type: replace-cross 
Abstract: The fundamental lemma by Jan C. Willems and co-authors enables the representation of all input-output trajectories of a linear time-invariant system by measured input-output data. This result has proven to be pivotal for data-driven control. Building on a stochastic variant of the fundamental lemma, this paper presents a data-driven output-feedback predictive control scheme for stochastic Linear Time-Invariant (LTI) systems. The considered LTI systems are subject to non-Gaussian disturbances about which only information about their first two moments is known. Leveraging polynomial chaos expansions, the proposed scheme is centered around a data-driven stochastic Optimal Control Problem (OCP). Through tailored online design of initial conditions, we provide sufficient conditions for the recursive feasibility of the proposed output-feedback scheme based on a data-driven design of the terminal ingredients of the OCP. Furthermore, we provide a robustness analysis of the closed-loop performance. A numerical example illustrates the efficacy of the proposed scheme.</description>
      <guid isPermaLink="false">oai:arXiv.org:2211.17074v3</guid>
      <category>eess.SY</category>
      <category>cs.SY</category>
      <category>math.OC</category>
      <pubDate>Wed, 06 Nov 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Guanru Pan, Ruchuan Ou, Timm Faulwasser</dc:creator>
    </item>
    <item>
      <title>On the Global Convergence of Risk-Averse Policy Gradient Methods with Expected Conditional Risk Measures</title>
      <link>https://arxiv.org/abs/2301.10932</link>
      <description>arXiv:2301.10932v3 Announce Type: replace-cross 
Abstract: Risk-sensitive reinforcement learning (RL) has become a popular tool for controlling the risk of uncertain outcomes and ensuring reliable performance in highly stochastic sequential decision-making problems. While Policy Gradient (PG) methods have been developed for risk-sensitive RL, it remains unclear if these methods enjoy the same global convergence guarantees as in the risk-neutral case \citep{mei2020global,agarwal2021theory,cen2022fast,bhandari2024global}. In this paper, we consider a class of dynamic time-consistent risk measures, named Expected Conditional Risk Measures (ECRMs), and derive PG and Natural Policy Gradient (NPG) updates for ECRMs-based RL problems. We provide global optimality {and iteration complexities} of the proposed algorithms under the following four settings: (i) PG with constrained direct parameterization, (ii) PG with softmax parameterization and log barrier regularization, (iii) NPG with softmax parameterization and entropy regularization, and (iv) approximate NPG with inexact policy evaluation. Furthermore, we test a risk-averse REINFORCE algorithm \citep{williams1992simple} and a risk-averse NPG algorithm \citep{kakade2001natural} on a stochastic Cliffwalk environment to demonstrate the efficacy of our methods and the importance of risk control.</description>
      <guid isPermaLink="false">oai:arXiv.org:2301.10932v3</guid>
      <category>cs.LG</category>
      <category>math.OC</category>
      <category>stat.ML</category>
      <pubDate>Wed, 06 Nov 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Xian Yu, Lei Ying</dc:creator>
    </item>
    <item>
      <title>Optimal Scalarizations for Sublinear Hypervolume Regret</title>
      <link>https://arxiv.org/abs/2307.03288</link>
      <description>arXiv:2307.03288v4 Announce Type: replace-cross 
Abstract: Scalarization is a general, parallizable technique that can be deployed in any multiobjective setting to reduce multiple objectives into one, yet some have dismissed this versatile approach because linear scalarizations cannot explore concave regions of the Pareto frontier. To that end, we aim to find simple non-linear scalarizations that provably explore a diverse set of $k$ objectives on the Pareto frontier, as measured by the dominated hypervolume. We show that hypervolume scalarizations with uniformly random weights achieves an optimal sublinear hypervolume regret bound of $O(T^{-1/k})$, with matching lower bounds that preclude any algorithm from doing better asymptotically. For the setting of multiobjective stochastic linear bandits, we utilize properties of hypervolume scalarizations to derive a novel non-Euclidean analysis to get regret bounds of $\tilde{O}( d T^{-1/2} + T^{-1/k})$, removing unnecessary $\text{poly}(k)$ dependencies. We support our theory with strong empirical performance of using non-linear scalarizations that outperforms both their linear counterparts and other standard multiobjective algorithms in a variety of natural settings.</description>
      <guid isPermaLink="false">oai:arXiv.org:2307.03288v4</guid>
      <category>cs.LG</category>
      <category>cs.DS</category>
      <category>math.OC</category>
      <pubDate>Wed, 06 Nov 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <dc:creator>Qiuyi Zhang (Richard)</dc:creator>
    </item>
    <item>
      <title>Decision-focused predictions via pessimistic bilevel optimization: a computational study</title>
      <link>https://arxiv.org/abs/2312.17640</link>
      <description>arXiv:2312.17640v4 Announce Type: replace-cross 
Abstract: Dealing with uncertainty in optimization parameters is an important and longstanding challenge. Typically, uncertain parameters are predicted accurately, and then a deterministic optimization problem is solved. However, the decisions produced by this so-called \emph{predict-then-optimize} procedure can be highly sensitive to uncertain parameters. In this work, we contribute to recent efforts in producing \emph{decision-focused} predictions, i.e., to build predictive models that are constructed with the goal of minimizing a \emph{regret} measure on the decisions taken with them. We begin by formulating the exact expected regret minimization as a pessimistic bilevel optimization model. Then, we establish NP-completeness of this problem, even in a heavily restricted case. Using duality arguments, we reformulate it as a non-convex quadratic optimization problem. Finally, we show various computational techniques to achieve tractability. We report extensive computational results on shortest-path instances with uncertain cost vectors. Our results indicate that our approach can improve training performance over the approach of Elmachtoub and Grigas (2022), a state-of-the-art method for decision-focused learning.</description>
      <guid isPermaLink="false">oai:arXiv.org:2312.17640v4</guid>
      <category>cs.LG</category>
      <category>math.OC</category>
      <pubDate>Wed, 06 Nov 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>V\'ictor Bucarey, Sophia Calder\'on, Gonzalo Mu\~noz, Frederic Semet</dc:creator>
    </item>
    <item>
      <title>Global Convergence Guarantees for Federated Policy Gradient Methods with Adversaries</title>
      <link>https://arxiv.org/abs/2403.09940</link>
      <description>arXiv:2403.09940v2 Announce Type: replace-cross 
Abstract: Federated Reinforcement Learning (FRL) allows multiple agents to collaboratively build a decision making policy without sharing raw trajectories. However, if a small fraction of these agents are adversarial, it can lead to catastrophic results. We propose a policy gradient based approach that is robust to adversarial agents which can send arbitrary values to the server. Under this setting, our results form the first global convergence guarantees with general parametrization. These results demonstrate resilience with adversaries, while achieving optimal sample complexity of order $\tilde{\mathcal{O}}\left( \frac{1}{N\epsilon^2} \left( 1+ \frac{f^2}{N}\right)\right)$, where $N$ is the total number of agents and $f&lt;N/2$ is the number of adversarial agents.</description>
      <guid isPermaLink="false">oai:arXiv.org:2403.09940v2</guid>
      <category>cs.LG</category>
      <category>cs.AI</category>
      <category>math.OC</category>
      <pubDate>Wed, 06 Nov 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Swetha Ganesh, Jiayu Chen, Gugan Thoppe, Vaneet Aggarwal</dc:creator>
    </item>
    <item>
      <title>Recurrent neural networks: vanishing and exploding gradients are not the end of the story</title>
      <link>https://arxiv.org/abs/2405.21064</link>
      <description>arXiv:2405.21064v2 Announce Type: replace-cross 
Abstract: Recurrent neural networks (RNNs) notoriously struggle to learn long-term memories, primarily due to vanishing and exploding gradients. The recent success of state-space models (SSMs), a subclass of RNNs, to overcome such difficulties challenges our theoretical understanding. In this paper, we delve into the optimization challenges of RNNs and discover that, as the memory of a network increases, changes in its parameters result in increasingly large output variations, making gradient-based learning highly sensitive, even without exploding gradients. Our analysis further reveals the importance of the element-wise recurrence design pattern combined with careful parametrizations in mitigating this effect. This feature is present in SSMs, as well as in other architectures, such as LSTMs. Overall, our insights provide a new explanation for some of the difficulties in gradient-based learning of RNNs and why some architectures perform better than others.</description>
      <guid isPermaLink="false">oai:arXiv.org:2405.21064v2</guid>
      <category>cs.LG</category>
      <category>cs.AI</category>
      <category>math.OC</category>
      <pubDate>Wed, 06 Nov 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Nicolas Zucchet, Antonio Orvieto</dc:creator>
    </item>
    <item>
      <title>Maximum Likelihood Identification of Linear Models with Integrating Disturbances for Offset-Free Control</title>
      <link>https://arxiv.org/abs/2406.03760</link>
      <description>arXiv:2406.03760v2 Announce Type: replace-cross 
Abstract: This paper addresses the identification of models for offset-free model predictive control (MPC), where LTI models are augmented with (fictitious) uncontrollable integrating modes, called integrating disturbances. The states and disturbances are typically estimated with a Kalman filter. The disturbance estimates effectively provide integral control, so the quality of the disturbance model (and resulting filter) directly influences the control performance. We implement eigenvalue constraints to protect against undesirable filter behavior (unstable or marginally stable modes, high-frequency oscillations). Specifically, we consider the class of linear matrix inequality (LMI) regions for eigenvalue constraints. These LMI regions are open sets by default, so we introduce a barrier function method to create tightened, but closed, eigenvalue constraints. To solve the resulting nonlinear semidefinite program, we approximate it as a nonlinear program using a Cholesky factorization method that exploits known sparsity structures of semidefinite optimization variables and matrix inequalities. The algorithm is applied to real-world data taken from two physical systems: first, a low-cost benchmark temperature microcontroller suitable for classroom laboratories, and second, an industrial-scale chemical reactor at Eastman Chemical's plant in Kingsport, TN.</description>
      <guid isPermaLink="false">oai:arXiv.org:2406.03760v2</guid>
      <category>eess.SY</category>
      <category>cs.SY</category>
      <category>math.OC</category>
      <pubDate>Wed, 06 Nov 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Steven J. Kuntz, James B. Rawlings</dc:creator>
    </item>
    <item>
      <title>Privacy of the last iterate in cyclically-sampled DP-SGD on nonconvex composite losses</title>
      <link>https://arxiv.org/abs/2407.05237</link>
      <description>arXiv:2407.05237v2 Announce Type: replace-cross 
Abstract: Differentially-private stochastic gradient descent (DP-SGD) is a family of iterative machine learning training algorithms that privatize gradients to generate a sequence of differentially-private (DP) model parameters. It is also the standard tool used to train DP models in practice, even though most users are only interested in protecting the privacy of the final model. Tight DP accounting for the last iterate would minimize the amount of noise required while maintaining the same privacy guarantee and potentially increasing model utility. However, last-iterate accounting is challenging, and existing works require strong assumptions not satisfied by most implementations. These include assuming (i) the global sensitivity constant is known - to avoid gradient clipping; (ii) the loss function is Lipschitz or convex; and (iii) input batches are sampled randomly.
  In this work, we forego any unrealistic assumptions and provide privacy bounds for the most commonly used variant of DP-SGD, in which data is traversed cyclically, gradients are clipped, and only the last model is released. More specifically, we establish new Renyi differential privacy (RDP) upper bounds for the last iterate under realistic assumptions of small stepsize and Lipschitz smoothness of the loss function. Our general bounds also recover the special-case convex bounds when the weak-convexity parameter of the objective function approaches zero and no clipping is performed. The approach itself leverages optimal transport techniques for last iterate bounds, which is a nontrivial task when the data is traversed cyclically and the loss function is nonconvex.</description>
      <guid isPermaLink="false">oai:arXiv.org:2407.05237v2</guid>
      <category>cs.LG</category>
      <category>cs.CR</category>
      <category>cs.DS</category>
      <category>math.OC</category>
      <category>stat.ML</category>
      <pubDate>Wed, 06 Nov 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Weiwei Kong, M\'onica Ribero</dc:creator>
    </item>
    <item>
      <title>Convergence of Decentralized Actor-Critic Algorithm in General-sum Markov Games</title>
      <link>https://arxiv.org/abs/2409.04613</link>
      <description>arXiv:2409.04613v3 Announce Type: replace-cross 
Abstract: Markov games provide a powerful framework for modeling strategic multi-agent interactions in dynamic environments. Traditionally, convergence properties of decentralized learning algorithms in these settings have been established only for special cases, such as Markov zero-sum and potential games, which do not fully capture real-world interactions. In this paper, we address this gap by studying the asymptotic properties of learning algorithms in general-sum Markov games. In particular, we focus on a decentralized algorithm where each agent adopts an actor-critic learning dynamic with asynchronous step sizes. This decentralized approach enables agents to operate independently, without requiring knowledge of others' strategies or payoffs. We introduce the concept of a Markov Near-Potential Function (MNPF) and demonstrate that it serves as an approximate Lyapunov function for the policy updates in the decentralized learning dynamics, which allows us to characterize the convergent set of strategies. We further strengthen our result under specific regularity conditions and with finite Nash equilibria.</description>
      <guid isPermaLink="false">oai:arXiv.org:2409.04613v3</guid>
      <category>cs.MA</category>
      <category>cs.AI</category>
      <category>cs.GT</category>
      <category>cs.SY</category>
      <category>eess.SY</category>
      <category>math.OC</category>
      <pubDate>Wed, 06 Nov 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Chinmay Maheshwari, Manxi Wu, Shankar Sastry</dc:creator>
    </item>
    <item>
      <title>Learning to Optimize for Mixed-Integer Non-linear Programming</title>
      <link>https://arxiv.org/abs/2410.11061</link>
      <description>arXiv:2410.11061v3 Announce Type: replace-cross 
Abstract: Mixed-integer non-linear programs (MINLPs) arise in various domains, such as energy systems and transportation, but are notoriously difficult to solve. Recent advances in machine learning have led to remarkable successes in optimization tasks, an area broadly known as learning to optimize. This approach includes using predictive models to generate solutions for optimization problems with continuous decision variables, thereby avoiding the need for computationally expensive optimization algorithms. However, applying learning to MINLPs remains challenging primarily due to the presence of integer decision variables, which complicate gradient-based learning. To address this limitation, we propose two differentiable correction layers that generate integer outputs while preserving gradient information. Combined with a soft penalty for constraint violation, our framework can tackle both the integrality and non-linear constraints in a MINLP. Experiments on three problem classes with convex/non-convex objective/constraints and integer/mixed-integer variables show that the proposed learning-based approach consistently produces high-quality solutions for parametric MINLPs extremely quickly. As problem size increases, traditional exact solvers and heuristic methods struggle to find feasible solutions, whereas our approach continues to deliver reliable results. Our work extends the scope of learning-to-optimize to MINLP, paving the way for integrating integer constraints into deep learning models. Our code is available at https://github.com/pnnl/L2O-pMINLP.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.11061v3</guid>
      <category>cs.LG</category>
      <category>math.OC</category>
      <pubDate>Wed, 06 Nov 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Bo Tang, Elias B. Khalil, J\'an Drgo\v{n}a</dc:creator>
    </item>
    <item>
      <title>Hierarchical Network Partitioning for Solution of Potential-Driven, Steady-State Nonlinear Network Flow Equations</title>
      <link>https://arxiv.org/abs/2410.19850</link>
      <description>arXiv:2410.19850v2 Announce Type: replace-cross 
Abstract: Potential-driven steady-state flow in networks is an abstract problem which manifests in various engineering applications, such as transport of natural gas, water, electric power through infrastructure networks or flow through fractured rocks modeled as discrete fracture networks. The relevance of steady-state network flow to control systems and optimization, as well as the question of the existence of a solution for a particular class of flows, has been established in a prior article (IEEE Control Systems Letters (2024), doi:10.1109/LCSYS.2024.3394317). Building on that foundation, this article concerns itself with computation of such a solution for a large network since the problem while simple when restricted to a single edge of a network, ceases to be so for a large network. The resultant system of nonlinear equations depends on the network topology and in general there is no numerical algorithm that offers guaranteed convergence to the solution (assuming a solution exists). Some methods offer guarantees in cases where the network topology satisfies certain assumptions, but these methods fail for larger networks. On the other hand, the Newton-Raphson algorithm offers a convergence guarantee if the starting point lies close to the (unknown) solution. It would be advantageous to compute the solution of the large nonlinear system through the solution of smaller nonlinear sub-systems wherein the solution algorithms (Newton-Raphson or otherwise) are more likely to succeed. This article proposes and describes such a procedure, an hierarchical network partitioning algorithm that enables the solution of large nonlinear systems corresponding to potential-driven steady-state network flow equations.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.19850v2</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <category>math.OC</category>
      <pubDate>Wed, 06 Nov 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Shriram Srinivasan, Kaarthik Sundar</dc:creator>
    </item>
  </channel>
</rss>
