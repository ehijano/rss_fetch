<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>q-bio.NC updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/q-bio.NC</link>
    <description>q-bio.NC updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/q-bio.NC" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Wed, 31 Jul 2024 01:46:55 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Tue, 30 Jul 2024 00:00:00 -0400</pubDate>
    <skipDays>
      <day>Sunday</day>
      <day>Saturday</day>
    </skipDays>
    <item>
      <title>Synchronization in a small-world network of non-identical Chialvo neurons</title>
      <link>https://arxiv.org/abs/2407.18922</link>
      <description>arXiv:2407.18922v1 Announce Type: new 
Abstract: We investigate the synchronization dynamics of a neuron network constructed using the small-world algorithm. The stochastic version of the map-based Chialvo neuron model is used to simulate each node of the network. To represent non-identical neurons, we introduce a mismatch in one of the main model parameters. Our study explores the impact of this mismatch, noise intensity in the stochastic model, and coupling strength between neurons on synchronization and firing frequency. In our initial approach, we consider electrically coupled neurons with both excitatory and inhibitory connections. We have identified critical values of noise intensity, parameter mismatch, and rewiring probability that lead to effective synchronization within the network. Additionally, we observe that the balance between excitatory and inhibitory connections significantly influences global synchronization. Our findings provide insights into the mechanisms underlying synchronization dynamics in complex neuron networks.</description>
      <guid isPermaLink="false">oai:arXiv.org:2407.18922v1</guid>
      <category>q-bio.NC</category>
      <category>nlin.CD</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>J. Used, J. M. Seoane, I. Bashkirtseva, L. Ryashko, M. A. F. Sanju\'an</dc:creator>
    </item>
    <item>
      <title>Markov Processes and Brain Network Hubs</title>
      <link>https://arxiv.org/abs/2407.18924</link>
      <description>arXiv:2407.18924v1 Announce Type: new 
Abstract: Current concepts of neural networks have emerged over two centuries of progress beginning with the neural doctrine to the idea of neural cell assemblies. Presently the model of neural networks involves distributed neural circuits of nodes, hubs, and connections that are dynamic in different states of brain function. Advances in neurophysiology, neuroimaging and the field of connectomics have given impetus to the application of mathematical concepts of graph theory. Current approaches do carry limitations and inconsistency in results achieved. We model the neural network of the brain as a directed graph and attach a matrix (called the Markov matrix) of transition probabilities (determined by the synaptic strengths) to every pair of distinct nodes giving rise to a (continuous) Markov process. We postulate that the network hubs are the nodes with the highest probabilities given by the stationary distribution of Markov theory. We also derive a new upper bound for the diameter of a graph in terms of the eigenvalues of the Markov matrix.</description>
      <guid isPermaLink="false">oai:arXiv.org:2407.18924v1</guid>
      <category>q-bio.NC</category>
      <category>math.PR</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>M. Ram Murty, A. Narayan Prasad</dc:creator>
    </item>
    <item>
      <title>QEEGNet: Quantum Machine Learning for Enhanced Electroencephalography Encoding</title>
      <link>https://arxiv.org/abs/2407.19214</link>
      <description>arXiv:2407.19214v2 Announce Type: new 
Abstract: Electroencephalography (EEG) is a critical tool in neuroscience and clinical practice for monitoring and analyzing brain activity. Traditional neural network models, such as EEGNet, have achieved considerable success in decoding EEG signals but often struggle with the complexity and high dimensionality of the data. Recent advances in quantum computing present new opportunities to enhance machine learning models through quantum machine learning (QML) techniques. In this paper, we introduce Quantum-EEGNet (QEEGNet), a novel hybrid neural network that integrates quantum computing with the classical EEGNet architecture to improve EEG encoding and analysis, as a forward-looking approach, acknowledging that the results might not always surpass traditional methods but it shows its potential. QEEGNet incorporates quantum layers within the neural network, allowing it to capture more intricate patterns in EEG data and potentially offering computational advantages. We evaluate QEEGNet on a benchmark EEG dataset, BCI Competition IV 2a, demonstrating that it consistently outperforms traditional EEGNet on most of the subjects and other robustness to noise. Our results highlight the significant potential of quantum-enhanced neural networks in EEG analysis, suggesting new directions for both research and practical applications in the field.</description>
      <guid isPermaLink="false">oai:arXiv.org:2407.19214v2</guid>
      <category>q-bio.NC</category>
      <category>quant-ph</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Chi-Sheng Chen, Samuel Yen-Chi Chen, Aidan Hung-Wen Tsai, Chun-Shu Wei</dc:creator>
    </item>
    <item>
      <title>Analyzing the Brain's Dynamic Response to Targeted Stimulation using Generative Modeling</title>
      <link>https://arxiv.org/abs/2407.19737</link>
      <description>arXiv:2407.19737v1 Announce Type: new 
Abstract: Generative models of brain activity have been instrumental in testing hypothesized mechanisms underlying brain dynamics against experimental datasets. Beyond capturing the key mechanisms underlying spontaneous brain dynamics, these models hold an exciting potential for understanding the mechanisms underlying the dynamics evoked by targeted brain-stimulation techniques. This paper delves into this emerging application, using concepts from dynamical systems theory to argue that the stimulus-evoked dynamics in such experiments may be shaped by new types of mechanisms distinct from those that dominate spontaneous dynamics. We review and discuss: (i) the targeted experimental techniques across spatial scales that can both perturb the brain to novel states and resolve its relaxation trajectory back to spontaneous dynamics; and (ii) how we can understand these dynamics in terms of mechanisms using physiological, phenomenological, and data-driven models. A tight integration of targeted stimulation experiments with generative quantitative modeling provides an important opportunity to uncover novel mechanisms of brain dynamics that are difficult to detect in spontaneous settings.</description>
      <guid isPermaLink="false">oai:arXiv.org:2407.19737v1</guid>
      <category>q-bio.NC</category>
      <category>physics.bio-ph</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <dc:creator>Rishikesan Maran, Eli J. M\"uller, Ben D. Fulcher</dc:creator>
    </item>
    <item>
      <title>Phase transformation and synchrony for a network of coupled Izhikevich neurons</title>
      <link>https://arxiv.org/abs/2407.20055</link>
      <description>arXiv:2407.20055v1 Announce Type: new 
Abstract: A number of recent articles have employed the Lorentz ansatz to reduce a network of Izhikevich neurons to a tractable mean-field description. In this letter, we construct an equivalent phase model for the Izhikevich model and apply the Ott-Antonsen ansatz, to derive the mean field dynamics in terms of the Kuramoto order parameter. In addition, we show that by defining an appropriate order parameter in the voltage-firing rate framework, the conformal mapping of Montbri\'o et al., which relates the two mean-field descriptions, remains valid.</description>
      <guid isPermaLink="false">oai:arXiv.org:2407.20055v1</guid>
      <category>q-bio.NC</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>\'Aine Byrne</dc:creator>
    </item>
    <item>
      <title>Multi-modal Imaging Genomics Transformer: Attentive Integration of Imaging with Genomic Biomarkers for Schizophrenia Classification</title>
      <link>https://arxiv.org/abs/2407.19385</link>
      <description>arXiv:2407.19385v1 Announce Type: cross 
Abstract: Schizophrenia (SZ) is a severe brain disorder marked by diverse cognitive impairments, abnormalities in brain structure, function, and genetic factors. Its complex symptoms and overlap with other psychiatric conditions challenge traditional diagnostic methods, necessitating advanced systems to improve precision. Existing research studies have mostly focused on imaging data, such as structural and functional MRI, for SZ diagnosis. There has been less focus on the integration of genomic features despite their potential in identifying heritable SZ traits. In this study, we introduce a Multi-modal Imaging Genomics Transformer (MIGTrans), that attentively integrates genomics with structural and functional imaging data to capture SZ-related neuroanatomical and connectome abnormalities. MIGTrans demonstrated improved SZ classification performance with an accuracy of 86.05% (+/- 0.02), offering clear interpretations and identifying significant genomic locations and brain morphological/connectivity patterns associated with SZ.</description>
      <guid isPermaLink="false">oai:arXiv.org:2407.19385v1</guid>
      <category>cs.CV</category>
      <category>cs.AI</category>
      <category>cs.LG</category>
      <category>q-bio.NC</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Nagur Shareef Shaik, Teja Krishna Cherukuri, Vince D. Calhoun, Dong Hye Ye</dc:creator>
    </item>
    <item>
      <title>Classification of Alzheimer's Dementia vs. Healthy subjects by studying structural disparities in fMRI Time-Series of DMN</title>
      <link>https://arxiv.org/abs/2407.19990</link>
      <description>arXiv:2407.19990v1 Announce Type: cross 
Abstract: Time series from different regions of interest (ROI) of default mode network (DMN) from Functional Magnetic Resonance Imaging (fMRI) can reveal significant differences between healthy and unhealthy people. Here, we propose the utility of an existing metric quantifying the lack/presence of structure in a signal called, "deviation from stochasticity" (DS) measure to characterize resting-state fMRI time series. The hypothesis is that differences in the level of structure in the time series can lead to discrimination between the subject groups. In this work, an autoencoder-based model is utilized to learn efficient representations of data by training the network to reconstruct its input data. The proposed methodology is applied on fMRI time series of 50 healthy individuals and 50 subjects with Alzheimer's Disease (AD), obtained from publicly available ADNI database. DS measure for healthy fMRI as expected turns out to be different compared to that of AD. Peak classification accuracy of 95% was obtained using Gradient Boosting classifier, using the DS measure applied on 100 subjects.</description>
      <guid isPermaLink="false">oai:arXiv.org:2407.19990v1</guid>
      <category>cs.LG</category>
      <category>eess.IV</category>
      <category>q-bio.NC</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Sneha Noble, Chakka Sai Pradeep, Neelam Sinha, Thomas Gregor Issac</dc:creator>
    </item>
    <item>
      <title>Bridging Cognitive Maps: a Hierarchical Active Inference Model of Spatial Alternation Tasks and the Hippocampal-Prefrontal Circuit</title>
      <link>https://arxiv.org/abs/2308.11463</link>
      <description>arXiv:2308.11463v3 Announce Type: replace 
Abstract: Cognitive problem-solving benefits from cognitive maps aiding navigation and planning. Previous studies revealed that cognitive maps for physical space navigation involve hippocampal (HC) allocentric codes, while cognitive maps for abstract task space engage medial prefrontal cortex (mPFC) task-specific codes. Solving challenging cognitive tasks requires integrating these two types of maps. This is exemplified by spatial alternation tasks in multi-corridor settings, where animals like rodents are rewarded upon executing an alternation pattern in maze corridors. Existing studies demonstrated the HC - mPFC circuit's engagement in spatial alternation tasks and that its disruption impairs task performance. Yet, a comprehensive theory explaining how this circuit integrates task-related and spatial information is lacking. We advance a novel hierarchical active inference model clarifying how the HC - mPFC circuit enables the resolution of spatial alternation tasks, by merging physical and task-space cognitive maps. Through a series of simulations, we demonstrate that the model's dual layers acquire effective cognitive maps for navigation within physical (HC map) and task (mPFC map) spaces, using a biologically-inspired approach: a clone-structured cognitive graph. The model solves spatial alternation tasks through reciprocal interactions between the two layers. Importantly, disrupting inter-layer communication impairs difficult decisions, consistent with empirical findings. The same model showcases the ability to switch between multiple alternation rules. However, inhibiting message transmission between the two layers results in perseverative behavior, consistent with empirical findings. In summary, our model provides a mechanistic account of how the HC - mPFC circuit supports spatial alternation tasks and how its disruption impairs task performance.</description>
      <guid isPermaLink="false">oai:arXiv.org:2308.11463v3</guid>
      <category>q-bio.NC</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Toon Van de Maele, Bart Dhoedt, Tim Verbelen, Giovanni Pezzulo</dc:creator>
    </item>
    <item>
      <title>Is artificial consciousness achievable? Lessons from the human brain</title>
      <link>https://arxiv.org/abs/2405.04540</link>
      <description>arXiv:2405.04540v2 Announce Type: replace 
Abstract: We here analyse the question of developing artificial consciousness from an evolutionary perspective, taking the evolution of the human brain and its relation with consciousness as a reference model. This kind of analysis reveals several structural and functional features of the human brain that appear to be key for reaching human-like complex conscious experience and that current research on Artificial Intelligence (AI) should take into account in its attempt to develop systems capable of conscious processing. We argue that, even if AI is limited in its ability to emulate human consciousness for both intrinsic (structural and architectural) and extrinsic (related to the current stage of scientific and technological knowledge) reasons, taking inspiration from those characteristics of the brain that make conscious processing possible and/or modulate it, is a potentially promising strategy towards developing conscious AI. Also, it is theoretically possible that AI research can develop partial or potentially alternative forms of consciousness that is qualitatively different from the human, and that may be either more or less sophisticated depending on the perspectives. Therefore, we recommend neuroscience-inspired caution in talking about artificial consciousness: since the use of the same word consciousness for humans and AI becomes ambiguous and potentially misleading, we propose to clearly specify what is common and what differs in AI conscious processing from full human conscious experience.</description>
      <guid isPermaLink="false">oai:arXiv.org:2405.04540v2</guid>
      <category>q-bio.NC</category>
      <category>cs.AI</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Michele Farisco, Kathinka Evers, Jean-Pierre Changeux</dc:creator>
    </item>
  </channel>
</rss>
