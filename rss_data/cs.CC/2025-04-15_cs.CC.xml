<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>cs.CC updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/cs.CC</link>
    <description>cs.CC updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/cs.CC" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Tue, 15 Apr 2025 04:00:12 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Tue, 15 Apr 2025 00:00:00 -0400</pubDate>
    <skipDays>
      <day>Saturday</day>
      <day>Sunday</day>
    </skipDays>
    <item>
      <title>Relative-error testing of conjunctions and decision lists</title>
      <link>https://arxiv.org/abs/2504.08987</link>
      <description>arXiv:2504.08987v1 Announce Type: new 
Abstract: We study the relative-error property testing model for Boolean functions that was recently introduced in the work of Chen et al. (SODA 2025). In relative-error testing, the testing algorithm gets uniform random satisfying assignments as well as black-box queries to $f$, and it must accept $f$ with high probability whenever $f$ has the property that is being tested and reject any $f$ that is relative-error far from having the property. Here the relative-error distance from $f$ to a function $g$ is measured with respect to $|f^{-1}(1)|$ rather than with respect to the entire domain size $2^n$ as in the Hamming distance measure that is used in the standard model; thus, unlike the standard model, relative-error testing allows us to study the testability of sparse Boolean functions that have few satisfying assignments. It was shown in Chen et al. (SODA 2025) that relative-error testing is at least as difficult as standard-model property testing, but for many natural and important Boolean function classes the precise relationship between the two notions is unknown.
  In this paper we consider the well-studied and fundamental properties of being a conjunction and being a decision list. In the relative-error setting, we give an efficient one-sided error tester for conjunctions with running time and query complexity $O(1/\epsilon)$.
  Secondly, we give a two-sided relative-error $\tilde{O}$$(1/\epsilon)$ tester for decision lists, matching the query complexity of the state-of-the-art algorithm in the standard model Bshouty (RANDOM 2020) and Diakonikolas et al. (FOCS 2007).</description>
      <guid isPermaLink="false">oai:arXiv.org:2504.08987v1</guid>
      <category>cs.CC</category>
      <category>cs.DM</category>
      <category>cs.DS</category>
      <pubDate>Tue, 15 Apr 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Xi Chen, William Pires, Toniann Pitassi, Rocco A. Servedio</dc:creator>
    </item>
    <item>
      <title>Testing Juntas and Junta Subclasses with Relative Error</title>
      <link>https://arxiv.org/abs/2504.09312</link>
      <description>arXiv:2504.09312v1 Announce Type: new 
Abstract: This papers considers the junta testing problem in a recently introduced ``relative error'' variant of the standard Boolean function property testing model. In relative-error testing we measure the distance from $f$ to $g$, where $f,g: \{0,1\}^n \to \{0,1\}$, by the ratio of $|f^{-1}(1) \triangle g^{-1}(1)|$ (the number of inputs on which $f$ and $g$ disagree) to $|f^{-1}(1)|$ (the number of satisfying assignments of $f$), and we give the testing algorithm both black-box access to $f$ and also access to independent uniform samples from $f^{-1}(1)$.
  Chen et al. (SODA 2025) observed that the class of $k$-juntas is $\text{poly}(2^k,1/\epsilon)$-query testable in the relative-error model, and asked whether $\text{poly}(k,1/\epsilon)$ queries is achievable. We answer this question affirmatively by giving a $\tilde{O}(k/\epsilon)$-query algorithm, matching the optimal complexity achieved in the less challenging standard model. Moreover, as our main result, we show that any subclass of $k$-juntas that is closed under permuting variables is relative-error testable with a similar complexity. This gives highly efficient relative-error testing algorithms for a number of well-studied function classes, including size-$k$ decision trees, size-$k$ branching programs, and size-$k$ Boolean formulas.</description>
      <guid isPermaLink="false">oai:arXiv.org:2504.09312v1</guid>
      <category>cs.CC</category>
      <category>cs.DM</category>
      <category>cs.DS</category>
      <pubDate>Tue, 15 Apr 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Xi Chen, William Pires, Toniann Pitassi, Rocco A. Servedio</dc:creator>
    </item>
    <item>
      <title>Bipartite Matching is in Catalytic Logspace</title>
      <link>https://arxiv.org/abs/2504.09991</link>
      <description>arXiv:2504.09991v1 Announce Type: new 
Abstract: Matching is a central problem in theoretical computer science, with a large body of work spanning the last five decades. However, understanding matching in the time-space bounded setting remains a longstanding open question, even in the presence of additional resources such as randomness or non-determinism.
  In this work we study space-bounded machines with access to catalytic space, which is additional working memory that is full with arbitrary data that must be preserved at the end of its computation. Despite this heavy restriction, many recent works have shown the power of catalytic space, its utility in designing classical space-bounded algorithms, and surprising connections between catalytic computation and derandomization.
  Our main result is that bipartite maximum matching ($MATCH$) can be computed in catalytic logspace ($CL$) with a polynomial time bound ($CLP$). Moreover, we show that $MATCH$ can be reduced to the lossy coding problem for $NC$ circuits ($LOSSY[NC]$). This has consequences for matching, catalytic space, and derandomization:
  - Matching: this is the first well studied subclass of $P$ which is known to compute $MATCH$, as well as the first algorithm simultaneously using sublinear free space and polynomial time with any additional resources.
  - Catalytic space: this is the first new problem shown to be in $CL$ since the model was defined, and one which is extremely central and well-studied.
  - Derandomization: we give the first class $\mathcal{C}$ beyond $L$ for which we exhibit a natural problem in $LOSSY[\mathcal{C}]$ which is not known to be in $\mathcal{C}$, as well as a full derandomization of the isolation lemma in $CL$ in the context of $MATCH$.
  Our proof combines a number of strengthened ideas from isolation-based algorithms for matching alongside the compress-or-random framework in catalytic computation.</description>
      <guid isPermaLink="false">oai:arXiv.org:2504.09991v1</guid>
      <category>cs.CC</category>
      <category>cs.DS</category>
      <pubDate>Tue, 15 Apr 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Aryan Agarwala, Ian Mertz</dc:creator>
    </item>
    <item>
      <title>Circuits and Formulas for Datalog over Semirings</title>
      <link>https://arxiv.org/abs/2504.08914</link>
      <description>arXiv:2504.08914v1 Announce Type: cross 
Abstract: In this paper, we study circuits and formulas for provenance polynomials of Datalog programs. We ask the following question: given an absorptive semiring and a fact of a Datalog program, what is the optimal depth and size of a circuit/formula that computes its provenance polynomial? We focus on absorptive semirings as these guarantee the existence of a polynomial-size circuit. Our main result is a dichotomy for several classes of Datalog programs on whether they admit a formula of polynomial size or not. We achieve this result by showing that for these Datalog programs the optimal circuit depth is either $\Theta(\log m)$ or $\Theta(\log^2 m)$, where $m$ is the input size. We also show that for Datalog programs with the polynomial fringe property, we can always construct low-depth circuits of size $O(\log^2 m)$. Finally, we give characterizations of when Datalog programs are bounded over more general semirings.</description>
      <guid isPermaLink="false">oai:arXiv.org:2504.08914v1</guid>
      <category>cs.DB</category>
      <category>cs.CC</category>
      <pubDate>Tue, 15 Apr 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Austen Z. Fan, Paraschos Koutris, Sudeepa Roy</dc:creator>
    </item>
    <item>
      <title>Adaptive Robustness of Hypergrid Johnson-Lindenstrauss</title>
      <link>https://arxiv.org/abs/2504.09331</link>
      <description>arXiv:2504.09331v1 Announce Type: cross 
Abstract: Johnson and Lindenstrauss (Contemporary Mathematics, 1984) showed that for $n &gt; m$, a scaled random projection $\mathbf{A}$ from $\mathbb{R}^n$ to $\mathbb{R}^m$ is an approximate isometry on any set $S$ of size at most exponential in $m$. If $S$ is larger, however, its points can contract arbitrarily under $\mathbf{A}$. In particular, the hypergrid $([-B, B] \cap \mathbb{Z})^n$ is expected to contain a point that is contracted by a factor of $\kappa_{\mathsf{stat}} = \Theta(B)^{-1/\alpha}$, where $\alpha = m/n$.
  We give evidence that finding such a point exhibits a statistical-computational gap precisely up to $\kappa_{\mathsf{comp}} = \widetilde{\Theta}(\sqrt{\alpha}/B)$. On the algorithmic side, we design an online algorithm achieving $\kappa_{\mathsf{comp}}$, inspired by a discrepancy minimization algorithm of Bansal and Spencer (Random Structures &amp; Algorithms, 2020). On the hardness side, we show evidence via a multiple overlap gap property (mOGP), which in particular captures online algorithms; and a reduction-based lower bound, which shows hardness under standard worst-case lattice assumptions.
  As a cryptographic application, we show that the rounded Johnson-Lindenstrauss embedding is a robust property-preserving hash function (Boyle, Lavigne and Vaikuntanathan, TCC 2019) on the hypergrid for the Euclidean metric in the computationally hard regime. Such hash functions compress data while preserving $\ell_2$ distances between inputs up to some distortion factor, with the guarantee that even knowing the hash function, no computationally bounded adversary can find any pair of points that violates the distortion bound.</description>
      <guid isPermaLink="false">oai:arXiv.org:2504.09331v1</guid>
      <category>stat.CO</category>
      <category>cs.CC</category>
      <category>cs.DS</category>
      <pubDate>Tue, 15 Apr 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Andrej Bogdanov, Alon Rosen, Neekon Vafa, Vinod Vaikuntanathan</dc:creator>
    </item>
    <item>
      <title>The Rate-Immediacy Barrier in Explicit Tree Code Constructions</title>
      <link>https://arxiv.org/abs/2504.09388</link>
      <description>arXiv:2504.09388v1 Announce Type: cross 
Abstract: Since the introduction of tree codes by Schulman (STOC 1993), explicit construction of such codes has remained a notorious challenge. While the construction of asymptotically-good explicit tree codes continues to be elusive, a work by Cohen, Haeupler and Schulman (STOC 2018), as well as the state-of-the-art construction by Ben Yaacov, Cohen, and Yankovitz (STOC 2022) have achieved codes with rate $\Omega(1/\log\log n)$, exponentially improving upon the original construction of Evans, Klugerman and Schulman from 1994. All of these constructions rely, at least in part, on increasingly sophisticated methods of combining (block) error-correcting codes.
  In this work, we identify a fundamental barrier to constructing tree codes using current techniques. We introduce a key property, which we call immediacy, that, while not required by the original definition of tree codes, is shared by all known constructions and inherently arises from recursive combinations of error-correcting codes. Our main technical contribution is the proof of a rate-immediacy tradeoff, which, in particular, implies that any tree code with constant distance and non-trivial immediacy must necessarily have vanishing rate. By applying our rate-immediacy tradeoff to existing constructions, we establish that their known rate analyses are essentially optimal. More broadly, our work highlights the need for fundamentally new ideas--beyond the recursive use of error-correcting codes--to achieve substantial progress in explicitly constructing asymptotically-good tree codes.</description>
      <guid isPermaLink="false">oai:arXiv.org:2504.09388v1</guid>
      <category>cs.IT</category>
      <category>cs.CC</category>
      <category>cs.DM</category>
      <category>math.IT</category>
      <pubDate>Tue, 15 Apr 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Gil Cohen, Leonard J. Schulman, Piyush Srivastava</dc:creator>
    </item>
    <item>
      <title>Fine-Grained Complexity via Quantum Natural Proofs</title>
      <link>https://arxiv.org/abs/2504.10363</link>
      <description>arXiv:2504.10363v1 Announce Type: cross 
Abstract: Buhrman, Patro, and Speelman presented a framework of conjectures that together form a quantum analogue of the strong exponential-time hypothesis and its variants. They called it the QSETH framework. In this paper, using a notion of quantum natural proofs (built from natural proofs introduced by Razborov and Rudich), we show how part of the QSETH conjecture that requires properties to be `compression oblivious' can in many cases be replaced by assuming the existence of quantum-secure pseudorandom functions, a standard hardness assumption. Combined with techniques from Fourier analysis of Boolean functions, we show that properties such as PARITY and MAJORITY are compression oblivious for certain circuit class $\Lambda$ if subexponentially secure quantum pseudorandom functions exist in $\Lambda$, answering an open question in [Buhrman-Patro-Speelman 2021].</description>
      <guid isPermaLink="false">oai:arXiv.org:2504.10363v1</guid>
      <category>quant-ph</category>
      <category>cs.CC</category>
      <pubDate>Tue, 15 Apr 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Yanlin Chen, Yilei Chen, Rajendra Kumar, Subhasree Patro, Florian Speelman</dc:creator>
    </item>
    <item>
      <title>Constructibility, computational complexity and P versus NP</title>
      <link>https://arxiv.org/abs/2406.16843</link>
      <description>arXiv:2406.16843v5 Announce Type: replace 
Abstract: A decision problem called the IPL problem is defined, and it is argued for the validity of an associated thesis called the IPL thesis. This thesis states that for some instances of the IPL problem, while an algorithm for verifying correct solutions to the problem in polynomial time is explicitly constructible, the IPL problem itself is algorithmically unsolvable in the sense that no explicitly constructed algorithm can be verified as solving the problem. Thus under a constructive interpretation of algorithmic complexity classes, which is arguably their only meaningful interpretation, the IPL thesis implies that NP is not contained in any complexity class consisting of algorithmically solvable problems. In particular, the thesis implies a solution to the P versus NP problem: P is not equal to NP. It also implies that NP is not contained in larger complexity classes such as EXPTIME, seemingly contradicting known results. However, the proofs of the these results all tacitly employ an existence assumption which according to the IPL thesis, does not hold for the IPL problem under a constructive interpretation of algorithmic complexity classes.</description>
      <guid isPermaLink="false">oai:arXiv.org:2406.16843v5</guid>
      <category>cs.CC</category>
      <category>cs.LO</category>
      <pubDate>Tue, 15 Apr 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Arne Hole</dc:creator>
    </item>
    <item>
      <title>On the computational power of $C$-random strings</title>
      <link>https://arxiv.org/abs/2409.04448</link>
      <description>arXiv:2409.04448v3 Announce Type: replace 
Abstract: Denote by $H$ the Halting problem. Let $R_U: = \{ x | C_U(x) \ge |x|\}$, where $C_U(x)$ is the plain Kolmogorov complexity of $x$ under a universal decompressor $U$. We prove that there exists a universal $U$ such that $H \in P^{R_U}$, solving the problem posted by Eric Allender.</description>
      <guid isPermaLink="false">oai:arXiv.org:2409.04448v3</guid>
      <category>cs.CC</category>
      <pubDate>Tue, 15 Apr 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Alexey Milovanov</dc:creator>
    </item>
    <item>
      <title>Space-bounded online Kolmogorov complexity is additive</title>
      <link>https://arxiv.org/abs/2502.02777</link>
      <description>arXiv:2502.02777v2 Announce Type: replace 
Abstract: The even online Kolmogorov complexity of a string $x = x_1 x_2 \cdots x_{n}$ is the minimal length of a program that for all $i\le n/2$, on input $x_1x_3 \cdots x_{2i-1}$ outputs $x_{2i}$. The odd complexity is defined similarly. The sum of the odd and even complexities is called the dialogue complexity.
  In [Bauwens, 2014] it is proven that for all $n$, there exist $n$-bit $x$ for which the dialogue complexity exceeds the Kolmogorov complexity by $n\log \frac 4 3 + O(\log n)$. Let $\mathrm C^s(x)$ denote the Kolmogorov complexity with space bound~$s$. Here, we prove that the space-bounded dialogue complexity with bound $s + 6n + O(1)$ is at most $\mathrm C^{s}(x) + O(\log (sn))$, where $n=|x|$.</description>
      <guid isPermaLink="false">oai:arXiv.org:2502.02777v2</guid>
      <category>cs.CC</category>
      <category>cs.IT</category>
      <category>math.IT</category>
      <pubDate>Tue, 15 Apr 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Bruno Bauwens, Maria Marchenko</dc:creator>
    </item>
    <item>
      <title>Ineffectiveness for Search and Undecidability of PCSP Meta-Problems</title>
      <link>https://arxiv.org/abs/2504.04639</link>
      <description>arXiv:2504.04639v2 Announce Type: replace 
Abstract: It is an open question whether the search and decision versions of promise CSPs are equivalent. Most known algorithms for PCSPs solve only their \emph{decision} variant, and it is unknown whether they can be adapted to solve \emph{search} as well. The main approaches, called BLP, AIP and BLP+AIP, handle a PCSP by finding a solution to a relaxation of some integer program. We prove that rounding those solutions to a proper search certificate can be as hard as any problem in the class TFNP. In other words, these algorithms are ineffective for search. Building on the algebraic approach to PCSPs, we find sufficient conditions that imply ineffectiveness for search. Our tools are tailored to algorithms that are characterized by minions in a suitable way, and can also be used to prove undecidability results for meta-problems. This way, we show that the families of templates solvable via BLP, AIP, and BLP+AIP are undecidable.
  Using the same techniques we also analyze several algebraic conditions that are known to guarantee the tractability of finite-template CSPs. We prove that several meta-problems related to cyclic polymorphims and WNUs are undecidable for PCSPs. In particular, there is no algorithm deciding whether a finite PCSP template (1) admits cyclic a polymorphism, (2) admits a WNU.</description>
      <guid isPermaLink="false">oai:arXiv.org:2504.04639v2</guid>
      <category>cs.CC</category>
      <category>cs.CL</category>
      <category>cs.DS</category>
      <category>cs.LO</category>
      <pubDate>Tue, 15 Apr 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Alberto Larrauri</dc:creator>
    </item>
  </channel>
</rss>
