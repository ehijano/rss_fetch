<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>math.ST updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/math.ST</link>
    <description>math.ST updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/math.ST" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Thu, 27 Mar 2025 04:00:16 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Thu, 27 Mar 2025 00:00:00 -0400</pubDate>
    <skipDays>
      <day>Sunday</day>
      <day>Saturday</day>
    </skipDays>
    <item>
      <title>Functional structural equation models with out-of-sample guarantees</title>
      <link>https://arxiv.org/abs/2503.20072</link>
      <description>arXiv:2503.20072v1 Announce Type: new 
Abstract: Statistical learning methods typically assume that the training and test data originate from the same distribution, enabling effective risk minimization. However, real-world applications frequently involve distributional shifts, leading to poor model generalization. To address this, recent advances in causal inference and robust learning have introduced strategies such as invariant causal prediction and anchor regression. While these approaches have been explored for traditional structural equation models (SEMs), their extension to functional systems remains limited. This paper develops a risk minimization framework for functional SEMs using linear, potentially unbounded operators. We introduce a functional worst-risk minimization approach, ensuring robust predictive performance across shifted environments. Our key contribution is a novel worst-risk decomposition theorem, which expresses the maximum out-of-sample risk in terms of observed environments. We establish conditions for the existence and uniqueness of the worst-risk minimizer and provide consistent estimation procedures. Empirical results on functional systems illustrate the advantages of our method in mitigating distributional shifts. These findings contribute to the growing literature on robust functional regression and causal learning, offering practical guarantees for out-of-sample generalization in dynamic environments.</description>
      <guid isPermaLink="false">oai:arXiv.org:2503.20072v1</guid>
      <category>math.ST</category>
      <category>stat.ME</category>
      <category>stat.TH</category>
      <pubDate>Thu, 27 Mar 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Philip Kennerberg, Ernst C. Wit</dc:creator>
    </item>
    <item>
      <title>Nonparametric MLE for Gaussian Location Mixtures: Certified Computation and Generic Behavior</title>
      <link>https://arxiv.org/abs/2503.20193</link>
      <description>arXiv:2503.20193v1 Announce Type: new 
Abstract: We study the nonparametric maximum likelihood estimator $\widehat{\pi}$ for Gaussian location mixtures in one dimension. It has been known since (Lindsay, 1983) that given an $n$-point dataset, this estimator always returns a mixture with at most $n$ components, and more recently (Wu-Polyanskiy, 2020) gave a sharp $O(\log n)$ bound for subgaussian data. In this work we study computational aspects of $\widehat{\pi}$. We provide an algorithm which for small enough $\varepsilon&gt;0$ computes an $\varepsilon$-approximation of $\widehat\pi$ in Wasserstein distance in time $K+Cnk^2\log\log(1/\varepsilon)$. Here $K$ is data-dependent but independent of $\varepsilon$, while $C$ is an absolute constant and $k=|supp(\widehat{\pi})|\leq n$ is the number of atoms in $\widehat\pi$. We also certifiably compute the exact value of $|supp(\widehat\pi)|$ in finite time. These guarantees hold almost surely whenever the dataset $(x_1,\dots,x_n)\in [-cn^{1/4},cn^{1/4}]$ consists of independent points from a probability distribution with a density (relative to Lebesgue measure). We also show the distribution of $\widehat\pi$ conditioned to be $k$-atomic admits a density on the associated $2k-1$ dimensional parameter space for all $k\leq \sqrt{n}/3$, and almost sure locally linear convergence of the EM algorithm. One key tool is a classical Fourier analytic estimate for non-degenerate curves.</description>
      <guid isPermaLink="false">oai:arXiv.org:2503.20193v1</guid>
      <category>math.ST</category>
      <category>stat.ML</category>
      <category>stat.TH</category>
      <pubDate>Thu, 27 Mar 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Yury Polyanskiy, Mark Sellke</dc:creator>
    </item>
    <item>
      <title>Estimation and variable selection in nonlinear mixed-effects models</title>
      <link>https://arxiv.org/abs/2503.20401</link>
      <description>arXiv:2503.20401v1 Announce Type: new 
Abstract: We consider nonlinear mixed effects models including high-dimensional covariates to model individual parameters. The objective is to identify relevant covariates and estimate model parameters. We combine a penalized LASSO-type estimator with an eBIC model choice criterion to select the covariates of interest. Then we estimate the parameters by maximum likelihood in the reduced model. We calculate the LASSO-type penalized estimator by a weighted proximal gradient descent algorithm with an  adaptive learning rate. This choice allows us in particular to consider models that do not necessarily belong to the curved exponential family. We compare first the performance of the proposed methodology with those of the glmmLasso procedure in a linear mixed effects model in a simulation study. We then illustrate its performance  in a nonlinear mixed-effects logistic growth model through simulation.</description>
      <guid isPermaLink="false">oai:arXiv.org:2503.20401v1</guid>
      <category>math.ST</category>
      <category>stat.TH</category>
      <pubDate>Thu, 27 Mar 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Antoine Caillebotte (MaIAGE, GQE-Le Moulon), Estelle Kuhn (MaIAGE), Sarah Lemler (MICS)</dc:creator>
    </item>
    <item>
      <title>Revisiting general source condition in learning over a Hilbert space</title>
      <link>https://arxiv.org/abs/2503.20495</link>
      <description>arXiv:2503.20495v1 Announce Type: new 
Abstract: In Learning Theory, the smoothness assumption on the target function (known as source condition) is a key factor in establishing theoretical convergence rates for an estimator. The existing general form of the source condition, as discussed in learning theory literature, has traditionally been restricted to a class of functions that can be expressed as a product of an operator monotone function and a Lipschitz continuous function. In this note, we remove these restrictions on the index function and establish optimal convergence rates for least-square regression over a Hilbert space with general regularization under a general source condition, thereby significantly broadening the scope of existing theoretical results.</description>
      <guid isPermaLink="false">oai:arXiv.org:2503.20495v1</guid>
      <category>math.ST</category>
      <category>stat.TH</category>
      <pubDate>Thu, 27 Mar 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Naveen Gupta, S. Sivananthan</dc:creator>
    </item>
    <item>
      <title>Parameter estimation for fractional autoregressive process with periodic structure</title>
      <link>https://arxiv.org/abs/2503.20736</link>
      <description>arXiv:2503.20736v1 Announce Type: new 
Abstract: This paper introduces a new kind of periodic fractional autoregressive process (PFAR) driven by fractional Gaussian noise (fGn). The new model is a specialized varying coefficient fractional autoregressive model, where the coefficients adhere to a periodic structure. In this working, Generalized least squares estimation and GPH method are employed to construct an initial estimator to estimate the joint estimation of the parameters of these models. Then one-step procedure is used to obtain a more asymptotically-efficient estimator. The paper proves that both estimators are consistent and asymptotically normal, and their performance is demonstrated through a simulation study using finite-size samples via Monte Carlo simulations. Simulation studies suggests that, while both estimation methods can accurately estimate the model, the one-step estimator outperforms the initial estimator.</description>
      <guid isPermaLink="false">oai:arXiv.org:2503.20736v1</guid>
      <category>math.ST</category>
      <category>stat.TH</category>
      <pubDate>Thu, 27 Mar 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Chunhao Cai, Yiwu Shang</dc:creator>
    </item>
    <item>
      <title>Concentration inequalities for the sum in sampling without replacement: an approach via majorization</title>
      <link>https://arxiv.org/abs/2503.20473</link>
      <description>arXiv:2503.20473v1 Announce Type: cross 
Abstract: Let $P=(x_1,\ldots,x_n)$ be a population consisting of $n\ge 2$ real numbers whose sum is zero, and let $k &lt;n$ be a positive integer. We sample $k$ elements from $P$ without replacement and denote by $X_P$ the sum of the elements in our sample. In this article, using ideas from the theory of majorization, we deduce non-asymptotic lower and upper bounds on the probability that $X_P$ exceeds its expected value.</description>
      <guid isPermaLink="false">oai:arXiv.org:2503.20473v1</guid>
      <category>math.PR</category>
      <category>math.ST</category>
      <category>stat.TH</category>
      <pubDate>Thu, 27 Mar 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Jianhang Ai, Ond\v{r}ej Ku\v{z}elka, Christos Pelekis</dc:creator>
    </item>
    <item>
      <title>Stochastic Transport Maps in Diffusion Models and Sampling</title>
      <link>https://arxiv.org/abs/2503.20573</link>
      <description>arXiv:2503.20573v1 Announce Type: cross 
Abstract: In this work, we present a theoretical and computational framework for constructing stochastic transport maps between probability distributions using diffusion processes. We begin by proving that the time-marginal distribution of the sum of two independent diffusion processes satisfies a Fokker-Planck equation. Building on this result and applying Ambrosio-Figalli-Trevisan's superposition principle, we establish the existence and uniqueness of solutions to the associated stochastic differential equation (SDE). Leveraging these theoretical foundations, we develop a method to construct (stochastic) transport maps between arbitrary probability distributions using dynamical ordinary differential equations (ODEs) and SDEs. Furthermore, we introduce a unified framework that generalizes and extends a broad class of diffusion-based generative models and sampling techniques. Finally, we analyze the convergence properties of particle approximations for the SDEs underlying our framework, providing theoretical guarantees for their practical implementation. This work bridges theoretical insights with practical applications, offering new tools for generative modeling and sampling in high-dimensional spaces.</description>
      <guid isPermaLink="false">oai:arXiv.org:2503.20573v1</guid>
      <category>math.PR</category>
      <category>math.ST</category>
      <category>stat.TH</category>
      <pubDate>Thu, 27 Mar 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/publicdomain/zero/1.0/</dc:rights>
      <dc:creator>Xicheng Zhang</dc:creator>
    </item>
    <item>
      <title>Learning extremal graphical structures in high dimensions</title>
      <link>https://arxiv.org/abs/2111.00840</link>
      <description>arXiv:2111.00840v5 Announce Type: replace 
Abstract: Extremal graphical models encode the conditional independence structure of multivariate extremes. Key statistics for learning extremal graphical structures are empirical extremal variograms, for which we prove non-asymptotic concentration bounds that hold under general domain of attraction conditions. For the popular class of H\"usler--Reiss models, we propose a majority voting algorithm for learning the underlying graph from data through $L^1$ regularized optimization. Our concentration bounds are used to derive explicit conditions that ensure the consistent recovery of any connected graph. The methodology is illustrated through a simulation study as well as the analysis of river discharge and currency exchange data.</description>
      <guid isPermaLink="false">oai:arXiv.org:2111.00840v5</guid>
      <category>math.ST</category>
      <category>stat.TH</category>
      <pubDate>Thu, 27 Mar 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Sebastian Engelke, Micha\"el Lalancette, Stanislav Volgushev</dc:creator>
    </item>
    <item>
      <title>Depth Patterns and their Applications in Animal Tracking</title>
      <link>https://arxiv.org/abs/2401.13532</link>
      <description>arXiv:2401.13532v2 Announce Type: replace 
Abstract: We establish a definition of ordinal patterns for multivariate data sets based on the concept of Tukey's halfspace depth. Given the definition of these \emph{depth patterns}, we are interested in the probabilities of observing specific patterns in time series. For this, we consider the relative frequency of depth patterns as natural estimators for their occurrence probabilities. Depending on the choice of reference distribution and the relation between reference and data distribution, we distinguish different settings that are considered separately. Within these settings we study statistical properties of depth pattern probabilities, establishing consistency and asymptotic normality under the assumption of weakly dependent time series. Since our concept only depends on ordinal depth information, the resulting values are robust under small perturbations and measurement errors. We emphasize the applicability of our method by analyzing the depth patterns which are found in seal pubs' movement. We use our approach in order to choose an appropriate model out of a range of two-dimensional random walks, which are commonly used in mathematical biology.</description>
      <guid isPermaLink="false">oai:arXiv.org:2401.13532v2</guid>
      <category>math.ST</category>
      <category>math.PR</category>
      <category>stat.TH</category>
      <pubDate>Thu, 27 Mar 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Annika Betken, Alexander Schnurr</dc:creator>
    </item>
    <item>
      <title>Sharp phase transitions in high-dimensional changepoint detection</title>
      <link>https://arxiv.org/abs/2403.11704</link>
      <description>arXiv:2403.11704v2 Announce Type: replace 
Abstract: We study a hypothesis testing problem in the context of high-dimensional changepoint detection. Given a matrix $X \in \R^{p \times n}$ with independent Gaussian entries, the goal is to determine whether or not a sparse, non-null fraction of rows in $X$ exhibits a shift in mean at a common index between $1$ and $n$. We focus on three aspects of this problem: the sparsity of non-null rows, the presence of a single, common changepoint in the non-null rows, and the signal strength associated with the changepoint. Within an asymptotic regime relating the data dimensions $n$ and $p$ to the signal sparsity and strength, the information-theoretic limits of this testing problem are characterized by a formula that determines whether or not there exists a testing procedure whose sum of Type I and II errors tends to zero as $n,p \to \infty$. The formula, called the \emph{detection boundary}, partitions the parameter space into a two regions: one where it is possible to detect the presence of a single aligned changepoint (detectable region), and another where no test is able to consistently distinguish the mean matrix from one with constant rows (undetectable region).</description>
      <guid isPermaLink="false">oai:arXiv.org:2403.11704v2</guid>
      <category>math.ST</category>
      <category>stat.TH</category>
      <pubDate>Thu, 27 Mar 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Daniel Xiang, Chao Gao</dc:creator>
    </item>
    <item>
      <title>What Is a Good Imputation Under MAR Missingness?</title>
      <link>https://arxiv.org/abs/2403.19196</link>
      <description>arXiv:2403.19196v4 Announce Type: replace 
Abstract: Missing values pose a persistent challenge in modern data science. Consequently, there is an ever-growing number of publications introducing new imputation methods in various fields. The present paper attempts to take a step back and provide a more systematic analysis. Starting from an in-depth discussion of the Missing at Random (MAR) condition for nonparametric imputation, we first develop an identification result showing that the widely used fully conditional specification (FCS) approach indeed identifies the correct conditional distributions. Based on this analysis, we propose three essential properties an ideal imputation method should meet, thus enabling a more principled evaluation of existing methods and more targeted development of new methods. In particular, we introduce a new imputation method, denoted mice-DRF, that meets two out of the three criteria. We also discuss ways to compare imputation methods, based on distributional distances. Finally, numerical experiments illustrate the points made in this discussion.</description>
      <guid isPermaLink="false">oai:arXiv.org:2403.19196v4</guid>
      <category>math.ST</category>
      <category>stat.TH</category>
      <pubDate>Thu, 27 Mar 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Jeffrey N\"af (PREMEDICAL), Erwan Scornet (USPC, CNRS), Julie Josse (PREMEDICAL, IDESP)</dc:creator>
    </item>
    <item>
      <title>Bounds on the Distribution of a Sum of Two Random Variables: Revisiting a problem of Kolmogorov with application to Individual Treatment Effects</title>
      <link>https://arxiv.org/abs/2405.08806</link>
      <description>arXiv:2405.08806v2 Announce Type: replace 
Abstract: We revisit the following problem, proposed by Kolmogorov: given prescribed marginal distributions $F$ and $G$ for random variables $X,Y$ respectively, characterize the set of compatible distribution functions for the sum $Z=X+Y$. Bounds on the distribution function for $Z$ were first given by Markarov (1982) and R\"uschendorf (1982) independently. Frank et al. (1987) provided a solution to the same problem using copula theory. However, though these authors obtain the same bounds, they make different assertions concerning their sharpness. In addition, their solutions leave some open problems in the case when the given marginal distribution functions are discontinuous. These issues have led to some confusion and erroneous statements in subsequent literature, which we correct.
  Kolmogorov's problem is closely related to inferring possible distributions for individual treatment effects $Y_1 - Y_0$ given the marginal distributions of $Y_1$ and $Y_0$; the latter being identified from a randomized experiment. We use our new insights to sharpen and correct the results due to Fan and Park (2010) concerning individual treatment effects, and to fill some other logical gaps.</description>
      <guid isPermaLink="false">oai:arXiv.org:2405.08806v2</guid>
      <category>math.ST</category>
      <category>econ.EM</category>
      <category>math.PR</category>
      <category>stat.TH</category>
      <pubDate>Thu, 27 Mar 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Zhehao Zhang, Thomas S. Richardson</dc:creator>
    </item>
    <item>
      <title>Local linear smoothing for regression surfaces on the simplex using Dirichlet kernels</title>
      <link>https://arxiv.org/abs/2408.07209</link>
      <description>arXiv:2408.07209v3 Announce Type: replace 
Abstract: This paper introduces a local linear smoother for regression surfaces on the simplex. The estimator solves a least-squares regression problem weighted by a locally adaptive Dirichlet kernel, ensuring good boundary properties. Asymptotic results for the bias, variance, mean squared error, and mean integrated squared error are derived, generalizing the univariate results of Chen [Ann. Inst. Statist. Math., 54(2) (2002), pp. 312-323]. A simulation study shows that the proposed local linear estimator with Dirichlet kernel outperforms its only direct competitor in the literature, the Nadaraya-Watson estimator with Dirichlet kernel due to Bouzebda, Nezzal and Elhattab [AIMS Math., 9(9) (2024), pp. 26195-26282].</description>
      <guid isPermaLink="false">oai:arXiv.org:2408.07209v3</guid>
      <category>math.ST</category>
      <category>stat.AP</category>
      <category>stat.ME</category>
      <category>stat.TH</category>
      <pubDate>Thu, 27 Mar 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Christian Genest, Fr\'ed\'eric Ouimet</dc:creator>
    </item>
    <item>
      <title>Diffusion on the circle and a stochastic correlation model</title>
      <link>https://arxiv.org/abs/2412.06343</link>
      <description>arXiv:2412.06343v2 Announce Type: replace 
Abstract: We propose analytically tractable SDE models for correlation in financial markets. We study diffusions on the circle, namely the Brownian motion on the circle and the von Mises process, and consider these as models for correlation. The von Mises process was proposed in Kent (1975) as a probabilistic justification for the von Mises distribution which is widely used in Circular statistics. The transition density of the von Mises process has been unknown, we identify an approximate analytic transition density for the von Mises process. We discuss the estimation of these diffusion models and a stochastic correlation model in finance. We illustrate the application of the proposed model on real-data of equity-currency pairs.</description>
      <guid isPermaLink="false">oai:arXiv.org:2412.06343v2</guid>
      <category>math.ST</category>
      <category>q-fin.MF</category>
      <category>stat.TH</category>
      <pubDate>Thu, 27 Mar 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Sourav Majumdar, Arnab Kumar Laha</dc:creator>
    </item>
    <item>
      <title>Asymptotic Normality in LAD Polynomial Regression and Hilbert Matrices</title>
      <link>https://arxiv.org/abs/2503.15041</link>
      <description>arXiv:2503.15041v2 Announce Type: replace 
Abstract: This paper investigates the asymptotic properties of least absolute deviation (LAD) regression for linear models with polynomial regressors, highlighting its robustness against heavy-tailed noise and outliers. Assuming independent and identically distributed (i.i.d.) errors, we establish the multiscale asymptotic normality of LAD estimators. A central result is the derivation of the asymptotic precision matrix, shown to be proportional to Hilbert matrices, with the proportionality coefficient depending on the asymptotic variance of the sample median of the noise distribution. We further explore the estimator's convergence properties, both in probability and almost surely, under varying model specifications. Through comprehensive simulations, we evaluate the speed of convergence of the LAD estimator and the empirical coverage probabilities of confidence intervals constructed under different scaling factors (T 1/2 and T $\alpha$ ). These experiments incorporate a range of noise distributions, including Laplace, Gaussian, and Cauchy, to demonstrate the estimator's robustness and efficiency. The findings underscore the versatility and practical relevance of LAD regression in handling non-standard data environments. By connecting the statistical properties of LAD estimators to classical mathematical structures, such as Hilbert matrices, this study offers both theoretical insights and practical tools for robust statistical modeling.</description>
      <guid isPermaLink="false">oai:arXiv.org:2503.15041v2</guid>
      <category>math.ST</category>
      <category>stat.TH</category>
      <pubDate>Thu, 27 Mar 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Sa\"id Maanan (LPP), Azzouz Dermoune (LPP), Ahmed El Ghini</dc:creator>
    </item>
    <item>
      <title>Strang Splitting for Parametric Inference in Second-order Stochastic Differential Equations</title>
      <link>https://arxiv.org/abs/2405.03606</link>
      <description>arXiv:2405.03606v2 Announce Type: replace-cross 
Abstract: We address parameter estimation in second-order stochastic differential equations (SDEs), which are prevalent in physics, biology, and ecology. The second-order SDE is converted to a first-order system by introducing an auxiliary velocity variable, which raises two main challenges. First, the system is hypoelliptic since the noise affects only the velocity, making the Euler-Maruyama estimator ill-conditioned. We propose an estimator based on the Strang splitting scheme to overcome this. Second, since the velocity is rarely observed, we adapt the estimator to partial observations. We present four estimators for complete and partial observations, using the full pseudo-likelihood or only the velocity-based partial pseudo-likelihood. These estimators are intuitive, easy to implement, and computationally fast, and we prove their consistency and asymptotic normality. Our analysis demonstrates that using the full pseudo-likelihood with complete observations reduces the asymptotic variance of the diffusion estimator. With partial observations, the asymptotic variance increases as a result of information loss but remains unaffected by the likelihood choice. However, a numerical study on the Kramers oscillator reveals that using the partial pseudo-likelihood for partial observations yields less biased estimators. We apply our approach to paleoclimate data from the Greenland ice core by fitting the Kramers oscillator model, capturing transitions between metastable states reflecting observed climatic conditions during glacial eras.</description>
      <guid isPermaLink="false">oai:arXiv.org:2405.03606v2</guid>
      <category>stat.ME</category>
      <category>math.ST</category>
      <category>stat.TH</category>
      <pubDate>Thu, 27 Mar 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Predrag Pilipovic, Adeline Samson, Susanne Ditlevsen</dc:creator>
    </item>
    <item>
      <title>Review and Prospect of Algebraic Research in Equivalent Framework between Statistical Mechanics and Machine Learning Theory</title>
      <link>https://arxiv.org/abs/2406.10234</link>
      <description>arXiv:2406.10234v3 Announce Type: replace-cross 
Abstract: Mathematical equivalence between statistical mechanics and machine learning theory has been known since the 20th century, and research based on this equivalence has provided novel methodologies in both theoretical physics and statistical learning theory. It is well known that algebraic approaches in statistical mechanics such as operator algebra enable us to analyze phase transition phenomena mathematically. In this paper, we review and prospect algebraic research in machine learning theory for theoretical physicists who are interested in artificial intelligence.
  If a learning machine has a hierarchical structure or latent variables, then the random Hamiltonian cannot be expressed by any quadratic perturbation because it has singularities. To study an equilibrium state defined by such a singular random Hamiltonian, algebraic approaches are necessary to derive the asymptotic form of the free energy and the generalization error.
  We also introduce the most recent advance: the theoretical foundation for the alignment of artificial intelligence is now being constructed based on algebraic learning theory.
  This paper is devoted to the memory of Professor Huzihiro Araki who is a pioneering founder of algebraic research in both statistical mechanics and quantum field theory.</description>
      <guid isPermaLink="false">oai:arXiv.org:2406.10234v3</guid>
      <category>cond-mat.stat-mech</category>
      <category>cs.LG</category>
      <category>math.ST</category>
      <category>stat.ML</category>
      <category>stat.TH</category>
      <pubDate>Thu, 27 Mar 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Sumio Watanabe</dc:creator>
    </item>
  </channel>
</rss>
