<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>cs.SI updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/cs.SI</link>
    <description>cs.SI updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/cs.SI" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Mon, 16 Feb 2026 05:00:38 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Mon, 16 Feb 2026 00:00:00 -0500</pubDate>
    <skipDays>
      <day>Saturday</day>
      <day>Sunday</day>
    </skipDays>
    <item>
      <title>Semantic Communities and Boundary-Spanning Lyrics in K-pop: A Graph-Based Unsupervised Analysis</title>
      <link>https://arxiv.org/abs/2602.12881</link>
      <description>arXiv:2602.12881v1 Announce Type: new 
Abstract: Large-scale lyric corpora present unique challenges for data-driven analysis, including the absence of reliable annotations, multilingual content, and high levels of stylistic repetition. Most existing approaches rely on supervised classification, genre labels, or coarse document-level representations, limiting their ability to uncover latent semantic structure. We present a graph-based framework for unsupervised discovery and evaluation of semantic communities in K-pop lyrics using line-level semantic representations. By constructing a similarity graph over lyric texts and applying community detection, we uncover stable micro-theme communities without genre, artist, or language supervision. We further identify boundary-spanning songs via graph-theoretic bridge metrics and analyse their structural properties. Across multiple robustness settings, boundary-spanning lyrics exhibit higher lexical diversity and lower repetition compared to core community members, challenging the assumption that hook intensity or repetition drives cross-theme connectivity. Our framework is language-agnostic and applicable to unlabeled cultural text corpora.</description>
      <guid isPermaLink="false">oai:arXiv.org:2602.12881v1</guid>
      <category>cs.SI</category>
      <category>cs.CL</category>
      <pubDate>Mon, 16 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Oktay Karaku\c{s}</dc:creator>
    </item>
    <item>
      <title>Jointly Optimizing Debiased CTR and Uplift for Coupons Marketing: A Unified Causal Framework</title>
      <link>https://arxiv.org/abs/2602.12972</link>
      <description>arXiv:2602.12972v1 Announce Type: new 
Abstract: In online advertising, marketing interventions such as coupons introduce significant confounding bias into Click-Through Rate (CTR) prediction. Observed clicks reflect a mixture of users' intrinsic preferences and the uplift induced by these interventions. This causes conventional models to miscalibrate base CTRs, which distorts downstream ranking and billing decisions. Furthermore, marketing interventions often operate as multi-valued treatments with varying magnitudes, introducing additional complexity to CTR prediction.
  To address these issues, we propose the \textbf{Uni}fied \textbf{M}ulti-\textbf{V}alued \textbf{T}reatment Network (UniMVT). Specifically, UniMVT disentangles confounding factors from treatment-sensitive representations, enabling a full-space counterfactual inference module to jointly reconstruct the debiased base CTR and intensity-response curves. To handle the complexity of multi-valued treatments, UniMVT employs an auxiliary intensity estimation task to capture treatment propensities and devise a unit uplift objective that normalizes the intervention effect. This ensures comparable estimation across the continuous coupon-value spectrum. UniMVT simultaneously achieves debiased CTR prediction for accurate system calibration and precise uplift estimation for incentive allocation. Extensive experiments on synthetic and industrial datasets demonstrate UniMVT's superiority in both predictive accuracy and calibration. Furthermore, real-world A/B tests confirm that UniMVT significantly improves business metrics through more effective coupon distribution.</description>
      <guid isPermaLink="false">oai:arXiv.org:2602.12972v1</guid>
      <category>cs.SI</category>
      <category>cs.LG</category>
      <pubDate>Mon, 16 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Siyun Yang, Shixiao Yang, Jian Wang, Di Fan, Kehe Cai, Haoyan Fu, Jiaming Zhang, Wenjin Wu, Peng Jiang</dc:creator>
    </item>
    <item>
      <title>Revealing Process Structure in Urban Mobility Networks</title>
      <link>https://arxiv.org/abs/2602.13082</link>
      <description>arXiv:2602.13082v1 Announce Type: new 
Abstract: Urban mobility is a multi-entity system that involves travelers, transport modes, and infrastructure. Beyond conventional origin/destination analysis, this paper investigates how process mining can structure and interpret mobility behavior from event data. Using Call Detail Records (CDRs) from Oeiras in the Lisbon metropolitan area (Portugal), we construct both case-centric and object-centric event logs and discover models that summarize flows and typical durations. Results show that most trips are intra-municipal, while inter-municipal flows connect strongly to neighboring areas, with typical inter-parish travel times of about 20 minutes. The object-centric perspective explicitly links trips and transport modes, revealing mode-specific duration differences (e.g., bus vs. car) that inform multimodal planning. Our contributions are: (i) a reproducible pipeline to transform CDRs into process mining artifacts, (ii) empirical evidence that mobility data exhibit a process-like structure, and (iii) the added value of object-centric models for multimodal analysis. Limitations include the low spatial precision of CDRs (tower-sector level) and heuristic transport-mode labels. Future work will integrate transport-network context (e.g., stations and routes) and model object-centric logs as heterogeneous graphs to enable richer and more reliable analysis.</description>
      <guid isPermaLink="false">oai:arXiv.org:2602.13082v1</guid>
      <category>cs.SI</category>
      <pubDate>Mon, 16 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Khristina Filonchik, Jose Pedro Pinto, Fl\'avio L. Pinheiro, Fernando Bacao</dc:creator>
    </item>
    <item>
      <title>Policy4OOD: A Knowledge-Guided World Model for Policy Intervention Simulation against the Opioid Overdose Crisis</title>
      <link>https://arxiv.org/abs/2602.12373</link>
      <description>arXiv:2602.12373v1 Announce Type: cross 
Abstract: The opioid epidemic remains one of the most severe public health crises in the United States, yet evaluating policy interventions before implementation is difficult: multiple policies interact within a dynamic system where targeting one risk pathway may inadvertently amplify another. We argue that effective opioid policy evaluation requires three capabilities -- forecasting future outcomes under current policies, counterfactual reasoning about alternative past decisions, and optimization over candidate interventions -- and propose to unify them through world modeling. We introduce Policy4OOD, a knowledge-guided spatio-temporal world model that addresses three core challenges: what policies prescribe, where effects manifest, and when effects unfold.Policy4OOD jointly encodes policy knowledge graphs, state-level spatial dependencies, and socioeconomic time series into a policy-conditioned Transformer that forecasts future opioid outcomes.Once trained, the world model serves as a simulator: forecasting requires only a forward pass, counterfactual analysis substitutes alternative policy encodings in the historical sequence, and policy optimization employs Monte Carlo Tree Search over the learned simulator. To support this framework, we construct a state-level monthly dataset (2019--2024) integrating opioid mortality, socioeconomic indicators, and structured policy encodings. Experiments demonstrate that spatial dependencies and structured policy knowledge significantly improve forecasting accuracy, validating each architectural component and the potential of world modeling for data-driven public health decision support.</description>
      <guid isPermaLink="false">oai:arXiv.org:2602.12373v1</guid>
      <category>cs.LG</category>
      <category>cs.AI</category>
      <category>cs.SI</category>
      <pubDate>Mon, 16 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Yijun Ma, Zehong Wang, Weixiang Sun, Zheyuan Zhang, Kaiwen Shi, Nitesh Chawla, Yanfang Ye</dc:creator>
    </item>
    <item>
      <title>Governing Social Media as a Public Utility: A Case for Sovereign Digital Infrastructure</title>
      <link>https://arxiv.org/abs/2602.12535</link>
      <description>arXiv:2602.12535v1 Announce Type: cross 
Abstract: Social media platforms connect billions, but their business models often amplify societal harm through misinformation, which is linked to polarization, violence, and declining mental health. Current governance frameworks, such as the U.S. Section 230 and the EU Digital Services Act, delegate content moderation to corporations. This creates structural conflicts of interest because misinformation drives engagement, and engagement drives profit. We propose a public utility model for social media governance that prioritizes the public good over commercial incentives. Integrating legislated content removal with democratic content moderation, the model protects free expression while mitigating societal harms. It frames social media as sovereign digital infrastructure governed through democratic oversight, transparent algorithms, and institutional safeguards.</description>
      <guid isPermaLink="false">oai:arXiv.org:2602.12535v1</guid>
      <category>cs.CY</category>
      <category>cs.SI</category>
      <pubDate>Mon, 16 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <arxiv:DOI>10.1145/3788880</arxiv:DOI>
      <arxiv:journal_reference>Communications of the ACM, 2026</arxiv:journal_reference>
      <dc:creator>Christoph Mueller-Bloch, Raffaele Ciriello</dc:creator>
    </item>
    <item>
      <title>Finding Super-spreaders in SIS Epidemics</title>
      <link>https://arxiv.org/abs/2602.12568</link>
      <description>arXiv:2602.12568v1 Announce Type: cross 
Abstract: In network epidemic models, controlling the spread of a disease often requires targeted interventions such as vaccinating high-risk individuals based on network structure. However, typical approaches assume complete knowledge of the underlying contact network, which is often unavailable. While network structure can be learned from observed epidemic dynamics, existing methods require long observation windows that may delay critical interventions.
  In this work, we show that full network reconstruction may not be necessary: control-relevant features, such as high-degree vertices (super-spreaders), can be learned far more efficiently than the complete structure. Specifically, we develop an algorithm to identify such vertices from the dynamics of a Susceptible-Infected-Susceptible (SIS) process. We prove that in an $n$-vertex graph, vertices of degree at least $n^\alpha$ can be identified over an observation window of size $\Omega (1/\alpha)$, for any $\alpha \in (0,1)$. In contrast, existing methods for exact network reconstruction requires an observation window that grows linearly with $n$. Simulations demonstrate that our approach accurately identifies super-spreaders and enables effective epidemic control.</description>
      <guid isPermaLink="false">oai:arXiv.org:2602.12568v1</guid>
      <category>math.ST</category>
      <category>cs.SI</category>
      <category>math.PR</category>
      <category>stat.TH</category>
      <pubDate>Mon, 16 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Anirudh Sridhar, Arnob Ghosh</dc:creator>
    </item>
    <item>
      <title>Buy versus Build an LLM: A Decision Framework for Governments</title>
      <link>https://arxiv.org/abs/2602.13033</link>
      <description>arXiv:2602.13033v1 Announce Type: cross 
Abstract: Large Language Models (LLMs) represent a new frontier of digital infrastructure that can support a wide range of public-sector applications, from general purpose citizen services to specialized and sensitive state functions. When expanding AI access, governments face a set of strategic choices over whether to buy existing services, build domestic capabilities, or adopt hybrid approaches across different domains and use cases. These are critical decisions especially when leading model providers are often foreign corporations, and LLM outputs are increasingly treated as trusted inputs to public decision-making and public discourse. In practice, these decisions are not intended to mandate a single approach across all domains; instead, national AI strategies are typically pluralistic, with sovereign, commercial and open-source models coexisting to serve different purposes. Governments may rely on commercial models for non-sensitive or commodity tasks, while pursuing greater control for critical, high-risk or strategically important applications.
  This paper provides a strategic framework for making this decision by evaluating these options across dimensions including sovereignty, safety, cost, resource capability, cultural fit, and sustainability. Importantly, "building" does not imply that governments must act alone: domestic capabilities may be developed through public research institutions, universities, state-owned enterprises, joint ventures, or broader national ecosystems. By detailing the technical requirements and practical challenges of each pathway, this work aims to serve as a reference for policy-makers to determine whether a buy or build approach best aligns with their specific national needs and societal goals.</description>
      <guid isPermaLink="false">oai:arXiv.org:2602.13033v1</guid>
      <category>cs.CY</category>
      <category>cs.AI</category>
      <category>cs.CE</category>
      <category>cs.CL</category>
      <category>cs.SI</category>
      <pubDate>Mon, 16 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Jiahao Lu, Ziwei Xu, William Tjhi, Junnan Li, Antoine Bosselut, Pang Wei Koh, Mohan Kankanhalli</dc:creator>
    </item>
    <item>
      <title>Leveraging Content Producer Networks and User Perception to Detect Online Discursive Communities</title>
      <link>https://arxiv.org/abs/2405.04896</link>
      <description>arXiv:2405.04896v3 Announce Type: replace 
Abstract: Online discussions are often characterized by strong behavioral asymmetries: a relatively small fraction of users actively produces content, while the majority primarily consumes and redistributes it. Here we propose a community-detection framework for online social networks that exploits this asymmetry by first identifying and clustering a set of leading users, and then extending the resulting labels to the broader user base. We introduce two complementary strategies to cluster leaders, one based on their mutual interactions and the other on audience overlap, both relying on entropy-based filtering to separate signal from noise. We evaluate the framework on three major Italian political debates on Twitter/X, using public figures--identified through the pre-2022 verification system--as leaders, and known affiliations of political actors as ground truth labels. Compared with standard baselines, the proposed approach yields more coherent and interpretable communities aligned with political structures, with the two variants respectively recovering parties and coalitions. Activity-based criteria for selecting leaders produce qualitatively similar but consistently weaker results, particularly at the coalition level. Overall, our findings show that creating statistically validated networks of publicly recognized figures, whose off-platform roles constrain and stabilize their online behavior, provide a strong basis to identify discursive communities on social media. Although developed for Twitter/X, the approach is conceptually general, as it leverages structural asymmetries common to many online platforms.</description>
      <guid isPermaLink="false">oai:arXiv.org:2405.04896v3</guid>
      <category>cs.SI</category>
      <category>cs.CY</category>
      <pubDate>Mon, 16 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <dc:creator>Stefano Guarino, Ayoub Mounim, Guido Caldarelli, Fabio Saracco</dc:creator>
    </item>
    <item>
      <title>Multimodal Coordinated Online Behavior: Trade-offs and Strategies</title>
      <link>https://arxiv.org/abs/2507.12108</link>
      <description>arXiv:2507.12108v3 Announce Type: replace 
Abstract: Coordinated online behavior, which spans from beneficial collective actions to harmful manipulation such as disinformation campaigns, has become a key focus in digital ecosystem analysis. Traditional methods often rely on monomodal approaches, focusing on single types of interactions like co-retweets or co-hashtags, or consider multiple modalities independently of each other. However, these approaches may overlook the complex dynamics inherent in multimodal coordination. This study compares different ways of operationalizing multimodal coordinated behavior, examining the trade-off between weakly and strongly integrated models and their ability to capture broad versus tightly aligned coordination patterns. By contrasting monomodal, flattened, and multimodal methods, we evaluate the distinct contributions of each modality and the impact of different integration strategies. Our findings show that while not all modalities provide unique insights, multimodal analysis consistently offers a more informative representation of coordinated behavior, preserving structures that monomodal and flattened approaches often lose. This work enhances the ability to detect and analyze coordinated online behavior, offering new perspectives for safeguarding the integrity of digital platforms.</description>
      <guid isPermaLink="false">oai:arXiv.org:2507.12108v3</guid>
      <category>cs.SI</category>
      <category>cs.AI</category>
      <category>cs.CY</category>
      <category>cs.HC</category>
      <category>cs.LG</category>
      <pubDate>Mon, 16 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Lorenzo Mannocci, Stefano Cresci, Matteo Magnani, Anna Monreale, Maurizio Tesconi</dc:creator>
    </item>
    <item>
      <title>Far-reaching consequences of trait preferences for animal social network structure and function</title>
      <link>https://arxiv.org/abs/2303.08107</link>
      <description>arXiv:2303.08107v3 Announce Type: replace-cross 
Abstract: Social network structures play an important role in the lives of animals by affecting individual fitness and the spread of disease and information. Nevertheless, we still lack a good understanding of how these structures emerge from the behavior of individuals. Generative network models provide a powerful approach that can help close this gap. Empirical research has shown that trait-based social preferences (preferences for social partners with certain trait values, such as sex, body size, relatedness etc.) play a key role in the formation of social networks across species. Currently, however, we lack a good understanding of how such preferences affect network properties. In this study: 1) we develop a general and flexible generative network model that can create artificial (simulated) networks where social connection is affected by trait-based social preferences; 2) we use this model to investigate how different trait-based social preferences affect social network structure and function. We find that the preferences can affect the efficiency of the networks in terms of transmitting disease and information, and their robustness against fragmentation when individuals disappear, with the effects often - but not always - going in the direction of slower transmission and lower robustness. Furthermore, the extent and form of the effects depend on both the type of preference and the type of trait it is used with. The findings lead to new insights about the potential mechanisms driving the structural diversity of animal social networks, the importance of trait value distributions for social structure, the degree distributions of social networks, and the detectability of trait effects from network data. Overall, the study shows that trait-based social preferences can have far-reaching consequences for populations.</description>
      <guid isPermaLink="false">oai:arXiv.org:2303.08107v3</guid>
      <category>physics.soc-ph</category>
      <category>cs.SI</category>
      <category>q-bio.PE</category>
      <pubDate>Mon, 16 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <arxiv:DOI>10.1093/beheco/araf132</arxiv:DOI>
      <arxiv:journal_reference>Behavioral Ecology, 37(1), araf132 (2026)</arxiv:journal_reference>
      <dc:creator>Josefine Bohr Brask, Andreas Koher, Darren P. Croft, Sune Lehmann</dc:creator>
    </item>
    <item>
      <title>SaVe-TAG: LLM-based Interpolation for Long-Tailed Text-Attributed Graphs</title>
      <link>https://arxiv.org/abs/2410.16882</link>
      <description>arXiv:2410.16882v5 Announce Type: replace-cross 
Abstract: Real-world graph data often follows long-tailed distributions, making it difficult for Graph Neural Networks (GNNs) to generalize well across both head and tail classes. Recent advances in Vicinal Risk Minimization (VRM) have shown promise in mitigating class imbalance with numeric interpolation; however, existing approaches largely rely on embedding-space arithmetic, which fails to capture the rich semantics inherent in text-attributed graphs. In this work, we propose our method, SaVe-TAG (Semantic-aware Vicinal Risk Minimization for Long-Tailed Text-Attributed Graphs), a novel VRM framework that leverages Large Language Models (LLMs) to perform text-level interpolation, generating on-manifold, boundary-enriching synthetic samples for minority classes. To mitigate the risk of noisy generation, we introduce a confidence-based edge assignment mechanism that uses graph topology as a natural filter to ensure structural consistency. We provide theoretical justification for our method and conduct extensive experiments on benchmark datasets, showing that our approach consistently outperforms both numeric interpolation and prior long-tailed node classification baselines. Our results highlight the importance of integrating semantic and structural signals for balanced and effective learning on text-attributed graphs. The source code is publicly available at: https://github.com/LWang-Laura/SaVe-TAG.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.16882v5</guid>
      <category>cs.AI</category>
      <category>cs.LG</category>
      <category>cs.SI</category>
      <pubDate>Mon, 16 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <arxiv:DOI>10.1145/3770854.3780311</arxiv:DOI>
      <dc:creator>Leyao Wang, Yu Wang, Bo Ni, Yuying Zhao, Hanyu Wang, Yao Ma, Tyler Derr</dc:creator>
    </item>
    <item>
      <title>Can Users Fix Algorithms? A Game-Theoretic Analysis of Collective Content Amplification in Recommender Systems</title>
      <link>https://arxiv.org/abs/2506.04525</link>
      <description>arXiv:2506.04525v3 Announce Type: replace-cross 
Abstract: Users of social media platforms based on recommendation systems (e.g. TikTok, X, YouTube) strategically interact with platform content to influence future recommendations. On some such platforms, users have been documented to form large-scale grassroots movements encouraging others to purposefully interact with algorithmically suppressed content in order to counteractively ``boost'' its recommendation. However, despite widespread documentation of this phenomenon, there is little theoretical work analyzing its impact on the platform or users themselves. We study a game between users and a RecSys, where users (potentially strategically) interact with the content available to them, and the RecSys -- limited by preference learning ability -- provides each user her approximately most-preferred item. We compare recommendations and social welfare when users interact with content according to their personal interests and when a collective of users intentionally interacts with an otherwise suppressed item. We provide sufficient conditions to ensure a pareto improvement in recommendations and strict increases in user social welfare under collective interaction, and provide a robust algorithm to find an effective collective strategy. Interestingly, despite the intended algorithmic protest of these movements, we show that for commonly assumed recommender utility functions, effective collective strategies also improve the utility of the RecSys. Our theoretical analysis is complemented by empirical results of effective collective interaction strategies on the GoodReads dataset and an online survey on how real-world users attempt to influence others' recommendations on RecSys platforms. Our findings examine how and when platforms' recommendation algorithms may incentivize users to collectivize and interact with content in algorithmic protest as well as what this collectivization means for the platform.</description>
      <guid isPermaLink="false">oai:arXiv.org:2506.04525v3</guid>
      <category>cs.GT</category>
      <category>cs.CY</category>
      <category>cs.HC</category>
      <category>cs.IR</category>
      <category>cs.SI</category>
      <pubDate>Mon, 16 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Ekaterina Fedorova, Madeline Kitch, Chara Podimata</dc:creator>
    </item>
    <item>
      <title>Life Finds A Way: Emergence of Cooperative Structures in Adaptive Threshold Networks</title>
      <link>https://arxiv.org/abs/2507.13253</link>
      <description>arXiv:2507.13253v4 Announce Type: replace-cross 
Abstract: There has been a long debate on how new levels of organization have evolved. It might seem unlikely, as cooperation must prevail over competition. One well-studied example is the emergence of autocatalytic sets, which seem to be a prerequisite for the evolution of life. Using a simple model, we investigate how varying bias toward cooperation versus antagonism shapes network dynamics, revealing that higher-order organization emerges even amid pervasive antagonistic interactions. In general, we observe that a quantitative increase in the number of elements in a system leads to a qualitative transition.
  We present a random threshold-directed network model that integrates node-specific traits with dynamic edge formation and node removal, simulating arbitrary levels of cooperation and competition. In our framework, intrinsic node values determine directed links through various threshold rules. Our model generates a multi-digraph with signed edges (reflecting support/antagonism, labeled ``help''/``harm''), which ultimately yields two parallel yet interdependent threshold graphs. Incorporating temporal growth and node turnover in our approach allows exploration of the evolution, adaptation, and potential collapse of communities and reveals regime changes in both connectivity and resilience.
  Our findings extend classical random threshold and Erd\H{o}s-R\'enyi models, offering new insights into adaptive systems in biological and economic contexts, with emphasis on the application to Collective Affordance Sets. This framework should also be useful for making predictions that will be tested by ongoing experiments of microbial communities in soil.</description>
      <guid isPermaLink="false">oai:arXiv.org:2507.13253v4</guid>
      <category>q-bio.PE</category>
      <category>cs.SI</category>
      <pubDate>Mon, 16 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Sean P. Maley, Carlos Gershenson, Stuart A. Kauffman</dc:creator>
    </item>
    <item>
      <title>What Do Temporal Graph Learning Models Learn?</title>
      <link>https://arxiv.org/abs/2510.09416</link>
      <description>arXiv:2510.09416v2 Announce Type: replace-cross 
Abstract: Learning on temporal graphs has become a central topic in graph representation learning, with numerous benchmarks indicating the strong performance of state-of-the-art models. However, recent work has raised concerns about the reliability of benchmark results, noting issues with commonly used evaluation protocols and the surprising competitiveness of simple heuristics. This contrast raises the question of which characteristics of the underlying graphs temporal graph learning models actually use to form their predictions. We address this by systematically evaluating eight models on their ability to capture eight fundamental characteristics related to the link structure of temporal graphs. These include structural characteristics such as density, temporal patterns such as recency, and edge formation mechanisms such as homophily. Using both synthetic and real-world datasets, we analyze how well models learn these characteristics. Our findings reveal a mixed picture: models capture some characteristics well but fail to reproduce others. With this, we expose important limitations. Overall, we believe that our results provide practical insights for the application of temporal graph learning models and motivate more interpretability-driven evaluations in graph learning research.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.09416v2</guid>
      <category>cs.LG</category>
      <category>cs.SI</category>
      <pubDate>Mon, 16 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Abigail J. Hayes, Tobias Schumacher, Markus Strohmaier</dc:creator>
    </item>
  </channel>
</rss>
