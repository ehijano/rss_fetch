<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>eess.SP updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/eess.SP</link>
    <description>eess.SP updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/eess.SP" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Thu, 03 Jul 2025 01:31:10 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Wed, 02 Jul 2025 00:00:00 -0400</pubDate>
    <skipDays>
      <day>Saturday</day>
      <day>Sunday</day>
    </skipDays>
    <item>
      <title>Fast Simulation of Damage Diffusion Distribution in Scanning Transmission Electron Microscopy</title>
      <link>https://arxiv.org/abs/2507.00294</link>
      <description>arXiv:2507.00294v1 Announce Type: new 
Abstract: Scanning Transmission Electron Microscopy (STEM) is a critical tool for imaging the properties of materials and biological specimens at atomic scale, yet our understanding of relevant electron beam damage mechanisms is incomplete. Recent studies suggest that certain types of damage can be modelled as a diffusion process. However, numerical simulation of such diffusion processes has remained computationally intensive. This work introduces a high-performance C++ framework for simulating damage diffusion process in STEM that combines efficient numerical computation, advanced visualisations, and multithreading to achieve efficient runtime while maintaining accuracy.</description>
      <guid isPermaLink="false">oai:arXiv.org:2507.00294v1</guid>
      <category>eess.SP</category>
      <category>cond-mat.mtrl-sci</category>
      <pubDate>Wed, 02 Jul 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <dc:creator>Amir Javadi Rad, Amirafshar Moshtaghpour, Dongdong Chen, Angus I. Kirkland</dc:creator>
    </item>
    <item>
      <title>Quadrature Over-the-Air-Computing for Multimodal Dual-Stream Signal Processing</title>
      <link>https://arxiv.org/abs/2507.00508</link>
      <description>arXiv:2507.00508v1 Announce Type: new 
Abstract: We propose a novel quadrature over-the-air computing (Q-OTAC) framework that enables the simultaneously computation of two independent functions and/or data stream within a single transmission. In contrast to conventional OTAC schemes, where a single function is computed by treating each complex signal as a single component, the proposed Q-OTAC exploits both in-phase and quadrature (IQ) components of a complex signal, encoding two distinct functions and/or data streams at the edge devices (EDs) and employing a novel low-complexity IQ-decoupled combiner at the access point (AP) to independently recover each stream, which effectively doubles the computation rate. A key strength of this framework lies in its simplicity and broad compatibility: the extension into the quadrature domain is conceptually straightforward, yet remakably powerful, allowing seamless integration into existing OTAC techniques. Simulation results validate the effectiveness of this approach, including the first demonstration of dual-function aggregation (e.g., parallel summation and product), highlighting the potential of Q-OTAC for enabling multi-modal and high-efficiency beyond fifth generation (B5G) applications.</description>
      <guid isPermaLink="false">oai:arXiv.org:2507.00508v1</guid>
      <category>eess.SP</category>
      <pubDate>Wed, 02 Jul 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Hyeon Seok Rou, Kengo Ando, Giuseppe Thadeu Freitas de Abreu, David Gonz\'alez G</dc:creator>
    </item>
    <item>
      <title>Fair Rate Maximization for Fluid Antenna Relay (FAR)-assisted Multi-user MISO Communications</title>
      <link>https://arxiv.org/abs/2507.00529</link>
      <description>arXiv:2507.00529v1 Announce Type: new 
Abstract: In this paper, we investigate the problem of max-min rate maximization in fluid antenna relay (FAR)-assisted multi-user uplink multiple-input single-output (MISO) wireless systems, where each user is equipped with a single fluid antenna (FA) and the base station (BS) is equipped with multiple FAs. Unlike most existing relevant work focusing on maximizing sum rate of the fluid antenna system (FAS), which may cause unbearable rate loss to weak users, we propose to maximize the minimal rate of the system to ensure fairness. The max-min optimization problem is formulated by jointly optimizing the positions of FAs with meeting the minimum distance requirements of FAs, maximum transmitting power limit, and feasible antenna region constraints. To solve this problem, we propose an alternating algorithm with utilizing the successive convex approximation (SCA) method. Simulation results demonstrate that the proposed method significantly outperforms conventional methods in terms of maximizing the minimal achievable rate across different signal-to-noise ratios (SNRs) and normalized region sizes.</description>
      <guid isPermaLink="false">oai:arXiv.org:2507.00529v1</guid>
      <category>eess.SP</category>
      <pubDate>Wed, 02 Jul 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Ruopeng Xu, Zhaohui Yang, Ting Zhang, Mingzhe Chen, Chen Zhu, Zhaoyang Zhang</dc:creator>
    </item>
    <item>
      <title>Delay Bound Relaxation with Deep Learning-based Haptic Estimation for Tactile Internet</title>
      <link>https://arxiv.org/abs/2507.00571</link>
      <description>arXiv:2507.00571v1 Announce Type: new 
Abstract: Haptic teleoperation typically demands sub-millisecond latency and ultra-high reliability (99.999%) in Tactile Internet. At a 1 kHz haptic signal sampling rate, this translates into an extremely high packet transmission rate, posing significant challenges for timely delivery and introducing substantial complexity and overhead in radio resource allocation. To address this critical challenge, we introduce a novel DL modelthat estimates force feedback using multi-modal input, i.e. both force measurements from the remote side and local operator motion signals. The DL model can capture complex temporal features of haptic time-series with the use of CNN and LSTM layers, followed by a transformer encoder, and autoregressively produce a highly accurate estimation of the next force values for different teleoperation activities. By ensuring that the estimation error is within a predefined threshold, the teleoperation system can safely relax its strict delay requirements. This enables the batching and transmission of multiple haptic packets within a single resource block, improving resource efficiency and facilitating scheduling in resource allocation. Through extensive simulations, we evaluated network performance in terms of reliability and capacity. Results show that, for both dynamic and rigid object interactions, the proposed method increases the number of reliably served users by up to 66%.</description>
      <guid isPermaLink="false">oai:arXiv.org:2507.00571v1</guid>
      <category>eess.SP</category>
      <pubDate>Wed, 02 Jul 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Georgios Kokkinis, Alexandros Iosifidis, Qi Zhang</dc:creator>
    </item>
    <item>
      <title>Quantize-Sample-and-Verify: LLM Acceleration via Adaptive Edge-Cloud Speculative Decoding</title>
      <link>https://arxiv.org/abs/2507.00605</link>
      <description>arXiv:2507.00605v1 Announce Type: new 
Abstract: In edge-cloud speculative decoding (SD), edge devices equipped with small language models (SLMs) generate draft tokens that are verified by large language models (LLMs) in the cloud. A key bottleneck in such systems is the limited communication bandwidth between edge and cloud, which necessitates quantization of the information transmitted about generated tokens. In this work, we introduce a novel quantize-sample (Q-S) strategy that provably preserves the output distribution of the cloud-based model, ensuring that the verified tokens match the distribution of those that would have been generated directly by the LLM. We develop a throughput model for edge-cloud SD that explicitly accounts for communication latency. Leveraging this model, we propose an adaptive mechanism that optimizes token throughput by dynamically adjusting the draft length and quantization precision in response to both semantic uncertainty and channel conditions. Simulations demonstrate that the proposed Q-S approach significantly improves decoding efficiency in realistic edge-cloud deployment scenarios.</description>
      <guid isPermaLink="false">oai:arXiv.org:2507.00605v1</guid>
      <category>eess.SP</category>
      <pubDate>Wed, 02 Jul 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Guangyi Zhang, Yunlong Cai, Guanding Yu, Petar Popovski, Osvaldo Simeone</dc:creator>
    </item>
    <item>
      <title>Physical Layer Group Key Generation With the Aid of Reconfigurable Intelligent Surfaces</title>
      <link>https://arxiv.org/abs/2507.00714</link>
      <description>arXiv:2507.00714v1 Announce Type: new 
Abstract: Reconfigurable intelligent surfaces (RIS) have the ability to alter the wireless environment by making changes in the impinging signal. Motivated by this ability, in this study, we exploit the RIS to make the aggregate reflecting channels of different user terminals (UTs) as similar as possible to be able to extract common group secret keys from their channels. Specifically, the RIS will adjust its parameters to pave the way for group key generation (GKG) based on the physical channels of the UTs. Our method exploits the already gathered channel state information (CSI) in the RIS to beneficially design the phase shifts and does not impose additional probing burden on the network. Additionally, this scheme is broadcast-based and does not entail the overheads of the pairwise-based key generation. We consider both passive RIS (PRIS) and active RIS (ARIS) to generate the group keys. The PRIS is widely adopted in physical layer key generation (PLKG) studies due to its use of passive elements, whereas the ARIS demonstrates superior capability in aligning the aggregate reflected channels among nodes in the GKG scenario, as demonstrated in this study. We will exploit various optimization methods like successive convex approximation (SCA) and semidefinite relaxation with Gaussian randomization (SDR-GR) to address the raised optimization problems. Unlike most of the studies in the literature, our scheme can achieve a high GKG rate in static environments as well. Finally, we will examine the performance of the proposed method by normalized mean squared error (NMSE), key error rate (KER), key generation rate (KGR) and key randomness metrics. Our numerical results verify that for the equal available power budget, the ARIS significantly outperforms PRIS in NMSE and KER, achieving more than four times higher KGR.</description>
      <guid isPermaLink="false">oai:arXiv.org:2507.00714v1</guid>
      <category>eess.SP</category>
      <pubDate>Wed, 02 Jul 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Vahid Shahiri, Guyue Li, Hamid Behroozi</dc:creator>
    </item>
    <item>
      <title>SComCP: Task-Oriented Semantic Communication for Collaborative Perception</title>
      <link>https://arxiv.org/abs/2507.00895</link>
      <description>arXiv:2507.00895v1 Announce Type: new 
Abstract: Reliable detection of surrounding objects is critical for the safe operation of connected automated vehicles (CAVs). However, inherent limitations such as the restricted perception range and occlusion effects compromise the reliability of single-vehicle perception systems in complex traffic environments. Collaborative perception has emerged as a promising approach by fusing sensor data from surrounding CAVs with diverse viewpoints, thereby improving environmental awareness. Although collaborative perception holds great promise, its performance is bottlenecked by wireless communication constraints, as unreliable and bandwidth-limited channels hinder the transmission of sensor data necessary for real-time perception. To address these challenges, this paper proposes SComCP, a novel task-oriented semantic communication framework for collaborative perception. Specifically, SComCP integrates an importance-aware feature selection network that selects and transmits semantic features most relevant to the perception task, significantly reducing communication overhead without sacrificing accuracy. Furthermore, we design a semantic codec network based on a joint source and channel coding (JSCC) architecture, which enables bidirectional transformation between semantic features and noise-tolerant channel symbols, thereby ensuring stable perception under adverse wireless conditions. Extensive experiments demonstrate the effectiveness of the proposed framework. In particular, compared to existing approaches, SComCP can maintain superior perception performance across various channel conditions, especially in low signal-to-noise ratio (SNR) scenarios. In addition, SComCP exhibits strong generalization capability, enabling the framework to maintain high performance across diverse channel conditions, even when trained with a specific channel model.</description>
      <guid isPermaLink="false">oai:arXiv.org:2507.00895v1</guid>
      <category>eess.SP</category>
      <pubDate>Wed, 02 Jul 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Jipeng Gan, Yucheng Sheng, Hua Zhang, Le Liang, Hao Ye, Chongtao Guo, Shi Jin</dc:creator>
    </item>
    <item>
      <title>Enhancing Open RAN Digital Twin Through Power Consumption Measurement</title>
      <link>https://arxiv.org/abs/2507.00928</link>
      <description>arXiv:2507.00928v1 Announce Type: new 
Abstract: The increasing demand for high-speed, ultra-reliable and low-latency communications in 5G and beyond networks has led to a significant increase in power consumption, particularly within the Radio Access Network (RAN). This growing energy demand raises operational and sustainability challenges for mobile network operators, requiring novel solutions to enhance energy efficiency while maintaining Quality of Service (QoS). 5G networks are evolving towards disaggregated, programmable, and intelligent architectures, with Open Radio Access Network (O-RAN) spearheaded by the O-RAN Alliance, enabling greater flexibility, interoperability, and cost-effectiveness. However, this disaggregated approach introduces new complexities, especially in terms of power consumption across different network components, including Open Radio Units (RUs), Open Distributed Units (DUs) and Open Central Units (CUs). Understanding the power efficiency of different O-RAN functional splits is crucial for optimising energy consumption and network sustainability. In this paper, we present a comprehensive measurement study of power consumption in RUs, DUs and CUs under varying network loads, specifically analysing the impact of Physical resource block (PRB) utilisation in Split 8 and Split 7.2b. The measurements were conducted on both software-defined radio (SDR)-based RUs and commercial indoor and outdoor RU, as well as their corresponding DU and CU. By evaluating real-world hardware deployments under different operational conditions, this study provides empirical insights into the power efficiency of various O-RAN configurations. The results highlight that power consumption does not scale significantly with network load, suggesting that a large portion of energy consumption remains constant regardless of traffic demand.</description>
      <guid isPermaLink="false">oai:arXiv.org:2507.00928v1</guid>
      <category>eess.SP</category>
      <pubDate>Wed, 02 Jul 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Ahmed Al-Tahmeesschi, Yi Chu, Josh Shackleton, Swarna Chetty, Mostafa Rahmani, David Grace, Hamed Ahmadi</dc:creator>
    </item>
    <item>
      <title>Leveraging Unlabeled Audio-Visual Data in Speech Emotion Recognition using Knowledge Distillation</title>
      <link>https://arxiv.org/abs/2507.00055</link>
      <description>arXiv:2507.00055v1 Announce Type: cross 
Abstract: Voice interfaces integral to the human-computer interaction systems can benefit from speech emotion recognition (SER) to customize responses based on user emotions. Since humans convey emotions through multi-modal audio-visual cues, developing SER systems using both the modalities is beneficial. However, collecting a vast amount of labeled data for their development is expensive. This paper proposes a knowledge distillation framework called LightweightSER (LiSER) that leverages unlabeled audio-visual data for SER, using large teacher models built on advanced speech and face representation models. LiSER transfers knowledge regarding speech emotions and facial expressions from the teacher models to lightweight student models. Experiments conducted on two benchmark datasets, RAVDESS and CREMA-D, demonstrate that LiSER can reduce the dependence on extensive labeled datasets for SER tasks.</description>
      <guid isPermaLink="false">oai:arXiv.org:2507.00055v1</guid>
      <category>cs.LG</category>
      <category>cs.HC</category>
      <category>cs.MM</category>
      <category>eess.AS</category>
      <category>eess.IV</category>
      <category>eess.SP</category>
      <pubDate>Wed, 02 Jul 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Varsha Pendyala, Pedro Morgado, William Sethares</dc:creator>
    </item>
    <item>
      <title>Smooth-Distill: A Self-distillation Framework for Multitask Learning with Wearable Sensor Data</title>
      <link>https://arxiv.org/abs/2507.00061</link>
      <description>arXiv:2507.00061v1 Announce Type: cross 
Abstract: This paper introduces Smooth-Distill, a novel self-distillation framework designed to simultaneously perform human activity recognition (HAR) and sensor placement detection using wearable sensor data. The proposed approach utilizes a unified CNN-based architecture, MTL-net, which processes accelerometer data and branches into two outputs for each respective task. Unlike conventional distillation methods that require separate teacher and student models, the proposed framework utilizes a smoothed, historical version of the model itself as the teacher, significantly reducing training computational overhead while maintaining performance benefits. To support this research, we developed a comprehensive accelerometer-based dataset capturing 12 distinct sleep postures across three different wearing positions, complementing two existing public datasets (MHealth and WISDM). Experimental results show that Smooth-Distill consistently outperforms alternative approaches across different evaluation scenarios, achieving notable improvements in both human activity recognition and device placement detection tasks. This method demonstrates enhanced stability in convergence patterns during training and exhibits reduced overfitting compared to traditional multitask learning baselines. This framework contributes to the practical implementation of knowledge distillation in human activity recognition systems, offering an effective solution for multitask learning with accelerometer data that balances accuracy and training efficiency. More broadly, it reduces the computational cost of model training, which is critical for scenarios requiring frequent model updates or training on resource-constrained platforms. The code and model are available at https://github.com/Kuan2vn/smooth\_distill.</description>
      <guid isPermaLink="false">oai:arXiv.org:2507.00061v1</guid>
      <category>cs.LG</category>
      <category>cs.AI</category>
      <category>eess.SP</category>
      <pubDate>Wed, 02 Jul 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Hoang-Dieu Vu, Duc-Nghia Tran, Quang-Tu Pham, Hieu H. Pham, Nicolas Vuillerme, Duc-Tan Tran</dc:creator>
    </item>
    <item>
      <title>Towards transparent and data-driven fault detection in manufacturing: A case study on univariate, discrete time series</title>
      <link>https://arxiv.org/abs/2507.00102</link>
      <description>arXiv:2507.00102v1 Announce Type: cross 
Abstract: Ensuring consistent product quality in modern manufacturing is crucial, particularly in safety-critical applications. Conventional quality control approaches, reliant on manually defined thresholds and features, lack adaptability to the complexity and variability inherent in production data and necessitate extensive domain expertise. Conversely, data-driven methods, such as machine learning, demonstrate high detection performance but typically function as black-box models, thereby limiting their acceptance in industrial environments where interpretability is paramount. This paper introduces a methodology for industrial fault detection, which is both data-driven and transparent. The approach integrates a supervised machine learning model for multi-class fault classification, Shapley Additive Explanations for post-hoc interpretability, and a do-main-specific visualisation technique that maps model explanations to operator-interpretable features. Furthermore, the study proposes an evaluation methodology that assesses model explanations through quantitative perturbation analysis and evaluates visualisations by qualitative expert assessment. The approach was applied to the crimping process, a safety-critical joining technique, using a dataset of univariate, discrete time series. The system achieves a fault detection accuracy of 95.9 %, and both quantitative selectivity analysis and qualitative expert evaluations confirmed the relevance and inter-pretability of the generated explanations. This human-centric approach is designed to enhance trust and interpretability in data-driven fault detection, thereby contributing to applied system design in industrial quality control.</description>
      <guid isPermaLink="false">oai:arXiv.org:2507.00102v1</guid>
      <category>cs.LG</category>
      <category>cs.AI</category>
      <category>eess.SP</category>
      <pubDate>Wed, 02 Jul 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Bernd Hofmann, Patrick Bruendl, Huong Giang Nguyen, Joerg Franke</dc:creator>
    </item>
    <item>
      <title>AI-Hybrid TRNG: Kernel-Based Deep Learning for Near-Uniform Entropy Harvesting from Physical Noise</title>
      <link>https://arxiv.org/abs/2507.00145</link>
      <description>arXiv:2507.00145v1 Announce Type: cross 
Abstract: AI-Hybrid TRNG is a deep-learning framework that extracts near-uniform entropy directly from physical noise, eliminating the need for bulky quantum devices or expensive laboratory-grade RF receivers. Instead, it relies on a low-cost, thumb-sized RF front end, plus CPU-timing jitter, for training, and then emits 32-bit high-entropy streams without any quantization step.
  Unlike deterministic or trained artificial intelligence random number generators (RNGs), our dynamic inner-outer network couples adaptive natural sources and reseeding, yielding truly unpredictable and autonomous sequences. Generated numbers pass the NIST SP 800-22 battery better than a CPU-based method. It also passes nineteen bespoke statistical tests for both bit- and integer-level analysis. All results satisfy cryptographic standards, while forward and backward prediction experiments reveal no exploitable biases. The model's footprint is below 0.5 MB, making it deployable on MCUs and FPGA soft cores, as well as suitable for other resource-constrained platforms.
  By detaching randomness quality from dedicated hardware, AI-Hybrid TRNG broadens the reach of high-integrity random number generators across secure systems, cryptographic protocols, embedded and edge devices, stochastic simulations, and server applications that need randomness.</description>
      <guid isPermaLink="false">oai:arXiv.org:2507.00145v1</guid>
      <category>cs.CR</category>
      <category>cs.AI</category>
      <category>cs.ET</category>
      <category>cs.IT</category>
      <category>eess.SP</category>
      <category>math.IT</category>
      <pubDate>Wed, 02 Jul 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Hasan Yi\u{g}it</dc:creator>
    </item>
    <item>
      <title>Do Music Source Separation Models Preserve Spatial Information in Binaural Audio?</title>
      <link>https://arxiv.org/abs/2507.00155</link>
      <description>arXiv:2507.00155v1 Announce Type: cross 
Abstract: Binaural audio remains underexplored within the music information retrieval community. Motivated by the rising popularity of virtual and augmented reality experiences as well as potential applications to accessibility, we investigate how well existing music source separation (MSS) models perform on binaural audio. Although these models process two-channel inputs, it is unclear how effectively they retain spatial information. In this work, we evaluate how several popular MSS models preserve spatial information on both standard stereo and novel binaural datasets. Our binaural data is synthesized using stems from MUSDB18-HQ and open-source head-related transfer functions by positioning instrument sources randomly along the horizontal plane. We then assess the spatial quality of the separated stems using signal processing and interaural cue-based metrics. Our results show that stereo MSS models fail to preserve the spatial information critical for maintaining the immersive quality of binaural audio, and that the degradation depends on model architecture as well as the target instrument. Finally, we highlight valuable opportunities for future work at the intersection of MSS and immersive audio.</description>
      <guid isPermaLink="false">oai:arXiv.org:2507.00155v1</guid>
      <category>eess.AS</category>
      <category>cs.SD</category>
      <category>eess.SP</category>
      <pubDate>Wed, 02 Jul 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Richa Namballa, Agnieszka Roginska, Magdalena Fuentes</dc:creator>
    </item>
    <item>
      <title>Observation of Blood Flow in Major Neck Vessels Modulated 1 by Physiological Maneuvers</title>
      <link>https://arxiv.org/abs/2507.00231</link>
      <description>arXiv:2507.00231v1 Announce Type: cross 
Abstract: Large neck vessels (carotid artery and internal jugular vein, IJV) offer a unique opportunity to monitor hemodynamics non-invasively by optical means. The primary shortcoming of past work has been the focus on healthy volunteers in normal physiological conditions and well-controlled environments. To drive the technology closer to the bedside, testing is required under more re-alistic conditions, including in pathologies and real-world environments (e.g., similar toICU or emergency care settings). The primary goal of the current work was to extend the range of physiological maneuvers for blood flow modulation by introducing new maneuvers and ob-serving PPG response to them. The data from the necks of two healthy volunteers in a supine position were collected by clinical PPG and in-house built PPG sensors, accompanied by ECG signal collection. Seven maneuvers (abdominojugular test, breath holding, Valsalva, proximal occlusion of right IJV, distal occlusion of right IJV, proximal occlusion of left IJV, distal occlusion of left IJV) were performed in sequence with 1 min allocated for each maneuver. The 1 min was split into three segments: baseline (15 s), experiment (15 s), and recovery (30 s). Thus, the overall du-ration of the experiment was 7 min. AC amplitude from clinical PPG, DC amplitudes from in-house built PPG, and ECG signal were compared during all seven physiological maneuvers. Newly proposed maneuvers (Valsalva and IJV occlusions) demonstrated modulation of blood flow, which was more significant than previously reported maneuvers (abdominojugular test and breath holding). The proposed physiological maneuvers demonstrate high potential as instruments for modulating blood flow in major neck vessels.</description>
      <guid isPermaLink="false">oai:arXiv.org:2507.00231v1</guid>
      <category>physics.med-ph</category>
      <category>cs.SY</category>
      <category>eess.SP</category>
      <category>eess.SY</category>
      <pubDate>Wed, 02 Jul 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Gennadi Saiko, Timothy Burton, Faraz Sadrzadeh-Afsharazar, Shota Yamashita, Kenshin Shimono, Yasuyuki Kakihana, Alexandre Douplik</dc:creator>
    </item>
    <item>
      <title>Wireless AI Evolution: From Statistical Learners to Electromagnetic-Guided Foundation Models</title>
      <link>https://arxiv.org/abs/2507.00366</link>
      <description>arXiv:2507.00366v1 Announce Type: cross 
Abstract: While initial applications of artificial intelligence (AI) in wireless communications over the past decade have demonstrated considerable potential using specialized models for targeted communication tasks, the revolutionary demands of sixth-generation (6G) networks for holographic communications, ubiquitous sensing, and native intelligence are propelling a necessary evolution towards AI-native wireless networks. The arrival of large AI models paves the way for the next phase of Wireless AI, driven by wireless foundation models (WFMs). In particular, pre-training on universal electromagnetic (EM) principles equips WFMs with the essential adaptability for a multitude of demanding 6G applications. However, existing large AI models face critical limitations, including pre-training strategies disconnected from EM-compliant constraints leading to physically inconsistent predictions, a lack of embedded understanding of wave propagation physics, and the inaccessibility of massive labeled datasets for comprehensive EM-aware training. To address these challenges, this article presents an electromagnetic information theory-guided self-supervised pre-training (EIT-SPT) framework designed to systematically inject EM physics into WFMs. The EIT-SPT framework aims to infuse WFMs with intrinsic EM knowledge, thereby enhancing their physical consistency, generalization capabilities across varied EM landscapes, and overall data efficiency. Building upon the proposed EIT-SPT framework, this article first elaborates on diverse potential applications in 6G scenarios of WFMs, then validates the efficacy of the proposed framework through illustrative case studies, and finally summarizes critical open research challenges and future directions for WFMs.</description>
      <guid isPermaLink="false">oai:arXiv.org:2507.00366v1</guid>
      <category>cs.IT</category>
      <category>eess.SP</category>
      <category>math.IT</category>
      <pubDate>Wed, 02 Jul 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Jian Xiao, Ji Wang, Kunrui Cao, Xingwang Li, Zhao Chen, Chau Yuen</dc:creator>
    </item>
    <item>
      <title>Accuracy and Security-Guaranteed Participant Selection and Beamforming Design for RIS-Assisted Federated Learning</title>
      <link>https://arxiv.org/abs/2507.00388</link>
      <description>arXiv:2507.00388v1 Announce Type: cross 
Abstract: Federated learning (FL) has emerged as an effective approach for training neural network models without requiring the sharing of participants' raw data, thereby addressing data privacy concerns. In this paper, we propose a reconfigurable intelligent surface (RIS)-assisted FL framework in the presence of eavesdropping, where partial edge devices are selected to participate in the FL training process. In contrast, the remaining devices serve as cooperative jammers by transmitting jamming signals to disrupt eavesdropping. We aim to minimize the training latency in each FL round by jointly optimizing participant selection, bandwidth allocation, and RIS beamforming design, subject to the convergence accuracy of FL and the secure uploading requirements. To solve the resulting mixed-integer nonlinear programming problem, we propose a twin delayed deep deterministic policy gradient (TD3) algorithm. Simulation results demonstrate that the proposed scheme reduces the FL training latency by approximately 27$\%$ compared to baselines.</description>
      <guid isPermaLink="false">oai:arXiv.org:2507.00388v1</guid>
      <category>cs.IT</category>
      <category>eess.SP</category>
      <category>math.IT</category>
      <pubDate>Wed, 02 Jul 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Mengru Wu, Yu Gao, Weidang Lu, Huimei Han, Lei Sun, Wanli Ni</dc:creator>
    </item>
    <item>
      <title>Neural Augmented Kalman Filters for Road Network assisted GNSS positioning</title>
      <link>https://arxiv.org/abs/2507.00654</link>
      <description>arXiv:2507.00654v1 Announce Type: cross 
Abstract: The Global Navigation Satellite System (GNSS) provides critical positioning information globally, but its accuracy in dense urban environments is often compromised by multipath and non-line-of-sight errors. Road network data can be used to reduce the impact of these errors and enhance the accuracy of a positioning system. Previous works employing road network data are either limited to offline applications, or rely on Kalman Filter (KF) heuristics with little flexibility and robustness. We instead propose training a Temporal Graph Neural Network (TGNN) to integrate road network information into a KF. The TGNN is designed to predict the correct road segment and its associated uncertainty to be used in the measurement update step of the KF. We validate our approach with real-world GNSS data and open-source road networks, observing a 29% decrease in positioning error for challenging scenarios compared to a GNSS-only KF. To the best of our knowledge, ours is the first deep learning-based approach jointly employing road network data and GNSS measurements to determine the user position on Earth.</description>
      <guid isPermaLink="false">oai:arXiv.org:2507.00654v1</guid>
      <category>cs.LG</category>
      <category>cs.SY</category>
      <category>eess.SP</category>
      <category>eess.SY</category>
      <pubDate>Wed, 02 Jul 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Hans van Gorp, Davide Belli, Amir Jalalirad, Bence Major</dc:creator>
    </item>
    <item>
      <title>Biorthogonal Tunable Wavelet Unit with Lifting Scheme in Convolutional Neural Network</title>
      <link>https://arxiv.org/abs/2507.00739</link>
      <description>arXiv:2507.00739v1 Announce Type: cross 
Abstract: This work introduces a novel biorthogonal tunable wavelet unit constructed using a lifting scheme that relaxes both the orthogonality and equal filter length constraints, providing greater flexibility in filter design. The proposed unit enhances convolution, pooling, and downsampling operations, leading to improved image classification and anomaly detection in convolutional neural networks (CNN). When integrated into an 18-layer residual neural network (ResNet-18), the approach improved classification accuracy on CIFAR-10 by 2.12% and on the Describable Textures Dataset (DTD) by 9.73%, demonstrating its effectiveness in capturing fine-grained details. Similar improvements were observed in ResNet-34. For anomaly detection in the hazelnut category of the MVTec Anomaly Detection dataset, the proposed method achieved competitive and wellbalanced performance in both segmentation and detection tasks, outperforming existing approaches in terms of accuracy and robustness.</description>
      <guid isPermaLink="false">oai:arXiv.org:2507.00739v1</guid>
      <category>cs.CV</category>
      <category>eess.IV</category>
      <category>eess.SP</category>
      <pubDate>Wed, 02 Jul 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>An Le, Hung Nguyen, Sungbal Seo, You-Suk Bae, Truong Nguyen</dc:creator>
    </item>
    <item>
      <title>Tunable Wavelet Unit based Convolutional Neural Network in Optical Coherence Tomography Analysis Enhancement for Classifying Type of Epiretinal Membrane Surgery</title>
      <link>https://arxiv.org/abs/2507.00743</link>
      <description>arXiv:2507.00743v1 Announce Type: cross 
Abstract: In this study, we developed deep learning-based method to classify the type of surgery performed for epiretinal membrane (ERM) removal, either internal limiting membrane (ILM) removal or ERM-alone removal. Our model, based on the ResNet18 convolutional neural network (CNN) architecture, utilizes postoperative optical coherence tomography (OCT) center scans as inputs. We evaluated the model using both original scans and scans preprocessed with energy crop and wavelet denoising, achieving 72% accuracy on preprocessed inputs, outperforming the 66% accuracy achieved on original scans. To further improve accuracy, we integrated tunable wavelet units with two key adaptations: Orthogonal Lattice-based Wavelet Units (OrthLatt-UwU) and Perfect Reconstruction Relaxation-based Wavelet Units (PR-Relax-UwU). These units allowed the model to automatically adjust filter coefficients during training and were incorporated into downsampling, stride-two convolution, and pooling layers, enhancing its ability to distinguish between ERM-ILM removal and ERM-alone removal, with OrthLattUwU boosting accuracy to 76% and PR-Relax-UwU increasing performance to 78%. Performance comparisons showed that our AI model outperformed a trained human grader, who achieved only 50% accuracy in classifying the removal surgery types from postoperative OCT scans. These findings highlight the potential of CNN based models to improve clinical decision-making by providing more accurate and reliable classifications. To the best of our knowledge, this is the first work to employ tunable wavelets for classifying different types of ERM removal surgery.</description>
      <guid isPermaLink="false">oai:arXiv.org:2507.00743v1</guid>
      <category>eess.IV</category>
      <category>cs.CV</category>
      <category>eess.SP</category>
      <pubDate>Wed, 02 Jul 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>An Le, Nehal Mehta, William Freeman, Ines Nagel, Melanie Tran, Anna Heinke, Akshay Agnihotri, Lingyun Cheng, Dirk-Uwe Bartsch, Hung Nguyen, Truong Nguyen, Cheolhong An</dc:creator>
    </item>
    <item>
      <title>Enhancing Vehicular Platooning with Wireless Federated Learning: A Resource-Aware Control Framework</title>
      <link>https://arxiv.org/abs/2507.00856</link>
      <description>arXiv:2507.00856v1 Announce Type: cross 
Abstract: This paper aims to enhance the performance of Vehicular Platooning (VP) systems integrated with Wireless Federated Learning (WFL). In highly dynamic environments, vehicular platoons experience frequent communication changes and resource constraints, which significantly affect information exchange and learning model synchronization. To address these challenges, we first formulate WFL in VP as a joint optimization problem that simultaneously considers Age of Information (AoI) and Federated Learning Model Drift (FLMD) to ensure timely and accurate control. Through theoretical analysis, we examine the impact of FLMD on convergence performance and develop a two-stage Resource-Aware Control framework (RACE). The first stage employs a Lagrangian dual decomposition method for resource configuration, while the second stage implements a multi-agent deep reinforcement learning approach for vehicle selection. The approach integrates Multi-Head Self-Attention and Long Short-Term Memory networks to capture spatiotemporal correlations in communication states. Experimental results demonstrate that, compared to baseline methods, the proposed framework improves AoI optimization by up to 45%, accelerates learning convergence, and adapts more effectively to dynamic VP environments on the AI4MARS dataset.</description>
      <guid isPermaLink="false">oai:arXiv.org:2507.00856v1</guid>
      <category>cs.NI</category>
      <category>eess.SP</category>
      <pubDate>Wed, 02 Jul 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Beining Wu, Jun Huang, Qiang Duan, Liang Dong, Zhipeng Cai</dc:creator>
    </item>
    <item>
      <title>Constellation as a Service: Tailored Connectivity Management in Direct-Satellite-to-Device Networks</title>
      <link>https://arxiv.org/abs/2507.00902</link>
      <description>arXiv:2507.00902v1 Announce Type: cross 
Abstract: Direct-satellite-to-device (DS2D) communication is emerging as a promising solution for global mobile service extension, leveraging the deployment of satellite constellations. However, the challenge of managing DS2D connectivity for multi-constellations becomes outstanding, including high interference and frequent handovers caused by multi-coverage overlap and rapid satellite movement. Moreover, existing approaches primarily operate within single-constellation shell, which inherently limits the ability to exploit the vast potential of multi-constellation connectivity provision, resulting in suboptimal DS2D service performances. To address these challenges, this article proposes a Constellation as a Service (CaaS) framework, which treats the entire multi-constellation infrastructure as a shared resource pool and dynamically forms optimal sub-constellations (SCs) for each DS2D service region. The formation of each SC integrates satellites from various orbits to provide tailored connectivity based on user demands, guided by two innovative strategies: predictive satellite beamforming using generative artificial intelligence (GenAI) and pre-configured handover path for efficient satellite access and mobility management. Simulation results demonstrate that CaaS significantly improves satellite service rates while reducing handover overhead, making it an efficient and continuable solution for managing DS2D connectivity in multi-constellation environments.</description>
      <guid isPermaLink="false">oai:arXiv.org:2507.00902v1</guid>
      <category>eess.SY</category>
      <category>cs.AI</category>
      <category>cs.SY</category>
      <category>eess.SP</category>
      <pubDate>Wed, 02 Jul 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Feng Wang, Shengyu Zhang, Een-Kee Hong, Tony Q. S. Quek</dc:creator>
    </item>
    <item>
      <title>Privacy-Preserving Quantized Federated Learning with Diverse Precision</title>
      <link>https://arxiv.org/abs/2507.00920</link>
      <description>arXiv:2507.00920v1 Announce Type: cross 
Abstract: Federated learning (FL) has emerged as a promising paradigm for distributed machine learning, enabling collaborative training of a global model across multiple local devices without requiring them to share raw data. Despite its advancements, FL is limited by factors such as: (i) privacy risks arising from the unprotected transmission of local model updates to the fusion center (FC) and (ii) decreased learning utility caused by heterogeneity in model quantization resolution across participating devices. Prior work typically addresses only one of these challenges because maintaining learning utility under both privacy risks and quantization heterogeneity is a non-trivial task. In this paper, our aim is therefore to improve the learning utility of a privacy-preserving FL that allows clusters of devices with different quantization resolutions to participate in each FL round. Specifically, we introduce a novel stochastic quantizer (SQ) that is designed to simultaneously achieve differential privacy (DP) and minimum quantization error. Notably, the proposed SQ guarantees bounded distortion, unlike other DP approaches. To address quantization heterogeneity, we introduce a cluster size optimization technique combined with a linear fusion approach to enhance model aggregation accuracy. Numerical simulations validate the benefits of our approach in terms of privacy protection and learning utility compared to the conventional LaplaceSQ-FL algorithm.</description>
      <guid isPermaLink="false">oai:arXiv.org:2507.00920v1</guid>
      <category>cs.LG</category>
      <category>eess.SP</category>
      <pubDate>Wed, 02 Jul 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Dang Qua Nguyen, Morteza Hashemi, Erik Perrins, Sergiy A. Vorobyov, David J. Love, Taejoon Kim</dc:creator>
    </item>
    <item>
      <title>Modern Base Station Architecture: Enabling Passive Beamforming with Beyond Diagonal RISs</title>
      <link>https://arxiv.org/abs/2501.15382</link>
      <description>arXiv:2501.15382v2 Announce Type: replace 
Abstract: Beamforming plays a crucial role in millimeter wave (mmWave) communication systems to mitigate the severe attenuation inherent to this spectrum. However, the use of large active antenna arrays in conventional architectures often results in high implementation costs and excessive power consumption, limiting their practicality. As an alternative, deploying large arrays at transceivers using passive devices, such as reconfigurable intelligent surfaces (RISs), offers a more cost-effective and energy-efficient solution. In this paper, we investigate a promising base station (BS) architecture that integrates a beyond diagonal RIS (BD-RIS) within the BS to enable passive beamforming. By utilizing Takagi's decomposition and leveraging the effective beamforming vector, the RIS profile can be designed to enable passive beamforming directed toward the target. Through the beamforming analysis, we reveal that BD-RIS provides robust beamforming performance across various system configurations, whereas the traditional diagonal RIS (D-RIS) exhibits instability with increasing RIS size and decreasing BS-RIS separation-two critical factors in optimizing RIS-assisted systems. Comprehensive computer simulation results across various aspects validate the superiority of the proposed BS-integrated BD-RIS over conventional D-RIS architectures, showcasing performance comparable to active analog beamforming antenna arrays.</description>
      <guid isPermaLink="false">oai:arXiv.org:2501.15382v2</guid>
      <category>eess.SP</category>
      <pubDate>Wed, 02 Jul 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Mahmoud Raeisi, Hui Chen, Henk Wymeersch, Ertugrul Basar</dc:creator>
    </item>
    <item>
      <title>Machine Learning-Based Analysis of ECG and PCG Signals for Rheumatic Heart Disease Detection: A Scoping Review (2015-2025)</title>
      <link>https://arxiv.org/abs/2505.18182</link>
      <description>arXiv:2505.18182v2 Announce Type: replace 
Abstract: AI-powered stethoscopes offer a promising alternative for screening rheumatic heart disease (RHD), particularly in regions with limited diagnostic infrastructure. Early detection is vital, yet echocardiography, the gold standard tool, remains largely inaccessible in low-resource settings due to cost and workforce constraints. This review systematically examines machine learning (ML) applications from 2015 to 2025 that analyze electrocardiogram (ECG) and phonocardiogram (PCG) data to support accessible, scalable screening of all RHD variants in relation to the World Heart Federation's "25 by 25" goal to reduce RHD mortality. Using PRISMA-ScR guidelines, 37 peer-reviewed studies were selected from PubMed, IEEE Xplore, Scopus, and Embase. Convolutional neural networks (CNNs) dominate recent efforts, achieving a median accuracy of 97.75%, F1-score of 0.95, and AUROC of 0.89. However, challenges remain: 73% of studies used single-center datasets, 81.1% relied on private data, only 10.8% were externally validated, and none assessed cost-effectiveness. Although 45.9% originated from endemic regions, few addressed demographic diversity or implementation feasibility. These gaps underscore the disconnect between model performance and clinical readiness. Bridging this divide requires standardized benchmark datasets, prospective trials in endemic areas, and broader validation. If these issues are addressed, AI-augmented auscultation could transform cardiovascular diagnostics in underserved populations, thereby aiding early detection. This review also offers practical recommendations for building accessible ML-based RHD screening tools, aiming to close the diagnostic gap in low-resource settings where conventional auscultation may miss up to 90% of cases and echocardiography remains out of reach.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.18182v2</guid>
      <category>eess.SP</category>
      <category>cs.LG</category>
      <pubDate>Wed, 02 Jul 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/publicdomain/zero/1.0/</dc:rights>
      <dc:creator>Damilare Emmanuel Olatunji, Julius Dona Zannu, Carine Pierrette Mukamakuza, Godbright Nixon Uiso, Chol Buol, Mona Mamoun Mubarak Aman, John Bosco Thuo, Nchofon Tagha Ghogomu, Evelyne Umubyeyi</dc:creator>
    </item>
    <item>
      <title>Sensing-Aware Transmit Waveform/Receive Filter Design for OFDM-MBS Systems</title>
      <link>https://arxiv.org/abs/2506.20231</link>
      <description>arXiv:2506.20231v2 Announce Type: replace 
Abstract: In this letter, we study the problem of cooperative sensing design for an orthogonal frequency division multiplexing (OFDM) multiple base stations (MBS) system. We consider a practical scenario where the base stations (BSs) exploit certain subcarriers to realize a sensing function. Since the high sidelobe level (SLL) of OFDM waveforms degrades radar detection for weak targets, and the cross-correlation generated by other BSs further exacerbates detection performance, we devise a joint design scheme for OFDM sequence and receive filter by minimizing the integrated sidelobe level (ISL) while satisfying mainlobe level, peak-to-average power ratio (PAPR) and spectrum allocation constraints. To address this non-convex problem, we propose an alternating optimization (AO)-based algorithm. Numerical simulations validate the effectiveness of the proposed method, demonstrating the superiority of SSL reduction in the MBS system over the matched filtering method.</description>
      <guid isPermaLink="false">oai:arXiv.org:2506.20231v2</guid>
      <category>eess.SP</category>
      <pubDate>Wed, 02 Jul 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Xinghe Li, Kainan Cheng, Hongzhi Guo, Huiyong Li, Ziyang Cheng</dc:creator>
    </item>
    <item>
      <title>ECG-Byte: A Tokenizer for End-to-End Generative Electrocardiogram Language Modeling</title>
      <link>https://arxiv.org/abs/2412.14373</link>
      <description>arXiv:2412.14373v2 Announce Type: replace-cross 
Abstract: Large Language Models (LLMs) have demonstrated exceptional versatility across domains, including applications to electrocardiograms (ECGs). A growing body of work focuses on generating text from multi-channeled ECG signals and corresponding textual prompts. Existing approaches often involve a two-stage process: pretraining an ECG-specific encoder with a self-supervised learning (SSL) objective, followed by finetuning an LLM for natural language generation (NLG) using encoder-derived features. However, these methods face two key limitations: inefficiency due to multi-stage training and challenges in interpreting encoder-generated features. To overcome these issues, we propose ECG-Byte, an adapted byte pair encoding (BPE) tokenizer pipeline for autoregressive language modeling of ECGs. ECG-Byte compresses and encodes ECG signals into tokens, enabling direct end-to-end LLM training by combining ECG and text tokens. This approach enhances interpretability, as ECG tokens can be directly mapped back to the original signals. Leveraging ECG-Byte, we achieve competitive NLG performance while training 3 times faster and using just 48\% of the data required by traditional two-stage methods.</description>
      <guid isPermaLink="false">oai:arXiv.org:2412.14373v2</guid>
      <category>cs.CL</category>
      <category>eess.SP</category>
      <pubDate>Wed, 02 Jul 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>William Han, Chaojing Duan, Michael A. Rosenberg, Emerson Liu, Ding Zhao</dc:creator>
    </item>
    <item>
      <title>Mirror Online Conformal Prediction with Intermittent Feedback</title>
      <link>https://arxiv.org/abs/2503.10345</link>
      <description>arXiv:2503.10345v4 Announce Type: replace-cross 
Abstract: Online conformal prediction enables the runtime calibration of a pre-trained artificial intelligence model using feedback on its performance. Calibration is achieved through set predictions that are updated via online rules so as to ensure long-term coverage guarantees. While recent research has demonstrated the benefits of incorporating prior knowledge into the calibration process, this has come at the cost of replacing coverage guarantees with less tangible regret guarantees based on the quantile loss. This work introduces intermittent mirror online conformal prediction (IM-OCP), a novel runtime calibration framework that integrates prior knowledge, operates under potentially intermittent feedback, and features minimal memory complexity. IM-OCP guarantees long-term coverage and sub-linear regret, both of which hold deterministically for any given data sequence and in expectation with respect to the intermittent feedback.</description>
      <guid isPermaLink="false">oai:arXiv.org:2503.10345v4</guid>
      <category>cs.LG</category>
      <category>eess.SP</category>
      <pubDate>Wed, 02 Jul 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Bowen Wang, Matteo Zecchin, Osvaldo Simeone</dc:creator>
    </item>
    <item>
      <title>Analogical Learning for Cross-Scenario Generalization: Framework and Application to Intelligent Localization</title>
      <link>https://arxiv.org/abs/2504.08811</link>
      <description>arXiv:2504.08811v2 Announce Type: replace-cross 
Abstract: Existing learning models often exhibit poor generalization when deployed across diverse scenarios. It is primarily due to that the underlying reference frame of the data varies with the deployment environment and settings. However, despite that data of each scenario has a distinct reference frame, its generation generally follows common underlying physical rules. Based on this understanding, this article proposes a deep learning framework named analogical learning (AL), which implicitly retrieves the reference frame information associated with a scenario and then to make accurate prediction by relative analogy with other scenarios. Specifically, we design a bipartite neural network called Mateformer. Its first part captures the relativity within multiple latent feature spaces between the input data and a small amount of embedded data from the studied scenario, while its second part uses this relativity to guide the nonlinear analogy. We apply AL to the typical multi-scenario learning problem of intelligent wireless localization in cellular networks. Extensive experiments validate AL's superiority across three key dimensions. First, it achieves state-of-the-art accuracy in single-scenario benchmarks. Second, it demonstrates stable transferability between different scenarios, avoiding catastrophic forgetting. Finally, and most importantly, it robustly adapts to new, unseen scenarios--including dynamic weather and traffic conditions--without any tuning. All data and code are available at https://github.com/ziruichen-research/ALLoc.</description>
      <guid isPermaLink="false">oai:arXiv.org:2504.08811v2</guid>
      <category>cs.LG</category>
      <category>cs.CE</category>
      <category>eess.SP</category>
      <pubDate>Wed, 02 Jul 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Zirui Chen, Zhaoyang Zhang, Ziqing Xing, Ridong Li, Zhaohui Yang, Richeng Jin, Chongwen Huang, Yuzhi Yang, M\'erouane Debbah</dc:creator>
    </item>
  </channel>
</rss>
