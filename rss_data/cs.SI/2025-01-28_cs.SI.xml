<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>cs.SI updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/cs.SI</link>
    <description>cs.SI updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/cs.SI" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Wed, 29 Jan 2025 02:34:10 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Tue, 28 Jan 2025 00:00:00 -0500</pubDate>
    <skipDays>
      <day>Saturday</day>
      <day>Sunday</day>
    </skipDays>
    <item>
      <title>Sharp exact recovery threshold for two-community Euclidean random graphs</title>
      <link>https://arxiv.org/abs/2501.14830</link>
      <description>arXiv:2501.14830v1 Announce Type: new 
Abstract: This paper considers the problem of label recovery in random graphs and matrices. Motivated by transitive behavior in real-world networks (i.e., ``the friend of my friend is my friend''), a recent line of work considers spatially-embedded networks, which exhibit transitive behavior. In particular, the Geometric Hidden Community Model (GHCM), introduced by Gaudio, Guan, Niu, and Wei, models a network as a labeled Poisson point process where every pair of vertices is associated with a pairwise observation whose distribution depends on the labels and positions of the vertices. The GHCM is in turn a generalization of the Geometric SBM (proposed by Baccelli and Sankararaman). Gaudio et al. provided a threshold below which exact recovery is information-theoretically impossible. Above the threshold, they provided a linear-time algorithm that succeeds in exact recovery under a certain ``distinctness-of-distributions'' assumption, which they conjectured to be unnecessary. In this paper, we partially resolve the conjecture by showing that the threshold is indeed tight for the two-community GHCM. We provide a two-phase, linear-time algorithm that explores the spatial graph in a data-driven manner in Phase I to yield an almost exact labeling, which is refined to achieve exact recovery in Phase II. Our results extend achievability to geometric formulations of well-known inference problems, such as the planted dense subgraph problem and submatrix localization, in which the distinctness-of-distributions assumption does not hold.</description>
      <guid isPermaLink="false">oai:arXiv.org:2501.14830v1</guid>
      <category>cs.SI</category>
      <category>math.PR</category>
      <pubDate>Tue, 28 Jan 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Julia Gaudio, Charlie K. Guan</dc:creator>
    </item>
    <item>
      <title>Principal Graph Encoder Embedding and Principal Community Detection</title>
      <link>https://arxiv.org/abs/2501.14939</link>
      <description>arXiv:2501.14939v1 Announce Type: new 
Abstract: In this paper, we introduce the concept of principal communities and propose a principal graph encoder embedding method that concurrently detects these communities and achieves vertex embedding. Given a graph adjacency matrix with vertex labels, the method computes a sample community score for each community, ranking them to measure community importance and estimate a set of principal communities. The method then produces a vertex embedding by retaining only the dimensions corresponding to these principal communities. Theoretically, we define the population version of the encoder embedding and the community score based on a random Bernoulli graph distribution. We prove that the population principal graph encoder embedding preserves the conditional density of the vertex labels and that the population community score successfully distinguishes the principal communities. We conduct a variety of simulations to demonstrate the finite-sample accuracy in detecting ground-truth principal communities, as well as the advantages in embedding visualization and subsequent vertex classification. The method is further applied to a set of real-world graphs, showcasing its numerical advantages, including robustness to label noise and computational scalability.</description>
      <guid isPermaLink="false">oai:arXiv.org:2501.14939v1</guid>
      <category>cs.SI</category>
      <category>stat.ML</category>
      <pubDate>Tue, 28 Jan 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Cencheng Shen, Yuexiao Dong, Carey E. Priebe, Jonathan Larson, Ha Trinh, Youngser Park</dc:creator>
    </item>
    <item>
      <title>YouTube Recommendations Reinforce Negative Emotions: Auditing Algorithmic Bias with Emotionally-Agentic Sock Puppets</title>
      <link>https://arxiv.org/abs/2501.15048</link>
      <description>arXiv:2501.15048v1 Announce Type: new 
Abstract: Personalized recommendation algorithms, like those on YouTube, significantly shape online content consumption. These systems aim to maximize engagement by learning users' preferences and aligning content accordingly but may unintentionally reinforce impulsive and emotional biases. Using a sock-puppet audit methodology, this study examines YouTube's capacity to recognize and reinforce emotional preferences. Simulated user accounts with assigned emotional preferences navigate the platform, selecting videos that align with their assigned preferences and recording subsequent recommendations. Our findings reveal reveal that YouTube amplifies negative emotions, such as anger and grievance, by increasing their prevalence and prominence in recommendations. This reinforcement intensifies over time and persists across contexts. Surprisingly, contextual recommendations often exceed personalized ones in reinforcing emotional alignment. These findings suggest the algorithm amplifies user biases, contributing to emotional filter bubbles and raising concerns about user well-being and societal impacts. The study emphasizes the need for balancing personalization with content diversity and user agency.</description>
      <guid isPermaLink="false">oai:arXiv.org:2501.15048v1</guid>
      <category>cs.SI</category>
      <category>cs.CY</category>
      <pubDate>Tue, 28 Jan 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <dc:creator>Hussam Habib, Rishab Nithyanand</dc:creator>
    </item>
    <item>
      <title>Community Detection in Large-Scale Complex Networks via Structural Entropy Game</title>
      <link>https://arxiv.org/abs/2501.15130</link>
      <description>arXiv:2501.15130v1 Announce Type: new 
Abstract: Community detection is a critical task in graph theory, social network analysis, and bioinformatics, where communities are defined as clusters of densely interconnected nodes. However, detecting communities in large-scale networks with millions of nodes and billions of edges remains challenging due to the inefficiency and unreliability of existing methods. Moreover, many current approaches are limited to specific graph types, such as unweighted or undirected graphs, reducing their broader applicability. To address these issues, we propose a novel heuristic community detection algorithm, termed CoDeSEG, which identifies communities by minimizing the two-dimensional (2D) structural entropy of the network within a potential game framework. In the game, nodes decide to stay in current community or move to another based on a strategy that maximizes the 2D structural entropy utility function. Additionally, we introduce a structural entropy-based node overlapping heuristic for detecting overlapping communities, with a near-linear time complexity.Experimental results on real-world networks demonstrate that CoDeSEG is the fastest method available and achieves state-of-the-art performance in overlapping normalized mutual information (ONMI) and F1 score.</description>
      <guid isPermaLink="false">oai:arXiv.org:2501.15130v1</guid>
      <category>cs.SI</category>
      <pubDate>Tue, 28 Jan 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Yantuan Xian, Pu Li, Hao Peng, Zhengtao Yu, Yan Xiang, Philip S. Yu</dc:creator>
    </item>
    <item>
      <title>Studying Behavioral Addiction by Combining Surveys and Digital Traces: A Case Study of TikTok</title>
      <link>https://arxiv.org/abs/2501.15539</link>
      <description>arXiv:2501.15539v1 Announce Type: new 
Abstract: Opaque algorithms disseminate and mediate the content that users consume on online social media platforms. This algorithmic mediation serves users with contents of their liking, on the other hand, it may cause several inadvertent risks to society at scale. While some of these risks, e.g., filter bubbles or dissemination of hateful content, are well studied in the community, behavioral addiction, designated by the Digital Services Act (DSA) as a potential systemic risk, has been understudied. In this work, we aim to study if one can effectively diagnose behavioral addiction using digital data traces from social media platforms. Focusing on the TikTok short-format video platform as a case study, we employ a novel mixed methodology of combining survey responses with data donations of behavioral traces. We survey 1590 TikTok users and stratify them into three addiction groups (i.e., less/moderately/highly likely addicted). Then, we obtain data donations from 107 surveyed participants. By analyzing users' data we find that, among others, highly likely addicted users spend more time watching TikTok videos and keep coming back to TikTok throughout the day, indicating a compulsion to use the platform. Finally, by using basic user engagement features, we train classifier models to identify highly likely addicted users with $F_1 \geq 0.55$. The performance of the classifier models suggests predicting addictive users solely based on their usage is rather difficult.</description>
      <guid isPermaLink="false">oai:arXiv.org:2501.15539v1</guid>
      <category>cs.SI</category>
      <category>cs.CY</category>
      <pubDate>Tue, 28 Jan 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Cai Yang, Sepehr Mousavi, Abhisek Dash, Krishna P. Gummadi, Ingmar Weber</dc:creator>
    </item>
    <item>
      <title>Modeling shared micromobility as a label propagation process for detecting the overlapping communities</title>
      <link>https://arxiv.org/abs/2501.15713</link>
      <description>arXiv:2501.15713v1 Announce Type: new 
Abstract: Shared micro-mobility such as e-scooters has gained significant popularity in many cities. However, existing methods for detecting community structures in mobility networks often overlook potential overlaps between communities. In this study, we conceptualize shared micro-mobility in urban spaces as a process of information exchange, where locations are connected through e-scooters, facilitating the interaction and propagation of community affiliations. As a result, similar locations are assigned the same label. Based on this concept, we developed a Geospatial Interaction Propagation model (GIP) by designing a Speaker-Listener Label Propagation Algorithm (SLPA) that accounts for geographic distance decay, incorporating anomaly detection to ensure the derived community structures reflect meaningful spatial patterns. We applied this model to detect overlapping communities within the e-scooter system in Washington, D.C. The results demonstrate that our algorithm outperforms existing model of overlapping community detection in both efficiency and modularity. However, existing methods for detecting community structures in mobility networks often overlook potential overlaps between communities. In this study, we conceptualize shared micro-mobility in urban spaces as a process of information exchange, where locations are connected through e-scooters, facilitating the interaction and propagation of community affiliations. As a result, similar locations are assigned the same label. Based on this concept, we developed a Geospatial Interaction Propagation model (GIP) by designing a Speaker-Listener Label Propagation Algorithm (SLPA) that accounts for geographic distance decay, incorporating anomaly detection to ensure the derived community structures reflect meaningful spatial patterns.</description>
      <guid isPermaLink="false">oai:arXiv.org:2501.15713v1</guid>
      <category>cs.SI</category>
      <category>physics.app-ph</category>
      <pubDate>Tue, 28 Jan 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Peng Luo, Chengyu Song, Hao Li, Di Zhu, Fabio Duarte</dc:creator>
    </item>
    <item>
      <title>Epidemics on the Move: How Public Transport Demand and Capacity Shape Disease Spread</title>
      <link>https://arxiv.org/abs/2501.16004</link>
      <description>arXiv:2501.16004v1 Announce Type: new 
Abstract: Understanding the dynamics of passenger interactions and their epidemiological impact throughout public transportation systems is crucial for both service efficiency and public health. High passenger density and close physical proximity has been shown to accelerate the spread of infectious diseases. During the COVID-19 pandemic, many public transportation companies took measures to slow down and minimize disease spreading. One of these measures was introducing spacing and capacity constraints to public transit vehicles. Our objective is to explore the effects of demand changes and transportation measures from an epidemiological point of view, offering alternative measures to public transportation companies to keep the system alive while minimizing the epidemiological risk as much as possible.</description>
      <guid isPermaLink="false">oai:arXiv.org:2501.16004v1</guid>
      <category>cs.SI</category>
      <category>physics.soc-ph</category>
      <pubDate>Tue, 28 Jan 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>L\'aszl\'o Hajdu, Jovan Pavlovi\'c, Mikl\'os Kr\'esz, Andr\'as B\'ota</dc:creator>
    </item>
    <item>
      <title>Minimizing Polarization and Disagreement in the Friedkin-Johnsen Model with Unknown Innate Opinions</title>
      <link>https://arxiv.org/abs/2501.16076</link>
      <description>arXiv:2501.16076v2 Announce Type: new 
Abstract: The bulk of the literature on opinion optimization in social networks adopts the Friedkin-Johnsen (FJ) opinion dynamics model, in which the innate opinions of all nodes are known: this is an unrealistic assumption. In this paper, we study opinion optimization under the FJ model without the full knowledge of innate opinions. Specifically, we borrow from the literature a series of objective functions, aimed at minimizing polarization and/or disagreement, and we tackle the budgeted optimization problem, where we can query the innate opinions of only a limited number of nodes. Given the complexity of our problem, we propose a framework based on three steps: (1) select the limited number of nodes we query, (2) reconstruct the innate opinions of all nodes based on those queried, and (3) optimize the objective function with the reconstructed opinions. For each step of the framework, we present and systematically evaluate several effective strategies. A key contribution of our work is a rigorous error propagation analysis that quantifies how reconstruction errors in innate opinions impact the quality of the final solutions. Our experiments on various synthetic and real-world datasets show that we can effectively minimize polarization and disagreement even if we have quite limited information about innate opinions.</description>
      <guid isPermaLink="false">oai:arXiv.org:2501.16076v2</guid>
      <category>cs.SI</category>
      <pubDate>Tue, 28 Jan 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <dc:creator>Federico Cinus, Atsushi Miyauchi, Yuko Kuroki, Francesco Bonchi</dc:creator>
    </item>
    <item>
      <title>Posting Patterns of Members of Parental Subreddits</title>
      <link>https://arxiv.org/abs/2501.16193</link>
      <description>arXiv:2501.16193v1 Announce Type: new 
Abstract: Online forums (e.g., Reddit) are used by many parents to discuss their challenges, needs, and receive support. While studies have investigated the contents of posts made to popular parental subreddits revealing the family health concerns being expressed, little is known about parents' posting patterns or other issues they engage in. In this study, we explore the posting activity of users of 55 parental subreddits. Exploring posts made by these users (667K) across Reddit (34M posts) reveals that over 85% of posters are not one-time users of Reddit and actively engage with the community. Studying cross-posting patterns also reveals the use of subreddits dedicated to other topics such as relationship and health advice (e.g., r/AskDocs, r/relationship_advice) by this population. As a result, for a comprehensive understanding of the type of information posters share and seek, future work should investigate sub-communities outside of parental-specific ones. Finally, we expand the list of parental subreddits, compiling a total of 115 subreddits that could be utilized in future studies of parental concerns.</description>
      <guid isPermaLink="false">oai:arXiv.org:2501.16193v1</guid>
      <category>cs.SI</category>
      <pubDate>Tue, 28 Jan 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Nazanin Sabri, Mai Elsherief</dc:creator>
    </item>
    <item>
      <title>New Frontiers in Fighting Misinformation</title>
      <link>https://arxiv.org/abs/2501.16210</link>
      <description>arXiv:2501.16210v1 Announce Type: new 
Abstract: Despite extensive research and development of tools and technologies for misinformation tracking and detection, we often find ourselves largely on the losing side of the battle against misinformation. In an era where misinformation poses a substantial threat to public discourse, trust in information sources, and societal and political stability, it is imperative that we regularly revisit and reorient our work strategies. While we have made significant strides in understanding how and why misinformation spreads, we must now broaden our focus and explore how technology can help realise new approaches to address this complex challenge more efficiently.</description>
      <guid isPermaLink="false">oai:arXiv.org:2501.16210v1</guid>
      <category>cs.SI</category>
      <pubDate>Tue, 28 Jan 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Harith Alani, Gr\'egoire Burel</dc:creator>
    </item>
    <item>
      <title>Linked Data on Geo-annotated Events and Use Cases for the Resilience of Ukraine</title>
      <link>https://arxiv.org/abs/2501.14762</link>
      <description>arXiv:2501.14762v1 Announce Type: cross 
Abstract: The mission of resilience of Ukrainian cities calls for international collaboration with the scientific community to increase the quality of information by identifying and integrating information from various news and social media sources. Linked Data technology can be used to unify, enrich, and integrate data from multiple sources. In our work, we focus on datasets about damaging events in Ukraine due to Russia's invasion between February 2022 and the end of April 2023. We convert two selected datasets to Linked Data and enrich them with additional geospatial information. Following that, we present an algorithm for the detection of identical events from different datasets. Our pipeline makes it easy to convert and enrich datasets to integrated Linked Data. The resulting dataset consists of 10K reported events covering damage to hospitals, schools, roads, residential buildings, etc. Finally, we demonstrate in use cases how our dataset can be applied to different scenarios for resilience purposes.</description>
      <guid isPermaLink="false">oai:arXiv.org:2501.14762v1</guid>
      <category>cs.CY</category>
      <category>cs.SI</category>
      <pubDate>Tue, 28 Jan 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Manar Attar, Shuai Wang, Ronald Siebes, Eirik Kultorp, Zhisheng Huang, Tianyang Lu</dc:creator>
    </item>
    <item>
      <title>Leveraging Social Media Data and Artificial Intelligence for Improving Earthquake Response Efforts</title>
      <link>https://arxiv.org/abs/2501.14767</link>
      <description>arXiv:2501.14767v1 Announce Type: cross 
Abstract: The integration of social media and artificial intelligence (AI) into disaster management, particularly for earthquake response, represents a profound evolution in emergency management practices. In the digital age, real-time information sharing has reached unprecedented levels, with social media platforms emerging as crucial communication channels during crises. This shift has transformed traditional, centralized emergency services into more decentralized, participatory models of disaster situational awareness. Our study includes an experimental analysis of 8,900 social media interactions, including 2,920 posts and 5,980 replies on X (formerly Twitter), following a magnitude 5.1 earthquake in Oklahoma on February 2, 2024. The analysis covers data from the immediate aftermath and extends over the following seven days, illustrating the critical role of digital platforms in modern disaster response. The results demonstrate that social media platforms can be effectively used as real-time situational awareness tools, delivering critical information to society and authorities during emergencies.</description>
      <guid isPermaLink="false">oai:arXiv.org:2501.14767v1</guid>
      <category>cs.CY</category>
      <category>cs.AI</category>
      <category>cs.CL</category>
      <category>cs.IR</category>
      <category>cs.SI</category>
      <pubDate>Tue, 28 Jan 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <arxiv:DOI>10.1007/978-3-031-74707-6_24</arxiv:DOI>
      <dc:creator>Kalin Kopanov, Velizar Varbanov, Tatiana Atanasova</dc:creator>
    </item>
    <item>
      <title>ED-Filter: Dynamic Feature Filtering for Eating Disorder Classification</title>
      <link>https://arxiv.org/abs/2501.14785</link>
      <description>arXiv:2501.14785v1 Announce Type: cross 
Abstract: Eating disorders (ED) are critical psychiatric problems that have alarmed the mental health community. Mental health professionals are increasingly recognizing the utility of data derived from social media platforms such as Twitter. However, high dimensionality and extensive feature sets of Twitter data present remarkable challenges for ED classification. To overcome these hurdles, we introduce a novel method, an informed branch and bound search technique known as ED-Filter. This strategy significantly improves the drawbacks of conventional feature selection algorithms such as filters and wrappers. ED-Filter iteratively identifies an optimal set of promising features that maximize the eating disorder classification accuracy. In order to adapt to the dynamic nature of Twitter ED data, we enhance the ED-Filter with a hybrid greedy-based deep learning algorithm. This algorithm swiftly identifies sub-optimal features to accommodate the ever-evolving data landscape. Experimental results on Twitter eating disorder data affirm the effectiveness and efficiency of ED-Filter. The method demonstrates significant improvements in classification accuracy and proves its value in eating disorder detection on social media platforms.</description>
      <guid isPermaLink="false">oai:arXiv.org:2501.14785v1</guid>
      <category>stat.ML</category>
      <category>cs.AI</category>
      <category>cs.LG</category>
      <category>cs.SI</category>
      <pubDate>Tue, 28 Jan 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Mehdi Naseriparsa, Suku Sukunesan, Zhen Cai, Osama Alfarraj, Amr Tolba, Saba Fathi Rabooki, Feng Xia</dc:creator>
    </item>
    <item>
      <title>Who is the root in a syntactic dependency structure?</title>
      <link>https://arxiv.org/abs/2501.15188</link>
      <description>arXiv:2501.15188v1 Announce Type: cross 
Abstract: The syntactic structure of a sentence can be described as a tree that indicates the syntactic relationships between words. In spite of significant progress in unsupervised methods that retrieve the syntactic structure of sentences, guessing the right direction of edges is still a challenge. As in a syntactic dependency structure edges are oriented away from the root, the challenge of guessing the right direction can be reduced to finding an undirected tree and the root. The limited performance of current unsupervised methods demonstrates the lack of a proper understanding of what a root vertex is from first principles. We consider an ensemble of centrality scores, some that only take into account the free tree (non-spatial scores) and others that take into account the position of vertices (spatial scores). We test the hypothesis that the root vertex is an important or central vertex of the syntactic dependency structure. We confirm that hypothesis and find that the best performance in guessing the root is achieved by novel scores that only take into account the position of a vertex and that of its neighbours. We provide theoretical and empirical foundations towards a universal notion of rootness from a network science perspective.</description>
      <guid isPermaLink="false">oai:arXiv.org:2501.15188v1</guid>
      <category>cs.CL</category>
      <category>cs.SI</category>
      <category>physics.soc-ph</category>
      <pubDate>Tue, 28 Jan 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Ramon Ferrer-i-Cancho, Marta Arias</dc:creator>
    </item>
    <item>
      <title>Figurative-cum-Commonsense Knowledge Infusion for Multimodal Mental Health Meme Classification</title>
      <link>https://arxiv.org/abs/2501.15321</link>
      <description>arXiv:2501.15321v1 Announce Type: cross 
Abstract: The expression of mental health symptoms through non-traditional means, such as memes, has gained remarkable attention over the past few years, with users often highlighting their mental health struggles through figurative intricacies within memes. While humans rely on commonsense knowledge to interpret these complex expressions, current Multimodal Language Models (MLMs) struggle to capture these figurative aspects inherent in memes. To address this gap, we introduce a novel dataset, AxiOM, derived from the GAD anxiety questionnaire, which categorizes memes into six fine-grained anxiety symptoms. Next, we propose a commonsense and domain-enriched framework, M3H, to enhance MLMs' ability to interpret figurative language and commonsense knowledge. The overarching goal remains to first understand and then classify the mental health symptoms expressed in memes. We benchmark M3H against 6 competitive baselines (with 20 variations), demonstrating improvements in both quantitative and qualitative metrics, including a detailed human evaluation. We observe a clear improvement of 4.20% and 4.66% on weighted-F1 metric. To assess the generalizability, we perform extensive experiments on a public dataset, RESTORE, for depressive symptom identification, presenting an extensive ablation study that highlights the contribution of each module in both datasets. Our findings reveal limitations in existing models and the advantage of employing commonsense to enhance figurative understanding.</description>
      <guid isPermaLink="false">oai:arXiv.org:2501.15321v1</guid>
      <category>cs.CL</category>
      <category>cs.SI</category>
      <pubDate>Tue, 28 Jan 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Abdullah Mazhar, Zuhair hasan shaik, Aseem Srivastava, Polly Ruhnke, Lavanya Vaddavalli, Sri Keshav Katragadda, Shweta Yadav, Md Shad Akhtar</dc:creator>
    </item>
    <item>
      <title>Community-centric modeling of citation dynamics explains collective citation patterns in science, law, and patents</title>
      <link>https://arxiv.org/abs/2501.15552</link>
      <description>arXiv:2501.15552v2 Announce Type: cross 
Abstract: Many human knowledge systems, such as science, law, and invention, are built on documents and the citations that link them. Citations, while serving multiple purposes, primarily function as a way to explicitly document the use of prior work and thus have become central to the study of knowledge systems. Analyzing citation dynamics has revealed statistical patterns that shed light on knowledge production, recognition, and formalization, and has helped identify key mechanisms driving these patterns. However, most quantitative findings are confined to scientific citations, raising the question of universality of these findings. Moreover, existing models of individual citation trajectories fail to explain phenomena such as delayed recognition, calling for a unifying framework. Here, we analyze a newly available corpus of U.S. case law, in addition to scientific and patent citation networks, to show that they share remarkably similar citation patterns, including a heavy-tailed distribution of sleeping beauties. We propose a holistic model that captures the three core mechanisms driving collective dynamics and replicates the elusive phenomenon of delayed recognition. We demonstrate that the model not only replicates observed citation patterns, but also better predicts future successes by considering the whole system. Our work offers insights into key mechanisms that govern large-scale patterns of collective human knowledge systems and may provide generalizable perspectives on discovery and innovation across domains.</description>
      <guid isPermaLink="false">oai:arXiv.org:2501.15552v2</guid>
      <category>physics.soc-ph</category>
      <category>cs.SI</category>
      <pubDate>Tue, 28 Jan 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <dc:creator>Sadamori Kojaku, Robert Mahari, Sandro Claudio Lera, Esteban Moro, Alex Pentland, Yong-Yeol Ahn</dc:creator>
    </item>
    <item>
      <title>Vienna Mosaic: Navigating Social Borders in a Melting Pot</title>
      <link>https://arxiv.org/abs/2501.15920</link>
      <description>arXiv:2501.15920v1 Announce Type: cross 
Abstract: Urban segregation poses a critical challenge in cities, exacerbating inequalities, social tensions, fears, and polarization. It emerges from a complex interplay of socioeconomic disparities and residential preferences, disproportionately impacting migrant communities. In this paper, using a comprehensive administrative data from Vienna, where nearly 40% of the population consists of international migrants, we analyse co-residence preferences between migrants and locals at the neighbourhood level. Our findings reveal two major clusters in Vienna shaped by wealth disparities, district diversity, and nationality-based homophily. These insights shed light on the underlying mechanisms of urban segregation and designing policies for better integration.</description>
      <guid isPermaLink="false">oai:arXiv.org:2501.15920v1</guid>
      <category>physics.soc-ph</category>
      <category>cs.SI</category>
      <category>physics.data-an</category>
      <pubDate>Tue, 28 Jan 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <dc:creator>Marc Sadurn\'i, Samuel Martin-Gutierrez, Ola Ali, Ana Mar\'ia Jaramillo, Rafael Prieto-Curiel, Fariba Karimi</dc:creator>
    </item>
    <item>
      <title>Generalizing Egocentric Temporal Neighborhoods to probe for spatial correlations in temporal networks and infer their topology</title>
      <link>https://arxiv.org/abs/2501.16070</link>
      <description>arXiv:2501.16070v1 Announce Type: cross 
Abstract: Motifs are thought to be some fundamental components of social face-to-face interaction temporal networks. However, the motifs previously considered are either limited to a handful of nodes and edges, or do not include triangles, which are thought to be of critical relevance to understand the dynamics of social systems. Thus, we introduce a new class of motifs, that include these triangles, are not limited in their number of nodes or edges, and yet can be mined efficiently in any temporal network. Referring to these motifs as the edge-centered motifs, we show analytically how they subsume the Egocentric Temporal Neighborhoods motifs of [A. Longa, G. Cencetti, B. Lepri, and A. Passerini, An efficient procedure for mining egocentric temporal motifs, Data Mining and Knowledge Discovery 36, 355 (2022)]. We also confirm in empirical data that the edge-centered motifs bring relevant information with respect to the Egocentric motifs by using a principle of maximum entropy. Then, we show how mining for the edge-centered motifs in a network can be used to probe for spatial correlations in the underlying dynamics that have produced that network. We deduce an approximate formula for the distribution of the edge-centered motifs in empirical networks of social face-to-face interactions. In the last section of this paper, we explore how the statistics of the edge-centered motifs can be used to infer the complete topology of the network they were sampled from. This leads to the needs of mathematical development, that we inaugurate here under the name of graph tiling theory.</description>
      <guid isPermaLink="false">oai:arXiv.org:2501.16070v1</guid>
      <category>physics.soc-ph</category>
      <category>cs.SI</category>
      <pubDate>Tue, 28 Jan 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-sa/4.0/</dc:rights>
      <dc:creator>Didier Le Bail</dc:creator>
    </item>
    <item>
      <title>Targeted Advertising on Social Networks Using Online Variational Tensor Regression</title>
      <link>https://arxiv.org/abs/2208.10627</link>
      <description>arXiv:2208.10627v4 Announce Type: replace 
Abstract: This paper is concerned with online targeted advertising on social networks. The main technical task we address is to estimate the activation probability for user pairs, which quantifies the influence one user may have on another towards purchasing decisions. This is a challenging task because one marketing episode typically involves a multitude of marketing campaigns/strategies of different products for highly diverse customers. In this paper, we propose what we believe is the first tensor-based contextual bandit framework for online targeted advertising. The proposed framework is designed to accommodate any number of feature vectors in the form of multi-mode tensor, thereby enabling to capture the heterogeneity that may exist over user preferences, products, and campaign strategies in a unified manner. To handle inter-dependency of tensor modes, we introduce an online variational algorithm with a mean-field approximation. We empirically confirm that the proposed TensorUCB algorithm achieves a significant improvement in influence maximization tasks over the benchmarks, which is attributable to its capability of capturing the user-product heterogeneity.</description>
      <guid isPermaLink="false">oai:arXiv.org:2208.10627v4</guid>
      <category>cs.SI</category>
      <category>cs.LG</category>
      <pubDate>Tue, 28 Jan 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <arxiv:DOI>10.1007/s10115-024-02304-2</arxiv:DOI>
      <arxiv:journal_reference>Published as Tsuyoshi Id\'e, Keerthiram Murugesan, Djallel Bouneffouf, and Naoki Abe, "Sequential uncertainty quantification with contextual tensors for social targeting," Knowledge and Information Systems (2024)</arxiv:journal_reference>
      <dc:creator>Tsuyoshi Id\'e, Keerthiram Murugesan, Djallel Bouneffouf, Naoki Abe</dc:creator>
    </item>
    <item>
      <title>The Strong Maximum Circulation Algorithm: A New Method for Aggregating Preference Rankings</title>
      <link>https://arxiv.org/abs/2307.15702</link>
      <description>arXiv:2307.15702v4 Announce Type: replace 
Abstract: We present a new optimization-based method for aggregating preferences in settings where each voter expresses preferences over pairs of alternatives. Our approach to identifying a consensus partial order is motivated by the observation that collections of votes that form a cycle can be treated as collective ties. Our approach then removes unions of cycles of votes, or circulations, from the vote graph and determines aggregate preferences from the remainder. Specifically, we study the removal of maximal circulations attained by any union of cycles the removal of which leaves an acyclic graph. We introduce the strong maximum circulation, the removal of which guarantees a unique outcome in terms of the induced partial order, called the strong partial order. The strong maximum circulation also satisfies strong complementary slackness conditions, and is shown to be solved efficiently as a network flow problem. We further establish the relationship between the dual of the maximum circulation problem and Kemeny's method, a popular optimization-based approach for preference aggregation. We also show that identifying a minimum maximal circulation -- i.e., a maximal circulation containing the smallest number of votes -- is an NP-hard problem. Further an instance of the minimum maximal circulation may have multiple optimal solutions whose removal results in conflicting partial orders.</description>
      <guid isPermaLink="false">oai:arXiv.org:2307.15702v4</guid>
      <category>cs.SI</category>
      <category>econ.TH</category>
      <category>math.OC</category>
      <pubDate>Tue, 28 Jan 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Nathan Atkinson, Scott C. Ganz, Dorit S. Hochbaum, James B. Orlin</dc:creator>
    </item>
    <item>
      <title>Analyzing User Characteristics of Hate Speech Spreaders on Social Media</title>
      <link>https://arxiv.org/abs/2310.15772</link>
      <description>arXiv:2310.15772v3 Announce Type: replace 
Abstract: Hate speech on social media threatens the mental and physical well-being of individuals and contributes to real-world violence. Resharing is an important driver behind the spread of hate speech on social media. Yet, little is known about who reshares hate speech and what their characteristics are. In this paper, we analyze the role of user characteristics in hate speech resharing across different types of hate speech (e.g., political hate). For this, we proceed as follows: First, we cluster hate speech posts using large language models to identify different types of hate speech. Then we model the effects of user attributes on users' probability to reshare hate speech using an explainable machine learning model. To do so, we apply debiasing to control for selection bias in our observational social media data and further control for the latent vulnerability of users to hate speech. We find that, all else equal, users with fewer followers, fewer friends, fewer posts, and older accounts share more hate speech. This shows that users with little social influence tend to share more hate speech. Further, we find substantial heterogeneity across different types of hate speech. For example, racist and misogynistic hate is spread mostly by users with little social influence. In contrast, political anti-Trump and anti-right-wing hate is reshared by users with larger social influence. Overall, understanding the factors that drive users to share hate speech is crucial for detecting individuals at risk of engaging in harmful behavior and for designing effective mitigation strategies.</description>
      <guid isPermaLink="false">oai:arXiv.org:2310.15772v3</guid>
      <category>cs.SI</category>
      <category>cs.AI</category>
      <category>cs.CY</category>
      <pubDate>Tue, 28 Jan 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Dominique Geissler, Abdurahman Maarouf, Stefan Feuerriegel</dc:creator>
    </item>
    <item>
      <title>Community Fact-Checks Trigger Moral Outrage in Replies to Misleading Posts on Social Media</title>
      <link>https://arxiv.org/abs/2409.08829</link>
      <description>arXiv:2409.08829v2 Announce Type: replace 
Abstract: Displaying community fact-checks is a promising approach to reduce engagement with misinformation on social media. However, how users respond to misleading content emotionally after community fact-checks are displayed on posts is unclear. Here, we employ quasi-experimental methods to causally analyze changes in sentiments and (moral) emotions in replies to misleading posts following the display of community fact-checks. Our evaluation is based on a large-scale panel dataset comprising N=2,225,260 replies across 1841 source posts from X's Community Notes platform. We find that informing users about falsehoods through community fact-checks significantly increases negativity (by 7.3%), anger (by 13.2%), disgust (by 4.7%), and moral outrage (by 16.0%) in the corresponding replies. These results indicate that users perceive spreading misinformation as a violation of social norms and that those who spread misinformation should expect negative reactions once their content is debunked. We derive important implications for the design of community-based fact-checking systems.</description>
      <guid isPermaLink="false">oai:arXiv.org:2409.08829v2</guid>
      <category>cs.SI</category>
      <category>cs.HC</category>
      <pubDate>Tue, 28 Jan 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <arxiv:DOI>10.1145/3706598.3713909</arxiv:DOI>
      <dc:creator>Yuwei Chuai, Anastasia Sergeeva, Gabriele Lenzini, Nicolas Pr\"ollochs</dc:creator>
    </item>
    <item>
      <title>Opinion dynamics in bounded confidence models with manipulative agents: Moving the Overton window</title>
      <link>https://arxiv.org/abs/2501.12198</link>
      <description>arXiv:2501.12198v2 Announce Type: replace 
Abstract: This paper focuses on the opinion dynamics under the influence of manipulative agents. This type of agents is characterized by the fact that their opinions follow a trajectory that does not respond to the dynamics of the model, although it does influence the rest of the normal agents. Simulation has been implemented to study how one manipulative group modifies the natural dynamics of some opinion models of bounded confidence. It is studied what strategies based on the number of manipulative agents and their common opinion trajectory can be carried out by a manipulative group to influence normal agents and attract them to their opinions. In certain weighted models, some effects are observed in which normal agents move in the opposite direction to the manipulator group. Moreover, the conditions which ensure the influence of a manipulative group on a group of normal agents over time are also established for the Hegselmann-Krause model.</description>
      <guid isPermaLink="false">oai:arXiv.org:2501.12198v2</guid>
      <category>cs.SI</category>
      <category>physics.soc-ph</category>
      <category>stat.AP</category>
      <pubDate>Tue, 28 Jan 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <arxiv:DOI>10.1016/j.physa.2025.130379</arxiv:DOI>
      <arxiv:journal_reference>Physica A: Statistical Mechanics and its Applications, Volume 660, 2025, 130379</arxiv:journal_reference>
      <dc:creator>A. Bautista</dc:creator>
    </item>
    <item>
      <title>Fine-grained Graph Rationalization</title>
      <link>https://arxiv.org/abs/2312.07859</link>
      <description>arXiv:2312.07859v3 Announce Type: replace-cross 
Abstract: Rationale discovery is defined as finding a subset of the input data that maximally supports the prediction of downstream tasks. In the context of graph machine learning, graph rationale is defined to locate the critical subgraph in the given graph topology. In contrast to the rationale subgraph, the remaining subgraph is named the environment subgraph. Graph rationalization can enhance the model performance as the mapping between the graph rationale and prediction label is viewed as invariant, by assumption. To ensure the discriminative power of the extracted rationale subgraphs, a key technique named "intervention" is applied whose heart is that given changing environment subgraphs, the semantics from the rationale subgraph is invariant, guaranteeing the correct prediction result. However, most, if not all, of the existing graph rationalization methods develop their intervention strategies on the graph level, which is coarse-grained. In this paper, we propose fine-grained graph rationalization (FIG). Our idea is driven by the self-attention mechanism, which provides rich interactions between input nodes. Based on that, FIG can achieve node-level and virtual node-level intervention. Our experiments involve 7 real-world datasets, and the proposed FIG shows significant performance advantages compared to 13 baseline methods.</description>
      <guid isPermaLink="false">oai:arXiv.org:2312.07859v3</guid>
      <category>cs.LG</category>
      <category>cs.SI</category>
      <pubDate>Tue, 28 Jan 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Zhe Xu, Menghai Pan, Yuzhong Chen, Huiyuan Chen, Yuchen Yan, Mahashweta Das, Hanghang Tong</dc:creator>
    </item>
    <item>
      <title>Uncovering Latent Arguments in Social Media Messaging by Employing LLMs-in-the-Loop Strategy</title>
      <link>https://arxiv.org/abs/2404.10259</link>
      <description>arXiv:2404.10259v4 Announce Type: replace-cross 
Abstract: The widespread use of social media has led to a surge in popularity for automated methods of analyzing public opinion. Supervised methods are adept at text categorization, yet the dynamic nature of social media discussions poses a continual challenge for these techniques due to the constant shifting of the focus. On the other hand, traditional unsupervised methods for extracting themes from public discourse, such as topic modeling, often reveal overarching patterns that might not capture specific nuances. Consequently, a significant portion of research into social media discourse still depends on labor-intensive manual coding techniques and a human-in-the-loop approach, which are both time-consuming and costly. In this work, we study the problem of discovering arguments associated with a specific theme. We propose a generic LLMs-in-the-Loop strategy that leverages the advanced capabilities of Large Language Models (LLMs) to extract latent arguments from social media messaging. To demonstrate our approach, we apply our framework to contentious topics. We use two publicly available datasets: (1) the climate campaigns dataset of 14k Facebook ads with 25 themes and (2) the COVID-19 vaccine campaigns dataset of 9k Facebook ads with 14 themes. Additionally, we design a downstream task as stance prediction by leveraging talking points in climate debates. Furthermore, we analyze demographic targeting and the adaptation of messaging based on real-world events.</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.10259v4</guid>
      <category>cs.CL</category>
      <category>cs.AI</category>
      <category>cs.CY</category>
      <category>cs.LG</category>
      <category>cs.SI</category>
      <pubDate>Tue, 28 Jan 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Tunazzina Islam, Dan Goldwasser</dc:creator>
    </item>
    <item>
      <title>Community detection in bipartite signed networks is highly dependent on parameter choice</title>
      <link>https://arxiv.org/abs/2405.08203</link>
      <description>arXiv:2405.08203v2 Announce Type: replace-cross 
Abstract: Decision-making processes often involve voting. Human interactions with exogenous entities such as legislations or products can be effectively modeled as two-mode (bipartite) signed networks-where people can either vote positively, negatively, or abstain from voting on the entities. Detecting communities in such networks could help us understand underlying properties: for example ideological camps or consumer preferences. While community detection is an established practice separately for bipartite and signed networks, it remains largely unexplored in the case of bipartite signed networks. In this paper, we systematically evaluate the efficacy of community detection methods on projected bipartite signed networks using a synthetic benchmark and real-world datasets. Our findings reveal that when no communities are present in the data, these methods often recover spurious user communities. When communities are present, the algorithms exhibit promising performance, although their performance is highly susceptible to parameter choice. This indicates that researchers using community detection methods in the context of bipartite signed networks should not take the communities found at face value: it is essential to assess the robustness of parameter choices or perform domain-specific external validation.</description>
      <guid isPermaLink="false">oai:arXiv.org:2405.08203v2</guid>
      <category>physics.soc-ph</category>
      <category>cs.SI</category>
      <category>stat.ME</category>
      <pubDate>Tue, 28 Jan 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Elena Candellone, Erik-Jan van Kesteren, Sofia Chelmi, Javier Garcia-Bernardo</dc:creator>
    </item>
    <item>
      <title>Graph Representation Learning via Causal Diffusion for Out-of-Distribution Recommendation</title>
      <link>https://arxiv.org/abs/2408.00490</link>
      <description>arXiv:2408.00490v2 Announce Type: replace-cross 
Abstract: Graph Neural Networks (GNNs)-based recommendation algorithms typically assume that training and testing data are drawn from independent and identically distributed (IID) spaces. However, this assumption often fails in the presence of out-of-distribution (OOD) data, resulting in significant performance degradation. In this study, we construct a Structural Causal Model (SCM) to analyze interaction data, revealing that environmental confounders (e.g., the COVID-19 pandemic) lead to unstable correlations in GNN-based models, thus impairing their generalization to OOD data. To address this issue, we propose a novel approach, graph representation learning via causal diffusion (CausalDiffRec) for OOD recommendation. This method enhances the model's generalization on OOD data by eliminating environmental confounding factors and learning invariant graph representations. Specifically, we use backdoor adjustment and variational inference to infer the real environmental distribution, thereby eliminating the impact of environmental confounders. This inferred distribution is then used as prior knowledge to guide the representation learning in the reverse phase of the diffusion process to learn the invariant representation. In addition, we provide a theoretical derivation that proves optimizing the objective function of CausalDiffRec can encourage the model to learn environment-invariant graph representations, thereby achieving excellent generalization performance in recommendations under distribution shifts. Our extensive experiments validate the effectiveness of CausalDiffRec in improving the generalization of OOD data, and the average improvement is up to 10.69% on Food, 18.83% on KuaiRec, 22.41% on Yelp2018, and 11.65% on Douban datasets.</description>
      <guid isPermaLink="false">oai:arXiv.org:2408.00490v2</guid>
      <category>cs.LG</category>
      <category>cs.AI</category>
      <category>cs.IR</category>
      <category>cs.SI</category>
      <pubDate>Tue, 28 Jan 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Chu Zhao, Enneng Yang, Yuliang Liang, Pengxiang Lan, Yuting Liu, Jianzhe Zhao, Guibing Guo, Xingwei Wang</dc:creator>
    </item>
    <item>
      <title>Signed Graph Autoencoder for Explainable and Polarization-Aware Network Embeddings</title>
      <link>https://arxiv.org/abs/2409.10452</link>
      <description>arXiv:2409.10452v2 Announce Type: replace-cross 
Abstract: Autoencoders based on Graph Neural Networks (GNNs) have garnered significant attention in recent years for their ability to extract informative latent representations, characterizing the structure of complex topologies, such as graphs. Despite the prevalence of Graph Autoencoders, there has been limited focus on developing and evaluating explainable neural-based graph generative models specifically designed for signed networks. To address this gap, we propose the Signed Graph Archetypal Autoencoder (SGAAE) framework. SGAAE extracts node-level representations that express node memberships over distinct extreme profiles, referred to as archetypes, within the network. This is achieved by projecting the graph onto a learned polytope, which governs its polarization. The framework employs a recently proposed likelihood for analyzing signed networks based on the Skellam distribution, combined with relational archetypal analysis and GNNs. Our experimental evaluation demonstrates the SGAAEs' capability to successfully infer node memberships over the different underlying latent structures while extracting competing communities formed through the participation of the opposing views in the network. Additionally, we introduce the 2-level network polarization problem and show how SGAAE is able to characterize such a setting. The proposed model achieves high performance in different tasks of signed link prediction across four real-world datasets, outperforming several baseline models.</description>
      <guid isPermaLink="false">oai:arXiv.org:2409.10452v2</guid>
      <category>cs.LG</category>
      <category>cs.SI</category>
      <pubDate>Tue, 28 Jan 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Nikolaos Nakis, Chrysoula Kosma, Giannis Nikolentzos, Michalis Chatzianastasis, Iakovos Evdaimon, Michalis Vazirgiannis</dc:creator>
    </item>
    <item>
      <title>Large Language Model-based Augmentation for Imbalanced Node Classification on Text-Attributed Graphs</title>
      <link>https://arxiv.org/abs/2410.16882</link>
      <description>arXiv:2410.16882v2 Announce Type: replace-cross 
Abstract: Node classification on graphs often suffers from class imbalance, leading to biased predictions and significant risks in real-world applications. While data-centric solutions have been explored, they largely overlook Text-Attributed Graphs (TAGs) and the potential of using rich textual semantics to improve the classification of minority nodes. Given this gap, we propose Large Language Model-based Augmentation on Text-Attributed Graphs (LA-TAG), a novel framework that leverages Large Language Models (LLMs) to handle imbalanced node classification. Specifically, we develop prompting strategies inspired by interpolation to synthesize textual node attributes. Additionally, to effectively integrate synthetic nodes into the graph structure, we introduce a textual link predictor that connects the generated nodes to the original graph, preserving structural and contextual information. Experiments across various datasets and evaluation metrics demonstrate that LA-TAG outperforms existing textual augmentation and graph imbalance learning methods, emphasizing the efficacy of our approach in addressing class imbalance in TAGs.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.16882v2</guid>
      <category>cs.AI</category>
      <category>cs.LG</category>
      <category>cs.SI</category>
      <pubDate>Tue, 28 Jan 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Leyao Wang, Yu Wang, Bo Ni, Yuying Zhao, Tyler Derr</dc:creator>
    </item>
    <item>
      <title>Keeping Score: A Quantitative Analysis of How the CHI Community Appreciates Its Milestones</title>
      <link>https://arxiv.org/abs/2501.02456</link>
      <description>arXiv:2501.02456v3 Announce Type: replace-cross 
Abstract: The ACM CHI Conference has a tradition of citing its intellectual heritage. At the same time, we know CHI is highly diverse and evolving. In this highly dynamic context, it is not clear how the CHI community continues to appreciate its milestones (within and outside of CHI). We present an investigation into how the community's citations to milestones have evolved over 43 years of CHI Proceedings (1981-2024). Forgetting curves plotted for each year suggest that milestones are slowly fading from the CHI community's collective memory. However, the picture is more nuanced when we trace citations to the top-cited milestones over time. We identify three distinct types of milestones cited at CHI, a typology of milestone contributions, and define the Milestone Coefficient as a metric to assess the impact of milestone papers on a continuous scale. Further, we provide empirical evidence of a Matthew effect at CHI. We discuss the broader ramifications for the CHI community and the field of HCI.</description>
      <guid isPermaLink="false">oai:arXiv.org:2501.02456v3</guid>
      <category>cs.HC</category>
      <category>cs.SI</category>
      <pubDate>Tue, 28 Jan 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <arxiv:DOI>10.1145/3706598.3713464</arxiv:DOI>
      <dc:creator>Jonas Oppenlaender, Simo Hosio</dc:creator>
    </item>
  </channel>
</rss>
