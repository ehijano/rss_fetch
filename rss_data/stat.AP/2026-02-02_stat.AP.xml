<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>stat.AP updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/stat.AP</link>
    <description>stat.AP updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/stat.AP" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Tue, 03 Feb 2026 04:29:09 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Mon, 02 Feb 2026 00:00:00 -0500</pubDate>
    <skipDays>
      <day>Sunday</day>
      <day>Saturday</day>
    </skipDays>
    <item>
      <title>A Time-Varying Branching Process Approach to Model Self-Renewing Cells</title>
      <link>https://arxiv.org/abs/2601.22282</link>
      <description>arXiv:2601.22282v1 Announce Type: new 
Abstract: Stem cells, through their ability to produce daughter stem cells and differentiate into specialized cells, are essential in the growth, maintenance, and repair of biological tissues. Understanding the dynamics of cell populations in the proliferation process not only uncovers proliferative properties of stem cells, but also offers insight into tissue development under both normal conditions and pathological disruption. In this paper, we develop a continuous time branching process model with time-dependent offspring distribution to characterize stem cell proliferation process. We derive analytical expressions for mean, variance, and autocovariance of the stem cell counts, and develop likelihood-based inference procedures to estimate model parameters. Particularly, we construct a forward algorithm likelihood to handle situations when some cell types cannot be directly observed. Simulation results demonstrate that our estimation method recovers the time-dependent division probabilities with good accuracy.</description>
      <guid isPermaLink="false">oai:arXiv.org:2601.22282v1</guid>
      <category>stat.AP</category>
      <pubDate>Mon, 02 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Huyen Nguyen, Haim Bar, Zhiyi Chi, Vladimir Pozdnyakov</dc:creator>
    </item>
    <item>
      <title>Beyond the Null Effect: Unmasking the True Impact of Teacher-Child Interaction Quality on Child Outcomes in Early Head Start</title>
      <link>https://arxiv.org/abs/2601.23203</link>
      <description>arXiv:2601.23203v1 Announce Type: new 
Abstract: In Early Head Start (EHS), teacher-child interactions are widely believed to shape infant-toddler outcomes, yet large-scale studies often find only modest or null associations. This study addresses four methodological sources of attenuation -- item-level measurement error, center-level confounding, teacher- and classroom-level covariate imbalance, and overlooked nonlinearities -- to clarify classroom process quality's true influence on child development. Using data from the 2018 wave of the Early Head Start Family and Child Experiences Survey (Baby FACES), we applied a three-level generalized additive latent and mixed model (GALAMM) to distinguish genuine classroom-level variability in process quality, as measured by the Classroom Assessment Scoring System (CLASS) and Quality of Caregiver-Child Interactions for Infants and Toddlers (QCIT), from item-level noise and center-level effects. We then estimated dose-response relationships with children's language and socioemotional outcomes, employing covariate balancing weights and generalized additive models. Results show that nearly half of each item's variance reflects classroom-level processes, with the remainder tied to measurement error or center-wide influences, masking true classroom effects. After correcting for these biases, domain-focused dose-response analyses reveal robust linear associations between cognitive/language supports and children's English communicative skills, while emotional-behavioral supports better predict social-emotional competence. Some domains display plateaus when pushed to extremes, underscoring potential nonlinearities. These findings challenge the "null effect" narrative, demonstrating that rigorous methodology can uncover the critical, domain-specific impacts of teacher-child interaction quality, offering clearer guidance for targeted professional development and policy in EHS.</description>
      <guid isPermaLink="false">oai:arXiv.org:2601.23203v1</guid>
      <category>stat.AP</category>
      <pubDate>Mon, 02 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>JoonHo Lee, Alison Hooper</dc:creator>
    </item>
    <item>
      <title>Label-Efficient Monitoring of Classification Models via Stratified Importance Sampling</title>
      <link>https://arxiv.org/abs/2601.22326</link>
      <description>arXiv:2601.22326v1 Announce Type: cross 
Abstract: Monitoring the performance of classification models in production is critical yet challenging due to strict labeling budgets, one-shot batch acquisition of labels and extremely low error rates. We propose a general framework based on Stratified Importance Sampling (SIS) that directly addresses these constraints in model monitoring. While SIS has previously been applied in specialized domains, our theoretical analysis establishes its broad applicability to the monitoring of classification models. Under mild conditions, SIS yields unbiased estimators with strict finite-sample mean squared error (MSE) improvements over both importance sampling (IS) and stratified random sampling (SRS). The framework does not rely on optimally defined proposal distributions or strata: even with noisy proxies and sub-optimal stratification, SIS can improve estimator efficiency compared to IS or SRS individually, though extreme proposal mismatch may limit these gains. Experiments across binary and multiclass tasks demonstrate consistent efficiency improvements under fixed label budgets, underscoring SIS as a principled, label-efficient, and operationally lightweight methodology for post-deployment model monitoring.</description>
      <guid isPermaLink="false">oai:arXiv.org:2601.22326v1</guid>
      <category>cs.LG</category>
      <category>stat.AP</category>
      <pubDate>Mon, 02 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Lupo Marsigli, Angel Lopez de Haro</dc:creator>
    </item>
    <item>
      <title>It's all the (Exponential) Family: An Equivalence between Maximum Likelihood Estimation and Control Variates for Sketching Algorithms</title>
      <link>https://arxiv.org/abs/2601.22378</link>
      <description>arXiv:2601.22378v1 Announce Type: cross 
Abstract: Maximum likelihood estimators (MLE) and control variate estimators (CVE) have been used in conjunction with known information across sketching algorithms and applications in machine learning. We prove that under certain conditions in an exponential family, an optimal CVE will achieve the same asymptotic variance as the MLE, giving an Expectation-Maximization (EM) algorithm for the MLE. Experiments show the EM algorithm is faster and numerically stable compared to other root finding algorithms for the MLE for the bivariate Normal distribution, and we expect this to hold across distributions satisfying these conditions. We show how the EM algorithm leads to reproducibility for algorithms using MLE / CVE, and demonstrate how the EM algorithm leads to finding the MLE when the CV weights are known.</description>
      <guid isPermaLink="false">oai:arXiv.org:2601.22378v1</guid>
      <category>stat.ML</category>
      <category>cs.LG</category>
      <category>stat.AP</category>
      <pubDate>Mon, 02 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Keegan Kang, Kerong Wang, Ding Zhang, Rameshwar Pratap, Bhisham Dev Verma, Benedict H. W. Wong</dc:creator>
    </item>
    <item>
      <title>Changepoint Detection As Model Selection: A General Framework</title>
      <link>https://arxiv.org/abs/2601.22481</link>
      <description>arXiv:2601.22481v1 Announce Type: cross 
Abstract: This dissertation presents a general framework for changepoint detection based on L0 model selection. The core method, Iteratively Reweighted Fused Lasso (IRFL), improves upon the generalized lasso by adaptively reweighting penalties to enhance support recovery and minimize criteria such as the Bayesian Information Criterion (BIC). The approach allows for flexible modeling of seasonal patterns, linear and quadratic trends, and autoregressive dependence in the presence of changepoints.
  Simulation studies demonstrate that IRFL achieves accurate changepoint detection across a wide range of challenging scenarios, including those involving nuisance factors such as trends, seasonal patterns, and serially correlated errors. The framework is further extended to image data, where it enables edge-preserving denoising and segmentation, with applications spanning medical imaging and high-throughput plant phenotyping.
  Applications to real-world data demonstrate IRFL's utility. In particular, analysis of the Mauna Loa CO2 time series reveals changepoints that align with volcanic eruptions and ENSO events, yielding a more accurate trend decomposition than ordinary least squares. Overall, IRFL provides a robust, extensible tool for detecting structural change in complex data.</description>
      <guid isPermaLink="false">oai:arXiv.org:2601.22481v1</guid>
      <category>stat.ME</category>
      <category>stat.AP</category>
      <category>stat.ML</category>
      <pubDate>Mon, 02 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Michael Grantham, Xueheng Shi, Bertrand Clarke</dc:creator>
    </item>
    <item>
      <title>Learning to Defer in Non-Stationary Time Series via Switching State-Space Models</title>
      <link>https://arxiv.org/abs/2601.22538</link>
      <description>arXiv:2601.22538v1 Announce Type: cross 
Abstract: We study Learning to Defer for non-stationary time series with partial feedback and time-varying expert availability. At each time step, the router selects an available expert, observes the target, and sees only the queried expert's prediction. We model signed expert residuals using L2D-SLDS, a factorized switching linear-Gaussian state-space model with context-dependent regime transitions, a shared global factor enabling cross-expert information transfer, and per-expert idiosyncratic states. The model supports expert entry and pruning via a dynamic registry. Using one-step-ahead predictive beliefs, we propose an IDS-inspired routing rule that trades off predicted cost against information gained about the latent regime and shared factor. Experiments show improvements over contextual-bandit baselines and a no-shared-factor ablation.</description>
      <guid isPermaLink="false">oai:arXiv.org:2601.22538v1</guid>
      <category>cs.LG</category>
      <category>stat.AP</category>
      <pubDate>Mon, 02 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Yannis Montreuil, Letian Yu, Axel Carlier, Lai Xing Ng, Wei Tsang Ooi</dc:creator>
    </item>
    <item>
      <title>A unified theory of order flow, market impact, and volatility</title>
      <link>https://arxiv.org/abs/2601.23172</link>
      <description>arXiv:2601.23172v2 Announce Type: cross 
Abstract: We propose a microstructural model for the order flow in financial markets that distinguishes between {\it core orders} and {\it reaction flow}, both modeled as Hawkes processes. This model has a natural scaling limit that reconciles a number of salient empirical properties: persistent signed order flow, rough trading volume and volatility, and power-law market impact. In our framework, all these quantities are pinned down by a single statistic $H_0$, which measures the persistence of the core flow. Specifically, the signed flow converges to the sum of a fractional process with Hurst index $H_0$ and a martingale, while the limiting traded volume is a rough process with Hurst index $H_0-1/2$. No-arbitrage constraints imply that volatility is rough, with Hurst parameter $2H_0-3/2$, and that the price impact of trades follows a power law with exponent $2-2H_0$. The analysis of signed order flow data yields an estimate $H_0 \approx 3/4$. This is not only consistent with the square-root law of market impact, but also turns out to match estimates for the roughness of traded volumes and volatilities remarkably well.</description>
      <guid isPermaLink="false">oai:arXiv.org:2601.23172v2</guid>
      <category>q-fin.ST</category>
      <category>math.PR</category>
      <category>q-fin.MF</category>
      <category>q-fin.TR</category>
      <category>stat.AP</category>
      <pubDate>Mon, 02 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Johannes Muhle-Karbe, Youssef Ouazzani Chahdi, Mathieu Rosenbaum, Gr\'egoire Szymanski</dc:creator>
    </item>
    <item>
      <title>Leaf clustering using circular densities</title>
      <link>https://arxiv.org/abs/2211.10547</link>
      <description>arXiv:2211.10547v2 Announce Type: replace 
Abstract: In the biology field of botany, leaf shape recognition is an important task. One way of characterising the leaf shape is through the centroid contour distances (CCD). Each CCD path might have different resolution, so normalisation is done by associating each contour to a circular density. Densities are rotated by subtracting the mean or mode preferred direction. Distance measures between densities are used to produce a hierarchical clustering method to cluster the leaves. We illustrate our approach with a motivating small dataset as well as a larger dataset.</description>
      <guid isPermaLink="false">oai:arXiv.org:2211.10547v2</guid>
      <category>stat.AP</category>
      <pubDate>Mon, 02 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Luis E. Nieto-Barajas</dc:creator>
    </item>
    <item>
      <title>Quantifying sleep apnea heterogeneity using hierarchical Bayesian modeling</title>
      <link>https://arxiv.org/abs/2503.11599</link>
      <description>arXiv:2503.11599v5 Announce Type: replace 
Abstract: Obstructive Sleep Apnea (OSA) is a breathing disorder during sleep that affects millions of people worldwide. The diagnosis of OSA often occurs through an overnight polysomnogram (PSG) sleep study that generates a massive amount of physiological data. However, despite the evidence of substantial heterogeneity in the expression and symptoms of OSA, diagnosis and scientific analysis of severity typically focus on a single summary statistic, the Apnea-Hypopnea Index (AHI). We address the limitations of this approach through hierarchical Bayesian modeling of PSG data. Our approach produces interpretable random effects for each patient, which govern sleep-stage dynamics, rates of OSA events, and impacts of OSA events on subsequent sleep-stage dynamics. We propose a novel approach for using these random effects to produce a Bayes optimal clustering of patients. We use the proposed approach to analyze data from the APPLES study. Our analysis produces clinically interesting groups of patients with sleep apnea and a novel finding of an association between OSA expression and cognitive performance that is missed by an AHI-based analysis.</description>
      <guid isPermaLink="false">oai:arXiv.org:2503.11599v5</guid>
      <category>stat.AP</category>
      <pubDate>Mon, 02 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Glenn Palmer, Narat Srivali, David B. Dunson</dc:creator>
    </item>
    <item>
      <title>CLE-SH: Comprehensive Literal Explanation package for SHapley values by statistical validity</title>
      <link>https://arxiv.org/abs/2409.12578</link>
      <description>arXiv:2409.12578v2 Announce Type: replace-cross 
Abstract: Recently, SHapley Additive exPlanations (SHAP) has been widely utilized in various research domains. This is particularly evident in application fields, where SHAP analysis serves as a crucial tool for identifying biomarkers and assisting in result validation. However, despite its frequent usage, SHAP is often not applied in a manner that maximizes its potential contributions. A review of recent papers employing SHAP reveals that many studies subjectively select a limited number of features as 'important' and analyze SHAP values by approximately observing plots without assessing statistical significance. Such superficial application may hinder meaningful contributions to the applied fields. To address this, we propose a library package designed to simplify the interpretation of SHAP values. By simply inputting the original data and SHAP values, our library provides: 1) the number of important features to analyze, 2) the pattern of each feature via univariate analysis, and 3) the interaction between features. All information is extracted based on its statistical significance and presented in simple, comprehensible sentences, enabling users of all levels to understand the interpretations. We hope this library fosters a comprehensive understanding of statistically valid SHAP results.</description>
      <guid isPermaLink="false">oai:arXiv.org:2409.12578v2</guid>
      <category>stat.CO</category>
      <category>stat.AP</category>
      <pubDate>Mon, 02 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <arxiv:DOI>10.1109/ACCESS.2026.3654890</arxiv:DOI>
      <arxiv:journal_reference>IEEE Access, vol. 14, pp. 12514-12525, 2026</arxiv:journal_reference>
      <dc:creator>Kyungjin Kim, Youngro Lee, Jongmo Seo</dc:creator>
    </item>
    <item>
      <title>Bayesian Kernel Machine Regression via Random Fourier Features for Estimating Joint Health Effects of Multiple Exposures</title>
      <link>https://arxiv.org/abs/2502.13157</link>
      <description>arXiv:2502.13157v2 Announce Type: replace-cross 
Abstract: Environmental epidemiology has traditionally examined single exposure one at a time. Advances in exposure assessment and statistical methods now enable studies of multiple exposures and their combined health impacts. Bayesian Kernel Machine Regression (BKMR) is a widely used approach to flexibly estimates joint, nonlinear effects of multiple exposures. But BMKR is computationally intensive for large datasets, as repeated kernel inversion in Markov chain Monte Carlo (MCMC) can be time-consuming and often infeasible in practice. To address this issue, we propose using supervised random Fourier basis functions to replace the Gaussian process random effects. This re-frames the kernel machine regression into a linear mixed-effect model that facilitates computationally efficient estimation and prediction. Bayesian inference is conducted using MCMC with Hamiltonian Monte Carlo algorithms. Simulation studies demonstrate that our method yields results comparable to BKMR while significantly reduces the computation time. Our approach outperforms BKMR when the exposure-response surface has stronger dependency and when using predictive process as an alternative approximation method. Finally, we applied this approach to analyze over 270,000 birth records, examining associations between multiple ambient air pollutants and birthweight in Georgia.</description>
      <guid isPermaLink="false">oai:arXiv.org:2502.13157v2</guid>
      <category>stat.ME</category>
      <category>stat.AP</category>
      <pubDate>Mon, 02 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Danlu Zhang, Stephanie M. Eick, Howard H. Chang</dc:creator>
    </item>
    <item>
      <title>A Zero-Inflated Poisson Latent Position Cluster Model</title>
      <link>https://arxiv.org/abs/2502.13790</link>
      <description>arXiv:2502.13790v2 Announce Type: replace-cross 
Abstract: The latent position network model (LPM) is a popular approach for the statistical analysis of network data. A central aspect of this model is that it assigns nodes to random positions in a latent space, such that the probability of an interaction between each pair of individuals or nodes is determined by their distance in this latent space. A key feature of this model is that it allows one to visualize nuanced structures via the latent space representation. The LPM can be further extended to the Latent Position Cluster Model (LPCM), to accommodate the clustering of nodes by assuming that the latent positions are distributed following a finite mixture distribution. In this paper, we extend the LPCM to accommodate missing network data and apply this to non-negative discrete weighted social networks. By treating missing data as ``unusual'' zero interactions, we propose a combination of the LPCM with the zero-inflated Poisson distribution. Statistical inference is based on a novel partially collapsed Markov chain Monte Carlo algorithm, where a Mixture-of-Finite-Mixtures (MFM) model is adopted to automatically determine the number of clusters and optimal group partitioning. Our algorithm features a truncated absorb-eject move, which is a novel adaptation of an idea commonly used in collapsed samplers, within the context of MFMs. Another aspect of our work is that we illustrate our results on 3-dimensional latent spaces, maintaining clear visualizations while achieving more flexibility than 2-dimensional models. The performance of this approach is illustrated via three carefully designed simulation studies, as well as four different publicly available real networks, where some interesting new perspectives are uncovered.</description>
      <guid isPermaLink="false">oai:arXiv.org:2502.13790v2</guid>
      <category>stat.ME</category>
      <category>stat.AP</category>
      <category>stat.CO</category>
      <pubDate>Mon, 02 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <arxiv:DOI>10.1017/nws.2025.10021</arxiv:DOI>
      <arxiv:journal_reference>Net Sci 14 (2026) e2</arxiv:journal_reference>
      <dc:creator>Chaoyi Lu, Riccardo Rastelli, Nial Friel</dc:creator>
    </item>
    <item>
      <title>Two-Phase Treatment with Noncompliance: Identifying the Cumulative Average Treatment Effect via Multisite Instrumental Variables</title>
      <link>https://arxiv.org/abs/2506.03104</link>
      <description>arXiv:2506.03104v3 Announce Type: replace-cross 
Abstract: When evaluating a two-phase intervention, the cumulative average treatment effect (ATE) is often the primary causal estimand of interest. However, some individuals who do not respond well to the Phase I treatment may subsequently display noncompliant behaviors. At the same time, exposure to the Phase I treatment is expected to directly influence an individual's potential outcomes, thereby violating the exclusion restriction. Building on an instrumental variable (IV) strategy for multisite trials, we clarify the conditions under which the cumulative ATE of a two-phase treatment can be identified by employing the random assignment of the Phase I treatment as the instrument. Our strategy relaxes both the conventional exclusion restriction and sequential ignorability assumptions. We assess the performance of the new strategy through simulation studies. Additionally, we reanalyze data from the Tennessee class size study, in which students and teachers were randomly assigned to either small or regular class types in kindergarten (Phase I) with noncompliance emerging in Grade 1 (Phase II). Applying our new strategy, we estimate the cumulative ATE of receiving two consecutive years of instruction in a small versus regular class.</description>
      <guid isPermaLink="false">oai:arXiv.org:2506.03104v3</guid>
      <category>stat.ME</category>
      <category>stat.AP</category>
      <pubDate>Mon, 02 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Guanglei Hong, Xu Qin, Zhengyan Xu, Fan Yang</dc:creator>
    </item>
    <item>
      <title>Defects and Inconsistencies in Solar Flare Data Sources: Implications for Machine Learning Forecasting</title>
      <link>https://arxiv.org/abs/2512.13417</link>
      <description>arXiv:2512.13417v2 Announce Type: replace-cross 
Abstract: Machine learning models for forecasting solar flares have been trained and evaluated using a variety of data sources, including Space Weather Prediction Center (SWPC) operational and science-quality data. Typically, data from these sources is minimally processed before being used to train and validate a forecasting model. However, predictive performance can be affected if defects and inconsistencies between these data sources are ignored. For a set of commonly used data sources, along with the software that queries and outputs processed data, we identify their defects and inconsistencies, quantify their extent, and show how they can affect predictions from data-driven machine-learning forecasting models. We also outline procedures for fixing these issues or at least mitigating their impacts. Finally, based on thorough comparisons of the effects of data sources on the trained forecasting model's predictive skill scores, we offer recommendations for using different data products in operational forecasting.</description>
      <guid isPermaLink="false">oai:arXiv.org:2512.13417v2</guid>
      <category>astro-ph.SR</category>
      <category>stat.AP</category>
      <pubDate>Mon, 02 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Ke Hu, Kevin Jin, Victor Verma, Weihao Liu, Ward Manchester IV, Lulu Zhao, Tamas Gombosi, Yang Chen</dc:creator>
    </item>
    <item>
      <title>Standardized Descriptive Index for Measuring Deviation and Uncertainty in Psychometric Indicators</title>
      <link>https://arxiv.org/abs/2512.21399</link>
      <description>arXiv:2512.21399v2 Announce Type: replace-cross 
Abstract: The use of descriptive statistics in pilot testing procedures requires objective, standard diagnostic tools that are feasible for small sample sizes. While current psychometric practices report item-level statistics, they often report these raw descriptives separately rather than consolidating both mean and standard deviation into a single diagnostic tool to directly measure item quality. By leveraging the analytical properties of Cohen's d, this article repurposes its use in scale development as a standardized item deviation index. This measures the extent of an item's raw deviation relative to its scale midpoint while accounting for its own uncertainty. Analytical properties such as boundedness, scale invariance, and bias are explored to further understand how the index values behave, which will aid future efforts to establish empirical thresholds that characterize redundancy among formative indicators and consistency among reflective indicators.</description>
      <guid isPermaLink="false">oai:arXiv.org:2512.21399v2</guid>
      <category>stat.ME</category>
      <category>stat.AP</category>
      <pubDate>Mon, 02 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Mark Dominique Dalipe Mu\~noz</dc:creator>
    </item>
  </channel>
</rss>
