<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>cs.FL updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/cs.FL</link>
    <description>cs.FL updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/cs.FL" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Wed, 24 Sep 2025 04:01:01 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Wed, 24 Sep 2025 00:00:00 -0400</pubDate>
    <skipDays>
      <day>Saturday</day>
      <day>Sunday</day>
    </skipDays>
    <item>
      <title>A Layered Implementation Framework for Regular Languages</title>
      <link>https://arxiv.org/abs/2509.18232</link>
      <description>arXiv:2509.18232v1 Announce Type: new 
Abstract: I present the most fundamental features of an implemented system designed to manipulate representations of regular languages. The system is structured into two layers, allowing regular languages to be represented in an increasingly compact, efficient, and integrated way. Both layers are first presented at a high level, adequate to design and prove the correctness of abstract algorithms. Then, their low-level implementations are described meticulously.
  At the high level, the first layer offers a notion of normalized regular expressions ensuring that the set of all syntactic derivatives of an expression is finite. At the low level, normalized expressions are uniquely represented by identifiers, i.e. by standard integers.
  The second layer, called the background, introduces additional notions to record, integrate, and simplify things computed within the first layer. At the high level, normalized expressions denoting the same regular language can be unified by grouping them into equivalence classes. One shortest expression is chosen in each class as its representative, which can be used to form equations relating expressions to their derivatives.
  This paper also presents extensive experimental results to demonstrate the usefulness of the proposed framework and, in particular, the fact that it makes it possible to represent large sets of regular languages in a unified way where distinct identifiers designate different languages, represented by both a small expression and a minimal deteministic automaton.</description>
      <guid isPermaLink="false">oai:arXiv.org:2509.18232v1</guid>
      <category>cs.FL</category>
      <pubDate>Wed, 24 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Baudouin Le Charlier</dc:creator>
    </item>
    <item>
      <title>AD-VF: LLM-Automatic Differentiation Enables Fine-Tuning-Free Robot Planning from Formal Methods Feedback</title>
      <link>https://arxiv.org/abs/2509.18384</link>
      <description>arXiv:2509.18384v1 Announce Type: cross 
Abstract: Large language models (LLMs) can translate natural language instructions into executable action plans for robotics, autonomous driving, and other domains. Yet, deploying LLM-driven planning in the physical world demands strict adherence to safety and regulatory constraints, which current models often violate due to hallucination or weak alignment. Traditional data-driven alignment methods, such as Direct Preference Optimization (DPO), require costly human labeling, while recent formal-feedback approaches still depend on resource-intensive fine-tuning. In this paper, we propose LAD-VF, a fine-tuning-free framework that leverages formal verification feedback for automated prompt engineering. By introducing a formal-verification-informed text loss integrated with LLM-AutoDiff, LAD-VF iteratively refines prompts rather than model parameters. This yields three key benefits: (i) scalable adaptation without fine-tuning; (ii) compatibility with modular LLM architectures; and (iii) interpretable refinement via auditable prompts. Experiments in robot navigation and manipulation tasks demonstrate that LAD-VF substantially enhances specification compliance, improving success rates from 60% to over 90%. Our method thus presents a scalable and interpretable pathway toward trustworthy, formally-verified LLM-driven control systems.</description>
      <guid isPermaLink="false">oai:arXiv.org:2509.18384v1</guid>
      <category>cs.RO</category>
      <category>cs.FL</category>
      <pubDate>Wed, 24 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Yunhao Yang, Junyuan Hong, Gabriel Jacob Perin, Zhiwen Fan, Li Yin, Zhangyang Wang, Ufuk Topcu</dc:creator>
    </item>
    <item>
      <title>Petri Nets-based Methods on Automatically Detecting for Concurrency Bugs in Rust Programs</title>
      <link>https://arxiv.org/abs/2212.02754</link>
      <description>arXiv:2212.02754v3 Announce Type: replace-cross 
Abstract: Rust's memory safety guarantees, notably ownership and lifetime systems, have driven its widespread adoption. Concurrency bugs still occur in Rust programs, and existing detection approaches exhibit significant limitations: static analyzers suffer from context insensitivity and high false positives, while dynamic methods incur prohibitive runtime costs due to exponential path exploration. This paper presents a Petri net-based method for efficient, precise detection of Rust concurrency bugs. The method rests on three pillars: (1) A syntax-preserving program-to-Petri-net transformation tailored for target bug classes; (2) Semantics-preserving state compression via context-aware slicing; (3) Bug detection through efficient Petri net reachability analysis.
  The core innovation is its rigorous, control-flow-driven modeling of Rust's ownership semantics and synchronization primitives within the Petri net structure, with data operations represented as token movements. Integrated pointer analysis automates alias identification during transformation. Experiments on standard Rust concurrency benchmarks demonstrate that our method outperforms the state-of-the-art methods LockBud and Miri that are both tools of detecting concurrency bugs of Rust programs. Compared to LockBud, our approach reduces false positives by 35.7\% and false negatives by 28.3\% , which is obtained through our precise flow-sensitive pointer analysis. Compared with Miri that is a dynamic analysis tool, although Miri can obtain the same detection results, our method achieves 100% faster verification speed since our method takes a state reduce algorithm.</description>
      <guid isPermaLink="false">oai:arXiv.org:2212.02754v3</guid>
      <category>cs.PL</category>
      <category>cs.FL</category>
      <category>cs.SE</category>
      <pubDate>Wed, 24 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Kaiwen Zhang, Guanjun Liu</dc:creator>
    </item>
  </channel>
</rss>
