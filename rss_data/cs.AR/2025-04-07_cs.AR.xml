<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>cs.AR updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/cs.AR</link>
    <description>cs.AR updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/cs.AR" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Tue, 08 Apr 2025 03:06:54 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Mon, 07 Apr 2025 00:00:00 -0400</pubDate>
    <skipDays>
      <day>Saturday</day>
      <day>Sunday</day>
    </skipDays>
    <item>
      <title>Unlocking the AMD Neural Processing Unit for ML Training on the Client Using Bare-Metal-Programming Tools</title>
      <link>https://arxiv.org/abs/2504.03083</link>
      <description>arXiv:2504.03083v1 Announce Type: new 
Abstract: There has been a growing interest in executing machine learning (ML) workloads on the client side for reasons of customizability, privacy, performance, and availability. In response, hardware manufacturers have begun to incorporate so-called Neural Processing Units (NPUs) into their processors for consumer devices. Such dedicated hardware optimizes both power efficiency and throughput for common machine learning tasks. AMD's NPU, part of their Ryzen AI processors, is one of the first such accelerators integrated into a chip with an x86 processor. AMD supports bare-metal programming of their NPU rather than limiting programmers to pre-configured libraries.
  In this paper, we explore the potential of using a bare-metal toolchain to accelerate the weight fine-tuning of a large language model, GPT-2, entirely on the client side using the AMD NPU. Fine-tuning on the edge allows for private customization of a model to a specific use case. To the best of our knowledge, this is the first time such an accelerator has been used to perform training on the client side. We offload time-intensive matrix multiplication operations from the CPU onto the NPU, achieving a speedup of over 2.8x for these operations. This improves end-to-end performance of the model in terms of throughput (1.7x and 1.2x speedup in FLOPS/s on mains and battery power, respectively) and energy efficiency (1.4x improvement in FLOPS/Ws on battery power). We detail our implementation approach and present an in-depth exploration of the NPU hardware and bare-metal tool-flow.</description>
      <guid isPermaLink="false">oai:arXiv.org:2504.03083v1</guid>
      <category>cs.AR</category>
      <pubDate>Mon, 07 Apr 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <dc:creator>Andr\'e R\"osti (University of California, Irvine), Michael Franz (University of California, Irvine)</dc:creator>
    </item>
    <item>
      <title>NDFT: Accelerating Density Functional Theory Calculations via Hardware/Software Co-Design on Near-Data Computing System</title>
      <link>https://arxiv.org/abs/2504.03451</link>
      <description>arXiv:2504.03451v1 Announce Type: new 
Abstract: Linear-response time-dependent Density Functional Theory (LR-TDDFT) is a widely used method for accurately predicting the excited-state properties of physical systems. Previous works have attempted to accelerate LR-TDDFT using heterogeneous systems such as GPUs, FPGAs, and the Sunway architecture. However, a major drawback of these approaches is the constant data movement between host memory and the memory of the heterogeneous systems, which results in substantial \textit{data movement overhead}. Moreover, these works focus primarily on optimizing the compute-intensive portions of LR-TDDFT, despite the fact that the calculation steps are fundamentally \textit{memory-bound}.
  To address these challenges, we propose NDFT, a \underline{N}ear-\underline{D}ata Density \underline{F}unctional \underline{T}heory framework. Specifically, we design a novel task partitioning and scheduling mechanism to offload each part of LR-TDDFT to the most suitable computing units within a CPU-NDP system. Additionally, we implement a hardware/software co-optimization of a critical kernel in LR-TDDFT to further enhance performance on the CPU-NDP system. Our results show that NDFT achieves performance improvements of 5.2x and 2.5x over CPU and GPU baselines, respectively, on a large physical system.</description>
      <guid isPermaLink="false">oai:arXiv.org:2504.03451v1</guid>
      <category>cs.AR</category>
      <category>physics.comp-ph</category>
      <pubDate>Mon, 07 Apr 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-sa/4.0/</dc:rights>
      <dc:creator>Qingcai Jiang, Buxin Tu, Xiaoyu Hao, Junshi Chen, Hong An</dc:creator>
    </item>
    <item>
      <title>Linear Decomposition of the Majority Boolean Function using the Ones on Smaller Variables</title>
      <link>https://arxiv.org/abs/2504.03262</link>
      <description>arXiv:2504.03262v1 Announce Type: cross 
Abstract: A long-investigated problem in circuit complexity theory is to decompose an $n$-input or $n$-variable Majority Boolean function (call it $M_n$) using $k$-input ones ($M_k$), $k &lt; n$, where the objective is to achieve the decomposition using fewest $M_k$'s. An $\mathcal{O}(n)$ decomposition for $M_n$ has been proposed recently with $k=3$. However, for an arbitrary value of $k$, no such construction exists even though there are several works reporting continual improvement of lower bounds, finally achieving an optimal lower bound $\Omega(\frac{n}{k}\log k)$ as provided by Lecomte et. al., in CCC '22. In this direction, here we propose two decomposition procedures for $M_n$, utilizing counter trees and restricted partition functions, respectively. The construction technique based on counter tree requires $\mathcal{O}(n)$ such many $M_k$ functions, hence presenting a construction closest to the optimal lower bound, reported so far. The decomposition technique using restricted partition functions present a novel link between Majority Boolean function construction and elementary number theory. These decomposition techniques close a gap in circuit complexity studies and are also useful for leveraging emerging computing technologies.</description>
      <guid isPermaLink="false">oai:arXiv.org:2504.03262v1</guid>
      <category>cs.LO</category>
      <category>cs.AR</category>
      <category>cs.ET</category>
      <pubDate>Mon, 07 Apr 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Anupam Chattopadhyay, Debjyoti Bhattacharjee, Subhamoy Maitra</dc:creator>
    </item>
    <item>
      <title>PHOENIX: Pauli-Based High-Level Optimization Engine for Instruction Execution on NISQ Devices</title>
      <link>https://arxiv.org/abs/2504.03529</link>
      <description>arXiv:2504.03529v1 Announce Type: cross 
Abstract: Variational quantum algorithms (VQA) based on Hamiltonian simulation represent a specialized class of quantum programs well-suited for near-term quantum computing applications due to its modest resource requirements in terms of qubits and circuit depth. Unlike the conventional single-qubit (1Q) and two-qubit (2Q) gate sequence representation, Hamiltonian simulation programs are essentially composed of disciplined subroutines known as Pauli exponentiations (Pauli strings with coefficients) that are variably arranged. To capitalize on these distinct program features, this study introduces PHOENIX, a highly effective compilation framework that primarily operates at the high-level Pauli-based intermediate representation (IR) for generic Hamiltonian simulation programs. PHOENIX exploits global program optimization opportunities to the greatest extent, compared to existing SOTA methods despite some of them also utilizing similar IRs. PHOENIX employs the binary symplectic form (BSF) to formally describe Pauli strings and reformulates IR synthesis as reducing the column weights of BSF by appropriate Clifford transformations. It comes with a heuristic BSF simplification algorithm that searches for the most appropriate 2Q Clifford operators in sequence to maximally simplify the BSF at each step, until the BSF can be directly synthesized by basic 1Q and 2Q gates. PHOENIX further performs a global ordering strategy in a Tetris-like fashion for these simplified IR groups, carefully balancing optimization opportunities for gate cancellation, minimizing circuit depth, and managing qubit routing overhead. Experimental results demonstrate that PHOENIX outperforms SOTA VQA compilers across diverse program categories, backend ISAs, and hardware topologies.</description>
      <guid isPermaLink="false">oai:arXiv.org:2504.03529v1</guid>
      <category>quant-ph</category>
      <category>cs.AR</category>
      <category>cs.PL</category>
      <pubDate>Mon, 07 Apr 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Zhaohui Yang, Dawei Ding, Chenghong Zhu, Jianxin Chen, Yuan Xie</dc:creator>
    </item>
    <item>
      <title>Performance Analysis of HPC applications on the Aurora Supercomputer: Exploring the Impact of HBM-Enabled Intel Xeon Max CPUs</title>
      <link>https://arxiv.org/abs/2504.03632</link>
      <description>arXiv:2504.03632v1 Announce Type: cross 
Abstract: The Aurora supercomputer is an exascale-class system designed to tackle some of the most demanding computational workloads. Equipped with both High Bandwidth Memory (HBM) and DDR memory, it provides unique trade-offs in performance, latency, and capacity. This paper presents a comprehensive analysis of the memory systems on the Aurora supercomputer, with a focus on evaluating the trade-offs between HBM and DDR memory systems. We explore how different memory configurations, including memory modes (Flat and Cache) and clustering modes (Quad and SNC4), influence key system performance metrics such as memory bandwidth, latency, CPU-GPU PCIe bandwidth, and MPI communication bandwidth. Additionally, we examine the performance of three representative HPC applications -- HACC, QMCPACK, and BFS -- each illustrating the impact of memory configurations on performance. By using microbenchmarks and application-level analysis, we provide insights into how to select the optimal memory system and configuration to maximize performance based on the application characteristics. The findings presented in this paper offer guidance for users of the Aurora system and similar exascale systems.</description>
      <guid isPermaLink="false">oai:arXiv.org:2504.03632v1</guid>
      <category>cs.DC</category>
      <category>cs.AR</category>
      <category>cs.PF</category>
      <pubDate>Mon, 07 Apr 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Huda Ibeid, Vikram Narayana, Jeongnim Kim, Anthony Nguyen, Vitali Morozov, Ye Luo</dc:creator>
    </item>
    <item>
      <title>Late Breaking Results: Breaking Symmetry- Unconventional Placement of Analog Circuits using Multi-Level Multi-Agent Reinforcement Learning</title>
      <link>https://arxiv.org/abs/2503.22958</link>
      <description>arXiv:2503.22958v2 Announce Type: replace 
Abstract: Layout-dependent effects (LDEs) significantly impact analog circuit performance. Traditionally, designers have relied on symmetric placement of circuit components to mitigate variations caused by LDEs. However, due to non-linear nature of these effects, conventional methods often fall short. We propose an objective-driven, multi-level, multi-agent Q-learning framework to explore unconventional design space of analog layout, opening new avenues for optimizing analog circuit performance. Our approach achieves better variation performance than the state-of-the-art layout techniques. Notably, this is the first application of multi-agent RL in analog layout automation. The proposed approach is compared with non-ML approach based on simulated annealing.</description>
      <guid isPermaLink="false">oai:arXiv.org:2503.22958v2</guid>
      <category>cs.AR</category>
      <category>cs.AI</category>
      <pubDate>Mon, 07 Apr 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Supriyo Maji, Linran Zhao, Souradip Poddar, David Z. Pan</dc:creator>
    </item>
    <item>
      <title>ARCANE: Adaptive RISC-V Cache Architecture for Near-memory Extensions</title>
      <link>https://arxiv.org/abs/2504.02533</link>
      <description>arXiv:2504.02533v2 Announce Type: replace 
Abstract: Modern data-driven applications expose limitations of von Neumann architectures - extensive data movement, low throughput, and poor energy efficiency. Accelerators improve performance but lack flexibility and require data transfers. Existing compute in- and near-memory solutions mitigate these issues but face usability challenges due to data placement constraints. We propose a novel cache architecture that doubles as a tightly-coupled compute-near-memory coprocessor. Our RISC-V cache controller executes custom instructions from the host CPU using vector operations dispatched to near-memory vector processing units within the cache memory subsystem. This architecture abstracts memory synchronization and data mapping from application software while offering software-based ISA extensibility. Our implementation shows $30\times$ to $84\times$ performance improvement when operating on 8-bit data over the same system with a traditional cache when executing a worst-case 32-bit CNN workload, with only $41.3\%$ area overhead.</description>
      <guid isPermaLink="false">oai:arXiv.org:2504.02533v2</guid>
      <category>cs.AR</category>
      <pubDate>Mon, 07 Apr 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-sa/4.0/</dc:rights>
      <dc:creator>Vincenzo Petrolo, Flavia Guella, Michele Caon, Pasquale Davide Schiavone, Guido Masera, Maurizio Martina</dc:creator>
    </item>
    <item>
      <title>When Radiation Meets Linux: Analyzing Soft Errors in Linux on COTS SoCs under Proton Irradiation</title>
      <link>https://arxiv.org/abs/2503.03722</link>
      <description>arXiv:2503.03722v3 Announce Type: replace-cross 
Abstract: The increasing use of Linux on commercial off-the-shelf (COTS) system-on-chip (SoC) in spaceborne computing inherits COTS susceptibility to radiation-induced failures like soft errors. Modern SoCs exacerbate this issue as aggressive transistor scaling reduces critical charge thresholds to induce soft errors and increases radiation effects within densely packed transistors, degrading overall reliability. Linux's monolithic architecture amplifies these risks, as tightly coupled kernel subsystems propagate errors to critical components (e.g., memory management), while limited error-correcting code (ECC) offers minimal mitigation. Furthermore, the lack of public soft error data from irradiation tests on COTS SoCs running Linux hinders reliability improvements. This study evaluates proton irradiation effects (20-50 MeV) on Linux across three COTS SoC architectures: Raspberry Pi Zero 2 W (40 nm CMOS, Cortex-A53), NXP i MX 8M Plus (14 nm FinFET, Cortex-A53), and OrangeCrab (40 nm FPGA, RISC-V). Irradiation results show the 14 nm FinFET NXP SoC achieved 2-3x longer Linux uptime without ECC memory versus both 40 nm CMOS counterparts, partially due to FinFET's reduced charge collection. Additionally, this work presents the first cross-architecture analysis of soft error-prone Linux kernel components in modern SoCs to develop targeted mitigations. The findings establish foundational data on Linux's soft error sensitivity in COTS SoCs, guiding mission readiness for space applications.</description>
      <guid isPermaLink="false">oai:arXiv.org:2503.03722v3</guid>
      <category>cs.OS</category>
      <category>cs.AR</category>
      <pubDate>Mon, 07 Apr 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-sa/4.0/</dc:rights>
      <dc:creator>Saad Memon, Rafal Graczyk, Tomasz Rajkowski, Jan Swakon, Damian Wrobel, Sebastian Kusyk, Seth Roffe, Mike Papadakis</dc:creator>
    </item>
  </channel>
</rss>
