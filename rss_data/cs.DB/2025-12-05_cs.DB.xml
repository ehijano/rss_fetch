<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>cs.DB updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/cs.DB</link>
    <description>cs.DB updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/cs.DB" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Fri, 05 Dec 2025 05:00:17 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Fri, 05 Dec 2025 00:00:00 -0500</pubDate>
    <skipDays>
      <day>Saturday</day>
      <day>Sunday</day>
    </skipDays>
    <item>
      <title>Energy Profiling of Data-Sharing Pipelines: Modeling, Estimation, and Reuse Strategies</title>
      <link>https://arxiv.org/abs/2512.04086</link>
      <description>arXiv:2512.04086v1 Announce Type: new 
Abstract: Data-sharing pipelines involve a series of stages that apply policy-based data transformations to enable secure and effective data exchange among organizations. Although numerous tools and platforms exist to manage governance and enforcement in these pipelines, energy efficiency in data exchange has received limited attention. This paper introduces a novel method to model and estimate the energy consumption of different execution configurations in data-sharing pipelines. Additionally, this method identifies reuse potential in shared stages across pipelines that hold the key to reducing energy in large data-sharing federations. We validate this method through simulation experiments, revealing promising potential for cross-organizational pipeline optimization and laying a foundation for energy-conscious execution strategies.</description>
      <guid isPermaLink="false">oai:arXiv.org:2512.04086v1</guid>
      <category>cs.DB</category>
      <category>cs.DC</category>
      <pubDate>Fri, 05 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Sepideh Masoudi, Sebastian Werner, Pierluigi Plebani, Stefan Tai</dc:creator>
    </item>
    <item>
      <title>A Fast Ethereum-Compatible Forkless Database</title>
      <link>https://arxiv.org/abs/2512.04735</link>
      <description>arXiv:2512.04735v1 Announce Type: new 
Abstract: The State Database of a blockchain stores account data and enables authentication. Modern blockchains use fast consensus protocols to avoid forking, improving throughput and finality. However, Ethereum's StateDB was designed for a forking chain that maintains multiple state versions. While newer blockchains adopt Ethereum's standard for DApp compatibility, they do not require multiple state versions, making legacy Ethereum databases inefficient for fast, non-forking blockchains. Moreover, existing StateDB implementations have been built on key-value stores (e.g., LevelDB), which make them less efficient.
  This paper introduces a novel state database that is a native database implementation and maintains Ethereum compatibility while being specialized for non-forking blockchains. Our database delivers ten times speedups and 99% space reductions for validators, and a threefold decrease in storage requirements for archive nodes.</description>
      <guid isPermaLink="false">oai:arXiv.org:2512.04735v1</guid>
      <category>cs.DB</category>
      <pubDate>Fri, 05 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Herbert Jordan, Kamil Jezek, Pavle Subotic, Bernhard Scholz</dc:creator>
    </item>
    <item>
      <title>High-Performance DBMSs with io_uring: When and How to use it</title>
      <link>https://arxiv.org/abs/2512.04859</link>
      <description>arXiv:2512.04859v1 Announce Type: new 
Abstract: We study how modern database systems can leverage the Linux io_uring interface for efficient, low-overhead I/O. io_uring is an asynchronous system call batching interface that unifies storage and network operations, addressing limitations of existing Linux I/O interfaces. However, naively replacing traditional I/O interfaces with io_uring does not necessarily yield performance benefits. To demonstrate when io_uring delivers the greatest benefits and how to use it effectively in modern database systems, we evaluate it in two use cases: Integrating io_uring into a storage-bound buffer manager and using it for high-throughput data shuffling in network-bound analytical workloads. We further analyze how advanced io_uring features, such as registered buffers and passthrough I/O, affect end-to-end performance. Our study shows when low-level optimizations translate into tangible system-wide gains and how architectural choices influence these benefits. Building on these insights, we derive practical guidelines for designing I/O-intensive systems using io_uring and validate their effectiveness in a case study of PostgreSQL's recent io_uring integration, where applying our guidelines yields a performance improvement of 14%.</description>
      <guid isPermaLink="false">oai:arXiv.org:2512.04859v1</guid>
      <category>cs.DB</category>
      <pubDate>Fri, 05 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Matthias Jasny, Muhammad El-Hindi, Tobias Ziegler, Viktor Leis, Carsten Binnig</dc:creator>
    </item>
    <item>
      <title>Towards Contextual Sensitive Data Detection</title>
      <link>https://arxiv.org/abs/2512.04120</link>
      <description>arXiv:2512.04120v1 Announce Type: cross 
Abstract: The emergence of open data portals necessitates more attention to protecting sensitive data before datasets get published and exchanged. While an abundance of methods for suppressing sensitive data exist, the conceptualization of sensitive data and methods to detect it, focus particularly on personal data that, if disclosed, may be harmful or violate privacy. We observe the need for refining and broadening our definitions of sensitive data, and argue that the sensitivity of data depends on its context. Based on this definition, we introduce two mechanisms for contextual sensitive data detection that con- sider the broader context of a dataset at hand. First, we introduce type contextualization, which first detects the semantic type of particular data values, then considers the overall context of the data values within the dataset or document. Second, we introduce domain contextualization which determines sensitivity of a given dataset in the broader context based on the retrieval of relevant rules from documents that specify data sensitivity (e.g., data topic and geographic origin). Experiments with these mechanisms, assisted by large language models (LLMs), confirm that: 1) type-contextualization significantly reduces the number of false positives for type-based sensitive data detection and reaches a recall of 94% compared to 63% with commercial tools, and 2) domain-contextualization leveraging sensitivity rule retrieval is effective for context-grounded sensitive data detection in non-standard data domains such as humanitarian datasets. Evaluation with humanitarian data experts also reveals that context-grounded LLM explanations provide useful guidance in manual data auditing processes, improving consistency. We open-source mechanisms and annotated datasets for contextual sensitive data detection at https://github.com/trl-lab/sensitive-data-detection.</description>
      <guid isPermaLink="false">oai:arXiv.org:2512.04120v1</guid>
      <category>cs.CR</category>
      <category>cs.AI</category>
      <category>cs.CL</category>
      <category>cs.CY</category>
      <category>cs.DB</category>
      <category>cs.IR</category>
      <pubDate>Fri, 05 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Liang Telkamp, Madelon Hulsebos</dc:creator>
    </item>
    <item>
      <title>MechDetect: Detecting Data-Dependent Errors</title>
      <link>https://arxiv.org/abs/2512.04138</link>
      <description>arXiv:2512.04138v1 Announce Type: cross 
Abstract: Data quality monitoring is a core challenge in modern information processing systems. While many approaches to detect data errors or shifts have been proposed, few studies investigate the mechanisms governing error generation. We argue that knowing how errors were generated can be key to tracing and fixing them. In this study, we build on existing work in the statistics literature on missing values and propose MechDetect, a simple algorithm to investigate error generation mechanisms. Given a tabular data set and a corresponding error mask, the algorithm estimates whether or not the errors depend on the data using machine learning models. Our work extends established approaches to detect mechanisms underlying missing values and can be readily applied to other error types, provided that an error mask is available. We demonstrate the effectiveness of MechDetect in experiments on established benchmark datasets.</description>
      <guid isPermaLink="false">oai:arXiv.org:2512.04138v1</guid>
      <category>cs.LG</category>
      <category>cs.DB</category>
      <category>cs.IR</category>
      <pubDate>Fri, 05 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-sa/4.0/</dc:rights>
      <dc:creator>Philipp Jung, Nicholas Chandler, Sebastian J\"ager, Felix Biessmann</dc:creator>
    </item>
    <item>
      <title>OsmT: Bridging OpenStreetMap Queries and Natural Language with Open-source Tag-aware Language Models</title>
      <link>https://arxiv.org/abs/2512.04738</link>
      <description>arXiv:2512.04738v1 Announce Type: cross 
Abstract: Bridging natural language and structured query languages is a long-standing challenge in the database community. While recent advances in language models have shown promise in this direction, existing solutions often rely on large-scale closed-source models that suffer from high inference costs, limited transparency, and lack of adaptability for lightweight deployment. In this paper, we present OsmT, an open-source tag-aware language model specifically designed to bridge natural language and Overpass Query Language (OverpassQL), a structured query language for accessing large-scale OpenStreetMap (OSM) data. To enhance the accuracy and structural validity of generated queries, we introduce a Tag Retrieval Augmentation (TRA) mechanism that incorporates contextually relevant tag knowledge into the generation process. This mechanism is designed to capture the hierarchical and relational dependencies present in the OSM database, addressing the topological complexity inherent in geospatial query formulation. In addition, we define a reverse task, OverpassQL-to-Text, which translates structured queries into natural language explanations to support query interpretation and improve user accessibility. We evaluate OsmT on a public benchmark against strong baselines and observe consistent improvements in both query generation and interpretation. Despite using significantly fewer parameters, our model achieves competitive accuracy, demonstrating the effectiveness of open-source pre-trained language models in bridging natural language and structured query languages within schema-rich geospatial environments.</description>
      <guid isPermaLink="false">oai:arXiv.org:2512.04738v1</guid>
      <category>cs.CL</category>
      <category>cs.AI</category>
      <category>cs.DB</category>
      <pubDate>Fri, 05 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Zhuoyue Wan, Wentao Hu, Chen Jason Zhang, Yuanfeng Song, Shuaimin Li, Ruiqiang Xiao, Xiao-Yong Wei, Raymond Chi-Wing Wong</dc:creator>
    </item>
    <item>
      <title>IBM Multilevel Process Mining vs de facto Object-Centric Process Mining approaches</title>
      <link>https://arxiv.org/abs/2512.03906</link>
      <description>arXiv:2512.03906v2 Announce Type: replace 
Abstract: The academic evolution of process mining is moving toward object centric process mining, marking a significant shift in how processes are modeled and analyzed. IBM has developed its own distinctive approach called Multilevel Process Mining. This paper provides a description of the two approaches and presents a comparative analysis of their respective advantages and limitations. IBM leveraged this comparison to drive the evolution of IBM Process Mining product, creating the new Organizational Mining feature, an innovation that combines the best of the two approaches. Demonstrate the potential of this novel, innovative and distinct methodology with an example.</description>
      <guid isPermaLink="false">oai:arXiv.org:2512.03906v2</guid>
      <category>cs.DB</category>
      <pubDate>Fri, 05 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Alberto Ronzoni, Anina Antony, Anjana M R, Francesca De Leo, Jesna Jose, Mattia Freda, Nandini Narayanankutty, Rafflesia Khan, Raji RV, Thomas Diacci</dc:creator>
    </item>
  </channel>
</rss>
