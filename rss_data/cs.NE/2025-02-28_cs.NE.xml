<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>cs.NE updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/cs.NE</link>
    <description>cs.NE updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/cs.NE" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Fri, 28 Feb 2025 05:00:18 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Fri, 28 Feb 2025 00:00:00 -0500</pubDate>
    <skipDays>
      <day>Sunday</day>
      <day>Saturday</day>
    </skipDays>
    <item>
      <title>Evolutionary Algorithms Approach For Search Based On Semantic Document Similarity</title>
      <link>https://arxiv.org/abs/2502.19437</link>
      <description>arXiv:2502.19437v1 Announce Type: new 
Abstract: Advancements in cloud computing and distributed computing have fostered research activities in Computer science. As a result, researchers have made significant progress in Neural Networks, Evolutionary Computing Algorithms like Genetic, and Differential evolution algorithms. These algorithms are used to develop clustering, recommendation, and question-and-answering systems using various text representation and similarity measurement techniques. In this research paper, Universal Sentence Encoder (USE) is used to capture the semantic similarity of text; And the transfer learning technique is used to apply Genetic Algorithm (GA) and Differential Evolution (DE) algorithms to search and retrieve relevant top N documents based on user query. The proposed approach is applied to the Stanford Question and Answer (SQuAD) Dataset to identify a user query. Finally, through experiments, we prove that text documents can be efficiently represented as sentence embedding vectors using USE to capture the semantic similarity, and by comparing the results of the Manhattan Distance, GA, and DE algorithms we prove that the evolutionary algorithms are good at finding the top N results than the traditional ranking approach.</description>
      <guid isPermaLink="false">oai:arXiv.org:2502.19437v1</guid>
      <category>cs.NE</category>
      <category>cs.AI</category>
      <category>cs.LG</category>
      <pubDate>Fri, 28 Feb 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <arxiv:DOI>10.1145/3617733.3617753</arxiv:DOI>
      <arxiv:journal_reference>ICCCM '23: Proceedings of the 2023 11th International Conference on Computer and Communications Management</arxiv:journal_reference>
      <dc:creator>Chandrashekar Muniyappa, Eujin Kim</dc:creator>
    </item>
    <item>
      <title>Multi-objective Cat Swarm Optimization Algorithm based on a Grid System</title>
      <link>https://arxiv.org/abs/2502.19439</link>
      <description>arXiv:2502.19439v1 Announce Type: new 
Abstract: This paper presents a multi-objective version of the Cat Swarm Optimization Algorithm called the Grid-based Multi-objective Cat Swarm Optimization Algorithm (GMOCSO). Convergence and diversity preservation are the two main goals pursued by modern multi-objective algorithms to yield robust results. To achieve these goals, we first replace the roulette wheel method of the original CSO algorithm with a greedy method. Then, two key concepts from Pareto Archived Evolution Strategy Algorithm (PAES) are adopted: the grid system and double archive strategy. Several test functions and a real-world scenario called the Pressure vessel design problem are used to evaluate the proposed algorithm's performance. In the experiment, the proposed algorithm is compared with other well-known algorithms using different metrics such as Reversed Generational Distance, Spacing metric, and Spread metric. The optimization results show the robustness of the proposed algorithm, and the results are further confirmed using statistical methods and graphs. Finally, conclusions and future directions were presented..</description>
      <guid isPermaLink="false">oai:arXiv.org:2502.19439v1</guid>
      <category>cs.NE</category>
      <category>cs.AI</category>
      <pubDate>Fri, 28 Feb 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <arxiv:DOI>10.1201/9781003601555</arxiv:DOI>
      <dc:creator>Aram M. Ahmed, Bryar A. Hassan, Tarik A. Rashid, Kaniaw A. Noori, Soran Ab. M. Saeed, Omed H. Ahmed, Shahla U. Umar</dc:creator>
    </item>
    <item>
      <title>Modified FOX Optimizer for Solving optimization problems</title>
      <link>https://arxiv.org/abs/2502.20027</link>
      <description>arXiv:2502.20027v1 Announce Type: new 
Abstract: The FOX optimizer, inspired by red fox hunting behavior, is a powerful algorithm for solving real-world and engineering problems. However, despite balancing exploration and exploitation, it can prematurely converge to local optima, as agent positions are updated solely based on the current best-known position, causing all agents to converge on one location. This study proposes the modified FOX optimizer (mFOX) to enhance exploration and balance exploration and exploitation in three steps. First, the Oppositional-Based Learning (OBL) strategy is used to improve the initial population. Second, control parameters are refined to achieve a better balance between exploration and exploitation. Third, a new update equation is introduced, allowing agents to adjust their positions relative to one another rather than relying solely on the best-known position. This approach improves exploration efficiency without adding complexity. The mFOX algorithm's performance is evaluated against 12 well-known algorithms on 23 classical benchmark functions, 10 CEC2019 functions, and 12 CEC2022 functions. It outperforms competitors in 74% of the classical benchmarks, 60% of the CEC2019 benchmarks, and 58% of the CEC2022 benchmarks. Additionally, mFOX effectively addresses four engineering problems. These results demonstrate mFOX's strong competitiveness in solving complex optimization tasks, including unimodal, constrained, and high-dimensional problems.</description>
      <guid isPermaLink="false">oai:arXiv.org:2502.20027v1</guid>
      <category>cs.NE</category>
      <category>math.OC</category>
      <pubDate>Fri, 28 Feb 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Dler O. Hasan, Hardi M. Mohammed, Zrar Khalid Abdul</dc:creator>
    </item>
    <item>
      <title>Waves and symbols in neuromorphic hardware: from analog signal processing to digital computing on the same computational substrate</title>
      <link>https://arxiv.org/abs/2502.20381</link>
      <description>arXiv:2502.20381v1 Announce Type: new 
Abstract: Neural systems use the same underlying computational substrate to carry out analog filtering and signal processing operations, as well as discrete symbol manipulation and digital computation. Inspired by the computational principles of canonical cortical microcircuits, we propose a framework for using recurrent spiking neural networks to seamlessly and robustly switch between analog signal processing and categorical and discrete computation. We provide theoretical analysis and practical neural network design tools to formally determine the conditions for inducing this switch. We demonstrate the robustness of this framework experimentally with hardware soft Winner-Take-All and mixed-feedback recurrent spiking neural networks, implemented by appropriately configuring the analog neuron and synapse circuits of a mixed-signal neuromorphic processor chip.</description>
      <guid isPermaLink="false">oai:arXiv.org:2502.20381v1</guid>
      <category>cs.NE</category>
      <pubDate>Fri, 28 Feb 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <dc:creator>Dmitrii Zendrikov, Alessio Franci, Giacomo Indiveri</dc:creator>
    </item>
    <item>
      <title>A Novel P-bit-based Probabilistic Computing Approach for Solving the 3-D Protein Folding Problem</title>
      <link>https://arxiv.org/abs/2502.20050</link>
      <description>arXiv:2502.20050v1 Announce Type: cross 
Abstract: In the post-Moore era, the need for efficient solutions to non-deterministic polynomial-time (NP) problems is becoming more pressing. In this context, the Ising model implemented by the probabilistic computing systems with probabilistic bits (p-bits) has attracted attention due to the widespread availability of p-bits and support for large-scale simulations. This study marks the first work to apply probabilistic computing to tackle protein folding, a significant NP-complete problem challenge in biology. We represent proteins as sequences of hydrophobic (H) and polar (P) beads within a three-dimensional (3-D) grid and introduce a novel many-body interaction-based encoding method to map the problem onto an Ising model. Our simulations show that this approach significantly simplifies the energy landscape for short peptide sequences of six amino acids, halving the number of energy levels. Furthermore, the proposed mapping method achieves approximately 100 times acceleration for sequences consisting of ten amino acids in identifying the correct folding configuration. We predicted the optimal folding configuration for a peptide sequence of 36 amino acids by identifying the ground state. These findings highlight the unique potential of the proposed encoding method for solving protein folding and, importantly, provide new tools for solving similar NP-complete problems in biology by probabilistic computing approach.</description>
      <guid isPermaLink="false">oai:arXiv.org:2502.20050v1</guid>
      <category>physics.app-ph</category>
      <category>cs.NE</category>
      <pubDate>Fri, 28 Feb 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Chao Fang, Yihan He, Xiao Gong, Gengchiau Liang</dc:creator>
    </item>
    <item>
      <title>Forward-Cooperation-Backward (FCB) learning in a Multi-Encoding Uni-Decoding neural network architecture</title>
      <link>https://arxiv.org/abs/2502.20113</link>
      <description>arXiv:2502.20113v1 Announce Type: cross 
Abstract: The most popular technique to train a neural network is backpropagation. Recently, the Forward-Forward technique has also been introduced for certain learning tasks. However, in real life, human learning does not follow any of these techniques exclusively. The way a human learns is basically a combination of forward learning, backward propagation and cooperation. Humans start learning a new concept by themselves and try to refine their understanding hierarchically during which they might come across several doubts. The most common approach to doubt solving is a discussion with peers, which can be called cooperation. Cooperation/discussion/knowledge sharing among peers is one of the most important steps of learning that humans follow. However, there might still be a few doubts even after the discussion. Then the difference between the understanding of the concept and the original literature is identified and minimized over several revisions. Inspired by this, the paper introduces Forward-Cooperation-Backward (FCB) learning in a deep neural network framework mimicking the human nature of learning a new concept. A novel deep neural network architecture, called Multi Encoding Uni Decoding neural network model, has been designed which learns using the notion of FCB. A special lateral synaptic connection has also been introduced to realize cooperation. The models have been justified in terms of their performance in dimension reduction on four popular datasets. The ability to preserve the granular properties of data in low-rank embedding has been tested to justify the quality of dimension reduction. For downstream analyses, classification has also been performed. An experimental study on convergence analysis has been performed to establish the efficacy of the FCB learning strategy.</description>
      <guid isPermaLink="false">oai:arXiv.org:2502.20113v1</guid>
      <category>cs.LG</category>
      <category>cs.AI</category>
      <category>cs.CV</category>
      <category>cs.NE</category>
      <pubDate>Fri, 28 Feb 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Prasun Dutta, Koustab Ghosh, Rajat K. De</dc:creator>
    </item>
    <item>
      <title>Accelerating Model-Based Reinforcement Learning with State-Space World Models</title>
      <link>https://arxiv.org/abs/2502.20168</link>
      <description>arXiv:2502.20168v1 Announce Type: cross 
Abstract: Reinforcement learning (RL) is a powerful approach for robot learning. However, model-free RL (MFRL) requires a large number of environment interactions to learn successful control policies. This is due to the noisy RL training updates and the complexity of robotic systems, which typically involve highly non-linear dynamics and noisy sensor signals. In contrast, model-based RL (MBRL) not only trains a policy but simultaneously learns a world model that captures the environment's dynamics and rewards. The world model can either be used for planning, for data collection, or to provide first-order policy gradients for training. Leveraging a world model significantly improves sample efficiency compared to model-free RL. However, training a world model alongside the policy increases the computational complexity, leading to longer training times that are often intractable for complex real-world scenarios. In this work, we propose a new method for accelerating model-based RL using state-space world models. Our approach leverages state-space models (SSMs) to parallelize the training of the dynamics model, which is typically the main computational bottleneck. Additionally, we propose an architecture that provides privileged information to the world model during training, which is particularly relevant for partially observable environments. We evaluate our method in several real-world agile quadrotor flight tasks, involving complex dynamics, for both fully and partially observable environments. We demonstrate a significant speedup, reducing the world model training time by up to 10 times, and the overall MBRL training time by up to 4 times. This benefit comes without compromising performance, as our method achieves similar sample efficiency and task rewards to state-of-the-art MBRL methods.</description>
      <guid isPermaLink="false">oai:arXiv.org:2502.20168v1</guid>
      <category>cs.RO</category>
      <category>cs.AI</category>
      <category>cs.LG</category>
      <category>cs.NE</category>
      <category>stat.ML</category>
      <pubDate>Fri, 28 Feb 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Maria Krinner, Elie Aljalbout, Angel Romero, Davide Scaramuzza</dc:creator>
    </item>
    <item>
      <title>On the Importance of Reward Design in Reinforcement Learning-based Dynamic Algorithm Configuration: A Case Study on OneMax with (1+($\lambda$,$\lambda$))-GA</title>
      <link>https://arxiv.org/abs/2502.20265</link>
      <description>arXiv:2502.20265v1 Announce Type: cross 
Abstract: Dynamic Algorithm Configuration (DAC) has garnered significant attention in recent years, particularly in the prevalence of machine learning and deep learning algorithms. Numerous studies have leveraged the robustness of decision-making in Reinforcement Learning (RL) to address the optimization challenges associated with algorithm configuration. However, making an RL agent work properly is a non-trivial task, especially in reward design, which necessitates a substantial amount of handcrafted knowledge based on domain expertise. In this work, we study the importance of reward design in the context of DAC via a case study on controlling the population size of the $(1+(\lambda,\lambda))$-GA optimizing OneMax. We observed that a poorly designed reward can hinder the RL agent's ability to learn an optimal policy because of a lack of exploration, leading to both scalability and learning divergence issues. To address those challenges, we propose the application of a reward shaping mechanism to facilitate enhanced exploration of the environment by the RL agent. Our work not only demonstrates the ability of RL in dynamically configuring the $(1+(\lambda,\lambda))$-GA, but also confirms the advantages of reward shaping in the scalability of RL agents across various sizes of OneMax problems.</description>
      <guid isPermaLink="false">oai:arXiv.org:2502.20265v1</guid>
      <category>cs.LG</category>
      <category>cs.NE</category>
      <pubDate>Fri, 28 Feb 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Tai Nguyen, Phong Le, Andr\'e Biendenkapp, Carola Doerr, Nguyen Dang</dc:creator>
    </item>
    <item>
      <title>A RankNet-Inspired Surrogate-Assisted Hybrid Metaheuristic for Expensive Coverage Optimization</title>
      <link>https://arxiv.org/abs/2501.07375</link>
      <description>arXiv:2501.07375v2 Announce Type: replace 
Abstract: Coverage optimization generally involves deploying a set of facilities to best satisfy the demands of specified points, with broad applications in fields such as location science and sensor networks. Recent applications reveal that the subset site selection coupled with continuous angular parameter optimization can be formulated as Mixed-Variable Optimization Problems (MVOPs). Meanwhile, high-fidelity discretization and visibility analysis significantly increase computational cost and complexity, evolving the MVOP into an Expensive Mixed-Variable Optimization Problem (EMVOP). While canonical Evolutionary Algorithms have yielded promising results, their reliance on numerous fitness evaluations is too costly for our problem. Furthermore, most surrogate-assisted methods face limitations due to their reliance on regression-based models. To address these issues, we propose the RankNet-Inspired Surrogate-assisted Hybrid Metaheuristic (RI-SHM), an extension of our previous work. RI-SHM integrates three key components: (1) a RankNet-based pairwise global surrogate that innovatively predicts rankings between pairs of individuals, bypassing the challenges of fitness estimation in discontinuous solution space; (2) a surrogate-assisted local Estimation of Distribution Algorithm that enhances local exploitation and helps escape from local optima; and (3) a fitness diversity-driven switching strategy that dynamically balances exploration and exploitation. Experiments demonstrate that our algorithm can effectively handle large-scale coverage optimization tasks of up to 300 dimensions and more than 1,800 targets within desirable runtime. Compared to state-of-the-art algorithms for EMVOPs, RI-SHM consistently outperforms them by up to 56.5$\%$ across all tested instances.</description>
      <guid isPermaLink="false">oai:arXiv.org:2501.07375v2</guid>
      <category>cs.NE</category>
      <pubDate>Fri, 28 Feb 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Tongyu Wu, Changhao Miao, Yuntian Zhang, Fang Deng, Chen Chen</dc:creator>
    </item>
    <item>
      <title>Continual learning with the neural tangent ensemble</title>
      <link>https://arxiv.org/abs/2408.17394</link>
      <description>arXiv:2408.17394v2 Announce Type: replace-cross 
Abstract: A natural strategy for continual learning is to weigh a Bayesian ensemble of fixed functions. This suggests that if a (single) neural network could be interpreted as an ensemble, one could design effective algorithms that learn without forgetting. To realize this possibility, we observe that a neural network classifier with N parameters can be interpreted as a weighted ensemble of N classifiers, and that in the lazy regime limit these classifiers are fixed throughout learning. We call these classifiers the neural tangent experts and show they output valid probability distributions over the labels. We then derive the likelihood and posterior probability of each expert given past data. Surprisingly, the posterior updates for these experts are equivalent to a scaled and projected form of stochastic gradient descent (SGD) over the network weights. Away from the lazy regime, networks can be seen as ensembles of adaptive experts which improve over time. These results offer a new interpretation of neural networks as Bayesian ensembles of experts, providing a principled framework for understanding and mitigating catastrophic forgetting in continual learning settings.</description>
      <guid isPermaLink="false">oai:arXiv.org:2408.17394v2</guid>
      <category>cs.LG</category>
      <category>cs.NE</category>
      <pubDate>Fri, 28 Feb 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <arxiv:journal_reference>Neural Information Processing Systems 34 (2024)</arxiv:journal_reference>
      <dc:creator>Ari S. Benjamin, Christian Pehle, Kyle Daruwalla</dc:creator>
    </item>
    <item>
      <title>Hierarchy of chaotic dynamics in random modular networks</title>
      <link>https://arxiv.org/abs/2410.06361</link>
      <description>arXiv:2410.06361v2 Announce Type: replace-cross 
Abstract: We introduce a model of randomly connected neural populations and study its dynamics by means of the dynamical mean-field theory and simulations. Our analysis uncovers a rich phase diagram, featuring high- and low-dimensional chaotic phases, separated by a crossover region characterized by low values of the maximal Lyapunov exponent and participation ratio dimension, but with high values of the Lyapunov dimension that change significantly across the region. Counterintuitively, chaos can be attenuated by either adding noise to strongly modular connectivity or by introducing modularity into random connectivity. Extending the model to include a multilevel, hierarchical connectivity reveals that a loose balance between activities across levels drives the system towards the edge of chaos.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.06361v2</guid>
      <category>physics.bio-ph</category>
      <category>cond-mat.dis-nn</category>
      <category>cs.NE</category>
      <category>nlin.CD</category>
      <category>q-bio.NC</category>
      <pubDate>Fri, 28 Feb 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>{\L}ukasz Ku\'smierz, Ulises Pereira-Obilinovic, Zhixin Lu, Dana Mastrovito, Stefan Mihalas</dc:creator>
    </item>
  </channel>
</rss>
