<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>cs.GT updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/cs.GT</link>
    <description>cs.GT updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/cs.GT" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Thu, 29 Jan 2026 02:42:06 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Wed, 28 Jan 2026 00:00:00 -0500</pubDate>
    <skipDays>
      <day>Saturday</day>
      <day>Sunday</day>
    </skipDays>
    <item>
      <title>Fog of War Chess</title>
      <link>https://arxiv.org/abs/2601.18813</link>
      <description>arXiv:2601.18813v1 Announce Type: new 
Abstract: Fog of War chess is a popular variant of classical chess, in which both players have only partial information about the position of the opponent's pieces. This study provides the first theoretical analysis of endgames in Fog of War chess. In particular, we analyze the setups king and queen versus king, king and rook versus king, and king and two rooks versus king. We show that a king and queen can always guarantee a win against a lone king. In contrast to classical chess, a king and a rook cannot guarantee a win against a lone king. However, adding one more rook guarantees a win.</description>
      <guid isPermaLink="false">oai:arXiv.org:2601.18813v1</guid>
      <category>cs.GT</category>
      <pubDate>Wed, 28 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Matthias Gehnen, Julius Stannat</dc:creator>
    </item>
    <item>
      <title>Differential Voting: Loss Functions For Axiomatically Diverse Aggregation of Heterogeneous Preferences</title>
      <link>https://arxiv.org/abs/2601.18824</link>
      <description>arXiv:2601.18824v1 Announce Type: new 
Abstract: Reinforcement learning from human feedback (RLHF) implicitly aggregates heterogeneous human preferences into a single utility function, even though the underlying utilities of the participants are in practice diverse. Hence, RLHF can be viewed as a form of voting, where the aggregation mechanism is defined by the loss function. Although Arrow's Impossibility Theorem suggests that different mechanisms satisfy different sets of desirable axioms, most existing methods rely on a single aggregation principle, typically the Bradley-Terry-Luce (BTL) model, which corresponds to Borda count voting. This restricts the axiomatic properties of the learned reward and obscures the normative assumptions embedded in optimization. In this work, we introduce Differential Voting, a unifying framework that constructs instance-wise, differentiable loss functions whose population-level optima provably correspond to distinct classical voting rules. We develop differentiable surrogates for majority-based aggregation (BTL), Copeland, and Kemeny rules, and formally analyze their calibration properties, gradient fields, and limiting behavior as smoothing parameters vanish. For each loss, we establish consistency with the corresponding social choice rule and characterize the axioms it satisfies or violates. Our analysis shows how design choices in loss geometry-such as margin sensitivity and boundary concentration-directly translate into normative aggregation behavior. Differential Voting makes preference aggregation an explicit and controllable design choice in RLHF, enabling principled trade-offs between axiomatic guarantees and optimization stability. Code to reproduce our experiments is open-sourced.</description>
      <guid isPermaLink="false">oai:arXiv.org:2601.18824v1</guid>
      <category>cs.GT</category>
      <category>cs.AI</category>
      <pubDate>Wed, 28 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Zhiyu An, Duaa Nakshbandi, Wan Du</dc:creator>
    </item>
    <item>
      <title>Ad Insertion in LLM-Generated Responses</title>
      <link>https://arxiv.org/abs/2601.19435</link>
      <description>arXiv:2601.19435v1 Announce Type: new 
Abstract: Sustainable monetization of Large Language Models (LLMs) remains a critical open challenge. Traditional search advertising, which relies on static keywords, fails to capture the fleeting, context-dependent user intents--the specific information, goods, or services a user seeks--embedded in conversational flows. Beyond the standard goal of social welfare maximization, effective LLM advertising imposes additional requirements on contextual coherence (ensuring ads align semantically with transient user intents) and computational efficiency (avoiding user interaction latency), as well as adherence to ethical and regulatory standards, including preserving privacy and ensuring explicit ad disclosure. Although various recent solutions have explored bidding on token-level and query-level, both categories of approaches generally fail to holistically satisfy this multifaceted set of constraints.
  We propose a practical framework that resolves these tensions through two decoupling strategies. First, we decouple ad insertion from response generation to ensure safety and explicit disclosure. Second, we decouple bidding from specific user queries by using ``genres'' (high-level semantic clusters) as a proxy. This allows advertisers to bid on stable categories rather than sensitive real-time response, reducing computational burden and privacy risks. We demonstrate that applying the VCG auction mechanism to this genre-based framework yields approximately dominant strategy incentive compatibility (DSIC) and individual rationality (IR), as well as approximately optimal social welfare, while maintaining high computational efficiency. Finally, we introduce an "LLM-as-a-Judge" metric to estimate contextual coherence. Our experiments show that this metric correlates strongly with human ratings (Spearman's $\rho\approx 0.66$), outperforming 80% of individual human evaluators.</description>
      <guid isPermaLink="false">oai:arXiv.org:2601.19435v1</guid>
      <category>cs.GT</category>
      <category>cs.AI</category>
      <category>cs.CL</category>
      <pubDate>Wed, 28 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Shengwei Xu, Zhaohua Chen, Xiaotie Deng, Zhiyi Huang, Grant Schoenebeck</dc:creator>
    </item>
    <item>
      <title>Single-Winner Voting on Matchings</title>
      <link>https://arxiv.org/abs/2601.19653</link>
      <description>arXiv:2601.19653v1 Announce Type: new 
Abstract: We introduce a single-winner perspective on voting on matchings, in which voters have preferences over possible matchings in a graph, and the goal is to select a single collectively desirable matching. Unlike in classical matching problems, voters in our model are not part of the graph; instead, they have preferences over the entire matching. In the resulting election, the candidate space consists of all feasible matchings, whose exponential size renders standard algorithms for identifying socially desirable outcomes computationally infeasible. We study whether the computational tractability of finding such outcomes can be regained by exploiting the matching structure of the candidate space. Specifically, we provide a complete complexity landscape for questions concerning the maximization of social welfare, the construction and verification of Pareto optimal outcomes, and the existence and verification of Condorcet winners under one affine and two approval-based utility models. Our results consist of a mix of algorithmic and intractability results, revealing sharp boundaries between tractable and intractable cases, with complexity jumps arising from subtle changes in the utility model or solution concept.</description>
      <guid isPermaLink="false">oai:arXiv.org:2601.19653v1</guid>
      <category>cs.GT</category>
      <pubDate>Wed, 28 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Niclas Boehmer, Jessica Dierking</dc:creator>
    </item>
    <item>
      <title>Robustness of Approval-Based Multiwinner Voting Rules</title>
      <link>https://arxiv.org/abs/2601.19706</link>
      <description>arXiv:2601.19706v1 Announce Type: new 
Abstract: We investigate how robust approval-based multiwinner voting rules are to small perturbations in the votes. In particular, we consider the extent to which a committee can change after we add/remove/swap one approval, and we consider the computational complexity of deciding how many such operations are necessary to change the set of winning committees. We also consider the counting variants of our problems, which can be interpreted as computing the probability that the result of an election changes after a given number of random perturbations of the given election.</description>
      <guid isPermaLink="false">oai:arXiv.org:2601.19706v1</guid>
      <category>cs.GT</category>
      <pubDate>Wed, 28 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Piotr Faliszewski, Grzegorz Gawron, Bartosz Kusek</dc:creator>
    </item>
    <item>
      <title>How Similar Are Two Elections?</title>
      <link>https://arxiv.org/abs/2601.19716</link>
      <description>arXiv:2601.19716v1 Announce Type: new 
Abstract: We introduce and study isomorphic distances between ordinal
  elections (with the same numbers of candidates and voters). The main
  feature of these distances is that they are invariant to renaming
  the candidates and voters, and two elections are at distance zero if
  and only if they are isomorphic. Specifically, we consider
  isomorphic extensions of distances between preference orders: Given
  such a distance d, we extend it to distance d-ID between
  elections by unifying candidate names and finding a matching between
  the votes, so that the sum of the d-distances between the matched
  votes is as small as possible.
  We show that testing isomorphism of two elections can be done in
  polynomial time so, in principle, such distances can be tractable.
  Yet, we show that two very natural isomorphic distances are
  NP-complete and hard to approximate. We attempt to rectify the
  situation by showing FPT algorithms for several natural
  parameterizations.</description>
      <guid isPermaLink="false">oai:arXiv.org:2601.19716v1</guid>
      <category>cs.GT</category>
      <pubDate>Wed, 28 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <arxiv:DOI>10.1016/j.jcss.2025.103632</arxiv:DOI>
      <arxiv:journal_reference>Journal of Computer and System Sciences 150 (2025) 103632</arxiv:journal_reference>
      <dc:creator>Piotr Faliszewski, Piotr Skowron, Arkadii Slinko, Krzysztof Sornat, Stanis{\l}aw Szufa, Nimrod Talmon</dc:creator>
    </item>
    <item>
      <title>Who Restores the Peg? A Mean-Field Game Approach to Model Stablecoin Market Dynamics</title>
      <link>https://arxiv.org/abs/2601.18991</link>
      <description>arXiv:2601.18991v1 Announce Type: cross 
Abstract: USDC and USDT are the dominant stablecoins pegged to \$1 with a total market capitalization of over \$300B and rising. Stablecoins make dollar value globally accessible with secure transfer and settlement. Yet in practice, these stablecoins experience periods of stress and de-pegging from their \$1 target, posing significant systemic risks. The behavior of market participants during these stress events and the collective actions that either restore or break the peg are not well understood. This paper addresses the question: who restores the peg? We develop a dynamic, agent-based mean-field game framework for fiat-collateralized stablecoins, in which a large population of arbitrageurs and retail traders strategically interacts across explicit primary (mint/redeem) and secondary (exchange) markets during a de-peg episode. The key advantage of this equilibrium formulation is that it endogenously maps market frictions into a market-clearing price path and implied net order flows, allowing us to attribute peg-reverting pressure by channel and to stress-test when a given mechanism becomes insufficient for recovery. Using three historical de-peg events, we show that the calibrated equilibrium reproduces observed recovery half-lives and yields an order flow decomposition in which system-wide stress is predominantly stabilized by primary-market arbitrage, whereas episodes with impaired primary redemption require a joint recovery via both primary and secondary markets. Finally, a quantitative sensitivity analysis of primary-rail frictions identifies a non-linear breakdown threshold. Beyond this point, secondary-market liquidity acts mainly as a second-order amplifier around this primary-market bottleneck.</description>
      <guid isPermaLink="false">oai:arXiv.org:2601.18991v1</guid>
      <category>q-fin.TR</category>
      <category>cs.GT</category>
      <category>econ.GN</category>
      <category>q-fin.EC</category>
      <pubDate>Wed, 28 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Hardhik Mohanty, Bhaskar Krishnamachari</dc:creator>
    </item>
    <item>
      <title>More at Stake: How Payoff and Language Shape LLM Agent Strategies in Cooperation Dilemmas</title>
      <link>https://arxiv.org/abs/2601.19082</link>
      <description>arXiv:2601.19082v1 Announce Type: cross 
Abstract: As LLMs increasingly act as autonomous agents in interactive and multi-agent settings, understanding their strategic behavior is critical for safety, coordination, and AI-driven social and economic systems. We investigate how payoff magnitude and linguistic context shape LLM strategies in repeated social dilemmas, using a payoff-scaled Prisoner's Dilemma to isolate sensitivity to incentive strength. Across models and languages, we observe consistent behavioral patterns, including incentive-sensitive conditional strategies and cross-linguistic divergence. To interpret these dynamics, we train supervised classifiers on canonical repeated-game strategies and apply them to LLM decisions, revealing systematic, model- and language-dependent behavioral intentions, with linguistic framing sometimes matching or exceeding architectural effects. Our results provide a unified framework for auditing LLMs as strategic agents and highlight cooperation biases with direct implications for AI governance and multi-agent system design.</description>
      <guid isPermaLink="false">oai:arXiv.org:2601.19082v1</guid>
      <category>cs.AI</category>
      <category>cs.CL</category>
      <category>cs.GT</category>
      <category>cs.LG</category>
      <category>cs.MA</category>
      <pubDate>Wed, 28 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Trung-Kiet Huynh, Dao-Sy Duy-Minh, Thanh-Bang Cao, Phong-Hao Le, Hong-Dan Nguyen, Nguyen Lam Phu Quy, Minh-Luan Nguyen-Vo, Hong-Phat Pham, Pham Phu Hoa, Thien-Kim Than, Chi-Nguyen Tran, Huy Tran, Gia-Thoai Tran-Le, Alessio Buscemi, Le Hong Trang, The Anh Han</dc:creator>
    </item>
    <item>
      <title>Reimagining Peer Review Process Through Multi-Agent Mechanism Design</title>
      <link>https://arxiv.org/abs/2601.19778</link>
      <description>arXiv:2601.19778v1 Announce Type: cross 
Abstract: The software engineering research community faces a systemic crisis: peer review is failing under growing submissions, misaligned incentives, and reviewer fatigue. Community surveys reveal that researchers perceive the process as "broken." This position paper argues that these dysfunctions are mechanism design failures amenable to computational solutions. We propose modeling the research community as a stochastic multi-agent system and applying multi-agent reinforcement learning to design incentive-compatible protocols. We outline three interventions: a credit-based submission economy, MARL-optimized reviewer assignment, and hybrid verification of review consistency. We present threat models, equity considerations, and phased pilot metrics. This vision charts a research agenda toward sustainable peer review.</description>
      <guid isPermaLink="false">oai:arXiv.org:2601.19778v1</guid>
      <category>cs.MA</category>
      <category>cs.AI</category>
      <category>cs.CY</category>
      <category>cs.GT</category>
      <category>cs.SE</category>
      <pubDate>Wed, 28 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <arxiv:DOI>10.1145/3793657.3793893</arxiv:DOI>
      <dc:creator>Ahmad Farooq, Kamran Iqbal</dc:creator>
    </item>
    <item>
      <title>Calibration without Ground Truth</title>
      <link>https://arxiv.org/abs/2601.19862</link>
      <description>arXiv:2601.19862v1 Announce Type: cross 
Abstract: Villalobos et al. [2024] predict that publicly available human text will be exhausted within the next decade. Thus, improving models without access to ground-truth labels becomes increasingly important. We propose a label-free post-processing framework that improves a strong but miscalibrated model using a weaker yet better-calibrated reference. Our framework guarantees a strict performance improvement under any proper loss. Our approach is based on a characterization of when strict improvement is possible: when the strong and reference models are not mutually calibrated. We formalize this condition, connect it to arbitrage and no-trade results from economics, and develop an efficient Bregman projection algorithm that guarantees worst-case loss reduction without labels. Experiments on representative LLMs across varying scales demonstrate that our label-free method significantly reduces proper losses and calibration errors, achieving performance competitive with supervised baselines.</description>
      <guid isPermaLink="false">oai:arXiv.org:2601.19862v1</guid>
      <category>cs.LG</category>
      <category>cs.GT</category>
      <pubDate>Wed, 28 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Yuqing Kong, Mingyu Song, Yizhou Wang, Yifan Wu</dc:creator>
    </item>
    <item>
      <title>AI Cap-and-Trade: Efficiency Incentives for Accessibility and Sustainability</title>
      <link>https://arxiv.org/abs/2601.19886</link>
      <description>arXiv:2601.19886v1 Announce Type: cross 
Abstract: The race for artificial intelligence (AI) dominance often prioritizes scale over efficiency. Hyper-scaling is the common industry approach: larger models, more data, and as many computational resources as possible. Using more resources is a simpler path to improved AI performance. Thus, efficiency has been de-emphasized. Consequently, the need for costly computational resources has marginalized academics and smaller companies. Simultaneously, increased energy expenditure, due to growing AI use, has led to mounting environmental costs. In response to accessibility and sustainability concerns, we argue for research into, and implementation of, market-based methods that incentivize AI efficiency. We believe that incentivizing efficient operations and approaches will reduce emissions while opening new opportunities for academics and smaller companies. As a call to action, we propose a cap-and-trade system for AI. Our system provably reduces computations for AI deployment, thereby lowering emissions and monetizing efficiency to the benefit of of academics and smaller companies.</description>
      <guid isPermaLink="false">oai:arXiv.org:2601.19886v1</guid>
      <category>econ.GN</category>
      <category>cs.AI</category>
      <category>cs.CY</category>
      <category>cs.GT</category>
      <category>q-fin.EC</category>
      <pubDate>Wed, 28 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Marco Bornstein, Amrit Singh Bedi</dc:creator>
    </item>
    <item>
      <title>Truth-Revealing Participatory Budgeting</title>
      <link>https://arxiv.org/abs/2601.17538</link>
      <description>arXiv:2601.17538v2 Announce Type: replace 
Abstract: Participatory Budgeting (PB) is commonly studied from an axiomatic perspective, where the aim is to design procedurally fair and economically efficient rules for voters with full information regarding their preferences. In contrast, we take an epistemic perspective and consider a framework where PB projects have different levels of underlying quality, indicating how well the project will take effect, which cannot be directly observed before implementation. Agents with noisy information cast votes to aggregate their information, and aim to elect a high-quality set of projects. We evaluate the performance of common PB rules by measuring the expected utility of their outcomes, compared to the optimal set of projects. We find that the quality of approximation improves as the range of project costs shrinks. When projects have unit cost, these common rules can identify the ``best'' set with probability converging to 1. We also study whether strategic agents have incentives to honestly convey their information in the vote. We find that it happens only under very restrictive conditions. We also run numerical experiments to examine the performance of different rules empirically and support our theoretical findings.</description>
      <guid isPermaLink="false">oai:arXiv.org:2601.17538v2</guid>
      <category>cs.GT</category>
      <pubDate>Wed, 28 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Qishen Han, Artem Ivaniuk, Edith Elkind, Lirong Xia</dc:creator>
    </item>
  </channel>
</rss>
