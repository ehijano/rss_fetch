<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>math.ST updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/math.ST</link>
    <description>math.ST updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/math.ST" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Fri, 20 Feb 2026 05:00:24 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Fri, 20 Feb 2026 00:00:00 -0500</pubDate>
    <skipDays>
      <day>Saturday</day>
      <day>Sunday</day>
    </skipDays>
    <item>
      <title>Support Recovery and $\ell_2$-Error Bound for Sparse Regression with Quadratic Measurements via Weakly-Convex-Concave Regularization</title>
      <link>https://arxiv.org/abs/2602.17466</link>
      <description>arXiv:2602.17466v1 Announce Type: new 
Abstract: The recovery of unknown signals from quadratic measurements finds extensive applications in fields such as phase retrieval, power system state estimation, and unlabeled distance geometry. This paper investigates the finite sample properties of weakly convex--concave regularized estimators in high-dimensional quadratic measurements models. By employing a weakly convex--concave penalized least squares approach, we establish support recovery and $\ell_2$-error bounds for the local minimizer. To solve the corresponding optimization problem, we adopt two proximal gradient strategies, where the proximal step is computed either in closed form or via a weighted $\ell_1$ approximation, depending on the regularization function. Numerical examples demonstrate the efficacy of the proposed method.</description>
      <guid isPermaLink="false">oai:arXiv.org:2602.17466v1</guid>
      <category>math.ST</category>
      <category>cs.IT</category>
      <category>math.IT</category>
      <category>stat.TH</category>
      <pubDate>Fri, 20 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Jun Fan, Jingyu Yang, Xinyu Zhang, Liqun Wang</dc:creator>
    </item>
    <item>
      <title>Optimal Unconstrained Self-Distillation in Ridge Regression: Strict Improvements, Precise Asymptotics, and One-Shot Tuning</title>
      <link>https://arxiv.org/abs/2602.17565</link>
      <description>arXiv:2602.17565v1 Announce Type: new 
Abstract: Self-distillation (SD) is the process of retraining a student on a mixture of ground-truth labels and the teacher's own predictions using the same architecture and training data. Although SD has been empirically shown to often improve generalization, its formal guarantees remain limited. We study SD for ridge regression in unconstrained setting in which the mixing weight $\xi$ may be outside the unit interval. Conditioned on the training data and without any distributional assumptions, we prove that for any squared prediction risk (including out-of-distribution), the optimally mixed student strictly improves upon the ridge teacher for every regularization level $\lambda &gt; 0$ at which the teacher ridge risk $R(\lambda)$ is nonstationary (i.e., $R'(\lambda) \neq 0$). We obtain a closed-form expression for the optimal mixing weight $\xi^\star(\lambda)$ for any value of $\lambda$ and show that it obeys the sign rule: $\operatorname{sign}(\xi^\star(\lambda))=-\operatorname{sign}(R'(\lambda))$. In particular, $\xi^\star(\lambda)$ can be negative, which is the case in over-regularized regimes. To quantify the risk improvement due to SD, we derive exact deterministic equivalents for the optimal SD risk in the proportional asymptotics regime (where the sample and feature sizes $n$ and $p$ both diverge but their aspect ratio $p/n$ converges) under general anisotropic covariance and deterministic signals. Our asymptotic analysis extends standard second-order ridge deterministic equivalents to their fourth-order analogs using block linearization, which may be of independent interest. From a practical standpoint, we propose a consistent one-shot tuning method to estimate $\xi^\star$ without grid search, sample splitting, or refitting. Experiments on real-world datasets and pretrained neural network features support our theory and the one-shot tuning method.</description>
      <guid isPermaLink="false">oai:arXiv.org:2602.17565v1</guid>
      <category>math.ST</category>
      <category>cs.LG</category>
      <category>stat.ML</category>
      <category>stat.TH</category>
      <pubDate>Fri, 20 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Hien Dang, Pratik Patil, Alessandro Rinaldo</dc:creator>
    </item>
    <item>
      <title>Asymptotically Optimal Sequential Testing with Markovian Data</title>
      <link>https://arxiv.org/abs/2602.17587</link>
      <description>arXiv:2602.17587v1 Announce Type: new 
Abstract: We study one-sided and $\alpha$-correct sequential hypothesis testing for data generated by an ergodic Markov chain. The null hypothesis is that the unknown transition matrix belongs to a prescribed set $P$ of stochastic matrices, and the alternative corresponds to a disjoint set $Q$. We establish a tight non-asymptotic instance-dependent lower bound on the expected stopping time of any valid sequential test under the alternative. Our novel analysis improves the existing lower bounds, which are either asymptotic or provably sub-optimal in this setting. Our lower bound incorporates both the stationary distribution and the transition structure induced by the unknown Markov chain. We further propose an optimal test whose expected stopping time matches this lower bound asymptotically as $\alpha \to 0$. We illustrate the usefulness of our framework through applications to sequential detection of model misspecification in Markov Chain Monte Carlo and to testing structural properties, such as the linearity of transition dynamics, in Markov decision processes. Our findings yield a sharp and general characterization of optimal sequential testing procedures under Markovian dependence.</description>
      <guid isPermaLink="false">oai:arXiv.org:2602.17587v1</guid>
      <category>math.ST</category>
      <category>cs.LG</category>
      <category>stat.ML</category>
      <category>stat.TH</category>
      <pubDate>Fri, 20 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Alhad Sethi, Kavali Sofia Sagar, Shubhada Agrawal, Debabrota Basu, P. N. Karthik</dc:creator>
    </item>
    <item>
      <title>First versus full or first versus last: U-statistic change-point tests under fixed and local alternatives</title>
      <link>https://arxiv.org/abs/2602.16789</link>
      <description>arXiv:2602.16789v1 Announce Type: cross 
Abstract: The use of U-statistics in the change-point context has received considerable attention in the literature. We compare two approaches of constructing CUSUM-type change-point tests, which we call the first-vs-full and first-vs-last approach. Both have been pursued by different authors. The question naturally arises if the two tests substantially differ and, if so, which of them is better in which data situation. In large samples, both tests are similar: they are asymptotically equivalent under the null hypothesis and under sequences of local alternatives. In small samples, there may be quite noticeable differences, which is in line with a different asymptotic behavior under fixed alternatives. We derive a simple criterion for deciding which test is more powerful. We examine the examples Gini's mean difference, the sample variance, and Kendall's tau in detail. Particularly, when testing for changes in scale by Gini's mean difference, we show that the first-vs-full approach has a higher power if and only if the scale changes from a smaller to a larger value -- regardless of the population distribution or the location of the change. The asymptotic derivations are under weak dependence. The results are illustrated by numerical simulations and data examples.</description>
      <guid isPermaLink="false">oai:arXiv.org:2602.16789v1</guid>
      <category>stat.ME</category>
      <category>math.ST</category>
      <category>stat.TH</category>
      <pubDate>Fri, 20 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Herold Dehling, Daniel Vogel, Martin Wendler</dc:creator>
    </item>
    <item>
      <title>M-estimation under Two-Phase Multiwave Sampling with Applications to Prediction-Powered Inference</title>
      <link>https://arxiv.org/abs/2602.16933</link>
      <description>arXiv:2602.16933v1 Announce Type: cross 
Abstract: In two-phase multiwave sampling, inexpensive measurements are collected on a large sample and expensive, more informative measurements are adaptively obtained on subsets of units across multiple waves. Adaptively collecting the expensive measurements can increase efficiency but complicates statistical inference. We give valid estimators and confidence intervals for M-estimation under adaptive two-phase multiwave sampling. We focus on the case where proxies for the expensive variables -- such as predictions from pretrained machine learning models -- are available for all units and propose a Multiwave Predict-Then-Debias estimator that combines proxy information with the expensive, higher-quality measurements to improve efficiency while removing bias. We establish asymptotic linearity and normality and propose asymptotically valid confidence intervals. We also develop an approximately greedy sampling strategy that improves efficiency relative to uniform sampling. Data-based simulation studies support the theoretical results and demonstrate efficiency gains.</description>
      <guid isPermaLink="false">oai:arXiv.org:2602.16933v1</guid>
      <category>stat.ME</category>
      <category>math.ST</category>
      <category>stat.ML</category>
      <category>stat.TH</category>
      <pubDate>Fri, 20 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Dan M. Kluger, Stephen Bates</dc:creator>
    </item>
    <item>
      <title>Dynamic Decision-Making under Model Misspecification: A Stochastic Stability Approach</title>
      <link>https://arxiv.org/abs/2602.17086</link>
      <description>arXiv:2602.17086v1 Announce Type: cross 
Abstract: Dynamic decision-making under model uncertainty is central to many economic environments, yet existing bandit and reinforcement learning algorithms rely on the assumption of correct model specification. This paper studies the behavior and performance of one of the most commonly used Bayesian reinforcement learning algorithms, Thompson Sampling (TS), when the model class is misspecified. We first provide a complete dynamic classification of posterior evolution in a misspecified two-armed Gaussian bandit, identifying distinct regimes: correct model concentration, incorrect model concentration, and persistent belief mixing, characterized by the direction of statistical evidence and the model-action mapping. These regimes yield sharp predictions for limiting beliefs, action frequencies, and asymptotic regret. We then extend the analysis to a general finite model class and develop a unified stochastic stability framework that represents posterior evolution as a Markov process on the belief simplex. This approach characterizes two sufficient conditions to classify the ergodic and transient behaviors and provides inductive dimensional reductions of the posterior dynamics. Our results offer the first qualitative and geometric classification of TS under misspecification, bridging Bayesian learning with evolutionary dynamics, and also build the foundations of robust decision-making in structured bandits.</description>
      <guid isPermaLink="false">oai:arXiv.org:2602.17086v1</guid>
      <category>econ.TH</category>
      <category>cs.LG</category>
      <category>math.ST</category>
      <category>stat.TH</category>
      <pubDate>Fri, 20 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Xinyu Dai, Daniel Chen, Yian Qian</dc:creator>
    </item>
    <item>
      <title>Variational inference via radial transport</title>
      <link>https://arxiv.org/abs/2602.17525</link>
      <description>arXiv:2602.17525v1 Announce Type: cross 
Abstract: In variational inference (VI), the practitioner approximates a high-dimensional distribution $\pi$ with a simple surrogate one, often a (product) Gaussian distribution. However, in many cases of practical interest, Gaussian distributions might not capture the correct radial profile of $\pi$, resulting in poor coverage. In this work, we approach the VI problem from the perspective of optimizing over these radial profiles. Our algorithm radVI is a cheap, effective add-on to many existing VI schemes, such as Gaussian (mean-field) VI and Laplace approximation. We provide theoretical convergence guarantees for our algorithm, owing to recent developments in optimization over the Wasserstein space--the space of probability distributions endowed with the Wasserstein distance--and new regularity properties of radial transport maps in the style of Caffarelli (2000).</description>
      <guid isPermaLink="false">oai:arXiv.org:2602.17525v1</guid>
      <category>cs.LG</category>
      <category>math.ST</category>
      <category>stat.ML</category>
      <category>stat.TH</category>
      <pubDate>Fri, 20 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Luca Ghafourpour, Sinho Chewi, Alessio Figalli, Aram-Alexandre Pooladian</dc:creator>
    </item>
    <item>
      <title>genriesz: A Python Package for Automatic Debiased Machine Learning with Generalized Riesz Regression</title>
      <link>https://arxiv.org/abs/2602.17543</link>
      <description>arXiv:2602.17543v1 Announce Type: cross 
Abstract: Efficient estimation of causal and structural parameters can be automated using the Riesz representation theorem and debiased machine learning (DML). We present genriesz, an open-source Python package that implements automatic DML and generalized Riesz regression, a unified framework for estimating Riesz representers by minimizing empirical Bregman divergences. This framework includes covariate balancing, nearest-neighbor matching, calibrated estimation, and density ratio estimation as special cases. A key design principle of the package is automatic regressor balancing (ARB): given a Bregman generator $g$ and a representer model class, genriesz} automatically constructs a compatible link function so that the generalized Riesz regression estimator satisfies balancing (moment-matching) optimality conditions in a user-chosen basis. The package provides a modulr interface for specifying (i) the target linear functional via a black-box evaluation oracle, (ii) the representer model via basis functions (polynomial, RKHS approximations, random forest leaf encodings, neural embeddings, and a nearest-neighbor catchment basis), and (iii) the Bregman generator, with optional user-supplied derivatives. It returns regression adjustment (RA), Riesz weighting (RW), augmented Riesz weighting (ARW), and TMLE-style estimators with cross-fitting, confidence intervals, and $p$-values. We highlight representative workflows for estimation problems such as the average treatment effect (ATE), ATE on treated (ATT), and average marginal effect estimation. The Python package is available at https://github.com/MasaKat0/genriesz and on PyPI.</description>
      <guid isPermaLink="false">oai:arXiv.org:2602.17543v1</guid>
      <category>stat.ML</category>
      <category>cs.LG</category>
      <category>econ.EM</category>
      <category>math.ST</category>
      <category>stat.ME</category>
      <category>stat.TH</category>
      <pubDate>Fri, 20 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Masahiro Kato</dc:creator>
    </item>
    <item>
      <title>M\"obius inversion and the iterated bootstrap</title>
      <link>https://arxiv.org/abs/2408.05826</link>
      <description>arXiv:2408.05826v2 Announce Type: replace 
Abstract: Estimating nonlinear functionals of probability distributions from samples is a fundamental statistical problem. The "plug-in" estimator obtained by applying the target functional to the empirical distribution of samples is biased. Resampling methods such as the bootstrap derive artificial datasets from the original one by resampling. Comparing the outcome of the plug-in estimator in the original and resampled datasets allows estimating and thus correcting the bias. In the asymptotic setting, iterations of this procedure attain an arbitrarily high order of bias correction, but finite sample results are scarce. This work develops a new theoretical understanding of bootstrap bias correction by viewing it as an iterative linear solver for the combinatorial operation of M\"obius inversion. It sharply characterizes the regime of linear convergence of the bootstrap bias reduction for moment polynomials. It uses these results to show its superalgebraic convergence rate for band-limited functionals. Finally, it derives a modified bootstrap iteration enabling the unbiased estimation of unknown order-$m$ moment polynomials in $m$ bootstrap iterations.</description>
      <guid isPermaLink="false">oai:arXiv.org:2408.05826v2</guid>
      <category>math.ST</category>
      <category>math.CO</category>
      <category>math.PR</category>
      <category>stat.TH</category>
      <pubDate>Fri, 20 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Florian Sch\"afer</dc:creator>
    </item>
    <item>
      <title>Finite-sample performance of the maximum likelihood estimator in logistic regression</title>
      <link>https://arxiv.org/abs/2411.02137</link>
      <description>arXiv:2411.02137v3 Announce Type: replace 
Abstract: Logistic regression is a classical model for describing the probabilistic dependence of binary responses to multivariate covariates. We consider the predictive performance of the maximum likelihood estimator (MLE) for logistic regression, assessed in terms of logistic risk. We consider two questions: first, that of the existence of the MLE (which occurs when the dataset is not linearly separated), and second, that of its accuracy when it exists. These properties depend on both the dimension of covariates and the signal strength. In the case of Gaussian covariates and a well-specified logistic model, we obtain sharp non-asymptotic guarantees for the existence and excess logistic risk of the MLE. We then generalize these results in two ways: first, to non-Gaussian covariates satisfying a certain two-dimensional margin condition, and second to the general case of statistical learning with a possibly misspecified logistic model. Finally, we consider the case of a Bernoulli design, where the behavior of the MLE is highly sensitive to the parameter direction.</description>
      <guid isPermaLink="false">oai:arXiv.org:2411.02137v3</guid>
      <category>math.ST</category>
      <category>cs.LG</category>
      <category>stat.ML</category>
      <category>stat.TH</category>
      <pubDate>Fri, 20 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Hugo Chardon, Matthieu Lerasle, Jaouad Mourtada</dc:creator>
    </item>
    <item>
      <title>Two statistical problems for multivariate mixture distributions</title>
      <link>https://arxiv.org/abs/2503.12147</link>
      <description>arXiv:2503.12147v5 Announce Type: replace 
Abstract: We address two important statistical problems: that of estimating for mixtures of multivariate normal distributions and mixtures of $t$-distributions based of univariate projections, and that of measuring the agreement between two different random partitions. The results are based on an earlier work of the authors, where it was shown that mixtures of multivariate Gaussian or $t$-distributions can be distinguished by projecting them onto a certain predetermined finite set of lines, the number of lines depending only on the total number of distributions involved and on the ambient dimension. We also compare our proposal with robust versions of the expectation-maximization method EM. In each case, we present algorithms for effecting the task, and compare them with existing methods by carrying out some simulati</description>
      <guid isPermaLink="false">oai:arXiv.org:2503.12147v5</guid>
      <category>math.ST</category>
      <category>stat.TH</category>
      <pubDate>Fri, 20 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Ricardo Fraiman, Leonardo Moreno, Thomas Ransford</dc:creator>
    </item>
    <item>
      <title>Offline changepoint localization using a matrix of conformal p-values</title>
      <link>https://arxiv.org/abs/2505.00292</link>
      <description>arXiv:2505.00292v5 Announce Type: replace 
Abstract: Changepoint localization is the problem of estimating the index at which a change occurred in the data generating distribution of an ordered list of data, or declaring that no change occurred. We present the broadly applicable MCP algorithm, which uses a matrix of conformal p-values to produce a confidence interval for a (single) changepoint under the mild assumption that the pre-change and post-change distributions are each exchangeable. We prove a novel conformal Neyman-Pearson lemma, motivating practical classifier-based choices for our conformal score function. Finally, we exemplify the MCP algorithm on a variety of synthetic and real-world datasets, including using black-box pre-trained classifiers to detect changes in sequences of images, text, and accelerometer data.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.00292v5</guid>
      <category>math.ST</category>
      <category>eess.SP</category>
      <category>stat.ME</category>
      <category>stat.TH</category>
      <pubDate>Fri, 20 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Sanjit Dandapanthula, Aaditya Ramdas</dc:creator>
    </item>
    <item>
      <title>A Note on Inferential Decisions, Errors and Path-Dependency</title>
      <link>https://arxiv.org/abs/2507.05634</link>
      <description>arXiv:2507.05634v5 Announce Type: replace 
Abstract: Consider the sequential testing of binary outcomes. The a posteriori belief process and its objective conditional-probability counterpart generally differ but converge to the same result in well-defined tests. We show that unless the two processes are 'essentially identical', differing only by an a priori factor, time-homogeneous continuous decisions based on the former are path-dependent with respect to state-variables based on the latter or any other non-essentially-identical processes. Inferential error decomposes into a path-dependent and a path-independent component, whose distinct properties are relevant to error mitigation.</description>
      <guid isPermaLink="false">oai:arXiv.org:2507.05634v5</guid>
      <category>math.ST</category>
      <category>stat.TH</category>
      <pubDate>Fri, 20 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Kangda K. Wren</dc:creator>
    </item>
    <item>
      <title>Self-Normalization for CUSUM-based Change Detection in Locally Stationary Time Series</title>
      <link>https://arxiv.org/abs/2509.07112</link>
      <description>arXiv:2509.07112v2 Announce Type: replace 
Abstract: A new self-normalized CUSUM test is proposed for detecting changes in the mean of a locally stationary time series. For stationary data, self-normalization relies on the factorization of a constant long-run variance and a stochastic factor. In this case, the CUSUM statistic can be divided by another statistic proportional to the long-run variance, so that the latter cancels, avoiding estimation of the long-run variance. Under local stationarity, the partial sum process converges to $\int_0^t \sigma(x) d B_x$ and no such factorization is possible. To overcome this obstacle, a self-normalized test statistic is introduced, based on a bivariate partial-sum process. Weak convergence of the process is proven, and it is shown that the resulting self-normalized test attains asymptotic level $\alpha$ under the null hypothesis of no change, while being consistent against abrupt, gradual, and multiple changes under mild assumptions. Simulation studies show that the proposed test has accurate size and substantially improved finite-sample power relative to existing approaches. Two data examples illustrate practical performance.</description>
      <guid isPermaLink="false">oai:arXiv.org:2509.07112v2</guid>
      <category>math.ST</category>
      <category>stat.ME</category>
      <category>stat.TH</category>
      <pubDate>Fri, 20 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Florian Heinrichs</dc:creator>
    </item>
    <item>
      <title>The Unseen Species Problem Revisited</title>
      <link>https://arxiv.org/abs/2602.08769</link>
      <description>arXiv:2602.08769v2 Announce Type: replace 
Abstract: The unseen species problem is a classical problem in statistics. It asks us to, given $n$ i.i.d. samples from an unknown discrete distribution over an unknown set, predict how many never before seen outcomes would be observed if $m$ additional samples were collected. For small $m$ we show the classical but poorly understood Good-Toulmin estimator to be minimax optimal to within a factor $2$ and resolve the open problem of constructing principled prediction intervals for it. For intermediate $m$ we propose a new estimator and, if one is willing to insist on respecting a certain problem symmetry, we get a pre-asymptotic optimality result up to an explicit multiplicative constant. This is in contrast to a pre-existing asymptotic result with an unknown constant in the exponent for the Smoothed Good-Toulmin estimator (SGTE). Our estimator vastly outperforms the standard SGTE in the worst case and performs substantially better on several real data sets, namely those with many rare species. For large $m$ we follow previous authors in assuming a power law tail and show that an older estimator without known rate guarantees actually achieves a marginally better rate than subsequent work. Moreover, we give a pre-asymptotic tail bound, in contrast with the purely asymptotic results in that subsequent work.
  We show in all three regimes that the same methods also achieve the same rate on incidence data, without further independence assumptions, provided that the sets are of bounded size. We establish, by means of bounded size biased couplings, concentration for some natural functionals of sequences of i.i.d. discrete-set-valued random variables which may be of independent interest.</description>
      <guid isPermaLink="false">oai:arXiv.org:2602.08769v2</guid>
      <category>math.ST</category>
      <category>stat.TH</category>
      <pubDate>Fri, 20 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Edward Eriksson</dc:creator>
    </item>
    <item>
      <title>The Sample Complexity of Lossless Data Compression</title>
      <link>https://arxiv.org/abs/2601.06688</link>
      <description>arXiv:2601.06688v2 Announce Type: replace-cross 
Abstract: A new framework is introduced for examining and evaluating the fundamental limits of lossless data compression, that emphasizes genuinely non-asymptotic results. The {\em sample complexity} of compressing a given source is defined as the smallest blocklength at which it is possible to compress that source at a specified rate and to within a specified excess-rate probability. This formulation parallels corresponding developments in statistics and computer science, and it facilitates the use of existing results on the sample complexity of various hypothesis testing problems. For arbitrary sources, the sample complexity of general variable-length compressors is shown to be tightly coupled with the sample complexity of prefix-free codes and fixed-length codes. For memoryless sources, it is shown that the sample complexity is characterized not by the source entropy, but by its R\'{e}nyi entropy of order~$1/2$. Nonasymptotic bounds on the sample complexity are obtained, with explicit constants. Generalizations to Markov sources are established, showing that the sample complexity is determined by the source's R\'{e}nyi entropy rate of order~$1/2$. Finally, bounds on the sample complexity of universal data compression are developed for arbitrary families of memoryless sources. There, the sample complexity is characterized by the minimum R\'{e}nyi divergence of order~$1/2$ between elements of the family and the uniform distribution. The connection of this problem with identity testing and with the associated separation rates is explored and discussed.</description>
      <guid isPermaLink="false">oai:arXiv.org:2601.06688v2</guid>
      <category>cs.IT</category>
      <category>math.IT</category>
      <category>math.ST</category>
      <category>stat.TH</category>
      <pubDate>Fri, 20 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Terence Viaud, Ioannis Kontoyiannis</dc:creator>
    </item>
    <item>
      <title>Locally Gentle State Certification for High Dimensional Quantum Systems</title>
      <link>https://arxiv.org/abs/2602.04550</link>
      <description>arXiv:2602.04550v2 Announce Type: replace-cross 
Abstract: Standard approaches to quantum statistical inference rely on measurements that induce a collapse of the wave function, effectively consuming the quantum state to extract information. In this work, we investigate the fundamental limits of \emph{locally-gentle} quantum state certification, where the learning algorithm is constrained to perturb the state by at most $\alpha$ in trace norm, thereby allowing for the reuse of samples. We analyze the hypothesis testing problem of distinguishing whether an unknown state $\rho$ is equal to a reference $\rho_0$ or $\epsilon$-far from it. We derive the minimax sample complexity for this problem, quantifying the information-theoretic price of non-destructive measurements. Specifically, by constructing explicit measurement operators, we show that the constraint of $\alpha$-gentleness imposes a sample size penalty of $\frac{d}{\alpha^2}$, yielding a total sample complexity of $n = \Theta(\frac{d^3}{\epsilon^2 \alpha^2})$. Our results clarify the trade-off between information extraction and state disturbance, and highlight deep connections between physical measurement constraints and privacy mechanisms in quantum learning. Crucially, we find that the sample size penalty incurred by enforcing $\alpha$-gentleness scales linearly with the Hilbert-space dimension $d$ rather than the number of parameters $d^2-1$ typical for high-dimensional private estimation.</description>
      <guid isPermaLink="false">oai:arXiv.org:2602.04550v2</guid>
      <category>quant-ph</category>
      <category>math.ST</category>
      <category>stat.TH</category>
      <pubDate>Fri, 20 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Cristina Butucea, Jan Johannes, Henning Stein</dc:creator>
    </item>
  </channel>
</rss>
