<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>math.OC updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/math.OC</link>
    <description>math.OC updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/math.OC" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Wed, 12 Feb 2025 05:00:58 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Wed, 12 Feb 2025 00:00:00 -0500</pubDate>
    <skipDays>
      <day>Sunday</day>
      <day>Saturday</day>
    </skipDays>
    <item>
      <title>Dual Conic Proxy for Semidefinite Relaxation of AC Optimal Power Flow</title>
      <link>https://arxiv.org/abs/2502.06978</link>
      <description>arXiv:2502.06978v1 Announce Type: new 
Abstract: The nonlinear, non-convex AC Optimal Power Flow (AC-OPF) problem is fundamental for power systems operations. The intrinsic complexity of AC-OPF has fueled a growing interest in the development of optimization proxies for the problem, i.e., machine learning models that predict high-quality, close-to-optimal solutions. More recently, dual conic proxy architectures have been proposed, which combine machine learning and convex relaxations of AC-OPF, to provide valid certificates of optimality using learning-based methods. Building on this methodology, this paper proposes, for the first time, a dual conic proxy architecture for the semidefinite (SDP) relaxation of AC-OPF problems. Although the SDP relaxation is stronger than the second-order cone relaxation considered in previous work, its practical use has been hindered by its computational cost. The proposed method combines a neural network with a differentiable dual completion strategy that leverages the structure of the dual SDP problem. This approach guarantees dual feasibility, and therefore valid dual bounds, while providing orders of magnitude of speedups compared to interior-point algorithms. The paper also leverages self-supervised learning, which alleviates the need for time-consuming data generation and allows to train the proposed models efficiently. Numerical experiments are presented on several power grid benchmarks with up to 500 buses. The results demonstrate that the proposed SDP-based proxies can outperform weaker conic relaxations, while providing several orders of magnitude speedups compared to a state-of-the-art interior-point SDP solver.</description>
      <guid isPermaLink="false">oai:arXiv.org:2502.06978v1</guid>
      <category>math.OC</category>
      <category>cs.LG</category>
      <pubDate>Wed, 12 Feb 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Guancheng Qiu, Mathieu Tanneau, Pascal Van Hentenryck</dc:creator>
    </item>
    <item>
      <title>Control on Hilbert Space and Mean Field Control: the Common Noise Case</title>
      <link>https://arxiv.org/abs/2502.07051</link>
      <description>arXiv:2502.07051v1 Announce Type: new 
Abstract: The objective of this paper is to provide an equivalent of the theory developed in P.~Cardaliaguet, F.~Delarue, J.M.~Lasry, P.L.~Lions \cite{CDLL}, following the approach of control on Hilbert spaces introduced by the authors in \cite{BGY-2}. We include the common noise in this paper, so the alternative is now complete. Since we consider a control problem, our theory applies only to Mean field control and not to mean field games. The assumptions are adapted to guarantee a unique optimal control, so they insure that the cost functional is strictly convex and coercive.</description>
      <guid isPermaLink="false">oai:arXiv.org:2502.07051v1</guid>
      <category>math.OC</category>
      <category>math.AP</category>
      <pubDate>Wed, 12 Feb 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Alain Bensoussan, P. Jameson Graber, Phillip Yam</dc:creator>
    </item>
    <item>
      <title>Nonlinear Open-Loop Mean field Stackelberg Stochastic Differential Game</title>
      <link>https://arxiv.org/abs/2502.07390</link>
      <description>arXiv:2502.07390v1 Announce Type: new 
Abstract: This paper studies a nonlinear open-loop mean field Stackelberg stochastic differential game by using the probabilistic method through the FBSDE system and the idea of taking control as the fixed point. We successively construct the decentralized optimal control problems for the followers and the leader, among which the leader's decentralized optimal control problem is a partial information optimal control problem with the fully coupled conditional mean-field forward-backward stochastic differential equation (FBSDE, in short) as the state equation. We successively derive the maximum principles for the corresponding decentralized optimal control problems of the followers and the leader. To obtain the existence, uniqueness and estimations of solutions of the state equation, the variational equation and the adjoint equation for the leader's decentralized optimal control problem, we study the well-posedness of a new form of conditional mean-field FBSDE. Finally, the decentralized optimal controls of the leader and followers are proved to be the approximate Stackelberg equilibrium of the nonlinear mean field Stackelberg game.</description>
      <guid isPermaLink="false">oai:arXiv.org:2502.07390v1</guid>
      <category>math.OC</category>
      <pubDate>Wed, 12 Feb 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Jianhui Huang, Qi Huang</dc:creator>
    </item>
    <item>
      <title>Enhancing finite-difference based derivative-free optimization methods with machine learning</title>
      <link>https://arxiv.org/abs/2502.07435</link>
      <description>arXiv:2502.07435v1 Announce Type: new 
Abstract: Derivative-Free Optimization (DFO) involves methods that rely solely on evaluations of the objective function. One of the earliest strategies for designing DFO methods is to adapt first-order methods by replacing gradients with finite-difference approximations. The execution of such methods generates a rich dataset about the objective function, including iterate points, function values, approximate gradients, and successful step sizes. In this work, we propose a simple auxiliary procedure to leverage this dataset and enhance the performance of finite-difference-based DFO methods. Specifically, our procedure trains a surrogate model using the available data and applies the gradient method with Armijo line search to the surrogate until it fails to ensure sufficient decrease in the true objective function, in which case we revert to the original algorithm and improve our surrogate based on the new available information. As a proof of concept, we integrate this procedure with the derivative-free method proposed in (Optim. Lett. 18: 195--213, 2024). Numerical results demonstrate significant performance improvements, particularly when the approximate gradients are also used to train the surrogates.</description>
      <guid isPermaLink="false">oai:arXiv.org:2502.07435v1</guid>
      <category>math.OC</category>
      <pubDate>Wed, 12 Feb 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Timoth\'e Taminiau, Estelle Massart, Geovani Nunes Grapiglia</dc:creator>
    </item>
    <item>
      <title>Optimization Methods for Joint Eigendecomposition</title>
      <link>https://arxiv.org/abs/2502.07484</link>
      <description>arXiv:2502.07484v1 Announce Type: new 
Abstract: Joint diagonalization, the process of finding a shared set of approximate eigenvectors for a collection of matrices, arises in diverse applications such as multidimensional harmonic analysis or quantum information theory. This task is typically framed as an optimization problem: minimizing a non-convex function that quantifies off-diagonal matrix elements across possible bases. In this work, we introduce a suite of efficient algorithms designed to locate local minimizers of this functional. Our methods leverage the Hessian's structure to bypass direct computation of second-order derivatives, evaluating it as either an operator or bilinear form - a strategy that remains computationally feasible even for large-scale applications. Additionally, we demonstrate that this Hessian-based information enables precise estimation of parameters, such as step-size, in first-order optimization techniques like Gradient Descent and Conjugate Gradient, and the design of second-order methods such as (Quasi-)Newton. The resulting algorithms for joint diagonalization outperform existing techniques, and we provide comprehensive numerical evidence of their superior performance.</description>
      <guid isPermaLink="false">oai:arXiv.org:2502.07484v1</guid>
      <category>math.OC</category>
      <pubDate>Wed, 12 Feb 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Erik Troedsson, Marcus Carlsson, Herwig Wendt</dc:creator>
    </item>
    <item>
      <title>Approximate Energetic Resilience of Nonlinear Systems under Partial Loss of Control Authority</title>
      <link>https://arxiv.org/abs/2502.07603</link>
      <description>arXiv:2502.07603v1 Announce Type: new 
Abstract: In this paper, we quantify the resilience of nonlinear dynamical systems by studying the increased energy used by all inputs of a system that suffers a partial loss of control authority, either through actuator malfunctions or through adversarial attacks. To quantify the maximal increase in energy, we introduce the notion of an energetic resilience metric. Prior work in this particular setting considers only simple linear models and not general nonlinear dynamical systems. We first characterize the mean value of the control signal in both the nominal and malfunctioning systems, which allows us to approximate the energy in the control. We then obtain a worst-case approximation of this energy for the malfunctioning system, over all malfunctioning inputs. Based on this approximation, we derive bounds on the energetic resilience metric when control authority is lost over one actuator. A simulation example on an academic nonlinear system demonstrates that the metric is useful in quantifying the resilience of the system without significant conservatism, despite the approximations used in obtaining control energies.</description>
      <guid isPermaLink="false">oai:arXiv.org:2502.07603v1</guid>
      <category>math.OC</category>
      <pubDate>Wed, 12 Feb 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Ram Padmanabhan, Melkior Ornik</dc:creator>
    </item>
    <item>
      <title>A physical model approach to order lot sizing</title>
      <link>https://arxiv.org/abs/2502.06856</link>
      <description>arXiv:2502.06856v1 Announce Type: cross 
Abstract: The growing need for companies to reduce costs and maximize profits has led to an increased focus on logistics activities. Among these, inventory management plays a crucial role in minimizing organizational expenses by optimizing the storage and transportation of materials. In this context, this study introduces an optimization model for the lot-sizing problem based on a physical system approach. By establishing that the material supply problem is isomorphic to a one-dimensional mechanical system of point particles connected by elastic elements, we leverage this analogy to derive cost optimization conditions naturally and obtain an exact solution. This approach determines lot sizes that minimize the combined ordering and inventory holding costs in a significantly shorter time, eliminating the need for heuristic methods. The optimal lot sizes are defined in terms of the parameter $ \gamma = 2C_O / C_H $, which represents the relationship between the ordering cost per order ($ C_O $) and the holding cost per period for the material required in one period ($ C_H $). This parameter fully dictates the system's behavior: when $ \gamma \leq 1 $, the optimal strategy is to place one order per period, whereas for $ \gamma &gt; 1 $, the number of orders $ N $ is reduced relative to the planning horizon $ M $, meaning $ N &lt; M $. By formulating the total cost function in terms of the intensive variable $ N/M $, we consolidate the entire optimization problem into a single function of $ \gamma $. This eliminates the need for complex algorithms, enabling faster and more precise purchasing decisions. The proposed model was validated through a real-world case study and benchmarked against classical algorithms, demonstrating superior cost optimization and reduced execution time. These findings underscore the potential of this approach for improving material lot-sizing strategies.</description>
      <guid isPermaLink="false">oai:arXiv.org:2502.06856v1</guid>
      <category>physics.app-ph</category>
      <category>math.OC</category>
      <pubDate>Wed, 12 Feb 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Tania Daiana Tobares, Margarita Miguelina Mieras, Fabricio Orlando Sanchez Varretti, Jos\'e Luis Iguain, Antonio Jos\'e Ramirez-Pastor</dc:creator>
    </item>
    <item>
      <title>Optimal Steady-State Secondary Control of MT-HVdc Grids with Reduced Communications</title>
      <link>https://arxiv.org/abs/2502.07102</link>
      <description>arXiv:2502.07102v1 Announce Type: cross 
Abstract: In this paper, we propose a centralized secondary control for the real-time steady-state optimization of multi-terminal HVdc grids under voltage and current limits. First, we present the dynamic models of the grid components, including the modular multilevel converter (MMC) stations and their different control layers. We also derive the quasi-static input-output model of the system, which is suitable for the steady-state control design. Second, we formulate a general optimization problem using this quasi-static model and find the Karush-Kuhn-Tucker optimality conditions of its solutions. Third, we propose a secondary control based on primal-dual dynamics to adjust the voltage setpoints of the dispatchable MMCs, with which the system asymptotically converges to a steady state that satisfies these optimality conditions. Fourth, we provide a communication triggering mechanism to reduce the communication traffic between the secondary control unit and the MMC stations. Finally, we verify our proposal for different case studies by adapting it to an offshore multi-terminal HVdc grid composed of heterogeneous MMC stations simulated in the MATLAB/Simulink environment. The problems of proportional current minimization and loss reduction are two special case studies.</description>
      <guid isPermaLink="false">oai:arXiv.org:2502.07102v1</guid>
      <category>eess.SY</category>
      <category>cs.SY</category>
      <category>math.OC</category>
      <pubDate>Wed, 12 Feb 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Babak Abdolmaleki, Gilbert Bergna-Diaz</dc:creator>
    </item>
    <item>
      <title>Online Covariance Matrix Estimation in Sketched Newton Methods</title>
      <link>https://arxiv.org/abs/2502.07114</link>
      <description>arXiv:2502.07114v1 Announce Type: cross 
Abstract: Given the ubiquity of streaming data, online algorithms have been widely used for parameter estimation, with second-order methods particularly standing out for their efficiency and robustness. In this paper, we study an online sketched Newton method that leverages a randomized sketching technique to perform an approximate Newton step in each iteration, thereby eliminating the computational bottleneck of second-order methods. While existing studies have established the asymptotic normality of sketched Newton methods, a consistent estimator of the limiting covariance matrix remains an open problem. We propose a fully online covariance matrix estimator that is constructed entirely from the Newton iterates and requires no matrix factorization. Compared to covariance estimators for first-order online methods, our estimator for second-order methods is batch-free. We establish the consistency and convergence rate of our estimator, and coupled with asymptotic normality results, we can then perform online statistical inference for the model parameters based on sketched Newton methods. We also discuss the extension of our estimator to constrained problems, and demonstrate its superior performance on regression problems as well as benchmark problems in the CUTEst set.</description>
      <guid isPermaLink="false">oai:arXiv.org:2502.07114v1</guid>
      <category>stat.ML</category>
      <category>cs.LG</category>
      <category>cs.NA</category>
      <category>math.NA</category>
      <category>math.OC</category>
      <category>stat.CO</category>
      <pubDate>Wed, 12 Feb 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Wei Kuang, Mihai Anitescu, Sen Na</dc:creator>
    </item>
    <item>
      <title>Online Scheduling for LLM Inference with KV Cache Constraints</title>
      <link>https://arxiv.org/abs/2502.07115</link>
      <description>arXiv:2502.07115v1 Announce Type: cross 
Abstract: Large Language Model (LLM) inference, where a trained model generates text one word at a time in response to user prompts, is a computationally intensive process requiring efficient scheduling to optimize latency and resource utilization. A key challenge in LLM inference is the management of the Key-Value (KV) cache, which reduces redundant computations but introduces memory constraints. In this work, we model LLM inference with KV cache constraints theoretically and propose novel batching and scheduling algorithms that minimize inference latency while effectively managing the KV cache's memory.
  We analyze both semi-online and fully online scheduling models, and our results are threefold. First, we provide a polynomial-time algorithm that achieves exact optimality in terms of average latency in the semi-online prompt arrival model. Second, in the fully online case with a stochastic prompt arrival, we introduce an efficient online scheduling algorithm with constant regret. Third, we prove that no algorithm (deterministic or randomized) can achieve a constant competitive ratio in fully online adversarial settings. Our empirical evaluations on a public LLM inference dataset, using the Llama-70B model on A100 GPUs, show that our approach significantly outperforms benchmark algorithms used currently in practice, achieving lower latency while reducing energy consumption. Overall, our results offer a path toward more sustainable and cost-effective LLM deployment.</description>
      <guid isPermaLink="false">oai:arXiv.org:2502.07115v1</guid>
      <category>cs.LG</category>
      <category>cs.AI</category>
      <category>math.OC</category>
      <pubDate>Wed, 12 Feb 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Patrick Jaillet, Jiashuo Jiang, Chara Podimata, Zijie Zhou</dc:creator>
    </item>
    <item>
      <title>On properties driving diversity index selection</title>
      <link>https://arxiv.org/abs/2502.07426</link>
      <description>arXiv:2502.07426v1 Announce Type: cross 
Abstract: Phylogenies are commonly used to represent the evolutionary relationships between species, and often these phylogenies are equipped with edge lengths that indicate degrees of evolutionary difference. Given such a phylogeny, a popular measure for the biodiversity of a subset of the species is the phylogenetic diversity (PD). But if we want to focus conservation efforts on particular species, we may use a phylogenetic diversity index, a function that shares out the PD value of an entire phylogeny across all of its species. With these indices, various species-level conservation strategies can be evaluated. This work explores how the most suitable diversity indices can be found. In particular, how formalizing the requirement for diversity indices to capture high levels of PD, or to maintain a scoring of taxa in the presence of uncertain edge lengths drives the selection of a suitable index. Furthermore, we provide illustrations of these new mechanisms for diversity index selection in a case study. This analysis includes the comparison to popular phylogenetic indices from the conservation literature.</description>
      <guid isPermaLink="false">oai:arXiv.org:2502.07426v1</guid>
      <category>q-bio.PE</category>
      <category>math.OC</category>
      <pubDate>Wed, 12 Feb 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Martin Frohn, Kerry Manson</dc:creator>
    </item>
    <item>
      <title>Training Deep Learning Models with Norm-Constrained LMOs</title>
      <link>https://arxiv.org/abs/2502.07529</link>
      <description>arXiv:2502.07529v1 Announce Type: cross 
Abstract: In this work, we study optimization methods that leverage the linear minimization oracle (LMO) over a norm-ball. We propose a new stochastic family of algorithms that uses the LMO to adapt to the geometry of the problem and, perhaps surprisingly, show that they can be applied to unconstrained problems. The resulting update rule unifies several existing optimization methods under a single framework. Furthermore, we propose an explicit choice of norm for deep architectures, which, as a side benefit, leads to the transferability of hyperparameters across model sizes. Experimentally, we demonstrate significant speedups on nanoGPT training without any reliance on Adam. The proposed method is memory-efficient, requiring only one set of model weights and one set of gradients, which can be stored in half-precision.</description>
      <guid isPermaLink="false">oai:arXiv.org:2502.07529v1</guid>
      <category>cs.LG</category>
      <category>math.OC</category>
      <pubDate>Wed, 12 Feb 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Thomas Pethick, Wanyun Xie, Kimon Antonakopoulos, Zhenyu Zhu, Antonio Silveti-Falls, Volkan Cevher</dc:creator>
    </item>
    <item>
      <title>An Improved Optimal Proximal Gradient Algorithm for Non-Blind Image Deblurring</title>
      <link>https://arxiv.org/abs/2502.07602</link>
      <description>arXiv:2502.07602v1 Announce Type: cross 
Abstract: Image deblurring remains a central research area within image processing, critical for its role in enhancing image quality and facilitating clearer visual representations across diverse applications. This paper tackles the optimization problem of image deblurring, assuming a known blurring kernel. We introduce an improved optimal proximal gradient algorithm (IOptISTA), which builds upon the optimal gradient method and a weighting matrix, to efficiently address the non-blind image deblurring problem. Based on two regularization cases, namely the $l_1$ norm and total variation norm, we perform numerical experiments to assess the performance of our proposed algorithm. The results indicate that our algorithm yields enhanced PSNR and SSIM values, as well as a reduced tolerance, compared to existing methods.</description>
      <guid isPermaLink="false">oai:arXiv.org:2502.07602v1</guid>
      <category>cs.CV</category>
      <category>math.OC</category>
      <pubDate>Wed, 12 Feb 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Qingsong Wang, Shengze Xu, Xiaojiao Tong, Tieyong Zeng</dc:creator>
    </item>
    <item>
      <title>Online matching and market imbalance</title>
      <link>https://arxiv.org/abs/2502.07731</link>
      <description>arXiv:2502.07731v1 Announce Type: cross 
Abstract: Our work introduces the effect of supply/demand imbalances into the literature on online matching with stochastic rewards in bipartite graphs. We provide a parameterized definition that characterizes instances as over- or undersupplied (or balanced), and show that higher competitive ratios against an offline clairvoyant algorithm are achievable, for both adversarial and stochastic arrivals, when instances are more imbalanced. The competitive ratio guarantees we obtain are the best-possible for the class of delayed algorithms we focus on (such algorithms may adapt to the history of arrivals and the algorithm's own decisions, but not to the stochastic realization of each potential match).
  We then explore the real-world implications of our improved competitive ratios. First, we demonstrate analytically that the improved competitive ratios under imbalanced instances is not a one-way street by showing that a platform that conducts effective supply- and demand management should incorporate the effect of imbalance on its matching performance on its supply planning in order to create imbalanced instances. Second, we empirically study the relationship between achieved competitive ratios and imbalance using the data of a volunteer matching platform.</description>
      <guid isPermaLink="false">oai:arXiv.org:2502.07731v1</guid>
      <category>cs.DS</category>
      <category>math.OC</category>
      <pubDate>Wed, 12 Feb 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Benjamin Barrientos, Daniel Freund, Daniela Saban</dc:creator>
    </item>
    <item>
      <title>EIQP: Execution-time-certified and Infeasibility-detecting QP Solver</title>
      <link>https://arxiv.org/abs/2502.07738</link>
      <description>arXiv:2502.07738v1 Announce Type: cross 
Abstract: Solving real-time quadratic programming (QP) is a ubiquitous task in control engineering, such as in model predictive control and control barrier function-based QP. In such real-time scenarios, certifying that the employed QP algorithm can either return a solution within a predefined level of optimality or detect QP infeasibility before the predefined sampling time is a pressing requirement. This article considers convex QP and adopts its homogeneous formulation to achieve infeasibility detection. Exploiting this homogeneous formulation, this article proposes a novel infeasible interior-point method (IPM) algorithm with the best theoretical $O(\sqrt{n})$ iteration complexity that feasible IPM algorithms enjoy. The iteration complexity is proved to be \textit{exact} (rather than an upper bound), \textit{simple to calculate}, and \textit{data independent}, with the value $\left\lceil\frac{\log(\frac{n+1}{\epsilon})}{-\log(1-\frac{0.414213}{\sqrt{n+1}})}\right\rceil$ (where $n$ and $\epsilon$ denote the number of constraints and the predefined optimality level, respectively), making it appealing to certify the execution time of online time-varying convex QPs. The proposed algorithm is simple to implement without requiring a line search procedure (uses the full Newton step), and its C-code implementation (offering MATLAB, Julia, and Python interfaces) and numerical examples are publicly available at https://github.com/liangwu2019/EIQP.</description>
      <guid isPermaLink="false">oai:arXiv.org:2502.07738v1</guid>
      <category>eess.SY</category>
      <category>cs.SY</category>
      <category>math.OC</category>
      <pubDate>Wed, 12 Feb 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Liang Wu, Wei Xiao, Richard D. Braatz</dc:creator>
    </item>
    <item>
      <title>Compressed Gradient Tracking Algorithms for Distributed Nonconvex Optimization</title>
      <link>https://arxiv.org/abs/2310.18871</link>
      <description>arXiv:2310.18871v4 Announce Type: replace 
Abstract: In this paper, we study the distributed nonconvex optimization problem, which aims to minimize the average value of the local nonconvex cost functions using local information exchange. To reduce the communication overhead, we introduce three general classes of compressors, i.e., compressors with bounded relative compression error, compressors with globally bounded absolute compression error, and compressors with locally bounded absolute compression error. By integrating them with distributed gradient tracking algorithm, we then propose three compressed distributed nonconvex optimization algorithms. For each algorithm, we design a novel Lyapunov function to demonstrate its sublinear convergence to a stationary point if the local cost functions are smooth. Furthermore, when the global cost function satisfies the Polyak--{\L}ojasiewicz (P--{\L}) condition, we show that our proposed algorithms linearly converge to a global optimal point. It is worth noting that, for compressors with bounded relative compression error and globally bounded absolute compression error, our proposed algorithms' parameters do not require prior knowledge of the P--{\L} constant. The theoretical results are illustrated by numerical examples, which demonstrate the effectiveness of the proposed algorithms in significantly reducing the communication burden while maintaining the convergence performance. Moreover, simulation results show that the proposed algorithms outperform state-of-the-art compressed distributed nonconvex optimization algorithms.</description>
      <guid isPermaLink="false">oai:arXiv.org:2310.18871v4</guid>
      <category>math.OC</category>
      <pubDate>Wed, 12 Feb 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Lei Xu, Xinlei Yi, Guanghui Wen, Yang Shi, Karl H. Johansson, Tao Yang</dc:creator>
    </item>
    <item>
      <title>Complete Upper Bound Hierarchies for Spectral Minimum in Noncommutative Polynomial Optimization</title>
      <link>https://arxiv.org/abs/2402.02126</link>
      <description>arXiv:2402.02126v2 Announce Type: replace 
Abstract: This work focuses on finding the spectral minimum (ground state energy) of a noncommutative polynomial subject to a finite number of noncommutative polynomial constraints. Based on the Helton-McCullough Positivstellensatz, the Navascu\'es-Pironio-Ac\'in (NPA) hierarchy is the noncommutative analog of Lasserre's moment-sum of squares hierarchy and provides a sequence of lower bounds converging to the spectral minimum, under mild assumptions on the constraint set. Each lower bound can be obtained by solving a semidefinite program.
  This paper derives complementary complete hierarchies of upper bounds for the spectral minimum. They are noncommutative analogues of the upper bound hierarchies due to Lasserre for minimizing commutative polynomials over compact sets. Each upper bound is obtained by solving a generalized eigenvalue problem. The derived hierarchies apply to optimization problems in bounded and unbounded operator algebras, as demonstrated on a variety of examples.</description>
      <guid isPermaLink="false">oai:arXiv.org:2402.02126v2</guid>
      <category>math.OC</category>
      <category>math.FA</category>
      <category>quant-ph</category>
      <pubDate>Wed, 12 Feb 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Igor Klep, Victor Magron, Jurij Vol\v{c}i\v{c}</dc:creator>
    </item>
    <item>
      <title>Global weight optimization of frame structures under free-vibration eigenvalue constraints</title>
      <link>https://arxiv.org/abs/2405.08894</link>
      <description>arXiv:2405.08894v2 Announce Type: replace 
Abstract: Topology optimization of frame structures under free-vibration eigenvalue constraints constitutes a challenging nonconvex polynomial optimization problem with disconnected feasible sets. In this article, we first formulate it as a polynomial semidefinite programming problem (SDP) of minimizing a linear function over a basic semi-algebraic feasible set. We then propose to solve this problem by Lasserre hierarchy of linear semidefinite relaxations providing a sequence of increasing lower bounds. To obtain also a sequence of upper bounds and thus conditions on global $\varepsilon$-optimality, we propose a novel technique. Namely, we provide a bilevel reformulation that exhibits a special structure: The lower level is quasiconvex univariate and its solution satisfies the constraints of the upper-level problem. After deriving the conditions for the solvability of the lower-level problem, we thus provide a way to construct feasible points to the original SDP. Using such a feasible point, we modify the original nonlinear SDP to satisfy the conditions for the deployment of the Lasserre hierarchy. Solving arbitrary degree relaxation of the hierarchy, we prove that scaled first-order moments associated with the problem variables satisfy feasibility conditions for the lower-level problem and thus provide guaranteed upper and lower bounds on the objective function. Using these bounds, we develop a simple sufficient condition for global $\varepsilon$-optimality and prove that the optimality gap $\varepsilon$ converges to zero if the set of global minimizers is convex. Finally, we illustrate these results with three representative problems for which the hierarchy converges in at most four relaxation degrees.</description>
      <guid isPermaLink="false">oai:arXiv.org:2405.08894v2</guid>
      <category>math.OC</category>
      <pubDate>Wed, 12 Feb 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Marek Tyburec, Michal Ko\v{c}vara, Marouan Handa, Jan Zeman</dc:creator>
    </item>
    <item>
      <title>Accelerated Mirror Descent for Non-Euclidean Star-convex Functions</title>
      <link>https://arxiv.org/abs/2405.18976</link>
      <description>arXiv:2405.18976v2 Announce Type: replace 
Abstract: Acceleration for non-convex functions is a fundamental challenge in optimisation. We revisit star-convex functions, which are strictly unimodal on all lines through a minimizer. [1] accelerate unconstrained star-convex minimization of functions that are smooth with respect to the Euclidean norm. To do so, they add a certain binary search step to gradient descent. In this paper, we accelerate unconstrained star-convex minimization of functions that are weakly smooth with respect to an arbitrary norm. We add a binary search step to mirror descent, generalize the approach and refine its complexity analysis. We prove that our algorithms have sharp convergence rates for star-convex functions with $\alpha$-Holder continuous gradients and demonstrate that our rates are nearly optimal for $p$-norms.
  [1] Near-Optimal Methods for Minimizing Star-Convex Functions and Beyond, Hinder Oliver and Sidford Aaron and Sohoni Nimit</description>
      <guid isPermaLink="false">oai:arXiv.org:2405.18976v2</guid>
      <category>math.OC</category>
      <pubDate>Wed, 12 Feb 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Clement Lezane, Sophie Langer, Wouter M Koolen</dc:creator>
    </item>
    <item>
      <title>Why Study the Spherical Convexity of Non-Homogeneous Quadratic Functions, and What Makes It Surprising?</title>
      <link>https://arxiv.org/abs/2406.04205</link>
      <description>arXiv:2406.04205v2 Announce Type: replace 
Abstract: This paper presents necessary, sufficient, and equivalent conditions for the spherical convexity of non-homogeneous quadratic functions. In addition to motivating this study and identifying useful criteria for determining whether such functions are spherically convex, we discovered surprising properties that distinguish spherically convex quadratic functions from their geodesically convex counterparts in both hyperbolic and Euclidean spaces. Since spherically convex functions over the entire sphere are constant, we restricted our focus to proper spherically convex subsets of the sphere. Although most of our results pertain to non-homogeneous quadratic functions on the spherically convex set of unit vectors with positive coordinates, we also present findings for more general spherically convex sets. Beyond the general non-homogeneous quadratic functions, we consider explicit special cases where the matrix in the function's definition is of a specific type, such as positive, diagonal, and Z-matrix.</description>
      <guid isPermaLink="false">oai:arXiv.org:2406.04205v2</guid>
      <category>math.OC</category>
      <pubDate>Wed, 12 Feb 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>R. Bolton, S. Z. N\'emeth</dc:creator>
    </item>
    <item>
      <title>Multicriteria Optimization and Decision Making: Principles, Algorithms and Case Studies</title>
      <link>https://arxiv.org/abs/2407.00359</link>
      <description>arXiv:2407.00359v4 Announce Type: replace 
Abstract: Real-world decision and optimization problems, often involve constraints and conflicting criteria. For example, choosing a travel method must balance speed, cost, environmental footprint, and convenience. Similarly, designing an industrial process must consider safety, environmental impact, and cost efficiency. Ideal solutions where all objectives are optimally met are rare; instead, we seek good compromises and aim to avoid lose-lose scenarios. Multicriteria optimization offers computational techniques to compute Pareto optimal solutions, aiding decision analysis and decision making. This reader offers an introduction to this topic and has been developed on the basis of the revised edition of the reader for the MSc computer science course "Multicriteria Optimization and Decision Analysis" at the Leiden Institute of Advanced Computer Science, Leiden University, The Netherlands. This course was taught annually by the first author from 2007 to 2023 as a single semester course with lectures and practicals. Our aim was to make the material accessible to MSc students who do not study mathematics as their core discipline by introducing basic numerical analysis concepts when necessary and providing numerical examples for interesting cases. The introduction is organized in a unique didactic manner developed by the authors, starting from more simple concepts such as linear programming and single-point methods, and advancing from these to more difficult concepts such as optimality conditions for nonlinear optimization and set-oriented solution algorithms. Besides, we focus on the mathematical modeling and foundations rather than on specific algorithms, though not excluding the discussion of some representative examples of solution algorithms.</description>
      <guid isPermaLink="false">oai:arXiv.org:2407.00359v4</guid>
      <category>math.OC</category>
      <category>cs.NA</category>
      <category>math.NA</category>
      <pubDate>Wed, 12 Feb 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Michael Emmerich, Andr\'e Deutz</dc:creator>
    </item>
    <item>
      <title>Pointwise-Sparse Actuator Scheduling for Linear Systems with Controllability Guarantee</title>
      <link>https://arxiv.org/abs/2407.12125</link>
      <description>arXiv:2407.12125v3 Announce Type: replace 
Abstract: This paper considers the design of sparse actuator schedules for linear time-invariant systems. An actuator schedule selects, for each time instant, which control inputs act on the system in that instant. We address the optimal scheduling of control inputs under a hard constraint on the number of inputs that can be used at each time. For a sparsely controllable system, we characterize sparse actuator schedules that make the system controllable, and then devise a greedy selection algorithm that guarantees controllability while heuristically providing low control effort. We further show how to enhance our greedy algorithm via Markov chain Monte Carlo-based randomized optimization</description>
      <guid isPermaLink="false">oai:arXiv.org:2407.12125v3</guid>
      <category>math.OC</category>
      <category>cs.SY</category>
      <category>eess.SY</category>
      <pubDate>Wed, 12 Feb 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <arxiv:DOI>10.1109/LCSYS.2024.3475886</arxiv:DOI>
      <arxiv:journal_reference>IEEE Control Systems Letters, vol. 8, pp. 2361 - 2366, 2024</arxiv:journal_reference>
      <dc:creator>Luca Ballotta, Geethu Joseph, Irawati Rahul Thete</dc:creator>
    </item>
    <item>
      <title>Pessimistic bilevel optimization approach for decision-focused learning</title>
      <link>https://arxiv.org/abs/2501.16826</link>
      <description>arXiv:2501.16826v2 Announce Type: replace 
Abstract: The recent interest in contextual optimization problems, where randomness is associated with side information, has led to two primary strategies for formulation and solution. The first, estimate-then-optimize, separates the estimation of the problem's parameters from the optimization process. The second, decision-focused optimization, integrates the optimization problem's structure directly into the prediction procedure. In this work, we propose a pessimistic bilevel approach for solving general decision-focused formulations of combinatorial optimization problems. Our method solves an $\varepsilon$-approximation of the pessimistic bilevel problem using a specialized cut generation algorithm. We benchmark its performance on the 0-1 knapsack problem against estimate-then-optimize and decision-focused methods, including the popular SPO+ approach. Computational experiments highlight the proposed method's advantages, particularly in reducing out-of-sample regret.</description>
      <guid isPermaLink="false">oai:arXiv.org:2501.16826v2</guid>
      <category>math.OC</category>
      <category>cs.DM</category>
      <pubDate>Wed, 12 Feb 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Diego Jim\'enez, Bernardo K. Pagnoncelli, Hande Yaman</dc:creator>
    </item>
    <item>
      <title>On a conjecture with implications for multicriteria decision making</title>
      <link>https://arxiv.org/abs/2502.05180</link>
      <description>arXiv:2502.05180v2 Announce Type: replace 
Abstract: We prove a conjecture by Richard Soland that given an efficient solution to a multicriteria optimization problem, there need not exist a continuous, strictly increasing and strictly concave criterion space function that attains its maximum at the vector of criteria values achieved by that solution.</description>
      <guid isPermaLink="false">oai:arXiv.org:2502.05180v2</guid>
      <category>math.OC</category>
      <pubDate>Wed, 12 Feb 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Anas Mifrani</dc:creator>
    </item>
    <item>
      <title>Universal Neural Optimal Transport</title>
      <link>https://arxiv.org/abs/2212.00133</link>
      <description>arXiv:2212.00133v5 Announce Type: replace-cross 
Abstract: Optimal Transport (OT) problems are a cornerstone of many applications, but solving them is computationally expensive. To address this problem, we propose UNOT (Universal Neural Optimal Transport), a novel framework capable of accurately predicting (entropic) OT distances and plans between discrete measures of variable resolution for a given cost function. UNOT builds on Fourier Neural Operators, a universal class of neural networks that map between function spaces and that are discretization-invariant, which enables our network to process measures of varying sizes. The network is trained adversarially using a second, generating network and a self-supervised bootstrapping loss. We theoretically justify the use of FNOs, prove that our generator is universal, and that minimizing the bootstrapping loss provably minimizes the ground truth loss. Through extensive experiments, we show that our network not only accurately predicts optimal transport distances and plans across a wide range of datasets, but also captures the geometry of the Wasserstein space correctly. Furthermore, we show that our network can be used as a state-of-the-art initialization for the Sinkhorn algorithm, significantly outperforming existing approaches.</description>
      <guid isPermaLink="false">oai:arXiv.org:2212.00133v5</guid>
      <category>cs.LG</category>
      <category>math.OC</category>
      <category>stat.ML</category>
      <pubDate>Wed, 12 Feb 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Jonathan Geuter, Gregor Kornhardt, Ingimar Tomasson, Vaios Laschos</dc:creator>
    </item>
    <item>
      <title>Communication-Efficient Federated Optimization over Semi-Decentralized Networks</title>
      <link>https://arxiv.org/abs/2311.18787</link>
      <description>arXiv:2311.18787v3 Announce Type: replace-cross 
Abstract: In large-scale federated and decentralized learning, communication efficiency is one of the most challenging bottlenecks. While gossip communication -- where agents can exchange information with their connected neighbors -- is more cost-effective than communicating with the remote server, it often requires a greater number of communication rounds, especially for large and sparse networks. To tackle the trade-off, we examine the communication efficiency under a semi-decentralized communication protocol, in which agents can perform both agent-to-agent and agent-to-server communication in a probabilistic manner. We design a tailored communication-efficient algorithm over semi-decentralized networks, referred to as PISCO, which inherits the robustness to data heterogeneity thanks to gradient tracking and allows multiple local updates for saving communication. We establish the convergence rate of PISCO for nonconvex problems and show that PISCO enjoys a linear speedup in terms of the number of agents and local updates. Our numerical results highlight the superior communication efficiency of PISCO and its resilience to data heterogeneity and various network topologies.</description>
      <guid isPermaLink="false">oai:arXiv.org:2311.18787v3</guid>
      <category>cs.LG</category>
      <category>cs.DC</category>
      <category>math.OC</category>
      <pubDate>Wed, 12 Feb 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>He Wang, Yuejie Chi</dc:creator>
    </item>
    <item>
      <title>Dual Interior Point Optimization Learning</title>
      <link>https://arxiv.org/abs/2402.02596</link>
      <description>arXiv:2402.02596v2 Announce Type: replace-cross 
Abstract: In many practical applications of constrained optimization, scale and solving time limits make traditional optimization solvers prohibitively slow. Thus, the research question of how to design optimization proxies -- machine learning models that produce high-quality solutions -- has recently received significant attention. Orthogonal to this research thread which focuses on learning primal solutions, this paper studies how to learn dual feasible solutions that complement primal approaches and provide quality guarantees. The paper makes two distinct contributions. First, to train dual linear optimization proxies, the paper proposes a smoothed self-supervised loss function that augments the objective function with a dual penalty term. Second, the paper proposes a novel dual completion strategy that guarantees dual feasibility by solving a convex optimization problem. Moreover, the paper derives closed-form solutions to this completion optimization for several classes of dual penalties, eliminating the need for computationally-heavy implicit layers. Numerical results are presented on large linear optimization problems and demonstrate the effectiveness of the proposed approach. The proposed dual completion outperforms methods for learning optimization proxies which do not exploit the structure of the dual problem. Compared to commercial optimization solvers, the learned dual proxies achieve optimality gaps below $1\%$ and several orders of magnitude speedups.</description>
      <guid isPermaLink="false">oai:arXiv.org:2402.02596v2</guid>
      <category>cs.LG</category>
      <category>math.OC</category>
      <pubDate>Wed, 12 Feb 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <dc:creator>Michael Klamkin, Mathieu Tanneau, Pascal Van Hentenryck</dc:creator>
    </item>
    <item>
      <title>Reinforcement Learning from Human Feedback with Active Queries</title>
      <link>https://arxiv.org/abs/2402.09401</link>
      <description>arXiv:2402.09401v2 Announce Type: replace-cross 
Abstract: Aligning large language models (LLM) with human preference plays a key role in building modern generative models and can be achieved by reinforcement learning from human feedback (RLHF). Despite their superior performance, current RLHF approaches often require a large amount of human-labelled preference data, which is expensive to collect. In this paper, inspired by the success of active learning, we address this problem by proposing query-efficient RLHF methods. We first formalize the alignment problem as a contextual dueling bandit problem and design an active-query-based proximal policy optimization (APPO) algorithm with an $\tilde{O}(d^2/\Delta)$ instance-dependent regret bound and an $\tilde{O}(d^2/\Delta^2)$ query complexity, where $d$ is the dimension of feature space and $\Delta$ is the sub-optimality gap over all the contexts. We then propose ADPO, a practical version of our algorithm based on direct preference optimization (DPO) and apply it to fine-tuning LLMs. Our experiments show that ADPO, while only making about half of queries for human preference, matches the performance of the state-of-the-art DPO method.</description>
      <guid isPermaLink="false">oai:arXiv.org:2402.09401v2</guid>
      <category>cs.LG</category>
      <category>cs.AI</category>
      <category>cs.CL</category>
      <category>math.OC</category>
      <category>stat.ML</category>
      <pubDate>Wed, 12 Feb 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Kaixuan Ji, Jiafan He, Quanquan Gu</dc:creator>
    </item>
    <item>
      <title>Revealing hidden physical nonclassicality with nonnegative polynomials</title>
      <link>https://arxiv.org/abs/2403.09807</link>
      <description>arXiv:2403.09807v2 Announce Type: replace-cross 
Abstract: Understanding quantum phenomena which go beyond classical concepts is a focus of modern quantum physics. Here, we show how the theory of nonnegative polynomials emerging around Hilbert's 17th problem, can be used to optimally exploit data capturing the nonclassical nature of light. Specifically, we show that nonnegative polynomials can reveal nonclassicality in data even when it is hidden from standard detection methods up to now. Moreover, the abstract language of nonnegative polynomials also leads to a unified mathematical approach to nonclassicality for light and spin systems, allowing us to map methods for one to the other. Conversely, the physical problems arising also inspire several mathematical insights into characterisation of nonnegative polynomials.</description>
      <guid isPermaLink="false">oai:arXiv.org:2403.09807v2</guid>
      <category>quant-ph</category>
      <category>math.OC</category>
      <pubDate>Wed, 12 Feb 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <arxiv:DOI>10.1103/PhysRevLett.134.030201</arxiv:DOI>
      <arxiv:journal_reference>Phys. Rev. Lett. 134, 030201 (2025)</arxiv:journal_reference>
      <dc:creator>Ties-A. Ohst, Benjamin Yadin, Birte Ostermann, Timo de Wolff, Otfried G\"uhne, Hai-Chau Nguyen</dc:creator>
    </item>
    <item>
      <title>Drago: Primal-Dual Coupled Variance Reduction for Faster Distributionally Robust Optimization</title>
      <link>https://arxiv.org/abs/2403.10763</link>
      <description>arXiv:2403.10763v2 Announce Type: replace-cross 
Abstract: We consider the penalized distributionally robust optimization (DRO) problem with a closed, convex uncertainty set, a setting that encompasses learning using $f$-DRO and spectral/$L$-risk minimization. We present Drago, a stochastic primal-dual algorithm that combines cyclic and randomized components with a carefully regularized primal update to achieve dual variance reduction. Owing to its design, Drago enjoys a state-of-the-art linear convergence rate on strongly convex-strongly concave DRO problems with a fine-grained dependency on primal and dual condition numbers. Theoretical results are supported by numerical benchmarks on regression and classification tasks.</description>
      <guid isPermaLink="false">oai:arXiv.org:2403.10763v2</guid>
      <category>stat.ML</category>
      <category>cs.LG</category>
      <category>math.OC</category>
      <pubDate>Wed, 12 Feb 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Ronak Mehta, Jelena Diakonikolas, Zaid Harchaoui</dc:creator>
    </item>
    <item>
      <title>A priori error estimates for optimal control problems governed by the transient Stokes equations and subject to state constraints pointwise in time</title>
      <link>https://arxiv.org/abs/2407.20702</link>
      <description>arXiv:2407.20702v2 Announce Type: replace-cross 
Abstract: In this paper, we consider a state constrained optimal control problem governed by the transient Stokes equations. The state constraint is given by an L2 functional in space, which is required to fulfill a pointwise bound in time. The discretization scheme for the Stokes equations consists of inf-sup stable finite elements in space and a discontinuous Galerkin method in time, for which we have recently established best approximation type error estimates. Using these error estimates, for the discrete control problem we establish error estimates and as a by-product we show an improved regularity for the optimal control. We complement our theoretical analysis with numerical results.</description>
      <guid isPermaLink="false">oai:arXiv.org:2407.20702v2</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <category>math.OC</category>
      <pubDate>Wed, 12 Feb 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Dmitriy Leykekhman, Boris Vexler, Jakob Wagner</dc:creator>
    </item>
    <item>
      <title>The Plug-in Approach for Average-Reward and Discounted MDPs: Optimal Sample Complexity Analysis</title>
      <link>https://arxiv.org/abs/2410.07616</link>
      <description>arXiv:2410.07616v2 Announce Type: replace-cross 
Abstract: We study the sample complexity of the plug-in approach for learning $\varepsilon$-optimal policies in average-reward Markov decision processes (MDPs) with a generative model. The plug-in approach constructs a model estimate then computes an average-reward optimal policy in the estimated model. Despite representing arguably the simplest algorithm for this problem, the plug-in approach has never been theoretically analyzed. Unlike the more well-studied discounted MDP reduction method, the plug-in approach requires no prior problem information or parameter tuning. Our results fill this gap and address the limitations of prior approaches, as we show that the plug-in approach is optimal in several well-studied settings without using prior knowledge. Specifically it achieves the optimal diameter- and mixing-based sample complexities of $\widetilde{O}\left(SA \frac{D}{\varepsilon^2}\right)$ and $\widetilde{O}\left(SA \frac{\tau_{\mathrm{unif}}}{\varepsilon^2}\right)$, respectively, without knowledge of the diameter $D$ or uniform mixing time $\tau_{\mathrm{unif}}$. We also obtain span-based bounds for the plug-in approach, and complement them with algorithm-specific lower bounds suggesting that they are unimprovable. Our results require novel techniques for analyzing long-horizon problems which may be broadly useful and which also improve results for the discounted plug-in approach, removing effective-horizon-related sample size restrictions and obtaining the first optimal complexity bounds for the full range of sample sizes without reward perturbation.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.07616v2</guid>
      <category>cs.LG</category>
      <category>cs.IT</category>
      <category>math.IT</category>
      <category>math.OC</category>
      <category>stat.ML</category>
      <pubDate>Wed, 12 Feb 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Matthew Zurek, Yudong Chen</dc:creator>
    </item>
    <item>
      <title>Vertical Federated Learning with Missing Features During Training and Inference</title>
      <link>https://arxiv.org/abs/2410.22564</link>
      <description>arXiv:2410.22564v2 Announce Type: replace-cross 
Abstract: Vertical federated learning trains models from feature-partitioned datasets across multiple clients, who collaborate without sharing their local data. Standard approaches assume that all feature partitions are available during both training and inference. Yet, in practice, this assumption rarely holds, as for many samples only a subset of the clients observe their partition. However, not utilizing incomplete samples during training harms generalization, and not supporting them during inference limits the utility of the model. Moreover, if any client leaves the federation after training, its partition becomes unavailable, rendering the learned model unusable. Missing feature blocks are therefore a key challenge limiting the applicability of vertical federated learning in real-world scenarios. To address this, we propose LASER-VFL, a vertical federated learning method for efficient training and inference of split neural network-based models that is capable of handling arbitrary sets of partitions. Our approach is simple yet effective, relying on the sharing of model parameters and on task-sampling to train a family of predictors. We show that LASER-VFL achieves a $\mathcal{O}({1}/{\sqrt{T}})$ convergence rate for nonconvex objectives and, under the Polyak-{\L}ojasiewicz inequality, it achieves linear convergence to a neighborhood of the optimum. Numerical experiments show improved performance of LASER-VFL over the baselines. Remarkably, this is the case even in the absence of missing features. For example, for CIFAR-100, we see an improvement in accuracy of $18.2\%$ when each of four feature blocks is observed with a probability of 0.5 and of $7.4\%$ when all features are observed. The code for this work is available at https://github.com/Valdeira/LASER-VFL.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.22564v2</guid>
      <category>cs.LG</category>
      <category>cs.DC</category>
      <category>cs.DS</category>
      <category>math.OC</category>
      <pubDate>Wed, 12 Feb 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Pedro Valdeira, Shiqiang Wang, Yuejie Chi</dc:creator>
    </item>
    <item>
      <title>Neural Networks and (Virtual) Extended Formulations</title>
      <link>https://arxiv.org/abs/2411.03006</link>
      <description>arXiv:2411.03006v2 Announce Type: replace-cross 
Abstract: Neural networks with piecewise linear activation functions, such as rectified linear units (ReLU) or maxout, are among the most fundamental models in modern machine learning. We make a step towards proving lower bounds on the size of such neural networks by linking their representative capabilities to the notion of the extension complexity $\mathrm{xc}(P)$ of a polytope $P$. This is a well-studied quantity in combinatorial optimization and polyhedral geometry describing the number of inequalities needed to model $P$ as a linear program. We show that $\mathrm{xc}(P)$ is a lower bound on the size of any monotone or input-convex neural network that solves the linear optimization problem over $P$. This implies exponential lower bounds on such neural networks for a variety of problems, including the polynomially solvable maximum weight matching problem.
  In an attempt to prove similar bounds also for general neural networks, we introduce the notion of virtual extension complexity $\mathrm{vxc}(P)$, which generalizes $\mathrm{xc}(P)$ and describes the number of inequalities needed to represent the linear optimization problem over $P$ as a difference of two linear programs. We prove that $\mathrm{vxc}(P)$ is a lower bound on the size of any neural network that optimizes over $P$. While it remains an open question to derive useful lower bounds on $\mathrm{vxc}(P)$, we argue that this quantity deserves to be studied independently from neural networks by proving that one can efficiently optimize over a polytope $P$ using a small virtual extended formulation.</description>
      <guid isPermaLink="false">oai:arXiv.org:2411.03006v2</guid>
      <category>math.CO</category>
      <category>cs.CC</category>
      <category>cs.DM</category>
      <category>cs.LG</category>
      <category>math.OC</category>
      <pubDate>Wed, 12 Feb 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Christoph Hertrich, Georg Loho</dc:creator>
    </item>
    <item>
      <title>A Particle Algorithm for Mean-Field Variational Inference</title>
      <link>https://arxiv.org/abs/2412.20385</link>
      <description>arXiv:2412.20385v2 Announce Type: replace-cross 
Abstract: Variational inference is a fast and scalable alternative to Markov chain Monte Carlo and has been widely applied to posterior inference tasks in statistics and machine learning. A traditional approach for implementing mean-field variational inference (MFVI) is coordinate ascent variational inference (CAVI), which relies crucially on parametric assumptions on complete conditionals. In this paper, we introduce a novel particle-based algorithm for mean-field variational inference, which we term PArticle VI (PAVI). Notably, our algorithm does not rely on parametric assumptions on complete conditionals, and it applies to the nonparametric setting. We provide non-asymptotic finite-particle convergence guarantee for our algorithm. To our knowledge, this is the first end-to-end guarantee for particle-based MFVI.</description>
      <guid isPermaLink="false">oai:arXiv.org:2412.20385v2</guid>
      <category>math.ST</category>
      <category>cs.LG</category>
      <category>math.OC</category>
      <category>stat.ML</category>
      <category>stat.TH</category>
      <pubDate>Wed, 12 Feb 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Qiang Du, Kaizheng Wang, Edith Zhang, Chenyang Zhong</dc:creator>
    </item>
    <item>
      <title>GANQ: GPU-Adaptive Non-Uniform Quantization for Large Language Models</title>
      <link>https://arxiv.org/abs/2501.12956</link>
      <description>arXiv:2501.12956v2 Announce Type: replace-cross 
Abstract: Large Language Models (LLMs) face significant deployment challenges due to their substantial resource requirements. While low-bit quantized weights can reduce memory usage and improve inference efficiency, current hardware lacks native support for mixed-precision General Matrix Multiplication (mpGEMM), resulting in inefficient dequantization-based implementations. Moreover, uniform quantization methods often fail to capture weight distributions adequately, leading to performance degradation. We propose GANQ (GPU-Adaptive Non-Uniform Quantization), a layer-wise post-training non-uniform quantization framework optimized for hardware-efficient lookup table-based mpGEMM. GANQ achieves superior quantization performance by utilizing a training-free, GPU-adaptive optimization algorithm to efficiently reduce layer-wise quantization errors. Extensive experiments demonstrate GANQ's ability to reduce the perplexity gap from the FP16 baseline compared to state-of-the-art methods for both 3-bit and 4-bit quantization. Furthermore, when deployed on a single NVIDIA RTX 4090 GPU, GANQ's quantized models achieve up to 2.57$\times$ speedup over the baseline, advancing memory and inference efficiency in LLM deployment.</description>
      <guid isPermaLink="false">oai:arXiv.org:2501.12956v2</guid>
      <category>cs.LG</category>
      <category>cs.AI</category>
      <category>math.OC</category>
      <pubDate>Wed, 12 Feb 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Pengxiang Zhao, Xiaoming Yuan</dc:creator>
    </item>
    <item>
      <title>End-to-End Learning Framework for Solving Non-Markovian Optimal Control</title>
      <link>https://arxiv.org/abs/2502.04649</link>
      <description>arXiv:2502.04649v2 Announce Type: replace-cross 
Abstract: Integer-order calculus often falls short in capturing the long-range dependencies and memory effects found in many real-world processes. Fractional calculus addresses these gaps via fractional-order integrals and derivatives, but fractional-order dynamical systems pose substantial challenges in system identification and optimal control due to the lack of standard control methodologies. In this paper, we theoretically derive the optimal control via \textit{linear quadratic regulator} (LQR) for \textit{fractional-order linear time-invariant }(FOLTI) systems and develop an end-to-end deep learning framework based on this theoretical foundation. Our approach establishes a rigorous mathematical model, derives analytical solutions, and incorporates deep learning to achieve data-driven optimal control of FOLTI systems. Our key contributions include: (i) proposing an innovative system identification method control strategy for FOLTI systems, (ii) developing the first end-to-end data-driven learning framework, \textbf{F}ractional-\textbf{O}rder \textbf{L}earning for \textbf{O}ptimal \textbf{C}ontrol (FOLOC), that learns control policies from observed trajectories, and (iii) deriving a theoretical analysis of sample complexity to quantify the number of samples required for accurate optimal control in complex real-world problems. Experimental results indicate that our method accurately approximates fractional-order system behaviors without relying on Gaussian noise assumptions, pointing to promising avenues for advanced optimal control.</description>
      <guid isPermaLink="false">oai:arXiv.org:2502.04649v2</guid>
      <category>cs.SY</category>
      <category>cs.LG</category>
      <category>math.OC</category>
      <pubDate>Wed, 12 Feb 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Xiaole Zhang, Peiyu Zhang, Xiongye Xiao, Shixuan Li, Vasileios Tzoumas, Vijay Gupta, Paul Bogdan</dc:creator>
    </item>
  </channel>
</rss>
