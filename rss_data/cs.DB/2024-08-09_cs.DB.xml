<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>cs.DB updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/cs.DB</link>
    <description>cs.DB updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/cs.DB" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Fri, 09 Aug 2024 04:00:07 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Fri, 09 Aug 2024 00:00:00 -0400</pubDate>
    <skipDays>
      <day>Saturday</day>
      <day>Sunday</day>
    </skipDays>
    <item>
      <title>Programmable Dataflows: Abstraction and Programming Model for Data Sharing</title>
      <link>https://arxiv.org/abs/2408.04092</link>
      <description>arXiv:2408.04092v1 Announce Type: new 
Abstract: Data sharing is central to a wide variety of applications such as fraud detection, ad matching, and research. The lack of data sharing abstractions makes the solution to each data sharing problem bespoke and cost-intensive, hampering value generation. In this paper, we first introduce a data sharing model to represent every data sharing problem with a sequence of dataflows. From the model, we distill an abstraction, the contract, which agents use to communicate the intent of a dataflow and evaluate its consequences, before the dataflow takes place. This helps agents move towards a common sharing goal without violating any regulatory and privacy constraints. Then, we design and implement the contract programming model (CPM), which allows agents to program data sharing applications catered to each problem's needs.
  Contracts permit data sharing, but their interactive nature may introduce inefficiencies. To mitigate those inefficiencies, we extend the CPM so that it can save intermediate outputs of dataflows, and skip computation if a dataflow tries to access data that it does not have access to. In our evaluation, we show that 1) the contract abstraction is general enough to represent a wide range of sharing problems, 2) we can write programs for complex data sharing problems and exhibit qualitative improvements over other alternate technologies, and 3) quantitatively, our optimizations make sharing programs written with the CPM efficient.</description>
      <guid isPermaLink="false">oai:arXiv.org:2408.04092v1</guid>
      <category>cs.DB</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Siyuan Xia, Chris Zhu, Tapan Srivastava, Bridget Fahey, Raul Castro Fernandez</dc:creator>
    </item>
    <item>
      <title>UpLIF: An Updatable Self-Tuning Learned Index Framework</title>
      <link>https://arxiv.org/abs/2408.04113</link>
      <description>arXiv:2408.04113v1 Announce Type: new 
Abstract: The emergence of learned indexes has caused a paradigm shift in our perception of indexing by considering indexes as predictive models that estimate keys' positions within a data set, resulting in notable improvements in key search efficiency and index size reduction; however, a significant challenge inherent in learned index modeling is its constrained support for update operations, necessitated by the requirement for a fixed distribution of records. Previous studies have proposed various approaches to address this issue with the drawback of high overhead due to multiple model retraining. In this paper, we present UpLIF, an adaptive self-tuning learned index that adjusts the model to accommodate incoming updates, predicts the distribution of updates for performance improvement, and optimizes its index structure using reinforcement learning. We also introduce the concept of balanced model adjustment, which determines the model's inherent properties (i.e. bias and variance), enabling the integration of these factors into the existing index model without the need for retraining with new data. Our comprehensive experiments show that the system surpasses state-of-the-art indexing solutions (both traditional and ML-based), achieving an increase in throughput of up to 3.12 times with 1000 times less memory usage.</description>
      <guid isPermaLink="false">oai:arXiv.org:2408.04113v1</guid>
      <category>cs.DB</category>
      <category>cs.LG</category>
      <category>math.OC</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Alireza Heidari, Amirhossein Ahmadi, Wei Zhang</dc:creator>
    </item>
    <item>
      <title>Pairwise Judgment Formulation for Semantic Embedding Model in Web Search</title>
      <link>https://arxiv.org/abs/2408.04197</link>
      <description>arXiv:2408.04197v1 Announce Type: cross 
Abstract: Semantic Embedding Model (SEM), a neural network-based Siamese architecture, is gaining momentum in information retrieval and natural language processing. In order to train SEM in a supervised fashion for Web search, the search engine query log is typically utilized to automatically formulate pairwise judgments as training data. Despite the growing application of semantic embeddings in the search engine industry, little work has been done on formulating effective pairwise judgments for training SEM. In this paper, we make the first in-depth investigation of a wide range of strategies for generating pairwise judgments for SEM. An interesting (perhaps surprising) discovery reveals that the conventional pairwise judgment formulation strategy wildly used in the field of pairwise Learning-to-Rank (LTR) is not necessarily effective for training SEM. Through a large-scale empirical study based on query logs and click-through activities from a major commercial search engine, we demonstrate the effective strategies for SEM and highlight the advantages of a hybrid heuristic (i.e., Clicked &gt; Non-Clicked) in comparison to the atomic heuristics (e.g., Clicked &gt; Skipped) in LTR. We conclude with best practices for training SEM and offer promising insights for future research.</description>
      <guid isPermaLink="false">oai:arXiv.org:2408.04197v1</guid>
      <category>cs.IR</category>
      <category>cs.AI</category>
      <category>cs.DB</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Mengze Hong, Chen Jason Zhang</dc:creator>
    </item>
    <item>
      <title>Refl-Spanners: A Purely Regular Approach to Non-Regular Core Spanners</title>
      <link>https://arxiv.org/abs/2010.13442</link>
      <description>arXiv:2010.13442v4 Announce Type: replace 
Abstract: The regular spanners (characterised by vset-automata) are closed under the algebraic operations of union, join and projection, and have desirable algorithmic properties. The core spanners (introduced by Fagin, Kimelfeld, Reiss, and Vansummeren (PODS 2013, JACM 2015) as a formalisation of the core functionality of the query language AQL used in IBM's SystemT) additionally need string-equality selections and it has been shown by Freydenberger and Holldack (ICDT 2016, Theory of Computing Systems 2018) that this leads to high complexity and even undecidability of the typical problems in static analysis and query evaluation. We propose an alternative approach to core spanners: by incorporating the string-equality selections directly into the regular language that represents the underlying regular spanner (instead of treating it as an algebraic operation on the table extracted by the regular spanner), we obtain a fragment of core spanners that, while having slightly weaker expressive power than the full class of core spanners, arguably still covers the intuitive applications of string-equality selections for information extraction and has much better upper complexity bounds of the typical problems in static analysis and query evaluation.</description>
      <guid isPermaLink="false">oai:arXiv.org:2010.13442v4</guid>
      <category>cs.DB</category>
      <category>cs.FL</category>
      <category>cs.IR</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Markus L. Schmid, Nicole Schweikardt</dc:creator>
    </item>
    <item>
      <title>On enforcing function diagram commutativity and anti-commutativity constraints in MatBase</title>
      <link>https://arxiv.org/abs/2406.16082</link>
      <description>arXiv:2406.16082v2 Announce Type: replace 
Abstract: Presented are algorithms for enforcing function diagram commutativity and anti-commutativity database constraints, using the database software application constraint-driven design and development methodology, in the realm of the (Elementary) Mathematical Data Model ((E)MDM). MatBase, an intelligent data and knowledge management system prototype mainly based on the (E)MDM, uses these algorithms to automatically generate corresponding code in both its versions (i.e., the MS Access and the .NET and SQL Server ones). Of course, any software developer may also use these algorithms manually. The paper also discusses the code generated to enforce two such constraints from a Geography database.</description>
      <guid isPermaLink="false">oai:arXiv.org:2406.16082v2</guid>
      <category>cs.DB</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <arxiv:journal_reference>Open Access Journal of Computer Science and Engineering, Volume 1, Issue 1, 2024, PP:01-13</arxiv:journal_reference>
      <dc:creator>Christian Mancas, Diana Christina Mancas</dc:creator>
    </item>
    <item>
      <title>A Simple Representation of Tree Covering Utilizing Balanced Parentheses and Efficient Implementation of Average-Case Optimal RMQs</title>
      <link>https://arxiv.org/abs/2407.00573</link>
      <description>arXiv:2407.00573v2 Announce Type: replace-cross 
Abstract: Tree covering is a technique for decomposing a tree into smaller-sized trees with desirable properties, and has been employed in various succinct data structures. However, significant hurdles stand in the way of a practical implementation of tree covering: a lot of pointers are used to maintain the tree-covering hierarchy and many indices for tree navigational queries consume theoretically negligible yet practically vast space. To tackle these problems, we propose a simple representation of tree covering using a balanced parenthesis representation. The key to the proposal is the observation that every micro tree splits into at most two intervals on the BP representation. Utilizing the representation, we propose several data structures that represent a tree and its tree cover, which consequently allow micro tree compression with arbitrary coding and efficient tree navigational queries. We also applied our data structure to average-case optimal RMQ by Munro et al.~[ESA 2021] and implemented the RMQ data structure. Our RMQ data structures spend less than $2n$ bits and process queries in a practical time on several settings of the performance evaluation, reducing the gap between theoretical space complexity and actual space consumption. We also implement tree navigational operations while using the same amount of space as the RMQ data structures. We believe the representation can be widely utilized for designing practically memory-efficient data structures based on tree covering.</description>
      <guid isPermaLink="false">oai:arXiv.org:2407.00573v2</guid>
      <category>cs.DS</category>
      <category>cs.DB</category>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Kou Hamada, Sankardeep Chakraborty, Seungbum Jo, Takuto Koriyama, Kunihiko Sadakane, Srinivasa Rao Satti</dc:creator>
    </item>
  </channel>
</rss>
