<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>cs.ET updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/cs.ET</link>
    <description>cs.ET updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/cs.ET" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Tue, 05 Nov 2024 05:00:19 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Tue, 05 Nov 2024 00:00:00 -0500</pubDate>
    <skipDays>
      <day>Saturday</day>
      <day>Sunday</day>
    </skipDays>
    <item>
      <title>AI-Guided Codesign Framework for Novel Material and Device Design applied to MTJ-based True Random Number Generators</title>
      <link>https://arxiv.org/abs/2411.01008</link>
      <description>arXiv:2411.01008v1 Announce Type: new 
Abstract: Novel devices and novel computing paradigms are key for energy efficient, performant future computing systems. However, designing devices for new applications is often time consuming and tedious. Here, we investigate the design and optimization of spin orbit torque and spin transfer torque magnetic tunnel junction models as the probabilistic devices for true random number generation. We leverage reinforcement learning and evolutionary optimization to vary key device and material properties of the various device models for stochastic operation. Our AI guided codesign methods generated different candidate devices capable of generating stochastic samples for a desired probability distribution, while also minimizing energy usage for the devices.</description>
      <guid isPermaLink="false">oai:arXiv.org:2411.01008v1</guid>
      <category>cs.ET</category>
      <category>cs.LG</category>
      <category>cs.NE</category>
      <pubDate>Tue, 05 Nov 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Karan P. Patel, Andrew Maicke, Jared Arzate, Jaesuk Kwon, J. Darby Smith, James B. Aimone, Jean Anne C. Incorvia, Suma G. Cardwell, Catherine D. Schuman</dc:creator>
    </item>
    <item>
      <title>A Comprehensive Simulation Framework for CXL Disaggregated Memory</title>
      <link>https://arxiv.org/abs/2411.02282</link>
      <description>arXiv:2411.02282v1 Announce Type: new 
Abstract: Compute eXpress Link (CXL) is a pivotal technology for memory disaggregation in future heterogeneous computing systems, enabling on-demand memory expansion and improved resource utilization. Despite its potential, CXL is in its early stages with limited market products, highlighting the need for a reliable system-level simulation tool. This paper introduces CXL-DMSim, an open-source, high-fidelity full-system simulator for CXL disaggregated memory systems, comparable in speed to gem5. CXL-DMSim includes a flexible CXL memory expander model, device driver, and support for CXL.io and CXL.mem protocols. It supports both app-managed and kernel-managed modes, with the latter featuring a NUMA-compatible mechanism. Rigorous verification against real hardware testbeds with FPGA-based and ASIC-based CXL memory prototypes confirms CXL-DMSim's accuracy, with an average simulation error of 4.1%. Benchmark results using LMbench and STREAM indicate that CXL-FPGA memory has approximately ~2.88x higher latency than local DDR, while CXL-ASIC latency is about ~2.18x. CXL-FPGA achieves 45-69% of local DDR's memory bandwidth, and CXL-ASIC reaches 82-83%. The performance of CXL memory is significantly more sensitive to Rd/Wr patterns than local DDR, with optimal bandwidth at a 74%:26% ratio rather than 50%:50% due to the current CXL+DDR controller design. The study also shows that CXL memory can markedly enhance the performance of memory-intensive applications, with the most improvement seen in Viper (~23x) and in bandwidth-sensitive scenarios like MERCI (16%). CXL-DMSim's observability and expandability are demonstrated through detailed case studies, showcasing its potential for research on future CXL-interconnected hybrid memory pools.</description>
      <guid isPermaLink="false">oai:arXiv.org:2411.02282v1</guid>
      <category>cs.ET</category>
      <category>cs.AR</category>
      <pubDate>Tue, 05 Nov 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Wentao Hong (Nong Xiao National University of Defense Technology, Sun Yat-sen University, Peking University), Lizhou Wu (Nong Xiao National University of Defense Technology, Sun Yat-sen University, Peking University), Yanjing Wang (Nong Xiao National University of Defense Technology, Sun Yat-sen University, Peking University), Yang Ou (Nong Xiao National University of Defense Technology, Sun Yat-sen University, Peking University), Zicong Wang (Nong Xiao National University of Defense Technology, Sun Yat-sen University, Peking University), Yongfeng Wang (Nong Xiao National University of Defense Technology, Sun Yat-sen University, Peking University), Jie Zhang (Nong Xiao National University of Defense Technology, Sun Yat-sen University, Peking University), Sheng Ma (Nong Xiao National University of Defense Technology, Sun Yat-sen University, Peking University), Dezun Dong (Nong Xiao National University of Defense Technology, Sun Yat-sen University, Peking University), Xingyun Qi (Nong Xiao National University of Defense Technology, Sun Yat-sen University, Peking University), Mingche Lai (Nong Xiao National University of Defense Technology, Sun Yat-sen University, Peking University)</dc:creator>
    </item>
    <item>
      <title>Profiling AI Models: Towards Efficient Computation Offloading in Heterogeneous Edge AI Systems</title>
      <link>https://arxiv.org/abs/2411.00859</link>
      <description>arXiv:2411.00859v1 Announce Type: cross 
Abstract: The rapid growth of end-user AI applications, such as computer vision and generative AI, has led to immense data and processing demands often exceeding user devices' capabilities. Edge AI addresses this by offloading computation to the network edge, crucial for future services in 6G networks. However, it faces challenges such as limited resources during simultaneous offloads and the unrealistic assumption of homogeneous system architecture. To address these, we propose a research roadmap focused on profiling AI models, capturing data about model types, hyperparameters, and underlying hardware to predict resource utilisation and task completion time. Initial experiments with over 3,000 runs show promise in optimising resource allocation and enhancing Edge AI performance.</description>
      <guid isPermaLink="false">oai:arXiv.org:2411.00859v1</guid>
      <category>cs.LG</category>
      <category>cs.AI</category>
      <category>cs.DC</category>
      <category>cs.ET</category>
      <category>cs.NI</category>
      <pubDate>Tue, 05 Nov 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Juan Marcelo Parra-Ullauri, Oscar Dilley, Hari Madhukumar, Dimitra Simeonidou</dc:creator>
    </item>
    <item>
      <title>Exploratory Models of Human-AI Teams: Leveraging Human Digital Twins to Investigate Trust Development</title>
      <link>https://arxiv.org/abs/2411.01049</link>
      <description>arXiv:2411.01049v1 Announce Type: cross 
Abstract: As human-agent teaming (HAT) research continues to grow, computational methods for modeling HAT behaviors and measuring HAT effectiveness also continue to develop. One rising method involves the use of human digital twins (HDT) to approximate human behaviors and socio-emotional-cognitive reactions to AI-driven agent team members. In this paper, we address three research questions relating to the use of digital twins for modeling trust in HATs. First, to address the question of how we can appropriately model and operationalize HAT trust through HDT HAT experiments, we conducted causal analytics of team communication data to understand the impact of empathy, socio-cognitive, and emotional constructs on trust formation. Additionally, we reflect on the current state of the HAT trust science to discuss characteristics of HAT trust that must be replicable by a HDT such as individual differences in trust tendencies, emergent trust patterns, and appropriate measurement of these characteristics over time. Second, to address the question of how valid measures of HDT trust are for approximating human trust in HATs, we discuss the properties of HDT trust: self-report measures, interaction-based measures, and compliance type behavioral measures. Additionally, we share results of preliminary simulations comparing different LLM models for generating HDT communications and analyze their ability to replicate human-like trust dynamics. Third, to address how HAT experimental manipulations will extend to human digital twin studies, we share experimental design focusing on propensity to trust for HDTs vs. transparency and competency-based trust for AI agents.</description>
      <guid isPermaLink="false">oai:arXiv.org:2411.01049v1</guid>
      <category>cs.HC</category>
      <category>cs.AI</category>
      <category>cs.ET</category>
      <pubDate>Tue, 05 Nov 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Daniel Nguyen, Myke C. Cohen, Hsien-Te Kao, Grant Engberson, Louis Penafiel, Spencer Lynch, Svitlana Volkova</dc:creator>
    </item>
    <item>
      <title>Interacting Large Language Model Agents. Interpretable Models and Social Learning</title>
      <link>https://arxiv.org/abs/2411.01271</link>
      <description>arXiv:2411.01271v1 Announce Type: cross 
Abstract: This paper develops theory and algorithms for interacting large language model agents (LLMAs) using methods from statistical signal processing and microeconomics. While both fields are mature, their application to decision-making by interacting LLMAs remains unexplored. Motivated by Bayesian sentiment analysis on online platforms, we construct interpretable models and stochastic control algorithms that enable LLMAs to interact and perform Bayesian inference. Because interacting LLMAs learn from prior decisions and external inputs, they exhibit bias and herding behavior. Thus, developing interpretable models and stochastic control algorithms is essential to understand and mitigate these behaviors. This paper has three main results. First, we show using Bayesian revealed preferences from microeconomics that an individual LLMA satisfies the sufficient conditions for rationally inattentive (bounded rationality) utility maximization and, given an observation, the LLMA chooses an action that maximizes a regularized utility. Second, we utilize Bayesian social learning to construct interpretable models for LLMAs that interact sequentially with each other and the environment while performing Bayesian inference. Our models capture the herding behavior exhibited by interacting LLMAs. Third, we propose a stochastic control framework to delay herding and improve state estimation accuracy under two settings: (a) centrally controlled LLMAs and (b) autonomous LLMAs with incentives. Throughout the paper, we demonstrate the efficacy of our methods on real datasets for hate speech classification and product quality assessment, using open-source models like Mistral and closed-source models like ChatGPT. The main takeaway of this paper, based on substantial empirical analysis and mathematical formalism, is that LLMAs act as rationally bounded Bayesian agents that exhibit social learning when interacting.</description>
      <guid isPermaLink="false">oai:arXiv.org:2411.01271v1</guid>
      <category>cs.LG</category>
      <category>cs.AI</category>
      <category>cs.ET</category>
      <category>cs.MA</category>
      <category>cs.SY</category>
      <category>eess.SY</category>
      <pubDate>Tue, 05 Nov 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Adit Jain, Vikram Krishnamurthy</dc:creator>
    </item>
    <item>
      <title>Differentiable Quantum Computing for Large-scale Linear Control</title>
      <link>https://arxiv.org/abs/2411.01391</link>
      <description>arXiv:2411.01391v1 Announce Type: cross 
Abstract: As industrial models and designs grow increasingly complex, the demand for optimal control of large-scale dynamical systems has significantly increased. However, traditional methods for optimal control incur significant overhead as problem dimensions grow. In this paper, we introduce an end-to-end quantum algorithm for linear-quadratic control with provable speedups. Our algorithm, based on a policy gradient method, incorporates a novel quantum subroutine for solving the matrix Lyapunov equation. Specifically, we build a quantum-assisted differentiable simulator for efficient gradient estimation that is more accurate and robust than classical methods relying on stochastic approximation. Compared to the classical approaches, our method achieves a super-quadratic speedup. To the best of our knowledge, this is the first end-to-end quantum application to linear control problems with provable quantum advantage.</description>
      <guid isPermaLink="false">oai:arXiv.org:2411.01391v1</guid>
      <category>quant-ph</category>
      <category>cs.ET</category>
      <category>cs.LG</category>
      <category>cs.NA</category>
      <category>math.NA</category>
      <category>math.OC</category>
      <pubDate>Tue, 05 Nov 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Connor Clayton, Jiaqi Leng, Gengzhi Yang, Yi-Ling Qiao, Ming C. Lin, Xiaodi Wu</dc:creator>
    </item>
    <item>
      <title>Fairness-Utilization Trade-off in Wireless Networks with Explainable Kolmogorov-Arnold Networks</title>
      <link>https://arxiv.org/abs/2411.01924</link>
      <description>arXiv:2411.01924v1 Announce Type: cross 
Abstract: The effective distribution of user transmit powers is essential for the significant advancements that the emergence of 6G wireless networks brings. In recent studies, Deep Neural Networks (DNNs) have been employed to address this challenge. However, these methods frequently encounter issues regarding fairness and computational inefficiency when making decisions, rendering them unsuitable for future dynamic services that depend heavily on the participation of each individual user. To address this gap, this paper focuses on the challenge of transmit power allocation in wireless networks, aiming to optimize $\alpha$-fairness to balance network utilization and user equity. We introduce a novel approach utilizing Kolmogorov-Arnold Networks (KANs), a class of machine learning models that offer low inference costs compared to traditional DNNs through superior explainability. The study provides a comprehensive problem formulation, establishing the NP-hardness of the power allocation problem. Then, two algorithms are proposed for dataset generation and decentralized KAN training, offering a flexible framework for achieving various fairness objectives in dynamic 6G environments. Extensive numerical simulations demonstrate the effectiveness of our approach in terms of fairness and inference cost. The results underscore the potential of KANs to overcome the limitations of existing DNN-based methods, particularly in scenarios that demand rapid adaptation and fairness.</description>
      <guid isPermaLink="false">oai:arXiv.org:2411.01924v1</guid>
      <category>cs.NI</category>
      <category>cs.AI</category>
      <category>cs.ET</category>
      <category>cs.LG</category>
      <category>cs.NA</category>
      <category>math.NA</category>
      <pubDate>Tue, 05 Nov 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Masoud Shokrnezhad, Hamidreza Mazandarani, Tarik Taleb</dc:creator>
    </item>
    <item>
      <title>Complex Vector Gain-Based Annealer for Minimizing XY Hamiltonians</title>
      <link>https://arxiv.org/abs/2411.02010</link>
      <description>arXiv:2411.02010v1 Announce Type: cross 
Abstract: This paper presents the Complex Vector Gain-Based Annealer (CoVeGA), an analog computing platform designed to overcome energy barriers in XY Hamiltonians through a higher-dimensional representation. Traditional gain-based solvers utilizing optical or photonic hardware typically represent each XY spin with a single complex field. These solvers often struggle with large energy barriers in complex landscapes, leading to relaxation into excited states. CoVeGA addresses these limitations by employing two complex fields to represent each XY spin and dynamically evolving the energy landscape through time-dependent annealing. Operating in a higher-dimensional space, CoVeGA bridges energy barriers in this expanded space during the continuous phase evolution, thus avoiding entrapment in local minima. We introduce several graph structures that pose challenges for XY minimization and use them to benchmark CoVeGA against single-dimension XY solvers, highlighting the benefits of higher-dimensional operation.</description>
      <guid isPermaLink="false">oai:arXiv.org:2411.02010v1</guid>
      <category>cond-mat.dis-nn</category>
      <category>cond-mat.other</category>
      <category>cs.ET</category>
      <category>nlin.AO</category>
      <category>physics.optics</category>
      <pubDate>Tue, 05 Nov 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>James S. Cummins, Natalia G. Berloff</dc:creator>
    </item>
    <item>
      <title>A Quantum Algorithm for Shapley Value Estimation</title>
      <link>https://arxiv.org/abs/2301.04727</link>
      <description>arXiv:2301.04727v4 Announce Type: replace 
Abstract: In the classical context, the cooperative game theory concept of the Shapley value has been adapted for post hoc explanations of machine learning models. However, this approach does not easily translate to eXplainable Quantum ML (XQML). Finding Shapley values can be highly computationally complex. We propose quantum algorithms which can extract Shapley values within some confidence interval. Our results perform in polynomial time. We demonstrate the validity of each approach under specific examples of cooperative voting games.</description>
      <guid isPermaLink="false">oai:arXiv.org:2301.04727v4</guid>
      <category>cs.ET</category>
      <category>cs.CR</category>
      <category>math.QA</category>
      <pubDate>Tue, 05 Nov 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <arxiv:DOI>10.1109/QCE57702.2023.00024</arxiv:DOI>
      <dc:creator>Iain Burge, Michel Barbeau, Joaquin Garcia-Alfaro</dc:creator>
    </item>
    <item>
      <title>Compilation for Dynamically Field-Programmable Qubit Arrays with Efficient and Provably Near-Optimal Scheduling</title>
      <link>https://arxiv.org/abs/2405.15095</link>
      <description>arXiv:2405.15095v2 Announce Type: replace 
Abstract: Dynamically field-programmable qubit arrays based on neutral atoms feature high fidelity and highly parallel gates for quantum computing. However, it is challenging for compilers to fully leverage the novel flexibility offered by such hardware while respecting its various constraints. In this study, we break down the compilation for this architecture into three tasks: scheduling, placement, and routing. We formulate these three problems and present efficient solutions to them. Notably, our scheduling based on graph edge-coloring is provably near-optimal in terms of the number of two-qubit gate stages (at most one more than the optimum). As a result, our compiler, Enola, reduces this number of stages by 3.7x and improves the fidelity by 5.9x compared to OLSQ-DPQA, the current state of the art. Additionally, Enola is highly scalable, e.g., within 30 minutes, it can compile circuits with 10,000 qubits, a scale sufficient for the current era of quantum computing. Enola is open source at https://github.com/UCLA-VAST/Enola</description>
      <guid isPermaLink="false">oai:arXiv.org:2405.15095v2</guid>
      <category>cs.ET</category>
      <category>quant-ph</category>
      <pubDate>Tue, 05 Nov 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <arxiv:DOI>10.1145/3658617.3697778</arxiv:DOI>
      <dc:creator>Daniel Bochen Tan, Wan-Hsuan Lin, Jason Cong</dc:creator>
    </item>
    <item>
      <title>Scaling Whole-Chip QAOA for Higher-Order Ising Spin Glass Models on Heavy-Hex Graphs</title>
      <link>https://arxiv.org/abs/2312.00997</link>
      <description>arXiv:2312.00997v2 Announce Type: replace-cross 
Abstract: We show through numerical simulation that the Quantum Approximate Optimization Algorithm (QAOA) for higher-order, random-coefficient, heavy-hex compatible spin glass Ising models has strong parameter concentration across problem sizes from $16$ up to $127$ qubits for $p=1$ up to $p=5$, which allows for straight-forward transfer learning of QAOA angles on instance sizes where exhaustive grid-search is prohibitive even for $p&gt;1$. We use Matrix Product State (MPS) simulation at different bond dimensions to obtain confidence in these results, and we obtain the optimal solutions to these combinatorial optimization problems using CPLEX. In order to assess the ability of current noisy quantum hardware to exploit such parameter concentration, we execute short-depth QAOA circuits (with a CNOT depth of 6 per $p$, resulting in circuits which contain $1420$ two qubit gates for $127$ qubit $p=5$ QAOA) on $100$ higher-order (cubic term) Ising models on IBM quantum superconducting processors with $16, 27, 127$ qubits using QAOA angles learned from a single $16$-qubit instance. We show that (i) the best quantum processors generally find lower energy solutions up to $p=3$ for 27 qubit systems and up to $p=2$ for 127 qubit systems and are overcome by noise at higher values of $p$, (ii) the best quantum processors find mean energies that are about a factor of two off from the noise-free numerical simulation results. Additional insights from our experiments are that large performance differences exist among different quantum processors even of the same generation and that dynamical decoupling significantly improve performance for some, but decrease performance for other quantum processors. Lastly we show $p=1$ QAOA angle mean energy landscapes computed using up to a $414$ qubit quantum computer, showing that the mean QAOA energy landscapes remain very similar as the problem size changes.</description>
      <guid isPermaLink="false">oai:arXiv.org:2312.00997v2</guid>
      <category>quant-ph</category>
      <category>cond-mat.dis-nn</category>
      <category>cs.DS</category>
      <category>cs.ET</category>
      <pubDate>Tue, 05 Nov 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Elijah Pelofske, Andreas B\"artschi, Lukasz Cincio, John Golden, Stephan Eidenbenz</dc:creator>
    </item>
    <item>
      <title>AI-Enabled System for Efficient and Effective Cyber Incident Detection and Response in Cloud Environments</title>
      <link>https://arxiv.org/abs/2404.05602</link>
      <description>arXiv:2404.05602v3 Announce Type: replace-cross 
Abstract: The escalating sophistication and volume of cyber threats in cloud environments necessitate a paradigm shift in strategies. Recognising the need for an automated and precise response to cyber threats, this research explores the application of AI and ML and proposes an AI-powered cyber incident response system for cloud environments. This system, encompassing Network Traffic Classification, Web Intrusion Detection, and post-incident Malware Analysis (built as a Flask application), achieves seamless integration across platforms like Google Cloud and Microsoft Azure. The findings from this research highlight the effectiveness of the Random Forest model, achieving an accuracy of 90% for the Network Traffic Classifier and 96% for the Malware Analysis Dual Model application. Our research highlights the strengths of AI-powered cyber security. The Random Forest model excels at classifying cyber threats, offering an efficient and robust solution. Deep learning models significantly improve accuracy, and their resource demands can be managed using cloud-based TPUs and GPUs. Cloud environments themselves provide a perfect platform for hosting these AI/ML systems, while container technology ensures both efficiency and scalability. These findings demonstrate the contribution of the AI-led system in guaranteeing a robust and scalable cyber incident response solution in the cloud.</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.05602v3</guid>
      <category>cs.CR</category>
      <category>cs.ET</category>
      <category>cs.NI</category>
      <pubDate>Tue, 05 Nov 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Mohammed Ashfaaq M. Farzaan, Mohamed Chahine Ghanem, Ayman El-Hajjar, Deepthi N. Ratnayake</dc:creator>
    </item>
    <item>
      <title>Leverage Multi-source Traffic Demand Data Fusion with Transformer Model for Urban Parking Prediction</title>
      <link>https://arxiv.org/abs/2405.01055</link>
      <description>arXiv:2405.01055v2 Announce Type: replace-cross 
Abstract: The escalation in urban private car ownership has worsened the urban parking predicament, necessitating effective parking availability prediction for urban planning and management. However, the existing prediction methods suffer from low prediction accuracy with the lack of spatial-temporal correlation features related to parking volume, and neglect of flow patterns and correlations between similar parking lots within certain areas. To address these challenges, this study proposes a parking availability prediction framework integrating spatial-temporal deep learning with multi-source data fusion, encompassing traffic demand data from multiple sources (e.g., metro, bus, taxi services), and parking lot data. The framework is based on the Transformer as the spatial-temporal deep learning model and leverages K-means clustering to establish parking cluster zones, extracting and integrating traffic demand characteristics from various transportation modes (i.e., metro, bus, online ride-hailing, and taxi) connected to parking lots. Real-world empirical data was used to verify the effectiveness of the proposed method compared with different machine learning, deep learning, and traditional statistical models for predicting parking availability. Experimental results reveal that, with the proposed pipeline, the developed Transformer model outperforms other models in terms of various metrics, e.g., Mean Squared Error (MSE), Mean Absolute Error (MAE), and Mean Absolute Percentage Error (MAPE). By fusing multi-source demanding data with spatial-temporal deep learning techniques, this approach offers the potential to develop parking availability prediction systems that furnish more accurate and timely information to both drivers and urban planners, thereby fostering more efficient and sustainable urban mobility.</description>
      <guid isPermaLink="false">oai:arXiv.org:2405.01055v2</guid>
      <category>cs.LG</category>
      <category>cs.AI</category>
      <category>cs.ET</category>
      <pubDate>Tue, 05 Nov 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/publicdomain/zero/1.0/</dc:rights>
      <dc:creator>Yin Huang, Yongqi Dong, Youhua Tang, Li Li</dc:creator>
    </item>
    <item>
      <title>Decentralized Social Networks and the Future of Free Speech Online</title>
      <link>https://arxiv.org/abs/2406.06934</link>
      <description>arXiv:2406.06934v2 Announce Type: replace-cross 
Abstract: Decentralized social networks like Mastodon and BlueSky are trending topics that have drawn much attention and discussion in recent years. By devolving powers from the central node to the end users, decentralized social networks aim to cure existing pathologies on the centralized platforms and have been viewed by many as the future of the Internet. This article critically and systematically assesses the decentralization project's prospect for communications online. It uses normative theories of free speech to examine whether and how the decentralization design could facilitate users' freedom of expression online. The analysis shows that both promises and pitfalls exist, highlighting the importance of value-based design in this area. Two most salient issues for the design of the decentralized networks are: how to balance the decentralization ideal with constant needs of centralization on the network, and how to empower users to make them truly capable of exercising their control. The article then uses some design examples, such as the shared blocklist and the opt-in search function, to illustrate the value considerations underlying the design choices. Some tentative proposals for law and policy interventions are offered to better facilitate the design of the new network. Rather than providing clear answers, the article seeks to map the value implications of the design choices, highlight the stakes, and point directions for future research.</description>
      <guid isPermaLink="false">oai:arXiv.org:2406.06934v2</guid>
      <category>cs.CY</category>
      <category>cs.ET</category>
      <category>cs.NI</category>
      <category>cs.SI</category>
      <pubDate>Tue, 05 Nov 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <arxiv:DOI>10.1016/j.clsr.2024.106059</arxiv:DOI>
      <arxiv:journal_reference>Computer Law &amp; Security Review 55, 106059 (2024)</arxiv:journal_reference>
      <dc:creator>Tao Huang</dc:creator>
    </item>
    <item>
      <title>From x*y=k to Uniswap Hooks: A Comparative Review of Decentralized Exchanges (DEX)</title>
      <link>https://arxiv.org/abs/2410.10162</link>
      <description>arXiv:2410.10162v2 Announce Type: replace-cross 
Abstract: Decentralized Exchanges (DEXs) are pivotal applications in the Decentralized Finance (DeFi) landscape, aiming to facilitate trustless cryptocurrency trading by relying on smart contracts and blockchain networks. The developments in the DEXs sector began with the implementation of an Automated Market Maker (AMM) system using a simple math formula by Uniswap in 2018. Absorbing significant funding and the attention of web3 enthusiasts, DEXs have seen numerous advancements in their evolution. A notable recent advancement is the introduction of hooks in Uniswap v4, which allows users to take advantage of a wide range of plugin-like features with liquidity pools. This paper provides a comprehensive classification and comparative analyses of prominent DEX protocols, namely Uniswap, Curve, and Balancer, in addition to investigating other protocols' noteworthy aspects. The evaluation framework encompasses mechanisms, components, mathematical formulations, and the performance of liquidity pools. The goals are to elucidate the strengths and limitations of different AMM models, highlight emerging concepts in DEX development, outline current challenges, and differentiate optimal models for specific applications. The results and comparative insights can be a reference for web3 developers, blockchain researchers, traders, and regulatory parties.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.10162v2</guid>
      <category>cs.CE</category>
      <category>cs.CR</category>
      <category>cs.ET</category>
      <pubDate>Tue, 05 Nov 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Mohammad Ali Asef, Seyed Mojtaba Hosseini Bamakan</dc:creator>
    </item>
  </channel>
</rss>
