<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>math.OC updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/math.OC</link>
    <description>math.OC updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/math.OC" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Fri, 31 May 2024 01:49:39 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Thu, 30 May 2024 00:00:00 -0400</pubDate>
    <skipDays>
      <day>Sunday</day>
      <day>Saturday</day>
    </skipDays>
    <item>
      <title>A Framework for Balancing Power Grid Efficiency and Risk with Bi-objective Stochastic Integer Optimization</title>
      <link>https://arxiv.org/abs/2405.18538</link>
      <description>arXiv:2405.18538v1 Announce Type: new 
Abstract: Power grid expansion planning requires making large investment decisions in the present that will impact the future cost and reliability of a system exposed to wide-ranging uncertainties. Extreme temperatures can pose significant challenges to providing power by increasing demand and decreasing supply and have contributed to recent major power outages. We propose to address a modeling challenge of such high-impact, low-frequency events with a bi-objective stochastic integer optimization model that finds solutions with different trade-offs between efficiency in normal conditions and risk to extreme events. We propose a conditional sampling approach paired with a risk measure to address the inherent challenge in approximating the risk of low-frequency events within a sampling based approach. We present a model for spatially correlated, county-specific temperatures and a method to generate both unconditional and conditionally extreme temperature samples from this model efficiently. These models are investigated within an extensive case study with realistic data that demonstrates the effectiveness of the bi-objective approach and the conditional sampling technique. We find that spatial correlations in the temperature samples are essential to finding good solutions and that modeling generator temperature dependence is an important consideration for finding efficient, low-risk solutions.</description>
      <guid isPermaLink="false">oai:arXiv.org:2405.18538v1</guid>
      <category>math.OC</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Ramsey Rossmann, Mihai Anitescu, Julie Bessac, Michael Ferris, Mitchell Krock, James Luedtke, Line Roald</dc:creator>
    </item>
    <item>
      <title>Single-loop Stochastic Algorithms for Difference of Max-Structured Weakly Convex Functions</title>
      <link>https://arxiv.org/abs/2405.18577</link>
      <description>arXiv:2405.18577v2 Announce Type: new 
Abstract: In this paper, we study a class of non-smooth non-convex problems in the form of $\min_{x}[\max_{y\in Y}\phi(x, y) - \max_{z\in Z}\psi(x, z)]$, where both $\Phi(x) = \max_{y\in Y}\phi(x, y)$ and $\Psi(x)=\max_{z\in Z}\psi(x, z)$ are weakly convex functions, and $\phi(x, y), \psi(x, z)$ are strongly concave functions in terms of $y$ and $z$, respectively. It covers two families of problems that have been studied but are missing single-loop stochastic algorithms, i.e., difference of weakly convex functions and weakly convex strongly-concave min-max problems. We propose a stochastic Moreau envelope approximate gradient method dubbed SMAG, the first single-loop algorithm for solving these problems, and provide a state-of-the-art non-asymptotic convergence rate. The key idea of the design is to compute an approximate gradient of the Moreau envelopes of $\Phi, \Psi$ using only one step of stochastic gradient update of the primal and dual variables. Empirically, we conduct experiments on positive-unlabeled (PU) learning and partial area under ROC curve (pAUC) optimization with an adversarial fairness regularizer to validate the effectiveness of our proposed algorithms.</description>
      <guid isPermaLink="false">oai:arXiv.org:2405.18577v2</guid>
      <category>math.OC</category>
      <category>cs.LG</category>
      <category>stat.ML</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Quanqi Hu, Qi Qi, Zhaosong Lu, Tianbao Yang</dc:creator>
    </item>
    <item>
      <title>Battery Degradation Heuristics for Predictive Energy Management in Shipboard Power Systems</title>
      <link>https://arxiv.org/abs/2405.18633</link>
      <description>arXiv:2405.18633v1 Announce Type: new 
Abstract: The presence of Pulse Power Loads (PPLs) in the Notional Shipboard Power System (SPS) presents a challenge in the form of meeting their high ramp rate requirements. Considering the ramp rate limitations on the generators, this might hinder the power flow in the grid. Failure to meet the ramp rate requirements might cause instability. Aggregating generators with energy storage elements usually addresses the ramp requirements while ensuring the power demand is achieved. This paper proposes an energy management strategy that adaptively splits the power demand between the generators and the batteries while simultaneously considering the battery degradation and the generator's efficient operation. Since it is challenging to incorporate the battery degradation model directly into the optimization problem due to its complex structure and the degradation time scale which is not practical for real-time implementation, two reasonable heuristics in terms of minimizing the absolute battery power and minimizing the battery state of charge are proposed and compared to manage the battery degradation. A model predictive energy management strategy is then developed to coordinate the power split considering the generator efficiency and minimizing the battery degradation based on the two heuristic approaches. The designed strategy is tested via a simulation of a lumped notional shipboard power system. The results show the impact of the battery degradation heuristics for energy management strategy in mitigating battery degradation and its health management.</description>
      <guid isPermaLink="false">oai:arXiv.org:2405.18633v1</guid>
      <category>math.OC</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Satish Vedula, Ayobami Olajube, Koto Omiloli, Olugbenga Moses Anubi</dc:creator>
    </item>
    <item>
      <title>A simple inverse power method for balanced graph cut</title>
      <link>https://arxiv.org/abs/2405.18705</link>
      <description>arXiv:2405.18705v1 Announce Type: new 
Abstract: The existing inverse power ($\mathbf{IP}$) method for solving the balanced graph cut lacks local convergence and its inner subproblem requires a nonsmooth convex solver. To address these issues, we develop a simple inverse power ($\mathbf{SIP}$) method using a novel equivalent continuous formulation of the balanced graph cut, and its inner subproblem allows an explicit analytic solution, which is the biggest advantage over $\mathbf{IP}$ and constitutes the main reason why we call it $\mathit{simple}$. By fully exploiting the closed-form of the inner subproblem solution, we design a boundary-detected subgradient selection with which $\mathbf{SIP}$ is proved to be locally converged. We show that $\mathbf{SIP}$ is also applicable to a new ternary valued $\theta$-balanced cut which reduces to the balanced cut when $\theta=1$. When $\mathbf{SIP}$ reaches its local optimum, we seamlessly transfer to solve the $\theta$-balanced cut within exactly the same iteration algorithm framework and thus obtain $\mathbf{SIP}$-$\mathbf{perturb}$ -- an efficient local breakout improvement of $\mathbf{SIP}$, which transforms some ``partitioned" vertices back to the ``un-partitioned" ones through the adjustable $\theta$. Numerical experiments on G-set for Cheeger cut and Sparsest cut demonstrate that $\mathbf{SIP}$ is significantly faster than $\mathbf{IP}$ while maintaining approximate solutions of comparable quality, and $\mathbf{SIP}$-$\mathbf{perturb}$ outperforms $\mathtt{Gurobi}$ in terms of both computational cost and solution quality.</description>
      <guid isPermaLink="false">oai:arXiv.org:2405.18705v1</guid>
      <category>math.OC</category>
      <category>cs.NA</category>
      <category>math.CO</category>
      <category>math.NA</category>
      <category>math.SP</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Sihong Shao, Chuan Yang</dc:creator>
    </item>
    <item>
      <title>SPABA: A Single-Loop and Probabilistic Stochastic Bilevel Algorithm Achieving Optimal Sample Complexity</title>
      <link>https://arxiv.org/abs/2405.18777</link>
      <description>arXiv:2405.18777v1 Announce Type: new 
Abstract: While stochastic bilevel optimization methods have been extensively studied for addressing large-scale nested optimization problems in machine learning, it remains an open question whether the optimal complexity bounds for solving bilevel optimization are the same as those in single-level optimization. Our main result resolves this question: SPABA, an adaptation of the PAGE method for nonconvex optimization in (Li et al., 2021) to the bilevel setting, can achieve optimal sample complexity in both the finite-sum and expectation settings. We show the optimality of SPABA by proving that there is no gap in complexity analysis between stochastic bilevel and single-level optimization when implementing PAGE. Notably, as indicated by the results of (Dagr\'eou et al., 2022), there might exist a gap in complexity analysis when implementing other stochastic gradient estimators, like SGD and SAGA. In addition to SPABA, we propose several other single-loop stochastic bilevel algorithms, that either match or improve the state-of-the-art sample complexity results, leveraging our convergence rate and complexity analysis. Numerical experiments demonstrate the superior practical performance of the proposed methods.</description>
      <guid isPermaLink="false">oai:arXiv.org:2405.18777v1</guid>
      <category>math.OC</category>
      <category>cs.LG</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <dc:creator>Tianshu Chu, Dachuan Xu, Wei Yao, Jin Zhang</dc:creator>
    </item>
    <item>
      <title>Distributed Bilevel Optimization with Communication Compression</title>
      <link>https://arxiv.org/abs/2405.18858</link>
      <description>arXiv:2405.18858v1 Announce Type: new 
Abstract: Stochastic bilevel optimization tackles challenges involving nested optimization structures. Its fast-growing scale nowadays necessitates efficient distributed algorithms. In conventional distributed bilevel methods, each worker must transmit full-dimensional stochastic gradients to the server every iteration, leading to significant communication overhead and thus hindering efficiency and scalability. To resolve this issue, we introduce the first family of distributed bilevel algorithms with communication compression. The primary challenge in algorithmic development is mitigating bias in hypergradient estimation caused by the nested structure. We first propose C-SOBA, a simple yet effective approach with unbiased compression and provable linear speedup convergence. However, it relies on strong assumptions on bounded gradients. To address this limitation, we explore the use of moving average, error feedback, and multi-step compression in bilevel optimization, resulting in a series of advanced algorithms with relaxed assumptions and improved convergence properties. Numerical experiments show that our compressed bilevel algorithms can achieve $10\times$ reduction in communication overhead without severe performance degradation.</description>
      <guid isPermaLink="false">oai:arXiv.org:2405.18858v1</guid>
      <category>math.OC</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Yutong He, Jie Hu, Xinmeng Huang, Songtao Lu, Bin Wang, Kun Yuan</dc:creator>
    </item>
    <item>
      <title>Damped Newton Method with Near-Optimal Global $\mathcal {O}\left(k^{-3} \right)$ Convergence Rate</title>
      <link>https://arxiv.org/abs/2405.18926</link>
      <description>arXiv:2405.18926v1 Announce Type: new 
Abstract: This paper investigates the global convergence of stepsized Newton methods for convex functions. We propose several simple stepsize schedules with fast global convergence guarantees, up to $\mathcal{O} (k^{-3})$, nearly matching lower complexity bounds $\Omega (k^{-3.5})$ of second-order methods. For cases with multiple plausible smoothness parameterizations or an unknown smoothness constant, we introduce a stepsize backtracking procedure that ensures convergence as if the optimal smoothness parameters were known.</description>
      <guid isPermaLink="false">oai:arXiv.org:2405.18926v1</guid>
      <category>math.OC</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Slavom\'ir Hanzely, Farshed Abdukhakimov, Martin Tak\'a\v{c}</dc:creator>
    </item>
    <item>
      <title>Beyond the fundamental lemma: from finite time series to linear system</title>
      <link>https://arxiv.org/abs/2405.18962</link>
      <description>arXiv:2405.18962v1 Announce Type: new 
Abstract: We state necessary and sufficient conditions to uniquely identify (modulo state isomorphism) a linear time-invariant minimal input-state-output system from finite input-output data and upper- and lower bounds on lag and state space dimension.</description>
      <guid isPermaLink="false">oai:arXiv.org:2405.18962v1</guid>
      <category>math.OC</category>
      <category>cs.SY</category>
      <category>eess.SY</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Kanat Camlibel, Paolo Rapisarda</dc:creator>
    </item>
    <item>
      <title>Accelerated Mirror Descent for Non-Euclidean Star-convex Functions</title>
      <link>https://arxiv.org/abs/2405.18976</link>
      <description>arXiv:2405.18976v1 Announce Type: new 
Abstract: Acceleration for non-convex functions has been an important problem in optimisation. We revisit star-convex functions, which are strictly unimodal on all lines through a minimizer. In [1], the authors accelerate gradient descent for star-convex functions with gradients that are Lipschitz with respect to the Euclidean norm in an unconstrained domain. In this paper, we introduce a new assumption about the regularity of the derivative of a general norm and we accelerate mirror descent for this class of normed spaces. We show that, under it, our algorithms show sharp convergence rates for star-convex functions with -H"older continuous gradients. We also prove that our convergence rate is near optimal for -norms.
  [1] Near-Optimal Methods for Minimizing Star-Convex Functions and Beyond, Hinder Oliver and Sidford Aaron and Sohoni Nimit</description>
      <guid isPermaLink="false">oai:arXiv.org:2405.18976v1</guid>
      <category>math.OC</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Clement Lezane, Sophie Langer, Wouter M Koolen</dc:creator>
    </item>
    <item>
      <title>Computational bounds on randomized algorithms for online bin stretching</title>
      <link>https://arxiv.org/abs/2405.19071</link>
      <description>arXiv:2405.19071v1 Announce Type: new 
Abstract: A frequently studied performance measure in online optimization is competitive analysis. It corresponds to the worst-case ratio, over all possible inputs of an algorithm, between the performance of the algorithm and the optimal offline performance. However, this analysis may be too pessimistic to give valuable insight on a problem. Several workarounds exist, such as randomized algorithms. This paper aims to propose computational methods to construct randomized algorithms and to bound their performance on the classical online bin stretching problem. A game theory method is adapted to construct lower bounds on the performance of randomized online algorithms via linear programming. Another computational method is then proposed to construct randomized algorithms which perform better than the best deterministic algorithms known. Finally, another lower bound method for a restricted class of randomized algorithm for this problem is proposed.</description>
      <guid isPermaLink="false">oai:arXiv.org:2405.19071v1</guid>
      <category>math.OC</category>
      <category>cs.GT</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Antoine Lhomme, Nicolas Catusse, Nadia Brauner</dc:creator>
    </item>
    <item>
      <title>Least multivariate Chebyshev polynomials on diagonally determined domains</title>
      <link>https://arxiv.org/abs/2405.19219</link>
      <description>arXiv:2405.19219v1 Announce Type: new 
Abstract: We consider a new multivariate generalization of the classical monic (univariate) Chebyshev polynomial that minimizes the uniform norm on the interval $[-1,1]$. Let $\Pi^*_n$ be the subset of polynomials of degree at most $n$ in $d$ variables, whose homogeneous part of degree $n$ has coefficients summing up to $1$. The problem is determining a polynomial in $\Pi^*_n$ with the smallest uniform norm on a domain $\Omega$, which we call a least Chebyshev polynomial (associated with $\Omega$). Our main result solves the problem for $\Omega$ belonging to a non-trivial class of domains, defined by a property of its diagonal, and establishes the remarkable result that a least Chebyshev polynomial can be given via the classical, univariate, Chebyshev polynomial. In particular, the solution can be independent of the dimension. The result is valid for fairly general domains that can be non-convex and highly irregular.</description>
      <guid isPermaLink="false">oai:arXiv.org:2405.19219v1</guid>
      <category>math.OC</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Mareike Dressler, Simon Foucart, Mioara Joldes, Etienne de Klerk, Jean-Bernard Lasserre, Yuan Xu</dc:creator>
    </item>
    <item>
      <title>A random-key GRASP for combinatorial optimization</title>
      <link>https://arxiv.org/abs/2405.18681</link>
      <description>arXiv:2405.18681v2 Announce Type: cross 
Abstract: This paper proposes a problem-independent GRASP metaheuristic using the random-key optimizer (RKO) paradigm. GRASP (greedy randomized adaptive search procedure) is a metaheuristic for combinatorial optimization that repeatedly applies a semi-greedy construction procedure followed by a local search procedure. The best solution found over all iterations is returned as the solution of the GRASP. Continuous GRASP (C-GRASP) is an extension of GRASP for continuous optimization in the unit hypercube. A random-key optimizer (RKO) uses a vector of random keys to encode a solution to a combinatorial optimization problem. It uses a decoder to evaluate a solution encoded by the vector of random keys. A random-key GRASP is a C-GRASP where points in the unit hypercube are evaluated employing a decoder. We describe random key GRASP consisting of a problem-independent component and a problem-dependent decoder. As a proof of concept, the random-key GRASP is tested on five NP-hard combinatorial optimization problems: traveling salesman problem, tree of hubs location problem, Steiner triple covering problem, node capacitated graph partitioning problem, and job sequencing and tool switching problem.</description>
      <guid isPermaLink="false">oai:arXiv.org:2405.18681v2</guid>
      <category>cs.NE</category>
      <category>cs.AI</category>
      <category>math.OC</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Antonio A. Chaves, Mauricio G. C. Resende, Ricardo M. A. Silva</dc:creator>
    </item>
    <item>
      <title>Diffeomorphic interpolation for efficient persistence-based topological optimization</title>
      <link>https://arxiv.org/abs/2405.18820</link>
      <description>arXiv:2405.18820v1 Announce Type: cross 
Abstract: Topological Data Analysis (TDA) provides a pipeline to extract quantitative topological descriptors from structured objects. This enables the definition of topological loss functions, which assert to what extent a given object exhibits some topological properties. These losses can then be used to perform topological optimizationvia gradient descent routines. While theoretically sounded, topological optimization faces an important challenge: gradients tend to be extremely sparse, in the sense that the loss function typically depends on only very few coordinates of the input object, yielding dramatically slow optimization schemes in practice.Focusing on the central case of topological optimization for point clouds, we propose in this work to overcome this limitation using diffeomorphic interpolation, turning sparse gradients into smooth vector fields defined on the whole space, with quantifiable Lipschitz constants. In particular, we show that our approach combines efficiently with subsampling techniques routinely used in TDA, as the diffeomorphism derived from the gradient computed on a subsample can be used to update the coordinates of the full input object, allowing us to perform topological optimization on point clouds at an unprecedented scale. Finally, we also showcase the relevance of our approach for black-box autoencoder (AE) regularization, where we aim at enforcing topological priors on the latent spaces associated to fixed, pre-trained, black-box AE models, and where we show thatlearning a diffeomorphic flow can be done once and then re-applied to new data in linear time (while vanilla topological optimization has to be re-run from scratch). Moreover, reverting the flow allows us to generate data by sampling the topologically-optimized latent space directly, yielding better interpretability of the model.</description>
      <guid isPermaLink="false">oai:arXiv.org:2405.18820v1</guid>
      <category>cs.AI</category>
      <category>cs.CG</category>
      <category>math.OC</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Mathieu Carriere (CRISAM), Marc Theveneau (LIGM), Th\'eo Lacombe (LIGM)</dc:creator>
    </item>
    <item>
      <title>Compressing Large Language Models using Low Rank and Low Precision Decomposition</title>
      <link>https://arxiv.org/abs/2405.18886</link>
      <description>arXiv:2405.18886v1 Announce Type: cross 
Abstract: The prohibitive sizes of Large Language Models (LLMs) today make it difficult to deploy them on memory-constrained edge devices. This work introduces $\rm CALDERA$ -- a new post-training LLM compression algorithm that harnesses the inherent low-rank structure of a weight matrix $\mathbf{W}$ by approximating it via a low-rank, low-precision decomposition as $\mathbf{W} \approx \mathbf{Q} + \mathbf{L}\mathbf{R}$. Here, $\mathbf{L}$ and $\mathbf{R}$ are low rank factors, and the entries of $\mathbf{Q}$, $\mathbf{L}$ and $\mathbf{R}$ are quantized. The model is compressed by substituting each layer with its $\mathbf{Q} + \mathbf{L}\mathbf{R}$ decomposition, and the zero-shot performance of the compressed model is evaluated. Additionally, $\mathbf{L}$ and $\mathbf{R}$ are readily amenable to low-rank adaptation, consequently enhancing the zero-shot performance. $\rm CALDERA$ obtains this decomposition by formulating it as an optimization problem $\min_{\mathbf{Q},\mathbf{L},\mathbf{R}}\lVert(\mathbf{Q} + \mathbf{L}\mathbf{R} - \mathbf{W})\mathbf{X}^\top\rVert_{\rm F}^2$, where $\mathbf{X}$ is the calibration data, and $\mathbf{Q}, \mathbf{L}, \mathbf{R}$ are constrained to be representable using low-precision formats. Theoretical upper bounds on the approximation error of $\rm CALDERA$ are established using a rank-constrained regression framework, and the tradeoff between compression ratio and model performance is studied by analyzing the impact of target rank and quantization bit budget. Results illustrate that compressing LlaMa-$2$ $7$B/$70$B and LlaMa-$3$ $8$B models obtained using $\rm CALDERA$ outperforms existing post-training LLM compression techniques in the regime of less than $2.5$ bits per parameter. The implementation is available at: \href{https://github.com/pilancilab/caldera}{https://github.com/pilancilab/caldera}.</description>
      <guid isPermaLink="false">oai:arXiv.org:2405.18886v1</guid>
      <category>cs.LG</category>
      <category>cs.AI</category>
      <category>math.OC</category>
      <category>stat.ML</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Rajarshi Saha, Naomi Sagan, Varun Srivastava, Andrea J. Goldsmith, Mert Pilanci</dc:creator>
    </item>
    <item>
      <title>Decoding a mean field game by the Cauchy data around its unknown stationary states</title>
      <link>https://arxiv.org/abs/2405.18943</link>
      <description>arXiv:2405.18943v1 Announce Type: cross 
Abstract: In recent years, mean field games (MFGs) have garnered considerable attention and emerged as a dynamic and actively researched field across various domains, including economics, social sciences, finance, and transportation. The inverse design and decoding of MFGs offer valuable means to extract information from observed data and gain insights into the intricate underlying dynamics and strategies of these complex physical systems. This paper presents a novel approach to the study of inverse problems in MFGs by analyzing the Cauchy data around their unknown stationary states. This study distinguishes itself from existing inverse problem investigations in three key significant aspects: Firstly, we consider MFG problems in a highly general form. Secondly, we address the technical challenge of the probability measure constraint by utilizing Cauchy data in our inverse problem study. Thirdly, we enhance existing high order linearization methods by introducing a novel approach that involves conducting linearization around non-trivial stationary states of the MFG system, which are not a-priori known. These contributions provide new insights and offer promising avenues for studying inverse problems for MFGs. By unraveling the hidden structure of MFGs, researchers and practitioners can make informed decisions, optimize system performance, and address real-world challenges more effectively.</description>
      <guid isPermaLink="false">oai:arXiv.org:2405.18943v1</guid>
      <category>math.AP</category>
      <category>math.OC</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Hongyu Liu, Catharine W. K. Lo, Shen Zhang</dc:creator>
    </item>
    <item>
      <title>Determining state space anomalies in mean field games</title>
      <link>https://arxiv.org/abs/2405.18954</link>
      <description>arXiv:2405.18954v1 Announce Type: cross 
Abstract: In this paper, we are concerned with the inverse problem of determining anomalies in the state space associated with the stationary mean field game (MFG) system. We establish novel unique identifiability results for the intrinsic structure of these anomalies in mean field games systems, including their topological structure and parameter configurations, in several general scenarios of practical interest, including traffic flow, market economics and epidemics. To the best of our knowledge, this is the first work that considers anomalies in the state space for the nonlinear coupled MFG system.</description>
      <guid isPermaLink="false">oai:arXiv.org:2405.18954v1</guid>
      <category>math.AP</category>
      <category>math.OC</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Hongyu Liu, Catharine W. K. Lo</dc:creator>
    </item>
    <item>
      <title>On Dissipativity of Cross-Entropy Loss in Training ResNets</title>
      <link>https://arxiv.org/abs/2405.19013</link>
      <description>arXiv:2405.19013v1 Announce Type: cross 
Abstract: The training of ResNets and neural ODEs can be formulated and analyzed from the perspective of optimal control. This paper proposes a dissipative formulation of the training of ResNets and neural ODEs for classification problems by including a variant of the cross-entropy as a regularization in the stage cost. Based on the dissipative formulation of the training, we prove that the trained ResNet exhibit the turnpike phenomenon. We then illustrate that the training exhibits the turnpike phenomenon by training on the two spirals and MNIST datasets. This can be used to find very shallow networks suitable for a given classification task.</description>
      <guid isPermaLink="false">oai:arXiv.org:2405.19013v1</guid>
      <category>cs.LG</category>
      <category>cs.SY</category>
      <category>eess.SY</category>
      <category>math.OC</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Jens P\"uttschneider, Timm Faulwasser</dc:creator>
    </item>
    <item>
      <title>Efficient Optimal Control of Open Quantum Systems</title>
      <link>https://arxiv.org/abs/2405.19245</link>
      <description>arXiv:2405.19245v1 Announce Type: cross 
Abstract: The optimal control problem for open quantum systems can be formulated as a time-dependent Lindbladian that is parameterized by a number of time-dependent control variables. Given an observable and an initial state, the goal is to tune the control variables so that the expected value of some observable with respect to the final state is maximized. In this paper, we present algorithms for solving this optimal control problem efficiently, i.e., having a poly-logarithmic dependency on the system dimension, which is exponentially faster than best-known classical algorithms. Our algorithms are hybrid, consisting of both quantum and classical components. The quantum procedure simulates time-dependent Lindblad evolution that drives the initial state to the final state, and it also provides access to the gradients of the objective function via quantum gradient estimation. The classical procedure uses the gradient information to update the control variables.
  At the technical level, we provide the first (to the best of our knowledge) simulation algorithm for time-dependent Lindbladians with an $\ell_1$-norm dependence. As an alternative, we also present a simulation algorithm in the interaction picture to improve the algorithm for the cases where the time-independent component of a Lindbladian dominates the time-dependent part. On the classical side, we heavily adapt the state-of-the-art classical optimization analysis to interface with the quantum part of our algorithms. Both the quantum simulation techniques and the classical optimization analyses might be of independent interest.</description>
      <guid isPermaLink="false">oai:arXiv.org:2405.19245v1</guid>
      <category>quant-ph</category>
      <category>math.OC</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Wenhao He, Tongyang Li, Xiantao Li, Zecheng Li, Chunhao Wang, Ke Wang</dc:creator>
    </item>
    <item>
      <title>Simulation of Nonlinear Systems Trajectories: between Models and Behaviors</title>
      <link>https://arxiv.org/abs/2304.02930</link>
      <description>arXiv:2304.02930v3 Announce Type: replace 
Abstract: In this paper, we study connections between the classical model-based approach to nonlinear system theory, where systems are represented by equations, and the nonlinear behavioral approach, where systems are defined as sets of trajectories. In particular, we focus on equivalent representations of the systems in the two frameworks for the problem of simulating a future nonlinear system trajectory starting from a given set of noisy data. The goal also includes extending some existing results from the deterministic to the stochastic setting.</description>
      <guid isPermaLink="false">oai:arXiv.org:2304.02930v3</guid>
      <category>math.OC</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Antonio Fazzi, Alessandro Chiuso</dc:creator>
    </item>
    <item>
      <title>Finite element error analysis of affine optimal control problems</title>
      <link>https://arxiv.org/abs/2304.04882</link>
      <description>arXiv:2304.04882v5 Announce Type: replace 
Abstract: This paper is concerned with error estimates for the numerical approximation for affine optimal control problems subject to semilinear elliptic PDEs. To investigate the error estimates, we focus on local minimizers that satisfy certain local growth conditions. The local growth conditions we consider in this paper appeared recently in the context of solution stability and contain the joint growth of the first and second variation of the objective functional. These growth conditions are especially meaningful for affine control constrained optimal control problems because the first variation can satisfy a local growth, which is not the case for unconstrained problems. The main results of this paper are the achievement of error estimates for the numerical approximations generated by a finite element scheme with piecewise constant controls or a variational discretization scheme. Even though the growth conditions considered are weaker than those appearing in the recent literature on finite element error estimates for affine problems, this paper substantially improves the existing error estimates for both the optimal controls and the states when a H\"older-type growth is assumed.</description>
      <guid isPermaLink="false">oai:arXiv.org:2304.04882v5</guid>
      <category>math.OC</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Nicolai Jork</dc:creator>
    </item>
    <item>
      <title>A Homogenization Approach for Gradient-Dominated Stochastic Optimization</title>
      <link>https://arxiv.org/abs/2308.10630</link>
      <description>arXiv:2308.10630v3 Announce Type: replace 
Abstract: Gradient dominance property is a condition weaker than strong convexity, yet sufficiently ensures global convergence even in non-convex optimization. This property finds wide applications in machine learning, reinforcement learning (RL), and operations management. In this paper, we propose the stochastic homogeneous second-order descent method (SHSODM) for stochastic functions enjoying gradient dominance property based on a recently proposed homogenization approach. Theoretically, we provide its sample complexity analysis, and further present an enhanced result by incorporating variance reduction techniques. Our findings show that SHSODM matches the best-known sample complexity achieved by other second-order methods for gradient-dominated stochastic optimization but without cubic regularization. Empirically, since the homogenization approach only relies on solving extremal eigenvector problem at each iteration instead of Newton-type system, our methods gain the advantage of cheaper computational cost and robustness in ill-conditioned problems. Numerical experiments on several RL tasks demonstrate the better performance of SHSODM compared to other off-the-shelf methods.</description>
      <guid isPermaLink="false">oai:arXiv.org:2308.10630v3</guid>
      <category>math.OC</category>
      <category>cs.LG</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Jiyuan Tan, Chenyu Xue, Chuwen Zhang, Qi Deng, Dongdong Ge, Yinyu Ye</dc:creator>
    </item>
    <item>
      <title>Position: Optimization in SciML Should Employ the Function Space Geometry</title>
      <link>https://arxiv.org/abs/2402.07318</link>
      <description>arXiv:2402.07318v2 Announce Type: replace 
Abstract: Scientific machine learning (SciML) is a relatively new field that aims to solve problems from different fields of natural sciences using machine learning tools. It is well-documented that the optimizers commonly used in other areas of machine learning perform poorly on many SciML problems. We provide an infinite-dimensional view on optimization problems encountered in scientific machine learning and advocate for the paradigm first optimize, then discretize for their solution. This amounts to first choosing an appropriate infinite-dimensional algorithm which is then discretized in a second step. To illustrate this point, we show that recently proposed state-of-the-art algorithms for SciML applications can be derived within this framework. As the infinite-dimensional viewpoint is presently underdeveloped in scientific machine learning, we formalize it here and advocate for its use in SciML in the development of efficient optimization algorithms.</description>
      <guid isPermaLink="false">oai:arXiv.org:2402.07318v2</guid>
      <category>math.OC</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <arxiv:journal_reference>Proceedings of the 41 st International Conference on Machine Learning, Vienna, Austria. PMLR 235, 2024</arxiv:journal_reference>
      <dc:creator>Johannes M\"uller, Marius Zeinhofer</dc:creator>
    </item>
    <item>
      <title>Universal generalization guarantees for Wasserstein distributionally robust models</title>
      <link>https://arxiv.org/abs/2402.11981</link>
      <description>arXiv:2402.11981v2 Announce Type: replace 
Abstract: Distributionally robust optimization has emerged as an attractive way to train robust machine learning models, capturing data uncertainty and distribution shifts. Recent statistical analyses have proved that robust models built from Wasserstein ambiguity sets have nice generalization guarantees, breaking the curse of dimensionality. However, these results are obtained in specific cases, at the cost of approximations, or under assumptions difficult to verify in practice. In contrast, we establish, in this article, exact generalization guarantees that cover all practical cases, including any transport cost function and any loss function, potentially non-convex and nonsmooth. For instance, our result applies to deep learning, without requiring restrictive assumptions. We achieve this result through a novel proof technique that combines nonsmooth analysis rationale with classical concentration results. Our approach is general enough to extend to the recent versions of Wasserstein/Sinkhorn distributionally robust problems that involve (double) regularizations.</description>
      <guid isPermaLink="false">oai:arXiv.org:2402.11981v2</guid>
      <category>math.OC</category>
      <category>stat.ML</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Tam Le (DAO), J\'er\^ome Malick (DAO)</dc:creator>
    </item>
    <item>
      <title>Hamiltonian Descent and Coordinate Hamiltonian Descent</title>
      <link>https://arxiv.org/abs/2402.13988</link>
      <description>arXiv:2402.13988v2 Announce Type: replace 
Abstract: We propose an optimization algorithm called Hamiltonian Descent, which is a direct counterpart of classical Hamiltonian Monte Carlo in sampling. We find that Hamiltonian Descent for solving strongly convex quadratic problems exhibits a novel update scheme that involves matrix-power-vector products. We also propose Coordinate Hamiltonian Descent and its parallelizable variant, which turns out to encapsulate the classical Gauss-Seidel method, Successive Over-relaxation, Jacobi method, and more, for solving a linear system of equations. The result not only offers a new perspective on these existing algorithms but also leads to a broader class of update schemes that guarantee the convergence.</description>
      <guid isPermaLink="false">oai:arXiv.org:2402.13988v2</guid>
      <category>math.OC</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Jun-Kun Wang</dc:creator>
    </item>
    <item>
      <title>A gradient flow method for smooth splines versus least-squares fitting on Riemannian manifolds</title>
      <link>https://arxiv.org/abs/2402.18067</link>
      <description>arXiv:2402.18067v2 Announce Type: replace 
Abstract: This article presents a novel resolution to the problem of spline interpolation versus least-squares fitting on smooth Riemannian manifolds utilizing the method of gradient flows of networks. This approach represents a contribution to both geometric control theory and statistical shape data analysis. Our work encompasses a rigorous proof for the existence of global solutions in H\"{o}lder spaces for the gradient flow. The asymptotic limits of these solutions establish the existence of the spline interpolation versus least-squares fitting problem on smooth Riemannian manifolds, offering a comprehensive solution. Notably, the constructive nature of the proof suggests potential numerical schemes for finding solutions.</description>
      <guid isPermaLink="false">oai:arXiv.org:2402.18067v2</guid>
      <category>math.OC</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Chun-Chi Lin, The Dung Tran</dc:creator>
    </item>
    <item>
      <title>Identification of High-dimensional ARMA Models with Binary-Valued Observations</title>
      <link>https://arxiv.org/abs/2404.01613</link>
      <description>arXiv:2404.01613v4 Announce Type: replace 
Abstract: This paper studies system identification of high-dimensional ARMA models with binary-valued observations. Compared with existing quantized identification of ARMA models, this problem is more challenging since the accessible information is much less. Different from the identification of FIR models with binary-valued observations, the prediction of original system output and the parameter both need to be estimated in ARMA models. We propose an online identification algorithm consisting of parameter estimation and prediction of original system output. The parameter estimation and the prediction of original output are strongly coupled but mutually reinforcing. By analyzing the two estimates at the same time instead of analyzing separately, we finally prove that the parameter estimate can converge to the true parameter with convergence rate $O(1/k)$ under certain conditions. Simulations are given to demonstrate the theoretical results.</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.01613v4</guid>
      <category>math.OC</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Xin Li, Ting Wang, Jin Guo, Yanlong Zhao</dc:creator>
    </item>
    <item>
      <title>Why does the two-timescale Q-learning converge to different mean field solutions? A unified convergence analysis</title>
      <link>https://arxiv.org/abs/2404.04357</link>
      <description>arXiv:2404.04357v3 Announce Type: replace 
Abstract: We revisit the unified two-timescale Q-learning algorithm as initially introduced by Angiuli et al. \cite{angiuli2022unified}. This algorithm demonstrates efficacy in solving mean field game (MFG) and mean field control (MFC) problems, simply by tuning the ratio of two learning rates for mean field distribution and the Q-functions respectively. In this paper, we provide a comprehensive theoretical explanation of the algorithm's bifurcated numerical outcomes under fixed learning rates. We achieve this by establishing a diagram that correlates continuous-time mean field problems to their discrete-time Q-function counterparts, forming the basis of the algorithm. Our key contribution lies in the construction of a Lyapunov function integrating both mean field distribution and Q-function iterates. This Lyapunov function facilitates a unified convergence of the algorithm across the entire spectrum of learning rates, thus providing a cohesive framework for analysis.</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.04357v3</guid>
      <category>math.OC</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Jing An, Jianfeng Lu, Yue Wu, Yang Xiang</dc:creator>
    </item>
    <item>
      <title>Regularized Q-learning through Robust Averaging</title>
      <link>https://arxiv.org/abs/2405.02201</link>
      <description>arXiv:2405.02201v2 Announce Type: replace 
Abstract: We propose a new Q-learning variant, called 2RA Q-learning, that addresses some weaknesses of existing Q-learning methods in a principled manner. One such weakness is an underlying estimation bias which cannot be controlled and often results in poor performance. We propose a distributionally robust estimator for the maximum expected value term, which allows us to precisely control the level of estimation bias introduced. The distributionally robust estimator admits a closed-form solution such that the proposed algorithm has a computational cost per iteration comparable to Watkins' Q-learning. For the tabular case, we show that 2RA Q-learning converges to the optimal policy and analyze its asymptotic mean-squared error. Lastly, we conduct numerical experiments for various settings, which corroborate our theoretical findings and indicate that 2RA Q-learning often performs better than existing methods.</description>
      <guid isPermaLink="false">oai:arXiv.org:2405.02201v2</guid>
      <category>math.OC</category>
      <category>cs.LG</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Peter Schmitt-F\"orster, Tobias Sutter</dc:creator>
    </item>
    <item>
      <title>A Symplectic Analysis of Alternating Mirror Descent</title>
      <link>https://arxiv.org/abs/2405.03472</link>
      <description>arXiv:2405.03472v2 Announce Type: replace 
Abstract: Motivated by understanding the behavior of the Alternating Mirror Descent (AMD) algorithm for bilinear zero-sum games, we study the discretization of continuous-time Hamiltonian flow via the symplectic Euler method. We provide a framework for analysis using results from Hamiltonian dynamics, Lie algebra, and symplectic numerical integrators, with an emphasis on the existence and properties of a conserved quantity, the modified Hamiltonian (MH), for the symplectic Euler method. We compute the MH in closed-form when the original Hamiltonian is a quadratic function, and show that it generally differs from the other conserved quantity known previously in that case. We derive new error bounds on the MH when truncated at orders in the stepsize in terms of the number of iterations, $K$, and use these bounds to show an improved $\mathcal{O}(K^{1/5})$ total regret bound and an $\mathcal{O}(K^{-4/5})$ duality gap of the average iterates for AMD. Finally, we propose a conjecture which, if true, would imply that the total regret for AMD scales as $\mathcal{O}\left(K^{\varepsilon}\right)$ and the duality gap of the average iterates as $\mathcal{O}\left(K^{-1+\varepsilon}\right)$ for any $\varepsilon&gt;0$, and we can take $\varepsilon=0$ upon certain convergence conditions for the MH.</description>
      <guid isPermaLink="false">oai:arXiv.org:2405.03472v2</guid>
      <category>math.OC</category>
      <category>cs.GT</category>
      <category>cs.LG</category>
      <category>cs.NA</category>
      <category>math.DS</category>
      <category>math.NA</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Jonas Katona, Xiuyuan Wang, Andre Wibisono</dc:creator>
    </item>
    <item>
      <title>Generalized Nash equilibrium problems with quasi-linear constraints</title>
      <link>https://arxiv.org/abs/2405.03926</link>
      <description>arXiv:2405.03926v2 Announce Type: replace 
Abstract: We study generalized Nash equilibrium problems (GNEPs) such that objectives are polynomial functions, and each player's constraints are linear in their own strategy. For such GNEPs, the KKT sets can be represented as unions of simpler sets by Carath\'{e}odory's theorem. We give a convenient representation for KKT sets using partial Lagrange multiplier expressions. This produces a set of branch polynomial optimization problems, which can be efficiently solved by Moment-SOS relaxations. By doing this, we can compute all generalized Nash equilibria or detect their nonexistence. Numerical experiments are also provided to demonstrate the computational efficiency.</description>
      <guid isPermaLink="false">oai:arXiv.org:2405.03926v2</guid>
      <category>math.OC</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Jiyoung Choi, Jiawang Nie, Xindong Tang, Suhan Zhong</dc:creator>
    </item>
    <item>
      <title>Convergence Rates of Online Critic Value Function Approximation in Native Spaces</title>
      <link>https://arxiv.org/abs/2405.05887</link>
      <description>arXiv:2405.05887v3 Announce Type: replace 
Abstract: In this paper, the evolution equation that defines the online critic for the approximation of the optimal value function is cast in a general class of reproducing kernel Hilbert spaces (RKHSs). Exploiting some core tools of RKHS theory, this formulation allows deriving explicit bounds on the performance of the critic in terms of the kernel and definition of the RKHS, the number of basis functions, and the location of centers used to define scattered bases. The performance of the critic is precisely measured in terms of the power function of the scattered basis used in approximations, and it can be used either in an a priori evaluation of potential bases or in an a posteriori assessments of value function error for basis enrichment or pruning. The most concise bounds in the paper describe explicitly how the critic performance depends on the placement of centers, as measured by their fill distance in a subset that contains the trajectory of the critic.</description>
      <guid isPermaLink="false">oai:arXiv.org:2405.05887v3</guid>
      <category>math.OC</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <dc:creator>Shengyuan Niu, Ali Bouland, Haoran Wang, Filippos Fotiadis, Andrew Kurdila, Andrea L'Afflitto, Sai Tej Paruchuri, Kyriakos G. Vamvoudakis</dc:creator>
    </item>
    <item>
      <title>Subgradient Convergence Implies Subdifferential Convergence on Weakly Convex Functions: With Uniform Rates Guarantees</title>
      <link>https://arxiv.org/abs/2405.10289</link>
      <description>arXiv:2405.10289v3 Announce Type: replace 
Abstract: In nonsmooth, nonconvex stochastic optimization, understanding the uniform convergence of subdifferential mappings is crucial for analyzing stationary points of sample average approximations of risk as they approach the population risk. Yet, characterizing this convergence remains a fundamental challenge.
  This work introduces a novel perspective by connecting the uniform convergence of subdifferential mappings to that of subgradient mappings as empirical risk converges to the population risk. We prove that, for stochastic weakly-convex objectives, and within any open set, a uniform bound on the convergence of subgradients -- chosen arbitrarily from the corresponding subdifferential sets -- translates to a uniform bound on the convergence of the subdifferential sets itself, measured by the Hausdorff metric.
  Using this technique, we derive uniform convergence rates for subdifferential sets of stochastic convex-composite objectives. Our results do not rely on key distributional assumptions in the literature, which require the population and finite sample subdifferentials to be continuous in the Hausdorff metric, yet still provide tight convergence rates. These guarantees lead to new insights into the nonsmooth landscapes of such objectives within finite samples.</description>
      <guid isPermaLink="false">oai:arXiv.org:2405.10289v3</guid>
      <category>math.OC</category>
      <category>math.ST</category>
      <category>stat.ML</category>
      <category>stat.TH</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Feng Ruan</dc:creator>
    </item>
    <item>
      <title>Bagging Improves Generalization Exponentially</title>
      <link>https://arxiv.org/abs/2405.14741</link>
      <description>arXiv:2405.14741v2 Announce Type: replace 
Abstract: Bagging is a popular ensemble technique to improve the accuracy of machine learning models. It hinges on the well-established rationale that, by repeatedly retraining on resampled data, the aggregated model exhibits lower variance and hence higher stability, especially for discontinuous base learners. In this paper, we provide a new perspective on bagging: By suitably aggregating the base learners at the parametrization instead of the output level, bagging improves generalization performances exponentially, a strength that is significantly more powerful than variance reduction. More precisely, we show that for general stochastic optimization problems that suffer from slowly (i.e., polynomially) decaying generalization errors, bagging can effectively reduce these errors to an exponential decay. Moreover, this power of bagging is agnostic to the solution schemes, including common empirical risk minimization, distributionally robust optimization, and various regularizations. We demonstrate how bagging can substantially improve generalization performances in a range of examples involving heavy-tailed data that suffer from intrinsically slow rates.</description>
      <guid isPermaLink="false">oai:arXiv.org:2405.14741v2</guid>
      <category>math.OC</category>
      <category>cs.LG</category>
      <category>stat.ML</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/publicdomain/zero/1.0/</dc:rights>
      <dc:creator>Huajie Qian, Donghao Ying, Henry Lam, Wotao Yin</dc:creator>
    </item>
    <item>
      <title>Coupling Analysis of the Asymptotic Behaviour of a Primal-Dual Langevin Algorithm</title>
      <link>https://arxiv.org/abs/2405.18098</link>
      <description>arXiv:2405.18098v2 Announce Type: replace 
Abstract: We analyze a recently proposed algorithm for the problem of sampling from probability distributions $\mu^\ast$ in $\mathbb{R}^d$ with a Lebesgue density of the form $\mu^\ast(x) \propto \exp(-f(Kx)-g(x))$, where $K$ is a linear operator and $f,g$ convex and non-smooth. The algorithm is a generalization of the primal-dual hybrid gradient (PDHG) convex optimization algorithm to a sampling scheme. We analyze the method's continuous time limit, an SDE in the joint primal-dual variable. We give mild conditions under which the corresponding Fokker-Planck equation converges to a unique stationary state, which however does not concentrate in the dual variable and consequently does not have $\mu^\ast$ as its primal marginal. Under a smoothness assumption on $f$, we show that the scheme converges to the purely primal overdamped Langevin diffusion in the limit of small primal and large dual step sizes. We further prove that the target can never be the primal marginal of the invariant solution for any modification of the SDE with space-homogeneous diffusion coefficient. A correction with inhomogeneous diffusion coefficient and the correct invariant solution is proposed, but the scheme requires the same smoothness assumptions on $f$ and is numerically inferior to overdamped Langevin diffusion. We demonstrate our findings numerically, first on small-scale examples in which we can exactly verify the theoretical results, and subsequently on typical examples of larger scale from Bayesian imaging inverse problems.</description>
      <guid isPermaLink="false">oai:arXiv.org:2405.18098v2</guid>
      <category>math.OC</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Martin Burger, Matthias J. Ehrhardt, Lorenz Kuger, Lukas Weigand</dc:creator>
    </item>
    <item>
      <title>3D genome reconstruction from partially phased Hi-C data</title>
      <link>https://arxiv.org/abs/2301.11764</link>
      <description>arXiv:2301.11764v2 Announce Type: replace-cross 
Abstract: The 3-dimensional (3D) structure of the genome is of significant importance for many cellular processes. In this paper, we study the problem of reconstructing the 3D structure of chromosomes from Hi-C data of diploid organisms, which poses additional challenges compared to the better-studied haploid setting. With the help of techniques from algebraic geometry, we prove that a small amount of phased data is sufficient to ensure finite identifiability, both for noiseless and noisy data. In the light of these results, we propose a new 3D reconstruction method based on semidefinite programming, paired with numerical algebraic geometry and local optimization. The performance of this method is tested on several simulated datasets under different noise levels and with different amounts of phased data. We also apply it to a real dataset from mouse X chromosomes, and we are then able to recover previously known structural features.</description>
      <guid isPermaLink="false">oai:arXiv.org:2301.11764v2</guid>
      <category>q-bio.GN</category>
      <category>math.AG</category>
      <category>math.OC</category>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <arxiv:DOI>10.1007/s11538-024-01263-7</arxiv:DOI>
      <arxiv:journal_reference>Bulletin of Mathematical Biology 86, 33 (2024)</arxiv:journal_reference>
      <dc:creator>Diego Cifuentes, Jan Draisma, Oskar Henriksson, Annachiara Korchmaros, Kaie Kubjas</dc:creator>
    </item>
    <item>
      <title>Incentivising Demand Side Response through Discount Scheduling using Hybrid Quantum Optimization</title>
      <link>https://arxiv.org/abs/2309.05502</link>
      <description>arXiv:2309.05502v2 Announce Type: replace-cross 
Abstract: Demand Side Response (DSR) is a strategy that enables consumers to actively participate in managing electricity demand. It aims to alleviate strain on the grid during high demand and promote a more balanced and efficient use of (renewable) electricity resources. We implement DSR through discount scheduling, which involves offering discrete price incentives to consumers to adjust their electricity consumption patterns to times when their local energy mix consists of more renewable energy. Since we tailor the discounts to individual customers' consumption, the Discount Scheduling Problem (DSP) becomes a large combinatorial optimization task. Consequently, we adopt a hybrid quantum computing approach, using D-Wave's Leap Hybrid Cloud. We benchmark Leap against Gurobi, a classical Mixed Integer optimizer in terms of solution quality at fixed runtime and fairness in terms of discount allocation. Furthermore, we propose a large-scale decomposition algorithm/heuristic for the DSP, applied with either quantum or classical computers running the subroutines, which significantly reduces the problem size while maintaining solution quality. Using synthetic data generated from real-world data, we observe that the classical decomposition method obtains the best overall \newp{solution quality for problem sizes up to 3200 consumers, however, the hybrid quantum approach provides more evenly distributed discounts across consumers.</description>
      <guid isPermaLink="false">oai:arXiv.org:2309.05502v2</guid>
      <category>quant-ph</category>
      <category>math.OC</category>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>David Bucher, Jonas N\"u{\ss}lein, Corey O'Meara, Ivan Angelov, Benedikt Wimmer, Kumar Ghosh, Giorgio Cortiana, Claudia Linnhoff-Popien</dc:creator>
    </item>
    <item>
      <title>On the Error-Propagation of Inexact Hotelling's Deflation for Principal Component Analysis</title>
      <link>https://arxiv.org/abs/2310.04283</link>
      <description>arXiv:2310.04283v2 Announce Type: replace-cross 
Abstract: Principal Component Analysis (PCA) aims to find subspaces spanned by the so-called principal components that best represent the variance in the dataset. The deflation method is a popular meta-algorithm that sequentially finds individual principal components, starting from the most important ones and working towards the less important ones. However, as deflation proceeds, numerical errors from the imprecise estimation of principal components propagate due to its sequential nature. This paper mathematically characterizes the error propagation of the inexact Hotelling's deflation method. We consider two scenarios: $i)$ when the sub-routine for finding the leading eigenvector is abstract and can represent various algorithms; and $ii)$ when power iteration is used as the sub-routine. In the latter case, the additional directional information from power iteration allows us to obtain a tighter error bound than the sub-routine agnostic case. For both scenarios, we explicitly characterize how the errors progress and affect subsequent principal component estimations.</description>
      <guid isPermaLink="false">oai:arXiv.org:2310.04283v2</guid>
      <category>cs.LG</category>
      <category>math.OC</category>
      <category>stat.ML</category>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Fangshuo Liao, Junhyung Lyle Kim, Cruz Barnum, Anastasios Kyrillidis</dc:creator>
    </item>
    <item>
      <title>High-Performance Hybrid Algorithm for Minimum Sum-of-Squares Clustering of Infinitely Tall Data</title>
      <link>https://arxiv.org/abs/2311.04517</link>
      <description>arXiv:2311.04517v3 Announce Type: replace-cross 
Abstract: This paper introduces a novel formulation of the clustering problem, namely the Minimum Sum-of-Squares Clustering of Infinitely Tall Data (MSSC-ITD), and presents HPClust, an innovative set of hybrid parallel approaches for its effective solution. By utilizing modern high-performance computing techniques, HPClust enhances key clustering metrics: effectiveness, computational efficiency, and scalability. In contrast to vanilla data parallelism, which only accelerates processing time through the MapReduce framework, our approach unlocks superior performance by leveraging the multi-strategy competitive-cooperative parallelism and intricate properties of the objective function landscape. Unlike other available algorithms that struggle to scale, our algorithm is inherently parallel in nature, improving solution quality through increased scalability and parallelism, and outperforming even advanced algorithms designed for small and medium-sized datasets. Our evaluation of HPClust, featuring four parallel strategies, demonstrates its superiority over traditional and cutting-edge methods by offering better performance in the key metrics. These results also show that parallel processing not only enhances the clustering efficiency, but the accuracy as well. Additionally, we explore the balance between computational efficiency and clustering quality, providing insights into optimal parallel strategies based on dataset specifics and resource availability. This research advances our understanding of parallelism in clustering algorithms, demonstrating that a judicious hybridization of advanced parallel approaches yields optimal results for MSSC-ITD. Experiments on synthetic data further confirm HPClust's exceptional scalability and robustness to noise.</description>
      <guid isPermaLink="false">oai:arXiv.org:2311.04517v3</guid>
      <category>cs.DC</category>
      <category>cs.LG</category>
      <category>math.OC</category>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-sa/4.0/</dc:rights>
      <dc:creator>Ravil Mussabayev, Rustam Mussabayev</dc:creator>
    </item>
    <item>
      <title>Gradient Descent with Polyak's Momentum Finds Flatter Minima via Large Catapults</title>
      <link>https://arxiv.org/abs/2311.15051</link>
      <description>arXiv:2311.15051v3 Announce Type: replace-cross 
Abstract: Although gradient descent with Polyak's momentum is widely used in modern machine and deep learning, a concrete understanding of its effects on the training trajectory remains elusive. In this work, we empirically show that for linear diagonal networks and nonlinear neural networks, momentum gradient descent with a large learning rate displays large catapults, driving the iterates towards much flatter minima than those found by gradient descent. We hypothesize that the large catapult is caused by momentum "prolonging" the self-stabilization effect (Damian et al., 2023). We provide theoretical and empirical support for our hypothesis in a simple toy example and empirical evidence supporting our hypothesis for linear diagonal networks.</description>
      <guid isPermaLink="false">oai:arXiv.org:2311.15051v3</guid>
      <category>cs.LG</category>
      <category>math.OC</category>
      <category>stat.ML</category>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Prin Phunyaphibarn, Junghyun Lee, Bohan Wang, Huishuai Zhang, Chulhee Yun</dc:creator>
    </item>
    <item>
      <title>Decoupling Learning and Decision-Making: Breaking the $\mathcal{O}(\sqrt{T})$ Barrier in Online Resource Allocation with First-Order Methods</title>
      <link>https://arxiv.org/abs/2402.07108</link>
      <description>arXiv:2402.07108v2 Announce Type: replace-cross 
Abstract: Online linear programming plays an important role in both revenue management and resource allocation, and recent research has focused on developing efficient first-order online learning algorithms. Despite the empirical success of first-order methods, they typically achieve a regret no better than $\mathcal{O}(\sqrt{T})$, which is suboptimal compared to the $\mathcal{O}(\log T)$ bound guaranteed by the state-of-the-art linear programming (LP)-based online algorithms. This paper establishes several important facts about online linear programming, which unveils the challenge for first-order-method-based online algorithms to achieve beyond $\mathcal{O}(\sqrt{T})$ regret. To address the challenge, we introduce a new algorithmic framework that decouples learning from decision-making. For the first time, we show that first-order methods can attain regret $\mathcal{O}(T^{1/3})$ with this new framework.</description>
      <guid isPermaLink="false">oai:arXiv.org:2402.07108v2</guid>
      <category>cs.LG</category>
      <category>math.OC</category>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Wenzhi Gao, Chunlin Sun, Chenyu Xue, Dongdong Ge, Yinyu Ye</dc:creator>
    </item>
    <item>
      <title>Efficient Algorithms for Regularized Nonnegative Scale-invariant Low-rank Approximation Models</title>
      <link>https://arxiv.org/abs/2403.18517</link>
      <description>arXiv:2403.18517v2 Announce Type: replace-cross 
Abstract: Regularized nonnegative low-rank approximations such as sparse Nonnegative Matrix Factorization or sparse Nonnegative Tucker Decomposition are an important branch of dimensionality reduction models with enhanced interpretability. However, from a practical perspective, the choice of regularizers and regularization coefficients, as well as the design of efficient algorithms, is challenging because of the multifactor nature of these models and the lack of theory to back these choices. This paper aims at improving upon these issues. By studying a more general model called the Homogeneous Regularized Scale-Invariant, we prove that the scale-invariance inherent to low-rank approximation models causes an implicit regularization with both unexpected beneficial and detrimental effects. This observation allows to better understand the effect of regularization functions in low-rank approximation models, to guide the choice of the regularization hyperparameters, and to design balancing strategies to enhance the convergence speed of dedicated optimization algorithms. Some of these results were already known but restricted to specific instances of regularized low-rank approximations. We also derive a generic Majorization Minimization algorithm that handles many regularized nonnegative low-rank approximations, with convergence guarantees. We showcase our contributions on sparse Nonnegative Matrix Factorization, ridge-regularized Canonical Polyadic decomposition and sparse Nonnegative Tucker Decomposition.</description>
      <guid isPermaLink="false">oai:arXiv.org:2403.18517v2</guid>
      <category>cs.LG</category>
      <category>cs.NA</category>
      <category>math.NA</category>
      <category>math.OC</category>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Jeremy E. Cohen, Valentin Leplat</dc:creator>
    </item>
    <item>
      <title>Constrained monotone mean--variance investment-reinsurance under the Cram\'er--Lundberg model with random coefficients</title>
      <link>https://arxiv.org/abs/2405.17841</link>
      <description>arXiv:2405.17841v2 Announce Type: replace-cross 
Abstract: This paper studies an optimal investment-reinsurance problem for an insurer (she) under the Cram\'er--Lundberg model with monotone mean--variance (MMV) criterion. At any time, the insurer can purchase reinsurance (or acquire new business) and invest in a security market consisting of a risk-free asset and multiple risky assets whose excess return rate and volatility rate are allowed to be random. The trading strategy is subject to a general convex cone constraint, encompassing no-shorting constraint as a special case. The optimal investment-reinsurance strategy and optimal value for the MMV problem are deduced by solving certain backward stochastic differential equations with jumps. In the literature, it is known that models with MMV criterion and mean--variance criterion lead to the same optimal strategy and optimal value when the wealth process is continuous. Our result shows that the conclusion remains true even if the wealth process has compensated Poisson jumps and the market coefficients are random.</description>
      <guid isPermaLink="false">oai:arXiv.org:2405.17841v2</guid>
      <category>q-fin.PM</category>
      <category>math.OC</category>
      <category>q-fin.MF</category>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <arxiv:DOI>10.1016/j.sysconle.2024.105796</arxiv:DOI>
      <dc:creator>Xiaomin Shi, Zuo Quan Xu</dc:creator>
    </item>
  </channel>
</rss>
