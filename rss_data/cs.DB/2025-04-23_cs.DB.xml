<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>cs.DB updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/cs.DB</link>
    <description>cs.DB updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/cs.DB" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Thu, 24 Apr 2025 04:00:36 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Thu, 24 Apr 2025 00:00:00 -0400</pubDate>
    <skipDays>
      <day>Saturday</day>
      <day>Sunday</day>
    </skipDays>
    <item>
      <title>Circinus: Efficient Query Planner for Compound ML Serving</title>
      <link>https://arxiv.org/abs/2504.16397</link>
      <description>arXiv:2504.16397v1 Announce Type: new 
Abstract: The rise of compound AI serving -- integrating multiple operators in a pipeline that may span edge and cloud tiers -- enables end-user applications such as autonomous driving, generative AI-powered meeting companions, and immersive gaming. Achieving high service goodput -- i.e., meeting service level objectives (SLOs) for pipeline latency, accuracy, and costs -- requires effective planning of operator placement, configuration, and resource allocation across infrastructure tiers. However, the diverse SLO requirements, varying edge capabilities, and high query volumes create an enormous planning search space, rendering current solutions fundamentally limited for real-time serving and cost-efficient deployments.
  This paper presents Circinus, an SLO-aware query planner for large-scale compound AI workloads. Circinus novelly decomposes multi-query planning and multi-dimensional SLO objectives while preserving global decision quality. By exploiting plan similarities within and across queries, it significantly reduces search steps. It further improves per-step efficiency with a precision-aware plan profiler that incrementally profiles and strategically applies early stopping based on imprecise estimates of plan performance. At scale, Circinus selects query-plan combinations to maximize global SLO goodput. Evaluations in real-world settings show that Circinus improves service goodput by 3.2-5.0$\times$, accelerates query planning by 4.2-5.8$\times$, achieving query response in seconds, while reducing deployment costs by 3.2-4.0$\times$ over state of the arts even in their intended single-tier deployments.</description>
      <guid isPermaLink="false">oai:arXiv.org:2504.16397v1</guid>
      <category>cs.DB</category>
      <category>cs.LG</category>
      <pubDate>Thu, 24 Apr 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Banruo Liu, Wei-Yu Lin, Minghao Fang, Yihan Jiang, Fan Lai</dc:creator>
    </item>
    <item>
      <title>MPAD: A New Dimension-Reduction Method for Preserving Nearest Neighbors in High-Dimensional Vector Search</title>
      <link>https://arxiv.org/abs/2504.16335</link>
      <description>arXiv:2504.16335v1 Announce Type: cross 
Abstract: High-dimensional vector embeddings are widely used in retrieval systems, yet dimensionality reduction (DR) is seldom applied due to its tendency to distort nearest-neighbor (NN) structure critical for search. Existing DR techniques such as PCA and UMAP optimize global or manifold-preserving criteria, rather than retrieval-specific objectives. We present MPAD: Maximum Pairwise Absolute Difference, an unsupervised DR method that explicitly preserves approximate NN relations by maximizing the margin between k-NNs and non-k-NNs under a soft orthogonality constraint. This design enables MPAD to retain ANN-relevant geometry without supervision or changes to the original embedding model. Experiments across multiple domains show that MPAD consistently outperforms standard DR methods in preserving neighborhood structure, enabling more accurate search in reduced dimensions.</description>
      <guid isPermaLink="false">oai:arXiv.org:2504.16335v1</guid>
      <category>cs.IR</category>
      <category>cs.DB</category>
      <pubDate>Thu, 24 Apr 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Jiuzhou Fu, Dongfang Zhao</dc:creator>
    </item>
    <item>
      <title>Efficient Data Valuation Approximation in Federated Learning: A Sampling-based Approach</title>
      <link>https://arxiv.org/abs/2504.16668</link>
      <description>arXiv:2504.16668v1 Announce Type: cross 
Abstract: Federated learning paradigm to utilize datasets across multiple data providers. In FL, cross-silo data providers often hesitate to share their high-quality dataset unless their data value can be fairly assessed. Shapley value (SV) has been advocated as the standard metric for data valuation in FL due to its desirable properties. However, the computational overhead of SV is prohibitive in practice, as it inherently requires training and evaluating an FL model across an exponential number of dataset combinations. Furthermore, existing solutions fail to achieve high accuracy and efficiency, making practical use of SV still out of reach, because they ignore choosing suitable computation scheme for approximation framework and overlook the property of utility function in FL. We first propose a unified stratified-sampling framework for two widely-used schemes. Then, we analyze and choose the more promising scheme under the FL linear regression assumption. After that, we identify a phenomenon termed key combinations, where only limited dataset combinations have a high-impact on final data value. Building on these insights, we propose a practical approximation algorithm, IPSS, which strategically selects high-impact dataset combinations rather than evaluating all possible combinations, thus substantially reducing time cost with minor approximation error. Furthermore, we conduct extensive evaluations on the FL benchmark datasets to demonstrate that our proposed algorithm outperforms a series of representative baselines in terms of efficiency and effectiveness.</description>
      <guid isPermaLink="false">oai:arXiv.org:2504.16668v1</guid>
      <category>cs.LG</category>
      <category>cs.DB</category>
      <pubDate>Thu, 24 Apr 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Shuyue Wei, Yongxin Tong, Zimu Zhou, Tianran He, Yi Xu</dc:creator>
    </item>
    <item>
      <title>Towards Practicable Algorithms for Rewriting Graph Queries beyond DL-Lite</title>
      <link>https://arxiv.org/abs/2405.18181</link>
      <description>arXiv:2405.18181v3 Announce Type: replace 
Abstract: Despite the many advantages that ontology-based data access (OBDA) has brought to a range of application domains, state-of-the-art OBDA systems still do not support popular graph database management systems such as Neo4j. Algorithms for query rewriting focus on languages like conjunctive queries and their unions, which are fragments of first-order logic and were developed for relational data. Such query languages are poorly suited for querying graph data. Moreover, they also limit the expressiveness of the ontology languages that admit rewritings, restricting them to those where the data complexity of reasoning is not higher than it is in first-order logic. In this paper, we propose a technique for rewriting a family of navigational queries for a suitably restricted fragment of ELHI that extends DL-Lite and that is NL-complete in data complexity. We implemented a proof-of-concept prototype that rewrites into Cypher queries, and tested it on a real-world cognitive neuroscience use case with promising results.</description>
      <guid isPermaLink="false">oai:arXiv.org:2405.18181v3</guid>
      <category>cs.DB</category>
      <category>cs.LO</category>
      <pubDate>Thu, 24 Apr 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Bianca L\"ohnert, Nikolaus Augsten, Cem Okulmus, Magdalena Ortiz</dc:creator>
    </item>
    <item>
      <title>Hub Star Modeling 2.0 for Medallion Architecture</title>
      <link>https://arxiv.org/abs/2504.08788</link>
      <description>arXiv:2504.08788v2 Announce Type: replace 
Abstract: Data warehousing enables performant access to high-quality data integrated from dynamic data sources. The medallion architecture, a standard for data warehousing, addresses these goals by organizing data into bronze, silver and gold layers, representing raw, integrated, and fit-to-purpose data, respectively. In terms of data modeling, bronze layer retains the structure of source data with additional metadata. The gold layer follows established modeling approaches such as star schema, snowflake, and flattened tables. The silver layer, acting as a canonical form, requires a flexible and scalable model to support continuous changes and incremental development. This paper introduces an enhanced Hub Star modeling approach tailored for the medallion architecture, simplifying silver-layer data modeling by generalizing hub and star concepts. This approach has been demonstrated using Databricks and the retail-org sample dataset, with all modeling and transformation scripts available on GitHub.</description>
      <guid isPermaLink="false">oai:arXiv.org:2504.08788v2</guid>
      <category>cs.DB</category>
      <pubDate>Thu, 24 Apr 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Shahram Salami</dc:creator>
    </item>
    <item>
      <title>GNN-based Anchor Embedding for Exact Subgraph Matching</title>
      <link>https://arxiv.org/abs/2502.00031</link>
      <description>arXiv:2502.00031v3 Announce Type: replace-cross 
Abstract: Subgraph matching query is a classic problem in graph data management and has a variety of real-world applications, such as discovering structures in biological or chemical networks, finding communities in social network analysis, explaining neural networks, and so on. To further solve the subgraph matching problem, several recent advanced works attempt to utilize deep-learning-based techniques to handle the subgraph matching query. However, most of these works only obtain approximate results for subgraph matching without theoretical guarantees of accuracy. In this paper, we propose a novel and effective graph neural network (GNN)-based anchor embedding framework (GNN-AE), which allows exact subgraph matching. Unlike GNN-based approximate subgraph matching approaches that only produce inexact results, in this paper, we pioneer a series of concepts related to anchor (including anchor, anchor graph/path, etc.) in subgraph matching and carefully devise the anchor (graph) embedding technique based on GNN models. We transform the subgraph matching problem into a search problem in the embedding space via the anchor (graph &amp; path) embedding techniques. With the proposed anchor matching mechanism, GNN-AE can guarantee subgraph matching has no false dismissals. We design an efficient matching growth algorithm, which can retrieve the locations of all exact matches in parallel. We also propose a cost-model-based DFS query plan to enhance the parallel matching growth algorithm. Through extensive experiments on 6 real-world and 3 synthetic datasets, we confirm the effectiveness and efficiency of our GNN-AE approach for exact subgraph matching.</description>
      <guid isPermaLink="false">oai:arXiv.org:2502.00031v3</guid>
      <category>cs.SI</category>
      <category>cs.DB</category>
      <pubDate>Thu, 24 Apr 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Bin Yang, Zhaonian Zou, Jianxiong Ye</dc:creator>
    </item>
  </channel>
</rss>
