<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>math.OC updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/math.OC</link>
    <description>math.OC updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/math.OC" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Fri, 31 Oct 2025 01:39:25 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Thu, 30 Oct 2025 00:00:00 -0400</pubDate>
    <skipDays>
      <day>Saturday</day>
      <day>Sunday</day>
    </skipDays>
    <item>
      <title>A Compressive Sensing Inspired Monte-Carlo Method for Combinatorial Optimization</title>
      <link>https://arxiv.org/abs/2510.24755</link>
      <description>arXiv:2510.24755v1 Announce Type: new 
Abstract: In this paper, we present the Monte-Carlo Compressive Optimization algorithm, a new method to solve a combinatorial optimization problem that is assumed compressible. The method relies on random queries to the objective function in order to estimate generalized moments. Next, a greedy algorithm from compressive sensing is repurposed to find the global optimum when not overfitting to samples. We provide numerical results giving evidences that our methods overcome state-of-the-art dual annealing. Moreover, we also give theoretical justification of the algorithm success and analyze its properties. The practicality of our algorithm is enhanced by the ability to tune heuristic parameters to available computational resources.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.24755v1</guid>
      <category>math.OC</category>
      <category>quant-ph</category>
      <pubDate>Thu, 30 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Baptiste Chevalier, Shimpei Yamaguchi, Wojciech Roga, Masahiro Takeoka</dc:creator>
    </item>
    <item>
      <title>Convergence analysis for an implementable scheme to solve the linear-quadratic stochastic optimal control problem with stochastic wave equation</title>
      <link>https://arxiv.org/abs/2510.24876</link>
      <description>arXiv:2510.24876v1 Announce Type: new 
Abstract: We study an optimal control problem for the stochastic wave equation driven by affine multiplicative noise, formulated as a stochastic linear-quadratic (SLQ) problem. By applying a stochastic Pontryagin's maximum principle, we characterize the optimal state-control pair via a coupled forward-backward SPDE system. We propose an implementable discretization using conforming finite elements in space and an implicit midpoint rule in time. By a new technical approach we obtain strong convergence rates for the discrete state-control pair without relying on Malliavin calculus. For the practical computation we develop a gradient-descent algorithm based on artificial iterates that employs an exact computation for the arising conditional expectations, thereby eliminating costly Monte Carlo sampling. Consequently, each iteration has a computational cost that is proportional to the number of spatial degrees of freedom, producing a scalable method that preserves the established strong convergence rates. Numerical results validate its efficiency.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.24876v1</guid>
      <category>math.OC</category>
      <category>cs.NA</category>
      <category>math.AP</category>
      <category>math.NA</category>
      <category>math.PR</category>
      <pubDate>Thu, 30 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/publicdomain/zero/1.0/</dc:rights>
      <dc:creator>Abhishek Chaudhary</dc:creator>
    </item>
    <item>
      <title>Zeroth-order gradient estimators for stochastic problems with decision-dependent distributions</title>
      <link>https://arxiv.org/abs/2510.24929</link>
      <description>arXiv:2510.24929v1 Announce Type: new 
Abstract: Stochastic optimization problems with unknown decision-dependent distributions have attracted increasing attention in recent years due to its importance in applications. Since the gradient of the objective function is inaccessible as a result of the unknown distribution, various zeroth-order methods have been developed to solve the problem. However, it remains unclear which search direction to construct a gradient estimator is more appropriate and how to set the algorithmic parameters. In this paper, we conduct a unified sample complexity analysis of zeroth-order methods across gradient estimators with different search directions. As a result, we show that gradient estimators that average over multiple directions, either uniformly from the unit sphere or from a Gaussian distribution, achieve the lowest sample complexity. The attained sample complexities improve those of existing zeroth-order methods in the problem setting that allows nonconvexity and unboundedness of the objective function. Moreover, by simulation experiments on multiple products pricing and strategic classification applications, we show practical performance of zeroth-order methods with various gradient estimators.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.24929v1</guid>
      <category>math.OC</category>
      <pubDate>Thu, 30 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Yuya Hikima, Akiko Takeda</dc:creator>
    </item>
    <item>
      <title>Adaptive Multilevel Newton: A Quadratically Convergent Optimization Method</title>
      <link>https://arxiv.org/abs/2510.24967</link>
      <description>arXiv:2510.24967v1 Announce Type: new 
Abstract: Newton's method may exhibit slower convergence than vanilla Gradient Descent in its initial phase on strongly convex problems. Classical Newton-type multilevel methods mitigate this but, like Gradient Descent, achieve only linear convergence near the minimizer. We introduce an adaptive multilevel Newton-type method with a principled automatic switch to full Newton once its quadratic phase is reached. The local quadratic convergence for strongly convex functions with Lipschitz continuous Hessians and for self-concordant functions is established and confirmed empirically. Although per-iteration cost can exceed that of classical multilevel schemes, the method is efficient and consistently outperforms Newton's method, Gradient Descent, and the multilevel Newton method, indicating that second-order methods can outperform first-order methods even when Newton's method is initially slow.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.24967v1</guid>
      <category>math.OC</category>
      <category>cs.NA</category>
      <category>math.NA</category>
      <pubDate>Thu, 30 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Nick Tsipinakis, Panos Parpas, Matthias Voigt</dc:creator>
    </item>
    <item>
      <title>Star Quasiconvexity: an Unified Approach for Linear Convergence of First-Order Methods Beyond Convexity</title>
      <link>https://arxiv.org/abs/2510.24981</link>
      <description>arXiv:2510.24981v1 Announce Type: new 
Abstract: We introduce a class of generalized convex functions, termed star quasiconvexity, to ensure the linear convergence of gradient and proximal point methods. This class encompasses convex, star-convex, quasiconvex, and quasar-convex functions. We establish that a function is star quasiconvex if and only if all its sublevel sets are star-shaped with respect to the set of its minimizers. Furthermore, we provide several characterizations of this class, including nonsmooth and differentiable cases, and derive key properties that fa\-ci\-li\-ta\-te the implementation of first-order methods. Finally, we prove that the proximal point algorithm converges linearly to the unique solution when applied to strongly star quasiconvex functions defined over closed, star-shaped sets, which are not necessarily convex.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.24981v1</guid>
      <category>math.OC</category>
      <pubDate>Thu, 30 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/publicdomain/zero/1.0/</dc:rights>
      <dc:creator>Phan Quoc Khanh, Felipe Lara</dc:creator>
    </item>
    <item>
      <title>Nonlinear Dynamics In Optimization Landscape of Shallow Neural Networks with Tunable Leaky ReLU</title>
      <link>https://arxiv.org/abs/2510.25060</link>
      <description>arXiv:2510.25060v1 Announce Type: new 
Abstract: In this work, we study the nonlinear dynamics of a shallow neural network trained with mean-squared loss and leaky ReLU activation. Under Gaussian inputs and equal layer width k, (1) we establish, based on the equivariant gradient degree, a theoretical framework, applicable to any number of neurons k&gt;= 4, to detect bifurcation of critical points with associated symmetries from global minimum as leaky parameter $\alpha$ varies. Typically, our analysis reveals that a multi-mode degeneracy consistently occurs at the critical number 0, independent of k. (2) As a by-product, we further show that such bifurcations are width-independent, arise only for nonnegative $\alpha$ and that the global minimum undergoes no further symmetry-breaking instability throughout the engineering regime $\alpha$ in range (0,1). An explicit example with k=5 is presented to illustrate the framework and exhibit the resulting bifurcation together with their symmetries.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.25060v1</guid>
      <category>math.OC</category>
      <category>cs.LG</category>
      <category>math.DS</category>
      <pubDate>Thu, 30 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Jingzhou Liu</dc:creator>
    </item>
    <item>
      <title>Optimal Control Strategies for Multi-Agent Sheep Herding</title>
      <link>https://arxiv.org/abs/2510.25115</link>
      <description>arXiv:2510.25115v2 Announce Type: new 
Abstract: We develop a cost functional and state-space equations to model the problem of herding m sheep to the origin using n dogs. Our initial approach uses solve_bvp to approximate optimal control trajectories. But this method often fails to converge due to the system's high dimensionality and nonlinearity. However, with a well-chosen initial guess and carefully selected hyperparameters, we succeed in getting solve_bvp to converge. We also explore alternatives including the shooting method and linearization with the iterative Linear Quadratic Regulator (iLQR). While the shooting method also suffers from poor convergence, the linearized iLQR approach proves more scalable and successfully handles scenarios with more agents. However, it struggles in regions where dogs and sheep are in close proximity, due to strong nonlinearities that violate the assumptions of local linearization. This leads to jagged, oscillatory paths and slow convergence, particularly when the number of sheep exceeds the number of dogs. These challenges reveal key limitations of standard numerical techniques in multi-agent control and underscore the need for more robust, nonlinear strategies for coordinating interacting agents.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.25115v2</guid>
      <category>math.OC</category>
      <pubDate>Thu, 30 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Drake Brown, Trevor Garrity, Daniel Perkins, Davis Hunter, Wyatt Pochman</dc:creator>
    </item>
    <item>
      <title>Minimum time consensus for damped second order agents using Gr\"{o}bner basis</title>
      <link>https://arxiv.org/abs/2510.25243</link>
      <description>arXiv:2510.25243v1 Announce Type: new 
Abstract: A problem of achieving minimum time consensus for a set of $N$ second-order LTI system agents with bounded inputs and fuel constraints is considered. Unlike our other works, here the damping effect in agent dynamics is included. First, the attainable set for each agent with fuel budget constraints is characterized, and its boundary equations are derived. Then, using the convexity property, the minimum time at which attainable sets of all agents have a non-empty intersection is computed. By applying Helly's theorem, the computation reduces to finding the minimum time to consensus and the corresponding consensus point for each of the triplets separately.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.25243v1</guid>
      <category>math.OC</category>
      <category>cs.SY</category>
      <category>eess.SY</category>
      <pubDate>Thu, 30 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Akansha Rautela, Deepak U. Patil, Ameer Mulla, Indra Narayan Kar</dc:creator>
    </item>
    <item>
      <title>Convergence of a Relative-type Inexact Proximal ALM for Convex Nonlinear Programming</title>
      <link>https://arxiv.org/abs/2510.25261</link>
      <description>arXiv:2510.25261v1 Announce Type: new 
Abstract: This article investigates the convergence properties of a relative-type inexact proximal augmented Lagrangian method (ripALM) for convex nonlinear programming, a fundamental class of optimization problems with broad applications in science and engineering. Inexact proximal augmented Lagrangian methods have proven to be highly effective for solving such problems, owing to their attractive theoretical properties and strong practical performance. However, the convergence behavior of the relative-type inexact variant remains insufficiently understood. This work aims to reduce this gap by rigorously establishing the global convergence of the sequence generated by ripALM and proving its asymptotic (super)linear convergence rate under standard assumptions. In addition, we derive the global ergodic convergence rate with respect to both the primal feasibility violation and the primal objective residual, thereby offering a more comprehensive characterization of the overall performance of ripALM.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.25261v1</guid>
      <category>math.OC</category>
      <pubDate>Thu, 30 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Lei Yang, Jiayi Zhu, Ling Liang, Kim-Chuan Toh</dc:creator>
    </item>
    <item>
      <title>On the Rate of Convergence of Iterative Methods for Nonexpansive Mappings in CAT(0) Spaces and Hyperbolic Optimization</title>
      <link>https://arxiv.org/abs/2510.25363</link>
      <description>arXiv:2510.25363v1 Announce Type: new 
Abstract: The Krasnosel'ski\u{\i} Mann and Halpern iterations are classical schemes for approximating fixed points of nonexpansive mappings in Banach spaces, and have been widely studied in more general frameworks such as $CAT(\kappa)$ and, more generally, geodesic spaces. Convergence results and convergence rate estimates in these nonlinear settings are already well established. The contribution of this paper is to extend to complete $CAT(0)$ spaces the proof techniques originally developed in the linear setting of Banach and Hilbert spaces, thereby recovering the same asymptotic regularity bounds and to introduce a novel optimizer for Hyperbolic Deep learning based on Halpern Iteration similarly to HalpernSGD \cite{foglia2024halpernsgd,colao2025optimizer} in Euclidean setting.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.25363v1</guid>
      <category>math.OC</category>
      <category>math.FA</category>
      <pubDate>Thu, 30 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Katherine Rossella Foglia, Vittorio Colao</dc:creator>
    </item>
    <item>
      <title>Averaging favors MPC: How typical evaluation setups overstate MPC performance for residential battery scheduling</title>
      <link>https://arxiv.org/abs/2510.25373</link>
      <description>arXiv:2510.25373v1 Announce Type: new 
Abstract: Residential prosumers with PV-battery systems increasingly manage their electricity exchange with the power grid to minimize costs. This study investigates the performance of Model Predictive Control (MPC) and Rule-Based Control (RBC) under 15/30/60 minute averaging commonly used in research, when Net Billing and battery degradation are considered. We simulate five consecutive months for 15 buildings in northern Germany, generating costs at up to 1-minute resolution while scheduling at 15/30/60 minutes. We find that time-averaged evaluations make MPC look consistently better than RBC, yet when costs are recomputed at minute-level ground-truth, the reported advantage shrinks by 69\% on average for hourly schedulers. For individual buildings, the finer evaluation can reverse conclusions, and simple RBC can achieve lower total costs than an MPC with perfect foresight. These findings caution against drawing conclusions from coarse averages and show how a fair assessment of battery scheduling approaches can be obtained.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.25373v1</guid>
      <category>math.OC</category>
      <pubDate>Thu, 30 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-sa/4.0/</dc:rights>
      <dc:creator>Janik Pinter, Maximilian Beichter, Ralf Mikut, Frederik Zahn, Veit Hagenmeyer</dc:creator>
    </item>
    <item>
      <title>Centralized and Competitive Extraction for Distributed Renewable Resources with Nonlinear Reproduction</title>
      <link>https://arxiv.org/abs/2510.25398</link>
      <description>arXiv:2510.25398v1 Announce Type: new 
Abstract: We study optimal and strategic extraction of a renewable resource that is distributed over a network, migrates mass-conservatively across nodes, and evolves under nonlinear (concave) growth. A subset of nodes hosts extractors while the remaining nodes serve as reserves. We analyze a centralized planner and a non-cooperative game with stationary Markov strategies. The migration operator transports shadow values along the network so that Perron-Frobenius geometry governs long-run spatial allocations, while nonlinear growth couples aggregate biomass with its spatial distribution and bounds global dynamics. For three canonical growth families, logistic, power, and log-type saturating laws, under related utilities, we derive closed-form value functions and feedback rules for the planner and construct a symmetric Markov equilibrium on strongly connected networks. To our knowledge, this is the first paper to obtain explicit policies for spatial resource extraction with nonlinear growth and, a fortiori, closed-form Markov equilibria, on general networks.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.25398v1</guid>
      <category>math.OC</category>
      <pubDate>Thu, 30 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Filippo de Feo, Giorgio Fabbri, Silvia Faggian, Giuseppe Freni</dc:creator>
    </item>
    <item>
      <title>Data-Driven Stabilization Using Prior Knowledge on Stabilizability and Controllability</title>
      <link>https://arxiv.org/abs/2510.25452</link>
      <description>arXiv:2510.25452v2 Announce Type: new 
Abstract: In this work, we study data-driven stabilization of linear time-invariant systems using prior knowledge of system-theoretic properties, specifically stabilizability and controllability. To formalize this, we extend the concept of data informativity by requiring the existence of a controller that stabilizes all systems consistent with the data and the prior knowledge. We show that if the system is controllable, then incorporating this as prior knowledge does not relax the conditions required for data-driven stabilization. Remarkably, however, we show that if the system is stabilizable, then using this as prior knowledge leads to necessary and sufficient conditions that are weaker than those for data-driven stabilization without prior knowledge. In other words, data-driven stabilization is easier if one knows that the underlying system is stabilizable. We also provide new data-driven control design methods in terms of linear matrix inequalities that complement the conditions for informativity.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.25452v2</guid>
      <category>math.OC</category>
      <category>cs.SY</category>
      <category>eess.SY</category>
      <pubDate>Thu, 30 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Amir Shakouri, Henk J. van Waarde, Tren M. J. T. Baltussen, W. P. M. H. Heemels</dc:creator>
    </item>
    <item>
      <title>A strong formulation for Multiple Allocation Hub Location based on supermodular inequalities</title>
      <link>https://arxiv.org/abs/2510.25490</link>
      <description>arXiv:2510.25490v1 Announce Type: new 
Abstract: We introduce a new formulation for the multiple allocation hub location problem that exploits supermodular properties and uses 1- and 2-index variables only. We show that the new formulation produces the same Linear Programming bound as the tightest existing formulations for the studied problem, which use 4-index variables, outperforming existing supermodular formulations adapted to the considered problem. Computational results are presented with instances of up to 200 nodes optimally solved within a time limit of two hours.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.25490v1</guid>
      <category>math.OC</category>
      <pubDate>Thu, 30 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Elena Fern\'andez, Nicol\'as Zerega</dc:creator>
    </item>
    <item>
      <title>Stochastic Control of Dividends with a Drawdown Penalty</title>
      <link>https://arxiv.org/abs/2510.25494</link>
      <description>arXiv:2510.25494v1 Announce Type: new 
Abstract: We consider a diffusion risk model where dividends are paid at rate $U(t) \in [0, u_0]$. We are interested in maximising the dividend payments under a drawdown constraint, that is, we penalise a drawdown size larger than a level $d &gt; 0$. We show that the optimal dividend rate $U(t)$ is either zero or the maximal rate $u_0$ and determine the optimal strategy. Moreover, we derive an explicit expression for the value function by solving a system of differential equations.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.25494v1</guid>
      <category>math.OC</category>
      <pubDate>Thu, 30 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Kira Dudziak, Hanspeter Schmidli</dc:creator>
    </item>
    <item>
      <title>Sum-of-Squares Certificates for Almost-Sure Reachability of Stochastic Polynomial Systems</title>
      <link>https://arxiv.org/abs/2510.25513</link>
      <description>arXiv:2510.25513v1 Announce Type: new 
Abstract: In this paper, we present a computational approach to certify almost sure reachability for discrete-time polynomial stochastic systems by turning drift--variant criteria into sum-of-squares (SOS) programs solved with standard semidefinite solvers. Specifically, we provide an SOS method based on two complementary certificates: (i) a drift certificate that enforces a radially unbounded function to be non-increasing in expectation outside a compact set of states; and (ii) a variant certificate that guarantees a one-step decrease with positive probability and ensures the target contains its nonpositive sublevel set. We transform these conditions to SOS constraints. For the variant condition, we enforce a robust decrease over a parameterized disturbance ball with nonzero probability and encode the constraints via an S-procedure with polynomial multipliers. The resulting bilinearities are handled by an alternating scheme that alternates between optimizing multipliers and updating the variant and radius until a positive slack is obtained. Two case studies illustrate the workflow and certifies almost-sure reachability.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.25513v1</guid>
      <category>math.OC</category>
      <category>cs.SY</category>
      <category>eess.SY</category>
      <pubDate>Thu, 30 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Arash Bahari Kordabad, Rupak Majumdar, Sadegh Soudjani</dc:creator>
    </item>
    <item>
      <title>Local Convergence of Adaptively Regularized Tensor Methods</title>
      <link>https://arxiv.org/abs/2510.25643</link>
      <description>arXiv:2510.25643v1 Announce Type: new 
Abstract: Optimization methods that make use of derivatives of the objective function up to order $p &gt; 2$ are called tensor methods. Among them, ones that minimize a regularized $p$th-order Taylor expansion at each step have been shown to possess optimal global complexity, which improves as $p$ increases. The local convergence of such optimization algorithms on functions that have Lipschitz continuous $p$th derivatives and are uniformly convex of order $q$ has been studied by Doikov and Nesterov [Math. Program., 193 (2022), pp. 315--336]. We extend these local convergence results to locally uniformly convex functions and fully adaptive methods, which do not need knowledge of the Lipschitz constant, thus providing the first sharp local rates for AR$p$. We discuss the surprising new challenges encountered by nonconvex local models and non-unique model minimizers. For $p &gt; 2$, our examples show that in particular when using the global minimizer of the subproblem, even asymptotically not all iterations need to be successful. Only if the "right" local model minimizer is used, the $p/(q-1)$th-order local convergence from the non-adaptive case is preserved for $p &gt; q-1$, otherwise the superlinear rate can degrade. We thus confirm that adaptive higher-order methods achieve superlinear convergence for certain degenerate problems as long as $p$ is large enough and provide sharp bounds on the order of convergence one can expect in the limit.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.25643v1</guid>
      <category>math.OC</category>
      <pubDate>Thu, 30 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Karl Welzel, Yang Liu, Raphael A. Hauser, Coralia Cartis</dc:creator>
    </item>
    <item>
      <title>A Low-Rank Symplectic Gradient Adjustment Method for Computing Nash Equilibria</title>
      <link>https://arxiv.org/abs/2510.25716</link>
      <description>arXiv:2510.25716v1 Announce Type: new 
Abstract: This work presents a theoretical and numerical investigation of the symplectic gradient adjustment (SGA) method and of a low-rank SGA (LRSGA) method for efficiently solving two-objective optimization problems in the framework of Nash games. The SGA method outperforms the gradient method by including second-order mixed derivatives computed at each iterate, which requires considerably larger computational effort. For this reason, a LRSGA method is proposed where the approximation to second-order mixed derivatives are obtained by rank-one updates. The theoretical analysis presented in this work focuses on novel convergence estimates for the SGA and LRSGA methods, including parameter bounds. The superior computational complexity of the LRSGA method is demonstrated in the training of a CLIP neural architecture, where the LRSGA method outperforms the SGA method by orders of magnitude smaller CPU time.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.25716v1</guid>
      <category>math.OC</category>
      <category>math.FA</category>
      <pubDate>Thu, 30 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Nadja Vater, Katherine Rossella Foglia, Vittorio Colao, Alfio Borz\`i</dc:creator>
    </item>
    <item>
      <title>Socio-cognitive agent-oriented evolutionary algorithm with trust-based optimization</title>
      <link>https://arxiv.org/abs/2510.25095</link>
      <description>arXiv:2510.25095v1 Announce Type: cross 
Abstract: This paper introduces the Trust-Based Optimization (TBO), a novel extension of the island model in evolutionary computation that replaces conventional periodic migrations with a flexible, agent-driven interaction mechanism based on trust or reputation. Experimental results demonstrate that TBO generally outperforms the standard island model evolutionary algorithm across various optimization problems. Nevertheless, algorithm performance varies depending on the problem type, with certain configurations being more effective for specific landscapes or dimensions. The findings suggest that trust and reputation mechanisms provide a flexible and adaptive approach to evolutionary optimization, improving solution quality in many cases.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.25095v1</guid>
      <category>cs.NE</category>
      <category>math.OC</category>
      <pubDate>Thu, 30 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <arxiv:DOI>10.1007/978-3-031-97554-7_18</arxiv:DOI>
      <arxiv:journal_reference>Computational Science - ICCS 2025 Workshops, Lecture Notes in Computer Science, 15907, 249-264</arxiv:journal_reference>
      <dc:creator>Aleksandra Urba\'nczyk, Krzysztof Czech, Piotr Urba\'nczyk, Marek Kisiel-Dorohinicki, Aleksander Byrski</dc:creator>
    </item>
    <item>
      <title>The Neural Differential Manifold: An Architecture with Explicit Geometric Structure</title>
      <link>https://arxiv.org/abs/2510.25113</link>
      <description>arXiv:2510.25113v1 Announce Type: cross 
Abstract: This paper introduces the Neural Differential Manifold (NDM), a novel neural network architecture that explicitly incorporates geometric structure into its fundamental design. Departing from conventional Euclidean parameter spaces, the NDM re-conceptualizes a neural network as a differentiable manifold where each layer functions as a local coordinate chart, and the network parameters directly parameterize a Riemannian metric tensor at every point. The architecture is organized into three synergistic layers: a Coordinate Layer implementing smooth chart transitions via invertible transformations inspired by normalizing flows, a Geometric Layer that dynamically generates the manifold's metric through auxiliary sub-networks, and an Evolution Layer that optimizes both task performance and geometric simplicity through a dual-objective loss function. This geometric regularization penalizes excessive curvature and volume distortion, providing intrinsic regularization that enhances generalization and robustness. The framework enables natural gradient descent optimization aligned with the learned manifold geometry and offers unprecedented interpretability by endowing internal representations with clear geometric meaning. We analyze the theoretical advantages of this approach, including its potential for more efficient optimization, enhanced continual learning, and applications in scientific discovery and controllable generative modeling. While significant computational challenges remain, the Neural Differential Manifold represents a fundamental shift towards geometrically structured, interpretable, and efficient deep learning systems.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.25113v1</guid>
      <category>cs.LG</category>
      <category>cs.AI</category>
      <category>math.DG</category>
      <category>math.OC</category>
      <pubDate>Thu, 30 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Di Zhang</dc:creator>
    </item>
    <item>
      <title>A Unified Bilevel Model for Adversarial Learning and A Case Study</title>
      <link>https://arxiv.org/abs/2510.25121</link>
      <description>arXiv:2510.25121v1 Announce Type: cross 
Abstract: Adversarial learning has been attracting more and more attention thanks to the fast development of machine learning and artificial intelligence. However, due to the complicated structure of most machine learning models, the mechanism of adversarial attacks is not well interpreted. How to measure the effect of attack is still not quite clear. In this paper, we propose a unified bilevel model for adversarial learning. We further investigate the adversarial attack in clustering models and interpret it from data perturbation point of view. We reveal that when the data perturbation is relatively small, the clustering model is robust, whereas if it is relatively large, the clustering result changes, which leads to an attack. To measure the effect of attacks for clustering models, we analyse the well-definedness of the so-called $\delta$-measure, which can be used in the proposed bilevel model for adversarial learning of clustering models.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.25121v1</guid>
      <category>cs.LG</category>
      <category>math.OC</category>
      <pubDate>Thu, 30 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Yutong Zheng, Qingna Li</dc:creator>
    </item>
    <item>
      <title>Machine Learning Guided Optimal Transmission Switching to Mitigate Wildfire Ignition Risk</title>
      <link>https://arxiv.org/abs/2510.25147</link>
      <description>arXiv:2510.25147v1 Announce Type: cross 
Abstract: To mitigate acute wildfire ignition risks, utilities de-energize power lines in high-risk areas. The Optimal Power Shutoff (OPS) problem optimizes line energization statuses to manage wildfire ignition risks through de-energizations while reducing load shedding. OPS problems are computationally challenging Mixed-Integer Linear Programs (MILPs) that must be solved rapidly and frequently in operational settings. For a particular power system, OPS instances share a common structure with varying parameters related to wildfire risks, loads, and renewable generation. This motivates the use of Machine Learning (ML) for solving OPS problems by exploiting shared patterns across instances. In this paper, we develop an ML-guided framework that quickly produces high-quality de-energization decisions by extending existing ML-guided MILP solution methods while integrating domain knowledge on the number of energized and de-energized lines. Results on a large-scale realistic California-based synthetic test system show that the proposed ML-guided method produces high-quality solutions faster than traditional optimization methods.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.25147v1</guid>
      <category>cs.LG</category>
      <category>math.OC</category>
      <pubDate>Thu, 30 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Weimin Huang, Ryan Piansky, Bistra Dilkina, Daniel K. Molzahn</dc:creator>
    </item>
    <item>
      <title>Machine Learning and CPU (Central Processing Unit) Scheduling Co-Optimization over a Network of Computing Centers</title>
      <link>https://arxiv.org/abs/2510.25176</link>
      <description>arXiv:2510.25176v1 Announce Type: cross 
Abstract: In the rapidly evolving research on artificial intelligence (AI) the demand for fast, computationally efficient, and scalable solutions has increased in recent years. The problem of optimizing the computing resources for distributed machine learning (ML) and optimization is considered in this paper. Given a set of data distributed over a network of computing-nodes/servers, the idea is to optimally assign the CPU (central processing unit) usage while simultaneously training each computing node locally via its own share of data. This formulates the problem as a co-optimization setup to (i) optimize the data processing and (ii) optimally allocate the computing resources. The information-sharing network among the nodes might be time-varying, but with balanced weights to ensure consensus-type convergence of the algorithm. The algorithm is all-time feasible, which implies that the computing resource-demand balance constraint holds at all iterations of the proposed solution. Moreover, the solution allows addressing possible log-scale quantization over the information-sharing channels to exchange log-quantized data. For some example applications, distributed support-vector-machine (SVM) and regression are considered as the ML training models. Results from perturbation theory, along with Lyapunov stability and eigen-spectrum analysis, are used to prove the convergence towards the optimal case. As compared to existing CPU scheduling solutions, the proposed algorithm improves the cost optimality gap by more than $50\%$.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.25176v1</guid>
      <category>cs.LG</category>
      <category>cs.DC</category>
      <category>cs.MA</category>
      <category>cs.SY</category>
      <category>eess.SY</category>
      <category>math.OC</category>
      <pubDate>Thu, 30 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Mohammadreza Doostmohammadian, Zulfiya R. Gabidullina, Hamid R. Rabiee</dc:creator>
    </item>
    <item>
      <title>A Convexity-dependent Two-Phase Training Algorithm for Deep Neural Networks</title>
      <link>https://arxiv.org/abs/2510.25366</link>
      <description>arXiv:2510.25366v2 Announce Type: cross 
Abstract: The key task of machine learning is to minimize the loss function that measures the model fit to the training data. The numerical methods to do this efficiently depend on the properties of the loss function. The most decisive among these properties is the convexity or non-convexity of the loss function. The fact that the loss function can have, and frequently has, non-convex regions has led to a widespread commitment to non-convex methods such as Adam. However, a local minimum implies that, in some environment around it, the function is convex. In this environment, second-order minimizing methods such as the Conjugate Gradient (CG) give a guaranteed superlinear convergence. We propose a novel framework grounded in the hypothesis that loss functions in real-world tasks swap from initial non-convexity to convexity towards the optimum. This is a property we leverage to design an innovative two-phase optimization algorithm. The presented algorithm detects the swap point by observing the gradient norm dependence on the loss. In these regions, non-convex (Adam) and convex (CG) algorithms are used, respectively. Computing experiments confirm the hypothesis that this simple convexity structure is frequent enough to be practically exploited to substantially improve convergence and accuracy.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.25366v2</guid>
      <category>cs.LG</category>
      <category>cs.AI</category>
      <category>math.OC</category>
      <pubDate>Thu, 30 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <arxiv:DOI>10.5220/0013696100004000</arxiv:DOI>
      <dc:creator>Tomas Hrycej, Bernhard Bermeitinger, Massimo Pavone, G\"otz-Henrik Wiegand, Siegfried Handschuh</dc:creator>
    </item>
    <item>
      <title>Minimizing point configurations for tensor product energies on the torus</title>
      <link>https://arxiv.org/abs/2510.25442</link>
      <description>arXiv:2510.25442v1 Announce Type: cross 
Abstract: We study point configurations on the torus $\mathbb T^d$ that minimize interaction energies with tensor product structure which arise naturally in the context of discrepancy theory and quasi-Monte Carlo integration. Permutation sets on $\mathbb T^2$ and Latin hypercube sets in higher dimensions (i.e. sets whose projections onto coordinate axes are equispaced points) are natural candidates to be energy minimizers. We show that such point configurations that have only one distance in the vector sense minimize the energy for a wide range of potentials, in other words, such sets satisfy a tensor product version of universal optimality. This applies, in particular, to three- and five-point Fibonacci lattices. We also characterize all lattices with this property and exhibit some non-lattice sets of this type. In addition, we obtain several further structural results about global and local minimizers of tensor product energies.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.25442v1</guid>
      <category>math.MG</category>
      <category>cs.NA</category>
      <category>math.CO</category>
      <category>math.NA</category>
      <category>math.OC</category>
      <pubDate>Thu, 30 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Dmitriy Bilyk, Nicolas Nagel, Ian Ruohoniemi</dc:creator>
    </item>
    <item>
      <title>Collision avoidance and path finding in a robotic mobile fulfillment system using multi-objective meta-heuristics</title>
      <link>https://arxiv.org/abs/2510.25650</link>
      <description>arXiv:2510.25650v1 Announce Type: cross 
Abstract: Multi-Agent Path Finding (MAPF) has gained significant attention, with most research focusing on minimizing collisions and travel time. This paper also considers energy consumption in the path planning of automated guided vehicles (AGVs). It addresses two main challenges: i) resolving collisions between AGVs and ii) assigning tasks to AGVs. We propose a new collision avoidance strategy that takes both energy use and travel time into account. For task assignment, we present two multi-objective algorithms: Non-Dominated Sorting Genetic Algorithm (NSGA) and Adaptive Large Neighborhood Search (ALNS). Comparative evaluations show that these proposed methods perform better than existing approaches in both collision avoidance and task assignment.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.25650v1</guid>
      <category>cs.RO</category>
      <category>math.OC</category>
      <pubDate>Thu, 30 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Ahmad Kokhahi, Mary Kurz</dc:creator>
    </item>
    <item>
      <title>Bi-Parameterized Two-Stage Stochastic Min-Max and Min-Min Mixed Integer Programs</title>
      <link>https://arxiv.org/abs/2501.01081</link>
      <description>arXiv:2501.01081v2 Announce Type: replace 
Abstract: We introduce two-stage stochastic min-max and min-min integer programs with bi-parameterized recourse (BTSPs), where the first-stage decisions affect both the objective function and the feasible region of the second-stage problem. To solve these programs efficiently, we introduce Lagrangian-integrated $L$-shaped ($L^2$) methods, which guarantee exact solutions when the first-stage decisions are pure binary. For mixed-binary first-stage programs, we present a regularization-augmented variant of this method. Our computational results for a stochastic network interdiction problem show that the $L^2$ method outperforms a benchmark method, solving all instances in 23 seconds on average, while the benchmark method failed to solve any instance within 3600 seconds. The $L^2$ method also achieves optimal solutions, on average, 18.4 times faster for a stochastic facility location problem. Furthermore, we show that the $L^2$ method can effectively address distributionally robust optimization problems with decision-dependent ambiguity sets that may be empty for some first-stage decisions, achieving optimal solutions, on average, 5.3 times faster than existing methods.</description>
      <guid isPermaLink="false">oai:arXiv.org:2501.01081v2</guid>
      <category>math.OC</category>
      <pubDate>Thu, 30 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Sumin Kang, Manish Bansal</dc:creator>
    </item>
    <item>
      <title>Hidden convexity property of a speed planning problem</title>
      <link>https://arxiv.org/abs/2503.09424</link>
      <description>arXiv:2503.09424v2 Announce Type: replace 
Abstract: In this paper we address the speed planning problem for a vehicle along a predefined path. A weighted average of two (conflicting) terms, energy consumption and travel time, is minimized. After deriving a non-convex mathematical model of the problem, we introduce a convex relaxation of the model and show that, after the application of a suitable feasibility-based bound tightening procedure, the convex relaxation shares the same optimal value and solution of the non-convex problem. We also establish that the feasible region of the non-convex problem is a lattice and, through that, a necessary and sufficient condition for the non-emptiness of the feasible region.</description>
      <guid isPermaLink="false">oai:arXiv.org:2503.09424v2</guid>
      <category>math.OC</category>
      <pubDate>Thu, 30 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Stefano Ardizzoni, Luca Consolini, Mattia Laurini, Marco Locatelli</dc:creator>
    </item>
    <item>
      <title>Continuity Conditions for Piecewise Quadratic Functions on Simplicial Conic Partitions are Equivalent</title>
      <link>https://arxiv.org/abs/2504.15914</link>
      <description>arXiv:2504.15914v2 Announce Type: replace 
Abstract: Analysis of continuous-time piecewise linear systems based on piecewise quadratic (PWQ) Lyapunov functions typically requires continuity of these functions over a partition of the state space. Several conditions for guaranteeing continuity of PWQ functions over state space partitions can be found in the literature. In this technical note, we show that these continuity conditions are equivalent over so-called simplicial conic partitions. As a consequence, the choice of which condition to impose can be based solely on practical considerations such as specific application or numerical aspects, without introducing additional conservatism in the analysis.</description>
      <guid isPermaLink="false">oai:arXiv.org:2504.15914v2</guid>
      <category>math.OC</category>
      <category>cs.SY</category>
      <category>eess.SY</category>
      <pubDate>Thu, 30 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Magne Erlandsen (Maurice), Tomas Meijer (Maurice), W. P. M. H. (Maurice),  Heemels, Sebastiaan van den Eijnden</dc:creator>
    </item>
    <item>
      <title>Set Smoothness Unlocks Clarke Hyper-stationarity in Bilevel Optimization</title>
      <link>https://arxiv.org/abs/2506.04587</link>
      <description>arXiv:2506.04587v2 Announce Type: replace 
Abstract: Solving bilevel optimization (BLO) problems to global optimality is generally intractable. A common surrogate is to compute a hyper-stationary point -- a stationary point of the hyper-objective function obtained by minimizing or maximizing the upper-level objective over the lower-level solution set. Existing methods, however, either provide weak notions of stationarity or require restrictive assumptions to guarantee the smoothness of hyper-objective functions. In this paper, we eliminate these impractical assumptions and show that strong (Clarke) hyper-stationarity remains computable even when the hyper-objective is nonsmooth. Our key ingredient is a new structural property, called set smoothness, which captures the variational dependence of the lower-level solution set on the upper-level variable. We prove that this property holds for a broad class of BLO problems and ensures weak convexity (resp. concavity) of pessimistic (resp. optimistic) hyper-objective functions. Building on this foundation, we show that a zeroth-order algorithm that computes approximate Clarke hyper-stationary points with non-asymptotic convergence guarantees. To the best of our knowledge, this is the first computational guarantee for Clarke-type stationarity in nonsmooth BLO. Beyond this specific application, the set smoothness property emerges as a structural concept of independent interest, with potential to inform the analysis of broader classes of optimization and variational problems.</description>
      <guid isPermaLink="false">oai:arXiv.org:2506.04587v2</guid>
      <category>math.OC</category>
      <pubDate>Thu, 30 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>He Chen, Jiajin Li, Anthony Man-Cho So</dc:creator>
    </item>
    <item>
      <title>Multi-to -one dimensional and semi-discrete screening</title>
      <link>https://arxiv.org/abs/2506.21740</link>
      <description>arXiv:2506.21740v2 Announce Type: replace 
Abstract: We study the monopolist's screening problem with a multi-dimensional distribution of consumers and a one-dimensional space of goods. We establish general conditions under which solutions satisfy a structural condition known as nestedness, which greatly simplifies their analysis and characterization. Under these assumptions, we go on to develop a general method to solve the problem, either in closed form or with relatively simple numerical computations, and illustrate it with examples. These results are established both when the monopolist has access to only a discrete subset of the one-dimensional space of products, as well as when the entire continuum is available. In the former case, we also establish a uniqueness result.</description>
      <guid isPermaLink="false">oai:arXiv.org:2506.21740v2</guid>
      <category>math.OC</category>
      <category>econ.TH</category>
      <pubDate>Thu, 30 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Omar Abdul Halim, Brendan Pass</dc:creator>
    </item>
    <item>
      <title>Dual-Regularized Riccati Recursions for Interior-Point Optimal Control</title>
      <link>https://arxiv.org/abs/2509.16370</link>
      <description>arXiv:2509.16370v3 Announce Type: replace 
Abstract: We derive closed-form extensions of Riccati's recursions (both sequential and parallel) for solving dual-regularized LQR problems. We show how these methods can be used to solve general constrained, non-convex, discrete-time optimal control problems via a regularized interior point method, while guaranteeing that each step is a descent direction of an Augmented Barrier-Lagrangian merit function. We provide MIT-licensed implementations of our methods in C++ and JAX.</description>
      <guid isPermaLink="false">oai:arXiv.org:2509.16370v3</guid>
      <category>math.OC</category>
      <category>cs.MS</category>
      <category>cs.RO</category>
      <category>cs.SY</category>
      <category>eess.SY</category>
      <pubDate>Thu, 30 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Jo\~ao Sousa-Pinto, Dominique Orban</dc:creator>
    </item>
    <item>
      <title>Robust Fitted-Q-Evaluation and Iteration under Sequentially Exogenous Unobserved Confounders</title>
      <link>https://arxiv.org/abs/2302.00662</link>
      <description>arXiv:2302.00662v3 Announce Type: replace-cross 
Abstract: Offline reinforcement learning is important in domains such as medicine, economics, and e-commerce where online experimentation is costly, dangerous or unethical, and where the true model is unknown. However, most methods assume all covariates used in the behavior policy's action decisions are observed. Though this assumption, sequential ignorability/unconfoundedness, likely does not hold in observational data, most of the data that accounts for selection into treatment may be observed, motivating sensitivity analysis. We study robust policy evaluation and policy optimization in the presence of sequentially-exogenous unobserved confounders under a sensitivity model. We propose and analyze orthogonalized robust fitted-Q-iteration that uses closed-form solutions of the robust Bellman operator to derive a loss minimization problem for the robust Q function, and adds a bias-correction to quantile estimation. Our algorithm enjoys the computational ease of fitted-Q-iteration and statistical improvements (reduced dependence on quantile estimation error) from orthogonalization. We provide sample complexity bounds, insights, and show effectiveness both in simulations and on real-world longitudinal healthcare data of treating sepsis. In particular, our model of sequential unobserved confounders yields an online Markov decision process, rather than partially observed Markov decision process: we illustrate how this can enable warm-starting optimistic reinforcement learning algorithms with valid robust bounds from observational data.</description>
      <guid isPermaLink="false">oai:arXiv.org:2302.00662v3</guid>
      <category>stat.ML</category>
      <category>cs.LG</category>
      <category>math.OC</category>
      <pubDate>Thu, 30 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>David Bruns-Smith, Angela Zhou</dc:creator>
    </item>
    <item>
      <title>Sharp Quantitative Stability of the Dirichlet spectrum near the ball</title>
      <link>https://arxiv.org/abs/2304.10916</link>
      <description>arXiv:2304.10916v2 Announce Type: replace-cross 
Abstract: Let $\Omega\subset\mathbb{R}^n$ be an open set with the same volume as the unit ball $B$ and let $\lambda_k(\Omega)$ be the $k$-th eigenvalue of the Laplace operator of $\Omega$ with Dirichlet boundary conditions on $\partial\Omega$. In this work, we answer the following question: if $\lambda_1(\Omega)-\lambda_1(B)$ is small, how large can $|\lambda_k(\Omega)-\lambda_k(B)|$ be ?
  We establish quantitative bounds of the form $|\lambda_k(\Omega)-\lambda_k(B)|\le C (\lambda_1(\Omega)-\lambda_1(B))^\alpha$ with sharp exponents $\alpha$ depending on the multiplicity of $\lambda_k(B)$. We first show that such an inequality is valid with $\alpha=1/2$ for any $k$, improving previous known results and providing the sharpest possible exponent. Then, through the study of a vectorial free boundary problem, we show that one can achieve the better exponent $\alpha=1$ if $\lambda_{k}(B)$ is simple. We also obtain a similar result for the whole cluster of eigenvalues when $\lambda_{k}(B)$ is multiple, thus providing a complete answer to the question above. As a consequence of these results, we obtain the persistence of the ball as the minimizer for a large class of spectral functionals which are small perturbations of the fundamental eigenvalue on the one hand, and a full reverse Kohler-Jobin inequality on the other hand, solving an open problem formulated by M. Van Den Berg, G. Buttazzo and A. Pratelli.</description>
      <guid isPermaLink="false">oai:arXiv.org:2304.10916v2</guid>
      <category>math.AP</category>
      <category>math.OC</category>
      <pubDate>Thu, 30 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Dorin Bucur, Jimmy Lamboley, Micka\"el Nahon, Rapha\"el Prunier</dc:creator>
    </item>
    <item>
      <title>Score-Aware Policy-Gradient and Performance Guarantees using Local Lyapunov Stability</title>
      <link>https://arxiv.org/abs/2312.02804</link>
      <description>arXiv:2312.02804v3 Announce Type: replace-cross 
Abstract: In this paper, we introduce a policy-gradient method for model-based reinforcement learning (RL) that exploits a type of stationary distributions commonly obtained from Markov decision processes (MDPs) in stochastic networks, queueing systems, and statistical mechanics. Specifically, when the stationary distribution of the MDP belongs to an exponential family that is parametrized by policy parameters, we can improve existing policy gradient methods for average-reward RL. Our key identification is a family of gradient estimators, called score-aware gradient estimators (SAGEs), that enable policy gradient estimation without relying on value-function estimation in the aforementioned setting. We show that SAGE-based policy-gradient locally converges, and we obtain its regret. This includes cases when the state space of the MDP is countable and unstable policies can exist. Under appropriate assumptions such as starting sufficiently close to a maximizer and the existence of a local Lyapunov function, the policy under SAGE-based stochastic gradient ascent has an overwhelming probability of converging to the associated optimal policy. Furthermore, we conduct a numerical comparison between a SAGE-based policy-gradient method and an actor-critic method on several examples inspired from stochastic networks, queueing systems, and models derived from statistical physics. Our results demonstrate that a SAGE-based method finds close-to-optimal policies faster than an actor-critic method.</description>
      <guid isPermaLink="false">oai:arXiv.org:2312.02804v3</guid>
      <category>cs.LG</category>
      <category>cs.PF</category>
      <category>math.OC</category>
      <category>math.PR</category>
      <pubDate>Thu, 30 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <arxiv:journal_reference>Journal of Machine Learning Research 26, no. 132 (2025): 1-74</arxiv:journal_reference>
      <dc:creator>C\'eline Comte, Matthieu Jonckheere, Jaron Sanders, Albert Senen-Cerda</dc:creator>
    </item>
    <item>
      <title>Tracking the Median of Gradients with a Stochastic Proximal Point Method</title>
      <link>https://arxiv.org/abs/2402.12828</link>
      <description>arXiv:2402.12828v2 Announce Type: replace-cross 
Abstract: There are several applications of stochastic optimization where one can benefit from a robust estimate of the gradient. For example, domains such as distributed learning with corrupted nodes, the presence of large outliers in the training data, learning under privacy constraints, or even heavy-tailed noise due to the dynamics of the algorithm itself. Here we study SGD with robust gradient estimators based on estimating the median.
  We first derive iterative methods based on the stochastic proximal point method for computing the median gradient and generalizations thereof. Then we propose an algorithm estimating the median gradient across iterations, and find that several well known methods are particular cases of this framework. For instance, we observe that different forms of clipping allow to compute online estimators of the median of gradients, in contrast to (heavy-ball) momentum, which corresponds to an online estimator of the mean. Finally, we provide a theoretical framework for an algorithm computing the median gradient across samples, and show that the resulting method can converge even under heavy-tailed, state-dependent noise.</description>
      <guid isPermaLink="false">oai:arXiv.org:2402.12828v2</guid>
      <category>stat.ML</category>
      <category>cs.LG</category>
      <category>math.OC</category>
      <pubDate>Thu, 30 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <arxiv:journal_reference>Transactions on Machine Learning Research (2025)</arxiv:journal_reference>
      <dc:creator>Fabian Schaipp, Guillaume Garrigos, Umut Simsekli, Robert Gower</dc:creator>
    </item>
    <item>
      <title>Optimal Kinematic Synthesis and Prototype Development of Knee Exoskeleton</title>
      <link>https://arxiv.org/abs/2409.02635</link>
      <description>arXiv:2409.02635v3 Announce Type: replace-cross 
Abstract: The range of rotation (RoR) in a knee exoskeleton is a critical factor in rehabilitation, as it directly influences joint mobility, muscle activation, and recovery outcomes. A well-designed RoR ensures that patients achieve near-natural knee kinematics, which is essential for restoring gait patterns and preventing compensatory movements. This paper presents optimal design of one degree of freedom knee exoskeleton. In kinematic analysis, the existing design being represented by nonlinear and nonconvex mathematical functions. To obtain feasible and optimum measurement of the links of knee exoskeleton, an optimization problem is formulated based on the kinematic analysis and average human's leg measurement. The optimized solution increases the range of motion of knee exoskeleton during sit to stand motion by $24 \%$ as compared with inspired design. Furthermore, misalignment study is conducted by comparing the trajectory of human's knee and exoskeleton's knee during sit to stand motion. The joint movement is calculated using marker and camera system. Finally, a prototype of the knee joint exoskeleton is being developed based on optimal dimensions which validate the maximum range of motion achieved during simulation.</description>
      <guid isPermaLink="false">oai:arXiv.org:2409.02635v3</guid>
      <category>cs.RO</category>
      <category>math.OC</category>
      <pubDate>Thu, 30 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/publicdomain/zero/1.0/</dc:rights>
      <dc:creator>Shashank Mani Gautam, Ekta Singla, Ashish Singla</dc:creator>
    </item>
    <item>
      <title>Reducing the Large Set Threshold for Oertel's Conjecture on the Mixed-Integer Volume</title>
      <link>https://arxiv.org/abs/2411.11864</link>
      <description>arXiv:2411.11864v3 Announce Type: replace-cross 
Abstract: In 1960, Gr\"{u}nbaum proved that for any convex body $C\subset\mathbb{R}^d$ and every halfspace $H$ containing the centroid of $C$, one has that the volume of $H\cap C$ is at least a $\frac{1}{e}$-fraction of the volume of $C$. Recently, in 2014, Oertel conjectured that a similar result holds for mixed-integer convex sets. Concretely, he proposed that for any convex body $C\subset \mathbb{R}^{n+d}$, there should exist a point $\mathbf{x} \in S=C\cap(\mathbb{Z}^{n}\times\mathbb{R}^d)$ such that for every halfspace $H$ containing $\mathbf{x}$, one has that
  \[
  \mathcal{H}_d(H\cap S) \geq \frac{1}{2^n}\frac{1}{e}\mathcal{H}_d(S),
  \]
  where $\mathcal{H}_d$ denotes the $d$-dimensional Hausdorff measure. While the conjecture remains open, Basu and Oertel proved in 2017 that the above inequality holds true for sufficiently large sets, in terms of a measure known as the \emph{lattice width} of a set. In this work, by following a geometric approach, we improve this result by substantially reducing the threshold at which a set can be considered large. We reduce this threshold from an exponential to a polynomial dependency on the dimension, therefore significantly enlarging the family of mixed-integer convex sets over which Oertel's conjecture holds true.</description>
      <guid isPermaLink="false">oai:arXiv.org:2411.11864v3</guid>
      <category>math.MG</category>
      <category>math.OC</category>
      <pubDate>Thu, 30 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Andr\'es Cristi, David Salas</dc:creator>
    </item>
    <item>
      <title>Euclidean distance discriminants and Morse attractors</title>
      <link>https://arxiv.org/abs/2412.16957</link>
      <description>arXiv:2412.16957v5 Announce Type: replace-cross 
Abstract: Our study concerns the Euclidean distance function in case of complex plane curves. We decompose the ED discriminant into components which are responsible for three types of behavior of the Morse points. Besides the traditional focal component, which is non--linear; the other components are lines. In particular we shed light on the ``atypical discriminant'' which is due to the loss of Morse critical points at isotropic points at infinity. This phenomenon is specific for the complex setting.
  We find formulas for the number of Morse singularities which abut to the corresponding type of attractors when moving the centre of the distance function toward a point of the discriminant.</description>
      <guid isPermaLink="false">oai:arXiv.org:2412.16957v5</guid>
      <category>math.AG</category>
      <category>math.OC</category>
      <pubDate>Thu, 30 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Cezar Joi\c{t}a, Dirk Siersma, Mihai Tib\u{a}r</dc:creator>
    </item>
    <item>
      <title>Exact Sequence Interpolation with Transformers</title>
      <link>https://arxiv.org/abs/2502.02270</link>
      <description>arXiv:2502.02270v2 Announce Type: replace-cross 
Abstract: We prove that transformers can exactly interpolate datasets of finite input sequences in $\mathbb{R}^d$, $d\geq 2$, with corresponding output sequences of smaller or equal length. Specifically, given $N$ sequences of arbitrary but finite lengths in $\mathbb{R}^d$ and output sequences of lengths $m^1, \dots, m^N \in \mathbb{N}$, we construct a transformer with $\mathcal{O}(\sum_{j=1}^N m^j)$ blocks and $\mathcal{O}(d \sum_{j=1}^N m^j)$ parameters that exactly interpolates the dataset. Our construction provides complexity estimates that are independent of the input sequence length, by alternating feed-forward and self-attention layers and by capitalizing on the clustering effect inherent to the latter. Our novel constructive method also uses low-rank parameter matrices in the self-attention mechanism, a common feature of practical transformer implementations. These results are first established in the hardmax self-attention setting, where the geometric structure permits an explicit and quantitative analysis, and are then extended to the softmax setting. Finally, we demonstrate the applicability of our exact interpolation construction to learning problems, in particular by providing convergence guarantees to a global minimizer under regularized training strategies. Our analysis contributes to the theoretical understanding of transformer models, offering an explanation for their excellent performance in exact sequence-to-sequence interpolation tasks.</description>
      <guid isPermaLink="false">oai:arXiv.org:2502.02270v2</guid>
      <category>cs.LG</category>
      <category>math.OC</category>
      <category>stat.ML</category>
      <pubDate>Thu, 30 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Albert Alcalde, Giovanni Fantuzzi, Enrique Zuazua</dc:creator>
    </item>
    <item>
      <title>ASGO: Adaptive Structured Gradient Optimization</title>
      <link>https://arxiv.org/abs/2503.20762</link>
      <description>arXiv:2503.20762v3 Announce Type: replace-cross 
Abstract: Training deep neural networks is a structured optimization problem, because the parameters are naturally represented by matrices and tensors rather than by vectors. Under this structural representation, it has been widely observed that gradients are low-rank and Hessians are approximately block diagonal. These structured properties are crucial for designing efficient optimization algorithms, but are not utilized by many current popular optimizers like Adam. In this paper, we present a novel optimization algorithm ASGO that capitalizes on these properties by employing a preconditioner that is adaptively updated using structured gradients. By a fine-grained theoretical analysis, ASGO is proven to achieve superior convergence rates compared to existing structured gradient methods. Based on this convergence theory, we further demonstrate that ASGO can benefit from low-rank gradients and block diagonal Hessians. We also discuss practical modifications of ASGO and empirically verify ASGO's effectiveness on language model tasks. Code is available at https://github.com/infinity-stars/ASGO.</description>
      <guid isPermaLink="false">oai:arXiv.org:2503.20762v3</guid>
      <category>cs.LG</category>
      <category>math.OC</category>
      <pubDate>Thu, 30 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Kang An, Yuxing Liu, Rui Pan, Yi Ren, Shiqian Ma, Donald Goldfarb, Tong Zhang</dc:creator>
    </item>
    <item>
      <title>Adaptive Frontier Exploration on Graphs with Applications to Network-Based Disease Testing</title>
      <link>https://arxiv.org/abs/2505.21671</link>
      <description>arXiv:2505.21671v3 Announce Type: replace-cross 
Abstract: We study a sequential decision-making problem on a $n$-node graph $\mathcal{G}$ where each node has an unknown label from a finite set $\mathbf{\Omega}$, drawn from a joint distribution $\mathcal{P}$ that is Markov with respect to $\mathcal{G}$. At each step, selecting a node reveals its label and yields a label-dependent reward. The goal is to adaptively choose nodes to maximize expected accumulated discounted rewards. We impose a frontier exploration constraint, where actions are limited to neighbors of previously selected nodes, reflecting practical constraints in settings such as contact tracing and robotic exploration. We design a Gittins index-based policy that applies to general graphs and is provably optimal when $\mathcal{G}$ is a forest. Our implementation runs in $\mathcal{O}(n^2 \cdot |\mathbf{\Omega}|^2)$ time while using $\mathcal{O}(n \cdot |\mathbf{\Omega}|^2)$ oracle calls to $\mathcal{P}$ and $\mathcal{O}(n^2 \cdot |\mathbf{\Omega}|)$ space. Experiments on synthetic and real-world graphs show that our method consistently outperforms natural baselines, including in non-tree, budget-limited, and undiscounted settings. For example, in HIV testing simulations on real-world sexual interaction networks, our policy detects nearly all positive cases with only half the population tested, substantially outperforming other baselines.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.21671v3</guid>
      <category>cs.AI</category>
      <category>cs.DS</category>
      <category>cs.LG</category>
      <category>math.OC</category>
      <pubDate>Thu, 30 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Davin Choo, Yuqi Pan, Tonghan Wang, Milind Tambe, Alastair van Heerden, Cheryl Johnson</dc:creator>
    </item>
    <item>
      <title>Quantum Fisher information matrix via its classical counterpart from random measurements</title>
      <link>https://arxiv.org/abs/2509.08196</link>
      <description>arXiv:2509.08196v3 Announce Type: replace-cross 
Abstract: Preconditioning with the quantum Fisher information matrix (QFIM) is a popular approach in quantum variational algorithms. Yet the QFIM is costly to obtain directly, usually requiring more state preparation than its classical counterpart: the classical Fisher information matrix (CFIM). By revealing its relation to covariant measurement in quantum metrology, we show that averaging the classical Fisher information matrix over Haar-random measurement bases yields $\mathbb{E}_{U\sim\mu_H}[F^U(\boldsymbol{\theta})] = \frac{1}{2}Q(\boldsymbol{\theta})$ for pure states in $\mathbb{C}^N$. Furthermore, we obtain the variance of CFIM ($O(N^{-1})$) and establish non-asymptotic concentration bounds ($\exp(-\Theta(N)t^2)$), demonstrating that using few random measurement bases is sufficient to approximate the QFIM accurately, especially in high-dimensional settings. This work establishes a solid theoretical foundation for efficient quantum natural gradient methods via randomized measurements.</description>
      <guid isPermaLink="false">oai:arXiv.org:2509.08196v3</guid>
      <category>quant-ph</category>
      <category>math-ph</category>
      <category>math.MP</category>
      <category>math.OC</category>
      <pubDate>Thu, 30 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Jianfeng Lu, Kecen Sha</dc:creator>
    </item>
  </channel>
</rss>
