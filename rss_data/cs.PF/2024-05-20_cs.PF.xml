<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>cs.PF updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/cs.PF</link>
    <description>cs.PF updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/cs.PF" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Tue, 21 May 2024 04:00:56 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Tue, 21 May 2024 00:00:00 -0400</pubDate>
    <skipDays>
      <day>Saturday</day>
      <day>Sunday</day>
    </skipDays>
    <item>
      <title>Enabling full-speed random access to the entire memory on the A100 GPU</title>
      <link>https://arxiv.org/abs/2405.11425</link>
      <description>arXiv:2405.11425v1 Announce Type: new 
Abstract: We describe some features of the A100 memory architecture. In particular, we give a technique to reverse-engineer some hardware layout information. Using this information, we show how to avoid TLB issues to obtain full-speed random HBM access to the entire memory, as long as we constrain any particular thread to a reduced access window of less than 64GB.</description>
      <guid isPermaLink="false">oai:arXiv.org:2405.11425v1</guid>
      <category>cs.PF</category>
      <category>cs.AR</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Alden Walker</dc:creator>
    </item>
    <item>
      <title>Response time in a pair of processor sharing queues with Join-the-Shortest-Queue scheduling</title>
      <link>https://arxiv.org/abs/2405.11927</link>
      <description>arXiv:2405.11927v1 Announce Type: new 
Abstract: Join-the-Shortest-Queue (JSQ) is the scheduling policy of choice for many network providers, cloud servers and traffic management systems, where individual queues are served under processor sharing (PS) queueing discipline. A numerical solution for the response time distribution in two parallel PS queues with JSQ scheduling is derived for the first time. Using the generating function method, two partial differential equations (PDEs) are obtained corresponding to conditional response times, where the conditioning is on a particular traced task joining the first or the second queue. These PDEs are functional equations that contain partial generating functions and their partial derivatives, and therefore cannot be solved by commonly used techniques. We are able to solve these PDEs numerically with good accuracy and perform the deconditioning with respect to the queue-length probabilities by evaluating a certain complex integral. Numerical results for the density and the first four moments compare well against regenerative simulation with 500,000 regeneration cycles.</description>
      <guid isPermaLink="false">oai:arXiv.org:2405.11927v1</guid>
      <category>cs.PF</category>
      <category>math.PR</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Julianna Bor, Peter G Harrison</dc:creator>
    </item>
    <item>
      <title>Vectorization of Gradient Boosting of Decision Trees Prediction in the CatBoost Library for RISC-V Processors</title>
      <link>https://arxiv.org/abs/2405.11062</link>
      <description>arXiv:2405.11062v1 Announce Type: cross 
Abstract: The emergence and rapid development of the open RISC-V instruction set architecture opens up new horizons on the way to efficient devices, ranging from existing low-power IoT boards to future high-performance servers. The effective use of RISC-V CPUs requires software optimization for the target platform. In this paper, we focus on the RISC-V-specific optimization of the CatBoost library, one of the widely used implementations of gradient boosting for decision trees. The CatBoost library is deeply optimized for commodity CPUs and GPUs. However, vectorization is required to effectively utilize the resources of RISC-V CPUs with the RVV 0.7.1 vector extension, which cannot be done automatically with a C++ compiler yet. The paper reports on our experience in benchmarking CatBoost on the Lichee Pi 4a, RISC-V-based board, and shows how manual vectorization of computationally intensive loops with intrinsics can speed up the use of decision trees several times, depending on the specific workload. The developed codes are publicly available on GitHub.</description>
      <guid isPermaLink="false">oai:arXiv.org:2405.11062v1</guid>
      <category>cs.DC</category>
      <category>cs.PF</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Evgeny Kozinov, Evgeny Vasiliev, Andrey Gorshkov, Valentina Kustikova, Artem Maklaev, Valentin Volokitin, Iosif Meyerov</dc:creator>
    </item>
    <item>
      <title>Count-Min Sketch with Conservative Updates: Worst-Case Analysis</title>
      <link>https://arxiv.org/abs/2405.12034</link>
      <description>arXiv:2405.12034v1 Announce Type: cross 
Abstract: Count-Min Sketch with Conservative Updates (\texttt{CMS-CU}) is a memory-efficient hash-based data structure used to estimate the occurrences of items within a data stream. \texttt{CMS-CU} stores~$m$ counters and employs~$d$ hash functions to map items to these counters. We first argue that the estimation error in \texttt{CMS-CU} is maximal when each item appears at most once in the stream. Next, we study \texttt{CMS-CU} in this setting. Precisely, \begin{enumerate}
  \item In the case where~$d=m-1$, we prove that the average estimation error and the average counter rate converge almost surely to~$\frac{1}{2}$, contrasting with the vanilla Count-Min Sketch, where the average counter rate is equal to~$\frac{m-1}{m}$.
  \item For any given~$m$ and~$d$, we prove novel lower and upper bounds on the average estimation error, incorporating a positive integer parameter~$g$. Larger values of this parameter improve the accuracy of the bounds. Moreover, the computation of each bound involves examining an ergodic Markov process with a state space of size~$\binom{m+g-d}{g}$ and a sparse transition probabilities matrix containing~$\mathcal{O}(m\binom{m+g-d}{g})$ non-zero entries.
  \item For~$d=m-1$, $g=1$, and as $m\to \infty$, we show that the lower and upper bounds coincide. In general, our bounds exhibit high accuracy for small values of $g$, as shown by numerical computation. For example, for $m=50$, $d=4$, and $g=5$, the difference between the lower and upper bounds is smaller than~$10^{-4}$.
  \end{enumerate}</description>
      <guid isPermaLink="false">oai:arXiv.org:2405.12034v1</guid>
      <category>cs.DS</category>
      <category>cs.PF</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Younes Ben Mazziane, Othmane Marfoq</dc:creator>
    </item>
  </channel>
</rss>
