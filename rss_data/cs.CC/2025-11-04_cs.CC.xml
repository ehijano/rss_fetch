<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>cs.CC updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/cs.CC</link>
    <description>cs.CC updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/cs.CC" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Wed, 05 Nov 2025 02:39:36 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Tue, 04 Nov 2025 00:00:00 -0500</pubDate>
    <skipDays>
      <day>Saturday</day>
      <day>Sunday</day>
    </skipDays>
    <item>
      <title>Computation as a Game</title>
      <link>https://arxiv.org/abs/2511.00058</link>
      <description>arXiv:2511.00058v1 Announce Type: new 
Abstract: We present a unifying representation of computation as a two-player game between an \emph{Algorithm} and \emph{Nature}, grounded in domain theory and game theory. The Algorithm produces progressively refined approximations within a Scott domain, while Nature assigns penalties proportional to their distance from the true value. Correctness corresponds to equilibrium in the limit of refinement. This framework allows us to define complexity classes game-theoretically, characterizing $\mathbf{P}$, $\mathbf{NP}$, and related classes as sets of problems admitting particular equilibria. The open question $\mathbf{P} \stackrel{?}{=} \mathbf{NP}$ becomes a problem about the equivalence of Nash equilibria under differing informational and temporal constraints.</description>
      <guid isPermaLink="false">oai:arXiv.org:2511.00058v1</guid>
      <category>cs.CC</category>
      <category>cs.GT</category>
      <category>cs.LO</category>
      <pubDate>Tue, 04 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Paul Alexander Bilokon</dc:creator>
    </item>
    <item>
      <title>A new metric for evaluating the performance and complexity of computer programs: A new approach to the traditional ways of measuring the complexity of algorithms and estimating running times</title>
      <link>https://arxiv.org/abs/2511.00589</link>
      <description>arXiv:2511.00589v1 Announce Type: new 
Abstract: This paper presents a refined complexity calculus model: r-Complexity, a new asymptotic notation that offers better complexity feedback for similar programs than the traditional Bachmann-Landau notation, providing subtle insights even for algorithms that are part of the same conventional complexity class. The architecture-dependent metric represents an enhancement that provides better sensitivity with respect to discrete analysis.</description>
      <guid isPermaLink="false">oai:arXiv.org:2511.00589v1</guid>
      <category>cs.CC</category>
      <pubDate>Tue, 04 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <arxiv:DOI>10.1109/CSCS52396.2021.00033</arxiv:DOI>
      <arxiv:journal_reference>2021 23rd International Conference on Control Systems and Computer Science (CSCS)</arxiv:journal_reference>
      <dc:creator>Rares Folea, Emil-Ioan Slusanschi</dc:creator>
    </item>
    <item>
      <title>Sorting by Strip Swaps is NP-Hard</title>
      <link>https://arxiv.org/abs/2511.00015</link>
      <description>arXiv:2511.00015v1 Announce Type: cross 
Abstract: We show that \emph{Sorting by Strip Swaps} (SbSS) is NP-hard by a polynomial reduction of \emph{Block Sorting}. The key idea is a local gadget, a \emph{cage}, that replaces every decreasing adjacency $(a_i,a_{i+1})$ by a guarded triple $a_i,m_i,a_{i+1}$ enclosed by guards $L_i,U_i$, so the only decreasing adjacencies are the two inside the cage. Small \emph{hinge} gadgets couple adjacent cages that share an element and enforce that a strip swap that removes exactly two adjacencies corresponds bijectively to a block move that removes exactly one decreasing adjacency in the source permutation. This yields a clean equivalence between exact SbSS schedules and perfect block schedules, establishing NP-hardness.</description>
      <guid isPermaLink="false">oai:arXiv.org:2511.00015v1</guid>
      <category>cs.DS</category>
      <category>cs.AI</category>
      <category>cs.CC</category>
      <pubDate>Tue, 04 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Swapnoneel Roy, Asai Asaithambi, Debajyoti Mukhopadhyay</dc:creator>
    </item>
    <item>
      <title>Scheduling Problems with Constrained Rejections</title>
      <link>https://arxiv.org/abs/2511.00184</link>
      <description>arXiv:2511.00184v1 Announce Type: cross 
Abstract: We study bicriteria versions of Makespan Minimization on Unrelated Machines and Santa Claus by allowing a constrained number of rejections. Given an instance of Makespan Minimization on Unrelated Machines where the optimal makespan for scheduling $n$ jobs on $m$ unrelated machines is $T$, (Feige and Vondr\'ak, 2006) gave an algorithm that schedules a $(1-1/e+10^{-180})$ fraction of jobs in time $T$. We show the ratio can be improved to $0.6533&gt;1-1/e+0.02$ if we allow makespan $3T/2$. To the best our knowledge, this is the first result examining the tradeoff between makespan and the fraction of scheduled jobs when the makespan is not $T$ or $2T$.
  For the Santa Claus problem (the Max-Min version of Makespan Minimization), the analogous bicriteria objective was studied by (Golovin, 2005), who gave an algorithm providing an allocation so a $(1-1/k)$ fraction of agents receive value at least $T/k$, for any $k \in \mathbb{Z}^+$ and $T$ being the optimal minimum value every agent can receive. We provide the first hardness result by showing there are constants $\delta,\varepsilon&gt;0$ such that it is NP-hard to find an allocation where a $(1-\delta)$ fraction of agents receive value at least $(1-\varepsilon) T$. To prove this hardness result, we introduce a bicriteria version of Set Packing, which may be of independent interest, and prove some algorithmic and hardness results for it. Overall, we believe these bicriteria scheduling problems warrant further study as they provide an interesting lens to understand how robust the difficulty of the original optimization goal might be.</description>
      <guid isPermaLink="false">oai:arXiv.org:2511.00184v1</guid>
      <category>cs.DS</category>
      <category>cs.CC</category>
      <pubDate>Tue, 04 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Sami Davies, Venkatesan Guruswami, Xuandi Ren</dc:creator>
    </item>
    <item>
      <title>Computing the Polytope Diameter is Even Harder than NP-hard (Already for Perfect Matchings)</title>
      <link>https://arxiv.org/abs/2502.16398</link>
      <description>arXiv:2502.16398v3 Announce Type: replace 
Abstract: The diameter of a polytope is a fundamental geometric parameter that plays a crucial role in understanding the efficiency of the simplex method. Despite its central nature, the computational complexity of computing the diameter of a given polytope is poorly understood. Already in 1994, Frieze and Teng [Comp. Compl.] recognized the possibility that this task could potentially be harder than NP-hard, and asked whether the corresponding decision problem is complete for the second stage of the polynomial hierarchy, i.e. $\Pi^p_2$-complete. In the following years, partial results could be obtained. In a cornerstone result, Frieze and Teng themselves proved weak NP-hardness for a family of custom defined polytopes. Sanit\`a [FOCS18] in a break-through result proved that already for the much simpler fractional matching polytope the problem is strongly NP-hard. Very recently, Steiner and N\"obel [SODA25] generalized this result to the even simpler bipartite perfect matching polytope and the circuit diameter. In this paper, we finally show that computing the diameter of the bipartite perfect matching polytope is $\Pi^p_2$-hard. Since the corresponding decision problem is also trivially contained in $\Pi^p_2$, this decidedly answers Frieze and Teng's 30 year old question. Our results also hold when the diameter is replaced by the circuit diameter. As our second main result, we prove that for some $\varepsilon &gt; 0$ the (circuit) diameter of the bipartite perfect matching polytope cannot be approximated by a factor better than $(1 + \varepsilon)$. This answers a recent question by N\"obel and Steiner. It is the first known inapproximability result for the circuit diameter, and extends Sanit\`a's inapproximability result of the diameter to the totally unimodular case.</description>
      <guid isPermaLink="false">oai:arXiv.org:2502.16398v3</guid>
      <category>cs.CC</category>
      <category>cs.CG</category>
      <pubDate>Tue, 04 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Lasse Wulf</dc:creator>
    </item>
    <item>
      <title>On the order of the shortest solution sequences for the pebble motion problems</title>
      <link>https://arxiv.org/abs/2503.20550</link>
      <description>arXiv:2503.20550v5 Announce Type: replace-cross 
Abstract: Let $G$ be a connected graph with $N$ vertices. Let $k$ be the number of vertices in a longest path of $G$ such that every vertex on the path is a cut vertex of $G$, and every intermediate vertex of the path is a degree-two vertex of $G$. We conventionally set $k = 1$ when $G$ is $2$-edge-connected. Let $P=\{1,\ldots,n\}$ be a set of pebbles with $k &lt; N-n$. A \textit{configuration} of $P$ on $G$ is defined as a function $f$ from $V(G)$ to $\{0, 1, \ldots, n \}$ with $|f^{-1}(i)| = 1$ for $1 \le i \le n$, where $f^{-1}(i)$ is a vertex occupied with the $i$th pebble for $1 \le i \le n$ and $f^{-1}(0)$ is a set of unoccupied vertices. A \textit{move} is defined as shifting a pebble from a vertex to some unoccupied neighbor. The {\it pebble motion problem on the pair $(G,P)$} is to decide whether a given configuration of pebbles is reachable from another by executing a sequence of moves. Let $\D(G)$ denote the diameter of the graph $G$, and let $\CL(G)$ denote the maximum length of a shortest cycle containing a vertex $v$, taken over all vertices $v$ in all $2$-connected components of $G$. For completeness, we define $\CL(G) := 1$ when $G$ is a tree. In this paper, we show that the length of the shortest solution sequences for the pebble motion problem on a pair $(G, P)$ is in $\Ord\left(n\D(G) + \min\left\{k n \D(G),\ n^{2} \log\big(1+\min\{n, k\}\big)\right\}\right)$ if $G$ is an $N$-vertex tree, and in $\Ord\left(n\D(G)+\frac{n^2\min\{n,\CL(G)\}}{N-n}+n^2\log(1+\min\{n, N-n\})\right)$ if $G$ is a connected general $N$-vertex graph. Furthermore, in the case where $G$ is a connected general $N$-vertex graph and the number of unoccupied spaces $N - n$ is bounded by some constant, this length admits an upper bound of $\Ord(n \CL(G) \D(G))$.
  Keywords: pebble motion, motion planning, multi-agent path finding, $15$-puzzle, tree</description>
      <guid isPermaLink="false">oai:arXiv.org:2503.20550v5</guid>
      <category>math.CO</category>
      <category>cs.CC</category>
      <category>cs.DM</category>
      <pubDate>Tue, 04 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Tomoki Nakamigawa, Tadashi Sakuma</dc:creator>
    </item>
    <item>
      <title>On the Classical Hardness of the Semidirect Discrete Logarithm Problem in Finite Groups</title>
      <link>https://arxiv.org/abs/2508.05048</link>
      <description>arXiv:2508.05048v2 Announce Type: replace-cross 
Abstract: The semidirect discrete logarithm problem (SDLP) in finite groups was proposed as a foundation for post-quantum cryptographic protocols, based on the belief that its non-abelian structure would resist quantum attacks. However, recent results have shown that SDLP in finite groups admits efficient quantum algorithms, undermining its quantum resistance. This raises a fundamental question: does the SDLP offer any computational advantages over the standard discrete logarithm problem (DLP) against classical adversaries? In this work, we investigate the classical hardness of SDLP across different finite group platforms. We establish that the group-case SDLP can be reformulated as a generalized discrete logarithm problem, enabling adaptation of classical algorithms to study its complexity. We present a concrete adaptation of the Baby-Step Giant-Step algorithm for SDLP, achieving time and space complexity $O(\sqrt{r})$ where $r$ is the period of the underlying cycle structure. Through theoretical analysis and experimental validation in SageMath, we demonstrate that the classical hardness of SDLP is highly platform-dependent and does not uniformly exceed that of standard DLP. In finite fields $\mathbb{F}_p^*$, both problems exhibit comparable complexity. Surprisingly, in elliptic curves $E(\mathbb{F}_p)$, the SDLP becomes trivial due to the bounded automorphism group, while in elementary abelian groups $\mathbb{F}_p^n$, the SDLP can be harder than DLP, with complexity varying based on the eigenvalue structure of the automorphism. Our findings reveal that the non-abelian structure of semidirect products does not inherently guarantee increased classical hardness, suggesting that the search for classically hard problems for cryptographic applications requires more careful consideration of the underlying algebraic structures.</description>
      <guid isPermaLink="false">oai:arXiv.org:2508.05048v2</guid>
      <category>cs.CR</category>
      <category>cs.CC</category>
      <pubDate>Tue, 04 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Mohammad Ferry Husnil Arif, Muhammad Imran</dc:creator>
    </item>
    <item>
      <title>Inclusive and Exclusive Vertex Splitting into Specific Graph Classes: NP Hardness and Algorithms</title>
      <link>https://arxiv.org/abs/2510.26938</link>
      <description>arXiv:2510.26938v2 Announce Type: replace-cross 
Abstract: We study a family of graph modification problems called the F-Vertex Splitting problem. Given a graph G, the task is to determine whether G can be transformed into a graph G-prime belonging to a graph class F through a sequence of at most k vertex splits. We investigate this problem for several target graph classes, namely constellations, cycle graphs, linear forests, and bipartite graphs. We analyze both inclusive and exclusive variants of vertex splitting, as introduced by Abu-Khzam and collaborators (ISCO 2018). Our results show that the F-Vertex Splitting problem is polynomial-time solvable when F is a cycle graph or a linear forest, for both variants. In contrast, when F is a constellation or a bipartite graph, the problem is NP-complete for both variants.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.26938v2</guid>
      <category>cs.DS</category>
      <category>cs.CC</category>
      <pubDate>Tue, 04 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Ajinkya Gaikwad, Hitendra Kumar, S. Padmapriya, Praneet Kumar Patra, Harsh Sanklecha, Soumen Maity</dc:creator>
    </item>
  </channel>
</rss>
