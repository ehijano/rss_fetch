<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>cs.DS updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/cs.DS</link>
    <description>cs.DS updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/cs.DS" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Wed, 09 Apr 2025 11:05:36 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Wed, 09 Apr 2025 00:00:00 -0400</pubDate>
    <skipDays>
      <day>Saturday</day>
      <day>Sunday</day>
    </skipDays>
    <item>
      <title>Radial Isotropic Position via an Implicit Newton's Method</title>
      <link>https://arxiv.org/abs/2504.05687</link>
      <description>arXiv:2504.05687v1 Announce Type: new 
Abstract: Placing a dataset $A = \{\mathbf{a}_i\}_{i \in [n]} \subset \mathbb{R}^d$ in radial isotropic position, i.e., finding an invertible $\mathbf{R} \in \mathbb{R}^{d \times d}$ such that the unit vectors $\{(\mathbf{R} \mathbf{a}_i) \|\mathbf{R} \mathbf{a}_i\|_2^{-1}\}_{i \in [n]}$ are in isotropic position, is a powerful tool with applications in functional analysis, communication complexity, coding theory, and the design of learning algorithms. When the transformed dataset has a second moment matrix within a $\exp(\pm \epsilon)$ factor of a multiple of $\mathbf{I}_d$, we call $\mathbf{R}$ an $\epsilon$-approximate Forster transform.
  We give a faster algorithm for computing approximate Forster transforms, based on optimizing an objective defined by Barthe [Barthe98]. When the transform has a polynomially-bounded aspect ratio, our algorithm uses $O(nd^{\omega - 1}(\frac n \epsilon)^{o(1)})$ time to output an $\epsilon$-approximate Forster transform with high probability, when one exists. This is almost the natural limit of this approach, as even evaluating Barthe's objective takes $O(nd^{\omega - 1})$ time. Previously, the state-of-the-art runtime in this regime was based on cutting-plane methods, and scaled at least as $\approx n^3 + n^2 d^{\omega - 1}$. We also provide explicit estimates on the aspect ratio in the smoothed analysis setting, and show that our algorithm similarly improves upon those in the literature.
  To obtain our results, we develop a subroutine of potential broader interest: a reduction from almost-linear time sparsification of graph Laplacians to the ability to support almost-linear time matrix-vector products. We combine this tool with new stability bounds on Barthe's objective to implicitly implement a box-constrained Newton's method [CMTV17, ALOW17].</description>
      <guid isPermaLink="false">oai:arXiv.org:2504.05687v1</guid>
      <category>cs.DS</category>
      <category>math.OC</category>
      <pubDate>Wed, 09 Apr 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Arun Jambulapati, Jonathan Li, Kevin Tian</dc:creator>
    </item>
    <item>
      <title>Linear-space LCS enumeration with quadratic-time delay for two strings</title>
      <link>https://arxiv.org/abs/2504.05742</link>
      <description>arXiv:2504.05742v1 Announce Type: new 
Abstract: Suppose we want to seek the longest common subsequences (LCSs) of two strings as informative patterns that explain the relationship between the strings. The dynamic programming algorithm gives us a table from which all LCSs can be extracted by traceback. However, the need for quadratic space to hold this table can be an obstacle when dealing with long strings. A question that naturally arises in this situation would be whether it is possible to exhaustively search for all LCSs one by one in a time-efficient manner using only a space linear in the LCS length, where we treat read-only memory for storing the strings as excluded from the space consumed. As a part of the answer to this question, we propose an $O(L)$-space algorithm that outputs all distinct LCSs of the strings one by one each in $O(n^2)$ time, where the strings are both of length $n$ and $L$ is the LCS length of the strings.</description>
      <guid isPermaLink="false">oai:arXiv.org:2504.05742v1</guid>
      <category>cs.DS</category>
      <pubDate>Wed, 09 Apr 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Yoshifumi Sakai</dc:creator>
    </item>
    <item>
      <title>Kronecker scaling of tensors with applications to arithmetic circuits and algorithms</title>
      <link>https://arxiv.org/abs/2504.05772</link>
      <description>arXiv:2504.05772v1 Announce Type: new 
Abstract: We show that sufficiently low tensor rank for the balanced tripartitioning tensor $P_d(x,y,z)=\sum_{A,B,C\in\binom{[3d]}{d}:A\cup B\cup C=[3d]}x_Ay_Bz_C$ for a large enough constant $d$ implies uniform arithmetic circuits for the matrix permanent that are exponentially smaller than circuits obtainable from Ryser's formula.
  We show that the same low-rank assumption implies exponential time improvements over the state of the art for a wide variety of other related counting and decision problems.
  As our main methodological contribution, we show that the tensors $P_n$ have a desirable Kronecker scaling property: They can be decomposed efficiently into a small sum of restrictions of Kronecker powers of $P_d$ for constant $d$. We prove this with a new technique relying on Steinitz's lemma, which we hence call Steinitz balancing.
  As a consequence of our methods, we show that the mentioned low rank assumption (and hence the improved algorithms) is implied by Strassen's asymptotic rank conjecture [Progr. Math. 120 (1994)], a bold conjecture that has recently seen intriguing progress.</description>
      <guid isPermaLink="false">oai:arXiv.org:2504.05772v1</guid>
      <category>cs.DS</category>
      <category>cs.CC</category>
      <pubDate>Wed, 09 Apr 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Andreas Bj\"orklund, Petteri Kaski, Tomohiro Koana, Jesper Nederlof</dc:creator>
    </item>
    <item>
      <title>A Method for Generating Connected Erdos-Renyi Random Graphs</title>
      <link>https://arxiv.org/abs/2504.05907</link>
      <description>arXiv:2504.05907v1 Announce Type: new 
Abstract: We propose a novel and exact algorithm for generating connected Erdos-Renyi random graphs $G(n, p)$. Our approach exploits a link between the distribution of exploration process trajectories and an inhomogeneous random walk. In contrast to existing methods, our approach guarantees the correct distribution under the connectivity condition and achieves $O(n^2)$ runtime in the sparse case $p = c/n$. Furthermore, we show that our method can be extended to uniformly generate connected graphs $G(n, m)$ via an acceptance-rejection procedure.</description>
      <guid isPermaLink="false">oai:arXiv.org:2504.05907v1</guid>
      <category>cs.DS</category>
      <category>cs.DM</category>
      <category>cs.IT</category>
      <category>math.CO</category>
      <category>math.IT</category>
      <category>math.PR</category>
      <pubDate>Wed, 09 Apr 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Boris Chinyaev</dc:creator>
    </item>
    <item>
      <title>Indexing Strings with Utilities</title>
      <link>https://arxiv.org/abs/2504.05917</link>
      <description>arXiv:2504.05917v1 Announce Type: new 
Abstract: Applications in domains ranging from bioinformatics to advertising feature strings that come with numerical scores (utilities). The utilities quantify the importance, interest, profit, or risk of the letters occurring at every position of a string. Motivated by the ever-increasing rate of generating such data, as well as by their importance in several domains, we introduce Useful String Indexing (USI), a natural generalization of the classic String Indexing problem. Given a string $S$ (the text) of length $n$, USI asks for preprocessing $S$ into a compact data structure supporting the following queries efficiently: given a shorter string $P$ (the pattern), return the global utility $U(P)$ of $P$ in $S$, where $U$ is a function that maps any string $P$ to a utility score based on the utilities of the letters of every occurrence of $P$ in $S$. Our work also makes the following contributions: (1) We propose a novel and efficient data structure for USI based on finding the top-$K$ frequent substrings of $S$. (2) We propose a linear-space data structure that can be used to mine the top-$K$ frequent substrings of $S$ or to tune the parameters of the USI data structure. (3) We propose a novel space-efficient algorithm for estimating the set of the top-$K$ frequent substrings of $S$, thus improving the construction space of the data structure for USI. (4) We show that popular space-efficient top-$K$ frequent item mining strategies employed by state-of-the-art algorithms do not smoothly translate from items to substrings. (5) Using billion-letter datasets, we experimentally demonstrate that: (i) our top-$K$ frequent substring mining algorithms are accurate and scalable, unlike two state-of-the-art methods; and (ii) our USI data structures are up to $15$ times faster in querying than $4$ nontrivial baselines while occupying the same space with them.</description>
      <guid isPermaLink="false">oai:arXiv.org:2504.05917v1</guid>
      <category>cs.DS</category>
      <category>cs.DB</category>
      <pubDate>Wed, 09 Apr 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Giulia Bernardini, Huiping Chen, Alessio Conte, Roberto Grossi, Veronica Guerrini, Grigorios Loukides, Nadia Pisanti, and Solon P. Pissis</dc:creator>
    </item>
    <item>
      <title>Parallel Small Vertex Connectivity in Near-Linear Work and Polylogarithmic Depth</title>
      <link>https://arxiv.org/abs/2504.06033</link>
      <description>arXiv:2504.06033v1 Announce Type: new 
Abstract: We present a randomized parallel algorithm in the {\sf PRAM} model for $k$-vertex connectivity. Given an undirected simple graph, our algorithm either finds a set of fewer than $k$ vertices whose removal disconnects the graph or reports that no such set exists. The algorithm runs in $O(m \cdot \text{poly}(k, \log n))$ work and $O(\text{poly}(k, \log n))$ depth, which is nearly optimal for any $k = \text{poly}(\log n)$. Prior to our work, algorithms with near-linear work and polylogarithmic depth were known only for $k=3$ [Miller, Ramachandran, STOC'87]; for $k=4$, sequential algorithms achieving near-linear time were known [Forster, Nanongkai, Yang, Saranurak, Yingchareonthawornchai, SODA'20], but no algorithm with near-linear work could achieve even sublinear (on $n$) depth.</description>
      <guid isPermaLink="false">oai:arXiv.org:2504.06033v1</guid>
      <category>cs.DS</category>
      <pubDate>Wed, 09 Apr 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Yonggang Jiang, Changki Yun</dc:creator>
    </item>
    <item>
      <title>Binary Tree Block Encoding of Classical Matrix</title>
      <link>https://arxiv.org/abs/2504.05624</link>
      <description>arXiv:2504.05624v1 Announce Type: cross 
Abstract: Block-encoding is a critical subroutine in quantum computing, enabling the transformation of classical data into a matrix representation within a quantum circuit. The resource trade-offs in simulating a block-encoding can be quantified by the circuit size, the normalization factor, and the time and space complexity of parameter computation. Previous studies have primarily focused either on the time and memory complexity of computing the parameters, or on the circuit size and normalization factor in isolation, often neglecting the balance between these trade-offs. In early fault-tolerant quantum computers, the number of qubits is limited. For a classical matrix of size $2^{n}\times 2^{n}$, our approach not only improves the time of decoupling unitary for block-encoding with time complexity $\mathcal{O}(n2^{2n})$ and memory complexity $\Theta(2^{2n})$ using only a few ancilla qubits, but also demonstrates superior resource trade-offs. Our proposed block-encoding protocol is named Binary Tree Block-encoding (\texttt{BITBLE}). Under the benchmark, \textit{size metric}, defined by the product of the number of gates and the normalization factor, numerical experiments demonstrate the improvement of both resource trade-off and classical computing time efficiency of the \texttt{BITBLE} protocol. The algorithms are all open-source.</description>
      <guid isPermaLink="false">oai:arXiv.org:2504.05624v1</guid>
      <category>quant-ph</category>
      <category>cs.DS</category>
      <pubDate>Wed, 09 Apr 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Zexian Li, Xiao-Ming Zhang, Chunlin Yang, Guofeng Zhang</dc:creator>
    </item>
    <item>
      <title>Uncovering Fairness through Data Complexity as an Early Indicator</title>
      <link>https://arxiv.org/abs/2504.05923</link>
      <description>arXiv:2504.05923v1 Announce Type: cross 
Abstract: Fairness constitutes a concern within machine learning (ML) applications. Currently, there is no study on how disparities in classification complexity between privileged and unprivileged groups could influence the fairness of solutions, which serves as a preliminary indicator of potential unfairness. In this work, we investigate this gap, specifically, we focus on synthetic datasets designed to capture a variety of biases ranging from historical bias to measurement and representational bias to evaluate how various complexity metrics differences correlate with group fairness metrics. We then apply association rule mining to identify patterns that link disproportionate complexity differences between groups with fairness-related outcomes, offering data-centric indicators to guide bias mitigation. Our findings are also validated by their application in real-world problems, providing evidence that quantifying group-wise classification complexity can uncover early indicators of potential fairness challenges. This investigation helps practitioners to proactively address bias in classification tasks.</description>
      <guid isPermaLink="false">oai:arXiv.org:2504.05923v1</guid>
      <category>cs.LG</category>
      <category>cs.AI</category>
      <category>cs.DS</category>
      <pubDate>Wed, 09 Apr 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Juliett Su\'arez Ferreira, Marija Slavkovik, Jorge Casillas</dc:creator>
    </item>
    <item>
      <title>Old and New Results on Alphabetic Codes</title>
      <link>https://arxiv.org/abs/2504.05959</link>
      <description>arXiv:2504.05959v1 Announce Type: cross 
Abstract: This comprehensive survey examines the field of alphabetic codes, tracing their development from the 1960s to the present day. We explore classical alphabetic codes and their variants, analyzing their properties and the underlying mathematical and algorithmic principles. The paper covers the fundamental relationship between alphabetic codes and comparison-based search procedures and their applications in data compression, routing, and testing. We review optimal alphabetic code construction algorithms, necessary and sufficient conditions for their existence, and upper bounds on the average code length of optimal alphabetic codes. The survey also discusses variations and generalizations of the classical problem of constructing minimum average length alphabetic codes. By elucidating both classical results and recent findings, this paper aims to serve as a valuable resource for researchers and students, concluding with promising future research directions in this still-active field.</description>
      <guid isPermaLink="false">oai:arXiv.org:2504.05959v1</guid>
      <category>cs.IT</category>
      <category>cs.DS</category>
      <category>math.IT</category>
      <pubDate>Wed, 09 Apr 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <arxiv:DOI>10.1007/978-3-031-82014-4_7</arxiv:DOI>
      <arxiv:journal_reference>Information Theory and Related Fields, Lecture Notes in Computer Science, Springer, vol. 14620, pp. 151-194, 2025</arxiv:journal_reference>
      <dc:creator>Roberto Bruno, Roberto De Prisco, Ugo Vaccaro</dc:creator>
    </item>
    <item>
      <title>Collaborative Prediction: Tractable Information Aggregation via Agreement</title>
      <link>https://arxiv.org/abs/2504.06075</link>
      <description>arXiv:2504.06075v1 Announce Type: cross 
Abstract: We give efficient "collaboration protocols" through which two parties, who observe different features about the same instances, can interact to arrive at predictions that are more accurate than either could have obtained on their own. The parties only need to iteratively share and update their own label predictions-without either party ever having to share the actual features that they observe. Our protocols are efficient reductions to the problem of learning on each party's feature space alone, and so can be used even in settings in which each party's feature space is illegible to the other-which arises in models of human/AI interaction and in multi-modal learning. The communication requirements of our protocols are independent of the dimensionality of the data. In an online adversarial setting we show how to give regret bounds on the predictions that the parties arrive at with respect to a class of benchmark policies defined on the joint feature space of the two parties, despite the fact that neither party has access to this joint feature space. We also give simpler algorithms for the same task in the batch setting in which we assume that there is a fixed but unknown data distribution. We generalize our protocols to a decision theoretic setting with high dimensional outcome spaces, where parties communicate only "best response actions."
  Our theorems give a computationally and statistically tractable generalization of past work on information aggregation amongst Bayesians who share a common and correct prior, as part of a literature studying "agreement" in the style of Aumann's agreement theorem. Our results require no knowledge of (or even the existence of) a prior distribution and are computationally efficient. Nevertheless we show how to lift our theorems back to this classical Bayesian setting, and in doing so, give new information aggregation theorems for Bayesian agreement.</description>
      <guid isPermaLink="false">oai:arXiv.org:2504.06075v1</guid>
      <category>cs.LG</category>
      <category>cs.DS</category>
      <category>cs.GT</category>
      <pubDate>Wed, 09 Apr 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Natalie Collina, Ira Globus-Harris, Surbhi Goel, Varun Gupta, Aaron Roth, Mirah Shi</dc:creator>
    </item>
    <item>
      <title>Unbounded Error Correcting Codes</title>
      <link>https://arxiv.org/abs/2411.04803</link>
      <description>arXiv:2411.04803v2 Announce Type: replace 
Abstract: Traditional error-correcting codes (ECCs) assume a fixed message length, but many scenarios involve ongoing or indefinite transmissions where the message length is not known in advance. For example, when streaming a video, the user should be able to fix a fraction of errors that occurred before any point in time. We introduce unbounded error-correcting codes (unbounded codes), a natural generalization of ECCs that supports arbitrarily long messages without a predetermined length. An unbounded code with rate $R$ and distance $\varepsilon$ ensures that for every sufficiently large $k$, the message prefix of length $Rk$ can be recovered from the code prefix of length $k$ even if an adversary corrupts up to an $\varepsilon$ fraction of the symbols in this code prefix.
  We study unbounded codes over binary alphabets in the regime of small error fraction $\varepsilon$, establishing nearly tight upper and lower bounds on their optimal rate. Our main results show that: (1) The optimal rate of unbounded codes satisfies $R&lt;1-\Omega(\sqrt{\varepsilon})$ and $R&gt;1-O(\sqrt{\varepsilon \log \log(1/\varepsilon)})$. (2) Surprisingly, our construction is inherently non-linear, as we prove that linear unbounded codes achieve a strictly worse rate of $R=1-\Theta(\sqrt{\varepsilon \log(1/\varepsilon)})$. (3) In the setting of random noise, unbounded codes achieve the same optimal rate as standard ECCs, $R=1-\Theta(\varepsilon \log(1/\varepsilon))$.
  These results demonstrate fundamental differences between standard and unbounded codes.</description>
      <guid isPermaLink="false">oai:arXiv.org:2411.04803v2</guid>
      <category>cs.DS</category>
      <category>cs.IT</category>
      <category>math.CO</category>
      <category>math.IT</category>
      <pubDate>Wed, 09 Apr 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Klim Efremenko, Or Zamir</dc:creator>
    </item>
    <item>
      <title>Avoiding Pitfalls for Privacy Accounting of Subsampled Mechanisms under Composition</title>
      <link>https://arxiv.org/abs/2405.20769</link>
      <description>arXiv:2405.20769v2 Announce Type: replace-cross 
Abstract: We consider the problem of computing tight privacy guarantees for the composition of subsampled differentially private mechanisms. Recent algorithms can numerically compute the privacy parameters to arbitrary precision but must be carefully applied.
  Our main contribution is to address two common points of confusion. First, some privacy accountants assume that the privacy guarantees for the composition of a subsampled mechanism are determined by self-composing the worst-case datasets for the uncomposed mechanism. We show that this is not true in general. Second, Poisson subsampling is sometimes assumed to have similar privacy guarantees compared to sampling without replacement. We show that the privacy guarantees may in fact differ significantly between the two sampling schemes. In particular, we give an example of hyperparameters that result in $\varepsilon \approx 1$ for Poisson subsampling and $\varepsilon &gt; 10$ for sampling without replacement. This occurs for some parameters that could realistically be chosen for DP-SGD.</description>
      <guid isPermaLink="false">oai:arXiv.org:2405.20769v2</guid>
      <category>cs.CR</category>
      <category>cs.DS</category>
      <category>cs.LG</category>
      <category>stat.ML</category>
      <pubDate>Wed, 09 Apr 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Christian Janos Lebeda, Matthew Regehr, Gautam Kamath, Thomas Steinke</dc:creator>
    </item>
  </channel>
</rss>
