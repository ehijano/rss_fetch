<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>cs.PL updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/cs.PL</link>
    <description>cs.PL updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/cs.PL" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Tue, 25 Mar 2025 03:03:04 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Mon, 24 Mar 2025 00:00:00 -0400</pubDate>
    <skipDays>
      <day>Sunday</day>
      <day>Saturday</day>
    </skipDays>
    <item>
      <title>A Unified Framework for Quantitative Cache Analysis</title>
      <link>https://arxiv.org/abs/2503.16588</link>
      <description>arXiv:2503.16588v1 Announce Type: new 
Abstract: In this work we unify two existing lines of work towards cache analysis for non-LRU policies. To this end, we extend the notion of competitiveness to block-wise competitiveness and systematically analyze the competitiveness and block competitiveness of FIFO and MRU relative to LRU for arbitrary associativities. We show how competitiveness and block competitiveness can be exploited in state-of-the-art WCET analysis based on the results of existing persistence analyses for LRU. Unlike prior work, our approach is applicable to microarchitectures that exhibit timing anomalies. We experimentally evaluate the precision and cost of our approach on benchmarks from TACLeBench. The experiments demonstrate that quantitative cache analysis for FIFO and MRU comes close to the precision of LRU.</description>
      <guid isPermaLink="false">oai:arXiv.org:2503.16588v1</guid>
      <category>cs.PL</category>
      <pubDate>Mon, 24 Mar 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Sophie Kahlen, Jan Reineke</dc:creator>
    </item>
    <item>
      <title>Nofl: A Precise Immix</title>
      <link>https://arxiv.org/abs/2503.16971</link>
      <description>arXiv:2503.16971v1 Announce Type: new 
Abstract: Can a memory manager be built with fast bump-pointer allocation, single-pass heap tracing, and a low upper bound on memory overhead? The Immix collector answered in the affirmative for the first two, but the granularity at which it reclaims memory means that in the worst case a tiny object can keep two 128-byte lines of memory from being re-used for allocation.
  This paper takes Immix to an extreme of precision, allowing all free space between objects to be reclaimed, down to the limit of the allocator's minimum alignment. We present the design of this Nofl layout, build a collector library around it, and build a new Scheme-to-C compiler as a workbench. We make a first evaluation of the Nofl-based mostly-marking collector when compared to standard copying and mark-sweep collectors and run against a limited set of microbenchmarks, finding that Nofl outperforms the others for tight-to-adequate heap sizes.</description>
      <guid isPermaLink="false">oai:arXiv.org:2503.16971v1</guid>
      <category>cs.PL</category>
      <pubDate>Mon, 24 Mar 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Andy Wingo</dc:creator>
    </item>
    <item>
      <title>Text2Model: Generating dynamic chemical reactor models using large language models (LLMs)</title>
      <link>https://arxiv.org/abs/2503.17004</link>
      <description>arXiv:2503.17004v1 Announce Type: new 
Abstract: As large language models have shown remarkable capabilities in conversing via natural language, the question arises as to how LLMs could potentially assist chemical engineers in research and industry with domain-specific tasks. We generate dynamic chemical reactor models in Modelica code format from textual descriptions as user input. We fine-tune Llama 3.1 8B Instruct on synthetically generated Modelica code for different reactor scenarios. We compare the performance of our fine-tuned model to the baseline Llama 3.1 8B Instruct model and GPT4o. We manually assess the models' predictions regarding the syntactic and semantic accuracy of the generated dynamic models. We find that considerable improvements are achieved by the fine-tuned model with respect to both the semantic and the syntactic accuracy of the Modelica models. However, the fine-tuned model lacks a satisfactory ability to generalize to unseen scenarios compared to GPT4o.</description>
      <guid isPermaLink="false">oai:arXiv.org:2503.17004v1</guid>
      <category>cs.PL</category>
      <category>cs.CL</category>
      <pubDate>Mon, 24 Mar 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Sophia Rupprecht, Yassine Hounat, Monisha Kumar, Giacomo Lastrucci, Artur M. Schweidtmann</dc:creator>
    </item>
    <item>
      <title>VeriMind: Agentic LLM for Automated Verilog Generation with a Novel Evaluation Metric</title>
      <link>https://arxiv.org/abs/2503.16514</link>
      <description>arXiv:2503.16514v2 Announce Type: cross 
Abstract: Designing Verilog modules requires meticulous attention to correctness, efficiency, and adherence to design specifications. However, manually writing Verilog code remains a complex and time-consuming task that demands both expert knowledge and iterative refinement. Leveraging recent advancements in large language models (LLMs) and their structured text generation capabilities, we propose VeriMind, an agentic LLM framework for Verilog code generation that significantly automates and optimizes the synthesis process. Unlike traditional LLM-based code generators, VeriMind employs a structured reasoning approach: given a user-provided prompt describing design requirements, the system first formulates a detailed train of thought before the final Verilog code is generated. This multi-step methodology enhances interpretability, accuracy, and adaptability in hardware design. In addition, we introduce a novel evaluation metric-pass@ARC-which combines the conventional pass@k measure with Average Refinement Cycles (ARC) to capture both success rate and the efficiency of iterative refinement. Experimental results on diverse hardware design tasks demonstrated that our approach achieved up to $8.3\%$ improvement on pass@k metric and $8.1\%$ on pass@ARC metric. These findings underscore the transformative potential of agentic LLMs in automated hardware design, RTL development, and digital system synthesis.</description>
      <guid isPermaLink="false">oai:arXiv.org:2503.16514v2</guid>
      <category>cs.AR</category>
      <category>cs.AI</category>
      <category>cs.LG</category>
      <category>cs.PL</category>
      <pubDate>Mon, 24 Mar 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <dc:creator>Bardia Nadimi, Ghali Omar Boutaib, Hao Zheng</dc:creator>
    </item>
    <item>
      <title>Spatial Data Science Languages: commonalities and needs</title>
      <link>https://arxiv.org/abs/2503.16686</link>
      <description>arXiv:2503.16686v1 Announce Type: cross 
Abstract: Recent workshops brought together several developers, educators and users of software packages extending popular languages for spatial data handling, with a primary focus on R, Python and Julia. Common challenges discussed included handling of spatial or spatio-temporal support, geodetic coordinates, in-memory vector data formats, data cubes, inter-package dependencies, packaging upstream libraries, differences in habits or conventions between the GIS and physical modelling communities, and statistical models. The following set of insights have been formulated: (i) considering software problems across data science language silos helps to understand and standardise analysis approaches, also outside the domain of formal standardisation bodies; (ii) whether attribute variables have block or point support, and whether they are spatially intensive or extensive has consequences for permitted operations, and hence for software implementing those; (iii) handling geometries on the sphere rather than on the flat plane requires modifications to the logic of {\em simple features}, (iv) managing communities and fostering diversity is a necessary, on-going effort, and (v) tools for cross-language development need more attention and support.</description>
      <guid isPermaLink="false">oai:arXiv.org:2503.16686v1</guid>
      <category>stat.CO</category>
      <category>cs.PL</category>
      <pubDate>Mon, 24 Mar 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-sa/4.0/</dc:rights>
      <dc:creator>Edzer Pebesma, Martin Fleischmann, Josiah Parry, Jakub Nowosad, Anita Graser, Dewey Dunnington, Maarten Pronk, Rafael Schouten, Robin Lovelace, Marius Appel, Lorena Abad</dc:creator>
    </item>
  </channel>
</rss>
