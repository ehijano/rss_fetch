<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>math.OC updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/math.OC</link>
    <description>math.OC updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/math.OC" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Mon, 20 Jan 2025 05:01:47 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Mon, 20 Jan 2025 00:00:00 -0500</pubDate>
    <skipDays>
      <day>Saturday</day>
      <day>Sunday</day>
    </skipDays>
    <item>
      <title>On the Complexity of p-Order Cone Programs</title>
      <link>https://arxiv.org/abs/2501.09828</link>
      <description>arXiv:2501.09828v1 Announce Type: new 
Abstract: This manuscript explores novel complexity results for the feasibility problem over $p$-order cones, extending the foundational work of Porkolab and Khachiyan. By leveraging the intrinsic structure of $p$-order cones, we derive refined complexity bounds that surpass those obtained via standard semidefinite programming reformulations. Our analysis not only improves theoretical bounds but also provides practical insights into the computational efficiency of solving such problems. In addition to establishing complexity results, we derive explicit bounds for solutions when the feasibility problem admits one. For infeasible instances, we analyze their discrepancy quantifying the degree of infeasibility. Finally, we examine specific cases of interest, highlighting scenarios where the geometry of $p$-order cones or problem structure yields further computational simplifications. These findings contribute to both the theoretical understanding and practical tractability of optimization problems involving $p$-order cones.</description>
      <guid isPermaLink="false">oai:arXiv.org:2501.09828v1</guid>
      <category>math.OC</category>
      <category>cs.CC</category>
      <pubDate>Mon, 20 Jan 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>V\'ictor Blanco, Victor Magron, Miguel Mart\'inez-Ant\'on</dc:creator>
    </item>
    <item>
      <title>A Family of Controllable Momentum Coefficients for Forward-Backward Accelerated Algorithms</title>
      <link>https://arxiv.org/abs/2501.10051</link>
      <description>arXiv:2501.10051v1 Announce Type: new 
Abstract: Nesterov's accelerated gradient method (NAG) marks a pivotal advancement in gradient-based optimization, achieving faster convergence compared to the vanilla gradient descent method for convex functions. However, its algorithmic complexity when applied to strongly convex functions remains unknown, as noted in the comprehensive review by Chambolle and Pock [2016]. This issue, aside from the critical step size, was addressed by Li et al. [2024b], with the monotonic case further explored by Fu and Shi [2024]. In this paper, we introduce a family of controllable momentum coefficients for forward-backward accelerated methods, focusing on the critical step size $s=1/L$. Unlike traditional linear forms, the proposed momentum coefficients follow an $\alpha$-th power structure, where the parameter $r$ is adaptively tuned to $\alpha$. Using a Lyapunov function specifically designed for $\alpha$, we establish a controllable $O\left(1/k^{2\alpha} \right)$ convergence rate for the NAG-$\alpha$ method, provided that $r &gt; 2\alpha$. At the critical step size, NAG-$\alpha$ achieves an inverse polynomial convergence rate of arbitrary degree by adjusting $r$ according to $\alpha &gt; 0$. We further simplify the Lyapunov function by expressing it in terms of the iterative sequences $x_k$ and $y_k$, eliminating the need for phase-space representations. This simplification enables us to extend the controllable $O \left(1/k^{2\alpha} \right)$ rate to the monotonic variant, M-NAG-$\alpha$, thereby enhancing optimization efficiency. Finally, by leveraging the fundamental inequality for composite functions, we extended the controllable $O\left(1/k^{2\alpha} \right)$ rate to proximal algorithms, including the fast iterative shrinkage-thresholding algorithm (FISTA-$\alpha$) and its monotonic counterpart (M-FISTA-$\alpha$).</description>
      <guid isPermaLink="false">oai:arXiv.org:2501.10051v1</guid>
      <category>math.OC</category>
      <category>cs.NA</category>
      <category>math.NA</category>
      <category>stat.ML</category>
      <pubDate>Mon, 20 Jan 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <dc:creator>Mingwei Fu, Bin Shi</dc:creator>
    </item>
    <item>
      <title>Optimal Restart Strategies for Parameter-dependent Optimization Algorithms</title>
      <link>https://arxiv.org/abs/2501.10173</link>
      <description>arXiv:2501.10173v1 Announce Type: new 
Abstract: This paper examines restart strategies for algorithms whose successful termination depends on an unknown parameter $\lambda$. After each restart, $\lambda$ is increased, until the algorithm terminates successfully. It is assumed that there is a unique, unknown, optimal value for $\lambda$. For the algorithm to run successfully, this value must be reached or surpassed. The key question is whether there exists an optimal strategy for selecting $\lambda$ after each restart taking into account that the computational costs (runtime) increases with $\lambda$. In this work, potential restart strategies are classified into parameter-dependent strategy types. A loss function is introduced to quantify the wasted computational cost relative to the optimal strategy. A crucial requirement for any efficient restart strategy is that its loss, relative to the optimal $\lambda$, remains bounded. To this end, upper and lower bounds of the loss are derived. Using these bounds it will be shown that not all strategy types are bounded. However, for a particular strategy type, where $\lambda$ is increased multiplicatively by a constant factor $\lambda$, the relative loss function is bounded. Furthermore, it will be demonstrated that within this strategy type, there exists an optimal value for $\lambda$ that minimizes the maximum relative loss. In the asymptotic limit, this optimal choice of $\lambda$ does not depend on the unknown optimal $\lambda$.</description>
      <guid isPermaLink="false">oai:arXiv.org:2501.10173v1</guid>
      <category>math.OC</category>
      <category>cs.NE</category>
      <pubDate>Mon, 20 Jan 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Lisa Sch\"onenberger, Hans-Georg Beyer</dc:creator>
    </item>
    <item>
      <title>DADA: Dual Averaging with Distance Adaptation</title>
      <link>https://arxiv.org/abs/2501.10258</link>
      <description>arXiv:2501.10258v1 Announce Type: new 
Abstract: We present a novel universal gradient method for solving convex optimization problems. Our algorithm -- Dual Averaging with Distance Adaptation (DADA) -- is based on the classical scheme of dual averaging and dynamically adjusts its coefficients based on observed gradients and the distance between iterates and the starting point, eliminating the need for problem-specific parameters. DADA is a universal algorithm that simultaneously works for a broad spectrum of problem classes, provided the local growth of the objective function around its minimizer can be bounded. Particular examples of such problem classes are nonsmooth Lipschitz functions, Lipschitz-smooth functions, H\"older-smooth functions, functions with high-order Lipschitz derivative, quasi-self-concordant functions, and $(L_0,L_1)$-smooth functions. Crucially, DADA is applicable to both unconstrained and constrained problems, even when the domain is unbounded, without requiring prior knowledge of the number of iterations or desired accuracy.</description>
      <guid isPermaLink="false">oai:arXiv.org:2501.10258v1</guid>
      <category>math.OC</category>
      <category>cs.LG</category>
      <pubDate>Mon, 20 Jan 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Mohammad Moshtaghifar, Anton Rodomanov, Daniil Vankov, Sebastian Stich</dc:creator>
    </item>
    <item>
      <title>Fixed Confidence and Fixed Tolerance Bi-level Optimization for Selecting the Best Optimized System</title>
      <link>https://arxiv.org/abs/2501.10268</link>
      <description>arXiv:2501.10268v1 Announce Type: new 
Abstract: In this paper, we study a fixed-confidence, fixed-tolerance formulation of a class of stochastic bi-level optimization problems, where the upper-level problem selects from a finite set of systems based on a performance metric, and the lower-level problem optimizes continuous decision variables for each system. Notably, the objective functions for the upper and lower levels can differ. This class of problems has a wide range of applications, including model selection, ranking and selection under input uncertainty, and optimal design. To address this, we propose a multi-stage Pruning-Optimization framework that alternates between comparing the performance of different systems (Pruning) and optimizing systems (Optimization). % In the Pruning stage, we design a sequential algorithm that identifies and eliminates inferior systems through systematic performance evaluations. In the Optimization stage, the goal is to solve for a near-optimal solution that meets specified confidence and tolerance requirements. This multi-stage framework is designed to enhance computational efficiency by pruning inferior systems with high tolerance early on, thereby avoiding unnecessary computational efforts. We demonstrate the effectiveness of the proposed algorithm through both theoretical analysis of statistical validity and sample complexity and numerical experiments.</description>
      <guid isPermaLink="false">oai:arXiv.org:2501.10268v1</guid>
      <category>math.OC</category>
      <category>stat.ME</category>
      <pubDate>Mon, 20 Jan 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Yuhao Wang, Seong-Hee Kim, Enlu Zhou</dc:creator>
    </item>
    <item>
      <title>Micro-Macro Decomposition of Particle Swarm Optimization Methods</title>
      <link>https://arxiv.org/abs/2501.10306</link>
      <description>arXiv:2501.10306v1 Announce Type: new 
Abstract: Solving non-convex minimization problems using multi-particle metaheuristic derivative-free optimization methods is still active area of research. Popular methods are Particle Swarm Optimization (PSO) methods, that iteratively update a population of particles according to dynamics inspired by social interactions between individuals. We present a modification to include constrained minimization problems using exact penalization. Additionally, we utilize the hierarchical structure of PSO to introduce a micro-macro decomposition of the algorithm. The probability density of particles is written as a convex combination of microscopic and macroscopic contributions, and both parts are propagated separately. The decomposition is dynamically updated based on heuristic considerations. Numerical examples compare the results obtained using the algorithm in the microscopic scale, in the macroscopic scale, and, using the new micro-macro decomposition.</description>
      <guid isPermaLink="false">oai:arXiv.org:2501.10306v1</guid>
      <category>math.OC</category>
      <pubDate>Mon, 20 Jan 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Michael Herty, Sara Veneruso</dc:creator>
    </item>
    <item>
      <title>Adaptive Weighted Total Variation boosted by learning techniques in few-view tomographic imaging</title>
      <link>https://arxiv.org/abs/2501.09845</link>
      <description>arXiv:2501.09845v1 Announce Type: cross 
Abstract: This study presents the development of a spatially adaptive weighting strategy for Total Variation regularization, aimed at addressing under-determined linear inverse problems. The method leverages the rapid computation of an accurate approximation of the true image (or its gradient magnitude) through a neural network. Our approach operates without requiring prior knowledge of the noise intensity in the data and avoids the iterative recomputation of weights. Additionally, the paper includes a theoretical analysis of the proposed method, establishing its validity as a regularization approach. This framework integrates advanced neural network capabilities within a regularization context, thereby making the results of the networks interpretable. The results are promising as they enable high-quality reconstructions from limited-view tomographic measurements.</description>
      <guid isPermaLink="false">oai:arXiv.org:2501.09845v1</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <category>math.OC</category>
      <pubDate>Mon, 20 Jan 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Elena Morotti, Davide Evangelista, Andrea Sebastiani, Elena Loli Piccolomini</dc:creator>
    </item>
    <item>
      <title>Client-Centric Federated Adaptive Optimization</title>
      <link>https://arxiv.org/abs/2501.09946</link>
      <description>arXiv:2501.09946v1 Announce Type: cross 
Abstract: Federated Learning (FL) is a distributed learning paradigm where clients collaboratively train a model while keeping their own data private. With an increasing scale of clients and models, FL encounters two key challenges, client drift due to a high degree of statistical/system heterogeneity, and lack of adaptivity. However, most existing FL research is based on unrealistic assumptions that virtually ignore system heterogeneity. In this paper, we propose Client-Centric Federated Adaptive Optimization, which is a class of novel federated adaptive optimization approaches. We enable several features in this framework such as arbitrary client participation, asynchronous server aggregation, and heterogeneous local computing, which are ubiquitous in real-world FL systems but are missed in most existing works. We provide a rigorous convergence analysis of our proposed framework for general nonconvex objectives, which is shown to converge with the best-known rate. Extensive experiments show that our approaches consistently outperform the baseline by a large margin across benchmarks.</description>
      <guid isPermaLink="false">oai:arXiv.org:2501.09946v1</guid>
      <category>cs.LG</category>
      <category>cs.AI</category>
      <category>math.OC</category>
      <pubDate>Mon, 20 Jan 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Jianhui Sun, Xidong Wu, Heng Huang, Aidong Zhang</dc:creator>
    </item>
    <item>
      <title>Optimal Control of Several Motion Models</title>
      <link>https://arxiv.org/abs/2205.00260</link>
      <description>arXiv:2205.00260v2 Announce Type: replace 
Abstract: This paper is devoted to the study of the dynamic optimization of several controlled crowd motion models in the general planar settings, which is an application of a class of optimal control problems involving a general nonconvex sweeping process with perturbations. A set of necessary optimality conditions for such optimal control problems involving the crowd motion models with multiple agents and obstacles is obtained and analyzed. Several effective algorithms based on such necessary optimality conditions are proposed and various nontrivial illustrative examples together with their simulations are also presented. The implementation of all the considered motion models can be found via the link: https://github.com/tancao1128/Optimal_Control_of_Several_Motion_Models with the instruction and demonstration video uploaded at https://www.youtube.com/watch?v=B8DQ0wvCtIQ.</description>
      <guid isPermaLink="false">oai:arXiv.org:2205.00260v2</guid>
      <category>math.OC</category>
      <pubDate>Mon, 20 Jan 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Tan H. Cao, Nilson Chapagain, Haejoon Lee, Phung Ngoc Thi, Nguyen Nang Thieu</dc:creator>
    </item>
    <item>
      <title>Solving Optimal Control Problems of Rigid-Body Dynamics with Collisions Using the Hybrid Minimum Principle</title>
      <link>https://arxiv.org/abs/2205.08622</link>
      <description>arXiv:2205.08622v3 Announce Type: replace 
Abstract: Collisions are common in many dynamical systems with real applications. They can be formulated as hybrid dynamical systems with discontinuities automatically triggered when states transverse certain manifolds. We present an algorithm for the optimal control problem of such hybrid dynamical systems based on solving the equations derived from the hybrid minimum principle (HMP). The algorithm is an iterative scheme following the spirit of the method of successive approximations (MSA), and it is robust to undesired collisions observed in the initial guesses. We propose several techniques to address the additional numerical challenges introduced by the presence of discontinuities. The algorithm is tested on disc collision problems whose optimal solutions exhibit one or multiple collisions. Linear convergence in terms of iteration steps and asymptotic first-order accuracy in terms of time discretization are observed when the algorithm is implemented with the forward-Euler scheme. The numerical results demonstrate that the proposed algorithm has better accuracy and convergence than direct methods based on gradient descent. Furthermore, the algorithm is also simpler, more accurate, and more stable than a deep reinforcement learning method.</description>
      <guid isPermaLink="false">oai:arXiv.org:2205.08622v3</guid>
      <category>math.OC</category>
      <pubDate>Mon, 20 Jan 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Wei Hu, Jihao Long, Yaohua Zang, Weinan E, Jiequn Han</dc:creator>
    </item>
    <item>
      <title>Stochastic Optimal Control via Local Occupation Measures</title>
      <link>https://arxiv.org/abs/2211.15652</link>
      <description>arXiv:2211.15652v3 Announce Type: replace 
Abstract: Viewing stochastic processes through the lens of occupation measures has proved to be a powerful angle of attack for the theoretical and computational analysis of stochastic optimal control problems. We present a simple modification of the traditional occupation measure framework derived from resolving the occupation measures locally on a partition of the control problem's space-time domain. This notion of local occupation measures provides fine-grained control over the construction of structured semidefinite programming relaxations for a rich class of stochastic optimal control problems with embedded diffusion and jump processes via the moment-sum-of-squares hierarchy. As such, it bridges the gap between discretization-based approximations to the Hamilton-Jacobi-Bellmann equations and occupation measure relaxations. We demonstrate with examples that this approach enables the computation of high quality bounds for the optimal value of a large class of stochastic optimal control problems with significant performance gains relative to the traditional occupation measure framework.</description>
      <guid isPermaLink="false">oai:arXiv.org:2211.15652v3</guid>
      <category>math.OC</category>
      <category>cs.SY</category>
      <category>eess.SY</category>
      <pubDate>Mon, 20 Jan 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Flemming Holtorf, Alan Edelman, Christopher Rackauckas</dc:creator>
    </item>
    <item>
      <title>Time-Varying Convex Optimization: A Contraction and Equilibrium Tracking Approach</title>
      <link>https://arxiv.org/abs/2305.15595</link>
      <description>arXiv:2305.15595v4 Announce Type: replace 
Abstract: In this article, we provide a novel and broadly-applicable contraction-theoretic approach to continuous-time time-varying convex optimization. For any parameter-dependent contracting dynamics, we show that the tracking error is asymptotically proportional to the rate of change of the parameter and that the proportionality constant is upper bounded by Lipschitz constant in which the parameter appears divided by the contraction rate of the dynamics squared. We additionally establish that augmenting any parameter-dependent contracting dynamics with a feedforward prediction term ensures that the tracking error vanishes exponentially quickly. To apply these results to time-varying convex optimization, we establish the strong infinitesimal contractivity of dynamics solving three canonical problems: monotone inclusions, linear equality-constrained problems, and composite minimization problems. For each case, we derive the sharpest-known contraction rates and provide explicit bounds on the tracking error between solution trajectories and minimizing trajectories. We validate our theoretical results on two numerical examples and on an application to control barrier function-based controller design that involves real hardware.</description>
      <guid isPermaLink="false">oai:arXiv.org:2305.15595v4</guid>
      <category>math.OC</category>
      <category>cs.SY</category>
      <category>eess.SP</category>
      <category>eess.SY</category>
      <pubDate>Mon, 20 Jan 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Alexander Davydov, Veronica Centorrino, Anand Gokhale, Giovanni Russo, Francesco Bullo</dc:creator>
    </item>
    <item>
      <title>Controlling the Rates of a Chain of Harmonic Oscillators with a Point Langevin Thermostat</title>
      <link>https://arxiv.org/abs/2401.06536</link>
      <description>arXiv:2401.06536v4 Announce Type: replace 
Abstract: We consider the control problem of controlling the rates of an infinite chain of coupled harmonic oscillators with a Langevin thermostat at the origin. We study the effect of two types of open-loop boundary controls, impulsive control and linear memory-feedback control, in the high frequency limit. We investigate their action on the reflection-transmission coefficients for the wave energy for the scattering of the thermostat. Our study shows that the impulsive boundary controls have no impact on the rates and are thus not appropriate to act on the system, despite their physical meaning and relevance. In contrast, the second kind of control that we propose, which is less standard and uses the past of the state solution of the system, is adequate and relevant. We prove that any triple of rates satisfying appropriate assumptions is asymptotically reachable thanks to the linear memory-feedback controls that we design explicitly.</description>
      <guid isPermaLink="false">oai:arXiv.org:2401.06536v4</guid>
      <category>math.OC</category>
      <pubDate>Mon, 20 Jan 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Amirali Hannani, Minh-Binh Tran, Minh Nhat Phung, Emmanuel Tr\'elat</dc:creator>
    </item>
    <item>
      <title>Effective Front-Descent Algorithms with Convergence Guarantees</title>
      <link>https://arxiv.org/abs/2405.08450</link>
      <description>arXiv:2405.08450v2 Announce Type: replace 
Abstract: In this manuscript, we address continuous unconstrained multi-objective optimization problems and we discuss descent type methods for the reconstruction of the Pareto set. Specifically, we analyze the class of Front Descent methods, which generalizes the Front Steepest Descent algorithm allowing the employment of suitable, effective search directions (e.g., Newton, Quasi-Newton, Barzilai-Borwein). We provide a deep characterization of the behavior and the mechanisms of the algorithmic framework, and we prove that, under reasonable assumptions, standard convergence results and some complexity bounds hold for the generalized approach. Moreover, we prove that popular search directions can indeed be soundly used within the framework. Then, we provide a completely novel type of convergence results, concerning the sequence of sets produced by the procedure. In particular, iterate sets are shown to asymptotically approach stationarity for all of their points; the convergence result is accompanied by a worst-case iteration complexity bound; additionally, in finite precision settings, the sets are shown to only be enriched through exploration steps in later iterations, and suitable stopping conditions can be devised. Finally, the results from a large experimental benchmark show that the proposed class of approaches far outperforms state-of-the-art methodologies.</description>
      <guid isPermaLink="false">oai:arXiv.org:2405.08450v2</guid>
      <category>math.OC</category>
      <pubDate>Mon, 20 Jan 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Matteo Lapucci, Pierluigi Mansueto, Davide Pucci</dc:creator>
    </item>
    <item>
      <title>Adjustable Robust Nonlinear Network Design Without Controllable Elements under Load Scenario Uncertainties</title>
      <link>https://arxiv.org/abs/2405.17867</link>
      <description>arXiv:2405.17867v2 Announce Type: replace 
Abstract: We study network design problems for nonlinear and nonconvex flow models without controllable elements under load scenario uncertainties, i.e., under uncertain injections and withdrawals. To this end, we apply the concept of adjustable robust optimization to compute a network design that admits a feasible transport for all, possibly infinitely many, load scenarios within a given uncertainty set. For solving the corresponding adjustable robust mixed-integer nonlinear optimization problem, we show that a given network design is robust feasible, i.e., it admits a feasible transport for all load scenario uncertainties, if and only if a finite number of worst-case load scenarios can be routed through the network. We compute these worst-case scenarios by solving polynomially many nonlinear optimization problems. Embedding this result for robust feasibility in an adversarial approach leads to an exact algorithm that computes an optimal robust network design in a finite number of iterations. Since all of the results are valid for general potential-based flows, the approach can be applied to different utility networks such as gas, hydrogen, or water networks. We finally demonstrate the applicability of the method by computing robust gas networks that are protected from future load fluctuations.</description>
      <guid isPermaLink="false">oai:arXiv.org:2405.17867v2</guid>
      <category>math.OC</category>
      <pubDate>Mon, 20 Jan 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Johannes Th\"urauf, Julia Gr\"ubel, Martin Schmidt</dc:creator>
    </item>
    <item>
      <title>Extremum Seeking for Linear Time-Varying Systems with Unknown Control Directions</title>
      <link>https://arxiv.org/abs/2408.13344</link>
      <description>arXiv:2408.13344v2 Announce Type: replace 
Abstract: We consider bounded extremum seeking controls for time-varying linear systems with uncertain coefficient matrices and measurement uncertainty. Using a new change of variables, Lyapunov functions, and a comparison principle, we provide practical exponential stability bounds for the states of the closed loop systems that hold for all nonnegative times. For the first time for linear time-varying systems with unknown control directions, we consider bounded extremum seeking controls in the presence of uncertain time-varying input delays with small time-varying delay uncertainties, and we provide reduction model controllers to compensate for the constant part of the delays.</description>
      <guid isPermaLink="false">oai:arXiv.org:2408.13344v2</guid>
      <category>math.OC</category>
      <pubDate>Mon, 20 Jan 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Frederic Mazenc, Michael Malisoff, Emilia Fridman</dc:creator>
    </item>
    <item>
      <title>Centralized Reduction of Decentralized Stochastic Control Models and their weak-Feller Regularity</title>
      <link>https://arxiv.org/abs/2408.13828</link>
      <description>arXiv:2408.13828v4 Announce Type: replace 
Abstract: Decentralized stochastic control problems involving general state/measurement/action spaces are intrinsically difficult to study because of the inapplicability of standard tools from centralized (single-agent) stochastic control. In this paper, we address some of these challenges for decentralized stochastic control with standard Borel spaces under two different but tightly related information structures: the one-step delayed information sharing pattern (OSDISP), and the $K$-step periodic information sharing pattern (KSPISP). We will show that the one-step delayed and $K$-step periodic problems can be reduced to a centralized Markov Decision Process (MDP), generalizing prior results which considered finite, linear, or static models, by addressing several measurability and topological questions. We then provide sufficient conditions for the transition kernels of both centralized reductions to be weak-Feller. The existence and separated nature of optimal policies under both information structures are then established. The weak Feller regularity also facilitates rigorous approximation and learning theoretic results, as shown in the paper.</description>
      <guid isPermaLink="false">oai:arXiv.org:2408.13828v4</guid>
      <category>math.OC</category>
      <category>cs.MA</category>
      <pubDate>Mon, 20 Jan 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Omar Mrani-Zentar, Serdar Y\"uksel</dc:creator>
    </item>
    <item>
      <title>A Two-Timescale Decision-Hazard-Decision Formulation for Storage Usage Values Calculation</title>
      <link>https://arxiv.org/abs/2408.17113</link>
      <description>arXiv:2408.17113v2 Announce Type: replace 
Abstract: The penetration of renewable energies requires additional storages to deal with intermittency. Accordingly, there is growing interest in evaluating the opportunity cost (usage value) associated with stored energy in large storages, a cost obtained by solving a multistage stochastic optimization problem. Today, to compute usage values under uncertainties, an adequacy resource problem is solved using stochastic dynamic programming assuming a hazard-decision information structure. This modelling assumes complete knowledge of the coming week uncertainties, which is not adapted to the system operation as the intermittency occurs at smaller timescale. We equip the twotimescale problem with a new information structure considering planning and recourse decisions: decision-hazard-decision. This structure is used to decompose the multistage decision-making process into a nonanticipative planning step in which the on/off decisions for the thermal units are made, and a recourse step in which the power modulation decisions are made once the uncertainties have been disclosed. In a numerical case, we illustrate how usage values are sensitive as how the disclosure of information is modelled.</description>
      <guid isPermaLink="false">oai:arXiv.org:2408.17113v2</guid>
      <category>math.OC</category>
      <pubDate>Mon, 20 Jan 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Camila Martinez Parra (RTE, CERMICS), Michel de Lara (CERMICS), Jean-Philippe Chancelier (CERMICS), Pierre Carpentier (OC), Jean-Marc Janin (RTE), Manuel Ruiz (RTE)</dc:creator>
    </item>
    <item>
      <title>Decentralized Conjugate Gradient and Memoryless BFGS Methods</title>
      <link>https://arxiv.org/abs/2409.07122</link>
      <description>arXiv:2409.07122v3 Announce Type: replace 
Abstract: This paper proposes a new decentralized conjugate gradient (NDCG) method and a decentralized memoryless BFGS (DMBFGS) method for the nonconvex and strongly convex decentralized optimization problem, respectively, of minimizing a finite sum of continuously differentiable functions over a fixed-connected undirected network. Gradient tracking techniques are applied in these two methods to enhance their convergence properties and the numerical stability. In particular, we show global convergence of NDCG with constant stepsize for general nonconvex smooth decentralized optimization. Our new DMBFGS method uses a scaled memoryless BFGS technique and only requires gradient information to approximate second-order information of the component functions in the objective. We also establish global convergence and linear convergence rate of DMBFGS with constant stepsize for strongly convex smooth decentralized optimization. Our numerical results show that NDCG and DMBFGS are very efficient in terms of both iteration and communication cost compared with other state-of-the-art methods for solving smooth decentralized optimization.</description>
      <guid isPermaLink="false">oai:arXiv.org:2409.07122v3</guid>
      <category>math.OC</category>
      <pubDate>Mon, 20 Jan 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Liping Wang, Hao Wu, Hongchao Zhang</dc:creator>
    </item>
    <item>
      <title>Near Optimal Approximations and Finite Memory Policies for POMPDs with Continuous Spaces</title>
      <link>https://arxiv.org/abs/2410.02895</link>
      <description>arXiv:2410.02895v2 Announce Type: replace 
Abstract: We study an approximation method for partially observed Markov decision processes (POMDPs) with continuous spaces. Belief MDP reduction, which has been the standard approach to study POMDPs requires rigorous approximation methods for practical applications, due to the state space being lifted to the space of probability measures. Generalizing recent work, in this paper we present rigorous approximation methods via discretizing the observation space and constructing a fully observed finite MDP model using a finite length history of the discrete observations and control actions. We show that the resulting policy is near-optimal under some regularity assumptions on the channel, and under certain controlled filter stability requirements for the hidden state process. Furthermore, by quantizing the measurements, we are able to utilize refined filter stability conditions. We also provide a Q learning algorithm that uses a finite memory of discretized information variables, and prove its convergence to the optimality equation of the finite fully observed MDP constructed using the approximation method.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.02895v2</guid>
      <category>math.OC</category>
      <category>cs.SY</category>
      <category>eess.SY</category>
      <pubDate>Mon, 20 Jan 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Ali Devran Kara, Erhan Bayraktar, Serdar Yuksel</dc:creator>
    </item>
    <item>
      <title>On the Hypomonotone Class of Variational Inequalities</title>
      <link>https://arxiv.org/abs/2410.09182</link>
      <description>arXiv:2410.09182v2 Announce Type: replace 
Abstract: This paper studies the behavior of the extragradient algorithm [Korpelevich, 1976] when applied to hypomonotone operators, a class of problems that extends beyond the classical monotone setting. To support the understanding of this variational inequality problem class, we focus on a subclass of hypomonotone linear operators, characterizing them based on their eigenvalues and providing concrete examples. While the extragradient method is widely recognized for its efficiency in solving variational inequalities involving monotone and Lipschitz continuous operators, we demonstrate that it does not guarantee convergence in the hypomonotone case. In particular, we construct a counterexample where the extragradient method diverges regardless of the step size. A numerical experiment is presented to support this result.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.09182v2</guid>
      <category>math.OC</category>
      <category>stat.ML</category>
      <pubDate>Mon, 20 Jan 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Khaled Alomar, Tatjana Chavdarova</dc:creator>
    </item>
    <item>
      <title>A Bottom-Up Approach to Optimizing the Solar Organic Rankine Cycle for Transactive Energy Trading</title>
      <link>https://arxiv.org/abs/2412.01359</link>
      <description>arXiv:2412.01359v2 Announce Type: replace 
Abstract: Solar Organic Rankine Cycle (ORC)-based power generation plants leverage solar irradiation to produce thermal energy, offering a highly compatible renewable technology due to the alignment between solar irradiation temperatures and ORC operating requirements. Their superior performance compared to steam Rankine cycles in small-scale applications makes them particularly relevant within the smart grid and microgrid contexts. This study explores the role of ORC in peer-to-peer (P2P) energy trading within renewable-based community microgrids, where consumers become prosumers, simultaneously producing and consuming energy while engaging in virtual trading at the distribution system level. Focusing on a microgrid integrating solar ORC with a storage system to meet consumer demand, the paper highlights the importance of combining these technologies with storage to enhance predictability and competitiveness with conventional energy plants, despite management challenges. A methodology based on operations research techniques is developed to optimize system performance. Furthermore, the impact of various technological parameters of the solar ORC on the system's performance is examined. The study concludes by assessing the value of solar ORC within the transactive energy trading framework across different configurations and scenarios. Results demonstrate an average 16\% reduction in operational costs, showcasing the benefits of implementing a predictable and manageable system in P2P transactive energy trading.</description>
      <guid isPermaLink="false">oai:arXiv.org:2412.01359v2</guid>
      <category>math.OC</category>
      <pubDate>Mon, 20 Jan 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Silvia Anna Cordieri, Chiara Bordin, Sambeet Mishra</dc:creator>
    </item>
    <item>
      <title>Solving Monge problem by Hilbert space embeddings of probability measures</title>
      <link>https://arxiv.org/abs/2412.03478</link>
      <description>arXiv:2412.03478v3 Announce Type: replace 
Abstract: We propose deep learning methods for classical Monge's optimal mass transportation problems, where where the distribution constraint is treated as penalty terms defined by the maximum mean discrepancy in the theory of Hilbert space embeddings of probability measures. We prove that the transport maps given by the proposed methods converge to optimal transport maps in the problem with $L^2$ cost. Several numerical experiments validate our methods. In particular, we show that our methods are applicable to large-scale Monge problems.</description>
      <guid isPermaLink="false">oai:arXiv.org:2412.03478v3</guid>
      <category>math.OC</category>
      <category>cs.NA</category>
      <category>math.NA</category>
      <pubDate>Mon, 20 Jan 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Takafumi Saito, Yumiharu Nakano</dc:creator>
    </item>
    <item>
      <title>The Effective Generalized Moment Problem</title>
      <link>https://arxiv.org/abs/2501.09385</link>
      <description>arXiv:2501.09385v2 Announce Type: replace 
Abstract: We establish new convergence rates for the moment-sum-of-squares (Moment-SOS) relaxations for the Generalized Moment Problem (GMP). These bounds, which adapt to the geometry of the underlying semi-algebraic set, apply to both the convergence of optima, and to the convergence in Hausdorff distance between the relaxation feasibility set and the GMP feasibility set. This research extends previous works limited to specific problems in polynomial optimization, volume computation and optimal control. We complement our theoretical analysis with an application: minimal rank symmetric tensor decomposition. In the examples, we formulate the problem as a GMP, solve using Moment-SOS relaxation, and apply the theoretical results to observe a convergence rate of the relaxations.</description>
      <guid isPermaLink="false">oai:arXiv.org:2501.09385v2</guid>
      <category>math.OC</category>
      <pubDate>Mon, 20 Jan 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Lucas Gamertsfelder, Bernard Mourrain</dc:creator>
    </item>
    <item>
      <title>A Simplification Method for Inequality Constraints in Integer Binary Encoding HOBO Formulations</title>
      <link>https://arxiv.org/abs/2501.09670</link>
      <description>arXiv:2501.09670v2 Announce Type: replace 
Abstract: This study proposes a novel method for simplifying inequality constraints in Higher-Order Binary Optimization (HOBO) formulations. The proposed method addresses challenges associated with Quadratic Unconstrained Binary Optimization (QUBO) formulations, specifically the increased computational complexity and reduced solution accuracy caused by the introduction of slack variables and the resulting growth in auxiliary qubits. By efficiently integrating constraints, the method enhances the computational efficiency and accuracy of both quantum and classical solvers. The effectiveness of the proposed approach is demonstrated through numerical experiments applied to combinatorial optimization problems. The results indicate that this method expands the applicability of quantum algorithms to high-dimensional problems and improves the practicality of classical optimization solvers for optimization problems involving inequality constraints.</description>
      <guid isPermaLink="false">oai:arXiv.org:2501.09670v2</guid>
      <category>math.OC</category>
      <category>quant-ph</category>
      <pubDate>Mon, 20 Jan 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Yuichiro Minato</dc:creator>
    </item>
    <item>
      <title>From Semi-Infinite Constraints to Structured Robust Policies: Optimal Gain Selection for Financial Systems</title>
      <link>https://arxiv.org/abs/2202.02300</link>
      <description>arXiv:2202.02300v2 Announce Type: replace-cross 
Abstract: This paper studies the robust optimal gain selection problem for financial trading systems, formulated within a \emph{double linear policy} framework, which allocates capital across long and short positions. The key objective is to guarantee \emph{robust positive expected} (RPE) profits uniformly across a range of uncertain market conditions while ensuring risk control. This problem leads to a robust optimization formulation with \emph{semi-infinite} constraints, where the uncertainty is modeled by a bounded set of possible return parameters. We address this by transforming semi-infinite constraints into structured policies -- the \emph{balanced} policy and the \emph{complementary} policy -- which enable explicit characterization of the optimal solution. Additionally, we propose a novel graphical approach to efficiently solve the robust gain selection problem, drastically reducing computational complexity. Empirical validation on historical stock price data demonstrates superior performance in terms of risk-adjusted returns and downside risk compared to conventional strategies. This framework generalizes classical mean-variance optimization by incorporating robustness considerations, offering a systematic and efficient solution for robust trading under uncertainty.</description>
      <guid isPermaLink="false">oai:arXiv.org:2202.02300v2</guid>
      <category>eess.SY</category>
      <category>cs.SY</category>
      <category>math.OC</category>
      <category>q-fin.CP</category>
      <category>q-fin.MF</category>
      <pubDate>Mon, 20 Jan 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Chung-Han Hsieh</dc:creator>
    </item>
    <item>
      <title>Dynamic Sensor Selection for Biomarker Discovery</title>
      <link>https://arxiv.org/abs/2405.09809</link>
      <description>arXiv:2405.09809v5 Announce Type: replace-cross 
Abstract: Advances in methods of biological data collection are driving the rapid growth of comprehensive datasets across clinical and research settings. These datasets provide the opportunity to monitor biological systems in greater depth and at finer time steps than was achievable in the past. Classically, biomarkers are used to represent and track key aspects of a biological system. Biomarkers retain utility even with the availability of large datasets, since monitoring and interpreting changes in a vast number of molecules remains impractical. However, given the large number of molecules in these datasets, a major challenge is identifying the best biomarkers for a particular setting Here, we apply principles of observability theory to establish a general methodology for biomarker selection. We demonstrate that observability measures effectively identify biologically meaningful sensors in a range of time series transcriptomics data. Motivated by the practical considerations of biological systems, we introduce the method of dynamic sensor selection (DSS) to maximize observability over time, thus enabling observability over regimes where system dynamics themselves are subject to change. This observability framework is flexible, capable of modeling gene expression dynamics and using auxiliary data, including chromosome conformation, to select biomarkers. Additionally, we demonstrate the applicability of this approach beyond genomics by evaluating the observability of neural activity These applications demonstrate the utility of observability-guided biomarker selection for across a wide range of biological systems, from agriculture and biomanufacturing to neural applications and beyond.</description>
      <guid isPermaLink="false">oai:arXiv.org:2405.09809v5</guid>
      <category>q-bio.MN</category>
      <category>math.OC</category>
      <pubDate>Mon, 20 Jan 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Joshua Pickard, Cooper Stansbury, Amit Surana, Lindsey Muir, Anthony Bloch, Indika Rajapakse</dc:creator>
    </item>
    <item>
      <title>Sensor-Based Distributionally Robust Control for Safe Robot Navigation in Dynamic Environments</title>
      <link>https://arxiv.org/abs/2405.18251</link>
      <description>arXiv:2405.18251v2 Announce Type: replace-cross 
Abstract: We introduce a novel method for mobile robot navigation in dynamic, unknown environments, leveraging onboard sensing and distributionally robust optimization to impose probabilistic safety constraints. Our method introduces a distributionally robust control barrier function (DR-CBF) that directly integrates noisy sensor measurements and state estimates to define safety constraints. This approach is applicable to a wide range of control-affine dynamics, generalizable to robots with complex geometries, and capable of operating at real-time control frequencies. Coupled with a control Lyapunov function (CLF) for path following, the proposed CLF-DR-CBF control synthesis method achieves safe, robust, and efficient navigation in challenging environments. We demonstrate the effectiveness and robustness of our approach for safe autonomous navigation under uncertainty in simulations and real-world experiments with differential-drive robots.</description>
      <guid isPermaLink="false">oai:arXiv.org:2405.18251v2</guid>
      <category>cs.RO</category>
      <category>cs.SY</category>
      <category>eess.SY</category>
      <category>math.OC</category>
      <pubDate>Mon, 20 Jan 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Kehan Long, Yinzhuang Yi, Zhirui Dai, Sylvia Herbert, Jorge Cort\'es, Nikolay Atanasov</dc:creator>
    </item>
  </channel>
</rss>
