<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>stat.ME updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/stat.ME</link>
    <description>stat.ME updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/stat.ME" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Thu, 23 Jan 2025 05:00:08 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Thu, 23 Jan 2025 00:00:00 -0500</pubDate>
    <skipDays>
      <day>Saturday</day>
      <day>Sunday</day>
    </skipDays>
    <item>
      <title>On the maximum of Cramer's V</title>
      <link>https://arxiv.org/abs/2501.12411</link>
      <description>arXiv:2501.12411v1 Announce Type: new 
Abstract: The Cramer's V is popular as an association coefficient in goodness-of-fit tests for contingency tables and its maximum value is known to be $1$, but it is not true. We propose a modified Cramer's V.</description>
      <guid isPermaLink="false">oai:arXiv.org:2501.12411v1</guid>
      <category>stat.ME</category>
      <pubDate>Thu, 23 Jan 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Etsuo Hamada</dc:creator>
    </item>
    <item>
      <title>On the two-step hybrid design for augmenting randomized trials using real-world data</title>
      <link>https://arxiv.org/abs/2501.12453</link>
      <description>arXiv:2501.12453v1 Announce Type: new 
Abstract: Hybrid clinical trials, that borrow real-world data (RWD), are gaining interest, especially for rare diseases. They assume RWD and randomized control arm be exchangeable, but violations can bias results, inflate type I error, or reduce power. A two-step hybrid design first tests exchangeability, reducing inappropriate borrowing but potentially inflating type I error (Yuan et al., 2019). We propose four methods to better control type I error. Approach 1 estimates the variance of test statistics, rejecting the null hypothesis based on large sample normal approximation. Approach 2 uses a numerical approach for exact critical value determination. Approach 3 splits type I error rates by equivalence test outcome. Approach 4 adjusts the critical value only when equivalence is established. Simulation studies using a hypothetical ALS scenario, evaluate type I error and power under various conditions, compared to the Bayesian power prior approach (Ibrahim et al., 2015). Our methods and the Bayesian power prior control type I error, whereas Yuan et al. (2019) increases it under exchangeability. If exchangeability doesn't hold, all methods fail to control type I error. Our methods show type I error inflation of 6%-8%, compared to 10% for Yuan et al. (2019) and 16% for the Bayesian power prior.</description>
      <guid isPermaLink="false">oai:arXiv.org:2501.12453v1</guid>
      <category>stat.ME</category>
      <category>stat.AP</category>
      <pubDate>Thu, 23 Jan 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Jiapeng Xu, Ruben P. A. van Eijk, Alicia Ellis, Tianyu Pan, Lorene M. Nelson, Kit C. B. Roes, Marc van Dijk, Maria Sarno, Leonard H. van den Berg, Lu Tian, Ying Lu</dc:creator>
    </item>
    <item>
      <title>Outcome-Assisted Multiple Imputation of Missing Treatments</title>
      <link>https://arxiv.org/abs/2501.12471</link>
      <description>arXiv:2501.12471v1 Announce Type: new 
Abstract: We provide guidance on multiple imputation of missing at random treatments in observational studies. Specifically, analysts should account for both covariates and outcomes, i.e., not just use propensity scores, when imputing the missing treatments. To do so, we develop outcome-assisted multiple imputation of missing treatments: the analyst fits a regression for the outcome on the treatment indicator and covariates, which is used to sharpen the predictive probabilities for missing treatments under an estimated propensity score model. We derive an expression for the bias of the inverse probability weighted estimator for the average treatment effect under multiple imputation of missing treatments, and we show theoretically that this bias can be made small by using outcome-assisted multiple imputation. Simulations demonstrate empirically that outcome-assisted multiple imputation can offer better inferential properties than using the treatment assignment model alone. We illustrate the procedure in an analysis of data from the National Longitudinal Survey of Youth.</description>
      <guid isPermaLink="false">oai:arXiv.org:2501.12471v1</guid>
      <category>stat.ME</category>
      <category>stat.AP</category>
      <category>stat.CO</category>
      <pubDate>Thu, 23 Jan 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Joseph Feldman, Jerome P. Reiter</dc:creator>
    </item>
    <item>
      <title>Flexible tree-structured regression for clustered data with an application to quality of life in older adults</title>
      <link>https://arxiv.org/abs/2501.12787</link>
      <description>arXiv:2501.12787v1 Announce Type: new 
Abstract: Tree-structured models are a powerful alternative to parametric regression models if non-linear effects and interactions are present in the data. Yet, classical tree-structured models might not be appropriate if data comes in clusters of units, which requires taking the dependence of observations into account. This is, for example, the case in cross-national studies, as presented here, where country-specific effects should not be neglected. To address this issue, we present a flexible tree-structured approach that achieves a sparse modeling of unit-specific effects and identifies subgroups (based on individual-level covariates) that differ with regard to the outcome. The methodological advances were motivated by the analysis of quality of life in older adults using data from the survey of Health, Ageing and Retirement in Europe. Application of the proposed model yields promising results and illustrated the accessibility of the approach. A comparison to alternative methods with regard to variable selection and goodness-of-fit was performed in several simulation experiments.</description>
      <guid isPermaLink="false">oai:arXiv.org:2501.12787v1</guid>
      <category>stat.ME</category>
      <pubDate>Thu, 23 Jan 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Nikolai Spuck, Matthias Schmid, Moritz Berger</dc:creator>
    </item>
    <item>
      <title>BRBVS: An R Package for Bivariate Variable selection in Copula Survival Model(s) domain</title>
      <link>https://arxiv.org/abs/2501.12837</link>
      <description>arXiv:2501.12837v1 Announce Type: new 
Abstract: BRBVS is a publicly available \texttt{R} package on CRAN that implements the algorithm proposed in Petti et al.(2024a). The algorithm was developed as the first proposal of variable selection for the class of Bivariate Survival Copula Models originally proposed in Marra &amp; Radice (2020) and implemented in the \texttt{GJRM} package. The core of the \texttt{BRBVS} package is to implement and make available to practitioners variable selection algorithms for bivariate survival data affected by censoring, providing easy-to-use functions and graphical outputs. The idea behind the algorithm is almost general and may also be extended to different class of models.</description>
      <guid isPermaLink="false">oai:arXiv.org:2501.12837v1</guid>
      <category>stat.ME</category>
      <category>stat.CO</category>
      <pubDate>Thu, 23 Jan 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Danilo Petti, Marcella Niglio, Marialuisa Restaino</dc:creator>
    </item>
    <item>
      <title>Differentiable Causal Discovery of Linear Non-Gaussian Acyclic Models Under Unmeasured Confounding</title>
      <link>https://arxiv.org/abs/2501.12854</link>
      <description>arXiv:2501.12854v1 Announce Type: new 
Abstract: We propose a novel score-based causal discovery method, named ABIC LiNGAM, which extends the linear non-Gaussian acyclic model (LiNGAM) framework to address the challenges of causal structure estimation in scenarios involving unmeasured confounders. By introducing the assumption that error terms follow a multivariate generalized normal distribution, our method leverages continuous optimization techniques to recover acyclic directed mixed graphs (ADMGs), including causal directions rather than just equivalence classes. We provide theoretical guarantees on the identifiability of causal parameters and demonstrate the effectiveness of our approach through extensive simulations and applications to real-world datasets.</description>
      <guid isPermaLink="false">oai:arXiv.org:2501.12854v1</guid>
      <category>stat.ME</category>
      <pubDate>Thu, 23 Jan 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Yoshimitsu Morinishi, Shohei Shimizu</dc:creator>
    </item>
    <item>
      <title>A Dimension-Reduced Multivariate Spatial Model for Extreme Events: Balancing Flexibility and Scalability</title>
      <link>https://arxiv.org/abs/2501.13070</link>
      <description>arXiv:2501.13070v1 Announce Type: new 
Abstract: Modeling extreme precipitation and temperature is vital for understanding the impacts of climate change, as hazards like intense rainfall and record-breaking temperatures can result in severe consequences, including floods, droughts, and wildfires. Gaining insight into the spatial variation and interactions between these extremes is critical for effective risk management, early warning systems, and informed policy-making. However, challenges such as the rarity of extreme events, spatial dependencies, and complex cross-variable interactions hinder accurate modeling. We introduce a novel framework for modeling spatial extremes, building upon spatial generalized extreme value (GEV) models. Our approach incorporates a dimension-reduced latent spatial process to improve scalability and flexibility, particularly in capturing asymmetry in cross-covariance structures. This Joint Latent Spatial GEV model (JLS-GEV) overcomes key limitations of existing methods by providing a more flexible framework for inter-variable dependencies. In addition to addressing event rarity, spatial dependence and cross-variable interactions, JLS-GEV supports nonstationary spatial behaviors and independently collected data sources, while maintaining practical fitting times through dimension reduction. We validate JLS-GEV through extensive simulation studies, demonstrating its superior performance in capturing spatial extremes compared to baseline modeling approaches. Application to real-world data on extreme precipitation and temperature in the southeastern United States highlights its practical utility. While primarily motivated by environmental challenges, this framework is broadly applicable to interdisciplinary studies of spatial extremes in interdependent natural processes.</description>
      <guid isPermaLink="false">oai:arXiv.org:2501.13070v1</guid>
      <category>stat.ME</category>
      <pubDate>Thu, 23 Jan 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Remy MacDonald, Benjamin Seiyon Lee, John Foley, Justin Lee</dc:creator>
    </item>
    <item>
      <title>Interpolation pour l'augmentation de donnees : Application \`a la gestion des adventices de la canne a sucre a la Reunion</title>
      <link>https://arxiv.org/abs/2501.12400</link>
      <description>arXiv:2501.12400v1 Announce Type: cross 
Abstract: Data augmentation is a crucial step in the development of robust supervised learning models, especially when dealing with limited datasets. This study explores interpolation techniques for the augmentation of geo-referenced data, with the aim of predicting the presence of Commelina benghalensis L. in sugarcane plots in La R\'eunion. Given the spatial nature of the data and the high cost of data collection, we evaluated two interpolation approaches: Gaussian processes (GPs) with different kernels and kriging with various variograms. The objectives of this work are threefold: (i) to identify which interpolation methods offer the best predictive performance for various regression algorithms, (ii) to analyze the evolution of performance as a function of the number of observations added, and (iii) to assess the spatial consistency of augmented datasets. The results show that GP-based methods, in particular with combined kernels (GP-COMB), significantly improve the performance of regression algorithms while requiring less additional data. Although kriging shows slightly lower performance, it is distinguished by a more homogeneous spatial coverage, a potential advantage in certain contexts.</description>
      <guid isPermaLink="false">oai:arXiv.org:2501.12400v1</guid>
      <category>q-bio.QM</category>
      <category>cs.LG</category>
      <category>stat.AP</category>
      <category>stat.ME</category>
      <category>stat.ML</category>
      <pubDate>Thu, 23 Jan 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Frederick Fabre Ferber, Dominique Gay, Jean-Christophe Soulie, Jean Diatta, Odalric-Ambrym Maillard</dc:creator>
    </item>
    <item>
      <title>Identification of Nonparametric Dynamic Causal Structure and Latent Process in Climate System</title>
      <link>https://arxiv.org/abs/2501.12500</link>
      <description>arXiv:2501.12500v1 Announce Type: cross 
Abstract: The study of learning causal structure with latent variables has advanced the understanding of the world by uncovering causal relationships and latent factors, e.g., Causal Representation Learning (CRL). However, in real-world scenarios, such as those in climate systems, causal relationships are often nonparametric, dynamic, and exist among both observed variables and latent variables. These challenges motivate us to consider a general setting in which causal relations are nonparametric and unrestricted in their occurrence, which is unconventional to current methods. To solve this problem, with the aid of 3-measurement in temporal structure, we theoretically show that both latent variables and processes can be identified up to minor indeterminacy under mild assumptions. Moreover, we tackle the general nonlinear Causal Discovery (CD) from observations, e.g., temperature, as a specific task of learning independent representation, through the principle of functional equivalence. Based on these insights, we develop an estimation approach simultaneously recovering both the observed causal structure and latent causal process in a nontrivial manner. Simulation studies validate the theoretical foundations and demonstrate the effectiveness of the proposed methodology. In the experiments involving climate data, this approach offers a powerful and in-depth understanding of the climate system.</description>
      <guid isPermaLink="false">oai:arXiv.org:2501.12500v1</guid>
      <category>cs.LG</category>
      <category>stat.ME</category>
      <pubDate>Thu, 23 Jan 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Minghao Fu, Biwei Huang, Zijian Li, Yujia Zheng, Ignavier Ng, Yingyao Hu, Kun Zhang</dc:creator>
    </item>
    <item>
      <title>Slamming the sham: A Bayesian model for adaptive adjustment with noisy control data</title>
      <link>https://arxiv.org/abs/1905.09693</link>
      <description>arXiv:1905.09693v3 Announce Type: replace 
Abstract: It is not always clear how to adjust for control data in causal inference, balancing the goals of reducing bias and variance. We show how, in a setting with repeated experiments, Bayesian hierarchical modeling yields an adaptive procedure that uses the data to determine how much adjustment to perform. The result is a novel analysis with increased statistical efficiency compared to the default analysis based on difference estimates. We demonstrate this procedure on two real examples, as well as on a series of simulated datasets. We show that the increased efficiency can have real-world consequences in terms of the conclusions that can be drawn from the experiments. We also discuss the relevance of this work to causal inference and statistical design and analysis more generally.</description>
      <guid isPermaLink="false">oai:arXiv.org:1905.09693v3</guid>
      <category>stat.ME</category>
      <category>stat.AP</category>
      <pubDate>Thu, 23 Jan 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Andrew Gelman, Matthijs V\'ak\'ar</dc:creator>
    </item>
    <item>
      <title>Perturbation-based Effect Measures for Compositional Data</title>
      <link>https://arxiv.org/abs/2311.18501</link>
      <description>arXiv:2311.18501v3 Announce Type: replace 
Abstract: Existing effect measures for compositional features are inadequate for many modern applications for two reasons. First, modern datasets with compositional covariates, for example in microbiome research, display traits such as high-dimensionality and sparsity that can be poorly modelled with traditional parametric approaches. Second, assessing -- in an unbiased way -- how summary statistics of a composition (e.g., racial diversity) affect a response variable is not straightforward. In this work, we propose a framework based on hypothetical data perturbations that addresses both issues. Unlike many existing effect measures for compositional features, we do not define our effects based on a parametric model or a transformation of the data. Instead, we use perturbations to define interpretable statistical functionals on the compositions themselves, which we call average perturbation effects. These effects naturally account for confounding that biases frequently used marginal dependence analyses. We show how average perturbation effects can be estimated efficiently by deriving a perturbation-dependent reparametrization and applying semiparametric estimation techniques. We analyze the proposed estimators empirically on simulated and semi-synthetic data and demonstrate advantages over existing techniques on data from New York schools and microbiome data. For all proposed estimators, we provide confidence intervals with uniform asymptotic coverage guarantees.</description>
      <guid isPermaLink="false">oai:arXiv.org:2311.18501v3</guid>
      <category>stat.ME</category>
      <category>math.ST</category>
      <category>stat.ML</category>
      <category>stat.TH</category>
      <pubDate>Thu, 23 Jan 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Anton Rask Lundborg, Niklas Pfister</dc:creator>
    </item>
    <item>
      <title>Logistic Multidimensional Data Analysis for Ordinal Response Variables using a Cumulative Link function</title>
      <link>https://arxiv.org/abs/2402.07629</link>
      <description>arXiv:2402.07629v2 Announce Type: replace 
Abstract: We present a multidimensional data analysis framework for the analysis of ordinal response variables. Underlying the ordinal variables, we assume a continuous latent variable, leading to cumulative logit models. The framework includes unsupervised methods, when no predictor variables are available, and supervised methods, when predictor variables are available. We distinguish between dominance variables and proximity variables, where dominance variables are analyzed using inner product models, whereas the proximity variables are analyzed using distance models. An expectation-majorization-minimization algorithm is derived for estimation of the parameters of the models. We illustrate our methodology with three empirical data sets highlighting the advantages of the proposed framework. A simulation study is conducted to evaluate the performance of the algorithm.</description>
      <guid isPermaLink="false">oai:arXiv.org:2402.07629v2</guid>
      <category>stat.ME</category>
      <category>stat.CO</category>
      <pubDate>Thu, 23 Jan 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Mark de Rooij, Ligaya Breemer, Dion Woestenburg, Frank Busing</dc:creator>
    </item>
    <item>
      <title>A Multinomial Canonical Decomposition Model, with emphasis on the analysis of Multivariate Binary data</title>
      <link>https://arxiv.org/abs/2402.07634</link>
      <description>arXiv:2402.07634v3 Announce Type: replace 
Abstract: In this paper, we propose to decompose the canonical parameter of a multinomial model into a set of participant scores and category scores. External information about the participants or the categories can be used to restrict these scores. Therefore, we impose the constraint that the scores are linear combinations of the external variables. For the estimation of the parameters of the decomposition, we derive a majorization-minimization algorithm. We place special emphasis on the case where the categories represent profiles of binary response variables. In that case, the multinomial model becomes a regression model for multiple binary response variables and researchers might be interested in the effect of an external variable for the participant (i.e., a predictor) on a binary response variable or in the effect of this predictor on the association among binary response variables. We derive interpretational rules for these relationships in terms of changes in log odds or log odds ratios. Connections between our multinomial canonical decomposition and loglinear models, multinomial logistic regression, multinomial reduced rank logistic regression, and double constrained correspondence analysis are discussed. We use two empirical data sets, the first to show the relationships between a loglinear analysis approach and our modelling approach. The second data set is used as an illustration of our modelling approach and describes the model selection and interpretation in detail.</description>
      <guid isPermaLink="false">oai:arXiv.org:2402.07634v3</guid>
      <category>stat.ME</category>
      <category>stat.CO</category>
      <pubDate>Thu, 23 Jan 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Mark de Rooij</dc:creator>
    </item>
    <item>
      <title>Degree-heterogeneous Latent Class Analysis for High-dimensional Discrete Data</title>
      <link>https://arxiv.org/abs/2402.18745</link>
      <description>arXiv:2402.18745v5 Announce Type: replace 
Abstract: The latent class model is a widely used mixture model for multivariate discrete data. Besides the existence of qualitatively heterogeneous latent classes, real data often exhibit additional quantitative heterogeneity nested within each latent class. The modern latent class analysis also faces extra challenges, including the high-dimensionality, sparsity, and heteroskedastic noise inherent in discrete data. Motivated by these phenomena, we introduce the Degree-heterogeneous Latent Class Model and propose an easy-to-implement HeteroClustering algorithm for it. HeteroClustering uses heteroskedastic PCA with $\ell_2$ normalization to remove degree effects and perform clustering in the top singular subspace of the data matrix. We establish the result of exact clustering under minimal signal-to-noise conditions. We further investigate the estimation and inference of the high-dimensional continuous item parameters in the model, which are crucial to interpreting and finding useful markers for latent classes. We provide comprehensive procedures for global testing and multiple testing of these parameters with valid error controls. The superior performance of our methods is demonstrated through extensive simulations and applications to three diverse real-world datasets from political voting records, genetic variations, and single-cell sequencing.</description>
      <guid isPermaLink="false">oai:arXiv.org:2402.18745v5</guid>
      <category>stat.ME</category>
      <category>math.ST</category>
      <category>stat.TH</category>
      <pubDate>Thu, 23 Jan 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Zhongyuan Lyu, Ling Chen, Yuqi Gu</dc:creator>
    </item>
    <item>
      <title>Statistical algorithms for low-frequency diffusion data: A PDE approach</title>
      <link>https://arxiv.org/abs/2405.01372</link>
      <description>arXiv:2405.01372v3 Announce Type: replace 
Abstract: We consider the problem of making nonparametric inference in a class of multi-dimensional diffusions in divergence form, from low-frequency data. Statistical analysis in this setting is notoriously challenging due to the intractability of the likelihood and its gradient, and computational methods have thus far largely resorted to expensive simulation-based techniques. In this article, we propose a new computational approach which is motivated by PDE theory and is built around the characterisation of the transition densities as solutions of the associated heat (Fokker-Planck) equation. Employing optimal regularity results from the theory of parabolic PDEs, we prove a novel characterisation for the gradient of the likelihood. Using these developments, for the nonlinear inverse problem of recovering the diffusivity, we then show that the numerical evaluation of the likelihood and its gradient can be reduced to standard elliptic eigenvalue problems, solvable by powerful finite element methods. This enables the efficient implementation of a large class of popular statistical algorithms, including (i) preconditioned Crank-Nicolson and Langevin-type methods for posterior sampling, and (ii) gradient-based descent optimisation schemes to compute maximum likelihood and maximum-a-posteriori estimates. We showcase the effectiveness of these methods via extensive simulation studies in a nonparametric Bayesian model with Gaussian process priors, in which both the proposed optimisation and sampling schemes provide good numerical recovery. The reproducible code is available online at https://github.com/MattGiord/LF-Diffusion.</description>
      <guid isPermaLink="false">oai:arXiv.org:2405.01372v3</guid>
      <category>stat.ME</category>
      <category>cs.NA</category>
      <category>math.NA</category>
      <category>math.ST</category>
      <category>stat.CO</category>
      <category>stat.TH</category>
      <pubDate>Thu, 23 Jan 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Matteo Giordano, Sven Wang</dc:creator>
    </item>
    <item>
      <title>Reduced Rank Regression for Mixed Predictor and Response Variables</title>
      <link>https://arxiv.org/abs/2405.19865</link>
      <description>arXiv:2405.19865v2 Announce Type: replace 
Abstract: In this paper, we propose the generalized mixed reduced rank regression method, GMR$^3$ for short. GMR$^3$ is a regression method for a mix of numeric, binary, and ordinal response variables. The predictor variables can be a mix of binary, nominal, ordinal, and numeric variables. For dealing with the categorical predictors we use optimal scaling. A majorization-minimization algorithm is derived for maximum likelihood estimation under a local independence assumption. A series of simulation studies is shown (Section 4) to evaluate the performance of the algorithm with different types of predictor and response variables. In Section 5.2, we briefly discuss the choices to make when applying the model the empirical data and give suggestions for supporting such choices. In Section 6.1, we show an application of GMR$^3$ using the Eurobarometer Surveys data set of 2023.</description>
      <guid isPermaLink="false">oai:arXiv.org:2405.19865v2</guid>
      <category>stat.ME</category>
      <category>stat.CO</category>
      <pubDate>Thu, 23 Jan 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Mark de Rooij, Lorenza Cotugno, Roberta Siciliano</dc:creator>
    </item>
    <item>
      <title>Structural adaptation via directional regularity: rate accelerated estimation in multivariate functional data</title>
      <link>https://arxiv.org/abs/2409.00817</link>
      <description>arXiv:2409.00817v3 Announce Type: replace 
Abstract: We introduce directional regularity, a new definition of anisotropy for multivariate functional data. Instead of taking the conventional view which determines anisotropy as a notion of smoothness along a dimension, directional regularity additionally views anisotropy through the lens of directions. We show that faster rates of convergence can be obtained through a change-of-basis by adapting to the directional regularity of a multivariate process. An algorithm for the estimation and identification of the change-of-basis matrix is constructed, made possible due to the replication structure of functional data. Non-asymptotic bounds are provided for our algorithm, supplemented by numerical evidence from an extensive simulation study. Possible applications of the directional regularity approach are discussed, and we advocate its consideration as a standard pre-processing step in multivariate functional data analysis.</description>
      <guid isPermaLink="false">oai:arXiv.org:2409.00817v3</guid>
      <category>stat.ME</category>
      <category>math.ST</category>
      <category>stat.ML</category>
      <category>stat.TH</category>
      <pubDate>Thu, 23 Jan 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <dc:creator>Omar Kassi, Sunny G. W. Wang</dc:creator>
    </item>
    <item>
      <title>On the Role of Surrogates in Conformal Inference of Individual Causal Effects</title>
      <link>https://arxiv.org/abs/2412.12365</link>
      <description>arXiv:2412.12365v2 Announce Type: replace 
Abstract: Learning the Individual Treatment Effect (ITE) is essential for personalized decision-making, yet causal inference has traditionally focused on aggregated treatment effects. While integrating conformal prediction with causal inference can provide valid uncertainty quantification for ITEs, the resulting prediction intervals are often excessively wide, limiting their practical utility. To address this limitation, we introduce \underline{S}urrogate-assisted \underline{C}onformal \underline{I}nference for \underline{E}fficient I\underline{N}dividual \underline{C}ausal \underline{E}ffects (SCIENCE), a framework designed to construct more efficient prediction intervals for ITEs. SCIENCE accommodates the covariate shifts between source data and target data and applies to various data configurations, including semi-supervised and surrogate-assisted semi-supervised learning. Leveraging semi-parametric efficiency theory, SCIENCE produces rate double-robust prediction intervals under mild rate convergence conditions, permitting the use of flexible non-parametric models to estimate nuisance functions. We quantify efficiency gains by comparing semi-parametric efficiency bounds with and without the surrogates. Simulation studies demonstrate that our surrogate-assisted intervals offer substantial efficiency improvements over existing methods while maintaining valid group-conditional coverage. Applied to the phase 3 Moderna COVE COVID-19 vaccine trial, SCIENCE illustrates how multiple surrogate markers can be leveraged to generate more efficient prediction intervals.</description>
      <guid isPermaLink="false">oai:arXiv.org:2412.12365v2</guid>
      <category>stat.ME</category>
      <category>math.ST</category>
      <category>stat.AP</category>
      <category>stat.ML</category>
      <category>stat.TH</category>
      <pubDate>Thu, 23 Jan 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <dc:creator>Chenyin Gao, Peter B. Gilbert, Larry Han</dc:creator>
    </item>
    <item>
      <title>Bayesian Shrinkage Priors for Penalized Synthetic Control Estimators in the Presence of Spillovers</title>
      <link>https://arxiv.org/abs/2501.08231</link>
      <description>arXiv:2501.08231v2 Announce Type: replace 
Abstract: Synthetic control (SC) methods are widely used to evaluate the impact of policy interventions, particularly those targeting specific geographic areas or regions, commonly referred to as units. These methods construct an artificial (synthetic) unit from untreated (control) units, intended to mirror the characteristics of the treated region had the intervention not occurred. While neighboring areas are often chosen as controls due to their assumed similarities with the treated, their proximity can introduce spillovers, where the intervention indirectly affects these controls, biasing the estimates. To address this challenge, we propose a Bayesian SC method with distance-based shrinkage priors, designed to estimate causal effects while accounting for spillovers. Modifying traditional penalization techniques, our approach incorporates a weighted distance function that considers both covariate information and spatial proximity to the treated. Rather than simply excluding nearby controls, this framework data-adaptively selects those less likely to be impacted by spillovers, providing a balance between bias and variance reduction. Through simulation studies, we demonstrate the finite-sample properties of our method under varying levels of spillover. We then apply this approach to evaluate the impact of Philadelphia's beverage tax on the sales of sugar-sweetened and artificially sweetened beverages in mass merchandise stores.</description>
      <guid isPermaLink="false">oai:arXiv.org:2501.08231v2</guid>
      <category>stat.ME</category>
      <pubDate>Thu, 23 Jan 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Esteban Fern\'andez-Morales, Arman Oganisian, Youjin Lee</dc:creator>
    </item>
    <item>
      <title>Model Averaging Under Flexible Loss Functions</title>
      <link>https://arxiv.org/abs/2501.09924</link>
      <description>arXiv:2501.09924v2 Announce Type: replace 
Abstract: To address model uncertainty under flexible loss functions in prediction problems, we propose a model averaging method that accommodates various loss functions, including asymmetric linear and quadratic loss functions, as well as many other asymmetric/symmetric loss functions as special cases. The flexible loss function allows the proposed method to average a large range of models, such as the quantile and expectile regression models. To determine the weights of the candidate models, we establish a J-fold cross-validation criterion. Asymptotic optimality and weights convergence are proved for the proposed method. Simulations and an empirical application show the superior performance of the proposed method, compared with other methods of model selection and averaging.</description>
      <guid isPermaLink="false">oai:arXiv.org:2501.09924v2</guid>
      <category>stat.ME</category>
      <pubDate>Thu, 23 Jan 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <arxiv:DOI>10.1287/ijoc.2023.0291</arxiv:DOI>
      <dc:creator>Dieqi Gu, Qingfeng Liu, Xinyu Zhang</dc:creator>
    </item>
    <item>
      <title>Cheap Subsampling bootstrap confidence intervals for fast and robust inference</title>
      <link>https://arxiv.org/abs/2501.10289</link>
      <description>arXiv:2501.10289v2 Announce Type: replace 
Abstract: Bootstrapping is often applied to get confidence limits for semiparametric inference of a target parameter in the presence of nuisance parameters. Bootstrapping with replacement can be computationally expensive and problematic when cross-validation is used in the estimation algorithm due to duplicate observations in the bootstrap samples. We provide a valid, fast, easy-to-implement subsampling bootstrap method for constructing confidence intervals for asymptotically linear estimators and discuss its application to semiparametric causal inference. Our method, inspired by the Cheap Bootstrap (Lam, 2022), leverages the quantiles of a t-distribution and has the desired coverage with few bootstrap replications. We show that the method is asymptotically valid if the subsample size is chosen appropriately as a function of the sample size. We illustrate our method with data from the LEADER trial (Marso et al., 2016), obtaining confidence intervals for a longitudinal targeted minimum loss-based estimator (van der Laan and Gruber, 2012). Through a series of empirical experiments, we also explore the impact of subsample size, sample size, and the number of bootstrap repetitions on the performance of the confidence interval.</description>
      <guid isPermaLink="false">oai:arXiv.org:2501.10289v2</guid>
      <category>stat.ME</category>
      <category>stat.AP</category>
      <pubDate>Thu, 23 Jan 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Johan Sebastian Ohlendorff, Anders Munch, Kathrine Kold S{\o}rensen, Thomas Alexander Gerds</dc:creator>
    </item>
    <item>
      <title>Sparsity meets correlation in Gaussian sequence model</title>
      <link>https://arxiv.org/abs/2312.09356</link>
      <description>arXiv:2312.09356v2 Announce Type: replace-cross 
Abstract: We study estimation of an $s$-sparse signal in the $p$-dimensional Gaussian sequence model with equicorrelated observations and derive the minimax rate. A new phenomenon emerges from correlation, namely the rate scales with respect to $p-2s$ and exhibits a phase transition at $p-2s \asymp \sqrt{p}$. Correlation is shown to be a blessing provided it is sufficiently strong, and the critical correlation level exhibits a delicate dependence on the sparsity level. Due to correlation, the minimax rate is driven by two subproblems: estimation of a linear functional (the average of the signal) and estimation of the signal's $(p-1)$-dimensional projection onto the orthogonal subspace. The high-dimensional projection is estimated via sparse regression and the linear functional is cast as a robust location estimation problem. Existing robust estimators turn out to be suboptimal, and we show a kernel mode estimator with a widening bandwidth exploits the Gaussian character of the data to achieve the optimal estimation rate.</description>
      <guid isPermaLink="false">oai:arXiv.org:2312.09356v2</guid>
      <category>math.ST</category>
      <category>stat.ME</category>
      <category>stat.TH</category>
      <pubDate>Thu, 23 Jan 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Subhodh Kotekal, Chao Gao</dc:creator>
    </item>
  </channel>
</rss>
