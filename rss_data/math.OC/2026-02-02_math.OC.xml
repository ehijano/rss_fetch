<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>math.OC updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/math.OC</link>
    <description>math.OC updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/math.OC" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Mon, 02 Feb 2026 05:26:10 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Mon, 02 Feb 2026 00:00:00 -0500</pubDate>
    <skipDays>
      <day>Sunday</day>
      <day>Saturday</day>
    </skipDays>
    <item>
      <title>Forecasting in the presence of scale-free noise</title>
      <link>https://arxiv.org/abs/2601.22294</link>
      <description>arXiv:2601.22294v1 Announce Type: new 
Abstract: The extraction of signals from noise is a common problem in all areas of science and engineering. A particularly useful version is that of forecasting: determining a causal filter that estimates a future value of a hidden process from past observations. Current techniques for deriving the filter require that the noise be well described by rational power spectra. However, scale-free noises, whose spectra scale as a non-integer power of frequency, are ubiquitous in practice. We establish a method, together with performance guarantees, that solves the forecasting problem in the presence of scale-free noise. Via the duality between estimation and control, our technique can be used to design control for distributed systems. These results will have wide-ranging applications in neuroscience, finance, fluid dynamics, and quantum measurements.</description>
      <guid isPermaLink="false">oai:arXiv.org:2601.22294v1</guid>
      <category>math.OC</category>
      <category>cs.SY</category>
      <category>eess.SP</category>
      <category>eess.SY</category>
      <pubDate>Mon, 02 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Serhii Kryhin, Tatiana Mouzykantskii, Vivishek Sudhir</dc:creator>
    </item>
    <item>
      <title>Operating Imperfect AI: Reliability Drift and Human Congestion</title>
      <link>https://arxiv.org/abs/2601.22295</link>
      <description>arXiv:2601.22295v1 Announce Type: new 
Abstract: The deployment of machine learning in high-stakes services relies on ``human-in-the-loop'' architectures to mitigate algorithmic uncertainty. However, existing static policies fail to address a fundamental tension: algorithms suffer from stochastic ``reliability drift,'' while human override capacity is scarce and congestible. We formulate the management of such systems as a dynamic queueing control problem. The system state is defined by the tuple (queue backlog, reliability regime), and the control variable is a state-dependent risk threshold. We prove that the optimal escalation policy is driven by the endogenous ``Shadow Price of Capacity.'' We establish two key structural monotonicity results: (i) Congestion Shedding, where the threshold rises with backlog to sacrifice marginal accuracy for responsiveness; and (ii) Safety Buffering, where the threshold lowers during drift to use the queue as a ``risk capacitor.'' Furthermore, we identify a critical ``Capacity Phase Transition'' in the arrival-drift parameter space, beyond which no policy can maintain safety standards without causing structural system failure (infinite queues). Our results provide rigorous operational rules for managing the interface between imperfect algorithms and congested experts.</description>
      <guid isPermaLink="false">oai:arXiv.org:2601.22295v1</guid>
      <category>math.OC</category>
      <pubDate>Mon, 02 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Ziyao Wang, Svetlozar T Rachev</dc:creator>
    </item>
    <item>
      <title>Square Root-Factorized Covariance Steering</title>
      <link>https://arxiv.org/abs/2601.22348</link>
      <description>arXiv:2601.22348v1 Announce Type: new 
Abstract: Covariance steering (CS) synthesizes a control policy which drives the state's mean and covariance matrix towards desired values. Offering tractable computation of a closed-loop policy which can obey chance constraints in uncertain environments, application to many real-world control problems have been proposed. We consider the chance-constrained, discrete-time, linear time-varying CS with Gaussian noise. The contribution of this paper is a novel solution method for this problem, explicitly writing the propagation equations of the Cholesky factor of the state covariance matrix by using the QR decomposition. The use of the square-root form of covariance matrices brings two key benefits over other existing methods: (i) computational scalability and (ii) numerical reliability. (i) Compared to solution methods that require large block matrix formulations, the proposed method scales better with the growth in horizon length, shows better optimality, and uses memoryless state feedback. (ii) Compared to another class of methods that explicitly define the covariance matrix as variables, the proposed method allows flexible cost formulations and shows better numerical reliability when uncertainty terms are smaller than the mean. On the other hand, these benefits come with a minor drawback: the propagation equation of covariance square roots is non-convex, necessitating sequential convex programming to solve. However, this paper proves the global optimality of the proposed approach for CS without chance constraints. When chance constraints are present, the existing optimal CS formulation is also non-convex, and we prove that the proposed approach shares the same local minima. We verify the mathematical arguments via extensive numerical simulations.</description>
      <guid isPermaLink="false">oai:arXiv.org:2601.22348v1</guid>
      <category>math.OC</category>
      <pubDate>Mon, 02 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Naoya Kumagai, Kenshiro Oguri</dc:creator>
    </item>
    <item>
      <title>Operator Splitting with Hamilton-Jacobi-based Proximals</title>
      <link>https://arxiv.org/abs/2601.22370</link>
      <description>arXiv:2601.22370v1 Announce Type: new 
Abstract: Operator splitting algorithms are a cornerstone of modern first-order optimization, decomposing complex problems into simpler subproblems solved via proximal operators. However, most functions lack closed-form proximal operators, which has long restricted these methods to a narrow set of problems. Hamilton-Jacobi-based proximal operator (HJ-Prox) is a recent derivative-free Monte Carlo technique based on Hamilton-Jacobi PDE theory, that approximates proximal operators numerically. In this work, we introduce a unified framework for operator splitting via HJ-Prox, which allows for deployment of operator splitting even when functions are not proximable. We prove that replacing exact proximal steps with HJ-Prox in algorithms such as proximal point, proximal gradient descent, Douglas-Rachford splitting, Davis-Yin splitting, and primal-dual hybrid gradient preserves convergence guarantees under mild assumptions. Numerical experiments demonstrate HJ-Prox is competitive and effective on a wide variety of statistical learning tasks.</description>
      <guid isPermaLink="false">oai:arXiv.org:2601.22370v1</guid>
      <category>math.OC</category>
      <pubDate>Mon, 02 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Nicholas Di, Eric C. Chi, Samy Wu Fung</dc:creator>
    </item>
    <item>
      <title>Visibility in Polygonal Environments with Holes: Finding Best Spots for Hiding and Surveillance</title>
      <link>https://arxiv.org/abs/2601.22405</link>
      <description>arXiv:2601.22405v1 Announce Type: new 
Abstract: Visibility plays an important role for decision making in cluttered, uncertain environments. This paper considers the problem of identifying optimal hiding spots for an agent against line-of-sight detection by an adversary whose location is unknown. We consider environments modeled as polygons with holes. We develop a set of mathematical tools for reasoning about visibility as a function of position and rely on non-smooth analysis to formally characterize the regularity properties of various visibility-based metrics. These metrics are non-smooth and non-convex, so off-the-shelf optimization algorithms can only guarantee convergence to Clarke critical points. To address this, the proposed Normalized Descent algorithm leverages the structure of non-smooth points in visibility problems and introduces randomness to escape saddle points. Our technical analysis allows for the non-monotonic decrease in the visibility metric and strengthens the algorithm guarantees, ensuring convergence to local minima with high probability. Simulations on two hide-and-seek scenarios showcase the effectiveness of the proposed approach.</description>
      <guid isPermaLink="false">oai:arXiv.org:2601.22405v1</guid>
      <category>math.OC</category>
      <pubDate>Mon, 02 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Neilabh Banzal, Jorge Cort\'es, Sonia Mart\'inez</dc:creator>
    </item>
    <item>
      <title>Leader-Follower Linear-Quadratic Stochastic Graphon Games</title>
      <link>https://arxiv.org/abs/2601.22429</link>
      <description>arXiv:2601.22429v1 Announce Type: new 
Abstract: This paper investigates leader-follower linear-quadratic stochastic graphon games, which consist of a single leader and a continuum of followers. The state equations of the followers interact through graphon coupling terms, with their diffusion coefficients depending on the state, the graphon aggregation term, and the control variables. The diffusion term of the leader's state equation depends on its state and control variables. Within this framework, a hierarchical decision-making structure is established: for any strategy adopted by the leader, the followers compete to attain a Nash equilibrium, while the leader optimizes its own cost functional by anticipating the followers' equilibrium response. This work develops a rigorous mathematical model for the game, proves the existence and uniqueness of solutions to the system's state equations under admissible control sets, and constructs a Stackelberg-Nash equilibrium for the continuum follower game. By employing the continuity method, we establish the existence, uniqueness, and stability of solutions to the associated forward-backward stochastic differential equation with a graphon aggregation term.</description>
      <guid isPermaLink="false">oai:arXiv.org:2601.22429v1</guid>
      <category>math.OC</category>
      <pubDate>Mon, 02 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/publicdomain/zero/1.0/</dc:rights>
      <dc:creator>Weijia Chen, Jingtao Shi</dc:creator>
    </item>
    <item>
      <title>Selective Adaptation of Beliefs and Communication on Cellular Sheaves</title>
      <link>https://arxiv.org/abs/2601.22431</link>
      <description>arXiv:2601.22431v1 Announce Type: new 
Abstract: We extend opinion dynamics on discourse sheaves to incorporate "directional stubbornness": agents may hold fixed positions in specified directions of their opinion stalk while remaining flexible in others. This converts the equilibrium problem from harmonic extension to a forced sheaf equation: the free-opinion component satisfies a sheaf Poisson equation with forcing induced by the clamped directions.
  We develop a parallel theory for "selective learning" of expression policies. When only a designated subset of incidence maps may adapt, the resulting gradient flow is sheaf diffusion on an auxiliary structure sheaf whose global sections correspond to sheaf structures making a fixed opinion profile publicly consistent.
  For joint evolution of beliefs and expressions, we give conditions (and regularized variants) guaranteeing convergence to nondegenerate equilibria, excluding spurious agreement via vanishing opinions or trivialized communication maps. Finally, we derive stagnation bounds in terms of the rate ratio between opinion updating and structural adaptation, quantifying when rapid rhetorical accommodation masks nearly unchanged beliefs, and conversely when flexible beliefs conform to rigid communication norms.</description>
      <guid isPermaLink="false">oai:arXiv.org:2601.22431v1</guid>
      <category>math.OC</category>
      <pubDate>Mon, 02 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Vicente Bosca, Robert Ghrist</dc:creator>
    </item>
    <item>
      <title>Local controllability of the Cahn-Hilliard-Burgers' equation around certain steady states</title>
      <link>https://arxiv.org/abs/2601.22611</link>
      <description>arXiv:2601.22611v1 Announce Type: new 
Abstract: In this article we study the local controllability of the one-dimensional Cahn-Hilliard-Navier-Stokes equation, that is Cahn-Hilliard-Burgers' equation, around a certain steady state using a localized interior control acting only in the concentration equation. To do it, we first linearize the nonlinear equation around the steady state. The linearized system turns out to be a system coupled between second order and fourth order parabolic equations and the control acts in the fourth order parabolic equation. The null controllability of the linearized system is obtained by a duality argument proving an observability inequality. To prove the observability inequality, a new Carleman inequality for the coupled system is derived. Next, using the source term method, it is shown that the null controllability of the linearized system with non-homogeneous terms persists provided the non-homogeneous terms satisfy certain estimates in a suitable weighted space. Finally, using a Banach fixed point theorem in a suitable weighted space, the local controllability of the nonlinear system is obtained.</description>
      <guid isPermaLink="false">oai:arXiv.org:2601.22611v1</guid>
      <category>math.OC</category>
      <pubDate>Mon, 02 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Manika Bag, Sheetal Dharmatti, Subrata Majumdar, Debanjana Mitra</dc:creator>
    </item>
    <item>
      <title>SUN-DSBO: A Structured Unified Framework for Nonconvex Decentralized Stochastic Bilevel Optimization</title>
      <link>https://arxiv.org/abs/2601.22682</link>
      <description>arXiv:2601.22682v1 Announce Type: new 
Abstract: Decentralized stochastic bilevel optimization (DSBO) is a powerful tool for various machine learning tasks, including decentralized meta-learning and hyperparameter tuning. Existing DSBO methods primarily address problems with strongly convex lower-level objective functions. However, nonconvex objective functions are increasingly prevalent in modern deep learning. In this work, we introduce SUN-DSBO, a Structured Unified framework for Nonconvex DSBO, in which both the upper- and lower-level objective functions may be nonconvex. Notably, SUN-DSBO offers the flexibility to incorporate decentralized stochastic gradient descent or various techniques for mitigating data heterogeneity, such as gradient tracking (GT). We demonstrate that SUN-DSBO-GT, an adaptation of the GT technique within our framework, achieves a linear speedup with respect to the number of agents. This is accomplished without relying on restrictive assumptions, such as gradient boundedness or any specific assumptions regarding gradient heterogeneity. Numerical experiments validate the effectiveness of our method.</description>
      <guid isPermaLink="false">oai:arXiv.org:2601.22682v1</guid>
      <category>math.OC</category>
      <pubDate>Mon, 02 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Yaoshuai Ma, Xiao Wang, Wei Yao, Jin Zhang</dc:creator>
    </item>
    <item>
      <title>Enhancing Exploration in Global Optimization by Noise Injection in the Probability Measures Space</title>
      <link>https://arxiv.org/abs/2601.22753</link>
      <description>arXiv:2601.22753v1 Announce Type: new 
Abstract: McKean-Vlasov (MKV) systems provide a unifying framework for recent state-of-the-art particlebased methods for global optimization. While individual particles follow stochastic trajectories, the probability law evolves deterministically in the mean-field limit, potentially limiting exploration in multimodal landscapes. We introduce two principled approaches to inject noise directly into the probability law dynamics: a perturbative method based on conditional MKV theory, and a geometric approach leveraging tangent space structure. While these approaches are of independent interest, the aim of this work is to apply them to global optimization. Our framework applies generically to any method that can be formulated as a MKV system. Extensive experiments on multimodal objective functions demonstrate that both our noise injection strategies enhance consistently the exploration and convergence across different configurations of dynamics, such as Langevin, Consensus-Based Optimization, and Stein Boltzmann Sampling, providing a versatile toolkit for global optimization.</description>
      <guid isPermaLink="false">oai:arXiv.org:2601.22753v1</guid>
      <category>math.OC</category>
      <category>math.PR</category>
      <pubDate>Mon, 02 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Ga\"etan Serr\'e (ENS Paris Saclay, CB), Pierre Germain (UNINE), Samuel Gruffaz (CB, ENS Paris Saclay), Argyris Kalogeratos (CB, ENS Paris Saclay)</dc:creator>
    </item>
    <item>
      <title>Rapid stabilizability of delayed infinite-dimensional control systems</title>
      <link>https://arxiv.org/abs/2601.22819</link>
      <description>arXiv:2601.22819v1 Announce Type: new 
Abstract: In this paper, the rapid stabilizability of linear infinite-dimensional control system with constant-valued delay is studied. Under assumptions that the state operator generates an immediately compact semigroup and the coefficient of the delay term is constant, we mainly prove the following two results: (i) the delay does not affect rapid stabilizability of the control system; (ii) from the perspective of observation-feedback, it is not necessary to use historical information to stabilize the control system when the system is rapidly stabilizable. Some applications are given.</description>
      <guid isPermaLink="false">oai:arXiv.org:2601.22819v1</guid>
      <category>math.OC</category>
      <pubDate>Mon, 02 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Yaxing Ma, Lijuan Wang, Huaiqiang Yu</dc:creator>
    </item>
    <item>
      <title>Convergence Rates for the Alternating Minimization Algorithm in Structured Nonsmooth and Nonconvex Optimization</title>
      <link>https://arxiv.org/abs/2601.22850</link>
      <description>arXiv:2601.22850v1 Announce Type: new 
Abstract: This paper is devoted to developing the alternating minimization algorithm for problems of structured nonconvex optimization proposed by Attouch, Bolt\'e, Redont, and Soubeyran in 2010. Our main result provides significant improvements of the convergence rate of the algorithm, especially under the low exponent Polyak-{\L}ojasiewicz-Kurdyka condition when we establish either finite termination of this algorithm or its superlinear convergence rate instead of the previously known linear convergence. We also investigate the PLK exponent calculus and discuss applications to noncooperative games and behavioral science.</description>
      <guid isPermaLink="false">oai:arXiv.org:2601.22850v1</guid>
      <category>math.OC</category>
      <pubDate>Mon, 02 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/publicdomain/zero/1.0/</dc:rights>
      <dc:creator>Glaydston C. Bento, Boris S. Mordukhovich, Tiago S. Mota, Antoine Soubeyran</dc:creator>
    </item>
    <item>
      <title>Grassmannian Geometry and Global Convergence of Variable Projection for Neural Networks</title>
      <link>https://arxiv.org/abs/2601.22897</link>
      <description>arXiv:2601.22897v1 Announce Type: new 
Abstract: Training deep neural networks and Physics-Informed Neural Networks (PINNs) often leads to ill-conditioned and stiff optimization problems. A key structural feature of these models is that they are linear in the output-layer parameters and nonlinear in the hiddenlayer parameters, yielding a separable nonlinear least-squares formulation. In this work, we study the classical variable projection (VarPro) method for such problems in the context of deep neural networks. We provide a geometric formulation on the Grassmannian and analyze the structure of critical points and convergence properties of the reduced problem. When the feature map is parametrized by a neural network, we show that these properties persist except in rank-deficient regimes, which we address via a regularized Grassmannian framework. Numerical experiments for regression and PINNs, including an efficient solver for the heat equation, illustrate the practical effectiveness of the approach.</description>
      <guid isPermaLink="false">oai:arXiv.org:2601.22897v1</guid>
      <category>math.OC</category>
      <pubDate>Mon, 02 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Mathias Dus (IRMA)</dc:creator>
    </item>
    <item>
      <title>Breaking the Stochasticity Barrier: An Adaptive Variance-Reduced Method for Variational Inequalities</title>
      <link>https://arxiv.org/abs/2601.23034</link>
      <description>arXiv:2601.23034v1 Announce Type: new 
Abstract: Stochastic non-convex non-concave optimization, formally characterized as Stochastic Variational Inequalities (SVIs), presents unique challenges due to rotational dynamics and the absence of a global merit function. While adaptive step-size methods (like Armijo line-search) have revolutionized convex minimization, their application to this setting is hindered by the Stochasticity Barrier: the noise in gradient estimation masks the true operator curvature, triggering erroneously large steps that destabilize convergence. In this work, we propose VR-SDA-A (Variance-Reduced Stochastic Descent-Ascent with Armijo), a novel algorithm that integrates recursive momentum (STORM) with a rigorous Same-Batch Curvature Verification mechanism. We introduce a theoretical framework based on a Lyapunov potential tracking the Operator Norm, proving that VR- SDA-A achieves an oracle complexity of O(epsilon -3) for finding an epsilon-stationary point in general Lipschitz continuous operators. This matches the optimal rate for non-convex minimization while uniquely enabling automated step-size adaptation in the saddle-point setting. We validate our approach on canonical rotational benchmarks and non-convex robust regression tasks, demonstrating that our method effectively suppresses limit cycles and accelerates convergence with reduced dependence on manual learning rate scheduling.</description>
      <guid isPermaLink="false">oai:arXiv.org:2601.23034v1</guid>
      <category>math.OC</category>
      <pubDate>Mon, 02 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <arxiv:DOI>10.13140/RG.2.2.29337.07528</arxiv:DOI>
      <dc:creator>Yungi Jeong, Takumi Otsuka</dc:creator>
    </item>
    <item>
      <title>Accelerated Inertial Gradient Algorithms with Vanishing Tikhonov Regularization</title>
      <link>https://arxiv.org/abs/2601.23035</link>
      <description>arXiv:2601.23035v1 Announce Type: new 
Abstract: In this paper, we study an explicit Tikhonov-regularized inertial gradient algorithm for smooth convex minimization with Lipschitz continuous gradient. The method is derived via an explicit time discretization of a damped inertial system with vanishing Tikhonov regularization. Under appropriate control of the decay rate of the Tikhonov term, we establish accelerated convergence of the objective values to the minimum together with strong convergence of the iterates to the minimum-norm minimizer. In particular, for polynomial schedules $\varepsilon_k = k^{-p}$ with $0&lt;p&lt;2$, we prove strong convergence to the minimum-norm solution while preserving fast objective decay. In the critical case $p=2$, we still obtain fast rates for the objective values, while our analysis does not guarantee strong convergence to the minimum-norm minimizer. Furthermore, we provide a thorough theoretical analysis for several choices of Tikhonov schedules. Numerical experiments on synthetic, benchmark, and real datasets illustrate the practical performance of the proposed algorithm.</description>
      <guid isPermaLink="false">oai:arXiv.org:2601.23035v1</guid>
      <category>math.OC</category>
      <pubDate>Mon, 02 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Samir Adly, Vinh Thanh Ho, Huu Nhan Nguyen</dc:creator>
    </item>
    <item>
      <title>Stationary Mean-Field singular control of an Ornstein-Uhlenbeck process</title>
      <link>https://arxiv.org/abs/2601.23036</link>
      <description>arXiv:2601.23036v1 Announce Type: new 
Abstract: Motivated by continuous-time optimal inventory management, we study a class of stationary mean-field control problems with singular controls. The dynamics are modeled by a mean-reverting Ornstein-Uhlenbeck process, and the performance criterion is given by a quadratic long-time average expected cost functional. The mean-field dependence is through the stationary mean of the controlled process itself, which enters the ergodic cost functional. We characterize the solution to the stationary mean-field control problem in terms of the equilibria of an associated stationary mean-field game, showing that solutions of the control problem are in bijection with the equilibria of this mean-field game. Finally, we solve the stationary mean-field game explicitly, thereby providing a solution to the original stationary mean-field control problem.</description>
      <guid isPermaLink="false">oai:arXiv.org:2601.23036v1</guid>
      <category>math.OC</category>
      <pubDate>Mon, 02 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Federico Cannerozzi</dc:creator>
    </item>
    <item>
      <title>A General Tikhonov Regularized Second-Order Dynamical System for Convex-Concave Bilinear Saddle Point Problems</title>
      <link>https://arxiv.org/abs/2601.23120</link>
      <description>arXiv:2601.23120v1 Announce Type: new 
Abstract: In this paper, we propose a general Tikhonov regularized second-order dynamical system with viscous damping, time scaling and extrapolation coefficients for the convex-concave bilinear saddle point problem. By the Lyapunov function approach, we show that the convergence properties of the proposed dynamical system depend on the choice of the Tikhonov regularization parameter. Specifically, when the Tikhonov regularization parameter tends to zero rapidly, the convergence rate of the primal-dual gap along the generated trajectory is O(1 over t squared times beta(t)); when the Tikhonov regularization parameter tends to zero slowly, the convergence rate of the primal-dual gap is o(1 over beta(t)). We also prove the strong convergence property of the trajectory generated by the Tikhonov regularized dynamical system to the minimum-norm solution of the convex-concave bilinear saddle point problem, and derive several integral estimates. In addition, the effectiveness of the proposed dynamical system is verified through a series of numerical experiments.</description>
      <guid isPermaLink="false">oai:arXiv.org:2601.23120v1</guid>
      <category>math.OC</category>
      <category>math.DS</category>
      <pubDate>Mon, 02 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Bohan Zhang, Xiaojun Zhang</dc:creator>
    </item>
    <item>
      <title>General Optimal Stopping without Time Consistency</title>
      <link>https://arxiv.org/abs/2601.23187</link>
      <description>arXiv:2601.23187v1 Announce Type: new 
Abstract: In this paper, we propose a new framework for solving a general dynamic optimal stopping problem without time consistency. A sophisticated solution is proposed and is well-defined for any time setting with general flows of objectives. A backward iteration is proposed to find the solution. The iteration works with an additional condition, which holds in interesting cases including the time inconsistency arising from non-exponential discounting. Even if the iteration does not work, the equilibrium solution can still be studied by a forward definition.</description>
      <guid isPermaLink="false">oai:arXiv.org:2601.23187v1</guid>
      <category>math.OC</category>
      <pubDate>Mon, 02 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Hanqing Jin, Yanzhao Yang</dc:creator>
    </item>
    <item>
      <title>Theoretical Challenges in Learning for Branch-and-Cut</title>
      <link>https://arxiv.org/abs/2601.23249</link>
      <description>arXiv:2601.23249v1 Announce Type: new 
Abstract: Machine learning is increasingly used to guide branch-and-cut (B&amp;C) for mixed-integer linear programming by learning score-based policies for selecting branching variables and cutting planes. Many approaches train on local signals from lookahead heuristics such as strong branching, and linear programming (LP) bound improvement for cut selection. Training and evaluation of the learned models often focus on local score accuracy. We show that such local score-based methods can lead to search trees exponentially larger than optimal tree sizes, by identifying two sources of this gap. The first is that these widely used expert signals can be misaligned with overall tree size. LP bound improvement can select a root cut set that yields an exponentially larger strong branching tree than selecting cuts by a simple proxy score, and strong branching itself can be exponentially suboptimal (Dey et al., 2024). The second is that small discrepancies can be amplified by the branch-and-bound recursion. An arbitrarily small perturbation of the right-hand sides in a root cut set can change the minimum tree size from a single node to exponentially many. For branching, arbitrarily small score discrepancies, and differences only in tie-breaking, can produce trees of exponentially different sizes, and even a small number of decision differences along a trajectory can incur exponential growth. These results show that branch-and-cut policies trained and learned using local expert scores do not guarantee small trees, thus motivating the study of data-driven methods that produce policies better aligned with tree size rather than only accuracy on expert scores.</description>
      <guid isPermaLink="false">oai:arXiv.org:2601.23249v1</guid>
      <category>math.OC</category>
      <pubDate>Mon, 02 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Hongyu Cheng, Amitabh Basu</dc:creator>
    </item>
    <item>
      <title>Forward-KL Convergence of Time-Inhomogeneous Langevin Diffusions</title>
      <link>https://arxiv.org/abs/2601.22349</link>
      <description>arXiv:2601.22349v1 Announce Type: cross 
Abstract: Many practical samplers rely on time-dependent drifts -- often induced by annealing or tempering schedules -- to improve exploration and stability. This motivates a unified non-asymptotic analysis of the corresponding Langevin diffusions and their discretizations. We provide a convergence analysis that includes non-asymptotic bounds for the continuous-time diffusion and its Euler--Maruyama discretization in the forward-Kullback--Leibler divergence under a single set of abstract conditions on the time-dependent drift. The results apply to many practically-relevant annealing schemes, including geometric tempering and annealed Langevin sampling. In addition, we provide numerical experiments comparing the annealing schemes covered by our theory in low- and high-dimensional settings.</description>
      <guid isPermaLink="false">oai:arXiv.org:2601.22349v1</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <category>math.OC</category>
      <pubDate>Mon, 02 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Andreas Habring, Martin Zach</dc:creator>
    </item>
    <item>
      <title>An inertial minimal-deformation-rate framework for shape optimization</title>
      <link>https://arxiv.org/abs/2601.22605</link>
      <description>arXiv:2601.22605v1 Announce Type: cross 
Abstract: We propose a robust numerical framework for PDE-constrained shape optimization and Willmore-driven surface hole filling. To address two central challenges -- slow progress in flat energy landscapes, which can trigger premature stagnation at suboptimal configurations, and mesh deterioration during geometric evolution -- we couple a second-order inertial flow with a minimal-deformation-rate (MDR) mesh motion strategy. This coupling accelerates convergence while preserving mesh quality and thus avoids remeshing. To further enhance robustness for non-smooth or non-convex initial geometries, we incorporate surface-diffusion regularization within the Barrett-Garcke-N"urnberg (BGN) framework. Moreover, we extend the inertial MDR methodology to Willmore-type surface hole filling, enabling high-order smooth reconstructions even from incompatible initial data. Numerical experiments demonstrate markedly faster convergence to lower original objective values, together with consistently superior mesh preservation throughout the evolution.</description>
      <guid isPermaLink="false">oai:arXiv.org:2601.22605v1</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <category>math.OC</category>
      <pubDate>Mon, 02 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/publicdomain/zero/1.0/</dc:rights>
      <dc:creator>Falai Chen, Buyang Li, Jiajie Li, Rong Tang</dc:creator>
    </item>
    <item>
      <title>Distance Optimization in the Grassmannian of Lines</title>
      <link>https://arxiv.org/abs/2601.22843</link>
      <description>arXiv:2601.22843v1 Announce Type: cross 
Abstract: The square of a skew-symmetric matrix is a symmetric matrix whose eigenvalues have even multiplicities. When the matrices have rank two, they represent the Grassmannian of lines, and the squaring operation takes Pl\"ucker coordinates to projection coordinates. We develop metric algebraic geometry for varieties of lines in this linear algebra setting. The Grassmann distance (GD) degree is introduced as a new invariant for subvarieties of a Grassmannian. We study the GD degree for Schubert varieties and other models.</description>
      <guid isPermaLink="false">oai:arXiv.org:2601.22843v1</guid>
      <category>math.AG</category>
      <category>math.OC</category>
      <pubDate>Mon, 02 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Hannah Friedman, Andrea Rosana, Bernd Sturmfels</dc:creator>
    </item>
    <item>
      <title>Unconditional well-posedness of the master equation for monotone mean field games of controls</title>
      <link>https://arxiv.org/abs/2601.22845</link>
      <description>arXiv:2601.22845v1 Announce Type: cross 
Abstract: We establish the first unconditional well-posedness result for the master equation associated with a general class of mean field games of controls. Our analysis covers games with displacement monotone or Lasry--Lions monotone data, as well as those with a small time horizon. By unconditional, we mean that all assumptions are imposed solely at the level of the Lagrangian and the terminal cost. In particular, we do not require any a priori regularity or structural assumptions on the additional fixed-point mappings arising from the control interactions; instead we show that these fixed-point mappings are well-behaved as a consequence of the regularity and the monotonicity of the data. Our approach is bottom-up in nature, unlike most previous results which rely on a generalized method of characteristics. In particular, we build a classical solution of the master equation by showing that the solutions of the corresponding $N$-player Nash systems are compact, in an appropriate sense, and that their subsequential limit points must be solutions to the master equation. Compactness is obtained via uniform-in-$N$ decay estimates for derivatives of the $N$-player value functions. The underlying games are driven by non-degenerate idiosyncratic Brownian noise, and our results allow for the presence of common noise with constant intensity.</description>
      <guid isPermaLink="false">oai:arXiv.org:2601.22845v1</guid>
      <category>math.AP</category>
      <category>math.OC</category>
      <category>math.PR</category>
      <pubDate>Mon, 02 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Joe Jackson, Alp\'ar R. M\'esz\'aros</dc:creator>
    </item>
    <item>
      <title>Robust Rigid Body Assembly via Contact-Implicit Optimal Control with Exact Second-Order Derivatives</title>
      <link>https://arxiv.org/abs/2601.22849</link>
      <description>arXiv:2601.22849v1 Announce Type: cross 
Abstract: Efficient planning of assembly motions is a long standing challenge in the field of robotics that has been primarily tackled with reinforcement learning and sampling-based methods by using extensive physics simulations. This paper proposes a sample-efficient robust optimal control approach for the determination of assembly motions, which requires significantly less physics simulation steps during planning through the efficient use of derivative information. To this end, a differentiable physics simulation is constructed that provides second-order analytic derivatives to the numerical solver and allows one to traverse seamlessly from informative derivatives to accurate contact simulation. The solution of the physics simulation problem is made differentiable by using smoothing inspired by interior-point methods applied to both the collision detection as well as the contact resolution problem. We propose a modified variant of an optimization-based formulation of collision detection formulated as a linear program and present an efficient implementation for the nominal evaluation and corresponding first- and second-order derivatives. Moreover, a multi-scenario-based trajectory optimization problem that ensures robustness with respect to sim-to-real mismatches is derived. The capability of the considered formulation is illustrated by results where over 99\% successful executions are achieved in real-world experiments. Thereby, we carefully investigate the effect of smooth approximations of the contact dynamics and robust modeling on the success rates. Furthermore, the method's capability is tested on different peg-in-hole problems in simulation to show the benefit of using exact Hessians over commonly used Hessian approximations.</description>
      <guid isPermaLink="false">oai:arXiv.org:2601.22849v1</guid>
      <category>cs.RO</category>
      <category>math.OC</category>
      <pubDate>Mon, 02 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Christian Dietz, Sebastian Albrecht, Gianluca Frison, Moritz Diehl, Armin Nurkanovi\'c</dc:creator>
    </item>
    <item>
      <title>A Framework for the Bayesian Calibration of Complex and Data-Scarce Models in Applied Sciences</title>
      <link>https://arxiv.org/abs/2601.22890</link>
      <description>arXiv:2601.22890v1 Announce Type: cross 
Abstract: In this work, we review the theory involved in the Bayesian calibration of complex computer models, with particular emphasis on their use for applications involving computationally expensive simulations and scarce experimental data. In the article, we present a unified framework that incorporates various Bayesian calibration methods, including well-established approaches. Furthermore, we describe their implementation and use with a new, open-source Python library, ACBICI (A Configurable BayesIan Calibration and Inference Package). All algorithms are implemented with an object-oriented structure designed to be both easy to use and readily extensible. In particular, single-output and multiple-output calibration are addressed in a consistent manner. The article completes the theory and its implementation with practical recommendations for calibrating the problems of interest. These guidelines -- currently unavailable in a unified form elsewhere -- together with the open-source Python library, are intended to support the reliable calibration of computational codes and models commonly used in engineering and related fields. Overall, this work aims to serve both as a comprehensive review of the statistical foundations and (computational) tools required to perform such calculations, and as a practical guide to Bayesian calibration with modern software tools.</description>
      <guid isPermaLink="false">oai:arXiv.org:2601.22890v1</guid>
      <category>stat.CO</category>
      <category>cond-mat.mtrl-sci</category>
      <category>math.OC</category>
      <category>math.ST</category>
      <category>stat.TH</category>
      <pubDate>Mon, 02 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Christina Schenk, Ignacio Romero</dc:creator>
    </item>
    <item>
      <title>Status Updating via Integrated Sensing and Communication: Freshness Optimisation</title>
      <link>https://arxiv.org/abs/2601.22901</link>
      <description>arXiv:2601.22901v1 Announce Type: cross 
Abstract: This paper studies strategic design in an integrated sensing and communication (ISAC) architecture for status updating of remotely navigating agents. We consider an ISAC-enabled base station that can sense the state of a remote source and communicate this information back to the source. Both sensing and communication succeed with given probabilities and incur distinct costs. The objective is to optimise a long-term cost that captures information freshness, measured by the age of information (AoI), at the source together with sensing and communication overheads. The resulting sequential decision problem is formulated as a discounted infinite-horizon Markov decision process with a two-dimensional AoI state, representing information freshness at the source and at the base station. We prove that the optimal stationary policy admits a monotone threshold structure characterised by a nondecreasing switching curve in the AoI state space. Our numerical analysis illustrates the structures of the value function and the optimal decision map. These results demonstrate that freshness-based objectives can be naturally integrated into ISAC design, while yielding interpretable and implementable strategies.</description>
      <guid isPermaLink="false">oai:arXiv.org:2601.22901v1</guid>
      <category>cs.IT</category>
      <category>math.IT</category>
      <category>math.OC</category>
      <pubDate>Mon, 02 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Touraj Soleymani, Mohamad Assaad, John S. Baras</dc:creator>
    </item>
    <item>
      <title>Feedback Control via Integrated Sensing and Communication: Uncertainty Optimisation</title>
      <link>https://arxiv.org/abs/2601.22912</link>
      <description>arXiv:2601.22912v1 Announce Type: cross 
Abstract: This paper studies strategic design in an integrated sensing and communication (ISAC) architecture for feedback control of cyber-physical systems. We focus on a setting in which the regulation of a physical process (i.e., remote source) is performed via an ISAC-enabled base station. The base station can alternate between tracking the state of the source and delivering control-relevant information back to the source. For a Gauss-Markov source subject to i.i.d. Bernoulli sensing and communication links, under a finite-horizon linear-quadratic-Gaussian cost, we rigorously characterise the optimal policies through an uncertainty-aware synthesis. We establish that the optimal switching policy, for the ISAC system at the base station, is threshold-based in terms of the source and base-station estimation covariances, while the optimal control policy, for the actuator at the source, is linear in the source state estimate. We show that the threshold region$\unicode{x2014}$defined as the set of estimation covariance pairs for which communication is preferred over sensing$\unicode{x2014}$expands with increasing source uncertainty and contracts with increasing base-station uncertainty.</description>
      <guid isPermaLink="false">oai:arXiv.org:2601.22912v1</guid>
      <category>cs.IT</category>
      <category>math.IT</category>
      <category>math.OC</category>
      <pubDate>Mon, 02 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Touraj Soleymani, Mohamad Assaad, John S. Baras</dc:creator>
    </item>
    <item>
      <title>Robust Control of Constrained Linear Systems using Online Convex Optimization and a Reference Governor</title>
      <link>https://arxiv.org/abs/2601.23160</link>
      <description>arXiv:2601.23160v1 Announce Type: cross 
Abstract: This article develops a control method for linear time-invariant systems subject to time-varying and a priori unknown cost functions, that satisfies state and input constraints, and is robust to exogenous disturbances. To this end, we combine the online convex optimization framework with a reference governor and a constraint tightening approach. The proposed framework guarantees recursive feasibility and robust constraint satisfaction. Its closed-loop performance is studied in terms of its dynamic regret, which is bounded linearly by the variation of the cost functions and the magnitude of the disturbances. The proposed method is illustrated by a numerical case study of a tracking control problem.</description>
      <guid isPermaLink="false">oai:arXiv.org:2601.23160v1</guid>
      <category>eess.SY</category>
      <category>cs.SY</category>
      <category>math.OC</category>
      <pubDate>Mon, 02 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <arxiv:DOI>10.1109/CDC56724.2024.10886274</arxiv:DOI>
      <arxiv:journal_reference>2024 IEEE 63rd Conference on Decision and Control (CDC), 2024, pp. 6553-6559</arxiv:journal_reference>
      <dc:creator>Marko Nonhoff, Mohammad Taher Al Torshan, Matthias A. M\"uller</dc:creator>
    </item>
    <item>
      <title>YuriiFormer: A Suite of Nesterov-Accelerated Transformers</title>
      <link>https://arxiv.org/abs/2601.23236</link>
      <description>arXiv:2601.23236v1 Announce Type: cross 
Abstract: We propose a variational framework that interprets transformer layers as iterations of an optimization algorithm acting on token embeddings. In this view, self-attention implements a gradient step of an interaction energy, while MLP layers correspond to gradient updates of a potential energy. Standard GPT-style transformers emerge as vanilla gradient descent on the resulting composite objective, implemented via Lie--Trotter splitting between these two energy functionals. This perspective enables principled architectural design using classical optimization ideas. As a proof of concept, we introduce a Nesterov-style accelerated transformer that preserves the same attention and MLP oracles. The resulting architecture consistently outperforms a nanoGPT baseline on TinyStories and OpenWebText, demonstrating that optimization-theoretic insights can translate into practical gains.</description>
      <guid isPermaLink="false">oai:arXiv.org:2601.23236v1</guid>
      <category>cs.LG</category>
      <category>cs.AI</category>
      <category>math.OC</category>
      <category>stat.ML</category>
      <pubDate>Mon, 02 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Aleksandr Zimin, Yury Polyanskiy, Philippe Rigollet</dc:creator>
    </item>
    <item>
      <title>A Primal-Dual Level Set Method for Computing Geodesic Distances</title>
      <link>https://arxiv.org/abs/2601.23244</link>
      <description>arXiv:2601.23244v1 Announce Type: cross 
Abstract: The numerical computation of shortest paths or geodesics on surfaces, along with the associated geodesic distance, has a wide range of applications. Compared to Euclidean distance computation, these tasks are more complex due to the influence of surface geometry on the behavior of shortest paths. This paper introduces a primal-dual level set method for computing geodesic distances. A key insight is that the underlying surface can be implicitly represented as a zero level set, allowing us to formulate a constraint minimization problem. We employ the primal-dual methodology, along with regularization and acceleration techniques, to develop our algorithm. This approach is robust, efficient, and easy to implement. We establish a convergence result for the high-resolution PDE system, and numerical evidence suggests that the method converges to a geodesic in the limit of refinement.</description>
      <guid isPermaLink="false">oai:arXiv.org:2601.23244v1</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <category>math.OC</category>
      <pubDate>Mon, 02 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Hailiang Liu, Laura Zinnel</dc:creator>
    </item>
    <item>
      <title>Cardinal Optimizer (COPT) User Guide</title>
      <link>https://arxiv.org/abs/2208.14314</link>
      <description>arXiv:2208.14314v4 Announce Type: replace 
Abstract: Cardinal Optimizer is a high-performance mathematical programming solver for efficiently solving largescale optimization problem. This documentation provides basic introduction to the Cardinal Optimizer.</description>
      <guid isPermaLink="false">oai:arXiv.org:2208.14314v4</guid>
      <category>math.OC</category>
      <category>cs.MS</category>
      <pubDate>Mon, 02 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Dongdong Ge, Qi Huangfu, Zizhuo Wang, Jian Wu, Yinyu Ye</dc:creator>
    </item>
    <item>
      <title>Optimal Stabilization of Periodic Orbits: A Symplectic Geometry Approach</title>
      <link>https://arxiv.org/abs/2211.11955</link>
      <description>arXiv:2211.11955v3 Announce Type: replace 
Abstract: In this contribution, the optimal stabilization problem of periodic orbits is studied via invariant manifold theory and symplectic geometry. The stable manifold theory for the optimal point stabilization case is generalized to the case of periodic orbit stabilization, where a normally hyperbolic invariant manifold plays the role of a hyperbolic equilibrium point. A sufficient condition for the existence of an NHIM of an extended Hamiltonian system is derived in terms of a periodic Riccati differential equation. It is shown that the problem of optimal orbit stabilization has a solution if a linearized periodic system is stabilizable and detectable. A moving orthogonal coordinate system is employed along the periodic orbit, which is a natural framework for orbital stabilization and linearization along the orbit. Two illustrative examples are presented: the first involves stabilizing a spring-mass oscillator at a target energy level, and the second addresses an orbit transfer problem for a satellite-a classic scenario in orbital mechanics. In both cases, we show that the proposed nonlinear feedback controller outperforms traditional linear control.</description>
      <guid isPermaLink="false">oai:arXiv.org:2211.11955v3</guid>
      <category>math.OC</category>
      <pubDate>Mon, 02 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Fabian Beck, Noboru Sakamoto</dc:creator>
    </item>
    <item>
      <title>Frank--Wolfe algorithms for piecewise star-convex functions with a nonsmooth difference-of-convex structure</title>
      <link>https://arxiv.org/abs/2308.16444</link>
      <description>arXiv:2308.16444v4 Announce Type: replace 
Abstract: In the present paper, we formulate two versions of Frank--Wolfe algorithm or conditional gradient method to solve the DC optimization problem with an adaptive step size. The DC objective function consists of two components; the first is thought to be differentiable with a continuous Lipschitz gradient, while the second is only thought to be convex. The second version is based on the first and employs finite differences to approximate the gradient of the first component of the objective function. In contrast to past formulations that used the curvature/Lipschitz-type constant of the objective function, the step size computed does not require any constant associated with the components. For the first version, we established that the algorithm is well-defined of the algorithm and that every limit point of the generated sequence is a stationary point of the problem. We also introduce the class of weak-star-convex functions and show that, despite the fact that these functions are non-convex in general, the rate of convergence of the first version of the algorithm to minimize these functions is ${\cal O}(1/k)$. The finite difference used to approximate the gradient in the second version of the Frank-Wolfe algorithm is computed with the step-size adaptively updated using two previous iterations. Unlike previous applications of finite difference in the Frank-Wolfe algorithm, which provided approximate gradients with absolute error, the one used here provides us with a relative error, simplifying the algorithm analysis. In this case, we show that all limit points of the generated sequence for the second version of the Frank-Wolfe algorithm are stationary points for the problem under consideration, and we establish that the rate of convergence for the duality gap is ${\cal O}(1/\sqrt{k})$.</description>
      <guid isPermaLink="false">oai:arXiv.org:2308.16444v4</guid>
      <category>math.OC</category>
      <category>cs.NA</category>
      <category>math.NA</category>
      <pubDate>Mon, 02 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>R. D\'iaz Mill\'an, O. P. Ferreira, J. Ugon</dc:creator>
    </item>
    <item>
      <title>Optimal sampling for stochastic and natural gradient descent</title>
      <link>https://arxiv.org/abs/2402.03113</link>
      <description>arXiv:2402.03113v2 Announce Type: replace 
Abstract: We consider the problem of optimising the expected value of a loss functional over a nonlinear model class of functions, assuming that we have only access to realisations of the gradient of the loss. This is a classical task in statistics, machine learning and physics-informed machine learning. A straightforward solution is to replace the exact objective with a Monte Carlo estimate before employing standard first-order methods like gradient descent, which yields the classical stochastic gradient descent method. But replacing the true objective with an estimate ensues a generalisation error. Rigorous bounds for this error typically require strong compactness and Lipschitz continuity assumptions while providing a very slow decay with sample size. To alleviate these issues, we propose a version of natural gradient descent that is based on optimal sampling methods. Under classical assumptions on the loss and the nonlinear model class, we prove that this scheme converges almost surely monotonically to a stationary point of the true objective. Under Polyak-Lojasiewicz-type conditions, this provides bounds for the generalisation error. As a remarkable result, we show that our stochastic optimisation scheme achieves the linear or exponential convergence rates of deterministic first order descent methods under suitable conditions.</description>
      <guid isPermaLink="false">oai:arXiv.org:2402.03113v2</guid>
      <category>math.OC</category>
      <category>math.ST</category>
      <category>stat.TH</category>
      <pubDate>Mon, 02 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Robert Gruhlke, Anthony Nouy, Philipp Trunschke</dc:creator>
    </item>
    <item>
      <title>On uniqueness in structured model learning</title>
      <link>https://arxiv.org/abs/2410.22009</link>
      <description>arXiv:2410.22009v3 Announce Type: replace 
Abstract: This paper addresses the problem of uniqueness in learning physical laws for systems of partial differential equations (PDEs). Contrary to most existing approaches, it considers a framework of structured model learning, where existing, approximately correct physical models are augmented with components that are learned from data. The main results of the paper are a uniqueness and a convergence result that cover a large class of PDEs and a suitable class of neural networks used for approximating the unknown model components. The uniqueness result shows that, in the limit of full, noiseless measurements, a unique identification of the unknown model components as functions is possible as classical regularization-minimizing solutions of the PDE system. This result is complemented by a convergence result showing that model components learned as parameterized neural networks from incomplete, noisy measurements approximate the regularization-minimizing solutions of the PDE system in the limit. These results are possible under specific properties of the approximating neural networks and due to a dedicated choice of regularization. With this, a practical contribution of this analytic paper is to provide a class of model learning frameworks different to standard settings where uniqueness can be expected in the limit of full measurements.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.22009v3</guid>
      <category>math.OC</category>
      <category>cs.LG</category>
      <category>math.AP</category>
      <pubDate>Mon, 02 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Martin Holler, Erion Morina</dc:creator>
    </item>
    <item>
      <title>Inexact Moreau Envelope Lagrangian Method for Non-Convex Constrained Optimization under Local Error Bound Conditions on Constraint Functions</title>
      <link>https://arxiv.org/abs/2502.19764</link>
      <description>arXiv:2502.19764v2 Announce Type: replace 
Abstract: In this paper, we investigate how structural properties of the constraint system impact the oracle complexity of smooth non-convex optimization problems with convex inequality constraints over a simple polytope. In particular, we show that, under a local error bound condition with exponent $d\in[1,2]$ on constraint functions, an inexact Moreau envelope Lagrangian method can attain an $\epsilon$-Karush--Kuhn--Tucker point with $\tilde O(\epsilon^{-2d})$ gradient oracle complexity. When $d=1$, this result matches the best-known complexity in literature up to logarithmic factors. Importantly, the assumed error bound condition with any $d\in[1,2]$ is strictly weaker than the local linear independence constraint qualification that is required to achieve the best-known complexity. Our results clarify the interplay between error bound conditions of constraints and algorithmic complexity, and extend complexity guarantees to a broader class of constrained non-convex problems.</description>
      <guid isPermaLink="false">oai:arXiv.org:2502.19764v2</guid>
      <category>math.OC</category>
      <category>cs.LG</category>
      <pubDate>Mon, 02 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <dc:creator>Yankun Huang, Qihang Lin, Yangyang Xu</dc:creator>
    </item>
    <item>
      <title>Dynamic Programming in Ordered Vector Space</title>
      <link>https://arxiv.org/abs/2503.06055</link>
      <description>arXiv:2503.06055v2 Announce Type: replace 
Abstract: New approaches to the theory of dynamic programming view dynamic programs as families of policy operators acting on partially ordered sets. In this paper, we extend these ideas by shifting from arbitrary partially ordered sets to ordered vector spaces. The integrated algebraic and order structure in such spaces leads to sharper fixed point results. These fixed point results can then be exploited to obtain optimality properties. We illustrate our results through applications ranging from firm management to data valuation. These applications include features from the recent literature on dynamic programming, including risk-sensitive preferences, nonlinear discounting, and state-dependent discounting. In all cases we establish existence of optimal policies, characterize them in terms of Bellman optimality relationships, and prove convergence of major algorithms.</description>
      <guid isPermaLink="false">oai:arXiv.org:2503.06055v2</guid>
      <category>math.OC</category>
      <pubDate>Mon, 02 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Nisha Peng, John Stachurski</dc:creator>
    </item>
    <item>
      <title>A Dantzig-Wolfe Decomposition Method for Quasi-Variational Inequalities</title>
      <link>https://arxiv.org/abs/2505.08108</link>
      <description>arXiv:2505.08108v2 Announce Type: replace 
Abstract: We propose an algorithm to solve quasi-variational inequality problems, based on the Dantzig-Wolfe decomposition paradigm. Our approach solves in the subproblems variational inequalities, which is a simpler problem, while restricting quasi-variational inequalities in the master subproblems, making them generally (much) smaller in size when the original problem is large-scale. We prove global convergence of our algorithm, assuming that the mapping of the quasi-variational inequality is either single-valued and continuous or it is set-valued maximally monotone. Quasi-variational inequalities serve as a framework for several equilibrium problems, and we apply our algorithm to an important example in the field of economics, namely the Walrasian equilibrium problem formulated as a generalized Nash equilibrium problem. Our numerical assessment demonstrates good performance and usefullness of the approach for the large-scale cases.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.08108v2</guid>
      <category>math.OC</category>
      <pubDate>Mon, 02 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Manoel Jardim, Claudia Sagastiz\'abal, Mikhail Solodov</dc:creator>
    </item>
    <item>
      <title>Bias-Optimal Bounds for SGD: A Computer-Aided Lyapunov Analysis</title>
      <link>https://arxiv.org/abs/2505.17965</link>
      <description>arXiv:2505.17965v2 Announce Type: replace 
Abstract: The non-asymptotic analysis of Stochastic Gradient Descent (SGD) typically yields bounds that decompose into a bias term and a variance term. In this work, we focus on the bias component and study the extent to which SGD can match the optimal convergence behavior of deterministic gradient descent. Assuming only (strong) convexity and smoothness of the objective, we derive new bounds that are bias-optimal, in the sense that the bias term coincides with the worst-case rate of gradient descent. Our results hold for the full range of constant step-sizes $\gamma L \in (0,2)$, including critical and large step-size regimes that were previously unexplored without additional variance assumptions. The bounds are obtained through the construction of a simple Lyapunov energy whose monotonicity yields sharp convergence guarantees. To design the parameters of this energy, we employ the Performance Estimation Problem framework, which we also use to provide numerical evidence for the optimality of the associated variance terms.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.17965v2</guid>
      <category>math.OC</category>
      <category>cs.LG</category>
      <category>stat.ML</category>
      <pubDate>Mon, 02 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Daniel Cortild, Lucas Ketels, Juan Peypouquet, Guillaume Garrigos</dc:creator>
    </item>
    <item>
      <title>A Generalized Analytical Framework for the Nonlinear Best-Worst Method</title>
      <link>https://arxiv.org/abs/2508.06048</link>
      <description>arXiv:2508.06048v2 Announce Type: replace 
Abstract: The nonlinear model of the best-worst method frequently produces multiple optimal weight sets, which are conventionally determined through optimization software. While an analytical approach exists that provides both a closed-form expression for the optimal interval-weights and a secondary objective function to determine the best optimal weight set, we demonstrate that this approach is only valid when preferences are quantified using the Saaty scale and only a single decision-maker is involved. To tackle this issue, we propose a framework compatible with any scale and any number of decision-makers. We first derive an analytical expression for optimal interval-weights and then select the best optimal weight set. After demonstrating that the values of consistency index for the Saaty scale in the existing literature are not well-defined, we derive a formula of consistency index. We also obtain an analytical expression for the consistency ratio, enabling its use as an input-based consistency indicator. Furthermore, we establish that when multiple best/worst criteria are present, weights may vary among best criteria and among the worst criteria. To address this limitation, we modify the original optimization model for weight computation in such instances, solve it analytically to obtain optimal interval-weights and then select the best optimal weight set using a secondary objective function. Finally, we demonstrate and validate the proposed approach using numerical examples and a real-world case study of ranking barriers to energy efficiency in buildings.</description>
      <guid isPermaLink="false">oai:arXiv.org:2508.06048v2</guid>
      <category>math.OC</category>
      <pubDate>Mon, 02 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <dc:creator>Harshit M. Ratandhara, Mohit Kumar</dc:creator>
    </item>
    <item>
      <title>A bottleneck model with shared autonomous vehicles: Scale economies and price regulations</title>
      <link>https://arxiv.org/abs/2508.08848</link>
      <description>arXiv:2508.08848v2 Announce Type: replace 
Abstract: This study examines how scale economies in the operation of shared autonomous vehicles (SAVs) affect the efficiency of a transportation system where SAVs coexist with normal vehicles (NVs). We develop a bottleneck model where commuters choose their departure times and mode of travel between SAVs and NVs, and analyze equilibria under three SAV fare-setting scenarios: marginal cost pricing, average cost pricing, and unregulated monopoly pricing. Marginal cost pricing reduces commuting costs but results in financial deficits for the service provider. Average cost pricing ensures financial sustainability but has contrasting effects depending on the timing of implementation due to the existence of multiple equilibria: when implemented too early, it discourages adoption of SAVs and increases commuting costs; when introduced after SAV adoption reaches the monopoly equilibrium level, it promotes high adoption and achieves substantial cost reductions without a deficit. We also show that expanding road capacity may increase commuting costs under average cost pricing, demonstrating the Downs--Thomson paradox in transportation systems with SAVs. We next examine two optimal policies that improve social cost, including the operator's profit: the first-best policy that combines marginal cost pricing with congestion tolls, and the second-best policy that relies on fare regulation alone. Our analysis shows that these policies can limit excessive adoption by discouraging overuse of SAVs. This suggests that promoting SAV adoption does not always reduce social cost.</description>
      <guid isPermaLink="false">oai:arXiv.org:2508.08848v2</guid>
      <category>math.OC</category>
      <pubDate>Mon, 02 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Koki Satsukawa, Yuki Takayama</dc:creator>
    </item>
    <item>
      <title>On the SOS Rank of Simple and Diagonal Biquadratic Forms</title>
      <link>https://arxiv.org/abs/2601.19195</link>
      <description>arXiv:2601.19195v2 Announce Type: replace 
Abstract: We study the sum-of-squares (SOS) rank of simple and diagonal biquadratic forms. For simple biquadratic forms in $3 \times 3$ variables, we show that the maximum SOS rank is exactly $6$, attained by a specific six-term form. We further prove that for any $m \ge 3$, there exists an $m \times m$ simple biquadratic form whose SOS rank is exactly $2m$, providing a general lower bound that extends the $3\times3$ case. For diagonal biquadratic forms with nonnegative coefficients, we prove an SOS rank upper bound of $7$, improving the general bound of $8$ for $3 \times 3$ forms. In addition, we extend the techniques to a broader class of \textbf{sparse biquadratic forms}, obtaining combinatorial upper bounds and constructing explicit families whose SOS rank grows linearly with the number of terms. These results provide new lower and upper bounds on the worst-case SOS rank of biquadratic forms and highlight the role of structure in reducing the required number of squares.</description>
      <guid isPermaLink="false">oai:arXiv.org:2601.19195v2</guid>
      <category>math.OC</category>
      <pubDate>Mon, 02 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Yi Xu, Chufeng Cui, Liqun Qi</dc:creator>
    </item>
    <item>
      <title>Quantum speedups for linear programming via interior point methods</title>
      <link>https://arxiv.org/abs/2311.03215</link>
      <description>arXiv:2311.03215v3 Announce Type: replace-cross 
Abstract: We describe a quantum algorithm based on an interior point method for solving a linear program with $n$ inequality constraints on $d$ variables. The algorithm explicitly returns a feasible solution that is $\varepsilon$-close to optimal, and runs in time $\sqrt{n} \cdot \mathrm{poly}(d,\log(n),\log(1/\varepsilon))$ which is sublinear for tall linear programs (i.e., $n \gg d$). Our algorithm speeds up the Newton step in the state-of-the-art interior point method of Lee and Sidford [FOCS '14]. This requires us to efficiently approximate the Hessian and gradient of the barrier function, and these are our main contributions.
  To approximate the Hessian, we describe a quantum algorithm for the \emph{spectral approximation} of $A^T A$ for a tall matrix $A \in \mathbb R^{n \times d}$. The algorithm uses leverage score sampling in combination with Grover search, and returns a $\delta$-approximation by making $O(\sqrt{nd}/\delta)$ row queries to $A$. This generalizes an earlier quantum speedup for graph sparsification by Apers and de Wolf [FOCS '20]. To approximate the gradient, we use a recent quantum algorithm for multivariate mean estimation by Cornelissen, Hamoudi and Jerbi [STOC '22]. While a naive implementation introduces a dependence on the condition number of the Hessian, we avoid this by pre-conditioning our random variable using our quantum algorithm for spectral approximation.</description>
      <guid isPermaLink="false">oai:arXiv.org:2311.03215v3</guid>
      <category>quant-ph</category>
      <category>cs.DS</category>
      <category>math.OC</category>
      <pubDate>Mon, 02 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Simon Apers, Sander Gribling</dc:creator>
    </item>
    <item>
      <title>PPO in the Fisher-Rao geometry</title>
      <link>https://arxiv.org/abs/2506.03757</link>
      <description>arXiv:2506.03757v2 Announce Type: replace-cross 
Abstract: Proximal Policy Optimization (PPO) is widely used in reinforcement learning due to its strong empirical performance, yet it lacks formal guarantees for policy improvement and convergence. PPO's clipped surrogate objective is motivated by a lower bound on linearization of the value function in flat geometry setting. We derive a tighter surrogate objective and introduce Fisher-Rao PPO (FR-PPO) by leveraging the Fisher-Rao (FR) geometry. Our scheme provides strong theoretical guarantees, including monotonic policy improvement. In the direct parametrization setting, we show that FR-PPO achieves sub-linear convergence with no dependence on action or state space dimensions, and for parametrized policies we further obtain sub-linear convergence up to the compatible function approximation error. Finally, although our primary focus is theoretical, we also demonstrate empirically that FR-PPO performs well across a range of standard reinforcement learning tasks.</description>
      <guid isPermaLink="false">oai:arXiv.org:2506.03757v2</guid>
      <category>cs.LG</category>
      <category>math.OC</category>
      <pubDate>Mon, 02 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Razvan-Andrei Lascu, David \v{S}i\v{s}ka, {\L}ukasz Szpruch</dc:creator>
    </item>
    <item>
      <title>MARS-M: When Variance Reduction Meets Matrices</title>
      <link>https://arxiv.org/abs/2510.21800</link>
      <description>arXiv:2510.21800v3 Announce Type: replace-cross 
Abstract: Matrix-based preconditioned optimizers, such as Muon, have recently been shown to be more efficient than scalar-based optimizers for training large-scale neural networks, including large language models (LLMs). Recent benchmark studies of LLM pretraining optimizers have demonstrated that variance-reduction techniques such as MARS can substantially speed up training compared with standard optimizers that do not employ variance reduction. In this paper, we introduce MARS-M, a new optimizer that integrates MARS-style variance reduction with Muon. Under standard regularity conditions, we prove that MARS-M converges to a first-order stationary point at a rate of $\tilde{\mathcal{O}}(T^{-1/3})$, improving upon the $\tilde{\mathcal{O}}(T^{-1/4})$ rate attained by Muon. Empirical results on language modeling and computer vision tasks demonstrate that MARS-M consistently yields lower losses and improved performance across various downstream benchmarks. The implementation of MARS-M is available at https://github.com/AGI-Arena/MARS/tree/main/MARS_M.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.21800v3</guid>
      <category>cs.LG</category>
      <category>math.OC</category>
      <category>stat.ML</category>
      <pubDate>Mon, 02 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Yifeng Liu, Angela Yuan, Quanquan Gu</dc:creator>
    </item>
    <item>
      <title>The Blueprints of Intelligence: A Functional-Topological Foundation for Perception and Representation</title>
      <link>https://arxiv.org/abs/2512.05089</link>
      <description>arXiv:2512.05089v4 Announce Type: replace-cross 
Abstract: Real-world phenomena do not generate arbitrary variability: their signals concentrate on compact, low-variability subsets of functional space, enabling rapid generalization from few examples. A small child can recognize a dog after extremely limited exposure because the perceptual manifold of "dog" is compact, structured, and low-dimensional. We formalize this principle through a deterministic functional-topological framework in which the set of valid realizations produced by a physical process forms a compact subset of a Banach space, endowed with stable invariants, a finite Hausdorff radius, and an induced continuous perceptual functional.
  This geometry provides explicit limits on knowledge, conditions for identifiability, and guarantees for generalization from sparse evidence -- properties fundamental to both natural and artificial intelligence. Across electromechanical, electrochemical, and physiological domains, we show that real-world processes consistently generate compact perceptual manifolds with the same geometric characteristics. Their boundaries can be discovered in a fully self-supervised manner as the empirical radius saturates with increasing sampling, even when the governing equations are unknown.
  These results demonstrate that deterministic functional topology offers a unified mathematical foundation for perception, representation, and world-model construction. It provides a geometric explanation for why biological learners and self-supervised AI systems can generalize from few observations, and establishes compact perceptual manifolds as a fundamental building block for future AI architectures. Finally, this work unifies biological perception and modern self-supervised models under a single geometric principle: both derive their generalization ability from the compactness and invariants of real-world perceptual manifolds.</description>
      <guid isPermaLink="false">oai:arXiv.org:2512.05089v4</guid>
      <category>cs.LG</category>
      <category>math.OC</category>
      <pubDate>Mon, 02 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Eduardo Di Santi</dc:creator>
    </item>
  </channel>
</rss>
