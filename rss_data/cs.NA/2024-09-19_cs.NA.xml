<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>cs.NA updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/cs.NA</link>
    <description>cs.NA updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/cs.NA" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Fri, 20 Sep 2024 04:00:51 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Fri, 20 Sep 2024 00:00:00 -0400</pubDate>
    <skipDays>
      <day>Sunday</day>
      <day>Saturday</day>
    </skipDays>
    <item>
      <title>JKO for Landau: a variational particle method for homogeneous Landau equation</title>
      <link>https://arxiv.org/abs/2409.12296</link>
      <description>arXiv:2409.12296v1 Announce Type: new 
Abstract: Inspired by the gradient flow viewpoint of the Landau equation and corresponding dynamic formulation of the Landau metric in [arXiv:2007.08591], we develop a novel implicit particle method for the Landau equation in the framework of the JKO scheme. We first reformulate the Landau metric in a computationally friendly form, and then translate it into the Lagrangian viewpoint using the flow map. A key observation is that, while the flow map evolves according to a rather complicated integral equation, the unknown component is merely a score function of the corresponding density plus an additional term in the null space of the collision kernel. This insight guides us in approximating the flow map with a neural network and simplifies the training. Additionally, the objective function is in a double summation form, making it highly suitable for stochastic methods. Consequently, we design a tailored version of stochastic gradient descent that maintains particle interactions and reduces the computational complexity. Compared to other deterministic particle methods, the proposed method enjoys exact entropy dissipation and unconditional stability, therefore making it suitable for large-scale plasma simulations over extended time periods.</description>
      <guid isPermaLink="false">oai:arXiv.org:2409.12296v1</guid>
      <category>math.NA</category>
      <category>cs.LG</category>
      <category>cs.NA</category>
      <pubDate>Fri, 20 Sep 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Yan Huang, Li Wang</dc:creator>
    </item>
    <item>
      <title>A Stochastic Iteratively Regularized Gauss-Newton Method</title>
      <link>https://arxiv.org/abs/2409.12381</link>
      <description>arXiv:2409.12381v1 Announce Type: new 
Abstract: This work focuses on developing and motivating a stochastic version of a wellknown inverse problem methodology. Specifically, we consider the iteratively regularized Gauss-Newton method, originally proposed by Bakushinskii for infinite-dimensional problems. Recent work have extended this method to handle sequential observations, rather than a single instance of the data, demonstrating notable improvements in reconstruction accuracy. In this paper, we further extend these methods to a stochastic framework through mini-batching, introducing a new algorithm, the stochastic iteratively regularized Gauss-Newton method (SIRGNM). Our algorithm is designed through the use randomized sketching. We provide an analysis for the SIRGNM, which includes a preliminary error decomposition and a convergence analysis, related to the residuals. We provide numerical experiments on a 2D elliptic PDE example. This illustrates the effectiveness of the SIRGNM, through maintaining a similar level of accuracy while reducing on the computational time.</description>
      <guid isPermaLink="false">oai:arXiv.org:2409.12381v1</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <category>math.OC</category>
      <pubDate>Fri, 20 Sep 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <dc:creator>El Houcine Bergou, Neil K. Chada, Youssef Diouane</dc:creator>
    </item>
    <item>
      <title>Shape-informed surrogate models based on signed distance function domain encoding</title>
      <link>https://arxiv.org/abs/2409.12400</link>
      <description>arXiv:2409.12400v1 Announce Type: new 
Abstract: We propose a non-intrusive method to build surrogate models that approximate the solution of parameterized partial differential equations (PDEs), capable of taking into account the dependence of the solution on the shape of the computational domain. Our approach is based on the combination of two neural networks (NNs). The first NN, conditioned on a latent code, provides an implicit representation of geometry variability through signed distance functions. This automated shape encoding technique generates compact, low-dimensional representations of geometries within a latent space, without requiring the explicit construction of an encoder. The second NN reconstructs the output physical fields independently for each spatial point, thus avoiding the computational burden typically associated with high-dimensional discretizations like computational meshes. Furthermore, we show that accuracy in geometrical characterization can be further enhanced by employing Fourier feature mapping as input feature of the NN. The meshless nature of the proposed method, combined with the dimensionality reduction achieved through automatic feature extraction in latent space, makes it highly flexible and computationally efficient. This strategy eliminates the need for manual intervention in extracting geometric parameters, and can even be applied in cases where geometries undergo changes in their topology. Numerical tests in the field of fluid dynamics and solid mechanics demonstrate the effectiveness of the proposed method in accurately predict the solution of PDEs in domains of arbitrary shape. Remarkably, the results show that it achieves accuracy comparable to the best-case scenarios where an explicit parametrization of the computational domain is available.</description>
      <guid isPermaLink="false">oai:arXiv.org:2409.12400v1</guid>
      <category>math.NA</category>
      <category>cs.LG</category>
      <category>cs.NA</category>
      <pubDate>Fri, 20 Sep 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-sa/4.0/</dc:rights>
      <dc:creator>Linying Zhang, Stefano Pagani, Jun Zhang, Francesco Regazzoni</dc:creator>
    </item>
    <item>
      <title>An Adaptive Difference Method for Variable-Order Diffusion Equations</title>
      <link>https://arxiv.org/abs/2409.12422</link>
      <description>arXiv:2409.12422v1 Announce Type: new 
Abstract: An adaptive finite difference scheme for variable-order fractional-time subdiffusion equations in the Caputo form is studied. The fractional time derivative is discretized by the L1 procedure but using nonhomogeneous timesteps. The size of these timesteps is chosen by an adaptive algorithm in order to keep the local error bounded around a preset value, a value that can be chosen at will. For some types of problems this adaptive method is much faster than the corresponding usual method with fixed timesteps while keeping the local error of the numerical solution around the preset values. These findings turns out to be similar to those found for constant-order fractional diffusion equations.</description>
      <guid isPermaLink="false">oai:arXiv.org:2409.12422v1</guid>
      <category>math.NA</category>
      <category>cond-mat.stat-mech</category>
      <category>cs.NA</category>
      <category>physics.comp-ph</category>
      <pubDate>Fri, 20 Sep 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <arxiv:DOI>10.1007/s00009-024-02681-6</arxiv:DOI>
      <arxiv:journal_reference>Mediterr. J. Math. 21, 145 (2024)</arxiv:journal_reference>
      <dc:creator>Joaqu\'in Quintana-Murillo, Santos Bravo Yuste</dc:creator>
    </item>
    <item>
      <title>Well-balanced Point-Average-Moment PolynomiAl-interpreted (PAMPA) Methods for Shallow Water Equations on Triangular Meshes</title>
      <link>https://arxiv.org/abs/2409.12606</link>
      <description>arXiv:2409.12606v1 Announce Type: new 
Abstract: In this paper, we develop novel well-balanced Point-Average-Moment PolynomiAl-interpreted (PAMPA) numerical methods for solving the two-dimensional shallow water equations on triangular meshes. The proposed PAMPA methods use a globally continuous representation of the variables, with degree of freedoms (DoFs) consisting of point values on the edges and average values within each triangular element. The update of cell averages is carried out using a conservative form of the partial differential equations (PDEs), while the point values are updated using a non-conservative formulation. This non-conservative formulation can be expressed in terms of either conservative or primitive variables. This new class of schemes is proved to be well-balanced and positivity-preserving. We validate the performance of the proposed methods through a series of numerical experiments. The numerical results are as expected and confirm that the performance of the PAMPA method using primitive variables in the non-conservative formulation is comparable to that using only the conservative variables. This work represents a step forward in the development and application of PAMPA methods for solving hyperbolic balance laws.</description>
      <guid isPermaLink="false">oai:arXiv.org:2409.12606v1</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <pubDate>Fri, 20 Sep 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Yongle Liu</dc:creator>
    </item>
    <item>
      <title>The inverse obstacle scattering with a tapered wave incidence</title>
      <link>https://arxiv.org/abs/2409.12762</link>
      <description>arXiv:2409.12762v1 Announce Type: new 
Abstract: This paper is concerned with the reconstruction of the shape of an acoustic obstacle. Based on the use of the tapered waves with very narrow widths illuminating the obstacle, the boundary of the obstacle is reconstructed by a direct imaging algorithm. The stability of the imaging scheme is mathematically analyzed. We emphasize that different from the incident plane waves or point sources, the tapered waves with narrow widths bring several benefits in the inverse scattering: 1. local property. A tapered wave can illuminate only on a local part of the boundary of the obstacle, which generates the scattered field; 2. high resolution. We need only reconstruct the boundary near the beam, which improves the quality of some well-known algorithms; 3. fast and easy to implement. Numerical examples are included to demonstrate the effectiveness of the tapered waves.</description>
      <guid isPermaLink="false">oai:arXiv.org:2409.12762v1</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <pubDate>Fri, 20 Sep 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Deyue Zhang, Mengjiao Bai, Yan Chang, Yukun Guo</dc:creator>
    </item>
    <item>
      <title>QMC integration based on arbitrary (t,m,s)-nets yields optimal convergence rates on several scales of function spaces</title>
      <link>https://arxiv.org/abs/2409.12879</link>
      <description>arXiv:2409.12879v1 Announce Type: new 
Abstract: We study the integration problem over the $s$-dimensional unit cube on four types of Banach spaces of integrands. First we consider Haar wavelet spaces, consisting of functions whose Haar wavelet coefficients exhibit a certain decay behavior measured by a parameter $\alpha &gt;0$. We study the worst case error of integration over the norm unit ball and provide upper error bounds for quasi-Monte Carlo (QMC) cubature rules based on arbitrary $(t,m,s)$-nets as well as matching lower error bounds for arbitrary cubature rules. These results show that using arbitrary $(t,m,s)$-nets as sample points yields the best possible rate of convergence. Afterwards we study spaces of integrands of fractional smoothness $\alpha \in (0,1)$ and state a sharp Koksma-Hlawka-type inequality. More precisely, we show that on those spaces the worst case error of integration is equal to the corresponding fractional discrepancy. Those spaces can be continuously embedded into tensor product Bessel potential spaces, also known as Sobolev spaces of dominated mixed smoothness, with the same set of parameters. The latter spaces can be embedded into suitable Besov spaces of dominating mixed smoothness $\alpha$, which in turn can be embedded into the Haar wavelet spaces with the same set of parameters. Therefore our upper error bounds on Haar wavelet spaces for QMC cubatures based on $(t,m,s)$-nets transfer (with possibly different constants) to the corresponding spaces of integrands of fractional smoothness and to Sobolev and Besov spaces of dominating mixed smoothness. Moreover, known lower error bounds for periodic Sobolev and Besov spaces of dominating mixed smoothness show that QMC integration based on arbitrary $(t,m,s)$-nets yields the best possible convergence rate on periodic as well as on non-periodic Sobolev and Besov spaces of dominating smoothness.</description>
      <guid isPermaLink="false">oai:arXiv.org:2409.12879v1</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <pubDate>Fri, 20 Sep 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Michael Gnewuch, Josef Dick, Lev Markhasin, Winfried Sickel</dc:creator>
    </item>
    <item>
      <title>Stochastic gradient descent in continuous time for drift identification in multiscale diffusions</title>
      <link>https://arxiv.org/abs/2409.12935</link>
      <description>arXiv:2409.12935v1 Announce Type: new 
Abstract: We consider the setting of multiscale overdamped Langevin stochastic differential equations, and study the problem of learning the drift function of the homogenized dynamics from continuous-time observations of the multiscale system. We decompose the drift term in a truncated series of basis functions, and employ the stochastic gradient descent in continuous time to infer the coefficients of the expansion. Due to the incompatibility between the multiscale data and the homogenized model, the estimator alone is not able to reconstruct the exact drift. We therefore propose to filter the original trajectory through appropriate kernels and include filtered data in the stochastic differential equation for the estimator, which indeed solves the misspecification issue. Several numerical experiments highlight the accuracy of our approach. Moreover, we show theoretically in a simplified framework the asymptotic unbiasedness of our estimator in the limit of infinite data and when the multiscale parameter describing the fastest scale vanishes.</description>
      <guid isPermaLink="false">oai:arXiv.org:2409.12935v1</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <pubDate>Fri, 20 Sep 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Max Hirsch, Andrea Zanoni</dc:creator>
    </item>
    <item>
      <title>Convergence of Markov Chains for Constant Step-size Stochastic Gradient Descent with Separable Functions</title>
      <link>https://arxiv.org/abs/2409.12243</link>
      <description>arXiv:2409.12243v1 Announce Type: cross 
Abstract: Stochastic gradient descent (SGD) is a popular algorithm for minimizing objective functions that arise in machine learning. For constant step-sized SGD, the iterates form a Markov chain on a general state space. Focusing on a class of separable (non-convex) objective functions, we establish a "Doeblin-type decomposition," in that the state space decomposes into a uniformly transient set and a disjoint union of absorbing sets. Each of the absorbing sets contains a unique invariant measure, with the set of all invariant measures being the convex hull. Moreover the set of invariant measures are shown to be global attractors to the Markov chain with a geometric convergence rate. The theory is highlighted with examples that show: (1) the failure of the diffusion approximation to characterize the long-time dynamics of SGD; (2) the global minimum of an objective function may lie outside the support of the invariant measures (i.e., even if initialized at the global minimum, SGD iterates will leave); and (3) bifurcations may enable the SGD iterates to transition between two local minima. Key ingredients in the theory involve viewing the SGD dynamics as a monotone iterated function system and establishing a "splitting condition" of Dubins and Freedman 1966 and Bhattacharya and Lee 1988.</description>
      <guid isPermaLink="false">oai:arXiv.org:2409.12243v1</guid>
      <category>math.OC</category>
      <category>cs.NA</category>
      <category>math.DS</category>
      <category>math.NA</category>
      <pubDate>Fri, 20 Sep 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>David Shirokoff, Philip Zaleski</dc:creator>
    </item>
    <item>
      <title>Provable In-Context Learning of Linear Systems and Linear Elliptic PDEs with Transformers</title>
      <link>https://arxiv.org/abs/2409.12293</link>
      <description>arXiv:2409.12293v1 Announce Type: cross 
Abstract: Foundation models for natural language processing, powered by the transformer architecture, exhibit remarkable in-context learning (ICL) capabilities, allowing pre-trained models to adapt to downstream tasks using few-shot prompts without updating their weights. Recently, transformer-based foundation models have also emerged as versatile tools for solving scientific problems, particularly in the realm of partial differential equations (PDEs). However, the theoretical foundations of the ICL capabilities in these scientific models remain largely unexplored. This work develops a rigorous error analysis for transformer-based ICL applied to solution operators associated with a family of linear elliptic PDEs. We first demonstrate that a linear transformer, defined by a linear self-attention layer, can provably learn in-context to invert linear systems arising from the spatial discretization of PDEs. This is achieved by deriving theoretical scaling laws for the prediction risk of the proposed linear transformers in terms of spatial discretization size, the number of training tasks, and the lengths of prompts used during training and inference. These scaling laws also enable us to establish quantitative error bounds for learning PDE solutions. Furthermore, we quantify the adaptability of the pre-trained transformer on downstream PDE tasks that experience distribution shifts in both tasks (represented by PDE coefficients) and input covariates (represented by the source term). To analyze task distribution shifts, we introduce a novel concept of task diversity and characterize the transformer's prediction error in terms of the magnitude of task shift, assuming sufficient diversity in the pre-training tasks. We also establish sufficient conditions to ensure task diversity. Finally, we validate the ICL-capabilities of transformers through extensive numerical experiments.</description>
      <guid isPermaLink="false">oai:arXiv.org:2409.12293v1</guid>
      <category>cs.LG</category>
      <category>cs.NA</category>
      <category>math.NA</category>
      <category>stat.ML</category>
      <pubDate>Fri, 20 Sep 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Frank Cole, Yulong Lu, Riley O'Neill, Tianhao Zhang</dc:creator>
    </item>
    <item>
      <title>Computing Bouligand stationary points efficiently in low-rank optimization</title>
      <link>https://arxiv.org/abs/2409.12298</link>
      <description>arXiv:2409.12298v1 Announce Type: cross 
Abstract: This paper considers the problem of minimizing a differentiable function with locally Lipschitz continuous gradient on the algebraic variety of all $m$-by-$n$ real matrices of rank at most $r$. Several definitions of stationarity exist for this nonconvex problem. Among them, Bouligand stationarity is the strongest necessary condition for local optimality. Only a handful of algorithms generate a sequence in the variety whose accumulation points are provably Bouligand stationary. Among them, the most parsimonious with (truncated) singular value decompositions (SVDs) or eigenvalue decompositions can still require a truncated SVD of a matrix whose rank can be as large as $\min\{m, n\}-r+1$ if the gradient does not have low rank, which is computationally prohibitive in the typical case where $r \ll \min\{m, n\}$. This paper proposes a first-order algorithm that generates a sequence in the variety whose accumulation points are Bouligand stationary while requiring SVDs of matrices whose smaller dimension is always at most $r$. A standard measure of Bouligand stationarity converges to zero along the bounded subsequences at a rate at least $O(1/\sqrt{i+1})$, where $i$ is the iteration counter. Furthermore, a rank-increasing scheme based on the proposed algorithm is presented, which can be of interest if the parameter $r$ is potentially overestimated.</description>
      <guid isPermaLink="false">oai:arXiv.org:2409.12298v1</guid>
      <category>math.OC</category>
      <category>cs.NA</category>
      <category>math.NA</category>
      <pubDate>Fri, 20 Sep 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Guillaume Olikier, P. -A. Absil</dc:creator>
    </item>
    <item>
      <title>Bridging the Gap Between Approximation and Learning via Optimal Approximation by ReLU MLPs of Maximal Regularity</title>
      <link>https://arxiv.org/abs/2409.12335</link>
      <description>arXiv:2409.12335v1 Announce Type: cross 
Abstract: The foundations of deep learning are supported by the seemingly opposing perspectives of approximation or learning theory. The former advocates for large/expressive models that need not generalize, while the latter considers classes that generalize but may be too small/constrained to be universal approximators. Motivated by real-world deep learning implementations that are both expressive and statistically reliable, we ask: "Is there a class of neural networks that is both large enough to be universal but structured enough to generalize?"
  This paper constructively provides a positive answer to this question by identifying a highly structured class of ReLU multilayer perceptions (MLPs), which are optimal function approximators and are statistically well-behaved. We show that any $L$-Lipschitz function from $[0,1]^d$ to $[-n,n]$ can be approximated to a uniform $Ld/(2n)$ error on $[0,1]^d$ with a sparsely connected $L$-Lipschitz ReLU MLP of width $\mathcal{O}(dn^d)$, depth $\mathcal{O}(\log(d))$, with $\mathcal{O}(dn^d)$ nonzero parameters, and whose weights and biases take values in $\{0,\pm 1/2\}$ except in the first and last layers which instead have magnitude at-most $n$. Unlike previously known "large" classes of universal ReLU MLPs, the empirical Rademacher complexity of our class remains bounded even when its depth and width become arbitrarily large. Further, our class of MLPs achieves a near-optimal sample complexity of $\mathcal{O}(\log(N)/\sqrt{N})$ when given $N$ i.i.d. normalized sub-Gaussian training samples.
  We achieve this by avoiding the standard approach to constructing optimal ReLU approximators, which sacrifices regularity by relying on small spikes. Instead, we introduce a new construction that perfectly fits together linear pieces using Kuhn triangulations and avoids these small spikes.</description>
      <guid isPermaLink="false">oai:arXiv.org:2409.12335v1</guid>
      <category>cs.LG</category>
      <category>cs.NA</category>
      <category>cs.NE</category>
      <category>math.FA</category>
      <category>math.NA</category>
      <category>stat.ML</category>
      <pubDate>Fri, 20 Sep 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Ruiyang Hong, Anastasis Kratsios</dc:creator>
    </item>
    <item>
      <title>The effective use of BLAS interface for implementation of finite-element ADER-DG and finite-volume ADER-WENO methods</title>
      <link>https://arxiv.org/abs/2409.12483</link>
      <description>arXiv:2409.12483v1 Announce Type: cross 
Abstract: Numerical methods of the ADER family, in particular finite-element ADER-DG and finite-volume ADER-WENO methods, are among the most accurate numerical methods for solving quasilinear PDE systems. The internal structure of ADER-DG and ADER-WENO numerical methods contains a large number of basic linear algebra operations related to matrix multiplication. At the moment, the main interface of software libraries for high-performance computing is BLAS. This paper presents an effective method for integration the standard functions of the BLAS interface into the implementation of these numerical methods. The calculated matrices are small matrices; at the same time, the proposed implementation makes it possible to effectively use existing JIT technologies. The proposed approach immediately operates on AoS, which makes it possible to efficiently calculate flux, source and non-conservative terms without need to carry out transposition. The obtained computational costs allowed to conclude that the effective implementation, based on the use of the JIT functions of the BLAS, outperformed both the implementation based on the general BLAS functions and the naive implementations by several times. At the same time, the complexity of developing an implementation based on the approach proposed in this work does not exceed the complexity of developing a naive optimized implementation.</description>
      <guid isPermaLink="false">oai:arXiv.org:2409.12483v1</guid>
      <category>physics.flu-dyn</category>
      <category>cs.NA</category>
      <category>math.AP</category>
      <category>math.NA</category>
      <category>physics.app-ph</category>
      <category>physics.comp-ph</category>
      <pubDate>Fri, 20 Sep 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>I. S. Popov</dc:creator>
    </item>
    <item>
      <title>Robust State Estimation from Partial Out-Core Measurements with Shallow Recurrent Decoder for Nuclear Reactors</title>
      <link>https://arxiv.org/abs/2409.12550</link>
      <description>arXiv:2409.12550v1 Announce Type: cross 
Abstract: Reliable, real-time state estimation in nuclear reactors is of critical importance for monitoring, control and safety. It further empowers the development of digital twins that are sufficiently accurate for real-world deployment. As nuclear engineering systems are typically characterised by extreme environments, their in-core sensing is a challenging task, even more so in Generation-IV reactor concepts, which feature molten salt or liquid metals as thermal carriers. The emergence of data-driven methods allows for new techniques for accurate and robust estimation of the full state space vector characterising the reactor (mainly composed by neutron fluxes and the thermal-hydraulics fields). These techniques can combine different sources of information, including computational proxy models and local noisy measurements on the system, in order to robustly estimate the state. This work leverages the Shallow Recurrent Decoder (SHRED) architecture to estimate the entire state vector of a reactor from three, out-of-core time-series neutron flux measurements alone. Specifically, the Molten Salt Fast Reactor, in the EVOL geometry (Evaluation and Viability of Liquid Fuel Fast Reactor System project), is demonstrated as a test case, with neutron flux measurements alone allowing for reconstruction of the 20 coupled field variables of the dynamics. This approach can further quantify the uncertainty associated with the state estimation due to its considerably low training cost on compressed data. The accurate reconstruction of every characteristic field in real-time makes this approach suitable for monitoring and control purposes in the framework of a reactor digital twin.</description>
      <guid isPermaLink="false">oai:arXiv.org:2409.12550v1</guid>
      <category>physics.ins-det</category>
      <category>cs.NA</category>
      <category>math.NA</category>
      <category>physics.comp-ph</category>
      <pubDate>Fri, 20 Sep 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-sa/4.0/</dc:rights>
      <dc:creator>Stefano Riva, Carolina Introini, Antonio Cammi, J. Nathan Kutz</dc:creator>
    </item>
    <item>
      <title>Iterative algorithms for the reconstruction of early states of prostate cancer growth</title>
      <link>https://arxiv.org/abs/2409.12844</link>
      <description>arXiv:2409.12844v1 Announce Type: cross 
Abstract: The development of mathematical models of cancer informed by time-resolved measurements has enabled personalised predictions of tumour growth and treatment response. However, frequent cancer monitoring is rare, and many tumours are treated soon after diagnosis with limited data. To improve the predictive capabilities of cancer models, we investigate the problem of recovering earlier tumour states from a single spatial measurement at a later time. Focusing on prostate cancer, we describe tumour dynamics using a phase-field model coupled with two reaction-diffusion equations for a nutrient and the local prostate-specific antigen. We generate synthetic data using a discretisation based on Isogeometric Analysis. Then, building on our previous analytical work (Beretta et al., SIAP (2024)), we propose an iterative reconstruction algorithm based on the Landweber scheme, showing local convergence with quantitative rates and exploring an adaptive step size that leads to faster reconstruction algorithms. Finally, we run simulations demonstrating high-quality reconstructions even with long time horizons and noisy data.</description>
      <guid isPermaLink="false">oai:arXiv.org:2409.12844v1</guid>
      <category>math.AP</category>
      <category>cs.NA</category>
      <category>math.NA</category>
      <category>q-bio.TO</category>
      <pubDate>Fri, 20 Sep 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Elena Beretta, Cecilia Cavaterra, Matteo Fornoni, Guillermo Lorenzo, Elisabetta Rocca</dc:creator>
    </item>
    <item>
      <title>Order conditions for Runge--Kutta-like methods with solution-dependent coefficients</title>
      <link>https://arxiv.org/abs/2305.14297</link>
      <description>arXiv:2305.14297v3 Announce Type: replace 
Abstract: In recent years, many positivity-preserving schemes for initial value problems have been constructed by modifying a Runge--Kutta (RK) method by weighting the right-hand side of the system of differential equations with solution-dependent factors. These include the classes of modified Patankar--Runge--Kutta (MPRK) and Geometric Conservative (GeCo) methods. Compared to traditional RK methods, the analysis of accuracy and stability of these methods is more complicated. In this work, we provide a comprehensive and unifying theory of order conditions for such RK-like methods, which differ from original RK schemes in that their coefficients are solution-dependent. The resulting order conditions are themselves solution-dependent and obtained using the theory of NB-series, and thus, can easily be read off from labeled N-trees. We present for the first time order conditions for MPRK and GeCo schemes of arbitrary order; For MPRK schemes, the order conditions are given implicitly in terms of the stages. From these results, we recover as particular cases all known order conditions from the literature for first- and second-order GeCo as well as first-, second- and third-order MPRK methods. Additionally, we derive sufficient and necessary conditions in an explicit form for 3rd and 4th order GeCo schemes as well as 4th order MPRK methods. We also present a new 4th order MPRK method within this framework and numerically confirm its convergence rate.</description>
      <guid isPermaLink="false">oai:arXiv.org:2305.14297v3</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <pubDate>Fri, 20 Sep 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Thomas Izgin, David I. Ketcheson, Andreas Meister</dc:creator>
    </item>
    <item>
      <title>Global convergence of Newton's method for the regularized $p$-Stokes equations</title>
      <link>https://arxiv.org/abs/2307.02930</link>
      <description>arXiv:2307.02930v2 Announce Type: replace 
Abstract: The motion of glaciers can be simulated with the $p$-Stokes equations. Up to now, Newton's method to solve these equations has been analyzed in finite-dimensional settings only. We analyze the problem in infinite dimensions to gain a new viewpoint. We do that by proving global convergence of the infinite-dimensional Newton's method with Armijo step sizes to the solution of these equations. We only have to add an arbitrarily small diffusion term for this convergence result. We prove that the additional diffusion term only causes minor differences in the solution compared to the original $p$-Stokes equations under the assumption of some regularity. Finally, we test our algorithms on two experiments: A reformulation of the experiment ISMIP-HOM $B$ without sliding and a block with sliding. For the former, the approximation of exact step sizes for the Picard iteration and exact step sizes and Armijo step sizes for Newton's method are superior in the experiment compared to the Picard iteration. For the latter experiment, Newton's method with Armijo step sizes needs many iterations until it converges fast to the solution. Thus, Newton's method with approximately exact step sizes is better than Armijo step sizes in this experiment.</description>
      <guid isPermaLink="false">oai:arXiv.org:2307.02930v2</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <pubDate>Fri, 20 Sep 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <arxiv:DOI>10.1007/s11075-024-01941-6</arxiv:DOI>
      <arxiv:journal_reference>Numer Algor (2024)</arxiv:journal_reference>
      <dc:creator>Niko Schmidt</dc:creator>
    </item>
    <item>
      <title>A convergent stochastic scalar auxiliary variable method</title>
      <link>https://arxiv.org/abs/2308.07060</link>
      <description>arXiv:2308.07060v3 Announce Type: replace 
Abstract: We discuss an extension of the scalar auxiliary variable approach, which was originally introduced by Shen et al. ([Shen, Xu, Yang, J. Comput. Phys., 2018]) for the discretization of deterministic gradient flows. By introducing an additional scalar auxiliary variable, this approach allows to derive a linear scheme, while still maintaining unconditional stability. Our extension augments the approximation of the evolution of this scalar auxiliary variable with higher order terms, which enables its application to stochastic partial differential equations. Using the stochastic Allen--Cahn equation as a prototype for nonlinear stochastic partial differential equations with multiplicative noise, we propose an unconditionally energy stable, linear, fully discrete finite element scheme based on our augmented scalar auxiliary variable method. Recovering a discrete version of the energy estimate and establishing Nikolskii estimates with respect to time, we are able to prove convergence of discrete solutions towards pathwise unique martingale solutions by applying Jakubowski's generalization of Skorokhod's theorem. A generalization of the Gy\"ongy--Krylov characterization of convergence in probability to quasi-Polish spaces finally provides convergence of fully discrete solutions towards strong solutions of the stochastic Allen--Cahn equation. Finally, we present numerical simulations underlining the practicality of the scheme and the importance of the introduced augmentation terms.</description>
      <guid isPermaLink="false">oai:arXiv.org:2308.07060v3</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <category>math.AP</category>
      <pubDate>Fri, 20 Sep 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <arxiv:DOI>10.1093/imanum/drae065</arxiv:DOI>
      <dc:creator>Stefan Metzger</dc:creator>
    </item>
    <item>
      <title>Two-scale exponential integrators with uniform accuracy for three-dimensional charged-particle dynamics under strong magnetic field</title>
      <link>https://arxiv.org/abs/2311.18615</link>
      <description>arXiv:2311.18615v2 Announce Type: replace 
Abstract: The numerical simulation of three-dimensional charged-particle dynamics (CPD) under strong magnetic field is a basic and challenging algorithmic task in plasma physics. In this paper, we introduce a new methodology to design two-scale exponential integrators for three-dimensional CPD whose magnetic field's strength is inversely proportional to a dimensionless and small parameter $0&lt;\varepsilon \ll 1$. By dealing with the transformed form of three-dimensional CPD, we linearize the magnetic field and put the residual component in a new nonlinear function which is shown to be uniformly bounded. Based on this foundation and the proposed two-scale exponential integrators, a class of novel integrators is formulated and studied. The corresponding uniform accuracy of the proposed $r$-th order integrator is shown to be $\mathcal{O}(h^r)$, where $r=1,2,3,4$ and the constant symbolized by $\mathcal{O}$, the time stepsize $h$ and the computation cost are all independent of $\varepsilon$. Moreover, in the case of maximal ordering strong magnetic field, improved error bound $\mathcal{O}(\varepsilon^r h^r)$ is obtained for the proposed $r$-th order integrator. A rigorous proof of these uniform and improved error bounds is presented, and a numerical test is performed to illustrate the error and efficiency behaviour of the proposed integrators.</description>
      <guid isPermaLink="false">oai:arXiv.org:2311.18615v2</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <pubDate>Fri, 20 Sep 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Bin Wang, Zhen Miao, Yaolin Jiang</dc:creator>
    </item>
    <item>
      <title>Optimal convergence rates of MCMC integration for functions with unbounded second moment</title>
      <link>https://arxiv.org/abs/2403.16920</link>
      <description>arXiv:2403.16920v2 Announce Type: replace 
Abstract: We study the Markov chain Monte Carlo (MCMC) estimator for numerical integration for functions that do not need to be square integrable w.r.t. the invariant distribution. For chains with a spectral gap we show that the absolute mean error for $L^p$ functions, with $p \in (1,2)$, decreases like $n^{1/p -1}$, which is known to be the optimal rate. This improves currently known results where an additional parameter $\delta&gt;0$ appears and the convergence is of order $n^{(1+\delta)/p-1}$.</description>
      <guid isPermaLink="false">oai:arXiv.org:2403.16920v2</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <pubDate>Fri, 20 Sep 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Julian Hofstadler</dc:creator>
    </item>
    <item>
      <title>Orthogonal Laurent polynomials of two real variables</title>
      <link>https://arxiv.org/abs/2404.14303</link>
      <description>arXiv:2404.14303v2 Announce Type: replace 
Abstract: In this paper we consider an appropriate ordering of the Laurent monomials $x^{i}y^{j}$, $i,j \in \mathbb{Z}$ that allows us to study sequences of orthogonal Laurent polynomials of the real variables $x$ and $y$ with respect to a positive Borel measure $\mu$ defined on $\mathbb{R}^2$ such that $\{ x=0 \}\cup \{ y=0 \} \not\in \textrm{supp}(\mu)$. This ordering is suitable for considering the {\em multiplication plus inverse multiplication operator} on each varibale $\left( x+\frac{1}{x}\right.$ and $\left. y+\frac{1}{y}\right)$, and as a result we obtain five-term recurrence relations, Christoffel-Darboux and confluent formulas for the reproducing kernel and a related Favard's theorem. A connection with the one variable case is also presented, along with some applications for future research.</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.14303v2</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <pubDate>Fri, 20 Sep 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Ruym\'an Cruz-Barroso, Lidia Fern\'andez</dc:creator>
    </item>
    <item>
      <title>Meshfree Variational Physics Informed Neural Networks (MF-VPINN): an adaptive training strategy</title>
      <link>https://arxiv.org/abs/2406.19831</link>
      <description>arXiv:2406.19831v2 Announce Type: replace 
Abstract: In this paper, we introduce a Meshfree Variational-Physics-Informed Neural Network. It is a Variational-Physics-Informed Neural Network that does not require the generation of the triangulation of the entire domain and that can be trained with an adaptive set of test functions. In order to generate the test space, we exploit an a posteriori error indicator and add test functions only where the error is higher. Four training strategies are proposed and compared. Numerical results show that the accuracy is higher than the one of a Variational-Physics-Informed Neural Network trained with the same number of test functions but defined on a quasi-uniform mesh.</description>
      <guid isPermaLink="false">oai:arXiv.org:2406.19831v2</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <category>math.OC</category>
      <pubDate>Fri, 20 Sep 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <arxiv:DOI>10.3390/a17090415</arxiv:DOI>
      <arxiv:journal_reference>Algorithms 17(9), 415 (2024)</arxiv:journal_reference>
      <dc:creator>Stefano Berrone, Moreno Pintore</dc:creator>
    </item>
    <item>
      <title>A convergent augmented SAV scheme for stochastic Cahn--Hilliard equations with dynamic boundary conditions describing contact line tension</title>
      <link>https://arxiv.org/abs/2407.20424</link>
      <description>arXiv:2407.20424v2 Announce Type: replace 
Abstract: We augment a thermodynamically consistent diffuse interface model for the description of line tension phenomena by multiplicative stochastic noise to capture the effects of thermal fluctuations and establish the existence of pathwise unique (stochastically) strong solutions. By starting from a fully discrete linear finite element scheme, we do not only prove the well-posedness of the model, but also provide a practicable and convergent scheme for its numerical treatment. Conceptually, our discrete scheme relies on a recently developed augmentation of the scalar auxiliary variable approach, which reduces the requirements on the time regularity of the solution. By showing that fully discrete solutions to this scheme satisfy an energy estimate, we obtain first uniform regularity results. Establishing Nikolskii estimates with respect to time, we are able to show convergence towards pathwise unique martingale solutions by applying Jakubowski's generalization of Skorokhod's theorem. Finally, a generalization of the Gy\"ongy--Krylov characterization of convergence in probability provides convergence towards strong solutions and thereby completes the proof.</description>
      <guid isPermaLink="false">oai:arXiv.org:2407.20424v2</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <pubDate>Fri, 20 Sep 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Stefan Metzger</dc:creator>
    </item>
    <item>
      <title>Fast Algorithms for Fourier extension based on boundary interval data</title>
      <link>https://arxiv.org/abs/2409.04265</link>
      <description>arXiv:2409.04265v2 Announce Type: replace 
Abstract: This paper present a new algorithm for the computation of Fourier extension based on boundary data, which can obtain a super-algebraic convergent Fourier approximation for non-periodic functions. The algorithm calculates the extension part through boundary data and connects it with the original function to form a periodic smooth function. By testing the key parameters involved, their impact on the algorithm is clarified and the optimization setting scheme of the parameters is proposed. Compared with FFT, the algorithm only needs to increase the computational complexity by a fixed small amount.</description>
      <guid isPermaLink="false">oai:arXiv.org:2409.04265v2</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <pubDate>Fri, 20 Sep 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Z. Y. Zhao, Y. F Wang</dc:creator>
    </item>
    <item>
      <title>Spline-based solution transfer for space-time methods in 2D+t</title>
      <link>https://arxiv.org/abs/2409.11639</link>
      <description>arXiv:2409.11639v2 Announce Type: replace 
Abstract: This work introduces a new solution-transfer process for slab-based space-time finite element methods. The new transfer process is based on Hsieh-Clough-Tocher (HCT) splines and satisfies the following requirements: (i) it maintains high-order accuracy up to 4th order, (ii) it preserves a discrete maximum principle, (iii) it asymptotically enforces mass conservation, and (iv) it constructs a smooth, continuous surrogate solution in between space-time slabs. While many existing transfer methods meet the first three requirements, the fourth requirement is crucial for enabling visualization and boundary condition enforcement for space-time applications. In this paper, we derive an error bound for our HCT spline-based transfer process. Additionally, we conduct numerical experiments quantifying the conservative nature and order of accuracy of the transfer process. Lastly, we present a qualitative evaluation of the visualization properties of the smooth surrogate solution.</description>
      <guid isPermaLink="false">oai:arXiv.org:2409.11639v2</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <pubDate>Fri, 20 Sep 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Logan Larose, Jude T. Anderson, David M. Williams</dc:creator>
    </item>
    <item>
      <title>Decentralized Neural Networks for Robust and Scalable Eigenvalue Computation</title>
      <link>https://arxiv.org/abs/2409.06746</link>
      <description>arXiv:2409.06746v2 Announce Type: replace-cross 
Abstract: This paper introduces a novel method for eigenvalue computation using a distributed cooperative neural network framework. Unlike traditional techniques that face scalability challenges in large systems, our decentralized algorithm enables multiple autonomous agents to collaboratively estimate the smallest eigenvalue of large matrices. Each agent employs a localized neural network, refining its estimates through communication with neighboring agents. Our empirical results confirm the algorithm's convergence towards the true eigenvalue, with estimates clustered closely around the true value. Even in the presence of communication delays or network disruptions, the method demonstrates strong robustness and scalability. Theoretical analysis further validates the accuracy and stability of the proposed approach, while empirical tests highlight its efficiency and precision, surpassing traditional centralized algorithms in large-scale eigenvalue computations.</description>
      <guid isPermaLink="false">oai:arXiv.org:2409.06746v2</guid>
      <category>cs.LG</category>
      <category>cs.NA</category>
      <category>math.NA</category>
      <pubDate>Fri, 20 Sep 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Ronald Katende</dc:creator>
    </item>
  </channel>
</rss>
