<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>cs.CC updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/cs.CC</link>
    <description>cs.CC updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/cs.CC" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Thu, 12 Dec 2024 02:42:18 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Wed, 11 Dec 2024 00:00:00 -0500</pubDate>
    <skipDays>
      <day>Sunday</day>
      <day>Saturday</day>
    </skipDays>
    <item>
      <title>Lossless Model Compression via Joint Low-Rank Factorization Optimization</title>
      <link>https://arxiv.org/abs/2412.06867</link>
      <description>arXiv:2412.06867v1 Announce Type: cross 
Abstract: Low-rank factorization is a popular model compression technique that minimizes the error $\delta$ between approximated and original weight matrices. Despite achieving performances close to the original models when $\delta$ is optimized, a performance discrepancy remains due to the separate optimization processes for low-rank factorization and model performance, resulting in unavoidable losses. We address this issue by introducing a novel joint optimization strategy for lossless low-rank weight factorization, which, for the first time, enhances the model's performance beyond the original. Our approach begins with a theoretical analysis of the relationship between low-rank factorization and model optimization objectives, establishing a precise perturbation range for matrix factorization errors on model performance. This challenge is then reformulated as a numerical rank deficiency problem with inequality constraints and develop a joint objective that simultaneously addresses factorization error and model performance. Based on the above analysis, we propose two optimization algorithms: \textbf{a lossless optimization algorithm} that maximizes model accuracy while ensuring compression, and \textbf{a compact optimization algorithm} that minimizes model size while preserving performance. These algorithms do not require fine-tuning and can directly compress numerous deep models to achieve lossless results. Our methods demonstrate robust efficacy across various vision and language tasks. For example, the compressed model reduced by 70\% on ResNext50 outperforms the original. Our code will be made public.</description>
      <guid isPermaLink="false">oai:arXiv.org:2412.06867v1</guid>
      <category>cs.LG</category>
      <category>cs.AI</category>
      <category>cs.CC</category>
      <pubDate>Wed, 11 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Boyang Zhang, Daning Cheng, Yunquan Zhang, Fangmin Liu, Jiake Tian</dc:creator>
    </item>
    <item>
      <title>Random regular graph states are complex at almost any depth</title>
      <link>https://arxiv.org/abs/2412.07058</link>
      <description>arXiv:2412.07058v1 Announce Type: cross 
Abstract: Graph states are fundamental objects in the theory of quantum information due to their simple classical description and rich entanglement structure. They are also intimately related to IQP circuits, which have applications in quantum pseudorandomness and quantum advantage. For us, they are a toy model to understand the relation between circuit connectivity, entanglement structure and computational complexity. In the worst case, a strict dichotomy in the computational universality of such graph states appears as a function of the degree $d$ of a regular graph state [GDH+23]. In this paper, we initiate the study of the average-case complexity of simulating random graph states of varying degree when measured in random product bases and give distinct evidence that a similar complexity-theoretic dichotomy exists in the average case. Specifically, we consider random $d$-regular graph states and prove three distinct results: First, we exhibit two families of IQP circuits of depth $d$ and show that they anticoncentrate for any $2 &lt; d = o(n)$ when measured in a random $X$-$Y$-plane product basis. This implies anticoncentration for random constant-regular graph states. Second, in the regime $d = \Theta(n^c)$ with $c \in (0,1)$, we prove that random $d$-regular graph states contain polynomially large grid graphs as induced subgraphs with high probability. This implies that they are universal resource states for measurement-based computation. Third, in the regime of high degree ($d\sim n/2$), we show that random graph states are not sufficiently entangled to be trivially classically simulable, unlike Haar random states. Proving the three results requires different techniques--the analysis of a classical statistical-mechanics model using Krawtchouck polynomials, graph theoretic analysis using the switching method, and analysis of the ranks of submatrices of random adjacency matrices, respectively.</description>
      <guid isPermaLink="false">oai:arXiv.org:2412.07058v1</guid>
      <category>quant-ph</category>
      <category>cs.CC</category>
      <category>math.CO</category>
      <pubDate>Wed, 11 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <dc:creator>Soumik Ghosh, Dominik Hangleiter, Jonas Helsen</dc:creator>
    </item>
    <item>
      <title>Payment Scheduling in the Interval Debt Model</title>
      <link>https://arxiv.org/abs/2403.02198</link>
      <description>arXiv:2403.02198v2 Announce Type: replace-cross 
Abstract: The network-based study of financial systems has received considerable attention in recent years but has seldom explicitly incorporated the dynamic aspects of such systems. We consider this problem setting from the temporal point of view and introduce the Interval Debt Model (IDM) and some scheduling problems based on it, namely: Bankruptcy Minimization/Maximization, in which the aim is to produce a payment schedule with at most/at least a given number of bankruptcies; Perfect Scheduling, the special case of the minimization variant where the aim is to produce a schedule with no bankruptcies (that is, a perfect schedule); and Bailout Minimization, in which a financial authority must allocate a smallest possible bailout package to enable a perfect schedule. We show that each of these problems is NP-complete, in many cases even on very restricted input instances. On the positive side, we provide for Perfect Scheduling a polynomial-time algorithm on (rooted) out-trees although in contrast we prove NP-completeness on directed acyclic graphs, as well as on instances with a constant number of nodes (and hence also constant treewidth). When we allow non-integer payments, we show by a linear programming argument that the problem Bailout Minimization can be solved in polynomial time.</description>
      <guid isPermaLink="false">oai:arXiv.org:2403.02198v2</guid>
      <category>cs.DM</category>
      <category>cs.CC</category>
      <category>cs.CE</category>
      <pubDate>Wed, 11 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Tom Friedetzky, David C. Kutner, George B. Mertzios, Iain A. Stewart, Amitabh Trehan</dc:creator>
    </item>
    <item>
      <title>Characterization of the set of zero-noise limits measures of perturbed cellular automata</title>
      <link>https://arxiv.org/abs/2412.04672</link>
      <description>arXiv:2412.04672v2 Announce Type: replace-cross 
Abstract: We add small random perturbations to a cellular automaton and consider the one-parameter family $(F_\epsilon)_{\epsilon&gt;0}$ parameterized by $\epsilon$ where $\epsilon&gt;0$ is the level of noise. The objective of the article is to study the set of limiting invariant distributions as $\epsilon$ tends to zero denoted $\mathcal{M}_0^l$. Some topological obstructions appear, $\mathcal{M}_0^l$ is compact and connected, as well as combinatorial obstructions as the set of cellular automata is countable: $\mathcal{M}_0^l$ is $\Pi_3$-computable in general and $\Pi_2$-computable if it is uniformly approached. Reciprocally, for any set of probability measures $\mathcal{K}$ which is compact, connected and $\Pi_2$-computable, we construct a cellular automaton whose perturbations by an uniform noise admit $\mathcal{K}$ as the zero-noise limits measure and this set is uniformly approached. To finish, we study how the set of limiting invariant measures can depend on a bias in the noise. We construct a cellular automaton which realizes any connected compact set (without computable constraints) if the bias is changed for an arbitrary small value. In some sense this cellular automaton is very unstable with respect to the noise.</description>
      <guid isPermaLink="false">oai:arXiv.org:2412.04672v2</guid>
      <category>math.DS</category>
      <category>cs.CC</category>
      <category>cs.DM</category>
      <category>math.PR</category>
      <pubDate>Wed, 11 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Hugo Marsan, Mathieu Sablik</dc:creator>
    </item>
    <item>
      <title>Fast Matrix Multiplication meets the Subdmodular Width</title>
      <link>https://arxiv.org/abs/2412.06189</link>
      <description>arXiv:2412.06189v2 Announce Type: replace-cross 
Abstract: One fundamental question in database theory is the following: Given a Boolean conjunctive query Q, what is the best complexity for computing the answer to Q in terms of the input database size N? When restricted to the class of combinatorial algorithms, it is known that the best known complexity for any query Q is captured by the submodular width of Q. However, beyond combinatorial algorithms, certain queries are known to admit faster algorithms that often involve a clever combination of fast matrix multiplication and data partitioning. Nevertheless, there is no systematic way to derive and analyze the complexity of such algorithms for arbitrary queries Q.
  In this work, we introduce a general framework that captures the best complexity for answering any Boolean conjunctive query Q using matrix multiplication. Our framework unifies both combinatorial and non-combinatorial techniques under the umbrella of information theory. It generalizes the notion of submodular width to a new stronger notion called the omega-submodular width that naturally incorporates the power of fast matrix multiplication. We describe a matching algorithm that computes the answer to any query Q in time corresponding to the omega-submodular width of Q. We show that our framework recovers the best known complexities for Boolean queries that have been studied in the literature, to the best of our knowledge, and also discovers new algorithms for some classes of queries that improve upon the best known complexities.</description>
      <guid isPermaLink="false">oai:arXiv.org:2412.06189v2</guid>
      <category>cs.DB</category>
      <category>cs.CC</category>
      <category>cs.IT</category>
      <category>math.IT</category>
      <pubDate>Wed, 11 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Mahmoud Abo-Khamis, Xiao Hu, Dan Suciu</dc:creator>
    </item>
  </channel>
</rss>
