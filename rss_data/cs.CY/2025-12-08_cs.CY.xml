<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>cs.CY updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/cs.CY</link>
    <description>cs.CY updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/cs.CY" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Mon, 08 Dec 2025 05:00:29 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Mon, 08 Dec 2025 00:00:00 -0500</pubDate>
    <skipDays>
      <day>Sunday</day>
      <day>Saturday</day>
    </skipDays>
    <item>
      <title>La transformation num{\'e}rique de la justice : ambitions, r{\'e}alit{\'e}s et perspectives</title>
      <link>https://arxiv.org/abs/2512.05143</link>
      <description>arXiv:2512.05143v1 Announce Type: new 
Abstract: The study, conducted over a four-year academic cycle with the assistance of M2 students from the Cyberjustice Master's programme at the Faculty of Law, Political Science and Management at the University of Strasbourg, aims to objectively assess the discourse and representations of the digital transformation of justice, in particular by capitalising on testimonials from professionals in the field and drawing on the available literature.</description>
      <guid isPermaLink="false">oai:arXiv.org:2512.05143v1</guid>
      <category>cs.CY</category>
      <pubDate>Mon, 08 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Yannick Meneceur (UNISTRA, CRLD, IRB)</dc:creator>
    </item>
    <item>
      <title>Deadline-Chasing in Digital Health: Modeling EMR Adoption Dynamics and Regulatory Impact in Indonesian Primary Care</title>
      <link>https://arxiv.org/abs/2512.05381</link>
      <description>arXiv:2512.05381v1 Announce Type: new 
Abstract: Indonesia digital healthcare transformation is accelerating under Minister of Health Regulation Number 24 of 2022, which mandates the adoption of Electronic Medical Records EMR and integration with the SATUSEHAT platform. However, empirical evidence regarding the factors, trajectory and speed of adoption in Primary Health Facilities FKTP remains limited. This study aims to evaluate the level and rate of EMR adoption within the customer network of a major EMR system provider PT MTK and model short-term projections. This is an observational study with the main variables being cumulative registered EMR facilities, monthly registration flow, same-month activation, same-month inactivation, and the estimated number of eligible FKTPs nationally monthly known as eligible facilities. The analysis uses descriptive analysis, logistic growth modeling, and ARIMA forecasting. The results of the study over 33 months showed that cumulative registered facilities increased from 2 to 3,533, with a median same-month activation rate of 0.889 IQR 0.717 to 0.992. The proportion of final adoption compared to eligible facilities was 8.9 percent 3,533 of 39,852. The ARIMA model projects a cumulative approximately 3,997 clinics 95 percent CI 3,697 to 4,298 by June 2025. The estimated growth in logistics converges with a carrying capacity of 4.1 thousand facilities. The study findings reveal that EMR adoption within the customer network of EMR system providers is showing steady growth with rapid activation in the month of registration. Although the cumulative series showed no major departures from the long-term trend, localized step-ups around deadlines suggest deadline chasing, so impact should be maximized by aligning interventions to the deadline calendar. Given the trajectory, total market share of FKTP for PT MTK remains less than 10 percent at the end of 2024, but continues to increase in 2025.</description>
      <guid isPermaLink="false">oai:arXiv.org:2512.05381v1</guid>
      <category>cs.CY</category>
      <pubDate>Mon, 08 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Suryo Satrio, Bukhori Muhammad Aqid</dc:creator>
    </item>
    <item>
      <title>Building Capacity for Artificial Intelligence in Africa: A Cross-Country Survey of Challenges and Governance Pathways</title>
      <link>https://arxiv.org/abs/2512.05432</link>
      <description>arXiv:2512.05432v1 Announce Type: new 
Abstract: Artificial intelligence (AI) is transforming education and the workforce, but access to AI learning opportunities in Africa remains uneven. With rapid demographic shifts and growing labour market pressures, AI has become a strategic development priority, making the demand for relevant skills more urgent. This study investigates how universities and industries engage in shaping AI education and workforce preparation, drawing on survey responses from five African countries (Ghana, Namibia, Rwanda, Kenya and Zambia). The findings show broad recognition of AI importance but limited evidence of consistent engagement, practical training, or equitable access to resources. Most respondents who rated the AI component of their curriculum as very relevant reported being well prepared for jobs, but financial barriers, poor infrastructure, and weak communication limit participation, especially among students and underrepresented groups. Respondents highlighted internships, industry partnerships, and targeted support mechanisms as critical enablers, alongside the need for inclusive governance frameworks. The results showed both the growing awareness of AI's potential and the structural gaps that hinder its translation into workforce capacity. Strengthening university-industry collaboration and addressing barriers of access, funding, and policy are central to ensuring that AI contributes to equitable and sustainable development across the continent.</description>
      <guid isPermaLink="false">oai:arXiv.org:2512.05432v1</guid>
      <category>cs.CY</category>
      <category>cs.AI</category>
      <pubDate>Mon, 08 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Jeffrey N. A. Aryee, Patrick Davies, Godfred A. Torsah, Mercy M. Apaw, Cyril D. Boateng, Sam M. Mwando, Chris Kwisanga, Eric Jobunga, Leonard K. Amekudzi</dc:creator>
    </item>
    <item>
      <title>Knowing Your Uncertainty -- On the application of LLM in social sciences</title>
      <link>https://arxiv.org/abs/2512.05461</link>
      <description>arXiv:2512.05461v1 Announce Type: new 
Abstract: Large language models (LLMs) are rapidly being integrated into computational social science research, yet their blackboxed training and designed stochastic elements in inference pose unique challenges for scientific inquiry. This article argues that applying LLMs to social scientific tasks requires explicit assessment of uncertainty-an expectation long established in both quantitative methodology in the social sciences and machine learning. We introduce a unified framework for evaluating LLM uncertainty along two dimensions: the task type (T), which distinguishes between classification, short-form, and long-form generation, and the validation type (V), which captures the availability of reference data or evaluative criteria. Drawing from both computer science and social science literature, we map existing uncertainty quantification (UQ) methods to this T-V typology and offer practical recommendations for researchers. Our framework provides both a methodological safeguard and a practical guide for integrating LLMs into rigorous social science research.</description>
      <guid isPermaLink="false">oai:arXiv.org:2512.05461v1</guid>
      <category>cs.CY</category>
      <category>cs.AI</category>
      <category>cs.HC</category>
      <pubDate>Mon, 08 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Bolun Zhang, Linzhuo Li, Yunqi Chen, Qinlin Zhao, Zihan Zhu, Xiaoyuan Yi, Xing Xie</dc:creator>
    </item>
    <item>
      <title>The Topology of Hardship: Empirical Curriculum Graphs and Structural Bottlenecks in Engineering Degrees</title>
      <link>https://arxiv.org/abs/2512.05561</link>
      <description>arXiv:2512.05561v1 Announce Type: new 
Abstract: Engineering degrees are often perceived as "hard", yet this hardness is usually discussed in terms of content difficulty or student weaknesses rather than as a structural property of the curriculum itself. Recent work on course-prerequisite networks and curriculum graphs has shown that study plans can be modelled as complex networks with identifiable hubs and bottlenecks, but most studies rely on official syllabi rather than on how students actually progress through the system (Simon de Blas et al., 2021; Stavrinides &amp; Zuev, 2023; Yang et al., 2024; Wang et al., 2025).
  This paper introduces the notion of topology of hardship: a quantitative description of curriculum complexity derived from empirical student trajectories in long-cycle engineering programmes. Building on the CAPIRE framework for multilevel trajectory modelling (Paz, 2025a, 2025b), we reconstruct degree-curriculum graphs from enrolment and completion data for 29 engineering curricula across several cohorts. For each graph we compute structural metrics (e.g., density, longest path, bottleneck centrality) and empirical hardship measures capturing blocking probability and time-to-progress. These are combined into a composite hardship index, which is then related to observed dropout rates and time to degree.
  Our findings show that curriculum hardness is not a vague perception but a measurable topological property: a small number of structurally dense, bottleneck-heavy curricula account for a disproportionate share of dropout and temporal desynchronisation. We discuss implications for curriculum reform, accreditation, and data-informed policy design.</description>
      <guid isPermaLink="false">oai:arXiv.org:2512.05561v1</guid>
      <category>cs.CY</category>
      <pubDate>Mon, 08 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>H. R. Paz</dc:creator>
    </item>
    <item>
      <title>Open Data, Privacy, and Fair Information Principles: Towards a Balancing Framework</title>
      <link>https://arxiv.org/abs/2512.05728</link>
      <description>arXiv:2512.05728v1 Announce Type: new 
Abstract: Open data are held to contribute to a wide variety of social and political goals, including strengthening transparency, public participation and democratic accountability, promoting economic growth and innovation, and enabling greater public sector efficiency and cost savings. However, releasing government data that contain personal information may threaten privacy and related rights and interests. In this Article we ask how these privacy interests can be respected, without unduly hampering benefits from disclosing public sector information. We propose a balancing framework to help public authorities address this question in different contexts. The framework takes into account different levels of privacy risks for different types of data. It also separates decisions about access and re-use, and highlights a range of different disclosure routes. A circumstance catalogue lists factors that might be considered when assessing whether, under which conditions, and how a dataset can be released. While open data remains an important route for the publication of government information, we conclude that it is not the only route, and there must be clear and robust public interest arguments in order to justify the disclosure of personal information as open data.</description>
      <guid isPermaLink="false">oai:arXiv.org:2512.05728v1</guid>
      <category>cs.CY</category>
      <pubDate>Mon, 08 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <arxiv:DOI>10.15779/Z389S18</arxiv:DOI>
      <arxiv:journal_reference>Berkeley Technology Law Journal 2015, Vol. 30, No. 3</arxiv:journal_reference>
      <dc:creator>Frederik Zuiderveen Borgesius, Jonathan Gray, Mireille van Eechoud</dc:creator>
    </item>
    <item>
      <title>Informed Consent: We Can Do Better to Defend Privacy</title>
      <link>https://arxiv.org/abs/2512.05729</link>
      <description>arXiv:2512.05729v1 Announce Type: new 
Abstract: We need to rethink our approach to defend privacy on the internet. Currently, policymakers focus heavily on the idea of informed consent as a means to defend privacy. For instance, in many countries the law requires firms to obtain an individual's consent before they use data about her; with such informed consent requirements, the law aims to empower people to make privacy choices in their best interests. But behavioural studies cast doubt on this approach's effectiveness, as people tend to click OK to almost any request they see on their screens. To improve privacy protection, this article argues for a combined approach of protecting and empowering the individual. This article discusses practical problems with informed consent as a means to protect privacy, and illustrates the problems with current data privacy rules regarding behavioural targeting. First, the privacy problems of behavioural targeting, and the central role of informed consent in privacy law are discussed. Following that, practical problems with informed consent are highlighted. Then, the article argues that policymakers should give more attention to rules that protect, rather than empower, people.</description>
      <guid isPermaLink="false">oai:arXiv.org:2512.05729v1</guid>
      <category>cs.CY</category>
      <pubDate>Mon, 08 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <arxiv:journal_reference>IEEE 2015 (Volume 13, Issue 2, p. 103-107)</arxiv:journal_reference>
      <dc:creator>Frederik Zuiderveen Borgesius</dc:creator>
    </item>
    <item>
      <title>De mythe van ge\"informeerde toestemming: online privacybescherming kan beter [Informed Consent: We Can Do Better to Defend Privacy]</title>
      <link>https://arxiv.org/abs/2512.05730</link>
      <description>arXiv:2512.05730v1 Announce Type: new 
Abstract: We need to rethink our approach to defend privacy on the internet. Currently, policymakers focus heavily on the idea of informed consent as a means to defend privacy. For instance, in many countries the law requires firms to obtain an individual's consent before they use data about her; with such informed consent requirements, the law aims to empower people to make privacy choices in their best interests. But behavioural studies cast doubt on this approach's effectiveness, as people tend to click OK to almost any request they see on their screens. To improve privacy protection, this article argues for a combined approach of protecting and empowering the individual. This article discusses practical problems with informed consent as a means to protect privacy, and illustrates the problems with current data privacy rules regarding behavioural targeting. First, the privacy problems of behavioural targeting, and the central role of informed consent in privacy law are discussed. Following that, practical problems with informed consent are highlighted. Then, the article argues that policymakers should give more attention to rules that protect, rather than empower, people.</description>
      <guid isPermaLink="false">oai:arXiv.org:2512.05730v1</guid>
      <category>cs.CY</category>
      <pubDate>Mon, 08 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <arxiv:journal_reference>Nederlands Juristenblad 2015-14, p. 878-883</arxiv:journal_reference>
      <dc:creator>Frederik Zuiderveen Borgesius</dc:creator>
    </item>
    <item>
      <title>Internal Deployment in the EU AI Act</title>
      <link>https://arxiv.org/abs/2512.05742</link>
      <description>arXiv:2512.05742v1 Announce Type: new 
Abstract: This memorandum analyzes and stress-tests arguments in favor and against the inclusion of internal deployment within the scope of the European Union Artificial Intelligence Act (EU AI Act). In doing so, it aims to offer several possible interpretative pathways to the European Commission, AI providers and deployers, and the legal and policy community at large based on Articles 2(1), 2(6), 2(8) of the EU AI Act. Specifically, this memorandum first analyzes four interpretative pathways based on Article 2(1)(a)-(c) supporting the application of the EU AI Act to internally deployed AI models and systems. Then, it examines possible objections and exceptions based on Articles 2(1)(a), 2(6), and 2(8), with particular attention to the complexity of the scientific R&amp;D exception under Article 2(6). Finally, it illustrates how Articles 2(1), 2(6), and 2(8) can be viewed as complementary to each other, once broken down to their most plausible meaning and interpreted in conjunction with Articles 3(1), 3(3), 3(4), 3(9), 3(10), 3(11), 3(12), 3(63), and Recitals 12, 13, 21, 25, 97, and 109.</description>
      <guid isPermaLink="false">oai:arXiv.org:2512.05742v1</guid>
      <category>cs.CY</category>
      <pubDate>Mon, 08 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Matteo Pistillo</dc:creator>
    </item>
    <item>
      <title>LLM Harms: A Taxonomy and Discussion</title>
      <link>https://arxiv.org/abs/2512.05929</link>
      <description>arXiv:2512.05929v1 Announce Type: new 
Abstract: This study addresses categories of harm surrounding Large Language Models (LLMs) in the field of artificial intelligence. It addresses five categories of harms addressed before, during, and after development of AI applications: pre-development, direct output, Misuse and Malicious Application, and downstream application. By underscoring the need to define risks of the current landscape to ensure accountability, transparency and navigating bias when adapting LLMs for practical applications. It proposes mitigation strategies and future directions for specific domains and a dynamic auditing system guiding responsible development and integration of LLMs in a standardized proposal.</description>
      <guid isPermaLink="false">oai:arXiv.org:2512.05929v1</guid>
      <category>cs.CY</category>
      <pubDate>Mon, 08 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/publicdomain/zero/1.0/</dc:rights>
      <dc:creator>Kevin Chen, Saleh Afroogh, Abhejay Murali, David Atkinson, Amit Dhurandhar, Junfeng Jiao</dc:creator>
    </item>
    <item>
      <title>Job Satisfaction Through the Lens of Social Media: Rural--Urban Patterns in the U.S</title>
      <link>https://arxiv.org/abs/2512.05144</link>
      <description>arXiv:2512.05144v1 Announce Type: cross 
Abstract: We analyze a novel large-scale social-media-based measure of U.S. job satisfaction, constructed by applying a fine-tuned large language model to 2.6 billion georeferenced tweets, and link it to county-level labor market conditions (2013-2023). Logistic regressions show that rural counties consistently report lower job satisfaction sentiment than urban ones, but this gap decreases under tight labor markets. In contrast to widening rural-urban income disparities, perceived job quality converges when unemployment is low, suggesting that labor market slack, not income alone, drives spatial inequality in subjective work-related well-being.</description>
      <guid isPermaLink="false">oai:arXiv.org:2512.05144v1</guid>
      <category>econ.GN</category>
      <category>cs.CY</category>
      <category>cs.SI</category>
      <category>q-fin.EC</category>
      <category>stat.AP</category>
      <pubDate>Mon, 08 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Stefano M Iacus, Giuseppe Porro</dc:creator>
    </item>
    <item>
      <title>Integrating Wearable Data into Process Mining: Event, Case and Activity Enrichment</title>
      <link>https://arxiv.org/abs/2512.05203</link>
      <description>arXiv:2512.05203v1 Announce Type: cross 
Abstract: In this short paper, we explore the enrichment of event logs with data from wearable devices. We discuss three approaches: (1) treating wearable data as event attributes, linking them directly to individual events, (2) treating wearable data as case attributes, using aggregated day-level scores, and (3) introducing new events derived from wearable data, such as sleep episodes or physical activities. To illustrate these approaches, we use real-world data from one person, matching health data from a smartwatch with events extracted from a digital calendar application. Finally, we discuss the technical and conceptual challenges involved in integrating wearable data into process mining for personal productivity and well-being.</description>
      <guid isPermaLink="false">oai:arXiv.org:2512.05203v1</guid>
      <category>cs.DB</category>
      <category>cs.CY</category>
      <pubDate>Mon, 08 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Vinicius Stein Dani, Xixi Lu, Iris Beerepoot</dc:creator>
    </item>
    <item>
      <title>Decoding the Black Box: Discerning AI Rhetorics About and Through Poetic Prompting</title>
      <link>https://arxiv.org/abs/2512.05243</link>
      <description>arXiv:2512.05243v1 Announce Type: cross 
Abstract: Prompt engineering has emerged as a useful way studying the algorithmic tendencies and biases of large language models. Meanwhile creatives and academics have leveraged LLMs to develop creative works and explore the boundaries of their writing capabilities through text generation and code. This study suggests that creative text prompting, specifically Poetry Prompt Patterns, may be a useful addition to the toolbox of the prompt engineer, and outlines the process by which this approach may be taken. Then, the paper uses poetic prompts to assess descriptions and evaluations of three models of a renowned poet and test the consequences of the willingness of models to adapt or rewrite original creative works for presumed audiences.</description>
      <guid isPermaLink="false">oai:arXiv.org:2512.05243v1</guid>
      <category>cs.CL</category>
      <category>cs.CY</category>
      <pubDate>Mon, 08 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>P. D. Edgar, Alia Hall</dc:creator>
    </item>
    <item>
      <title>Invisible Load: Uncovering the Challenges of Neurodivergent Women in Software Engineering</title>
      <link>https://arxiv.org/abs/2512.05350</link>
      <description>arXiv:2512.05350v1 Announce Type: cross 
Abstract: Neurodivergent women in Software Engineering (SE) encounter distinctive challenges at the intersection of gender bias and neurological differences. To the best of our knowledge, no prior work in SE research has systematically examined this group, despite increasing recognition of neurodiversity in the workplace. Underdiagnosis, masking, and male-centric workplace cultures continue to exacerbate barriers that contribute to stress, burnout, and attrition. In response, we propose a hybrid methodological approach that integrates InclusiveMag's inclusivity framework with the GenderMag walkthrough process, tailored to the context of neurodivergent women in SE. The overarching design unfolds across three stages, scoping through literature review, deriving personas and analytic processes, and applying the method in collaborative workshops. We present a targeted literature review that synthesize challenges into cognitive, social, organizational, structural and career progression challenges neurodivergent women face in SE, including how under/late diagnosis and masking intensify exclusion. These findings lay the groundwork for subsequent stages that will develop and apply inclusive analytic methods to support actionable change.</description>
      <guid isPermaLink="false">oai:arXiv.org:2512.05350v1</guid>
      <category>cs.SE</category>
      <category>cs.AI</category>
      <category>cs.CY</category>
      <pubDate>Mon, 08 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Munazza Zaib, Wei Wang, Dulaji Hidellaarachchi, Isma Farah Siddiqui</dc:creator>
    </item>
    <item>
      <title>Parajudica: An RDF-Based Reasoner and Metamodel for Multi-Framework Context-Dependent Data Compliance Assessments</title>
      <link>https://arxiv.org/abs/2512.05453</link>
      <description>arXiv:2512.05453v1 Announce Type: cross 
Abstract: Motivated by the challenges of implementing policy-based data access control (PBAC) under multiple simultaneously applicable compliance frameworks, we present Parajudica, an open, modular, and extensible RDF/SPARQL-based rule system for evaluating context-dependent data compliance status. We demonstrate the utility of this resource and accompanying metamodel through application to existing legal frameworks and industry standards, offering insights for comparative framework analysis. Applications include compliance policy enforcement, compliance monitoring, data discovery, and risk assessment.</description>
      <guid isPermaLink="false">oai:arXiv.org:2512.05453v1</guid>
      <category>cs.DB</category>
      <category>cs.AI</category>
      <category>cs.CY</category>
      <category>cs.LO</category>
      <pubDate>Mon, 08 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Luc Moreau (University of Sussex, Brighton, United Kingdom), Alfred Rossi (Immuta Research, Boston, Massachusetts, USA), Sophie Stalla-Bourdillon (Brussels Privacy Hub, Vrije Universiteit Brussel, Brussels, Belgium)</dc:creator>
    </item>
    <item>
      <title>User Negotiations of Authenticity, Ownership, and Governance on AI-Generated Video Platforms: Evidence from Sora</title>
      <link>https://arxiv.org/abs/2512.05519</link>
      <description>arXiv:2512.05519v1 Announce Type: cross 
Abstract: As AI-generated video platforms rapidly advance, ethical challenges such as copyright infringement emerge. This study examines how users make sense of AI-generated videos on OpenAI's Sora by conducting a qualitative content analysis of user comments. Through a thematic analysis, we identified four dynamics that characterize how users negotiate authenticity, authorship, and platform governance on Sora. First, users acted as critical evaluators of realism, assessing micro-details such as lighting, shadows, fluid motion, and physics to judge whether AI-generated scenes could plausibly exist. Second, users increasingly shifted from passive viewers to active creators, expressing curiosity about prompts, techniques, and creative processes. Text prompts were perceived as intellectual property, generating concerns about plagiarism and remixing norms. Third, users reported blurred boundaries between real and synthetic media, worried about misinformation, and even questioned the authenticity of other commenters, suspecting bot-generated engagement. Fourth, users contested platform governance: some perceived moderation as inconsistent or opaque, while others shared tactics for evading prompt censorship through misspellings, alternative phrasing, emojis, or other languages. Despite this, many users also enforced ethical norms by discouraging the misuse of real people's images or disrespectful content. Together, these patterns highlighted how AI-mediated platforms complicate notions of reality, creativity, and rule-making in emerging digital ecosystems. Based on the findings, we discuss governance challenges in Sora and how user negotiations inform future platform governance.</description>
      <guid isPermaLink="false">oai:arXiv.org:2512.05519v1</guid>
      <category>cs.HC</category>
      <category>cs.AI</category>
      <category>cs.CY</category>
      <pubDate>Mon, 08 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Bohui Shen, Shrikar Bhatta, Alex Ireebanije, Zexuan Liu, Abhinav Choudhry, Ece Gumusel, Kyrie Zhixuan Zhou</dc:creator>
    </item>
    <item>
      <title>The Power of Network Pluralism: Multi-Perspective Modeling of Heterogeneous Legal Document Networks</title>
      <link>https://arxiv.org/abs/2512.05679</link>
      <description>arXiv:2512.05679v1 Announce Type: cross 
Abstract: Insights are relative - influenced by a range of factors such as assumptions, scopes, or methods that together define a research perspective. In normative and empirical fields alike, this insight has led to the conclusion that no single perspective can generate complete knowledge. As a response, epistemological pluralism mandates that researchers consider multiple perspectives simultaneously to obtain a holistic understanding of their phenomenon under study. Translating this mandate to network science, our work introduces Network Pluralism as a conceptual framework that leverages multi-perspectivity to yield more complete, meaningful, and robust results. We develop and demonstrate the benefits of this approach via a hands-on analysis of complex legal systems, constructing a network space from references across documents from different branches of government as well as including organizational hierarchy above and fine-grained structure below the document level. Leveraging the resulting heterogeneity in a multi-network analysis, we show how complementing perspectives can help contextualize otherwise high-level findings, how contrasting several networks derived from the same data enables researchers to learn by difference, and how relating metrics to perspectives may increase the transparency and robustness of network-analytical results. To analyze a space of networks as perspectives, researchers need to map dimensions of variation in a given domain to network-modeling decisions and network-metric parameters. While this remains a challenging and inherently interdisciplinary task, our work acts as a blueprint to facilitate the broader adoption of Network Pluralism in domain-driven network research.</description>
      <guid isPermaLink="false">oai:arXiv.org:2512.05679v1</guid>
      <category>cs.SI</category>
      <category>cs.CY</category>
      <category>physics.soc-ph</category>
      <pubDate>Mon, 08 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Titus P\"under, Corinna Coupette</dc:creator>
    </item>
    <item>
      <title>Heard or Halted? Gender, Interruptions, and Emotional Tone in U.S. Supreme Court Oral Arguments</title>
      <link>https://arxiv.org/abs/2512.05832</link>
      <description>arXiv:2512.05832v1 Announce Type: cross 
Abstract: This study examines how interruptions during U.S. Supreme Court oral arguments shape both the semantic content and emotional tone of advocates' speech, with a focus on gendered dynamics in judicial discourse. Using the ConvoKit Supreme Court Corpus (2010-2019), we analyze 12,663 speech chunks from advocate-justice interactions to assess whether interruptions alter the meaning of an advocate's argument and whether interruptions toward female advocates exhibit more negative emotional valence. Semantic shifts are quantified using GloVe-based sentence embeddings, while sentiment is measured through lexicon-based analysis. We find that semantic similarity between pre- and post-interruption speech remains consistently high, suggesting that interruptions do not substantially alter argumentative content. However, interruptions directed at female advocates contain significantly higher levels of negative sentiment. These results deepen empirical understanding of gendered communication in elite institutional settings and demonstrate the value of computational linguistic methods for studying power, discourse, and equity in judicial proceedings.</description>
      <guid isPermaLink="false">oai:arXiv.org:2512.05832v1</guid>
      <category>cs.CL</category>
      <category>cs.CY</category>
      <pubDate>Mon, 08 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Yifei Tong</dc:creator>
    </item>
    <item>
      <title>Rolling in the deep of cognitive and AI biases</title>
      <link>https://arxiv.org/abs/2407.21202</link>
      <description>arXiv:2407.21202v2 Announce Type: replace-cross 
Abstract: Nowadays, we delegate many of our decisions to Artificial Intelligence (AI) that acts either in solo or as a human companion in decisions made to support several sensitive domains, like healthcare, financial services and law enforcement. AI systems, even carefully designed to be fair, are heavily criticized for delivering misjudged and discriminated outcomes against individuals and groups. Numerous work on AI algorithmic fairness is devoted on Machine Learning pipelines which address biases and quantify fairness under a pure computational view. However, the continuous unfair and unjust AI outcomes, indicate that there is urgent need to understand AI as a sociotechnical system, inseparable from the conditions in which it is designed, developed and deployed. Although, the synergy of humans and machines seems imperative to make AI work, the significant impact of human and societal factors on AI bias is currently overlooked. We address this critical issue by following a radical new methodology under which human cognitive biases become core entities in our AI fairness overview. Inspired by the cognitive science definition and taxonomy of human heuristics, we identify how harmful human actions influence the overall AI lifecycle, and reveal human to AI biases hidden pathways. We introduce a new mapping, which justifies the human heuristics to AI biases reflections and we detect relevant fairness intensities and inter-dependencies. We envision that this approach will contribute in revisiting AI fairness under deeper human-centric case studies, revealing hidden biases cause and effects.</description>
      <guid isPermaLink="false">oai:arXiv.org:2407.21202v2</guid>
      <category>cs.AI</category>
      <category>cs.CY</category>
      <pubDate>Mon, 08 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Athena Vakali, Nicoleta Tantalaki</dc:creator>
    </item>
    <item>
      <title>Relational Dissonance in Human-AI Interactions: The Case of Knowledge Work</title>
      <link>https://arxiv.org/abs/2509.15836</link>
      <description>arXiv:2509.15836v2 Announce Type: replace-cross 
Abstract: When AI systems allow human-like communication, they elicit increasingly complex relational responses. Knowledge workers face a particular challenge: They approach these systems as tools while interacting with them in ways that resemble human social interaction. To understand the relational contexts that arise when humans engage with anthropomorphic conversational agents, we need to expand existing human-computer interaction frameworks. Through three workshops with qualitative researchers, we found that the fundamental ontological and relational ambiguities inherent in anthropomorphic conversational agents make it difficult for individuals to maintain consistent relational stances toward them. Our findings indicate that people's articulated positioning toward such agents often differs from the relational dynamics that occur during interactions. We propose the concept of relational dissonance to help researchers, designers, and policymakers recognize the resulting tensions in the development, deployment, and governance of anthropomorphic conversational agents and address the need for relational transparency.</description>
      <guid isPermaLink="false">oai:arXiv.org:2509.15836v2</guid>
      <category>cs.HC</category>
      <category>cs.CY</category>
      <pubDate>Mon, 08 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Emrecan Gulay, Eleonora Picco, Enrico Glerean, Corinna Coupette</dc:creator>
    </item>
    <item>
      <title>Exploring ChatGPT's Capabilities, Stability, Potential and Risks in Conducting Psychological Counseling through Simulations in School Counseling</title>
      <link>https://arxiv.org/abs/2511.01788</link>
      <description>arXiv:2511.01788v2 Announce Type: replace-cross 
Abstract: This study explores ChatGPT's capabilities, stability, and risks in simulating psychological counseling sessions in a school counseling context. Using scripted role-plays between a human counselor and an AI client, we examine how a large language model performs core counseling skills such as empathy, reflection, summarizing, and asking open-ended questions, as well as its ability to maintain therapeutic communication over time. We focus on how consistently ChatGPT can behave like a "virtual client" for school counselors in training, and how its responses might support or disrupt counselor skill development, supervision, and practice. At the same time, we analyze potential risks, including inaccurate or unsafe suggestions, over-compliance with counselor prompts, and the illusion of a competent therapist where no real professional judgment exists. The findings suggest that ChatGPT can serve as a low-cost, always-available training tool for practicing counseling techniques and interviewing skills in education and mental health settings, but it should not be viewed as a replacement for a human therapist or school counselor. We propose practical guidelines for educators, supervisors, and researchers who wish to use ChatGPT or similar LLM-based conversational agents in counseling training, highlighting how to leverage its potential while managing ethical, pedagogical, and psychological risks.</description>
      <guid isPermaLink="false">oai:arXiv.org:2511.01788v2</guid>
      <category>cs.HC</category>
      <category>cs.CY</category>
      <pubDate>Mon, 08 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <arxiv:DOI>10.1108/MHDT-02-2025-0013</arxiv:DOI>
      <arxiv:journal_reference>Mental Health and Digital Technologies, 2025</arxiv:journal_reference>
      <dc:creator>Yang Ni, Yanzhuo Cao</dc:creator>
    </item>
    <item>
      <title>A Longitudinal Study on the Attitudes of Gay Men in Beijing Towards Gay Social Media Platforms: Lonely Souls in the Digital Concrete Jungle</title>
      <link>https://arxiv.org/abs/2511.14174</link>
      <description>arXiv:2511.14174v3 Announce Type: replace-cross 
Abstract: Over the past decade, specialized social networking applications have become a cornerstone of life for many gay men in China. This paper employs a longitudinal mixed-methods approach to investigate how Chinese men who have sex with men (MSM) have shifted their attitudes toward these platforms between approximately 2013 and 2023. Drawing on archival analysis of online discourses, a quantitative survey of 412 participants, and in-depth semi-structured interviews with 32 participants, we trace the complex trajectory of this evolution. Our findings reveal a clear pattern: from the initial embrace of these applications as revolutionary tools for community building and identity affirmation (2014--2017), to a period of growing ambivalence and critique centered on commercialization, ``hookup culture,'' and multiple forms of discrimination (2017--2020), and finally to the present era (2020--2023), characterized by pragmatic, fragmented, yet simultaneously critical and reconstructive uses. Today, users strategically employ a repertoire of applications -- including global platforms (e.g., Grindr and Tinder), domestic mainstream platforms (e.g., Blued), and niche alternatives (e.g., Aloha) -- to fulfill differentiated needs. We develop a detailed temporal framework to capture this attitudinal evolution and discuss its design implications for creating more supportive, secure, and community-oriented digital environments for marginalized groups.</description>
      <guid isPermaLink="false">oai:arXiv.org:2511.14174v3</guid>
      <category>cs.HC</category>
      <category>cs.CY</category>
      <pubDate>Mon, 08 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Yibo Meng, Xiaolan Ding, Lyumanshan Ye, Zhiming Liu, Yan Guan</dc:creator>
    </item>
  </channel>
</rss>
