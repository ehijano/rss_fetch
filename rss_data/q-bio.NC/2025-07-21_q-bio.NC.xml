<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>q-bio.NC updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/q-bio.NC</link>
    <description>q-bio.NC updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/q-bio.NC" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Tue, 22 Jul 2025 04:00:22 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Tue, 22 Jul 2025 00:00:00 -0400</pubDate>
    <skipDays>
      <day>Saturday</day>
      <day>Sunday</day>
    </skipDays>
    <item>
      <title>Predicting Perceptual Boundaries in Auditory Streaming using Delay Differential Equations</title>
      <link>https://arxiv.org/abs/2507.14157</link>
      <description>arXiv:2507.14157v1 Announce Type: new 
Abstract: Auditory streaming enables the brain to organize sequences of sounds into perceptually distinct sources, such as following a conversation in a noisy environment. A typical experiment for investigating perceptual boundaries and bistability is to present a subject with a stream containing two alternating tone stimuli. We investigate a model for the processing of such a stream consisting of two identical neural populations of excitatory and inhibitory neurons. The populations are coupled via delayed cross-inhibition and periodically forced with sharp step-type signals (the two-tone stream). We track how the perception boundary depends on threshold selection and establish how boundaries between three different auditory perceptions (single tone versus two tones versus bistability between both perceptions) relate to bifurcations such as symmetry breaking. We demonstrate that these transitions are governed by symmetry-breaking bifurcations and that the perceptual classification based on neural thresholds is highly sensitive to threshold choice. Our analysis reveals that a fixed threshold is insufficient to capture the true perceptual boundaries and proposes a variable-threshold criterion, informed by the amplitude dynamics of neural responses. Finally, we illustrate how key stimulus parameters such as tone duration, delay, and internal time scale shape the boundaries of auditory perceptual organization in the plane of the two most commonly varied experimental parameters, the representation rate, and the difference in tone frequency. These findings offer mechanistic insight into auditory perception dynamics and provide a refined framework for linking neural activity to perceptual organization.</description>
      <guid isPermaLink="false">oai:arXiv.org:2507.14157v1</guid>
      <category>q-bio.NC</category>
      <pubDate>Tue, 22 Jul 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Asim Alawfi, Farzaneh Darki, Jan Sieber</dc:creator>
    </item>
    <item>
      <title>Modeling Language Evolution Using a Spin Glass Approach</title>
      <link>https://arxiv.org/abs/2507.14375</link>
      <description>arXiv:2507.14375v1 Announce Type: new 
Abstract: The evolution of natural languages poses a riddle to any theoretical perspective based on efficiency considerations. If languages are already optimally effective means of organization and communication of thought, why do they change? And if they are driven to become optimally effective in the future, why do they change so slowly, and why do they diversify, rather than converge towards an optimum? We look here at the hypothesis that disorder, rather than efficiency, may play a dominant role. Most traditional approaches to study diachronic language dynamics emphasize lexical data, but a crucial contribution to the effectiveness of a thought-coding device is given by its core structure, its syntax. Based on the reduction of syntax to a set of binary parameters, we introduce here a model of natural language change in which diachronic dynamics are mediated by disordered interactions between parameters, even in the idealized limit of identical external inputs. We show in which region of `phase space' such dynamics show the glassy features that are observed in natural languages. In particular, syntactic vectors remain trapped in glassy metastable (tendentially stable) states when the degree of asymmetry in the disordered interactions is below a critical value, consistent with studies of spin glasses with asymmetric interactions. We further show that an added Hopfield-type memory term, would indeed, if strong enough, stabilize syntactic configurations even above the critical value, but losing the multiplicity of stable states. Finally, using a notion of linguistic distance in syntactic space we show that a phylogenetic signal may remain among related languages, despite their gradually divergent syntax, exactly as recently pointed out for real-world languages. These statistical results appear to generalize beyond the dataset of 94 syntactic parameters across 58 languages, used in this study.</description>
      <guid isPermaLink="false">oai:arXiv.org:2507.14375v1</guid>
      <category>q-bio.NC</category>
      <pubDate>Tue, 22 Jul 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Hediye Yarahmadi, Giuseppe Longobardi, Alessandro Treves</dc:creator>
    </item>
    <item>
      <title>Baseline behaviour in human vision</title>
      <link>https://arxiv.org/abs/2507.14573</link>
      <description>arXiv:2507.14573v1 Announce Type: new 
Abstract: Humans perceive their visual environment by directing their eyes towards relevant objects. The deployment of visual attention depends substantially on the stimulus's properties, higher cognitive processes, and biases and constraints of the visual system. Numerous models describe people's eye movements depending on the performed task or the viewed content. However, there is no universal, context-invariant model of human gaze behaviour. Here we show that statistical regularities can be utilised to model human gaze behaviour regardless of task, observer, and content. Using a context-agnostic eye movement model, we were able to describe human gaze behaviour better than a uniform random model in various viewing situations. Using a fixed transition kernel, the model can describe gaze patterns during reading, visual search, and scene perception, as well as for both adults and children. Thus, contrary to current belief, human gaze patterns follow a baseline behaviour, making them comparable across contexts. Since gaze behaviour is directly related to brain structure, our results provide the first evidence for the existence of an underlying, context-invariant motor prior in the human visual system.</description>
      <guid isPermaLink="false">oai:arXiv.org:2507.14573v1</guid>
      <category>q-bio.NC</category>
      <pubDate>Tue, 22 Jul 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Thomas Fabian</dc:creator>
    </item>
    <item>
      <title>The Role of Excitatory Parvalbumin-positive Neurons in the Tectofugal Pathway of Pigeon (Columba livia) Hierarchical Visual Processing</title>
      <link>https://arxiv.org/abs/2507.15486</link>
      <description>arXiv:2507.15486v1 Announce Type: new 
Abstract: The visual systems of birds and mammals exhibit remarkable organizational similarities: the dorsal ventricular ridge (DVR) demonstrates a columnar microcircuitry that parallels the cortical architecture observed in mammals. However, the specific neuronal subtypes involved and their functional roles in pigeon hierarchical visual processing remain unclear. This study investigates the role of excitatory parvalbumin (PV+) neurons within the Ento-MVL (entoallium-mesopallium venterolaterale) circuit of pigeons underlying hierarchical moving target recognition. Electrophysiological recordings and immunofluorescence staining reveal that excitatory PV+ neurons originating from the entopallial internal (Ei) predominantly modulate MVL responses to varying visual stimuli. Using a heterochronous-speed recurrent neural network (HS-RNN) model, we further validated these dynamics, replicating the rapid adaptation of the Ento-MVL circuit to moving visual targets. The findings suggest that the fast-spiking and excitatory properties of PV+ neurons enable rapid processing of motion-related information within the Ento-MVL circuit. Our results elucidate the functional role of excitatory PV+ neurons in hierarchical information processing under the columnar organization of the visual DVR and underscore the convergent neural processing strategies shared by avian and mammalian visual systems.</description>
      <guid isPermaLink="false">oai:arXiv.org:2507.15486v1</guid>
      <category>q-bio.NC</category>
      <category>cs.NE</category>
      <pubDate>Tue, 22 Jul 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Shan Lu, Xiaoteng Zhang, Yueyang Cang, Shihao Pan, Yanyan Peng, Xinwei Li, Shaoju Zeng, Yingjie Zhu, Li Shi</dc:creator>
    </item>
    <item>
      <title>Switching States: Heteroclinic Cycles as Organising Centres of Neuronal Dynamics</title>
      <link>https://arxiv.org/abs/2507.15519</link>
      <description>arXiv:2507.15519v1 Announce Type: new 
Abstract: Neuronal networks alternate between high- and low-activity regimes, known as up and down states. They also display rhythmic patterns essential for perception, memory consolidation, and sensory processing. Despite their importance, the principles behind such state transitions remain elusive. We propose necessary conditions for the existence of a novel bifurcation structure as a universal organising centre governing these transitions. Bifurcation analysis and simulations of canonical mean-field network models, including Wilson--Cowan, Tsodyks--Markram, and Jansen--Rit frameworks, show that this bifurcation structure emerges robustly across models. We demonstrate that the interplay between external input and (synaptic) connectivity converges onto this shared mechanism, providing a fundamental principle for understanding how diverse brain states arise and are regulated. Beyond phenomenological mean-field models, we show that a shared mathematical structure of nonlinear input-output relationships, rather than model-specific details, preserves the organising centre across frameworks, revealing a general mechanism for dynamic state transitions.</description>
      <guid isPermaLink="false">oai:arXiv.org:2507.15519v1</guid>
      <category>q-bio.NC</category>
      <category>math.DS</category>
      <pubDate>Tue, 22 Jul 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Kateryna Nechyporenko, Peter Ashwin, Krasimira Tsaneva-Atanasova</dc:creator>
    </item>
    <item>
      <title>Brain rhythms in cognition -- controversies and future directions</title>
      <link>https://arxiv.org/abs/2507.15639</link>
      <description>arXiv:2507.15639v1 Announce Type: new 
Abstract: Brain rhythms seem central to understanding the neurophysiological basis of human cognition. Yet, despite significant advances, key questions remain unresolved. In this comprehensive position paper, we review the current state of the art on oscillatory mechanisms and their cognitive relevance. The paper critically examines physiological underpinnings, from phase-related dynamics like cyclic excitability, to amplitude-based phenomena, such as gating by inhibition, and their interactions, such as phase-amplitude coupling, as well as frequency dynamics, like sampling mechanisms. We also critically evaluate future research directions, including travelling waves and brain-body interactions. We then provide an in-depth analysis of the role of brain rhythms across cognitive domains, including perception, attention, memory, and communication, emphasising ongoing debates and open questions in each area. By summarising current theories and highlighting gaps, this position paper offers a roadmap for future research, aimed at facilitating a unified framework of rhythmic brain function underlying cognition.</description>
      <guid isPermaLink="false">oai:arXiv.org:2507.15639v1</guid>
      <category>q-bio.NC</category>
      <pubDate>Tue, 22 Jul 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Anne Keitel, Christian Keitel, Mohsen Alavash, Karin Bakardjian, Christopher S. Y. Benwell, Sophie Bouton, Niko A. Busch, Antonio Criscuolo, Keith B. Doelling, Laura Dugue, Laetitia Grabot, Joachim Gross, Simon Hanslmayr, Laura-Isabelle Klatt, Daniel S. Kluger, Gemma Learmonth, Raquel E. London, Christina Lubinus, Andrea E. Martin, Jonas Obleser, Johanna M. Rimmele, Vincenzo Romei, Manuela Ruzzoli, Felix Siebenhuhner, Sophie Slaats, Eelke Spaak, Luca Tarasi, Gregor Thut, Jelena Trajkovic, Danying Wang, Malte Wostmann, Benedikt Zoefel, Satu Palva, Paul Sauseng, Sonja A. Kotz</dc:creator>
    </item>
    <item>
      <title>Ubiquity of Uncertainty in Neuron Systems</title>
      <link>https://arxiv.org/abs/2507.15702</link>
      <description>arXiv:2507.15702v1 Announce Type: new 
Abstract: We demonstrate that final-state uncertainty is ubiquitous in multistable systems of coupled neuronal maps, meaning that predicting whether one such system will eventually be chaotic or nonchaotic is often nearly impossible. We propose a "chance synchronization" mechanism that governs the emergence of unpredictability in neuron systems and support it by using basin classification, uncertainty exponent, and basin entropy techniques to analyze five simple discrete-time systems, each consisting of a different neuron model. Our results illustrate that uncertainty in neuron systems is not just a product of noise or high-dimensional complexity; it is also a fundamental property of low-dimensional, deterministic models, which has profound implications for understanding brain function, modeling cognition, and interpreting unpredictability in general multistable systems.</description>
      <guid isPermaLink="false">oai:arXiv.org:2507.15702v1</guid>
      <category>q-bio.NC</category>
      <category>math.DS</category>
      <category>nlin.CD</category>
      <category>physics.bio-ph</category>
      <pubDate>Tue, 22 Jul 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Brandon B. Le, Bennett Lamb, Luke Benfer, Sriharsha Sambangi, Nisal Geemal Vismith, Akshaj Jagarapu</dc:creator>
    </item>
    <item>
      <title>Dissociating model architectures from inference computations</title>
      <link>https://arxiv.org/abs/2507.15776</link>
      <description>arXiv:2507.15776v1 Announce Type: new 
Abstract: Parr et al., 2025 examines how auto-regressive and deep temporal models differ in their treatment of non-Markovian sequence modelling. Building on this, we highlight the need for dissociating model architectures, i.e., how the predictive distribution factorises, from the computations invoked at inference. We demonstrate that deep temporal computations are mimicked by autoregressive models by structuring context access during iterative inference. Using a transformer trained on next-token prediction, we show that inducing hierarchical temporal factorisation during iterative inference maintains predictive capacity while instantiating fewer computations. This emphasises that processes for constructing and refining predictions are not necessarily bound to their underlying model architectures.</description>
      <guid isPermaLink="false">oai:arXiv.org:2507.15776v1</guid>
      <category>q-bio.NC</category>
      <category>cs.CL</category>
      <category>cs.LG</category>
      <pubDate>Tue, 22 Jul 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <arxiv:DOI>10.1080/17588928.2025.2532604</arxiv:DOI>
      <arxiv:journal_reference>Cognitive Neuroscience PCNS 2025</arxiv:journal_reference>
      <dc:creator>Noor Sajid, Johan Medrano</dc:creator>
    </item>
    <item>
      <title>Biological detail and graph structure in network neuroscience</title>
      <link>https://arxiv.org/abs/2507.15789</link>
      <description>arXiv:2507.15789v1 Announce Type: new 
Abstract: Endowing brain anatomy, dynamics, and function with a network structure is becoming standard in neuroscience. In its simplest form, a network is a collection of units and relationships between them. The pattern of relations among the units encodes numerous properties which have been shown to have a profound effect on networked systems' dynamics and function. In an effort to strike a balance between idealization and detail, network neuroscience studies typically involve simplifying assumptions at both neural and network modeling levels. However, the extent to which existing neural models depend on such approximations is as yet poorly understood. Here, we discuss whether and how increasing neurophysiological detail and generalizing the basic simple network structure often adopted in network neuroscience may help improve our understanding of brain phenomenology and function.</description>
      <guid isPermaLink="false">oai:arXiv.org:2507.15789v1</guid>
      <category>q-bio.NC</category>
      <category>physics.bio-ph</category>
      <pubDate>Tue, 22 Jul 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>David Papo, Javier M. Buld\'u</dc:creator>
    </item>
    <item>
      <title>Graph Convolutional Neural Networks to Model the Brain for Insomnia</title>
      <link>https://arxiv.org/abs/2507.14147</link>
      <description>arXiv:2507.14147v1 Announce Type: cross 
Abstract: Insomnia affects a vast population of the world and can have a wide range of causes. Existing treatments for insomnia have been linked with many side effects like headaches, dizziness, etc. As such, there is a clear need for improved insomnia treatment. Brain modelling has helped with assessing the effects of brain pathology on brain network dynamics and with supporting clinical decisions in the treatment of Alzheimer's disease, epilepsy, etc. However, such models have not been developed for insomnia. Therefore, this project attempts to understand the characteristics of the brain of individuals experiencing insomnia using continuous long-duration EEG data. Brain networks are derived based on functional connectivity and spatial distance between EEG channels. The power spectral density of the channels is then computed for the major brain wave frequency bands. A graph convolutional neural network (GCNN) model is then trained to capture the functional characteristics associated with insomnia and configured for the classification task to judge performance. Results indicated a 50-second non-overlapping sliding window was the most suitable choice for EEG segmentation. This approach achieved a classification accuracy of 70% at window level and 68% at subject level. Additionally, the omission of EEG channels C4-P4, F4-C4 and C4-A1 caused higher degradation in model performance than the removal of other channels. These channel electrodes are positioned near brain regions known to exhibit atypical levels of functional connectivity in individuals with insomnia, which can explain such results.</description>
      <guid isPermaLink="false">oai:arXiv.org:2507.14147v1</guid>
      <category>eess.SP</category>
      <category>cs.LG</category>
      <category>q-bio.NC</category>
      <pubDate>Tue, 22 Jul 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Kevin Monteiro, Sam Nallaperuma-Herzberg, Martina Mason, Steve Niederer</dc:creator>
    </item>
    <item>
      <title>The content and structure of dreams are coupled to affect</title>
      <link>https://arxiv.org/abs/2409.14279</link>
      <description>arXiv:2409.14279v2 Announce Type: replace 
Abstract: Dreams offer a unique window into the cognitive and affective dynamics of the sleeping and the waking mind. Recent quantitative linguistic approaches have shown promise in obtaining corpus-level measures of dream sentiment and topic occurrence. However, it is currently unclear how the affective content of individual dreams relates to their semantic content and structure. Here, we combine word embedding, topic modeling, and network analysis to investigate this relationship. By applying Discourse Atom Topic Modeling (DATM) to the DreamBank corpus of &gt;18K dream reports, we represent the latent themes arising within dream reports as a sparse dictionary of topics and identify the affective associations of those topics. We show that variation in dream report affect (valence and arousal) is associated with changes in topical content. By representing each dream report as a network of topics, we demonstrate that the affective content of dream narratives is also coupled to semantic structure. Positively valenced dream reports exhibit more coherent, structured, and linear narratives, whilst negatively valenced dreams have more narrative loops and dominant topics. Topic networks of high arousal dream reports are structurally dominated by few high arousal topics and incoherent topical connections, whereas low arousal dream reports contain more loops. These findings suggest that affective processes are associated with both the content and structure of dreams. Our approach showcases the potential of integrating natural language processing and network analysis with psychology to elucidate the interplay of affect, cognition and narrative in dreams. This methodology has broad applications for the study of narrated experience and psychiatric symptomatology.</description>
      <guid isPermaLink="false">oai:arXiv.org:2409.14279v2</guid>
      <category>q-bio.NC</category>
      <pubDate>Tue, 22 Jul 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Luke Leckie, Anya K. Bershad, Jes Heppler, Mason McClay, Sofiia Rappe, Jacob G. Foster</dc:creator>
    </item>
    <item>
      <title>BrainNetMLP: An Efficient and Effective Baseline for Functional Brain Network Classification</title>
      <link>https://arxiv.org/abs/2505.11538</link>
      <description>arXiv:2505.11538v2 Announce Type: replace 
Abstract: Recent studies have made great progress in functional brain network classification by modeling the brain as a network of Regions of Interest (ROIs) and leveraging their connections to understand brain functionality and diagnose mental disorders. Various deep learning architectures, including Convolutional Neural Networks, Graph Neural Networks, and the recent Transformer, have been developed. However, despite the increasing complexity of these models, the performance gain has not been as salient. This raises a question: Does increasing model complexity necessarily lead to higher classification accuracy? In this paper, we revisit the simplest deep learning architecture, the Multi-Layer Perceptron (MLP), and propose a pure MLP-based method, named BrainNetMLP, for functional brain network classification, which capitalizes on the advantages of MLP, including efficient computation and fewer parameters. Moreover, BrainNetMLP incorporates a dual-branch structure to jointly capture both spatial connectivity and spectral information, enabling precise spatiotemporal feature fusion. We evaluate our proposed BrainNetMLP on two public and popular brain network classification datasets, the Human Connectome Project (HCP) and the Autism Brain Imaging Data Exchange (ABIDE). Experimental results demonstrate pure MLP-based methods can achieve state-of-the-art performance, revealing the potential of MLP-based models as more efficient yet effective alternatives in functional brain network classification. The code will be available at https://github.com/JayceonHo/BrainNetMLP.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.11538v2</guid>
      <category>q-bio.NC</category>
      <category>cs.CV</category>
      <pubDate>Tue, 22 Jul 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Jiacheng Hou, Zhenjie Song, Ercan Engin Kuruoglu</dc:creator>
    </item>
    <item>
      <title>CNeuroMod-THINGS, a densely-sampled fMRI dataset for visual neuroscience</title>
      <link>https://arxiv.org/abs/2507.09024</link>
      <description>arXiv:2507.09024v2 Announce Type: replace 
Abstract: Data-hungry neuro-AI modelling requires ever larger neuroimaging datasets. CNeuroMod-THINGS meets this need by capturing neural representations for a wide set of semantic concepts using well-characterized images in a new densely-sampled, large-scale fMRI dataset. Importantly, CNeuroMod-THINGS exploits synergies between two existing projects: the THINGS initiative (THINGS) and the Courtois Project on Neural Modelling (CNeuroMod). THINGS has developed a common set of thoroughly annotated images broadly sampling natural and man-made objects which is used to acquire a growing collection of large-scale multimodal neural responses. Meanwhile, CNeuroMod is acquiring hundreds of hours of fMRI data from a core set of participants during controlled and naturalistic tasks, including visual tasks like movie watching and videogame playing. For CNeuroMod-THINGS, four CNeuroMod participants each completed 33-36 sessions of a continuous recognition paradigm using approximately 4000 images from the THINGS stimulus set spanning 720 categories. We report behavioural and neuroimaging metrics that showcase the quality of the data. By bridging together large existing resources, CNeuroMod-THINGS expands our capacity to model broad slices of the human visual experience.</description>
      <guid isPermaLink="false">oai:arXiv.org:2507.09024v2</guid>
      <category>q-bio.NC</category>
      <category>cs.CV</category>
      <pubDate>Tue, 22 Jul 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/publicdomain/zero/1.0/</dc:rights>
      <dc:creator>Marie St-Laurent, Basile Pinsard, Oliver Contier, Elizabeth DuPre, Katja Seeliger, Valentina Borghesani, Julie A. Boyle, Lune Bellec, Martin N. Hebart</dc:creator>
    </item>
  </channel>
</rss>
