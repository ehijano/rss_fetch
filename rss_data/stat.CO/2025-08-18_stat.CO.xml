<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>stat.CO updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/stat.CO</link>
    <description>stat.CO updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/stat.CO" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Tue, 19 Aug 2025 02:09:15 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Mon, 18 Aug 2025 00:00:00 -0400</pubDate>
    <skipDays>
      <day>Saturday</day>
      <day>Sunday</day>
    </skipDays>
    <item>
      <title>Importance Sampling Approximation of Sequence Evolution Models with Site-Dependence</title>
      <link>https://arxiv.org/abs/2508.11461</link>
      <description>arXiv:2508.11461v1 Announce Type: new 
Abstract: We consider models for molecular sequence evolution in which the transition rates at each site depend on the local sequence context, giving rise to a time-inhomogeneous Markov process in which sites evolve under a complex dependency structure. We introduce a randomized approximation algorithm for the marginal sequence likelihood under these models using importance sampling, and provide matching order upper and lower bounds on the finite sample approximation error. Given two sequences of length $n$ with $r$ observed mutations, we show that for practical regimes of $r/n$, the complexity of the importance sampler does not grow exponentially $n$, but rather in $r$, making the algorithm practical for many applied problems. We demonstrate the use of our techniques to obtain problem-specific complexity bounds for a well-known dependent-site model from the phylogenetics literature.</description>
      <guid isPermaLink="false">oai:arXiv.org:2508.11461v1</guid>
      <category>stat.CO</category>
      <category>math.PR</category>
      <pubDate>Mon, 18 Aug 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Joseph Mathews, Scott C. Schmidler</dc:creator>
    </item>
    <item>
      <title>MDNS: Masked Diffusion Neural Sampler via Stochastic Optimal Control</title>
      <link>https://arxiv.org/abs/2508.10684</link>
      <description>arXiv:2508.10684v1 Announce Type: cross 
Abstract: We study the problem of learning a neural sampler to generate samples from discrete state spaces where the target probability mass function $\pi\propto\mathrm{e}^{-U}$ is known up to a normalizing constant, which is an important task in fields such as statistical physics, machine learning, combinatorial optimization, etc. To better address this challenging task when the state space has a large cardinality and the distribution is multi-modal, we propose $\textbf{M}$asked $\textbf{D}$iffusion $\textbf{N}$eural $\textbf{S}$ampler ($\textbf{MDNS}$), a novel framework for training discrete neural samplers by aligning two path measures through a family of learning objectives, theoretically grounded in the stochastic optimal control of the continuous-time Markov chains. We validate the efficiency and scalability of MDNS through extensive experiments on various distributions with distinct statistical properties, where MDNS learns to accurately sample from the target distributions despite the extremely high problem dimensions and outperforms other learning-based baselines by a large margin. A comprehensive study of ablations and extensions is also provided to demonstrate the efficacy and potential of the proposed framework.</description>
      <guid isPermaLink="false">oai:arXiv.org:2508.10684v1</guid>
      <category>cs.LG</category>
      <category>math.OC</category>
      <category>stat.CO</category>
      <category>stat.ML</category>
      <pubDate>Mon, 18 Aug 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Yuchen Zhu, Wei Guo, Jaemoo Choi, Guan-Horng Liu, Yongxin Chen, Molei Tao</dc:creator>
    </item>
    <item>
      <title>Two-Sample Testing with Missing Data via Energy Distance: Weighting and Imputation Approaches</title>
      <link>https://arxiv.org/abs/2508.11421</link>
      <description>arXiv:2508.11421v1 Announce Type: cross 
Abstract: In this paper, we address the problem of two-sample testing in the presence of missing data under a variety of missingness mechanisms. Our focus is on the well-known energy distance-based two-sample test. In addition to the standard complete-case approach, we propose a modification of the test statistic that incorporates all available data, utilizing appropriate weights. The asymptotic null distribution of the test statistic is derived and two resampling procedures for approximating the corresponding p-values are proposed. We also propose a new bootstrap method specifically designed for a test statistic based on samples completed via common imputation methods. Through an extensive simulation study, we compare all methods in terms of type I error control and statistical power across a set of sample sizes, dimensions, distributions, missingness mechanisms, and missingness rates. Based on these results, we provide general recommendations for each considered scenario.</description>
      <guid isPermaLink="false">oai:arXiv.org:2508.11421v1</guid>
      <category>stat.ME</category>
      <category>math.ST</category>
      <category>stat.CO</category>
      <category>stat.TH</category>
      <pubDate>Mon, 18 Aug 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Danijel G. Aleksi\'c, Bojana Milo\v{s}evi\'c</dc:creator>
    </item>
    <item>
      <title>Simulation-based inference using splitting schemes for partially observed diffusions in chemical reaction networks</title>
      <link>https://arxiv.org/abs/2508.11438</link>
      <description>arXiv:2508.11438v1 Announce Type: cross 
Abstract: We address the problem of simulation and parameter inference for chemical reaction networks described by the chemical Langevin equation, a stochastic differential equation (SDE) representation of the dynamics of the chemical species. This is challenging for two main reasons. First, the (multi-dimensional) SDEs cannot be explicitly solved and are driven by multiplicative and non-commutative noise, requiring the development of advanced numerical schemes for their approximation and simulation. Second, not all components of the SDEs are directly observed, as the available discrete-time data are typically incomplete and/or perturbed with measurement error. We tackle these issues via three contributions. First, we show that these models can be rewritten as perturbed conditionally Cox-Ingersoll-Ross-type SDEs, i.e., each coordinate, conditioned on all other coordinates being fixed, follows an SDE with linear drift and square root diffusion coefficient perturbed by additional Brownian motions. Second, for this class of SDEs, we develop a numerical splitting scheme that preserves structural properties of the model, such as oscillations, state space and invariant distributions, unlike the commonly used Euler-Maruyama scheme. Our numerical method is robust for large integration time steps. Third, we propose a sequential Monte Carlo approximate Bayesian computation algorithm incorporating "data-conditional" simulation and sequential learning of summary statistics, allowing inference for multidimensional partially observed systems, further developing previous results on fully observed systems based on the Euler-Maruyama scheme. We validate our approach on models of interest in chemical reaction networks, such as the stochastic Repressilator, Lotka-Volterra, and two-pool systems, demonstrating its effectiveness, in terms of both numerical and inferential accuracy, and reduced computational cost.</description>
      <guid isPermaLink="false">oai:arXiv.org:2508.11438v1</guid>
      <category>stat.ME</category>
      <category>stat.CO</category>
      <pubDate>Mon, 18 Aug 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Petar Jovanovski, Andrew Golightly, Umberto Picchini, Massimiliano Tamborrino</dc:creator>
    </item>
    <item>
      <title>Differentiating Generalized Eigenvalues and Eigenvectors</title>
      <link>https://arxiv.org/abs/2508.09355</link>
      <description>arXiv:2508.09355v2 Announce Type: replace 
Abstract: We give formulae for first and second derivatives of generalized eigenvalues/eigenvectors of symmetric matrices and generalized singular values/singular vectors of rectangular matrices when the matrices are linear or nonlinear functions of a vector of parameters. In addition we provide functions in R to compute these derivatives, both in the general case and in various special cases. Formulae are checked against Jacobians and Hessians computed by numerical differentiation. Some applications to multivariate data analysis are discussed.</description>
      <guid isPermaLink="false">oai:arXiv.org:2508.09355v2</guid>
      <category>stat.CO</category>
      <pubDate>Mon, 18 Aug 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/publicdomain/zero/1.0/</dc:rights>
      <dc:creator>Jan de Leeuw</dc:creator>
    </item>
    <item>
      <title>Modeling Sampling Distributions of Test Statistics with Autograd</title>
      <link>https://arxiv.org/abs/2405.02488</link>
      <description>arXiv:2405.02488v3 Announce Type: replace-cross 
Abstract: Simulation-based inference methods that feature correct conditional coverage of confidence sets based on observations that have been compressed to a scalar test statistic require accurate modeling of either the p-value function or the cumulative distribution function (cdf) of the test statistic. If the model of the cdf, which is typically a deep neural network, is a function of the test statistic then the derivative of the neural network with respect to the test statistic furnishes an approximation of the sampling distribution of the test statistic. We explore whether this approach to modeling conditional 1-dimensional sampling distributions is a viable alternative to the probability density-ratio method, also known as the likelihood-ratio trick. Relatively simple, yet effective, neural network models are used whose predictive uncertainty is quantified through a variety of methods.</description>
      <guid isPermaLink="false">oai:arXiv.org:2405.02488v3</guid>
      <category>stat.ML</category>
      <category>cs.LG</category>
      <category>hep-ex</category>
      <category>stat.CO</category>
      <pubDate>Mon, 18 Aug 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Ali Al Kadhim, Harrison B. Prosper</dc:creator>
    </item>
  </channel>
</rss>
