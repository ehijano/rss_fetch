<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>cs.CE updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/cs.CE</link>
    <description>cs.CE updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/cs.CE" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Tue, 02 Dec 2025 05:00:42 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Tue, 02 Dec 2025 00:00:00 -0500</pubDate>
    <skipDays>
      <day>Sunday</day>
      <day>Saturday</day>
    </skipDays>
    <item>
      <title>Multi-Task Temporal Fusion Transformer for Joint Sales and Inventory Forecasting in Amazon E-Commerce Supply Chain</title>
      <link>https://arxiv.org/abs/2512.00370</link>
      <description>arXiv:2512.00370v1 Announce Type: new 
Abstract: Efficient inventory management and accurate sales forecasting are critical challenges in large-scale e-commerce platforms such as Amazon, where stockouts and overstocking can lead to substantial financial losses and operational inefficiencies. Traditional single-task forecasting models, which focus solely on sales or inventory, often fail to capture the complex temporal dependencies and cross-task interactions that characterize real-world supply chain dynamics. To address this limitation, this study proposes a Multi-Task Temporal Fusion Transformer (TFT-MTL) framework designed for joint sales and inventory forecasting within the Amazon e-commerce ecosystem. The model integrates heterogeneous data sources, including historical sales records, warehouse inventory levels, pricing, promotions, and event-driven factors such as holidays and Prime Day campaigns, through a unified deep learning architecture. A shared encoder captures long-term temporal patterns, while task-specific decoder heads predict sales volume, inventory turnover, and stockout probability simultaneously. Experiments on large-scale real-world datasets demonstrate that the proposed TFT-MTL model significantly outperforms baseline methods such as LSTM, GRU, and single-task TFT. Compared with the single-task TFT model, the proposed approach achieves a 6.2% reduction in Sales RMSE, a 12.7% decrease in Sales MAPE, a 6.4% reduction in Inventory RMSE, and a 12.4% decrease in Inventory MAPE. These results confirm the model's ability to effectively capture multi-dimensional dependencies across supply chain variables. The proposed framework provides an interpretable, data-driven decision support tool for optimizing Amazon's inventory scheduling and demand planning strategies.</description>
      <guid isPermaLink="false">oai:arXiv.org:2512.00370v1</guid>
      <category>cs.CE</category>
      <pubDate>Tue, 02 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Zheqi Hu, Yiwen Hu, Hanwu Li</dc:creator>
    </item>
    <item>
      <title>GPU-native Embedding of Complex Geometries in Adaptive Octree Grids Applied to the Lattice Boltzmann Method</title>
      <link>https://arxiv.org/abs/2512.01251</link>
      <description>arXiv:2512.01251v1 Announce Type: new 
Abstract: Adaptive mesh refinement (AMR) reduces computational costs in CFD by concentrating resolution where needed, but efficiently embedding complex, non-aligned geometries on GPUs remains challenging. We present a GPU-native algorithm for incorporating stationary triangle-mesh geometries into block-structured forest-of-octrees grids, performing both solid voxelization and automated near-wall refinement entirely on the device. The method employs local ray casting accelerated by a hierarchy of spatial bins, leveraging efficient grid-block traversal to eliminate the need for index orderings and hash tables commonly used in CPU pipelines, and enabling coalesced memory access without CPU-GPU synchronization. A flattened lookup table of cut-link distances between fluid and solid cells is constructed to support accurate interpolated bounce-back boundary conditions for the lattice Boltzmann method (LBM). We implement this approach as an extension of the AGAL framework for GPU-based AMR and benchmark the geometry module using the Stanford Bunny (112K triangles) and XYZ RGB Dragon (7.2M triangles) models from the Stanford 3D Scanning Repository. The extended solver is validated for external flows past a circular/square cylinder (2D, $Re = 100$), and a sphere (3D, $\text{Re}\in\{10, 15, 20\}$). Results demonstrate that geometry handling and interpolation impose modest overhead while delivering accurate force predictions and stable near-wall resolution on adaptive Cartesian grids. The approach is general and applicable to other explicit solvers requiring GPU-resident geometry embedding.</description>
      <guid isPermaLink="false">oai:arXiv.org:2512.01251v1</guid>
      <category>cs.CE</category>
      <category>physics.comp-ph</category>
      <category>physics.flu-dyn</category>
      <pubDate>Tue, 02 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Khodr Jaber, Ebenezer E. Essel, Pierre E. Sullivan</dc:creator>
    </item>
    <item>
      <title>Integrating Artificial Intelligence and Mixed Integer Linear Programming: Explainable Graph-Based Instance Space Analysis in Air Transportation</title>
      <link>https://arxiv.org/abs/2512.01698</link>
      <description>arXiv:2512.01698v1 Announce Type: new 
Abstract: This paper analyzes the integration of artificial intelligence (AI) with mixed integer linear programming (MILP) to address complex optimization challenges in air transportation with explainability. The study aims to validate the use of Graph Neural Networks (GNNs) for extracting structural feature embeddings from MILP instances, using the air05 crew scheduling problem. The MILP instance was transformed into a heterogeneous bipartite graph to model relationships between variables and constraints. Two neural architectures, Graph Convolutional Networks (GCN) and Graph Attention Networks (GAT) were trained to generate node embeddings. These representations were evaluated using Instance Space Analysis (ISA) through linear (PCA) and non-linear (UMAP, t-SNE) dimensionality reduction techniques. Analysis revealed that PCA failed to distinguish cluster structures, necessitating non-linear reductions to visualize the embedding topology. The GCN architecture demonstrated superior performance, capturing global topology with well-defined clusters for both variables and constraints. In contrast, the GAT model failed to organize the constraint space. The findings confirm that simpler graph architectures can effectively map the sparse topology of aviation logistics problems without manual feature engineering, contributing to explainability of instance complexity. This structural awareness provides a validated foundation for developing future Learning to Optimize (L2O) agents capable of improving solver performance in safety-critical environments.</description>
      <guid isPermaLink="false">oai:arXiv.org:2512.01698v1</guid>
      <category>cs.CE</category>
      <category>cs.NE</category>
      <category>math.OC</category>
      <pubDate>Tue, 02 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Artur Guerra Rosa, Felipe Tavares Loureiro, Marcus Vinicius Santos da Silva, Andr\'eia Elizabeth Silva Barros, Silvia Ara\'ujo dos Reis, Victor Rafael Rezende Celestino</dc:creator>
    </item>
    <item>
      <title>Doppler-Enhanced Deep Learning: Improving Thyroid Nodule Segmentation with YOLOv5 Instance Segmentation</title>
      <link>https://arxiv.org/abs/2512.00639</link>
      <description>arXiv:2512.00639v1 Announce Type: cross 
Abstract: The increasing prevalence of thyroid cancer globally has led to the development of various computer-aided detection methods. Accurate segmentation of thyroid nodules is a critical first step in the development of AI-assisted clinical decision support systems. This study focuses on instance segmentation of thyroid nodules using YOLOv5 algorithms on ultrasound images. We evaluated multiple YOLOv5 variants (Nano, Small, Medium, Large, and XLarge) across two dataset versions, with and without doppler images. The YOLOv5-Large algorithm achieved the highest performance with a dice score of 91\% and mAP of 0.87 on the dataset including doppler images. Notably, our results demonstrate that doppler images, typically excluded by physicians, can significantly improve segmentation performance. The YOLOv5-Small model achieved 79\% dice score when doppler images were excluded, while including them improved performance across all model variants. These findings suggest that instance segmentation with YOLOv5 provides an effective real-time approach for thyroid nodule detection, with potential clinical applications in automated diagnostic systems.</description>
      <guid isPermaLink="false">oai:arXiv.org:2512.00639v1</guid>
      <category>cs.CV</category>
      <category>cs.AI</category>
      <category>cs.CE</category>
      <category>cs.LG</category>
      <category>cs.PF</category>
      <pubDate>Tue, 02 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Mahmoud El Hussieni</dc:creator>
    </item>
    <item>
      <title>Finite Operator Learning: Bridging Neural Operators and Numerical Methods for Efficient Parametric Solution and Optimization of PDEs</title>
      <link>https://arxiv.org/abs/2407.04157</link>
      <description>arXiv:2407.04157v3 Announce Type: replace 
Abstract: We introduce a method that combines neural operators, physics-informed machine learning, and standard numerical methods for solving PDEs. The proposed approach extends each of the aforementioned methods and unifies them within a single framework. We can parametrically solve partial differential equations in a data-free manner and provide accurate sensitivities, meaning the derivatives of the solution space with respect to the design space. These capabilities enable gradient-based optimization without the typical sensitivity analysis costs, unlike adjoint methods that scale directly with the number of response functions. Our Finite Operator Learning (FOL) approach uses an uncomplicated feed-forward neural network model to directly map the discrete design space (i.e. parametric input space) to the discrete solution space (i.e. finite number of sensor points in the arbitrary shape domain) ensuring compliance with physical laws by designing them into loss functions. The discretized governing equations, as well as the design and solution spaces, can be derived from any well-established numerical techniques. In this work, we employ the Finite Element Method (FEM) to approximate fields and their spatial derivatives. Subsequently, we conduct Sobolev training to minimize a multi-objective loss function, which includes the discretized weak form of the energy functional, boundary conditions violations, and the stationarity of the residuals with respect to the design variables. Our study focuses on the steady-state heat equation within heterogeneous materials that exhibits significant phase contrast and possibly temperature-dependent conductivity. The network's tangent matrix is directly used for gradient-based optimization to improve the microstructure's heat transfer characteristics. ...</description>
      <guid isPermaLink="false">oai:arXiv.org:2407.04157v3</guid>
      <category>cs.CE</category>
      <category>cs.LG</category>
      <pubDate>Tue, 02 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Shahed Rezaei, Reza Najian Asl, Kianoosh Taghikhani, Ahmad Moeineddin, Michael Kaliske, Markus Apel</dc:creator>
    </item>
    <item>
      <title>Generative Optimization: A Perspective on AI-Enhanced Problem Solving in Engineering</title>
      <link>https://arxiv.org/abs/2412.13281</link>
      <description>arXiv:2412.13281v2 Announce Type: replace 
Abstract: The field of engineering is shaped by the tools and methods used to solve problems. Optimization is one such class of powerful, robust, and effective engineering tools proven over decades of use. Within just a few years, generative artificial intelligence (GenAI) has risen as another promising tool for general-purpose problem-solving. While optimization shines at precisely identifying highly-optimal solutions, GenAI excels at inferring problem requirements, bridging solution domains, handling mixed data modalities, and rapidly generating copious numbers of solutions. These differing attributes also make the two frameworks complementary. Hybrid `generative optimization' algorithms have gained traction across a few engineering applications and now comprise an emerging paradigm for engineering problem-solving. We expect significant developments in the near future around generative optimization, leading to changes in how engineers solve problems using computational tools. We offer our perspective on existing methods, areas of promise, and key research questions.</description>
      <guid isPermaLink="false">oai:arXiv.org:2412.13281v2</guid>
      <category>cs.CE</category>
      <pubDate>Tue, 02 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Lyle Regenwetter, Cyril Picard, Amin Heyrani Nobari, Akash Srivastava, Faez Ahmed</dc:creator>
    </item>
    <item>
      <title>WeightFlow: Learning Stochastic Dynamics via Evolving Weight of Neural Network</title>
      <link>https://arxiv.org/abs/2508.00451</link>
      <description>arXiv:2508.00451v2 Announce Type: replace 
Abstract: Modeling stochastic dynamics from discrete observations is a key interdisciplinary challenge. Existing methods often fail to estimate the continuous evolution of probability densities from trajectories or face the curse of dimensionality. To address these limitations, we presents a novel paradigm: modeling dynamics directly in the weight space of a neural network by projecting the evolving probability distribution. We first theoretically establish the connection between dynamic optimal transport in measure space and an equivalent energy functional in weight space. Subsequently, we design WeightFlow, which constructs the neural network weights into a graph and learns its evolution via a graph controlled differential equation. Experiments on interdisciplinary datasets demonstrate that WeightFlow improves performance by an average of 43.02\% over state-of-the-art methods, providing an effective and scalable solution for modeling high-dimensional stochastic dynamics.</description>
      <guid isPermaLink="false">oai:arXiv.org:2508.00451v2</guid>
      <category>cs.CE</category>
      <pubDate>Tue, 02 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Ruikun Li, Jiazhen Liu, Huandong Wang, Qingmin Liao, Yong Li</dc:creator>
    </item>
    <item>
      <title>Auditing Algorithmic Bias in Transformer-Based Trading</title>
      <link>https://arxiv.org/abs/2510.05140</link>
      <description>arXiv:2510.05140v2 Announce Type: replace-cross 
Abstract: Transformer models have become increasingly popular in financial applications, yet their potential risk making and biases remain under-explored. The purpose of this work is to audit the reliance of the model on volatile data for decision-making, and quantify how the frequency of price movements affects the model's prediction confidence. We employ a transformer model for prediction, and introduce a metric based on Partial Information Decomposition (PID) to measure the influence of each asset on the model's decision making. Our analysis reveals two key observations: first, the model disregards data volatility entirely, and second, it is biased toward data with lower-frequency price movements.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.05140v2</guid>
      <category>cs.LG</category>
      <category>cs.CE</category>
      <pubDate>Tue, 02 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Armin Gerami, Ramani Duraiswami</dc:creator>
    </item>
    <item>
      <title>Shared Spatial Memory Through Predictive Coding</title>
      <link>https://arxiv.org/abs/2511.04235</link>
      <description>arXiv:2511.04235v2 Announce Type: replace-cross 
Abstract: Constructing a consistent shared spatial memory is a critical challenge in multi-agent systems, where partial observability and limited bandwidth often lead to catastrophic failures in coordination. We introduce a multi-agent predictive coding framework that formulates coordination as the minimization of mutual uncertainty among agents. Through an information bottleneck objective, this framework prompts agents to learn not only who and what to communicate but also when. At the foundation of this framework lies a grid-cell-like metric as internal spatial coding for self-localization, emerging spontaneously from self-supervised motion prediction. Building upon this internal spatial code, agents gradually develop a bandwidth-efficient communication mechanism and specialized neural populations that encode partners' locations-an artificial analogue of hippocampal social place cells (SPCs). These social representations are further utilized by a hierarchical reinforcement learning policy that actively explores to reduce joint uncertainty. On the Memory-Maze benchmark, our approach shows exceptional resilience to bandwidth constraints: success degrades gracefully from 73.5% to 64.4% as bandwidth shrinks from 128 to 4 bits/step, whereas a full-broadcast baseline collapses from 67.6% to 28.6%. Our findings establish a theoretically principled and biologically plausible basis for how complex social representations emerge from a unified predictive drive, leading to collective intelligence.</description>
      <guid isPermaLink="false">oai:arXiv.org:2511.04235v2</guid>
      <category>cs.AI</category>
      <category>cs.CE</category>
      <pubDate>Tue, 02 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Zhengru Fang, Yu Guo, Jingjing Wang, Yuang Zhang, Haonan An, Yinhai Wang, Yuguang Fang</dc:creator>
    </item>
    <item>
      <title>PARROT: Persuasion and Agreement Robustness Rating of Output Truth -- A Sycophancy Robustness Benchmark for LLMs</title>
      <link>https://arxiv.org/abs/2511.17220</link>
      <description>arXiv:2511.17220v2 Announce Type: replace-cross 
Abstract: This study presents PARROT (Persuasion and Agreement Robustness Rating of Output Truth), a robustness focused framework designed to measure the degradation in accuracy that occurs under social pressure exerted on users through authority and persuasion in large language models (LLMs) the phenomenon of sycophancy (excessive conformity). PARROT (i) isolates causal effects by comparing the neutral version of the same question with an authoritatively false version using a double-blind evaluation, (ii) quantifies confidence shifts toward the correct and imposed false responses using log-likelihood-based calibration tracking, and (iii) systematically classifies failure modes (e.g., robust correct, sycophantic agreement, reinforced error, stubborn error, self-correction, etc.) using an eight-state behavioral taxonomy. We evaluated 22 models using 1,302 MMLU-style multiple-choice questions across 13 domains and domain-specific authority templates. Findings show marked heterogeneity: advanced models (e.g., GPT-5, GPT-4.1, Claude Sonnet 4.5) exhibit low "follow rates" ($\leq 11\%$, GPT-5: 4\%) and minimal accuracy loss, while older/smaller models show severe epistemic collapse (GPT-4: 80\%, Qwen 2.5-1.5B: 94\%). The danger is not limited to response changes; weak models reduce confidence in the correct response while increasing confidence in the imposed incorrect response. While international law and global knowledge at the domain level exhibit high fragility, elementary mathematics is relatively resilient. Consequently, we argue that the goal of "resistance to overfitting pressure" should be addressed as a primary objective alongside accuracy, harm avoidance, and privacy for safe deployment in the real world.</description>
      <guid isPermaLink="false">oai:arXiv.org:2511.17220v2</guid>
      <category>cs.CL</category>
      <category>cs.AI</category>
      <category>cs.CE</category>
      <category>cs.LG</category>
      <pubDate>Tue, 02 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Yusuf \c{C}elebi, \"Ozay Ezerceli, Mahmoud El Hussieni</dc:creator>
    </item>
  </channel>
</rss>
