<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>cs.NA updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/cs.NA</link>
    <description>cs.NA updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/cs.NA" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Fri, 16 May 2025 04:00:00 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Fri, 16 May 2025 00:00:00 -0400</pubDate>
    <skipDays>
      <day>Sunday</day>
      <day>Saturday</day>
    </skipDays>
    <item>
      <title>Accelerating Fast Ewald Summation with Prolates for Molecular Dynamics Simulations</title>
      <link>https://arxiv.org/abs/2505.09727</link>
      <description>arXiv:2505.09727v1 Announce Type: new 
Abstract: Fast Ewald summation is the most widely used approach for computing long-range Coulomb interactions in molecular dynamics (MD) simulations. While the asymptotic scaling is nearly optimal, its performance on parallel architectures is dominated by the global communication required for the underlying fast Fourier transform (FFT). Here, we develop a novel method, ESP - Ewald summation with prolate spheroidal wave functions (PSWFs) - that, for a fixed precision, sharply reduces the size of this transform by performing the Ewald split via a PSWF. In addition, PSWFs minimize the cost of spreading and interpolation steps that move information between the particles and the underlying uniform grid. We have integrated the ESP method into two widely-used open-source MD packages: LAMMPS and GROMACS. Detailed benchmarks show that this reduces the cost of computing far-field electrostatic interactions by an order of magnitude, leading to better strong scaling with respect to number of cores. The total execution time is reduced by a factor of 2 to 3 when using more than one thousand cores, even after optimally tuning the existing internal parameters in the native codes. We validate the accelerated codes in realistic long-time biological simulations.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.09727v1</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <category>physics.bio-ph</category>
      <pubDate>Fri, 16 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Jiuyang Liang, Libin Lu, Alex Barnett, Leslie Greengard, Shidong Jiang</dc:creator>
    </item>
    <item>
      <title>On the Well-Posedness of Green's Function Reconstruction via the Kirchhoff-Helmholtz Equation for One-Speed Neutron Diffusion</title>
      <link>https://arxiv.org/abs/2505.09766</link>
      <description>arXiv:2505.09766v1 Announce Type: new 
Abstract: This work presents a methodology for reconstructing the spatial distribution of the neutron flux in a nuclear reactor, leveraging real-time measurements obtained from ex-core detectors. The Kirchhoff-Helmholtz (K-H) equation inherently defines the problem of estimating a scalar field within a domain based on boundary data, making it a natural mathematical framework for this task. The main challenge lies in deriving the Green's function specific to the domain and the neutron diffusion process. While analytical solutions for Green's functions exist for simplified geometries, their derivation of complex, heterogeneous domains-such as a nuclear reactor-requires a numerical approach. The objective of this work is to demonstrate the well-posedness of the data-driven Green's function approximation by formulating and solving the K-H equation as an inverse problem. After establishing the symmetry properties that the Green's function must satisfy, the K-H equation is derived from the one-speed neutron diffusion model. This is followed by a comprehensive description of the procedure for interpreting sensor readings and implementing the neutron flux reconstruction algorithm. Finally, the existence and uniqueness of the Green's function inferred from the sampled data are demonstrated, ensuring the reliability of the proposed method and its predictions.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.09766v1</guid>
      <category>math.NA</category>
      <category>cs.AI</category>
      <category>cs.NA</category>
      <pubDate>Fri, 16 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Roberto Ponciroli</dc:creator>
    </item>
    <item>
      <title>Efficient Calculation of Modified Bessel Functions of the First Kind, $I_{\nu} (z)$, for Real Orders and Complex Arguments: Fortran Implementation with Double and Quadruple Precision</title>
      <link>https://arxiv.org/abs/2505.09770</link>
      <description>arXiv:2505.09770v1 Announce Type: new 
Abstract: We present an efficient self-contained algorithm for computing the modified Bessel function of the first kind $I_{\nu}(z)$, implemented in a robust Fortran code supporting double and quadruple (quad) precision. The algorithm overcomes the limitations of Algorithm 644, which is restricted to double precision and applies overly conservative underflow and overflow thresholds, leading to failures in large parameter regions. Accuracy is validated against high-precision Maple calculations, and benchmarking shows execution time reductions to 54%-80% of Algorithm 644 (in double precision). Quad precision enhances numerical stability and broadens the domain of computations, making the implementation well suited for high-precision applications in physics and engineering. This work also provides a foundation for the development of efficient algorithms for other Bessel functions.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.09770v1</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <pubDate>Fri, 16 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Mofreh R. Zaghloul, Steven G. Johnson</dc:creator>
    </item>
    <item>
      <title>High-Order Hermite Optimization: Fast and Exact Gradient Computation in Open-Loop Quantum Optimal Control using a Discrete Adjoint Approach</title>
      <link>https://arxiv.org/abs/2505.09857</link>
      <description>arXiv:2505.09857v1 Announce Type: new 
Abstract: This work introduces the High-Order Hermite Optimization (HOHO) method, an open-loop discrete adjoint method for quantum optimal control. Our method is the first of its kind to efficiently compute exact (discrete) gradients when using continuous, parameterized control pulses while solving the forward equations (e.g. Schrodinger's equation or the Linblad master equation) with an arbitrarily high-order Hermite Runge-Kutta method. The HOHO method is implemented in QuantumGateDesign.jl, an open-source software package for the Julia programming language, which we use to perform numerical experiments comparing the method to Juqbox.jl. For realistic model problems we observe speedups up to 775x.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.09857v1</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <category>quant-ph</category>
      <pubDate>Fri, 16 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Spencer Lee, Daniel Appelo</dc:creator>
    </item>
    <item>
      <title>Discontinuous hybrid neural networks for the one-dimensional partial differential equations</title>
      <link>https://arxiv.org/abs/2505.09911</link>
      <description>arXiv:2505.09911v1 Announce Type: new 
Abstract: A feedforward neural network, including hidden layers, motivated by nonlinear functions (such as Tanh, ReLU, and Sigmoid functions), exhibits uniform approximation properties in Sobolev space, and discontinuous neural networks can reduce computational complexity. In this work, we present a discontinuous hybrid neural network method for solving the partial differential equations, construct a new hybrid loss functional that incorporates the variational of the approximation equation, interface jump stencil and boundary constraints. The RMSprop algorithm and discontinuous Galerkin method are employed to update the nonlinear parameters and linear parameters in neural networks, respectively. This approach guarantees the convergence of the loss functional and provides an approximate solution with high accuracy.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.09911v1</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <pubDate>Fri, 16 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Xiaoyu Wang, Long Yuan, Yao Yu</dc:creator>
    </item>
    <item>
      <title>Error Estimates and Graded Mesh Refinement for Isogeometric Analysis on Polar Domains with Corners</title>
      <link>https://arxiv.org/abs/2505.10095</link>
      <description>arXiv:2505.10095v1 Announce Type: new 
Abstract: Isogeometric analysis (IGA) enables exact representations of computational geometries and higher-order approximation of PDEs. In non-smooth domains, however, singularities near corners limit the effectiveness of IGA, since standard methods typically fail to achieve optimal convergence rates. These constraints can be addressed through local mesh refinement, but existing approaches require breaking the tensor-product structure of splines, which leads to increased implementation complexity.
  This work introduces a novel local refinement strategy based on a polar parameterization, in which one edge of the parametric square is collapsed into the corner. By grading the standard mesh toward the collapsing edge, the desired locality near the singularity is obtained while maintaining the tensor-product structure. A mathematical analysis and numerical tests show that the resulting isogeometric approximation achieves optimal convergence rates with suitable grading parameters.
  Polar parameterizations, however, suffer from a lack of regularity at the polar point, making existing standard isogeometric approximation theory inapplicable. To address this, a new framework is developed for deriving error estimates on polar domains with corners. This involves the construction of polar function spaces on the parametric domain and a modified projection operator onto the space of $C^0$-smooth polar splines. The theoretical results are verified by numerical experiments confirming both the accuracy and efficiency of the proposed approach.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.10095v1</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <pubDate>Fri, 16 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <dc:creator>Thomas Apel, Philipp Zilk</dc:creator>
    </item>
    <item>
      <title>A generalized discontinuous Hamilton Monte Carlo for transdimensional sampling</title>
      <link>https://arxiv.org/abs/2505.10108</link>
      <description>arXiv:2505.10108v1 Announce Type: new 
Abstract: In this paper, we propose a discontinuous Hamilton Monte Carlo (DHMC) to sample from dimensional varying distributions, and particularly the grand canonical ensemble. The DHMC was proposed in [Biometrika, 107(2)] for discontinuous potential where the variable has a fixed dimension. When the dimension changes, there is no clear explanation of the volume-preserving property, and the conservation of energy is also not necessary. We use a random sampling for the extra dimensions, which corresponds to a measure transform. We show that when the energy is corrected suitably for the trans-dimensional Hamiltonian dynamics, the detailed balance condition is then satisfied. For the grand canonical ensemble, such a procedure can be explained very naturally to be the extra free energy change brought by the newly added particles, which justifies the rationality of our approach. To sample the grand canonical ensemble for interacting particle systems, the DHMC is then combined with the random batch method to yield an efficient sampling method. In experiments, we show that the proposed DHMC combined with the random batch method generates samples with much less correlation when compared with the traditional Metropolis-Hastings method.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.10108v1</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <pubDate>Fri, 16 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Lei Li, Xiangxian Luo, Yinchen Luo</dc:creator>
    </item>
    <item>
      <title>The finiteness conjecture for $3 \times 3$ binary matrices</title>
      <link>https://arxiv.org/abs/2505.10178</link>
      <description>arXiv:2505.10178v1 Announce Type: new 
Abstract: The invariant polytope algorithm was a breakthrough in the joint spectral radius computation, allowing to find the exact value of the joint spectral radius for most matrix families~\cite{GP2013,GP2016}. This algorithm found many applications in problems of functional analysis, approximation theory, combinatorics, etc. In this paper we propose a modification of the invariant polytope algorithm enlarging the class of problems to which it is applicable. Precisely, we introduce mixed numeric and symbolic computations. A further minor modification of augmenting the input set with additional matrices speeds up the algorithm in certain cases. With this modifications we are able to automatically prove the finiteness conjecture for all pairs of binary $3\times 3$ matrices and sign $2\times 2$ matrices.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.10178v1</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <pubDate>Fri, 16 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <arxiv:DOI>10.14658/PUPJ-DRNA-2022-5-3</arxiv:DOI>
      <arxiv:journal_reference>Dolomites Research Notes on Approximation, 15(5), 24-38 (2022)</arxiv:journal_reference>
      <dc:creator>Thomas Mejstrik</dc:creator>
    </item>
    <item>
      <title>Discrete Geodesic Calculus in the Space of Sobolev Curves</title>
      <link>https://arxiv.org/abs/2505.10298</link>
      <description>arXiv:2505.10298v1 Announce Type: new 
Abstract: The Riemannian manifold of curves with a Sobolev metric is an important and frequently studied model in the theory of shape spaces. Various numerical approaches have been proposed to compute geodesics, but so far elude a rigorous convergence theory. By a slick modification of a temporal Galerkin discretization we manage to preserve coercivity and compactness properties of the continuous model and thereby are able to prove convergence for the geodesic boundary value problem. Likewise, for the numerical analysis of the geodesic initial value problem we are able to exploit the geodesic completeness of the underlying continuous model for the error control of a time-stepping approximation. In fact, we develop a convergent discretization of a comprehensive Riemannian calculus that in addition includes parallel transport, covariant differentiation, the Riemann curvature tensor, and sectional curvature, all important tools to explore the geometry of the space of curves. Selected numerical examples confirm the theoretical findings and show the qualitative behaviour. To this end, a low-dimensional submanifold of Sobolev curves with explicit formulas for ground truth covariant derivatives and curvatures are considered.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.10298v1</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <pubDate>Fri, 16 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Sascha Beutler, Florine Hartwig, Martin Rumpf, Benedikt Wirth</dc:creator>
    </item>
    <item>
      <title>A general regularization strategy for singular Stokes problems and convergence analysis for corresponding discretization and iterative solution</title>
      <link>https://arxiv.org/abs/2505.10404</link>
      <description>arXiv:2505.10404v1 Announce Type: new 
Abstract: A general regularization strategy is considered for the efficient iterative solution of the lowest-order weak Galerkin approximation of singular Stokes problems. The strategy adds a rank-one regularization term to the zero (2,2) block of the underlying singular saddle point system. This strategy includes the existing pressure pinning and mean-zero enforcement regularization as special examples. It is shown that the numerical error maintains the optimal-order convergence provided that the nonzero Dirichlet boundary datum is approximated numerically with sufficient accuracy. Inexact block diagonal and triangular Schur complement preconditioners are considered for the regularized system. The convergence analysis for MINRES and GMRES with corresponding block preconditioners is provided for different choices of the regularization term. Numerical experiments in two and three dimensions are presented to verify the theoretical findings and the effectiveness of the preconditioning for solving the regularized system.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.10404v1</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <pubDate>Fri, 16 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Weizhang Huang, Zhuoran Wang</dc:creator>
    </item>
    <item>
      <title>Connections between convex optimization algorithms and subspace correction methods</title>
      <link>https://arxiv.org/abs/2505.09765</link>
      <description>arXiv:2505.09765v1 Announce Type: cross 
Abstract: We show that a broad range of convex optimization algorithms, including alternating projection, operator splitting, and multiplier methods, can be systematically derived from the framework of subspace correction methods via convex duality. To formalize this connection, we introduce the notion of dualization, a process that transforms an iterative method for the dual problem into an equivalent method for the primal problem. This concept establishes new connections across these algorithmic classes, encompassing both well-known and new methods. In particular, we show that classical algorithms such as the von Neumann, Dykstra, Peaceman--Rachford, and Douglas--Rachford methods can be interpreted as dualizations of subspace correction methods applied to appropriate dual formulations. Beyond unifying existing methods, our framework enables the systematic development of new algorithms for convex optimization. For instance, we derive parallel variants of alternating projection and operator splitting methods, as dualizations of parallel subspace correction methods, that are well-suited for large-scale problems on modern computing architectures and offer straightforward convergence guarantees. We also propose new alternating direction method of multipliers-type algorithms, derived as dualizations of certain operator splitting methods. These algorithms naturally ensure convergence even in the multi-block setting, where the conventional method does not guarantee convergence when applied to more than two blocks. This unified perspective not only facilitates algorithm design and the transfer of theoretical results but also opens new avenues for research and innovation in convex optimization.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.09765v1</guid>
      <category>math.OC</category>
      <category>cs.NA</category>
      <category>math.NA</category>
      <pubDate>Fri, 16 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Boou Jiang, Jongho Park, Jinchao Xu</dc:creator>
    </item>
    <item>
      <title>On the critical length conjecture for spherical Bessel functions in CAGD</title>
      <link>https://arxiv.org/abs/2505.09964</link>
      <description>arXiv:2505.09964v1 Announce Type: cross 
Abstract: A conjecture of J.M. Carnicer, E. Mainar and J.M. Pe\~{n}a states that the critical length of the space $P_{n}\odot C_{1}$ generated by the functions $x^{k}\sin x$ and $x^{k}\cos x$ for $k=0,...n$ is equal to the first positive zero $j_{n+\frac{1}{2},1}$ of the Bessel function $J_{n+\frac{1}{2}}$ of the first kind. It is known that the conjecture implies the following statement (D3): the determinant of the Hankel matrix \begin{equation} \left( \begin{array} [c]{ccc} f &amp; f^{\prime} &amp; f^{\prime\prime}\\ f^{\prime} &amp; f^{\prime\prime} &amp; f^{\left( 3\right) }\\ f^{\prime\prime} &amp; f^{\prime\prime\prime} &amp; f^{\left( 4\right) } \end{array} \right) \label{eqabstract} \end{equation} does not have a zero in the interval $(0,j_{n+\frac{1}{2},1})$ whenever $f=f_{n}$ is given by $f_{n}\left( x\right) =\sqrt{\frac{\pi}{2}} x^{n+\frac{1}{2}}J_{n+\frac{1}{2}}\left( x\right) .$ In this paper we shall prove (D3) and various generalizations.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.09964v1</guid>
      <category>math.CA</category>
      <category>cs.NA</category>
      <category>math.NA</category>
      <pubDate>Fri, 16 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Ognyan Kounchev, Hermann Render</dc:creator>
    </item>
    <item>
      <title>Superclosenes error estimates for the div least-squares finite element method on elliptic problems</title>
      <link>https://arxiv.org/abs/2404.04918</link>
      <description>arXiv:2404.04918v2 Announce Type: replace 
Abstract: In this paper we provide some error estimates for the div least-squares finite element method on elliptic problems. The main contribution is presenting a complete error analysis, which improves the current \emph{state-of-the-art} results. The error estimates for both the scalar and the flux variables are established by specially designed dual arguments with the help of two projections: elliptic projection and H(div) projection, which are crucial to supercloseness estimates. In most cases, $H^3$ regularity is omitted to get the optimal convergence rate for vector and scalar unknowns, and most of our results require a lower regularity for the vector variable than the scalar. Moreover, a series of supercloseness results are proved, which are \emph{never seen} in the previous work of least-squares finite element methods.</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.04918v2</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <pubDate>Fri, 16 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Gang Chen, Fanyi Yang, Zheyuan Zhang</dc:creator>
    </item>
    <item>
      <title>A simple linear convergence analysis of the reshuffling Kaczmarz method</title>
      <link>https://arxiv.org/abs/2410.01140</link>
      <description>arXiv:2410.01140v2 Announce Type: replace 
Abstract: The random reshuffling Kaczmarz (RRK) method enjoys the simplicity and efficiency in solving linear systems as a Kaczmarz-type method, whereas it also inherits the practical improvements of the stochastic gradient descent (SGD) with random reshuffling (RR) over original SGD. However, the current studies on RRK do not characterize its convergence comprehensively. In this paper, we present a novel analysis of the RRK method and prove its linear convergence towards the unique least-norm solution of the linear system. Furthermore, the convergence upper bound is tight and does not depend on the dimension of the coefficient matrix.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.01140v2</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <pubDate>Fri, 16 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Deren Han, Jiaxin Xie</dc:creator>
    </item>
    <item>
      <title>An optimization-based positivity-preserving limiter in semi-implicit discontinuous Galerkin schemes solving Fokker-Planck equations</title>
      <link>https://arxiv.org/abs/2410.19143</link>
      <description>arXiv:2410.19143v2 Announce Type: replace 
Abstract: For high-order accurate schemes such as discontinuous Galerkin (DG) methods solving Fokker-Planck equations, it is desired to efficiently enforce positivity without losing conservation and high-order accuracy, especially for implicit time discretizations. We consider an optimization-based positivity-preserving limiter for enforcing positivity of cell averages of DG solutions in a semi-implicit time discretization scheme, so that the point values can be easily enforced to be positive by a simple scaling limiter on the DG polynomial in each cell. The optimization can be efficiently solved by a first-order splitting method with nearly optimal parameters, which has an $\mathcal{O}(N)$ computational complexity and is flexible for parallel computation. Numerical tests are shown on some representative examples to demonstrate the performance of the proposed method.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.19143v2</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <pubDate>Fri, 16 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Chen Liu, Jingwei Hu, William T. Taitano, Xiangxiong Zhang</dc:creator>
    </item>
    <item>
      <title>Determination of Preferred Fiber Orientation State based on Newton-Raphson Method using Exact Jacobian</title>
      <link>https://arxiv.org/abs/2501.02663</link>
      <description>arXiv:2501.02663v2 Announce Type: replace 
Abstract: Fiber orientation is an important descriptor of the microstructure for short fiber polymer composite materials where accurate and efficient prediction of the orientation state is crucial when evaluating the bulk thermo-mechanical response of the material. Recent macroscopic fiber orientation models have employed the moment-tensor form in representing the fiber orientation state which all require a closure approximation for the higher order orientation tensors. In addition, various models have been developed to account for rotary diffusion due to fiber-fiber and fiber-matrix interactions which can now more accurately simulate the experimentally observed slow fiber kinematics in polymer composite processing. Traditionally explicit numerical IVP-ODE transient solvers like the 4th order Runge-Kutta method have been used to predict the steady-state fiber orientation state. Here we propose a computationally efficient method based on the Newton-Raphson iterative technique for determining steady state orientation tensor values by evaluating the exact derivatives of the moment-tensor evolution equation with respect to the independent components of the orientation tensor. We consider various existing macroscopic fiber orientation models and several closure ap-proximations to ensure the robustness and reliability of the method. The performance and stability of the approach for obtaining physical solutions in various homogeneous flow fields is demonstrated through several examples. Validation of the obtained exact derivatives of the orientation tensor is performed by benchmarking with results of finite difference techniques</description>
      <guid isPermaLink="false">oai:arXiv.org:2501.02663v2</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <pubDate>Fri, 16 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Aigbe Awenlimobor, Douglas E. Smith</dc:creator>
    </item>
    <item>
      <title>Quasi-3D beam theory based on equilibrium stress definition and mixed element model for accurate analysis of functionally graded beams</title>
      <link>https://arxiv.org/abs/2505.09127</link>
      <description>arXiv:2505.09127v2 Announce Type: replace 
Abstract: This paper presents a novel quasi-3D theory and the corresponding mixed beam element model to achieve accurate solutions for functionally graded beams. The key innovations include the development of equilibrium-based stress expressions, the modified cross-sectional stiffness matrix, and the mixed beam element model based on semi-analytical definition of internal force fields. In contrast to the conventional quasi-3D theory where stress expressions are derived from constitutive equations and geometric relations, the stress expressions in this study are derived from the differential equilibrium equations among stresses, ensuring strict adherence of stress solutions to equilibrium conditions. To incorporate the influence of equilibrium-derived stress distributions, the modified cross-sectional stiffness matrix is derived, enhancing the theoretical and practical feasibility of the beam model. For beam element construction, the mixed variational principle of two-field variables is employed, with generalized internal forces and generalized displacements regarded as two independent fields. Especially, semi-analytical internal force fields, which partially satisfy the differential equilibrium equations, are introduced to improve the element performance. Numerical examples are conducted to verify the accuracy and effectiveness of the proposed theory and beam element.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.09127v2</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <pubDate>Fri, 16 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Wenxiong Li, Zhiwei Liu, Suiyin Chen, Gengying Li</dc:creator>
    </item>
    <item>
      <title>Machine Learning with Physics Knowledge for Prediction: A Survey</title>
      <link>https://arxiv.org/abs/2408.09840</link>
      <description>arXiv:2408.09840v2 Announce Type: replace-cross 
Abstract: This survey examines the broad suite of methods and models for combining machine learning with physics knowledge for prediction and forecast, with a focus on partial differential equations. These methods have attracted significant interest due to their potential impact on advancing scientific research and industrial practices by improving predictive models with small- or large-scale datasets and expressive predictive models with useful inductive biases. The survey has two parts. The first considers incorporating physics knowledge on an architectural level through objective functions, structured predictive models, and data augmentation. The second considers data as physics knowledge, which motivates looking at multi-task, meta, and contextual learning as an alternative approach to incorporating physics knowledge in a data-driven fashion. Finally, we also provide an industrial perspective on the application of these methods and a survey of the open-source ecosystem for physics-informed machine learning.</description>
      <guid isPermaLink="false">oai:arXiv.org:2408.09840v2</guid>
      <category>cs.LG</category>
      <category>cs.NA</category>
      <category>math.NA</category>
      <category>physics.comp-ph</category>
      <pubDate>Fri, 16 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Joe Watson, Chen Song, Oliver Weeger, Theo Gruner, An T. Le, Kay Pompetzki, Ahmed Hendawy, Oleg Arenz, Will Trojak, Miles Cranmer, Carlo D'Eramo, Fabian B\"ulow, Tanmay Goyal, Jan Peters, Martin W. Hoffman</dc:creator>
    </item>
    <item>
      <title>AneuPy: An open source Python tool for creating simulation-ready geometries of abdominal aortic aneurysms</title>
      <link>https://arxiv.org/abs/2504.15285</link>
      <description>arXiv:2504.15285v2 Announce Type: replace-cross 
Abstract: Abdominal aortic aneurysms (AAAs) are localized dilatations of the abdominal aorta that can lead to life-threatening rupture if left untreated. AAAs primarily affect older individuals, with high mortality rates following rupture, so early diagnosis and risk assessment are critical. The geometrical characteristics of an AAA, such as its maximum diameter, asymmetry, and wall thickness, are extremely significant in biomechanical models for the assessment of rupture risk. Despite the growing use of computational modeling for AAA investigation, there is a notable gap in accessible, open-source software capable of generating simulation-ready geometries for biomechanical and hemodynamic simulations. To address this gap, we introduce \textbf{AneuPy}, an open-source Python-based tool designed to create both idealized and patient-specific AAA geometric models. \textbf{AneuPy} is a fast and automated approach for generating aneurysm geometries from minimal input data, allowing for extensive parameter customization. By automating the creation of simulation-ready geometries for finite element analysis (FEA), computational fluid dynamics (CFD), or fluid-structure interaction (FSI) models, \textbf{AneuPy} can facilitate research in AAA and improve patient-specific risk prediction.</description>
      <guid isPermaLink="false">oai:arXiv.org:2504.15285v2</guid>
      <category>physics.med-ph</category>
      <category>cs.CE</category>
      <category>cs.NA</category>
      <category>math.NA</category>
      <pubDate>Fri, 16 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Mario de Lucio, Jacobo Diaz, Alberto de Castro, Luis E. Romera</dc:creator>
    </item>
  </channel>
</rss>
