<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>math.OC updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/math.OC</link>
    <description>math.OC updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/math.OC" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Tue, 16 Apr 2024 04:00:25 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Tue, 16 Apr 2024 00:00:00 -0400</pubDate>
    <skipDays>
      <day>Saturday</day>
      <day>Sunday</day>
    </skipDays>
    <item>
      <title>Practical Safe Extremum Seeking with Assignable Rate of Attractivity to the Safe Set</title>
      <link>https://arxiv.org/abs/2404.08842</link>
      <description>arXiv:2404.08842v1 Announce Type: new 
Abstract: We present Assignably Safe Extremum Seeking (ASfES), an algorithm designed to minimize a measured objective function while maintaining a measured metric of safety (a control barrier function or CBF) be positive in a practical sense. We ensure that for trajectories with safe initial conditions, the violation of safety can be made arbitrarily small with appropriately chosen design constants. We also guarantee an assignable ``attractivity'' rate: from unsafe initial conditions, the trajectories approach the safe set, in the sense of the measured CBF, at a rate no slower than a user-assigned rate. Similarly, from safe initial conditions, the trajectories approach the unsafe set, in the sense of the CBF, no faster than the assigned attractivity rate. The feature of assignable attractivity is not present in the semiglobal version of safe extremum seeking, where the semiglobality of convergence is achieved by slowing the adaptation. We also demonstrate local convergence of the parameter to a neighborhood of the minimum of the objective function constrained to the safe set. The ASfES algorithm and analysis are multivariable, but we also extend the algorithm to a Newton-Based ASfES scheme (NB-ASfES) which we show is only useful in the scalar case. The proven properties of the designs are illustrated through simulation examples.</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.08842v1</guid>
      <category>math.OC</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Alan Williams, Miroslav Krstic, Alexander Scheinker</dc:creator>
    </item>
    <item>
      <title>Improving Autoencoder Image Interpolation via Dynamic Optimal Transport</title>
      <link>https://arxiv.org/abs/2404.08900</link>
      <description>arXiv:2404.08900v1 Announce Type: new 
Abstract: Autoencoders are important generative models that, among others, have the ability to interpolate image sequences. However, interpolated images are usually not semantically meaningful.In this paper, motivated by dynamic optimal transport, we consider image interpolation as a mass transfer problem and propose a novel regularization term to penalize non-smooth and unrealistic changes in the interpolation result. Specifically, we define the path energy function for each path connecting the source and target images. The autoencoder is trained to generate the $L^2$ optimal transport geodesic path when decoding a linear interpolation of their latent codes. With a simple extension, this model can handle complicated environments, such as allowing mass transfer between obstacles and unbalanced optimal transport. A key feature of the proposed method is that it is physics-driven and can generate robust and realistic interpretation results even when only very limited training data are available.</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.08900v1</guid>
      <category>math.OC</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Xue Feng, Thomas Strohmer</dc:creator>
    </item>
    <item>
      <title>A Novel State-Centric Necessary Condition for Time-Optimal Control of Controllable Linear Systems Based on Augmented Switching Laws</title>
      <link>https://arxiv.org/abs/2404.08943</link>
      <description>arXiv:2404.08943v1 Announce Type: new 
Abstract: Most existing necessary conditions for optimal control based on adjoining methods require both state information and costate information, yet the lack of costates for a given feasible trajectory in practice impedes the determination of optimality. This paper establishes a novel theoretical framework for time-optimal control of controllable linear systems, proposing the augmented switching law that represents the input control and the feasibility in a compact form. Given a feasible trajectory, the disturbed trajectory under the constraints of augmented switching law is guaranteed to be feasible, resulting in a novel state-centric necessary condition without dependence on costate information. A first order necessary condition is proposed that the Jacobian matrix of the augmented switching law is not full row rank, which also results in an approach to optimizing a given feasible trajectory further. The proposed necessary condition is applied to the chain-of-integrators systems with full box constraints, contributing to some conclusions challenging to reason by traditional costate-based necessary conditions.</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.08943v1</guid>
      <category>math.OC</category>
      <category>cs.SY</category>
      <category>eess.SY</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Yunan Wang, Chuxiong Hu, Yujie Lin, Zeyang Li, Shize Lin, Suqin He</dc:creator>
    </item>
    <item>
      <title>Asynchronous Heterogeneous Linear Quadratic Regulator Design</title>
      <link>https://arxiv.org/abs/2404.09061</link>
      <description>arXiv:2404.09061v1 Announce Type: new 
Abstract: We address the problem of designing an LQR controller in a distributed setting, where M similar but not identical systems share their locally computed policy gradient (PG) estimates with a server that aggregates the estimates and computes a controller that, on average, performs well on all systems. Learning in a distributed setting has the potential to offer statistical benefits - multiple datasets can be leveraged simultaneously to produce more accurate policy gradient estimates. However, the interplay of heterogeneous trajectory data and varying levels of local computational power introduce bias to the aggregated PG descent direction, and prevents us from fully exploiting the parallelism in the distributed computation. The latter stems from synchronous aggregation, where straggler systems negatively impact the runtime. To address this, we propose an asynchronous policy gradient algorithm for LQR control design. By carefully controlling the "staleness" in the asynchronous aggregation, we show that the designed controller converges to each system's $\epsilon$-near optimal controller up to a heterogeneity bias. Furthermore, we prove that our asynchronous approach obtains exact local convergence at a sub-linear rate.</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.09061v1</guid>
      <category>math.OC</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Leonardo F. Toso, Han Wang, James Anderson</dc:creator>
    </item>
    <item>
      <title>Cost-effective company response policy for product co-creation in company-sponsored online community</title>
      <link>https://arxiv.org/abs/2404.09307</link>
      <description>arXiv:2404.09307v1 Announce Type: new 
Abstract: Product co-creation based on company-sponsored online community has come to be a paradigm of developing new products collaboratively with customers. In such a product co-creation campaign, the sponsoring company needs to interact intensively with active community members about the design scheme of the product. We call the collection of the rates of the company's response to active community members at all time in the co-creation campaign as a company response policy (CRP). This paper addresses the problem of finding a cost-effective CRP (the CRP problem). First, we introduce a novel community state evolutionary model and, thereby, establish an optimal control model for the CRP problem (the CRP model). Second, based on the optimality system for the CRP model, we present an iterative algorithm for solving the CRP model (the CRP algorithm). Thirdly, through extensive numerical experiments, we conclude that the CRP algorithm converges and the resulting CRP exhibits excellent cost benefit. Consequently, we recommend the resulting CRP to companies that embrace product co-creation. Next, we discuss how to implement the resulting CRP. Finally, we investigate the effect of some factors on the cost benefit of the resulting CRP. To our knowledge, this work is the first attempt to study value co-creation through optimal control theoretic approach.</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.09307v1</guid>
      <category>math.OC</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <arxiv:DOI>10.1109/TSMC.2024.3379408</arxiv:DOI>
      <dc:creator>Jiamin Hu, Lu-Xing Yang, Xiaofan Yang, Kaifan Huang, Gang Li, Yong Xiang</dc:creator>
    </item>
    <item>
      <title>Incremental data compression for PDE-constrained optimization with a data assimilation application</title>
      <link>https://arxiv.org/abs/2404.09323</link>
      <description>arXiv:2404.09323v1 Announce Type: new 
Abstract: This paper proposes and analyzes an inexact gradient method based on incremental proper orthogonal decomposition (iPOD) to address the data storage difficulty in time-dependent PDE-constrained optimization, particularly for a data assimilation problem as a detailed demonstration for the key ideas. The proposed method is proved robust by rigorous analysis. We first derive a sharp data compression error estimate of the iPOD with the help of Hilbert-Schmidt operators. Then we demonstrate a numerical PDE analysis to show how to properly choose Hilbert space for the iPOD data compression so that the gradient error is under control. We further prove that for a convex problem with appropriately bounded gradient error, the inexact gradient method achieves the accuracy level of the optimal solution while not hurting the convergence rate compared with the usual gradient method. Finally, numerical experiments are provided to verify the theoretical results and validate the proposed method.</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.09323v1</guid>
      <category>math.OC</category>
      <category>math.AP</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Xuejian Li, John R. Singler, Xiaoming He</dc:creator>
    </item>
    <item>
      <title>Momentum-based gradient descent methods for Lie groups</title>
      <link>https://arxiv.org/abs/2404.09363</link>
      <description>arXiv:2404.09363v1 Announce Type: new 
Abstract: Polyak's Heavy Ball (PHB; Polyak, 1964), a.k.a. Classical Momentum, and Nesterov's Accelerated Gradient (NAG; Nesterov, 1983) are well know examples of momentum-descent methods for optimization. While the latter outperforms the former, solely generalizations of PHB-like methods to nonlinear spaces have been described in the literature. We propose here a generalization of NAG-like methods for Lie group optimization based on the variational one-to-one correspondence between classical and accelerated momentum methods (Campos et al., 2023). Numerical experiments are shown.</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.09363v1</guid>
      <category>math.OC</category>
      <category>cs.LG</category>
      <category>cs.NA</category>
      <category>math.DG</category>
      <category>math.NA</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>C\'edric M. Campos, David Mart\'in de Diego, Jos\'e Torrente</dc:creator>
    </item>
    <item>
      <title>Developing Lagrangian-based Methods for Nonsmooth Nonconvex Optimization</title>
      <link>https://arxiv.org/abs/2404.09438</link>
      <description>arXiv:2404.09438v1 Announce Type: new 
Abstract: In this paper, we consider the minimization of a nonsmooth nonconvex objective function $f(x)$ over a closed convex subset $\mathcal{X}$ of $\mathbb{R}^n$, with additional nonsmooth nonconvex constraints $c(x) = 0$. We develop a unified framework for developing Lagrangian-based methods, which takes a single-step update to the primal variables by some subgradient methods in each iteration. These subgradient methods are ``embedded'' into our framework, in the sense that they are incorporated as black-box updates to the primal variables. We prove that our proposed framework inherits the global convergence guarantees from these embedded subgradient methods under mild conditions. In addition, we show that our framework can be extended to solve constrained optimization problems with expectation constraints. Based on the proposed framework, we show that a wide range of existing stochastic subgradient methods, including the proximal SGD, proximal momentum SGD, and proximal ADAM, can be embedded into Lagrangian-based methods. Preliminary numerical experiments on deep learning tasks illustrate that our proposed framework yields efficient variants of Lagrangian-based methods with convergence guarantees for nonconvex nonsmooth constrained optimization problems.</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.09438v1</guid>
      <category>math.OC</category>
      <category>cs.LG</category>
      <category>stat.ML</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Nachuan Xiao, Kuangyu Ding, Xiaoyin Hu, Kim-Chuan Toh</dc:creator>
    </item>
    <item>
      <title>Optimal Real-time Bidding Strategy For EV Aggregators in Wholesale Electricity Markets</title>
      <link>https://arxiv.org/abs/2404.09460</link>
      <description>arXiv:2404.09460v1 Announce Type: new 
Abstract: With the rapid growth of electric vehicles (EVs), EV aggregators have been playing a increasingly vital role in power systems by not merely providing charging management but also participating in wholesale electricity markets. This work studies the optimal real-time bidding strategy for an EV aggregator. Since the charging process of EVs is time-coupled, it is necessary for EV aggregators to consider future operational conditions (e.g., future EV arrivals) when deciding the current bidding strategy. However, accurately forecasting future operational conditions is challenging under the inherent uncertainties. Hence, there demands a real-time bidding strategy based solely on the up-to-date information, which is the main goal of this work. We start by developing an online optimal EV charging management algorithm for the EV aggregator via Lyapunov optimization. Based on this, an optimal real-time bidding strategy (bidding cost curve and bounds) for the aggregator is derived. Then, an efficient yet practical algorithm is proposed to obtain the bidding strategy. It shows that with the proposed bidding strategy, the aggregator's profit is nearly offline optimal. Moreover, the wholesale electricity market clearing result aligns with the individual aggregator's optimal charging strategy given the prices. Case studies against several benchmarks are conducted to evaluate the performance of the proposed method.</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.09460v1</guid>
      <category>math.OC</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Shihan Huang, Dongkun Han, John Zhen Fu Pang, Yue Chen</dc:creator>
    </item>
    <item>
      <title>Data-driven identification of reaction-diffusion dynamics from finitely many non-local noisy measurements by exponential fitting</title>
      <link>https://arxiv.org/abs/2404.09503</link>
      <description>arXiv:2404.09503v1 Announce Type: new 
Abstract: Given a reaction-diffusion equation with unknown right-hand side, we consider a nonlinear inverse problem of estimating the associated leading eigenvalues and initial condition modes from a finite number of non-local noisy measurements. We define a reconstruction criterion and, for a small enough noise, we prove the existence and uniqueness of the desired approximation and derive closed-form expressions for the first-order condition numbers, as well as bounds for their asymptotic behavior in a regime when the number of measured samples is fixed and the inter-sampling interval length tends to infinity. When computing the sought estimates numerically, our simulations show that the exponential fitting algorithm ESPRIT is first-order optimal, as its first-order condition numbers have the same asymptotic behavior as the analytic condition numbers in the considered regime.</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.09503v1</guid>
      <category>math.OC</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Rami Katz, Giulia Giordano, Dmitry Batenkov</dc:creator>
    </item>
    <item>
      <title>Safeguarding adaptive methods: global convergence of Barzilai-Borwein and other stepsize choices</title>
      <link>https://arxiv.org/abs/2404.09617</link>
      <description>arXiv:2404.09617v1 Announce Type: new 
Abstract: Leveraging on recent advancements on adaptive methods for convex minimization problems, this paper provides a linesearch-free proximal gradient framework for globalizing the convergence of popular stepsize choices such as Barzilai-Borwein and one-dimensional Anderson acceleration. This framework can cope with problems in which the gradient of the differentiable function is merely locally H\"older continuous. Our analysis not only encompasses but also refines existing results upon which it builds. The theory is corroborated by numerical evidence that showcases the synergetic interplay between fast stepsize selections and adaptive methods.</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.09617v1</guid>
      <category>math.OC</category>
      <category>cs.LG</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Ou Hongjia, Andreas Themelis</dc:creator>
    </item>
    <item>
      <title>Nonconvergence of a sum-of-squares hierarchy for global polynomial optimization based on push-forward measures</title>
      <link>https://arxiv.org/abs/2404.09710</link>
      <description>arXiv:2404.09710v1 Announce Type: new 
Abstract: Let $\mathbf{X} \subseteq \mathbb{R}^n$ be a closed set, and consider the problem of computing the minimum $f_{\min}$ of a polynomial $f$ on $\mathbf{X}$. Given a measure $\mu$ supported on $\mathbf{X}$, Lasserre (SIAM J. Optim. 21(3), 2011) proposes a decreasing sequence of upper bounds on $f_{\min}$, each of which may be computed by solving a semidefinite program. When $\mathbf{X}$ is compact, these bounds converge to $f_{\min}$ under minor assumptions on $\mu$. Later, Lasserre (Math. Program. 190, 2020) introduces a related, but far more economical sequence of upper bounds which rely on the push-forward measure of $\mu$ by $f$. While these new bounds are weaker a priori, they actually achieve similar asymptotic convergence rates on compact sets. In this work, we show that no such free lunch exists in the non-compact setting. While convergence of the standard bounds to $f_{\min}$ is guaranteed when $\mathbf{X} = \mathbb{R}^n$ and $\mu$ is a Gaussian distribution, we prove that the bounds relying on the push-forward measure fail to converge to $f_{\min}$ in that setting already for polynomials of degree $6$.</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.09710v1</guid>
      <category>math.OC</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Lucas Slot, Manuel Wiedmer</dc:creator>
    </item>
    <item>
      <title>Gradient descent for unbounded convex functions on Hadamard manifolds and its applications to scaling problems</title>
      <link>https://arxiv.org/abs/2404.09746</link>
      <description>arXiv:2404.09746v1 Announce Type: new 
Abstract: In this paper, we study asymptotic behaviors of continuous-time and discrete-time gradient flows of a ``lower-unbounded" convex function $f$ on a Hadamard manifold $M$, particularly, their convergence properties to the boundary $M^{\infty}$ at infinity of $M$. We establish a duality theorem that the infimum of the gradient-norm $\|\nabla f(x)\|$ of $f$ over $M$ is equal to the supremum of the negative of the recession function $f^{\infty}$ of $f$ over the boundary $M^{\infty}$, provided the infimum is positive. Further, the infimum and the supremum are obtained by the limits of the gradient flows of $f$, Our results feature convex-optimization ingredients of the moment-weight inequality for reductive group actions by Georgoulas, Robbin, and Salamon,and are applied to noncommutative optimization by B\"urgisser et al. FOCS 2019. We show that the gradient descent of the Kempf-Ness function for an unstable orbit converges to a 1-parameter subgroup in the Hilbert-Mumford criterion, and the associated moment-map sequence converges to the mimimum-norm point of the moment polytope. We show further refinements for operator scaling -- the left-right action on a matrix tuple $A= (A_1,A_2,\ldots,A_N)$. We characterize the gradient-flow limit of operator scaling via a vector-space generalization of the classical Dulmage-Mendelsohn decomposition of a bipartite graph. Also, for a special case of $N = 2$, we reveal that this limit determines the Kronecker canonical form of matrix pencils $s A_1+A_2$.</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.09746v1</guid>
      <category>math.OC</category>
      <category>math.DG</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Hiroshi Hirai, Keiya Sakabe</dc:creator>
    </item>
    <item>
      <title>A cut-and-project perspective for linearized Bregman iterations</title>
      <link>https://arxiv.org/abs/2404.09776</link>
      <description>arXiv:2404.09776v1 Announce Type: new 
Abstract: The linearized Bregman iterations (LBreI) and its variants are powerful tools for finding sparse or low-rank solutions to underdetermined linear systems. In this study, we propose a cut-and-project perspective for the linearized Bregman method via a bilevel optimization formulation, along with a new unified algorithmic framework. The new perspective not only encompasses various existing linearized Bregman iteration variants as specific instances, but also allows us to extend the linearized Bregman method to solve more general inverse problems. We provide a completed convergence result of the proposed algorithmic framework, including convergence guarantees to feasible points and optimal solutions, and the sublinear convergence rate. Moreover, we introduce the Bregman distance growth condition to ensure linear convergence. At last, our findings are illustrated via numerical tests.</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.09776v1</guid>
      <category>math.OC</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Yu-Hong Dai, Kangkang Deng, Hui Zhang</dc:creator>
    </item>
    <item>
      <title>The Challenges of Optimization For Data Science</title>
      <link>https://arxiv.org/abs/2404.09810</link>
      <description>arXiv:2404.09810v1 Announce Type: new 
Abstract: Optimization problems arising in data science have given rise to a number of new derivative-based optimization methods. Such methods often use standard smoothness assumptions -- namely, global Lipschitz continuity of the gradient function -- to establish a convergence theory. Unfortunately, in this work, we show that common optimization problems from data science applications are not globally Lipschitz smooth, nor do they satisfy some more recently developed smoothness conditions in literature. Instead, we show that such optimization problems are better modeled as having locally Lipschitz continuous gradients. We then construct explicit examples satisfying this assumption on which existing classes of optimization methods are either unreliable or experience an explosion in evaluation complexity. In summary, we show that optimization problems arising in data science are particularly difficult to solve, and that there is a need for methods that can reliably and practically solve these problems.</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.09810v1</guid>
      <category>math.OC</category>
      <category>stat.CO</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Christian Varner, Vivak Patel</dc:creator>
    </item>
    <item>
      <title>A Systematic Methodology for Modeling and Attitude Control of Multi-body Space Telescopes</title>
      <link>https://arxiv.org/abs/2404.09869</link>
      <description>arXiv:2404.09869v1 Announce Type: new 
Abstract: This paper derives a symbolic multi-body rigid nonlinear model for a space telescope using Stoneking's implementation of Kane's method. This symbolic nonlinear model is linearized using Matlab symbolic functions {\tt diff} and {\tt inv} because the analytic linearization is intractable for manual derivation. The linearized system model is then used to design the controllers using both linear quadratic regulator (LQR) and robust pole assignment methods. The closed-loop systems for the two designs are simulated using both the rigid model as well as a second model containing flexible modes. The performances of the two designs are compared based on the simulation testing results. Our conclusion is that the robust pole assignment design offers better performance than that of the LQR system in terms of actuator usage and pointing accuracy. However, the LQR approach remains an effective first design step that can inform the selection of real eigenvalues for robust pole assignment. The proposed method may be used for the modeling and controller designs for various multi-body systems.</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.09869v1</guid>
      <category>math.OC</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Yaguang Yang, William Bentz, Lia Lewis</dc:creator>
    </item>
    <item>
      <title>Convergence of coordinate ascent variational inference for log-concave measures via optimal transport</title>
      <link>https://arxiv.org/abs/2404.08792</link>
      <description>arXiv:2404.08792v1 Announce Type: cross 
Abstract: Mean field variational inference (VI) is the problem of finding the closest product (factorized) measure, in the sense of relative entropy, to a given high-dimensional probability measure $\rho$. The well known Coordinate Ascent Variational Inference (CAVI) algorithm aims to approximate this product measure by iteratively optimizing over one coordinate (factor) at a time, which can be done explicitly. Despite its popularity, the convergence of CAVI remains poorly understood. In this paper, we prove the convergence of CAVI for log-concave densities $\rho$. If additionally $\log \rho$ has Lipschitz gradient, we find a linear rate of convergence, and if also $\rho$ is strongly log-concave, we find an exponential rate. Our analysis starts from the observation that mean field VI, while notoriously non-convex in the usual sense, is in fact displacement convex in the sense of optimal transport when $\rho$ is log-concave. This allows us to adapt techniques from the optimization literature on coordinate descent algorithms in Euclidean space.</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.08792v1</guid>
      <category>stat.ML</category>
      <category>cs.LG</category>
      <category>math.OC</category>
      <category>math.PR</category>
      <category>math.ST</category>
      <category>stat.TH</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Manuel Arnese, Daniel Lacker</dc:creator>
    </item>
    <item>
      <title>Local control on quaternionic Heisenberg group of dimension $7$</title>
      <link>https://arxiv.org/abs/2404.08953</link>
      <description>arXiv:2404.08953v1 Announce Type: cross 
Abstract: We describe the quaternionic Heisenberg group in the dimension $7$ as a matrix group. We study the local control of a compatible left-invariant control system. We describe the impact of symmetries of the corresponding sub-Riemannian structure on the optimality of geodesics.</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.08953v1</guid>
      <category>math.DG</category>
      <category>math.OC</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Jan Eisner, Lenka Zalabov\'a</dc:creator>
    </item>
    <item>
      <title>Queues with resetting: a perspective</title>
      <link>https://arxiv.org/abs/2404.08961</link>
      <description>arXiv:2404.08961v1 Announce Type: cross 
Abstract: Performance modeling is a key issue in queuing theory and operation research. It is well-known that the length of a queue that awaits service or the time spent by a job in a queue depends not only on the service rate, but also crucially on the fluctuations in service time. The larger the fluctuations, the longer the delay becomes and hence, this is a major hindrance for the queue to operate efficiently. Various strategies have been adapted to prevent this drawback. In this perspective, we investigate the effects of one such novel strategy namely resetting or restart, an emerging concept in statistical physics and stochastic complex process, that was recently introduced to mitigate fluctuations-induced delays in queues. In particular, we show that a service resetting mechanism accompanied with an overhead time can remarkably shorten the average queue lengths and waiting times. We examine various resetting strategies and further shed light on the intricate role of the overhead times to the queuing performance. Our analysis opens up future avenues in operation research where resetting-based strategies can be universally promising.</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.08961v1</guid>
      <category>cond-mat.stat-mech</category>
      <category>cs.PF</category>
      <category>cs.SY</category>
      <category>eess.SY</category>
      <category>math.OC</category>
      <category>math.PR</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <arxiv:DOI>10.1088/2632-072X/ad3e5a</arxiv:DOI>
      <dc:creator>Reshmi Roy, Arup Biswas, Arnab Pal</dc:creator>
    </item>
    <item>
      <title>Numerical Methods for Optimal Boundary Control of Advection-Diffusion-Reaction Systems</title>
      <link>https://arxiv.org/abs/2404.09209</link>
      <description>arXiv:2404.09209v1 Announce Type: cross 
Abstract: This paper considers the optimal boundary control of chemical systems described by advection-diffusion-reaction (ADR) equations. We use a discontinuous Galerkin finite element method (DG-FEM) for the spatial discretization of the governing partial differential equations, and the optimal control problem is directly discretized using multiple shooting. The temporal discretization and the corresponding sensitivity calculations are achieved by an explicit singly diagonally-implicit Runge Kutta (ESDIRK) method. ADR systems arise in process systems engineering and their operation can potentially be improved by nonlinear model predictive control (NMPC). We demonstrate a numerical approach for the solution to their optimal control problems (OCPs) in a chromatography case study. Preparative liquid chromatography is an important downstream process in biopharmaceutical manufacturing. We show that multi-step elution trajectories for batch processes can be optimized for economic objectives, providing superior performance compared to classical gradient elution trajectories.</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.09209v1</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <category>math.OC</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Marcus Johan Schytt, John Bagterp J{\o}rgensen</dc:creator>
    </item>
    <item>
      <title>Optimum Beamforming and Grating Lobe Mitigation for Intelligent Reflecting Surfaces</title>
      <link>https://arxiv.org/abs/2404.09215</link>
      <description>arXiv:2404.09215v1 Announce Type: cross 
Abstract: Ensuring adequate wireless coverage in upcoming communication technologies such as 6G is expected to be challenging. This is because user demands of higher datarate require an increase in carrier frequencies, which in turn reduce the diffraction effects (and hence coverage) in complex multipath environments. Intelligent reflecting surfaces have been proposed as a way of restoring coverage by adaptively reflecting incoming electromagnetic waves in desired directions. This is accomplished by judiciously adding extra phases at different points on the surface. In practice, these extra phases are only available in discrete quantities due to hardware constraints. Computing these extra phases is computationally challenging when they can only be picked from a discrete distribution, and existing approaches for solving this problem were either heuristic or based on evolutionary algorithms. We solve this problem by proposing fast algorithms with provably optimal solutions. Our algorithms have linear complexity, and are presented with rigorous proofs for their optimality. We show that the proposed algorithms exhibit better performance. We analyze situations when unwanted grating lobes arise in the radiation pattern, and discuss mitigation strategies, such as the use of triangular lattices and prephasing techniques, to eliminate them. We also demonstrate how our algorithms can leverage these techniques to deliver optimum beamforming solutions.</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.09215v1</guid>
      <category>eess.SP</category>
      <category>math.OC</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Sai Sanjay Narayanan, Uday K Khankhoje, Radha Krishna Ganti</dc:creator>
    </item>
    <item>
      <title>Optimal Control of a Markovian Qubit with Unitary Control</title>
      <link>https://arxiv.org/abs/2404.09279</link>
      <description>arXiv:2404.09279v1 Announce Type: cross 
Abstract: We study a single Markovian qubit governed by a Lindblad master equation and subject to fast unitary control. Using reduced control systems and optimal control theory we determine (i) controls for cooling and heating such systems in a time-optimal way as well as (ii) the set of stabilizable states in the Bloch ball. No restrictions on the Lindblad equation are assumed, and several known results, for instance for the Bloch equations, are recovered. Furthermore we introduce integral systems, for which the solutions take a particularly nice form. These integral systems include all systems with real Lindblad terms as well as all coolable systems. The method allows for intuitive visualizations and is mostly analytical, making use of only basic numerical methods.</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.09279v1</guid>
      <category>quant-ph</category>
      <category>math.OC</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Emanuel Malvetti</dc:creator>
    </item>
    <item>
      <title>Revisiting some classical linearizations of the quadratic binary optimization problem</title>
      <link>https://arxiv.org/abs/2404.09437</link>
      <description>arXiv:2404.09437v1 Announce Type: cross 
Abstract: In this paper, we present several new linearizations of a quadratic binary optimization problem (QBOP), primarily using the method of aggregations. Although aggregations were studied in the past in the context of solving system of Diophantine equations in non-negative variables, none of the approaches developed produced practical models, particularly due to the large size of associate multipliers. Exploiting the special structure of QBOP we show that selective aggregation of constraints provide valid linearizations with interesting properties. For our aggregations, multipliers can be any non-zero real numbers. Moreover, choosing the multipliers appropriately, we demonstrate that the resulting LP relaxations have value identical to the corresponding non-aggregated models. We also provide a review of existing explicit linearizations of QBOP and presents the first systematic study of such models. Theoretical and experimental comparisons of new and existing models are also provided.</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.09437v1</guid>
      <category>cs.DM</category>
      <category>math.OC</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Abraham P. Punnen (Department of Mathematics, Simon Fraser University Surrey, BC, Canada), Navpreet Kaur (Department of Mathematics, Simon Fraser University Surrey, BC, Canada)</dc:creator>
    </item>
    <item>
      <title>LatticeML: A data-driven application for predicting the effective Young Modulus of high temperature graph based architected materials</title>
      <link>https://arxiv.org/abs/2404.09470</link>
      <description>arXiv:2404.09470v1 Announce Type: cross 
Abstract: Architected materials with their unique topology and geometry offer the potential to modify physical and mechanical properties. Machine learning can accelerate the design and optimization of these materials by identifying optimal designs and forecasting performance. This work presents LatticeML, a data-driven application for predicting the effective Young's Modulus of high-temperature graph-based architected materials. The study considers eleven graph-based lattice structures with two high-temperature alloys, Ti-6Al-4V and Inconel 625. Finite element simulations were used to compute the effective Young's Modulus of the 2x2x2 unit cell configurations. A machine learning framework was developed to predict Young's Modulus, involving data collection, preprocessing, implementation of regression models, and deployment of the best-performing model. Five supervised learning algorithms were evaluated, with the XGBoost Regressor achieving the highest accuracy (MSE = 2.7993, MAE = 1.1521, R-squared = 0.9875). The application uses the Streamlit framework to create an interactive web interface, allowing users to input material and geometric parameters and obtain predicted Young's Modulus values.</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.09470v1</guid>
      <category>cs.LG</category>
      <category>cs.AI</category>
      <category>cs.HC</category>
      <category>math.OC</category>
      <category>physics.app-ph</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Akshansh Mishra</dc:creator>
    </item>
    <item>
      <title>MPC using mixed-integer programming for aquifer thermal energy storages</title>
      <link>https://arxiv.org/abs/2404.09786</link>
      <description>arXiv:2404.09786v1 Announce Type: cross 
Abstract: Aquifer thermal energy storages (ATES) are used to temporally store thermal energy in groundwater saturated aquifers. Typically, two storages are combined, one for heat and one for cold, to support heating and cooling of buildings. This way, the use of classical fossil fuel-based heating, ventilation, and air conditioning can be significantly reduced. Exploiting the benefits of ATES beyond ``seasonal'' heating in winter and cooling in summer as well as meeting legislative restrictions requires sophisticated control. We propose a tailored model predictive control (MPC) scheme for the sustainable operation of ATES systems, which mainly builds on a novel model and objective function. The new approach leads to a mixed-integer quadratic program. Its performance is evaluated on real data from an ATES system in Belgium.</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.09786v1</guid>
      <category>eess.SY</category>
      <category>cs.SY</category>
      <category>math.OC</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Johannes van Randenborgh, Moritz Schulze Darup</dc:creator>
    </item>
    <item>
      <title>Steering opinion dynamics through control of social networks</title>
      <link>https://arxiv.org/abs/2404.09849</link>
      <description>arXiv:2404.09849v1 Announce Type: cross 
Abstract: In this paper we propose a novel control approach for opinion dynamics on evolving networks. The controls modify the strength of connections in the network, rather than influencing opinions directly, with the overall goal of steering the population towards a target opinion. This requires that the social network remains sufficiently connected, the population does not break into separate opinion clusters, and that the target opinion remains accessible. We present several approaches to addressing these challenges, considering questions of controllability, instantaneous control and optimal control. Each of these approaches provides a different view on the complex relationship between opinion and network dynamics and raises interesting questions for future research.</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.09849v1</guid>
      <category>physics.soc-ph</category>
      <category>math.DS</category>
      <category>math.OC</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Andrew Nugent, Susana N. Gomes, Marie-Therese Wolfram</dc:creator>
    </item>
    <item>
      <title>Sample-Based Conservative Bias Linear Power Flow Approximations</title>
      <link>https://arxiv.org/abs/2404.09876</link>
      <description>arXiv:2404.09876v1 Announce Type: cross 
Abstract: The power flow equations are central to many problems in power system planning, analysis, and control. However, their inherent non-linearity and non-convexity present substantial challenges during problem-solving processes, especially for optimization problems. Accordingly, linear approximations are commonly employed to streamline computations, although this can often entail compromises in accuracy and feasibility. This paper proposes an approach termed Conservative Bias Linear Approximations (CBLA) for addressing these limitations. By minimizing approximation errors across a specified operating range while incorporating conservativeness (over- or under-estimating quantities of interest), CBLA strikes a balance between accuracy and tractability by maintaining linear constraints. By allowing users to design loss functions tailored to the specific approximated function, the bias approximation approach significantly enhances approximation accuracy. We illustrate the effectiveness of our proposed approach through several test cases.</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.09876v1</guid>
      <category>eess.SY</category>
      <category>cs.SY</category>
      <category>math.OC</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Paprapee Buason, Sidhant Misra, Daniel K. Molzahn</dc:creator>
    </item>
    <item>
      <title>Global controllability of Boussinesq flows by using only a temperature control</title>
      <link>https://arxiv.org/abs/2404.09903</link>
      <description>arXiv:2404.09903v1 Announce Type: cross 
Abstract: We show that buoyancy driven flows can be steered in an arbitrary time towards any state by applying as control only an external temperature profile in a subset of small measure. More specifically, we prove that the 2D incompressible Boussinesq system on the torus is globally approximately controllable via physically localized heating or cooling. In addition, our controls have an explicitly prescribed structure; even without such structural requirements, large data controllability results for Boussinesq flows driven merely by a physically localized temperature profile were so far unknown. The presented method exploits various connections between the model's underlying transport-, coupling-, and scaling mechanisms.</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.09903v1</guid>
      <category>math.AP</category>
      <category>math.OC</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Vahagn Nersesyan, Manuel Rissel</dc:creator>
    </item>
    <item>
      <title>Mutually unbiased bases: polynomial optimization and symmetry</title>
      <link>https://arxiv.org/abs/2111.05698</link>
      <description>arXiv:2111.05698v5 Announce Type: replace 
Abstract: A set of $k$ orthonormal bases of $\mathbb C^d$ is called mutually unbiased if $|\langle e,f\rangle |^2 = 1/d$ whenever $e$ and $f$ are basis vectors in distinct bases. A natural question is for which pairs $(d,k)$ there exist~$k$ mutually unbiased bases in dimension $d$. The (well-known) upper bound $k \leq d+1$ is attained when~$d$ is a power of a prime. For all other dimensions it is an open problem whether the bound can be attained. Navascu\'es, Pironio, and Ac\'in showed how to reformulate the existence question in terms of the existence of a certain $C^*$-algebra. This naturally leads to a noncommutative polynomial optimization problem and an associated hierarchy of semidefinite programs. The problem has a symmetry coming from the wreath product of $S_d$ and $S_k$.
  We exploit this symmetry (analytically) to reduce the size of the semidefinite programs making them (numerically) tractable. A key step is a novel explicit decomposition of the $S_d \wr S_k$-module $\mathbb C^{([d]\times [k])^t}$ into irreducible modules. We present numerical results for small $d,k$ and low levels of the hierarchy. In particular, we obtain sum-of-squares proofs for the (well-known) fact that there do not exist $d+2$ mutually unbiased bases in dimensions~$d=2,3,4,5,6,7,8$. Moreover, our numerical results indicate that a sum-of-squares refutation, in the above-mentioned framework, of the existence of more than $3$ MUBs in dimension $6$ requires polynomials of total degree at least~$12$.</description>
      <guid isPermaLink="false">oai:arXiv.org:2111.05698v5</guid>
      <category>math.OC</category>
      <category>math.RT</category>
      <category>quant-ph</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Sander Gribling, Sven Polak</dc:creator>
    </item>
    <item>
      <title>Statistical Inference of Constrained Stochastic Optimization via Sketched Sequential Quadratic Programming</title>
      <link>https://arxiv.org/abs/2205.13687</link>
      <description>arXiv:2205.13687v4 Announce Type: replace 
Abstract: We consider online statistical inference of constrained stochastic nonlinear optimization problems. We apply the Stochastic Sequential Quadratic Programming (StoSQP) method to solve these problems, which can be regarded as applying second-order Newton's method to the Karush-Kuhn-Tucker (KKT) conditions. In each iteration, the StoSQP method computes the Newton direction by solving a quadratic program, and then selects a proper adaptive stepsize $\bar{\alpha}_t$ to update the primal-dual iterate. To reduce dominant computational cost of the method, we inexactly solve the quadratic program in each iteration by employing an iterative sketching solver. Notably, the approximation error of the sketching solver need not vanish as iterations proceed, meaning that the per-iteration computational cost does not blow up. For the above StoSQP method, we show that under mild assumptions, the rescaled primal-dual sequence $1/\sqrt{\bar{\alpha}_t}\cdot (x_t - x^\star, \lambda_t - \lambda^\star)$ converges to a mean-zero Gaussian distribution with a nontrivial covariance matrix depending on the underlying sketching distribution. To perform inference in practice, we also analyze a plug-in covariance matrix estimator. We illustrate the asymptotic normality result of the method both on benchmark nonlinear problems in CUTEst test set and on linearly/nonlinearly constrained regression problems.</description>
      <guid isPermaLink="false">oai:arXiv.org:2205.13687v4</guid>
      <category>math.OC</category>
      <category>cs.LG</category>
      <category>stat.ML</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Sen Na, Michael W. Mahoney</dc:creator>
    </item>
    <item>
      <title>Computing Brascamp-Lieb Constants through the lens of Thompson Geometry</title>
      <link>https://arxiv.org/abs/2208.05013</link>
      <description>arXiv:2208.05013v3 Announce Type: replace 
Abstract: This paper studies algorithms for efficiently computing Brascamp-Lieb constants, a task that has recently received much interest. In particular, we reduce the computation to a nonlinear matrix-valued iteration, whose convergence we analyze through the lens of fixed-point methods under the well-known Thompson metric. This approach permits us to obtain (weakly) polynomial time guarantees, and it offers an efficient and transparent alternative to previous state-of-the-art approaches based on Riemannian optimization and geodesic convexity.</description>
      <guid isPermaLink="false">oai:arXiv.org:2208.05013v3</guid>
      <category>math.OC</category>
      <category>cs.CC</category>
      <category>cs.DS</category>
      <category>math.FA</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Melanie Weber, Suvrit Sra</dc:creator>
    </item>
    <item>
      <title>High Probability Bounds for Stochastic Subgradient Schemes with Heavy Tailed Noise</title>
      <link>https://arxiv.org/abs/2208.08567</link>
      <description>arXiv:2208.08567v2 Announce Type: replace 
Abstract: In this work we study high probability bounds for stochastic subgradient methods under heavy tailed noise. In this setting the noise is only assumed to have finite variance as opposed to a sub-Gaussian distribution for which it is known that standard subgradient methods enjoys high probability bounds. We analyzed a clipped version of the projected stochastic subgradient method, where subgradient estimates are truncated whenever they have large norms. We show that this clipping strategy leads both to near optimal any-time and finite horizon bounds for many classical averaging schemes. Preliminary experiments are shown to support the validity of the method.</description>
      <guid isPermaLink="false">oai:arXiv.org:2208.08567v2</guid>
      <category>math.OC</category>
      <category>stat.ML</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Daniela A. Parletta, Andrea Paudice, Massimiliano Pontil, Saverio Salzo</dc:creator>
    </item>
    <item>
      <title>Learning Decentralized Linear Quadratic Regulator with $\sqrt{T}$ Regret</title>
      <link>https://arxiv.org/abs/2210.08886</link>
      <description>arXiv:2210.08886v3 Announce Type: replace 
Abstract: We propose an online learning algorithm that adaptively designs a decentralized linear quadratic regulator when the system model is unknown a priori and new data samples from a single system trajectory become progressively available. The algorithm uses a disturbance-feedback representation of state-feedback controllers coupled with online convex optimization with memory and delayed feedback. Under the assumption that the system is stable or given a known stabilizing controller, we show that our controller enjoys an expected regret that scales as $\sqrt{T}$ with the time horizon $T$ for the case of partially nested information pattern. For more general information patterns, the optimal controller is unknown even if the system model is known. In this case, the regret of our controller is shown with respect to a linear sub-optimal controller. We validate our theoretical findings using numerical experiments.</description>
      <guid isPermaLink="false">oai:arXiv.org:2210.08886v3</guid>
      <category>math.OC</category>
      <category>cs.LG</category>
      <category>cs.SY</category>
      <category>eess.SY</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Lintao Ye, Ming Chi, Ruiquan Liao, Vijay Gupta</dc:creator>
    </item>
    <item>
      <title>Accelerated Optimization Landscape of Linear-Quadratic Regulator</title>
      <link>https://arxiv.org/abs/2307.03590</link>
      <description>arXiv:2307.03590v3 Announce Type: replace 
Abstract: Linear-quadratic regulator (LQR) is a landmark problem in the field of optimal control, which is the concern of this paper. Generally, LQR is classified into state-feedback LQR (SLQR) and output-feedback LQR (OLQR) based on whether the full state is obtained. It has been suggested in existing literature that both SLQR and OLQR could be viewed as \textit{constrained nonconvex matrix optimization} problems in which the only variable to be optimized is the feedback gain matrix. In this paper, we introduce a first-order accelerated optimization framework of handling the LQR problem, and give its convergence analysis for the cases of SLQR and OLQR, respectively.
  Specifically, a Lipschiz Hessian property of LQR performance criterion is presented, which turns out to be a crucial property for the application of modern optimization techniques. For the SLQR problem, a continuous-time hybrid dynamic system is introduced, whose solution trajectory is shown to converge exponentially to the optimal feedback gain with Nesterov-optimal order $1-\frac{1}{\sqrt{\kappa}}$ ($\kappa$ the condition number). Then, the symplectic Euler scheme is utilized to discretize the hybrid dynamic system, and a Nesterov-type method with a restarting rule is proposed that preserves the continuous-time convergence rate, i.e., the discretized algorithm admits the Nesterov-optimal convergence order. For the OLQR problem, a Hessian-free accelerated framework is proposed, which is a two-procedure method consisting of semiconvex function optimization and negative curvature exploitation. In a time $\mathcal{O}(\epsilon^{-7/4}\log(1/\epsilon))$, the method can find an $\epsilon$-stationary point of the performance criterion; this entails that the method improves upon the $\mathcal{O}(\epsilon^{-2})$ complexity of vanilla gradient descent. Moreover, our method provides the second-order guarantee of stationary point.</description>
      <guid isPermaLink="false">oai:arXiv.org:2307.03590v3</guid>
      <category>math.OC</category>
      <category>cs.LG</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Lechen Feng, Yuan-Hua Ni</dc:creator>
    </item>
    <item>
      <title>An Algorithm with Optimal Dimension-Dependence for Zero-Order Nonsmooth Nonconvex Stochastic Optimization</title>
      <link>https://arxiv.org/abs/2307.04504</link>
      <description>arXiv:2307.04504v3 Announce Type: replace 
Abstract: We study the complexity of producing $(\delta,\epsilon)$-stationary points of Lipschitz objectives which are possibly neither smooth nor convex, using only noisy function evaluations. Recent works proposed several stochastic zero-order algorithms that solve this task, all of which suffer from a dimension-dependence of $\Omega(d^{3/2})$ where $d$ is the dimension of the problem, which was conjectured to be optimal. We refute this conjecture by providing a faster algorithm that has complexity $O(d\delta^{-1}\epsilon^{-3})$, which is optimal (up to numerical constants) with respect to $d$ and also optimal with respect to the accuracy parameters $\delta,\epsilon$, thus solving an open question due to Lin et al. (NeurIPS'22). Moreover, the convergence rate achieved by our algorithm is also optimal for smooth objectives, proving that in the nonconvex stochastic zero-order setting, nonsmooth optimization is as easy as smooth optimization. We provide algorithms that achieve the aforementioned convergence rate in expectation as well as with high probability. Our analysis is based on a simple yet powerful lemma regarding the Goldstein-subdifferential set, which allows utilizing recent advancements in first-order nonsmooth nonconvex optimization.</description>
      <guid isPermaLink="false">oai:arXiv.org:2307.04504v3</guid>
      <category>math.OC</category>
      <category>cs.LG</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Guy Kornowski, Ohad Shamir</dc:creator>
    </item>
    <item>
      <title>Disturbance attenuation in the Euler-Bernoulli beam using piezoelectric actuators</title>
      <link>https://arxiv.org/abs/2308.05551</link>
      <description>arXiv:2308.05551v2 Announce Type: replace 
Abstract: We consider a simply-supported Euler-Bernoulli beam with viscous and Kelvin-Voigt damping. Our objective is to attenuate the effect of an unknown distributed disturbance using one piezoelectric actuator. We show how to design a suitable $H_\infty$ state-feedback controller based on a finite number of dominating modes. If the remaining (infinitely many) modes are ignored, the calculated $L^2$ gain is wrong. This happens because of the spillover phenomenon that occurs when the effect of the control on truncated modes is not accounted for in the feedback design. We propose a simple modification of the $H_\infty$ cost that prevents spillover. The key idea is to treat the control as a disturbance in the truncated modes and find the corresponding $L^2$ gains using the bounded real lemma. These $L^2$ gains are added to the control weight in the $H_\infty$ cost for the dominating modes, which prevents spillover. A numerical simulation of an aluminum beam with realistic parameters demonstrates the effectiveness of the proposed method.</description>
      <guid isPermaLink="false">oai:arXiv.org:2308.05551v2</guid>
      <category>math.OC</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Anton Selivanov, Emilia Fridman</dc:creator>
    </item>
    <item>
      <title>A search-free $O(1/k^{3/2})$ homotopy inexact proximal-Newton extragradient algorithm for monotone variational inequalities</title>
      <link>https://arxiv.org/abs/2308.05887</link>
      <description>arXiv:2308.05887v2 Announce Type: replace 
Abstract: We present and study the iteration-complexity of a relative-error inexact proximal-Newton extragradient algorithm for solving smooth monotone variational inequality problems in real Hilbert spaces. We removed a search procedure from Monteiro and Svaiter (2012) by introducing a novel approach based on homotopy, which requires the resolution (at each iteration) of a single strongly monotone linear variational inequality. For a given tolerance $\rho&gt;0$, our main algorithm exhibits pointwise $O\left(\frac{1}{\rho}\right)$ and ergodic $O\left(\frac{1}{\rho^{2/3}}\right)$ iteration-complexities. From a practical perspective, preliminary numerical experiments indicate that our main algorithm outperforms some previous proximal-Newton schemes.</description>
      <guid isPermaLink="false">oai:arXiv.org:2308.05887v2</guid>
      <category>math.OC</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>M. Marques Alves, Jo\~ao M. Pereira, Benar F. Svaiter</dc:creator>
    </item>
    <item>
      <title>A Control Theoretical Approach to Online Constrained Optimization</title>
      <link>https://arxiv.org/abs/2309.15498</link>
      <description>arXiv:2309.15498v2 Announce Type: replace 
Abstract: In this paper we focus on the solution of online problems with time-varying, linear equality and inequality constraints. Our approach is to design a novel online algorithm by leveraging the tools of control theory. In particular, for the case of equality constraints only, using robust control we design an online algorithm with asymptotic convergence to the optimal trajectory, differently from the alternatives that achieve non-zero tracking error. When also inequality constraints are present, we show how to modify the proposed algorithm to account for the wind-up induced by the nonnegativity constraints on the dual variables. We report numerical results that corroborate the theoretical analysis, and show how the proposed approach outperforms state-of-the-art algorithms both with equality and inequality constraints.</description>
      <guid isPermaLink="false">oai:arXiv.org:2309.15498v2</guid>
      <category>math.OC</category>
      <category>cs.SY</category>
      <category>eess.SY</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Umberto Casti, Nicola Bastianello, Ruggero Carli, Sandro Zampieri</dc:creator>
    </item>
    <item>
      <title>Minimum-time interception of a moving target by a material point in a viscous medium</title>
      <link>https://arxiv.org/abs/2311.05264</link>
      <description>arXiv:2311.05264v2 Announce Type: replace 
Abstract: In this paper we investigated a model that describes the motion of a material point in a viscous medium under a force that is arbitrary in direction, but limited in magnitude. This model was named "the isotropic rocket" in the early work of Rufus Isaacs. We obtained a parametric description of a reachable set for the isotropic rocket and solved a group of reachability problems for a final configuration that varies in a known time-dependent manner (moving target). To describe the reachable set, we obtained an explicit parametric form of its boundary and all its projections onto all subspaces of the state space. Convergent algorithms have been proposed for computing minimum-time interception in position and velocity spaces. Finally, we numerically investigated particular cases of minimum-time interception, validating the development of this study.</description>
      <guid isPermaLink="false">oai:arXiv.org:2311.05264v2</guid>
      <category>math.OC</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <dc:creator>Maksim E. Buzikov, Alina M. Mayer</dc:creator>
    </item>
    <item>
      <title>Near-optimal Closed-loop Method via Lyapunov Damping for Convex Optimization</title>
      <link>https://arxiv.org/abs/2311.10053</link>
      <description>arXiv:2311.10053v2 Announce Type: replace 
Abstract: We introduce an autonomous system with closed-loop damping for first-order convex optimization. While, to this day, optimal rates of convergence are almost exclusively achieved by non-autonomous methods via open-loop damping (e.g., Nesterov's algorithm), we show that our system, featuring a closed-loop damping, exhibits a rate arbitrarily close to the optimal one. We do so by coupling the damping and the speed of convergence of the system via a well-chosen Lyapunov function. By discretizing our system we then derive an algorithm and present numerical experiments supporting our theoretical findings.</description>
      <guid isPermaLink="false">oai:arXiv.org:2311.10053v2</guid>
      <category>math.OC</category>
      <category>cs.LG</category>
      <category>math.DS</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Severin Maier, Camille Castera, Peter Ochs</dc:creator>
    </item>
    <item>
      <title>Dynamic Information Manipulation Game</title>
      <link>https://arxiv.org/abs/2312.07862</link>
      <description>arXiv:2312.07862v2 Announce Type: replace 
Abstract: We propose a dynamic information manipulation game (DIMG) to investigate the incentives of an information manipulator (IM) to influence the observation rules of a partially observable Markov decision process (POMDP). DIMG is a hierarchical game where the upper-level IM stealthily designs the POMDP's joint state distributions to influence the lower-level controller's actions. DIMP's fundamental feature is characterized by a stage-wise constraint that ensures the consistency between the unobservable marginals of the designed and the original kernels. In an equilibrium of information distortion, the IM minimizes cumulative cost that depends on the controller's informationally manipulated actions generated by the optimal policy to the POMDP. We characterize ex ante and interim equilibria of information distortion and show their connections. The IM's impact is characterized by a tight upper-bound on the performance degradation of the POMDP, which consists of the stage-wise instantaneous informational differences scaled by the amplifications at subsequent stages.</description>
      <guid isPermaLink="false">oai:arXiv.org:2312.07862v2</guid>
      <category>math.OC</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Shutian Liu, Quanyan Zhu</dc:creator>
    </item>
    <item>
      <title>On the $O(\frac{\sqrt{d}}{T^{1/4}})$ Convergence Rate of RMSProp and Its Momentum Extension Measured by $\ell_1$ Norm</title>
      <link>https://arxiv.org/abs/2402.00389</link>
      <description>arXiv:2402.00389v3 Announce Type: replace 
Abstract: Although adaptive gradient methods have been extensively used in deep learning, their convergence rates proved in the literature are all slower than that of SGD, particularly with respect to their dependence on the dimension. This paper considers the classical RMSProp and its momentum extension and establishes the convergence rate of $\frac{1}{T}\sum_{k=1}^T E\left[\|\nabla f(x^k)\|_1\right]\leq O(\frac{\sqrt{d}C}{T^{1/4}})$ measured by $\ell_1$ norm without the bounded gradient assumption, where $d$ is the dimension of the optimization variable, $T$ is the iteration number, and $C$ is a constant identical to that appeared in the optimal convergence rate of SGD. Our convergence rate matches the lower bound with respect to all the coefficients except the dimension $d$. Since $\|x\|_2\ll\|x\|_1\leq\sqrt{d}\|x\|_2$ for problems with extremely large $d$, our convergence rate can be considered to be analogous to the $\frac{1}{T}\sum_{k=1}^T E\left[\|\nabla f(x^k)\|_2\right]\leq O(\frac{C}{T^{1/4}})$ rate of SGD in the ideal case of $\|\nabla f(x)\|_1=\varTheta(\sqrt{d}\|\nabla f(x)\|_2)$.</description>
      <guid isPermaLink="false">oai:arXiv.org:2402.00389v3</guid>
      <category>math.OC</category>
      <category>cs.AI</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Huan Li, Zhouchen Lin</dc:creator>
    </item>
    <item>
      <title>Managing Distributional Ambiguity in Stochastic Optimization through a Statistical Upper Bound Framework</title>
      <link>https://arxiv.org/abs/2403.08966</link>
      <description>arXiv:2403.08966v2 Announce Type: replace 
Abstract: Stochastic optimization is often hampered by distributional ambiguity, where critical probability distributions are poorly characterized or unknown. Addressing this challenge, we introduce a new framework that targets the minimization of a statistical upper bound for the expected value of uncertain objectives, facilitating more statistically robust decision-making. Central to our approach is the Average Percentile Upper Bound (APUB), a novel construct that simultaneously delivers a statistically rigorous upper bound for the population mean and a meaningful risk metric for the sample mean. The integration of APUB into stochastic optimization not only fortifies the process against distributional ambiguity but also reinforces key data-driven decision-making attributes, such as reliability, consistency, and comprehensibility. Notably, APUB-enriched optimization problems feature tractability, with particular advantages in two-stage stochastic optimization with random recourse. Empirical demonstrations on two-stage product mix and multi-product newsvendor benchmark problems reveal the benefit of the APUB optimization framework, in comparison with conventional techniques such as sample average approximation and distributionally robust optimization.</description>
      <guid isPermaLink="false">oai:arXiv.org:2403.08966v2</guid>
      <category>math.OC</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Shixin Liu, Jian Hu</dc:creator>
    </item>
    <item>
      <title>Stochastic Halpern iteration in normed spaces and applications to reinforcement learning</title>
      <link>https://arxiv.org/abs/2403.12338</link>
      <description>arXiv:2403.12338v2 Announce Type: replace 
Abstract: We analyze the oracle complexity of the stochastic Halpern iteration with variance reduction, where we aim to approximate fixed-points of nonexpansive and contractive operators in a normed finite-dimensional space. We show that if the underlying stochastic oracle is with uniformly bounded variance, our method exhibits an overall oracle complexity of $\tilde{O}(\varepsilon^{-5})$, improving recent rates established for the stochastic Krasnoselskii-Mann iteration. Also, we establish a lower bound of $\Omega(\varepsilon^{-3})$, which applies to a wide range of algorithms, including all averaged iterations even with minibatching. Using a suitable modification of our approach, we derive a $O(\varepsilon^{-2}(1-\gamma)^{-3})$ complexity bound in the case in which the operator is a $\gamma$-contraction. As an application, we propose new synchronous algorithms for average reward and discounted reward Markov decision processes. In particular, for the average reward, our method improves on the best-known sample complexity.</description>
      <guid isPermaLink="false">oai:arXiv.org:2403.12338v2</guid>
      <category>math.OC</category>
      <category>cs.LG</category>
      <category>stat.ML</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Mario Bravo, Juan Pablo Contreras</dc:creator>
    </item>
    <item>
      <title>Direct Approach of Indefinite Linear-Quadratic Mean Field Games</title>
      <link>https://arxiv.org/abs/2404.05166</link>
      <description>arXiv:2404.05166v2 Announce Type: replace 
Abstract: This paper is concerned with an indefinite linear-quadratic (LQ) mean field games of stochastic large-polulation system, where the individual diffusion coefficients can depend on both the state and the control of the agents and the population state average. Moreover, the control weights in the cost functionals could be indefinite. We use a direct approach to derive the $\epsilon$-Nash equilibrium strategy. First, we formally solving an $N$-player game problem within a vast and finite population setting. Subsequently, decoupling or reducing high-dimensional systems by introducing two Riccati equations explicitly yields centralized strategies, contingent on the state of a specific player and the average state of the population. As the population size $N$ approaches infinity, the construction of decentralized strategies becomes feasible. Then, we demonstrated they are an $\epsilon$-Nash equilibrium.</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.05166v2</guid>
      <category>math.OC</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/publicdomain/zero/1.0/</dc:rights>
      <dc:creator>Wenyu Cong, Jingtao Shi</dc:creator>
    </item>
    <item>
      <title>Equitable Routing -- Rethinking the Multiple Traveling Salesman Problem</title>
      <link>https://arxiv.org/abs/2404.08157</link>
      <description>arXiv:2404.08157v2 Announce Type: replace 
Abstract: The Multiple Traveling Salesman Problem (MTSP) with a single depot is a generalization of the well-known Traveling Salesman Problem (TSP) that involves an additional parameter, namely, the number of salesmen. In the MTSP, several salesmen at the depot need to visit a set of interconnected targets, such that each target is visited precisely once by at most one salesman while minimizing the total length of their tours. An equally important variant of the MTSP, the min-max MTSP, aims to distribute the workload (length of the individual tours) among salesmen by requiring the longest tour of all the salesmen to be as short as possible, i.e., minimizing the maximum tour length among all salesmen. The min-max MTSP appears in real-life applications to ensure a good balance of workloads for the salesmen. It is known in the literature that the min-max MTSP is notoriously difficult to solve to optimality due to the poor lower bounds its linear relaxations provide. In this paper, we formulate two novel parametric variants of the MTSP called the "fair-MTSP". One variant is formulated as a Mixed-Integer Second Order Cone Program (MISOCP), and the other as a Mixed Integer Linear Program (MILP). Both focus on enforcing the workloads for the salesmen to be equitable, i.e., the distribution of tour lengths for the salesmen to be fair while minimizing the total cost of their tours. We present algorithms to solve the two variants of the fair-MTSP to global optimality and computational results on benchmark and real-world test instances that make a case for fair-MTSP as a viable alternative to the min-max MTSP.</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.08157v2</guid>
      <category>math.OC</category>
      <category>cs.RO</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Abhay Singh Bhadoriya, Deepjyoti Deka, Kaarthik Sundar</dc:creator>
    </item>
    <item>
      <title>Improving Convergence and Generalization Using Parameter Symmetries</title>
      <link>https://arxiv.org/abs/2305.13404</link>
      <description>arXiv:2305.13404v3 Announce Type: replace-cross 
Abstract: In many neural networks, different values of the parameters may result in the same loss value. Parameter space symmetries are loss-invariant transformations that change the model parameters. Teleportation applies such transformations to accelerate optimization. However, the exact mechanism behind this algorithm's success is not well understood. In this paper, we show that teleportation not only speeds up optimization in the short-term, but gives overall faster time to convergence. Additionally, teleporting to minima with different curvatures improves generalization, which suggests a connection between the curvature of the minimum and generalization ability. Finally, we show that integrating teleportation into a wide range of optimization algorithms and optimization-based meta-learning improves convergence. Our results showcase the versatility of teleportation and demonstrate the potential of incorporating symmetry in optimization.</description>
      <guid isPermaLink="false">oai:arXiv.org:2305.13404v3</guid>
      <category>cs.LG</category>
      <category>math.OC</category>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Bo Zhao, Robert M. Gower, Robin Walters, Rose Yu</dc:creator>
    </item>
    <item>
      <title>Statistically Optimal K-means Clustering via Nonnegative Low-rank Semidefinite Programming</title>
      <link>https://arxiv.org/abs/2305.18436</link>
      <description>arXiv:2305.18436v5 Announce Type: replace-cross 
Abstract: $K$-means clustering is a widely used machine learning method for identifying patterns in large datasets. Recently, semidefinite programming (SDP) relaxations have been proposed for solving the $K$-means optimization problem, which enjoy strong statistical optimality guarantees. However, the prohibitive cost of implementing an SDP solver renders these guarantees inaccessible to practical datasets. In contrast, nonnegative matrix factorization (NMF) is a simple clustering algorithm widely used by machine learning practitioners, but it lacks a solid statistical underpinning and theoretical guarantees. In this paper, we consider an NMF-like algorithm that solves a nonnegative low-rank restriction of the SDP-relaxed $K$-means formulation using a nonconvex Burer--Monteiro factorization approach. The resulting algorithm is as simple and scalable as state-of-the-art NMF algorithms while also enjoying the same strong statistical optimality guarantees as the SDP. In our experiments, we observe that our algorithm achieves significantly smaller mis-clustering errors compared to the existing state-of-the-art while maintaining scalability.</description>
      <guid isPermaLink="false">oai:arXiv.org:2305.18436v5</guid>
      <category>stat.ML</category>
      <category>cs.LG</category>
      <category>math.OC</category>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Yubo Zhuang, Xiaohui Chen, Yun Yang, Richard Y. Zhang</dc:creator>
    </item>
    <item>
      <title>A Lightweight Method for Tackling Unknown Participation Statistics in Federated Averaging</title>
      <link>https://arxiv.org/abs/2306.03401</link>
      <description>arXiv:2306.03401v3 Announce Type: replace-cross 
Abstract: In federated learning (FL), clients usually have diverse participation statistics that are unknown a priori, which can significantly harm the performance of FL if not handled properly. Existing works aiming at addressing this problem are usually based on global variance reduction, which requires a substantial amount of additional memory in a multiplicative factor equal to the total number of clients. An important open problem is to find a lightweight method for FL in the presence of clients with unknown participation rates. In this paper, we address this problem by adapting the aggregation weights in federated averaging (FedAvg) based on the participation history of each client. We first show that, with heterogeneous participation statistics, FedAvg with non-optimal aggregation weights can diverge from the optimal solution of the original FL objective, indicating the need of finding optimal aggregation weights. However, it is difficult to compute the optimal weights when the participation statistics are unknown. To address this problem, we present a new algorithm called FedAU, which improves FedAvg by adaptively weighting the client updates based on online estimates of the optimal weights without knowing the statistics of client participation. We provide a theoretical convergence analysis of FedAU using a novel methodology to connect the estimation error and convergence. Our theoretical results reveal important and interesting insights, while showing that FedAU converges to an optimal solution of the original objective and has desirable properties such as linear speedup. Our experimental results also verify the advantage of FedAU over baseline methods with various participation patterns.</description>
      <guid isPermaLink="false">oai:arXiv.org:2306.03401v3</guid>
      <category>cs.LG</category>
      <category>cs.DC</category>
      <category>cs.IT</category>
      <category>math.IT</category>
      <category>math.OC</category>
      <category>stat.ML</category>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Shiqiang Wang, Mingyue Ji</dc:creator>
    </item>
    <item>
      <title>Finite-horizon Approximations and Episodic Equilibrium for Stochastic Games</title>
      <link>https://arxiv.org/abs/2310.07256</link>
      <description>arXiv:2310.07256v2 Announce Type: replace-cross 
Abstract: This paper proposes a finite-horizon approximation scheme and introduces episodic equilibrium as a solution concept for stochastic games (SGs), where agents strategize based on the current state and episode stage. The paper also establishes an upper bound on the approximation error that decays with the episode length for both discounted and time-averaged utilities. This approach bridges the gap in the analysis of finite and infinite-horizon SGs, and provides a unifying framework to address time-averaged and discounted utilities. To show the effectiveness of the scheme, the paper presents episodic, decentralized (i.e., payoff-based), and model-free learning dynamics proven to reach (near) episodic equilibrium in broad classes of SGs, including zero-sum, identical-interest and specific general-sum SGs with switching controllers for both time-averaged and discounted utilities.</description>
      <guid isPermaLink="false">oai:arXiv.org:2310.07256v2</guid>
      <category>cs.GT</category>
      <category>math.OC</category>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Muhammed O. Sayin</dc:creator>
    </item>
    <item>
      <title>Enhancing power grid resilience to cyber-physical attacks using distributed retail electricity markets</title>
      <link>https://arxiv.org/abs/2311.05145</link>
      <description>arXiv:2311.05145v2 Announce Type: replace-cross 
Abstract: We propose using a hierarchical retail market structure to alert and dispatch resources to mitigate cyber-physical attacks on a distribution grid. We simulate attacks where a number of generation nodes in a distribution grid are attacked. We show that the market is able to successfully meet the shortfall between demand and supply by utilizing the flexibility of remaining resources while minimizing any extra power that needs to be imported from the main transmission grid. This includes utilizing upward flexibility or reserves of remaining online generators and some curtailment or shifting of flexible loads, which results in higher costs. Using price signals and market-based coordination, the grid operator can achieve its objectives without direct control over distributed energy resources and is able to accurately compensate prosumers for the grid support they provide.</description>
      <guid isPermaLink="false">oai:arXiv.org:2311.05145v2</guid>
      <category>eess.SY</category>
      <category>cs.SY</category>
      <category>math.OC</category>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Vineet Jagadeesan Nair, Priyank Srivastava, Anuradha Annaswamy</dc:creator>
    </item>
    <item>
      <title>A Survey of Recent Advances in Optimization Methods for Wireless Communications</title>
      <link>https://arxiv.org/abs/2401.12025</link>
      <description>arXiv:2401.12025v2 Announce Type: replace-cross 
Abstract: Mathematical optimization is now widely regarded as an indispensable modeling and solution tool for the design of wireless communications systems. While optimization has played a significant role in the revolutionary progress in wireless communication and networking technologies from 1G to 5G and onto the future 6G, the innovations in wireless technologies have also substantially transformed the nature of the underlying mathematical optimization problems upon which the system designs are based and have sparked significant innovations in the development of methodologies to understand, to analyze, and to solve those problems. In this paper, we provide a comprehensive survey of recent advances in mathematical optimization theory and algorithms for wireless communication system design. We begin by illustrating common features of mathematical optimization problems arising in wireless communication system design. We discuss various scenarios and use cases and their associated mathematical structures from an optimization perspective. We then provide an overview of recently developed optimization techniques in areas ranging from nonconvex optimization, global optimization, and integer programming, to distributed optimization and learning-based optimization. The key to successful solution of mathematical optimization problems is in carefully choosing or developing suitable algorithms (or neural network architectures) that can exploit the underlying problem structure. We conclude the paper by identifying several open research challenges and outlining future research directions.</description>
      <guid isPermaLink="false">oai:arXiv.org:2401.12025v2</guid>
      <category>cs.IT</category>
      <category>eess.SP</category>
      <category>math.IT</category>
      <category>math.OC</category>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Ya-Feng Liu, Tsung-Hui Chang, Mingyi Hong, Zheyu Wu, Anthony Man-Cho So, Eduard A. Jorswieck, Wei Yu</dc:creator>
    </item>
    <item>
      <title>Finite-Time Analysis of On-Policy Heterogeneous Federated Reinforcement Learning</title>
      <link>https://arxiv.org/abs/2401.15273</link>
      <description>arXiv:2401.15273v2 Announce Type: replace-cross 
Abstract: Federated reinforcement learning (FRL) has emerged as a promising paradigm for reducing the sample complexity of reinforcement learning tasks by exploiting information from different agents. However, when each agent interacts with a potentially different environment, little to nothing is known theoretically about the non-asymptotic performance of FRL algorithms. The lack of such results can be attributed to various technical challenges and their intricate interplay: Markovian sampling, linear function approximation, multiple local updates to save communication, heterogeneity in the reward functions and transition kernels of the agents' MDPs, and continuous state-action spaces. Moreover, in the on-policy setting, the behavior policies vary with time, further complicating the analysis. In response, we introduce FedSARSA, a novel federated on-policy reinforcement learning scheme, equipped with linear function approximation, to address these challenges and provide a comprehensive finite-time error analysis. Notably, we establish that FedSARSA converges to a policy that is near-optimal for all agents, with the extent of near-optimality proportional to the level of heterogeneity. Furthermore, we prove that FedSARSA leverages agent collaboration to enable linear speedups as the number of agents increases, which holds for both fixed and adaptive step-size configurations.</description>
      <guid isPermaLink="false">oai:arXiv.org:2401.15273v2</guid>
      <category>cs.LG</category>
      <category>cs.SY</category>
      <category>eess.SY</category>
      <category>math.OC</category>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Chenyu Zhang, Han Wang, Aritra Mitra, James Anderson</dc:creator>
    </item>
    <item>
      <title>Stochastic Hessian Fittings with Lie Groups</title>
      <link>https://arxiv.org/abs/2402.11858</link>
      <description>arXiv:2402.11858v3 Announce Type: replace-cross 
Abstract: This paper studies the fitting of Hessian or its inverse for stochastic optimizations using a Hessian fitting criterion from the preconditioned stochastic gradient descent (PSGD) method, which is intimately related to many commonly used second order and adaptive gradient optimizers, e.g., BFGS, Gaussian-Newton and natural gradient descent, AdaGrad, etc. Our analyses reveal the efficiency and reliability differences among a wide range of preconditioner fitting methods, from closed-form to iterative solutions, using Hessian-vector products or stochastic gradients only, with Hessian fittings in the Euclidean space, the manifold of symmetric positive definite (SPL) matrices, to a variety of Lie groups. The most intriguing discovery is that the Hessian fitting itself as an optimization problem is strongly convex under mild conditions with a specific yet general enough Lie group. This discovery turns Hessian fitting into a well behaved optimization problem, and facilitates the designs of highly efficient and elegant Lie group sparse preconditioner fitting methods for large scale stochastic optimizations.</description>
      <guid isPermaLink="false">oai:arXiv.org:2402.11858v3</guid>
      <category>stat.ML</category>
      <category>cs.LG</category>
      <category>math.OC</category>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Xi-Lin Li</dc:creator>
    </item>
    <item>
      <title>Conservative Linear Envelopes for Nonlinear, High-Dimensional, Hamilton-Jacobi Reachability</title>
      <link>https://arxiv.org/abs/2403.14184</link>
      <description>arXiv:2403.14184v2 Announce Type: replace-cross 
Abstract: Hamilton-Jacobi reachability (HJR) provides a value function that encodes the set of states from which a system with bounded control inputs can reach or avoid a target despite any bounded disturbance, and the corresponding robust, optimal control policy. Though powerful, traditional methods for HJR rely on dynamic programming (DP) and suffer from exponential computation growth with respect to state dimension. The recently favored Hopf formula mitigates this ``curse of dimensionality'' by providing an efficient and space-parallelizable approach for solving the reachability problem. However, the Hopf formula can only be applied to linear time-varying systems. To overcome this limitation, we show that the error between a nonlinear system and a linear model can be transformed into an adversarial bounded artificial disturbance. One may then solve the dimension-robust generalized Hopf formula for a linear game with this ``antagonistic error" to perform guaranteed conservative reachability analysis and control synthesis of nonlinear systems; this can be done for problem formulations in which no other HJR method is both computationally feasible and guaranteed. In addition, we offer several technical methods for reducing conservativeness in the analysis. We demonstrate the effectiveness of our results through one illustrative example (the controlled Van der Pol system) that can be compared to standard DP, and one higher-dimensional 15D example (a 5-agent pursuit-evasion game with Dubins cars).</description>
      <guid isPermaLink="false">oai:arXiv.org:2403.14184v2</guid>
      <category>eess.SY</category>
      <category>cs.SY</category>
      <category>math.OC</category>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <dc:creator>Will Sharpless, Yat Tin Chow, Sylvia Herbert</dc:creator>
    </item>
    <item>
      <title>Safe subspace screening for the adaptive nuclear norm regularized trace regression</title>
      <link>https://arxiv.org/abs/2404.07459</link>
      <description>arXiv:2404.07459v2 Announce Type: replace-cross 
Abstract: Matrix form data sets arise in many areas, so there are lots of works about the matrix regression models. One special model of these models is the adaptive nuclear norm regularized trace regression, which has been proven have good statistical performances. In order to accelerate the computation of this model, we consider the technique called screening rule. According to matrix decomposition and optimal condition of the model, we develop a safe subspace screening rule that can be used to identify inactive subspace of the solution decomposition and reduce the dimension of the solution. To evaluate the efficiency of the safe subspace screening rule, we embed this result into the alternating direction method of multipliers algorithm under a sequence of the tuning parameters. Under this process, each solution under the tuning parameter provides a matrix decomposition space. Then, the safe subspace screening rule is applied to eliminate inactive subspace, reduce the solution dimension and accelerate the computation process. Some numerical experiments are implemented on simulation data sets and real data sets, which illustrate the efficiency of our screening rule.</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.07459v2</guid>
      <category>stat.ME</category>
      <category>math.OC</category>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Pan Shang, Lingchen Kong</dc:creator>
    </item>
    <item>
      <title>A Novel Optimization-Based Collision Avoidance For Autonomous On-Orbit Assembly</title>
      <link>https://arxiv.org/abs/2404.07916</link>
      <description>arXiv:2404.07916v2 Announce Type: replace-cross 
Abstract: The collision avoidance constraints are prominent as non-convex, non-differentiable, and challenging when defined in optimization-based motion planning problems. To overcome these issues, this paper presents a novel non-conservative collision avoidance technique using the notion of convex optimization to establish the distance between robotic spacecraft and space structures for autonomous on-orbit assembly operations. The proposed technique defines each ellipsoidal- and polyhedral-shaped object as the union of convex compact sets, each represented non-conservatively by a real-valued convex function. Then, the functions are introduced as a set of constraints to a convex optimization problem to produce a new set of differentiable constraints resulting from the optimality conditions. These new constraints are later fed into an optimal control problem to enforce collision avoidance where the motion planning for the autonomous on-orbit assembly takes place. Numerical experiments for two assembly scenarios in tight environments are presented to demonstrate the capability and effectiveness of the proposed technique. The results show that this framework leads to optimal non-conservative trajectories for robotic spacecraft in tight environments. Although developed for autonomous on-orbit assembly, this technique could be used for any generic motion planning problem where collision avoidance is crucial.</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.07916v2</guid>
      <category>cs.RO</category>
      <category>cs.SY</category>
      <category>eess.SY</category>
      <category>math.OC</category>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Siavash Tavana, Sepideh Faghihi, Anton de Ruiter, Krishna Dev Kumar</dc:creator>
    </item>
  </channel>
</rss>
