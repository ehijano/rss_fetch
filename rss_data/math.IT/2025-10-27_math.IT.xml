<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>math.IT updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/math.IT</link>
    <description>math.IT updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/math.IT" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Tue, 28 Oct 2025 03:00:23 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Mon, 27 Oct 2025 00:00:00 -0400</pubDate>
    <skipDays>
      <day>Sunday</day>
      <day>Saturday</day>
    </skipDays>
    <item>
      <title>Information Theoretic Learning for Diffusion Models with Warm Start</title>
      <link>https://arxiv.org/abs/2510.20903</link>
      <description>arXiv:2510.20903v1 Announce Type: new 
Abstract: Generative models that maximize model likelihood have gained traction in many practical settings. Among them, perturbation based approaches underpin many strong likelihood estimation models, yet they often face slow convergence and limited theoretical understanding. In this paper, we derive a tighter likelihood bound for noise driven models to improve both the accuracy and efficiency of maximum likelihood learning. Our key insight extends the classical KL divergence Fisher information relationship to arbitrary noise perturbations, going beyond the Gaussian assumption and enabling structured noise distributions. This formulation allows flexible use of randomized noise distributions that naturally account for sensor artifacts, quantization effects, and data distribution smoothing, while remaining compatible with standard diffusion training. Treating the diffusion process as a Gaussian channel, we further express the mismatched entropy between data and model, showing that the proposed objective upper bounds the negative log-likelihood (NLL). In experiments, our models achieve competitive NLL on CIFAR-10 and SOTA results on ImageNet across multiple resolutions, all without data augmentation, and the framework extends naturally to discrete data.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.20903v1</guid>
      <category>cs.IT</category>
      <category>cs.LG</category>
      <category>math.IT</category>
      <pubDate>Mon, 27 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Yirong Shen, Lu Gan, Cong Ling</dc:creator>
    </item>
    <item>
      <title>Overlapped-repetition Shor codes achieving fourfold asymptotic rate</title>
      <link>https://arxiv.org/abs/2510.21030</link>
      <description>arXiv:2510.21030v1 Announce Type: new 
Abstract: The standard Shor code employs two repetition codes as inner and outer codes, yielding a simple structure but a relatively low code rate. By overlapping a small number of repetition codes, we enhance the asymptotic code rate fourfold. In the minimal-distance case $d = 3$, this construction reduces the overhead from $[[9,1,3]]$ to the more efficient $[[7,1,3]]$ configuration.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.21030v1</guid>
      <category>cs.IT</category>
      <category>math.IT</category>
      <category>quant-ph</category>
      <pubDate>Mon, 27 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>En-Jui Chang</dc:creator>
    </item>
    <item>
      <title>Complex DNA Synthesis Sequences</title>
      <link>https://arxiv.org/abs/2510.21253</link>
      <description>arXiv:2510.21253v1 Announce Type: new 
Abstract: DNA-based storage offers unprecedented density and durability, but its scalability is fundamentally limited by the efficiency of parallel strand synthesis. Existing methods either allow unconstrained nucleotide additions to individual strands, such as enzymatic synthesis, or enforce identical additions across many strands, such as photolithographic synthesis. We introduce and analyze a hybrid synthesis framework that generalizes both approaches: in each cycle, a nucleotide is selected from a restricted subset and incorporated in parallel. This model gives rise to a new notion of a complex synthesis sequence. Building on this framework, we extend the information rate definition of Lenz et al. and analyze an analog of the deletion ball, defined and studied in this setting, deriving tight expressions for the maximal information rate and its asymptotic behavior. These results bridge the theoretical gap between constrained models and the idealized setting in which every nucleotide is always available. For the case of known strands, we design a dynamic programming algorithm that computes an optimal complex synthesis sequence, highlighting structural similarities to the shortest common supersequence problem. We also define a distinct two-dimensional array model with synthesis constraints over the rows, which extends previous synthesis models in the literature and captures new structural limitations in large-scale strand arrays. Additionally, we develop a dynamic programming algorithm for this problem as well. Our results establish a new and comprehensive theoretical framework for constrained DNA, subsuming prior models and setting the stage for future advances in the field.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.21253v1</guid>
      <category>cs.IT</category>
      <category>math.IT</category>
      <pubDate>Mon, 27 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Boaz Moav, Ryan Gabrys, Eitan Yaakobi</dc:creator>
    </item>
    <item>
      <title>Text-Guided Diffusion Model-based Generative Communication for Wireless Image Transmission</title>
      <link>https://arxiv.org/abs/2510.21299</link>
      <description>arXiv:2510.21299v1 Announce Type: new 
Abstract: Reliable image transmission over wireless channels is particularly challenging at extremely low transmission rates, where conventional compression and channel coding schemes fail to preserve adequate visual quality. To address this issue, we propose a generative communication framework based on diffusion models, which integrates joint source channel coding (JSCC) with semantic-guided reconstruction leveraging a pre-trained generative model. Unlike conventional architectures that aim to recover exact pixel values of the original image, the proposed method focuses on preserving and reconstructing semantically meaningful visual content under severely constrained rates, ensuring perceptual plausibility and faithfulness to the scene intent. Specifically, the transmitter encodes the source image via JSCC and jointly transmits it with a textual prompt over the wireless channel. At the receiver, the corrupted low-rate representation is fused with the prompt and reconstructed through a Stable Diffusion model with ControlNet, enabling high-quality visual recovery. Leveraging both generative priors and semantic guidance, the proposed framework produces perceptually convincing images even under extreme bandwidth limitations. Experimental results demonstrate that the proposed method consistently outperforms conventional coding-based schemes and deep learning baselines, achieving superior perceptual quality and robustness across various channel conditions.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.21299v1</guid>
      <category>cs.IT</category>
      <category>math.IT</category>
      <pubDate>Mon, 27 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Shengkang Chen, Tong Wu, Zhiyong Chen, Feng Yang, Meixia Tao, Wenjun Zhang</dc:creator>
    </item>
    <item>
      <title>Low-Complexity MIMO Channel Estimation with Latent Diffusion Models</title>
      <link>https://arxiv.org/abs/2510.21386</link>
      <description>arXiv:2510.21386v1 Announce Type: new 
Abstract: Deep generative models offer a powerful alternative to conventional channel estimation by learning the complex prior distribution of wireless channels. Capitalizing on this potential, this paper proposes a novel channel estimation algorithm based on latent diffusion models (LDMs), termed posterior sampling with latent diffusion for channel estimation (PSLD-CE). The core of our approach is a lightweight LDM architecture specifically designed for channel estimation, which serves as a powerful generative prior to capture the intricate channel distribution. Furthermore, we enhance the diffusion posterior sampling process by introducing an effective approximation for the likelihood term and a tailored self-consistency constraint on the variational autoencoder latent space. Extensive experimental results demonstrate that PSLD-CE consistently outperforms a wide range of existing methods. Notably, these significant performance gains are achieved while maintaining low computational complexity and fast inference speed, establishing our method as a highly promising and practical solution for next-generation wireless systems.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.21386v1</guid>
      <category>cs.IT</category>
      <category>math.IT</category>
      <pubDate>Mon, 27 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Xiaotian Fan, Xingyu Zhou, Le Liang, Shi Jin</dc:creator>
    </item>
    <item>
      <title>Universal Maximum Likelihood (List) Decoding via Fast Vector-Matrix Multiplication</title>
      <link>https://arxiv.org/abs/2510.21414</link>
      <description>arXiv:2510.21414v1 Announce Type: new 
Abstract: Maximum-likelihood (ML) decoding for arbitrary block codes remains fundamentally hard, with worst-case time complexity-measured by the total number of multiplications-being no better than straightforward exhaustive search, which requires $q^{k} n$ operations for an $[n,k]_q$ code. This paper introduces a simple, code-agnostic framework that reduces the worst-case complexity by a factor of $n$, down to $q^{k}$ operations, a highly desirable reduction in practice. The result holds for both linear and nonlinear block codes over general memoryless channels and under both hard-decision and soft-decision decoding. It naturally extends to intersymbol-interference (ISI) channels and ML list decoding with only a negligible increase in complexity. Our core insight is that, upon receipt of each sequence at the receiver, the conditional probability of that sequence for each codeword in the codebook (i.e., the \emph{likelihood}) can be expressed as the inner product of two carefully constructed vectors -- the first depending on the received sequence, and the second on that codeword itself. As a result, evaluating the likelihoods for all codewords in the codebook reduces to a single vector-matrix multiplication, and ML decoding (MLD) becomes the simple task of picking the maximum entry in the resulting vector. The only non-trivial cost lies in the vector-matrix product. However, our matrix construction allows the use of the Mailman algorithm to reduce this cost. This time reduction is achieved at the cost of high space complexity, requiring $\mathcal{O}(q^{k+1} n)$ space to store the pre-computed codebook matrix.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.21414v1</guid>
      <category>cs.IT</category>
      <category>cs.DS</category>
      <category>math.IT</category>
      <pubDate>Mon, 27 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Hoang Ly, Emina Soljanin</dc:creator>
    </item>
    <item>
      <title>Resilient Radio Access Networks: AI and the Unknown Unknowns</title>
      <link>https://arxiv.org/abs/2510.21587</link>
      <description>arXiv:2510.21587v1 Announce Type: new 
Abstract: 5G networks offer exceptional reliability and availability, ensuring consistent performance and user satisfaction. Yet they might still fail when confronted with the unexpected. A resilient system is able to adapt to real-world complexity, including operating conditions completely unanticipated during system design. This makes resilience a vital attribute for communication systems that must sustain service in scenarios where models are absent or too intricate to provide statistical guarantees. Such considerations indicate that artifical intelligence (AI) will play a major role in delivering resilience. In this paper, we examine the challenges of designing AIs for resilient radio access networks, especially with respect to unanticipated and rare disruptions. Our theoretical results indicate strong limitations of current statistical learning methods for resilience and suggest connections to online learning and causal inference.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.21587v1</guid>
      <category>cs.IT</category>
      <category>math.IT</category>
      <pubDate>Mon, 27 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Bho Matthiesen, Armin Dekorsy, Petar Popovski</dc:creator>
    </item>
    <item>
      <title>A new measure for dynamic leakage based on quantitative information flow</title>
      <link>https://arxiv.org/abs/2510.20922</link>
      <description>arXiv:2510.20922v1 Announce Type: cross 
Abstract: Quantitative information flow (QIF) is concerned with assessing the leakage of information in computational systems. In QIF there are two main perspectives for the quantification of leakage. On one hand, the static perspective considers all possible runs of the system in the computation of information flow, and is usually employed when preemptively deciding whether or not to run the system. On the other hand, the dynamic perspective considers only a specific, concrete run of the system that has been realised, while ignoring all other runs. The dynamic perspective is relevant for, e.g., system monitors and trackers, especially when deciding whether to continue or to abort a particular run based on how much leakage has occurred up to a certain point. Although the static perspective of leakage is well-developed in the literature, the dynamic perspective still lacks the same level of theoretical maturity. In this paper we take steps towards bridging this gap with the following key contributions: (i) we provide a novel definition of dynamic leakage that decouples the adversary's belief about the secret value from a baseline distribution on secrets against which the success of the attack is measured; (ii) we demonstrate that our formalisation satisfies relevant information-theoretic axioms, including non-interference and relaxed versions of monotonicity and the data-processing inequality (DPI); (iii) we identify under what kind of analysis strong versions of the axioms of monotonicity and the DPI might not hold, and explain the implications of this (perhaps counter-intuitive) outcome; (iv) we show that our definition of dynamic leakage is compatible with the well-established static perspective; and (v) we exemplify the use of our definition on the formalisation of attacks against privacy-preserving data releases.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.20922v1</guid>
      <category>cs.CR</category>
      <category>cs.IT</category>
      <category>math.IT</category>
      <pubDate>Mon, 27 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Luigi D. C. Soares, M\'ario S. Alvim, Natasha Fernandes</dc:creator>
    </item>
    <item>
      <title>Physics-Informed Neural Networks for MIMO Beam Map and Environment Reconstruction</title>
      <link>https://arxiv.org/abs/2510.21238</link>
      <description>arXiv:2510.21238v1 Announce Type: cross 
Abstract: As communication networks evolve towards greater complexity (e.g., 6G and beyond), a deep understanding of the wireless environment becomes increasingly crucial. When explicit knowledge of the environment is unavailable, geometry-aware feature extraction from channel state information (CSI) emerges as a pivotal methodology to bridge physical-layer measurements with network intelligence. This paper proposes to explore the received signal strength (RSS) data, without explicit 3D environment knowledge, to jointly construct the radio beam map and environmental geometry for a multiple-input multiple-output (MIMO) system. Unlike existing methods that only learn blockage structures, we propose an oriented virtual obstacle model that captures the geometric features of both blockage and reflection. Reflective zones are formulated to identify relevant reflected paths according to the geometry relation of the environment. We derive an analytical expression for the reflective zone and further analyze its geometric characteristics to develop a reformulation that is more compatible with deep learning representations. A physics-informed deep learning framework that incorporates the reflective-zone-based geometry model is proposed to learn the blockage, reflection, and scattering components, along with the beam pattern, which leverages physics prior knowledge to enhance network transferability. Numerical experiments demonstrate that, in addition to reconstructing the blockage and reflection geometry, the proposed model can construct a more accurate MIMO beam map with a 32%-48% accuracy improvement.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.21238v1</guid>
      <category>eess.SY</category>
      <category>cs.AI</category>
      <category>cs.IT</category>
      <category>cs.SY</category>
      <category>math.IT</category>
      <pubDate>Mon, 27 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Wangqian Chen, Junting Chen, Shuguang Cui</dc:creator>
    </item>
    <item>
      <title>Multi-turn Training with Basic Human Feedback Helps Little on LLM Reasoning</title>
      <link>https://arxiv.org/abs/2510.21339</link>
      <description>arXiv:2510.21339v2 Announce Type: cross 
Abstract: The reasoning capabilities of Large Language Models (LLMs) are typically developed through the single-turn reinforcement learning, whereas real-world applications often involve multi-turn interactions with human feedback, leading to a potential mismatch between training and deployment conditions. In this work, we study whether multi-turn training with human feedback is necessary for reasoning tasks. We compare conventional single-turn training with three multi-turn strategies and reach contrary conclusions to previous research. We find that models trained in a single-turn setting generalize effectively to both single- and multi-turn evaluations, while models trained with multi-turn strategies exhibit a significant degradation in single-turn reasoning performance. These results suggest that for tasks with complete information, robust single-turn training remains more effective and reliable, as multi-turn training with basic feedback provides limited benefits and can even degrade reasoning capabilities.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.21339v2</guid>
      <category>cs.CL</category>
      <category>cs.IT</category>
      <category>cs.LG</category>
      <category>math.IT</category>
      <pubDate>Mon, 27 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Qiang Liu, Wuganjing Song, Zhenzhou Lin, Feifan Chen, Qiaolong Cai, Chen Li, Yongduo Sui</dc:creator>
    </item>
    <item>
      <title>Cost Minimization for Space-Air-Ground Integrated Multi-Access Edge Computing Systems</title>
      <link>https://arxiv.org/abs/2510.21541</link>
      <description>arXiv:2510.21541v1 Announce Type: cross 
Abstract: Space-air-ground integrated multi-access edge computing (SAGIN-MEC) provides a promising solution for the rapidly developing low-altitude economy (LAE) to deliver flexible and wide-area computing services. However, fully realizing the potential of SAGIN-MEC in the LAE presents significant challenges, including coordinating decisions across heterogeneous nodes with different roles, modeling complex factors such as mobility and network variability, and handling real-time decision-making under partially observable environment with hybrid variables. To address these challenges, we first present a hierarchical SAGIN-MEC architecture that enables the coordination between user devices (UDs), uncrewed aerial vehicles (UAVs), and satellites. Then, we formulate a UD cost minimization optimization problem (UCMOP) to minimize the UD cost by jointly optimizing the task offloading ratio, UAV trajectory planning, computing resource allocation, and UD association. We show that the UCMOP is an NP-hard problem. To overcome this challenge, we propose a multi-agent deep deterministic policy gradient (MADDPG)-convex optimization and coalitional game (MADDPG-COCG) algorithm. Specifically, we employ the MADDPG algorithm to optimize the continuous temporal decisions for heterogeneous nodes in the partially observable SAGIN-MEC system. Moreover, we propose a convex optimization and coalitional game (COCG) method to enhance the conventional MADDPG by deterministically handling the hybrid and varying-dimensional decisions. Simulation results demonstrate that the proposed MADDPG-COCG algorithm significantly enhances the user-centric performances in terms of the aggregated UD cost, task completion delay, and UD energy consumption, with a slight increase in UAV energy consumption, compared to the benchmark algorithms. Moreover, the MADDPG-COCG algorithm shows superior convergence stability and scalability.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.21541v1</guid>
      <category>cs.LG</category>
      <category>cs.IT</category>
      <category>math.IT</category>
      <pubDate>Mon, 27 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Weihong Qin, Aimin Wang, Geng Sun, Zemin Sun, Jiacheng Wang, Dusit Niyato, Dong In Kim, Zhu Han</dc:creator>
    </item>
    <item>
      <title>Rate-cost tradeoffs in continuous-time control with a biomolecular application</title>
      <link>https://arxiv.org/abs/2510.21612</link>
      <description>arXiv:2510.21612v1 Announce Type: cross 
Abstract: This paper focuses on rate-limited control of the generalized Ornstein-Uhlenbeck process where the control action can be either multiplicative or additive, and the noise variance can depend on the control action. We derive a lower bound on the data rate necessary to achieve the desired control cost. The lower bound is attained with equality if the control is performed via an additive white Gaussian channel. The system model approximates the dynamics of a discrete-state molecular birth-death process, and the result has direct implications on the control of a biomolecular system via chemical reactions, where the multiplicative control corresponds to the degradation rate, the additive control corresponds to the production rate, and the control objective is to decrease the fluctuations of the controlled molecular species around their desired concentration levels.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.21612v1</guid>
      <category>eess.SY</category>
      <category>cs.IT</category>
      <category>cs.SY</category>
      <category>math.IT</category>
      <category>math.OC</category>
      <pubDate>Mon, 27 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <arxiv:journal_reference>IEEE Transactions of Automatic Control, Apr. 2026</arxiv:journal_reference>
      <dc:creator>Yorie Nakahira, Fangzhou Xiao, Victoria Kostina, John C. Doyle</dc:creator>
    </item>
    <item>
      <title>Privacy Guarantee for Nash Equilibrium Computation of Aggregative Games Based on Pointwise Maximal Leakage</title>
      <link>https://arxiv.org/abs/2510.21668</link>
      <description>arXiv:2510.21668v1 Announce Type: cross 
Abstract: Privacy preservation has served as a key metric in designing Nash equilibrium (NE) computation algorithms. Although differential privacy (DP) has been widely employed for privacy guarantees, it does not exploit prior distributional knowledge of datasets and is ineffective in assessing information leakage for correlated datasets. To address these concerns, we establish a pointwise maximal leakage (PML) framework when computing NE in aggregative games. By incorporating prior knowledge of players' cost function datasets, we obtain a precise and computable upper bound of privacy leakage with PML guarantees. In the entire view, we show PML refines DP by offering a tighter privacy guarantee, enabling flexibility in designing NE computation. Also, in the individual view, we reveal that the lower bound of PML can exceed the upper bound of DP by constructing specific correlated datasets. The results emphasize that PML is a more proper privacy measure than DP since the latter fails to adequately capture privacy leakage in correlated datasets. Moreover, we conduct experiments with adversaries who attempt to infer players' private information to illustrate the effectiveness of our framework.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.21668v1</guid>
      <category>cs.GT</category>
      <category>cs.IT</category>
      <category>math.IT</category>
      <pubDate>Mon, 27 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Zhaoyang Cheng, Guanpu Chen, Tobias J. Oechtering, Mikael Skoglund</dc:creator>
    </item>
    <item>
      <title>Correcting Multiple Substitutions in Nanopore-Sequencing Reads</title>
      <link>https://arxiv.org/abs/2505.02447</link>
      <description>arXiv:2505.02447v2 Announce Type: replace 
Abstract: Despite their significant advantages over competing technologies, nanopore sequencers are plagued by high error rates, due to physical characteristics of the nanopore and inherent noise in the biological processes. It is thus paramount not only to formulate efficient error-correcting constructions for these channels, but also to establish bounds on the minimum redundancy required by such coding schemes. In this context, we adopt a simplified model of nanopore sequencing inspired by the work of Mao \emph{et al.}, accounting for the effects of intersymbol interference and measurement noise. For an input sequence of length $n$, the vector that is produced, designated as the \emph{read vector}, may additionally suffer at most \(t\) substitution errors. We employ the well-known graph-theoretic clique-cover technique to establish that at least \(t\log n -O(1)\) bits of redundancy are required to correct multiple (\(t \geq 2\)) substitutions. While this is surprising in comparison to the case of a single substitution, that necessitates at most \(\log \log n - O(1)\) bits of redundancy, a suitable error-correcting code that is optimal up to a constant follows immediately from the properties of read vectors.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.02447v2</guid>
      <category>cs.IT</category>
      <category>math.IT</category>
      <pubDate>Mon, 27 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <arxiv:DOI>10.1109/ISIT63088.2025.11195286</arxiv:DOI>
      <dc:creator>Anisha Banerjee, Yonatan Yehezkeally, Antonia Wachter-Zeh, Eitan Yaakobi</dc:creator>
    </item>
    <item>
      <title>L$^2$M: Mutual Information Scaling Law for Long-Context Language Modeling</title>
      <link>https://arxiv.org/abs/2503.04725</link>
      <description>arXiv:2503.04725v2 Announce Type: replace-cross 
Abstract: We present a universal theoretical framework for understanding long-context language modeling based on a bipartite mutual information scaling law that we rigorously verify in natural language. We demonstrate that bipartite mutual information captures multi-token interactions distinct from and scaling independently of conventional two-point mutual information, and show that this provides a more complete characterization of the dependencies needed for accurately modeling long sequences. Leveraging this scaling law, we formulate the Long-context Language Modeling (L$^2$M) condition, which lower bounds the necessary scaling of a model's history state -- the latent variables responsible for storing past information -- for effective long-context modeling. We validate the framework and its predictions on transformer and state-space models. Our work provides a principled foundation to understand long-context modeling and to design more efficient architectures with stronger long-context capabilities, with potential applications beyond natural language.</description>
      <guid isPermaLink="false">oai:arXiv.org:2503.04725v2</guid>
      <category>cs.CL</category>
      <category>cs.AI</category>
      <category>cs.IT</category>
      <category>cs.LG</category>
      <category>math.IT</category>
      <category>physics.data-an</category>
      <pubDate>Mon, 27 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Zhuo Chen, Oriol Mayn\'e i Comas, Zhuotao Jin, Di Luo, Marin Solja\v{c}i\'c</dc:creator>
    </item>
    <item>
      <title>Pilot Assignment for Distributed Massive MIMO Based on Channel Estimation Error Minimization</title>
      <link>https://arxiv.org/abs/2510.13732</link>
      <description>arXiv:2510.13732v2 Announce Type: replace-cross 
Abstract: Pilot contamination remains a major bottleneck in realizing the full potential of distributed massive MIMO systems. We propose two dynamic and scalable pilot assignment schemes designed for practical deployment in such networks. First, we present a low-complexity centralized scheme that sequentially assigns pilots to user equipments (UEs) to minimize the global channel estimation errors across serving access points (APs). This improves the channel estimation quality and reduces interference among UEs, enhancing the spectral efficiency. Second, we develop a fully distributed scheme that uses a priority-based pilot selection approach. In this scheme, each selected AP minimizes the channel estimation error using only local information and offers candidate pilots to the UEs. Every UE then selects a suitable pilot based on its AP priority. This approach ensures consistency and minimizes interference while significantly reducing pilot contamination. The method requires no global coordination, maintains low signaling overhead, and adapts dynamically to the UE deployment. Numerical simulations demonstrate the superiority of the proposed schemes in terms of network throughput when compared to the existing state-of-the-art schemes.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.13732v2</guid>
      <category>cs.NI</category>
      <category>cs.IT</category>
      <category>math.IT</category>
      <pubDate>Mon, 27 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Mohd Saif Ali Khan, Karthik RM, Samar Agnihotri</dc:creator>
    </item>
    <item>
      <title>Minimum Hellinger Distance Estimators for Complex Survey Designs</title>
      <link>https://arxiv.org/abs/2510.14055</link>
      <description>arXiv:2510.14055v2 Announce Type: replace-cross 
Abstract: Reliable inference from complex survey samples can be derailed by outliers and high-leverage observations induced by unequal inclusion probabilities and calibration. We develop a minimum Hellinger distance estimator (MHDE) for parametric superpopulation models under complex designs, including Poisson PPS and fixed-size SRS/PPS without replacement, with possibly stochastic post-stratified or calibrated weights. Using a Horvitz-Thompson-adjusted kernel density plug-in, we show: (i) $L^1$-consistency of the KDE with explicit large-deviation tail bounds driven by a variance-adaptive effective sample size; (ii) uniform exponential bounds for the Hellinger affinity that yield MHDE consistency under mild identifiability; (iii) an asymptotic Normal distribution for the MHDE with covariance $\mathbf A^{-1}\boldsymbol\Sigma \mathbf A^{\intercal}$ (and a finite-population correction under without-replacement designs); and (iv) robustness via the influence function and $\alpha$-influence curves in the Hellinger topology. Simulations under Gamma and lognormal superpopulation models quantify efficiency-robustness trade-offs relative to weighted MLE under independent and high-leverage contamination. An application to NHANES 2021-2023 total water consumption shows that the MHDE remains stable despite extreme responses that markedly bias the MLE. The estimator is simple to implement via quadrature over a fixed grid and is extensible to other divergence families.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.14055v2</guid>
      <category>math.ST</category>
      <category>cs.IT</category>
      <category>math.IT</category>
      <category>math.PR</category>
      <category>stat.TH</category>
      <pubDate>Mon, 27 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-sa/4.0/</dc:rights>
      <dc:creator>David Kepplinger, Anand N. Vidyashankar</dc:creator>
    </item>
  </channel>
</rss>
