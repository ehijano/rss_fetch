<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>q-bio.QM updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/q-bio.QM</link>
    <description>q-bio.QM updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/q-bio.QM" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Mon, 22 Apr 2024 04:00:26 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Mon, 22 Apr 2024 00:00:00 -0400</pubDate>
    <skipDays>
      <day>Saturday</day>
      <day>Sunday</day>
    </skipDays>
    <item>
      <title>The Length and the Width of the Human Brain Circuit Connections are Strongly Correlated</title>
      <link>https://arxiv.org/abs/2404.12763</link>
      <description>arXiv:2404.12763v1 Announce Type: cross 
Abstract: The correlations of several fundamental properties of human brain connections are investigated in a consensus connectome, constructed from 1064 braingraphs, each on 1015 vertices, corresponding to 1015 anatomical brain areas. The properties examined include the edge length, the fiber number, or edge width, meaning the number of discovered axon bundles forming the edge and the occurrence number of the edge, meaning the number of individual braingraphs where the edge exists. By using our previously published robust braingraphs at \url{https://braingraph.org}, we have prepared a single consensus graph from the data and compared the statistical similarity of the edge occurrence numbers, edge lengths, and fiber counts of the edges. We have found a strong positive Spearman correlation between the edge occurrence numbers and the fiber count numbers, showing that statistically, the most frequent cerebral connections have the largest widths, i.e., the fiber number. We have found a negative Spearman correlation between the fiber lengths and fiber counts, showing that, typically, the shortest edges are the widest or strongest by their fiber counts. We have also found a negative Spearman correlation between the occurrence numbers and the edge lengths: it shows that typically, the long edges are infrequent, and the frequent edges are short.</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.12763v1</guid>
      <category>q-bio.NC</category>
      <category>q-bio.QM</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>D\'aniel Heged\H{u}s, Vince Grolmusz</dc:creator>
    </item>
    <item>
      <title>Cross-modal Diffusion Modelling for Super-resolved Spatial Transcriptomics</title>
      <link>https://arxiv.org/abs/2404.12973</link>
      <description>arXiv:2404.12973v1 Announce Type: cross 
Abstract: The recent advancement of spatial transcriptomics (ST) allows to characterize spatial gene expression within tissue for discovery research. However, current ST platforms suffer from low resolution, hindering in-depth understanding of spatial gene expression. Super-resolution approaches promise to enhance ST maps by integrating histology images with gene expressions of profiled tissue spots. However, current super-resolution methods are limited by restoration uncertainty and mode collapse. Although diffusion models have shown promise in capturing complex interactions between multi-modal conditions, it remains a challenge to integrate histology images and gene expression for super-resolved ST maps. This paper proposes a cross-modal conditional diffusion model for super-resolving ST maps with the guidance of histology images. Specifically, we design a multi-modal disentangling network with cross-modal adaptive modulation to utilize complementary information from histology images and spatial gene expression. Moreover, we propose a dynamic cross-attention modelling strategy to extract hierarchical cell-to-tissue information from histology images. Lastly, we propose a co-expression-based gene-correlation graph network to model the co-expression relationship of multiple genes. Experiments show that our method outperforms other state-of-the-art methods in ST super-resolution on three public datasets.</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.12973v1</guid>
      <category>eess.IV</category>
      <category>cs.CV</category>
      <category>cs.LG</category>
      <category>q-bio.QM</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Xiaofei Wang, Xingxu Huang, Stephen J. Price, Chao Li</dc:creator>
    </item>
    <item>
      <title>UAlign: Pushing the Limit of Template-free Retrosynthesis Prediction with Unsupervised SMILES Alignment</title>
      <link>https://arxiv.org/abs/2404.00044</link>
      <description>arXiv:2404.00044v2 Announce Type: replace-cross 
Abstract: Motivation: Retrosynthesis planning poses a formidable challenge in the organic chemical industry. Single-step retrosynthesis prediction, a crucial step in the planning process, has witnessed a surge in interest in recent years due to advancements in AI for science. Various deep learning-based methods have been proposed for this task in recent years, incorporating diverse levels of additional chemical knowledge dependency.
  Results: This paper introduces UAlign, a template-free graph-to-sequence pipeline for retrosynthesis prediction. By combining graph neural networks and Transformers, our method can more effectively leverage the inherent graph structure of molecules. Based on the fact that the majority of molecule structures remain unchanged during a chemical reaction, we propose a simple yet effective SMILES alignment technique to facilitate the reuse of unchanged structures for reactant generation. Extensive experiments show that our method substantially outperforms state-of-the-art template-free and semi-template-based approaches. Importantly, our template-free method achieves effectiveness comparable to, or even surpasses, established powerful template-based methods.
  Scientific contribution: We present a novel graph-to-sequence template-free retrosynthesis prediction pipeline that overcomes the limitations of Transformer-based methods in molecular representation learning and insufficient utilization of chemical information. We propose an unsupervised learning mechanism for establishing product-atom correspondence with reactant SMILES tokens, achieving even better results than supervised SMILES alignment methods. Extensive experiments demonstrate that UAlign significantly outperforms state-of-the-art template-free methods and rivals or surpasses template-based approaches, with up to 5\% (top-5) and 5.4\% (top-10) increased accuracy over the strongest baseline.</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.00044v2</guid>
      <category>physics.chem-ph</category>
      <category>cs.AI</category>
      <category>cs.LG</category>
      <category>q-bio.QM</category>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Kaipeng Zeng, Bo yang, Xin Zhao, Yu Zhang, Fan Nie, Xiaokang Yang, Yaohui Jin, Yanyan Xu</dc:creator>
    </item>
  </channel>
</rss>
