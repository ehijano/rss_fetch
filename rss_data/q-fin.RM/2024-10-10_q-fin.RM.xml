<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>q-fin.RM updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/q-fin.RM</link>
    <description>q-fin.RM updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/q-fin.RM" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Fri, 11 Oct 2024 02:33:12 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Thu, 10 Oct 2024 00:00:00 -0400</pubDate>
    <skipDays>
      <day>Sunday</day>
      <day>Saturday</day>
    </skipDays>
    <item>
      <title>Application of AI in Credit Risk Scoring for Small Business Loans: A case study on how AI-based random forest model improves a Delphi model outcome in the case of Azerbaijani SMEs</title>
      <link>https://arxiv.org/abs/2410.05330</link>
      <description>arXiv:2410.05330v1 Announce Type: new 
Abstract: The research investigates how the application of a machine-learning random forest model improves the accuracy and precision of a Delphi model. The context of the research is Azerbaijani SMEs and the data for the study has been obtained from a financial institution which had gathered it from the enterprises (as there is no public data on local SMEs, it was not practical to verify the data independently). The research used accuracy, precision, recall and F-1 scores for both models to compare them and run the algorithms in Python. The findings showed that accuracy, precision, recall and F- 1 all improve considerably (from 0.69 to 0.83, from 0.65 to 0.81, from 0.56 to 0.77 and from 0.58 to 0.79, respectively). The implications are that by applying AI models in credit risk modeling, financial institutions can improve the accuracy of identifying potential defaulters which would reduce their credit risk. In addition, an unfair rejection of credit access for SMEs would also go down having a significant contribution to an economic growth in the economy. Finally, such ethical issues as transparency of algorithms and biases in historical data should be taken on board while making decisions based on AI algorithms in order to reduce mechanical dependence on algorithms that cannot be justified in practice.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.05330v1</guid>
      <category>q-fin.RM</category>
      <category>cs.LG</category>
      <pubDate>Thu, 10 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Nigar Karimova</dc:creator>
    </item>
    <item>
      <title>Cyber Risk Taxonomies: Statistical Analysis of Cybersecurity Risk Classifications</title>
      <link>https://arxiv.org/abs/2410.05297</link>
      <description>arXiv:2410.05297v1 Announce Type: cross 
Abstract: Cyber risk classifications are widely used in the modeling of cyber event distributions, yet their effectiveness in out of sample forecasting performance remains underexplored. In this paper, we analyse the most commonly used classifications and argue in favour of switching the attention from goodness-of-fit and in-sample predictive performance, to focusing on the out-of sample forecasting performance. We use a rolling window analysis, to compare cyber risk distribution forecasts via threshold weighted scoring functions. Our results indicate that business motivated cyber risk classifications appear to be too restrictive and not flexible enough to capture the heterogeneity of cyber risk events. We investigate how dynamic and impact-based cyber risk classifiers seem to be better suited in forecasting future cyber risk losses than the other considered classifications. These findings suggest that cyber risk types provide limited forecasting ability concerning cyber event severity distribution, and cyber insurance ratemakers should utilize cyber risk types only when modeling the cyber event frequency distribution. Our study offers valuable insights for decision-makers and policymakers alike, contributing to the advancement of scientific knowledge in the field of cyber risk management.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.05297v1</guid>
      <category>cs.CR</category>
      <category>q-fin.RM</category>
      <category>q-fin.ST</category>
      <pubDate>Thu, 10 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Matteo Malavasi (School of Risk and Actuarial Studies, UNSW Business School, University of New South Wales, Australia), Gareth W. Peters (Department of Statistics and Applied Probability, University of California Santa Barbara, USA), Stefan Treuck (Department of Actuarial Studies and Business Analytics, Macquarie University, Australia), Pavel V. Shevchenko (Department of Actuarial Studies and Business Analytics, Macquarie University, Australia), Jiwook Jang (Department of Actuarial Studies and Business Analytics, Macquarie University, Australia), Georgy Sofronov (School of Mathematical and Physical Sciences, Macquarie University, Australia)</dc:creator>
    </item>
    <item>
      <title>Coherent risk measures and uniform integrability</title>
      <link>https://arxiv.org/abs/2404.03783</link>
      <description>arXiv:2404.03783v2 Announce Type: replace 
Abstract: We establish a profound connection between coherent risk measures, a prominent object in quantitative finance, and uniform integrability, a fundamental concept in probability theory. Instead of working with absolute values of random variables, which is convenient in studying integrability, we work directly with random loses and gains, which have clear financial interpretation. We introduce a technical tool called the folding score of distortion risk measures. The analysis of the folding score allows us to convert some conditions on absolute values to those on gains and losses. As our main results, we obtain three sets of equivalent conditions for uniform integrability. In particular, a set is uniformly integrable if and only if one can find a coherent distortion risk measure that is bounded on the set, but not finite on $L^1$.</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.03783v2</guid>
      <category>q-fin.RM</category>
      <pubDate>Thu, 10 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Muqiao Huang, Ruodu Wang</dc:creator>
    </item>
    <item>
      <title>The checkerboard copula and dependence concepts</title>
      <link>https://arxiv.org/abs/2404.15023</link>
      <description>arXiv:2404.15023v2 Announce Type: replace 
Abstract: We study the problem of choosing the copula when the marginal distributions of a random vector are not all continuous. Inspired by four motivating examples including simulation from copulas, stress scenarios, co-risk measures, and dependence measures, we propose to use the checkerboard copula, that is, intuitively, the unique copula with a distribution that is as uniform as possible within regions of flexibility. We show that the checkerboard copula has the largest Shannon entropy, which means that it carries the least information among all possible copulas for a given random vector. Furthermore, the checkerboard copula preserves the dependence information of the original random vector, leading to two applications in the context of diversification penalty and impact portfolios. The numerical and empirical results illustrate the benefits of using the checkerboard copula in the calculation of co-risk measures.</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.15023v2</guid>
      <category>q-fin.RM</category>
      <pubDate>Thu, 10 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Liyuan Lin, Ruodu Wang, Ruixun Zhang, Chaoyi Zhao</dc:creator>
    </item>
    <item>
      <title>Worst-case values of target semi-variances with applications to robust portfolio selection</title>
      <link>https://arxiv.org/abs/2410.01732</link>
      <description>arXiv:2410.01732v2 Announce Type: replace 
Abstract: The expected regret and target semi-variance are two of the most important risk measures for downside risk. When the distribution of a loss is uncertain, and only partial information of the loss is known, their worst-case values play important roles in robust risk management for finance, insurance, and many other fields. Jagannathan (1977) derived the worst-case expected regrets when only the mean and variance of a loss are known and the loss is arbitrary, symmetric, or non-negative. While Chen et al. (2011) obtained the worst-case target semi-variances under similar conditions but focusing on arbitrary losses. In this paper, we first complement the study of Chen et al. (2011) on the worst-case target semi-variances and derive the closed-form expressions for the worst-case target semi-variance when only the mean and variance of a loss are known and the loss is symmetric or non-negative. Then, we investigate worst-case target semi-variances over uncertainty sets that represent undesirable scenarios faced by an investors. Our methods for deriving these worst-case values are different from those used in Jagannathan (1977) and Chen et al. (2011). As applications of the results derived in this paper, we propose robust portfolio selection methods that minimize the worst-case target semi-variance of a portfolio loss over different uncertainty sets. To explore the insights of our robust portfolio selection methods, we conduct numerical experiments with real financial data and compare our portfolio selection methods with several existing portfolio selection models related to the models proposed in this paper.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.01732v2</guid>
      <category>q-fin.RM</category>
      <category>q-fin.PM</category>
      <pubDate>Thu, 10 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <dc:creator>Jun Cai, Zhanyi Jiao, Tiantian Mao</dc:creator>
    </item>
  </channel>
</rss>
