<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>math.IT updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/math.IT</link>
    <description>math.IT updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/math.IT" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Thu, 08 May 2025 01:46:08 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Wed, 07 May 2025 00:00:00 -0400</pubDate>
    <skipDays>
      <day>Saturday</day>
      <day>Sunday</day>
    </skipDays>
    <item>
      <title>Multi-Antenna Users in Cell-Free Massive MIMO: Stream Allocation and Necessity of Downlink Pilots</title>
      <link>https://arxiv.org/abs/2505.02951</link>
      <description>arXiv:2505.02951v1 Announce Type: new 
Abstract: We consider a cell-free massive multiple-input multiple-output (MIMO) system with multiple antennas on the users and access points (APs). In previous works, the downlink spectral efficiency (SE) has been evaluated using the hardening bound that requires no downlink pilots. This approach works well for single-antenna users. In this paper, we show that much higher SEs can be achieved if downlink pilots are sent when having multi-antenna users. The reason is that the effective channel matrix does not harden. We propose a pilot-based downlink estimation scheme, derive a new SE expression, and show numerically that it yields substantially higher performance when having correlated Rayleigh fading channels.
  In cases with multi-antenna users, the APs can either transmit the same or different data streams. The latter reduces the fronthaul signaling but comes with a SE loss. We propose precoding and combining schemes for these cases and consider whether channel knowledge is shared between the APs. Finally, we show numerically how the number of users, APs, and the number of antennas on users and APs affect the SE.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.02951v1</guid>
      <category>cs.IT</category>
      <category>eess.SP</category>
      <category>math.IT</category>
      <pubDate>Wed, 07 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Eren Berk Kama, Junbeom Kim, Emil Bj\"ornson</dc:creator>
    </item>
    <item>
      <title>Edge Large AI Models: Collaborative Deployment and IoT Applications</title>
      <link>https://arxiv.org/abs/2505.03139</link>
      <description>arXiv:2505.03139v1 Announce Type: new 
Abstract: Large artificial intelligence models (LAMs) emulate human-like problem-solving capabilities across diverse domains, modalities, and tasks. By leveraging the communication and computation resources of geographically distributed edge devices, edge LAMs enable real-time intelligent services at the network edge. Unlike conventional edge AI, which relies on small or moderate-sized models for direct feature-to-prediction mappings, edge LAMs leverage the intricate coordination of modular components to enable context-aware generative tasks and multi-modal inference. We shall propose a collaborative deployment framework for edge LAM by characterizing the LAM intelligent capabilities and limited edge network resources. Specifically, we propose a collaborative training framework over heterogeneous edge networks that adaptively decomposes LAMs according to computation resources, data modalities, and training objectives, reducing communication and computation overheads during the fine-tuning process. Furthermore, we introduce a microservice-based inference framework that virtualizes the functional modules of edge LAMs according to their architectural characteristics, thereby improving resource utilization and reducing inference latency. The developed edge LAM will provide actionable solutions to enable diversified Internet-of-Things (IoT) applications, facilitated by constructing mappings from diverse sensor data to token representations and fine-tuning based on domain knowledge.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.03139v1</guid>
      <category>cs.IT</category>
      <category>eess.SP</category>
      <category>math.IT</category>
      <pubDate>Wed, 07 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Zixin Wang, Yuanming Shi, Khaled. B. Letaief</dc:creator>
    </item>
    <item>
      <title>Soft Best-of-n Sampling for Model Alignment</title>
      <link>https://arxiv.org/abs/2505.03156</link>
      <description>arXiv:2505.03156v1 Announce Type: new 
Abstract: Best-of-$n$ (BoN) sampling is a practical approach for aligning language model outputs with human preferences without expensive fine-tuning. BoN sampling is performed by generating $n$ responses to a prompt and then selecting the sample that maximizes a reward function. BoN yields high reward values in practice at a distortion cost, as measured by the KL-divergence between the sampled and original distribution. This distortion is coarsely controlled by varying the number of samples: larger $n$ yields a higher reward at a higher distortion cost. We introduce Soft Best-of-$n$ sampling, a generalization of BoN that allows for smooth interpolation between the original distribution and reward-maximizing distribution through a temperature parameter $\lambda$. We establish theoretical guarantees showing that Soft Best-of-$n$ sampling converges sharply to the optimal tilted distribution at a rate of $O(1/n)$ in KL and the expected (relative) reward. For sequences of discrete outputs, we analyze an additive reward model that reveals the fundamental limitations of blockwise sampling.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.03156v1</guid>
      <category>cs.IT</category>
      <category>cs.AI</category>
      <category>math.IT</category>
      <pubDate>Wed, 07 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Claudio Mayrink Verdun, Alex Oesterling, Himabindu Lakkaraju, Flavio P. Calmon</dc:creator>
    </item>
    <item>
      <title>Multiuser Communications Aided by Cross-Linked Movable Antenna Array: Architecture and Optimization</title>
      <link>https://arxiv.org/abs/2505.03175</link>
      <description>arXiv:2505.03175v1 Announce Type: new 
Abstract: Movable antenna (MA) has been regarded as a promising technology to enhance wireless communication performance by enabling flexible antenna movement. However, the hardware cost of conventional MA systems scales with the number of movable elements due to the need for independently controllable driving components. To reduce hardware cost, we propose in this paper a novel architecture named cross-linked MA (CL-MA) array, which enables the collective movement of multiple antennas in both horizontal and vertical directions. To evaluate the performance benefits of the CL-MA array, we consider an uplink multiuser communication scenario. Specifically, we aim to minimize the total transmit power while satisfying a given minimum rate requirement for each user by jointly optimizing the horizontal and vertical antenna position vectors (APVs), the receive combining at the base station (BS), and the transmit power of users. A globally lower bound on the total transmit power is derived, with closed-form solutions for the APVs obtained under the condition of a single channel path for each user. For the more general case of multiple channel paths, we develop a low-complexity algorithm based on discrete antenna position optimization. Additionally, to further reduce antenna movement overhead, a statistical channel-based antenna position optimization approach is proposed, allowing for unchanged APVs over a long time period. Simulation results demonstrate that the proposed CL-MA schemes significantly outperform conventional fixed-position antenna (FPA) systems and closely approach the theoretical lower bound on the total transmit power. Compared to the instantaneous channel-based CL-MA optimization, the statistical channel-based approach incurs a slight performance loss but achieves significantly lower movement overhead, making it an appealing solution for practical wireless systems.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.03175v1</guid>
      <category>cs.IT</category>
      <category>math.IT</category>
      <pubDate>Wed, 07 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Lipeng Zhu, He Sun, Wenyan Ma, Zhenyu Xiao, Rui Zhang</dc:creator>
    </item>
    <item>
      <title>Signal Prediction by Derivative Samples from the Past via Perfect Reconstruction</title>
      <link>https://arxiv.org/abs/2505.03471</link>
      <description>arXiv:2505.03471v1 Announce Type: new 
Abstract: This paper investigates signal prediction through the perfect reconstruction of signals from shift-invariant spaces using nonuniform samples of both the signal and its derivatives. The key advantage of derivative sampling is its ability to reduce the sampling rate. We derive a sampling formula based on periodic nonuniform sampling (PNS) sets with derivatives in a shift-invariant space. We establish the necessary and sufficient conditions for such a set to form a complete interpolating sequence (CIS) of order $r-1$. This framework is then used to develop an efficient approximation scheme in a shift-invariant space generated by a compactly supported function. Building on this, we propose a prediction algorithm that reconstructs a signal from a finite number of past derivative samples using the derived perfect reconstruction formula. Finally, we validate our theoretical results through practical examples involving cubic splines and the Daubechies scaling function of order 3.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.03471v1</guid>
      <category>cs.IT</category>
      <category>math.IT</category>
      <pubDate>Wed, 07 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Sreya T, Riya Ghosh, A. Antony Selvan</dc:creator>
    </item>
    <item>
      <title>SKALD: Scalable K-Anonymisation for Large Datasets</title>
      <link>https://arxiv.org/abs/2505.03529</link>
      <description>arXiv:2505.03529v1 Announce Type: new 
Abstract: Data privacy and anonymisation are critical concerns in today's data-driven society, particularly when handling personal and sensitive user data. Regulatory frameworks worldwide recommend privacy-preserving protocols such as k-anonymisation to de-identify releases of tabular data. Available hardware resources provide an upper bound on the maximum size of dataset that can be processed at a time. Large datasets with sizes exceeding this upper bound must be broken up into smaller data chunks for processing. In these cases, standard k-anonymisation tools such as ARX can only operate on a per-chunk basis. This paper proposes SKALD, a novel algorithm for performing k-anonymisation on large datasets with limited RAM. Our SKALD algorithm offers multi-fold performance improvement over standard k-anonymisation methods by extracting and combining sufficient statistics from each chunk during processing to ensure successful k-anonymisation while providing better utility.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.03529v1</guid>
      <category>cs.IT</category>
      <category>cs.CR</category>
      <category>math.IT</category>
      <pubDate>Wed, 07 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-sa/4.0/</dc:rights>
      <dc:creator>Kailash Reddy, Novoneel Chakraborty, Amogh Dharmavaram, Anshoo Tandon</dc:creator>
    </item>
    <item>
      <title>A Comprehensive Survey of Large AI Models for Future Communications: Foundations, Applications and Challenges</title>
      <link>https://arxiv.org/abs/2505.03556</link>
      <description>arXiv:2505.03556v1 Announce Type: new 
Abstract: The 6G wireless communications aim to establish an intelligent world of ubiquitous connectivity, providing an unprecedented communication experience. Large artificial intelligence models (LAMs) are characterized by significantly larger scales (e.g., billions or trillions of parameters) compared to typical artificial intelligence (AI) models. LAMs exhibit outstanding cognitive abilities, including strong generalization capabilities for fine-tuning to downstream tasks, and emergent capabilities to handle tasks unseen during training. Therefore, LAMs efficiently provide AI services for diverse communication applications, making them crucial tools for addressing complex challenges in future wireless communication systems. This study provides a comprehensive review of the foundations, applications, and challenges of LAMs in communication. First, we introduce the current state of AI-based communication systems, emphasizing the motivation behind integrating LAMs into communications and summarizing the key contributions. We then present an overview of the essential concepts of LAMs in communication. This includes an introduction to the main architectures of LAMs, such as transformer, diffusion models, and mamba. We also explore the classification of LAMs, including large language models (LLMs), large vision models (LVMs), large multimodal models (LMMs), and world models, and examine their potential applications in communication. Additionally, we cover the training methods and evaluation techniques for LAMs in communication systems. Lastly, we introduce optimization strategies such as chain of thought (CoT), retrieval augmented generation (RAG), and agentic systems. Following this, we discuss the research advancements of LAMs across various communication scenarios. Finally, we analyze the challenges in the current research and provide insights into potential future research directions.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.03556v1</guid>
      <category>cs.IT</category>
      <category>math.IT</category>
      <pubDate>Wed, 07 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Feibo Jiang, Cunhua Pan, Li Dong, Kezhi Wang, Merouane Debbah, Dusit Niyato, Zhu Han</dc:creator>
    </item>
    <item>
      <title>USF Spectral Estimation: Prevalence of Gaussian Cram\'er-Rao Bounds Despite Modulo Folding</title>
      <link>https://arxiv.org/abs/2505.03098</link>
      <description>arXiv:2505.03098v1 Announce Type: cross 
Abstract: Spectral Estimation (SpecEst) is a core area of signal processing with a history spanning two centuries and applications across various fields. With the advent of digital acquisition, SpecEst algorithms have been widely applied to tasks like frequency super-resolution. However, conventional digital acquisition imposes a trade-off: for a fixed bit budget, one can optimize either signal dynamic range or digital resolution (noise floor), but not both simultaneously. The Unlimited Sensing Framework (USF) overcomes this limitation using modulo non-linearity in analog hardware, enabling a novel approach to SpecEst (USF-SpecEst). However, USF-SpecEst requires new theoretical and algorithmic developments to handle folded samples effectively. In this paper, we derive the Cram\'er-Rao Bounds (CRBs) for SpecEst with noisy modulo-folded samples and reveal a surprising result: the CRBs for USF-SpecEst are scaled versions of the Gaussian CRBs for conventional samples. Numerical experiments validate these bounds, providing a benchmark for USF-SpecEst and facilitating its practical deployment.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.03098v1</guid>
      <category>eess.SP</category>
      <category>cs.IT</category>
      <category>math.IT</category>
      <pubDate>Wed, 07 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Ruiming Guo, Ayush Bhandari</dc:creator>
    </item>
    <item>
      <title>Integrated Sensing, Computing, Communication, and Control for Time-Sequence-Based Semantic Communications</title>
      <link>https://arxiv.org/abs/2505.03127</link>
      <description>arXiv:2505.03127v1 Announce Type: cross 
Abstract: In the upcoming industrial internet of things (IIoT) era, a surge of task-oriented applications will rely on real-time wireless control systems (WCSs). For these systems, ultra-reliable and low-latency wireless communication will be crucial to ensure the timely transmission of control information. To achieve this purpose, we propose a novel time-sequence-based semantic communication paradigm, where an integrated sensing, computing, communication, and control (ISC3) architecture is developed to make sensible semantic inference (SI) for the control information over time sequences, enabling adaptive control of the robot. However, due to the causal correlations in the time sequence, the control information does not present the Markov property. To address this challenge, we compute the mutual information of the control information sensed at the transmitter (Tx) over different time and identify their temporal semantic correlation via a semantic feature extractor (SFE) module. By this means, highly correlated information transmission can be avoided, thus greatly reducing the communication overhead. Meanwhile, a semantic feature reconstructor (SFR) module is employed at the receiver (Rx) to reconstruct the control information based on the previously received one if the information transmission is not activated at the Tx. Furthermore, a control gain policy is also employed at the Rx to adaptively adjust the control gain for the controlled target based on several practical aspects such as the quality of the information transmission from the Tx to the Rx. We design the neural network structures of the above modules/policies and train their parameters by a novel hybrid reward multi-agent deep reinforcement learning framework. On-site experiments are conducted to evaluate the performance of our proposed method in practice, which shows significant gains over other baseline schemes.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.03127v1</guid>
      <category>eess.SY</category>
      <category>cs.IT</category>
      <category>cs.SY</category>
      <category>math.IT</category>
      <pubDate>Wed, 07 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Qingliang Li, Bo Chang, Weidong Mei, Zhi Chen</dc:creator>
    </item>
    <item>
      <title>Rapid diagnostics of reconfigurable intelligent surfaces using space-time-coding modulation</title>
      <link>https://arxiv.org/abs/2505.03266</link>
      <description>arXiv:2505.03266v1 Announce Type: cross 
Abstract: Reconfigurable intelligent surfaces (RISs) have emerged as a key technology for shaping smart wireless environments in next-generation wireless communication systems. To support the large-scale deployment of RISs, a reliable and efficient diagnostic method is essential to ensure optimal performance. In this work, a robust and efficient approach for RIS diagnostics is proposed using a space-time coding strategy with orthogonal codes. The method encodes the reflected signals from individual RIS elements into distinct code channels, enabling the recovery of channel power at the receiving terminals for fault identification. Theoretical analysis shows that the normally functioning elements generate high power in their respective code channels, whereas the faulty elements exhibit significantly lower power. This distinction enables rapid and accurate diagnostics of elements' operational states through simple signal processing techniques. Simulation results validate the effectiveness of the proposed method, even under high fault ratios and varying reception angles. Proof-of-principle experiments on two RIS prototypes are conducted, implementing two coding strategies: direct and segmented. Experimental results in a realistic scenario confirm the reliability of the diagnostic method, demonstrating its potential for large-scale RIS deployment in future wireless communication systems and radar applications.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.03266v1</guid>
      <category>physics.optics</category>
      <category>cs.IT</category>
      <category>eess.SP</category>
      <category>math.IT</category>
      <pubDate>Wed, 07 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Yi Ning Zheng, Lei Zhang, Xiao Qing Chen, Marco Rossi, Giuseppe Castaldi, Shuo Liu, Tie Jun Cui, Vincenzo Galdi</dc:creator>
    </item>
    <item>
      <title>GNN-enabled Precoding for Massive MIMO LEO Satellite Communications</title>
      <link>https://arxiv.org/abs/2505.03311</link>
      <description>arXiv:2505.03311v1 Announce Type: cross 
Abstract: Low Earth Orbit (LEO) satellite communication is a critical component in the development of sixth generation (6G) networks. The integration of massive multiple-input multiple-output (MIMO) technology is being actively explored to enhance the performance of LEO satellite communications. However, the limited power of LEO satellites poses a significant challenge in improving communication energy efficiency (EE) under constrained power conditions. Artificial intelligence (AI) methods are increasingly recognized as promising solutions for optimizing energy consumption while enhancing system performance, thus enabling more efficient and sustainable communications. This paper proposes approaches to address the challenges associated with precoding in massive MIMO LEO satellite communications. First, we introduce an end-to-end graph neural network (GNN) framework that effectively reduces the computational complexity of traditional precoding methods. Next, we introduce a deep unfolding of the Dinkelbach algorithm and the weighted minimum mean square error (WMMSE) approach to achieve enhanced EE, transforming iterative optimization processes into a structured neural network, thereby improving convergence speed and computational efficiency. Furthermore, we incorporate the Taylor expansion method to approximate matrix inversion within the GNN, enhancing both the interpretability and performance of the proposed method. Numerical experiments demonstrate the validity of our proposed method in terms of complexity and robustness, achieving significant improvements over state-of-the-art methods.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.03311v1</guid>
      <category>eess.SP</category>
      <category>cs.IT</category>
      <category>math.IT</category>
      <pubDate>Wed, 07 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Huibin Zhou, Xinrui Gong, Christos G. Tsinos, Li You, Xiqi Gao, Bj\"orn Ottersten</dc:creator>
    </item>
    <item>
      <title>CB-cPIR: Code-Based Computational Private Information Retrieval</title>
      <link>https://arxiv.org/abs/2505.03407</link>
      <description>arXiv:2505.03407v1 Announce Type: cross 
Abstract: A private information retrieval (PIR) scheme is a protocol that allows a user to retrieve a file from a database without revealing the identity of the desired file to a curious database. Given a distributed data storage system, efficient PIR can be achieved by making assumptions about the colluding capabilities of the storage servers holding the database. If these assumptions turn out to be incorrect, privacy is lost. In this work, we focus on the worst-case assumption: full collusion or, equivalently, viewing the storage system virtually as a single honest-but-curious server. We present CB-cPIR, a single-server code-based computational private information retrieval (cPIR) scheme that derives security from code-based cryptography. Specifically, the queries are protected by the hardness of decoding a random linear code. The scheme is heavily inspired by the pioneering code-based cPIR scheme proposed by Holzbaur, Hollanti, and Wachter-Zeh in [Holzbaur et al., "Computational Code-Based Single-Server Private Information Retrieval", 2020 IEEE ISIT] and fixes the vulnerabilities of the original scheme arising from highly probable rank differences in submatrices of the user's query. For further validation, we draw comparisons to the state-of-the-art lattice-based cPIR schemes.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.03407v1</guid>
      <category>cs.IR</category>
      <category>cs.IT</category>
      <category>math.IT</category>
      <pubDate>Wed, 07 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Camilla Hollanti, Neehar Verma</dc:creator>
    </item>
    <item>
      <title>Information-theoretic reduction of deep neural networks to linear models in the overparametrized proportional regime</title>
      <link>https://arxiv.org/abs/2505.03577</link>
      <description>arXiv:2505.03577v1 Announce Type: cross 
Abstract: We rigorously analyse fully-trained neural networks of arbitrary depth in the Bayesian optimal setting in the so-called proportional scaling regime where the number of training samples and width of the input and all inner layers diverge proportionally. We prove an information-theoretic equivalence between the Bayesian deep neural network model trained from data generated by a teacher with matching architecture, and a simpler model of optimal inference in a generalized linear model. This equivalence enables us to compute the optimal generalization error for deep neural networks in this regime. We thus prove the "deep Gaussian equivalence principle" conjectured in Cui et al. (2023) (arXiv:2302.00375). Our result highlights that in order to escape this "trivialisation" of deep neural networks (in the sense of reduction to a linear model) happening in the strongly overparametrized proportional regime, models trained from much more data have to be considered.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.03577v1</guid>
      <category>math.ST</category>
      <category>cond-mat.dis-nn</category>
      <category>cs.IT</category>
      <category>math-ph</category>
      <category>math.IT</category>
      <category>math.MP</category>
      <category>stat.ML</category>
      <category>stat.TH</category>
      <pubDate>Wed, 07 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Francesco Camilli, Daria Tieplova, Eleonora Bergamin, Jean Barbier</dc:creator>
    </item>
    <item>
      <title>DNA Tails for Molecular Flash Memory</title>
      <link>https://arxiv.org/abs/2505.03629</link>
      <description>arXiv:2505.03629v1 Announce Type: cross 
Abstract: DNA-based data storage systems face practical challenges due to the high cost of DNA synthesis. A strategy to address the problem entails encoding data via topological modifications of the DNA sugar-phosphate backbone. The DNA Punchcards system, which introduces nicks (cuts) in the DNA backbone, encodes only one bit per nicking site, limiting density. We propose \emph{DNA Tails,} a storage paradigm that encodes nonbinary symbols at nicking sites by growing enzymatically synthesized single-stranded DNA of varied lengths. The average tail lengths encode multiple information bits and are controlled via a staggered nicking-tail extension process. We demonstrate the feasibility of this encoding approach experimentally and identify common sources of errors, such as calibration errors and stumped tail growth errors. To mitigate calibration errors, we use rank modulation proposed for flash memory. To correct stumped tail growth errors, we introduce a new family of rank modulation codes that can correct ``stuck-at'' errors. Our analytical results include constructions for order-optimal-redundancy permutation codes and accompanying encoding and decoding algorithms.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.03629v1</guid>
      <category>cs.ET</category>
      <category>cs.IT</category>
      <category>math.IT</category>
      <pubDate>Wed, 07 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Jin Sima, Chao Pan, S. Kasra Tabatabaei, Alvaro G. Hernandez, Charles M. Schroeder, Olgica Milenkovic</dc:creator>
    </item>
    <item>
      <title>Joint Signal and Topology Optimization for Maximum Instantaneous Field Intensity</title>
      <link>https://arxiv.org/abs/2409.16293</link>
      <description>arXiv:2409.16293v3 Announce Type: replace 
Abstract: This paper introduces a computational approach to identify performance constraints in the time-domain, offering a way to design systems in pulse operation. This work presents a comprehensive application of convex optimization to determine fundamental bounds on time-domain waveforms. The approach is applied to arbitrarily polarized multiport antennas and arrays, demonstrating their capability in maximizing peak radiation intensity in a specified direction and time under energy constraints. This methodology allows us to consider matching, which is crucial in such applications. To highlight the generality of the approach, receiving systems are also studied on an example of finding optimal illumination for antiferromagnetic memory switching. Thanks to its efficacy, this work enables joint optimization of excitation and system parameters.</description>
      <guid isPermaLink="false">oai:arXiv.org:2409.16293v3</guid>
      <category>cs.IT</category>
      <category>math.IT</category>
      <pubDate>Wed, 07 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Jakub Liska, Lukas Jelinek, Miloslav Capek</dc:creator>
    </item>
    <item>
      <title>Editable-DeepSC: Reliable Cross-Modal Semantic Communications for Facial Editing</title>
      <link>https://arxiv.org/abs/2411.15702</link>
      <description>arXiv:2411.15702v2 Announce Type: replace 
Abstract: Real-time computer vision (CV) plays a crucial role in various real-world applications, whose performance is highly dependent on communication networks. Nonetheless, the data-oriented characteristics of conventional communications often do not align with the special needs of real-time CV tasks. To alleviate this issue, the recently emerged semantic communications only transmit task-related semantic information and exhibit a promising landscape to address this problem. However, the communication challenges associated with Semantic Facial Editing, one of the most important real-time CV applications on social media, still remain largely unexplored. In this paper, we fill this gap by proposing Editable-DeepSC, a novel cross-modal semantic communication approach for facial editing. Firstly, we theoretically discuss different transmission schemes that separately handle communications and editings, and emphasize the necessity of Joint Editing-Channel Coding (JECC) via iterative attributes matching, which integrates editings into the communication chain to preserve more semantic mutual information. To compactly represent the high-dimensional data, we leverage inversion methods via pre-trained StyleGAN priors for semantic coding. To tackle the dynamic channel noise conditions, we propose SNR-aware channel coding via model fine-tuning. Extensive experiments indicate that Editable-DeepSC can achieve superior editings while significantly saving the transmission bandwidth, even under high-resolution and out-of-distribution (OOD) settings.</description>
      <guid isPermaLink="false">oai:arXiv.org:2411.15702v2</guid>
      <category>cs.IT</category>
      <category>cs.CV</category>
      <category>cs.NI</category>
      <category>math.IT</category>
      <pubDate>Wed, 07 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Bin Chen, Wenbo Yu, Qinshan Zhang, Tianqu Zhuang, Yong Jiang, Shu-Tao Xia</dc:creator>
    </item>
    <item>
      <title>Polarization under the Channel Noise with Memory</title>
      <link>https://arxiv.org/abs/2411.16557</link>
      <description>arXiv:2411.16557v2 Announce Type: replace 
Abstract: This paper presents a comprehensive study of channel polarization under noise with memory. By introducing a genie-aided channel model, we demonstrate that polarized subchannels still converge to extremal channels under the standard polar coding structure. Notably, the proportion of near-perfect subchannels can exceed the underlying channel capacity $I(W)$. However, we also show that the polarization rate is slower than that observed in the binary-input memoryless channel (BMC) scenario. In particular, the block error probability is upper-bounded by $\mathcal{O}(L^{-c_0})$, where $L$ denotes the block length and $c_0$ is a positive constant. Moreover, we investigate both upper and lower bounds on the gap between the channel capacity and the cutoff rate under finite block length, which offers greater relevance for practical implementations.</description>
      <guid isPermaLink="false">oai:arXiv.org:2411.16557v2</guid>
      <category>cs.IT</category>
      <category>eess.SP</category>
      <category>math.IT</category>
      <pubDate>Wed, 07 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Tianfu Qi, Jun Wang</dc:creator>
    </item>
    <item>
      <title>Numerical evaluation of Gaussian mixture entropy</title>
      <link>https://arxiv.org/abs/2503.14047</link>
      <description>arXiv:2503.14047v2 Announce Type: replace 
Abstract: We develop an approximation method for the differential entropy $h(\mathbf{X})$ of a $q$-component Gaussian mixture in $\mathbb{R}^n$. We provide two examples of approximations using our method denoted by $\bar{h}^{\mathrm{Taylor}}_{C,m}(\mathbf{X})$ and $\bar{h}^{\mathrm{Polyfit}}_{C,m}(\mathbf{X})$. We show that $\bar{h}^{\mathrm{Taylor}}_{C,m}(\mathbf{X})$ provides an easy to compute lower bound to $h(\mathbf{X})$, while $\bar{h}^{\mathrm{Polyfit}}_{C,m}(\mathbf{X})$ provides an accurate and efficient approximation to $h(\mathbf{X})$. $\bar{h}^{\mathrm{Polyfit}}_{C,m}(\mathbf{X})$ is more accurate than known bounds, and conjectured to be much more resilient than the approximation of [5] in high dimensions.</description>
      <guid isPermaLink="false">oai:arXiv.org:2503.14047v2</guid>
      <category>cs.IT</category>
      <category>math.IT</category>
      <pubDate>Wed, 07 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Basheer Joudeh, Boris \v{S}kori\'c</dc:creator>
    </item>
    <item>
      <title>Can Knowledge Improve Security? A Coding-Enhanced Jamming Approach for Semantic Communication</title>
      <link>https://arxiv.org/abs/2504.16960</link>
      <description>arXiv:2504.16960v3 Announce Type: replace 
Abstract: As semantic communication (SemCom) attracts growing attention as a novel communication paradigm, ensuring the security of transmitted semantic information over open wireless channels has become a critical issue. However, traditional encryption methods often introduce significant additional communication overhead to maintain stability, and conventional learning-based secure SemCom methods typically rely on a channel capacity advantage for the legitimate receiver, which is challenging to guarantee in real-world scenarios. In this paper, we propose a coding-enhanced jamming method that eliminates the need to transmit a secret key by utilizing shared knowledge-potentially part of the training set of the SemCom system-between the legitimate receiver and the transmitter. Specifically, we leverage the shared private knowledge base to generate a set of private digital codebooks in advance using neural network (NN)-based encoders. For each transmission, we encode the transmitted data into digital sequence Y1 and associate Y1 with a sequence randomly picked from the private codebook, denoted as Y2, through superposition coding. Here, Y1 serves as the outer code and Y2 as the inner code. By optimizing the power allocation between the inner and outer codes, the legitimate receiver can reconstruct the transmitted data using successive decoding with the index of Y2 shared, while the eavesdropper' s decoding performance is severely degraded, potentially to the point of random guessing. Experimental results demonstrate that our method achieves comparable security to state-of-the-art approaches while significantly improving the reconstruction performance of the legitimate receiver by more than 1 dB across varying channel signal-to-noise ratios (SNRs) and compression ratios.</description>
      <guid isPermaLink="false">oai:arXiv.org:2504.16960v3</guid>
      <category>cs.IT</category>
      <category>eess.IV</category>
      <category>math.IT</category>
      <pubDate>Wed, 07 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Weixuan Chen (Sherman), Qianqian Yang (Sherman), Shuo Shao (Sherman), Zhiguo Shi (Sherman), Jiming Chen (Sherman),  Xuemin (Sherman),  Shen</dc:creator>
    </item>
    <item>
      <title>SemSpaceFL: A Collaborative Hierarchical Federated Learning Framework for Semantic Communication in 6G LEO Satellites</title>
      <link>https://arxiv.org/abs/2505.00966</link>
      <description>arXiv:2505.00966v2 Announce Type: replace 
Abstract: The advent of the sixth-generation (6G) wireless networks, enhanced by artificial intelligence, promises ubiquitous connectivity through Low Earth Orbit (LEO) satellites. These satellites are capable of collecting vast amounts of geographically diverse and real-time data, which can be immensely valuable for training intelligent models. However, limited inter-satellite communication and data privacy constraints hinder data collection on a single server for training. Therefore, we propose SemSpaceFL, a novel hierarchical federated learning (HFL) framework for LEO satellite networks, with integrated semantic communication capabilities. Our framework introduces a two-tier aggregation architecture where satellite models are first aggregated at regional gateways before final consolidation at a cloud server, which explicitly accounts for satellite mobility patterns and energy constraints. The key innovation lies in our novel aggregation approach, which dynamically adjusts the contribution of each satellite based on its trajectory and association with different gateways, which ensures stable model convergence despite the highly dynamic nature of LEO constellations. To further enhance communication efficiency, we incorporate semantic encoding-decoding techniques trained through the proposed HFL framework, which enables intelligent data compression while maintaining signal integrity. Our experimental results demonstrate that the proposed aggregation strategy achieves superior performance and faster convergence compared to existing benchmarks, while effectively managing the challenges of satellite mobility and energy limitations in dynamic LEO networks.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.00966v2</guid>
      <category>cs.IT</category>
      <category>cs.DC</category>
      <category>cs.ET</category>
      <category>cs.NI</category>
      <category>math.IT</category>
      <pubDate>Wed, 07 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Loc X. Nguyen, Sheikh Salman Hassan, Yu Min Park, Yan Kyaw Tun, Zhu Han, Choong Seon Hong</dc:creator>
    </item>
    <item>
      <title>Alon's transmitting problem and multicolor Beck--Spencer Lemma</title>
      <link>https://arxiv.org/abs/2406.19945</link>
      <description>arXiv:2406.19945v3 Announce Type: replace-cross 
Abstract: The Hamming graph $H(n,q)$ is defined on the vertex set $\{1,2,\ldots,q\}^n$ and two vertices are adjacent if and only if they differ in precisely one coordinate. Alon (1992) proved that for any sequence $v_1,\ldots,v_b$ of $b=\lceil\frac n2\rceil$ vertices of $H(n,2)$, there is a vertex whose distance from $v_i$ is at least $b-i+1$ for all $1\leq i\leq b$. In this note, we prove that for any $q\geq 3$ and any sequence $v_1,\ldots,v_b$ of $b=\lfloor(1-\frac1q)n\rfloor$ vertices of $H(n,q)$, there is a vertex whose distance from $v_i$ is at least $b-i+1$ for all $1\leq i\leq b$.
  Alon used a lemma due to Beck and Spencer (1983) which, in turn, was based on the floating variable method introduced by Beck and Fiala (1981) who studied combinatorial discrepancies. For our proof, we extend the Beck--Spencer Lemma by using a multicolor version of the floating variable method due to Doerr and Srivastav (2003).</description>
      <guid isPermaLink="false">oai:arXiv.org:2406.19945v3</guid>
      <category>math.CO</category>
      <category>cs.IT</category>
      <category>math.IT</category>
      <category>math.OC</category>
      <pubDate>Wed, 07 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Norihide Tokushige</dc:creator>
    </item>
    <item>
      <title>On the metric mean dimensions of saturated sets</title>
      <link>https://arxiv.org/abs/2412.09218</link>
      <description>arXiv:2412.09218v3 Announce Type: replace-cross 
Abstract: Saturated sets and its reduced case, the set of generic points, constitute two significant types of fractal-like sets in multifractal analysis of dynamical systems. In the context of infinite entropy systems, we aim to provide some qualitative aspects of saturated sets and the set of generic points from both topological and measure-theoretic perspectives.
  For systems with the specification property, we establish certain variational principles for saturated sets in terms of Bowen and packing metric mean dimensions, and show the upper capacity metric mean dimension of saturated sets has full metric mean dimension. As applications, we further present some qualitative aspects of the metric mean dimensions of level sets and the set of mean Li-Yorke pairs in infinite entropy systems.</description>
      <guid isPermaLink="false">oai:arXiv.org:2412.09218v3</guid>
      <category>math.DS</category>
      <category>cs.IT</category>
      <category>math.IT</category>
      <pubDate>Wed, 07 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Yong Ji, Junye Li, Rui Yang</dc:creator>
    </item>
    <item>
      <title>Bayesian Rao test for distributed target detection in interference and noise with limited training data</title>
      <link>https://arxiv.org/abs/2504.13235</link>
      <description>arXiv:2504.13235v2 Announce Type: replace-cross 
Abstract: This paper has studied the problem of detecting a range-spread target in interference and noise when the number of training data is limited. The interference is located within a certain subspace with an unknown coordinate, while the noise follows a Gaussian distribution with an unknown covariance matrix. We concentrate on the scenarios where the training data are limited and employ a Bayesian framework to ffnd a solution. Speciffcally, the covariance matrix is assumed to follow an inverse Wishart distribution. Then, we introduce the Bayesian detector according to the Rao test, which, demonstrated by both simulation experiment and real data, has superior detection performance to the existing detectors in certain situations.</description>
      <guid isPermaLink="false">oai:arXiv.org:2504.13235v2</guid>
      <category>stat.ME</category>
      <category>cs.IT</category>
      <category>math.IT</category>
      <pubDate>Wed, 07 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <arxiv:DOI>10.1007/s11432-024-4422-3</arxiv:DOI>
      <dc:creator>Daipeng Xiao, Weijian Liu, Jun Liu, Yuntao Wu, Qinglei Du, Xiaoqiang Hua</dc:creator>
    </item>
    <item>
      <title>Sharpness-Aware Minimization with Z-Score Gradient Filtering for Neural Networks</title>
      <link>https://arxiv.org/abs/2505.02369</link>
      <description>arXiv:2505.02369v3 Announce Type: replace-cross 
Abstract: Sharpness-Aware Minimization (SAM) improves neural network generalization by optimizing the worst-case loss within a neighborhood of parameters, yet it perturbs parameters using the entire gradient vector, including components with low statistical significance. We introduce ZSharp, a refined sharpness-aware optimization method that incorporates layer-wise Z-score normalization followed by percentile-based filtering. This process selects only the most statistically significant gradient components-those with large standardized magnitudes-for constructing the perturbation direction. ZSharp retains the standard two-phase SAM structure of ascent and descent while modifying the ascent step to focus on sharper, curvature-relevant directions. We evaluate ZSharp on CIFAR-10, CIFAR-100, and Tiny-ImageNet using a range of models including ResNet, VGG, and Vision Transformers. Across all architectures and datasets, ZSharp consistently achieves higher test accuracy compared to SAM, ASAM, and Friendly-SAM. These results indicate that Z-score-based gradient filtering can enhance the sharpness sensitivity of the update direction, leading to improved generalization in deep neural network training.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.02369v3</guid>
      <category>cs.LG</category>
      <category>cs.AI</category>
      <category>cs.CV</category>
      <category>cs.IT</category>
      <category>cs.NE</category>
      <category>math.IT</category>
      <pubDate>Wed, 07 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/publicdomain/zero/1.0/</dc:rights>
      <dc:creator>Juyoung Yun</dc:creator>
    </item>
  </channel>
</rss>
