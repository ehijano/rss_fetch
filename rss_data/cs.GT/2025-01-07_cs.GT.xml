<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>cs.GT updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/cs.GT</link>
    <description>cs.GT updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/cs.GT" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Tue, 07 Jan 2025 05:00:11 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Tue, 07 Jan 2025 00:00:00 -0500</pubDate>
    <skipDays>
      <day>Sunday</day>
      <day>Saturday</day>
    </skipDays>
    <item>
      <title>Optimal bounds for dissatisfaction in perpetual voting</title>
      <link>https://arxiv.org/abs/2501.01969</link>
      <description>arXiv:2501.01969v1 Announce Type: new 
Abstract: In perpetual voting, multiple decisions are made at different moments in time. Taking the history of previous decisions into account allows us to satisfy properties such as proportionality over periods of time. In this paper, we consider the following question: is there a perpetual approval voting method that guarantees that no voter is dissatisfied too many times? We identify a sufficient condition on voter behavior -- which we call 'bounded conflicts' condition -- under which a sublinear growth of dissatisfaction is possible. We provide a tight upper bound on the growth of dissatisfaction under bounded conflicts, using techniques from Kolmogorov complexity. We also observe that the approval voting with binary choices mimics the machine learning setting of prediction with expert advice. This allows us to present a voting method with sublinear guarantees on dissatisfaction under bounded conflicts, based on the standard techniques from prediction with expert advice.</description>
      <guid isPermaLink="false">oai:arXiv.org:2501.01969v1</guid>
      <category>cs.GT</category>
      <category>cs.AI</category>
      <category>cs.LG</category>
      <pubDate>Tue, 07 Jan 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Alexander Kozachinskiy, Alexander Shen, Tomasz Steifer</dc:creator>
    </item>
    <item>
      <title>Approximating N-Player Nash Equilibrium through Gradient Descent</title>
      <link>https://arxiv.org/abs/2501.03001</link>
      <description>arXiv:2501.03001v1 Announce Type: new 
Abstract: Decoding how rational agents should behave in shared systems remains a critical challenge within theoretical computer science, artificial intelligence and economics studies. Central to this challenge is the task of computing the solution concept of games, which is Nash equilibrium (NE). Although computing NE in even two-player cases are known to be PPAD-hard, approximation solutions are of intensive interest in the machine learning domain. In this paper, we present a gradient-based approach to obtain approximate NE in N-player general-sum games. Specifically, we define a distance measure to an NE based on pure strategy best response, thereby computing an NE can be effectively transformed into finding the global minimum of this distance function through gradient descent. We prove that the proposed procedure converges to NE with rate $O(1/T)$ ($T$ is the number of iterations) when the utility function is convex. Experimental results suggest our method outperforms Tsaknakis-Spirakis algorithm, fictitious play and regret matching on various types of N-player normal-form games in GAMUT. In addition, our method demonstrates robust performance with increasing number of players and number of actions.</description>
      <guid isPermaLink="false">oai:arXiv.org:2501.03001v1</guid>
      <category>cs.GT</category>
      <pubDate>Tue, 07 Jan 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Dongge Wang, Xiang Yan, Zehao Dou, Wenhan Huang, Yaodong Yang, Xiaotie Deng</dc:creator>
    </item>
    <item>
      <title>To Analyze and Regulate Human-in-the-loop Learning for Congestion Games</title>
      <link>https://arxiv.org/abs/2501.03055</link>
      <description>arXiv:2501.03055v1 Announce Type: new 
Abstract: In congestion games, selfish users behave myopically to crowd to the shortest paths, and the social planner designs mechanisms to regulate such selfish routing through information or payment incentives. However, such mechanism design requires the knowledge of time-varying traffic conditions and it is the users themselves to learn and report past road experiences to the social planner (e.g., Waze or Google Maps). When congestion games meet mobile crowdsourcing, it is critical to incentivize selfish users to explore non-shortest paths in the best exploitation-exploration trade-off. First, we consider a simple but fundamental parallel routing network with one deterministic path and multiple stochastic paths for users with an average arrival probability $\lambda$. We prove that the current myopic routing policy (widely used in Waze and Google Maps) misses both exploration (when strong hazard belief) and exploitation (when weak hazard belief) as compared to the social optimum. Due to the myopic policy's under-exploration, we prove that the caused price of anarchy (PoA) is larger than \(\frac{1}{1-\rho^{\frac{1}{\lambda}}}\), which can be arbitrarily large as discount factor \(\rho\rightarrow1\). To mitigate such huge efficiency loss, we propose a novel selective information disclosure (SID) mechanism: we only reveal the latest traffic information to users when they intend to over-explore stochastic paths upon arrival, while hiding such information when they want to under-explore. We prove that our mechanism successfully reduces PoA to be less than~\(2\). Besides the parallel routing network, we further extend our mechanism and PoA results to any linear path graphs with multiple intermediate nodes.</description>
      <guid isPermaLink="false">oai:arXiv.org:2501.03055v1</guid>
      <category>cs.GT</category>
      <category>cs.AI</category>
      <pubDate>Tue, 07 Jan 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Hongbo Li, Lingjie Duan</dc:creator>
    </item>
    <item>
      <title>Foundations of Platform-Assisted Auctions</title>
      <link>https://arxiv.org/abs/2501.03141</link>
      <description>arXiv:2501.03141v1 Announce Type: new 
Abstract: Today, many auctions are carried out with the help of intermediary platforms like Google and eBay. We refer to such auctions as platform-assisted auctions.Traditionally, the auction theory literature mainly focuses on designing auctions that incentivize the buyers to bid truthfully,assuming that the platform always faithfully implements the auction. In practice, however, the platforms have been found to manipulate the auctions to earn more profit, resulting in high-profile anti-trust lawsuits. We propose a new model for studying platform-assisted auctions in the permissionless setting. We explore whether it is possible to design a dream auction in thisnew model, such that honest behavior is the utility-maximizing strategy for each individual buyer, the platform, the seller, as well as platform-seller or platform-buyer coalitions.Through a collection of feasibility and infeasibility results,we carefully characterize the mathematical landscape of platform-assisted auctions. We show how cryptography can lend to the design of an efficient platform-assisted auction with dream properties. Although a line of works have also used MPC or the blockchain to remove the reliance on a trusted auctioneer, our work is distinct in nature in several dimensions.First, we initiate a systematic exploration of the game theoretic implications when the service providers are strategic and can collude with sellers or buyers. Second, we observe that the full simulation paradigm is too stringent and leads to high asymptotical costs. Specifically, because every player has a different private outcomein an auction protocol, running any generic MPC protocol among the players would incur at least $n^2$ total cost. We propose a new notion of simulation calledutility-dominated emulation.Under this new notion, we showhow to design efficient auction protocols with quasilinear efficiency.</description>
      <guid isPermaLink="false">oai:arXiv.org:2501.03141v1</guid>
      <category>cs.GT</category>
      <category>cs.CR</category>
      <category>econ.TH</category>
      <pubDate>Tue, 07 Jan 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Hao Chung, Ke Wu, Elaine Shi</dc:creator>
    </item>
    <item>
      <title>Quantum Communication Complexity of Classical Auctions</title>
      <link>https://arxiv.org/abs/2311.12444</link>
      <description>arXiv:2311.12444v2 Announce Type: replace 
Abstract: We study the fundamental, classical mechanism design problem of single-buyer multi-item Bayesian revenue-maximizing auctions under the lens of communication complexity between the buyer and the seller. Specifically, we ask whether using quantum communication can be more efficient than classical communication. We have two sets of results, revealing a surprisingly rich landscape - which looks quite different from both quantum communication in non-strategic parties, and classical communication in mechanism design.
  We first study the expected communication complexity of approximately optimal auctions. We give quantum auction protocols for buyers with unit-demand or combinatorial valuations that obtain an arbitrarily good approximation of the optimal revenue while running in exponentially more efficient communication compared to classical approximately optimal auctions. However, these auctions come with the caveat that they may require the seller to charge exponentially large payments from a deviating buyer. We show that this caveat is necessary - we give an exponential lower bound on the product of the expected quantum communication and the maximum payment.
  We then study the worst-case communication complexity of exactly optimal auctions in an extremely simple setting: additive buyer's valuations over two items. We show the following separations:
  1. There exists a prior where the optimal classical auction protocol requires infinitely many bits, but a one-way message of 1 qubit and 2 classical bits suffices.
  2. There exists a prior where no finite one-way quantum auction protocol can obtain the optimal revenue. However, there is a barely-interactive revenue-optimal quantum auction protocol.
  3. There exists a prior where no multi-round quantum auction protocol with a finite bound on communication complexity can obtain the optimal revenue.</description>
      <guid isPermaLink="false">oai:arXiv.org:2311.12444v2</guid>
      <category>cs.GT</category>
      <category>quant-ph</category>
      <pubDate>Tue, 07 Jan 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Aviad Rubinstein, Zixin Zhou</dc:creator>
    </item>
    <item>
      <title>Automated Security Response through Online Learning with Adaptive Conjectures</title>
      <link>https://arxiv.org/abs/2402.12499</link>
      <description>arXiv:2402.12499v4 Announce Type: replace 
Abstract: We study automated security response for an IT infrastructure and formulate the interaction between an attacker and a defender as a partially observed, non-stationary game. We relax the standard assumption that the game model is correctly specified and consider that each player has a probabilistic conjecture about the model, which may be misspecified in the sense that the true model has probability 0. This formulation allows us to capture uncertainty and misconception about the infrastructure and the intents of the players. To learn effective game strategies online, we design Conjectural Online Learning (COL), a novel method where a player iteratively adapts its conjecture using Bayesian learning and updates its strategy through rollout. We prove that the conjectures converge to best fits, and we provide a bound on the performance improvement that rollout enables with a conjectured model. To characterize the steady state of the game, we propose a variant of the Berk-Nash equilibrium. We present COL through an advanced persistent threat use case. Testbed evaluations show that COL produces effective security strategies that adapt to a changing environment. We also find that COL enables faster convergence than current reinforcement learning techniques.</description>
      <guid isPermaLink="false">oai:arXiv.org:2402.12499v4</guid>
      <category>cs.GT</category>
      <category>cs.AI</category>
      <category>cs.CR</category>
      <category>cs.LG</category>
      <category>cs.SY</category>
      <category>eess.SY</category>
      <pubDate>Tue, 07 Jan 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-sa/4.0/</dc:rights>
      <dc:creator>Kim Hammar, Tao Li, Rolf Stadler, Quanyan Zhu</dc:creator>
    </item>
    <item>
      <title>Signal Observation Models and Historical Information Integration in Poker Hand Abstraction</title>
      <link>https://arxiv.org/abs/2403.11486</link>
      <description>arXiv:2403.11486v3 Announce Type: replace 
Abstract: Hand abstraction has been instrumental in developing powerful AI for Texas Hold'em poker, a widely studied testbed for imperfect information games (IIGs). Despite its success, the hand abstraction task lacks robust theoretical tools, limiting both algorithmic innovation and theoretical progress. To address this, we extend the IIG framework with the \textbf{signal observation ordered game} model and introduce \textbf{signal observation abstraction} to formalize the hand abstraction task. We further propose a novel evaluation metric, the \textbf{resolution bound}, to assess the performance of signal observation abstraction algorithms. Using this metric, we uncover critical limitations in current state-of-the-art algorithms, particularly the significant information loss caused by the enforced omission of historical information. To resolve these issues, we present the \textbf{KrwEmd} algorithm, which effectively incorporates historical information into the abstraction process. Experiments in the Numeral211 hold'em environment demonstrate that KrwEmd addresses these limitations and significantly outperforms existing algorithms.</description>
      <guid isPermaLink="false">oai:arXiv.org:2403.11486v3</guid>
      <category>cs.GT</category>
      <pubDate>Tue, 07 Jan 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Yanchang Fu, Pei Xu, Dongdong Bai, Lingyun Zhao, Kaiqi Huang</dc:creator>
    </item>
    <item>
      <title>The Cost and Complexity of Minimizing Envy in House Allocation</title>
      <link>https://arxiv.org/abs/2406.09744</link>
      <description>arXiv:2406.09744v2 Announce Type: replace 
Abstract: We study almost-envy-freeness in house allocation, where $m$ houses are to be allocated among $n$ agents so that every agent receives exactly one house. An envy-free allocation need not exist, and therefore we may have to settle for relaxations of envy-freeness. But typical relaxations such as envy-free up to one good do not make sense for house allocation, as every agent is required to receive exactly one house. Hence we turn to different aggregate measures of envy as markers of fairness. In particular, we define the amount of envy experienced by an agent $a$ w.r.t. an allocation to be the number of agents that agent $a$ envies under that allocation. We quantify the envy generated by an allocation using three different metrics: 1) the number of agents who are envious; 2) the maximum amount of envy experienced by any agent; and 3) the total amount of envy experienced by all agents, and look for allocations that minimize one of the three metrics. We thus study three computational problems corresponding to each of the three metrics and prove a host of algorithmic and hardness results. We also suggest practical approaches for these problems via integer linear program (ILP) formulations and report the findings of our experimental evaluation of ILPs. Finally, we study the price of fairness (PoF), which quantifies the loss of welfare we must suffer due to the fairness requirements, and we prove a number of results on PoF, including tight bounds as well as algorithms that simultaneously optimize both welfare and fairness.</description>
      <guid isPermaLink="false">oai:arXiv.org:2406.09744v2</guid>
      <category>cs.GT</category>
      <pubDate>Tue, 07 Jan 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Jayakrishnan Madathil, Neeldhara Misra, Aditi Sethia</dc:creator>
    </item>
    <item>
      <title>CERN for AI: A Theoretical Framework for Autonomous Simulation-Based Artificial Intelligence Testing and Alignment</title>
      <link>https://arxiv.org/abs/2312.09402</link>
      <description>arXiv:2312.09402v2 Announce Type: replace-cross 
Abstract: This paper explores the potential of a multidisciplinary approach to testing and aligning artificial intelligence (AI), specifically focusing on large language models (LLMs). Due to the rapid development and wide application of LLMs, challenges such as ethical alignment, controllability, and predictability of these models emerged as global risks. This study investigates an innovative simulation-based multi-agent system within a virtual reality framework that replicates the real-world environment. The framework is populated by automated 'digital citizens,' simulating complex social structures and interactions to examine and optimize AI. Application of various theories from the fields of sociology, social psychology, computer science, physics, biology, and economics demonstrates the possibility of a more human-aligned and socially responsible AI. The purpose of such a digital environment is to provide a dynamic platform where advanced AI agents can interact and make independent decisions, thereby mimicking realistic scenarios. The actors in this digital city, operated by the LLMs, serve as the primary agents, exhibiting high degrees of autonomy. While this approach shows immense potential, there are notable challenges and limitations, most significantly the unpredictable nature of real-world social dynamics. This research endeavors to contribute to the development and refinement of AI, emphasizing the integration of social, ethical, and theoretical dimensions for future research.</description>
      <guid isPermaLink="false">oai:arXiv.org:2312.09402v2</guid>
      <category>cs.CY</category>
      <category>cs.AI</category>
      <category>cs.GT</category>
      <pubDate>Tue, 07 Jan 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <arxiv:DOI>10.1186/s40309-024-00238-0</arxiv:DOI>
      <dc:creator>Ljubisa Bojic, Matteo Cinelli, Dubravko Culibrk, Boris Delibasic</dc:creator>
    </item>
  </channel>
</rss>
