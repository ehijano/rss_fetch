<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>cs.CE updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/cs.CE</link>
    <description>cs.CE updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/cs.CE" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Thu, 23 Oct 2025 04:00:17 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Thu, 23 Oct 2025 00:00:00 -0400</pubDate>
    <skipDays>
      <day>Saturday</day>
      <day>Sunday</day>
    </skipDays>
    <item>
      <title>Parameter Estimation in River Transport Models With Immobile Phase Exchange Using Dimensional Analysis and Reduced-Order Models</title>
      <link>https://arxiv.org/abs/2510.19664</link>
      <description>arXiv:2510.19664v1 Announce Type: new 
Abstract: We propose a framework for parameter estimation in river transport models using breakthrough curve data, which we refer to as Dimensionless Synthetic Transport Estimation (DSTE). We utilize this framework to parameterize the one-dimensional advection-dispersion equation model, incorporating immobile phase exchange through a memory function. We solve the governing equation analytically in the Laplace domain and numerically invert it to generate synthetic breakthrough curves for different memory functions and boundary conditions. A dimensionless formulation enables decoupling the estimation of advection velocity from other parameters, significantly reducing the number of required forward solutions. To improve computational efficiency, we apply a Karhunen-Loeve (KL) expansion to transform the synthetic dataset into a reduced-order space. Given a measured breakthrough curve, we estimate the advection velocity by minimizing the distance from the measurement to the synthetic data in KL space, and infer the remaining dimensionless parameters by Projected Barycentric Interpolation (PBI). We benchmark our method against several alternatives, including Laplace domain fitting, moment matching, global random optimization, and variations of the DSTE framework using nearest-neighbor interpolation and neural network-based estimation. Applied to 295 breakthrough curves from 54 tracer tests in 25 rivers, DSTE delivers accurate parameter estimates. The resulting labeled dataset allows researchers to link transport parameters with hydraulic conditions, site characteristics, and measured concentrations. The synthetic dataset can be leveraged for the analysis of new breakthrough curves, eliminating the need for additional forward simulations.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.19664v1</guid>
      <category>cs.CE</category>
      <pubDate>Thu, 23 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Manuel M. Reyna, Alexandre M. Tartakovsky</dc:creator>
    </item>
    <item>
      <title>The Black Tuesday Attack: how to crash the stock market with adversarial examples to financial forecasting models</title>
      <link>https://arxiv.org/abs/2510.18990</link>
      <description>arXiv:2510.18990v1 Announce Type: cross 
Abstract: We investigate and defend the possibility of causing a stock market crash via small manipulations of individual stock values that together realize an adversarial example to financial forecasting models, causing these models to make the self-fulfilling prediction of a crash. Such a crash triggered by an adversarial example would likely be hard to detect, since the model's predictions would be accurate and the interventions that would cause it are minor. This possibility is a major risk to financial stability and an opportunity for hostile actors to cause great economic damage to an adversary. This threat also exists against individual stocks and the corresponding valuation of individual companies. We outline how such an attack might proceed, what its theoretical basis is, how it can be directed towards a whole economy or an individual company, and how one might defend against it. We conclude that this threat is vastly underappreciated and requires urgent research on how to defend against it.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.18990v1</guid>
      <category>cs.CR</category>
      <category>cs.CE</category>
      <pubDate>Thu, 23 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <dc:creator>Thomas Hofweber, Jefrey Bergl, Ian Reyes, Amir Sadovnik</dc:creator>
    </item>
    <item>
      <title>Wind Variability and Its Effect on Transmission Line Capacity Estimation</title>
      <link>https://arxiv.org/abs/2510.19433</link>
      <description>arXiv:2510.19433v1 Announce Type: cross 
Abstract: This study investigates the impact of wind velocity averaging on Dynamic Thermal Rating (DTR) calculations. It is based on a high-temporal-resolution (1 second) wind measurements obtained from a transmission line in Slovenia, Europe. Wind speed and direction variability are analysed, and two averaging methods, namely vector averaging, where velocity is averaged as vector, and hybrid averaging, where speed is averaged as scalar, are employed. DTR calculations are performed on both high-resolution data and averaged data (5 minute averaging window). It is demonstrated that averaging has a significant effect on both Nusselt number and ampacity, and the effect exhibits a strong angular dependency on the relative angle of the wind to the line. Therefore, two limit cases are studied: in the case of parallel wind, averaged data underestimates the ampacity, and there is a significant amount of cases where the underestimation is larger than 10 %. In the case of perpendicular wind, the two averaging methods affect the results in different ways, but both result in a substantial amount of cases where ampacity is overestimated, potentially leading to unsafe operation. The main takeaway of the study is that averaging wind velocity has a significant impact on DTR results, and special emphasis should be given to the averaging method, as different methods affect the results in different ways.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.19433v1</guid>
      <category>physics.app-ph</category>
      <category>cs.CE</category>
      <category>physics.ao-ph</category>
      <pubDate>Thu, 23 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Nika Mlinari\v{c} Hribar, Matja\v{z} Depolli, Gregor Kosec</dc:creator>
    </item>
    <item>
      <title>Mesh Interpolation Graph Network for Dynamic and Spatially Irregular Global Weather Forecasting</title>
      <link>https://arxiv.org/abs/2509.20911</link>
      <description>arXiv:2509.20911v2 Announce Type: replace 
Abstract: Graph neural networks have shown promising results in weather forecasting, which is critical for human activity such as agriculture planning and extreme weather preparation. However, most studies focus on finite and local areas for training, overlooking the influence of broader areas and limiting their ability to generalize effectively. Thus, in this work, we study global weather forecasting that is irregularly distributed and dynamically varying in practice, requiring the model to generalize to unobserved locations. To address such challenges, we propose a general Mesh Interpolation Graph Network (MIGN) that models the irregular weather station forecasting, consisting of two key designs: (1) learning spatially irregular data with regular mesh interpolation network to align the data; (2) leveraging parametric spherical harmonics location embedding to further enhance spatial generalization ability. Extensive experiments on an up-to-date observation dataset show that MIGN significantly outperforms existing data-driven models. Besides, we show that MIGN has spatial generalization ability, and is capable of generalizing to previous unseen stations.</description>
      <guid isPermaLink="false">oai:arXiv.org:2509.20911v2</guid>
      <category>cs.CE</category>
      <pubDate>Thu, 23 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Zinan Zheng, Yang Liu, Jia Li</dc:creator>
    </item>
    <item>
      <title>Chem-R: Learning to Reason as a Chemist</title>
      <link>https://arxiv.org/abs/2510.16880</link>
      <description>arXiv:2510.16880v2 Announce Type: replace 
Abstract: Although large language models (LLMs) have significant potential to advance chemical discovery, current LLMs lack core chemical knowledge, produce unreliable reasoning trajectories, and exhibit suboptimal performance across diverse chemical tasks. To address these challenges, we propose Chem-R, a generalizable Chemical Reasoning model designed to emulate the deliberative processes of chemists. Chem-R is trained through a three-phase framework that progressively builds advanced reasoning capabilities, including: 1) Chemical Foundation Training, which establishes core chemical knowledge. 2) Chemical Reasoning Protocol Distillation, incorporating structured, expert-like reasoning traces to guide systematic and reliable problem solving. 3) Multi-task Group Relative Policy Optimization that optimizes the model for balanced performance across diverse molecular- and reaction-level tasks. This structured pipeline enables Chem-R to achieve state-of-the-art performance on comprehensive benchmarks, surpassing leading large language models, including Gemini-2.5-Pro and DeepSeek-R1, by up to 32% on molecular tasks and 48% on reaction tasks. Meanwhile, Chem-R also consistently outperforms the existing chemical foundation models across both molecular and reaction level tasks. These results highlight Chem-R's robust generalization, interpretability, and potential as a foundation for next-generation AI-driven chemical discovery. The code and model are available at https://github.com/davidweidawang/Chem-R.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.16880v2</guid>
      <category>cs.CE</category>
      <pubDate>Thu, 23 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Weida Wang, Benteng Chen, Di Zhang, Wanhao Liu, Shuchen Pu, Ben Gao, Jin Zeng, Xiaoyong Wei, Tianshu Yu, Shuzhou Sun, Tianfan Fu, Wanli Ouyang, Lei Bai, Jiatong Li, Zifu Wang, Yuqiang Li, Shufei Zhang</dc:creator>
    </item>
    <item>
      <title>Demystifying Domain-adaptive Post-training for Financial LLMs</title>
      <link>https://arxiv.org/abs/2501.04961</link>
      <description>arXiv:2501.04961v4 Announce Type: replace-cross 
Abstract: Domain-adaptive post-training of large language models (LLMs) has emerged as a promising approach for specialized domains such as medicine and finance. However, significant challenges remain in identifying optimal adaptation criteria and training strategies across varying data and model configurations. To address these challenges, we introduce FINDAP, a systematic and fine-grained investigation into domain-adaptive post-training of LLMs for the finance domain. Our approach consists of four key components: FinCap, which defines the core capabilities required for the target domain; FinRec, an effective training recipe that jointly optimizes continual pre-training and instruction-following, along with a novel preference data distillation method leveraging process signals from a generative reward model; FinTrain, a curated set of training datasets supporting FinRec; and FinEval, a comprehensive evaluation suite aligned with FinCap. The resulting model, Llama-Fin, achieves state-of-the-art performance across a wide range of financial tasks. Our analysis also highlights how each post-training stage contributes to distinct capabilities, uncovering specific challenges and effective solutions, providing valuable insights for domain adaptation of LLMs</description>
      <guid isPermaLink="false">oai:arXiv.org:2501.04961v4</guid>
      <category>cs.CL</category>
      <category>cs.AI</category>
      <category>cs.CE</category>
      <category>cs.LG</category>
      <pubDate>Thu, 23 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <dc:creator>Zixuan Ke, Yifei Ming, Xuan-Phi Nguyen, Caiming Xiong, Shafiq Joty</dc:creator>
    </item>
  </channel>
</rss>
