<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>cs.CC updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/cs.CC</link>
    <description>cs.CC updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/cs.CC" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Thu, 04 Jul 2024 04:00:00 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Thu, 04 Jul 2024 00:00:00 -0400</pubDate>
    <skipDays>
      <day>Saturday</day>
      <day>Sunday</day>
    </skipDays>
    <item>
      <title>Functional variant of Polynomial Analogue of Gandy's Fixed Point Theorem</title>
      <link>https://arxiv.org/abs/2407.02515</link>
      <description>arXiv:2407.02515v1 Announce Type: cross 
Abstract: In this work, a functional variant of the polynomial analogue of the classical Gandy's fixed point theorem is obtained. Sufficient conditions have been found to ensure that the complexity of the recursive function does not go beyond the polynomial. In 2021, we proved a polynomial analogue of the classical Gandy's fixed point theorem. This became an important impetus for the construction of p-complete programming languages. And such a language was first built by us in 2022. The main result of that work was: a solution of the problem P=L. Next are the followers of the works on building a new high-level language and the idea of building a general programming methodology. But there was one gap in our research: classes of recursive functions whose complexity was polynomial were not described. In this work we found sufficient conditions for such functions. In many ways, the main ideas of this work are similar to the ideas that we used in the proof of the polynomial analogue of Gandy's fixed point theorem. But there are also striking differences. Functions, as such, differ quite strongly from predicates precisely in the multitude of their values. If a predicate is either true or false, then a function can generally take on a variety of values. Moreover, even if there are not many values, but there is recursion and simple multiplication, then powers and factorials may arise during the calculations, which, of course, can violate the polynomial computational complexity of this function. Therefore, finding these restrictions on recursive functions that would be soft enough for the class of functions to be large, and at the same time tough enough not to go beyond polynomiality, has been a problem for us for the last 3 years, after the proof of the polynomial analogue Gandy's fixed point theorem in the case of predicate extensions.</description>
      <guid isPermaLink="false">oai:arXiv.org:2407.02515v1</guid>
      <category>cs.LO</category>
      <category>cs.CC</category>
      <category>math.LO</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Andrey Nechesov</dc:creator>
    </item>
    <item>
      <title>Quantum State Synthesis: Relation with Decision Complexity Classes and Impossibility of Synthesis Error Reduction</title>
      <link>https://arxiv.org/abs/2407.02907</link>
      <description>arXiv:2407.02907v1 Announce Type: cross 
Abstract: This work investigates the relationships between quantum state synthesis complexity classes (a recent concept in computational complexity that focuses on the complexity of preparing quantum states) and traditional decision complexity classes. We especially investigate the role of the synthesis error parameter, which characterizes the quality of the synthesis in quantum state synthesis complexity classes. We first show that in the high synthesis error regime, collapse of synthesis classes implies collapse of the equivalent decision classes. For more reasonable synthesis error, we then show a similar relationships for BQP and QCMA. Finally, we show that for quantum state synthesis classes it is in general impossible to improve the quality of the synthesis: unlike the completeness and soundness parameters (which can be improved via repetition), the synthesis error cannot be reduced, even with arbitrary computational power.</description>
      <guid isPermaLink="false">oai:arXiv.org:2407.02907v1</guid>
      <category>quant-ph</category>
      <category>cs.CC</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Hugo Delavenne, Fran\c{c}ois Le Gall</dc:creator>
    </item>
    <item>
      <title>Unified Anomaly Detection methods on Edge Device using Knowledge Distillation and Quantization</title>
      <link>https://arxiv.org/abs/2407.02968</link>
      <description>arXiv:2407.02968v1 Announce Type: cross 
Abstract: With the rapid advances in deep learning and smart manufacturing in Industry 4.0, there is an imperative for high-throughput, high-performance, and fully integrated visual inspection systems. Most anomaly detection approaches using defect detection datasets, such as MVTec AD, employ one-class models that require fitting separate models for each class. On the contrary, unified models eliminate the need for fitting separate models for each class and significantly reduce cost and memory requirements. Thus, in this work, we experiment with considering a unified multi-class setup. Our experimental study shows that multi-class models perform at par with one-class models for the standard MVTec AD dataset. Hence, this indicates that there may not be a need to learn separate object/class-wise models when the object classes are significantly different from each other, as is the case of the dataset considered. Furthermore, we have deployed three different unified lightweight architectures on the CPU and an edge device (NVIDIA Jetson Xavier NX). We analyze the quantized multi-class anomaly detection models in terms of latency and memory requirements for deployment on the edge device while comparing quantization-aware training (QAT) and post-training quantization (PTQ) for performance at different precision widths. In addition, we explored two different methods of calibration required in post-training scenarios and show that one of them performs notably better, highlighting its importance for unsupervised tasks. Due to quantization, the performance drop in PTQ is further compensated by QAT, which yields at par performance with the original 32-bit Floating point in two of the models considered.</description>
      <guid isPermaLink="false">oai:arXiv.org:2407.02968v1</guid>
      <category>cs.CV</category>
      <category>cs.AI</category>
      <category>cs.CC</category>
      <category>cs.ET</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Sushovan Jena, Arya Pulkit, Kajal Singh, Anoushka Banerjee, Sharad Joshi, Ananth Ganesh, Dinesh Singh, Arnav Bhavsar</dc:creator>
    </item>
    <item>
      <title>Explicit Directional Affine Extractors and Improved Hardness for Linear Branching Programs</title>
      <link>https://arxiv.org/abs/2304.11495</link>
      <description>arXiv:2304.11495v2 Announce Type: replace 
Abstract: In a recent work, Gryaznov, Pudl\'{a}k, and Talebanfard (CCC' 22) introduced a stronger version of affine extractors known as directional affine extractors, together with a generalization of $\mathsf{ROBP}$s where each node can make linear queries, and showed that the former implies strong lower bound for a certain type of the latter known as strongly read-once linear branching programs ($\mathsf{SROLBP}$s). Their main result gives explicit constructions of directional affine extractors for entropy $k &gt; 2n/3$, which implies average-case complexity $2^{n/3-o(n)}$ against $\mathsf{SROLBP}$s with exponentially small correlation. A follow-up work by Chattopadhyay and Liao (ECCC' 22) improves the hardness to $2^{n-o(n)}$ at the price of increasing the correlation to polynomially large.
  In this paper we show:
  An explicit construction of directional affine extractors with $k=o(n)$ and exponentially small error, which gives average-case complexity $2^{n-o(n)}$ against $\mathsf{SROLBP}$s with exponentially small correlation, thus answering the two open questions raised in previous works.
  An explicit function in $\mathsf{AC}^0$ that gives average-case complexity $2^{(1-\delta)n}$ against $\mathsf{ROBP}$s with negligible correlation, for any constant $\delta&gt;0$. Previously, no such average-case hardness is known, and the best size lower bound for any function in $\mathsf{AC}^0$ against $\mathsf{ROBP}$s is $2^{\Omega(n)}$.
  One of the key ingredients in our constructions is a new linear somewhere condenser for affine sources, which is based on dimension expanders. The condenser also leads to an unconditional improvement of the entropy requirement of explicit affine extractors with negligible error. We further show that the condenser also works for general weak random sources, under the Polynomial Freiman-Ruzsa Theorem in $\mathsf{F}_2^n$.</description>
      <guid isPermaLink="false">oai:arXiv.org:2304.11495v2</guid>
      <category>cs.CC</category>
      <category>math.CO</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Xin Li, Yan Zhong</dc:creator>
    </item>
    <item>
      <title>Two Simple Proofs of M\"uller's Theorem</title>
      <link>https://arxiv.org/abs/2402.05328</link>
      <description>arXiv:2402.05328v4 Announce Type: replace 
Abstract: Due to M\"{u}ller's theorem, the Kolmogorov complexity of a string was shown to be equal to its quantum Kolmogorov complexity. Thus there are no benefits to using quantum mechanics to compress classical information. The quantitative amount of information in classical sources is invariant to the physical model used. These consequences make this theorem arguably the most important result in the intersection of algorithmic information theory and physics. The original proof is quite extensive. This paper contains two simple proofs of this theorem. This paper also contains new bounds for quantum Kolmogorov complexity with error.</description>
      <guid isPermaLink="false">oai:arXiv.org:2402.05328v4</guid>
      <category>cs.CC</category>
      <category>quant-ph</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Samuel Epstein</dc:creator>
    </item>
    <item>
      <title>Small unsatisfiable $k$-CNFs with bounded literal occurrence</title>
      <link>https://arxiv.org/abs/2405.16149</link>
      <description>arXiv:2405.16149v2 Announce Type: replace-cross 
Abstract: We obtain the smallest unsatisfiable formulas in subclasses of $k$-CNF (exactly $k$ distinct literals per clause) with bounded variable or literal occurrences. Smaller unsatisfiable formulas of this type translate into stronger inapproximability results for MaxSAT in the considered formula class. Our results cover subclasses of 3-CNF and 4-CNF; in all subclasses of 3-CNF we considered we were able to determine the smallest size of an unsatisfiable formula; in the case of 4-CNF with at most 5 occurrences per variable we decreased the size of the smallest known unsatisfiable formula. Our methods combine theoretical arguments and symmetry-breaking exhaustive search based on SAT Modulo Symmetries (SMS), a recent framework for isomorph-free SAT-based graph generation. To this end, and as a standalone result of independent interest, we show how to encode formulas as graphs efficiently for SMS.</description>
      <guid isPermaLink="false">oai:arXiv.org:2405.16149v2</guid>
      <category>cs.DM</category>
      <category>cs.CC</category>
      <category>cs.LO</category>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Tianwei Zhang, Tom\'a\v{s} Peitl, Stefan Szeider</dc:creator>
    </item>
    <item>
      <title>Enumeration of minimal transversals of hypergraphs of bounded VC-dimension</title>
      <link>https://arxiv.org/abs/2407.00694</link>
      <description>arXiv:2407.00694v2 Announce Type: replace-cross 
Abstract: We consider the problem of enumerating all minimal transversals (also called minimal hitting sets) of a hypergraph $\mathcal{H}$. An equivalent formulation of this problem known as the \emph{transversal hypergraph} problem (or \emph{hypergraph dualization} problem) is to decide, given two hypergraphs, whether one corresponds to the set of minimal transversals of the other. The existence of a polynomial time algorithm to solve this problem is a long standing open question. In \cite{fredman_complexity_1996}, the authors present the first sub-exponential algorithm to solve the transversal hypergraph problem which runs in quasi-polynomial time, making it unlikely that the problem is (co)NP-complete.
  In this paper, we show that when one of the two hypergraphs is of bounded VC-dimension, the transversal hypergraph problem can be solved in polynomial time, or equivalently that if $\mathcal{H}$ is a hypergraph of bounded VC-dimension, then there exists an incremental polynomial time algorithm to enumerate its minimal transversals. This result generalizes most of the previously known polynomial cases in the literature since they almost all consider classes of hypergraphs of bounded VC-dimension. As a consequence, the hypergraph transversal problem is solvable in polynomial time for any class of hypergraphs closed under partial subhypergraphs. We also show that the proposed algorithm runs in quasi-polynomial time in general hypergraphs and runs in polynomial time if the conformality of the hypergraph is bounded, which is one of the few known polynomial cases where the VC-dimension is unbounded.</description>
      <guid isPermaLink="false">oai:arXiv.org:2407.00694v2</guid>
      <category>math.CO</category>
      <category>cs.CC</category>
      <category>cs.DM</category>
      <category>cs.DS</category>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Arnaud Mary</dc:creator>
    </item>
  </channel>
</rss>
