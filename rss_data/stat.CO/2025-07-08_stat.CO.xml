<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>stat.CO updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/stat.CO</link>
    <description>stat.CO updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/stat.CO" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Tue, 08 Jul 2025 04:03:05 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Tue, 08 Jul 2025 00:00:00 -0400</pubDate>
    <skipDays>
      <day>Sunday</day>
      <day>Saturday</day>
    </skipDays>
    <item>
      <title>Testing Hypotheses regarding Covariance and Correlation matrices with the R package CovCorTest</title>
      <link>https://arxiv.org/abs/2507.03406</link>
      <description>arXiv:2507.03406v1 Announce Type: new 
Abstract: In addition to the commonly analyzed measures of location, dispersion measurements such as variance and correlation provide many valuable information. Consequently, they play a crucial role in multivariate statistics, which leads to tests regarding covariance and correlation matrices. Furthermore, also the structure of these matrices leads to important hypotheses of interest, since it contains substantial information about the underlying model. In fact, assumptions regarding the structures of covariance and correlation matrices are often fundamental in statistical modelling and testing.
  In this context, semi-parametric settings with minimal distributional assumptions and very general hypotheses are essential for enabling manifold usage. The free available package CovCorTest provides suitable tests addressing all aforementioned issues, using bootstrap and similar techniques to achieve good performance, particularly in small samples. Additionally, the package offers flexible specification options for the hypotheses under investigation in two central tests, accommodating users with varying levels of expertise, which results in high flexibility and user-friendliness at the same time. This paper also presents the application of \textbf{CovCorTest} for various issues, illustrated by multiple examples, where the tests are applied to a real-world dataset.</description>
      <guid isPermaLink="false">oai:arXiv.org:2507.03406v1</guid>
      <category>stat.CO</category>
      <category>stat.ME</category>
      <pubDate>Tue, 08 Jul 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Paavo Sattler, Svenja Jedhoff</dc:creator>
    </item>
    <item>
      <title>Nested importance sampling for Bayesian inference: error bounds and the role of dimension</title>
      <link>https://arxiv.org/abs/2507.04163</link>
      <description>arXiv:2507.04163v1 Announce Type: new 
Abstract: Many Bayesian inference problems involve high dimensional models for which only a subset of the model variables are actual estimation targets. All other variables are just nuisance variables that one would ideally like to integrate out analytically. Unfortunately, such integration is often impossible. However, there are several computational methods that have been proposed over the past 15 years that replace intractable analytical marginalisation by numerical integration, typically using different flavours of importance sampling (IS). Such methods include particle Markov chain Monte Carlo, sequential Monte Carlo squared (SMC$^2$), IS$^2$, nested particle filters and others. In this paper, we investigate the role of the dimension of the nuisance variables in the error bounds achieved by nested IS methods in Bayesian inference. We prove that, under suitable regularity assumptions on the model, the approximation errors increase at a polynomial (rather than exponential) rate with respect to the dimension of the nuisance variables. Our analysis relies on tools from functional analysis and measure theory and it includes the case of polynomials of degree zero, where the approximation error remains uniformly bounded as the dimension of the nuisance variables increases without bound. We also show how the general analysis can be applied to specific classes of models, including linear and Gaussian settings, models with bounded observation functions, and others. These findings improve our current understanding of when and how IS can overcome the curse of dimensionality in Bayesian inference problems.</description>
      <guid isPermaLink="false">oai:arXiv.org:2507.04163v1</guid>
      <category>stat.CO</category>
      <category>math.PR</category>
      <pubDate>Tue, 08 Jul 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Fabi\'an Gonz\'alez, V\'ictor Elvira, Joaqu\'in Miguez</dc:creator>
    </item>
    <item>
      <title>Incremental Seeded EM Algorithm for Clusterwise Linear Regression</title>
      <link>https://arxiv.org/abs/2507.04629</link>
      <description>arXiv:2507.04629v1 Announce Type: new 
Abstract: This paper proposes Incremental Seeded Expectation Maximization, an algorithm that improves upon the traditional Expectation Maximization computational flow for clusterwise or finite mixture linear regression tasks. The proposed method shows significantly better performance, particularly in scenarios involving high-dimensional input, noisy data, or a large number of clusters. Alongside the new algorithm, this paper introduces the concepts of $\textit{Resolvability}$ and $\textit{X-predictability}$, which enable more rigorous discussions of clusterwise regression problems. The resolvability index is quantified using parameters derived from the model, and results demonstrate its strong connection to model quality without requiring knowledge of the ground truth. This makes the $\textit{Resolvability}$ especially useful for assessing the quality of clusterwise regression models, and by extension, the conclusions drawn from them.</description>
      <guid isPermaLink="false">oai:arXiv.org:2507.04629v1</guid>
      <category>stat.CO</category>
      <pubDate>Tue, 08 Jul 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Ye Chow Kuang, Melanie Ooi</dc:creator>
    </item>
    <item>
      <title>A note on the unique properties of the Kullback--Leibler divergence for sampling via gradient flows</title>
      <link>https://arxiv.org/abs/2507.04330</link>
      <description>arXiv:2507.04330v1 Announce Type: cross 
Abstract: We consider the problem of sampling from a probability distribution $\pi$. It is well known that this can be written as an optimisation problem over the space of probability distribution in which we aim to minimise a divergence from $\pi$. and The optimisation problem is normally solved through gradient flows in the space of probability distribution with an appropriate metric. We show that the Kullback--Leibler divergence is the only divergence in the family of Bregman divergences whose gradient flow w.r.t. many popular metrics does not require knowledge of the normalising constant of $\pi$.</description>
      <guid isPermaLink="false">oai:arXiv.org:2507.04330v1</guid>
      <category>stat.ME</category>
      <category>cs.LG</category>
      <category>math.ST</category>
      <category>stat.CO</category>
      <category>stat.TH</category>
      <pubDate>Tue, 08 Jul 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Francesca Romana Crucinio</dc:creator>
    </item>
    <item>
      <title>AL-SPCE -- Reliability analysis for nondeterministic models using stochastic polynomial chaos expansions and active learning</title>
      <link>https://arxiv.org/abs/2507.04553</link>
      <description>arXiv:2507.04553v1 Announce Type: cross 
Abstract: Reliability analysis typically relies on deterministic simulators, which yield repeatable outputs for identical inputs. However, many real-world systems display intrinsic randomness, requiring stochastic simulators whose outputs are random variables. This inherent variability must be accounted for in reliability analysis. While Monte Carlo methods can handle this, their high computational cost is often prohibitive. To address this, stochastic emulators have emerged as efficient surrogate models capable of capturing the random response of simulators at reduced cost. Although promising, current methods still require large training sets to produce accurate reliability estimates, which limits their practicality for expensive simulations. This work introduces an active learning framework to further reduce the computational burden of reliability analysis using stochastic emulators. We focus on stochastic polynomial chaos expansions (SPCE) and propose a novel learning function that targets regions of high predictive uncertainty relevant to failure probability estimation. To quantify this uncertainty, we exploit the asymptotic normality of the maximum likelihood estimator. The resulting method, named active learning stochastic polynomial chaos expansions (AL-SPCE), is applied to three test cases. Results demonstrate that AL-SPCE maintains high accuracy in reliability estimates while significantly improving efficiency compared to conventional surrogate-based methods and direct Monte Carlo simulation. This confirms the potential of active learning in enhancing the practicality of stochastic reliability analysis for complex, computationally expensive models.</description>
      <guid isPermaLink="false">oai:arXiv.org:2507.04553v1</guid>
      <category>stat.ME</category>
      <category>stat.CO</category>
      <category>stat.ML</category>
      <pubDate>Tue, 08 Jul 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>A. Pires, M. Moustapha, S. Marelli, B. Sudret</dc:creator>
    </item>
    <item>
      <title>Optimal Exact Designs of Multiresponse Experiments under Linear and Sparsity Constraints</title>
      <link>https://arxiv.org/abs/2507.04713</link>
      <description>arXiv:2507.04713v1 Announce Type: cross 
Abstract: We propose a computational approach to constructing exact designs on finite design spaces that are optimal for multiresponse regression experiments under a combination of the standard linear and specific 'sparsity' constraints. The linear constraints address, for example, limits on multiple resource consumption and the problem of optimal design augmentation, while the sparsity constraints control the set of distinct trial conditions utilized by the design. The key idea is to construct an artificial optimal design problem that can be solved using any existing mathematical programming technique for univariate-response optimal designs under pure linear constraints. The solution to this artificial problem can then be directly converted into an optimal design for the primary multivariate-response setting with combined linear and sparsity constraints. We demonstrate the utility and flexibility of the approach through dose-response experiments with constraints on safety, efficacy, and cost, where cost also depends on the number of distinct doses used.</description>
      <guid isPermaLink="false">oai:arXiv.org:2507.04713v1</guid>
      <category>stat.ME</category>
      <category>stat.CO</category>
      <pubDate>Tue, 08 Jul 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Lenka Filov\'a, P\'al Somogyi, Radoslav Harman</dc:creator>
    </item>
    <item>
      <title>Efficient Multivariate Initial Sequence Estimators for MCMC</title>
      <link>https://arxiv.org/abs/2406.15874</link>
      <description>arXiv:2406.15874v3 Announce Type: replace 
Abstract: Estimating Monte Carlo error is critical to valid simulation results in Markov chain Monte Carlo (MCMC) and initial sequence estimators were one of the first methods introduced for this. Over the last few years, focus has been on multivariate assessment of simulation error, and many multivariate generalizations of univariate methods have been developed. The multivariate initial sequence estimator is known to exhibit superior finite-sample performance compared to its competitors. However, the multivariate initial sequence estimator can be prohibitively slow, limiting its widespread use. We provide an efficient alternative to the multivariate initial sequence estimator that inherits both its asymptotic properties as well as the finite-sample superior performance. The effectiveness of the proposed estimator is shown via some MCMC example implementations. Further, we also present univariate and multivariate initial sequence estimators for when parallel MCMC chains are run and demonstrate their effectiveness over a popular alternative.</description>
      <guid isPermaLink="false">oai:arXiv.org:2406.15874v3</guid>
      <category>stat.CO</category>
      <pubDate>Tue, 08 Jul 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Arka Banerjee, Dootika Vats</dc:creator>
    </item>
    <item>
      <title>On synthetic interval data with predetermined subject partitioning, and partial control of the variables' marginal correlation structure</title>
      <link>https://arxiv.org/abs/1709.00872</link>
      <description>arXiv:1709.00872v3 Announce Type: replace-cross 
Abstract: A standard approach for assessing the performance of partition models is to create synthetic data sets with a prespecified clustering structure, and assess how well the model reveals this structure. A common format is that subjects are assigned to different clusters, with observations simulated so that subjects within the same cluster have similar profiles, allowing for some variability. In this manuscript, we consider observations from interval variables, taking a finite number of values. Interval data are commonly observed in cohort and Genome Wide Association studies, and our focus is on Single Nucleotide Polymorphisms. Theoretical and empirical results are utilized to explore the dependence structure between the variables, in relation with the clustering structure for the subjects. A novel algorithm is proposed that allows to control the marginal stratified correlation structure of the variables, specifying exact correlation values within groups of variables. Practical examples are shown, and a synthetic dataset is compared to a real one, to demonstrate similarities and differences.</description>
      <guid isPermaLink="false">oai:arXiv.org:1709.00872v3</guid>
      <category>stat.ME</category>
      <category>stat.CO</category>
      <pubDate>Tue, 08 Jul 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Michail Papathomas</dc:creator>
    </item>
    <item>
      <title>Non-negative matrix factorization algorithms generally improve topic model fits</title>
      <link>https://arxiv.org/abs/2105.13440</link>
      <description>arXiv:2105.13440v4 Announce Type: replace-cross 
Abstract: In an effort to develop topic modeling methods that can be quickly applied to large data sets, we revisit the problem of maximum-likelihood estimation in topic models. It is known, at least informally, that maximum-likelihood estimation in topic models is closely related to non-negative matrix factorization (NMF). Yet, to our knowledge, this relationship has not been exploited previously to fit topic models. We show that recent advances in NMF optimization methods can be leveraged to fit topic models very efficiently, often resulting in much better fits and in less time than existing algorithms for topic models. We also formally make the connection between the NMF optimization problem and maximum-likelihood estimation for the topic model, and using this result we show that the expectation maximization (EM) algorithm for the topic model is essentially the same as the classic multiplicative updates for NMF (the only difference being that the operations are performed in a different order). Our methods are implemented in the R package fastTopics.</description>
      <guid isPermaLink="false">oai:arXiv.org:2105.13440v4</guid>
      <category>stat.ML</category>
      <category>cs.LG</category>
      <category>stat.CO</category>
      <pubDate>Tue, 08 Jul 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Peter Carbonetto, Abhishek Sarkar, Zihao Wang, Matthew Stephens</dc:creator>
    </item>
    <item>
      <title>Mixtures of Gaussian Process Experts with SMC$^2$</title>
      <link>https://arxiv.org/abs/2208.12830</link>
      <description>arXiv:2208.12830v2 Announce Type: replace-cross 
Abstract: Gaussian processes are a key component of many flexible statistical and machine learning models. However, they exhibit cubic computational complexity and high memory constraints due to the need of inverting and storing a full covariance matrix. To circumvent this, mixtures of Gaussian process experts have been considered where data points are assigned to independent experts, reducing the complexity by allowing inference based on smaller, local covariance matrices. Moreover, mixtures of Gaussian process experts substantially enrich the model's flexibility, allowing for behaviors such as non-stationarity, heteroscedasticity, and discontinuities. In this work, we construct a novel inference approach based on nested sequential Monte Carlo samplers to simultaneously infer both the gating network and Gaussian process expert parameters. This greatly improves inference compared to importance sampling, particularly in settings when a stationary Gaussian process is inappropriate, while still being thoroughly parallelizable.</description>
      <guid isPermaLink="false">oai:arXiv.org:2208.12830v2</guid>
      <category>stat.ML</category>
      <category>cs.LG</category>
      <category>stat.CO</category>
      <pubDate>Tue, 08 Jul 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Teemu H\"ark\"onen, Sara Wade, Kody Law, Lassi Roininen</dc:creator>
    </item>
    <item>
      <title>Exploring Spatial Context: A Comprehensive Bibliography of GWR and MGWR</title>
      <link>https://arxiv.org/abs/2404.16209</link>
      <description>arXiv:2404.16209v4 Announce Type: replace-cross 
Abstract: Local spatial models such as Geographically Weighted Regression (GWR) and Multiscale Geographically Weighted Regression (MGWR) serve as instrumental tools to capture intrinsic contextual effects through the estimates of the local intercepts and behavioral contextual effects through estimates of the local slope parameters. GWR and MGWR provide simple implementation yet powerful frameworks that could be extended to various disciplines that handle spatial data. This bibliography aims to serve as a comprehensive compilation of peer-reviewed papers that have utilized GWR or MGWR as a primary analytical method to conduct spatial analyses and acts as a useful guide to anyone searching the literature for previous examples of local statistical modeling in a wide variety of application fields.</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.16209v4</guid>
      <category>stat.ME</category>
      <category>stat.AP</category>
      <category>stat.CO</category>
      <pubDate>Tue, 08 Jul 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>A. Stewart Fotheringham, Chen-Lun Kao, Hanchen Yu, Sarah Bardin, Taylor Oshan, Ziqi Li, Mehak Sachdeva, Wei Luo</dc:creator>
    </item>
    <item>
      <title>Skew-symmetric schemes for stochastic differential equations with non-Lipschitz drift: an unadjusted Barker algorithm</title>
      <link>https://arxiv.org/abs/2405.14373</link>
      <description>arXiv:2405.14373v4 Announce Type: replace-cross 
Abstract: We propose a new simple and explicit numerical scheme for time-homogeneous stochastic differential equations. The scheme is based on sampling increments at each time step from a skew-symmetric probability distribution, with the level of skewness determined by the drift and volatility of the underlying process. We show that as the step-size decreases the scheme converges weakly to the diffusion of interest. We then consider the problem of simulating from the limiting distribution of an ergodic diffusion process using the numerical scheme with a fixed step-size. We establish conditions under which the numerical scheme converges to equilibrium at a geometric rate, and quantify the bias between the equilibrium distributions of the scheme and of the true diffusion process. Notably, our results do not require a global Lipschitz assumption on the drift, in contrast to those required for the Euler--Maruyama scheme for long-time simulation at fixed step-sizes. Our weak convergence result relies on an extension of the theory of Milstein \&amp; Tretyakov to stochastic differential equations with non-Lipschitz drift, which could also be of independent interest. We support our theoretical results with numerical simulations.</description>
      <guid isPermaLink="false">oai:arXiv.org:2405.14373v4</guid>
      <category>math.PR</category>
      <category>cs.NA</category>
      <category>math.NA</category>
      <category>stat.CO</category>
      <pubDate>Tue, 08 Jul 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Yuga Iguchi, Samuel Livingstone, Nikolas N\"usken, Giorgos Vasdekis, Rui-Yang Zhang</dc:creator>
    </item>
    <item>
      <title>Polynomial approximation of noisy functions</title>
      <link>https://arxiv.org/abs/2410.02317</link>
      <description>arXiv:2410.02317v3 Announce Type: replace-cross 
Abstract: Approximating a univariate function on the interval $[-1,1]$ with a polynomial is among the most classical problems in numerical analysis. When the function evaluations come with noise, a least-squares fit is known to reduce the effect of noise as more samples are taken. The generic algorithm for the least-squares problem requires $O(Nn^2)$ operations, where $N+1$ is the number of sample points and $n$ is the degree of the polynomial approximant. This algorithm is unstable when $n$ is large, for example $n\gg \sqrt{N}$ for equispaced sample points. In this study, we blend numerical analysis and statistics to introduce a stable and fast $O(N\log N)$ algorithm called NoisyChebtrunc based on the Chebyshev interpolation. It has the same error reduction effect as least-squares and the convergence is spectral until the error reaches $O(\sigma \sqrt{{n}/{N}})$, where $\sigma$ is the noise level, after which the error continues to decrease at the Monte-Carlo $O(1/\sqrt{N})$ rate. To determine the polynomial degree, NoisyChebtrunc employs a statistical criterion, namely Mallows' $C_p$. We analyze NoisyChebtrunc in terms of the variance and concentration in the infinity norm to the underlying noiseless function. These results show that with high probability the infinity-norm error is bounded by a small constant times $\sigma \sqrt{{n}/{N}}$, when the noise {is} independent and follows a subgaussian or subexponential distribution. We illustrate the performance of NoisyChebtrunc with numerical experiments.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.02317v3</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <category>math.ST</category>
      <category>stat.CO</category>
      <category>stat.TH</category>
      <pubDate>Tue, 08 Jul 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Takeru Matsuda, Yuji Nakatsukasa</dc:creator>
    </item>
  </channel>
</rss>
