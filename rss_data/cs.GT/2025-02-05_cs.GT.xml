<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>cs.GT updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/cs.GT</link>
    <description>cs.GT updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/cs.GT" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Thu, 06 Feb 2025 02:49:04 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Wed, 05 Feb 2025 00:00:00 -0500</pubDate>
    <skipDays>
      <day>Saturday</day>
      <day>Sunday</day>
    </skipDays>
    <item>
      <title>Policy Design for Two-sided Platforms with Participation Dynamics</title>
      <link>https://arxiv.org/abs/2502.01792</link>
      <description>arXiv:2502.01792v1 Announce Type: new 
Abstract: In two-sided platforms (e.g., video streaming or e-commerce), viewers and providers engage in interactive dynamics, where an increased provider population results in higher viewer utility and the increase of viewer population results in higher provider utility. Despite the importance of such "population effects" on long-term platform health, recommendation policies do not generally take the participation dynamics into account. This paper thus studies the dynamics and policy design on two-sided platforms under the population effects for the first time. Our control- and game-theoretic findings warn against the use of myopic-greedy policy and shed light on the importance of provider-side considerations (i.e., effectively distributing exposure among provider groups) to improve social welfare via population growth. We also present a simple algorithm to optimize long-term objectives by considering the population effects, and demonstrate its effectiveness in synthetic and real-data experiments.</description>
      <guid isPermaLink="false">oai:arXiv.org:2502.01792v1</guid>
      <category>cs.GT</category>
      <category>cs.IR</category>
      <category>cs.LG</category>
      <category>cs.SY</category>
      <category>eess.SY</category>
      <pubDate>Wed, 05 Feb 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Haruka Kiyohara, Fan Yao, Sarah Dean</dc:creator>
    </item>
    <item>
      <title>Optimal Traffic Allocation for Multi-Slot Sponsored Search: Balance of Efficiency and Fairness</title>
      <link>https://arxiv.org/abs/2502.01862</link>
      <description>arXiv:2502.01862v1 Announce Type: new 
Abstract: The majority of online marketplaces offer promotion programs to sellers to acquire additional customers for their products. These programs typically allow sellers to allocate advertising budgets to promote their products, with higher budgets generally correlating to improve ad performance. Auction mechanisms with budget pacing are commonly employed to implement such ad systems. While auctions deliver satisfactory average effectiveness, ad performance under allocated budgets can be unfair in practice.
  To address this issue, we propose a novel ad allocation model that departs from traditional auction mechanics. Our approach focuses on solving a global optimization problem that balances traffic allocation while considering platform efficiency and fairness constraints.
  This study presents the following contributions. First, we introduce a fairness metric based on the Gini index. Second, we formulate the optimization problem incorporating efficiency and fairness objectives. Third, we offer an online algorithm to solve this optimization problem. Finally, we demonstrate that our approach achieves superior fairness compared to baseline auction-based algorithms without sacrificing efficiency. We contend that our proposed method can be effectively applied in real-time ad allocation scenarios and as an offline benchmark for evaluating the fairness-efficiency trade-off of existing auction-based systems.</description>
      <guid isPermaLink="false">oai:arXiv.org:2502.01862v1</guid>
      <category>cs.GT</category>
      <pubDate>Wed, 05 Feb 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Anastasiia Soboleva, Alexander Ledovsky, Yuriy Dorn, Egor Samosvat, Andrey Tikhanov, Fyodor Prazdnikov</dc:creator>
    </item>
    <item>
      <title>On the Core of the $b$-Matching Game</title>
      <link>https://arxiv.org/abs/2502.01914</link>
      <description>arXiv:2502.01914v1 Announce Type: new 
Abstract: The core is a quintessential solution concept for profit sharing in cooperative game theory. An imputation allocates the worth of the given game among its agents. The imputation lies in the core of the game if, for each sub-coalition, the amount allocated to its agents is at least the worth of this sub-coalition. Hence, under a core imputation, each of exponentially many sub-coalitions gets satisfied. The following computational question has received much attention: Given an imputation, does it lie in the core? Clearly, this question lies in co-NP, since a co-NP certificate for this problem would be a sub-coalition which is not satisfied under the imputation. This question is in P for the assignment game [SS71] and has been shown to be co-NP-hard for several natural games, including max-flow [FZCD02] and MST [FKFH97]. The one natural game for which this question has remained open is the b-matching game when the number of times an edge can be matched is unconstrained; in case each edge can be matched at most once, it is co-NP-hard [BKPW18]. At the outset, it was not clear which way this open question would resolve: on the one hand, for all but one game, this problem was shown co-NP-hard and on the other hand, proximity to the assignment problem and the deep structural properties of matching could lead to a positive result. In this paper, we show that the problem is indeed co-NP-hard.</description>
      <guid isPermaLink="false">oai:arXiv.org:2502.01914v1</guid>
      <category>cs.GT</category>
      <pubDate>Wed, 05 Feb 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Rohith Reddy Gangam, Shayan Taherijam, Vijay V. Vazirani</dc:creator>
    </item>
    <item>
      <title>Optimal Routing in the Presence of Hooks: Three Case Studies</title>
      <link>https://arxiv.org/abs/2502.02059</link>
      <description>arXiv:2502.02059v1 Announce Type: new 
Abstract: We consider the problem of optimally executing a user trade over networks of constant function market makers (CFMMs) in the presence of hooks. Hooks, introduced in an upcoming version of Uniswap, are auxiliary smart contracts that allow for extra information to be added to liquidity pools. This allows liquidity providers to enable constraints on trades, allowing CFMMs to read external data, such as volatility information, and implement additional features, such as onchain limit orders. We consider three important case studies for how to optimally route trades in the presence of hooks: 1) routing through limit orders, 2) optimal liquidations and time-weighted average market makers (TWAMMs), and 3) noncomposable hooks, which provide additional output in exchange for fill risk. Leveraging tools from convex optimization and dynamic programming, we propose simple methods for formulating and solving these problems that can be useful for practitioners.</description>
      <guid isPermaLink="false">oai:arXiv.org:2502.02059v1</guid>
      <category>cs.GT</category>
      <pubDate>Wed, 05 Feb 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Tarun Chitra, Kshitij Kulkarni, Karthik Srinivasan</dc:creator>
    </item>
    <item>
      <title>The Cost Perspective of Liquid Democracy: Feasibility and Control</title>
      <link>https://arxiv.org/abs/2502.02380</link>
      <description>arXiv:2502.02380v1 Announce Type: new 
Abstract: We examine an approval-based model of Liquid Democracy with a budget constraint on voting and delegating costs, aiming to centrally select casting voters ensuring complete representation of the electorate. From a computational complexity perspective, we focus on minimizing overall costs, maintaining short delegation paths, and preventing excessive concentration of voting power. Furthermore, we explore computational aspects of strategic control, specifically, whether external agents can change election components to influence the voting power of certain voters.</description>
      <guid isPermaLink="false">oai:arXiv.org:2502.02380v1</guid>
      <category>cs.GT</category>
      <category>cs.AI</category>
      <pubDate>Wed, 05 Feb 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Shiri Alouf-Heffetz, {\L}ukasz Janeczko, Grzegorz Lisowski, Georgios Papasotiropoulos</dc:creator>
    </item>
    <item>
      <title>Near-Feasible Solutions to Complex Stable Matching Problems</title>
      <link>https://arxiv.org/abs/2502.02503</link>
      <description>arXiv:2502.02503v1 Announce Type: new 
Abstract: In this paper, we demonstrate that in many NP-complete variants of the stable matching problem -- such as the Stable Hypergraph Matching problem and the College Admission problem with Common Quotas -- a near-feasible stable solution -- that is, a solution which is stable, but may slightly violate some capacities -- always exists. Our results provide strong theoretical guarantees that even under complex constraints, stability can be restored with minimal capacity modifications.
  To achieve this, we present an iterative rounding algorithm that starts from a stable fractional solution and systematically adjusts capacities to ensure the existence of an integral stable solution. This approach leverages Scarf's algorithm to compute an initial fractional stable solution, which serves as the foundation for our rounding process. Notably, in the case of the Stable Fixtures problem, where a stable fractional matching can be computed efficiently, our method runs in polynomial time.
  These findings have significant practical implications for market design, college admissions, and other real-world allocation problems, where small adjustments to institutional constraints can guarantee stable and implementable outcomes.</description>
      <guid isPermaLink="false">oai:arXiv.org:2502.02503v1</guid>
      <category>cs.GT</category>
      <pubDate>Wed, 05 Feb 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Gergely Cs\'aji</dc:creator>
    </item>
    <item>
      <title>Optimal Security Response to Network Intrusions in IT Systems</title>
      <link>https://arxiv.org/abs/2502.02541</link>
      <description>arXiv:2502.02541v1 Announce Type: new 
Abstract: Cybersecurity is one of the most pressing technological challenges of our time and requires measures from all sectors of society. A key measure is automated security response, which enables automated mitigation and recovery from cyber attacks. Significant strides toward such automation have been made due to the development of rule-based response systems. However, these systems have a critical drawback: they depend on domain experts to configure the rules, a process that is both error-prone and inefficient. Framing security response as an optimal control problem shows promise in addressing this limitation but introduces new challenges. Chief among them is bridging the gap between theoretical optimality and operational performance. Current response systems with theoretical optimality guarantees have only been validated analytically or in simulation, leaving their practical utility unproven.
  This thesis tackles the aforementioned challenges by developing a practical methodology for optimal security response in IT infrastructures. It encompasses two systems. First, it includes an emulation system that replicates key components of the target infrastructure. We use this system to gather measurements and logs, based on which we identify a game-theoretic model. Second, it includes a simulation system where game-theoretic response strategies are optimized through stochastic approximation to meet a given objective, such as mitigating potential attacks while maintaining operational services. These strategies are then evaluated and refined in the emulation system to close the gap between theoretical and operational performance. We prove structural properties of optimal response strategies and derive efficient algorithms for computing them. This enables us to solve a previously unsolved problem: demonstrating optimal security response against network intrusions on an IT infrastructure.</description>
      <guid isPermaLink="false">oai:arXiv.org:2502.02541v1</guid>
      <category>cs.GT</category>
      <category>cs.CR</category>
      <pubDate>Wed, 05 Feb 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-sa/4.0/</dc:rights>
      <dc:creator>Kim Hammar</dc:creator>
    </item>
    <item>
      <title>Posted Price Mechanisms for Online Allocation with Diseconomies of Scale</title>
      <link>https://arxiv.org/abs/2502.02543</link>
      <description>arXiv:2502.02543v1 Announce Type: new 
Abstract: This paper addresses the online $k$-selection problem with diseconomies of scale (OSDoS), where a seller seeks to maximize social welfare by optimally pricing items for sequentially arriving buyers, accounting for increasing marginal production costs. Previous studies have investigated deterministic dynamic pricing mechanisms for such settings. However, significant challenges remain, particularly in achieving optimality with small or finite inventories and developing effective randomized posted price mechanisms. To bridge this gap, we propose a novel randomized dynamic pricing mechanism for OSDoS, providing a tighter lower bound on the competitive ratio compared to prior work. Our approach ensures optimal performance in small inventory settings (i.e., when $k$ is small) and surpasses existing online mechanisms in large inventory settings (i.e., when $k$ is large), leading to the best-known posted price mechanism for optimizing online selection and allocation with diseconomies of scale across varying inventory sizes.</description>
      <guid isPermaLink="false">oai:arXiv.org:2502.02543v1</guid>
      <category>cs.GT</category>
      <category>cs.DS</category>
      <pubDate>Wed, 05 Feb 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Hossein Nekouyan Jazi, Bo Sun, Raouf Boutaba, Xiaoqi Tan</dc:creator>
    </item>
    <item>
      <title>A coding theoretic study of homogeneous Markovian predictive games</title>
      <link>https://arxiv.org/abs/2502.02433</link>
      <description>arXiv:2502.02433v1 Announce Type: cross 
Abstract: This paper explores a predictive game in which a Forecaster announces odds based on a time-homogeneous Markov kernel, establishing a game-theoretic law of large numbers for the relative frequencies of occurrences of all finite strings. A key feature of our proof is a betting strategy built on a universal coding scheme, inspired by the martingale convergence theorem and algorithmic randomness theory, without relying on a diversified betting approach that involves countably many operating accounts. We apply these insights to thermodynamics, offering a game-theoretic perspective on Le\'o Szil\'ard's thought experiment.</description>
      <guid isPermaLink="false">oai:arXiv.org:2502.02433v1</guid>
      <category>cs.IT</category>
      <category>cs.GT</category>
      <category>math.IT</category>
      <category>math.PR</category>
      <pubDate>Wed, 05 Feb 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Takara Nomura, Akio Fujiwara</dc:creator>
    </item>
    <item>
      <title>Generalized Veto Core and a Practical Voting Rule with Optimal Metric Distortion</title>
      <link>https://arxiv.org/abs/2305.19632</link>
      <description>arXiv:2305.19632v2 Announce Type: replace 
Abstract: We revisit the recent breakthrough result of Gkatzelis et al. on (single-winner) metric voting, which showed that the optimal distortion of 3 can be achieved by a mechanism called Plurality Matching. The rule picks an arbitrary candidate for whom a certain candidate-specific bipartite graph contains a perfect matching, and thus, it is not neutral (i.e, symmetric with respect to candidates). Subsequently, a much simpler rule called Plurality Veto was shown to achieve distortion 3 as well. This rule only constructs such a matching implicitly but the winner depends on the order that voters are processed, and thus, it is not anonymous (i.e., symmetric with respect to voters).
  We provide an intuitive interpretation of this matching by generalizing the classical notion of the (proportional) veto core in social choice theory. This interpretation opens up a number of immediate consequences. Previous methods for electing a candidate from the veto core can be interpreted simply as matching algorithms. Different election methods realize different matchings, in turn leading to different sets of candidates as winners. For a broad generalization of the veto core, we show that the generalized veto core is equal to the set of candidates who can emerge as winners under a natural class of matching algorithms reminiscent of Serial Dictatorship.
  Extending these matching algorithms into continuous time, we obtain a highly practical voting rule with optimal distortion 3, which is also intuitive and easy to explain: Each candidate starts off with public support equal to his plurality score. From time 0 to 1, every voter continuously brings down, at rate 1, the support of her bottom choice among not-yet-eliminated candidates. A candidate is eliminated if he is opposed by a voter after his support reaches 0. On top of being anonymous and neutral, this rule satisfies many other axioms desirable in practice.</description>
      <guid isPermaLink="false">oai:arXiv.org:2305.19632v2</guid>
      <category>cs.GT</category>
      <pubDate>Wed, 05 Feb 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Fatih Erdem Kizilkaya, David Kempe</dc:creator>
    </item>
    <item>
      <title>Approximating Competitive Equilibrium by Nash Welfare</title>
      <link>https://arxiv.org/abs/2402.09994</link>
      <description>arXiv:2402.09994v2 Announce Type: replace 
Abstract: We explore the relationship between two popular concepts in the allocation of divisible items: competitive equilibrium (CE) and allocations with maximum Nash welfare, i.e., allocations where the weighted geometric mean of the utilities is maximal. When agents have homogeneous concave utility functions, these two concepts coincide: the classical Eisenberg-Gale convex program that maximizes Nash welfare over feasible allocations yields a competitive equilibrium. However, these two concepts diverge for non-homogeneous utilities. From a computational perspective, maximizing Nash welfare amounts to solving a convex program for any concave utility functions, computing CE becomes PPAD-hard already for separable piecewise linear concave (SPLC) utilities.
  We introduce the concept of Gale-substitute utility functions, which is an analogue of the weak gross substitutes (WGS) property for the so-called Gale demand system. For Gale-substitutes utilities, we show that any allocation maximizing Nash welfare provides an approximate-CE with surprisingly strong guarantees, where every agent gets at least half the maximum utility they can get at any CE, and is approximately envy-free. Gale-substitutes include utility functions where computing CE is PPAD hard, such as all separable concave utilities and the previously studied non-separable class of Leontief-free utilities. We introduce a broad new class of utility functions called generalized network utilities based on the generalized flow model. This class includes SPLC and Leontief-free utilities, and we show that all such utilities are Gale-substitutes.
  Conversely, although some agents may get much higher utility at a Nash welfare maximizing allocation than at a CE, we show a price of anarchy type result: for general concave utilities, every CE achieves at least $(1/e)^{1/e} &gt; 0.69$ fraction of the maximum Nash welfare, and this factor is tight.</description>
      <guid isPermaLink="false">oai:arXiv.org:2402.09994v2</guid>
      <category>cs.GT</category>
      <category>math.OC</category>
      <pubDate>Wed, 05 Feb 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Jugal Garg, Yixin Tao, L\'aszl\'o A. V\'egh</dc:creator>
    </item>
    <item>
      <title>To Spend or to Gain: Online Learning in Repeated Karma Auctions</title>
      <link>https://arxiv.org/abs/2403.04057</link>
      <description>arXiv:2403.04057v2 Announce Type: replace 
Abstract: Recent years have seen a surge of artificial currency-based mechanisms in contexts where monetary instruments are deemed unfair or inappropriate, e.g., in allocating food donations to food banks, course seats to students, and, more recently, even for traffic congestion management. Yet the applicability of these mechanisms remains limited in repeated auction settings, as it is challenging for users to learn how to bid an artificial currency that has no value outside the auctions. Indeed, users must jointly learn the value of the currency in addition to how to spend it optimally. Moreover, in the prominent class of karma mechanisms, in which artificial karma payments are redistributed to users at each time step, users do not only spend karma to obtain public resources but also gain karma for yielding them. For this novel class of karma auctions, we propose an adaptive karma pacing strategy that learns to bid optimally, and show that this strategy a) is asymptotically optimal for a single user bidding against competing bids drawn from a stationary distribution; b) leads to convergent learning dynamics when all users adopt it; and c) constitutes an approximate Nash equilibrium as the number of users grows. Our results require a novel analysis in comparison to adaptive pacing strategies in monetary auctions, since we depart from the classical assumption that the currency has known value outside the auctions, and consider that the currency is both spent and gained through the redistribution of payments.</description>
      <guid isPermaLink="false">oai:arXiv.org:2403.04057v2</guid>
      <category>cs.GT</category>
      <category>econ.TH</category>
      <pubDate>Wed, 05 Feb 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Damien Berriaud, Ezzat Elokda, Devansh Jalota, Emilio Frazzoli, Marco Pavone, Florian D\"orfler</dc:creator>
    </item>
    <item>
      <title>Auction-Based Regulation for Artificial Intelligence</title>
      <link>https://arxiv.org/abs/2410.01871</link>
      <description>arXiv:2410.01871v2 Announce Type: replace 
Abstract: In an era of "moving fast and breaking things", regulators have moved slowly to pick up the safety, bias, and legal debris left in the wake of broken Artificial Intelligence (AI) deployment. While there is much-warranted discussion about how to address the safety, bias, and legal woes of state-of-the-art AI models, rigorous and realistic mathematical frameworks to regulate AI are lacking. Our paper addresses this challenge, proposing an auction-based regulatory mechanism that provably incentivizes devices (i) to deploy compliant models and (ii) to participate in the regulation process. We formulate AI regulation as an all-pay auction where enterprises submit models for approval. The regulator enforces compliance thresholds and further rewards models exhibiting higher compliance than their peers. We derive Nash Equilibria demonstrating that rational agents will submit models exceeding the prescribed compliance threshold. Empirical results show that our regulatory auction boosts compliance rates by 20% and participation rates by 15% compared to baseline regulatory mechanisms, outperforming simpler frameworks that merely impose minimum compliance standards.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.01871v2</guid>
      <category>cs.GT</category>
      <category>cs.AI</category>
      <category>cs.CY</category>
      <category>econ.GN</category>
      <category>q-fin.EC</category>
      <pubDate>Wed, 05 Feb 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Marco Bornstein, Zora Che, Suhas Julapalli, Abdirisak Mohamed, Amrit Singh Bedi, Furong Huang</dc:creator>
    </item>
    <item>
      <title>Approximating One-Sided and Two-Sided Nash Social Welfare With Capacities</title>
      <link>https://arxiv.org/abs/2411.14007</link>
      <description>arXiv:2411.14007v2 Announce Type: replace 
Abstract: We study the problem of maximizing Nash social welfare, which is the geometric mean of agents' utilities, in two well-known models. The first model involves one-sided preferences, where a set of indivisible items is allocated among a group of agents (commonly studied in fair division). The second model deals with two-sided preferences, where a set of workers and firms, each having numerical valuations for the other side, are matched with each other (commonly studied in matching-under-preferences literature). We study these models under capacity constraints, which restrict the number of items (respectively, workers) that an agent (respectively, a firm) can receive.
  We develop constant-factor approximation algorithms for both problems under a broad class of valuations. Specifically, our main results are the following: (a) For any $\epsilon &gt; 0$, a $(6+\epsilon)$-approximation algorithm for the one-sided problem when agents have submodular valuations, and (b) a $1.33$-approximation algorithm for the two-sided problem when the firms have subadditive valuations. The former result provides the first constant-factor approximation algorithm for Nash welfare in the one-sided problem with submodular valuations and capacities, while the latter result improves upon an existing $\sqrt{OPT}$-approximation algorithm for additive valuations. Our result for the two-sided setting also establishes a computational separation between the Nash and utilitarian welfare objectives. We also complement our algorithms with hardness-of-approximation results.</description>
      <guid isPermaLink="false">oai:arXiv.org:2411.14007v2</guid>
      <category>cs.GT</category>
      <pubDate>Wed, 05 Feb 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Salil Gokhale, Harshul Sagar, Rohit Vaish, Jatin Yadav</dc:creator>
    </item>
    <item>
      <title>Voter Participation Control in Online Polls</title>
      <link>https://arxiv.org/abs/2410.12256</link>
      <description>arXiv:2410.12256v2 Announce Type: replace-cross 
Abstract: News outlets, surveyors, and other organizations often conduct polls on social networks to gain insights into public opinion. Such a poll is typically started by someone on a social network who sends it to her friends. If a person participates in the poll, the poll information gets published on her wall, which in turn enables her friends to participate, and the process continues. Eventually, a subset of the population participates in the poll, and the pollster learns the outcome of that poll. We initiate the study of a new but natural type of election control in such online elections.
  We study how difficult/easy it is to sway the outcome of such polls in one's favor/against (aka constructive vs destructive) by any malicious influencer who nudges/bribes people for seemingly harmless actions like non-participation. These questions are important from the standpoint of studying the power of resistance of online voting against malicious behavior. The destructive version is also important to quantify the robustness of the winner of an online voting. We show that both problems are computationally intractable even if the election is over only two candidates and the influencer has an infinite amount of money to spend (that is, every voter can be persuaded to not participate). We strengthen this result by proving that the computational task remains substantially challenging even if the underlying network is a tree. Finally, we show that there is a polynomial-time algorithm for the constructive version of the problem when we have O(1) candidates, and the treewidth of the underlying graph is O(1); the algorithm for the destructive version does not even need to assume O(1) number of candidates. Hence, we observe that the destructive version is computationally easier than the constructive version.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.12256v2</guid>
      <category>cs.MA</category>
      <category>cs.GT</category>
      <pubDate>Wed, 05 Feb 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Koustav De, Palash Dey, Swagato Sanyal</dc:creator>
    </item>
  </channel>
</rss>
