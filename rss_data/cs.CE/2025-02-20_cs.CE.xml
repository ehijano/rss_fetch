<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>cs.CE updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/cs.CE</link>
    <description>cs.CE updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/cs.CE" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Fri, 21 Feb 2025 02:45:19 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Thu, 20 Feb 2025 00:00:00 -0500</pubDate>
    <skipDays>
      <day>Sunday</day>
      <day>Saturday</day>
    </skipDays>
    <item>
      <title>Probabilistically Robust Uncertainty Analysis and Optimal Control of Continuous Lyophilization via Polynomial Chaos Theory</title>
      <link>https://arxiv.org/abs/2502.13420</link>
      <description>arXiv:2502.13420v1 Announce Type: new 
Abstract: Lyophilization, aka freeze drying, is a process commonly used to increase the stability of various drug products in biotherapeutics manufacturing, e.g., mRNA vaccines, allowing for higher storage temperature. While the current trends in the industry are moving towards continuous manufacturing, the majority of industrial lyophilization processes are still being operated in a batch mode. This article presents a framework that accounts for the probabilistic uncertainty during the primary and secondary drying steps in continuous lyophilization. The probabilistic uncertainty is incorporated into the mechanistic model via polynomial chaos theory (PCT). The resulting PCT-based model is able to accurately and efficiently quantify the effects of uncertainty on several critical process variables, including the temperature, sublimation front, and concentration of bound water. The integration of the PCT-based model into stochastic optimization and control is demonstrated. The proposed framework and case studies can be used to guide the design and control of continuous lyophilization while accounting for probabilistic uncertainty.</description>
      <guid isPermaLink="false">oai:arXiv.org:2502.13420v1</guid>
      <category>cs.CE</category>
      <category>cs.SY</category>
      <category>eess.SY</category>
      <category>math.OC</category>
      <pubDate>Thu, 20 Feb 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Prakitr Srisuma, George Barbastathis, Richard D. Braatz</dc:creator>
    </item>
    <item>
      <title>AI-Empowered Catalyst Discovery: A Survey from Classical Machine Learning Approaches to Large Language Models</title>
      <link>https://arxiv.org/abs/2502.13626</link>
      <description>arXiv:2502.13626v1 Announce Type: new 
Abstract: Catalysts are essential for accelerating chemical reactions and enhancing selectivity, which is crucial for the sustainable production of energy, materials, and bioactive compounds. Catalyst discovery is fundamental yet challenging in computational chemistry and has garnered significant attention due to the promising performance of advanced Artificial Intelligence (AI) techniques. The development of Large Language Models (LLMs) notably accelerates progress in the discovery of both homogeneous and heterogeneous catalysts, where their chemical reactions differ significantly in material phases, temperature, dynamics, etc. However, there is currently no comprehensive survey that discusses the progress and latest developments in both areas, particularly with the application of LLM techniques. To address this gap, this paper presents a thorough and systematic survey of AI-empowered catalyst discovery, employing a unified and general categorization for homogeneous and heterogeneous catalysts. We examine the progress of AI-empowered catalyst discovery, highlighting their individual advantages and disadvantages, and discuss the challenges faced in this field. Furthermore, we suggest potential directions for future research from the perspective of computer science. Our goal is to assist researchers in computational chemistry, computer science, and related fields in easily tracking the latest advancements, providing a clear overview and roadmap of this area. We also organize and make accessible relevant resources, including article lists and datasets, in an open repository at https://github.com/LuckyGirl-XU/Awesome-Artificial-Intelligence-Empowered-Catalyst-Discovery.</description>
      <guid isPermaLink="false">oai:arXiv.org:2502.13626v1</guid>
      <category>cs.CE</category>
      <pubDate>Thu, 20 Feb 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <dc:creator>Yuanyuan Xu, Hanchen Wang, Wenjie Zhang, Lexing Xie, Yin Chen, Flora Salim, Ying Zhang, Justin Gooding, Toby Walsh</dc:creator>
    </item>
    <item>
      <title>A CFL condition for the finite cell method</title>
      <link>https://arxiv.org/abs/2502.13675</link>
      <description>arXiv:2502.13675v1 Announce Type: new 
Abstract: Immersed boundary finite element methods allow the user to bypass the potentially troublesome task of boundary-conforming mesh generation. However, they suffer from the influence of cut elements, i.e., elements that are intersected by the physical domain boundaries. When combined with explicit time integration, poorly cut elements with little support in the physical domain have a detrimental effect on the critical time step size, thereby hampering the application of immersed boundary methods to wave propagation simulations. In this paper, we investigate the stabilizing effect of the finite cell method concerning explicit time integration. Starting with an analytical solution of an example with one degree of freedom, we systematically study the influence of $\alpha$-stabilization on the maximum eigenvalue and thus on the critical time step size. The analysis is then complemented by a numerical study of an example with one element and an increasing polynomial degree. We demonstrate that the critical time step size does not decrease below a certain limit, even when further reducing the cut fraction of the element. This minimum critical time step size is controlled by the chosen $\alpha$ value and becomes less severe for higher dimensions. Increasing the polynomial degree has little effect on the degradation of the minimum critical time step size. Finally, we provide an estimate of the minimum critical time step size depending on the chosen stabilization parameter $\alpha$ and the dimension of the problem. Based on this estimate, we propose a modified CFL condition for the finite cell method, the validity of which we demonstrate on a numerical example of a perforated plate.</description>
      <guid isPermaLink="false">oai:arXiv.org:2502.13675v1</guid>
      <category>cs.CE</category>
      <category>cs.NA</category>
      <category>math.NA</category>
      <pubDate>Thu, 20 Feb 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Tim B\"urchner, Lars Radtke, Philipp Kopp</dc:creator>
    </item>
    <item>
      <title>BeforeIT.jl: High-Performance Agent-Based Macroeconomics Made Easy</title>
      <link>https://arxiv.org/abs/2502.13267</link>
      <description>arXiv:2502.13267v1 Announce Type: cross 
Abstract: BeforeIT is an open-source software for building and simulating state-of-the-art macroeconomic agent-based models (macro ABMs) based on the recently introduced macro ABM developed in [1] and here referred to as the base model. Written in Julia, it combines extraordinary computational efficiency with user-friendliness and extensibility. We present the main structure of the software, demonstrate its ease of use with illustrative examples, and benchmark its performance. Our benchmarks show that the base model built with BeforeIT is orders of magnitude faster than a Matlab version, and significantly faster than Matlab-generated C code. BeforeIT is designed to facilitate reproducibility, extensibility, and experimentation. As the first open-source, industry-grade software to build macro ABMs of the type of the base model, BeforeIT can significantly foster collaboration and innovation in the field of agent-based macroeconomic modelling. The package, along with its documentation, is freely available at https://github.com/bancaditalia/BeforeIT.jl under the AGPL-3.0.</description>
      <guid isPermaLink="false">oai:arXiv.org:2502.13267v1</guid>
      <category>cs.MA</category>
      <category>cs.CE</category>
      <category>econ.GN</category>
      <category>q-fin.EC</category>
      <pubDate>Thu, 20 Feb 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Aldo Glielmo, Mitja Devetak, Adriano Meligrana, Sebastian Poledna</dc:creator>
    </item>
    <item>
      <title>An Uncertainty-Aware Data-Driven Predictive Controller for Hybrid Power Plants</title>
      <link>https://arxiv.org/abs/2502.13333</link>
      <description>arXiv:2502.13333v1 Announce Type: cross 
Abstract: Given the advancements in data-driven modeling for complex engineering and scientific applications, this work utilizes a data-driven predictive control method, namely subspace predictive control, to coordinate hybrid power plant components and meet a desired power demand despite the presence of weather uncertainties. An uncertainty-aware data-driven predictive controller is proposed, and its potential is analyzed using real-world electricity demand profiles. For the analysis, a hybrid power plant with wind, solar, and co-located energy storage capacity of 4 MW each is considered. The analysis shows that the predictive controller can track a real-world-inspired electricity demand profile despite the presence of weather-induced uncertainties and be an intelligent forecaster for HPP performance.</description>
      <guid isPermaLink="false">oai:arXiv.org:2502.13333v1</guid>
      <category>eess.SY</category>
      <category>cs.CE</category>
      <category>cs.SY</category>
      <category>math.OC</category>
      <pubDate>Thu, 20 Feb 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Manavendra Desai, Himanshu Sharma, Sayak Mukherjee, Sonja Glavaski</dc:creator>
    </item>
    <item>
      <title>Refining embeddings with fill-tuning: data-efficient generalised performance improvements for materials foundation models</title>
      <link>https://arxiv.org/abs/2502.13886</link>
      <description>arXiv:2502.13886v1 Announce Type: cross 
Abstract: Pretrained foundation models learn embeddings that can be used for a wide range of downstream tasks. These embeddings optimise general performance, and if insufficiently accurate at a specific task the model can be fine-tuned to improve performance. For all current methodologies this operation necessarily degrades performance on all out-of-distribution tasks. In this work we present 'fill-tuning', a novel methodology to generate datasets for continued pretraining of foundation models that are not suited to a particular downstream task, but instead aim to correct poor regions of the embedding. We present the application of roughness analysis to latent space topologies and illustrate how it can be used to propose data that will be most valuable to improving the embedding. We apply fill-tuning to a set of state-of-the-art materials foundation models trained on $O(10^9)$ data points and show model improvement of almost 1% in all downstream tasks with the addition of only 100 data points. This method provides a route to the general improvement of foundation models at the computational cost of fine-tuning.</description>
      <guid isPermaLink="false">oai:arXiv.org:2502.13886v1</guid>
      <category>cs.LG</category>
      <category>cs.CE</category>
      <pubDate>Thu, 20 Feb 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Matthew P. Wilson, Edward O. Pyzer-Knapp, Nicolas Galichet, Luke Dicks</dc:creator>
    </item>
    <item>
      <title>M2L Translation Operators for Kernel Independent Fast Multipole Methods on Modern Architectures</title>
      <link>https://arxiv.org/abs/2408.07436</link>
      <description>arXiv:2408.07436v3 Announce Type: replace 
Abstract: Algorithm design must focus on minimising data movement even at the cost of more FLOPs due to the growing disparity between FLOP availability and memory bandwidth on modern architectures. We review the requirements for the Multipole to Local (M2L) operation, a sub-routine of the Kernel Independent Fast Multipole Method (kiFMM) algorithm. The kiFMM is a variant of the popular Fast Multipole Method (FMM), which accelerates the evaluation of N-body potential problems. Naively implemented, the M2L can lead to bandwidth pressure, and is therefore a key bottleneck in an FMMs. Recent software packages for the kiFMM have relied on the Fast Fourier Transform (FFT) to accelerate M2L as it can be formulated as a convolution type operation. However, parallelly developed 'black box' FMMs formulate the M2L as a BLAS operation and use direct matrix compression techniques for further acceleration. The FFT approach requires careful implementation to overcome the low operational intensity of the element-wise product inherent in its formulation, whereas the BLAS approach provides a high operational intensity formulation if the M2L is written in terms of level 3 BLAS operations. We describe algorithmic simplifications for the BLAS-based M2L operation, and show that the BLAS version of the M2L can be competitive in practice with the Fast Fourier Transform (FFT) version. We have developed a carefully optimised software implementation that allows us to flexibly switch between M2L approaches and is optimised for ARM and x86 targets, allowing for a fair comparison between both.</description>
      <guid isPermaLink="false">oai:arXiv.org:2408.07436v3</guid>
      <category>cs.CE</category>
      <pubDate>Thu, 20 Feb 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Srinath Kailasa, Timo Betcke, Sarah El Kazdadi</dc:creator>
    </item>
    <item>
      <title>On the Effectiveness of Neural Operators at Zero-Shot Weather Downscaling</title>
      <link>https://arxiv.org/abs/2409.13955</link>
      <description>arXiv:2409.13955v2 Announce Type: replace 
Abstract: Machine learning (ML) methods have shown great potential for weather downscaling. These data-driven approaches provide a more efficient alternative for producing high-resolution weather datasets and forecasts compared to physics-based numerical simulations. Neural operators, which learn solution operators for a family of partial differential equations (PDEs), have shown great success in scientific ML applications involving physics-driven datasets. Neural operators are grid-resolution-invariant and are often evaluated on higher grid resolutions than they are trained on, i.e., zero-shot super-resolution. Given their promising zero-shot super-resolution performance on dynamical systems emulation, we present a critical investigation of their zero-shot weather downscaling capabilities, which is when models are tasked with producing high-resolution outputs using higher upsampling factors than are seen during training. To this end, we create two realistic downscaling experiments with challenging upsampling factors (e.g., 8x and 15x) across data from different simulations: the European Centre for Medium-Range Weather Forecasts Reanalysis version 5 (ERA5) and the Wind Integration National Dataset Toolkit (WTK). While neural operator-based downscaling models perform better than interpolation and a simple convolutional baseline, we show the surprising performance of an approach that combines a powerful transformer-based model with parameter-free interpolation at zero-shot weather downscaling. We find that this Swin-Transformer-based approach mostly outperforms models with neural operator layers in terms of average error metrics, whereas an Enhanced Super-Resolution Generative Adversarial Network (ESRGAN)-based approach is better than most models in terms of capturing the physics of the ground truth data. We suggest their use in future work as strong baselines.</description>
      <guid isPermaLink="false">oai:arXiv.org:2409.13955v2</guid>
      <category>cs.CE</category>
      <pubDate>Thu, 20 Feb 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Saumya Sinha, Brandon Benton, Patrick Emami</dc:creator>
    </item>
    <item>
      <title>Mesh-based Super-Resolution of Fluid Flows with Multiscale Graph Neural Networks</title>
      <link>https://arxiv.org/abs/2409.07769</link>
      <description>arXiv:2409.07769v3 Announce Type: replace-cross 
Abstract: A graph neural network (GNN) approach is introduced in this work which enables mesh-based three-dimensional super-resolution of fluid flows. In this framework, the GNN is designed to operate not on the full mesh-based field at once, but on localized meshes of elements (or cells) directly. To facilitate mesh-based GNN representations in a manner similar to spectral (or finite) element discretizations, a baseline GNN layer (termed a message passing layer, which updates local node properties) is modified to account for synchronization of coincident graph nodes, rendering compatibility with commonly used element-based mesh connectivities. The architecture is multiscale in nature, and is comprised of a combination of coarse-scale and fine-scale message passing layer sequences (termed processors) separated by a graph unpooling layer. The coarse-scale processor embeds a query element (alongside a set number of neighboring coarse elements) into a single latent graph representation using coarse-scale synchronized message passing over the element neighborhood, and the fine-scale processor leverages additional message passing operations on this latent graph to correct for interpolation errors. Demonstration studies are performed using hexahedral mesh-based data from Taylor-Green Vortex and backward-facing step flow simulations at Reynolds numbers of 1600 and 3200. Through analysis of both global and local errors, the results ultimately show how the GNN is able to produce accurate super-resolved fields compared to targets in both coarse-scale and multiscale model configurations. Reconstruction errors for fixed architectures were found to increase in proportion to the Reynolds number. Geometry extrapolation studies on a separate cavity flow configuration show promising cross-mesh capabilities of the super-resolution strategy.</description>
      <guid isPermaLink="false">oai:arXiv.org:2409.07769v3</guid>
      <category>physics.flu-dyn</category>
      <category>cs.CE</category>
      <category>cs.LG</category>
      <category>physics.comp-ph</category>
      <pubDate>Thu, 20 Feb 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Shivam Barwey, Pinaki Pal, Saumil Patel, Riccardo Balin, Bethany Lusch, Venkatram Vishwanath, Romit Maulik, Ramesh Balakrishnan</dc:creator>
    </item>
    <item>
      <title>FLAG-Trader: Fusion LLM-Agent with Gradient-based Reinforcement Learning for Financial Trading</title>
      <link>https://arxiv.org/abs/2502.11433</link>
      <description>arXiv:2502.11433v3 Announce Type: replace-cross 
Abstract: Large language models (LLMs) fine-tuned on multimodal financial data have demonstrated impressive reasoning capabilities in various financial tasks. However, they often struggle with multi-step, goal-oriented scenarios in interactive financial markets, such as trading, where complex agentic approaches are required to improve decision-making. To address this, we propose \textsc{FLAG-Trader}, a unified architecture integrating linguistic processing (via LLMs) with gradient-driven reinforcement learning (RL) policy optimization, in which a partially fine-tuned LLM acts as the policy network, leveraging pre-trained knowledge while adapting to the financial domain through parameter-efficient fine-tuning. Through policy gradient optimization driven by trading rewards, our framework not only enhances LLM performance in trading but also improves results on other financial-domain tasks. We present extensive empirical evidence to validate these enhancements.</description>
      <guid isPermaLink="false">oai:arXiv.org:2502.11433v3</guid>
      <category>cs.AI</category>
      <category>cs.CE</category>
      <category>q-fin.TR</category>
      <pubDate>Thu, 20 Feb 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <dc:creator>Guojun Xiong, Zhiyang Deng, Keyi Wang, Yupeng Cao, Haohang Li, Yangyang Yu, Xueqing Peng, Mingquan Lin, Kaleb E Smith, Xiao-Yang Liu, Jimin Huang, Sophia Ananiadou, Qianqian Xie</dc:creator>
    </item>
  </channel>
</rss>
