<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>cs.NA updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/cs.NA</link>
    <description>cs.NA updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/cs.NA" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Wed, 22 Oct 2025 04:01:00 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Wed, 22 Oct 2025 00:00:00 -0400</pubDate>
    <skipDays>
      <day>Saturday</day>
      <day>Sunday</day>
    </skipDays>
    <item>
      <title>Image reconstruction from structured subsampled 2D Fourier data</title>
      <link>https://arxiv.org/abs/2510.18045</link>
      <description>arXiv:2510.18045v1 Announce Type: new 
Abstract: In this paper we study the performance of image reconstruction methods from incomplete samples of the 2D discrete Fourier transform. Inspired by requirements in parallel MRI, we focus on a special sampling pattern with a small number of acquired rows of the Fourier transformed image. We show the importance of the low-pass set of acquired rows around zero in the Fourier space for image reconstruction. A suitable choice of the width $L$ of this index set depends on the image data and is crucial to achieve optimal reconstruction results. We prove that non-adaptive reconstruction approaches cannot lead to satisfying recovery results. We propose a new hybrid algorithm which connects the TV minimization technique based on primal-dual optimization with a recovery algorithm which exploits properties of the special sampling pattern for reconstruction. Our method shows very good performance for natural images as well as for cartoon-like images for a data reduction rate up to 8 in the complex setting and even 16 for real images.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.18045v1</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <pubDate>Wed, 22 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Gerlind Plonka, Anahita Riahi</dc:creator>
    </item>
    <item>
      <title>Estimation of a Gas Diffusion Coefficient by Fitting Molecular Dynamics Trajectories to Finite-Difference Simulations</title>
      <link>https://arxiv.org/abs/2510.18191</link>
      <description>arXiv:2510.18191v1 Announce Type: new 
Abstract: A procedure is presented to estimate the diffusion coefficient of a uniform patch of argon gas in a uniform background of helium gas. Molecular Dynamics (MD) simulations of the two gases interacting through the Lennard-Jones potential are carried out using the LAMMPS software package. In addition, finite-difference (FD) calculations are used to solve the continuum diffusion equation for the argon concentration with a given diffusion coefficient. To contain the computational cost and facilitate data visualization, both MD and FD computations were done in two space dimensions. The MD argon trajectories were binned to the FD grid, and the optimal diffusion coefficient was estimated by minimizing the difference between the binned MD data and the FD solution with a nonlinear least squares procedure (Levenberg-Marquardt algorithm). Numerical results show the effect of the MD binning parameter and FD grid spacing. The estimated diffusion coefficient is compared to an experimental measurement.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.18191v1</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <pubDate>Wed, 22 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Isaac Viviano</dc:creator>
    </item>
    <item>
      <title>An Explicit Euler-type Scheme for L\'evy-driven SDEs with Superlinear and Time-Irregular Coefficients</title>
      <link>https://arxiv.org/abs/2510.18222</link>
      <description>arXiv:2510.18222v1 Announce Type: new 
Abstract: This paper introduces a randomized tamed Euler scheme tailored for L\'evy-driven stochastic differential equations (SDEs) with superlinear random coefficients and Carath\'eodory-type drift. Under assumptions that allow for time-irregular drifts while ensuring appropriate time-regularity of the diffusion and jump coefficients, the proposed scheme is shown to achieve the optimal strong $\mathcal{L}^2$-convergence rate, arbitrarily close to $0.5$.
  A crucial component of our methodology is the incorporation of drift randomization, which overcomes challenges due to low time-regularity, along with a taming technique to handle the superlinear state dependence.
  Our analysis moreover covers settings where the coefficients are random, providing for instance strong convergence of randomized tamed Euler schemes for L\'evy-driven stochastic delay differential equations (SDDEs) with Markovian switching. To our knowledge, this is the first {work} that addresses the case of superlinear coefficients in the numerical analysis of Carath\'eodory-type SDEs and even for ordinary differential equations.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.18222v1</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <category>math.PR</category>
      <pubDate>Wed, 22 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Sani Biswas, Joaquin Fontbona</dc:creator>
    </item>
    <item>
      <title>SPIKE: Stable Physics-Informed Kernel Evolution Method for Solving Hyperbolic Conservation Laws</title>
      <link>https://arxiv.org/abs/2510.18266</link>
      <description>arXiv:2510.18266v1 Announce Type: new 
Abstract: We introduce the Stable Physics-Informed Kernel Evolution (SPIKE) method for numerical computation of inviscid hyperbolic conservation laws. SPIKE resolves a fundamental paradox: how strong-form residual minimization can capture weak solutions containing discontinuities. SPIKE employs reproducing kernel representations with regularized parameter evolution, where Tikhonov regularization provides a smooth transition mechanism through shock formation, allowing the dynamics to traverse shock singularities. This approach automatically maintains conservation, tracks characteristics, and captures shocks satisfying Rankine-Hugoniot conditions within a unified framework requiring no explicit shock detection or artificial viscosity. Numerical validation across scalar and vector-valued conservation laws confirms the method's effectiveness.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.18266v1</guid>
      <category>math.NA</category>
      <category>cs.AI</category>
      <category>cs.LG</category>
      <category>cs.NA</category>
      <category>math.AP</category>
      <pubDate>Wed, 22 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Hua Su, Lei Zhang, Jin Zhao</dc:creator>
    </item>
    <item>
      <title>Provably realizability-preserving finite volume method for quadrature-based moment models of kinetic equations</title>
      <link>https://arxiv.org/abs/2510.18380</link>
      <description>arXiv:2510.18380v1 Announce Type: new 
Abstract: Quadrature-based moment methods (QBMM) provide tractable closures for multiscale kinetic equations, with diverse applications across aerosols, sprays, and particulate flows, etc. However, for the derived hyperbolic moment-closure systems, seeking numerical schemes preserving moment realizability is essential yet challenging due to strong nonlinear coupling and the lack of explicit conservative-to-flux maps. This paper proposes and analyzes a provably realizability-preserving finite-volume method for five-moment systems closed by the two-node Gaussian-EQMOM and three-point HyQMOM. Rather than relying on kinetic fluxes, we recast the realizability condition into a nonnegative quadratic form in the moment vector, reducing the original nonlinear constraints to bilinear inequalities amenable to analysis. On this basis, we construct a tailored Harten--Lax--van Leer (HLL) flux with rigorously derived wave speeds and intermediate states that embed realizability directly into the flux evaluation. We prove sufficient realizability-preserving conditions under explicit Courant--Friedrichs--Lewy (CFL) constraints in the collisionless case, and for BGK relaxation, we obtain coupled time-step conditions involving a realizability radius; a semi-implicit BGK variant inherits the collisionless CFL. From a multiscale perspective, the analysis yields stability conditions uniform in the relaxation time and supports stiff-to-kinetic transitions. A practical limiter enforces strict realizability of reconstructed interface states without degrading accuracy. Numerical experiments demonstrate the accuracy, robustness in low-density regions, and realizability for both closures. This framework unifies realizability preservation for solving hyperbolic moment systems with complex closures and extends naturally to higher-order space--time discretizations.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.18380v1</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <pubDate>Wed, 22 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Chuan Fan, Qian Huang, Kailiang Wu</dc:creator>
    </item>
    <item>
      <title>Prescribed Eigenvalues via Optimal Perturbation of main-diagonal submatrix</title>
      <link>https://arxiv.org/abs/2510.18486</link>
      <description>arXiv:2510.18486v1 Announce Type: new 
Abstract: Consider a given square matrix $\textrm {K}$ with square blocks $A_{11},A_{22},\ldots,A_{nn}$ on the main diagonal. This paper aims to compute an optimal perturbation $\Delta$ of a preassigned block $A_{ii}\in\mathbb{C}^{d_i\times d_k}, \left(1\le i\le n\right)$,with respect to the spectral norm distance, such that the perturbed matrix ${\textrm {K}_X}$ has $k \le d_i$ prescribed eigenvalues. This paper presents a method for constructing the optimal perturbation by improving and extending the methodology, necessary definitions and lemmas of previous related works. Some conceivable applications of this subject are also presented. Numerical experiments are provided to illustrate the validity of the method.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.18486v1</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <pubDate>Wed, 22 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>M. R. Eslahchi, E. Kokabifar</dc:creator>
    </item>
    <item>
      <title>Multi-subspace power method for decomposing all tensors</title>
      <link>https://arxiv.org/abs/2510.18627</link>
      <description>arXiv:2510.18627v1 Announce Type: new 
Abstract: We present an algorithm for decomposing low rank tensors of any symmetry type, from fully asymmetric to fully symmetric. It generalizes the recent subspace power method from symmetric tensors to all tensors. The algorithm transforms an input tensor into a tensor with orthonormal slices. We show that for tensors with orthonormal slices and low rank, the summands of their decomposition are in one-to-one correspondence with the partially symmetric singular vector tuples (pSVTs) with singular value one. We use this to show correctness of the algorithm. We introduce a shifted power method for computing pSVTs and establish its global convergence. Numerical experiments demonstrate that our decomposition algorithm achieves higher accuracy and faster runtime than existing methods.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.18627v1</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <pubDate>Wed, 22 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Kexin Wang, Jo\~ao M. Pereira, Joe Kileel, Anna Seigal</dc:creator>
    </item>
    <item>
      <title>AutoVARP - a framework for automated reproducible inducibility testing in computational models of cardiac electrophysiology</title>
      <link>https://arxiv.org/abs/2510.18635</link>
      <description>arXiv:2510.18635v1 Announce Type: new 
Abstract: Simulations of Cardiac Electrophysiology are gaining momentum beyond basic mechanistic studies, as an approach for supporting clinical decision making. The potential for in silico technologies observed from the research community is immense, with studies demonstrating significantly improved therapeutical outcome with little to no additional burden for patients. Two main factors hinder the translation of these technologies from pure research to applications: virtually no reproducibility of results, and lack of standardized procedures. Inspired by a previously published virtual induction study by Arevalo et al. (2016), We address the issues of reproducibility and standardization providing autoVARP, a framework for standardization of virtual arrhythmia inducibility studies, built upon openCARP and the carputils framework. Standardization relies on the previously published forCEPSS framework and is ensured by defining the whole induction study with input files that can be easily shared. Our approach also ensures numerical efficiency by separating the induction study into four stages: (i) pre-pacing with forCEPSS, (ii) S1 pacing tor each steady state, (iii) S2 induction with different extrastimuli, (iv) testing of sustenance of induced reentries. We demonstrate the approach in a large virtual subject cohort to investigate numerical artifacts that may arise when improper setups are provided to perform virtual induction, and additionally showcase autoVARP in a biventricular mesh. AutoVARP addresses effectively the current gap in standardization and reproducibility of results providing a uniform methodology that can be implemented even by non expert users. AutoVARP is highly scalable and adaptable to markedly different anatomies. Although less flexible than in house implementations it provides automated tools to share setups and does not require re-implementation of any process.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.18635v1</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <pubDate>Wed, 22 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Paolo Seghetti, Matthias Gsell, Anton Prassk, Martin Bishop, Gernot Plank</dc:creator>
    </item>
    <item>
      <title>The numerical solution of the Dirichlet generalized and classical harmonic problems for irregular n-sided pyramidal domains by the method of probabilistic solutions</title>
      <link>https://arxiv.org/abs/2510.18667</link>
      <description>arXiv:2510.18667v1 Announce Type: new 
Abstract: This paper describes the application of the method of probabilistic solutions (MPS) to numerically solve the Dirichlet generalized and classical harmonic problems for irregular n sided pyramidal domains. Here, generalized means that the boundary function has a finite number of first kind discontinuity curves, with the pyramid edges acting as these curves. The pyramid base is a convex polygon, and its vertex projection lies within the base. The proposed algorithm for solving boundary problems numerically includes the following steps: a) applying MPS, which relies on computer modeling of the Wiener process; b) determining the intersection point between the simulated Wiener process path and the pyramid surface; c) developing a code for numerical implementation and verifying the accuracy of the results; d) calculating the desired function value at any chosen point. Two examples are provided for illustration, and the results of the numerical experiments are presented and discussed.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.18667v1</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <pubDate>Wed, 22 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <arxiv:DOI>10.3934/math.2025789</arxiv:DOI>
      <arxiv:journal_reference>AIMS Mathematics 10(8), 17657 - 17671 (2025)</arxiv:journal_reference>
      <dc:creator>M. Zakradze, Z. Tabagari, N. Koblishvili, T. Davitashvili, J. M. Sanchez-Saez,  F.,  Criado-Aldeanueva</dc:creator>
    </item>
    <item>
      <title>Adaptive hyperviscosity stabilisation for the RBF-FD method in solving advection-dominated transport equations</title>
      <link>https://arxiv.org/abs/2510.18772</link>
      <description>arXiv:2510.18772v1 Announce Type: new 
Abstract: This paper presents an adaptive hyperviscosity stabilisation procedure for the Radial Basis Function-generated Finite Difference (RBF-FD) method, aimed at solving linear and non-linear advection-dominated transport equations on domains without a boundary. The approach employs a PDE-independent algorithm that adaptively determines the hyperviscosity constant based on the spectral radius of the RBF-FD evolution matrix. The proposed procedure supports general node layouts and is not tailored for specific equations, avoiding the limitations of empirical tuning and von Neumann-based estimates. To reduce computational cost, it is shown that lower monomial augmentation in the approximation of the hyperviscosity operator can still ensure consistent stabilisation, enabling the use of smaller stencils and improving overall efficiency. A hybrid strategy employing different spline orders for the advection and hyperviscosity operators is also implemented to enhance stability. The method is evaluated on pure linear advection and non-linear Burgers' equation, demonstrating stable performance with limited numerical dissipation. The two main contributions are: (1) a general hyperviscosity RBF-FD solution procedure demonstrated on both linear and non-linear advection-dominated problems, and (2) an in-depth analysis of the behaviour of hyperviscosity within the RBF-FD framework, addressing the interplay between key free parameters and their influence on numerical results.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.18772v1</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <category>physics.comp-ph</category>
      <pubDate>Wed, 22 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Miha Rot, \v{Z}iga Vaupoti\v{c}, Andrej Kolar-Po\v{z}un, Gregor Kosec</dc:creator>
    </item>
    <item>
      <title>Commuting quasi-interpolators and Maxwell compactness for a polytopal de Rham complex</title>
      <link>https://arxiv.org/abs/2510.18835</link>
      <description>arXiv:2510.18835v1 Announce Type: new 
Abstract: We establish Maxwell compactness results for the Discrete De Rham (DDR) polytopal complex: sequences in this polytopal complex with bounded discrete $\boldsymbol{H}(\mathbf{curl})$ (resp. discrete $\boldsymbol{H}(\mathrm{div})$) norm and orthogonal to discrete gradients (resp. discrete curls) have $L^2$-relatively compact potential reconstructions. The proof of these results hinges on the design of novel quasi-interpolators, that map the minimal-regularity de Rham spaces onto the discrete DDR spaces and form a commuting diagram. A full set of (primal and adjoint) consistency properties is established for these quasi-interpolators, which paves the way to convergence proofs, under minimal-regularity assumptions, of DDR schemes for partial differential equations based on the de Rham complex. Our analysis is performed with generic mixed boundary conditions, also covering the cases of no boundary conditions or fully homogeneous boundary conditions, and leverages recently introduced liftings from the DDR complex to the continuous de Rham complex.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.18835v1</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <pubDate>Wed, 22 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Th\'eophile Chaumont-Frelet, J\'er\^ome Droniou, Simon Lemaire</dc:creator>
    </item>
    <item>
      <title>Flexible inner-product free Krylov methods for inverse problems</title>
      <link>https://arxiv.org/abs/2510.18853</link>
      <description>arXiv:2510.18853v1 Announce Type: new 
Abstract: Flexible Krylov methods are a common standpoint for inverse problems. In particular, they are used to address the challenges associated with explicit variational regularization when it goes beyond the two-norm, for example involving an $\ell_p$ norm for $0 &lt; p \leq 1$. Moreover, inner-product free Krylov methods have been revisited in the context of ill-posed problems, to speed up computations and improve memory requirements by means of using low precision arithmetics. However, these are effectively quasi-minimal residual methods, and can be used in combination with tools from randomized numerical linear algebra to improve the quality of the results. This work presents new flexible and inner-product free Krylov methods, including a new flexible generalized Hessenberg method for iteration-dependent preconditioning. Moreover, it introduces new randomized versions of the methods, based on the sketch-and-solve framework. Theoretical considerations are given, and numerical experiments are provided for different variational regularization terms to show the performance of the new methods.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.18853v1</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <pubDate>Wed, 22 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Malena Sabat\'e Landman</dc:creator>
    </item>
    <item>
      <title>New flexible and inexact Golub-Kahan algorithms for inverse problems</title>
      <link>https://arxiv.org/abs/2510.18865</link>
      <description>arXiv:2510.18865v1 Announce Type: new 
Abstract: This paper introduces a new class of algorithms for solving large-scale linear inverse problems based on new flexible and inexact Golub-Kahan factorizations. The proposed methods iteratively compute regularized solutions by approximating a solution to (re)weighted least squares problems via projection onto adaptively generated subspaces, where the constraint subspaces for the residuals are (formally) equipped with iteration-dependent preconditioners or inexactness. The new solvers offer a flexible and inexact Krylov subspace alternative to other existing Krylov-based approaches for handling general data fidelity functionals, e.g., those expressed in the $p$-norm. Numerical experiments in imaging applications, such as image deblurring and computed tomography, highlight the effectiveness and competitiveness of the proposed methods with respect to other popular methods.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.18865v1</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <pubDate>Wed, 22 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Malena Sabat\'e Landman, Silvia Gazzola</dc:creator>
    </item>
    <item>
      <title>A Quantum Algorithm for the Finite Element Method</title>
      <link>https://arxiv.org/abs/2510.18150</link>
      <description>arXiv:2510.18150v1 Announce Type: cross 
Abstract: The finite element method (FEM) is a cornerstone numerical technique for solving partial differential equations (PDEs). Here, we present $\textbf{Qu-FEM}$, a fault-tolerant era quantum algorithm for the finite element method. In contrast to other quantum PDE solvers, Qu-FEM preserves the geometric flexibility of FEM by introducing two new primitives, the unit of interaction and the local-to-global indicator matrix, which enable the assembly of global finite element arrays with a constant-size linear combination of unitaries. We study the modified Poisson equation as an elliptic problem of interest, and provide explicit circuits for Qu-FEM in Cartesian domains. For problems with constant coefficients, our algorithm admits block-encodings of global arrays that require only $\tilde{\mathcal{O}}\left(d^2 p^2 n\right)$ Clifford+$T$ gates for $d$-dimensional, order-$p$ tensor product elements on grids with $2^n$ degrees of freedom in each dimension, where $n$ is the number of qubits representing the $N=2^n$ discrete grid points. For problems with spatially varying coefficients, we perform numerical integration directly on the quantum computer to assemble global arrays and force vectors. Dirichlet boundary conditions are enforced via the method of Lagrange multipliers, eliminating the need to modify the block-encodings that emerge from the assembly procedure. This work presents a framework for extending the geometric flexibility of quantum PDE solvers while preserving the possibility of a quantum advantage.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.18150v1</guid>
      <category>quant-ph</category>
      <category>cs.NA</category>
      <category>math.NA</category>
      <category>physics.comp-ph</category>
      <category>physics.flu-dyn</category>
      <pubDate>Wed, 22 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Ahmad M. Alkadri, Tyler D. Kharazi, K. Birgitta Whaley, Kranthi K. Mandadapu</dc:creator>
    </item>
    <item>
      <title>Uniqueness of Angular Velocity Reconstruction in Parallel-Beam and Diffraction Tomography</title>
      <link>https://arxiv.org/abs/2510.18829</link>
      <description>arXiv:2510.18829v1 Announce Type: cross 
Abstract: This work addresses the problem of uniquely determining a rotational motion from continuous time-dependent measurements within the frameworks of parallel-beam and diffraction tomography. The motivation stems from the challenge of imaging trapped biological samples manipulated and rotated using optical or acoustic tweezers. We analyze the conditions under which the rotation of the unknown sample can be uniquely recovered using the infinitesimal common line and circle method, respectively. We provide explicit criteria for the sample's structure and the induced motion that guarantee unique reconstruction of all rotation parameters. Moreover, we demonstrate that the set of objects for which uniqueness fails is nowhere dense.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.18829v1</guid>
      <category>math.FA</category>
      <category>cs.NA</category>
      <category>math-ph</category>
      <category>math.MP</category>
      <category>math.NA</category>
      <pubDate>Wed, 22 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Peter Elbau, Denise Schmutz</dc:creator>
    </item>
    <item>
      <title>Nonconforming finite element spaces for $H\Lambda^k$ in $\mathbb{R}^n$</title>
      <link>https://arxiv.org/abs/2206.12114</link>
      <description>arXiv:2206.12114v3 Announce Type: replace 
Abstract: This paper constructs a unified family of nonconforming finite element spaces for $H\Lambda^k$ in $\mathbb{R}^n$ ($0\leqslant k\leqslant n$, $n\geqslant 1$). The spaces employ piecewise Whitney forms as shape functions, and include the lowest-degree Crouzeix-Raviart element space for $H\Lambda^0$. Optimal approximations and uniform discrete Poincar\'e inequalities are presented. Based on the newly constructed finite element spaces, discrete de Rham complexes with commutative diagrams, and the discrete Helmholtz decomposition and Hodge decomposition for piecewise constant spaces are established. All discrete operators involved are local, acting cell-wise. A framework of nonconforming finite element exterior calculus is then established, and is naturally connected to the classical conforming one. The cooperation of conforming and nonconforming finite element spaces leads to new discretization schemes of the Hodge Laplace problem.
  The new finite element spaces are constructed by a novel approach that seeks to mimic the dual connections between adjoint operators; novel construction methods and basic estimations are presented. Although the new spaces do not fit Ciarlet's finite element definition, they admit locally supported basis functions each spanning at most two adjacent cells, which makes the computation of the local stiffness matrices and the assembling of the global stiffness matrix implementable by following the standard procedure. Some numerical experiments are given to show the implementability and the performance of the new kind of spaces.</description>
      <guid isPermaLink="false">oai:arXiv.org:2206.12114v3</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <category>math.FA</category>
      <pubDate>Wed, 22 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Shuo Zhang</dc:creator>
    </item>
    <item>
      <title>Robust, randomized preconditioning for kernel ridge regression</title>
      <link>https://arxiv.org/abs/2304.12465</link>
      <description>arXiv:2304.12465v5 Announce Type: replace 
Abstract: This paper investigates preconditioned conjugate gradient techniques for solving kernel ridge regression (KRR) problems with a medium to large number of data points ($10^4 \leq N \leq 10^7$), and it describes two methods with the strongest guarantees available. The first method, RPCholesky preconditioning, accurately solves the full-data KRR problem in $O(N^2)$ arithmetic operations, assuming sufficiently rapid polynomial decay of the kernel matrix eigenvalues. The second method, KRILL preconditioning, offers an accurate solution to a restricted version of the KRR problem involving $k \ll N$ selected data centers at a cost of $O((N + k^2) k \log k)$ operations. The proposed methods efficiently solve a range of KRR problems, making them well-suited for practical applications.</description>
      <guid isPermaLink="false">oai:arXiv.org:2304.12465v5</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <category>stat.ML</category>
      <pubDate>Wed, 22 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Mateo D\'iaz, Ethan N. Epperly, Zachary Frangella, Joel A. Tropp, Robert J. Webber</dc:creator>
    </item>
    <item>
      <title>Bilinear optimal control for the Stokes-Brinkman equations: a priori and a posteriori error analyses</title>
      <link>https://arxiv.org/abs/2404.18348</link>
      <description>arXiv:2404.18348v4 Announce Type: replace 
Abstract: We analyze a bilinear optimal control problem for the Stokes--Brinkman equations: the control variable enters the state equations as a coefficient. In two- and three-dimensional Lipschitz domains, we perform a complete continuous analysis that includes the existence of solutions and first- and second-order optimality conditions. We also develop two finite element methods that differ fundamentally in whether the admissible control set is discretized or not. For each of the proposed methods, we perform a convergence analysis and derive a priori error estimates; the latter under the assumption that the domain is convex. Finally, assuming that the domain is Lipschitz, we develop an a posteriori error estimator for each discretization scheme, obtain a global reliability bound, and investigate local efficiency estimates.</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.18348v4</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <category>math.OC</category>
      <pubDate>Wed, 22 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Alejandro Allendes, Gilberto Campa\~na, Enrique Otarola</dc:creator>
    </item>
    <item>
      <title>Mixed precision iterative refinement for linear inverse problems</title>
      <link>https://arxiv.org/abs/2409.08335</link>
      <description>arXiv:2409.08335v3 Announce Type: replace 
Abstract: This study investigates the iterative refinement method applied to the solution of linear discrete inverse problems by considering its application to the Tikhonov problem in mixed precision. Previous works on mixed precision iterative refinement methods for the solution of symmetric positive definite linear systems and least-squares problems have shown regularization to be a key requirement when computing low precision factorizations. For problems that are naturally severely ill-posed, we formulate the iterates of iterative refinement in mixed precision as a filtered solution using the preconditioned Landweber method with a Tikhonov-type preconditioner. Through numerical examples simulating various mixed precision choices, we showcase the filtering properties of the method and the achievement of comparable working accuracy of discrete inverse problems (i.e., to within a few decimal places in relative error) compared to results computed in double precision as well as another approximate iterative refinement method which we use as a benchmark.</description>
      <guid isPermaLink="false">oai:arXiv.org:2409.08335v3</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <pubDate>Wed, 22 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>James G. Nagy, Lucas Onisk</dc:creator>
    </item>
    <item>
      <title>Generalizing subdiffusive Black-Scholes model by variable exponent: Model transformation and numerical approximation</title>
      <link>https://arxiv.org/abs/2411.13913</link>
      <description>arXiv:2411.13913v2 Announce Type: replace 
Abstract: This work generalizes the subdiffusive Black-Scholes model by introducing the variable exponent in order to provide adequate descriptions for the option pricing, where the variable exponent may account for the variation of the memory property. In addition to standard nonlinear-to-linear transformation, we apply a further spatial-temporal transformation to convert the model to a more tractable form in order to circumvent the difficulties caused by the ``non-positive, non-monotonic'' variable-exponent memory kernel. An interesting phenomenon is that the spatial transformation not only eliminates the advection term but naturally turns the original noncoercive spatial operator into a coercive one due to the specific structure of the Black-Scholes model, which thus avoids imposing constraints on coefficients. Then we perform numerical analysis for both the semi-discrete and fully discrete schemes to support numerical simulation. Numerical experiments are carried out to substantiate the theoretical results.</description>
      <guid isPermaLink="false">oai:arXiv.org:2411.13913v2</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <pubDate>Wed, 22 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Meihui Zhang, Yaxue Liu, Mengmeng Liu, Wenlin Qiu, Xiangcheng Zheng</dc:creator>
    </item>
    <item>
      <title>Neural network-enhanced $hr$-adaptive finite element algorithm for parabolic equations</title>
      <link>https://arxiv.org/abs/2503.12717</link>
      <description>arXiv:2503.12717v2 Announce Type: replace 
Abstract: In this paper, we propose a novel $hr$-adaptive finite element method, enhanced by neural networks, for parabolic equations. The main challenge of the conventional $h$-adaptive finite element method is interpolating the finite element solution from the previous step in the updated mesh. The interpolation dependent on the new mesh must be recomputed at each adaptive iteration, resulting in high computational costs. The new approach addresses this challenge by introducing a neural network to construct a mesh-free surrogate of the previous step finite element solution. Since the neural network is mesh-free, it only requires training once per time step, with its parameters initialized using the minimizer of the previous time step. This approach effectively overcomes the interpolation challenges associated with non-nested meshes in computation, making node insertion and movement more convenient and efficient. The new algorithm also emphasizes SIZE and GENERATE, allowing each refinement to roughly double the number of mesh nodes of the previous iteration and then redistribute them to form a new mesh that effectively captures the singularities. It significantly reduces the time required for repeated refinement of the conventional methods and achieves the desired accuracy in no more than seven space-adaptive iterations per time step. Numerical experiments confirm the efficiency of the proposed algorithm in capturing dynamic changes of singularities. The code is made publicly available on GitHub.</description>
      <guid isPermaLink="false">oai:arXiv.org:2503.12717v2</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <pubDate>Wed, 22 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Jiaxiong Hao, Yunqing Huang, Nianyu Yi, Peimeng Yin</dc:creator>
    </item>
    <item>
      <title>Sampling Kantorovich operators for speckle noise reduction using a Down-Up scaling approach and gap filling in remote sensing images</title>
      <link>https://arxiv.org/abs/2505.02422</link>
      <description>arXiv:2505.02422v2 Announce Type: replace 
Abstract: In the literature, several approaches have been proposed for restoring and enhancing remote sensing images, including methods based on interpolation, filtering, and deep learning. In this paper, we investigate the application of multivariate sampling Kantorovich (SK) operators for image reconstruction, with a particular focus on gap filling and speckle noise reduction. To understand the accuracy performances of the proposed algorithms, we first derive a quantitative estimate in $C(\R^n)$ for the error of approximation using the Euler-Maclaurin summation formula, under weak regularity conditions. We also establish a convergence result and a quantitative estimate with respect to the dissimilarity index measured by the continuous SSIM for functions in Lebesgue spaces. Additionally, we prove a multidimensional linear prediction result, which is used to design a new SK-based reconstruction algorithm to handle missing data, that we call LP-SK algorithm. To address speckle noise, we integrate SK operators into a newly proposed Down-Up scaling approach. Numerical tests are presented on synthetic and real SAR images to validate the proposed methods. Performance is assessed using similarity metrics such as SSIM and PSNR, along with speckle-specific indexes. Comparative analysis with state-of-the-art techniques highlights the effectiveness of the proposed approaches.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.02422v2</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <pubDate>Wed, 22 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Danilo Costarelli, Mariarosaria Natale</dc:creator>
    </item>
    <item>
      <title>A surrogate model for topology optimisation of elastic structures via parametric autoencoders</title>
      <link>https://arxiv.org/abs/2507.22539</link>
      <description>arXiv:2507.22539v2 Announce Type: replace 
Abstract: A surrogate-based topology optimisation algorithm for linear elastic structures under parametric loads and boundary conditions is proposed. Instead of learning the parametric solution of the state (and adjoint) problems or the optimisation trajectory as a function of the iterations, the proposed approach devises a surrogate version of the entire optimisation pipeline. First, the method predicts a quasi-optimal topology for a given problem configuration as a surrogate model of high-fidelity topologies optimised with the homogenisation method. This is achieved by means of a feed-forward net learning the mapping between the input parameters characterising the system setup and a latent space determined by encoder/decoder blocks reducing the dimensionality of the parametric topology optimisation problem and reconstructing a high-dimensional representation of the topology. Then, the predicted topology is used as an educated initial guess for a computationally efficient algorithm penalising the intermediate values of the design variable, while enforcing the governing equations of the system. This step allows the method to correct potential errors introduced by the surrogate model, eliminate artifacts, and refine the design in order to produce topologies consistent with the underlying physics. Different architectures are proposed and the approximation and generalisation capabilities of the resulting models are numerically evaluated. The quasi-optimal topologies allow to outperform the high-fidelity optimiser by reducing the average number of optimisation iterations by $53\%$ while achieving discrepancies below $4\%$ in the optimal value of the objective functional, even in the challenging scenario of testing the model to extrapolate beyond the training and validation domain.</description>
      <guid isPermaLink="false">oai:arXiv.org:2507.22539v2</guid>
      <category>math.NA</category>
      <category>cs.AI</category>
      <category>cs.CE</category>
      <category>cs.LG</category>
      <category>cs.NA</category>
      <category>math.OC</category>
      <pubDate>Wed, 22 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Matteo Giacomini, Antonio Huerta</dc:creator>
    </item>
    <item>
      <title>Space-time finite element methods for nonlinear wave equations via elliptic regularisation</title>
      <link>https://arxiv.org/abs/2507.22757</link>
      <description>arXiv:2507.22757v2 Announce Type: replace 
Abstract: We present and analyse a new conforming space-time Galerkin discretisation of a semi-linear wave equation, based on a variational formulation derived from De Giorgi's elliptic regularisation viewpoint of the wave equation in second-order formulation. The method is shown to be well-posed through a minimisation approach, and also unconditionally stable for all choices of conforming discretisation spaces. Further, a priori error bounds are proven for sufficiently smooth solutions. Special attention is given to the conditioning of the method and its stable implementation. Numerical experiments are provided to validate the theoretical findings.</description>
      <guid isPermaLink="false">oai:arXiv.org:2507.22757v2</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <pubDate>Wed, 22 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Lehel Banjai, Emmanuil H. Georgoulis, Brian Hennessy</dc:creator>
    </item>
    <item>
      <title>Variable-preconditioned transformed primal-dual method for generalized Wasserstein Gradient Flows</title>
      <link>https://arxiv.org/abs/2509.15385</link>
      <description>arXiv:2509.15385v2 Announce Type: replace 
Abstract: We propose a Variable-Preconditioned Transformed Primal-Dual (VPTPD) method for solving generalized Wasserstein gradient flows based on the structure-preserving JKO scheme. This is a nontrivial extension of the TPD method [Chen et al. (2025) SIAM J. Sci. Comput.] incorporating proximal splitting techniques to address the challenges arising from the nonsmoothness of the objective function. Our key contributions include: (i) a semi-implicit-explicit iterative scheme that combines proximal gradient steps with explicit gradient steps to treat the nonsmooth and smooth terms respectively; (ii) variable-dependent preconditioners constructed from the Hessian of a regularized objective to balance iteration count and per-iteration cost; (iii) a proof of existence and uniqueness of bounded solutions for the generalized proximal operator with the chosen preconditioner, along with a convergent and bound-preserving Newton solver; and (iv) an adaptive step-size strategy to improve robustness and accelerate convergence under poor Lipschitz conditions of the energy derivative. Comprehensive numerical experiments spanning from 1D to 3D settings demonstrate that our method achieves superior computational efficiency-achieving up to a 20$\times$ speedup over existing methods-thereby highlighting its broad applicability through several challenging simulations.</description>
      <guid isPermaLink="false">oai:arXiv.org:2509.15385v2</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <pubDate>Wed, 22 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Jin Zeng, Dawei Zhan, Ruchi Guo, Chaozhen Wei</dc:creator>
    </item>
    <item>
      <title>Zeta expansion for long-range interactions under periodic boundary conditions with applications to micromagnetics</title>
      <link>https://arxiv.org/abs/2509.26274</link>
      <description>arXiv:2509.26274v2 Announce Type: replace 
Abstract: We address the efficient computation of power-law-based interaction potentials of homogeneous $d$-dimensional bodies with an infinite $n$-dimensional array of copies, including their higher-order derivatives. This problem forms a serious challenge in micromagnetics with periodic boundary conditions and related fields. Nowadays, it is common practice to truncate the associated infinite lattice sum to a finite number of images, introducing uncontrolled errors. We show that, for general interacting geometries, the exact infinite sum for both dipolar interactions and generalized Riesz power-law potentials can be obtained by complementing a small direct sum by a correction term that involves efficiently computable derivatives of generalized zeta functions. We show that the resulting representation converges exponentially in the derivative order, reaching machine precision at a computational cost no greater than that of truncated summation schemes. In order to compute the generalized zeta functions efficiently, we provide a superexponentially convergent algorithm for their evaluation, as well as for all required special functions, such as incomplete Bessel functions. Magnetic fields can thus be evaluated to machine precision in arbitrary cuboidal domains periodically extended along one or two dimensions. We benchmark our method against known formulas for magnetic interactions and against direct summation for Riesz potentials with large exponents, consistently achieving full precision. In addition, we identify new corrections to the asymptotic limit of the demagnetization field and tabulate high-precision benchmark values that can be used as a reliable reference for micromagnetic solvers. The techniques developed are broadly applicable, with direct impact in other areas such as molecular dynamics.</description>
      <guid isPermaLink="false">oai:arXiv.org:2509.26274v2</guid>
      <category>math.NA</category>
      <category>cond-mat.str-el</category>
      <category>cs.NA</category>
      <pubDate>Wed, 22 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Andreas A. Buchheit, Jonathan K. Busse, Torsten Ke{\ss}ler, Filipp N. Rybakov</dc:creator>
    </item>
    <item>
      <title>An Efficient Particle-Field Algorithm with Neural Interpolation based on a Parabolic-Hyperbolic Chemotaxis System in 3D</title>
      <link>https://arxiv.org/abs/2510.13199</link>
      <description>arXiv:2510.13199v2 Announce Type: replace 
Abstract: Tumor angiogenesis involves a collection of tumor cells moving towards blood vessels for nutrients to grow. Angiogenesis, and in general chemotaxis systems have been modeled using partial differential equations (PDEs) and as such require numerical methods to approximate their solutions in 3 space dimensions (3D). This is an expensive computation when solutions develop large gradients at unknown locations, and so efficient algorithms to capture the main dynamical behavior are valuable. Here as a case study, we consider a parabolic-hyperbolic Keller-Segel (PHKS) system in the angiogenesis literature, and develop a mesh-free particle-based neural network algorithm that scales better to 3D than traditional mesh based solvers. From a regularized approximation of PHKS, we derive a neural stochastic interacting particle-field (NSIPF) algorithm where the bacterial density is represented as empirical measures of particles and the field variable (concentration of chemo-attractant) by a convolutional neural network (CNN) trained on low cost synthetic data. As a new model, NSIPF preserves total mass and nonnegativity of the density, and captures the dynamics of 3D multi-bump solutions at much faster speeds compared with classical finite difference (FD) and SIPF methods.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.13199v2</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <pubDate>Wed, 22 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Jongwon David Kim, Jack Xin</dc:creator>
    </item>
    <item>
      <title>Finite element methods for electroneutral multicomponent electrolyte flows</title>
      <link>https://arxiv.org/abs/2510.14923</link>
      <description>arXiv:2510.14923v2 Announce Type: replace 
Abstract: We present a broad family of high-order finite element algorithms for simulating the flow of electroneutral electrolytes. The governing partial differential equations that we solve are the electroneutral Navier-Stokes-Onsager-Stefan-Maxwell (NSOSM) equations, which model momentum transport, multicomponent diffusion and electrical effects within the electrolyte. Our algorithms can be applied in the steady and transient settings, in two and three spatial dimensions, and under a variety of boundary conditions. Moreover, we allow for the material parameters (e.g. viscosity, diffusivities, thermodynamic factors and density) to be solution-dependent and thermodynamically non-ideal. The flexibility of our approach requires us to address subtleties that arise in the governing equations due to the interplay between boundary conditions and the equation of state. We demonstrate the algorithms in various physical configurations, including (i) electrolyte flow around a microfluidic rotating disk electrode and (ii) the flow in a Hull cell of a cosolvent electrolyte mixture used in lithium-ion batteries.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.14923v2</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <pubDate>Wed, 22 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Aaron Baier-Reinio, Patrick E. Farrell, Charles W. Monroe</dc:creator>
    </item>
    <item>
      <title>PDE-Free Mass-Constrained Learning of Complex Systems with Hidden States: The crowd dynamics case</title>
      <link>https://arxiv.org/abs/2510.17657</link>
      <description>arXiv:2510.17657v2 Announce Type: replace 
Abstract: We propose a machine learning framework based on the next-generation Equation-Free algorithm for learning the spatio-temporal dynamics of mass-constrained complex systems with hidden states, whose dynamics can in principle be described by PDEs, but lack explicit models. In these cases, some variables, closures, and potentials governing the dynamics are generally not directly observable and therefore must be inferred from data. Here, we construct manifold-ROMs -- using delayed coordinates, thus exploiting the Takens'/Whitney's embedding theorems. In the first stage, we employ both linear (POD) and nonlinear manifold learning (Diffusion Maps, DMs) to extract low-dimensional latent representations of the complex spatio-temporal evolution. In the second step, we learn predictive manifold-informed ROMs to approximate the solution operator on the latent space. In the final step, the latent dynamics are lifted back to the original high-dimensional space by solving a pre-image problem. We prove that both POD and the particular $k$-nearest neighbors lifting operators preserve the mass, a crucial property in the context of many problems, including computational fluid dynamics (CFD) and crowd dynamics. Actually, the proposed framework reconstructs the solution operator of the unavailable mass-constrained PDE, bypassing the need to discover an explicit form of the PDE per se. We demonstrate our approach via the Hughes model, approximating the dynamics of individuals minimizing travel time while avoiding obstacles and high-density regions. We show that DMs-informed ROMs outperform the best POD-informed ROMs thus resulting in stable and accurate approximations of the solution operator both in the latent space and, via reconstruction, in the high-dimensional space, and can therefore be integrated reliably over long time horizons.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.17657v2</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <category>physics.flu-dyn</category>
      <pubDate>Wed, 22 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Gianmaria Viola, Alessandro Della Pia, Lucia Russo, Ioannis Kevrekidis, Constantinos Siettos</dc:creator>
    </item>
    <item>
      <title>Swarm-based optimization with jumps: a kinetic BGK framework and convergence analysis</title>
      <link>https://arxiv.org/abs/2507.00871</link>
      <description>arXiv:2507.00871v2 Announce Type: replace-cross 
Abstract: Metaheuristic algorithms are powerful tools for global optimization, particularly for non-convex and non-differentiable problems where exact methods are often impractical. Particle-based optimization methods, inspired by swarm intelligence principles, have shown effectiveness due to their ability to balance exploration and exploitation within the search space. In this work, we introduce a novel particle-based optimization algorithm where velocities are updated via random jumps, a strategy commonly used to enhance stochastic exploration. We formalize this approach by describing the dynamics through a kinetic modelling of BGK type, offering a unified framework that accommodates general noise distributions, including heavy-tailed ones like Cauchy. Under suitable parameter scaling, the model reduces to the Consensus-Based Optimization (CBO) dynamics. For non-degenerate Gaussian noise in bounded domains, we prove propagation of chaos and convergence towards minimizers. Numerical results on benchmark problems validate the approach and highlight its connection to CBO.</description>
      <guid isPermaLink="false">oai:arXiv.org:2507.00871v2</guid>
      <category>math.OC</category>
      <category>cs.NA</category>
      <category>math.NA</category>
      <pubDate>Wed, 22 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Giacomo Borghi, Hyesung Im, Lorenzo Pareschi</dc:creator>
    </item>
    <item>
      <title>Does block size matter in randomized block Krylov low-rank approximation?</title>
      <link>https://arxiv.org/abs/2508.06486</link>
      <description>arXiv:2508.06486v2 Announce Type: replace-cross 
Abstract: We study the problem of computing a rank-$k$ approximation of a matrix using randomized block Krylov iteration. Prior work has shown that, for block size $b = 1$ or $b = k$, a $(1 + \varepsilon)$-factor approximation to the best rank-$k$ approximation can be obtained after $\tilde O(k/\sqrt{\varepsilon})$ matrix-vector products with the target matrix. On the other hand, when $b$ is between $1$ and $k$, the best known bound on the number of matrix-vector products scales with $b(k-b)$, which could be as large as $O(k^2)$. Nevertheless, in practice, the performance of block Krylov methods is often optimized by choosing a block size $1 \ll b \ll k$. We resolve this theory-practice gap by proving that randomized block Krylov iteration produces a $(1 + \varepsilon)$-factor approximate rank-$k$ approximation using $\tilde O(k/\sqrt{\varepsilon})$ matrix-vector products for any block size $1\le b\le k$. Our analysis relies on new bounds for the minimum singular value of a random block Krylov matrix, which may be of independent interest. Similar bounds are central to recent breakthroughs on faster algorithms for sparse linear systems [Peng &amp; Vempala, SODA 2021; Nie, STOC 2022].</description>
      <guid isPermaLink="false">oai:arXiv.org:2508.06486v2</guid>
      <category>cs.DS</category>
      <category>cs.NA</category>
      <category>math.NA</category>
      <pubDate>Wed, 22 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Tyler Chen, Ethan N. Epperly, Raphael A. Meyer, Christopher Musco, Akash Rao</dc:creator>
    </item>
    <item>
      <title>A Spatio-temporal CP decomposition analysis of New England region in the US</title>
      <link>https://arxiv.org/abs/2510.10322</link>
      <description>arXiv:2510.10322v2 Announce Type: replace-cross 
Abstract: Spatio temporal data consist of measurement for one or more raster fields such as weather, traffic volume, crime rate, or disease incidents. Advances in modern technology have increased the number of available information for this type of data hence the rise of multidimensional data. In this paper we take advantage of the multidimensional structure of the data but also its temporal and spatial structure. In fact, we will be using the NCAR Climate Data Gateway website which provides data discovery and access services for global and regional climate model data. The daily values of total precipitation (prec), maximum (tmax), and minimum (tmin) temperature are combined to create a multidimensional data called tensor (a multidimensional array). In this paper, we propose a spatio temporal principal component analysis to initialize CP decomposition component. We take full advantage of the spatial and temporal structure of the data in the initialization step for cp component analysis. The performance of our method is tested via comparison with most popular initialization method. We also run a clustering analysis to further show the performance of our analysis.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.10322v2</guid>
      <category>stat.AP</category>
      <category>cs.NA</category>
      <category>math.NA</category>
      <pubDate>Wed, 22 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Fatoumata Sanogo</dc:creator>
    </item>
    <item>
      <title>Automotive Crash Dynamics Modeling Accelerated with Machine Learning</title>
      <link>https://arxiv.org/abs/2510.15201</link>
      <description>arXiv:2510.15201v2 Announce Type: replace-cross 
Abstract: Crashworthiness assessment is a critical aspect of automotive design, traditionally relying on high-fidelity finite element (FE) simulations that are computationally expensive and time-consuming. This work presents an exploratory comparative study on developing machine learning-based surrogate models for efficient prediction of structural deformation in crash scenarios using the NVIDIA PhysicsNeMo framework. Given the limited prior work applying machine learning to structural crash dynamics, the primary contribution lies in demonstrating the feasibility and engineering utility of the various modeling approaches explored in this work. We investigate two state-of-the-art neural network architectures for modeling crash dynamics: MeshGraphNet, and Transolver. Additionally, we examine three strategies for modeling transient dynamics: time-conditional, the standard Autoregressive approach, and a stability-enhanced Autoregressive scheme incorporating rollout-based training. The models are evaluated on a comprehensive Body-in-White (BIW) crash dataset comprising 150 detailed FE simulations using LS-DYNA. The dataset represents a structurally rich vehicle assembly with over 200 components, including 38 key components featuring variable thickness distributions to capture realistic manufacturing variability. Each model utilizes the undeformed mesh geometry and component characteristics as inputs to predict the spatiotemporal evolution of the deformed mesh during the crash sequence. Evaluation results show that the models capture the overall deformation trends with reasonable fidelity, demonstrating the feasibility of applying machine learning to structural crash dynamics. Although not yet matching full FE accuracy, the models achieve orders-of-magnitude reductions in computational cost, enabling rapid design exploration and early-stage optimization in crashworthiness evaluation.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.15201v2</guid>
      <category>cs.LG</category>
      <category>cs.AI</category>
      <category>cs.NA</category>
      <category>math.NA</category>
      <category>physics.app-ph</category>
      <category>physics.comp-ph</category>
      <pubDate>Wed, 22 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Mohammad Amin Nabian, Sudeep Chavare, Deepak Akhare, Rishikesh Ranade, Ram Cherukuri, Srinivas Tadepalli</dc:creator>
    </item>
  </channel>
</rss>
