<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>cs.CY updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/cs.CY</link>
    <description>cs.CY updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/cs.CY" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Mon, 20 Jan 2025 05:00:34 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Mon, 20 Jan 2025 00:00:00 -0500</pubDate>
    <skipDays>
      <day>Saturday</day>
      <day>Sunday</day>
    </skipDays>
    <item>
      <title>Position: Open and Closed Large Language Models in Healthcare</title>
      <link>https://arxiv.org/abs/2501.09906</link>
      <description>arXiv:2501.09906v1 Announce Type: new 
Abstract: This position paper analyzes the evolving roles of open-source and closed-source large language models (LLMs) in healthcare, emphasizing their distinct contributions and the scientific community's response to their development. Due to their advanced reasoning capabilities, closed LLMs, such as GPT-4, have dominated high-performance applications, particularly in medical imaging and multimodal diagnostics. Conversely, open LLMs, like Meta's LLaMA, have gained popularity for their adaptability and cost-effectiveness, enabling researchers to fine-tune models for specific domains, such as mental health and patient communication.</description>
      <guid isPermaLink="false">oai:arXiv.org:2501.09906v1</guid>
      <category>cs.CY</category>
      <pubDate>Mon, 20 Jan 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Jiawei Xu, Ying Ding, Yi Bu</dc:creator>
    </item>
    <item>
      <title>Application of the Cyberinfrastructure Production Function Model to R1 Institutions</title>
      <link>https://arxiv.org/abs/2501.10264</link>
      <description>arXiv:2501.10264v1 Announce Type: new 
Abstract: High-performance computing (HPC) is widely used in higher education for modeling, simulation, and AI applications. A critical piece of infrastructure with which to secure funding, attract and retain faculty, and teach students, supercomputers come with high capital and operating costs that must be considered against other competing priorities. This study applies the concepts of the production function model from economics to evaluate if previous research on building a model for quantifying the value of investing in research computing is generalizable to a wider set of 5 universities. We show that this model does appear to generalize, showing positive institutional returns from the addition of computing resources and staff. We do, however, find that the relative relationships between model inputs and outputs vary across institutions, which can often be attributed to understandable institution-specific factors.</description>
      <guid isPermaLink="false">oai:arXiv.org:2501.10264v1</guid>
      <category>cs.CY</category>
      <pubDate>Mon, 20 Jan 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-sa/4.0/</dc:rights>
      <dc:creator>Preston M. Smith, Jill Gemmill, David Y. Hancock, Brian W. O'Shea, Winona Snapp-Childs, James Wilgenbusch</dc:creator>
    </item>
    <item>
      <title>Using Technology in Digital Humanities for Learning and Knowledge Dissemination</title>
      <link>https://arxiv.org/abs/2501.10275</link>
      <description>arXiv:2501.10275v1 Announce Type: new 
Abstract: Research on Digital Humanities (DH) has been boosted due to the investment in technology for developing access and interaction tools for handling Humanities and Heritage data. The availability of these tools lowers the distance between DH scholars and data generators, and students at various levels, not only because it facilitates access to information but also through the dissemination technologies used in these tools, designed for the improvement of user experience. Most of the disciplines associated with the humanities involve geographical and temporal references, often integrated. These references have been scientifically and pedagogically handled for centuries and are established through the use of maps and timelines. Both these supports have been implemented and used digitally and their potential has been risen through their innovative integration with narratives, storytelling and story maps, enabling the telling of historical events in narratives superimposed on maps. These can be enhanced when supported by rich data, such as images, videos, sound, and their possible combinations in virtual and augmented reality. In this paper, we describe an initial set of tools which use a subset of these technologies and data types to enable learning and dissemination of Humanities data and knowledge. We describe how techniques for making data available and tools for enhancing interaction with these data can improve user experience and potentiate learning and dissemination.</description>
      <guid isPermaLink="false">oai:arXiv.org:2501.10275v1</guid>
      <category>cs.CY</category>
      <category>cs.MM</category>
      <pubDate>Mon, 20 Jan 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <arxiv:journal_reference>Revista EDUCAONLINE, Volume 15, Number 3, December 2021, ISSN 1983-1664, WOS:000711975000006</arxiv:journal_reference>
      <dc:creator>Armanda Rodrigues, Nuno Correia</dc:creator>
    </item>
    <item>
      <title>Design Patterns for the Common Good: Building Better Technologies Using the Wisdom of Virtue Ethics</title>
      <link>https://arxiv.org/abs/2501.10288</link>
      <description>arXiv:2501.10288v1 Announce Type: new 
Abstract: Virtue ethics is a philosophical tradition that emphasizes the cultivation of virtues in achieving the common good. It has been suggested to be an effective framework for envisioning more ethical technology, yet previous work on virtue ethics and technology design has remained at theoretical recommendations. Therefore, we propose an approach for identifying user experience design patterns that embody particular virtues to more concretely articulate virtuous technology designs. As a proof of concept for our approach, we documented seven design patterns for social media that uphold the virtues of Catholic Social Teaching. We interviewed 24 technology researchers and industry practitioners to evaluate these patterns. We found that overall the patterns enact the virtues they were identified to embody; our participants valued that the patterns fostered intentional conversations and personal connections. We pave a path for technology professionals to incorporate diverse virtue traditions into the development of technologies that support human flourishing.</description>
      <guid isPermaLink="false">oai:arXiv.org:2501.10288v1</guid>
      <category>cs.CY</category>
      <category>cs.HC</category>
      <pubDate>Mon, 20 Jan 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Louisa Conwill, Megan K. Levis, Karla Badillo-Urquiola, Walter J. Scheirer</dc:creator>
    </item>
    <item>
      <title>Agent4Edu: Generating Learner Response Data by Generative Agents for Intelligent Education Systems</title>
      <link>https://arxiv.org/abs/2501.10332</link>
      <description>arXiv:2501.10332v1 Announce Type: new 
Abstract: Personalized learning represents a promising educational strategy within intelligent educational systems, aiming to enhance learners' practice efficiency. However, the discrepancy between offline metrics and online performance significantly impedes their progress. To address this challenge, we introduce Agent4Edu, a novel personalized learning simulator leveraging recent advancements in human intelligence through large language models (LLMs). Agent4Edu features LLM-powered generative agents equipped with learner profile, memory, and action modules tailored to personalized learning algorithms. The learner profiles are initialized using real-world response data, capturing practice styles and cognitive factors. Inspired by human psychology theory, the memory module records practice facts and high-level summaries, integrating reflection mechanisms. The action module supports various behaviors, including exercise understanding, analysis, and response generation. Each agent can interact with personalized learning algorithms, such as computerized adaptive testing, enabling a multifaceted evaluation and enhancement of customized services. Through a comprehensive assessment, we explore the strengths and weaknesses of Agent4Edu, emphasizing the consistency and discrepancies in responses between agents and human learners. The code, data, and appendix are publicly available at https://github.com/bigdata-ustc/Agent4Edu.</description>
      <guid isPermaLink="false">oai:arXiv.org:2501.10332v1</guid>
      <category>cs.CY</category>
      <category>cs.AI</category>
      <pubDate>Mon, 20 Jan 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Weibo Gao, Qi Liu, Linan Yue, Fangzhou Yao, Rui Lv, Zheng Zhang, Hao Wang, Zhenya Huang</dc:creator>
    </item>
    <item>
      <title>How Do Programming Students Use Generative AI?</title>
      <link>https://arxiv.org/abs/2501.10091</link>
      <description>arXiv:2501.10091v1 Announce Type: cross 
Abstract: Programming students have a widespread access to powerful Generative AI tools like ChatGPT. While this can help understand the learning material and assist with exercises, educators are voicing more and more concerns about an over-reliance on generated outputs and lack of critical thinking skills. It is thus important to understand how students actually use generative AI and what impact this could have on their learning behavior. To this end, we conducted a study including an exploratory experiment with 37 programming students, giving them monitored access to ChatGPT while solving a code understanding and improving exercise. While only 23 of the students actually opted to use the chatbot, the majority of those eventually prompted it to simply generate a full solution. We observed two prevalent usage strategies: to seek knowledge about general concepts and to directly generate solutions. Instead of using the bot to comprehend the code and their own mistakes, students often got trapped in a vicious cycle of submitting wrong generated code and then asking the bot for a fix. Those who self-reported using generative AI regularly were more likely to prompt the bot to generate a solution. Our findings indicate that concerns about potential decrease in programmers' agency and productivity with Generative AI are justified. We discuss how researchers and educators can respond to the potential risk of students uncritically over-relying on generative AI. We also discuss potential modifications to our study design for large-scale replications.</description>
      <guid isPermaLink="false">oai:arXiv.org:2501.10091v1</guid>
      <category>cs.HC</category>
      <category>cs.AI</category>
      <category>cs.CY</category>
      <pubDate>Mon, 20 Jan 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Christian Rahe, Walid Maalej</dc:creator>
    </item>
    <item>
      <title>Illustrative Industry Architecture to Mitigate Potential Fragmentation across a Central Bank Digital Currency and Commercial Bank Money</title>
      <link>https://arxiv.org/abs/2203.17018</link>
      <description>arXiv:2203.17018v2 Announce Type: replace 
Abstract: Central banks are actively exploring central bank digital currencies (CBDCs) by conducting research, proofs of concept and pilots. However, adoption of a CBDC can risk fragmenting both payments markets and retail deposits. In this paper, we aim to provide a mitigation to this fragmentation risk by presenting an illustrative industry architecture that places CBDCs and commercial bank money on a similar footing. We introduce the concept of ecosystems providing a common programmability layer that interfaces with the account systems at both commercial banks and the central bank. We focus on a potential UK CBDC, including industry ecosystems interfacing with commercial banks using Open Banking application programming interfaces.</description>
      <guid isPermaLink="false">oai:arXiv.org:2203.17018v2</guid>
      <category>cs.CY</category>
      <pubDate>Mon, 20 Jan 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <arxiv:DOI>10.21314/JFMI.2023.003</arxiv:DOI>
      <arxiv:journal_reference>Journal of Financial Market Infrastructures 10(4), 55-63 (2022)</arxiv:journal_reference>
      <dc:creator>Lee Braine, Shreepad Shukla</dc:creator>
    </item>
    <item>
      <title>Two Types of AI Existential Risk: Decisive and Accumulative</title>
      <link>https://arxiv.org/abs/2401.07836</link>
      <description>arXiv:2401.07836v3 Announce Type: replace 
Abstract: The conventional discourse on existential risks (x-risks) from AI typically focuses on abrupt, dire events caused by advanced AI systems, particularly those that might achieve or surpass human-level intelligence. These events have severe consequences that either lead to human extinction or irreversibly cripple human civilization to a point beyond recovery. This discourse, however, often neglects the serious possibility of AI x-risks manifesting incrementally through a series of smaller yet interconnected disruptions, gradually crossing critical thresholds over time. This paper contrasts the conventional "decisive AI x-risk hypothesis" with an "accumulative AI x-risk hypothesis." While the former envisions an overt AI takeover pathway, characterized by scenarios like uncontrollable superintelligence, the latter suggests a different causal pathway to existential catastrophes. This involves a gradual accumulation of critical AI-induced threats such as severe vulnerabilities and systemic erosion of economic and political structures. The accumulative hypothesis suggests a boiling frog scenario where incremental AI risks slowly converge, undermining societal resilience until a triggering event results in irreversible collapse. Through systems analysis, this paper examines the distinct assumptions differentiating these two hypotheses. It is then argued that the accumulative view can reconcile seemingly incompatible perspectives on AI risks. The implications of differentiating between these causal pathways -- the decisive and the accumulative -- for the governance of AI as well as long-term AI safety are discussed.</description>
      <guid isPermaLink="false">oai:arXiv.org:2401.07836v3</guid>
      <category>cs.CY</category>
      <category>cs.AI</category>
      <category>cs.LG</category>
      <pubDate>Mon, 20 Jan 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Atoosa Kasirzadeh</dc:creator>
    </item>
    <item>
      <title>Bounds and Bugs: The Limits of Symmetry Metrics to Detect Partisan Gerrymandering</title>
      <link>https://arxiv.org/abs/2406.12167</link>
      <description>arXiv:2406.12167v3 Announce Type: replace 
Abstract: We consider two symmetry metrics commonly used to analyze partisan gerrymandering: the Mean-Median Difference (MM) and Partisan Bias (PB). Our main results compare, for combinations of seats and votes achievable in districted elections, the number of districts won by each party to the extent of potential deviation from the ideal metric values, taking into account the political geography of the state. These comparisons are motivated by examples where the MM and PB have been used in efforts to detect when a districting plan awards extreme number of districts won by some party. These examples include expert testimony, public-facing apps, recommendations by experts to redistricting commissions, and public policy proposals.
  To achieve this goal we perform both theoretical and empirical analyses of the MM and PB. In our theoretical analysis, we consider vote-share, seat-share pairs (V, S) for which one can construct election data having vote share V and seat share S, and turnout is equal in each district. We calculate the range of values that MM and PB can achieve on that constructed election data. In the process, we find the range of (V,S) pairs that achieve MM = 0, and see that the corresponding range for PB is the same set of (V,S) pairs. We show how the set of such (V,S) pairs allowing for MM = 0 (and PB = 0) changes when turnout in each district is allowed to vary. By observing the results of this theoretical analysis, we can show that the values taken on by these metrics do not necessarily attain more extreme values in plans with more extreme numbers of districts won. We also analyze specific example elections, showing how these metrics can return unintuitive results. We follow this with an empirical study, where we show that on 18 different U.S. maps these metrics can fail to detect extreme seats outcomes.</description>
      <guid isPermaLink="false">oai:arXiv.org:2406.12167v3</guid>
      <category>cs.CY</category>
      <category>math.CO</category>
      <category>physics.soc-ph</category>
      <pubDate>Mon, 20 Jan 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Daryl DeFord, Ellen Veomett</dc:creator>
    </item>
    <item>
      <title>Reinforcement Learning from Human Feedback: Whose Culture, Whose Values, Whose Perspectives?</title>
      <link>https://arxiv.org/abs/2407.17482</link>
      <description>arXiv:2407.17482v2 Announce Type: replace 
Abstract: We argue for the epistemic and ethical advantages of pluralism in Reinforcement Learning from Human Feedback (RLHF) in the context of Large Language Models (LLM). Drawing on social epistemology and pluralist philosophy of science, we suggest ways in which RHLF can be made more responsive to human needs and how we can address challenges along the way. The paper concludes with an agenda for change, i.e. concrete, actionable steps to improve LLM development.</description>
      <guid isPermaLink="false">oai:arXiv.org:2407.17482v2</guid>
      <category>cs.CY</category>
      <category>cs.AI</category>
      <category>cs.CL</category>
      <category>cs.HC</category>
      <pubDate>Mon, 20 Jan 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Kristian Gonz\'alez Barman, Simon Lohse, Henk de Regt</dc:creator>
    </item>
    <item>
      <title>A Fairness-Oriented Reinforcement Learning Approach for the Operation and Control of Shared Micromobility Services</title>
      <link>https://arxiv.org/abs/2403.15780</link>
      <description>arXiv:2403.15780v3 Announce Type: replace-cross 
Abstract: As Machine Learning grows in popularity across various fields, equity has become a key focus for the AI community. However, fairness-oriented approaches are still underexplored in smart mobility. Addressing this gap, our study investigates the balance between performance optimization and algorithmic fairness in shared micromobility services providing a novel framework based on Reinforcement Learning. Exploiting Q-learning, the proposed methodology achieves equitable outcomes in terms of the Gini index across different areas characterized by their distance from central hubs. Through vehicle rebalancing, the provided scheme maximizes operator performance while ensuring fairness principles for users, reducing iniquity by up to 85% while only increasing costs by 30% (w.r.t. applying no equity adjustment). A case study with synthetic data validates our insights and highlights the importance of fairness in urban micromobility (source code: https://github.com/mcederle99/FairMSS.git).</description>
      <guid isPermaLink="false">oai:arXiv.org:2403.15780v3</guid>
      <category>eess.SY</category>
      <category>cs.CY</category>
      <category>cs.LG</category>
      <category>cs.SY</category>
      <pubDate>Mon, 20 Jan 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Matteo Cederle, Luca Vittorio Piron, Marina Ceccon, Federico Chiariotti, Alessandro Fabris, Marco Fabris, Gian Antonio Susto</dc:creator>
    </item>
    <item>
      <title>Careful About What App Promotion Ads Recommend! Detecting and Explaining Malware Promotion via App Promotion Graph</title>
      <link>https://arxiv.org/abs/2410.07588</link>
      <description>arXiv:2410.07588v2 Announce Type: replace-cross 
Abstract: In Android apps, their developers frequently place app promotion ads, namely advertisements to promote other apps. Unfortunately, the inadequate vetting of ad content allows malicious developers to exploit app promotion ads as a new distribution channel for malware. To help detect malware distributed via app promotion ads, in this paper, we propose a novel approach, named ADGPE, that synergistically integrates app user interface (UI) exploration with graph learning to automatically collect app promotion ads, detect malware promoted by these ads, and explain the promotion mechanisms employed by the detected malware. Our evaluation on 18, 627 app promotion ads demonstrates the substantial risks in the app promotion ecosystem.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.07588v2</guid>
      <category>cs.CR</category>
      <category>cs.CY</category>
      <pubDate>Mon, 20 Jan 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Shang Ma, Chaoran Chen, Shao Yang, Shifu Hou, Toby Jia-Jun Li, Xusheng Xiao, Tao Xie, Yanfang Ye</dc:creator>
    </item>
  </channel>
</rss>
