<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>math.OC updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/math.OC</link>
    <description>math.OC updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/math.OC" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Tue, 28 May 2024 04:00:13 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Tue, 28 May 2024 00:00:00 -0400</pubDate>
    <skipDays>
      <day>Saturday</day>
      <day>Sunday</day>
    </skipDays>
    <item>
      <title>Riemannian Bilevel Optimization</title>
      <link>https://arxiv.org/abs/2405.15816</link>
      <description>arXiv:2405.15816v1 Announce Type: new 
Abstract: We develop new algorithms for Riemannian bilevel optimization. We focus in particular on batch and stochastic gradient-based methods, with the explicit goal of avoiding second-order information such as Riemannian hyper-gradients. We propose and analyze $\mathrm{RF^2SA}$, a method that leverages first-order gradient information to navigate the complex geometry of Riemannian manifolds efficiently. Notably, $\mathrm{RF^2SA}$ is a single-loop algorithm, and thus easier to implement and use. Under various setups, including stochastic optimization, we provide explicit convergence rates for reaching $\epsilon$-stationary points. We also address the challenge of optimizing over Riemannian manifolds with constraints by adjusting the multiplier in the Lagrangian, ensuring convergence to the desired solution without requiring access to second-order derivatives.</description>
      <guid isPermaLink="false">oai:arXiv.org:2405.15816v1</guid>
      <category>math.OC</category>
      <category>cs.AI</category>
      <category>cs.LG</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Sanchayan Dutta, Xiang Cheng, Suvrit Sra</dc:creator>
    </item>
    <item>
      <title>Vector Spaces of Linearizations for Multivariable State-Space Systems</title>
      <link>https://arxiv.org/abs/2405.15819</link>
      <description>arXiv:2405.15819v1 Announce Type: new 
Abstract: Consider a multivariable state space system and associated transfer function G({\lambda}). The aim of this paper is to define and analyze two vector spaces of matrix pencils associated with the matrix G({\lambda}) and show that almost all of these pencils are linearizations of G({\lambda}). We also construct symmetric/Hermitian linearizations of G({\lambda}) when G({\lambda}) is regular and symmetric/Hermitian.</description>
      <guid isPermaLink="false">oai:arXiv.org:2405.15819v1</guid>
      <category>math.OC</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Avisek Bist, Namita Behera</dc:creator>
    </item>
    <item>
      <title>A Fisher-Rao gradient flow for entropic mean-field min-max games</title>
      <link>https://arxiv.org/abs/2405.15834</link>
      <description>arXiv:2405.15834v1 Announce Type: new 
Abstract: Gradient flows play a substantial role in addressing many machine learning problems. We examine the convergence in continuous-time of a \textit{Fisher-Rao} (Mean-Field Birth-Death) gradient flow in the context of solving convex-concave min-max games with entropy regularization. We propose appropriate Lyapunov functions to demonstrate convergence with explicit rates to the unique mixed Nash equilibrium.</description>
      <guid isPermaLink="false">oai:arXiv.org:2405.15834v1</guid>
      <category>math.OC</category>
      <category>cs.LG</category>
      <category>math.PR</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Razvan-Andrei Lascu, Mateusz B. Majka, {\L}ukasz Szpruch</dc:creator>
    </item>
    <item>
      <title>Global Output-Feedback Extremum Seeking Control with Source Seeking Experiments</title>
      <link>https://arxiv.org/abs/2405.15879</link>
      <description>arXiv:2405.15879v1 Announce Type: new 
Abstract: This paper discusses the design of an extremum seeking controller that relies on a monitoring function for a class of SISO uncertain nonlinear systems characterized by arbitrary and uncertain relative degree. Our demonstration illustrates the feasibility of achieving an arbitrarily small proximity to the desired optimal point through output feedback. The core concept involves integrating a monitoring function with a norm state observer for the unitary relative degree case and its expansion to arbitrary relative degrees by means of the employment of a time-scaling technique. Significantly, our proposed scheme attains the extremum of an unknown nonlinear mapping across the entire domain of initial conditions, ensuring global convergence and stability for the real-time optimization algorithm. Furthermore, we provide tuning rules to ensure convergence to the global maximum in the presence of local extrema. To validate the effectiveness of the proposed approach, we present a numerical example and apply it to a source-seeking problem involving a cart-track linear positioning servomechanism. Notably, the cart lacks the ability to sense its velocity or the source's position, but can detect the source of a light signal of unknown concentration field.</description>
      <guid isPermaLink="false">oai:arXiv.org:2405.15879v1</guid>
      <category>math.OC</category>
      <category>cs.SY</category>
      <category>eess.SY</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Nerito Oliveira Aminde, Tiago Roux Oliveira, Liu Hsu</dc:creator>
    </item>
    <item>
      <title>Derivatives of Stochastic Gradient Descent</title>
      <link>https://arxiv.org/abs/2405.15894</link>
      <description>arXiv:2405.15894v1 Announce Type: new 
Abstract: We consider stochastic optimization problems where the objective depends on some parameter, as commonly found in hyperparameter optimization for instance. We investigate the behavior of the derivatives of the iterates of Stochastic Gradient Descent (SGD) with respect to that parameter and show that they are driven by an inexact SGD recursion on a different objective function, perturbed by the convergence of the original SGD. This enables us to establish that the derivatives of SGD converge to the derivative of the solution mapping in terms of mean squared error whenever the objective is strongly convex. Specifically, we demonstrate that with constant step-sizes, these derivatives stabilize within a noise ball centered at the solution derivative, and that with vanishing step-sizes they exhibit $O(\log(k)^2 / k)$ convergence rates. Additionally, we prove exponential convergence in the interpolation regime. Our theoretical findings are illustrated by numerical experiments on synthetic tasks.</description>
      <guid isPermaLink="false">oai:arXiv.org:2405.15894v1</guid>
      <category>math.OC</category>
      <category>cs.LG</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Franck Iutzeler, Edouard Pauwels, Samuel Vaiter</dc:creator>
    </item>
    <item>
      <title>A Unified Theory of Stochastic Proximal Point Methods without Smoothness</title>
      <link>https://arxiv.org/abs/2405.15941</link>
      <description>arXiv:2405.15941v1 Announce Type: new 
Abstract: This paper presents a comprehensive analysis of a broad range of variations of the stochastic proximal point method (SPPM). Proximal point methods have attracted considerable interest owing to their numerical stability and robustness against imperfect tuning, a trait not shared by the dominant stochastic gradient descent (SGD) algorithm. A framework of assumptions that we introduce encompasses methods employing techniques such as variance reduction and arbitrary sampling. A cornerstone of our general theoretical approach is a parametric assumption on the iterates, correction and control vectors. We establish a single theorem that ensures linear convergence under this assumption and the $\mu$-strong convexity of the loss function, and without the need to invoke smoothness. This integral theorem reinstates best known complexity and convergence guarantees for several existing methods which demonstrates the robustness of our approach. We expand our study by developing three new variants of SPPM, and through numerical experiments we elucidate various properties inherent to them.</description>
      <guid isPermaLink="false">oai:arXiv.org:2405.15941v1</guid>
      <category>math.OC</category>
      <category>cs.LG</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Peter Richt\'arik, Abdurakhmon Sadiev, Yury Demidovich</dc:creator>
    </item>
    <item>
      <title>Generalized Dimension Reduction Using Semi-Relaxed Gromov-Wasserstein Distance</title>
      <link>https://arxiv.org/abs/2405.15959</link>
      <description>arXiv:2405.15959v1 Announce Type: new 
Abstract: Dimension reduction techniques typically seek an embedding of a high-dimensional point cloud into a low-dimensional Euclidean space which optimally preserves the geometry of the input data. Based on expert knowledge, one may instead wish to embed the data into some other manifold or metric space in order to better reflect the geometry or topology of the point cloud. We propose a general method for manifold-valued multidimensional scaling based on concepts from optimal transport. In particular, we establish theoretical connections between the recently introduced semi-relaxed Gromov-Wasserstein (srGW) framework and multidimensional scaling by solving the Monge problem in this setting. We also derive novel connections between srGW distance and Gromov-Hausdorff distance. We apply our computational framework to analyze ensembles of political redistricting plans for states with two Congressional districts, achieving an effective visualization of the ensemble as a distribution on a circle which can be used to characterize typical neutral plans, and to flag outliers.</description>
      <guid isPermaLink="false">oai:arXiv.org:2405.15959v1</guid>
      <category>math.OC</category>
      <category>math.MG</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Ranthony A. Clark, Tom Needham, Thomas Weighill</dc:creator>
    </item>
    <item>
      <title>Inference of Utilities and Time Preference in Sequential Decision-Making</title>
      <link>https://arxiv.org/abs/2405.15975</link>
      <description>arXiv:2405.15975v1 Announce Type: new 
Abstract: This paper introduces a novel stochastic control framework to enhance the capabilities of automated investment managers, or robo-advisors, by accurately inferring clients' investment preferences from past activities. Our approach leverages a continuous-time model that incorporates utility functions and a generic discounting scheme of a time-varying rate, tailored to each client's risk tolerance, valuation of daily consumption, and significant life goals. We address the resulting time inconsistency issue through state augmentation and the establishment of the dynamic programming principle and the verification theorem. Additionally, we provide sufficient conditions for the identifiability of client investment preferences. To complement our theoretical developments, we propose a learning algorithm based on maximum likelihood estimation within a discrete-time Markov Decision Process framework, augmented with entropy regularization. We prove that the log-likelihood function is locally concave, facilitating the fast convergence of our proposed algorithm. Practical effectiveness and efficiency are showcased through two numerical examples, including Merton's problem and an investment problem with unhedgeable risks.
  Our proposed framework not only advances financial technology by improving personalized investment advice but also contributes broadly to other fields such as healthcare, economics, and artificial intelligence, where understanding individual preferences is crucial.</description>
      <guid isPermaLink="false">oai:arXiv.org:2405.15975v1</guid>
      <category>math.OC</category>
      <category>cs.LG</category>
      <category>q-fin.CP</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Haoyang Cao, Zhengqi Wu, Renyuan Xu</dc:creator>
    </item>
    <item>
      <title>Exploring Jacobian Inexactness in Second-Order Methods for Variational Inequalities: Lower Bounds, Optimal Algorithms and Quasi-Newton Approximations</title>
      <link>https://arxiv.org/abs/2405.15990</link>
      <description>arXiv:2405.15990v1 Announce Type: new 
Abstract: Variational inequalities represent a broad class of problems, including minimization and min-max problems, commonly found in machine learning. Existing second-order and high-order methods for variational inequalities require precise computation of derivatives, often resulting in prohibitively high iteration costs. In this work, we study the impact of Jacobian inaccuracy on second-order methods. For the smooth and monotone case, we establish a lower bound with explicit dependence on the level of Jacobian inaccuracy and propose an optimal algorithm for this key setting. When derivatives are exact, our method converges at the same rate as exact optimal second-order methods. To reduce the cost of solving the auxiliary problem, which arises in all high-order methods with global convergence, we introduce several Quasi-Newton approximations. Our method with Quasi-Newton updates achieves a global sublinear convergence rate. We extend our approach with a tensor generalization for inexact high-order derivatives and support the theory with experiments.</description>
      <guid isPermaLink="false">oai:arXiv.org:2405.15990v1</guid>
      <category>math.OC</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-sa/4.0/</dc:rights>
      <dc:creator>Artem Agafonov, Petr Ostroukhov, Konstantin Yakovlev, Eduard Gorbunov, Martin Tak\'a\v{c}, Alexander Gasnikov, Dmitry Kamzolov</dc:creator>
    </item>
    <item>
      <title>Multifractal Analysis of the Sinkhorn Algorithm: Unveiling the Intricate Structure of Optimal Transport Maps</title>
      <link>https://arxiv.org/abs/2405.16006</link>
      <description>arXiv:2405.16006v1 Announce Type: new 
Abstract: The Sinkhorn algorithm has emerged as a powerful tool for solving optimal transport problems, finding applications in various domains such as machine learning, image processing, and computational biology. Despite its widespread use, the intricate structure and scaling properties of the coupling matrices generated by the Sinkhorn algorithm remain largely unexplored. In this paper, we delve into the multifractal properties of these coupling matrices, aiming to unravel their complex behavior and shed light on the underlying dynamics of the Sinkhorn algorithm. We prove the existence of the multifractal spectrum and the singularity spectrum for the Sinkhorn coupling matrices. Furthermore, we derive bounds on the generalized dimensions, providing a comprehensive characterization of their scaling properties. Our findings not only deepen our understanding of the Sinkhorn algorithm but also pave the way for novel applications and algorithmic improvements in the realm of optimal transport.</description>
      <guid isPermaLink="false">oai:arXiv.org:2405.16006v1</guid>
      <category>math.OC</category>
      <category>math.ST</category>
      <category>stat.TH</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Jose Rafael Espinosa Mena</dc:creator>
    </item>
    <item>
      <title>Block Acceleration Without Momentum: On Optimal Stepsizes of Block Gradient Descent for Least-Squares</title>
      <link>https://arxiv.org/abs/2405.16020</link>
      <description>arXiv:2405.16020v1 Announce Type: new 
Abstract: Block coordinate descent is a powerful algorithmic template suitable for big data optimization. This template admits a lot of variants including block gradient descent (BGD), which performs gradient descent on a selected block of variables, while keeping other variables fixed. For a very long time, the stepsize for each block has tacitly been set to one divided by the block-wise Lipschitz smoothness constant, imitating the vanilla stepsize rule for gradient descent (GD). However, such a choice for BGD has not yet been able to theoretically justify its empirical superiority over GD, as existing convergence rates for BGD have worse constants than GD in the deterministic cases.
  To discover such theoretical justification, we set up a simple environment where we consider BGD applied to least-squares with two blocks of variables. Assuming the data matrix corresponding to each block is orthogonal, we find optimal stepsizes of BGD in closed form, which provably lead to asymptotic convergence rates twice as fast as GD with Polyak's momentum; this means, under that orthogonality assumption, one can accelerate BGD by just tuning stepsizes and without adding any momentum. An application that satisfies this assumption is \textit{generalized alternating projection} between two subspaces, and applying our stepsizes to it improves the prior convergence rate that was once claimed, slightly inaccurately, to be optimal. The main proof idea is to minimize, in stepsize variables, the spectral radius of a matrix that controls convergence rates.</description>
      <guid isPermaLink="false">oai:arXiv.org:2405.16020v1</guid>
      <category>math.OC</category>
      <category>cs.NA</category>
      <category>math.NA</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Liangzu Peng, Wotao Yin</dc:creator>
    </item>
    <item>
      <title>A Novel Privacy Enhancement Scheme with Dynamic Quantization for Federated Learning</title>
      <link>https://arxiv.org/abs/2405.16058</link>
      <description>arXiv:2405.16058v1 Announce Type: new 
Abstract: Federated learning (FL) has been widely regarded as a promising paradigm for privacy preservation of raw data in machine learning. Although, the data privacy in FL is locally protected to some extent, it is still a desideratum to enhance privacy and alleviate communication overhead caused by repetitively transmitting model parameters. Typically, these challenges are addressed separately, or jointly via a unified scheme that consists of noise-injected privacy mechanism and communication compression, which may lead to model corruption due to the introduced composite noise. In this work, we propose a novel model-splitting privacy-preserving FL (MSP-FL) scheme to achieve private FL with precise accuracy guarantee. Based upon MSP-FL, we further propose a model-splitting privacy-preserving FL with dynamic quantization (MSPDQ-FL) to mitigate the communication overhead, which incorporates a shrinking quantization interval to reduce the quantization error. We provide privacy and convergence analysis for both MSP-FL and MSPDQ-FL under non-i.i.d. dataset, partial clients participation and finite quantization level. Numerical results are presented to validate the superiority of the proposed schemes.</description>
      <guid isPermaLink="false">oai:arXiv.org:2405.16058v1</guid>
      <category>math.OC</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Yifan Wang, Xianghui Cao, Shi Jin, Mo-Yuen Chow</dc:creator>
    </item>
    <item>
      <title>Near-Optimal Distributed Minimax Optimization under the Second-Order Similarity</title>
      <link>https://arxiv.org/abs/2405.16126</link>
      <description>arXiv:2405.16126v1 Announce Type: new 
Abstract: This paper considers the distributed convex-concave minimax optimization under the second-order similarity. We propose stochastic variance-reduced optimistic gradient sliding (SVOGS) method, which takes the advantage of the finite-sum structure in the objective by involving the mini-batch client sampling and variance reduction. We prove SVOGS can achieve the $\varepsilon$-duality gap within communication rounds of ${\mathcal O}(\delta D^2/\varepsilon)$, communication complexity of ${\mathcal O}(n+\sqrt{n}\delta D^2/\varepsilon)$, and local gradient calls of $\tilde{\mathcal O}(n+(\sqrt{n}\delta+L)D^2/\varepsilon\log(1/\varepsilon))$, where $n$ is the number of nodes, $\delta$ is the degree of the second-order similarity, $L$ is the smoothness parameter and $D$ is the diameter of the constraint set. We can verify that all of above complexity (nearly) matches the corresponding lower bounds. For the specific $\mu$-strongly-convex-$\mu$-strongly-convex case, our algorithm has the upper bounds on communication rounds, communication complexity, and local gradient calls of $\mathcal O(\delta/\mu\log(1/\varepsilon))$, ${\mathcal O}((n+\sqrt{n}\delta/\mu)\log(1/\varepsilon))$, and $\tilde{\mathcal O}(n+(\sqrt{n}\delta+L)/\mu)\log(1/\varepsilon))$ respectively, which are also nearly tight. Furthermore, we conduct the numerical experiments to show the empirical advantages of proposed method.</description>
      <guid isPermaLink="false">oai:arXiv.org:2405.16126v1</guid>
      <category>math.OC</category>
      <category>cs.LG</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Qihao Zhou, Haishan Ye, Luo Luo</dc:creator>
    </item>
    <item>
      <title>Higher Degree Inexact Model for Optimization problems</title>
      <link>https://arxiv.org/abs/2405.16140</link>
      <description>arXiv:2405.16140v1 Announce Type: new 
Abstract: In this paper, it was proposed a new concept of the inexact higher degree $(\delta, L, q)$-model of a function that is a generalization of the inexact $(\delta, L)$-model, $(\delta, L)$-oracle and $(\delta, L)$-oracle of degree $q \in [0,2)$. Some examples were provided to illustrate the proposed new model. Adaptive inexact gradient and fast gradient methods for convex and strongly convex functions were constructed and analyzed using the new proposed inexact model. A universal fast gradient method that allows solving optimization problems with a weaker level of smoothness, among them non-smooth problems was proposed. For convex optimization problems it was proved that the proposed gradient and fast gradient methods could be converged with rates $O\left(\frac{1}{k} + \frac{\delta}{k^{q/2}}\right)$ and $O\left(\frac{1}{k^2} + \frac{\delta}{k^{(3q-2)/2}}\right)$, respectively. For the gradient method, the coefficient of $\delta$ diminishes with $k$, and for the fast gradient method, there is no error accumulation for $q \geq 2/3$. It proposed a definition of an inexact higher degree oracle for strongly convex functions and a projected gradient method using this inexact oracle. For variational inequalities and saddle point problems, a higher degree inexact model and an adaptive method called Generalized Mirror Prox to solve such class of problems using the proposed inexact model were proposed. Some numerical experiments were conducted to demonstrate the effectiveness of the proposed inexact model, we test the universal fast gradient method to solve some non-smooth problems with a geometrical nature.</description>
      <guid isPermaLink="false">oai:arXiv.org:2405.16140v1</guid>
      <category>math.OC</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Mohammad Alkousa, Fedor Stonyakin, Alexander Gasnikov, Asmaa Abdo, Mohammad Alcheikh</dc:creator>
    </item>
    <item>
      <title>Restarted Primal-Dual Hybrid Conjugate Gradient Method for Large-Scale Quadratic Programming</title>
      <link>https://arxiv.org/abs/2405.16160</link>
      <description>arXiv:2405.16160v1 Announce Type: new 
Abstract: Convex quadratic programming (QP) is an essential class of optimization problems with broad applications across various fields. Traditional QP solvers, typically based on simplex or barrier methods, face significant scalability challenges. In response to these limitations, recent research has shifted towards matrix-free first-order methods to enhance scalability in QP. Among these, the restarted accelerated primal-dual hybrid gradient (rAPDHG) method, proposed by H.Lu(2023), has gained notable attention due to its linear convergence rate to an optimal solution and its straightforward implementation on Graphics Processing Units (GPUs). Building on this framework, this paper introduces a restarted primal-dual hybrid conjugate gradient (PDHCG) method, which incorporates conjugate gradient (CG) techniques to address the primal subproblems inexactly. We demonstrate that PDHCG maintains a linear convergence rate with an improved convergence constant and is also straightforward to implement on GPUs. Extensive numerical experiments affirm that, compared to rAPDHG, our method could significantly reduce the number of iterations required to achieve the desired accuracy and offer a substantial performance improvement in large-scale problems. These findings highlight the significant potential of our proposed PDHCG method to boost both the efficiency and scalability of solving complex QP challenges.</description>
      <guid isPermaLink="false">oai:arXiv.org:2405.16160v1</guid>
      <category>math.OC</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Yicheng Huang, Wanyu Zhang, Hongpei Li, Weihan Xue, Dongdong Ge, Huikang Liu, Yinyu Ye</dc:creator>
    </item>
    <item>
      <title>On the Optimal Time Complexities in Decentralized Stochastic Asynchronous Optimization</title>
      <link>https://arxiv.org/abs/2405.16218</link>
      <description>arXiv:2405.16218v1 Announce Type: new 
Abstract: We consider the decentralized stochastic asynchronous optimization setup, where many workers asynchronously calculate stochastic gradients and asynchronously communicate with each other using edges in a multigraph. For both homogeneous and heterogeneous setups, we prove new time complexity lower bounds under the assumption that computation and communication speeds are bounded. We develop a new nearly optimal method, Fragile SGD, and a new optimal method, Amelie SGD, that converge under arbitrary heterogeneous computation and communication speeds and match our lower bounds (up to a logarithmic factor in the homogeneous setting). Our time complexities are new, nearly optimal, and provably improve all previous asynchronous/synchronous stochastic methods in the decentralized setup.</description>
      <guid isPermaLink="false">oai:arXiv.org:2405.16218v1</guid>
      <category>math.OC</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Alexander Tyurin, Peter Richt\'arik</dc:creator>
    </item>
    <item>
      <title>Near Optimality of Lipschitz and Smooth Policies in Controlled Diffusions</title>
      <link>https://arxiv.org/abs/2405.16223</link>
      <description>arXiv:2405.16223v1 Announce Type: new 
Abstract: For optimal control of diffusions under several criteria, due to computational or analytical reasons, many studies have a apriori assumed control policies to be Lipschitz or smooth, often with no rigorous analysis on whether this restriction entails loss. While optimality of Markov/stationary Markov policies for expected finite horizon/infinite horizon (discounted/ergodic) cost and cost-up-to-exit time optimal control problems can be established under certain technical conditions, an optimal solution is typically only measurable in the state (and time, if the horizon is finite) with no apriori additional structural properties. In this paper, building on our recent work [S. Pradhan and S. Y\"uksel, Continuity of cost in Borkar control topology and implications on discrete space and time approximations for controlled diffusions under several criteria, Electronic Journal of Probability (2024)] establishing the regularity of optimal cost on the space of control policies under the Borkar control topology for a general class of diffusions, we establish near optimality of smooth/Lipschitz continuous policies for optimal control under expected finite horizon, infinite horizon discounted/average, and up-to-exit time cost criteria. Under mild assumptions, we first show that smooth/Lipschitz continuous policies are dense in the space of Markov/stationary Markov policies under the Borkar topology. Then utilizing the continuity of optimal costs as a function of policies on the space of Markov/stationary policies under the Borkar topology, we establish that optimal policies can be approximated by smooth/Lipschitz continuous policies with arbitrary precision. While our results are extensions of our recent work, the practical significance of an explicit statement and accessible presentation dedicated to Lipschitz and smooth policies, given their prominence in the literature, motivates our current paper.</description>
      <guid isPermaLink="false">oai:arXiv.org:2405.16223v1</guid>
      <category>math.OC</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Somnath Pradhan, Serdar Yuksel</dc:creator>
    </item>
    <item>
      <title>Unlabeled Sensing Using Rank-One Moment Matrix Completion</title>
      <link>https://arxiv.org/abs/2405.16407</link>
      <description>arXiv:2405.16407v1 Announce Type: new 
Abstract: We study the unlabeled sensing problem that aims to solve a linear system of equations $A x =\pi(y) $ for an unknown permutation $\pi$. For a generic matrix $A$ and a generic vector $y$, we construct a system of polynomial equations whose unique solution satisfies $ A\xi^*=\pi(y)$. In particular, $\xi^*$ can be recovered by solving the rank-one moment matrix completion problem. We propose symbolic and numeric algorithms to compute the unique solution. Some numerical experiments are conducted to show the efficiency and robustness of the proposed algorithms.</description>
      <guid isPermaLink="false">oai:arXiv.org:2405.16407v1</guid>
      <category>math.OC</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Hao Liang, Jingyu Lu, Manolis C. Tsakiris, Lihong Zhi</dc:creator>
    </item>
    <item>
      <title>Formalising the intentional stance: attributing goals and beliefs to stochastic processes</title>
      <link>https://arxiv.org/abs/2405.16490</link>
      <description>arXiv:2405.16490v1 Announce Type: new 
Abstract: We are concerned with the behaviour of stochastic systems with inputs and outputs, and how this might relate to the pursuit of a goal. We model this using what we term transducers, which are a mathematical object that captures only the external behaviour of such a system and not its internal state. We present a framework for reasoning about the optimality of such a process, when it is coupled to a 'teleo-environment' consisting of another transducer that also embodies a success criterion. We find that (globally) optimal transducers have a property closely related to Bellman's theorem: a transducer that is optimal in one time step will again be optimal in the next time step, but with respect to a different environment (obtained from the original one by a modified version of Bayesian filtering). We also consider bounded rationality and its relationship to constrained optimality, which in our framework means optimal within some subset of all transducers. We describe a condition that is sufficient for such a subset to have this Bellman property. Additionally, we show that a policy is deterministic if and only if there exists a teleo-envionment for which it is uniquely optimal among the set of all transducers; this is at least conceptually related to classical representation theorems from decision theory. This need not hold for constrained subsets; we give an example of this related to the so-called absent-minded driver problem. All of the formalism is defined using coinduction, following the style proposed by Czajka [9].</description>
      <guid isPermaLink="false">oai:arXiv.org:2405.16490v1</guid>
      <category>math.OC</category>
      <category>cs.SY</category>
      <category>eess.SY</category>
      <category>math.PR</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Simon McGregor,  timorl, Nathaniel Virgo</dc:creator>
    </item>
    <item>
      <title>A Complete Inverse Optimality Study for a Tank-Liquid System</title>
      <link>https://arxiv.org/abs/2405.16535</link>
      <description>arXiv:2405.16535v1 Announce Type: new 
Abstract: This paper presents a complete inverse optimality study for a linearized tank-liquid system where the liquid is described by the viscous Saint-Venant model with surface tension and possible wall friction. We define an appropriate weak solution notion for which we establish existence/uniqueness results with inputs that do not necessarily satisfy any compatibility condition as well as stabilization results with feedback laws that are constructed with the help of a Control Lyapunov Functional. We show that the proposed family of stabilizing feedback laws is optimal for a certain meaningful quadratic cost functional. Finally, we show that the optimal feedback law guarantees additional stronger stability estimates which are similar to those obtained in the case of classical solutions.</description>
      <guid isPermaLink="false">oai:arXiv.org:2405.16535v1</guid>
      <category>math.OC</category>
      <category>cs.SY</category>
      <category>eess.SY</category>
      <category>math.AP</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Iasson Karafyllis, Filippos Vokos, Miroslav Krstic</dc:creator>
    </item>
    <item>
      <title>Local Curvature Descent: Squeezing More Curvature out of Standard and Polyak Gradient Descent</title>
      <link>https://arxiv.org/abs/2405.16574</link>
      <description>arXiv:2405.16574v1 Announce Type: new 
Abstract: We contribute to the growing body of knowledge on more powerful and adaptive stepsizes for convex optimization, empowered by local curvature information. We do not go the route of fully-fledged second-order methods which require the expensive computation of the Hessian. Instead, our key observation is that, for some problems (e.g., when minimizing the sum of squares of absolutely convex functions), certain local curvature information is readily available, and can be used to obtain surprisingly powerful matrix-valued stepsizes, and meaningful theory. In particular, we develop three new methods$\unicode{x2013}$LCD1, LCD2 and LCD3$\unicode{x2013}$where the abbreviation stands for local curvature descent. While LCD1 generalizes gradient descent with fixed stepsize, LCD2 generalizes gradient descent with Polyak stepsize. Our methods enhance these classical gradient descent baselines with local curvature information, and our theory recovers the known rates in the special case when no curvature information is used. Our last method, LCD3, is a variable metric version of LCD2; this feature leads to a closed-form expression for the iterates. Our empirical results are encouraging, and show that the local curvature descent improves upon gradient descent.</description>
      <guid isPermaLink="false">oai:arXiv.org:2405.16574v1</guid>
      <category>math.OC</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Peter Richt\'arik, Simone Maria Giancola, Dymitr Lubczyk, Robin Yadav</dc:creator>
    </item>
    <item>
      <title>Decision support for sustainable forest harvest planning using multi-scenario multiobjective robust optimization</title>
      <link>https://arxiv.org/abs/2405.16612</link>
      <description>arXiv:2405.16612v1 Announce Type: new 
Abstract: Sustainable forest management requires handling uncertainty introduced from various sources, considering different conflicting economic, environmental, and social objectives, and involving multiple decision-making periods. This study proposes an interactive and intuitive decision-support approach for sustainable, robust forest harvest scheduling in multiple periods in a short-term (6-12 months) planning horizon. The approach includes a novel multi-scenario multiobjective mixed-integer optimization problem that allows forest planners to separately study the trade-offs between demand satisfactions for multiple assortments in different planning periods. Moreover, it provides an intuitive robust analysis to support forest planners in dealing with uncertainty and investigating potential variations of the outcomes as the consequences of uncertainty in tactical forest planning problems. We validate the proposed decision-support approach in a Swedish case study with 250 forest stands, three assortments (pine, spruce, deciduous trees), and a twelve-month harvest planning horizon. We demonstrate how the proposed approach supports a forest practitioner in trade-offs and robust analyses and finding the most preferred robust solution.</description>
      <guid isPermaLink="false">oai:arXiv.org:2405.16612v1</guid>
      <category>math.OC</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Babooshka Shavazipour, Lovisa Engberg Sundstr\"om</dc:creator>
    </item>
    <item>
      <title>An efficient optimization model and tabu search-based global optimization approach for continuous p-dispersion problem</title>
      <link>https://arxiv.org/abs/2405.16618</link>
      <description>arXiv:2405.16618v1 Announce Type: new 
Abstract: Continuous p-dispersion problems with and without boundary constraints are NP-hard optimization problems with numerous real-world applications, notably in facility location and circle packing, which are widely studied in mathematics and operations research. In this work, we concentrate on general cases with a non-convex multiply-connected region that are rarely studied in the literature due to their intractability and the absence of an efficient optimization model. Using the penalty function approach, we design a unified and almost everywhere differentiable optimization model for these complex problems and propose a tabu search-based global optimization (TSGO) algorithm for solving them. Computational results over a variety of benchmark instances show that the proposed model works very well, allowing popular local optimization methods (e.g., the quasi-Newton methods and the conjugate gradient methods) to reach high-precision solutions due to the differentiability of the model. These results further demonstrate that the proposed TSGO algorithm is very efficient and significantly outperforms several popular global optimization algorithms in the literature, improving the best-known solutions for several existing instances in a short computational time. Experimental analyses are conducted to show the influence of several key ingredients of the algorithm on computational performance.</description>
      <guid isPermaLink="false">oai:arXiv.org:2405.16618v1</guid>
      <category>math.OC</category>
      <category>cs.DM</category>
      <category>cs.MS</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Xiangjing Lai, Zhenheng Lin, Jin-Kao Hao, Qinghua Wu</dc:creator>
    </item>
    <item>
      <title>Six-Degree-of-Freedom Aircraft Landing Trajectory Planning with Runway Alignment</title>
      <link>https://arxiv.org/abs/2405.16680</link>
      <description>arXiv:2405.16680v1 Announce Type: new 
Abstract: This paper presents a numerical optimization algorithm for generating approach and landing trajectories for a six-degree-of-freedom (6-DoF) aircraft. We improve on the existing research on aircraft landing trajectory generation by formulating the trajectory optimization problem with additional real-world operational constraints, including 6-DoF aircraft dynamics, runway alignment, constant wind field, and obstacle avoidance, to obtain a continuous-time nonconvex optimal control problem. Particularly, the runway alignment constraint enforces the trajectory of the aircraft to be aligned with the runway only during the final approach phase. This is a novel feature that is essential for preventing an approach that is either too steep or too shallow. The proposed method models the runway alignment constraint through a multi-phase trajectory planning scheme, imposing alignment conditions exclusively during the final approach phase. We compare this formulation with the existing state-triggered constraint formulation for runway alignment. To solve the formulated problem, we design a novel sequential convex programming algorithm called xPTR that extends the penalized trust-region (PTR) algorithm by incorporating an extrapolation step to expedite convergence. We validate the proposed method through extensive numerical simulations, including a Monte Carlo study, to evaluate the robustness of the algorithm to varying initial conditions.</description>
      <guid isPermaLink="false">oai:arXiv.org:2405.16680v1</guid>
      <category>math.OC</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Taewan Kim, Abhinav G. Kamath, Niyousha Rahimi, Jasper Corleis, Beh\c{c}et A\c{c}{\i}kme\c{s}e, Mehran Mesbahi</dc:creator>
    </item>
    <item>
      <title>Delay Performance Analysis of Delay-Deterministic Wireless Networks with Infinite and Finite Blocklength Transmission</title>
      <link>https://arxiv.org/abs/2405.16840</link>
      <description>arXiv:2405.16840v1 Announce Type: new 
Abstract: In order to achieve stable and reliable industrial manufacturing, wireless networks must meet the stringent communication requirements of industrial automation, particularly the need for deterministic low latency communication. The limited wireless resources and time-varying fading channel contribute to the random fluctuations of transmission delay, making it challenging to realize delay-deterministic wireless networks. An open challenge in this context is to model delay determinism, also known as jitter, and analyze delay performance. In this paper, we model jitter as the variance of delay and conduct a comprehensive analysis of delay performance. Specifically, we consider two transmission regimes: infinite blocklength (IBL) and finite blocklength (FBL). In the IBL regime, the distribution of the transmission delay is analyzed, and the closed-form expressions for the average delay, jitter, and delay violation probability are derived. In the FBL regime, an upper bound on the transmission delay is first approximated at a high signalto-noise ratio. Based on this upper bound, the delay distribution, delay violation probability, average delay, and jitter are derived. Finally, simulation results are provided to validate the accuracy of the analysis and derivations. Additionally, the impact of system parameters on jitter is analyzed to gain further insights.</description>
      <guid isPermaLink="false">oai:arXiv.org:2405.16840v1</guid>
      <category>math.OC</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Hanxue Ding, Shaoyi Xu, Ziheng Xu, Rongtao Xu, Zonghui Li, Junhui Zhao</dc:creator>
    </item>
    <item>
      <title>Distributed Riemannian Stochastic Gradient Tracking Algorithm on the Stiefel Manifold</title>
      <link>https://arxiv.org/abs/2405.16900</link>
      <description>arXiv:2405.16900v1 Announce Type: new 
Abstract: This paper focus on investigating the distributed Riemannian stochastic optimization problem on the Stiefel manifold for multi-agent systems, where all the agents work collaboratively to optimize a function modeled by the average of their expectation-valued local costs. Each agent only processes its own local cost function and communicate with neighboring agents to achieve optimal results while ensuring consensus. Since the local Riemannian gradient in stochastic regimes cannot be directly calculated, we will estimate the gradient by the average of a variable number of sampled gradient, which however brings about noise to the system. We then propose a distributed Riemannian stochastic optimization algorithm on the Stiefel manifold by combining the variable sample size gradient approximation method with the gradient tracking dynamic. It is worth noticing that the suitably chosen increasing sample size plays an important role in improving the algorithm efficiency, as it reduces the noise variance. In an expectation-valued sense, the iterates of all agents are proved to converge to a stationary point (or neighborhood) with fixed step sizes. We further establish the convergence rate of the iterates for the cases when the sample size is exponentially increasing, polynomial increasing, or a constant, respectively. Finally, numerical experiments are implemented to demonstrate the theoretical results.</description>
      <guid isPermaLink="false">oai:arXiv.org:2405.16900v1</guid>
      <category>math.OC</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Jishu Zhao, Xi Wang, Jinlong Lei</dc:creator>
    </item>
    <item>
      <title>Kaczmarz Projection Algorithms in Moving Window: Performance Improvement via Extended Orthogonality &amp; Forgetting</title>
      <link>https://arxiv.org/abs/2405.16903</link>
      <description>arXiv:2405.16903v1 Announce Type: new 
Abstract: New Kaczmarz algorithms with rank two gain update, extended orthogonality property and forgetting mechanism which includes both exponential and instantaneous forgetting (implemented via a proper choice of the forgetting factor and the window size) are introduced and associated in this report with well-known Kaczmarz algorithms with rank one update.</description>
      <guid isPermaLink="false">oai:arXiv.org:2405.16903v1</guid>
      <category>math.OC</category>
      <category>cs.NA</category>
      <category>math.DS</category>
      <category>math.NA</category>
      <category>math.SP</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <arxiv:DOI>10.1007/s11265-024-01915-w</arxiv:DOI>
      <dc:creator>Alexander Stotsky</dc:creator>
    </item>
    <item>
      <title>Convergence of SGD with momentum in the nonconvex case: A novel time window-based analysis</title>
      <link>https://arxiv.org/abs/2405.16954</link>
      <description>arXiv:2405.16954v1 Announce Type: new 
Abstract: We propose a novel time window-based analysis technique to investigate the convergence behavior of the stochastic gradient descent method with momentum (SGDM) in nonconvex settings. Despite its popularity, the convergence behavior of SGDM remains less understood in nonconvex scenarios. This is primarily due to the absence of a sufficient descent property and challenges in controlling stochastic errors in an almost sure sense. To address these challenges, we study the behavior of SGDM over specific time windows, rather than examining the descent of consecutive iterates as in traditional analyses. This time window-based approach simplifies the convergence analysis and enables us to establish the first iterate convergence result for SGDM under the Kurdyka-Lojasiewicz (KL) property. Based on the underlying KL exponent and the utilized step size scheme, we further characterize local convergence rates of SGDM.</description>
      <guid isPermaLink="false">oai:arXiv.org:2405.16954v1</guid>
      <category>math.OC</category>
      <category>cs.LG</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Junwen Qiu, Bohao Ma, Andre Milzarek</dc:creator>
    </item>
    <item>
      <title>Analysis of Multiscale Reinforcement Q-Learning Algorithms for Mean Field Control Games</title>
      <link>https://arxiv.org/abs/2405.17017</link>
      <description>arXiv:2405.17017v1 Announce Type: new 
Abstract: Mean Field Control Games (MFCG), introduced in [Angiuli et al., 2022a], represent competitive games between a large number of large collaborative groups of agents in the infinite limit of number and size of groups. In this paper, we prove the convergence of a three-timescale Reinforcement Q-Learning (RL) algorithm to solve MFCG in a model-free approach from the point of view of representative agents. Our analysis uses a Q-table for finite state and action spaces updated at each discrete time-step over an infinite horizon. In [Angiuli et al., 2023], we proved convergence of two-timescale algorithms for MFG and MFC separately highlighting the need to follow multiple population distributions in the MFC case. Here, we integrate this feature for MFCG as well as three rates of update decreasing to zero in the proper ratios. Our technique of proof uses a generalization to three timescales of the two-timescale analysis in [Borkar, 1997]. We give a simple example satisfying the various hypothesis made in the proof of convergence and illustrating the performance of the algorithm.</description>
      <guid isPermaLink="false">oai:arXiv.org:2405.17017v1</guid>
      <category>math.OC</category>
      <category>cs.LG</category>
      <category>cs.MA</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Andrea Angiuli, Jean-Pierre Fouque, Mathieu Lauri\`ere, Mengrui Zhang</dc:creator>
    </item>
    <item>
      <title>Inverse reinforcement learning by expert imitation for the stochastic linear-quadratic optimal control problem</title>
      <link>https://arxiv.org/abs/2405.17085</link>
      <description>arXiv:2405.17085v1 Announce Type: new 
Abstract: This article studies inverse reinforcement learning (IRL) for the stochastic linear-quadratic optimal control problem, where two agents are considered. A learner agent does not know the expert agent's performance cost function, but it imitates the behavior of the expert agent by constructing an underlying cost function that obtains the same optimal feedback control as the expert's. We first develop a model-based IRL algorithm, which consists of a policy correction and a policy update from the policy iteration in reinforcement learning, as well as a cost function weight reconstruction based on the inverse optimal control. Then, under this scheme, we propose a model-free off-policy IRL algorithm, which does not need to know or identify the system and only needs to collect the behavior data of the expert agent and learner agent once during the iteration process. Moreover, the proofs of the algorithm's convergence, stability, and non-unique solutions are given. Finally, a simulation example is provided to verify the effectiveness of the proposed algorithm.</description>
      <guid isPermaLink="false">oai:arXiv.org:2405.17085v1</guid>
      <category>math.OC</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Zhongshi Sun, Guangyan Jia</dc:creator>
    </item>
    <item>
      <title>Analysing the interactions between demand side and supply side investment decisions in an oligopolistic electricity market using a stochastic mixed complementarity problem</title>
      <link>https://arxiv.org/abs/2405.17223</link>
      <description>arXiv:2405.17223v1 Announce Type: new 
Abstract: To meet carbon emission targets, governments around the world seek electricity consumers to invest in self-sufficiency technologies such as solar photovoltaic and battery storage. Such behaviour is sought in markets typically characterised by an oligopoly amongst generating firms. In this work, we study the interactions between investment decisions on the demand side and the supply side, and we investigate how price-making behaviour on the supply side affects these interactions compared to a situation with perfect competition. To do so, we introduce a novel stochastic mixed complementarity problem to model several players in an oligopolistic electricity market. On the supply side, we consider generating firms who make operational and investment decisions. On the demand side, we consider both industrial and residential consumers, each of whom may invest in self-sufficiency technologies. The uncertainties of wind and solar generation are the sources of the model's stochasticity. We apply the model to a case study of a stylised Irish electricity system in 2030. Our results demonstrate that price-making on the supply side increases investment in self-sufficiency on the demand side, leading to a reduction in prices and carbon emissions. We also find that both market power and self-sufficiency alter the investment and decommissioning decisions made by generation firms. Counter-intuitively, we also observe that the absence of a feed-in premium increases investment in solar generation on the demand side. Our findings highlight the importance of including both demand and supply side investment in models of electricity markets characterised by an oligopoly.</description>
      <guid isPermaLink="false">oai:arXiv.org:2405.17223v1</guid>
      <category>math.OC</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>M. T. Devine, V. Bertsch</dc:creator>
    </item>
    <item>
      <title>Measuring Exploration: Review and Systematic Evaluation of Modelling to Generate Alternatives Methods in Macro-Energy Systems Planning Models</title>
      <link>https://arxiv.org/abs/2405.17342</link>
      <description>arXiv:2405.17342v1 Announce Type: new 
Abstract: As decarbonization agendas mature, macro-energy systems modelling studies have increasingly focused on enhanced decision support methods that move beyond least-cost modelling to improve consideration of additional objectives and tradeoffs. One candidate is Modeling to Generate Alternatives (MGA), which systematically explores new objectives without explicit stakeholder elicitation. Previous literature lacks both a comprehensive review of MGA vector selection methods in large-scale energy system models and comparative testing of their relative efficacies in this setting. To fill this gap, this paper provides a comprehensive review of the MGA literature, identifying at least seven MGA vector selection methodologies and carrying out a systematic evaluation of four: Hop-Skip-Jump, Random Vector, Variable Min/Max, and Modelling All Alternatives. We examine each method's runtime, parallelizability, new solution discovery efficiency, and spatial exploration in lower dimensional (N &lt;= 100) spaces, as well as spatial exploration in a three-zone, 8760-hour capacity expansion model case. Through these tests, we find Random Vector provides the broadest exploration of the near-optimal feasible region and Variable Min/Max provides the most extreme results, while the two tie on computational speed. We thus propose a new Hybrid vector selection approach combining the two methods to take advantage of the strengths of each. Additional analysis is provided on MGA variable selection, in which we demonstrate MGA problems formulated over generation variables fail to retain cost-optimal dispatch and are thus not reflective of real operations of equivalent hypothetical capacity choices. As such, we recommend future studies utilize a parallelized combined vector approach over the set of capacity variables for best results in computational speed and spatial exploration while retaining optimal dispatch.</description>
      <guid isPermaLink="false">oai:arXiv.org:2405.17342v1</guid>
      <category>math.OC</category>
      <category>cs.SY</category>
      <category>eess.SY</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <arxiv:DOI>10.5281/zenodo.11088681</arxiv:DOI>
      <dc:creator>Michael Lau, Neha Patankar, Jesse D. Jenkins</dc:creator>
    </item>
    <item>
      <title>Remarks on potential mean field games</title>
      <link>https://arxiv.org/abs/2405.15921</link>
      <description>arXiv:2405.15921v1 Announce Type: cross 
Abstract: In this expository article, we give an overview of the concept of potential mean field games of first order. We give a new proof that minimizers of the potential are equilibria by using a Lagrangian formulation. We also provide criteria to determine whether or not a game has a potential. Finally, we discuss in some depth the selection problem in mean field games, which consists in choosing one out of multiple Nash equilibria.</description>
      <guid isPermaLink="false">oai:arXiv.org:2405.15921v1</guid>
      <category>math.AP</category>
      <category>math.OC</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>P. Jameson Graber</dc:creator>
    </item>
    <item>
      <title>Does SGD really happen in tiny subspaces?</title>
      <link>https://arxiv.org/abs/2405.16002</link>
      <description>arXiv:2405.16002v1 Announce Type: cross 
Abstract: Understanding the training dynamics of deep neural networks is challenging due to their high-dimensional nature and intricate loss landscapes. Recent studies have revealed that, along the training trajectory, the gradient approximately aligns with a low-rank top eigenspace of the training loss Hessian, referred to as the dominant subspace. Given this alignment, this paper explores whether neural networks can be trained within the dominant subspace, which, if feasible, could lead to more efficient training methods. Our primary observation is that when the SGD update is projected onto the dominant subspace, the training loss does not decrease further. This suggests that the observed alignment between the gradient and the dominant subspace is spurious. Surprisingly, projecting out the dominant subspace proves to be just as effective as the original update, despite removing the majority of the original update component. Similar observations are made for the large learning rate regime (also known as Edge of Stability) and Sharpness-Aware Minimization. We discuss the main causes and implications of this spurious alignment, shedding light on the intricate dynamics of neural network training.</description>
      <guid isPermaLink="false">oai:arXiv.org:2405.16002v1</guid>
      <category>cs.LG</category>
      <category>math.OC</category>
      <category>stat.ML</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Minhak Song, Kwangjun Ahn, Chulhee Yun</dc:creator>
    </item>
    <item>
      <title>Existence and nonexistence of solutions for underdetermined generalized absolute value equations</title>
      <link>https://arxiv.org/abs/2405.16172</link>
      <description>arXiv:2405.16172v1 Announce Type: cross 
Abstract: Underdetermined generalized absolute value equations (GAVE) has real applications. The underdetermined GAVE may have no solution, one solution, finitely multiple solutions or infinitely many solutions. This paper aims to give some sufficient conditions which guarantee the existence or nonexistence of solutions for the underdetermined GAVE. Particularly, sufficient conditions under which certain or each sign pattern possesses infinitely many solutions of the underdetermined GAVE are given. In addition, iterative methods are developed to solve a solution of the underdetermined GAVE. Some existing results about the square GAVE are extended.</description>
      <guid isPermaLink="false">oai:arXiv.org:2405.16172v1</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <category>math.OC</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Cairong Chen, Xuehua Li, Ren-Cang Li</dc:creator>
    </item>
    <item>
      <title>GeoAdaLer: Geometric Insights into Adaptive Stochastic Gradient Descent Algorithms</title>
      <link>https://arxiv.org/abs/2405.16255</link>
      <description>arXiv:2405.16255v1 Announce Type: cross 
Abstract: The Adam optimization method has achieved remarkable success in addressing contemporary challenges in stochastic optimization. This method falls within the realm of adaptive sub-gradient techniques, yet the underlying geometric principles guiding its performance have remained shrouded in mystery, and have long confounded researchers. In this paper, we introduce GeoAdaLer (Geometric Adaptive Learner), a novel adaptive learning method for stochastic gradient descent optimization, which draws from the geometric properties of the optimization landscape. Beyond emerging as a formidable contender, the proposed method extends the concept of adaptive learning by introducing a geometrically inclined approach that enhances the interpretability and effectiveness in complex optimization scenarios</description>
      <guid isPermaLink="false">oai:arXiv.org:2405.16255v1</guid>
      <category>cs.LG</category>
      <category>math.OC</category>
      <category>stat.ML</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Chinedu Eleh, Masuzyo Mwanza, Ekene Aguegboh, Hans-Werner van Wyk</dc:creator>
    </item>
    <item>
      <title>AdaFisher: Adaptive Second Order Optimization via Fisher Information</title>
      <link>https://arxiv.org/abs/2405.16397</link>
      <description>arXiv:2405.16397v1 Announce Type: cross 
Abstract: First-order optimization methods are currently the mainstream in training deep neural networks (DNNs). Optimizers like Adam incorporate limited curvature information by employing the diagonal matrix preconditioning of the stochastic gradient during the training. Despite their widespread, second-order optimization algorithms exhibit superior convergence properties compared to their first-order counterparts e.g. Adam and SGD. However, their practicality in training DNNs are still limited due to increased per-iteration computations and suboptimal accuracy compared to the first order methods. We present AdaFisher--an adaptive second-order optimizer that leverages a block-diagonal approximation to the Fisher information matrix for adaptive gradient preconditioning. AdaFisher aims to bridge the gap between enhanced convergence capabilities and computational efficiency in second-order optimization framework for training DNNs. Despite the slow pace of second-order optimizers, we showcase that AdaFisher can be reliably adopted for image classification, language modelling and stand out for its stability and robustness in hyperparameter tuning. We demonstrate that AdaFisher outperforms the SOTA optimizers in terms of both accuracy and convergence speed. Code available from \href{https://github.com/AtlasAnalyticsLab/AdaFisher}{https://github.com/AtlasAnalyticsLab/AdaFisher}</description>
      <guid isPermaLink="false">oai:arXiv.org:2405.16397v1</guid>
      <category>cs.LG</category>
      <category>math.OC</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Damien Martins Gomes, Yanlei Zhang, Eugene Belilovsky, Guy Wolf, Mahdi S. Hosseini</dc:creator>
    </item>
    <item>
      <title>Reinforcement Learning for Jump-Diffusions</title>
      <link>https://arxiv.org/abs/2405.16449</link>
      <description>arXiv:2405.16449v1 Announce Type: cross 
Abstract: We study continuous-time reinforcement learning (RL) for stochastic control in which system dynamics are governed by jump-diffusion processes. We formulate an entropy-regularized exploratory control problem with stochastic policies to capture the exploration--exploitation balance essential for RL. Unlike the pure diffusion case initially studied by Wang et al. (2020), the derivation of the exploratory dynamics under jump-diffusions calls for a careful formulation of the jump part. Through a theoretical analysis, we find that one can simply use the same policy evaluation and q-learning algorithms in Jia and Zhou (2022a, 2023), originally developed for controlled diffusions, without needing to check a priori whether the underlying data come from a pure diffusion or a jump-diffusion. However, we show that the presence of jumps ought to affect parameterizations of actors and critics in general. Finally, we investigate as an application the mean-variance portfolio selection problem with stock price modelled as a jump-diffusion, and show that both RL algorithms and parameterizations are invariant with respect to jumps.</description>
      <guid isPermaLink="false">oai:arXiv.org:2405.16449v1</guid>
      <category>cs.LG</category>
      <category>math.OC</category>
      <category>q-fin.MF</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Xuefeng Gao, Lingfei Li, Xun Yu Zhou</dc:creator>
    </item>
    <item>
      <title>A probabilistic approach to continuous differentiability of optimal stopping boundaries</title>
      <link>https://arxiv.org/abs/2405.16636</link>
      <description>arXiv:2405.16636v1 Announce Type: cross 
Abstract: We obtain the first probabilistic proof of continuous differentiability of time-dependent optimal boundaries in optimal stopping problems. The underlying stochastic dynamics is a one-dimensional, time-inhomogeneous diffusion. The gain function is also time-inhomogeneous and not necessarily smooth. Moreover, we include state-dependent discount rate and the time-horizon can be either finite or infinite. Our arguments of proof are of a local nature that allows us to obtain the result under more general conditions than those used in the PDE literature. As a byproduct of our main result we also obtain the first probabilistic proof of the link between the value function of an optimal stopping problem and the solution of the Stefan's problem.</description>
      <guid isPermaLink="false">oai:arXiv.org:2405.16636v1</guid>
      <category>math.PR</category>
      <category>math.OC</category>
      <category>q-fin.MF</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Tiziano De Angelis, Damien Lamberton</dc:creator>
    </item>
    <item>
      <title>Gaussian Approximation and Multiplier Bootstrap for Polyak-Ruppert Averaged Linear Stochastic Approximation with Applications to TD Learning</title>
      <link>https://arxiv.org/abs/2405.16644</link>
      <description>arXiv:2405.16644v1 Announce Type: cross 
Abstract: In this paper, we obtain the Berry-Esseen bound for multivariate normal approximation for the Polyak-Ruppert averaged iterates of the linear stochastic approximation (LSA) algorithm with decreasing step size. Our findings reveal that the fastest rate of normal approximation is achieved when setting the most aggressive step size $\alpha_{k} \asymp k^{-1/2}$. Moreover, we prove the non-asymptotic validity of the confidence intervals for parameter estimation with LSA based on multiplier bootstrap. This procedure updates the LSA estimate together with a set of randomly perturbed LSA estimates upon the arrival of subsequent observations. We illustrate our findings in the setting of temporal difference learning with linear function approximation.</description>
      <guid isPermaLink="false">oai:arXiv.org:2405.16644v1</guid>
      <category>stat.ML</category>
      <category>cs.LG</category>
      <category>math.OC</category>
      <category>math.PR</category>
      <category>math.ST</category>
      <category>stat.TH</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Sergey Samsonov, Eric Moulines, Qi-Man Shao, Zhuo-Song Zhang, Alexey Naumov</dc:creator>
    </item>
    <item>
      <title>The Collusion of Memory and Nonlinearity in Stochastic Approximation With Constant Stepsize</title>
      <link>https://arxiv.org/abs/2405.16732</link>
      <description>arXiv:2405.16732v1 Announce Type: cross 
Abstract: In this work, we investigate stochastic approximation (SA) with Markovian data and nonlinear updates under constant stepsize $\alpha&gt;0$. Existing work has primarily focused on either i.i.d. data or linear update rules. We take a new perspective and carefully examine the simultaneous presence of Markovian dependency of data and nonlinear update rules, delineating how the interplay between these two structures leads to complications that are not captured by prior techniques. By leveraging the smoothness and recurrence properties of the SA updates, we develop a fine-grained analysis of the correlation between the SA iterates $\theta_k$ and Markovian data $x_k$. This enables us to overcome the obstacles in existing analysis and establish for the first time the weak convergence of the joint process $(x_k, \theta_k)_{k\geq0}$. Furthermore, we present a precise characterization of the asymptotic bias of the SA iterates, given by $\mathbb{E}[\theta_\infty]-\theta^\ast=\alpha(b_\text{m}+b_\text{n}+b_\text{c})+O(\alpha^{3/2})$. Here, $b_\text{m}$ is associated with the Markovian noise, $b_\text{n}$ is tied to the nonlinearity, and notably, $b_\text{c}$ represents a multiplicative interaction between the Markovian noise and nonlinearity, which is absent in previous works. As a by-product of our analysis, we derive finite-time bounds on higher moment $\mathbb{E}[\|\theta_k-\theta^\ast\|^{2p}]$ and present non-asymptotic geometric convergence rates for the iterates, along with a Central Limit Theorem.</description>
      <guid isPermaLink="false">oai:arXiv.org:2405.16732v1</guid>
      <category>stat.ML</category>
      <category>cs.LG</category>
      <category>math.OC</category>
      <category>math.ST</category>
      <category>stat.TH</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Dongyan Huo, Yixuan Zhang, Yudong Chen, Qiaomin Xie</dc:creator>
    </item>
    <item>
      <title>Dual-Delayed Asynchronous SGD for Arbitrarily Heterogeneous Data</title>
      <link>https://arxiv.org/abs/2405.16966</link>
      <description>arXiv:2405.16966v1 Announce Type: cross 
Abstract: We consider the distributed learning problem with data dispersed across multiple workers under the orchestration of a central server. Asynchronous Stochastic Gradient Descent (SGD) has been widely explored in such a setting to reduce the synchronization overhead associated with parallelization. However, the performance of asynchronous SGD algorithms often depends on a bounded dissimilarity condition among the workers' local data, a condition that can drastically affect their efficiency when the workers' data are highly heterogeneous. To overcome this limitation, we introduce the \textit{dual-delayed asynchronous SGD (DuDe-ASGD)} algorithm designed to neutralize the adverse effects of data heterogeneity. DuDe-ASGD makes full use of stale stochastic gradients from all workers during asynchronous training, leading to two distinct time lags in the model parameters and data samples utilized in the server's iterations. Furthermore, by adopting an incremental aggregation strategy, DuDe-ASGD maintains a per-iteration computational cost that is on par with traditional asynchronous SGD algorithms. Our analysis demonstrates that DuDe-ASGD achieves a near-minimax-optimal convergence rate for smooth nonconvex problems, even when the data across workers are extremely heterogeneous. Numerical experiments indicate that DuDe-ASGD compares favorably with existing asynchronous and synchronous SGD-based algorithms.</description>
      <guid isPermaLink="false">oai:arXiv.org:2405.16966v1</guid>
      <category>cs.LG</category>
      <category>math.OC</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Xiaolu Wang, Yuchang Sun, Hoi-To Wai, Jun Zhang</dc:creator>
    </item>
    <item>
      <title>Delta-modular ILP Problems of Bounded Co-dimension, Discrepancy, and Convolution</title>
      <link>https://arxiv.org/abs/2405.17001</link>
      <description>arXiv:2405.17001v1 Announce Type: cross 
Abstract: For $k, n \geq 0$, and $c \in Z^n$, we consider ILP problems \begin{gather*}
  \max\bigl\{ c^\top x \colon A x = b,\, x \in Z^n_{\geq 0} \bigr\}\text{ with $A \in Z^{k \times n}$, $rank(A) = k$, $b \in Z^{k}$ and}
  \max\bigl\{ c^\top x \colon A x \leq b,\, x \in Z^n \bigr\} \text{ with $A \in Z^{(n+k) \times n}$, $rank(A) = n$, $b \in Z^{n+k}$.} \end{gather*} The first problem is called an \emph{ILP problem in the standard form of the codimension $k$}, and the second problem is called an \emph{ILP problem in the canonical form with $n+k$ constraints.} We show that, for any sufficiently large $\Delta$, both problems can be solved with $$ 2^{O(k)} \cdot (f_{k,d} \cdot \Delta)^2 / 2^{\Omega\bigl(\sqrt{\log(f_{k,d} \cdot \Delta)}\bigr)} $$ operations, where $
  f_{k,d} = \min \Bigl\{ k^{k/2},
  \bigl(\log k \cdot \log (d + k)\bigr)^{k/2}
  \Bigr\} $, $d$ is the dimension of a corresponding polyhedron and $\Delta$ is the maximum absolute value of $rank(A) \times rank(A)$ sub-determinants of $A$.
  As our second main result, we show that the feasibility variants of both problems can be solved with $$ 2^{O(k)} \cdot f_{k,d} \cdot \Delta \cdot \log^3(f_{k,d} \cdot \Delta) $$ operations. The constant $f_{k,d}$ can be replaced by other constant $g_{k,\Delta} = \bigl(\log k \cdot \log (k \Delta)\bigr)^{k/2}$ that depends only on $k$ and $\Delta$. Additionally, we consider different partial cases with $k=0$ and $k=1$, which have interesting applications.
  As a result of independent interest, we propose an $n^2/2^{\Omega\bigl(\sqrt{\log n}\bigr)}$-time algorithm for the tropical convolution problem on sequences, indexed by elements of a finite Abelian group of the order $n$. This result is obtained, reducing the above problem to the matrix multiplication problem on a tropical semiring and using seminal algorithm by R. Williams.</description>
      <guid isPermaLink="false">oai:arXiv.org:2405.17001v1</guid>
      <category>cs.CC</category>
      <category>cs.DS</category>
      <category>math.AC</category>
      <category>math.OC</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>D. Gribanov, D. Malyshev, P. M. Pardalos</dc:creator>
    </item>
    <item>
      <title>Developments in tropical convexity</title>
      <link>https://arxiv.org/abs/2405.17005</link>
      <description>arXiv:2405.17005v1 Announce Type: cross 
Abstract: The term "tropical convexity" was coined by Develin and Sturmfels who published a landmark paper with that title in 2004. However, the topic has much older roots and is deeply connected to linear and combinatorial optimization and other areas of mathematics. The purpose of this survey is to sketch how that article contributed to shaping the field of tropical geometry as we know it today.</description>
      <guid isPermaLink="false">oai:arXiv.org:2405.17005v1</guid>
      <category>math.CO</category>
      <category>math.OC</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Michael Joswig</dc:creator>
    </item>
    <item>
      <title>Verifying Properties of Binary Neural Networks Using Sparse Polynomial Optimization</title>
      <link>https://arxiv.org/abs/2405.17049</link>
      <description>arXiv:2405.17049v1 Announce Type: cross 
Abstract: This paper explores methods for verifying the properties of Binary Neural Networks (BNNs), focusing on robustness against adversarial attacks. Despite their lower computational and memory needs, BNNs, like their full-precision counterparts, are also sensitive to input perturbations. Established methods for solving this problem are predominantly based on Satisfiability Modulo Theories and Mixed-Integer Linear Programming techniques, which are characterized by NP complexity and often face scalability issues.
  We introduce an alternative approach using Semidefinite Programming relaxations derived from sparse Polynomial Optimization. Our approach, compatible with continuous input space, not only mitigates numerical issues associated with floating-point calculations but also enhances verification scalability through the strategic use of tighter first-order semidefinite relaxations. We demonstrate the effectiveness of our method in verifying robustness against both $\|.\|_\infty$ and $\|.\|_2$-based adversarial attacks.</description>
      <guid isPermaLink="false">oai:arXiv.org:2405.17049v1</guid>
      <category>cs.LG</category>
      <category>math.OC</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Jianting Yang, Sre\'cko {\DH}ura\v{s}inovi\'c, Jean-Bernard Lasserre, Victor Magron, Jun Zhao</dc:creator>
    </item>
    <item>
      <title>Instability and Efficiency of Non-cooperative Games</title>
      <link>https://arxiv.org/abs/2405.17196</link>
      <description>arXiv:2405.17196v1 Announce Type: cross 
Abstract: It is well known that a non-cooperative game may have multiple equilibria. In this paper we consider the efficiency of games, measured by the ratio between the aggregate payoff over all Nash equilibria and that over all admissible controls. Such efficiency operator is typically unstable with respect to small perturbation of the game. This seemingly bad property can actually be a good news in practice: it is possible that a small change of the game mechanism may improve the efficiency of the game dramatically. We shall introduce a game mediator with limited resources and investigate the mechanism designs aiming to improve the efficiency.</description>
      <guid isPermaLink="false">oai:arXiv.org:2405.17196v1</guid>
      <category>cs.GT</category>
      <category>math.OC</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Jianfeng Zhang</dc:creator>
    </item>
    <item>
      <title>Convex Relaxation for Solving Large-Margin Classifiers in Hyperbolic Space</title>
      <link>https://arxiv.org/abs/2405.17198</link>
      <description>arXiv:2405.17198v1 Announce Type: cross 
Abstract: Hyperbolic spaces have increasingly been recognized for their outstanding performance in handling data with inherent hierarchical structures compared to their Euclidean counterparts. However, learning in hyperbolic spaces poses significant challenges. In particular, extending support vector machines to hyperbolic spaces is in general a constrained non-convex optimization problem. Previous and popular attempts to solve hyperbolic SVMs, primarily using projected gradient descent, are generally sensitive to hyperparameters and initializations, often leading to suboptimal solutions. In this work, by first rewriting the problem into a polynomial optimization, we apply semidefinite relaxation and sparse moment-sum-of-squares relaxation to effectively approximate the optima. From extensive empirical experiments, these methods are shown to perform better than the projected gradient descent approach.</description>
      <guid isPermaLink="false">oai:arXiv.org:2405.17198v1</guid>
      <category>cs.LG</category>
      <category>math.OC</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-sa/4.0/</dc:rights>
      <dc:creator>Sheng Yang, Peihan Liu, Cengiz Pehlevan</dc:creator>
    </item>
    <item>
      <title>Simplicity Bias of Two-Layer Networks beyond Linearly Separable Data</title>
      <link>https://arxiv.org/abs/2405.17299</link>
      <description>arXiv:2405.17299v1 Announce Type: cross 
Abstract: Simplicity bias, the propensity of deep models to over-rely on simple features, has been identified as a potential reason for limited out-of-distribution generalization of neural networks (Shah et al., 2020). Despite the important implications, this phenomenon has been theoretically confirmed and characterized only under strong dataset assumptions, such as linear separability (Lyu et al., 2021). In this work, we characterize simplicity bias for general datasets in the context of two-layer neural networks initialized with small weights and trained with gradient flow. Specifically, we prove that in the early training phases, network features cluster around a few directions that do not depend on the size of the hidden layer. Furthermore, for datasets with an XOR-like pattern, we precisely identify the learned features and demonstrate that simplicity bias intensifies during later training stages. These results indicate that features learned in the middle stages of training may be more useful for OOD transfer. We support this hypothesis with experiments on image data.</description>
      <guid isPermaLink="false">oai:arXiv.org:2405.17299v1</guid>
      <category>stat.ML</category>
      <category>cs.LG</category>
      <category>math.OC</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Nikita Tsoy, Nikola Konstantinov</dc:creator>
    </item>
    <item>
      <title>Outcome-Driven Dynamic Refugee Assignment with Allocation Balancing</title>
      <link>https://arxiv.org/abs/2007.03069</link>
      <description>arXiv:2007.03069v5 Announce Type: replace 
Abstract: This study proposes two new dynamic assignment algorithms to match refugees and asylum seekers to geographic localities within a host country. The first, currently implemented in a multi-year randomized control trial in Switzerland, seeks to maximize the average predicted employment level (or any measured outcome of interest) of refugees through a minimum-discord online assignment algorithm. The performance of this algorithm is tested on real refugee resettlement data from both the US and Switzerland, where we find that it is able to achieve near-optimal expected employment compared to the hindsight-optimal solution, and is able to improve upon the status quo procedure by 40-50%. However, pure outcome maximization can result in a periodically imbalanced allocation to the localities over time, leading to implementation difficulties and an undesirable workflow for resettlement resources and agents. To address these problems, the second algorithm balances the goal of improving refugee outcomes with the desire for an even allocation over time. We find that this algorithm can achieve near-perfect balance over time with only a small loss in expected employment compared to the employment-maximizing algorithm. In addition, the allocation balancing algorithm offers a number of ancillary benefits compared to pure outcome maximization, including robustness to unknown arrival flows and greater exploration.</description>
      <guid isPermaLink="false">oai:arXiv.org:2007.03069v5</guid>
      <category>math.OC</category>
      <category>cs.GT</category>
      <category>cs.LG</category>
      <category>stat.ME</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <arxiv:DOI>10.1287/opre.2022.0445</arxiv:DOI>
      <dc:creator>Kirk Bansak, Elisabeth Paulson</dc:creator>
    </item>
    <item>
      <title>Extremum Seeking Tracking for Derivative-free Distributed Optimization</title>
      <link>https://arxiv.org/abs/2110.04234</link>
      <description>arXiv:2110.04234v4 Announce Type: replace 
Abstract: In this paper, we deal with a network of agents that want to cooperatively minimize the sum of local cost functions depending on a common decision variable. We consider the challenging scenario in which objective functions are unknown and agents have only access to local measurements of their local functions. We propose a novel distributed algorithm that combines a recent gradient tracking policy with an extremum-seeking technique to estimate the global descent direction. The joint use of these two techniques results in a distributed optimization scheme that provides arbitrarily accurate solution estimates through the combination of Lyapunov and averaging analysis approaches with consensus theory. We perform numerical simulations in a personalized optimization framework to corroborate the theoretical results.</description>
      <guid isPermaLink="false">oai:arXiv.org:2110.04234v4</guid>
      <category>math.OC</category>
      <category>cs.SY</category>
      <category>eess.SY</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Nicola Mimmo, Guido Carnevale, Andrea Testa, Giuseppe Notarstefano</dc:creator>
    </item>
    <item>
      <title>On the Douglas-Rachford and Peaceman-Rachford algorithms in the presence of uniform monotonicity and the absence of minimizers</title>
      <link>https://arxiv.org/abs/2201.06661</link>
      <description>arXiv:2201.06661v2 Announce Type: replace 
Abstract: The Douglas-Rachford and Peaceman-Rachford algorithms have been successfully employed to solve convex optimization problems, or more generally find zeros of monotone inclusions. Recently, the behaviour of these methods in the inconsistent case, i.e., in the absence of solutions has triggered significant consideration. It has been shown that under mild assumptions the shadow sequence of the Douglas-Rachford algorithm converges weakly to a generalized solution when the underlying operators are subdifferentials of proper lower semicontinuous convex functions. However, no convergence behaviour has been proved in the case of Peaceman-Rachford algorithm. In this paper, we prove the convergence of the shadow sequences associated with the Douglas-Rachford algorithm and Peaceman-Rachford algorithm when one of the operators is uniformly monotone and $3^*$ monotone but not necessarily a subdifferential. Several examples illustrate and strengthen our conclusion. We carry out numerical experiments using example instances of optimization problems.</description>
      <guid isPermaLink="false">oai:arXiv.org:2201.06661v2</guid>
      <category>math.OC</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Regina S. Burachik, Bethany I. Caldwell, C. Yal\c{c}{\i}n Kaya, Walaa M. Moursi, Matthew Saurette</dc:creator>
    </item>
    <item>
      <title>P-split formulations: A class of intermediate formulations between big-M and convex hull for disjunctive constraints</title>
      <link>https://arxiv.org/abs/2202.05198</link>
      <description>arXiv:2202.05198v2 Announce Type: replace 
Abstract: We develop a class of mixed-integer formulations for disjunctive constraints intermediate to the big-M and convex hull formulations in terms of relaxation strength. The main idea is to capture the best of both the big-M and convex hull formulations: a computationally light formulation with a tight relaxation. The "P-split" formulations are based on a lifted transformation that splits convex additively separable constraints into P partitions and forms the convex hull of the linearized and partitioned disjunction. The "P-split" formulations are derived for disjunctive constraints with convex constraints within each disjuct, and we generalize the results for the case with nonconvex constraints within the disjuncts. We analyze the continuous relaxation of the P-split formulations and show that, under certain assumptions, the formulations form a hierarchy starting from a big-M equivalent and converging to the convex hull. The goal of the P-split formulations is to form strong approximations of the convex hull through a computationally simpler formulation. We computationally compare the P-split formulations against big-M and convex hull formulations on 344 test instances. The test problems include K-means clustering, semi-supervised clustering, P_ball problems, and optimization over trained ReLU neural networks. The computational results show promising potential of the P-split formulations. For many of the test problems, P-split formulations are solved with a similar number of explored nodes as the convex hull formulation, while reducing the solution time by an order of magnitude and outperforming big-M both in time and number of explored nodes.</description>
      <guid isPermaLink="false">oai:arXiv.org:2202.05198v2</guid>
      <category>math.OC</category>
      <category>cs.LG</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Jan Kronqvist, Ruth Misener, Calvin Tsay</dc:creator>
    </item>
    <item>
      <title>Reinforcement Learning Approaches for the Orienteering Problem with Stochastic and Dynamic Release Dates</title>
      <link>https://arxiv.org/abs/2207.00885</link>
      <description>arXiv:2207.00885v3 Announce Type: replace 
Abstract: In this paper, we study a sequential decision-making problem faced by e-commerce carriers related to when to send out a vehicle from the central depot to serve customer requests, and in which order to provide the service, under the assumption that the time at which parcels arrive at the depot is stochastic and dynamic. The objective is to maximize the expected number of parcels that can be delivered during service hours. We propose two reinforcement learning (RL) approaches for solving this problem. These approaches rely on a look-ahead strategy in which future release dates are sampled in a Monte-Carlo fashion and a batch approach is used to approximate future routes. Both RL approaches are based on value function approximation - one combines it with a consensus function (VFA-CF) and the other one with a two-stage stochastic integer linear programming model (VFA-2S). VFA-CF and VFA-2S do not need extensive training as they are based on very few hyper-parameters and make good use of integer linear programming (ILP) and branch-and-cut-based exact methods to improve the quality of decisions. We also establish sufficient conditions for partial characterization of optimal policy and integrate them into VFA-CF/VFA-2S. In an empirical study, we conduct a competitive analysis using upper bounds with perfect information. We also show that VFA-CF and VFA-2S greatly outperform alternative approaches that: 1) do not rely on future information, or 2) are based on point estimation of future information, or 3) employ heuristics rather than exact methods, or 4) use exact evaluations of future rewards.</description>
      <guid isPermaLink="false">oai:arXiv.org:2207.00885v3</guid>
      <category>math.OC</category>
      <category>cs.LG</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Yuanyuan Li, Claudia Archetti, Ivana Ljubic</dc:creator>
    </item>
    <item>
      <title>A Non-Interior-Point Continuation Method for the Optimal Control Problem with Equilibrium Constraints</title>
      <link>https://arxiv.org/abs/2210.10336</link>
      <description>arXiv:2210.10336v2 Announce Type: replace 
Abstract: In this study, we focus on the numerical solution method for the optimal control problem with equilibrium constraints (OCPEC).It is extremely challenging to solve OCPEC owing to the absence of constraint regularity and strictly feasible interior points. To solve OCPEC efficiently, we first relax the discretized OCPEC to recover the constraint regularity and then map its Karush--Kuhn--Tucker (KKT) conditions into a perturbed system of equations. Subsequently, we propose a novel two-stage solution method, called the non-interior-point continuation method, to solve the perturbed system. In the first stage, a non-interior-point method, which solves the perturbed system using the Newton method and globalizes convergence using a dedicated merit function, is employed. In the second stage, a predictor-corrector continuation method is utilized to track the solution trajectory as a function of the perturbed parameter, starting at the solution obtained in the first stage. The proposed method regularizes the KKT matrix and does not enforce iterates to remain in the feasible interior, which mitigates the numerical difficulties of solving OCPEC. Convergence properties are analyzed under certain assumptions. Numerical experiments demonstrate that the proposed method can accurately track the solution trajectory while demanding significantly less computation time compared to the interior-point method.</description>
      <guid isPermaLink="false">oai:arXiv.org:2210.10336v2</guid>
      <category>math.OC</category>
      <category>cs.SY</category>
      <category>eess.SY</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Kangyu Lin, Toshiyuki Ohtsuka</dc:creator>
    </item>
    <item>
      <title>Averaging Orientations with Molecular Symmetry in Cryo-EM</title>
      <link>https://arxiv.org/abs/2301.05426</link>
      <description>arXiv:2301.05426v4 Announce Type: replace 
Abstract: Cryogenic electron microscopy (cryo-EM) is an invaluable technique for determining high-resolution three-dimensional structures of biological macromolecules using transmission particle images. The inherent symmetry in these macromolecules is advantageous, as it allows each image to represent multiple perspectives. However, data processing that incorporates symmetry can inadvertently average out asymmetric features. Therefore, a key preliminary step is to visualize 2D asymmetric features in the particle images, which requires estimating orientation statistics under molecular symmetry constraints. Motivated by this challenge, we introduce a novel method for estimating the mean and variance of orientations with molecular symmetry. Utilizing tools from non-unique games, we show that our proposed non-convex formulation can be simplified as a semi-definite programming problem. Moreover, we propose a novel rounding procedure to determine the representative values. Experimental results demonstrate that the proposed approach can find the global minima and the appropriate representatives with a high degree of probability. We release the code of our method as an open-source Python package named pySymStat. Finally, we apply pySymStat to visualize an asymmetric feature in an icosahedral virus, a feat that proved unachievable using the conventional 2D classification method in RELION.</description>
      <guid isPermaLink="false">oai:arXiv.org:2301.05426v4</guid>
      <category>math.OC</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Qi Zhang, Chenglong Bao, Hai Lin, Mingxu Hu</dc:creator>
    </item>
    <item>
      <title>Distributionally robust Kalman filtering with volatility uncertainty</title>
      <link>https://arxiv.org/abs/2302.05993</link>
      <description>arXiv:2302.05993v2 Announce Type: replace 
Abstract: This work presents a distributionally robust Kalman filter to address uncertainties in noise covariance matrices and predicted covariance estimates. We adopt a distributionally robust formulation using bicausal optimal transport to characterize a set of plausible alternative models. The optimization problem is transformed into a convex nonlinear semi-definite programming problem and solved using the trust-region interior point method with the aid of $LDL^\top$ decomposition. The empirical outperformance is demonstrated through target tracking and pairs trading.</description>
      <guid isPermaLink="false">oai:arXiv.org:2302.05993v2</guid>
      <category>math.OC</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Bingyan Han</dc:creator>
    </item>
    <item>
      <title>A Moment-SOS Hierarchy for Robust Polynomial Matrix Inequality Optimization with SOS-Convexity</title>
      <link>https://arxiv.org/abs/2304.12628</link>
      <description>arXiv:2304.12628v4 Announce Type: replace 
Abstract: We study a class of polynomial optimization problems with a robust polynomial matrix inequality (PMI) constraint where the uncertainty set itself is defined also by a PMI. These can be viewed as matrix generalizations of semi-infinite polynomial programs, since they involve actually infinitely many PMI constraints in general. Under certain SOS-convexity assumptions, we construct a hierarchy of increasingly tight moment-SOS relaxations for solving such problems. Most of the nice features of the moment-SOS hierarchy for the usual polynomial optimization are extended to this more complicated setting. In particular, asymptotic convergence of the hierarchy is guaranteed and finite convergence can be certified if some flat extension condition holds true. To extract global minimizers, we provide a linear algebra procedure for recovering a finitely atomic matrix-valued measure from truncated matrix-valued moments. As an application, we are able to solve the problem of minimizing the smallest eigenvalue of a polynomial matrix subject to a PMI constraint. If SOS-convexity is replaced by convexity, we can still approximate the optimal value as closely as desired by solving a sequence of semidefinite programs, and certify global optimality in case that certain flat extension conditions hold true. Finally, an extension to the non-convexity setting is provided under a rank one condition. To obtain the above-mentioned results, techniques from real algebraic geometry, matrix-valued measure theory, and convex optimization are employed.</description>
      <guid isPermaLink="false">oai:arXiv.org:2304.12628v4</guid>
      <category>math.OC</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Feng Guo, Jie Wang</dc:creator>
    </item>
    <item>
      <title>Sketch-and-Project Meets Newton Method: Global $\mathcal O(k^{-2})$ Convergence with Low-Rank Updates</title>
      <link>https://arxiv.org/abs/2305.13082</link>
      <description>arXiv:2305.13082v4 Announce Type: replace 
Abstract: In this paper, we propose the first sketch-and-project Newton method with fast $\mathcal O(k^{-2})$ global convergence rate for self-concordant functions. Our method, SGN, can be viewed in three ways: i) as a sketch-and-project algorithm projecting updates of Newton method, ii) as a cubically regularized Newton ethod in sketched subspaces, and iii) as a damped Newton method in sketched subspaces. SGN inherits best of all three worlds: cheap iteration costs of sketch-and-project methods, state-of-the-art $\mathcal O(k^{-2})$ global convergence rate of full-rank Newton-like methods and the algorithm simplicity of damped Newton methods. Finally, we demonstrate its comparable empirical performance to baseline algorithms.</description>
      <guid isPermaLink="false">oai:arXiv.org:2305.13082v4</guid>
      <category>math.OC</category>
      <category>cs.LG</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Slavom\'ir Hanzely</dc:creator>
    </item>
    <item>
      <title>Exact Two-Step Benders Decomposition for the Time Window Assignment Traveling Salesperson Problem</title>
      <link>https://arxiv.org/abs/2306.02849</link>
      <description>arXiv:2306.02849v3 Announce Type: replace 
Abstract: Next-day delivery logistics services are redefining the industry by increasingly focusing on customer service. A challenge each logistics service provider faces is to jointly optimize time window assignment and vehicle routing for such next-day delivery services. To do so in a cost-efficient and customer-centric fashion, real-life uncertainty such as stochastic travel times need to be incorporated in the optimization process. This paper focuses on the canonical optimization problem within this context; the Time Window Assignment Traveling Salesperson Problem with Stochastic Travel Times (TWATSP-ST). It belongs to the class of two-stage stochastic mixed-integer programming problems with continuous recourse. We introduce Two-Step Benders Decomposition with Scenario Clustering (TBDS) as a general exact solution methodology for solving such stochastic programs to optimality. The method combines and generalizes Benders dual decomposition, partial Benders decomposition, and Scenario Clustering techniques and does so within a novel two-step decomposition along the binary and continuous first-stage decisions. Extensive experiments show that TBDS is superior to state-of-the-art approaches in the literature. It solves TWATSP-ST instances with up to 25 customers to optimality. It provides better lower and upper bounds that lead to faster convergence than related methods. For example, Benders dual decomposition cannot optimally solve instances of 10 customers. We use TBDS to analyze the structure of the optimal solutions. By increasing routing costs only slightly, customer service can be improved tremendously, driven by smartly alternating between high- and low-variance travel arcs to reduce the impact of delay propagation throughout the executed vehicle route.</description>
      <guid isPermaLink="false">oai:arXiv.org:2306.02849v3</guid>
      <category>math.OC</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Sifa Celik, Layla Martin, Albert H. Schrotenboer, Tom Van Woensel</dc:creator>
    </item>
    <item>
      <title>Subgradient Langevin Methods for Sampling from Non-smooth Potentials</title>
      <link>https://arxiv.org/abs/2308.01417</link>
      <description>arXiv:2308.01417v3 Announce Type: replace 
Abstract: This paper is concerned with sampling from probability distributions $\pi$ on $\mathbb{R}^d$ admitting a density of the form $\pi(x) \propto e^{-U(x)}$, where $U(x)=F(x)+G(Kx)$ with $K$ being a linear operator and $G$ being non-differentiable. Two different methods are proposed, both employing a subgradient step with respect to $G\circ K$, but, depending on the regularity of $F$, either an explicit or an implicit gradient step with respect to $F$ can be implemented. For both methods, non-asymptotic convergence proofs are provided, with improved convergence results for more regular $F$. Further, numerical experiments are conducted for simple 2D examples, illustrating the convergence rates, and for examples of Bayesian imaging, showing the practical feasibility of the proposed methods for high dimensional data.</description>
      <guid isPermaLink="false">oai:arXiv.org:2308.01417v3</guid>
      <category>math.OC</category>
      <category>stat.CO</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Andreas Habring, Martin Holler, Thomas Pock</dc:creator>
    </item>
    <item>
      <title>Advancing the lower bounds: An accelerated, stochastic, second-order method with optimal adaptation to inexactness</title>
      <link>https://arxiv.org/abs/2309.01570</link>
      <description>arXiv:2309.01570v3 Announce Type: replace 
Abstract: We present a new accelerated stochastic second-order method that is robust to both gradient and Hessian inexactness, which occurs typically in machine learning. We establish theoretical lower bounds and prove that our algorithm achieves optimal convergence in both gradient and Hessian inexactness in this key setting. We further introduce a tensor generalization for stochastic higher-order derivatives. When the oracles are non-stochastic, the proposed tensor algorithm matches the global convergence of Nesterov Accelerated Tensor method. Both algorithms allow for approximate solutions of their auxiliary subproblems with verifiable conditions on the accuracy of the solution.</description>
      <guid isPermaLink="false">oai:arXiv.org:2309.01570v3</guid>
      <category>math.OC</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Artem Agafonov, Dmitry Kamzolov, Alexander Gasnikov, Ali Kavis, Kimon Antonakopoulos, Volkan Cevher, Martin Tak\'a\v{c}</dc:creator>
    </item>
    <item>
      <title>Higher-order Lie bracket approximation and averaging of control-affine systems with application to extremum seeking</title>
      <link>https://arxiv.org/abs/2310.07092</link>
      <description>arXiv:2310.07092v3 Announce Type: replace 
Abstract: This paper provides a rigorous derivation for what is known in the literature as the Lie bracket approximation of control-affine systems in a sequential framework for higher-orders. In fact, by using chronological calculus, we show that said Lie bracket approximations are themselves higher-order averaging terms. Hence, this paper bridges both averaging and approximation theories of control-affine systems. In particular, the Lie bracket approximation of order ($n$) turns out to be a higher-order averaging of order ($n+1$). The derivation and formulation provided in this paper can be directly reduced to the first and second-order Lie bracket approximations available in the literature. However, we do not need to make many of the unproven assumptions provided in the literature and show that they are in fact natural corollaries from our work. Moreover, we use our results to show that important and useful information about control-affine extremum seeking systems can be obtained and used for performance improvement, including faster convergence of very simple structures. We provide multiple numerical simulations to demonstrate both the conceptual elements of this work as well as the significance of our results on extremum seeking with comparison against the literature.</description>
      <guid isPermaLink="false">oai:arXiv.org:2310.07092v3</guid>
      <category>math.OC</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Sameer Pokhrel, Sameh A. Eisa</dc:creator>
    </item>
    <item>
      <title>New vector transport operators extending a Riemannian CG algorithm to generalized Stiefel manifold with low-rank applications</title>
      <link>https://arxiv.org/abs/2311.00907</link>
      <description>arXiv:2311.00907v2 Announce Type: replace 
Abstract: This paper proposes two innovative vector transport operators, leveraging the Cayley transform, for the generalized Stiefel manifold embedded with a non-standard metric. Specifically, it introduces the differentiated retraction and an approximation of the Cayley transform to the differentiated matrix exponential. These vector transports are demonstrated to satisfy the Ring-Wirth non-expansive condition under non-standard metrics, and one of them is also isometric. Building upon the novel vector transport operators, we extend the modified Polak-Ribi$\grave{e}$re-Polyak (PRP) conjugate gradient method to the generalized Stiefel manifold. Under a non-monotone line search condition, we prove our algorithm globally converges to a stationary point. The efficiency of the proposed vector transport operators is empirically validated through numerical experiments involving generalized eigenvalue problems and canonical correlation analysis.</description>
      <guid isPermaLink="false">oai:arXiv.org:2311.00907v2</guid>
      <category>math.OC</category>
      <category>cs.NA</category>
      <category>math.NA</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/publicdomain/zero/1.0/</dc:rights>
      <arxiv:DOI>10.1016/j.cam.2024.116024</arxiv:DOI>
      <dc:creator>Xuejie Wang, Kangkang Deng, Zheng Peng, Chengcheng Yan</dc:creator>
    </item>
    <item>
      <title>Accurate Linear Cutting-Plane Relaxations for ACOPF</title>
      <link>https://arxiv.org/abs/2312.04251</link>
      <description>arXiv:2312.04251v2 Announce Type: replace 
Abstract: We present a pure linear cutting-plane relaxation approach for rapidly proving tight and accurate lower bounds for the Alternating Current Optimal Power Flow Problem (ACOPF) and its multi-period extension with ramping constraints. Our method leverages outer-envelope linear cuts for well-known second-order cone relaxations for ACOPF together with modern cut management techniques and reformulations to attain numerical stability. These techniques prove effective on a broad family of ACOPF instances, including the largest ones publicly available, quickly and robustly yielding tight bounds. Additionally, we consider the (frequent) case where an ACOPF instance is handled following a small or moderate change in problem data, e.g., load changes and generator or branch shut-offs. We provide significant computational evidence, on single and multi-period ACOPF instances, that the cuts computed on the prior instance provide very good lower bounds when warm-starting our algorithm on the perturbed instance.</description>
      <guid isPermaLink="false">oai:arXiv.org:2312.04251v2</guid>
      <category>math.OC</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Daniel Bienstock, Matias Villagra</dc:creator>
    </item>
    <item>
      <title>On the Nonsmooth Geometry and Neural Approximation of the Optimal Value Function of Infinite-Horizon Pendulum Swing-up</title>
      <link>https://arxiv.org/abs/2312.17467</link>
      <description>arXiv:2312.17467v2 Announce Type: replace 
Abstract: We revisit the inverted pendulum problem with the goal of understanding and computing the true optimal value function. We start with an observation that the true optimal value function must be nonsmooth ($i.e.$, not globally $C^1$) due to the symmetry of the problem. We then give a result that can certify the optimality of a candidate $\textit{piece-wise}$ $C^1$ value function. Further, for a candidate value function obtained via numerical approximation, we provide a bound of suboptimality based on its Hamilton-Jacobi-Bellman (HJB) equation residuals. Inspired by Holzhuter (2004), we then design an algorithm that solves backward the Pontryagin's minimum principle (PMP) ODE from terminal conditions provided by the locally optimal LQR value function. This numerical procedure leads to a piece-wise $C^1$ value function whose nonsmooth region contains periodic $\textit{spiral lines}$ and smooth regions attain HJB residuals about $10^{-4}$, hence certified to be the optimal value function up to minor numerical inaccuracies. This optimal value function checks the power of optimality: (i) it sits above a polynomial lower bound; (ii) its induced controller globally swings up and stabilizes the pendulum, and (iii) attains lower trajectory cost than baseline methods such as energy shaping, model predictive control (MPC), and proximal policy optimization (with MPC attaining almost the same cost). We conclude by distilling the optimal value function into a simple neural network. Our code is avilable in https://github.com/ComputationalRobotics/InvertedPendulumOptimalValue.</description>
      <guid isPermaLink="false">oai:arXiv.org:2312.17467v2</guid>
      <category>math.OC</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Haoyu Han, Heng Yang</dc:creator>
    </item>
    <item>
      <title>Data-Driven Discovery of PDEs via the Adjoint Method</title>
      <link>https://arxiv.org/abs/2401.17177</link>
      <description>arXiv:2401.17177v2 Announce Type: replace 
Abstract: In this work, we present an adjoint-based method for discovering the underlying governing partial differential equations (PDEs) given data. The idea is to consider a parameterized PDE in a general form and formulate a PDE-constrained optimization problem aimed at minimizing the error of the PDE solution from data. Using variational calculus, we obtain an evolution equation for the Lagrange multipliers (adjoint equations) allowing us to compute the gradient of the objective function with respect to the parameters of PDEs given data in a straightforward manner. In particular, we consider a family of parameterized PDEs encompassing linear, nonlinear, and spatial derivative candidate terms, and elegantly derive the corresponding adjoint equations. We show the efficacy of the proposed approach in identifying the form of the PDE up to machine accuracy, enabling the accurate discovery of PDEs from data. We also compare its performance with the famous PDE Functional Identification of Nonlinear Dynamics method known as PDE-FIND (Rudy et al., 2017), on both smooth and noisy data sets. Even though the proposed adjoint method relies on forward/backward solvers, it outperforms PDE-FIND for large data sets thanks to the analytic expressions for gradients of the cost function with respect to each PDE parameter.</description>
      <guid isPermaLink="false">oai:arXiv.org:2401.17177v2</guid>
      <category>math.OC</category>
      <category>cs.LG</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Mohsen Sadr, Tony Tohme, Kamal Youcef-Toumi</dc:creator>
    </item>
    <item>
      <title>Median Clipping for Zeroth-order Non-Smooth Convex Optimization and Multi Arm Bandit Problem with Heavy-tailed Symmetric Noise</title>
      <link>https://arxiv.org/abs/2402.02461</link>
      <description>arXiv:2402.02461v3 Announce Type: replace 
Abstract: In this paper, we consider non-smooth convex optimization with a zeroth-order oracle corrupted by symmetric stochastic noise. Unlike the existing high-probability results requiring the noise to have bounded $\kappa$-th moment with $\kappa \in (1,2]$, our results allow even heavier noise with any $\kappa &gt; 0$, e.g., the noise distribution can have unbounded $1$-st moment. Moreover, our results match the best-known ones for the case of the bounded variance. To achieve this, we use the mini-batched median estimate of the sampled gradient differences, apply gradient clipping to the result, and plug in the final estimate into the accelerated method. We apply this technique to the stochastic multi-armed bandit problem with heavy-tailed distribution of rewards and achieve $O(\sqrt{Td})$ regret by incorporating noise symmetry.</description>
      <guid isPermaLink="false">oai:arXiv.org:2402.02461v3</guid>
      <category>math.OC</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Nikita Kornilov, Yuriy Dorn, Aleksandr Lobanov, Nikolay Kutuzov, Innokentiy Shibaev, Eduard Gorbunov, Alexander Gasnikov, Alexander Nazin</dc:creator>
    </item>
    <item>
      <title>High-dimensional multidisciplinary design optimization for aircraft eco-design / Optimisation multi-disciplinaire en grande dimension pour l'\'eco-conception avion en avant-projet</title>
      <link>https://arxiv.org/abs/2402.04711</link>
      <description>arXiv:2402.04711v3 Announce Type: replace 
Abstract: The objective of this Philosophiae Doctor (Ph.D) thesis is to propose an efficient approach for optimizing a multidisciplinary black-box model when the optimization problem is constrained and involves a large number of mixed integer design variables (typically 100 variables). The targeted optimization approach, called EGO, is based on a sequential enrichment of an adaptive surrogate model and, in this context, GP surrogate models are one of the most widely used in engineering problems to approximate time-consuming high fidelity models. EGO is a heuristic BO method that performs well in terms of solution quality. However, like any other global optimization method, EGO suffers from the curse of dimensionality, meaning that its performance is satisfactory on lower dimensional problems, but deteriorates as the dimensionality of the optimization search space increases. For realistic aircraft design problems, the typical size of the design variables can even exceed 100 and, thus, trying to solve directly the problems using EGO is ruled out. The latter is especially true when the problems involve both continuous and categorical variables increasing even more the size of the search space. In this Ph.D thesis, effective parameterization tools are investigated, including techniques like partial least squares regression, to significantly reduce the number of design variables. Additionally, Bayesian optimization is adapted to handle discrete variables and high-dimensional spaces in order to reduce the number of evaluations when optimizing innovative aircraft concepts such as the "DRAGON" hybrid airplane to reduce their climate impact.</description>
      <guid isPermaLink="false">oai:arXiv.org:2402.04711v3</guid>
      <category>math.OC</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Paul Saves</dc:creator>
    </item>
    <item>
      <title>Robust Radiotherapy Planning with Spatially Based Uncertainty Sets</title>
      <link>https://arxiv.org/abs/2402.17040</link>
      <description>arXiv:2402.17040v2 Announce Type: replace 
Abstract: Radiotherapy treatment planning is a challenging large-scale optimization problem plagued by uncertainty. Following the robust optimization methodology, we propose a novel, spatially based uncertainty set for robust modeling of radiotherapy planning, producing solutions that are immune to unexpected changes in biological conditions. Our proposed uncertainty set realistically captures biological radiosensitivity patterns that are observed using recent advances in imaging, while its parameters can be personalized for individual patients. We exploit the structure of this set to devise a compact reformulation of the robust model. We develop a row-generation scheme to solve real, large-scale instances of the robust model. This method is then extended to a relaxation-based scheme for enforcing challenging, yet clinically important, dose-volume cardinality constraints. The computational performance of our algorithms, as well as the quality and robustness of the computed treatment plans, are demonstrated on simulated and real imaging data. Based on accepted performance measures, such as minimal target dose and homogeneity, these examples demonstrate that the spatially robust model achieves almost the same performance as the nominal model in the nominal scenario, and otherwise, the spatial model outperforms both the nominal and the box-uncertainty models.</description>
      <guid isPermaLink="false">oai:arXiv.org:2402.17040v2</guid>
      <category>math.OC</category>
      <category>cs.CE</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Noam Goldberg, Mark P. Langer, Shimrit Shtern</dc:creator>
    </item>
    <item>
      <title>The Power of Extrapolation in Federated Learning</title>
      <link>https://arxiv.org/abs/2405.13766</link>
      <description>arXiv:2405.13766v2 Announce Type: replace 
Abstract: We propose and study several server-extrapolation strategies for enhancing the theoretical and empirical convergence properties of the popular federated learning optimizer FedProx [Li et al., 2020]. While it has long been known that some form of extrapolation can help in the practice of FL, only a handful of works provide any theoretical guarantees. The phenomenon seems elusive, and our current theoretical understanding remains severely incomplete. In our work, we focus on smooth convex or strongly convex problems in the interpolation regime. In particular, we propose Extrapolated FedProx (FedExProx), and study three extrapolation strategies: a constant strategy (depending on various smoothness parameters and the number of participating devices), and two smoothness-adaptive strategies; one based on the notion of gradient diversity (FedExProx-GraDS), and the other one based on the stochastic Polyak stepsize (FedExProx-StoPS). Our theory is corroborated with carefully constructed numerical experiments.</description>
      <guid isPermaLink="false">oai:arXiv.org:2405.13766v2</guid>
      <category>math.OC</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Hanmin Li, Kirill Acharya, Peter Richt\'arik</dc:creator>
    </item>
    <item>
      <title>High-probability complexity guarantees for nonconvex minimax problems</title>
      <link>https://arxiv.org/abs/2405.14130</link>
      <description>arXiv:2405.14130v2 Announce Type: replace 
Abstract: Stochastic smooth nonconvex minimax problems are prevalent in machine learning, e.g., GAN training, fair classification, and distributionally robust learning. Stochastic gradient descent ascent (GDA)-type methods are popular in practice due to their simplicity and single-loop nature. However, there is a significant gap between the theory and practice regarding high-probability complexity guarantees for these methods on stochastic nonconvex minimax problems. Existing high-probability bounds for GDA-type single-loop methods only apply to convex/concave minimax problems and to particular non-monotone variational inequality problems under some restrictive assumptions. In this work, we address this gap by providing the first high-probability complexity guarantees for nonconvex/PL minimax problems corresponding to a smooth function that satisfies the PL-condition in the dual variable. Specifically, we show that when the stochastic gradients are light-tailed, the smoothed alternating GDA method can compute an $\varepsilon$-stationary point within $O(\frac{\ell \kappa^2 \delta^2}{\varepsilon^4} + \frac{\kappa}{\varepsilon^2}(\ell+\delta^2\log({1}/{\bar{q}})))$ stochastic gradient calls with probability at least $1-\bar{q}$ for any $\bar{q}\in(0,1)$, where $\mu$ is the PL constant, $\ell$ is the Lipschitz constant of the gradient, $\kappa=\ell/\mu$ is the condition number, and $\delta^2$ denotes a bound on the variance of stochastic gradients. We also present numerical results on a nonconvex/PL problem with synthetic data and on distributionally robust optimization problems with real data, illustrating our theoretical findings.</description>
      <guid isPermaLink="false">oai:arXiv.org:2405.14130v2</guid>
      <category>math.OC</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Yassine Laguel, Yasa Syed, Necdet Serhat Aybat, Mert G\"urb\"uzbalaban</dc:creator>
    </item>
    <item>
      <title>A least-squares Galerkin approach to gradient recovery for Hamilton-Jacobi-Bellman equation with Cordes coefficients</title>
      <link>https://arxiv.org/abs/2205.07583</link>
      <description>arXiv:2205.07583v2 Announce Type: replace-cross 
Abstract: We propose a conforming finite element method to approximate the strong solution of the second order Hamilton-Jacobi-Bellman equation with Dirichlet boundary and coefficients satisfying Cordes condition. We show the convergence of the continuum semismooth Newton method for the fully nonlinear Hamilton-Jacobi-Bellman equation. Applying this linearization for the equation yields a recursive sequence of linear elliptic boundary value problems in nondivergence form. We deal numerically with such BVPs via the least-squares gradient recovery of Lakkis &amp; Mousavi [2021, arxiv:1909.00491]. We provide an optimal-rate apriori and aposteriori error bounds for the approximation. The aposteriori error are used to drive an adaptive refinement procedure. We close with computer experiments on uniform and adaptive meshes to reconcile the theoretical findings.</description>
      <guid isPermaLink="false">oai:arXiv.org:2205.07583v2</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <category>math.AP</category>
      <category>math.OC</category>
      <category>nlin.AO</category>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-sa/4.0/</dc:rights>
      <dc:creator>Omar Lakkis, Amireh Mousavi</dc:creator>
    </item>
    <item>
      <title>Policy-based Primal-Dual Methods for Concave CMDP with Variance Reduction</title>
      <link>https://arxiv.org/abs/2205.10715</link>
      <description>arXiv:2205.10715v4 Announce Type: replace-cross 
Abstract: We study Concave Constrained Markov Decision Processes (Concave CMDPs) where both the objective and constraints are defined as concave functions of the state-action occupancy measure. We propose the Variance-Reduced Primal-Dual Policy Gradient Algorithm (VR-PDPG), which updates the primal variable via policy gradient ascent and the dual variable via projected sub-gradient descent. Despite the challenges posed by the loss of additivity structure and the nonconcave nature of the problem, we establish the global convergence of VR-PDPG by exploiting a form of hidden concavity. In the exact setting, we prove an $O(T^{-1/3})$ convergence rate for both the average optimality gap and constraint violation, which further improves to $O(T^{-1/2})$ under strong concavity of the objective in the occupancy measure. In the sample-based setting, we demonstrate that VR-PDPG achieves an $\widetilde{O}(\epsilon^{-4})$ sample complexity for $\epsilon$-global optimality. Moreover, by incorporating a diminishing pessimistic term into the constraint, we show that VR-PDPG can attain a zero constraint violation without compromising the convergence rate of the optimality gap. Finally, we validate the effectiveness of our methods through numerical experiments.</description>
      <guid isPermaLink="false">oai:arXiv.org:2205.10715v4</guid>
      <category>cs.LG</category>
      <category>math.OC</category>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/publicdomain/zero/1.0/</dc:rights>
      <dc:creator>Donghao Ying, Mengzi Amy Guo, Hyunin Lee, Yuhao Ding, Javad Lavaei, Zuo-Jun Max Shen</dc:creator>
    </item>
    <item>
      <title>Large independent sets in recursive Markov random graphs</title>
      <link>https://arxiv.org/abs/2207.04514</link>
      <description>arXiv:2207.04514v4 Announce Type: replace-cross 
Abstract: Computing the maximum size of an independent set in a graph is a famously hard combinatorial problem that has been well-studied for various classes of graphs. When it comes to random graphs, only the classical Erd\H{o}s-R\'enyi-Gilbert random graph $G_{n,p}$ has been analysed and shown to have largest independent sets of size $\Theta(\log{n})$ w.h.p. This classical model does not capture any dependency structure between edges that can appear in real-world networks. We initiate study in this direction by defining random graphs $G^{r}_{n,p}$ whose existence of edges is determined by a Markov process that is also governed by a decay parameter $r\in(0,1]$. We prove that w.h.p. $G^{r}_{n,p}$ has independent sets of size $(\frac{1-r}{2+\epsilon}) \frac{n}{\log{n}}$ for arbitrary $\epsilon &gt; 0$, which implies an asymptotic lower bound of $\Omega(\pi(n))$ where $\pi(n)$ is the prime-counting function. This is derived using bounds on the terms of a harmonic series, Tur\'an bound on stability number, and a concentration analysis for a certain sequence of dependent Bernoulli variables that may also be of independent interest. Since $G^{r}_{n,p}$ collapses to $G_{n,p}$ when there is no decay, it follows that having even the slightest bit of dependency (any $r &lt; 1$) in the random graph construction leads to the presence of large independent sets and thus our random model has a phase transition at its boundary value of $r=1$. For the maximal independent set output by a greedy algorithm, we deduce that it has a performance ratio of at most $1 + \frac{\log{n}}{(1-r)}$ w.h.p. when the lowest degree vertex is picked at each iteration, and also show that under any other permutation of vertices the algorithm outputs a set of size $\Omega(n^{1/1+\tau})$, where $\tau=1/(1-r)$, and hence has a performance ratio of $O(n^{\frac{1}{2-r}})$.</description>
      <guid isPermaLink="false">oai:arXiv.org:2207.04514v4</guid>
      <category>math.CO</category>
      <category>cs.DM</category>
      <category>math.OC</category>
      <category>math.PR</category>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Akshay Gupte, Yiran Zhu</dc:creator>
    </item>
    <item>
      <title>How to escape sharp minima with random perturbations</title>
      <link>https://arxiv.org/abs/2305.15659</link>
      <description>arXiv:2305.15659v3 Announce Type: replace-cross 
Abstract: Modern machine learning applications have witnessed the remarkable success of optimization algorithms that are designed to find flat minima. Motivated by this design choice, we undertake a formal study that (i) formulates the notion of flat minima, and (ii) studies the complexity of finding them. Specifically, we adopt the trace of the Hessian of the cost function as a measure of flatness, and use it to formally define the notion of approximate flat minima. Under this notion, we then analyze algorithms that find approximate flat minima efficiently. For general cost functions, we discuss a gradient-based algorithm that finds an approximate flat local minimum efficiently. The main component of the algorithm is to use gradients computed from randomly perturbed iterates to estimate a direction that leads to flatter minima. For the setting where the cost function is an empirical risk over training data, we present a faster algorithm that is inspired by a recently proposed practical algorithm called sharpness-aware minimization, supporting its success in practice.</description>
      <guid isPermaLink="false">oai:arXiv.org:2305.15659v3</guid>
      <category>cs.LG</category>
      <category>cs.AI</category>
      <category>math.OC</category>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Kwangjun Ahn, Ali Jadbabaie, Suvrit Sra</dc:creator>
    </item>
    <item>
      <title>Decision-focused predictions via pessimistic bilevel optimization: a computational study</title>
      <link>https://arxiv.org/abs/2312.17640</link>
      <description>arXiv:2312.17640v2 Announce Type: replace-cross 
Abstract: Dealing with uncertainty in optimization parameters is an important and longstanding challenge. Typically, uncertain parameters are predicted accurately, and then a deterministic optimization problem is solved. However, the decisions produced by this so-called \emph{predict-then-optimize} procedure can be highly sensitive to uncertain parameters. In this work, we contribute to recent efforts in producing \emph{decision-focused} predictions, i.e., to build predictive models that are constructed with the goal of minimizing a \emph{regret} measure on the decisions taken with them. We begin by formulating the exact expected regret minimization as a pessimistic bilevel optimization model. Then, we establish NP-completeness of this problem, even in a heavily restricted case. Using duality arguments, we reformulate it as a non-convex quadratic optimization problem. Finally, we show various computational techniques to achieve tractability. We report extensive computational results on shortest-path instances with uncertain cost vectors. Our results indicate that our approach can improve training performance over the approach of Elmachtoub and Grigas (2022), a state-of-the-art method for decision-focused learning.</description>
      <guid isPermaLink="false">oai:arXiv.org:2312.17640v2</guid>
      <category>cs.LG</category>
      <category>math.OC</category>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>V\'ictor Bucarey, Sophia Calder\'on, Gonzalo Mu\~noz, Frederic Semet</dc:creator>
    </item>
    <item>
      <title>Deep learning algorithms for FBSDEs with jumps: Applications to option pricing and a MFG model for smart grids</title>
      <link>https://arxiv.org/abs/2401.03245</link>
      <description>arXiv:2401.03245v2 Announce Type: replace-cross 
Abstract: In this paper, we introduce various machine learning solvers for (coupled) forward-backward systems of stochastic differential equations (FBSDEs) driven by a Brownian motion and a Poisson random measure. We provide a rigorous comparison of the different algorithms and demonstrate their effectiveness in various applications, such as cases derived from pricing with jumps and mean-field games. In particular, we show the efficiency of the deep-learning algorithms to solve a coupled multi-dimensional FBSDE system driven by a time-inhomogeneous jump process with stochastic intensity, which describes the Nash equilibria for a specific mean-field game (MFG) problem for which we also provide the complete theoretical resolution. More precisely, we develop an extension of the MFG model for smart grids introduced in Alasseur, Campi, Dumitrescu and Zeng (Annals of Operations Research, 2023) to the case when the random jump times correspond to the jump times of a doubly Poisson process. We first provide an existence result of an equilibria and derive its semi-explicit characterization in terms of a system of FBSDEs in the linear-quadratic setting. We then compare the MFG solution to the optimal strategy of a central planner and provide several numerical illustrations using the deep-learning solvers presented in the first part of the paper.</description>
      <guid isPermaLink="false">oai:arXiv.org:2401.03245v2</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <category>math.OC</category>
      <category>math.PR</category>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Cl\'emence Alasseur, Zakaria Bensaid, Roxana Dumitrescu, Xavier Warin</dc:creator>
    </item>
    <item>
      <title>Generating Likely Counterfactuals Using Sum-Product Networks</title>
      <link>https://arxiv.org/abs/2401.14086</link>
      <description>arXiv:2401.14086v2 Announce Type: replace-cross 
Abstract: Explainability of decisions made by AI systems is driven by both recent regulation and user demand. These decisions are often explainable only \emph{post hoc}, after the fact. In counterfactual explanations, one may ask what constitutes the best counterfactual explanation. Clearly, multiple criteria must be taken into account, although "distance from the sample" is a key criterion. Recent methods that consider the plausibility of a counterfactual seem to sacrifice this original objective. Here, we present a system that provides high-likelihood explanations that are, at the same time, close and sparse. We show that the search for the most likely explanations satisfying many common desiderata for counterfactual explanations can be modeled using mixed-integer optimization (MIO). In the process, we propose an MIO formulation of a Sum-Product Network (SPN) and use the SPN to estimate the likelihood of a counterfactual, which can be of independent interest.</description>
      <guid isPermaLink="false">oai:arXiv.org:2401.14086v2</guid>
      <category>cs.AI</category>
      <category>cs.LG</category>
      <category>math.OC</category>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Jiri Nemecek, Tomas Pevny, Jakub Marecek</dc:creator>
    </item>
    <item>
      <title>Role of Momentum in Smoothing Objective Function in Implicit Graduated Optimization</title>
      <link>https://arxiv.org/abs/2402.02325</link>
      <description>arXiv:2402.02325v2 Announce Type: replace-cross 
Abstract: While stochastic gradient descent (SGD) with momentum has fast convergence and excellent generalizability, a theoretical explanation for this is lacking. In this paper, we show that SGD with momentum smooths the objective function, the degree of which is determined by the learning rate, the batch size, the momentum factor, the variance of the stochastic gradient, and the upper bound of the gradient norm. This theoretical finding reveals why momentum improves generalizability and provides new insights into the role of the hyperparameters, including momentum factor. We also present an implicit graduated optimization algorithm that exploits the smoothing properties of SGD with momentum and provide experimental results supporting our assertion that SGD with momentum smooths the objective function.</description>
      <guid isPermaLink="false">oai:arXiv.org:2402.02325v2</guid>
      <category>cs.LG</category>
      <category>math.OC</category>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Naoki Sato, Hideaki Iiduka</dc:creator>
    </item>
    <item>
      <title>SCAFFLSA: Taming Heterogeneity in Federated Linear Stochastic Approximation and TD Learning</title>
      <link>https://arxiv.org/abs/2402.04114</link>
      <description>arXiv:2402.04114v2 Announce Type: replace-cross 
Abstract: In this paper, we analyze the sample and communication complexity of the federated linear stochastic approximation (FedLSA) algorithm. We explicitly quantify the effects of local training with agent heterogeneity. We show that the communication complexity of FedLSA scales polynomially with the inverse of the desired accuracy $\epsilon$. To overcome this, we propose SCAFFLSA a new variant of FedLSA that uses control variates to correct for client drift, and establish its sample and communication complexities. We show that for statistically heterogeneous agents, its communication complexity scales logarithmically with the desired accuracy, similar to Scaffnew. An important finding is that, compared to the existing results for Scaffnew, the sample complexity scales with the inverse of the number of agents, a property referred to as linear speed-up. Achieving this linear speed-up requires completely new theoretical arguments. We apply the proposed method to federated temporal difference learning with linear function approximation and analyze the corresponding complexity improvements.</description>
      <guid isPermaLink="false">oai:arXiv.org:2402.04114v2</guid>
      <category>stat.ML</category>
      <category>cs.LG</category>
      <category>math.OC</category>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Paul Mangold, Sergey Samsonov, Safwan Labbi, Ilya Levin, Reda Alami, Alexey Naumov, Eric Moulines</dc:creator>
    </item>
    <item>
      <title>AdAdaGrad: Adaptive Batch Size Schemes for Adaptive Gradient Methods</title>
      <link>https://arxiv.org/abs/2402.11215</link>
      <description>arXiv:2402.11215v2 Announce Type: replace-cross 
Abstract: The choice of batch sizes in minibatch stochastic gradient optimizers is critical in large-scale model training for both optimization and generalization performance. Although large-batch training is arguably the dominant training paradigm for large-scale deep learning due to hardware advances, the generalization performance of the model deteriorates compared to small-batch training, leading to the so-called "generalization gap" phenomenon. To mitigate this, we investigate adaptive batch size strategies derived from adaptive sampling methods, originally developed only for stochastic gradient descent. Given the significant interplay between learning rates and batch sizes, and considering the prevalence of adaptive gradient methods in deep learning, we emphasize the need for adaptive batch size strategies in these contexts. We introduce AdAdaGrad and its scalar variant AdAdaGradNorm, which progressively increase batch sizes during training, while model updates are performed using AdaGrad and AdaGradNorm. We prove that AdAdaGradNorm converges with high probability at a rate of $\mathscr{O}(1/K)$ to find a first-order stationary point of smooth nonconvex functions within $K$ iterations. AdAdaGrad also demonstrates similar convergence properties when integrated with a novel coordinate-wise variant of our adaptive batch size strategies. We corroborate our theoretical claims by performing image classification experiments, highlighting the merits of the proposed schemes in terms of both training efficiency and model generalization. Our work unveils the potential of adaptive batch size strategies for adaptive gradient optimizers in large-scale model training.</description>
      <guid isPermaLink="false">oai:arXiv.org:2402.11215v2</guid>
      <category>cs.LG</category>
      <category>math.OC</category>
      <category>stat.ML</category>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Tim Tsz-Kit Lau, Han Liu, Mladen Kolar</dc:creator>
    </item>
    <item>
      <title>LoRA Training in the NTK Regime has No Spurious Local Minima</title>
      <link>https://arxiv.org/abs/2402.11867</link>
      <description>arXiv:2402.11867v2 Announce Type: replace-cross 
Abstract: Low-rank adaptation (LoRA) has become the standard approach for parameter-efficient fine-tuning of large language models (LLM), but our theoretical understanding of LoRA has been limited. In this work, we theoretically analyze LoRA fine-tuning in the neural tangent kernel (NTK) regime with $N$ data points, showing: (i) full fine-tuning (without LoRA) admits a low-rank solution of rank $r\lesssim \sqrt{N}$; (ii) using LoRA with rank $r\gtrsim \sqrt{N}$ eliminates spurious local minima, allowing gradient descent to find the low-rank solutions; (iii) the low-rank solution found using LoRA generalizes well.</description>
      <guid isPermaLink="false">oai:arXiv.org:2402.11867v2</guid>
      <category>cs.LG</category>
      <category>math.OC</category>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Uijeong Jang, Jason D. Lee, Ernest K. Ryu</dc:creator>
    </item>
    <item>
      <title>Extended Flow Matching: a Method of Conditional Generation with Generalized Continuity Equation</title>
      <link>https://arxiv.org/abs/2402.18839</link>
      <description>arXiv:2402.18839v4 Announce Type: replace-cross 
Abstract: The task of conditional generation is one of the most important applications of generative models, and numerous methods have been developed to date based on the celebrated flow-based models. However, many flow-based models in use today are not built to allow one to introduce an explicit inductive bias to how the conditional distribution to be generated changes with respect to conditions. This can result in unexpected behavior in the task of style transfer, for example. In this research, we introduce extended flow matching (EFM), a direct extension of flow matching that learns a ``matrix field'' corresponding to the continuous map from the space of conditions to the space of distributions. We show that we can introduce inductive bias to the conditional generation through the matrix field and demonstrate this fact with MMOT-EFM, a version of EFM that aims to minimize the Dirichlet energy or the sensitivity of the distribution with respect to conditions. We will present our theory along with experimental results that support the competitiveness of EFM in conditional generation.</description>
      <guid isPermaLink="false">oai:arXiv.org:2402.18839v4</guid>
      <category>cs.LG</category>
      <category>math.AP</category>
      <category>math.FA</category>
      <category>math.OC</category>
      <category>math.PR</category>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Noboru Isobe, Masanori Koyama, Jinzhe Zhang, Kohei Hayashi, Kenji Fukumizu</dc:creator>
    </item>
    <item>
      <title>Strategizing against Q-learners: A Control-theoretical Approach</title>
      <link>https://arxiv.org/abs/2403.08906</link>
      <description>arXiv:2403.08906v2 Announce Type: replace-cross 
Abstract: In this paper, we explore the susceptibility of the independent Q-learning algorithms (a classical and widely used multi-agent reinforcement learning method) to strategic manipulation of sophisticated opponents in normal-form games played repeatedly. We quantify how much strategically sophisticated agents can exploit naive Q-learners if they know the opponents' Q-learning algorithm. To this end, we formulate the strategic actors' interactions as a stochastic game (whose state encompasses Q-function estimates of the Q-learners) as if the Q-learning algorithms are the underlying dynamical system. We also present a quantization-based approximation scheme to tackle the continuum state space and analyze its performance for two competing strategic actors and a single strategic actor both analytically and numerically.</description>
      <guid isPermaLink="false">oai:arXiv.org:2403.08906v2</guid>
      <category>cs.GT</category>
      <category>cs.AI</category>
      <category>math.OC</category>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Yuksel Arslantas, Ege Yuceel, Muhammed O. Sayin</dc:creator>
    </item>
    <item>
      <title>LISA: Layerwise Importance Sampling for Memory-Efficient Large Language Model Fine-Tuning</title>
      <link>https://arxiv.org/abs/2403.17919</link>
      <description>arXiv:2403.17919v3 Announce Type: replace-cross 
Abstract: The machine learning community has witnessed impressive advancements since large language models (LLMs) first appeared. Yet, their massive memory consumption has become a significant roadblock to large-scale training. For instance, a 7B model typically requires at least 60 GB of GPU memory with full parameter training, which presents challenges for researchers without access to high-resource environments. Parameter Efficient Fine-Tuning techniques such as Low-Rank Adaptation (LoRA) have been proposed to alleviate this problem. However, in most large-scale fine-tuning settings, their performance does not reach the level of full parameter training because they confine the parameter search to a low-rank subspace. Attempting to complement this deficiency, we investigate the layerwise properties of LoRA on fine-tuning tasks and observe an unexpected but consistent skewness of weight norms across different layers. Utilizing this key observation, a surprisingly simple training strategy is discovered, which outperforms both LoRA and full parameter training in a wide range of settings with memory costs as low as LoRA. We name it Layerwise Importance Sampled AdamW (LISA), a promising alternative for LoRA, which applies the idea of importance sampling to different layers in LLMs and randomly freezes most middle layers during optimization. Experimental results show that with similar or less GPU memory consumption, LISA surpasses LoRA or even full parameter tuning in downstream fine-tuning tasks, where LISA consistently outperforms LoRA by over 10%-35% in terms of MT-Bench score while achieving on-par or better performance in MMLU, AGIEval and WinoGrande. On large models, specifically LLaMA-2-70B, LISA surpasses LoRA on MT-Bench, GSM8K, and PubMedQA, demonstrating its effectiveness across different domains.</description>
      <guid isPermaLink="false">oai:arXiv.org:2403.17919v3</guid>
      <category>cs.LG</category>
      <category>cs.AI</category>
      <category>cs.CL</category>
      <category>math.OC</category>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Rui Pan, Xiang Liu, Shizhe Diao, Renjie Pi, Jipeng Zhang, Chi Han, Tong Zhang</dc:creator>
    </item>
    <item>
      <title>A Mean-Field Analysis of Neural Stochastic Gradient Descent-Ascent for Functional Minimiax Optimization</title>
      <link>https://arxiv.org/abs/2404.12312</link>
      <description>arXiv:2404.12312v2 Announce Type: replace-cross 
Abstract: This paper studies minimax optimization problems defined over infinite-dimensional function classes of overparameterized two-layer neural networks. In particular, we consider the minimax optimization problem stemming from estimating linear functional equations defined by conditional expectations, where the objective functions are quadratic in the functional spaces. We address (i) the convergence of the stochastic gradient descent-ascent algorithm and (ii) the representation learning of the neural networks. We establish convergence under the mean-field regime by considering the continuous-time and infinite-width limit of the optimization dynamics. Under this regime, the stochastic gradient descent-ascent corresponds to a Wasserstein gradient flow over the space of probability measures defined over the space of neural network parameters. We prove that the Wasserstein gradient flow converges globally to a stationary point of the minimax objective at a $O(T^{-1} + \alpha^{-1})$ sublinear rate, and additionally finds the solution to the functional equation when the regularizer of the minimax objective is strongly convex. Here $T$ denotes the time and $\alpha$ is a scaling parameter of the neural networks. In terms of representation learning, our results show that the feature representation induced by the neural networks is allowed to deviate from the initial one by the magnitude of $O(\alpha^{-1})$, measured in terms of the Wasserstein distance. Finally, we apply our general results to concrete examples including policy evaluation, nonparametric instrumental variable regression, asset pricing, and adversarial Riesz representer estimation.</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.12312v2</guid>
      <category>cs.LG</category>
      <category>math.OC</category>
      <category>stat.ML</category>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Yuchen Zhu, Yufeng Zhang, Zhaoran Wang, Zhuoran Yang, Xiaohong Chen</dc:creator>
    </item>
    <item>
      <title>Optimality and uniqueness of the $D_4$ root system</title>
      <link>https://arxiv.org/abs/2404.18794</link>
      <description>arXiv:2404.18794v2 Announce Type: replace-cross 
Abstract: We prove that the $D_4$ root system (the set of vertices of the regular $24$-cell) is the unique optimal kissing configuration in $\mathbb R^4$, and is an optimal spherical code. For this, we use semidefinite programming to compute an exact optimal solution to the second level of the Lasserre hierarchy. We also improve the upper bound for the kissing number problem in $\mathbb R^6$ to $77$.</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.18794v2</guid>
      <category>math.MG</category>
      <category>math.OC</category>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>David de Laat, Nando M. Leijenhorst, Willem H. H. de Muinck Keizer</dc:creator>
    </item>
    <item>
      <title>Almost sure convergence rates of stochastic gradient methods under gradient domination</title>
      <link>https://arxiv.org/abs/2405.13592</link>
      <description>arXiv:2405.13592v2 Announce Type: replace-cross 
Abstract: Stochastic gradient methods are among the most important algorithms in training machine learning problems. While classical assumptions such as strong convexity allow a simple analysis they are rarely satisfied in applications. In recent years, global and local gradient domination properties have shown to be a more realistic replacement of strong convexity. They were proved to hold in diverse settings such as (simple) policy gradient methods in reinforcement learning and training of deep neural networks with analytic activation functions. We prove almost sure convergence rates $f(X_n)-f^*\in o\big( n^{-\frac{1}{4\beta-1}+\epsilon}\big)$ of the last iterate for stochastic gradient descent (with and without momentum) under global and local $\beta$-gradient domination assumptions. The almost sure rates get arbitrarily close to recent rates in expectation. Finally, we demonstrate how to apply our results to the training task in both supervised and reinforcement learning.</description>
      <guid isPermaLink="false">oai:arXiv.org:2405.13592v2</guid>
      <category>cs.LG</category>
      <category>math.OC</category>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Simon Weissmann, Sara Klein, Wa\"iss Azizian, Leif D\"oring</dc:creator>
    </item>
  </channel>
</rss>
