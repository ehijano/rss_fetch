<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>cs.CC updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/cs.CC</link>
    <description>cs.CC updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/cs.CC" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Thu, 26 Sep 2024 01:49:58 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Wed, 25 Sep 2024 00:00:00 -0400</pubDate>
    <skipDays>
      <day>Sunday</day>
      <day>Saturday</day>
    </skipDays>
    <item>
      <title>On the Complexity of Neural Computation in Superposition</title>
      <link>https://arxiv.org/abs/2409.15318</link>
      <description>arXiv:2409.15318v1 Announce Type: new 
Abstract: Recent advances in the understanding of neural networks suggest that superposition, the ability of a single neuron to represent multiple features simultaneously, is a key mechanism underlying the computational efficiency of large-scale networks. This paper explores the theoretical foundations of computing in superposition, focusing on explicit, provably correct algorithms and their efficiency. We present the first lower bounds showing that for a broad class of problems, including permutations and pairwise logical operations, a neural network computing in superposition requires at least $\Omega(m' \log m')$ parameters and $\Omega(\sqrt{m' \log m'})$ neurons, where $m'$ is the number of output features being computed. This implies that any ``lottery ticket'' sparse sub-network must have at least $\Omega(m' \log m')$ parameters no matter what the initial dense network size. Conversely, we show a nearly tight upper bound: logical operations like pairwise AND can be computed using $O(\sqrt{m'} \log m')$ neurons and $O(m' \log^2 m')$ parameters. There is thus an exponential gap between computing in superposition, the subject of this work, and representing features in superposition, which can require as little as $O(\log m'$) neurons based on the Johnson-Lindenstrauss Lemma. Our hope is that our results open a path for using complexity theoretic techniques in neural network interpretability research.</description>
      <guid isPermaLink="false">oai:arXiv.org:2409.15318v1</guid>
      <category>cs.CC</category>
      <category>cs.AI</category>
      <category>cs.DS</category>
      <category>cs.NE</category>
      <pubDate>Wed, 25 Sep 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Micah Adler, Nir Shavit</dc:creator>
    </item>
    <item>
      <title>Hardness of Approximate Sperner and Applications to Envy-Free Cake Cutting</title>
      <link>https://arxiv.org/abs/2409.15713</link>
      <description>arXiv:2409.15713v1 Announce Type: new 
Abstract: Given a so called ''Sperner coloring'' of a triangulation of the $D$-dimensional simplex, Sperner's lemma guarantees the existence of a rainbow simplex, i.e. a simplex colored by all $D+1$ colors. However, finding a rainbow simplex was the first problem to be proven $\mathsf{PPAD}$-complete in Papadimitriou's classical paper introducing the class $\mathsf{PPAD}$ (1994). In this paper, we prove that the problem does not become easier if we relax ''all $D+1$ colors'' to allow some fraction of missing colors: in fact, for any constant $D$, finding even a simplex with just three colors remains $\mathsf{PPAD}$-complete!
  Our result has an interesting application for the envy-free cake cutting from fair division. It is known that if agents value pieces of cake using general continuous functions satisfying a simple boundary condition (''a non-empty piece is better than an empty piece of cake''), there exists an envy-free allocation with connected pieces. We show that for any constant number of agents it is $\mathsf{PPAD}$-complete to find an allocation -- even using any constant number of possibly disconnected pieces -- that makes just three agents envy-free. Our results extend to super-constant dimension, number of agents, and number of pieces, as long as they are asymptotically bounded by any $\log^{1-\Omega(1)}(\epsilon)$, where $\epsilon$ is the precision parameter (side length for Sperner and approximate envy-free for cake cutting).</description>
      <guid isPermaLink="false">oai:arXiv.org:2409.15713v1</guid>
      <category>cs.CC</category>
      <category>cs.GT</category>
      <pubDate>Wed, 25 Sep 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Ruiquan Gao, Mohammad Roghani, Aviad Rubinstein, Amin Saberi</dc:creator>
    </item>
    <item>
      <title>Non-Boolean OMv: One More Reason to Believe Lower Bounds for Dynamic Problems</title>
      <link>https://arxiv.org/abs/2409.15970</link>
      <description>arXiv:2409.15970v1 Announce Type: new 
Abstract: Most of the known tight lower bounds for dynamic problems are based on the Online Boolean Matrix-Vector Multiplication (OMv) Hypothesis, which is not as well studied and understood as some more popular hypotheses in fine-grained complexity. It would be desirable to base hardness of dynamic problems on a more believable hypothesis. We propose analogues of the OMv Hypothesis for variants of matrix multiplication that are known to be harder than Boolean product in the offline setting, namely: equality, dominance, min-witness, min-max, and bounded monotone min-plus products. These hypotheses are a priori weaker assumptions than the standard (Boolean) OMv Hypothesis. Somewhat surprisingly, we show that they are actually equivalent to it. This establishes the first such fine-grained equivalence class for dynamic problems.</description>
      <guid isPermaLink="false">oai:arXiv.org:2409.15970v1</guid>
      <category>cs.CC</category>
      <category>cs.DS</category>
      <pubDate>Wed, 25 Sep 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Bingbing Hu, Adam Polak</dc:creator>
    </item>
    <item>
      <title>Examples of slow convergence for adaptive regularization optimization methods are not isolated</title>
      <link>https://arxiv.org/abs/2409.16047</link>
      <description>arXiv:2409.16047v1 Announce Type: cross 
Abstract: The adaptive regularization algorithm for unconstrained nonconvex optimization was shown in Nesterov and Polyak (2006) and Cartis, Gould and Toint (2011) to require, under standard assumptions, at most $\mathcal{O}(\epsilon^{3/(3-q)})$ evaluations of the objective function and its derivatives of degrees one and two to produce an $\epsilon$-approximate critical point of order $q\in\{1,2\}$. This bound was shown to be sharp for $q \in\{1,2\}$. This note revisits these results and shows that the example for which slow convergence is exhibited is not isolated, but that this behaviour occurs for a subset of univariate functions of nonzero measure.</description>
      <guid isPermaLink="false">oai:arXiv.org:2409.16047v1</guid>
      <category>math.OC</category>
      <category>cs.CC</category>
      <pubDate>Wed, 25 Sep 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Philippe L. Toint</dc:creator>
    </item>
    <item>
      <title>On the tractability and approximability of non-submodular cardinality-based $s$-$t$ cut problems in hypergraphs</title>
      <link>https://arxiv.org/abs/2409.16195</link>
      <description>arXiv:2409.16195v1 Announce Type: cross 
Abstract: A minimum $s$-$t$ cut in a hypergraph is a bipartition of vertices that separates two nodes $s$ and $t$ while minimizing a hypergraph cut function. The cardinality-based hypergraph cut function assigns a cut penalty to each hyperedge based on the number of nodes in the hyperedge that are on each side of the split. Previous work has shown that when hyperedge cut penalties are submodular, this problem can be reduced to a graph $s$-$t$ cut problem and hence solved in polynomial time. NP-hardness results are also known for a certain class of non-submodular penalties, though the complexity remained open in many parameter regimes. In this paper we highlight and leverage a connection to Valued Constraint Satisfaction Problems to show that the problem is NP-hard for all non-submodular hyperedge cut penalty, except for one trivial case where a 0-cost solution is always possible. We then turn our attention to approximation strategies and approximation hardness results in the non-submodular case. We design a strategy for projecting non-submodular penalties to the submodular region, which we prove gives the optimal approximation among all such projection strategies. We also show that alternative approaches are unlikely to provide improved guarantees, by showing it is UGC-hard to obtain a better approximation in the simplest setting where all hyperedges have exactly 4 nodes.</description>
      <guid isPermaLink="false">oai:arXiv.org:2409.16195v1</guid>
      <category>cs.DS</category>
      <category>cs.CC</category>
      <category>cs.DM</category>
      <pubDate>Wed, 25 Sep 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Vedangi Bengali, Nate Veldt</dc:creator>
    </item>
    <item>
      <title>Discreteness of asymptotic tensor ranks</title>
      <link>https://arxiv.org/abs/2306.01718</link>
      <description>arXiv:2306.01718v3 Announce Type: replace 
Abstract: Tensor parameters that are amortized or regularized over large tensor powers, often called "asymptotic" tensor parameters, play a central role in several areas including algebraic complexity theory (constructing fast matrix multiplication algorithms), quantum information (entanglement cost and distillable entanglement), and additive combinatorics (bounds on cap sets, sunflower-free sets, etc.). Examples are the asymptotic tensor rank, asymptotic slice rank and asymptotic subrank. Recent works (Costa-Dalai, Blatter-Draisma-Rupniewski, Christandl-Gesmundo-Zuiddam) have investigated notions of discreteness (no accumulation points) or "gaps" in the values of such tensor parameters.
  We prove a general discreteness theorem for asymptotic tensor parameters of order-three tensors and use this to prove that (1) over any finite field (and in fact any finite set of coefficients in any field), the asymptotic subrank and the asymptotic slice rank have no accumulation points, and (2) over the complex numbers, the asymptotic slice rank has no accumulation points.
  Central to our approach are two new general lower bounds on the asymptotic subrank of tensors, which measures how much a tensor can be diagonalized. The first lower bound says that the asymptotic subrank of any concise three-tensor is at least the cube-root of the smallest dimension. The second lower bound says that any concise three-tensor that is "narrow enough" (has one dimension much smaller than the other two) has maximal asymptotic subrank.
  Our proofs rely on new lower bounds on the maximum rank in matrix subspaces that are obtained by slicing a three-tensor in the three different directions. We prove that for any concise tensor, the product of any two such maximum ranks must be large, and as a consequence there are always two distinct directions with large max-rank.</description>
      <guid isPermaLink="false">oai:arXiv.org:2306.01718v3</guid>
      <category>cs.CC</category>
      <category>math.CO</category>
      <category>quant-ph</category>
      <pubDate>Wed, 25 Sep 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Jop Bri\"et, Matthias Christandl, Itai Leigh, Amir Shpilka, Jeroen Zuiddam</dc:creator>
    </item>
    <item>
      <title>Derandomized Non-Abelian Homomorphism Testing in Low Soundness Regime</title>
      <link>https://arxiv.org/abs/2405.18998</link>
      <description>arXiv:2405.18998v2 Announce Type: replace 
Abstract: We give a randomness-efficient homomorphism test in the low soundness regime for functions, $f: G\to \mathbb{U}_t$, from an arbitrary finite group $G$ to $t\times t$ unitary matrices. We show that if such a function passes a derandomized Blum--Luby--Rubinfeld (BLR) test (using small-bias sets), then (i) it correlates with a function arising from a genuine homomorphism, and (ii) it has a non-trivial Fourier mass on a low-dimensional irreducible representation.
  In the full randomness regime, such a test for matrix-valued functions on finite groups implicitly appears in the works of Gowers and Hatami [Sbornik: Mathematics '17], and Moore and Russell [SIAM Journal on Discrete Mathematics '15]. Thus, our work can be seen as a near-optimal derandomization of their results. Our key technical contribution is a "degree-2 expander mixing lemma'' that shows that Gowers' $\mathrm{U}^2$ norm can be efficiently estimated by restricting it to a small-bias subset. Another corollary is a "derandomized'' version of a useful lemma due to Babai, Nikolov, and Pyber [SODA'08] and Gowers [Comb. Probab. Comput.'08].</description>
      <guid isPermaLink="false">oai:arXiv.org:2405.18998v2</guid>
      <category>cs.CC</category>
      <category>cs.DM</category>
      <category>math.GR</category>
      <category>math.RT</category>
      <pubDate>Wed, 25 Sep 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Tushant Mittal, Sourya Roy</dc:creator>
    </item>
    <item>
      <title>On $NP$ versus ${\rm co}NP$ and Frege Systems</title>
      <link>https://arxiv.org/abs/2406.10476</link>
      <description>arXiv:2406.10476v5 Announce Type: replace 
Abstract: We prove in this paper that there is a language $L_d$ accepted by some nondeterministic Turing machines but not by any ${\rm co}\mathcal{NP}$-machines (defined later). Then we further show that $L_d$ is in $\mathcal{NP}$, thus proving that $\mathcal{NP}\neq{\rm co}\mathcal{NP}$. The techniques used in this paper are lazy-diagonalization and the novel new technique developed in author's recent work \cite{Lin21}. Since there exists oracle $A$ such that $\mathcal{NP}^A={\rm co}\mathcal{NP}^A$, we then explore what mysterious behind it and showing that if $\mathcal{NP}^A={\rm co}\mathcal{NP}^A$ and under some rational assumptions, the set of all polynomial-time co-nondeterministic oracle Turing machines with oracle $A$ is not enumerable. As a by-product, we reach the important result that $\mathcal{P}\neq\mathcal{NP}$ \cite{Lin21} once again, which is clear from the above outcome and the well-known fact that $\mathcal{P}={\rm co}\mathcal{P}$. Next, we show that the complexity class ${\rm co}\mathcal{NP}$ has intermediate languages, i.e., there are language $L_{inter}\in{\rm co}\mathcal{NP}$ which is not in $\mathcal{P}$ and not ${\rm co}\mathcal{NP}$-complete. We also summarize other direct consequences implied by our main outcome such as $\mathcal{NEXP}\neq{\rm co}\mathcal{NEXP}$ and other which is in the area of proof complexity. Lastly, we show a lower bounds result for Frege proof systems, i.e., no Frege proof systems can be polynomial bounded.</description>
      <guid isPermaLink="false">oai:arXiv.org:2406.10476v5</guid>
      <category>cs.CC</category>
      <pubDate>Wed, 25 Sep 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Tianrong Lin</dc:creator>
    </item>
    <item>
      <title>Assembly Theory Reduced to Shannon Entropy and Rendered Redundant by Naive Statistical Algorithms</title>
      <link>https://arxiv.org/abs/2408.15108</link>
      <description>arXiv:2408.15108v3 Announce Type: replace-cross 
Abstract: In this paper we give answer to an argument trying to show the divergence of Assembly Theory from LZ compression. We formally proved that any implementation of the concept of `copy number' underlying Assembly Theory (AT) and its assembly index (Ai) is equivalent to Shannon Entropy and not fundamentally or methodologically different from algorithms like ZIP and PNG via an LZ compressing grammar. Here we show that the weak empirical correlation between Ai and LZW, which the authors offered as a defence against the previously proven result that the assembly index calculation method is an LZ scheme, is based on an incomplete and misleading experiment. When the experiment is completed and conducted properly, the asymptotic convergence to LZ compression and Shannon Entropy is evident and aligned with the mathematical proof previously offered. Therefore, this completes both the theoretical and empirical demonstrations that any variation of the copy-number concept underlying AT, which resorts to counting the number of object repetitions `to arrive at a measure for life', is equivalent to statistical compression and Shannon Entropy. We demonstrate that the authors' `we-are-better-because-we-are-worse' defence argument against compression does not withstand basic scrutiny, and that their primary empirical results separating organic from inorganic compounds have not only been previously reported -- sans claims to unify physics and biology -- but are also driven solely by molecular length, not by any special feature of life captured by their assembly index. Finally, we show that Ai is a special case of our Block Decomposition Method introduced almost a decade earlier.</description>
      <guid isPermaLink="false">oai:arXiv.org:2408.15108v3</guid>
      <category>cs.IT</category>
      <category>cs.CC</category>
      <category>math.IT</category>
      <pubDate>Wed, 25 Sep 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Luan Ozelim, Abicumaran Uthamacumaran, Felipe S. Abrah\~ao, Santiago Hern\'andez-Orozco, Narsis A. Kiani, Jesper Tegn\'er, Hector Zenil</dc:creator>
    </item>
  </channel>
</rss>
