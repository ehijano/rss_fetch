<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>cs.IT updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/cs.IT</link>
    <description>cs.IT updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/cs.IT" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Thu, 24 Apr 2025 01:41:19 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Wed, 23 Apr 2025 00:00:00 -0400</pubDate>
    <skipDays>
      <day>Saturday</day>
      <day>Sunday</day>
    </skipDays>
    <item>
      <title>Capacity on BMS Channels via Code Symmetry and Nesting</title>
      <link>https://arxiv.org/abs/2504.15394</link>
      <description>arXiv:2504.15394v1 Announce Type: new 
Abstract: The past decade has seen notable advances in our understanding of structured error-correcting codes, particularly binary Reed--Muller (RM) codes. While initial breakthroughs were for erasure channels based on symmetry, extending these results to the binary symmetric channel (BSC) and other binary memoryless symmetric (BMS) channels required new tools and conditions. Recent work uses nesting to obtain multiple weakly correlated "looks" that imply capacity-achieving performance under bit-MAP and block-MAP decoding. This paper revisits and extends past approaches, aiming to simplify proofs, unify insights, and remove unnecessary conditions. By leveraging powerful results from the analysis of boolean functions, we derive recursive bounds using two or three looks at each stage. This gives bounds on the bit error probability that decay exponentially in the number of stages. For the BSC, we incorporate level-k inequalities and hypercontractive techniques to achieve the faster decay rate required for vanishing block error probability. The results are presented in a semitutorial style, providing both theoretical insights and practical implications for future research on structured codes.</description>
      <guid isPermaLink="false">oai:arXiv.org:2504.15394v1</guid>
      <category>cs.IT</category>
      <category>math.IT</category>
      <pubDate>Wed, 23 Apr 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Henry D. Pfister, Galen Reeves</dc:creator>
    </item>
    <item>
      <title>Validation of 3GPP TR 38.901 Indoor Hotspot Path Loss Model Based on Measurements Conducted at 6.75, 16.95, 28, and 73 GHz for 6G and Beyond</title>
      <link>https://arxiv.org/abs/2504.15589</link>
      <description>arXiv:2504.15589v1 Announce Type: new 
Abstract: This paper presents a thorough validation of the Third Generation Partnership Project (3GPP) Technical Report (TR) 38.901 indoor hotspot (InH) path loss model, as part of the 3GPP Release 19 study on "Channel model validation of TR 38.901 for 7-24 GHz," for 6G standardization. Specifically, we validate the 3GPP TR 38.901 path loss model for the InH scenario in both line of sight (LOS) and non line of sight (NLOS) channel conditions, using the floating intercept (FI) and alpha-beta-gamma (ABG) path loss models. The validation focuses on specific frequencies, including 6.75 GHz and 16.95 GHz, as well as the broader 7-24 GHz and 0.5-100 GHz frequency ranges. The validation is based on real-world measurements conducted at 6.75 GHz, 16.95 GHz, 28 GHz, and 73 GHz by NYU WIRELESS using a 1 GHz wideband time domain based sliding correlation channel sounder in the InH scenario for both LOS and NLOS channel conditions. Our results confirm that the 3GPP TR 38.901 path loss model for the InH scenario remains valid for the 7-24 GHz range in both LOS and NLOS conditions and provide valuable input for 6G standardization efforts.</description>
      <guid isPermaLink="false">oai:arXiv.org:2504.15589v1</guid>
      <category>cs.IT</category>
      <category>math.IT</category>
      <pubDate>Wed, 23 Apr 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Hitesh Poddar, Tomoki Yoshimura, Art Ishii</dc:creator>
    </item>
    <item>
      <title>Distributed Compression for Computation and Bounds on the Optimal Rate</title>
      <link>https://arxiv.org/abs/2504.15706</link>
      <description>arXiv:2504.15706v1 Announce Type: new 
Abstract: We address the problem of distributed computation of arbitrary functions of two correlated sources $X_1$ and $X_2$, residing in two distributed source nodes, respectively. We exploit the structure of a computation task by coding source characteristic graphs (and multiple instances using the $n$-fold OR product of this graph with itself). For regular graphs and general graphs, we establish bounds on the optimal rate -- characterized by the chromatic entropy for the $n$-fold graph products -- that allows a receiver for asymptotically lossless computation of arbitrary functions over finite fields. For the special class of cycle graphs (i.e., $2$-regular graphs), we establish an exact characterization of chromatic numbers and derive bounds on the required rates. Next, focusing on the more general class of $d$-regular graphs, we establish connections between $d$-regular graphs and expansion rates for $n$-fold graph powers using graph spectra. Finally, for general graphs, we leverage the Gershgorin Circle Theorem (GCT) to provide a characterization of the spectra, which allows us to build new bounds on the optimal rate. Our codes leverage the spectra of the computation and provide a graph expansion-based characterization to efficiently/succinctly capture the computation structure, providing new insights into the problem of distributed computation of arbitrary functions.</description>
      <guid isPermaLink="false">oai:arXiv.org:2504.15706v1</guid>
      <category>cs.IT</category>
      <category>math.IT</category>
      <pubDate>Wed, 23 Apr 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Mohammad Reza Deylam Salehi, Derya Malak</dc:creator>
    </item>
    <item>
      <title>Energy-Efficient SIM-assisted Communications: How Many Layers Do We Need?</title>
      <link>https://arxiv.org/abs/2504.15737</link>
      <description>arXiv:2504.15737v1 Announce Type: new 
Abstract: The stacked intelligent metasurface (SIM), comprising multiple layers of reconfigurable transmissive metasurfaces, is becoming an increasingly viable solution for future wireless communication systems. In this paper, we explore the integration of SIM in a multi-antenna base station for application to downlink multi-user communications, and a realistic power consumption model for SIM-assisted systems is presented. Specifically, we focus on maximizing the energy efficiency (EE) for hybrid precoding design, i.e., the base station digital precoding and SIM wave-based beamforming. Due to the non-convexity and high complexity of the formulated problem, we employ the quadratic transformation method to reformulate the optimization problem and propose an alternating optimization (AO)-based joint precoding framework. Specifically, a successive convex approximation (SCA) algorithm is adopted for the base station precoding design. For the SIM wave-based beamforming, two algorithms are employed: the high-performance semidefinite programming (SDP) method and the low-complexity projected gradient ascent (PGA) algorithm. In particular, the results indicate that while the optimal number of SIM layers for maximizing the EE and spectral efficiency differs, a design of 2 to 5 layers can achieve satisfactory performance for both. Finally, numerical results are illustrated to evaluate the effectiveness of the proposed hybrid precoding framework and to showcase the performance enhancement achieved by the algorithm in comparison to benchmark schemes.</description>
      <guid isPermaLink="false">oai:arXiv.org:2504.15737v1</guid>
      <category>cs.IT</category>
      <category>eess.SP</category>
      <category>math.IT</category>
      <pubDate>Wed, 23 Apr 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Enyu Shi, Jiayi Zhang, Jiancheng An, Marco Di Renzo, Bo Ai, Chau Yuen</dc:creator>
    </item>
    <item>
      <title>Shannon invariants: A scalable approach to information decomposition</title>
      <link>https://arxiv.org/abs/2504.15779</link>
      <description>arXiv:2504.15779v1 Announce Type: new 
Abstract: Distributed systems, such as biological and artificial neural networks, process information via complex interactions engaging multiple subsystems, resulting in high-order patterns with distinct properties across scales. Investigating how these systems process information remains challenging due to difficulties in defining appropriate multivariate metrics and ensuring their scalability to large systems. To address these challenges, we introduce a novel framework based on what we call "Shannon invariants" -- quantities that capture essential properties of high-order information processing in a way that depends only on the definition of entropy and can be efficiently calculated for large systems. Our theoretical results demonstrate how Shannon invariants can be used to resolve long-standing ambiguities regarding the interpretation of widely used multivariate information-theoretic measures. Moreover, our practical results reveal distinctive information-processing signatures of various deep learning architectures across layers, which lead to new insights into how these systems process information and how this evolves during training. Overall, our framework resolves fundamental limitations in analyzing high-order phenomena and offers broad opportunities for theoretical developments and empirical analyses.</description>
      <guid isPermaLink="false">oai:arXiv.org:2504.15779v1</guid>
      <category>cs.IT</category>
      <category>cs.AI</category>
      <category>cs.LG</category>
      <category>math.IT</category>
      <category>nlin.AO</category>
      <category>physics.data-an</category>
      <pubDate>Wed, 23 Apr 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Aaron J. Gutknecht, Fernando E. Rosas, David A. Ehrlich, Abdullah Makkeh, Pedro A. M. Mediano, Michael Wibral</dc:creator>
    </item>
    <item>
      <title>A new method for erasure decoding of convolutional codes</title>
      <link>https://arxiv.org/abs/2504.15873</link>
      <description>arXiv:2504.15873v1 Announce Type: new 
Abstract: In this paper, we propose a new erasure decoding algorithm for convolutional codes using the generator matrix. This implies that our decoding method also applies to catastrophic convolutional codes in opposite to the classic approach using the parity-check matrix. We compare the performance of both decoding algorithms. Moreover, we enlarge the family of optimal convolutional codes (complete-MDP) based on the generator matrix.</description>
      <guid isPermaLink="false">oai:arXiv.org:2504.15873v1</guid>
      <category>cs.IT</category>
      <category>math.IT</category>
      <pubDate>Wed, 23 Apr 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Julia Lieb, Raquel Pinto, Carlos Vela</dc:creator>
    </item>
    <item>
      <title>Active Reconfigurable Intelligent Surface Assisted MIMO: Electromagnetic-Compliant Modeling with Mutual Coupling</title>
      <link>https://arxiv.org/abs/2504.15961</link>
      <description>arXiv:2504.15961v1 Announce Type: new 
Abstract: Reconfigurable Intelligent Surfaces (RIS) represent a transformative technology for sixth-generation (6G) wireless communications, but it suffers from a significant limitation, namely the double-fading attenuation. Active RIS has emerged as a promising solution, effectively mitigating the attenuation issues associated with conventional RIS-assisted systems. However, the current academic work on active RIS focuses on the system-level optimization of active RIS, often overlooking the development of models that are compatible with its electromagnetic (EM) and physical properties. The challenge of constructing realistic, EM-compliant models for active RIS-assisted communication, as well as understanding their implications on system-level optimization, remains an open research area. To tackle these problems, in this paper we develop a novel EM-compliant model with mutual coupling (MC) for active RIS-assisted wireless systems by integrating the developed scattering-parameter ($S$-parameter) based active RIS framework with multiport network theory, which facilitates system-level analysis and optimization. To evaluate the performance of the EM-compliant active RIS model, we design the joint optimization scheme based on the transmit beamforming at the transmitter and the reflection coefficient at the active RIS to maximize the achievable rate of EM-compliant active RIS-assisted MIMO system. To tackle the inherent non-convexity of this problem, we employ the Sherman-Morrison inversion and Neumann series (SMaN)-based alternating optimization (AO) algorithm. Simulation results verified that EM property (i.e., MC effect) is an indispensable factor in the optimization process of MIMO systems. Neglecting this effect introduces a substantial performance gap, highlighting its significance in the more pronounced the MC effect is, the greater the gap in achievable rates.</description>
      <guid isPermaLink="false">oai:arXiv.org:2504.15961v1</guid>
      <category>cs.IT</category>
      <category>eess.SP</category>
      <category>math.IT</category>
      <pubDate>Wed, 23 Apr 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Yang Cao, Wenchi Cheng, Jingqing Wang, Wei Zhang</dc:creator>
    </item>
    <item>
      <title>A Markov Chain Monte Carlo Method for Efficient Finite-Length LDPC Code Design</title>
      <link>https://arxiv.org/abs/2504.16071</link>
      <description>arXiv:2504.16071v1 Announce Type: new 
Abstract: Low-density parity-check (LDPC) codes are among the most prominent error-correction schemes. They find application to fortify various modern storage, communication, and computing systems. Protograph-based (PB) LDPC codes offer many degrees of freedom in the code design and enable fast encoding and decoding. In particular, spatially-coupled (SC) and multi-dimensional (MD) circulant-based codes are PB-LDPC codes with excellent performance. Efficient finite-length (FL) algorithms are required in order to effectively exploit the available degrees of freedom offered by SC partitioning, lifting, and MD relocations. In this paper, we propose a novel Markov chain Monte Carlo (MCMC or MC$^2$) method to perform this FL optimization, addressing the removal of short cycles. While iterating, we draw samples from a defined distribution where the probability decreases as the number of short cycles from the previous iteration increases. We analyze our MC$^2$ method theoretically as we prove the invariance of the Markov chain where each state represents a possible partitioning or lifting arrangement. Via our simulations, we then fit the distribution of the number of cycles resulting from a given arrangement on a Gaussian distribution. We derive estimates for cycle counts that are close to the actual counts. Furthermore, we derive the order of the expected number of iterations required by our approach to reach a local minimum as well as the size of the Markov chain recurrent class. Our approach is compatible with code design techniques based on gradient-descent. Numerical results show that our MC$^2$ method generates SC codes with remarkably less number of short cycles compared with the current state-of-the-art. Moreover, to reach the same number of cycles, our method requires orders of magnitude less overall time compared with the available literature methods.</description>
      <guid isPermaLink="false">oai:arXiv.org:2504.16071v1</guid>
      <category>cs.IT</category>
      <category>eess.SP</category>
      <category>math.IT</category>
      <pubDate>Wed, 23 Apr 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Ata Tanr{\i}kulu, Mete Y{\i}ld{\i}r{\i}m, Ahmed Hareedy</dc:creator>
    </item>
    <item>
      <title>A Graph Based Raman Spectral Processing Technique for Exosome Classification</title>
      <link>https://arxiv.org/abs/2504.15324</link>
      <description>arXiv:2504.15324v1 Announce Type: cross 
Abstract: Exosomes are small vesicles crucial for cell signaling and disease biomarkers. Due to their complexity, an "omics" approach is preferable to individual biomarkers. While Raman spectroscopy is effective for exosome analysis, it requires high sample concentrations and has limited sensitivity to lipids and proteins. Surface-enhanced Raman spectroscopy helps overcome these challenges. In this study, we leverage Neo4j graph databases to organize 3,045 Raman spectra of exosomes, enhancing data generalization. To further refine spectral analysis, we introduce a novel spectral filtering process that integrates the PageRank Filter with optimal Dimensionality Reduction. This method improves feature selection, resulting in superior classification performance. Specifically, the Extra Trees model, using our spectral processing approach, achieves 0.76 and 0.857 accuracy in classifying hyperglycemic, hypoglycemic, and normal exosome samples based on Raman spectra and surface, respectively, with group 10-fold cross-validation. Our results show that graph-based spectral filtering combined with optimal dimensionality reduction significantly improves classification accuracy by reducing noise while preserving key biomarker signals. This novel framework enhances Raman-based exosome analysis, expanding its potential for biomedical applications, disease diagnostics, and biomarker discovery.</description>
      <guid isPermaLink="false">oai:arXiv.org:2504.15324v1</guid>
      <category>q-bio.QM</category>
      <category>cs.AI</category>
      <category>cs.IT</category>
      <category>cs.LG</category>
      <category>math.IT</category>
      <pubDate>Wed, 23 Apr 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Vuong M. Ngo, Edward Bolger, Stan Goodwin, John O'Sullivan, Dinh Viet Cuong, Mark Roantree</dc:creator>
    </item>
    <item>
      <title>Speculative Sampling via Exponential Races</title>
      <link>https://arxiv.org/abs/2504.15475</link>
      <description>arXiv:2504.15475v1 Announce Type: cross 
Abstract: Speculative decoding accelerates large language model inference using a smaller draft model. In this paper, we establish a surprising connection between speculative decoding and channel simulation, which aims at simulating a noisy channel using as few bits as possible. This connection allows us to provide an information-theoretic analysis of the speed up that can be achieved by speculative decoding. Leveraging this link, we derive an explicit relation between generation speed-up and the number of tokens $k$ generated by the draft model for large $k$, which serves as an upper bound for all $k$. We also propose a novel speculative decoding method via exponential race ERSD that matches state-of-the-art performance.</description>
      <guid isPermaLink="false">oai:arXiv.org:2504.15475v1</guid>
      <category>cs.CL</category>
      <category>cs.IT</category>
      <category>math.IT</category>
      <pubDate>Wed, 23 Apr 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Szymon Kobus, Deniz G\"und\"uz</dc:creator>
    </item>
    <item>
      <title>Transport f divergences</title>
      <link>https://arxiv.org/abs/2504.15515</link>
      <description>arXiv:2504.15515v2 Announce Type: cross 
Abstract: We define a class of divergences to measure differences between probability density functions in one-dimensional sample space. The construction is based on the convex function with the Jacobi operator of mapping function that pushforwards one density to the other. We call these information measures transport f-divergences. We present several properties of transport $f$-divergences, including invariances, convexities, variational formulations, and Taylor expansions in terms of mapping functions. Examples of transport f-divergences in generative models are provided.</description>
      <guid isPermaLink="false">oai:arXiv.org:2504.15515v2</guid>
      <category>math.ST</category>
      <category>cs.AI</category>
      <category>cs.IT</category>
      <category>math.IT</category>
      <category>stat.TH</category>
      <pubDate>Wed, 23 Apr 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Wuchen Li</dc:creator>
    </item>
    <item>
      <title>Bayesian information theoretic model-averaging stochastic item selection for computer adaptive testing: compromise-free item exposure</title>
      <link>https://arxiv.org/abs/2504.15543</link>
      <description>arXiv:2504.15543v1 Announce Type: cross 
Abstract: The goal of Computer Adaptive Testing (CAT) is to reliably estimate an individual's ability as modeled by an item response theory (IRT) instrument using only a subset of the instrument's items. A secondary goal is to vary the items presented across different testing sessions so that the sequence of items does not become overly stereotypical -- we want all items to have an exposure rate sufficiently far from zero. We formulate the optimization problem for CAT in terms of Bayesian information theory, where one chooses the item at each step based on the criterion of the ability model discrepancy -- the statistical distance between the ability estimate at the next step and the full-test ability estimate. This viewpoint of CAT naturally motivates a stochastic selection procedure that equates choosing the next item to sampling from a model-averaging ensemble ability model. Using the NIH Work Disability Functional Assessment Battery (WD-FAB), we evaluate our new methods in comparison to pre-existing methods found in the literature. We find that our stochastic selector has superior properties in terms of both item exposure and test accuracy/efficiency.</description>
      <guid isPermaLink="false">oai:arXiv.org:2504.15543v1</guid>
      <category>stat.ME</category>
      <category>cs.IT</category>
      <category>math.IT</category>
      <category>stat.ML</category>
      <pubDate>Wed, 23 Apr 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Joshua C. Chang, Edison Choe</dc:creator>
    </item>
    <item>
      <title>Cryptoanalysis of a public key exchange based on circulant matrix over digital semiring</title>
      <link>https://arxiv.org/abs/2504.15880</link>
      <description>arXiv:2504.15880v1 Announce Type: cross 
Abstract: We present a cryptanalysis of a key exchange protocol based on the digital semiring. For this purpose, we find the maximal solution of a linear system over such semiring, and use the properties of circulant matrix to demonstrate that the protocol is vulnerable. Specifically, we provide an efficient attack that recovers the shared secret key from publicly exchanged information for any instance of the digital semiring in polynomial time.</description>
      <guid isPermaLink="false">oai:arXiv.org:2504.15880v1</guid>
      <category>cs.CR</category>
      <category>cs.IT</category>
      <category>math.AC</category>
      <category>math.IT</category>
      <pubDate>Wed, 23 Apr 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Alvaro Otero Sanchez</dc:creator>
    </item>
    <item>
      <title>Over-the-Air Transmission of Zak-OTFS with Spread Pilots on Sub-THz Communications Testbed</title>
      <link>https://arxiv.org/abs/2504.15947</link>
      <description>arXiv:2504.15947v1 Announce Type: cross 
Abstract: Looking towards 6G wireless systems, frequency bands like the sub-terahertz (sub-THz) band (100 GHz - 300 GHz) are gaining traction for their promises of large available swaths of bandwidth to support the ever-growing data demands. However, challenges with harsh channel conditions and hardware nonlinearities in the sub-THz band require robust communication techniques with favorable properties, such as good spectral efficiency and low peak-to-average power ratio (PAPR). Recently, OTFS and its variants have garnered significant attention for their performance in severe conditions (like high delay and Doppler), making it a promising candidate for future communications. In this work, we implement Zak-OTFS for the over-the-air experiments with traditional point pilots and the new spread pilots. Notably, we design our spread-pilot waveforms with communications and sensing coexisting in the same radio resources. We define the system model and the signal design for integration onto our state-of-the-art sub-THz wireless testbed. We show successful data transmission over-the-air at 140 GHz and 240 GHz in a variety of signal-to-noise ratio (SNR) conditions. In addition, we demonstrate integrated sensing and communications (ISAC) capabilities and show PAPR improvement of over 5 dB with spread pilots compared to point pilots.</description>
      <guid isPermaLink="false">oai:arXiv.org:2504.15947v1</guid>
      <category>eess.SP</category>
      <category>cs.IT</category>
      <category>math.IT</category>
      <pubDate>Wed, 23 Apr 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Claire Parisi, Venkatesh Khammammetti, Robert Calderbank, Lauren Huie</dc:creator>
    </item>
    <item>
      <title>A Primer on Zadoff Chu Sequences</title>
      <link>https://arxiv.org/abs/2211.05702</link>
      <description>arXiv:2211.05702v3 Announce Type: replace 
Abstract: Zadoff-Chu (ZC) sequences are an important manifestation of spread spectrum in modern cellular systems, including LTE and 5G NR. They have to some extent displaced PN and Walsh sequences which were the mainstays of 3G cellular (WCDMA and cdma2000) and the 2G-era IS-95. ZC sequences are complex sequences with unit amplitude and particular phase shifts, as opposed to Walsh and PN codes which are real and binary valued, most commonly $\pm1$.
  ZC sequences have a number of remarkable and desirable properties that we define in the next section. Because of these properties, they are used for many key functions in current cellular systems, and are likely to be prevalent in future cellular systems as well. In LTE and 5G NR, they are widely used for a number of important initial access and overhead channel functions that are often overlooked by engineers who focus on data transmission. For example, ZC sequences are used for initial access in both the downlink (synchronization sequences) and uplink (random access premables). They are also used for transmitting uplink control information, and as pilot symbols for both uplink channel sounding and fine-grained channel estimation. It is not an exaggeration to say that most types of signals other than the data transmissions in modern cellular standards utilize ZC sequences.
  In this primer, we define ZC sequences and introduce their key properties, and provide some examples. We also discuss modified ZC sequences that are commonly used in practice, but are not, strictly speaking, ZC sequences. We also overview their uses in LTE and 5G.</description>
      <guid isPermaLink="false">oai:arXiv.org:2211.05702v3</guid>
      <category>cs.IT</category>
      <category>math.IT</category>
      <pubDate>Wed, 23 Apr 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Jeffrey G. Andrews</dc:creator>
    </item>
    <item>
      <title>Graph Neural Networks for Next-Generation-IoT: Recent Advances and Open Challenges</title>
      <link>https://arxiv.org/abs/2412.20634</link>
      <description>arXiv:2412.20634v2 Announce Type: replace 
Abstract: Graph Neural Networks (GNNs) have emerged as a critical tool for optimizing and managing the complexities of the Internet of Things (IoT) in next-generation networks. This survey presents a comprehensive exploration of how GNNs may be harnessed in 6G IoT environments, focusing on key challenges and opportunities through a series of open questions. We commence with an exploration of GNN paradigms and the roles of node, edge, and graph-level tasks in solving wireless networking problems and highlight GNNs' ability to overcome the limitations of traditional optimization methods. This guidance enhances problem-solving efficiency across various next-generation (NG) IoT scenarios. Next, we provide a detailed discussion of the application of GNN in advanced NG enabling technologies, including massive MIMO, reconfigurable intelligent surfaces, satellites, THz, mobile edge computing (MEC), and ultra-reliable low latency communication (URLLC). We then delve into the challenges posed by adversarial attacks, offering insights into defense mechanisms to secure GNN-based NG-IoT networks. Next, we examine how GNNs can be integrated with future technologies like integrated sensing and communication (ISAC), satellite-air-ground-sea integrated networks (SAGSIN), and quantum computing. Our findings highlight the transformative potential of GNNs in improving efficiency, scalability, and security within NG-IoT systems, paving the way for future advances. Finally, we propose a set of design guidelines to facilitate the development of efficient, scalable, and secure GNN models tailored for NG IoT applications.</description>
      <guid isPermaLink="false">oai:arXiv.org:2412.20634v2</guid>
      <category>cs.IT</category>
      <category>math.IT</category>
      <pubDate>Wed, 23 Apr 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Nguyen Xuan Tung, Le Tung Giang, Bui Duc Son, Seon Geun Jeong, Trinh Van Chien, Won Joo Hwang, Lajos Hanzo</dc:creator>
    </item>
    <item>
      <title>Effective Application of Normalized Min-Sum Decoding for Short BCH Codes</title>
      <link>https://arxiv.org/abs/2412.20828</link>
      <description>arXiv:2412.20828v3 Announce Type: replace 
Abstract: This paper introduces an enhanced normalized min-sum decoder designed to address the performance and complexity challenges associated with developing parallelizable decoders for short BCH codes in high-throughput applications. The decoder optimizes the standard parity-check matrix using heuristic binary summation and random cyclic row shifts, resulting in a Tanner graph with low density, controlled redundancy, and minimized length-4 cycles. The impact of row redundancy and rank deficiency in the dual code's minimum-weight codewords on decoding performance is analyzed. To improve convergence, three random automorphisms are applied simultaneously to the inputs, with the resulting messages merged at the end of each iteration. Extensive simulations demonstrate that, for BCH codes with block lengths of 63 and 127, the enhanced normalized min-sum decoder achieves a 1-2 dB performance gain and 100X faster convergence compared to existing parallel and iterative decoders. Additionally, a hybrid decoding scheme is proposed, which selectively activates order statistics decoding when the enhanced normalized min-sum decoder fails. This hybrid approach is shown to approach maximum-likelihood performance while retaining the advantages of the normalized min-sum decoder across a broad SNR range.</description>
      <guid isPermaLink="false">oai:arXiv.org:2412.20828v3</guid>
      <category>cs.IT</category>
      <category>math.IT</category>
      <pubDate>Wed, 23 Apr 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <dc:creator>Guangwen Li, Xiao Yu</dc:creator>
    </item>
    <item>
      <title>Universal Rate-Distortion-Classification Representations for Lossy Compression</title>
      <link>https://arxiv.org/abs/2504.09025</link>
      <description>arXiv:2504.09025v2 Announce Type: replace 
Abstract: In lossy compression, Wang et al. [1] recently introduced the rate-distortion-perception-classification function, which supports multi-task learning by jointly optimizing perceptual quality, classification accuracy, and reconstruction fidelity. Building on the concept of a universal encoder introduced in [2], we investigate the universal representations that enable a broad range of distortion-classification tradeoffs through a single shared encoder coupled with multiple task-specific decoders. We establish, through both theoretical analysis and numerical experiments, that for Gaussian source under mean squared error (MSE) distortion, the entire distortion-classification tradeoff region can be achieved using a single universal encoder. For general sources, we characterize the achievable region and identify conditions under which encoder reuse results in negligible distortion penalty. The experimental result on the MNIST dataset further supports our theoretical findings. We show that universal encoders can obtain distortion performance comparable to task-specific encoders. These results demonstrate the practicality and effectiveness of the proposed universal framework in multi-task compression scenarios.</description>
      <guid isPermaLink="false">oai:arXiv.org:2504.09025v2</guid>
      <category>cs.IT</category>
      <category>math.IT</category>
      <pubDate>Wed, 23 Apr 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Nam Nguyen, Thuan Nguyen, Thinh Nguyen, Bella Bose</dc:creator>
    </item>
    <item>
      <title>Code size constraints in b-symbol read channels: A bound analysis</title>
      <link>https://arxiv.org/abs/2504.10088</link>
      <description>arXiv:2504.10088v2 Announce Type: replace 
Abstract: In classical coding theory, error-correcting codes are designed to protect against errors occurring at individual symbol positions in a codeword. However, in practical storage and communication systems, errors often affect multiple adjacent symbols rather than single symbols independently. To address this, symbol-pair read channels were introduced \cite{Yuval2011}, and later generalized to $b$-symbol read channels \cite{yaakobi2016} to better model such error patterns. $b$-Symbol read channels generalize symbol-pair read channels to account for clustered errors in modern storage and communication systems. By developing bounds and efficient codes, researchers improve data reliability in applications such as storage devices, wireless networks, and DNA-based storage. Given integers $q$, $n$, $d$, and $b \geq 2$, let $A_b(n,d,q)$ denote the largest possible code size for which there exists a $q$-ary code of length $n$ with minimum $b$-symbol distance at least $d$. In \cite{chen2022}, various upper and lower bounds on $A_b(n,d,q)$ are given for $b=2$. In this paper, we generalize some of these bounds to the $b$-symbol read channels for $b&gt;2$ and present several new bounds on $A_b(n,d,q)$. In particular, we establish the linear programming bound, a recurrence relation on $A_b(n,d,q)$, the Johnson bound (even), the restricted Johnson bound, the Gilbert-Varshamov-type bound, and the Elias bound for the metric of symbols $b$, $b\geq 2$. Furthermore, we provide examples demonstrating that the Gilbert-Varshamov bound we establish offers a stronger lower bound than the one presented in \cite{Song2018}. Additionally, we introduce an alternative approach to deriving the Sphere-packing and Plotkin bounds.</description>
      <guid isPermaLink="false">oai:arXiv.org:2504.10088v2</guid>
      <category>cs.IT</category>
      <category>math.IT</category>
      <pubDate>Wed, 23 Apr 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Gyanendra K. Verma, Nupur Patanker, Abhay Kumar Singh</dc:creator>
    </item>
    <item>
      <title>On the Redundancy of Function-Correcting Codes over Finite Fields</title>
      <link>https://arxiv.org/abs/2504.14410</link>
      <description>arXiv:2504.14410v2 Announce Type: replace 
Abstract: Function-correcting codes (FCCs) protect specific function evaluations of a message against errors. This condition imposes a less stringent distance requirement than classical error-correcting codes (ECCs), allowing for reduced redundancy. FCCs were introduced by Lenz et al. (2021), who also established a lower bound on the optimal redundancy for FCCs over the binary field. Here, we derive an upper bound within a logarithmic factor of this lower bound. We show that the same lower bound holds for any finite field. Moreover, we show that this bound is tight for sufficiently large fields by demonstrating that it also serves as an upper bound. Furthermore, we construct an encoding scheme that achieves this optimal redundancy. Finally, motivated by these two extreme regimes, we conjecture that our bound serves as a valid upper bound across all finite fields.</description>
      <guid isPermaLink="false">oai:arXiv.org:2504.14410v2</guid>
      <category>cs.IT</category>
      <category>math.IT</category>
      <pubDate>Wed, 23 Apr 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Hoang Ly, Emina Soljanin</dc:creator>
    </item>
    <item>
      <title>Benign overfitting in Fixed Dimension via Physics-Informed Learning with Smooth Inductive Bias</title>
      <link>https://arxiv.org/abs/2406.09194</link>
      <description>arXiv:2406.09194v3 Announce Type: replace-cross 
Abstract: Recent advances in machine learning have inspired a surge of research into reconstructing specific quantities of interest from measurements that comply with certain physical laws. These efforts focus on inverse problems that are governed by partial differential equations (PDEs). In this work, we develop an asymptotic Sobolev norm learning curve for kernel ridge(less) regression when addressing (elliptical) linear inverse problems. Our results show that the PDE operators in the inverse problem can stabilize the variance and even behave benign overfitting for fixed-dimensional problems, exhibiting different behaviors from regression problems. Besides, our investigation also demonstrates the impact of various inductive biases introduced by minimizing different Sobolev norms as a form of implicit regularization. For the regularized least squares estimator, we find that all considered inductive biases can achieve the optimal convergence rate, provided the regularization parameter is appropriately chosen. The convergence rate is actually independent to the choice of (smooth enough) inductive bias for both ridge and ridgeless regression. Surprisingly, our smoothness requirement recovered the condition found in Bayesian setting and extend the conclusion to the minimum norm interpolation estimators.</description>
      <guid isPermaLink="false">oai:arXiv.org:2406.09194v3</guid>
      <category>stat.ML</category>
      <category>cs.IT</category>
      <category>cs.LG</category>
      <category>cs.NA</category>
      <category>math.IT</category>
      <category>math.NA</category>
      <category>math.ST</category>
      <category>stat.TH</category>
      <pubDate>Wed, 23 Apr 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Honam Wong, Wendao Wu, Fanghui Liu, Yiping Lu</dc:creator>
    </item>
    <item>
      <title>When resampling/reweighting improves feature learning in imbalanced classification?: A toy-model study</title>
      <link>https://arxiv.org/abs/2409.05598</link>
      <description>arXiv:2409.05598v2 Announce Type: replace-cross 
Abstract: A toy model of binary classification is studied with the aim of clarifying the class-wise resampling/reweighting effect on the feature learning performance under the presence of class imbalance. In the analysis, a high-dimensional limit of the input space is taken while keeping the ratio of the dataset size against the input dimension finite and the non-rigorous replica method from statistical mechanics is employed. The result shows that there exists a case in which the no resampling/reweighting situation gives the best feature learning performance irrespectively of the choice of losses or classifiers, supporting recent findings in Cao et al. (2019); Kang et al. (2019). It is also revealed that the key of the result is the symmetry of the loss and the problem setting. Inspired by this, we propose a further simplified model exhibiting the same property in the multiclass setting. These clarify when the class-wise resampling/reweighting becomes effective in imbalanced classification.</description>
      <guid isPermaLink="false">oai:arXiv.org:2409.05598v2</guid>
      <category>stat.ML</category>
      <category>cond-mat.dis-nn</category>
      <category>cs.IT</category>
      <category>cs.LG</category>
      <category>math.IT</category>
      <pubDate>Wed, 23 Apr 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <arxiv:journal_reference>Transactions on Machine Learning Research, 2025. Available at: https://openreview.net/forum?id=spqbyeGyLR</arxiv:journal_reference>
      <dc:creator>Tomoyuki Obuchi, Toshiyuki Tanaka</dc:creator>
    </item>
    <item>
      <title>Understanding LLM Behaviors via Compression: Data Generation, Knowledge Acquisition and Scaling Laws</title>
      <link>https://arxiv.org/abs/2504.09597</link>
      <description>arXiv:2504.09597v4 Announce Type: replace-cross 
Abstract: Large Language Models (LLMs) have demonstrated remarkable capabilities across numerous tasks, yet principled explanations for their underlying mechanisms and several phenomena, such as scaling laws, hallucinations, and related behaviors, remain elusive. In this work, we revisit the classical relationship between compression and prediction, grounded in Kolmogorov complexity and Shannon information theory, to provide deeper insights into LLM behaviors. By leveraging the Kolmogorov Structure Function and interpreting LLM compression as a two-part coding process, we offer a detailed view of how LLMs acquire and store information across increasing model and data scales -- from pervasive syntactic patterns to progressively rarer knowledge elements. Motivated by this theoretical perspective and natural assumptions inspired by Heap's and Zipf's laws, we introduce a simplified yet representative hierarchical data-generation framework called the Syntax-Knowledge model. Under the Bayesian setting, we show that prediction and compression within this model naturally lead to diverse learning and scaling behaviors of LLMs. In particular, our theoretical analysis offers intuitive and principled explanations for both data and model scaling laws, the dynamics of knowledge acquisition during training and fine-tuning, factual knowledge hallucinations in LLMs. The experimental results validate our theoretical predictions.</description>
      <guid isPermaLink="false">oai:arXiv.org:2504.09597v4</guid>
      <category>cs.AI</category>
      <category>cs.IT</category>
      <category>cs.LG</category>
      <category>math.IT</category>
      <pubDate>Wed, 23 Apr 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Zhixuan Pan, Shaowen Wang, Jian Li</dc:creator>
    </item>
  </channel>
</rss>
