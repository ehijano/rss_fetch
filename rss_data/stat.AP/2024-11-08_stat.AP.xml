<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>stat.AP updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/stat.AP</link>
    <description>stat.AP updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/stat.AP" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Fri, 08 Nov 2024 05:00:18 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Fri, 08 Nov 2024 00:00:00 -0500</pubDate>
    <skipDays>
      <day>Saturday</day>
      <day>Sunday</day>
    </skipDays>
    <item>
      <title>Using Linked Micromaps for Evidence-Based Policy</title>
      <link>https://arxiv.org/abs/2411.04211</link>
      <description>arXiv:2411.04211v1 Announce Type: new 
Abstract: Linked micromaps were originally developed to display geographically indexed statistics in an intuitive way by connecting them to a sequence of small maps. The approach integrates several visualization design principles, such as small multiples, discrete color indexing, and ordering. Linked micromaps allow for other types of data displays that are connected to and conditional on geographic areas. Initial applications of micromaps used data from the National Cancer Institute and the Environmental Protection Agency. In this paper, we will show how linked micromaps can be used to better understand and explore relationships and distributions of statistics linked to US states and Washington, DC. We will compare linked micromaps with other popular data displays of geographic data, such as bubble maps, choropleth maps, and bar charts. We will illustrate how linked micromaps can be used for evidence-based decision-making using data from the Bureau of Labor Statistics, the Census Bureau, and the Economic Research Service. The presentations, R scripts, and the data sets used in this article are available here: https://github.com/wlmcensus/Joint-Statistical-Meetings-Presentation-2024. The work discussed in this article was presented at the Joint Statistical Meetings (JSM) 2024 and the American Association for Public Opinion Research (AAPOR) 2024 Annual Conference.</description>
      <guid isPermaLink="false">oai:arXiv.org:2411.04211v1</guid>
      <category>stat.AP</category>
      <pubDate>Fri, 08 Nov 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/publicdomain/zero/1.0/</dc:rights>
      <dc:creator>Randall Powers, John Eltinge, Wendy Martinez, Darcy Steeg Morris</dc:creator>
    </item>
    <item>
      <title>dsld: A Socially Relevant Tool for Teaching Statistics</title>
      <link>https://arxiv.org/abs/2411.04228</link>
      <description>arXiv:2411.04228v1 Announce Type: cross 
Abstract: The growing power of data science can play a crucial role in addressing social discrimination, necessitating nuanced understanding and effective mitigation strategies of potential biases. Data Science Looks At Discrimination (dsld) is an R and Python package designed to provide users with a comprehensive toolkit of statistical and graphical methods for assessing possible discrimination related to protected groups, such as race, gender, and age. Our software offers techniques for discrimination analysis by identifying and mitigating confounding variables, along with methods for reducing bias in predictive models.
  In educational settings, dsld offers instructors powerful tools to teach important statistical principles through motivating real world examples of discrimination analysis. The inclusion of an 80-page Quarto book further supports users, from statistics educators to legal professionals, in effectively applying these analytical tools to real world scenarios.</description>
      <guid isPermaLink="false">oai:arXiv.org:2411.04228v1</guid>
      <category>stat.ME</category>
      <category>cs.IR</category>
      <category>cs.LG</category>
      <category>stat.AP</category>
      <pubDate>Fri, 08 Nov 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Taha Abdullah, Arjun Ashok, Brandon Estrada, Norman Matloff, Aditya Mittal</dc:creator>
    </item>
    <item>
      <title>Effective Capacity of a Battery Energy Storage System Captive to a Wind Farm</title>
      <link>https://arxiv.org/abs/2411.04274</link>
      <description>arXiv:2411.04274v1 Announce Type: cross 
Abstract: Wind energy's role in the global electric grid is set to expand significantly. New York State alone anticipates offshore wind farms (WFs) contributing 9GW by 2035. Integration of energy storage emerges as crucial for this advancement. In this study, we focus on a WF paired with a captive battery energy storage system (BESS). We aim to ascertain the capacity credit for a BESS with specified energy and power ratings. Unlike prior methods rooted in reliability theory, we define a power alignment function, which leads to a straightforward definition of capacity and incremental capacity for the BESS. We develop a solution method based on a linear programming formulation. Our analysis utilizes wind data, collected by NYSERDA off Long Island's coast and load demand data from NYISO. Additionally, we present theoretical insights into BESS sizing and a key time-series property influencing BESS capacity, aiding in simulating wind and demand for estimating BESS energy requirements.</description>
      <guid isPermaLink="false">oai:arXiv.org:2411.04274v1</guid>
      <category>eess.SY</category>
      <category>cs.SY</category>
      <category>stat.AP</category>
      <pubDate>Fri, 08 Nov 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Vinay A. Vaishampayan, Thilaharani Antony, Amirthagunaraj Yogarathnam</dc:creator>
    </item>
    <item>
      <title>Bounded Rationality in Central Bank Communication</title>
      <link>https://arxiv.org/abs/2411.04286</link>
      <description>arXiv:2411.04286v1 Announce Type: cross 
Abstract: This study explores the influence of FOMC sentiment on market expectations, focusing on cognitive differences between experts and non-experts. Using sentiment analysis of FOMC minutes, we integrate these insights into a bounded rationality model to examine the impact on inflation expectations. Results show that experts form more conservative expectations, anticipating FOMC stabilization actions, while non-experts react more directly to inflation concerns. A lead-lag analysis indicates that institutions adjust faster, though the gap with individual investors narrows in the short term. These findings highlight the need for tailored communication strategies to better align public expectations with policy goals.</description>
      <guid isPermaLink="false">oai:arXiv.org:2411.04286v1</guid>
      <category>econ.EM</category>
      <category>stat.AP</category>
      <pubDate>Fri, 08 Nov 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Wonseong Kim, Choong Lyol Lee</dc:creator>
    </item>
    <item>
      <title>Analysis of Droughts and Their Intensities in California from 2000 to 2020</title>
      <link>https://arxiv.org/abs/2411.04303</link>
      <description>arXiv:2411.04303v1 Announce Type: cross 
Abstract: Drought has been perceived as a persistent threat globally and the complex mechanism of various factors contributing to its emergence makes it more troublesome to understand. Droughts and their severity trends have been a point of concern in the USA as well, since the economic impact of droughts has been substantial, especially in parts that contribute majorly to US agriculture. California is the biggest agricultural contributor to the United States with its share amounting up to 12% approximately for all of US agricultural produce. Although, according to a 20-year average, California ranks fifth on the list of the highest average percentage of drought-hit regions. Therefore, drought analysis and drought prediction are of crucial importance for California in order to mitigate the associated risks. However, the design of a consistent drought prediction model based on the dynamic relationship of the drought index remains a challenging task. In the present study, we trained a Voting Ensemble classifier utilizing a soft voting system and three different Random Forest models, to predict the presence of drought and also its intensity. In this paper, initially, we have discussed the trends of droughts and their intensities in various California counties reviewed the correlation of meteorological indicators with drought intensities and used these meteorological indicators for drought prediction so as to evaluate their effectiveness as well as significance.</description>
      <guid isPermaLink="false">oai:arXiv.org:2411.04303v1</guid>
      <category>cs.CY</category>
      <category>stat.AP</category>
      <pubDate>Fri, 08 Nov 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator> Ujjwal, Shikha C. Patel, Bansari K. Shah, Nicholas Ogbonna, Huthaifa I Ashqar</dc:creator>
    </item>
    <item>
      <title>Influential Factors in Increasing an Amazon products Sales Rank</title>
      <link>https://arxiv.org/abs/2411.04305</link>
      <description>arXiv:2411.04305v1 Announce Type: cross 
Abstract: Amazon is the world number one online retailer and has nearly every product a person could need along with a treasure trove of product reviews to help consumers make educated purchases. Companies want to find a way to increase their sales in a very crowded market, and using this data is key. A very good indicator of how a product is selling is its sales rank; which is calculated based on all-time sales of a product where recent sales are weighted more than older sales. Using the data from the Amazon products and reviews we determined that the most influential factors in determining the sales rank of a product were the number of products Amazon showed that other customers also bought, the number of products Amazon showed that customers also viewed, and the price of the product. These results were consistent for the Digital Music category, the Office Products category, and the subcategory Holsters under Cell Phones and Accessories.</description>
      <guid isPermaLink="false">oai:arXiv.org:2411.04305v1</guid>
      <category>cs.CY</category>
      <category>stat.AP</category>
      <pubDate>Fri, 08 Nov 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Ben Chen, Rohit Mokashi, Mamata Khadka, Robert Reyes, Huthaifa I. Ashqar</dc:creator>
    </item>
    <item>
      <title>Neural Fingerprints for Adversarial Attack Detection</title>
      <link>https://arxiv.org/abs/2411.04533</link>
      <description>arXiv:2411.04533v1 Announce Type: cross 
Abstract: Deep learning models for image classification have become standard tools in recent years. A well known vulnerability of these models is their susceptibility to adversarial examples. These are generated by slightly altering an image of a certain class in a way that is imperceptible to humans but causes the model to classify it wrongly as another class. Many algorithms have been proposed to address this problem, falling generally into one of two categories: (i) building robust classifiers (ii) directly detecting attacked images. Despite the good performance of these detectors, we argue that in a white-box setting, where the attacker knows the configuration and weights of the network and the detector, they can overcome the detector by running many examples on a local copy, and sending only those that were not detected to the actual model. This problem is common in security applications where even a very good model is not sufficient to ensure safety. In this paper we propose to overcome this inherent limitation of any static defence with randomization. To do so, one must generate a very large family of detectors with consistent performance, and select one or more of them randomly for each input. For the individual detectors, we suggest the method of neural fingerprints. In the training phase, for each class we repeatedly sample a tiny random subset of neurons from certain layers of the network, and if their average is sufficiently different between clean and attacked images of the focal class they are considered a fingerprint and added to the detector bank. During test time, we sample fingerprints from the bank associated with the label predicted by the model, and detect attacks using a likelihood ratio test. We evaluate our detectors on ImageNet with different attack methods and model architectures, and show near-perfect detection with low rates of false detection.</description>
      <guid isPermaLink="false">oai:arXiv.org:2411.04533v1</guid>
      <category>cs.CV</category>
      <category>cs.LG</category>
      <category>stat.AP</category>
      <pubDate>Fri, 08 Nov 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Haim Fisher, Moni Shahar, Yehezkel S. Resheff</dc:creator>
    </item>
    <item>
      <title>Centrality Graph Shift Operators for Graph Neural Networks</title>
      <link>https://arxiv.org/abs/2411.04655</link>
      <description>arXiv:2411.04655v1 Announce Type: cross 
Abstract: Graph Shift Operators (GSOs), such as the adjacency and graph Laplacian matrices, play a fundamental role in graph theory and graph representation learning. Traditional GSOs are typically constructed by normalizing the adjacency matrix by the degree matrix, a local centrality metric. In this work, we instead propose and study Centrality GSOs (CGSOs), which normalize adjacency matrices by global centrality metrics such as the PageRank, $k$-core or count of fixed length walks. We study spectral properties of the CGSOs, allowing us to get an understanding of their action on graph signals. We confirm this understanding by defining and running the spectral clustering algorithm based on different CGSOs on several synthetic and real-world datasets. We furthermore outline how our CGSO can act as the message passing operator in any Graph Neural Network and in particular demonstrate strong performance of a variant of the Graph Convolutional Network and Graph Attention Network using our CGSOs on several real-world benchmark datasets.</description>
      <guid isPermaLink="false">oai:arXiv.org:2411.04655v1</guid>
      <category>cs.LG</category>
      <category>cs.SI</category>
      <category>math.SP</category>
      <category>stat.AP</category>
      <category>stat.ML</category>
      <pubDate>Fri, 08 Nov 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Yassine Abbahaddou, Fragkiskos D. Malliaros, Johannes F. Lutzeyer, Michalis Vazirgiannis</dc:creator>
    </item>
    <item>
      <title>Automated Image Color Mapping for a Historic Photographic Collection</title>
      <link>https://arxiv.org/abs/2411.04659</link>
      <description>arXiv:2411.04659v1 Announce Type: cross 
Abstract: In the 1970s, the United States Environmental Protection Agency sponsored Documerica, a large-scale photography initiative to document environmental subjects nation-wide. While over 15,000 digitized public-domain photographs from the collection are available online, most of the images were scanned from damaged copies of the original prints. We present and evaluate a modified histogram matching technique based on the underlying chemistry of the prints for correcting the damaged images by using training data collected from a small set of undamaged prints. The entire set of color-adjusted Documerica images is made available in an open repository.</description>
      <guid isPermaLink="false">oai:arXiv.org:2411.04659v1</guid>
      <category>cs.CV</category>
      <category>stat.AP</category>
      <pubDate>Fri, 08 Nov 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Taylor Arnold, Lauren Tilton</dc:creator>
    </item>
    <item>
      <title>Detection of LUAD-Associated Genes Using Wasserstein Distance in Multi-Omics Feature Selection</title>
      <link>https://arxiv.org/abs/2411.01773</link>
      <description>arXiv:2411.01773v2 Announce Type: replace 
Abstract: Lung adenocarcinoma (LUAD) is characterized by substantial genetic heterogeneity, posing challenges in identifying reliable biomarkers for improved diagnosis and treatment. Tumor Mutational Burden (TMB) has traditionally been regarded as a predictive biomarker, given its association with immune response and treatment efficacy. In this study, we treated TMB as a response variable to identify genes highly correlated with it, aiming to understand its genetic drivers. We conducted a thorough investigation of recent feature selection methods through extensive simulations, selecting PC-Screen, DC-SIS, and WD-Screen as top performers. These methods handle multi-omics structures effectively, and can accommodate both categorical and continuous data types at the same time for each gene. Using data from The Cancer Genome Atlas (TCGA) via cBioPortal, we combined copy number alteration (CNA), mRNA expression and DNA methylation data as multi-omics predictors and applied these methods, selecting genes consistently identified across all three methods. 13 common genes were identified, including HSD17B4, PCBD2, which show strong associations with TMB. Our multi-omics strategy and robust feature selection approach provide insights into the genetic determinants of TMB, with implications for targeted LUAD therapies.</description>
      <guid isPermaLink="false">oai:arXiv.org:2411.01773v2</guid>
      <category>stat.AP</category>
      <pubDate>Fri, 08 Nov 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Shaofei Zhao, Siming Huang, Kexuan Li, Weiyu Zhou, Lingli Yang, Shige Wang</dc:creator>
    </item>
    <item>
      <title>The TruEnd-procedure: Treating trailing zero-valued balances in credit data</title>
      <link>https://arxiv.org/abs/2404.17008</link>
      <description>arXiv:2404.17008v2 Announce Type: replace-cross 
Abstract: A novel procedure is presented for finding the true but latent endpoints within the repayment histories of individual loans. The monthly observations beyond these true endpoints are false, largely due to operational failures that delay account closure, thereby corrupting some loans in the dataset with `false' observations. Detecting these false observations is difficult at scale since each affected loan history might have a different sequence of zero (or very small) month-end balances that persist towards the end. Identifying these trails of diminutive balances would require an exact definition of a "small balance", which can be found using our so-called TruEnd-procedure. We demonstrate this procedure and isolate the ideal small-balance definition using residential mortgages from a large South African bank. Evidently, corrupted loans are remarkably prevalent and have excess histories that are surprisingly long, which ruin the timing of certain risk events and compromise any subsequent time-to-event model such as survival analysis. Excess histories can be discarded using the ideal small-balance definition, which demonstrably improves the accuracy of both the predicted timing and severity of risk events, without materially impacting the monetary value of the portfolio. The resulting estimates of credit losses are lower and less biased, which augurs well for raising accurate credit impairments under the IFRS 9 accounting standard. Our work therefore addresses a pernicious data error, which highlights the pivotal role of data preparation in producing credible forecasts of credit risk.</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.17008v2</guid>
      <category>q-fin.RM</category>
      <category>q-fin.ST</category>
      <category>stat.AP</category>
      <pubDate>Fri, 08 Nov 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Arno Botha, Tanja Verster, Roelinde Bester</dc:creator>
    </item>
  </channel>
</rss>
