<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>q-fin.RM updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/q-fin.RM</link>
    <description>q-fin.RM updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/q-fin.RM" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Wed, 03 Sep 2025 04:01:05 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Wed, 03 Sep 2025 00:00:00 -0400</pubDate>
    <skipDays>
      <day>Sunday</day>
      <day>Saturday</day>
    </skipDays>
    <item>
      <title>Neural L\'evy SDE for State--Dependent Risk and Density Forecasting</title>
      <link>https://arxiv.org/abs/2509.01041</link>
      <description>arXiv:2509.01041v1 Announce Type: new 
Abstract: Financial returns are known to exhibit heavy tails, volatility clustering and abrupt jumps that are poorly captured by classical diffusion models. Advances in machine learning have enabled highly flexible functional forms for conditional means and volatilities, yet few models deliver interpretable state--dependent tail risk, capture multiple forecast horizons and yield distributions amenable to backtesting and execution. This paper proposes a neural L\'evy jump--diffusion framework that jointly learns, as functions of observable state variables, the conditional drift, diffusion, jump intensity and jump size distribution. We show how a single shared encoder yields multiple forecasting heads corresponding to distinct horizons (daily, weekly, etc.), facilitating multi--horizon density forecasts and risk measures. The state vector includes conventional price and volume features as well as novel complexity measures such as permutation entropy and recurrence quantification analysis determinism, which quantify predictability in the underlying process. Estimation is based on a quasi--maximum likelihood approach that separates diffusion and jump contributions via bipower variation weights and incorporates monotonicity and smoothness regularisation to ensure identifiability. A cost--aware portfolio optimiser translates the model's conditional densities into implementable trading strategies under leverage, turnover and no--trade--band constraints. Extensive empirical analyses on cross--sectional equity data demonstrate improved calibration, sharper tail control and economically significant risk reduction relative to baseline diffusive and GARCH benchmarks. The proposed framework is therefore an interpretable, testable and practically deployable method for state--dependent risk and density forecasting.</description>
      <guid isPermaLink="false">oai:arXiv.org:2509.01041v1</guid>
      <category>q-fin.RM</category>
      <pubDate>Wed, 03 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Ziyao Wang, Svetlozar T Rachev</dc:creator>
    </item>
    <item>
      <title>Signal from Noise Signal from Noise: A Neural Network-Based Denoising Approach for Measuring Global Financial Spillovers</title>
      <link>https://arxiv.org/abs/2509.01156</link>
      <description>arXiv:2509.01156v1 Announce Type: new 
Abstract: Filtering signal from noise is fundamental to accurately assessing spillover effects in financial markets. This study investigates denoised return and volatility spillovers across a diversified set of markets, spanning developed and developing economies as well as key asset classes, using a neural network-based denoising architecture. By applying denoising to the covariance matrices prior to spillover estimation, we disentangle signal from noise. Our analysis covers the period from late 2014 to mid-2025 and adopts both static and time-varying frameworks. The results reveal that developed markets predominantly serve as net transmitters of volatility spillovers under normal conditions, but often transition into net receivers during episodes of systemic stress, such as the Covid-19 pandemic. In contrast, developing markets display heightened instability in their spillover roles, frequently oscillating between transmitter and receiver positions. Denoising not only clarifies the dynamic and heterogeneous nature of spillover channels, but also sharpens the alignment between observed spillover patterns and known financial events. These findings highlight the necessity of denoising in spillover analysis for effective monitoring of systemic risk and market interconnectedness.</description>
      <guid isPermaLink="false">oai:arXiv.org:2509.01156v1</guid>
      <category>q-fin.RM</category>
      <pubDate>Wed, 03 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Abdullah Karasan, \"Ozge Sezgin Alp</dc:creator>
    </item>
    <item>
      <title>Is Noisy Data a Blessing in Disguise? A Distributionally Robust Optimization Perspective</title>
      <link>https://arxiv.org/abs/2509.01076</link>
      <description>arXiv:2509.01076v1 Announce Type: cross 
Abstract: Noisy data are often viewed as a challenge for decision-making. This paper studies a distributionally robust optimization (DRO) that shows how such noise can be systematically incorporated. Rather than applying DRO to the noisy empirical distribution, we construct ambiguity sets over the \emph{latent} distribution by centering a Wasserstein ball at the noisy empirical distribution in the observation space and taking its inverse image through a known noise kernel. We validate this inverse-image construction by deriving a tractable convex reformulation and establishing rigorous statistical guarantees, including finite-sample performance and asymptotic consistency. Crucially, we demonstrate that, under mild conditions, noisy data may be a ``blessing in disguise." Our noisy-data DRO model is less conservative than its direct counterpart, leading to provably higher optimal values and a lower price of ambiguity. In the context of fair resource allocation problems, we demonstrate that this robust approach can induce solutions that are structurally more equitable. Our findings suggest that managers can leverage uncertainty by harnessing noise as a source of robustness rather than treating it as an obstacle, producing more robust and strategically balanced decisions.</description>
      <guid isPermaLink="false">oai:arXiv.org:2509.01076v1</guid>
      <category>math.OC</category>
      <category>cs.SY</category>
      <category>eess.SY</category>
      <category>q-fin.RM</category>
      <pubDate>Wed, 03 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Chung-Han Hsieh, Rong Gan</dc:creator>
    </item>
    <item>
      <title>Risk sharing with Lambda value at risk under heterogeneous beliefs</title>
      <link>https://arxiv.org/abs/2408.03147</link>
      <description>arXiv:2408.03147v3 Announce Type: replace 
Abstract: In this paper, we study the risk sharing problem among multiple agents using Lambda Value-at-Risk as their preference functional, under heterogeneous beliefs, where beliefs are represented by several probability measures. We obtain semi-explicit formulas for the inf-convolution of multiple Lambda Value-at-Risk measures under heterogeneous beliefs and the explicit forms of the corresponding optimal allocations. To show the impact of belief heterogeneity, we consider three cases: homogeneous beliefs, conditional beliefs and absolutely continuous beliefs. For those cases, we find more explicit expressions for the inf-convolution, showing the influence of the relation of the beliefs on the inf-convolution. Moreover, we consider, in a two-agent setting, the inf-convolution of one Lambda Value-at-Risk and a general risk measure, including expected utility, distortion risk measures and Lambda Value-at-Risk as special cases, with differing beliefs. The expression of the inf-convolution and the form of the optimal allocation are obtained. In all above cases we demonstrate that trivial outcomes arise when both belief inconsistency and risk tolerance are high. Finally, we discuss risk sharing for an alternative definition of Lambda Value-at-Risk.</description>
      <guid isPermaLink="false">oai:arXiv.org:2408.03147v3</guid>
      <category>q-fin.RM</category>
      <pubDate>Wed, 03 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Peng Liu, Andreas Tsanakas, Yunran Wei</dc:creator>
    </item>
    <item>
      <title>Forecasting Probability Distributions of Financial Returns with Deep Neural Networks</title>
      <link>https://arxiv.org/abs/2508.18921</link>
      <description>arXiv:2508.18921v2 Announce Type: replace 
Abstract: This study evaluates deep neural networks for forecasting probability distributions of financial returns. 1D convolutional neural networks (CNN) and Long Short-Term Memory (LSTM) architectures are used to forecast parameters of three probability distributions: Normal, Student's t, and skewed Student's t. Using custom negative log-likelihood loss functions, distribution parameters are optimized directly. The models are tested on six major equity indices (S\&amp;P 500, BOVESPA, DAX, WIG, Nikkei 225, and KOSPI) using probabilistic evaluation metrics including Log Predictive Score (LPS), Continuous Ranked Probability Score (CRPS), and Probability Integral Transform (PIT). Results show that deep learning models provide accurate distributional forecasts and perform competitively with classical GARCH models for Value-at-Risk estimation. The LSTM with skewed Student's t distribution performs best across multiple evaluation criteria, capturing both heavy tails and asymmetry in financial returns. This work shows that deep neural networks are viable alternatives to traditional econometric models for financial risk assessment and portfolio management.</description>
      <guid isPermaLink="false">oai:arXiv.org:2508.18921v2</guid>
      <category>q-fin.RM</category>
      <category>cs.LG</category>
      <pubDate>Wed, 03 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Jakub Micha\'nk\'ow</dc:creator>
    </item>
  </channel>
</rss>
