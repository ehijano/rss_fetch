<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>cs.DS updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/cs.DS</link>
    <description>cs.DS updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/cs.DS" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Wed, 10 Apr 2024 04:00:03 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Wed, 10 Apr 2024 00:00:00 -0400</pubDate>
    <skipDays>
      <day>Sunday</day>
      <day>Saturday</day>
    </skipDays>
    <item>
      <title>Polynomial-time derivation of optimal k-tree topology from Markov networks</title>
      <link>https://arxiv.org/abs/2404.05991</link>
      <description>arXiv:2404.05991v1 Announce Type: new 
Abstract: Characterization of joint probability distribution for large networks of random variables remains a challenging task in data science. Probabilistic graph approximation with simple topologies has practically been resorted to; typically the tree topology makes joint probability computation much simpler and can be effective for statistical inference on insufficient data. However, to characterize network components where multiple variables cooperate closely to influence others, model topologies beyond a tree are needed, which unfortunately are infeasible to acquire. In particular, our previous work has related optimal approximation of Markov networks of tree-width k &gt;=2 closely to the graph-theoretic problem of finding maximum spanning k-tree (MSkT), which is a provably intractable task.
  This paper investigates optimal approximation of Markov networks with k-tree topology that retains some designated underlying subgraph. Such a subgraph may encode certain background information that arises in scientific applications, for example, about a known significant pathway in gene networks or the indispensable backbone connectivity in the residue interaction graphs for a biomolecule 3D structure. In particular, it is proved that the \beta-retaining MSkT problem, for a number of classes \beta of graphs, admit O(n^{k+1})-time algorithms for every fixed k&gt;= 1. These \beta-retaining MSkT algorithms offer efficient solutions for approximation of Markov networks with k-tree topology in the situation where certain persistent information needs to be retained.</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.05991v1</guid>
      <category>cs.DS</category>
      <category>stat.ML</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <dc:creator>Fereshteh R. Dastjerdi, Liming Cai</dc:creator>
    </item>
    <item>
      <title>Fully Dynamic Matching and Ordered Ruzsa-Szemer\'edi Graphs</title>
      <link>https://arxiv.org/abs/2404.06069</link>
      <description>arXiv:2404.06069v1 Announce Type: new 
Abstract: We study the fully dynamic maximum matching problem. In this problem, the goal is to efficiently maintain an approximate maximum matching of a graph that is subject to edge insertions and deletions. Our focus is particularly on algorithms that maintain the edges of a $(1-\epsilon)$-approximate maximum matching for an arbitrarily small constant $\epsilon &gt; 0$. Until recently, the fastest known algorithm for this problem required $\Theta(n)$ time per update where $n$ is the number of vertices. This bound was slightly improved to $n/(\log^* n)^{\Omega(1)}$ by Assadi, Behnezhad, Khanna, and Li [STOC'23] and very recently to $n/2^{\Omega(\sqrt{\log n})}$ by Liu [ArXiv'24]. Whether this can be improved to $n^{1-\Omega(1)}$ remains a major open problem.
  In this paper, we present a new algorithm that maintains a $(1-\epsilon)$-approximate maximum matching. The update-time of our algorithm is parametrized based on the density of a certain class of graphs that we call Ordered Ruzsa-Szemer\'edi (ORS) graphs, a generalization of the well-known Ruzsa-Szemer\'edi graphs. While determining the density of ORS (or RS) remains a hard problem in combinatorics, we prove that if the existing constructions of ORS graphs are optimal, then our algorithm runs in $n^{1/2+O(\epsilon)}$ time for any fixed $\epsilon &gt; 0$ which would be significantly faster than existing near-linear in $n$ time algorithms.
  Our second main contribution is a better upper bound on density of both ORS and RS graphs with linear size matchings. The previous best upper bound was due to a proof of the triangle-removal lemma from more than a decade ago due to Fox [Annals of Mathematics '11].</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.06069v1</guid>
      <category>cs.DS</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Soheil Behnezhad, Alma Ghafari</dc:creator>
    </item>
    <item>
      <title>Characterizations of Sparsifiability for Affine CSPs and Symmetric CSPs</title>
      <link>https://arxiv.org/abs/2404.06327</link>
      <description>arXiv:2404.06327v1 Announce Type: new 
Abstract: CSP sparsification, introduced by Kogan and Krauthgamer (ITCS 2015), considers the following question: when can an instance of a constraint satisfaction problem be sparsified (by retaining a weighted subset of the constraints) while still roughly capturing the weight of constraints satisfied by {\em every} assignment. CSP sparsification generalizes and abstracts other commonly studied problems including graph cut-sparsification, hypergraph cut-sparsification and hypergraph XOR-sparsification. A central question here is to understand what properties of a constraint predicate $P:\Sigma^r \to \{0,1\}$ (where variables are assigned values in $\Sigma$) allow for nearly linear-size sparsifiers (in the number of variables). In this work (1) we significantly extend the class of CSPs for which nearly linear-size, and other non-trivial, sparsifications exist and give classifications in some broad settings and (2) give a polynomial-time algorithm to extract this sparsification.
  Our results captured in item (1) completely classify all symmetric Boolean predicates $P$ (i.e., on the Boolean domain $\Sigma = \{0,1\}$) that allow nearly-linear-size sparsifications. Symmetric Boolean CSPs already capture all the special classes of sparisifcation listed above including hypergraph cut-sparsification and variants. Our study of symmetric CSPs reveals an inherent, previously undetected, number-theoretic phenomenon that determines near-linear size sparsifiability. We also completely classify the set of Boolean predicates $P$ that allow non-trivial ($o(n^r)$-size) sparsifications, thus answering an open question from the work of Kogan and Krauthgamer.</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.06327v1</guid>
      <category>cs.DS</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <dc:creator>Sanjeev Khanna, Aaron L. Putterman, Madhu Sudan</dc:creator>
    </item>
    <item>
      <title>Bounded Edit Distance: Optimal Static and Dynamic Algorithms for Small Integer Weights</title>
      <link>https://arxiv.org/abs/2404.06401</link>
      <description>arXiv:2404.06401v1 Announce Type: new 
Abstract: The edit distance of two strings is the minimum number of insertions, deletions, and substitutions needed to transform one string into the other. The textbook algorithm determines the edit distance of length-$n$ strings in $O(n^2)$ time, which is optimal up to subpolynomial factors under Orthogonal Vectors Hypothesis. In the bounded version of the problem, parameterized by the edit distance $k$, the algorithm of Landau and Vishkin [JCSS'88] achieves $O(n+k^2)$ time, which is optimal as a function of $n$ and $k$.
  The dynamic version of the problem asks to maintain the edit distance of two strings that change dynamically, with each update modeled as an edit. A folklore approach supports updates in $\tilde O(k^2)$ time, where $\tilde O(\cdot)$ hides polylogarithmic factors. Recently, Charalampopoulos, Kociumaka, and Mozes [CPM'20] showed an algorithm with update time $\tilde O(n)$, which is optimal under OVH in terms of $n$. The update time of $\tilde O(\min\{n,k^2\})$ raised an exciting open question of whether $\tilde O(k)$ is possible; we answer it affirmatively.
  Our solution relies on tools originating from weighted edit distance, where the weight of each edit depends on the edit type and the characters involved. The textbook algorithm supports weights, but the Landau-Vishkin approach does not, and a simple $O(nk)$-time procedure long remained the fastest for bounded weighted edit distance. Only recently, Das et al. [STOC'23] provided an $O(n+k^5)$-time algorithm, whereas Cassis, Kociumaka, and Wellnitz [FOCS'23] presented an $\tilde O(n+\sqrt{nk^3})$-time solution and a matching conditional lower bound. In this paper, we show that, for integer edit weights between $0$ and $W$, weighted edit distance can be computed in $\tilde O(n+Wk^2)$ time and maintained dynamically in $\tilde O(W^2k)$ time per update. Our static algorithm can also be implemented in $\tilde O(n+k^{2.5})$ time.</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.06401v1</guid>
      <category>cs.DS</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Egor Gorbachev, Tomasz Kociumaka</dc:creator>
    </item>
    <item>
      <title>Balanced Partitioning for Optimizing Big Graph Computation: Complexities and Approximation Algorithms</title>
      <link>https://arxiv.org/abs/2404.05949</link>
      <description>arXiv:2404.05949v1 Announce Type: cross 
Abstract: Graph partitioning is a key fundamental problem in the area of big graph computation. Previous works do not consider the practical requirements when optimizing the big data analysis in real applications. In this paper, motivated by optimizing the big data computing applications, two typical problems of graph partitioning are studied. The first problem is to optimize the performance of specific workloads by graph partitioning, which lacks of algorithms with performance guarantees. The second problem is to optimize the computation of motifs by graph partitioning, which has not been focused by previous works. First, the formal definitions of the above two problems are introduced, and the semidefinite programming representations are also designed based on the analysis of the properties of the two problems. For the motif based partitioning problem, it is proved to be NP-complete even for the special case of $k=2$ and the motif is a triangle, and its inapproximability is also shown by proving that there are no efficient algorithms with finite approximation ratio. Finally, using the semidefinite programming and sophisticated rounding techniques, the bi-criteria $O(\sqrt{\log n\log k})$-approximation algorithms with polynomial time cost are designed and analyzed for them.</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.05949v1</guid>
      <category>cs.DB</category>
      <category>cs.DS</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Baoling Ning, Jianzhong Li</dc:creator>
    </item>
    <item>
      <title>AiSAQ: All-in-Storage ANNS with Product Quantization for DRAM-free Information Retrieval</title>
      <link>https://arxiv.org/abs/2404.06004</link>
      <description>arXiv:2404.06004v1 Announce Type: cross 
Abstract: In approximate nearest neighbor search (ANNS) methods based on approximate proximity graphs, DiskANN achieves good recall-speed balance for large-scale datasets using both of RAM and storage. Despite it claims to save memory usage by loading compressed vectors by product quantization (PQ), its memory usage increases in proportion to the scale of datasets. In this paper, we propose All-in-Storage ANNS with Product Quantization (AiSAQ), which offloads the compressed vectors to storage. Our method achieves $\sim$10 MB memory usage in query search even with billion-scale datasets with minor performance degradation. AiSAQ also reduces the index load time before query search, which enables the index switch between muitiple billion-scale datasets and significantly enhances the flexibility of retrieval-augmented generation (RAG). This method is applicable to all graph-based ANNS algorithms and can be combined with higher-spec ANNS methods in the future.</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.06004v1</guid>
      <category>cs.IR</category>
      <category>cs.CL</category>
      <category>cs.DS</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Kento Tatsuno, Daisuke Miyashita, Taiga Ikeda, Kiyoshi Ishiyama, Kazunari Sumiyoshi, Jun Deguchi</dc:creator>
    </item>
    <item>
      <title>The Voronoi Diagram of Weakly Smooth Planar Point Sets in $O(\log n)$ Deterministic Rounds on the Congested Clique</title>
      <link>https://arxiv.org/abs/2404.06068</link>
      <description>arXiv:2404.06068v1 Announce Type: cross 
Abstract: We study the problem of computing the Voronoi diagram of a set of $n^2$ points with $O(\log n)$-bit coordinates in the Euclidean plane in a substantially sublinear in $n$ number of rounds in the congested clique model with $n$ nodes. Recently, Jansson et al. have shown that if the points are uniformly at random distributed in a unit square then their Voronoi diagram within the square can be computed in $O(1)$ rounds with high probability (w.h.p.). We show that if a very weak smoothness condition is satisfied by an input set of $n^2$ points with $O(\log n)$-bit coordinates in the unit square then the Voronoi diagram of the point set within the unit square can be computed in $O(\log n)$ rounds in this model.</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.06068v1</guid>
      <category>cs.CG</category>
      <category>cs.DS</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Jesper Jansson, Christos Levcopoulos, Andrzej Lingas</dc:creator>
    </item>
    <item>
      <title>The Overlap Gap Property limits limit swapping in QAOA</title>
      <link>https://arxiv.org/abs/2404.06087</link>
      <description>arXiv:2404.06087v1 Announce Type: cross 
Abstract: The Quantum Approximate Optimization Algorithm (QAOA) is a quantum algorithm designed for combinatorial optimization problem. We show that under the assumption that the Overlap Gap Property (OGP) in the solution space for the Max-$q$-XORSAT is a monotonic increasing function, the swapping of limits in QAOA leads to suboptimal results limited by the OGP. Furthermore, since the performance of QAOA for the pure $q$-spin model matches asymptotically for Max-$q$-XORSAT on large-girth regular hypergraph, we show that the average-case value obtained by QAOA for the pure $q$-spin model for even $q\ge 4$ is bounded away from optimality even when the algorithm runs indefinitely. This suggests that a necessary condition for the validity of limit swapping in QAOA is the absence of OGP in a given combinatorial optimization problem. A corollary of this is that the spectral gap of a Hamiltonian exhibiting the OGP will close in the thermodynamic limit resulting in a limitation of the quantum adiabatic theorem and efficient optimization of QAOA parameters. Furthermore, the results suggests that even when sub-optimised, the performance of QAOA on spin glass is equal in performance to Montanari's classical algorithm in solving the mean field spin glass problem, the best known classical algorithm.</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.06087v1</guid>
      <category>quant-ph</category>
      <category>cond-mat.dis-nn</category>
      <category>cond-mat.stat-mech</category>
      <category>cs.DS</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Mark Xin Hong Goh</dc:creator>
    </item>
    <item>
      <title>Algorithms for Caching and MTS with reduced number of predictions</title>
      <link>https://arxiv.org/abs/2404.06280</link>
      <description>arXiv:2404.06280v1 Announce Type: cross 
Abstract: ML-augmented algorithms utilize predictions to achieve performance beyond their worst-case bounds. Producing these predictions might be a costly operation -- this motivated Im et al. '22 to introduce the study of algorithms which use predictions parsimoniously. We design parsimonious algorithms for caching and MTS with action predictions, proposed by Antoniadis et al. '20, focusing on the parameters of consistency (performance with perfect predictions) and smoothness (dependence of their performance on the prediction error). Our algorithm for caching is 1-consistent, robust, and its smoothness deteriorates with the decreasing number of available predictions. We propose an algorithm for general MTS whose consistency and smoothness both scale linearly with the decreasing number of predictions. Without the restriction on the number of available predictions, both algorithms match the earlier guarantees achieved by Antoniadis et al. '20.</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.06280v1</guid>
      <category>cs.LG</category>
      <category>cs.DS</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Karim Abdel Sadek, Marek Elias</dc:creator>
    </item>
    <item>
      <title>Simple algorithms to test and learn local Hamiltonians</title>
      <link>https://arxiv.org/abs/2404.06282</link>
      <description>arXiv:2404.06282v1 Announce Type: cross 
Abstract: We consider the problems of testing and learning an $n$-qubit $k$-local Hamiltonian from queries to its evolution operator with respect the 2-norm of the Pauli spectrum, or equivalently, the normalized Frobenius norm. For testing whether a Hamiltonian is $\epsilon_1$-close to $k$-local or $\epsilon_2$-far from $k$-local, we show that $O(1/(\epsilon_2-\epsilon_1)^{8})$ queries suffice. This solves two questions posed in a recent work by Bluhm, Caro and Oufkir. For learning up to error $\epsilon$, we show that $\exp(O(k^2+k\log(1/\epsilon)))$ queries suffice. Our proofs are simple, concise and based on Pauli-analytic techniques.</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.06282v1</guid>
      <category>quant-ph</category>
      <category>cs.CC</category>
      <category>cs.DS</category>
      <category>cs.IT</category>
      <category>cs.LG</category>
      <category>math.IT</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Francisco Escudero Guti\'errez</dc:creator>
    </item>
    <item>
      <title>Optimal Stopping with Interdependent Values</title>
      <link>https://arxiv.org/abs/2404.06293</link>
      <description>arXiv:2404.06293v1 Announce Type: cross 
Abstract: We study online selection problems in both the prophet and secretary settings, when arriving agents have interdependent values. In the interdependent values model, introduced in the seminal work of Milgrom and Weber [1982], each agent has a private signal and the value of an agent is a function of the signals held by all agents. Results in online selection crucially rely on some degree of independence of values, which is conceptually at odds with the interdependent values model. For prophet and secretary models under the standard independent values assumption, prior works provide constant factor approximations to the welfare. On the other hand, when agents have interdependent values, prior works in Economics and Computer Science provide truthful mechanisms that obtain optimal and approximately optimal welfare under certain assumptions on the valuation functions.
  We bring together these two important lines of work and provide the first constant factor approximations for prophet and secretary problems with interdependent values. We consider both the algorithmic setting, where agents are non-strategic (but have interdependent values), and the mechanism design setting with strategic agents. All our results are constructive and use simple stopping rules.</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.06293v1</guid>
      <category>cs.GT</category>
      <category>cs.DS</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Simon Mauras, Divyarthi Mohan, Rebecca Reiffenh\"auser</dc:creator>
    </item>
    <item>
      <title>A universal sequence of tensors for the asymptotic rank conjecture</title>
      <link>https://arxiv.org/abs/2404.06427</link>
      <description>arXiv:2404.06427v1 Announce Type: cross 
Abstract: The exponent $\sigma(T)$ of a tensor $T\in\mathbb{F}^d\otimes\mathbb{F}^d\otimes\mathbb{F}^d$ over a field $\mathbb{F}$ captures the base of the exponential growth rate of the tensor rank of $T$ under Kronecker powers. Tensor exponents are fundamental from the standpoint of algorithms and computational complexity theory; for example, the exponent $\omega$ of matrix multiplication can be characterized as $\omega=2\sigma(\mathrm{MM}_2)$, where $\mathrm{MM}_2\in\mathbb{F}^4\otimes\mathbb{F}^4\otimes\mathbb{F}^4$ is the tensor that represents $2\times 2$ matrix multiplication.
  Our main result is an explicit construction of a sequence $\mathcal{U}_d$ of zero-one-valued tensors that is universal for the worst-case tensor exponent; more precisely, we show that $\sigma(\mathcal{U}_d)=\sigma(d)$ where $\sigma(d)=\sup_{T\in\mathbb{F}^d\otimes\mathbb{F}^d\otimes\mathbb{F}^d}\sigma(T)$. We also supply an explicit universal sequence $\mathcal{U}_\Delta$ localised to capture the worst-case exponent $\sigma(\Delta)$ of tensors with support contained in $\Delta\subseteq [d]\times[d]\times [d]$; by combining such sequences, we obtain a universal sequence $\mathcal{T}_d$ such that $\sigma(\mathcal{T}_d)=1$ holds if and only if Strassen's asymptotic rank conjecture [Progr. Math. 120 (1994)] holds for $d$. Finally, we show that the limit $\lim_{d\rightarrow\infty}\sigma(d)$ exists and can be captured as $\lim_{d\rightarrow\infty} \sigma(D_d)$ for an explicit sequence $(D_d)_{d=1}^\infty$ of tensors obtained by diagonalisation of the sequences $\mathcal{U}_d$. As our second result we relate the absence of polynomials of fixed degree vanishing on tensors of low rank, or more generally asymptotic rank, with upper bounds on the exponent $\sigma(d)$. Using this technique, one may bound asymptotic rank for all tensors of a given format, knowing enough specific tensors of low asymptotic rank.</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.06427v1</guid>
      <category>cs.CC</category>
      <category>cs.DS</category>
      <category>math.AG</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Petteri Kaski, Mateusz Micha{\l}ek</dc:creator>
    </item>
    <item>
      <title>The Central Spanning Tree Problem</title>
      <link>https://arxiv.org/abs/2404.06447</link>
      <description>arXiv:2404.06447v1 Announce Type: cross 
Abstract: Spanning trees are an important primitive in many data analysis tasks, when a data set needs to be summarized in terms of its "skeleton", or when a tree-shaped graph over all observations is required for downstream processing. Popular definitions of spanning trees include the minimum spanning tree and the optimum distance spanning tree, a.k.a. the minimum routing cost tree. When searching for the shortest spanning tree but admitting additional branching points, even shorter spanning trees can be realized: Steiner trees. Unfortunately, both minimum spanning and Steiner trees are not robust with respect to noise in the observations; that is, small perturbations of the original data set often lead to drastic changes in the associated spanning trees. In response, we make two contributions when the data lies in a Euclidean space: on the theoretical side, we introduce a new optimization problem, the "(branched) central spanning tree", which subsumes all previously mentioned definitions as special cases. On the practical side, we show empirically that the (branched) central spanning tree is more robust to noise in the data, and as such is better suited to summarize a data set in terms of its skeleton. We also propose a heuristic to address the NP-hard optimization problem, and illustrate its use on single cell RNA expression data from biology and 3D point clouds of plants.</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.06447v1</guid>
      <category>cs.DM</category>
      <category>cs.CV</category>
      <category>cs.DS</category>
      <category>math.CO</category>
      <category>math.OC</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Enrique Fita Sanmart\'in, Christoph Schn\"orr, Fred A. Hamprecht</dc:creator>
    </item>
    <item>
      <title>Algorithmic Extensions of Dirac's Theorem</title>
      <link>https://arxiv.org/abs/2011.03619</link>
      <description>arXiv:2011.03619v4 Announce Type: replace 
Abstract: In 1952, Dirac proved the following theorem about long cycles in graphs with large minimum vertex degrees: Every $n$-vertex $2$-connected graph $G$ with minimum vertex degree $\delta\geq 2$ contains a cycle with at least $\min\{2\delta,n\}$ vertices. In particular, if $\delta\geq n/2$, then $G$ is Hamiltonian. The proof of Dirac's theorem is constructive, and it yields an algorithm computing the corresponding cycle in polynomial time. The combinatorial bound of Dirac's theorem is tight in the following sense. There are 2-connected graphs that do not contain cycles of length more than $2\delta+1$. Also, there are non-Hamiltonian graphs with all vertices but one of degree at least $n/2$. This prompts naturally to the following algorithmic questions. For $k\geq 1$,
  (A) How difficult is to decide whether a 2-connected graph contains a cycle of length at least $\min\{2\delta+k,n\}$?
  (B) How difficult is to decide whether a graph $G$ is Hamiltonian, when at least $n - k$ vertices of $G$ are of degrees at least $n/2-k$?
  The first question was asked by Fomin, Golovach, Lokshtanov, Panolan, Saurabh, and Zehavi. The second question is due to Jansen, Kozma, and Nederlof. Even for a very special case of $k=1$, the existence of a polynomial-time algorithm deciding whether $G$ contains a cycle of length at least $\min\{2\delta+1,n\}$ was open. We resolve both questions by proving the following algorithmic generalization of Dirac's theorem: If all but $k$ vertices of a $2$-connected graph $G$ are of degree at least $\delta$, then deciding whether $G$ has a cycle of length at least $\min\{2\delta +k, n\}$ can be done in time $2^{\mathcal{O}(k)}\cdot n^{\mathcal{O}(1)}$.
  The proof of the algorithmic generalization of Dirac's theorem builds on new graph-theoretical results that are interesting on their own.</description>
      <guid isPermaLink="false">oai:arXiv.org:2011.03619v4</guid>
      <category>cs.DS</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Fedor V. Fomin, Petr A. Golovach, Danil Sagunov, Kirill Simonov</dc:creator>
    </item>
    <item>
      <title>Simpler O(1) Query Algorithm for Level Ancestors</title>
      <link>https://arxiv.org/abs/2207.11954</link>
      <description>arXiv:2207.11954v2 Announce Type: replace 
Abstract: This note describes a very simple O(1) query time algorithm for finding level ancestors. This is basically a serial (re)-implementation of the parallel algorithm of Berkman and Vishkin (O.Berkman and U.Vishkin, Finding level-ancestors in trees, JCSS, 48, 214--230, 1994).
  Although the basic algorithm has preprocessing time of O(n log n), by having additional levels or using table lookup, the preprocessing time can be reduced to almost linear or linear.
  The table lookup algorithm can be built in O(1) parallel time with $n$ processors and can also be used to simplify the parallel algorithm of Berkman and Vishkin and make it optimal.</description>
      <guid isPermaLink="false">oai:arXiv.org:2207.11954v2</guid>
      <category>cs.DS</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Sanjeev Saxena</dc:creator>
    </item>
    <item>
      <title>Circular-arc graphs and the Helly property</title>
      <link>https://arxiv.org/abs/2404.00416</link>
      <description>arXiv:2404.00416v2 Announce Type: replace 
Abstract: In this paper we investigate some problems related to the Helly properties of circular-arc graphs, which are defined as intersection graphs of arcs of a fixed circle. As such, circular-arc graphs are among the simplest classes of intersection graphs whose models might not satisfy the Helly property. In particular, some cliques of a circular-arc graph might be Helly in some but not all arc intersection models of the graph.
  Our first result is an alternative proof of a theorem by Lin and Szwarcfiter which asserts that for every circular-arc graph $G$ either every normalized model of $G$ satisfies the Helly property or no normalized model of $G$ satisfies this property.
  Further, we study the Helly properties of a single clique of a circular-arc graph $G$. We divide the cliques of $G$ into three types: a clique $C$ of $G$ is always-Helly/always-non-Helly/ambiguous if $C$ is Helly in every/no/(some but not all) normalized model of $G$. We provide a combinatorial description for the cliques of each type, and based on it, we devise a polynomial time algorithm which determines the type of a given clique.
  Finally, we study the Helly Cliques problem, in which we are given an $n$-vertex circular-arc graph $G$ and some of its cliques $C_1, \ldots, C_k$ and we ask if there is an arc intersection model of $G$ in which all the cliques $C_1, \ldots, C_k$ satisfy the Helly property. We show that:
  (1) the Helly Cliques problem admits a $2^{O(k\log{k})}n^{O(1)}$-time algorithm (that is, it is FPT when parametrized by the number of cliques given in the input),
  (2) assuming Exponential Time Hypothesis (ETH), the Helly Cliques problem cannot be solved in time $2^{o(k)}n^{O(1)}$,
  (3) the Helly Cliques problem admits a polynomial kernel of size $O(k^6)$.
  All our results use a data structure, called a PQM-tree, which maintains all normalized models of a circular-arc graph $G$.</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.00416v2</guid>
      <category>cs.DS</category>
      <category>cs.DM</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Jan Derbisz, Tomasz Krawczyk</dc:creator>
    </item>
    <item>
      <title>Directed Buy-at-Bulk Spanners</title>
      <link>https://arxiv.org/abs/2404.05172</link>
      <description>arXiv:2404.05172v2 Announce Type: replace 
Abstract: We present a framework that unifies directed buy-at-bulk network design and directed spanner problems, namely, buy-at-bulk spanners. The goal is to find a minimum-cost routing solution for network design problems that capture economies at scale, while satisfying demands and distance constraints for terminal pairs. A more restricted version of this problem was shown to be $O(2^{{\log^{1-\varepsilon} n}})$-hard to approximate, where $n$ is the number of vertices, under a standard complexity assumption, due to Elkin and Peleg (Theory of Computing Systems, 2007).
  To the best of our knowledge, our results are the first sublinear factor approximation algorithms for directed buy-at-bulk spanners. Furthermore, these results hold even when we allow the edge lengths to be negative, unlike the previous literature for spanners. Our approximation ratios match the state-of-the-art ratios in special cases, namely, buy-at-bulk network design by Antonakopoulos (WAOA, 2010) and weighted spanners by Grigorescu, Kumar, and Lin (APPROX 2023).
  Our results are based on new approximation algorithms for the following two problems that are of independent interest: minimum-density distance-constrained junction trees and resource-constrained shortest path with negative consumption.</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.05172v2</guid>
      <category>cs.DS</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Elena Grigorescu, Nithish Kumar, Young-San Lin</dc:creator>
    </item>
    <item>
      <title>Generalized Nash Equilibrium Problems with Mixed-Integer Variables</title>
      <link>https://arxiv.org/abs/2107.13298</link>
      <description>arXiv:2107.13298v3 Announce Type: replace-cross 
Abstract: We consider generalized Nash equilibrium problems (GNEPs) with non-convex strategy spaces and non-convex cost functions. This general class of games includes the important case of games with mixed-integer variables for which only a few results are known in the literature. We present a new approach to characterize equilibria via a convexification technique using the Nikaido-Isoda function. To any given instance of the GNEP, we construct a set of convexified instances and show that a feasible strategy profile is an equilibrium for the original instance if and only if it is an equilibrium for any convexified instance and the convexified cost functions coincide with the initial ones. We develop this convexification approach along three dimensions: We first show that for quasi-linear models, where a convexified instance exists in which for fixed strategies of the opponent players, the cost function of every player is linear and the respective strategy space is polyhedral, the convexification reduces the GNEP to a standard (non-linear) optimization problem. Secondly, we derive two complete characterizations of those GNEPs for which the convexification leads to a jointly constrained or a jointly convex GNEP, respectively. These characterizations require new concepts related to the interplay of the convex hull operator applied to restricted subsets of feasible strategies and may be interesting on their own. Note that this characterization is also computationally relevant as jointly convex GNEPs have been extensively studied in the literature. Finally, we demonstrate the applicability of our results by presenting a numerical study regarding the computation of equilibria for three classes of GNEPs related to integral network flows and discrete market equilibria.</description>
      <guid isPermaLink="false">oai:arXiv.org:2107.13298v3</guid>
      <category>cs.GT</category>
      <category>cs.DM</category>
      <category>cs.DS</category>
      <category>math.OC</category>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <arxiv:DOI>10.1007/s10107-024-02063-6</arxiv:DOI>
      <arxiv:journal_reference>Mathematical Programming (2024)</arxiv:journal_reference>
      <dc:creator>Tobias Harks, Julian Schwarz</dc:creator>
    </item>
    <item>
      <title>From approximate to exact integer programming</title>
      <link>https://arxiv.org/abs/2211.03859</link>
      <description>arXiv:2211.03859v4 Announce Type: replace-cross 
Abstract: Approximate integer programming is the following: For a convex body $K \subseteq \mathbb{R}^n$, either determine whether $K \cap \mathbb{Z}^n$ is empty, or find an integer point in the convex body scaled by $2$ from its center of gravity $c$. Approximate integer programming can be solved in time $2^{O(n)}$ while the fastest known methods for exact integer programming run in time $2^{O(n)} \cdot n^n$. So far, there are no efficient methods for integer programming known that are based on approximate integer programming. Our main contribution are two such methods, each yielding novel complexity results.
  First, we show that an integer point $x^* \in (K \cap \mathbb{Z}^n)$ can be found in time $2^{O(n)}$, provided that the remainders of each component $x_i^* \mod{\ell}$ for some arbitrarily fixed $\ell \geq 5(n+1)$ of $x^*$ are given. The algorithm is based on a cutting-plane technique, iteratively halving the volume of the feasible set. The cutting planes are determined via approximate integer programming. Enumeration of the possible remainders gives a $2^{O(n)}n^n$ algorithm for general integer programming. This matches the current best bound of an algorithm by Dadush (2012) that is considerably more involved. Our algorithm also relies on a new asymmetric approximate Carath\'eodory theorem that might be of interest on its own.
  Our second method concerns integer programming problems in equation-standard form $Ax = b, 0 \leq x \leq u, \, x \in \mathbb{Z}^n$ . Such a problem can be reduced to the solution of $\prod_i O(\log u_i +1)$ approximate integer programming problems. This implies, for example that knapsack or subset-sum problems with polynomial variable range $0 \leq x_i \leq p(n)$ can be solved in time $(\log n)^{O(n)}$. For these problems, the best running time so far was $n^n \cdot 2^{O(n)}$.</description>
      <guid isPermaLink="false">oai:arXiv.org:2211.03859v4</guid>
      <category>math.OC</category>
      <category>cs.CC</category>
      <category>cs.DM</category>
      <category>cs.DS</category>
      <category>math.CO</category>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Daniel Dadush, Friedrich Eisenbrand, Thomas Rothvoss</dc:creator>
    </item>
    <item>
      <title>Fair integer programming under dichotomous and cardinal preferences</title>
      <link>https://arxiv.org/abs/2306.13383</link>
      <description>arXiv:2306.13383v2 Announce Type: replace-cross 
Abstract: One cannot make truly fair decisions using integer linear programs unless one controls the selection probabilities of the (possibly many) optimal solutions. For this purpose, we propose a unified framework when binary decision variables represent agents with dichotomous preferences, who only care about whether they are selected in the final solution. We develop several general-purpose algorithms to fairly select optimal solutions, for example, by maximizing the Nash product or the minimum selection probability, or by using a random ordering of the agents as a selection criterion (Random Serial Dictatorship). We also discuss in detail how to extend the proposed methods when agents have cardinal preferences. As such, we embed the black-box procedure of solving an integer linear program into a framework that is explainable from start to finish. Lastly, we evaluate the proposed methods on two specific applications, namely kidney exchange (dichotomous preferences), and the scheduling problem of minimizing total tardiness on a single machine (cardinal preferences). We find that while the methods maximizing the Nash product or the minimum selection probability outperform the other methods on the evaluated welfare criteria, methods such as Random Serial Dictatorship perform reasonably well in computation times that are similar to those of finding a single optimal solution.</description>
      <guid isPermaLink="false">oai:arXiv.org:2306.13383v2</guid>
      <category>cs.GT</category>
      <category>cs.DS</category>
      <category>econ.TH</category>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Tom Demeulemeester, Dries Goossens, Ben Hermans, Roel Leus</dc:creator>
    </item>
    <item>
      <title>Conjunctive Queries on Probabilistic Graphs: The Limits of Approximability</title>
      <link>https://arxiv.org/abs/2309.13287</link>
      <description>arXiv:2309.13287v4 Announce Type: replace-cross 
Abstract: Query evaluation over probabilistic databases is a notoriously intractable problem -- not only in combined complexity, but for many natural queries in data complexity as well. This motivates the study of probabilistic query evaluation through the lens of approximation algorithms, and particularly of combined FPRASes, whose runtime is polynomial in both the query and instance size. In this paper, we focus on tuple-independent probabilistic databases over binary signatures, which can be equivalently viewed as probabilistic graphs. We study in which cases we can devise combined FPRASes for probabilistic query evaluation in this setting.
  We settle the complexity of this problem for a variety of query and instance classes, by proving both approximability and (conditional) inapproximability results. This allows us to deduce many corollaries of possible independent interest. For example, we show how the results of Arenas et al. on counting fixed-length strings accepted by an NFA imply the existence of an FPRAS for the two-terminal network reliability problem on directed acyclic graphs: this was an open problem until now. We also show that one cannot extend a recent result of van Bremen and Meel that gives a combined FPRAS for self-join-free conjunctive queries of bounded hypertree width on probabilistic databases: neither the bounded-hypertree-width condition nor the self-join-freeness hypothesis can be relaxed. Finally, we complement all our inapproximability results with unconditional lower bounds, showing that DNNF provenance circuits must have at least moderately exponential size in combined complexity.</description>
      <guid isPermaLink="false">oai:arXiv.org:2309.13287v4</guid>
      <category>cs.DB</category>
      <category>cs.DS</category>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <arxiv:DOI>10.4230/LIPIcs.ICDT.2024.15</arxiv:DOI>
      <dc:creator>Antoine Amarilli, Timothy van Bremen, Kuldeep S. Meel</dc:creator>
    </item>
    <item>
      <title>Hamiltonian Property Testing</title>
      <link>https://arxiv.org/abs/2403.02968</link>
      <description>arXiv:2403.02968v2 Announce Type: replace-cross 
Abstract: Locality is a fundamental feature of many physical time evolutions. Assumptions on locality and related structural properties also underlie recently proposed procedures for learning an unknown Hamiltonian from access to the induced time evolution. However, no protocols to rigorously test whether an unknown Hamiltonian is local were known. We investigate Hamiltonian locality testing as a property testing problem, where the task is to determine whether an unknown $n$-qubit Hamiltonian $H$ is $k$-local or $\varepsilon$-far from all $k$-local Hamiltonians, given access to the time evolution along $H$. First, we emphasize the importance of the chosen distance measure: With respect to the operator norm, a worst-case distance measure, incoherent quantum locality testers require $\tilde{\Omega}(2^n)$ many time evolution queries and an expected total evolution time of $\tilde{\Omega}(2^n / \varepsilon)$, and even coherent testers need $\Omega(2^{n/2})$ many queries and $\Omega(2^{n/2}/\varepsilon)$ total evolution time. In contrast, when distances are measured according to the normalized Frobenius norm, corresponding to an average-case distance, we give a sample-, time-, and computationally efficient incoherent Hamiltonian locality testing algorithm based on randomized measurements. In fact, our procedure can be used to simultaneously test a wide class of Hamiltonian properties beyond locality. Finally, we prove that learning a general Hamiltonian remains exponentially hard with this average-case distance, thereby establishing an exponential separation between Hamiltonian testing and learning. Our work initiates the study of property testing for quantum Hamiltonians, demonstrating that a broad class of Hamiltonian properties is efficiently testable even with limited quantum capabilities, and positioning Hamiltonian testing as an independent area of research alongside Hamiltonian learning.</description>
      <guid isPermaLink="false">oai:arXiv.org:2403.02968v2</guid>
      <category>quant-ph</category>
      <category>cs.CC</category>
      <category>cs.DS</category>
      <category>cs.IT</category>
      <category>cs.LG</category>
      <category>math.IT</category>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Andreas Bluhm, Matthias C. Caro, Aadil Oufkir</dc:creator>
    </item>
    <item>
      <title>A simple lower bound for the complexity of estimating partition functions on a quantum computer</title>
      <link>https://arxiv.org/abs/2404.02414</link>
      <description>arXiv:2404.02414v2 Announce Type: replace-cross 
Abstract: We study the complexity of estimating the partition function $\mathsf{Z}(\beta)=\sum_{x\in\chi} e^{-\beta H(x)}$ for a Gibbs distribution characterized by the Hamiltonian $H(x)$. We provide a simple and natural lower bound for quantum algorithms that solve this task by relying on reflections through the coherent encoding of Gibbs states. Our primary contribution is a $\varOmega(1/\epsilon)$ lower bound for the number of reflections needed to estimate the partition function with a quantum algorithm. The proof is based on a reduction from the problem of estimating the Hamming weight of an unknown binary string.</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.02414v2</guid>
      <category>quant-ph</category>
      <category>cs.CC</category>
      <category>cs.DS</category>
      <category>math.ST</category>
      <category>stat.TH</category>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Zherui Chen, Giacomo Nannicini</dc:creator>
    </item>
  </channel>
</rss>
