<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>stat.CO updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/stat.CO</link>
    <description>stat.CO updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/stat.CO" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Wed, 16 Oct 2024 04:01:25 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Wed, 16 Oct 2024 00:00:00 -0400</pubDate>
    <skipDays>
      <day>Sunday</day>
      <day>Saturday</day>
    </skipDays>
    <item>
      <title>Variational Inference in Location-Scale Families: Exact Recovery of the Mean and Correlation Matrix</title>
      <link>https://arxiv.org/abs/2410.11067</link>
      <description>arXiv:2410.11067v1 Announce Type: cross 
Abstract: Given an intractable target density $p$, variational inference (VI) attempts to find the best approximation $q$ from a tractable family $Q$. This is typically done by minimizing the exclusive Kullback-Leibler divergence, $\text{KL}(q||p)$. In practice, $Q$ is not rich enough to contain $p$, and the approximation is misspecified even when it is a unique global minimizer of $\text{KL}(q||p)$. In this paper, we analyze the robustness of VI to these misspecifications when $p$ exhibits certain symmetries and $Q$ is a location-scale family that shares these symmetries. We prove strong guarantees for VI not only under mild regularity conditions but also in the face of severe misspecifications. Namely, we show that (i) VI recovers the mean of $p$ when $p$ exhibits an \textit{even} symmetry, and (ii) it recovers the correlation matrix of $p$ when in addition~$p$ exhibits an \textit{elliptical} symmetry. These guarantees hold for the mean even when $q$ is factorized and $p$ is not, and for the correlation matrix even when~$q$ and~$p$ behave differently in their tails. We analyze various regimes of Bayesian inference where these symmetries are useful idealizations, and we also investigate experimentally how VI behaves in their absence.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.11067v1</guid>
      <category>stat.ML</category>
      <category>cs.LG</category>
      <category>stat.CO</category>
      <pubDate>Wed, 16 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Charles C. Margossian, Lawrence K. Saul</dc:creator>
    </item>
    <item>
      <title>rquest: An R package for hypothesis tests and confidence intervals for quantiles and summary measures based on quantiles</title>
      <link>https://arxiv.org/abs/2410.11093</link>
      <description>arXiv:2410.11093v1 Announce Type: cross 
Abstract: Sample quantiles, such as the median, are often better suited than the sample mean for summarising location characteristics of a data set. Similarly, linear combinations of sample quantiles and ratios of such linear combinations, e.g. the interquartile range and quantile-based skewness measures, are often used to quantify characteristics such as spread and skew. While often reported, it is uncommon to accompany quantile estimates with confidence intervals or standard errors. The rquest package provides a simple way to conduct hypothesis tests and derive confidence intervals for quantiles, linear combinations of quantiles, ratios of dependent linear combinations (e.g., Bowley's measure of skewness) and differences and ratios of all of the above for comparisons between independent samples. Many commonly used measures based on quantiles are included, although it is also very simple for users to define their own. Additionally, quantile-based measures of inequality are also considered. The methods are based on recent research showing that reliable distribution-free confidence intervals can be obtained, even for moderate sample sizes. Several examples are provided herein.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.11093v1</guid>
      <category>stat.ME</category>
      <category>stat.CO</category>
      <pubDate>Wed, 16 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Luke A. Prendergast, Shenal Dedduwakumara, Robert G. Staudte</dc:creator>
    </item>
    <item>
      <title>Models for spatiotemporal data with some missing locations and application to emergency calls models calibration</title>
      <link>https://arxiv.org/abs/2410.11103</link>
      <description>arXiv:2410.11103v1 Announce Type: cross 
Abstract: We consider two classes of models for spatiotemporal data: one without covariates and one with covariates. If $\mathcal{T}$ is a partition of time and $\mathcal{I}$ a partition of the studied area into zones and if $\mathcal{C}$ is the set of arrival types, we assume that the process of arrivals for time interval $t \in \mathcal{T}$, zone $i \in \mathcal{I}$, and arrival type $c \in \mathcal{C}$ is Poisson with some intensity $\lambda_{c,i,t}$. We discussed the calibration and implementation of such models in \cite{laspatedpaper, laspatedmanual} with corresponding software LASPATED (Library for the Analysis of SPAtioTEmporal Discrete data) available on GitHub at https://github.com/vguigues/LASPATED. In this paper, we discuss the extension of these models when some of the locations are missing in the historical data. We propose three models to deal with missing locations and implemented them both in Matlab and C++. The corresponding code is available on GitHub as an extension of LASPATED at https://github.com/vguigues/LASPATED/Missing_Data. We tested our implementation using the process of emergency calls to an Emergency Health Service where many calls come with missing locations and show the importance and benefit of using models that consider missing locations, rather than discarding the calls with missing locations for the calibration of statistical models for such calls.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.11103v1</guid>
      <category>stat.ME</category>
      <category>math.ST</category>
      <category>stat.CO</category>
      <category>stat.TH</category>
      <pubDate>Wed, 16 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Vincent Guigues, Anton Kleywegt, Victor Hugo Nascimento, Lucas Lucas Rafael de Andrade</dc:creator>
    </item>
    <item>
      <title>Randomized Iterative Solver as Iterative Refinement: A Simple Fix Towards Backward Stability</title>
      <link>https://arxiv.org/abs/2410.11115</link>
      <description>arXiv:2410.11115v1 Announce Type: cross 
Abstract: Iterative sketching and sketch-and-precondition are well-established randomized algorithms for solving large-scale, over-determined linear least-squares problems. In this paper, we introduce a new perspective that interprets Iterative Sketching and Sketching-and-Precondition as forms of Iterative Refinement. We also examine the numerical stability of two distinct refinement strategies, iterative refinement and recursive refinement, which progressively improve the accuracy of a sketched linear solver. Building on this insight, we propose a novel algorithm, Sketched Iterative and Recursive Refinement (SIRR), which combines both refinement methods. SIRR demonstrates a \emph{four order of magnitude improvement} in backward error compared to iterative sketching, achieved simply by reorganizing the computational order, ensuring that the computed solution exactly solves a modified least-squares system where the coefficient matrix deviates only slightly from the original matrix. To the best of our knowledge, \emph{SIRR is the first asymptotically fast, single-stage randomized least-squares solver that achieves both forward and backward stability}.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.11115v1</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <category>stat.CO</category>
      <pubDate>Wed, 16 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Ruihan Xu, Yiping Lu</dc:creator>
    </item>
    <item>
      <title>Comparison Theorems for the Mixing Times of Systematic and Random Scan Dynamics</title>
      <link>https://arxiv.org/abs/2410.11136</link>
      <description>arXiv:2410.11136v1 Announce Type: cross 
Abstract: A popular method for sampling from high-dimensional distributions is the Gibbs sampler, which iteratively resamples sites from the conditional distribution of the desired measure given the values of the other coordinates. But to what extent does the order of site updates matter in the mixing time? Two natural choices are (i) standard, or random scan, Glauber dynamics where the updated variable is chosen uniformly at random, and (ii) the systematic scan dynamics where variables are updated in a fixed, cyclic order. We first show that for systems of dimension $n$, one round of the systematic scan dynamics has spectral gap at most a factor of order $n$ worse than the corresponding spectral gap of a single step of Glauber dynamics, tightening existing bounds in the literature by He, et al. [NeurIPS '16] and Chlebicka, {\L}atuszy\'nski, and Miasodejow [Ann. Appl. Probab. '24]. This result is sharp even for simple spin systems by an example of Roberts and Rosenthal [Int. J. Statist. Prob. '15]. We complement this with a converse statement: if all, or even just one scan order rapidly mixes, the Glauber dynamics has a polynomially related mixing time, resolving a question of Chlebicka, {\L}atuszy\'nski, and Miasodejow. Our arguments are simple and only use elementary linear algebra and probability.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.11136v1</guid>
      <category>math.PR</category>
      <category>cs.DS</category>
      <category>stat.CO</category>
      <pubDate>Wed, 16 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Jason Gaitonde, Elchanan Mossel</dc:creator>
    </item>
    <item>
      <title>Experimental Design Using Interlacing Polynomials</title>
      <link>https://arxiv.org/abs/2410.11390</link>
      <description>arXiv:2410.11390v1 Announce Type: cross 
Abstract: We present a unified deterministic approach for experimental design problems using the method of interlacing polynomials. Our framework recovers the best-known approximation guarantees for the well-studied D/A/E-design problems with simple analysis. Furthermore, we obtain improved non-trivial approximation guarantee for E-design in the challenging small budget regime. Additionally, our approach provides an optimal approximation guarantee for a generalized ratio objective that generalizes both D-design and A-design.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.11390v1</guid>
      <category>cs.DS</category>
      <category>cs.LG</category>
      <category>stat.CO</category>
      <category>stat.ML</category>
      <pubDate>Wed, 16 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Lap Chi Lau, Robert Wang, Hong Zhou</dc:creator>
    </item>
    <item>
      <title>Filtering coupled Wright-Fisher diffusions</title>
      <link>https://arxiv.org/abs/2410.11429</link>
      <description>arXiv:2410.11429v1 Announce Type: cross 
Abstract: Coupled Wright-Fisher diffusions have been recently introduced to model the temporal evolution of finitely-many allele frequencies at several loci. These are vectors of multidimensional diffusions whose dynamics are weakly coupled among loci through interaction coefficients, which make the reproductive rates for each allele depend on its frequencies at several loci. Here we consider the problem of filtering a coupled Wright-Fisher diffusion with parent-independent mutation, when this is seen as an unobserved signal in a hidden Markov model. We assume individuals are sampled multinomially at discrete times from the underlying population, whose type configuration at the loci is described by the diffusion states, and adapt recently introduced duality methods to derive the filtering and smoothing distributions. These respectively provide the conditional distribution of the diffusion states given past data, and that conditional on the entire dataset, and are key to be able to perform parameter inference on models of this type. We show that for this model these distributions are countable mixtures of tilted products of Dirichlet kernels, and describe their mixing weights and how these can be updated sequentially. The evaluation of the weights involves the transition probabilities of the dual process, which are not available in closed form. We lay out pseudo codes for the implementation of the algorithms, discuss how to handle the unavailable quantities, and briefly illustrate the procedure with synthetic data.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.11429v1</guid>
      <category>math.PR</category>
      <category>q-bio.PE</category>
      <category>stat.CO</category>
      <category>stat.ME</category>
      <pubDate>Wed, 16 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Chiara Boetti, Matteo Ruggiero</dc:creator>
    </item>
    <item>
      <title>Scalable likelihood-based estimation and variable selection for the Cox model with incomplete covariates</title>
      <link>https://arxiv.org/abs/2410.11482</link>
      <description>arXiv:2410.11482v1 Announce Type: cross 
Abstract: Regression analysis with missing data is a long-standing and challenging problem, particularly when there are many missing variables with arbitrary missing patterns. Likelihood-based methods, although theoretically appealing, are often computationally inefficient or even infeasible when dealing with a large number of missing variables. In this paper, we consider the Cox regression model with incomplete covariates that are missing at random. We develop an expectation-maximization (EM) algorithm for nonparametric maximum likelihood estimation, employing a transformation technique in the E-step so that it involves only a one-dimensional integration. This innovation makes our methods scalable with respect to the dimension of the missing variables. In addition, for variable selection, we extend the proposed EM algorithm to accommodate a LASSO penalty in the likelihood. We demonstrate the feasibility and advantages of the proposed methods over existing methods by large-scale simulation studies and apply the proposed methods to a cancer genomic study.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.11482v1</guid>
      <category>stat.ME</category>
      <category>stat.CO</category>
      <pubDate>Wed, 16 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Ngok Sang Kwok, Kin Yau Wong</dc:creator>
    </item>
    <item>
      <title>Statistical Taylor Expansion</title>
      <link>https://arxiv.org/abs/2410.01223</link>
      <description>arXiv:2410.01223v3 Announce Type: replace 
Abstract: Statistical Taylor expansion replaces the input precise variables in a conventional Taylor expansion with random variables each with known distribution, to calculate the result mean and deviation. It is based on the uncorrelated uncertainty assumption: Each input variable is measured independently with fine enough statistical precision, so that their uncertainties are independent of each other. Statistical Taylor expansion reviews that the intermediate analytic expressions can no longer be regarded as independent of each other, and the result of analytic expression should be path independent. This conclusion differs fundamentally from the conventional common approach in applied mathematics to find the best execution path for a result. This paper also presents an implementation of statistical Taylor expansion called variance arithmetic, and the tests on variance arithmetic.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.01223v3</guid>
      <category>stat.CO</category>
      <category>cs.LG</category>
      <pubDate>Wed, 16 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Chengpu Wang</dc:creator>
    </item>
    <item>
      <title>Structured Optimal Variational Inference for Dynamic Latent Space Models</title>
      <link>https://arxiv.org/abs/2209.15117</link>
      <description>arXiv:2209.15117v2 Announce Type: replace-cross 
Abstract: We consider a latent space model for dynamic networks, where our objective is to estimate the pairwise inner products plus the intercept of the latent positions. To balance posterior inference and computational scalability, we consider a structured mean-field variational inference framework, where the time-dependent properties of the dynamic networks are exploited to facilitate computation and inference. Additionally, an easy-to-implement block coordinate ascent algorithm is developed with message-passing type updates in each block, whereas the complexity per iteration is linear with the number of nodes and time points. To certify the optimality, we demonstrate that the variational risk of the proposed variational inference approach attains the minimax optimal rate with only a logarithm factor under certain conditions. To this end, we first derive the minimax lower bound, which might be of independent interest. In addition, we show that the posterior under commonly adopted Gaussian random walk priors can achieve the minimax lower bound with only a logarithm factor. To the best of our knowledge, this is the first such a throughout theoretical analysis of Bayesian dynamic latent space models. Simulations and real data analysis demonstrate the efficacy of our methodology and the efficiency of our algorithm.</description>
      <guid isPermaLink="false">oai:arXiv.org:2209.15117v2</guid>
      <category>stat.ML</category>
      <category>math.ST</category>
      <category>stat.CO</category>
      <category>stat.TH</category>
      <pubDate>Wed, 16 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Peng Zhao, Anirban Bhattacharya, Debdeep Pati, Bani K. Mallick</dc:creator>
    </item>
  </channel>
</rss>
