<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>cs.LO updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/cs.LO</link>
    <description>cs.LO updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/cs.LO" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Mon, 23 Jun 2025 04:00:43 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Mon, 23 Jun 2025 00:00:00 -0400</pubDate>
    <skipDays>
      <day>Sunday</day>
      <day>Saturday</day>
    </skipDays>
    <item>
      <title>Locality in Many-Valued Structures</title>
      <link>https://arxiv.org/abs/2506.16206</link>
      <description>arXiv:2506.16206v1 Announce Type: new 
Abstract: Many-valued models generalise the structures from classical model theory by defining truth values for a model with an arbitrary algebra. Just as algebraic varieties provide semantics for many non-classical propositional logics, models defined over algebras in a variety provide the semantics for the corresponding non-classical predicate logics. In particular models defined over varieties of residuated lattices represent the model theory for first-order substructrual logics.
  In this paper we study the extent to which the classical locality theorems from Hanf and Gaifman hold true in the residuated lattice setting. We demonstrate that the answer is sensitive both to how locality is understood in the generalised context and the behaviour of the truth-defining algebra. In the case of Hanf's theorem, we will show that the theorem fails for the natural understanding of local neighbourhoods, but is recoverable in one special case for well-connected residuated lattices. For Gaifman's theorem, rather than consider Gaifman normal forms directly we focus on the main lemma of the theorem from textbook proofs. We prove that for a number of different understandings of locality, provided the algebra is well-behaved enough to express locality in its syntax, this main lemma can be recovered. In each case we will see that importance of an order-interpreting connective which creates a link between the modelling relation between models and formulas and the valuation function from formulas into the algebra.</description>
      <guid isPermaLink="false">oai:arXiv.org:2506.16206v1</guid>
      <category>cs.LO</category>
      <category>math.LO</category>
      <pubDate>Mon, 23 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>James Carr</dc:creator>
    </item>
    <item>
      <title>A Quantum-Control Lambda-Calculus with Multiple Measurement Bases</title>
      <link>https://arxiv.org/abs/2506.16244</link>
      <description>arXiv:2506.16244v1 Announce Type: new 
Abstract: We introduce Lambda-SX, a typed quantum lambda-calculus that supports multiple measurement bases. By tracking duplicability relative to arbitrary bases within the type system, Lambda-SX enables more flexible control and compositional reasoning about measurements. We formalise its syntax, typing rules, subtyping, and operational semantics, and establish its key meta-theoretical properties. This proof-of-concept shows that support for multiple bases can be coherently integrated into the type discipline of quantum programming languages.</description>
      <guid isPermaLink="false">oai:arXiv.org:2506.16244v1</guid>
      <category>cs.LO</category>
      <category>quant-ph</category>
      <pubDate>Mon, 23 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Alejandro D\'iaz-Caro, Nicolas A. Monzon</dc:creator>
    </item>
    <item>
      <title>A Hyperlogic for Strategies in Stochastic Games (Extended Version)</title>
      <link>https://arxiv.org/abs/2506.16775</link>
      <description>arXiv:2506.16775v1 Announce Type: new 
Abstract: We propose a probabilistic hyperlogic called HyperSt$^2$ that can express hyperproperties of strategies in turn-based stochastic games. To the best of our knowledge, HyperSt$^2$ is the first hyperlogic for stochastic games. HyperSt$^2$ can relate probabilities of several independent executions of strategies in a stochastic game. For example, in HyperSt$^2$ it is natural to formalize optimality, i.e., to express that some strategy is better than all other strategies, or to express the existence of Nash equilibria. We investigate the expressivity of HyperSt$^2$ by comparing it to existing logics for stochastic games, as well as existing hyperlogics. Though the model-checking problem for HyperSt$^2$ is in general undecidable, we show that it becomes decidable for bounded memory and is in EXPTIME and PSPACE-hard over memoryless deterministic strategies, and we identify a fragment for which the model-checking problem is PSPACE-complete.</description>
      <guid isPermaLink="false">oai:arXiv.org:2506.16775v1</guid>
      <category>cs.LO</category>
      <pubDate>Mon, 23 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-sa/4.0/</dc:rights>
      <dc:creator>Lina Gerlach (RWTH Aachen University), Christof L\"oding (RWTH Aachen University), Erika \'Abrah\'am (RWTH Aachen University)</dc:creator>
    </item>
    <item>
      <title>A Note on Proper Relational Structures</title>
      <link>https://arxiv.org/abs/2506.17142</link>
      <description>arXiv:2506.17142v1 Announce Type: new 
Abstract: In this note we provide an algorithm for translating relational structures into "proper" relational structures, i.e., those such that there is no pair of worlds w and u such that w is accessible from u for every agent. In particular, our method of translation preserves many classical properties of relational structures, such as transitivity and the Euclidean property. As a result, this method of translation has many applications in the literature on Simplicial Semantics for modal logic, where the creation of proper canonical relational structures is a common step in proofs of completeness.</description>
      <guid isPermaLink="false">oai:arXiv.org:2506.17142v1</guid>
      <category>cs.LO</category>
      <category>math.LO</category>
      <pubDate>Mon, 23 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Adam Bjorndahl, Philip Sink</dc:creator>
    </item>
    <item>
      <title>Bayesian Epistemology with Weighted Authority: A Formal Architecture for Truth-Promoting Autonomous Scientific Reasoning</title>
      <link>https://arxiv.org/abs/2506.16015</link>
      <description>arXiv:2506.16015v1 Announce Type: cross 
Abstract: The exponential expansion of scientific literature has surpassed the epistemic processing capabilities of both human experts and current artificial intelligence systems. This paper introduces Bayesian Epistemology with Weighted Authority (BEWA), a formally structured architecture that operationalises belief as a dynamic, probabilistically coherent function over structured scientific claims. Each claim is contextualised, author-attributed, and evaluated through a system of replication scores, citation weighting, and temporal decay. Belief updates are performed via evidence-conditioned Bayesian inference, contradiction processing, and epistemic decay mechanisms. The architecture supports graph-based claim propagation, authorial credibility modelling, cryptographic anchoring, and zero-knowledge audit verification. By formalising scientific reasoning into a computationally verifiable epistemic network, BEWA advances the foundation for machine reasoning systems that promote truth utility, rational belief convergence, and audit-resilient integrity across dynamic scientific domains.</description>
      <guid isPermaLink="false">oai:arXiv.org:2506.16015v1</guid>
      <category>cs.AI</category>
      <category>cs.CL</category>
      <category>cs.DB</category>
      <category>cs.LO</category>
      <category>math.LO</category>
      <pubDate>Mon, 23 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <dc:creator>Craig S. Wright</dc:creator>
    </item>
    <item>
      <title>Floating-Point Neural Networks Are Provably Robust Universal Approximators</title>
      <link>https://arxiv.org/abs/2506.16065</link>
      <description>arXiv:2506.16065v1 Announce Type: cross 
Abstract: The classical universal approximation (UA) theorem for neural networks establishes mild conditions under which a feedforward neural network can approximate a continuous function $f$ with arbitrary accuracy. A recent result shows that neural networks also enjoy a more general interval universal approximation (IUA) theorem, in the sense that the abstract interpretation semantics of the network using the interval domain can approximate the direct image map of $f$ (i.e., the result of applying $f$ to a set of inputs) with arbitrary accuracy. These theorems, however, rest on the unrealistic assumption that the neural network computes over infinitely precise real numbers, whereas their software implementations in practice compute over finite-precision floating-point numbers. An open question is whether the IUA theorem still holds in the floating-point setting.
  This paper introduces the first IUA theorem for floating-point neural networks that proves their remarkable ability to perfectly capture the direct image map of any rounded target function $f$, showing no limits exist on their expressiveness. Our IUA theorem in the floating-point setting exhibits material differences from the real-valued setting, which reflects the fundamental distinctions between these two computational models. This theorem also implies surprising corollaries, which include (i) the existence of provably robust floating-point neural networks; and (ii) the computational completeness of the class of straight-line programs that use only floating-point additions and multiplications for the class of all floating-point programs that halt.</description>
      <guid isPermaLink="false">oai:arXiv.org:2506.16065v1</guid>
      <category>cs.LG</category>
      <category>cs.LO</category>
      <category>cs.PL</category>
      <pubDate>Mon, 23 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Geonho Hwang, Wonyeol Lee, Yeachan Park, Sejun Park, Feras Saad</dc:creator>
    </item>
    <item>
      <title>Approximation Fixpoint Theory with Refined Approximation Spaces</title>
      <link>https://arxiv.org/abs/2506.16294</link>
      <description>arXiv:2506.16294v1 Announce Type: cross 
Abstract: Approximation Fixpoint Theory (AFT) is a powerful theory covering various semantics of non-monotonic reasoning formalisms in knowledge representation such as Logic Programming and Answer Set Programming. Many semantics of such non-monotonic formalisms can be characterized as suitable fixpoints of a non-monotonic operator on a suitable lattice. Instead of working on the original lattice, AFT operates on intervals in such lattice to approximate or construct the fixpoints of interest. While AFT has been applied successfully across a broad range of non-monotonic reasoning formalisms, it is confronted by its limitations in other, relatively simple, examples. In this paper, we overcome those limitations by extending consistent AFT to deal with approximations that are more refined than intervals. Therefore, we introduce a more general notion of approximation spaces, showcase the improved expressiveness and investigate relations between different approximation spaces.</description>
      <guid isPermaLink="false">oai:arXiv.org:2506.16294v1</guid>
      <category>cs.AI</category>
      <category>cs.LO</category>
      <pubDate>Mon, 23 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Linde Vanbesien, Bart Bogaerts, Marc Denecker</dc:creator>
    </item>
    <item>
      <title>New Bounds for the Ideal Proof System in Positive Characteristic</title>
      <link>https://arxiv.org/abs/2506.16397</link>
      <description>arXiv:2506.16397v1 Announce Type: cross 
Abstract: In this work, we prove upper and lower bounds over fields of positive characteristics for several fragments of the Ideal Proof System (IPS), an algebraic proof system introduced by Grochow and Pitassi (J. ACM 2018). Our results extend the works of Forbes, Shpilka, Tzameret, and Wigderson (Theory of Computing 2021) and also of Govindasamy, Hakoniemi, and Tzameret (FOCS 2022). These works primarily focused on proof systems over fields of characteristic $0$, and we are able to extend these results to positive characteristic.
  The question of proving general IPS lower bounds over positive characteristic is motivated by the important question of proving $AC^{0}[p]$-Frege lower bounds. This connection was observed by Grochow and Pitassi (J. ACM 2018). Additional motivation comes from recent developments in algebraic complexity theory due to Forbes (CCC 2024) who showed how to extend previous lower bounds over characteristic $0$ to positive characteristic.
  In our work, we adapt the functional lower bound method of Forbes et al. (Theory of Computing 2021) to prove exponential-size lower bounds for various subsystems of IPS. Additionally, we derive upper bounds for the instances presented above. We show that they have efficient constant-depth IPS refutations. We also show that constant-depth IPS can efficiently refute a general class of instances, namely all symmetric instances, thereby further uncovering the strength of these algebraic proofs in positive characteristic.
  Notably, our lower bounds hold for fields of arbitrary characteristic but require the field size to be $n^{\omega(1)}$. In a concurrent work, Elbaz, Govindasamy, Lu, and Tzameret have shown lower bounds against restricted classes of IPS over finite fields of any size by considering different hard instances.</description>
      <guid isPermaLink="false">oai:arXiv.org:2506.16397v1</guid>
      <category>cs.CC</category>
      <category>cs.LO</category>
      <category>math.LO</category>
      <pubDate>Mon, 23 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Amik Raj Behera, Nutan Limaye, Varun Ramanathan, Srikanth Srinivasan</dc:creator>
    </item>
    <item>
      <title>Proofs that Modify Proofs, 1/2</title>
      <link>https://arxiv.org/abs/2506.16491</link>
      <description>arXiv:2506.16491v1 Announce Type: cross 
Abstract: This paper is a prelude and elaboration on Proofs that Modify Proofs. Here we present an ordinal analysis of a fragment of the $\mu$-calculus around the strength of parameter-free $\Pi^1_2$-comprehension using the same approach as that paper, interpreting functions on proofs as proofs in an expanded system. We build up the ordinal analysis in several stages, beginning by illustrating the method systems at the strength of paremeter-free $\Pi^1_1$-comprehension and full $\Pi^1_1$-comprehension.</description>
      <guid isPermaLink="false">oai:arXiv.org:2506.16491v1</guid>
      <category>math.LO</category>
      <category>cs.LO</category>
      <pubDate>Mon, 23 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Henry Towsner</dc:creator>
    </item>
    <item>
      <title>The Proof Analysis Problem</title>
      <link>https://arxiv.org/abs/2506.16956</link>
      <description>arXiv:2506.16956v1 Announce Type: cross 
Abstract: Atserias and M\"uller (JACM, 2020) proved that for every unsatisfiable CNF formula $\varphi$, the formula $\operatorname{Ref}(\varphi)$, stating "$\varphi$ has small Resolution refutations", does not have subexponential-size Resolution refutations. Conversely, when $\varphi$ is satisfiable, Pudl\'ak (TCS, 2003) showed how to construct a polynomial-size Resolution refutation of $\operatorname{Ref}(\varphi)$ given a satisfying assignment of $\varphi$. A question that remained open is: do all short Resolution refutations of $\operatorname{Ref}(\varphi)$ explicitly leak a satisfying assignment of $\varphi$?
  We answer this question affirmatively by giving a polynomial-time algorithm that extracts a satisfying assignment for $\varphi$ given any short Resolution refutation of $\operatorname{Ref}(\varphi)$. The algorithm follows from a new feasibly constructive proof of the Atserias-M\"uller lower bound, formalizable in Cook's theory $\mathsf{PV_1}$ of bounded arithmetic.
  Motivated by this, we introduce a computational problem concerning Resolution lower bounds: the Proof Analysis Problem (PAP). For a proof system $Q$, the Proof Analysis Problem for $Q$ asks, given a CNF formula $\varphi$ and a $Q$-proof of a Resolution lower bound for $\varphi$, encoded as $\neg \operatorname{Ref}(\varphi)$, whether $\varphi$ is satisfiable. In contrast to PAP for Resolution, we prove that PAP for Extended Frege (EF) is NP-complete.
  Our results yield new insights into proof complexity: (i) every proof system simulating EF is (weakly) automatable if and only if it is (weakly) automatable on formulas stating Resolution lower bounds; (ii) we provide Ref formulas exponentially hard for bounded-depth Frege systems; and (iii) for every strong enough theory of arithmetic $T$ we construct unsatisfiable CNF formulas exponentially hard for Resolution but for which $T$ cannot prove even a quadratic lower bound.</description>
      <guid isPermaLink="false">oai:arXiv.org:2506.16956v1</guid>
      <category>cs.CC</category>
      <category>cs.LO</category>
      <category>math.LO</category>
      <pubDate>Mon, 23 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Noel Arteche, Albert Atserias, Susanna F. de Rezende, Erfan Khaniki</dc:creator>
    </item>
    <item>
      <title>Towards Advanced Mathematical Reasoning for LLMs via First-Order Logic Theorem Proving</title>
      <link>https://arxiv.org/abs/2506.17104</link>
      <description>arXiv:2506.17104v1 Announce Type: cross 
Abstract: Large language models (LLMs) have shown promising first-order logic (FOL) reasoning capabilities with applications in various areas. However, their effectiveness in complex mathematical reasoning involving multi-step FOL deductions is still under-researched. While LLMs perform competitively on established mathematical reasoning benchmarks, they struggle with multi-step FOL tasks, as demonstrated by Deepseek-Prover-V2-7B's low accuracy (4.2%) on our proposed theorem proving dataset. This issue arises from the limited exploration of diverse proof strategies and the potential for early reasoning mistakes to undermine entire proofs. To address these issues, we propose DREAM, a self-adaptive solution that enhances the Diversity and REAsonability of LLMs' generation strategies. DREAM incorporates an Axiom-Driven Strategy Diversification mechanism to promote varied strategic outcomes and a Sub-Proposition Error Feedback to help LLMs reflect on and correct their proofs. Our contributions include pioneering advancements in LLMs' mathematical reasoning through FOL theorem proving, introducing a novel inference stage solution that improves performance by 0.6% to 6.4%, and providing a curated dataset of 447 mathematical theorems in Lean 4 format for evaluation.</description>
      <guid isPermaLink="false">oai:arXiv.org:2506.17104v1</guid>
      <category>cs.AI</category>
      <category>cs.CL</category>
      <category>cs.LO</category>
      <pubDate>Mon, 23 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Chuxue Cao, Mengze Li, Juntao Dai, Jinluan Yang, Zijian Zhao, Shengyu Zhang, Weijie Shi, Chengzhong Liu, Sirui Han, Yike Guo</dc:creator>
    </item>
    <item>
      <title>No Scratch Quantum Computing by Reducing Qubit Overhead for Efficient Arithmetics</title>
      <link>https://arxiv.org/abs/2506.17135</link>
      <description>arXiv:2506.17135v1 Announce Type: cross 
Abstract: Quantum arithmetic computation requires a substantial number of scratch qubits to stay reversible. These operations necessitate qubit and gate resources equivalent to those needed for the larger of the input or output registers due to state encoding. Quantum Hamiltonian Computing (QHC) introduces a novel approach by encoding input for logic operations within a single rotating quantum gate. This innovation reduces the required qubit register $ N $ to the size of the output states $ O $, where $ N = \log_2 O $. Leveraging QHC principles, we present reversible half-adder and full-adder circuits that compress the standard Toffoli + CNOT layout [Vedral et al., PRA, 54, 11, (1996)] from three-qubit and four-qubit formats for the Quantum half-adder circuit and five sequential Fredkin gates using five qubits [Moutinho et al., PRX Energy 2, 033002 (2023)] for full-adder circuit; into a two-qubit, 4$\times $4 Hilbert space. This scheme, presented here, is optimized for classical logic evaluated on quantum hardware, which due to unitary evolution can bypass classical CMOS energy limitations to certain degree. Although we avoid superposition of input and output states in this manuscript, this remains feasible in principle. We see the best application for QHC in finding the minimal qubit and gate resources needed to evaluate any truth table, advancing FPGA capabilities using integrated quantum circuits or photonics.</description>
      <guid isPermaLink="false">oai:arXiv.org:2506.17135v1</guid>
      <category>quant-ph</category>
      <category>cs.ET</category>
      <category>cs.LO</category>
      <pubDate>Mon, 23 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Omid Faizy, Norbert Wehn, Paul Lukowicz, Maximilian Kiefer-Emmanouilidis</dc:creator>
    </item>
    <item>
      <title>On the Descriptive Complexity of Groups without Abelian Normal Subgroups</title>
      <link>https://arxiv.org/abs/2209.13725</link>
      <description>arXiv:2209.13725v5 Announce Type: replace 
Abstract: In this paper, we explore the descriptive complexity theory of finite groups by examining the power of the second Ehrenfeucht--Fra\"iss\'e bijective pebble game in Hella's (Ann. Pure Appl. Log., 1989) hierarchy. This is a Spoiler--Duplicator game in which Spoiler can place up to two pebbles each round. While it trivially solves graph isomorphism, it may be nontrivial for finite groups, and other ternary relational structures. We first provide a novel generalization of Weisfeiler--Leman (WL) coloring, which we call 2-ary WL. We then show that 2-ary WL is equivalent to the second Ehrenfeucht--Fra\"iss\'e bijective pebble game in Hella's hierarchy.
  Our main result is that, in the pebble game characterization, only $O(1)$ pebbles and $O(1)$ rounds are sufficient to identify all groups without Abelian normal subgroups (a class of groups for which isomorphism testing is known to be in $\mathsf{P}$; Babai, Codenotti, &amp; Qiao, ICALP 2012). We actually show that $7$ pebbles and $7$ rounds suffice. In particular, we show that within the first few rounds, Spoiler can force Duplicator to select an isomorphism between two such groups at each subsequent round. By Hella's results (\emph{ibid.}), this is equivalent to saying that these groups are identified by formulas in first-order logic with generalized 2-ary quantifiers, using only $7$ variables and quantifier depth $7$.</description>
      <guid isPermaLink="false">oai:arXiv.org:2209.13725v5</guid>
      <category>cs.LO</category>
      <category>cs.CC</category>
      <category>math.GR</category>
      <category>math.LO</category>
      <pubDate>Mon, 23 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Joshua A. Grochow, Michael Levet</dc:creator>
    </item>
    <item>
      <title>Extended Resolution Clause Learning via Dual Implication Points</title>
      <link>https://arxiv.org/abs/2406.14190</link>
      <description>arXiv:2406.14190v2 Announce Type: replace 
Abstract: We present a new extended resolution clause learning (ERCL) algorithm, implemented as part of a conflict-driven clause-learning (CDCL) SAT solver, wherein new variables are dynamically introduced as definitions for {\it Dual Implication Points} (DIPs) in the implication graph constructed by the solver at runtime. DIPs are generalizations of unique implication points and can be informally viewed as a pair of dominator nodes, from the decision variable at the highest decision level to the conflict node, in an implication graph. We perform extensive experimental evaluation to establish the efficacy of our ERCL method, implemented as part of the MapleLCM SAT solver and dubbed xMapleLCM, against several leading solvers including the baseline MapleLCM, as well as CDCL solvers such as Kissat 3.1.1, CryptoMiniSat 5.11, and SBVA+CaDiCaL, the winner of SAT Competition 2023. We show that xMapleLCM outperforms these solvers on Tseitin and XORified formulas. We further compare xMapleLCM with GlucoseER, a system that implements extended resolution in a different way, and provide a detailed comparative analysis of their performance.</description>
      <guid isPermaLink="false">oai:arXiv.org:2406.14190v2</guid>
      <category>cs.LO</category>
      <pubDate>Mon, 23 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Sam Buss, Jonathan Chung, Vijay Ganesh, Albert Oliveras</dc:creator>
    </item>
    <item>
      <title>A Formal Correctness Proof of Edmonds' Blossom Shrinking Algorithm</title>
      <link>https://arxiv.org/abs/2412.20878</link>
      <description>arXiv:2412.20878v2 Announce Type: replace 
Abstract: We present the first formal correctness proof of Edmonds' blossom shrinking algorithm for maximum cardinality matching in general graphs. We focus on formalising the mathematical structures and properties that allow the algorithm to run in worst-case polynomial running time. We formalise Berge's lemma, blossoms and their properties, and a mathematical model of the algorithm, showing that it is totally correct. We provide the first detailed proofs of many of the facts underlying the algorithm's correctness.</description>
      <guid isPermaLink="false">oai:arXiv.org:2412.20878v2</guid>
      <category>cs.LO</category>
      <category>cs.DS</category>
      <pubDate>Mon, 23 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Mohammad Abdulaziz</dc:creator>
    </item>
    <item>
      <title>Verification of Quantum Circuits through Barrier Certificates using a Scenario Approach</title>
      <link>https://arxiv.org/abs/2506.07635</link>
      <description>arXiv:2506.07635v2 Announce Type: replace 
Abstract: In recent years, various techniques have been explored for the verification of quantum circuits, including the use of barrier certificates, mathematical tools capable of demonstrating the correctness of such systems. These certificates ensure that, starting from initial states and applying the system's dynamics, the system will never reach undesired states. In this paper, we propose a methodology for synthesizing such certificates for quantum circuits using a scenario-based approach, for both finite and infinite time horizons. In addition, our approach can handle uncertainty in the initial states and in the system's dynamics. We present several case studies on quantum circuits, comparing the performance of different types of barrier certificate and analyzing which one is most suitable for each case.</description>
      <guid isPermaLink="false">oai:arXiv.org:2506.07635v2</guid>
      <category>cs.LO</category>
      <category>quant-ph</category>
      <pubDate>Mon, 23 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Siwei Hu, Victor Lopata, Sadegh Soudjani, Paolo Zuliani</dc:creator>
    </item>
    <item>
      <title>Demystifying $\mu$</title>
      <link>https://arxiv.org/abs/2401.01096</link>
      <description>arXiv:2401.01096v3 Announce Type: replace-cross 
Abstract: We explore the theory of illfounded and cyclic proofs for the propositional modal $\mu$-calculus. A fine analysis of provability for classical and intuitionistic modal logic provides a novel bridge between finitary, cyclic and illfounded conceptions of proof and re-enforces the importance of two normal form theorems for the logic: guardedness and disjunctiveness.</description>
      <guid isPermaLink="false">oai:arXiv.org:2401.01096v3</guid>
      <category>math.LO</category>
      <category>cs.LO</category>
      <pubDate>Mon, 23 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Bahareh Afshari, Graham E. Leigh, Guillermo Men\'endez Turata</dc:creator>
    </item>
    <item>
      <title>Quantifying artificial intelligence through algorithmic generalization</title>
      <link>https://arxiv.org/abs/2411.05943</link>
      <description>arXiv:2411.05943v2 Announce Type: replace-cross 
Abstract: The rapid development of artificial intelligence (AI) systems has created an urgent need for their scientific quantification. While their fluency across a variety of domains is impressive, AI systems fall short on tests requiring algorithmic reasoning -- a glaring limitation given the necessity for interpretable and reliable technology. Despite a surge of reasoning benchmarks emerging from the academic community, no theoretical framework exists to quantify algorithmic reasoning in AI systems. Here, we adopt a framework from computational complexity theory to quantify algorithmic generalization using algebraic expressions: algebraic circuit complexity. Algebraic circuit complexity theory -- the study of algebraic expressions as circuit models -- is a natural framework to study the complexity of algorithmic computation. Algebraic circuit complexity enables the study of generalization by defining benchmarks in terms of the computational requirements to solve a problem. Moreover, algebraic circuits are generic mathematical objects; an arbitrarily large number of samples can be generated for a specified circuit, making it an ideal experimental sandbox for the data-hungry models that are used today. In this Perspective, we adopt tools from algebraic circuit complexity, apply them to formalize a science of algorithmic generalization, and address key challenges for its successful application to AI science.</description>
      <guid isPermaLink="false">oai:arXiv.org:2411.05943v2</guid>
      <category>cs.AI</category>
      <category>cs.CL</category>
      <category>cs.LG</category>
      <category>cs.LO</category>
      <pubDate>Mon, 23 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Takuya Ito, Murray Campbell, Lior Horesh, Tim Klinger, Parikshit Ram</dc:creator>
    </item>
    <item>
      <title>Synthesizing Composite Hierarchical Structure from Symbolic Music Corpora</title>
      <link>https://arxiv.org/abs/2502.15849</link>
      <description>arXiv:2502.15849v4 Announce Type: replace-cross 
Abstract: Western music is an innately hierarchical system of interacting levels of structure, from fine-grained melody to high-level form. In order to analyze music compositions holistically and at multiple granularities, we propose a unified, hierarchical meta-representation of musical structure called the structural temporal graph (STG). For a single piece, the STG is a data structure that defines a hierarchy of progressively finer structural musical features and the temporal relationships between them. We use the STG to enable a novel approach for deriving a representative structural summary of a music corpus, which we formalize as a nested NP-hard combinatorial optimization problem extending the Generalized Median Graph problem. Our approach first applies simulated annealing to develop a measure of structural distance between two music pieces rooted in graph isomorphism. Our approach then combines the formal guarantees of SMT solvers with nested simulated annealing over structural distances to produce a structurally sound, representative centroid STG for an entire corpus of STGs from individual pieces. To evaluate our approach, we conduct experiments verifying that structural distance accurately differentiates between music pieces, and that derived centroids accurately structurally characterize their corpora.</description>
      <guid isPermaLink="false">oai:arXiv.org:2502.15849v4</guid>
      <category>cs.AI</category>
      <category>cs.LO</category>
      <category>cs.SD</category>
      <pubDate>Mon, 23 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Ilana Shapiro, Ruanqianqian Huang, Zachary Novack, Cheng-i Wang, Hao-Wen Dong, Taylor Berg-Kirkpatrick, Shlomo Dubnov, Sorin Lerner</dc:creator>
    </item>
  </channel>
</rss>
