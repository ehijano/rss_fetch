<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>cs.IT updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/cs.IT</link>
    <description>cs.IT updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/cs.IT" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Wed, 19 Nov 2025 05:00:26 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Wed, 19 Nov 2025 00:00:00 -0500</pubDate>
    <skipDays>
      <day>Saturday</day>
      <day>Sunday</day>
    </skipDays>
    <item>
      <title>DNA Storage in the Short Molecule Regime</title>
      <link>https://arxiv.org/abs/2511.14284</link>
      <description>arXiv:2511.14284v1 Announce Type: new 
Abstract: We study the amount of reliable information that can be stored in a DNA-based storage system composed of short DNA molecules. In this regime, Shomorony and Heckel (2022) put forward a conjecture on the scaling of the number of information bits that can be reliably stored. In this paper, we complete the proof of this conjecture. We analyze a random-coding scheme in which each codeword is obtained by quantizing a randomly generated probability mass function drawn from the probability simplex. By analyzing the optimal maximum-likelihood decoder, we derive an achievability bound that matches a recently established converse bound across the entire short-molecule regime. We also propose a second coding scheme, which operates with significantly lower computational complexity but achieves the optimal scaling, except for a specific range of very short molecules.</description>
      <guid isPermaLink="false">oai:arXiv.org:2511.14284v1</guid>
      <category>cs.IT</category>
      <category>math.IT</category>
      <pubDate>Wed, 19 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Ran Tamir, Nir Weinberger, Albert Guill\'en i F\`abregas</dc:creator>
    </item>
    <item>
      <title>The Capacity of Collusion-Resilient Decentralized Secure Aggregation with Groupwise Keys</title>
      <link>https://arxiv.org/abs/2511.14444</link>
      <description>arXiv:2511.14444v1 Announce Type: new 
Abstract: This paper investigates the information-theoretic decentralized secure aggregation (DSA) problem under practical groupwise secret keys and collusion resilience. In DSA, $K$ users are interconnected through error-free broadcast channels. Each user holds a private input and aims to compute the sum of all other users' inputs, while satisfying the security constraint that no user, even when colluding with up to $T$ other users, can infer any information about the inputs beyond the recovered sum. To ensure security, users are equipped with secret keys to mask their inputs. Motivated by recent advances in efficient group-based key generation protocols, we consider the symmetric groupwise key setting, where every subset of $G$ users shares a group key that is independent of all other group keys. The problem is challenging because the recovery and security constraints must hold simultaneously for all users, and the structural constraints on the secret keys limit the flexibility of key correlations. We characterize the optimal rate region consisting of all achievable pairs of per-user broadcast communication rate and groupwise key rate. In particular, we show that DSA with groupwise keys is infeasible when $G=1$ or $G\ge K-T$. Otherwise, when $2\le G&lt;K-T$, to securely compute one symbol of the desired sum, each user must broadcast at least one symbol, and each group key must contain at least $(K-T-2)/\binom{K-T-1}{G}$ independent symbols. Our results establish the fundamental limits of DSA with groupwise keys and provide design insights for communication- and key-efficient secure aggregation in decentralized learning systems.</description>
      <guid isPermaLink="false">oai:arXiv.org:2511.14444v1</guid>
      <category>cs.IT</category>
      <category>math.IT</category>
      <pubDate>Wed, 19 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Zhou Li, Xiang Zhang, Yizhou Zhao, Haiqiang Chen, Jihao Fan, Giuseppe Caire</dc:creator>
    </item>
    <item>
      <title>Monimial Matrix Analogue of Yoshida's theorem</title>
      <link>https://arxiv.org/abs/2511.14480</link>
      <description>arXiv:2511.14480v1 Announce Type: new 
Abstract: In this paper, we study variants of weight enumerators of linear codes over $\mathbb{F}_q$. We generalize the concept of average complete joint weight enumerators of two linear codes over $\mathbb{F}_q$. We also give its MacWilliams type identities. Then we establish a monomial analogue of Yoshida's theorem for this average complete joint weight enumerators. Finally, we present the generalized representation for average of $g$-fold complete joint weight enumerators for $\mathbb{F}_q$-linear codes and establish a monomial matrix analogue of Yoshida's theorem for average $g$-fold complete joint weight enumerators.</description>
      <guid isPermaLink="false">oai:arXiv.org:2511.14480v1</guid>
      <category>cs.IT</category>
      <category>math.CO</category>
      <category>math.IT</category>
      <pubDate>Wed, 19 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <dc:creator>Ananda Chakraborty</dc:creator>
    </item>
    <item>
      <title>Neural Networks-Enabled Channel Reconstruction for Fluid Antenna Systems: A Data-Driven Approach</title>
      <link>https://arxiv.org/abs/2511.14520</link>
      <description>arXiv:2511.14520v1 Announce Type: new 
Abstract: Fluid antenna systems (FASs) offer substantial spatial diversity by exploiting the electromagnetic port correlation within compact array spaces, thereby generating favorable small-scale fading conditions with beneficial channel gain envelope fluctuations. This unique capability opens new opportunities for a wide range of communication applications and emerging technologies. However, accurate channel state information (CSI) must be acquired before a fluid antenna can be effectively utilized. Although several efforts have been made toward channel reconstruction in FASs, a generally applicable solution to both model-based or model-free scenario with both high precision and efficient computational flow remains lacking. In this work, we propose a data-driven channel reconstruction approach enabled by neural networks. The proposed framework not only achieves significantly enhanced reconstruction accuracy but also requires substantially lower computational complexity compared with existing model-free methods. Numerical results further demonstrate the rapid convergence and robust reconstruction capability of the proposed scheme, outperforming current state-of-the-art techniques.</description>
      <guid isPermaLink="false">oai:arXiv.org:2511.14520v1</guid>
      <category>cs.IT</category>
      <category>math.IT</category>
      <pubDate>Wed, 19 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Haoyu Liang, Zhentian Zhang, Jian Dang, Hao Jiang, Zaichen Zhang</dc:creator>
    </item>
    <item>
      <title>Compression with Privacy-Preserving Random Access</title>
      <link>https://arxiv.org/abs/2511.14524</link>
      <description>arXiv:2511.14524v1 Announce Type: new 
Abstract: It is shown that an i.i.d. binary source sequence $X_1, \ldots, X_n$ can be losslessly compressed at any rate above entropy such that the individual decoding of any $X_i$ reveals \emph{no} information about the other bits $\{X_j : j \neq i\}$.</description>
      <guid isPermaLink="false">oai:arXiv.org:2511.14524v1</guid>
      <category>cs.IT</category>
      <category>cs.CR</category>
      <category>cs.DS</category>
      <category>math.IT</category>
      <pubDate>Wed, 19 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Venkat Chandar, Aslan Tchamkerten, Shashank Vatedka</dc:creator>
    </item>
    <item>
      <title>Cross-Sparsity-Enabled Multipath Perception via Structured Bayesian Inference for Multi-Target Estimation</title>
      <link>https://arxiv.org/abs/2511.14051</link>
      <description>arXiv:2511.14051v1 Announce Type: cross 
Abstract: In this paper, we investigate a multi-target sensing system in multipath environment, where inter-target scattering gives rise to first-order reflected paths whose angles of departure (AoDs) and angles of arrival (AoAs) coincide with the direct-path angles of different targets. Unlike other multipath components, these first-order paths carry structural information that can be exploited as additional prior knowledge for target direction estimation. To exploit this property, we construct a sparse representation of the multi-target sensing channel and propose a novel cross sparsity structure under a three-layer hierarchical structured (3LHS) prior model, which leverages the first-order paths to enhance the prior probability of the direct paths and thereby improve the estimation accuracy. Building on this model, we propose a structured fast turbo variational Bayesian inference (SF-TVBI) algorithm, which integrates an efficient message-passing strategy to enable tractable probabilistic exchange within the cross sparsity, and a two-timescale update scheme to reduce the update frequency of the high-dimensional sparse vector. Simulation results demonstrate that leveraging the proposed cross sparsity structure is able to improve the target angle estimation accuracy substantially, and the SF-TVBI algorithm achieves estimation performance comparable to that of the Turbo-VBI, but with lower computational complexity.</description>
      <guid isPermaLink="false">oai:arXiv.org:2511.14051v1</guid>
      <category>eess.SP</category>
      <category>cs.IT</category>
      <category>math.IT</category>
      <pubDate>Wed, 19 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Xiang Chen, Ming-Min Zhao, An Liu, Min Li, Qingjiang Shi, Min-Jian Zhao</dc:creator>
    </item>
    <item>
      <title>Radial Compensation: Stable and Semantically Decoupled Generative Models on Riemannian Manifolds</title>
      <link>https://arxiv.org/abs/2511.14056</link>
      <description>arXiv:2511.14056v1 Announce Type: cross 
Abstract: Generative models on curved spaces rely on charts to map Euclidean spaces to manifolds. Exponential maps preserve geodesics but have stiff, radius-dependent Jacobians, while volume-preserving charts maintain densities but distort geodesic distances. Both approaches entangle curvature with model parameters, inflating gradient variance. In high-dimensional latent normalizing flows, the wrapped exponential prior can stretch radii far beyond the curvature scale, leading to poor test likelihoods and stiff solvers. We introduce Radial Compensation (RC), an information-geometric method that selects the base density in the tangent space so that the likelihood depends only on geodesic distance from a pole, decoupling parameter semantics from curvature. RC lets radial parameters retain their usual meaning in geodesic units, while the chart can be tuned as a numerical preconditioner. We extend RC to manifolds with known geodesic polar volume and show that RC is the only construction for geodesic-radial likelihoods with curvature-invariant Fisher information. We derive the Balanced-Exponential (bExp) chart family, balancing volume distortion and geodesic error. Under RC, all bExp settings preserve the same manifold density and Fisher information, with smaller dial values reducing gradient variance and flow cost. Empirically, RC yields stable generative models across densities, VAEs, flows on images and graphs, and protein models. RC improves likelihoods, restores clean geodesic radii, and prevents radius blow-ups in high-dimensional flows, making RC-bExp a robust default for likelihood-trained generative models on manifolds.</description>
      <guid isPermaLink="false">oai:arXiv.org:2511.14056v1</guid>
      <category>cs.LG</category>
      <category>cs.AI</category>
      <category>cs.IT</category>
      <category>math.DG</category>
      <category>math.IT</category>
      <category>stat.ML</category>
      <pubDate>Wed, 19 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Marios Papamichals, Regina Ruane</dc:creator>
    </item>
    <item>
      <title>Hermitian-Singer Functional and Differential Codes</title>
      <link>https://arxiv.org/abs/2511.14345</link>
      <description>arXiv:2511.14345v1 Announce Type: cross 
Abstract: Algebraic geometry codes on the Hermitian curve have been the subject of several papers, since they happen to have good performances and large automorphism groups. Here, those arising from the Singer cycle of the Hermitian curve are investigated.</description>
      <guid isPermaLink="false">oai:arXiv.org:2511.14345v1</guid>
      <category>math.AG</category>
      <category>cs.IT</category>
      <category>math.IT</category>
      <pubDate>Wed, 19 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>G\'abor Korchm\'aros, Federico Romaniello, Valentino Smaldore</dc:creator>
    </item>
    <item>
      <title>Covariance-based Imaging and Multi-View Fusion for Networked Sensing</title>
      <link>https://arxiv.org/abs/2511.14490</link>
      <description>arXiv:2511.14490v1 Announce Type: cross 
Abstract: This paper considers multi-view imaging in a sixth-generation (6G) integrated sensing and communication network, which consists of a transmit base-station (BS), multiple receive BSs connected to a central processing unit (CPU), and multiple extended targets. Our goal is to devise an effective multi-view imaging technique that can jointly leverage the targets' echo signals at all the receive BSs to precisely construct the image of these targets. To achieve this goal, we propose a two-phase approach. In Phase I, each receive BS recovers an individual image based on the sample covariance matrix of its received signals. Specifically, we propose a novel covariance-based imaging framework to jointly estimate effective scattering intensity and grid positions, which reduces the number of estimated parameters leveraging channel statistical properties and allows grid adjustment to conform to target geometry. In Phase II, the CPU fuses the individual images of all the receivers to construct a high-quality image of all the targets. Specifically, we design edge-preserving natural neighbor interpolation (EP-NNI) to map individual heterogeneous images onto common and finer grids, and then propose a joint optimization framework to estimate fused scattering intensity and BS fields of view. Extensive numerical results show that the proposed scheme significantly enhances imaging performance, facilitating high-quality environment reconstruction for future 6G networks.</description>
      <guid isPermaLink="false">oai:arXiv.org:2511.14490v1</guid>
      <category>eess.SP</category>
      <category>cs.IT</category>
      <category>math.IT</category>
      <pubDate>Wed, 19 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Junyuan Gao, Weifeng Zhu, Yanmo Hu, Shuowen Zhang, Jiannong Cao, Yongpeng Wu, Giuseppe Caire, Liang Liu</dc:creator>
    </item>
    <item>
      <title>Rate-Distortion Guided Knowledge Graph Construction from Lecture Notes Using Gromov-Wasserstein Optimal Transport</title>
      <link>https://arxiv.org/abs/2511.14595</link>
      <description>arXiv:2511.14595v1 Announce Type: cross 
Abstract: Task-oriented knowledge graphs (KGs) enable AI-powered learning assistant systems to automatically generate high-quality multiple-choice questions (MCQs). Yet converting unstructured educational materials, such as lecture notes and slides, into KGs that capture key pedagogical content remains difficult. We propose a framework for knowledge graph construction and refinement grounded in rate-distortion (RD) theory and optimal transport geometry. In the framework, lecture content is modeled as a metric-measure space, capturing semantic and relational structure, while candidate KGs are aligned using Fused Gromov-Wasserstein (FGW) couplings to quantify semantic distortion. The rate term, expressed via the size of KG, reflects complexity and compactness. Refinement operators (add, merge, split, remove, rewire) minimize the rate-distortion Lagrangian, yielding compact, information-preserving KGs. Our prototype applied to data science lectures yields interpretable RD curves and shows that MCQs generated from refined KGs consistently surpass those from raw notes on fifteen quality criteria. This study establishes a principled foundation for information-theoretic KG optimization in personalized and AI-assisted education.</description>
      <guid isPermaLink="false">oai:arXiv.org:2511.14595v1</guid>
      <category>cs.AI</category>
      <category>cs.IT</category>
      <category>math.IT</category>
      <pubDate>Wed, 19 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Yuan An, Ruhma Hashmi, Michelle Rogers, Jane Greenberg, Brian K. Smith</dc:creator>
    </item>
    <item>
      <title>On Noncoherent Multiple-Antenna Rayleigh Block-Fading Channels at Finite Blocklength</title>
      <link>https://arxiv.org/abs/2503.01504</link>
      <description>arXiv:2503.01504v3 Announce Type: replace 
Abstract: This paper investigates the maximum coding rate at which data can be transmitted over a noncoherent, multiple-input, multiple-output (MIMO) Rayleigh block-fading channel using an error-correcting code of a given blocklength with a block-error probability not exceeding a given value. A high-SNR normal approximation is derived that becomes accurate as the signal-to-noise ratio (SNR) and the number of coherence intervals over which we code tend to infinity. The obtained normal approximation complements the nonasymptotic bounds that have appeared in the literature, but whose evaluation is computationally demanding. It further lays the theoretical foundation for an analytical analysis of the fundamental tradeoff between diversity, multiplexing, and channel-estimation cost at finite blocklength and finite SNR.</description>
      <guid isPermaLink="false">oai:arXiv.org:2503.01504v3</guid>
      <category>cs.IT</category>
      <category>math.IT</category>
      <pubDate>Wed, 19 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Chao Qi, Tobias Koch</dc:creator>
    </item>
    <item>
      <title>Locally Repairable Convertible Codes: Improved Lower Bound and General Construction</title>
      <link>https://arxiv.org/abs/2504.06734</link>
      <description>arXiv:2504.06734v2 Announce Type: replace 
Abstract: In this paper, we consider the convertible code with locally repairable property. We present an improved lower bound on access cost associated with $(r,\delta)$. Then, we provide a general construction of convertible codes with optimal access cost which shows that those codes can be with super-linear length or maximum repairable property. Additionally, employing the known locally repairable codes with super-linear length or maximum repairable property, we provide explicit constructions of convertible codes with super-linear length or maximum repairable property.</description>
      <guid isPermaLink="false">oai:arXiv.org:2504.06734v2</guid>
      <category>cs.IT</category>
      <category>math.IT</category>
      <pubDate>Wed, 19 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Songping Ge, Han Cai, Xiaohu Tang</dc:creator>
    </item>
    <item>
      <title>Implicit Communication in Linear Quadratic Gaussian Control Systems</title>
      <link>https://arxiv.org/abs/2509.16146</link>
      <description>arXiv:2509.16146v2 Announce Type: replace 
Abstract: This paper studies implicit communication in linear quadratic Gaussian control systems. We show that the control system itself can serve as an implicit communication channel, enabling the controller to transmit messages through its inputs to a receiver that observes the system state. This communication is considered implicit because (i) no explicit communication channels are needed; and (ii) information is transmitted while simultaneously fulfilling the controller's primary objective--maintaining the control cost within a specified level. As a result, there exists an inherent trade-off between control and communication performance. This trade-off is formalized through the notion of implicit channel capacity, which characterizes the supremum reliable communication rate subject to a constraint on control performance. We investigate the implicit channel capacity in two settings. When both the controller and the receiver have noiseless observations of the system state, the channel capacity admits a closed-form expression. When both the controller and the receiver have noisy observations, we establish a lower bound on the implicit channel capacity. Surprisingly, in the noiseless observation case, the capacity-achieving input policy adheres to a separation principle, allowing the control and channel coding tasks to be addressed independently, without loss of optimality. While this separation principle no longer holds in the noisy observation setting, we show that linear Gaussian input policies still decouple the channel coding problem from control, and can thus greatly simplify the practical implementation of implicit communication.</description>
      <guid isPermaLink="false">oai:arXiv.org:2509.16146v2</guid>
      <category>cs.IT</category>
      <category>math.IT</category>
      <pubDate>Wed, 19 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Gongpu Chen, Deniz Gunduz</dc:creator>
    </item>
    <item>
      <title>Improved Sample Complexity Bounds for Diffusion Model Training</title>
      <link>https://arxiv.org/abs/2311.13745</link>
      <description>arXiv:2311.13745v4 Announce Type: replace-cross 
Abstract: Diffusion models have become the most popular approach to deep generative modeling of images, largely due to their empirical performance and reliability. From a theoretical standpoint, a number of recent works have studied the iteration complexity of sampling, assuming access to an accurate diffusion model. In this work, we focus on understanding the sample complexity of training such a model; how many samples are needed to learn an accurate diffusion model using a sufficiently expressive neural network? Prior work showed bounds polynomial in the dimension, desired Total Variation error, and Wasserstein error. We show an exponential improvement in the dependence on Wasserstein error and depth, along with improved dependencies on other relevant parameters.</description>
      <guid isPermaLink="false">oai:arXiv.org:2311.13745v4</guid>
      <category>cs.LG</category>
      <category>cs.CV</category>
      <category>cs.IT</category>
      <category>math.IT</category>
      <category>math.ST</category>
      <category>stat.ML</category>
      <category>stat.TH</category>
      <pubDate>Wed, 19 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Shivam Gupta, Aditya Parulekar, Eric Price, Zhiyang Xun</dc:creator>
    </item>
    <item>
      <title>Linguistic Structure from a Bottleneck on Sequential Information Processing</title>
      <link>https://arxiv.org/abs/2405.12109</link>
      <description>arXiv:2405.12109v3 Announce Type: replace-cross 
Abstract: Human language has a distinct systematic structure, where utterances break into individually meaningful words which are combined to form phrases. We show that natural-language-like systematicity arises in codes that are constrained by a statistical measure of complexity called predictive information, also known as excess entropy. Predictive information is the mutual information between the past and future of a stochastic process. In simulations, we find that such codes break messages into groups of approximately independent features which are expressed systematically and locally, corresponding to words and phrases. Next, drawing on crosslinguistic text corpora, we find that actual human languages are structured in a way that reduces predictive information compared to baselines at the levels of phonology, morphology, syntax, and lexical semantics. Our results establish a link between the statistical and algebraic structure of language and reinforce the idea that these structures are shaped by communication under general cognitive constraints.</description>
      <guid isPermaLink="false">oai:arXiv.org:2405.12109v3</guid>
      <category>cs.CL</category>
      <category>cs.IT</category>
      <category>math.IT</category>
      <pubDate>Wed, 19 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Richard Futrell, Michael Hahn</dc:creator>
    </item>
    <item>
      <title>Sample-Efficient Quantum State Tomography for Structured Quantum States in One Dimension</title>
      <link>https://arxiv.org/abs/2410.02583</link>
      <description>arXiv:2410.02583v4 Announce Type: replace-cross 
Abstract: While quantum state tomography (QST) remains the gold standard for benchmarking and verifying quantum devices, it requires an exponentially large number of measurements and classical computational resources for generic quantum many-body systems, making it impractical even for intermediate-size quantum devices. Fortunately, many physical quantum states often exhibit certain low-dimensional structures that enable the development of efficient QST. A notable example is the class of states represented by matrix product operators (MPOs) with a finite matrix/bond dimension, which include most physical states in one dimension and where the number of independent parameters describing the states only grows linearly with the number of qubits. Whether a sample efficient quantum state tomography protocol, where the number of required state copies scales only linearly as the number of parameters describing the state, exists for a generic MPO state still remains an important open question.
  In this paper, we answer this fundamental question affirmatively by using a class of informationally complete positive operator-valued measures (IC-POVMs) -- including symmetric IC-POVMs (SIC-POVMs) and spherical $t$-designs -- focusing on sample complexity while not accounting for the implementation complexity of the measurement settings. For SIC-POVMs and (approximate) spherical 2-designs, we show that the number of state copies to guarantee bounded recovery error of an MPO state with a constrained least-squares estimator depends on the probability distribution of the MPO under the POVM but scales only linearly with $n$ when the distribution is approximately uniform. For spherical $t$-designs with $t\geq 3$, we prove that only a number of state copies proportional to the number of independent parameters in the MPO is sufficient for a guaranteed recovery of any state represented by an MPO.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.02583v4</guid>
      <category>quant-ph</category>
      <category>cs.IT</category>
      <category>eess.SP</category>
      <category>math.IT</category>
      <category>math.OC</category>
      <pubDate>Wed, 19 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Zhen Qin, Casey Jameson, Alireza Goldar, Michael B. Wakin, Zhexuan Gong, Zhihui Zhu</dc:creator>
    </item>
    <item>
      <title>Gradient descent inference in empirical risk minimization</title>
      <link>https://arxiv.org/abs/2412.09498</link>
      <description>arXiv:2412.09498v3 Announce Type: replace-cross 
Abstract: Gradient descent is one of the most widely used iterative algorithms in modern statistical learning. However, its precise algorithmic dynamics in high-dimensional settings remain only partially understood, which has limited its broader potential for statistical inference applications.
  This paper provides a precise, non-asymptotic joint distributional characterization of gradient descent iterates and their debiased statistics in a broad class of empirical risk minimization problems, in the so-called mean-field regime where the sample size is proportional to the signal dimension. Our non-asymptotic state evolution theory holds for both general non-convex loss functions and non-Gaussian data, and reveals the central role of two Onsager correction matrices that precisely characterize the non-trivial dependence among all gradient descent iterates in the mean-field regime.
  Leveraging the joint state evolution characterization, we show that the gradient descent iterate retrieves approximate normality after a debiasing correction via a linear combination of all past iterates, where the debiasing coefficients can be estimated by the proposed gradient descent inference algorithm. This leads to a new algorithmic statistical inference framework based on debiased gradient descent, which (i) applies to a broad class of models with both convex and non-convex losses, (ii) remains valid at each iteration without requiring algorithmic convergence, and (iii) exhibits a certain robustness to possible model misspecification. As a by-product, our framework also provides algorithmic estimates of the generalization error at each iteration. As canonical examples, we demonstrate our theory and inference methods in the single-index regression model and a generalized logistic regression model, where the natural loss functions may exhibit arbitrarily non-convex landscapes.</description>
      <guid isPermaLink="false">oai:arXiv.org:2412.09498v3</guid>
      <category>math.ST</category>
      <category>cs.IT</category>
      <category>math.IT</category>
      <category>math.OC</category>
      <category>stat.ME</category>
      <category>stat.ML</category>
      <category>stat.TH</category>
      <pubDate>Wed, 19 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Qiyang Han, Xiaocong Xu</dc:creator>
    </item>
    <item>
      <title>Bayesian information theoretic model-averaging stochastic item selection for computer adaptive testing</title>
      <link>https://arxiv.org/abs/2504.15543</link>
      <description>arXiv:2504.15543v2 Announce Type: replace-cross 
Abstract: Computer Adaptive Testing (CAT) aims to accurately estimate an individual's ability using only a subset of an Item Response Theory (IRT) instrument. For many applications of CAT, one also needs to ensure diverse item exposure across different testing sessions, preventing any single item from being over or underutilized. In CAT, items are selected sequentially based on a running estimate of a respondent's ability. Prior methods almost universally see item selection through an optimization lens, motivating greedy item selection procedures. While efficient, these deterministic methods tend to have poor item exposure. Existing stochastic methods for item selection are ad-hoc, where item sampling weights lack theoretical justification. In this manuscript, we formulate stochastic CAT as a Bayesian model averaging problem. We seek item sampling probabilities, treated in the long run frequentist sense, that perform optimal model averaging for the ability estimate in a Bayesian sense. In doing so we derive a cross-entropy information criterion that yields optimal stochastic mixing. We tested our new method on the eight independent IRT models that comprise the Work Disability Functional Assessment Battery, comparing it to prior art. We found that our stochastic methodology had superior item exposure while not compromising in terms of test accuracy and efficiency.</description>
      <guid isPermaLink="false">oai:arXiv.org:2504.15543v2</guid>
      <category>stat.ME</category>
      <category>cs.IT</category>
      <category>math.IT</category>
      <category>stat.ML</category>
      <pubDate>Wed, 19 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Tina Su, Edison Choe, Joshua C. Chang</dc:creator>
    </item>
    <item>
      <title>Bayes optimal learning of attention-indexed models</title>
      <link>https://arxiv.org/abs/2506.01582</link>
      <description>arXiv:2506.01582v2 Announce Type: replace-cross 
Abstract: We introduce the attention-indexed model (AIM), a theoretical framework for analyzing learning in deep attention layers. Inspired by multi-index models, AIM captures how token-level outputs emerge from layered bilinear interactions over high-dimensional embeddings. Unlike prior tractable attention models, AIM allows full-width key and query matrices, aligning more closely with practical transformers. Using tools from statistical mechanics and random matrix theory, we derive closed-form predictions for Bayes-optimal generalization error and identify sharp phase transitions as a function of sample complexity, model width, and sequence length. We propose a matching approximate message passing algorithm and show that gradient descent can reach optimal performance. AIM offers a solvable playground for understanding learning in self-attention layers, that are key components of modern architectures.</description>
      <guid isPermaLink="false">oai:arXiv.org:2506.01582v2</guid>
      <category>cs.LG</category>
      <category>cond-mat.dis-nn</category>
      <category>cs.IT</category>
      <category>math.IT</category>
      <category>stat.ML</category>
      <pubDate>Wed, 19 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <arxiv:journal_reference>NeurIPS 2025</arxiv:journal_reference>
      <dc:creator>Fabrizio Boncoraglio, Emanuele Troiani, Vittorio Erba, Lenka Zdeborov\'a</dc:creator>
    </item>
    <item>
      <title>Cooperative Bistatic ISAC Systems for Low-Altitude Economy</title>
      <link>https://arxiv.org/abs/2506.18067</link>
      <description>arXiv:2506.18067v2 Announce Type: replace-cross 
Abstract: The burgeoning low-altitude economy (LAE) necessitates integrated sensing and communication (ISAC) systems capable of high-accuracy multi-target localization and velocity estimation under hardware and coverage constraints inherent in conventional ISAC architectures. This paper addresses these challenges by proposing a cooperative bistatic ISAC framework within MIMO-OFDM cellular networks, enabling robust sensing services for LAE applications through standardized 5G New Radio (NR) infrastructure. We first develop a low-complexity parameter extraction algorithm employing CANDECOMP/PARAFAC (CP) tensor decomposition, which exploits the inherent Vandermonde structure in delay-related factor matrices to efficiently recover bistatic ranges, Doppler velocities, and angles-of-arrival (AoA) from multi-dimensional received signal tensors. To resolve data association ambiguity across distributed transmitter-receiver pairs and mitigate erroneous estimates, we further design a robust fusion scheme based on the minimum spanning tree (MST) method, enabling joint 3D position and velocity reconstruction. Comprehensive simulation results validate the framework's superiority in computational efficiency and sensing performance for low-altitude scenarios.</description>
      <guid isPermaLink="false">oai:arXiv.org:2506.18067v2</guid>
      <category>eess.SP</category>
      <category>cs.IT</category>
      <category>math.IT</category>
      <pubDate>Wed, 19 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Zhenkun Zhang, Yining Xu, Cunhua Pan, Hong Ren, Qixuan Zhang, Songtao Gao, Jiangzhou Wang</dc:creator>
    </item>
    <item>
      <title>Optimal Hamiltonian for a quantum state with finite entropy</title>
      <link>https://arxiv.org/abs/2508.16575</link>
      <description>arXiv:2508.16575v2 Announce Type: replace-cross 
Abstract: We consider the following task: how for a given quantum state $\rho$ to find a grounded Hamiltonian $H$ satisfying the condition $\mathrm{Tr} H\rho\leq E_0&lt;+\infty$ in such a way that the von Neumann entropy of the Gibbs state $\gamma_H(E)$ corresponding to a given energy $E&gt;0$ be as small as possible. We show that for any mixed state $\rho$ with finite entropy and any $E&gt;0$ there exists a solution $H(\rho,E_0,E)$ of the above problem (unique in the non-degenerate case) which we call optimal Hamiltonian for the state $\rho$. Explicit expressions for $H(\rho,E_0,E)$, $\gamma_{H(\rho,E_0,E)}(E)$ and $S(\gamma_{H(\rho,E_0,E)}(E))$ are obtained. Analytical properties of the function $E\mapsto S(\gamma_{H(\rho,E_0,E)}(E))$ are explored. Several examples are considered. A basic application of the above task is briefly described (with the intention to give a detailed description in a separate article). As an example, a new semicontinuity bound for the entanglement of formation is obtained.</description>
      <guid isPermaLink="false">oai:arXiv.org:2508.16575v2</guid>
      <category>quant-ph</category>
      <category>cs.IT</category>
      <category>math-ph</category>
      <category>math.IT</category>
      <category>math.MP</category>
      <pubDate>Wed, 19 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>M. E. Shirokov</dc:creator>
    </item>
    <item>
      <title>Minimax Analysis of Estimation Problems in Coherent Imaging</title>
      <link>https://arxiv.org/abs/2508.18503</link>
      <description>arXiv:2508.18503v3 Announce Type: replace-cross 
Abstract: Unlike conventional imaging modalities, such as magnetic resonance imaging, which are often well described by a linear regression framework, coherent imaging systems follow a significantly more complex model. In these systems, the task is to estimate the unknown image ${\boldsymbol x}_o \in \mathbb{R}^n$ from observations ${\boldsymbol y}_1, \ldots, {\boldsymbol y}_L \in \mathbb{R}^m$ of the form \[ {\boldsymbol y}_l = A_l X_o {\boldsymbol w}_l + {\boldsymbol z}_l, \quad l = 1, \ldots, L, \] where $X_o = \mathrm{diag}({\boldsymbol x}_o)$ is an $n \times n$ diagonal matrix, ${\boldsymbol w}_1, \ldots, {\boldsymbol w}_L \stackrel{\text{i.i.d.}}{\sim} \mathcal{N}(0,I_n)$ represent speckle noise, and ${\boldsymbol z}_1, \ldots, {\boldsymbol z}_L \stackrel{\text{i.i.d.}}{\sim} \mathcal{N}(0,\sigma_z^2 I_m)$ denote additive noise. The matrices $A_1, \ldots, A_L$ are known forward operators determined by the imaging system.
  The fundamental limits of conventional imaging systems have been extensively studied through sparse linear regression models. However, the limits of coherent imaging systems remain largely unexplored. Our goal is to close this gap by characterizing the minimax risk of estimating ${\boldsymbol x}_o$ in high-dimensional settings.
  Motivated by insights from sparse regression, we observe that the structure of ${\boldsymbol x}_o$ plays a crucial role in determining the estimation error. In this work, we adopt a general notion of structure based on the covering numbers, which is more appropriate for coherent imaging systems. We show that the minimax mean squared error (MSE) scales as \[ \frac{\max\{\sigma_z^4,\, m^2,\, n^2\}\, k \log n}{m^2 n L}, \] where $k$ is a parameter that quantifies the effective complexity of the class of images.</description>
      <guid isPermaLink="false">oai:arXiv.org:2508.18503v3</guid>
      <category>math.ST</category>
      <category>cs.IT</category>
      <category>math.IT</category>
      <category>stat.TH</category>
      <pubDate>Wed, 19 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Hao Xing, Soham Jana, Arian Maleki</dc:creator>
    </item>
    <item>
      <title>Characterizing Agent-Based Model Dynamics via $\epsilon$-Machines and Kolmogorov-Style Complexity</title>
      <link>https://arxiv.org/abs/2510.12729</link>
      <description>arXiv:2510.12729v2 Announce Type: replace-cross 
Abstract: We propose a two-level information-theoretic framework for characterizing the informational organization of Agent-Based Model (ABM) dynamics within the broader paradigm of Complex Adaptive Systems (CAS). At the macro level, a pooled $\varepsilon$-machine is reconstructed as a reference model summarizing the system-wide informational regime. At the micro level, $\varepsilon$-machines are reconstructed for each caregiver--elder dyad and variable, complemented by algorithm-agnostic Kolmogorov-style measures, including normalized LZ78 complexity and bits per symbol from lossless compression. The resulting feature set, $\{h_{\mu}, C_{\mu}, E, \mathrm{LZ78}, \mathrm{bps}\}$, enables distributional analysis, stratified comparisons, and unsupervised clustering across agents and scenarios. Empirical results show that coupling $\varepsilon$-machines with compression diagnostics yields a coherent picture of where predictive information resides in the caregiving ABM. Global reconstructions provide a memoryless baseline ($L{=}0$ under coarse symbolizations), whereas per-dyad models reveal localized structure, particularly for walkability under ordinal encodings ($m{=}3$). Compression metrics corroborate these patterns: dictionary compressors agree on algorithmic redundancy, while normalized LZ78 captures statistical novelty. Socioeconomic variables display cross-sectional heterogeneity and near-memoryless dynamics, whereas spatial interaction induces bounded temporal memory and recurrent regimes. The framework thus distinguishes semantic organization (predictive causation and memory) from syntactic simplicity (description length) and clarifies how emergence manifests at different system layers. It is demonstrated on a caregiver--elder case study with dyad-level $\varepsilon$-machine reconstructions and compression-based diagnostics.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.12729v2</guid>
      <category>cs.MA</category>
      <category>cs.IT</category>
      <category>math.IT</category>
      <pubDate>Wed, 19 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Roberto Garrone (University of Milano-Bicocca)</dc:creator>
    </item>
    <item>
      <title>Taming Barren Plateaus in Arbitrary Parameterized Quantum Circuits without Sacrificing Expressibility</title>
      <link>https://arxiv.org/abs/2511.13408</link>
      <description>arXiv:2511.13408v2 Announce Type: replace-cross 
Abstract: Quantum algorithms based on parameterized quantum circuits (PQCs) have enabled a wide range of applications on near-term quantum devices. However, existing PQC architectures face several challenges, among which the ``barren plateaus" phenomenon is particularly prominent. In such cases, the loss function concentrates exponentially with increasing system size, thereby hindering effective parameter optimization. To address this challenge, we propose a general and hardware-efficient method for eliminating barren plateaus in an arbitrary PQC. Specifically, our approach achieves this by inserting a layer of easily implementable quantum channels into the original PQC, each channel requiring only one ancilla qubit and four additional gates, yielding a modified PQC (MPQC) that is provably at least as expressive as the original PQC and, under mild assumptions, is guaranteed to be free from barren plateaus. Furthermore, by appropriately adjusting the structure of MPQCs, we rigorously prove that any parameter in the original PQC can be made trainable. Importantly, the absence of barren plateaus in MPQCs is robust against realistic noise, making our approach directly applicable to current noisy intermediate-scale quantum (NISQ) hardware. Numerically, we demonstrate the practicality of our method by modifying a commonly used PQC for thermal-state preparation. The results show that {barren plateaus are effectively eliminated} in this class of circuits with up to 100 qubits and 2400 layers, whereas the original ansatz suffers from severe gradient vanishing.</description>
      <guid isPermaLink="false">oai:arXiv.org:2511.13408v2</guid>
      <category>quant-ph</category>
      <category>cs.CC</category>
      <category>cs.IT</category>
      <category>cs.LG</category>
      <category>math.IT</category>
      <pubDate>Wed, 19 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Zhenyu Chen, Yuguo Shao, Zhengwei Liu, Zhaohui Wei</dc:creator>
    </item>
  </channel>
</rss>
