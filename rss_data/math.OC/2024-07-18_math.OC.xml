<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>math.OC updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/math.OC</link>
    <description>math.OC updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/math.OC" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Fri, 19 Jul 2024 04:00:50 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Fri, 19 Jul 2024 00:00:00 -0400</pubDate>
    <skipDays>
      <day>Sunday</day>
      <day>Saturday</day>
    </skipDays>
    <item>
      <title>Mean Field Control for Diffusion Aggregation system with Coulomb Interaction</title>
      <link>https://arxiv.org/abs/2407.12936</link>
      <description>arXiv:2407.12936v1 Announce Type: new 
Abstract: The mean field control problem for a multi-dimensional diffusion-aggregation system with Coulomb interaction is considered. The existence of optimal control is proved through the Gamma convergence of the control problem of a regularized particle control problem. The optimal control problem on the particle level is studied by using the corresponding Liouville equation. Because of strong aggregation effect, additional difficulties arises from control function in the well-posedness theory, so that the known method for multi-dimensional Keller-Segel equation can not be directly applied. We use a combination of local existence result and boot-strap argument to obtain the global solution with small initial data. Since we obtain a strong propagation of chaos result by combining the convergence in probability and relative entropy method, the compact support requirement for control functions, which has been often used in the literature, is not need.</description>
      <guid isPermaLink="false">oai:arXiv.org:2407.12936v1</guid>
      <category>math.OC</category>
      <category>math.AP</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Li Chen, Yucheng Wang, Zhao Wang</dc:creator>
    </item>
    <item>
      <title>Nonlinear tomographic reconstruction via nonsmooth optimization</title>
      <link>https://arxiv.org/abs/2407.12984</link>
      <description>arXiv:2407.12984v1 Announce Type: new 
Abstract: We study iterative signal reconstruction in computed tomography (CT), wherein measurements are produced by a linear transformation of the unknown signal followed by an exponential nonlinear map. Approaches based on pre-processing the data with a log transform and then solving the resulting linear inverse problem are tempting since they are amenable to convex optimization methods; however, such methods perform poorly when the underlying image has high dynamic range, as in X-ray imaging of tissue with embedded metal. We show that a suitably initialized subgradient method applied to a natural nonsmooth, nonconvex loss function produces iterates that converge to the unknown signal of interest at a geometric rate under the statistical model proposed by Fridovich-Keil et al. (arXiv:2310.03956). Our recovery program enjoys improved conditioning compared to the formulation proposed by the latter work, enabling faster iterative reconstruction from substantially fewer samples.</description>
      <guid isPermaLink="false">oai:arXiv.org:2407.12984v1</guid>
      <category>math.OC</category>
      <category>cs.NA</category>
      <category>math.NA</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Vasileios Charisopoulos, Rebecca Willett</dc:creator>
    </item>
    <item>
      <title>Dynamic Programming Principle and Hamilton-Jacobi-Bellman Equation for Optimal Control Problems with Uncertainty</title>
      <link>https://arxiv.org/abs/2407.13045</link>
      <description>arXiv:2407.13045v1 Announce Type: new 
Abstract: We study the properties of the value function associated with an optimal control problem with uncertainties, known as average or Riemann-Stieltjes problem. Uncertainties are assumed to belong to a compact metric probability space, and appear in the dynamics, in the terminal cost and in the initial condition, which yield an infinite-dimensional formulation. By stating the problem as an evolution equation in a Hilbert space, we show that the value function is the unique lower semi-continuous proximal solution of the Hamilton-Jacobi-Bellman (HJB) equation. Our approach relies on invariance properties and the dynamic programming principle.</description>
      <guid isPermaLink="false">oai:arXiv.org:2407.13045v1</guid>
      <category>math.OC</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>M. Soledad Aronna, Michele Palladino, Oscar Sierra</dc:creator>
    </item>
    <item>
      <title>On Finding the Closest Zonotope to a Polytope in Hausdorff Distance</title>
      <link>https://arxiv.org/abs/2407.13125</link>
      <description>arXiv:2407.13125v1 Announce Type: new 
Abstract: We provide a local theory for the optimization of the Hausdorff distance between a polytope and a zonotope. To do this, we compute explicit local formulae for the Hausdorff function $d(P, -) : Z_n \to \mathbb{R}$, where $P$ is a fixed polytope and $Z_n$ is the space of rank $n$ zonotopes. This local theory is then used to provide an optimization algorithm based on subgradient descent that converges to critical points of $d(P, -)$. We also express the condition of being at a local minimum as a polyhedral feasibility condition.</description>
      <guid isPermaLink="false">oai:arXiv.org:2407.13125v1</guid>
      <category>math.OC</category>
      <category>cs.CG</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>George D. Torres</dc:creator>
    </item>
    <item>
      <title>Concrete convergence rates for common fixed point problems under Karamata regularity</title>
      <link>https://arxiv.org/abs/2407.13234</link>
      <description>arXiv:2407.13234v1 Announce Type: new 
Abstract: We introduce the notion of Karamata regular operators, which is a notion of regularity that is suitable for obtaining concrete convergence rates for common fixed point problems. This provides a broad framework that includes, but goes beyond, H\"olderian error bounds and H\"older regular operators. By concrete, we mean that the rates we obtain are explicitly expressed in terms of a function of the iteration number $k$ instead, of say, a function of the iterate $x^k$. While it is well-known that under H\"olderian-like assumptions many algorithms converge linearly/sublinearly (depending on the exponent), little it is known when the underlying problem data does not satisfy H\"olderian assumptions, which may happen if a problem involves exponentials and logarithms. Our main innovation is the usage of the theory of regularly varying functions which we showcase by obtaining concrete convergence rates for quasi-cylic algorithms in non-H\"olderian settings. This includes certain rates that are neither sublinear nor linear but sit somewhere in-between, including a case where the rate is expressed via the Lambert W function. Finally, we connect our discussion to o-minimal geometry and show that definable operators in any o-minimal structure are always Karamata regular.</description>
      <guid isPermaLink="false">oai:arXiv.org:2407.13234v1</guid>
      <category>math.OC</category>
      <category>cs.NA</category>
      <category>math.FA</category>
      <category>math.MG</category>
      <category>math.NA</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Tianxiang Liu, Bruno F. Louren\c{c}o</dc:creator>
    </item>
    <item>
      <title>Descent Methods for Vector Optimization Problems: A Majorization-Minimization Perspective</title>
      <link>https://arxiv.org/abs/2407.13245</link>
      <description>arXiv:2407.13245v1 Announce Type: new 
Abstract: In this paper, we develop a unified framework and convergence analysis of descent methods for vector optimization problems (VOPs) from a majorization-minimization perspective. By choosing different surrogate functions, the generic method reduces to some existing descent methods with and without line search, respectively. The unified convergence analysis shows that the slow convergence of the steepest descent method is mainly due to the large gap between surrogate and objective functions. As a result, the performance of descent methods can be improved by narrowing the surrogate gap. Interestingly, we observe that selecting a tighter surrogate function is equivalent to using an appropriate base of the dual cone in the direction-finding subproblem. Furthermore, we use Barzilai-Borwein method to narrow the surrogate gap and devise a Barzilai-Borwein descent method for VOPs with polyhedral cone. By reformulating the subproblem, we provide a new insight into the Barzilai-Borwein descent method and bridge it to the steepest descent method. Finally, several numerical experiments confirm the efficiency of the proposed method.</description>
      <guid isPermaLink="false">oai:arXiv.org:2407.13245v1</guid>
      <category>math.OC</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Jian Chen, Liping Tang, Xinmin Yang</dc:creator>
    </item>
    <item>
      <title>Deterministic Trajectory Optimization through Probabilistic Optimal Control</title>
      <link>https://arxiv.org/abs/2407.13316</link>
      <description>arXiv:2407.13316v1 Announce Type: new 
Abstract: This article proposes two new algorithms tailored to discrete-time deterministic finite-horizon nonlinear optimal control problems or so-called trajectory optimization problems. Both algorithms are inspired by a novel theoretical paradigm known as probabilistic optimal control, that reformulates optimal control as an equivalent probabilistic inference problem. This perspective allows to address the problem using the Expectation-Maximization algorithm. We show that the application of this algorithm results in a fixed point iteration of probabilistic policies that converge to the deterministic optimal policy. Two strategies for policy evaluation are discussed, using state-of-the-art uncertainty quantification methods resulting into two distinct algorithms. The algorithms are structurally closest related to the differential dynamic programming algorithm and related methods that use sigma-point methods to avoid direct gradient evaluations. The main advantage of our work is an improved balance between exploration and exploitation over the iterations, leading to improved numerical stability and accelerated convergence. These properties are demonstrated on different nonlinear systems.</description>
      <guid isPermaLink="false">oai:arXiv.org:2407.13316v1</guid>
      <category>math.OC</category>
      <category>cs.LG</category>
      <category>cs.SY</category>
      <category>eess.SY</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Mohammad Mahmoudi Filabadi, Tom Lefebvre, Guillaume Crevecoeur</dc:creator>
    </item>
    <item>
      <title>Douglas-Rachford splitting algorithm for projected solution of quasi variational inequality with non-self constraint map</title>
      <link>https://arxiv.org/abs/2407.13367</link>
      <description>arXiv:2407.13367v1 Announce Type: new 
Abstract: In this paper, we present a Douglas-Rachford splitting algorithm within a Hilbert space framework that yields a projected solution for a quasi-variational inequality. This is achieved under the conditions that the operator associated with the problem is Lipschitz continuous and strongly monotone. The proposed algorithm is based on the interaction between the resolvent operator and the reflected resolvent operator.</description>
      <guid isPermaLink="false">oai:arXiv.org:2407.13367v1</guid>
      <category>math.OC</category>
      <category>math.FA</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Maede Ramazannejad</dc:creator>
    </item>
    <item>
      <title>Double interdiction problem on trees on the sum of root-leaf distances by upgrading edges</title>
      <link>https://arxiv.org/abs/2407.13391</link>
      <description>arXiv:2407.13391v1 Announce Type: new 
Abstract: The double interdiction problem on trees (DIT) for the sum of root-leaf distances (SRD) has significant implications in diverse areas such as transportation networks, military strategies, and counter-terrorism efforts. It aims to maximize the SRD by upgrading edge weights subject to two constraints. One gives an upper bound for the cost of upgrades under certain norm and the other specifies a lower bound for the shortest root-leaf distance (StRD). We utilize both weighted $l_\infty$ norm and Hamming distance to measure the upgrade cost and denote the corresponding (DIT) problem by (DIT$_{H\infty}$) and its minimum cost problem by (MCDIT$_{H\infty}$). We establish the $\mathcal{NP}$-hardness of problem (DIT$_{H\infty}$) by building a reduction from the 0-1 knapsack problem. We solve the problem (DIT$_{H\infty}$) by two scenarios based on the number $N$ of upgrade edges. When $N=1$, a greedy algorithm with $O(n)$ complexity is proposed. For the general case, an exact dynamic programming algorithm within a pseudo-polynomial time is proposed, which is established on a structure of left subtrees by maximizing a convex combination of the StRD and SRD. Furthermore, we confirm the $\mathcal{NP}$-hardness of problem (MCDIT$_{H\infty}$) by reducing from the 0-1 knapsack problem. To tackle problem (MCDIT$_{H\infty}$), a binary search algorithm with pseudo-polynomial time complexity is outlined, which iteratively solves problem (DIT$_{H\infty}$). We culminate our study with numerical experiments, showcasing effectiveness of the algorithm.</description>
      <guid isPermaLink="false">oai:arXiv.org:2407.13391v1</guid>
      <category>math.OC</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Xiao Li, Xiucui Guan, Junhua Jia, Panos M. Pardalos</dc:creator>
    </item>
    <item>
      <title>Nonconvex landscapes for $\mathbf{Z}_2$ synchronization and graph clustering are benign near exact recovery thresholds</title>
      <link>https://arxiv.org/abs/2407.13407</link>
      <description>arXiv:2407.13407v1 Announce Type: new 
Abstract: We study the optimization landscape of a smooth nonconvex program arising from synchronization over the two-element group $\mathbf{Z}_2$, that is, recovering $z_1, \dots, z_n \in \{\pm 1\}$ from (noisy) relative measurements $R_{ij} \approx z_i z_j$. Starting from a max-cut--like combinatorial problem, for integer parameter $r \geq 2$, the nonconvex problem we study can be viewed both as a rank-$r$ Burer--Monteiro factorization of the standard max-cut semidefinite relaxation and as a relaxation of $\{ \pm 1 \}$ to the unit sphere in $\mathbf{R}^r$. First, we present deterministic, non-asymptotic conditions on the measurement graph and noise under which every second-order critical point of the nonconvex problem yields exact recovery of the ground truth. Then, via probabilistic analysis, we obtain asymptotic guarantees for three benchmark problems: (1) synchronization with a complete graph and Gaussian noise, (2) synchronization with an Erd\H{o}s--R\'enyi random graph and Bernoulli noise, and (3) graph clustering under the binary symmetric stochastic block model. In each case, we have, asymptotically as the problem size goes to infinity, a benign nonconvex landscape near a previously-established optimal threshold for exact recovery; we can approach this threshold to arbitrary precision with large enough (but finite) rank parameter $r$. In addition, our results are robust to monotone adversaries.</description>
      <guid isPermaLink="false">oai:arXiv.org:2407.13407v1</guid>
      <category>math.OC</category>
      <category>math.ST</category>
      <category>stat.TH</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Andrew D. McRae, Pedro Abdalla, Afonso S. Bandeira, Nicolas Boumal</dc:creator>
    </item>
    <item>
      <title>Constrained Approximate Optimal Transport Maps</title>
      <link>https://arxiv.org/abs/2407.13445</link>
      <description>arXiv:2407.13445v1 Announce Type: new 
Abstract: We investigate finding a map $g$ within a function class $G$ that minimises an Optimal Transport (OT) cost between a target measure $\nu$ and the image by $g$ of a source measure $\mu$. This is relevant when an OT map from $\mu$ to $\nu$ does not exist or does not satisfy the desired constraints of $G$. We address existence and uniqueness for generic subclasses of $L$-Lipschitz functions, including gradients of (strongly) convex functions and typical Neural Networks. We explore a variant that approaches a transport plan, showing equivalence to a map problem in some cases. For the squared Euclidean cost, we propose alternating minimisation over a transport plan $\pi$ and map $g$, with the optimisation over $g$ being the $L^2$ projection on $G$ of the barycentric mapping $\overline{\pi}$. In dimension one, this global problem equates the $L^2$ projection of $\overline{\pi^*}$ onto $G$ for an OT plan $\pi^*$ between $\mu$ and $\nu$, but this does not extend to higher dimensions. We introduce a simple kernel method to find $g$ within a Reproducing Kernel Hilbert Space in the discrete case. Finally, we present numerical methods for $L$-Lipschitz gradients of $\ell$-strongly convex potentials.</description>
      <guid isPermaLink="false">oai:arXiv.org:2407.13445v1</guid>
      <category>math.OC</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Eloi Tanguy, Agn\`es Desolneux, Julie Delon</dc:creator>
    </item>
    <item>
      <title>Solvability and Optimal Controls of Impulsive Stochastic Evolution Equations in Hilbert Spaces</title>
      <link>https://arxiv.org/abs/2407.13496</link>
      <description>arXiv:2407.13496v1 Announce Type: new 
Abstract: This paper examines the solvability and optimal control of a class of impulsive stochastic evolution equations in a Hilbert space. First, we investigate the existence and uniqueness of mild solutions for the considered system. Next, we determine the conditions necessary for the existence of optimal control pairs. Finally, we present an example to illustrate the effectiveness of our theoretical results.</description>
      <guid isPermaLink="false">oai:arXiv.org:2407.13496v1</guid>
      <category>math.OC</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Javad A. Asadzade, Nazim I. Mahmudov</dc:creator>
    </item>
    <item>
      <title>Convergence result for the gradient-push algorithm and its application to boost up the Push-DIging algorithm</title>
      <link>https://arxiv.org/abs/2407.13564</link>
      <description>arXiv:2407.13564v1 Announce Type: new 
Abstract: The gradient-push algorithm is a fundamental algorithm for the distributed optimization problem \begin{equation} \min_{x \in \mathbb{R}^d} f(x) = \sum_{j=1}^n f_j (x), \end{equation} where each local cost $f_j$ is only known to agent $a_i$ for $1 \leq i \leq n$ and the agents are connected by a directed graph. In this paper, we obtain convergence results for the gradient-push algorithm with constant stepsize whose range is sharp in terms the order of the smoothness constant $L&gt;0$. Precisely, under the two settings: 1) Each local cost $f_i$ is strongly convex and $L$-smooth, 2) Each local cost $f_i$ is convex quadratic and $L$-smooth while the aggregate cost $f$ is strongly convex, we show that the gradient-push algorithm with stepsize $\alpha&gt;0$ converges to an $O(\alpha)$-neighborhood of the minimizer of $f$ for a range $\alpha \in (0, c/L]$ with a value $c&gt;0$ independent of $L&gt;0$. As a benefit of the result, we suggest a hybrid algorithm that performs the gradient-push algorithm with a relatively large stepsize $\alpha&gt;0$ for a number of iterations and then go over to perform the Push-DIGing algorithm. It is verified by a numerical test that the hybrid algorithm enhances the performance of the Push-DIGing algorithm significantly. The convergence results of the gradient-push algorithm are also supported by numerical tests.</description>
      <guid isPermaLink="false">oai:arXiv.org:2407.13564v1</guid>
      <category>math.OC</category>
      <category>cs.SY</category>
      <category>eess.SY</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Hyogi Choi, Woocheol Choi, Gwangil Kim</dc:creator>
    </item>
    <item>
      <title>A Stochastic Record-Value Approach to Global Simulation Optimization</title>
      <link>https://arxiv.org/abs/2407.13576</link>
      <description>arXiv:2407.13576v1 Announce Type: new 
Abstract: Black-box optimization is ubiquitous in machine learning, operations research and engineering simulation. Black-box optimization algorithms typically do not assume structural information about the objective function and thus must make use of stochastic information to achieve statistical convergence to a globally optimal solution. One such class of methods is multi-start algorithms which use a probabilistic criteria to: determine when to stop a single run of an iterative optimization algorithm, also called an inner search, when to perform a restart, or outer search, and when to terminate the entire algorithm. Zabinsky, Bulger &amp; Khompatraporn introduced a record-value theoretic multi-start framework called Dynamic Multi-start Sequential Search (DMSS). We observe that DMSS performs poorly when the inner search method is a deterministic gradient-based search. In this thesis, we present an algorithmic modification to DMSS and empirically show that the Revised DMSS (RDMSS) algorithm can outperform DMSS in gradient-based settings for a broad class of objective test functions. We give a theoretical analysis of a stochastic process that was constructed specifically as an inner search stopping criteria within RDMSS. We discuss computational considerations of the RDMSS algorithm. Finally, we present numerical results to determine its effectiveness.</description>
      <guid isPermaLink="false">oai:arXiv.org:2407.13576v1</guid>
      <category>math.OC</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Rohan Rele, Zelda Zabinsky, Giulia Pedrielli, Aleksandr Aravkin</dc:creator>
    </item>
    <item>
      <title>Wasserstein Distributionally Robust Optimization with Heterogeneous Data Sources</title>
      <link>https://arxiv.org/abs/2407.13582</link>
      <description>arXiv:2407.13582v1 Announce Type: new 
Abstract: We study decision problems under uncertainty, where the decision-maker has access to $K$ data sources that carry {\em biased} information about the underlying risk factors. The biases are measured by the mismatch between the risk factor distribution and the $K$ data-generating distributions with respect to an optimal transport (OT) distance. In this situation the decision-maker can exploit the information contained in the biased samples by solving a distributionally robust optimization (DRO) problem, where the ambiguity set is defined as the intersection of $K$ OT neighborhoods, each of which is centered at the empirical distribution on the samples generated by a biased data source. We show that if the decision-maker has a prior belief about the biases, then the out-of-sample performance of the DRO solution can improve with $K$ -- irrespective of the magnitude of the biases. We also show that, under standard convexity assumptions, the proposed DRO problem is computationally tractable if either $K$ or the dimension of the risk factors is kept constant.</description>
      <guid isPermaLink="false">oai:arXiv.org:2407.13582v1</guid>
      <category>math.OC</category>
      <category>math.PR</category>
      <category>math.ST</category>
      <category>stat.TH</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Yves Rychener, Adrian Esteban-Perez, Juan M. Morales, Daniel Kuhn</dc:creator>
    </item>
    <item>
      <title>Distributionally and Adversarially Robust Logistic Regression via Intersecting Wasserstein Balls</title>
      <link>https://arxiv.org/abs/2407.13625</link>
      <description>arXiv:2407.13625v1 Announce Type: new 
Abstract: Empirical risk minimization often fails to provide robustness against adversarial attacks in test data, causing poor out-of-sample performance. Adversarially robust optimization (ARO) has thus emerged as the de facto standard for obtaining models that hedge against such attacks. However, while these models are robust against adversarial attacks, they tend to suffer severely from overfitting. To address this issue for logistic regression, we study the Wasserstein distributionally robust (DR) counterpart of ARO and show that this problem admits a tractable reformulation. Furthermore, we develop a framework to reduce the conservatism of this problem by utilizing an auxiliary dataset (e.g., synthetic, external, or out-of-domain data), whenever available, with instances independently sampled from a nonidentical but related ground truth. In particular, we intersect the ambiguity set of the DR problem with another Wasserstein ambiguity set that is built using the auxiliary dataset. We analyze the properties of the underlying optimization problem, develop efficient solution algorithms, and demonstrate that the proposed method consistently outperforms benchmark approaches on real-world datasets.</description>
      <guid isPermaLink="false">oai:arXiv.org:2407.13625v1</guid>
      <category>math.OC</category>
      <category>cs.LG</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Aras Selvi, Eleonora Kreacic, Mohsen Ghassemi, Vamsi Potluru, Tucker Balch, Manuela Veloso</dc:creator>
    </item>
    <item>
      <title>A Formal Analysis of Iterated TDD</title>
      <link>https://arxiv.org/abs/2407.12839</link>
      <description>arXiv:2407.12839v1 Announce Type: cross 
Abstract: In this paper we formally analyze the software methodology called (iterated) Test Driven Development (TDD). We formally define Specification, Software, Testing, Equivalence Partitions, Coupling, to argue about the nature of the software development in terms of TDD. We formalize Iterative TDD and find a context in which iterated TDD ``provably produce'' ``provably correct code'' from ``specifications'' while being stable in terms of iterated code churns. We demonstrate that outside this context iterated TDD will exhibit chaotic behavior, implying unpredictable messy amount of code churn. We argue that the research finding of ``ineffective'' iterated TDD found by earlier researches are due to missing this context, while the findings of ``effective'' iterated TDD is due to accidentally falling into the context or simply placebo.</description>
      <guid isPermaLink="false">oai:arXiv.org:2407.12839v1</guid>
      <category>cs.SE</category>
      <category>cs.SY</category>
      <category>eess.SY</category>
      <category>math.DS</category>
      <category>math.OC</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Hemil Ruparel, Nabarun Mondal</dc:creator>
    </item>
    <item>
      <title>HPPP: Halpern-type Preconditioned Proximal Point Algorithms and Applications to Image Restoration</title>
      <link>https://arxiv.org/abs/2407.13120</link>
      <description>arXiv:2407.13120v1 Announce Type: cross 
Abstract: Preconditioned Proximal Point (PPP) algorithms provide a unified framework for splitting methods in image restoration. Recent advancements with RED (Regularization by Denoising) and PnP (Plug-and-Play) priors have achieved state-of-the-art performance in this domain, emphasizing the need for a meaningful particular solution. However, degenerate PPP algorithms typically exhibit weak convergence in infinite-dimensional Hilbert space, leading to uncertain solutions. To address this issue, we propose the Halpern-type Preconditioned Proximal Point (HPPP) algorithm, which leverages the strong convergence properties of Halpern iteration to achieve a particular solution. Based on the implicit regularization defined by gradient RED, we further introduce the Gradient REgularization by Denoising via HPPP called GraRED-HP3 algorithm. The HPPP algorithm is shown to have the regularity converging to a particular solution by a toy example. Additionally, experiments in image deblurring and inpainting validate the effectiveness of GraRED-HP3, showing it surpasses classical methods such as Chambolle-Pock (CP), PPP, RED, and RED-PRO.</description>
      <guid isPermaLink="false">oai:arXiv.org:2407.13120v1</guid>
      <category>cs.CV</category>
      <category>math.OC</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Shuchang Zhang, Hui Zhang, Hongxia Wang</dc:creator>
    </item>
    <item>
      <title>Predictive control for nonlinear stochastic systems: Closed-loop guarantees with unbounded noise</title>
      <link>https://arxiv.org/abs/2407.13257</link>
      <description>arXiv:2407.13257v1 Announce Type: cross 
Abstract: We present a stochastic predictive control framework for nonlinear systems subject to unbounded process noise with closed-loop guarantees. First, we first provide a conceptual shrinking-horizon framework that utilizes general probabilistic reachable sets and minimizes the expected cost. Then, we provide a tractable receding-horizon formulation that uses a nominal state and a simple constraint tightening. Both formulations ensure recursive feasibility, satisfaction of chance constraints, and bounds on the expected cost for the resulting closed-loop system. We provide a constructive design for probabilistic reachable sets of nonlinear systems using stochastic contraction metrics. We demonstrate the practicality of the proposed method through a simulation of a chain of mass-spring-dampers with nonlinear Coulomb friction. Overall, this paper provides a framework for computationally tractable stochastic predictive control approaches with closed-loop guaranteed for nonlinear systems with unbounded noise.</description>
      <guid isPermaLink="false">oai:arXiv.org:2407.13257v1</guid>
      <category>eess.SY</category>
      <category>cs.SY</category>
      <category>math.OC</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Johannes K\"ohler, Melanie N. Zeilinger</dc:creator>
    </item>
    <item>
      <title>Deep Reinforcement Learning for Multi-Objective Optimization: Enhancing Wind Turbine Energy Generation while Mitigating Noise Emissions</title>
      <link>https://arxiv.org/abs/2407.13320</link>
      <description>arXiv:2407.13320v1 Announce Type: cross 
Abstract: We develop a torque-pitch control framework using deep reinforcement learning for wind turbines to optimize the generation of wind turbine energy while minimizing operational noise. We employ a double deep Q-learning, coupled to a blade element momentum solver, to enable precise control over wind turbine parameters. In addition to the blade element momentum, we use the wind turbine acoustic model of Brooks Pope and Marcolini. Through training with simple winds, the agent learns optimal control policies that allow efficient control for complex turbulent winds. Our experiments demonstrate that the reinforcement learning is able to find optima at the Pareto front, when maximizing energy while minimizing noise. In addition, the adaptability of the reinforcement learning agent to changing turbulent wind conditions, underscores its efficacy for real-world applications. We validate the methodology using a SWT2.3-93 wind turbine with a rated power of 2.3 MW. We compare the reinforcement learning control to classic controls to show that they are comparable when not taking into account noise emissions. When including a maximum limit of 45 dB to the noise produced (100 meters downwind of the turbine), the extracted yearly energy decreases by 22%. The methodology is flexible and allows for easy tuning of the objectives and constraints through the reward definitions, resulting in a flexible multi-objective optimization framework for wind turbine control. Overall, our findings highlight the potential of RL-based control strategies to improve wind turbine efficiency while mitigating noise pollution, thus advancing sustainable energy generation technologies</description>
      <guid isPermaLink="false">oai:arXiv.org:2407.13320v1</guid>
      <category>eess.SY</category>
      <category>cs.AI</category>
      <category>cs.SY</category>
      <category>math.OC</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Mart\'in de Frutos (ETSIAE-UPM-School of Aeronautics), Oscar A. Marino (ETSIAE-UPM-School of Aeronautics), David Huergo (ETSIAE-UPM-School of Aeronautics), Esteban Ferrer (ETSIAE-UPM-School of Aeronautics, Center for Computational Simulation, Universidad Polit\'ecnica de Madrid)</dc:creator>
    </item>
    <item>
      <title>Understanding Christensen-Sinclair factorization via semidefinite programming</title>
      <link>https://arxiv.org/abs/2407.13716</link>
      <description>arXiv:2407.13716v1 Announce Type: cross 
Abstract: We show that the Christensen-Sinclair factorization theorem, when the underlying Hilbert spaces are finite dimensional, is an instance of strong duality of semidefinite programming. This gives an elementary proof of the result and also provides an efficient algorithm to compute the Christensen-Sinclair factorization.</description>
      <guid isPermaLink="false">oai:arXiv.org:2407.13716v1</guid>
      <category>math.OA</category>
      <category>math.FA</category>
      <category>math.OC</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Francisco Escudero-Guti\'errez</dc:creator>
    </item>
    <item>
      <title>New notions of simultaneous diagonalizability of quadratic forms with applications to QCQPs</title>
      <link>https://arxiv.org/abs/2101.12141</link>
      <description>arXiv:2101.12141v2 Announce Type: replace 
Abstract: A set of quadratic forms is simultaneously diagonalizable via congruence (SDC) if there exists a basis under which each of the quadratic forms is diagonal. This property appears naturally when analyzing quadratically constrained quadratic programs (QCQPs) and has important implications in this context. This paper extends the reach of the SDC property by studying two new related but weaker notions of simultaneous diagonalizability. Specifically, we say that a set of quadratic forms is almost SDC (ASDC) if it is the limit of SDC sets and d-restricted SDC (d-RSDC) if it is the restriction of an SDC set in up to d-many additional dimensions. Our main contributions are a complete characterization of the ASDC pairs and the nonsingular ASDC triples, as well as a sufficient condition for the 1-RSDC property for pairs of quadratic forms. Surprisingly, we show that every singular pair is ASDC and that almost every pair is 1-RSDC.
  We accompany our theoretical results with preliminary numerical experiments applying the RSDC property to QCQPs with a single quadratic constraint.</description>
      <guid isPermaLink="false">oai:arXiv.org:2101.12141v2</guid>
      <category>math.OC</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Alex L. Wang, Rujun Jiang</dc:creator>
    </item>
    <item>
      <title>Hypodifferentials of nonsmooth convex functions and their applications to nonsmooth convex optimization</title>
      <link>https://arxiv.org/abs/2303.13464</link>
      <description>arXiv:2303.13464v2 Announce Type: replace 
Abstract: A hypodifferential is a compact family of affine mappings that defines a local max-type approximation of a nonsmooth convex function. We present a general theory of hypodifferentials of nonsmooth convex functions defined on a Banach space. In particular, we provide complete characterizations of hypodifferentiability and hypodifferentials of nonsmooth convex functions, derive calculus rules for hypodifferentials, and study the Lipschitz continuity/Lipschitz approximation property of hypodifferentials that can be viewed as a natural extension of the Lipschitz continuity of the gradient to the general nonsmooth setting. As an application of our theoretical results, we study the rate of convergence of several versions of the method of hypodifferential descent for nonsmooth convex optimization and present an accelerated version of this method having the faster rater of convergence $\mathcal{O}(1/k^2)$.</description>
      <guid isPermaLink="false">oai:arXiv.org:2303.13464v2</guid>
      <category>math.OC</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>M. V. Dolgopolik</dc:creator>
    </item>
    <item>
      <title>Sharpness and well-conditioning of nonsmooth convex formulations in statistical signal recovery</title>
      <link>https://arxiv.org/abs/2307.06873</link>
      <description>arXiv:2307.06873v2 Announce Type: replace 
Abstract: We study a sample complexity vs. conditioning tradeoff in modern signal recovery problems (including sparse recovery, low-rank matrix sensing, covariance estimation, and abstract phase retrieval), where convex optimization problems are built from sampled observations. We begin by introducing a set of condition numbers related to sharpness in $\ell_p$ or Schatten-$p$ norms ($p\in[1,2]$) of a nonsmooth formulation for these problems. Then, we show that these condition numbers become dimension independent constants in each of the example signal recovery problems once the sample size exceeds some constant multiple of the recovery threshold. Structurally, this result ensures that the inaccuracy in the recovered signal due to both observation noise and optimization error is well-controlled. Algorithmically, such a result ensures that a new restarted mirror descent method achieves nearly-dimension-independent linear convergence to the signal. This new first-order method is general and applies to any sharp convex function in an $\ell_p$ or Schatten-$p$ norm ($p\in[1,2]$).</description>
      <guid isPermaLink="false">oai:arXiv.org:2307.06873v2</guid>
      <category>math.OC</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Lijun Ding, Alex L. Wang</dc:creator>
    </item>
    <item>
      <title>A more efficient reformulation of complex SDP as real SDP</title>
      <link>https://arxiv.org/abs/2307.11599</link>
      <description>arXiv:2307.11599v3 Announce Type: replace 
Abstract: This note proposes a new reformulation of complex semidefinite programs (SDPs) as real SDPs. As an application, we present an economical reformulation of complex SDP relaxations of complex polynomial optimization problems as real SDPs and derive some further reductions by exploiting inner structure of the complex SDP relaxations. Various numerical examples demonstrate that our new reformulation runs significantly faster than the usual popular reformulation.</description>
      <guid isPermaLink="false">oai:arXiv.org:2307.11599v3</guid>
      <category>math.OC</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Jie Wang</dc:creator>
    </item>
    <item>
      <title>Carbon-Aware Optimal Power Flow</title>
      <link>https://arxiv.org/abs/2308.03240</link>
      <description>arXiv:2308.03240v2 Announce Type: replace 
Abstract: To facilitate effective decarbonization of the electric power sector, this paper introduces the generic Carbon-aware Optimal Power Flow (C-OPF) method for power system decision-making that considers demand-side carbon accounting and emission management. Built upon the classic optimal power flow (OPF) model, the C-OPF method incorporates carbon emission flow equations and constraints, as well as carbon-related objectives, to jointly optimize power flow and carbon flow. In particular, this paper establishes the feasibility and solution uniqueness of the carbon emission flow equations, and proposes modeling and linearization techniques to address the issues of undetermined power flow directions and bilinear terms in the C-OPF model. Additionally, two novel carbon emission models, together with the carbon accounting schemes, for energy storage systems are developed and integrated into the C-OPF model. Numerical simulations demonstrate the characteristics and effectiveness of the C-OPF method, in comparison with OPF solutions.</description>
      <guid isPermaLink="false">oai:arXiv.org:2308.03240v2</guid>
      <category>math.OC</category>
      <category>cs.SY</category>
      <category>eess.SY</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Xin Chen, Andy Sun, Wenbo Shi, Na Li</dc:creator>
    </item>
    <item>
      <title>Steepest geometric descent for regularized quasiconvex functions</title>
      <link>https://arxiv.org/abs/2310.01364</link>
      <description>arXiv:2310.01364v2 Announce Type: replace 
Abstract: We establish existence of steepest descent curves emanating from almost every point of a regular locally Lipschitz quasiconvex functions, where regularity means that the sweeping process flow induced by the sublevel sets is reversible. We then use max-convolution to regularize general quasiconvex functions and obtain a result of the same nature in a more general setting.</description>
      <guid isPermaLink="false">oai:arXiv.org:2310.01364v2</guid>
      <category>math.OC</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Aris Daniilidis, David Salas</dc:creator>
    </item>
    <item>
      <title>Efficient Branching Rules for Optimizing Range and Order-Based Objective Functions</title>
      <link>https://arxiv.org/abs/2311.03885</link>
      <description>arXiv:2311.03885v2 Announce Type: replace 
Abstract: We consider range minimization problems featuring exponentially many variables, as frequently arising in fairness-oriented or bi-objective optimization. While branch and price is successful at solving cost-oriented problems with many variables, the performance of classical branch-and-price algorithms for range minimization is drastically impaired by weak linear programming relaxations. We propose range branching, a generic branching rule that directly tackles this issue and can be used on top of problem-specific branching schemes. We show several desirable properties of range branching and show its effectiveness on a series of instances of the fair capacitated vehicle routing problem and fair generalized assignment problem. Range branching significantly improves multiple classical branching schemes in terms of computing time, optimality gap, and size of the branch-and-bound tree, allowing us to solve many more large instances than classical methods. Moreover, we show how range branching can be successfully generalized to order-based objective functions, such as the Gini deviation.</description>
      <guid isPermaLink="false">oai:arXiv.org:2311.03885v2</guid>
      <category>math.OC</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Bart van Rossum, Rui Chen, Andrea Lodi</dc:creator>
    </item>
    <item>
      <title>An inexact $q$-order regularized proximal Newton method for nonconvex composite optimization</title>
      <link>https://arxiv.org/abs/2311.06871</link>
      <description>arXiv:2311.06871v3 Announce Type: replace 
Abstract: This paper concerns the composite problem of minimizing the sum of a twice continuously differentiable function $f$ and a nonsmooth convex function. For this class of nonconvex and nonsmooth problems, by leveraging a practical inexactness criterion and a novel selection strategy for iterates, we propose an inexact $q$-order regularized proximal Newton method for $q\in[2,3]$, which becomes an inexact cubic regularization (CR) method for $q=3$. We prove that the whole iterate sequence converges to a stationary point for the KL objective function; and when the objective function has the KL property of exponent $\theta\in(0,\frac{q-1}{q})$, the convergence has a local $Q$-superlinear rate of order $\frac{q-1}{\theta q}$. In particular, under a local H\"{o}lderian error bound of order $\gamma\in(\frac{1}{q-1},1]$ on a second-order stationary point set, we show that the iterate and objective value sequences converge to a second-order stationary point and a second-order stationary value, respectively, with a local $Q$-superlinear rate of order $\gamma(q\!-\!1)$, specified as the $Q$-quadratic rate for $q=3$ and $\gamma=1$. This is the first practical inexact CR method with $Q$-quadratic convergence rate for nonconvex composite optimization. We validate the efficiency of the CR method with ZeroFPR as the inner solver by applying it to composite optimization problems with highly nonlinear $f$.</description>
      <guid isPermaLink="false">oai:arXiv.org:2311.06871v3</guid>
      <category>math.OC</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Ruyu Liu, Shaohua Pan, Yitian Qian</dc:creator>
    </item>
    <item>
      <title>Global Convergence Analysis of the Power Proximal Point and Augmented Lagrangian Method</title>
      <link>https://arxiv.org/abs/2312.12205</link>
      <description>arXiv:2312.12205v2 Announce Type: replace 
Abstract: In this paper we study an unconventional inexact Augmented Lagrangian Method (ALM) for convex optimization problems, as first proposed by Bertsekas, herein the penalty term is a potentially non-Euclidean norm raised to a power between one and two. We analyze the algorithm through the lens of a nonlinear Proximal Point Method (PPM), as originally introduced by Luque, applied to the dual problem. While Luque analyzes the order of local convergence of the scheme with Euclidean norms our focus is on the non-Euclidean case which prevents us from using standard tools for the analysis such as the nonexpansiveness of the proximal mapping. To allow for errors in the primal update, we derive two implementable stopping criteria under which we analyze both the global and the local convergence rates of the algorithm. More specifically, we show that the method enjoys a fast sublinear global rate in general and a local superlinear rate under suitable growth assumptions. We also highlight that the power ALM can be interpreted as classical ALM with an implicitly defined penalty-parameter schedule, reducing its parameter dependence. Our experiments on a number of relevant problems suggest that for certain powers the method performs similarly to a classical ALM with fine-tuned adaptive penalty rule, despite involving fewer parameters.</description>
      <guid isPermaLink="false">oai:arXiv.org:2312.12205v2</guid>
      <category>math.OC</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Konstantinos A. Oikonomidis, Alexander Bodard, Emanuel Laude, Panagiotis Patrinos</dc:creator>
    </item>
    <item>
      <title>Avoiding strict saddle points of nonconvex regularized problems</title>
      <link>https://arxiv.org/abs/2401.09274</link>
      <description>arXiv:2401.09274v3 Announce Type: replace 
Abstract: In this paper, we consider a class of non-convex and non-smooth sparse optimization problems, which encompass most existing nonconvex sparsity-inducing terms. We show the second-order optimality conditions only depend on the nonzeros of the stationary points. We propose two damped iterative reweighted algorithms including the iteratively reweighted $\ell_1$ algorithm (DIRL$_1$) and the iteratively reweighted $\ell_2$ (DIRL$_2$) algorithm, to solve these problems. For DIRL$_1$, we show the reweighted $\ell_1$ subproblem has support identification property so that DIRL$_1$ locally reverts to a gradient descent algorithm around a stationary point. For DIRL$_2$, we show the solution map of the reweighted $\ell_2$ subproblem is differentiable and Lipschitz continuous everywhere. Therefore, the map of DIRL$_1$ and DIRL$_2$ and their inverse are Lipschitz continuous, and the strict saddle points are their unstable fixed points. By applying the stable manifold theorem, these algorithms are shown to converge only to local minimizers with randomly initialization when the strictly saddle point property is assumed.</description>
      <guid isPermaLink="false">oai:arXiv.org:2401.09274v3</guid>
      <category>math.OC</category>
      <category>cs.LG</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Luwei Bai, Yaohua Hu, Hao Wang, Xiaoqi Yang</dc:creator>
    </item>
    <item>
      <title>Solving Two-Stage Stochastic Programs with Endogenous Uncertainty via Random Variable Transformation</title>
      <link>https://arxiv.org/abs/2402.15486</link>
      <description>arXiv:2402.15486v3 Announce Type: replace 
Abstract: Real-world decision-making problems often involve decision-dependent uncertainty, where the probability distribution of the random vector depends on the model decisions. Few studies focus on two-stage stochastic programs with this type of endogenous uncertainty, and those that do lack general methodologies. We propose a general method for solving a class of these programs based on random variable transformation, a technique widely employed in probability and statistics. The random variable transformation converts a stochastic program with endogenous uncertainty (original program) into an equivalent stochastic program with decision-independent uncertainty (transformed program), for which solution procedures are well-studied. Additionally, endogenous uncertainty usually leads to nonlinear nonconvex programs, which are theoretically intractable. Nonetheless, we show that, for some classical endogenous distributions, the proposed method yields mixed-integer linear or convex programs with exogenous uncertainty. We validate this method by applying it to a network design and facility-protection problem, considering distinct decision-dependent distributions for the random variables. While the original formulation of this problem is nonlinear nonconvex for most endogenous distributions, the proposed method transforms it into mixed-integer linear programs with exogenous uncertainty. We solve these transformed programs with the sample average approximation method. We highlight the superior performance of our approach compared to solving the original program in the case a mixed-integer linear formulation of this program exists.</description>
      <guid isPermaLink="false">oai:arXiv.org:2402.15486v3</guid>
      <category>math.OC</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Maria Bazotte, Margarida Carvalho, Thibaut Vidal</dc:creator>
    </item>
    <item>
      <title>An efficient algorithm for solving linear equality-constrained LQR problems</title>
      <link>https://arxiv.org/abs/2407.05433</link>
      <description>arXiv:2407.05433v2 Announce Type: replace 
Abstract: We present a new algorithm for solving linear-quadratic regulator (LQR) problems with linear equality constraints, also known as constrained LQR (CLQR) problems.
  Our method's sequential runtime is linear in the number of stages and constraints, and its parallel runtime is logarithmic in the number of stages.
  The main technical contribution of this paper is the derivation of parallelizable techniques for eliminating the linear equality constraints while preserving the standard positive (semi-)definiteness requirements of LQR problems.</description>
      <guid isPermaLink="false">oai:arXiv.org:2407.05433v2</guid>
      <category>math.OC</category>
      <category>cs.RO</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Jo\~ao Sousa-Pinto, Dominique Orban</dc:creator>
    </item>
    <item>
      <title>Inertial Methods with Viscous and Hessian driven Damping for Non-Convex Optimization</title>
      <link>https://arxiv.org/abs/2407.12518</link>
      <description>arXiv:2407.12518v2 Announce Type: replace 
Abstract: In this paper, we aim to study non-convex minimization problems via second-order (in-time) dynamics, including a non-vanishing viscous damping and a geometric Hessian-driven damping. Second-order systems that only rely on a viscous damping may suffer from oscillation problems towards the minima, while the inclusion of a Hessian-driven damping term is known to reduce this effect without explicit construction of the Hessian in practice. There are essentially two ways to introduce the Hessian-driven damping term: explicitly or implicitly. For each setting, we provide conditions on the damping coefficients to ensure convergence of the gradient towards zero. Moreover, if the objective function is definable, we show global convergence of the trajectory towards a critical point as well as convergence rates. Besides, in the autonomous case, if the objective function is Morse, we conclude that the trajectory converges to a local minimum of the objective for almost all initializations. We also study algorithmic schemes for both dynamics and prove all the previous properties in the discrete setting under proper choice of the step-size.</description>
      <guid isPermaLink="false">oai:arXiv.org:2407.12518v2</guid>
      <category>math.OC</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Rodrigo Maulen-Soto, Jalal Fadili, Peter Ochs</dc:creator>
    </item>
    <item>
      <title>Learning Risk Preferences in Markov Decision Processes: an Application to the Fourth Down Decision in the National Football League</title>
      <link>https://arxiv.org/abs/2309.00756</link>
      <description>arXiv:2309.00756v2 Announce Type: replace-cross 
Abstract: For decades, National Football League (NFL) coaches' observed fourth down decisions have been largely inconsistent with prescriptions based on statistical models. In this paper, we develop a framework to explain this discrepancy using an inverse optimization approach. We model the fourth down decision and the subsequent sequence of plays in a game as a Markov decision process (MDP), the dynamics of which we estimate from NFL play-by-play data from the 2014 through 2022 seasons. We assume that coaches' observed decisions are optimal but that the risk preferences governing their decisions are unknown. This yields an inverse decision problem for which the optimality criterion, or risk measure, of the MDP is the estimand. Using the quantile function to parameterize risk, we estimate which quantile-optimal policy yields the coaches' observed decisions as minimally suboptimal. In general, we find that coaches' fourth-down behavior is consistent with optimizing low quantiles of the next-state value distribution, which corresponds to conservative risk preferences. We also find that coaches exhibit higher risk tolerances when making decisions in the opponent's half of the field as opposed to their own half, and that league average fourth down risk tolerances have increased over time.</description>
      <guid isPermaLink="false">oai:arXiv.org:2309.00756v2</guid>
      <category>stat.AP</category>
      <category>math.OC</category>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Nathan Sandholtz, Lucas Wu, Martin Puterman, Timothy C. Y. Chan</dc:creator>
    </item>
    <item>
      <title>Certifying ground-state properties of quantum many-body systems</title>
      <link>https://arxiv.org/abs/2310.05844</link>
      <description>arXiv:2310.05844v5 Announce Type: replace-cross 
Abstract: A ubiquitous problem in quantum physics is to understand the ground-state properties of many-body systems. Confronted with the fact that exact diagonalisation quickly becomes impossible when increasing the system size, variational approaches are typically employed as a scalable alternative: energy is minimised over a subset of all possible states and then different physical quantities are computed over the solution state. Despite remarkable success, rigorously speaking, all what variational methods offer are upper bounds on the ground-state energy. On the other hand, so-called relaxations of the ground-state problem based on semidefinite programming represent a complementary approach, providing lower bounds to the ground-state energy. However, in their current implementation, neither variational nor relaxation methods offer provable bound on other observables in the ground state beyond the energy. In this work, we show that the combination of the two classes of approaches can be used to derive certifiable bounds on the value of any observable in the ground state, such as correlation functions of arbitrary order, structure factors, or order parameters. We illustrate the power of this approach in paradigmatic examples of 1D and 2D spin-one-half Heisenberg models. To improve the scalability of the method, we exploit the symmetries and sparsity of the considered systems to reach sizes of hundreds of particles at much higher precision than previous works. Our analysis therefore shows how to obtain certifiable bounds on many-body ground-state properties beyond energy in a scalable way.</description>
      <guid isPermaLink="false">oai:arXiv.org:2310.05844v5</guid>
      <category>quant-ph</category>
      <category>math.OC</category>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <arxiv:DOI>10.1103/PhysRevX.14.031006</arxiv:DOI>
      <dc:creator>Jie Wang, Jacopo Surace, Ir\'en\'ee Fr\'erot, Beno\^it Legat, Marc-Olivier Renou, Victor Magron, Antonio Ac\'in</dc:creator>
    </item>
    <item>
      <title>Positive definiteness of fourth order three dimensional symmetric tensors</title>
      <link>https://arxiv.org/abs/2406.04010</link>
      <description>arXiv:2406.04010v4 Announce Type: replace-cross 
Abstract: For a 4th order 3-dimensional symmetric tensor with its entries $1$ or $-1$, we show the analytic sufficient and necessary conditions of its positive definiteness. By applying these conclusions, several strict inequalities is bulit for ternary quartic homogeneous polynomials.</description>
      <guid isPermaLink="false">oai:arXiv.org:2406.04010v4</guid>
      <category>math.CA</category>
      <category>math.OC</category>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Yisheng Song</dc:creator>
    </item>
    <item>
      <title>Private Heterogeneous Federated Learning Without a Trusted Server Revisited: Error-Optimal and Communication-Efficient Algorithms for Convex Losses</title>
      <link>https://arxiv.org/abs/2407.09690</link>
      <description>arXiv:2407.09690v2 Announce Type: replace-cross 
Abstract: We revisit the problem of federated learning (FL) with private data from people who do not trust the server or other silos/clients. In this context, every silo (e.g. hospital) has data from several people (e.g. patients) and needs to protect the privacy of each person's data (e.g. health records), even if the server and/or other silos try to uncover this data. Inter-Silo Record-Level Differential Privacy (ISRL-DP) prevents each silo's data from being leaked, by requiring that silo i's communications satisfy item-level differential privacy. Prior work arXiv:2106.09779 characterized the optimal excess risk bounds for ISRL-DP algorithms with homogeneous (i.i.d.) silo data and convex loss functions. However, two important questions were left open: (1) Can the same excess risk bounds be achieved with heterogeneous (non-i.i.d.) silo data? (2) Can the optimal risk bounds be achieved with fewer communication rounds? In this paper, we give positive answers to both questions. We provide novel ISRL-DP FL algorithms that achieve the optimal excess risk bounds in the presence of heterogeneous silo data. Moreover, our algorithms are more communication-efficient than the prior state-of-the-art. For smooth loss functions, our algorithm achieves the optimal excess risk bound and has communication complexity that matches the non-private lower bound. Additionally, our algorithms are more computationally efficient than the previous state-of-the-art.</description>
      <guid isPermaLink="false">oai:arXiv.org:2407.09690v2</guid>
      <category>cs.LG</category>
      <category>cs.CR</category>
      <category>math.OC</category>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Changyu Gao, Andrew Lowy, Xingyu Zhou, Stephen J. Wright</dc:creator>
    </item>
  </channel>
</rss>
