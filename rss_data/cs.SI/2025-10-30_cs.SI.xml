<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>cs.SI updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/cs.SI</link>
    <description>cs.SI updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/cs.SI" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Fri, 31 Oct 2025 01:38:10 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Thu, 30 Oct 2025 00:00:00 -0400</pubDate>
    <skipDays>
      <day>Saturday</day>
      <day>Sunday</day>
    </skipDays>
    <item>
      <title>Merit Network Telescope: Processing and Initial Insights from Nearly 20 Years of Darknet Traffic for Cybersecurity Research</title>
      <link>https://arxiv.org/abs/2510.25050</link>
      <description>arXiv:2510.25050v1 Announce Type: new 
Abstract: This paper presents an initial longitudinal analysis of unsolicited Internet traffic collected between 2005 and 2025 by one of the largest and most persistent network telescopes in the United States, operated by Merit Network. The dataset provides a unique view into global threat activity as observed through scanning and backscatter traffic, key indicators of large-scale probing behavior, data outages, and ongoing denial-of-service (DoS) campaigns. To process this extensive archive, coarse-to-fine methodology is adopted in which general insights are first extracted through a resource-efficient metadata sub-pipeline, followed by a more detailed packet header sub-pipeline for finer-grained analysis. The methodology establishes two sub-pipelines to enable scalable processing of nearly two decades of telescope data and supports multi-level exploration of traffic dynamics. Initial insights highlight long-term trends and recurring traffic spikes, some attributable to Internet-wide scanning events and others likely linked to DoS activities.We present general observations spanning 2006-2024, with a focused analysis of traffic characteristics during 2024.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.25050v1</guid>
      <category>cs.SI</category>
      <pubDate>Thu, 30 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Shereen Ismail, Eman Hammad, William Hatcher, Salah Dandan, Ammar Alomari, Michael Spratt</dc:creator>
    </item>
    <item>
      <title>MMM-Fact: A Multimodal, Multi-Domain Fact-Checking Dataset with Multi-Level Retrieval Difficulty</title>
      <link>https://arxiv.org/abs/2510.25120</link>
      <description>arXiv:2510.25120v1 Announce Type: new 
Abstract: Misinformation and disinformation demand fact checking that goes beyond simple evidence-based reasoning. Existing benchmarks fall short: they are largely single modality (text-only), span short time horizons, use shallow evidence, cover domains unevenly, and often omit full articles -- obscuring models' real-world capability. We present MMM-Fact, a large-scale benchmark of 125,449 fact-checked statements (1995--2025) across multiple domains, each paired with the full fact-check article and multimodal evidence (text, images, videos, tables) from four fact-checking sites and one news outlet. To reflect verification effort, each statement is tagged with a retrieval-difficulty tier -- Basic (1--5 sources), Intermediate (6--10), and Advanced (&gt;10) -- supporting fairness-aware evaluation for multi-step, cross-modal reasoning. The dataset adopts a three-class veracity scheme (true/false/not enough information) and enables tasks in veracity prediction, explainable fact-checking, complex evidence aggregation, and longitudinal analysis. Baselines with mainstream LLMs show MMM-Fact is markedly harder than prior resources, with performance degrading as evidence complexity rises. MMM-Fact offers a realistic, scalable benchmark for transparent, reliable, multimodal fact-checking.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.25120v1</guid>
      <category>cs.SI</category>
      <pubDate>Thu, 30 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Wenyan Xu, Dawei Xiang, Tianqi Ding, Weihai Lu</dc:creator>
    </item>
    <item>
      <title>Stable Emotional Co-occurrence Patterns Revealed by Network Analysis of Social Media</title>
      <link>https://arxiv.org/abs/2510.25204</link>
      <description>arXiv:2510.25204v1 Announce Type: new 
Abstract: Examining emotion interactions as an emotion network in social media offers key insights into human psychology, yet few studies have explored how fluctuations in such emotion network evolve during crises and normal times. This study proposes a novel computational approach grounded in network theory, leveraging large-scale Japanese social media data spanning varied crisis events (earthquakes and COVID-19 vaccination) and non-crisis periods over the past decade. Our analysis identifies and evaluates links between emotions through the co-occurrence of emotion-related concepts (words), revealing a stable structure of emotion network across situations and over time at the population level. We find that some emotion links (represented as link strength) such as emotion links associated with Tension are significantly strengthened during earthquake and pre-vaccination periods. However, the rank of emotion links remains highly intact. These findings challenge the assumption that emotion co-occurrence is context-based and offer a deeper understanding of emotions' intrinsic structure. Moreover, our network-based framework offers a systematic, scalable method for analyzing emotion co-occurrence dynamics, opening new avenues for psychological research using large-scale textual data.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.25204v1</guid>
      <category>cs.SI</category>
      <category>stat.AP</category>
      <pubDate>Thu, 30 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Qianyun Wu, Orr Levy, Yoed N. Kenett, Yukie Sano, Hideki Takayasu, Shlomo Havlin, Misako Takayasu</dc:creator>
    </item>
    <item>
      <title>Testing Correlation in Graphs by Counting Bounded Degree Motifs</title>
      <link>https://arxiv.org/abs/2510.25289</link>
      <description>arXiv:2510.25289v1 Announce Type: new 
Abstract: Correlation analysis is a fundamental step for extracting meaningful insights from complex datasets. In this paper, we investigate the problem of detecting correlation between two Erd\H{o}s-R\'enyi graphs $G(n,p)$, formulated as a hypothesis testing problem: under the null hypothesis, the two graphs are independent, while under the alternative hypothesis, they are correlated. We develop a polynomial-time test by counting bounded degree motifs and prove its effectiveness for any constant correlation coefficient $\rho$ when the edge connecting probability satisfies $p\ge n^{-2/3}$. Our results overcome the limitation requiring $\rho \ge \sqrt{\alpha}$, where $\alpha\approx 0.338$ is the Otter's constant, extending it to any constant $\rho$. Methodologically, bounded degree motifs -- ubiquitous in real networks -- make the proposed statistic both natural and scalable. We also validate our method on synthetic and real co-citation networks, further confirming that this simple motif family effectively captures correlation signals and exhibits strong empirical performance.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.25289v1</guid>
      <category>cs.SI</category>
      <category>math.ST</category>
      <category>stat.TH</category>
      <pubDate>Thu, 30 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Dong Huang, Pengkun Yang</dc:creator>
    </item>
    <item>
      <title>YTLive: A Dataset of Real-World YouTube Live Streaming Sessions</title>
      <link>https://arxiv.org/abs/2510.24769</link>
      <description>arXiv:2510.24769v1 Announce Type: cross 
Abstract: Live streaming plays a major role in today's digital platforms, supporting entertainment, education, social media, etc. However, research in this field is limited by the lack of large, publicly available datasets that capture real-time viewer behavior at scale. To address this gap, we introduce YTLive, a public dataset focused on YouTube Live. Collected through the YouTube Researcher Program over May and June 2024, YTLive includes more than 507000 records from 12156 live streams, tracking concurrent viewer counts at five-minute intervals along with precise broadcast durations. We describe the dataset design and collection process and present an initial analysis of temporal viewing patterns. Results show that viewer counts are higher and more stable on weekends, especially during afternoon hours. Shorter streams attract larger and more consistent audiences, while longer streams tend to grow slowly and exhibit greater variability. These insights have direct implications for adaptive streaming, resource allocation, and Quality of Experience (QoE) modeling. YTLive offers a timely, open resource to support reproducible research and system-level innovation in live streaming. The dataset is publicly available at github.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.24769v1</guid>
      <category>cs.MM</category>
      <category>cs.SI</category>
      <pubDate>Thu, 30 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Mojtaba Mozhganfar, Pooya Jamshidi, Seyyed Ali Aghamiri, Mohsen Ghasemi, Mahdi Dolati, Farzad Tashtarian, Ahmad Khonsari, Christian Timmerer</dc:creator>
    </item>
    <item>
      <title>Beyond Leakage and Complexity: Towards Realistic and Efficient Information Cascade Prediction</title>
      <link>https://arxiv.org/abs/2510.25348</link>
      <description>arXiv:2510.25348v1 Announce Type: cross 
Abstract: Information cascade popularity prediction is a key problem in analyzing content diffusion in social networks. However, current related works suffer from three critical limitations: (1) temporal leakage in current evaluation--random cascade-based splits allow models to access future information, yielding unrealistic results; (2) feature-poor datasets that lack downstream conversion signals (e.g., likes, comments, or purchases), which limits more practical applications; (3) computational inefficiency of complex graph-based methods that require days of training for marginal gains. We systematically address these challenges from three perspectives: task setup, dataset construction, and model design. First, we propose a time-ordered splitting strategy that chronologically partitions data into consecutive windows, ensuring models are evaluated on genuine forecasting tasks without future information leakage. Second, we introduce Taoke, a large-scale e-commerce cascade dataset featuring rich promoter/product attributes and ground-truth purchase conversions--capturing the complete diffusion lifecycle from promotion to monetization. Third, we develop CasTemp, a lightweight framework that efficiently models cascade dynamics through temporal walks, Jaccard-based neighbor selection for inter-cascade dependencies, and GRU-based encoding with time-aware attention. Under leak-free evaluation, CasTemp achieves state-of-the-art performance across four datasets with orders-of-magnitude speedup. Notably, it excels at predicting second-stage popularity conversions--a practical task critical for real-world applications.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.25348v1</guid>
      <category>cs.LG</category>
      <category>cs.SI</category>
      <pubDate>Thu, 30 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Jie Peng, Rui Wang, Qiang Wang, Zhewei Wei, Bin Tong, Guan Wang</dc:creator>
    </item>
    <item>
      <title>Detecting sub-populations in online health communities: A mixed-methods exploration of breastfeeding messages in BabyCenter Birth Clubs</title>
      <link>https://arxiv.org/abs/2510.23692</link>
      <description>arXiv:2510.23692v2 Announce Type: replace 
Abstract: Parental stress is a nationwide health crisis according to the U.S. Surgeon General's 2024 advisory. To allay stress, expecting parents seek advice and share experiences in a variety of venues, from in-person birth education classes and parenting groups to virtual communities, for example, BabyCenter, a moderated online forum community with over 4 million members in the United States alone. In this study, we aim to understand how parents talk about pregnancy, birth, and parenting by analyzing 5.43M posts and comments from the April 2017--January 2024 cohort of 331,843 BabyCenter "birth club" users (that is, users who participate in due date forums or "birth clubs" based on their babies' due dates). Using BERTopic to locate breastfeeding threads and LDA to summarize themes, we compare documents in breastfeeding threads to all other birth-club content. Analyzing time series of word rank, we find that posts and comments containing anxiety-related terms increased steadily from April 2017 to January 2024. We used an ensemble of topic models to identify dominant breastfeeding topics within birth clubs, and then explored trends among all user content versus those who posted in threads related to breastfeeding topics. We conducted Latent Dirichlet Allocation (LDA) topic modeling to identify the most common topics in the full population, as well as within the subset breastfeeding population. We find that the topic of sleep dominates in content generated by the breastfeeding population, as well anxiety-related and work/daycare topics that are not predominant in the full BabyCenter birth club dataset.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.23692v2</guid>
      <category>cs.SI</category>
      <category>cs.CY</category>
      <pubDate>Thu, 30 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-sa/4.0/</dc:rights>
      <dc:creator>Calla Beauregard, Parisa Suchdev, Ashley M. A. Fehr, Isabelle T. Smith, Tabia Tanzin Prama, Julia Witte Zimmerman, Carter Ward, Juniper Lovato, Christopher M. Danforth, Peter Sheridan Dodds</dc:creator>
    </item>
    <item>
      <title>Hypergraph clustering using Ricci curvature: an edge transport perspective</title>
      <link>https://arxiv.org/abs/2412.15695</link>
      <description>arXiv:2412.15695v2 Announce Type: replace-cross 
Abstract: In this paper, we introduce a novel method for extending Ricci flow to hypergraphs by defining probability measures on the edges and transporting them on the line expansion. This approach yields a new weighting on the edges, which proves particularly effective for community detection. We extensively compare this method with a similar notion of Ricci flow defined on the clique expansion, demonstrating its enhanced sensitivity to the hypergraph structure, especially in the presence of large hyperedges. The two methods are complementary and together form a powerful and highly interpretable framework for community detection in hypergraphs.</description>
      <guid isPermaLink="false">oai:arXiv.org:2412.15695v2</guid>
      <category>cs.LG</category>
      <category>cs.SI</category>
      <category>stat.ML</category>
      <pubDate>Thu, 30 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Olympio Hacquard</dc:creator>
    </item>
    <item>
      <title>GnnXemplar: Exemplars to Explanations -- Natural Language Rules for Global GNN Interpretability</title>
      <link>https://arxiv.org/abs/2509.18376</link>
      <description>arXiv:2509.18376v2 Announce Type: replace-cross 
Abstract: Graph Neural Networks (GNNs) are widely used for node classification, yet their opaque decision-making limits trust and adoption. While local explanations offer insights into individual predictions, global explanation methods, those that characterize an entire class, remain underdeveloped. Existing global explainers rely on motif discovery in small graphs, an approach that breaks down in large, real-world settings where subgraph repetition is rare, node attributes are high-dimensional, and predictions arise from complex structure-attribute interactions. We propose GnnXemplar, a novel global explainer inspired from Exemplar Theory from cognitive science. GnnXemplar identifies representative nodes in the GNN embedding space, exemplars, and explains predictions using natural language rules derived from their neighborhoods. Exemplar selection is framed as a coverage maximization problem over reverse k-nearest neighbors, for which we provide an efficient greedy approximation. To derive interpretable rules, we employ a self-refining prompt strategy using large language models (LLMs). Experiments across diverse benchmarks show that GnnXemplar significantly outperforms existing methods in fidelity, scalability, and human interpretability, as validated by a user study with 60 participants.</description>
      <guid isPermaLink="false">oai:arXiv.org:2509.18376v2</guid>
      <category>cs.LG</category>
      <category>cs.SI</category>
      <pubDate>Thu, 30 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-sa/4.0/</dc:rights>
      <dc:creator>Burouj Armgaan, Eshan Jain, Harsh Pandey, Mahesh Chandran, Sayan Ranu</dc:creator>
    </item>
  </channel>
</rss>
