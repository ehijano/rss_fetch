<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>cs.CE updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/cs.CE</link>
    <description>cs.CE updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/cs.CE" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Thu, 02 May 2024 04:00:08 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Thu, 02 May 2024 00:00:00 -0400</pubDate>
    <skipDays>
      <day>Saturday</day>
      <day>Sunday</day>
    </skipDays>
    <item>
      <title>Cantera-Based Python Computer Program for Solving Steam Power Cycles with Superheating</title>
      <link>https://arxiv.org/abs/2405.00007</link>
      <description>arXiv:2405.00007v1 Announce Type: new 
Abstract: One of the main sources of electricity generation is power plants that use water (steam) to rotate turbines, which drive large electric generators. The steam can be generated from renewable or non-renewable energy sources, such as geothermal energy and nuclear fuels. Having an analysis tool for modeling the performance of such steam power plants can greatly help in reaching optimum designs, leading to less fuel consumption, reduced pollution, and cheaper electricity. It is further advantageous if such modeling tool is free to access, does not require many inputs from the user, and gives results in a very short time. These remarks establish a motivation for the current study. This article documents a computer code written in the Python programming language for numerically analysing the main processes in a steam power cycle with superheating. The code utilizes built-in thermodynamic properties for water in the open-source software package "Cantera". A validation case with a benchmarking example in the literature using an independent source of water properties suggests that the developed code is correct. The code can be viewed as an extension to the Python examples for thermodynamic and power generation applications. Cantera can handle both subcritical and supercritical types of superheating. In the subcritical superheating, the steam absolute pressure does not exceed 220.9 bar. In the supercritical superheating, water becomes in a special condition called supercritical fluid, with absolute pressures above 220.9 bar.</description>
      <guid isPermaLink="false">oai:arXiv.org:2405.00007v1</guid>
      <category>cs.CE</category>
      <category>cs.NA</category>
      <category>math.NA</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <arxiv:DOI>10.46338/ijetae0323_06</arxiv:DOI>
      <arxiv:journal_reference>International Journal of Emerging Technology and Advanced Engineering. 13(3), 63-73. 2023</arxiv:journal_reference>
      <dc:creator>Osama A. Marzouk</dc:creator>
    </item>
    <item>
      <title>A Multiscale Fracture Model using Peridynamic Enrichment of Finite Elements within an Adaptive Partition of Unity: Experimental Validation</title>
      <link>https://arxiv.org/abs/2405.00011</link>
      <description>arXiv:2405.00011v1 Announce Type: new 
Abstract: Partition of unity methods (PUM) are of domain decomposition type and provide the opportunity for multiscale and multiphysics numerical modeling. Within the PUM global-local enrichment scheme [1, 2] different physical models can exist to capture multiscale behavior. For instance, we consider classical linear elasticity globally and local zones where fractures occur. The elastic fields of the undamaged media provide appropriate boundary data for local PD simulations on a subdomain containing the crack tip to grow the crack path. Once the updated crack path is found, the elastic field in the body and surrounding the crack is updated using PUM basis with appropriate enrichment near the crack. The subdomain for the PD simulation is chosen to include the current crack tip as well as nearby features that will influence crack growth. This paper is part II of this series and validates the combined PD/PUM simulator against the experimental results presented in [3]. The presented results show that we can attain good agreement between experimental and simulation data with a local PD subdomain that is moving with the crack tip and adaptively chosen size.</description>
      <guid isPermaLink="false">oai:arXiv.org:2405.00011v1</guid>
      <category>cs.CE</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Matthias Birner, Patrick Diehl, Robert Lipton, Marc Alexander Schweitzer</dc:creator>
    </item>
    <item>
      <title>Enhancing Credit Card Fraud Detection A Neural Network and SMOTE Integrated Approach</title>
      <link>https://arxiv.org/abs/2405.00026</link>
      <description>arXiv:2405.00026v1 Announce Type: new 
Abstract: Credit card fraud detection is a critical challenge in the financial sector, demanding sophisticated approaches to accurately identify fraudulent transactions. This research proposes an innovative methodology combining Neural Networks (NN) and Synthet ic Minority Over-sampling Technique (SMOTE) to enhance the detection performance. The study addresses the inherent imbalance in credit card transaction data, focusing on technical advancements for robust and precise fraud detection. Results demonstrat e that the integration of NN and SMOTE exhibits superior precision, recall, and F1-score compared to traditional models, highlighting its potential as an advanced solution for handling imbalanced datasets in credit card fraud detection scenarios. This rese arch contributes to the ongoing efforts to develop effective and efficient mechanisms for safeguarding financial transactions from fraudulent activities.</description>
      <guid isPermaLink="false">oai:arXiv.org:2405.00026v1</guid>
      <category>cs.CE</category>
      <category>cs.AI</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Mengran Zhu, Ye Zhang, Yulu Gong, Changxin Xu, Yafei Xiang</dc:creator>
    </item>
    <item>
      <title>Reduced-order modeling for second-order computational homogenization with applications to geometrically parameterized elastomeric metamaterials</title>
      <link>https://arxiv.org/abs/2405.00437</link>
      <description>arXiv:2405.00437v1 Announce Type: new 
Abstract: The structural properties of mechanical metamaterials are typically studied with two-scale methods based on computational homogenization. Because such materials have a complex microstructure, enriched schemes such as second-order computational homogenization are required to fully capture their non-linear behavior, which arises from non-local interactions due to the buckling or patterning of the microstructure. In the two-scale formulation, the effective behavior of the microstructure is captured with a representative volume element (RVE), and a homogenized effective continuum is considered on the macroscale.
  Although an effective continuum formulation is introduced, solving such two-scale models concurrently is still computationally demanding due to the many repeated solutions for each RVE at the microscale level. In this work, we propose a reduced-order model for the microscopic problem arising in second-order computational homogenization, using proper orthogonal decomposition and a novel hyperreduction method that is specifically tailored for this problem and inspired by the empirical cubature method. Two numerical examples are considered, in which the performance of the reduced-order model is carefully assessed by comparing its solutions with direct numerical simulations (entirely resolving the underlying microstructure) and the full second-order computational homogenization model. The reduced-order model is able to approximate the result of the full computational homogenization well, provided that the training data is representative for the problem at hand. Any remaining errors, when compared with the direct numerical simulation, can be attributed to the inherent approximation errors in the computational homogenization scheme. Regarding run times for one thread, speed-ups on the order of 100 are achieved with the reduced-order model as compared to direct numerical simulations.</description>
      <guid isPermaLink="false">oai:arXiv.org:2405.00437v1</guid>
      <category>cs.CE</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>T. Guo, V. G. Kouznetsova, M. G. D. Geers, K. Veroy, O. Roko\v{s}</dc:creator>
    </item>
    <item>
      <title>NumLLM: Numeric-Sensitive Large Language Model for Chinese Finance</title>
      <link>https://arxiv.org/abs/2405.00566</link>
      <description>arXiv:2405.00566v1 Announce Type: new 
Abstract: Recently, many works have proposed various financial large language models (FinLLMs) by pre-training from scratch or fine-tuning open-sourced LLMs on financial corpora. However, existing FinLLMs exhibit unsatisfactory performance in understanding financial text when numeric variables are involved in questions. In this paper, we propose a novel LLM, called numeric-sensitive large language model (NumLLM), for Chinese finance. We first construct a financial corpus from financial textbooks which is essential for improving numeric capability of LLMs during fine-tuning. After that, we train two individual low-rank adaptation (LoRA) modules by fine-tuning on our constructed financial corpus. One module is for adapting general-purpose LLMs to financial domain, and the other module is for enhancing the ability of NumLLM to understand financial text with numeric variables. Lastly, we merge the two LoRA modules into the foundation model to obtain NumLLM for inference. Experiments on financial question-answering benchmark show that NumLLM can boost the performance of the foundation model and can achieve the best overall performance compared to all baselines, on both numeric and non-numeric questions.</description>
      <guid isPermaLink="false">oai:arXiv.org:2405.00566v1</guid>
      <category>cs.CE</category>
      <category>cs.CL</category>
      <category>q-fin.GN</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Huan-Yi Su, Ke Wu, Yu-Hao Huang, Wu-Jun Li</dc:creator>
    </item>
    <item>
      <title>Graph-Based Multivariate Multiscale Dispersion Entropy: Efficient Implementation and Applications to Real-World Network Data</title>
      <link>https://arxiv.org/abs/2405.00518</link>
      <description>arXiv:2405.00518v1 Announce Type: cross 
Abstract: We introduce Multivariate Multiscale Graph-based Dispersion Entropy (mvDEG), a novel, computationally efficient method for analyzing multivariate time series data in graph and complex network frameworks, and demonstrate its application in real-world data. mvDEG effectively combines temporal dynamics with topological relationships, offering enhanced analysis compared to traditional nonlinear entropy methods. Its efficacy is established through testing on synthetic signals, such as uncorrelated and correlated noise, showcasing its adeptness in discerning various levels of dependency and complexity.
  The robustness of mvDEG is further validated with real-world datasets, effectively differentiating various two-phase flow regimes and capturing distinct dynamics in weather data analysis. An important advancement of mvDEG is its computational efficiency. Our optimized algorithm displays a computational time that grows linearly with the number of vertices or nodes, in contrast to the exponential growth observed in classical methods. This efficiency is achieved through refined matrix power calculations that exploit matrix and Kronecker product properties, making our method faster than the state of the art. The significant acceleration in computational time positions mvDEG as a transformative tool for extensive and real-time applications, setting a new benchmark in the analysis of time series recorded at distributed locations and opening avenues for innovative applications.</description>
      <guid isPermaLink="false">oai:arXiv.org:2405.00518v1</guid>
      <category>math.CO</category>
      <category>cs.CE</category>
      <category>nlin.CD</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>John Stewart Fabila-Carrasco, Chao Tan, Javier Escudero</dc:creator>
    </item>
    <item>
      <title>Predicting the Temporal Dynamics of Prosthetic Vision</title>
      <link>https://arxiv.org/abs/2404.14591</link>
      <description>arXiv:2404.14591v2 Announce Type: replace 
Abstract: Retinal implants are a promising treatment option for degenerative retinal disease. While numerous models have been developed to simulate the appearance of elicited visual percepts ("phosphenes"), these models often either focus solely on spatial characteristics or inadequately capture the complex temporal dynamics observed in clinical trials, which vary heavily across implant technologies, subjects, and stimulus conditions. Here we introduce two computational models designed to accurately predict phosphene fading and persistence under varying stimulus conditions, cross-validated on behavioral data reported by nine users of the Argus II Retinal Prosthesis System. Both models segment the time course of phosphene perception into discrete intervals, decomposing phosphene fading and persistence into either sinusoidal or exponential components. Our spectral model demonstrates state-of-the-art predictions of phosphene intensity over time (r = 0.7 across all participants). Overall, this study lays the groundwork for enhancing prosthetic vision by improving our understanding of phosphene temporal dynamics.</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.14591v2</guid>
      <category>cs.CE</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Yuchen Hou, Laya Pullela, Jiaxin Su, Sriya Aluru, Shivani Sista, Xiankun Lu, Michael Beyeler</dc:creator>
    </item>
    <item>
      <title>MLQAOA: Graph Learning Accelerated Hybrid Quantum-Classical Multilevel QAOA</title>
      <link>https://arxiv.org/abs/2404.14399</link>
      <description>arXiv:2404.14399v3 Announce Type: replace-cross 
Abstract: Learning the problem structure at multiple levels of coarseness to inform the decomposition-based hybrid quantum-classical combinatorial optimization solvers is a promising approach to scaling up variational approaches. We introduce a multilevel algorithm reinforced with the spectral graph representation learning-based accelerator to tackle large-scale graph maximum cut instances and fused with several versions of the quantum approximate optimization algorithm (QAOA) and QAOA-inspired algorithms. The graph representation learning model utilizes the idea of QAOA variational parameters concentration and substantially improves the performance of QAOA. We demonstrate the potential of using multilevel QAOA and representation learning-based approaches on very large graphs by achieving high-quality solutions in a much faster time. Reproducibility: Our source code and results are available at https://github.com/bachbao/MLQAOA</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.14399v3</guid>
      <category>quant-ph</category>
      <category>cs.CE</category>
      <category>physics.comp-ph</category>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Bao Bach, Jose Falla, Ilya Safro</dc:creator>
    </item>
  </channel>
</rss>
