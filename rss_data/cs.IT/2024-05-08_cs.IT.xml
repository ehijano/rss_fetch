<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>cs.IT updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/cs.IT</link>
    <description>cs.IT updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/cs.IT" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Wed, 08 May 2024 04:01:12 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Wed, 08 May 2024 00:00:00 -0400</pubDate>
    <skipDays>
      <day>Saturday</day>
      <day>Sunday</day>
    </skipDays>
    <item>
      <title>Update Rate, Accuracy, and Age of Information in a Wireless Sensor Network</title>
      <link>https://arxiv.org/abs/2405.03798</link>
      <description>arXiv:2405.03798v1 Announce Type: new 
Abstract: Age of Information (AoI), namely the time that has elapsed since the most recently delivered packet was generated, is receiving increasing attention with the emergence of many real-time applications that rely on the exchange of time-sensitive information. AoI captures the freshness of the information from the perspective of the destination. The term "accuracy of information" is used to assess how close the estimate at the destination is to the parameter value measured by the sensor. In this paper, the mean square error (MSE) is used to evaluate the accuracy of information. We focus on a single sensor that monitors a time-sensitive physical process, which is modelled as a random walk. Whenever the state of the random walk changes by more than a specified threshold, the sensor generates a status update packet and transmits it to the destination. When no update packet is received, the destination assumes that the state of the process has not changed. We study the problem of finding the minimum update rate under AoI and accuracy of information constraints. More specifically, we derive analytical expressions for the update rate, the AoI, and the MSE.</description>
      <guid isPermaLink="false">oai:arXiv.org:2405.03798v1</guid>
      <category>cs.IT</category>
      <category>math.IT</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Xinlu Dai, Cyril Leung</dc:creator>
    </item>
    <item>
      <title>On the invariance of the Kolmogorov complexity of $\beta$-expansions</title>
      <link>https://arxiv.org/abs/2405.03816</link>
      <description>arXiv:2405.03816v1 Announce Type: new 
Abstract: Measuring the complexity of real numbers is of major importance in computer science, for the purpose of knowing which computations are allowed. Consider a non-computable real number $s$, i.e. a real number which cannot be stored on a computer. We can store only an approximation of $x$, for instance by considering a finite bitstring representing a finite prefix of its binary expansion. For a fixed approximation error $\varepsilon&gt;0$, the size of this finite bitstring is dependent on the \textit{algorithmic complexity} of the finite prefixes of the binary expansion of $s$. The \textit{algorithmic complexity} of a binary sequence $x$, often referred to as \textit{Kolmogorov complexity}, is the length of the smallest binary sequence $x'$, for which there exists an algorithm, such that when presented with $x'$ as input, it outputs $x$. The algorithmic complexity of the binary expansion of real numbers is widely studied, but the algorithmic complexity of other ways of representing real numbers remains poorly reported. However, knowing the algorithmic complexity of different representations may allow to define new and more efficient strategies to represent real numbers. Several papers have established an equivalence between the algorithmic complexity of the $q$-ary expansions, with $q \in \mathbb{N}$, $q \geq 2$, i.e. representations of real numbers in any integer base. In this paper, we study the algorithmic complexity of the so-called $\beta$-expansions, which are representations of real numbers in a base $\beta \in (1,2)$ that display a much more complex behavior as compared to the $q$-ary expansion. We show that for a given real number $s$, the binary expansion is a minimizer of algorithmic complexity, and that for every given $\beta \in (1,2)$, there exists a $\beta$-expansion of $s$ which achieves the lower bound of algorithmic complexity displayed by the binary expansion of $s$.</description>
      <guid isPermaLink="false">oai:arXiv.org:2405.03816v1</guid>
      <category>cs.IT</category>
      <category>math.IT</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-sa/4.0/</dc:rights>
      <dc:creator>Valentin Abadie, Helmut Boelcskei</dc:creator>
    </item>
    <item>
      <title>Learning Linear Block Error Correction Codes</title>
      <link>https://arxiv.org/abs/2405.04050</link>
      <description>arXiv:2405.04050v1 Announce Type: new 
Abstract: Error correction codes are a crucial part of the physical communication layer, ensuring the reliable transfer of data over noisy channels. The design of optimal linear block codes capable of being efficiently decoded is of major concern, especially for short block lengths. While neural decoders have recently demonstrated their advantage over classical decoding techniques, the neural design of the codes remains a challenge. In this work, we propose for the first time a unified encoder-decoder training of binary linear block codes. To this end, we adapt the coding setting to support efficient and differentiable training of the code for end-to-end optimization over the order two Galois field. We also propose a novel Transformer model in which the self-attention masking is performed in a differentiable fashion for the efficient backpropagation of the code gradient. Our results show that (i) the proposed decoder outperforms existing neural decoding on conventional codes, (ii) the suggested framework generates codes that outperform the {analogous} conventional codes, and (iii) the codes we developed not only excel with our decoder but also show enhanced performance with traditional decoding techniques.</description>
      <guid isPermaLink="false">oai:arXiv.org:2405.04050v1</guid>
      <category>cs.IT</category>
      <category>cs.AI</category>
      <category>math.IT</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <dc:creator>Yoni Choukroun, Lior Wolf</dc:creator>
    </item>
    <item>
      <title>On the quantization goodness of polar lattices</title>
      <link>https://arxiv.org/abs/2405.04051</link>
      <description>arXiv:2405.04051v1 Announce Type: new 
Abstract: In this work, we prove that polar lattices, when tailored for lossy compression, are quantization-good in the sense that their normalized second moments approach $\frac{1}{2\pi e}$ as the dimension of lattices increases. It has been predicted by Zamir et al. \cite{ZamirQZ96} that the Entropy Coded Dithered Quantization (ECDQ) system using quantization-good lattices can achieve the rate-distortion bound of i.i.d. Gaussian sources. In our previous work \cite{LingQZ}, we established that polar lattices are indeed capable of attaining the same objective. It is reasonable to conjecture that polar lattices also demonstrate quantization goodness in the context of lossy compression. This study confirms this hypothesis.</description>
      <guid isPermaLink="false">oai:arXiv.org:2405.04051v1</guid>
      <category>cs.IT</category>
      <category>math.IT</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Ling Liu, Shanxiang Lyu, Cong Ling, Baoming Bai</dc:creator>
    </item>
    <item>
      <title>Movable Antennas-Enabled Two-User Multicasting: Do We Really Need Alternating Optimization for Minimum Rate Maximization?</title>
      <link>https://arxiv.org/abs/2405.04120</link>
      <description>arXiv:2405.04120v1 Announce Type: new 
Abstract: Movable antenna (MA) technology, which can reconfigure wireless channels by flexibly moving antenna positions in a specified region, has great potential for improving communication performance. In this paper, we consider a new setup of MAs-enabled multicasting, where we adopt a simple setting in which a linear MA array-enabled source (${\rm{S}}$) transmits a common message to two single-antenna users ${\rm{U}}_1$ and ${\rm{U}}_2$. We aim to maximize the minimum rate among these two users, by jointly optimizing the transmit beamforming and antenna positions at ${\rm{S}}$. Instead of utilizing the widely-used alternating optimization (AO) approach, we reveal, with rigorous proof, that the above two variables can be optimized separately: i) the optimal antenna positions can be firstly determined via the successive convex approximation technique, based on the rule of maximizing the correlation between ${\rm{S}}$-${\rm{U}}_1$ and ${\rm{S}}$-${\rm{U}}_2$ channels; ii) afterwards, the optimal closed-form transmit beamforming can be derived via simple arguments. Compared to AO, this new approach yields the same performance but reduces the computational complexities significantly. Moreover, it can provide insightful conclusions which are not possible with AO.</description>
      <guid isPermaLink="false">oai:arXiv.org:2405.04120v1</guid>
      <category>cs.IT</category>
      <category>math.IT</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Guojie Hu, Qingqing Wu, Donghui Xu, Kui Xu, Jiangbo Si, Yunlong Cai, Naofal Al-Dhahir</dc:creator>
    </item>
    <item>
      <title>Lossy Compression with Data, Perception, and Classification Constraints</title>
      <link>https://arxiv.org/abs/2405.04144</link>
      <description>arXiv:2405.04144v1 Announce Type: new 
Abstract: Balancing diverse task objectives under limited rate is crucial for developing robust multi-task deep learning (DL) models and improving performance across various domains. In this paper, we consider the lossy compression problem with human-centric and task-oriented metrics, such as perceptual quality and classification accuracy. We investigate two ternary relationships, namely, the rate-distortion-classification (RDC) and rate-perception-classification (RPC). For both RDC and RPC functions, we derive the closed-form expressions of the optimal rate for both binary and Gaussian sources. Notably, both RDC and RPC relationships exhibit distinct characteristics compared to the previous RDP tradeoff proposed by Blau et al. Then, we conduct experiments by implementing a DL-based image compression framework, incorporating rate, distortion, perception, and classification constraints. The experimental results verify the theoretical characteristics of RDC and RPC tradeoffs, providing information-theoretical insights into the design of loss functions to balance diverse task objectives in deep learning.</description>
      <guid isPermaLink="false">oai:arXiv.org:2405.04144v1</guid>
      <category>cs.IT</category>
      <category>math.IT</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Yuhan Wang, Youlong Wu, Shuai Ma, Ying-Jun Angela Zhang</dc:creator>
    </item>
    <item>
      <title>Graph Reconstruction from Noisy Random Subgraphs</title>
      <link>https://arxiv.org/abs/2405.04261</link>
      <description>arXiv:2405.04261v1 Announce Type: new 
Abstract: We consider the problem of reconstructing an undirected graph $G$ on $n$ vertices given multiple random noisy subgraphs or "traces". Specifically, a trace is generated by sampling each vertex with probability $p_v$, then taking the resulting induced subgraph on the sampled vertices, and then adding noise in the form of either (a) deleting each edge in the subgraph with probability $1-p_e$, or (b) deleting each edge with probability $f_e$ and transforming a non-edge into an edge with probability $f_e$. We show that, under mild assumptions on $p_v$, $p_e$ and $f_e$, if $G$ is selected uniformly at random, then $O(p_e^{-1} p_v^{-2} \log n)$ or $O((f_e-1/2)^{-2} p_v^{-2} \log n)$ traces suffice to reconstruct $G$ with high probability. In contrast, if $G$ is arbitrary, then $\exp(\Omega(n))$ traces are necessary even when $p_v=1, p_e=1/2$.</description>
      <guid isPermaLink="false">oai:arXiv.org:2405.04261v1</guid>
      <category>cs.IT</category>
      <category>cs.DS</category>
      <category>math.IT</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Andrew McGregor, Rik Sengupta</dc:creator>
    </item>
    <item>
      <title>PDCCH Scheduling via Maximum Independent Set</title>
      <link>https://arxiv.org/abs/2405.04283</link>
      <description>arXiv:2405.04283v1 Announce Type: new 
Abstract: In 5G, the Physical Downlink Control CHannel (PDCCH) carries crucial information enabling the User Equipment (UE) to connect in UL and DL. UEs are unaware of the frequency location at which PDCCH is encoded, hence they need to perform blind decoding over a limited set of possible candidates. We address the problem faced by the gNodeB of selecting PDCCH candidates for each UE to optimize data transmission. We formulate it as a Maximum Weighted Independent Set (MWIS) problem, that is known to be an NP-hard problem and cannot even be approximated. A solution method called Weight-to-Degree Ratio (WDR) Greedy emerges as a strong contender for practical implementations due to its favorable performance-to-complexity trade-off and theoretical performance guarantees.</description>
      <guid isPermaLink="false">oai:arXiv.org:2405.04283v1</guid>
      <category>cs.IT</category>
      <category>math.IT</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Lorenzo Maggi, Alvaro Valcarce Rial, Alo\"is Herzog, Suresh Kalyanasundaram, Rakshak Agrawal</dc:creator>
    </item>
    <item>
      <title>A transversality theorem for semi-algebraic sets with application to signal recovery from the second moment and cryo-EM</title>
      <link>https://arxiv.org/abs/2405.04354</link>
      <description>arXiv:2405.04354v1 Announce Type: new 
Abstract: Semi-algebraic priors are ubiquitous in signal processing and machine learning. Prevalent examples include a) linear models where the signal lies in a low-dimensional subspace; b) sparse models where the signal can be represented by only a few coefficients under a suitable basis; and c) a large family of neural network generative models. In this paper, we prove a transversality theorem for semi-algebraic sets in orthogonal or unitary representations of groups: with a suitable dimension bound, a generic translate of any semi-algebraic set is transverse to the orbits of the group action. This, in turn, implies that if a signal lies in a low-dimensional semi-algebraic set, then it can be recovered uniquely from measurements that separate orbits.
  As an application, we consider the implications of the transversality theorem to the problem of recovering signals that are translated by random group actions from their second moment. As a special case, we discuss cryo-EM: a leading technology to constitute the spatial structure of biological molecules, which serves as our prime motivation. In particular, we derive explicit bounds for recovering a molecular structure from the second moment under a semi-algebraic prior and deduce information-theoretic implications. We also obtain information-theoretic bounds for three additional applications: factoring Gram matrices, multi-reference alignment, and phase retrieval. Finally, we deduce bounds for designing permutation invariant separators in machine learning.</description>
      <guid isPermaLink="false">oai:arXiv.org:2405.04354v1</guid>
      <category>cs.IT</category>
      <category>eess.SP</category>
      <category>math.AG</category>
      <category>math.IT</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Tamir Bendory, Nadav Dym, Dan Edidin, Arun Suresh</dc:creator>
    </item>
    <item>
      <title>Global Scale Self-Supervised Channel Charting with Sensor Fusion</title>
      <link>https://arxiv.org/abs/2405.04357</link>
      <description>arXiv:2405.04357v1 Announce Type: new 
Abstract: The sensing and positioning capabilities foreseen in 6G have great potential for technology advancements in various domains, such as future smart cities and industrial use cases. Channel charting has emerged as a promising technology in recent years for radio frequency-based sensing and localization. However, the accuracy of these techniques is yet far behind the numbers envisioned in 6G. To reduce this gap, in this paper, we propose a novel channel charting technique capitalizing on the time of arrival measurements from surrounding Transmission Reception Points (TRPs) along with their locations and leveraging sensor fusion in channel charting by incorporating laser scanner data during the training phase of our algorithm. The proposed algorithm remains self-supervised during training and test phases, requiring no geometrical models or user position ground truth. Simulation results validate the achievement of a sub-meter level localization accuracy using our algorithm 90% of the time, outperforming the state-of-the-art channel charting techniques and the traditional triangulation-based approaches.</description>
      <guid isPermaLink="false">oai:arXiv.org:2405.04357v1</guid>
      <category>cs.IT</category>
      <category>cs.AI</category>
      <category>math.IT</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Omid Esrafilian, Mohsen Ahadi, Florian Kaltenberger, David Gesbert</dc:creator>
    </item>
    <item>
      <title>Some Notes on the Sample Complexity of Approximate Channel Simulation</title>
      <link>https://arxiv.org/abs/2405.04363</link>
      <description>arXiv:2405.04363v1 Announce Type: new 
Abstract: Channel simulation algorithms can efficiently encode random samples from a prescribed target distribution $Q$ and find applications in machine learning-based lossy data compression. However, algorithms that encode exact samples usually have random runtime, limiting their applicability when a consistent encoding time is desirable. Thus, this paper considers approximate schemes with a fixed runtime instead. First, we strengthen a result of Agustsson and Theis and show that there is a class of pairs of target distribution $Q$ and coding distribution $P$, for which the runtime of any approximate scheme scales at least super-polynomially in $D_\infty[Q \Vert P]$. We then show, by contrast, that if we have access to an unnormalised Radon-Nikodym derivative $r \propto dQ/dP$ and knowledge of $D_{KL}[Q \Vert P]$, we can exploit global-bound, depth-limited A* coding to ensure $\mathrm{TV}[Q \Vert P] \leq \epsilon$ and maintain optimal coding performance with a sample complexity of only $\exp_2\big((D_{KL}[Q \Vert P] + o(1)) \big/ \epsilon\big)$.</description>
      <guid isPermaLink="false">oai:arXiv.org:2405.04363v1</guid>
      <category>cs.IT</category>
      <category>math.IT</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Gergely Flamich, Lennie Wells</dc:creator>
    </item>
    <item>
      <title>Decentralized Algorithms for Out-of-System Interference Suppression in Distributed MIMO</title>
      <link>https://arxiv.org/abs/2405.04400</link>
      <description>arXiv:2405.04400v1 Announce Type: new 
Abstract: Out-of-system (OoS) interference is a potential limitation for distributed networks that operate in unlicensed spectrum or in a spectrum sharing scenario. The OoS interference differs from the in-system interference in that OoS signals and their associated channels (or even their statistics) are completely unknown. In this paper, we propose a novel distributed algorithm that can mitigate OoS interference in the uplink and suppress the signal transmission in the OoS direction in the downlink. To estimate the OoS interference, each access point (AP), upon receiving an estimate of OoS interference from a previous AP, computes a better estimate of OoS interference by rotate-and-average using Procrustes method and forwards the estimates to the next AP. This process continues until the central processing unit (CPU) receives the final estimate. Our method has comparable performance to that of a fully centralized interference rejection combining algorithm and has much lower fronthaul load requirements.</description>
      <guid isPermaLink="false">oai:arXiv.org:2405.04400v1</guid>
      <category>cs.IT</category>
      <category>eess.SP</category>
      <category>math.IT</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <arxiv:DOI>10.1109/LWC.2024.3397559</arxiv:DOI>
      <dc:creator>Zakir Hussain Shaik, Erik G. Larsson</dc:creator>
    </item>
    <item>
      <title>R\'enyi divergence guarantees for hashing with linear codes</title>
      <link>https://arxiv.org/abs/2405.04406</link>
      <description>arXiv:2405.04406v1 Announce Type: new 
Abstract: We consider the problem of distilling uniform random bits from an unknown source with a given $p$-entropy using linear hashing. As our main result, we estimate the expected $p$-divergence from the uniform distribution over the ensemble of random linear codes for all integer $p\ge 2$. The proof relies on analyzing how additive noise, determined by a random element of the code from the ensemble, acts on the source distribution. This action leads to the transformation of the source distribution into an approximately uniform one, a process commonly referred to as distribution smoothing. We also show that hashing with Reed-Muller matrices reaches intrinsic randomness of memoryless Bernoulli sources in the $l_p$ sense for all integer $p\ge 2$.</description>
      <guid isPermaLink="false">oai:arXiv.org:2405.04406v1</guid>
      <category>cs.IT</category>
      <category>math.IT</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Madhura Pathegama, Alexander Barg</dc:creator>
    </item>
    <item>
      <title>Optimizing Information Freshness in IoT Systems with Update Rate Constraints: A Token-Based Approach</title>
      <link>https://arxiv.org/abs/2405.04431</link>
      <description>arXiv:2405.04431v1 Announce Type: new 
Abstract: In Internet of Things (IoT) status update systems, where information is sampled and subsequently transmitted from a source to a destination node, the imperative necessity lies in maintaining the timeliness of information and updating the system with optimal frequency. Optimizing information freshness in resource-limited status update systems often involves Constrained Markov Decision Process (CMDP) problems with update rate constraints. Solving CMDP problems, especially with multiple constraints, is a challenging task. To address this, we present a token-based approach that transforms CMDP into an unconstrained MDP, simplifying the solution process. We apply this approach to systems with one and two update rate constraints for optimizing Age of Incorrect Information (AoII) and Age of Information (AoI) metrics, respectively, and explore the analytical and numerical aspects. Additionally, we introduce an iterative triangle bisection method for solving the CMDP problems with two constraints, comparing its results with the token-based MDP approach. Our findings show that the token-based approach yields superior performance over baseline policies, converging to the optimal policy as the maximum number of tokens increases.</description>
      <guid isPermaLink="false">oai:arXiv.org:2405.04431v1</guid>
      <category>cs.IT</category>
      <category>cs.NI</category>
      <category>math.IT</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Erfan Delfani, Nikolaos Pappas</dc:creator>
    </item>
    <item>
      <title>Trajectory analysis through entropy characterization over coded representation</title>
      <link>https://arxiv.org/abs/2405.03693</link>
      <description>arXiv:2405.03693v1 Announce Type: cross 
Abstract: Any continuous curve in a higher dimensional space can be considered a trajectory that can be parameterized by a single variable, usually taken as time. It is well known that a continuous curve can have a fractional dimensionality, which can be estimated using already standard algorithms. However, characterizing a trajectory from an entropic perspective is far less developed. The search for such characterization leads us to use chain coding to discretize the description of a curve. Calculating the entropy density and entropy-related magnitudes from the resulting finite alphabet code becomes straightforward. In such a way, the entropy of a trajectory can be defined and used as an effective tool to assert creativity and pattern formation from a Shannon perspective. Applying the procedure to actual experimental physiological data and modelled trajectories of astronomical dynamics proved the robustness of the entropic characterization in a wealth of trajectories of different origins and the insight that can be gained from its use.</description>
      <guid isPermaLink="false">oai:arXiv.org:2405.03693v1</guid>
      <category>physics.data-an</category>
      <category>cs.IT</category>
      <category>math.IT</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Roxana Pe\~na-Mendieta, Ania Mesa-Rodr\'iguez, Ernesto Estevez-Rams, Daniel Estevez-Moya, Danays Kunka</dc:creator>
    </item>
    <item>
      <title>PoW Security-Latency under Random Delays and the Effect of Transaction Fees</title>
      <link>https://arxiv.org/abs/2405.04526</link>
      <description>arXiv:2405.04526v1 Announce Type: cross 
Abstract: Safety guarantees and security-latency problem of Nakamoto consensus have been extensively studied in the last decade with a bounded delay model. Recent studies have shown that PoW protocol is secure under random delay models as well. In this paper, we analyze the security-latency problem, i.e., how secure a block is, after it becomes k-deep in the blockchain, under general random delay distributions. We provide tight and explicit bounds which only require determining the distribution of the number of Poisson arrivals during the random delay. We further consider potential effects of recent Bitcoin halving on the security-latency problem by extending our results.</description>
      <guid isPermaLink="false">oai:arXiv.org:2405.04526v1</guid>
      <category>cs.CR</category>
      <category>cs.DC</category>
      <category>cs.DM</category>
      <category>cs.IT</category>
      <category>math.IT</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Mustafa Doger, Sennur Ulukus, Nail Akar</dc:creator>
    </item>
    <item>
      <title>Many-Help-One Problem for Gaussian Sources with a Tree Structure on their Correlation</title>
      <link>https://arxiv.org/abs/0901.1988</link>
      <description>arXiv:0901.1988v4 Announce Type: replace 
Abstract: In this paper we consider the separate coding problem for $L+1$ correlated Gaussian memoryless sources. We deal with the case where $L$ separately encoded data of sources work as side information at the decoder for the reconstruction of the remaining source. The determination problem of the rate distortion region for this system is the so called many-help-one problem and has been known as a highly challenging problem. The author determined the rate distortion region in the case where the $L$ sources working as partial side information are conditionally independent if the remaining source we wish to reconstruct is given. This condition on the correlation is called the CI condition. In this paper we extend the author's previous result to the case where $L+1$ sources satisfy a kind of tree structure on their correlation. We call this tree structure of information sources the TS condition, which contains the CI condition as a special case. In this paper we derive an explicit outer bound of the rate distortion region when information sources satisfy the TS condition. We further derive an explicit sufficient condtion for this outer bound to be tight. In particular, we determine the sum rate part of the rate distortion region for the case where information sources satisfy the TS condition. For some class of Gaussian sources with the TS condition we derive an explicit recursive formula of this sum rate part.</description>
      <guid isPermaLink="false">oai:arXiv.org:0901.1988v4</guid>
      <category>cs.IT</category>
      <category>math.IT</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Yasutada Oohama</dc:creator>
    </item>
    <item>
      <title>Families of sequences with good family complexity and cross-correlation measure</title>
      <link>https://arxiv.org/abs/2004.13938</link>
      <description>arXiv:2004.13938v3 Announce Type: replace 
Abstract: In this paper we study pseudorandomness of a family of sequences in terms of two measures, the family complexity ($f$-complexity) and the cross-correlation measure of order $\ell$. We consider sequences not only on binary alphabet but also on $k$-symbols ($k$-ary) alphabet. We first generalize some known methods on construction of the family of binary pseudorandom sequences. We prove a bound on the $f$-complexity of a large family of binary sequences of Legendre-symbols of certain irreducible polynomials. We show that this family as well as its dual family have both a large family complexity and a small cross-correlation measure up to a rather large order. Next, we present another family of binary sequences having high $f$-complexity and low cross-correlation measure. Then we extend the results to the family of sequences on $k$-symbols alphabet.</description>
      <guid isPermaLink="false">oai:arXiv.org:2004.13938v3</guid>
      <category>cs.IT</category>
      <category>cs.CR</category>
      <category>math.IT</category>
      <category>math.NT</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Kenan Do\u{g}an, Murat \c{S}ahin, O\u{g}uz Yayla</dc:creator>
    </item>
    <item>
      <title>Ternary Stochastic Geometry Theory for Performance Analysis of RIS-Assisted UDN</title>
      <link>https://arxiv.org/abs/2307.08200</link>
      <description>arXiv:2307.08200v3 Announce Type: replace 
Abstract: Currently, network topology becomes increasingly complex with the increased number of various network nodes, bringing in the challenge of network design and analysis. Most of the current studies are deduced based on the binary system stochastic geometry, overlooking the coupling and collaboration among nodes. This limitation makes it difficult to accurately analyze network systems, such as reconfigurable intelligent surface (RIS) assisted ultra-dense network (UDN). To address this issue, we propose a dual coordinate system analysis method, by using dual observation points and their established coordinates. The concept of a typical triangle that consists of a base station (BS), a RIS, and a user equipment (UE) is defined as the fundamental unit of analysis for ternary stochastic geometry. This triangle comprises the base station, the RIS, and the user equipment (UE). Furthermore, we extend Campbell's theorem and propose an approximate probability generating function for ternary stochastic geometry. Utilizing the theoretical framework of ternary stochastic geometry, we derive and analyze performance metrics of a RIS-assisted UDN system, such as coverage probability, area spectral efficiency, area energy efficiency, and energy coverage efficiency. Simulation results show that RIS can significantly enhance system performance, particularly for UEs with high signal-to-interference-plus-noise ratios, exhibiting a phenomenon similar to the Matthew effect.</description>
      <guid isPermaLink="false">oai:arXiv.org:2307.08200v3</guid>
      <category>cs.IT</category>
      <category>eess.SP</category>
      <category>math.IT</category>
      <category>math.ST</category>
      <category>stat.TH</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Hongchi Lin, Qiyue yu</dc:creator>
    </item>
    <item>
      <title>Deep Joint Source-Channel Coding for Adaptive Image Transmission over MIMO Channels</title>
      <link>https://arxiv.org/abs/2309.00470</link>
      <description>arXiv:2309.00470v3 Announce Type: replace 
Abstract: This paper introduces a vision transformer (ViT)-based deep joint source and channel coding (DeepJSCC) scheme for wireless image transmission over multiple-input multiple-output (MIMO) channels, denoted as DeepJSCC-MIMO. We consider DeepJSCC-MIMO for adaptive image transmission in both open-loop and closed-loop MIMO systems. The novel DeepJSCC-MIMO architecture surpasses the classical separation-based benchmarks with robustness to channel estimation errors and showcases remarkable flexibility in adapting to diverse channel conditions and antenna numbers without requiring retraining. Specifically, by harnessing the self-attention mechanism of ViT, DeepJSCC-MIMO intelligently learns feature mapping and power allocation strategies tailored to the unique characteristics of the source image and prevailing channel conditions. Extensive numerical experiments validate the significant improvements in transmission quality achieved by DeepJSCC-MIMO for both open-loop and closed-loop MIMO systems across a wide range of scenarios. Moreover, DeepJSCC-MIMO exhibits robustness to varying channel conditions, channel estimation errors, and different antenna numbers, making it an appealing solution for emerging semantic communication systems.</description>
      <guid isPermaLink="false">oai:arXiv.org:2309.00470v3</guid>
      <category>cs.IT</category>
      <category>eess.IV</category>
      <category>math.IT</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Haotian Wu, Yulin Shao, Chenghong Bian, Krystian Mikolajczyk, Deniz G\"und\"uz</dc:creator>
    </item>
    <item>
      <title>Near-Field Beam Training: Joint Angle and Range Estimation with DFT Codebook</title>
      <link>https://arxiv.org/abs/2309.11872</link>
      <description>arXiv:2309.11872v4 Announce Type: replace 
Abstract: Prior works on near-field beam training have mostly assumed dedicated polar-domain codebook and on-grid range estimation, which, however, may suffer long training overhead and degraded estimation accuracy. To address these issues, we propose in this paper new and efficient beam training schemes with off-grid range estimation by using conventional discrete Fourier transform (DFT) codebook. Specifically, we first analyze the received beam pattern at the user when far-field beamforming vectors are used for beam scanning, and show an interesting result that this beam pattern contains useful user angle and range information. Then, we propose two efficient schemes to jointly estimate the user angle and range with the DFT codebook. The first scheme estimates the user angle based on a defined angular support and resolves the user range by leveraging an approximated angular support width, while the second scheme estimates the user range by minimizing a power ratio mean square error (MSE) to improve the range estimation accuracy. Finally, numerical simulations show that our proposed schemes greatly reduce the near-field beam training overhead and improve the range estimation accuracy as compared to various benchmark schemes.</description>
      <guid isPermaLink="false">oai:arXiv.org:2309.11872v4</guid>
      <category>cs.IT</category>
      <category>eess.SP</category>
      <category>math.IT</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <arxiv:DOI>10.1109/TWC.2024.3385749</arxiv:DOI>
      <dc:creator>Xun Wu, Changsheng You, Jiapeng Li, Yunpu Zhang</dc:creator>
    </item>
    <item>
      <title>Approximation of Pufferfish Privacy for Gaussian Priors</title>
      <link>https://arxiv.org/abs/2401.12391</link>
      <description>arXiv:2401.12391v2 Announce Type: replace 
Abstract: This paper studies how to approximate pufferfish privacy when the adversary's prior belief of the published data is Gaussian distributed. Using Monge's optimal transport plan, we show that $(\epsilon, \delta)$-pufferfish privacy is attained if the additive Laplace noise is calibrated to the differences in mean and variance of the Gaussian distributions conditioned on every discriminative secret pair. A typical application is the private release of the summation (or average) query, for which sufficient conditions are derived for approximating $\epsilon$-statistical indistinguishability in individual's sensitive data. The result is then extended to arbitrary prior beliefs trained by Gaussian mixture models (GMMs): calibrating Laplace noise to a convex combination of differences in mean and variance between Gaussian components attains $(\epsilon,\delta)$-pufferfish privacy.</description>
      <guid isPermaLink="false">oai:arXiv.org:2401.12391v2</guid>
      <category>cs.IT</category>
      <category>cs.CR</category>
      <category>math.IT</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Ni Ding</dc:creator>
    </item>
    <item>
      <title>Correcting a Single Deletion in Reads from a Nanopore Sequencer</title>
      <link>https://arxiv.org/abs/2401.15939</link>
      <description>arXiv:2401.15939v2 Announce Type: replace 
Abstract: Owing to its several merits over other DNA sequencing technologies, nanopore sequencers hold an immense potential to revolutionize the efficiency of DNA storage systems. However, their higher error rates necessitate further research to devise practical and efficient coding schemes that would allow accurate retrieval of the data stored. Our work takes a step in this direction by adopting a simplified model of the nanopore sequencer inspired by Mao \emph{et al.}, which incorporates some of its physical aspects. This channel model can be viewed as a sliding window of length $\ell$ that passes over the incoming input sequence and produces the Hamming weight of the enclosed $\ell$ bits, while shifting by one position at each time step. The resulting $(\ell+1)$-ary vector, referred to as the $\ell$-\emph{read vector}, is susceptible to deletion errors due to imperfections inherent in the sequencing process. We establish that at least $\log n - \ell$ bits of redundancy are needed to correct a single deletion. An error-correcting code that is optimal up to an additive constant, is also proposed. Furthermore, we find that for $\ell \geq 2$, reconstruction from two distinct noisy $\ell$-read vectors can be accomplished without any redundancy, and provide a suitable reconstruction algorithm to this effect.</description>
      <guid isPermaLink="false">oai:arXiv.org:2401.15939v2</guid>
      <category>cs.IT</category>
      <category>math.IT</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Anisha Banerjee, Yonatan Yehezkeally, Antonia Wachter-Zeh, Eitan Yaakobi</dc:creator>
    </item>
    <item>
      <title>Quantum $X$-Secure $B$-Byzantine $T$-Colluding Private Information Retrieval</title>
      <link>https://arxiv.org/abs/2401.17252</link>
      <description>arXiv:2401.17252v2 Announce Type: replace 
Abstract: We consider the problems arising from the presence of Byzantine servers in a quantum private information retrieval (QPIR) setting. This is the first work to precisely define what the capabilities of Byzantine servers could be in a QPIR context. We show that quantum Byzantine servers have more capabilities than their classical counterparts due to the possibilities created by quantum encoding procedures. We focus on quantum Byzantine servers that can apply any reversible operation on their individual qudits. In this case, Byzantine servers can generate any error, i.e., this covers \emph{all} possible single qudit operations that can be applied by Byzantine servers on their qudits. We design a scheme based on cross-subspace alignment (CSA) and we show that this scheme achieves superdense coding gain in some cases.</description>
      <guid isPermaLink="false">oai:arXiv.org:2401.17252v2</guid>
      <category>cs.IT</category>
      <category>cs.CR</category>
      <category>cs.NI</category>
      <category>eess.SP</category>
      <category>math.IT</category>
      <category>quant-ph</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Mohamed Nomeir, Alptug Aytekin, Sennur Ulukus</dc:creator>
    </item>
    <item>
      <title>Explicit Formula for Partial Information Decomposition</title>
      <link>https://arxiv.org/abs/2402.03554</link>
      <description>arXiv:2402.03554v3 Announce Type: replace 
Abstract: Mutual information between two random variables is a well-studied notion, whose understanding is fairly complete. Mutual information between one random variable and a pair of other random variables, however, is a far more involved notion. Specifically, Shannon's mutual information does not capture fine-grained interactions between those three variables, resulting in limited insights in complex systems. To capture these fine-grained interactions, in 2010 Williams and Beer proposed to decompose this mutual information to information atoms, called unique, redundant, and synergistic, and proposed several operational axioms that these atoms must satisfy. In spite of numerous efforts, a general formula which satisfies these axioms has yet to be found. Inspired by Judea Pearl's do-calculus, we resolve this open problem by introducing the do-operation, an operation over the variable system which sets a certain marginal to a desired value, which is distinct from any existing approaches. Using this operation, we provide the first explicit formula for calculating the information atoms so that Williams and Beer's axioms are satisfied, as well as additional properties from subsequent studies in the field.</description>
      <guid isPermaLink="false">oai:arXiv.org:2402.03554v3</guid>
      <category>cs.IT</category>
      <category>math.IT</category>
      <category>math.PR</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Aobo Lyu, Andrew Clark, Netanel Raviv</dc:creator>
    </item>
    <item>
      <title>Marker+Codeword+Marker: A Coding Structure for Segmented Single-Insdel/-Edit Channels</title>
      <link>https://arxiv.org/abs/2402.04890</link>
      <description>arXiv:2402.04890v2 Announce Type: replace 
Abstract: An insdel refers to a deletion or an insertion, and an edit refers to an insdel or a substitution. In this paper, we consider the segmented single-insdel (resp. single-edit) channel, where the channel's input bit stream is partitioned into segments of length $n$ and each segment can suffer from at most a single insdel (resp. edit) error. The value of $n$ is known to the receiver but the boundaries of segments are not. We propose to encode each segment following a marker+codeword+marker structure, where the two markers are carefully selected and the codewords are chosen from Varshamov-Tenegolts (VT) codes. In this way, we are able to construct a new class of binary codes that can correct segmented single-insdel errors. Our codes have the lowest redundancy of $\log_2(n-6)+7$ bits and are the first one that has linear-time encoder/decoder in the literature. Moreover, by enhancing the VT codes and one of the markers, we are able to construct the first class of binary codes that can correct segmented single-edit errors. This class of codes has redundancy $\log_2(n-9)+10$ bits and has linear-time encoder/decoder.</description>
      <guid isPermaLink="false">oai:arXiv.org:2402.04890v2</guid>
      <category>cs.IT</category>
      <category>math.IT</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Zhen Li, Xuan He, Xiaohu Tang</dc:creator>
    </item>
    <item>
      <title>Restricted Isometry Property of Rank-One Measurements with Random Unit-Modulus Vectors</title>
      <link>https://arxiv.org/abs/2403.02654</link>
      <description>arXiv:2403.02654v2 Announce Type: replace 
Abstract: The restricted isometry property (RIP) is essential for the linear map to guarantee the successful recovery of low-rank matrices. The existing works show that the linear map generated by the measurement matrices with independent and identically distributed (i.i.d.) entries satisfies RIP with high probability. However, when dealing with non-i.i.d. measurement matrices, such as the rank-one measurements, the RIP compliance may not be guaranteed. In this paper, we show that the RIP can still be achieved with high probability, when the rank-one measurement matrix is constructed by the random unit-modulus vectors. Compared to the existing works, we first address the challenge of establishing RIP for the linear map in non-i.i.d. scenarios. As validated in the experiments, this linear map is memory-efficient, and not only satisfies the RIP but also exhibits similar recovery performance of the low-rank matrices to that of conventional i.i.d. measurement matrices.</description>
      <guid isPermaLink="false">oai:arXiv.org:2403.02654v2</guid>
      <category>cs.IT</category>
      <category>math.IT</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Wei Zhang, Zhenni Wang</dc:creator>
    </item>
    <item>
      <title>Robust Distributed Compression with Learned Heegard-Berger Scheme</title>
      <link>https://arxiv.org/abs/2403.08411</link>
      <description>arXiv:2403.08411v2 Announce Type: replace 
Abstract: We consider lossy compression of an information source when decoder-only side information may be absent. This setup, also referred to as the Heegard-Berger or Kaspi problem, is a special case of robust distributed source coding. Building upon previous works on neural network-based distributed compressors developed for the decoder-only side information (Wyner-Ziv) case, we propose learning-based schemes that are amenable to the availability of side information. We find that our learned compressors mimic the achievability part of the Heegard-Berger theorem and yield interpretable results operating close to information-theoretic bounds. Depending on the availability of the side information, our neural compressors recover characteristics of the point-to-point (i.e., with no side information) and the Wyner-Ziv coding strategies that include binning in the source space, although no structure exploiting knowledge of the source and side information was imposed into the design.</description>
      <guid isPermaLink="false">oai:arXiv.org:2403.08411v2</guid>
      <category>cs.IT</category>
      <category>eess.SP</category>
      <category>math.IT</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Eyyup Tasci, Ezgi Ozyilkan, Oguzhan Kubilay Ulger, Elza Erkip</dc:creator>
    </item>
    <item>
      <title>Static Grouping Strategy Design for Beyond Diagonal Reconfigurable Intelligent Surfaces</title>
      <link>https://arxiv.org/abs/2403.09275</link>
      <description>arXiv:2403.09275v2 Announce Type: replace 
Abstract: Beyond diagonal reconfigurable intelligent surface (BD-RIS) extends conventional RIS through novel architectures, such as group-connected RIS, with scattering matrix not restricted to being diagonal. However, it remains unexplored how to optimally group the elements in group-connected RISs to maximize the performance while maintaining a low-complexity circuit. In this study, we propose and model BD-RIS with a static grouping strategy optimized based on the channel statistics. After formulating the corresponding problems, we design the grouping in single- and multi-user systems. Numerical results reveal the benefits of grouping optimization, i.e., up to 60% sum rate improvement, especially in highly correlated channels.</description>
      <guid isPermaLink="false">oai:arXiv.org:2403.09275v2</guid>
      <category>cs.IT</category>
      <category>eess.SP</category>
      <category>math.IT</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Matteo Nerini, Shanpu Shen, Bruno Clerckx</dc:creator>
    </item>
    <item>
      <title>A Generalization of Relative Entropy to Count Vectors and its Concentration Property</title>
      <link>https://arxiv.org/abs/2404.15867</link>
      <description>arXiv:2404.15867v2 Announce Type: replace 
Abstract: We introduce a new generalization of relative entropy to non-negative vectors with sums $\gt 1$. We show in a purely combinatorial setting, with no probabilistic considerations, that in the presence of linear constraints defining a convex polytope, a concentration phenomenon arises for this generalized relative entropy, and we quantify the concentration precisely. We also present a probabilistic formulation, and extend the concentration results to it. In addition, we provide a number of simplifications and improvements to our previous work, notably in dualizing the optimization problem, in the concentration with respect to $\ell_{\infty}$ distance, and in the relationship to generalized KL-divergence. A number of our results apply to general compact convex sets, not necessarily polyhedral.</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.15867v2</guid>
      <category>cs.IT</category>
      <category>math.IT</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Kostas N. Oikonomou</dc:creator>
    </item>
    <item>
      <title>$\alpha$-leakage by R\'{e}nyi Divergence and Sibson Mutual Information</title>
      <link>https://arxiv.org/abs/2405.00423</link>
      <description>arXiv:2405.00423v3 Announce Type: replace 
Abstract: For $\tilde{f}(t) = \exp(\frac{\alpha-1}{\alpha}t)$, this paper proposes a $\tilde{f}$-mean information gain measure. R\'{e}nyi divergence is shown to be the maximum $\tilde{f}$-mean information gain incurred at each elementary event $y$ of channel output $Y$ and Sibson mutual information is the $\tilde{f}$-mean of this $Y$-elementary information gain. Both are proposed as $\alpha$-leakage measures, indicating the most information an adversary can obtain on sensitive data. It is shown that the existing $\alpha$-leakage by Arimoto mutual information can be expressed as $\tilde{f}$-mean measures by a scaled probability. Further, Sibson mutual information is interpreted as the maximum $\tilde{f}$-mean information gain over all estimation decisions applied to channel output. This reveals that the exiting generalized Blahut-Arimoto method for computing R\'{e}nyi capacity (or Gallager's error exponent) in fact maximizes a $\tilde{f}$-mean information gain iteratively over estimation decision and channel input. This paper also derives a decomposition of $\tilde{f}$-mean information gain, analogous to the Sibson identity for R\'{e}nyi divergence.</description>
      <guid isPermaLink="false">oai:arXiv.org:2405.00423v3</guid>
      <category>cs.IT</category>
      <category>math.IT</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Ni Ding, Mohammad Amin Zarrabian, Parastoo Sadeghi</dc:creator>
    </item>
    <item>
      <title>Double Self-Sustainable Reconfigurable Intelligent Surfaces Aided Wireless Communications</title>
      <link>https://arxiv.org/abs/2405.03101</link>
      <description>arXiv:2405.03101v2 Announce Type: replace 
Abstract: A double self-sustainable reconfigurable intelligent surfaces (RISs) assisted multi-user multiple input multiple output (MIMO) system is investigated. Two RISs are equipped with energy harvesting circuit to achieve self-sustainable transmission. The aim is to minimize the transmission power at the base station (BS), while guaranteeing the quality of service (QoS) requirements of the users and meeting the power consumption requirements of the RISs. A block coordinate descent (BCD) algorithm based on the penalty-based method and successive convex approximation (SCA) is employed to alternatively optimize the active beamforming at the BS and the phase shifts, as well as amplitude coefficients of two RISs. Simulation results show that the required power consumption at the BS for the proposed double self-sustainable RISs system is significantly reduced compared to conventional RIS systems.</description>
      <guid isPermaLink="false">oai:arXiv.org:2405.03101v2</guid>
      <category>cs.IT</category>
      <category>math.IT</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Ji Wang, Suhong Luo, Yixuan Li, Wenwu Xie, Xingwang Li, Arumugam Nallanathan</dc:creator>
    </item>
  </channel>
</rss>
