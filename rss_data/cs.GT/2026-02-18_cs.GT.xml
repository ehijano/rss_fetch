<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>cs.GT updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/cs.GT</link>
    <description>cs.GT updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/cs.GT" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Thu, 19 Feb 2026 02:34:34 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Wed, 18 Feb 2026 00:00:00 -0500</pubDate>
    <skipDays>
      <day>Saturday</day>
      <day>Sunday</day>
    </skipDays>
    <item>
      <title>Autodeleveraging as Online Learning</title>
      <link>https://arxiv.org/abs/2602.15182</link>
      <description>arXiv:2602.15182v1 Announce Type: new 
Abstract: Autodeleveraging (ADL) is a last-resort loss socialization mechanism used by perpetual futures venues when liquidation and insurance buffers are insufficient to restore solvency. Despite the scale of perpetual futures markets, ADL has received limited formal treatment as a sequential control problem. This paper provides a concise formalization of ADL as online learning on a PNL-haircut domain: at each round, the venue selects a solvency budget and a set of profitable trader accounts. The profitable accounts are liquidated to cover shortfalls up to the solvency budget, with the aim of recovering exchange-wide solvency. In this model, ADL haircuts apply to positive PNL (unrealized gains), not to posted collateral principal. Using our online learning model, we provide robustness results and theoretical upper bounds on how poorly a mechanism can perform at recovering solvency. We apply our model to the October 10, 2025 Hyperliquid stress episode. The regret caused by Hyperliquid's production ADL queue is about 50\% of an upper bound on regret, calibrated to this event, while our optimized algorithm achieves about 2.6\% of the same bound. In dollar terms, the production ADL model over liquidates trader profits by up to \$51.7M. We also counterfactually evaluated algorithms inspired by our online learning framework that perform better and found that the best algorithm reduces overshoot to \$3M. Our results provide simple, implementable mechanisms for improving ADL in live perpetuals exchanges.</description>
      <guid isPermaLink="false">oai:arXiv.org:2602.15182v1</guid>
      <category>cs.GT</category>
      <category>q-fin.RM</category>
      <category>q-fin.TR</category>
      <pubDate>Wed, 18 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Tarun Chitra, Nagu Thogiti, Mauricio Jean Pieer Trujillo Ramirez, Victor Xu</dc:creator>
    </item>
    <item>
      <title>Interbank Lending Games</title>
      <link>https://arxiv.org/abs/2602.15186</link>
      <description>arXiv:2602.15186v1 Announce Type: new 
Abstract: We define and study a lending game to model the interbank money market, in which lending banks strategically allocate their cash to borrowing banks. The interest rate offered by each borrowing bank is within the interest rate corridor set by the central bank and ultimately depends on the demand and the supply of cash in the interbank market. Lending banks naturally aim to maximise the income coming from the interest repayments. In its purest form, this is an infinite-strategy game that we show to be an exact potential game which has a unique pure strategy Nash equilibrium. We then define and solve a constrained optimisation problem and propose a strongly polynomial-time algorithm to compute this Nash equilibrium. We also study some variants of best-response dynamics of this lending game, showing that they converge to the Nash equilibrium in both discrete and continuous-time scenarios.</description>
      <guid isPermaLink="false">oai:arXiv.org:2602.15186v1</guid>
      <category>cs.GT</category>
      <pubDate>Wed, 18 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Jinyun Tong, Bart de Keijzer, Haoxiang Wang, Carmine Ventre</dc:creator>
    </item>
    <item>
      <title>Equilibria in Large Position-Optimization Games</title>
      <link>https://arxiv.org/abs/2602.15225</link>
      <description>arXiv:2602.15225v1 Announce Type: new 
Abstract: We propose a general class of symmetric games called position-optimization games. Given a probability distribution $Q$ over a set of targets $\mathcal{Y}$, the $n$ players each choose a position in a space $\mathcal{X}$. A player's utility is the $Q$-mass of targets they are closest to under some proximity measure, with ties broken evenly. Our model captures Hotelling games and forecasting competitions, among other applications. We show that for sufficiently large $n$, both pure and symmetric mixed Nash equilibria exist, and moreover are extreme: all players play on a finite set of pseudo-targets $\mathcal{X}^* \subseteq \mathcal{X}$. We further show that both pure and symmetric mixed equilibria converge to the distribution $P$ on $\mathcal{X}^*$ induced by $Q$, and bound the convergence rate in $n$. The generality of our model allows us to extend and strengthen previous work in Hotelling games, and prove entirely new results in forecasting competitions and other applications.</description>
      <guid isPermaLink="false">oai:arXiv.org:2602.15225v1</guid>
      <category>cs.GT</category>
      <pubDate>Wed, 18 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Rafael Frongillo, Melody Hsu, Mary Monroe, Anish Thilagar</dc:creator>
    </item>
    <item>
      <title>Computing Perfect Bayesian Equilibria, with Application to Empirical Game-Theoretic Analysis</title>
      <link>https://arxiv.org/abs/2602.15233</link>
      <description>arXiv:2602.15233v1 Announce Type: new 
Abstract: Perfect Bayesian Equilibrium (PBE) is a refinement of the Nash equilibrium for imperfect-information extensive-form games (EFGs) that enforces consistency between the two components of a solution: agents' strategy profile describing their decisions at information sets and the belief system quantifying their uncertainty over histories within an information set. We present a scalable approach for computing a PBE of an arbitrary two-player EFG. We adopt the definition of PBE enunciated by Bonanno in 2011 using a consistency concept based on the theory of belief revision due to Alchourr\'{o}n, G\"{a}rdenfors, and Makinson. Our algorithm for finding a PBE is an adaptation of Counterfactual Regret Minimization (CFR) that minimizes the expected regret at each information set given a belief system, while maintaining the necessary consistency criteria. We prove that our algorithm is correct for two-player zero-sum games and has a reasonable slowdown in time-complexity relative to classical CFR given the additional computation needed for refinement. We also experimentally demonstrate the competent performance of PBE-CFR in terms of equilibrium quality and running time on medium-to-large non-zero-sum EFGs. Finally, we investigate the effectiveness of using PBE for strategy exploration in empirical game-theoretic analysis. Specifically, we compute PBE as a meta-strategy solver (MSS) in a tree-exploiting variant of Policy Space Response Oracles (TE-PSRO). Our experiments show that PBE as an MSS leads to higher-quality empirical EFG models with complex imperfect information structures compared to MSSs based on an unrefined Nash equilibrium.</description>
      <guid isPermaLink="false">oai:arXiv.org:2602.15233v1</guid>
      <category>cs.GT</category>
      <pubDate>Wed, 18 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Christine Konicki, Mithun Chakraborty, Michael P. Wellman</dc:creator>
    </item>
    <item>
      <title>Decision Making under Imperfect Recall: Algorithms and Benchmarks</title>
      <link>https://arxiv.org/abs/2602.15252</link>
      <description>arXiv:2602.15252v1 Announce Type: new 
Abstract: In game theory, imperfect-recall decision problems model situations in which an agent forgets information it held before. They encompass games such as the ``absentminded driver'' and team games with limited communication. In this paper, we introduce the first benchmark suite for imperfect-recall decision problems. Our benchmarks capture a variety of problem types, including ones concerning privacy in AI systems that elicit sensitive information, and AI safety via testing of agents in simulation. Across 61 problem instances generated using this suite, we evaluate the performance of different algorithms for finding first-order optimal strategies in such problems. In particular, we introduce the family of regret matching (RM) algorithms for nonlinear constrained optimization. This class of parameter-free algorithms has enjoyed tremendous success in solving large two-player zero-sum games, but, surprisingly, they were hitherto relatively unexplored beyond that setting. Our key finding is that RM algorithms consistently outperform commonly employed first-order optimizers such as projected gradient descent, often by orders of magnitude. This establishes, for the first time, the RM family as a formidable approach to large-scale constrained optimization problems.</description>
      <guid isPermaLink="false">oai:arXiv.org:2602.15252v1</guid>
      <category>cs.GT</category>
      <category>cs.AI</category>
      <category>cs.LG</category>
      <pubDate>Wed, 18 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Emanuel Tewolde, Brian Hu Zhang, Ioannis Anagnostides, Tuomas Sandholm, Vincent Conitzer</dc:creator>
    </item>
    <item>
      <title>Simultaneous Ordinal Maximin Share and Envy-Based Guarantees</title>
      <link>https://arxiv.org/abs/2602.15566</link>
      <description>arXiv:2602.15566v1 Announce Type: new 
Abstract: We study the fair allocation of indivisible goods among agents with additive valuations. The fair division literature has traditionally focused on two broad classes of fairness notions: envy-based notions and share-based notions. Within the share-based framework, most attention has been devoted to the maximin share (MMS) guarantee and its relaxations, while envy-based fairness has primarily centered on EFX and its relaxations. Recent work has shown the existence of allocations that simultaneously satisfy multiplicative approximate MMS and envy-based guarantees such as EF1 or EFX.
  Motivated by this line of research, we study for the first time the compatibility between ordinal approximations of MMS and envy-based fairness notions. In particular, we establish the existence of allocations satisfying the following combined guarantees: (i) simultaneous $1$-out-of-$\lceil 3n/2 \rceil$ MMS and EFX for ordered instances; (ii) simultaneous $1$-out-of-$\lceil 3n/2 \rceil$ MMS and EF1 for top-$n$ instances; and (iii) simultaneous $1$-out-of-$4\lceil n/3 \rceil$ MMS and EF1 for ordered instances.</description>
      <guid isPermaLink="false">oai:arXiv.org:2602.15566v1</guid>
      <category>cs.GT</category>
      <pubDate>Wed, 18 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Hannaneh Akrami, Timo Reichert</dc:creator>
    </item>
    <item>
      <title>Outer Diversity of Structured Domains</title>
      <link>https://arxiv.org/abs/2602.15708</link>
      <description>arXiv:2602.15708v1 Announce Type: new 
Abstract: An ordinal preference domain is a subset of preference orders that the voters are allowed to cast in an election. We introduce and study the notion of outer diversity of a domain and evaluate its value for a number of well-known structured domains, such as the single-peaked, single-crossing, group-separable, and Euclidean ones.</description>
      <guid isPermaLink="false">oai:arXiv.org:2602.15708v1</guid>
      <category>cs.GT</category>
      <category>cs.AI</category>
      <category>cs.MA</category>
      <pubDate>Wed, 18 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Piotr Faliszewski, Krzysztof Sornat, Stanis{\l}aw Szufa, Tomasz W\k{a}s</dc:creator>
    </item>
    <item>
      <title>Stability in Distance Preservation Games on Graphs</title>
      <link>https://arxiv.org/abs/2602.15784</link>
      <description>arXiv:2602.15784v2 Announce Type: new 
Abstract: We introduce a new class of network allocation games called graphical distance preservation games. Here, we are given a graph, called a topology, and a set of agents that need to be allocated to its vertices. Moreover, every agent has an ideal (and possibly different) distance in which to be from some of the other agents. Given an allocation of agents, each one of them suffers a cost that is the sum of the differences from the ideal distance for each agent in their subset. The goal is to decide whether there is a stable allocation of the agents, i.e., no agent would like to deviate from their location. Specifically, we consider three different stability notions: envy-freeness, swap stability, and jump stability. We perform a comprehensive study of the (parameterized) complexity of the problem in three different dimensions: the topology of the graph, the number of agents, and the structure of preferences of the agents.</description>
      <guid isPermaLink="false">oai:arXiv.org:2602.15784v2</guid>
      <category>cs.GT</category>
      <pubDate>Wed, 18 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Argyrios Deligkas, Eduard Eiben, Tiger-Lily Goldsmith, Du\v{s}an Knop, \v{S}imon Schierreich</dc:creator>
    </item>
    <item>
      <title>Distortion of Multi-Winner Elections on the Line Metric: The Polar Comparison Rule</title>
      <link>https://arxiv.org/abs/2411.13720</link>
      <description>arXiv:2411.13720v3 Announce Type: replace 
Abstract: We study the problem of minimizing metric distortion in multi-winner elections, where a committee of size $k$ is selected from a set of candidates based on voters' ordinal preferences. We assume that voters and candidates are embedded on a line metric, and social cost is determined by the underlying metric distances.
  The distortion of a voting rule is the worst-case ratio between the social cost of the elected committee and an optimal committee. Previous work has focused on the $q$-cost model, in which a voter's cost is given by the distance to their $q$th closest committee member. Here, we study the additive cost, where a voter's cost is the sum of distances to all committee members.
  We introduce the Polar Comparison Rule and analyze its distortion under utilitarian additive cost. We show that it achieves a distortion of at most $2.33$ for all committee sizes $k&gt;2$, improving upon the previously best-known upper bound of $3$. Moreover, for $k=2$ and $k=3$, we establish tight distortion bounds of $2.41$ and $2.33$, respectively. We also derive lower bounds that depend on the parity of $k$ and analyze the behavior of distortion for small and large committee sizes. Finally, we extend our results to the egalitarian additive cost.</description>
      <guid isPermaLink="false">oai:arXiv.org:2411.13720v3</guid>
      <category>cs.GT</category>
      <pubDate>Wed, 18 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Negar Babashah, Hasti Karimi, Masoud Seddighin, Golnoosh Shahkarami</dc:creator>
    </item>
    <item>
      <title>Stochastic Knapsack with Costs: On Adaptivity and Return-on-Investment</title>
      <link>https://arxiv.org/abs/2509.05956</link>
      <description>arXiv:2509.05956v2 Announce Type: replace 
Abstract: We revisit the Stochastic Knapsack problem, where a policy-maker chooses an execution order for jobs with fixed values and stochastic running-times, aiming to maximize the value completed by a deadline. Dean et al. (FOCS'04) show that simple non-adaptive policies can approximate the (highly adaptive) optimum, initiating the study of adaptivity gaps.
  We introduce an economically motivated generalization in which each job also carries an execution cost. This uncovers new applications, most notably a new and natural variant of contract design: jobs are processed by agents who choose among effort levels that induce different processing-time distributions, and the principal must decide which jobs to run and what payments induce the intended effort.
  With costs, the objective becomes mixed-sign: value from completed jobs must be balanced against costs of execution, and running a job that misses the deadline can create negative utility. This changes the algorithmic picture, and the adaptivity gap is no longer constant. We give an economic explanation: the performance of non-adaptive policies is governed by jobs' return on investment (ROI) -- utility over cost -- which can be arbitrarily small.
  We introduce a hierarchy of increasingly adaptive policies, trading off simplicity and adaptivity. We prove near-tight guarantees across the hierarchy, showing that with costs the adaptivity gap is $\Theta(\alpha)$, where $1/\alpha$ is the ROI. Higher in the hierarchy, we identify an efficiently computable policy with limited adaptivity that is approximately-optimal. Analogous to the centrality of ROI in economics, we believe our ROI-based, simple-vs-optimal approach to adaptivity may be useful for additional stochastic optimization and online problems with mixed-sign objectives.</description>
      <guid isPermaLink="false">oai:arXiv.org:2509.05956v2</guid>
      <category>cs.GT</category>
      <pubDate>Wed, 18 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Zohar Barak, Asnat Berlin, Ilan Reuven Cohen, Alon Eden, Omri Porat, Inbal Talgam-Cohen</dc:creator>
    </item>
    <item>
      <title>Scale-Invariant Regret Matching and Online Learning with Optimal Convergence: Bridging Theory and Practice in Zero-Sum Games</title>
      <link>https://arxiv.org/abs/2510.04407</link>
      <description>arXiv:2510.04407v3 Announce Type: replace 
Abstract: A considerable chasm has been looming for decades between theory and practice in zero-sum game solving through first-order methods. Although a convergence rate of $T^{-1}$ has long been established, the most effective paradigm in practice is counterfactual regret minimization (CFR), which is based on regret matching and its modern variants. In particular, the state of the art across most benchmarks is predictive regret matching$^+$ (PRM$^+$). Yet, such algorithms can exhibit slower $T^{-1/2}$ convergence even in self-play.
  In this paper, we close the gap between theory and practice. We propose a new scale-invariant and parameter-free variant of PRM$^+$, which we call IREG-PRM$^+$. We show that it achieves $T^{-1/2}$ best-iterate and $T^{-1}$ (i.e., optimal) average-iterate convergence guarantees, while also being on par or even better relative to PRM$^+$ on benchmark games. From a technical standpoint, we draw an analogy between (IREG-)PRM$^+$ and optimistic gradient descent with adaptive learning rate. Reflecting this theoretical bridge, we find that the adaptive version of optimistic gradient descent we consider performs on par with IREG-PRM$^+$. This demystifies the effectiveness of the regret matching family vis-a-vis more standard optimization techniques.
  Moreover, we extend our analysis beyond zero-sum games to a family of variational inequality problems that includes harmonic games, as well as extensive-form games with fully-mixed equilibria, via a new and intriguing connection between CFR and harmonic games. Unlike prior work in harmonic games, our algorithms do not require knowing the underlying weights by virtue of scale invariance. Under the weighted Minty condition, we show that any algorithm satisfying a scale-invariant RVU property (such as IREG-PRM$^+$) has constant regret (in self-play) and $T^{-1/2}$ iterate convergence.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.04407v3</guid>
      <category>cs.GT</category>
      <category>cs.LG</category>
      <pubDate>Wed, 18 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Brian Hu Zhang, Ioannis Anagnostides, Tuomas Sandholm</dc:creator>
    </item>
    <item>
      <title>On Minimal Achievable Quotas in Multiwinner Voting</title>
      <link>https://arxiv.org/abs/2510.19620</link>
      <description>arXiv:2510.19620v2 Announce Type: replace 
Abstract: Justified representation (JR) and extended justified representation (EJR) are well-established proportionality axioms in approval-based multiwinner voting. Both axioms are always satisfiable, but they rely on a fixed quota (typically Hare or Droop), with the Droop quota being the smallest one that guarantees existence across all instances. With this in mind, we take a step beyond the fixed-quota paradigm by studying instance-dependent proportionality notions. More specifically, we minimize the quota requirements for JR and EJR using the parameter $\alpha$. We demonstrate that all commonly studied voting rules can have an additive gap to the optimum of $\frac{k^2}{(k+1)^2}$. Moreover, we examine the computational aspects of our instance-dependent quota and prove that determining the optimal value of $\alpha$ for a given approval profile that allows some committee to satisfy $\alpha$-JR is NP-complete. To address this, we introduce an integer linear programming (ILP) formulation for computing committees that satisfy $\alpha$-JR, and we provide positive computational results in the voter interval (VI) and candidate interval (CI) domains.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.19620v2</guid>
      <category>cs.GT</category>
      <category>cs.CC</category>
      <pubDate>Wed, 18 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Patrick Becker, Fabian Frank</dc:creator>
    </item>
    <item>
      <title>Strategy-robust Online Learning in Contextual Pricing</title>
      <link>https://arxiv.org/abs/2511.19842</link>
      <description>arXiv:2511.19842v3 Announce Type: replace 
Abstract: Learning effective pricing strategies is crucial in digital marketplaces, especially when buyers' valuations are unknown and must be inferred through interaction. We study the online contextual pricing problem, where a seller observes a stream of context-valuation pairs and dynamically sets prices. Moreover, departing from traditional online learning frameworks, we consider a strategic setting in which buyers may misreport valuations to influence future prices, a challenge known as strategic overfitting (Amin et al. 2013).
  We introduce a strategy-robust notion of regret for multi-buyer online environments, capturing worst-case strategic behavior in the spirit of the Price of Anarchy. Our first contribution is a polynomial-time approximation scheme (PTAS) for learning linear pricing policies in adversarial, adaptive environments, enabled by a novel online sketching technique. Building on this result, we propose our main construction: the Sparse Update Mechanism (SUM), a simple yet effective sequential mechanism that ensures robustness to all Nash equilibria among buyers. Moreover, our construction yields a black-box reduction from online expert algorithms to strategy-robust learners.</description>
      <guid isPermaLink="false">oai:arXiv.org:2511.19842v3</guid>
      <category>cs.GT</category>
      <pubDate>Wed, 18 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Joon Suk Huh, Kirthevasan Kandasamy</dc:creator>
    </item>
    <item>
      <title>Autodeleveraging: Impossibilities and Optimization</title>
      <link>https://arxiv.org/abs/2512.01112</link>
      <description>arXiv:2512.01112v3 Announce Type: replace 
Abstract: Autodeleveraging (ADL) is a last-resort loss socialization mechanism for perpetual futures venues. It is triggered when solvency-preserving liquidations fail. Despite the dominance of perpetual futures in the crypto derivatives market, with over \$60 trillion of volume in 2024, there has been no formal study of ADL. In this paper, we provide the first rigorous model of ADL. We prove that ADL mechanisms face a fundamental \emph{trilemma}: no policy can simultaneously satisfy exchange \emph{solvency}, \emph{revenue}, and \emph{fairness} to traders. This impossibility theorem implies that as participation scales, a novel form of \emph{moral hazard} grows asymptotically, rendering `zero-loss' socialization impossible. On the positive side, we show that three classes of ADL mechanisms can optimally navigate this trilemma to provide fairness, robustness to price shocks, and maximal exchange revenue. We analyze these mechanisms on the Hyperliquid dataset from October 10, 2025, when ADL was used repeatedly to close \$2.1 billion of positions in 12 minutes. By comparing production ADL to transparent benchmark allocations, we find that Hyperliquid's production algorithm overshot the minimum trader profit haircut required to cover the shortfall. Our methodology suggests the excess profits lost by profitable traders is between \$45.0M and \$51.7M. In terms of the positions liquidated, this corresponds to roughly \$653.6M of positions being closed. This comparison also suggests that Binance overutilized ADL far more than Hyperliquid. Our results show both theoretically and empirically that optimized ADL mechanisms can dramatically reduce losses of trader profitability while maintaining exchange solvency.</description>
      <guid isPermaLink="false">oai:arXiv.org:2512.01112v3</guid>
      <category>cs.GT</category>
      <category>q-fin.RM</category>
      <category>q-fin.TR</category>
      <pubDate>Wed, 18 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Tarun Chitra</dc:creator>
    </item>
    <item>
      <title>Clone-Robust Weights in Metric Spaces: Handling Redundancy Bias for Benchmark Aggregation</title>
      <link>https://arxiv.org/abs/2502.03576</link>
      <description>arXiv:2502.03576v3 Announce Type: replace-cross 
Abstract: We are given a set of elements in a metric space. The distribution of the elements is arbitrary, possibly adversarial. Can we weigh the elements in a way that is resistant to such (adversarial) manipulations? This problem arises in various contexts. For instance, the elements could represent data points, requiring robust domain adaptation. Alternatively, they might represent tasks to be aggregated into a benchmark; or questions about personal political opinions in voting advice applications. This article introduces a theoretical framework for dealing with such problems. We propose clone-proof weighting functions as a solution concept. These functions distribute importance across elements of a set such that similar objects (``clones'') share (some of) their weights, thus avoiding a potential bias introduced by their multiplicity. Our framework extends the maximum uncertainty principle to accommodate general metric spaces and includes a set of axioms -- symmetry, continuity, and clone-proofness -- that guide the construction of weighting functions. Finally, we address the existence of weighting functions satisfying our axioms in the significant case of Euclidean spaces and propose a general method for their construction.</description>
      <guid isPermaLink="false">oai:arXiv.org:2502.03576v3</guid>
      <category>cs.LG</category>
      <category>cs.GT</category>
      <pubDate>Wed, 18 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Damien Berriaud, Roger Wattenhofer</dc:creator>
    </item>
    <item>
      <title>CONSENT: A Negotiation Framework for Leveraging User Flexibility in Vehicle-to-Building Charging under Uncertainty</title>
      <link>https://arxiv.org/abs/2601.01581</link>
      <description>arXiv:2601.01581v3 Announce Type: replace-cross 
Abstract: The growth of Electric Vehicles (EVs) creates a conflict in vehicle-to-building (V2B) settings between building operators, who face high energy costs from uncoordinated charging, and drivers, who prioritize convenience and a full charge. To resolve this, we propose a negotiation-based framework that, by design, guarantees voluntary participation, strategy-proofness, and budget feasibility. It transforms EV charging into a strategic resource by offering drivers a range of incentive-backed options for modest flexibility in their departure time or requested state of charge (SoC). Our framework is calibrated with user survey data and validated using real operational data from a commercial building and an EV manufacturer. Simulations show that our negotiation protocol creates a mutually beneficial outcome: lowering the building operator's costs by over 3.5\% compared to an optimized, non-negotiating smart charging policy, while simultaneously reducing user charging expenses by 22\% below the utility's retail energy rate. By aligning operator and EV user objectives, our framework provides a strategic bridge between energy and mobility systems, transforming EV charging from a source of operational friction into a platform for collaboration and shared savings.</description>
      <guid isPermaLink="false">oai:arXiv.org:2601.01581v3</guid>
      <category>cs.MA</category>
      <category>cs.AI</category>
      <category>cs.GT</category>
      <category>cs.SY</category>
      <category>eess.SY</category>
      <pubDate>Wed, 18 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <arxiv:DOI>10.65109/V1X2Y3Z4</arxiv:DOI>
      <dc:creator>Rishav Sen, Fangqi Liu, Jose Paolo Talusan, Ava Pettet, Yoshinori Suzue, Mark Bailey, Ayan Mukhopadhyay, Abhishek Dubey</dc:creator>
    </item>
  </channel>
</rss>
