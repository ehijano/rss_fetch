<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>cs.MS updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/cs.MS</link>
    <description>cs.MS updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/cs.MS" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Tue, 05 Aug 2025 02:34:11 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Mon, 04 Aug 2025 00:00:00 -0400</pubDate>
    <skipDays>
      <day>Saturday</day>
      <day>Sunday</day>
    </skipDays>
    <item>
      <title>Extended Abstract: Partial-encapsulate and Its Support for Floating-point Operations in ACL2</title>
      <link>https://arxiv.org/abs/2508.00015</link>
      <description>arXiv:2508.00015v1 Announce Type: cross 
Abstract: We illustrate the power of partial-encapsulate, showing how it is used in the implementation of floating-point operations in ACL2.</description>
      <guid isPermaLink="false">oai:arXiv.org:2508.00015v1</guid>
      <category>cs.LO</category>
      <category>cs.MS</category>
      <pubDate>Mon, 04 Aug 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <arxiv:DOI>10.4204/EPTCS.423.6</arxiv:DOI>
      <arxiv:journal_reference>EPTCS 423, 2025, pp. 56-59</arxiv:journal_reference>
      <dc:creator>Matt Kaufmann, J Strother Moore</dc:creator>
    </item>
    <item>
      <title>chipfiring: A Python Package for Efficient Mathematical Analysis of Chip-Firing Games on Multigraphs</title>
      <link>https://arxiv.org/abs/2508.00269</link>
      <description>arXiv:2508.00269v2 Announce Type: cross 
Abstract: This paper presents `chipfiring`, a comprehensive Python package for the mathematical analysis of chip-firing games on finite graphs. The package provides a robust toolkit for defining graphs and chip configurations (divisors), performing chip-firing operations, and analyzing fundamental properties such as winnability, linear equivalence, and divisor rank. We detail the core components of the library, including its object-oriented graph and divisor implementations, integrated Laplacian matrix computations, and an efficient implementation of Dhar's algorithm for determining the solvability of the dollar game. The `chipfiring` package is designed for researchers and students in graph theory, combinatorics, and algebraic geometry, providing essential algorithms and data structures for exploring these rich mathematical models. We describe the library's architecture, illustrate its usage with comprehensive examples, and highlight its specialized contributions compared to general-purpose graph libraries.</description>
      <guid isPermaLink="false">oai:arXiv.org:2508.00269v2</guid>
      <category>math.CO</category>
      <category>cs.CG</category>
      <category>cs.MS</category>
      <category>math.AG</category>
      <pubDate>Mon, 04 Aug 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Dhyey Dharmendrakumar Mavani, Tairan Ji, Nathan Pflueger</dc:creator>
    </item>
    <item>
      <title>DGEMM without FP64 Arithmetic -- using FP64 Emulation and FP8 Tensor Cores with Ozaki Scheme</title>
      <link>https://arxiv.org/abs/2508.00441</link>
      <description>arXiv:2508.00441v1 Announce Type: cross 
Abstract: Since AI computations require low-precision matrix multiplications, processors with enhanced performance for these operations are increasing along with the growing demand for AI computations. However, it is difficult to use these operations directly for scientific computations. The Ozaki scheme, an accurate matrix multiplication method proposed by Ozaki et al. in 2012, enables FP64 matrix multiplication (DGEMM) using low-precision floating-point operations such as FP16. The method was subsequently extended to utilize integer arithmetic. The use of integer operations reduces computational cost compared to the floating-point based approach. It has also demonstrated higher performance than hardware FP64 operations on GPUs with fast INT8 Tensor Cores for AI workloads. However, the latest hardware tends to enhance low-precision floating-point operation performance such as FP8 instead of INT8. This study revisits the utilization of low-precision floating-point operations in the Ozaki scheme, considering the latest AI hardware. Specifically, we consider the use of FP6 and FP8 Tensor Cores. Moreover, for processors that support very slow FP64 operations or do not support them at all, we consider the use of the FP64 emulation based on integer arithmetic. We also examine a new blocking strategy. We demonstrate the effectiveness of these methods by evaluating the performance of DGEMM using FP8 Tensor Cores and FP64 emulation on a Blackwell architecture GPU.</description>
      <guid isPermaLink="false">oai:arXiv.org:2508.00441v1</guid>
      <category>cs.PF</category>
      <category>cs.AR</category>
      <category>cs.MS</category>
      <pubDate>Mon, 04 Aug 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Daichi Mukunoki</dc:creator>
    </item>
  </channel>
</rss>
