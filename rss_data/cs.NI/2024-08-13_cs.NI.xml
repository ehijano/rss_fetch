<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>cs.NI updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/cs.NI</link>
    <description>cs.NI updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/cs.NI" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Wed, 14 Aug 2024 04:00:10 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Wed, 14 Aug 2024 00:00:00 -0400</pubDate>
    <skipDays>
      <day>Sunday</day>
      <day>Saturday</day>
    </skipDays>
    <item>
      <title>DiffSG: A Generative Solver for Network Optimization with Diffusion Model</title>
      <link>https://arxiv.org/abs/2408.06701</link>
      <description>arXiv:2408.06701v1 Announce Type: new 
Abstract: Diffusion generative models, famous for their performance in image generation, are popular in various cross-domain applications. However, their use in the communication community has been mostly limited to auxiliary tasks like data modeling and feature extraction. These models hold greater promise for fundamental problems in network optimization compared to traditional machine learning methods. Discriminative deep learning often falls short due to its single-step input-output mapping and lack of global awareness of the solution space, especially given the complexity of network optimization's objective functions. In contrast, diffusion generative models can consider a broader range of solutions and exhibit stronger generalization by learning parameters that describe the distribution of the underlying solution space, with higher probabilities assigned to better solutions. We propose a new framework Diffusion Model-based Solution Generation (DiffSG), which leverages the intrinsic distribution learning capabilities of diffusion generative models to learn high-quality solution distributions based on given inputs. The optimal solution within this distribution is highly probable, allowing it to be effectively reached through repeated sampling. We validate the performance of DiffSG on several typical network optimization problems, including mixed-integer non-linear programming, convex optimization, and hierarchical non-convex optimization. Our results show that DiffSG outperforms existing baselines. In summary, we demonstrate the potential of diffusion generative models in tackling complex network optimization problems and outline a promising path for their broader application in the communication community.</description>
      <guid isPermaLink="false">oai:arXiv.org:2408.06701v1</guid>
      <category>cs.NI</category>
      <category>cs.LG</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Ruihuai Liang, Bo Yang, Zhiwen Yu, Bin Guo, Xuelin Cao, M\'erouane Debbah, H. Vincent Poor, Chau Yuen</dc:creator>
    </item>
    <item>
      <title>Optimizing RPL Routing Using Tabu Search to Improve Link Stability and Energy Consumption in IoT Networks</title>
      <link>https://arxiv.org/abs/2408.06702</link>
      <description>arXiv:2408.06702v1 Announce Type: new 
Abstract: In the Internet of Things (IoT) networks, the Routing Protocol forLow-power and Lossy Networks (RPL) is a widely adopted standard due toits efficiency in managing resource-constrained and energy-limited nodes.However, persistent challenges such as high energy consumption, unstablelinks, and suboptimal routing continue to hinder network performance,affecting both the longevity of the network and the reliability of datatransmission. This paper proposes an enhanced RPL routing mechanismby integrating the Tabu Search optimization algorithm to address theseissues. The proposed approach focuses on optimizing the parent and childselection process in the RPL protocol, leveraging a composite cost func-tion that incorporates key parameters including Residual Energy, Trans-mission Energy, Distance to Sink, Hop Count, Expected TransmissionCount (ETX), and Link Stability Rate. Through extensive simulations,we demonstrate that our method significantly improves link stability, re-duces energy consumption, and enhances the packet delivery ratio, leadingto a more efficient and longer-lasting IoT network. The findings suggestthat Tabu Search can effectively balance the trade-offs inherent in IoTrouting, providing a practical solution for improving the overall perfor-mance of RPL-based networks.</description>
      <guid isPermaLink="false">oai:arXiv.org:2408.06702v1</guid>
      <category>cs.NI</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-sa/4.0/</dc:rights>
      <dc:creator>Mehran Tarif</dc:creator>
    </item>
    <item>
      <title>Rural Handover Parameter Tuning to Achieve End to End Latency Requirements of Future Railway Mobile Communication Systems</title>
      <link>https://arxiv.org/abs/2408.06957</link>
      <description>arXiv:2408.06957v1 Announce Type: new 
Abstract: GSM-R (GSM for Railways) is a 2G-based standardized ground-to-train communications system that enabled interoperability across different countries. However, as a 2G-based system, it is nearing its lifetime and therefore, it will be replaced with 5G-based Future Railway Mobile Communications System (FRMCS). FRMCS is expected to bring in new use cases that demand low latency and high reliability. However, from a mobility perspective, it is not clear how the low latency and high reliability will be achieved. This paper investigates the effect of handover procedure on latency and reliability and analyzes which use cases of FRMCS can be satisfied using baseline handover. We also sweep through different handover parameter configurations and analyze their effect on mobility performance. Then, we analyze the effect of mobility performance on packet latency and reliability. Our results show that, with baseline handover, Standard Data Communications Scenario is met and optimizing for baseline handover performance can reduce latency by up to 18.5%, indicating that optimizing for mobility performance is crucial in FRMCS.</description>
      <guid isPermaLink="false">oai:arXiv.org:2408.06957v1</guid>
      <category>cs.NI</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <dc:creator>Dogukan Atik, Murat Gursu, Fidan Mehmeti, Wolfgang Kellerer</dc:creator>
    </item>
    <item>
      <title>IRS-Assisted Lossy Communications Under Correlated Rayleigh Fading: Outage Probability Analysis and Optimization</title>
      <link>https://arxiv.org/abs/2408.06969</link>
      <description>arXiv:2408.06969v1 Announce Type: new 
Abstract: This paper focuses on an intelligent reflecting surface (IRS)-assisted lossy communication system with correlated Rayleigh fading. We analyze the correlated channel model and derive the outage probability of the system. Then, we design a deep reinforce learning (DRL) method to optimize the phase shift of IRS, in order to maximize the received signal power. Moreover, this paper presents results of the simulations conducted to evaluate the performance of the DRL-based method. The simulation results indicate that the outage probability of the considered system increases significantly with more correlated channel coefficients. Moreover, the performance gap between DRL and theoretical limit increases with higher transmit power and/or larger distortion requirement.</description>
      <guid isPermaLink="false">oai:arXiv.org:2408.06969v1</guid>
      <category>cs.NI</category>
      <category>cs.LG</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Guanchang Li, Wensheng Lin, Lixin Li, Yixuan He, Fucheng Yang, Zhu Han</dc:creator>
    </item>
    <item>
      <title>Runtime Verification Containers for Publish/Subscribe Networks</title>
      <link>https://arxiv.org/abs/2408.06380</link>
      <description>arXiv:2408.06380v1 Announce Type: cross 
Abstract: Publish/subscribe (pub/sub) networks are a cornerstone of modern distributed systems, playing a crucial role in applications like the Internet of Things (IoT) and robotics. While runtime verification techniques seem ideal for ensuring the correctness of such highly dynamic and large-scale networks, integrating runtime monitors seamlessly into real-world industrial use cases presents significant challenges. This paper studies modern containerization technology to deploy runtime verification tools to monitor publish/subscribe networks with a performance focus. Runtime verification containers are lightweight and deployable alongside other containerized publisher and subscriber participants. Each runtime verification container monitors message flow, enabling runtime verification of network behavior. We comprehensively benchmark the container-based approach using several experiments and a real-world case study from the software-defined vehicle domain.</description>
      <guid isPermaLink="false">oai:arXiv.org:2408.06380v1</guid>
      <category>cs.DC</category>
      <category>cs.NI</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Ali Mehran, Dogan Ulus</dc:creator>
    </item>
    <item>
      <title>Neural Quantile Optimization for Edge-Cloud Networking</title>
      <link>https://arxiv.org/abs/2307.05170</link>
      <description>arXiv:2307.05170v2 Announce Type: replace 
Abstract: We seek the best traffic allocation scheme for the edge-cloud computing network that satisfies constraints and minimizes the cost based on burstable billing. First, for a fixed network topology, we formulate a family of integer programming problems with random parameters describing the various traffic demands. Then, to overcome the difficulty caused by the discrete feature of the problem, we generalize the Gumbel-softmax reparameterization method to induce an unconstrained continuous optimization problem as a regularized continuation of the discrete problem. Finally, we introduce the Gumbel-softmax sampling network to solve the optimization problems via unsupervised learning. The network structure reflects the edge-cloud computing topology and is trained to minimize the expectation of the cost function for unconstrained continuous optimization problems. The trained network works as an efficient traffic allocation scheme sampler, remarkably outperforming the random strategy in feasibility and cost function value. Besides testing the quality of the output allocation scheme, we examine the generalization property of the network by increasing the time steps and the number of users. We also feed the solution to existing integer optimization solvers as initial conditions and verify the warm-starts can accelerate the short-time iteration process. The framework is general with solid performance, and the decoupled feature of the random neural networks is adequate for practical implementations.</description>
      <guid isPermaLink="false">oai:arXiv.org:2307.05170v2</guid>
      <category>cs.NI</category>
      <category>cs.AI</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Bin Du, He Zhang, Xiangle Cheng, Lei Zhang</dc:creator>
    </item>
    <item>
      <title>Generative AI for Semantic Communication: Architecture, Challenges, and Outlook</title>
      <link>https://arxiv.org/abs/2308.15483</link>
      <description>arXiv:2308.15483v4 Announce Type: replace 
Abstract: Semantic communication (SemCom) is expected to be a core paradigm in future communication networks, yielding significant benefits in terms of spectrum resource saving and information interaction efficiency. However, the existing SemCom structure is limited by the lack of context-reasoning ability and background knowledge provisioning, which, therefore, motivates us to seek the potential of incorporating generative artificial intelligence (GAI) technologies with SemCom. Recognizing GAI's powerful capability in automating and creating valuable, diverse, and personalized multimodal content, this article first highlights the principal characteristics of the combination of GAI and SemCom along with their pertinent benefits and challenges. To tackle these challenges, we further propose a novel GAI-integrated SemCom network (GAI-SCN) framework in a cloud-edge-mobile design. Specifically, by employing global and local GAI models, our GAI-SCN enables multimodal semantic content provisioning, semantic-level joint-source-channel coding, and AIGC acquisition to maximize the efficiency and reliability of semantic reasoning and resource utilization. Afterward, we present a detailed implementation workflow of GAI-SCN, followed by corresponding initial simulations for performance evaluation in comparison with two benchmarks. Finally, we discuss several open issues and offer feasible solutions to unlock the full potential of GAI-SCN.</description>
      <guid isPermaLink="false">oai:arXiv.org:2308.15483v4</guid>
      <category>cs.NI</category>
      <category>eess.IV</category>
      <category>eess.SP</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Le Xia, Yao Sun, Chengsi Liang, Lei Zhang, Muhammad Ali Imran, Dusit Niyato</dc:creator>
    </item>
    <item>
      <title>Demystifying Datapath Accelerator Enhanced Off-path SmartNIC</title>
      <link>https://arxiv.org/abs/2402.03041</link>
      <description>arXiv:2402.03041v3 Announce Type: replace 
Abstract: Network speeds grow quickly in the modern cloud, so SmartNICs are introduced to offload network processing tasks, even application logic. However, typical multicore SmartNICs such as BlueFiled-2 are only capable of processing control-plane tasks with their embedded processors that have limited memory bandwidth and computing power. On the other hand, cloud applications evolve rapidly, such that a limited number of fixed hardware engines in a SmartNIC cannot satisfy the requirements of cloud applications. Therefore, SmartNIC programmers call for a programmable datapath accelerator (DPA) to process network traffic at line rate. However, no existing work has unveiled the performance characteristics of the existing DPA. To this end, we present the first architectural characterization of the latest DPA-enhanced BlueFiled-3 (BF3) SmartNIC. Our evaluation results indicate that BF3's DPA is significantly wimpier than the off-path Arm processor and the host CPU. However, we still identify that DPA has three unique architectural characteristics that unleash the performance potential of DPA. Specifically, we demonstrate how to take advantage of DPA's three architectural characteristics regarding computing, networking, and memory subsystems. Then we propose three important guidelines for programmers to fully unleash the potential of DPA. To demonstrate the effectiveness of our approach, we conduct detailed case studies regarding each guideline. Our case study on key-value aggregation achieves up to 4.3$\times$ higher throughput by using our guidelines to optimize memory combinations.</description>
      <guid isPermaLink="false">oai:arXiv.org:2402.03041v3</guid>
      <category>cs.NI</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Xuzheng Chen, Jie Zhang, Ting Fu, Yifan Shen, Shu Ma, Kun Qian, Lingjun Zhu, Chao Shi, Yin Zhang, Ming Liu, Zeke Wang</dc:creator>
    </item>
    <item>
      <title>STX-Vote: Improving Reliability with Bit Voting in Synchronous Transmission-based IoT Networks</title>
      <link>https://arxiv.org/abs/2405.02022</link>
      <description>arXiv:2405.02022v3 Announce Type: replace 
Abstract: Industrial Internet of Things (IIoT) networks must meet strict reliability, latency, and low energy consumption requirements. However, traditional low-power wireless protocols are ineffective in finding a sweet spot for balancing these performance metrics. Recently, network flooding protocols based on Synchronous Transmissions (STX) have been proposed for better performance in reliability-critical IIoT, where simultaneous transmissions are possible without packet collisions. STX-based protocols can offer a competitive edge over routing-based protocols, particularly in dependability. However, they notably suffer from the beating effect, a physical layer phenomenon that results in sinusoidal interference across a packet and, consequently, packet loss. Thus, we introduce STX-Vote, an error correction scheme that can handle errors caused by beating effects. Importantly, we utilize transmission redundancy already inherent within STX protocols so do not incur additional on-air overhead. Through simulation, we demonstrate STX-Vote can provide a 40% increase in reliability. We subsequently implement STX-Vote on nRF52840-DK devices and perform extensive experiments. The results confirm that STX-Vote improves reliability by 25-28% for BLE 5 PHYs and 8% for IEEE 802.15.4; thus, it can complement existing error correction schemes.</description>
      <guid isPermaLink="false">oai:arXiv.org:2405.02022v3</guid>
      <category>cs.NI</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Burhanuddin Rangwala, Ava Powelson, Michael Baddeley, Israat Haque</dc:creator>
    </item>
    <item>
      <title>Generative AI for Immersive Communication: The Next Frontier in Internet-of-Senses Through 6G</title>
      <link>https://arxiv.org/abs/2404.01713</link>
      <description>arXiv:2404.01713v2 Announce Type: replace-cross 
Abstract: Over the past two decades, the Internet-of-Things (IoT) has become a transformative concept, and as we approach 2030, a new paradigm known as the Internet of Senses (IoS) is emerging. Unlike conventional Virtual Reality (VR), IoS seeks to provide multi-sensory experiences, acknowledging that in our physical reality, our perception extends far beyond just sight and sound; it encompasses a range of senses. This article explores the existing technologies driving immersive multi-sensory media, delving into their capabilities and potential applications. This exploration includes a comparative analysis between conventional immersive media streaming and a proposed use case that leverages semantic communication empowered by generative Artificial Intelligence (AI). The focal point of this analysis is the substantial reduction in bandwidth consumption by 99.93% in the proposed scheme. Through this comparison, we aim to underscore the practical applications of generative AI for immersive media. Concurrently addressing major challenges in this field, such as temporal synchronization of multiple media, ensuring high throughput, minimizing the End-to-End (E2E) latency, and robustness to low bandwidth while outlining future trajectories.</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.01713v2</guid>
      <category>cs.CL</category>
      <category>cs.AI</category>
      <category>cs.HC</category>
      <category>cs.MM</category>
      <category>cs.NI</category>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Nassim Sehad, Lina Bariah, Wassim Hamidouche, Hamed Hellaoui, Riku J\"antti, M\'erouane Debbah</dc:creator>
    </item>
  </channel>
</rss>
