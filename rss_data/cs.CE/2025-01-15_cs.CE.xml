<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>cs.CE updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/cs.CE</link>
    <description>cs.CE updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/cs.CE" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Wed, 15 Jan 2025 05:00:07 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Wed, 15 Jan 2025 00:00:00 -0500</pubDate>
    <skipDays>
      <day>Saturday</day>
      <day>Sunday</day>
    </skipDays>
    <item>
      <title>Active Learning Enhanced Surrogate Modeling of Jet Engines in JuliaSim</title>
      <link>https://arxiv.org/abs/2501.07701</link>
      <description>arXiv:2501.07701v1 Announce Type: new 
Abstract: Surrogate models are effective tools for accelerated design of complex systems. The result of a design optimization procedure using surrogate models can be used to initialize an optimization routine using the full order system. High accuracy of the surrogate model can be advantageous for fast convergence. In this work, we present an active learning approach to produce a very high accuracy surrogate model of a turbofan jet engine, that demonstrates 0.1\% relative error for all quantities of interest. We contrast this with a surrogate model produced using a more traditional brute-force data generation approach.</description>
      <guid isPermaLink="false">oai:arXiv.org:2501.07701v1</guid>
      <category>cs.CE</category>
      <pubDate>Wed, 15 Jan 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Anas Abdelrehim, Dhairya Gandhi, Sharan Yalburgi, Ashutosh Bharambe, Ranjan Anantharaman, Chris Rackauckas</dc:creator>
    </item>
    <item>
      <title>Mechanics Informatics: A paradigm for efficiently learning constitutive models</title>
      <link>https://arxiv.org/abs/2501.08314</link>
      <description>arXiv:2501.08314v1 Announce Type: new 
Abstract: Efficient and accurate learning of constitutive laws is crucial for accurately predicting the mechanical behavior of materials under complex loading conditions. Accurate model calibration hinges on a delicate interplay between the information embedded in experimental data and the parameters that define our constitutive models. The information encoded in the parameters of the constitutive model must be complemented by the information in the data used for calibration. This interplay raises fundamental questions: How can we quantify the information content of test data? How much information does a single test convey? Also, how much information is required to accurately learn a constitutive model? To address these questions, we introduce mechanics informatics, a paradigm for efficient and accurate constitutive model learning. At its core is the stress state entropy, a metric quantifying the information content of experimental data. Using this framework, we analyzed specimen geometries with varying information content for learning an anisotropic inelastic law. Specimens with limited information enabled accurate identification of a few parameters sensitive to the information in the data. Furthermore, we optimized specimen design by incorporating stress state entropy into a Bayesian optimization scheme. This led to the design of cruciform specimens with maximized entropy for accurate parameter identification. Conversely, minimizing entropy in Peirs shear specimens yielded a uniform pure shear stress state, showcasing the framework's flexibility in tailoring designs for specific experimental goals. Finally, we addressed experimental uncertainties and demonstrated the potential of transfer learning for replacing challenging testing protocols with simpler alternatives, while preserving calibration accuracy.</description>
      <guid isPermaLink="false">oai:arXiv.org:2501.08314v1</guid>
      <category>cs.CE</category>
      <pubDate>Wed, 15 Jan 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Royal C. Ihuaenyi, Wei Li, Martin Z. Bazant, Juner Zhu</dc:creator>
    </item>
    <item>
      <title>An Adaptive Collocation Point Strategy For Physics Informed Neural Networks via the QR Discrete Empirical Interpolation Method</title>
      <link>https://arxiv.org/abs/2501.07700</link>
      <description>arXiv:2501.07700v1 Announce Type: cross 
Abstract: Physics-informed neural networks (PINNs) have gained significant attention for solving forward and inverse problems related to partial differential equations (PDEs). While advancements in loss functions and network architectures have improved PINN accuracy, the impact of collocation point sampling on their performance remains underexplored. Fixed sampling methods, such as uniform random sampling and equispaced grids, can fail to capture critical regions with high solution gradients, limiting their effectiveness for complex PDEs. Adaptive methods, inspired by adaptive mesh refinement from traditional numerical methods, address this by dynamically updating collocation points during training but may overlook residual dynamics between updates, potentially losing valuable information. To overcome this limitation, we propose an adaptive collocation point selection strategy utilizing the QR Discrete Empirical Interpolation Method (QR-DEIM), a reduced-order modeling technique for efficiently approximating nonlinear functions. Our results on benchmark PDEs, including the wave, Allen-Cahn, and Burgers' equations, demonstrate that our QR-DEIM-based approach improves PINN accuracy compared to existing methods, offering a promising direction for adaptive collocation point strategies.</description>
      <guid isPermaLink="false">oai:arXiv.org:2501.07700v1</guid>
      <category>cs.LG</category>
      <category>cs.CE</category>
      <category>cs.NA</category>
      <category>math.NA</category>
      <pubDate>Wed, 15 Jan 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Adrian Celaya, David Fuentes, Beatrice Riviere</dc:creator>
    </item>
    <item>
      <title>Bridging financial gaps for infrastructure climate adaptation via integrated carbon markets</title>
      <link>https://arxiv.org/abs/2501.08004</link>
      <description>arXiv:2501.08004v1 Announce Type: cross 
Abstract: Climate physical risks pose an increasing threat to urban infrastructure, necessitating urgent climate adaptation measures to protect lives and assets. Implementing such measures, including the development of resilient infrastructure and retrofitting existing systems, demands substantial financial investment. Unfortunately, a significant financial gap remains in funding infrastructure climate adaptation, primarily due to the unprofitability stemming from the conflict between long-term returns, uncertainty, and complexity of these adaptations and the short-term profit objectives of private capital. This study suggests incentivizing private capital to bridge this financial gap through integrated carbon markets. Specifically, the framework combines carbon taxes and carbon markets to involve infrastructures and individuals in the climate mitigation phase, using the funds collected for climate adaptation. It integrates lifestyle reformation, environmental mitigation, and infrastructure adaptation to establish harmonized standards and provide continuous positive feedback to sustain the markets. It is explored how integrated carbon markets can facilitate fund collection and discuss the challenges of incorporating them into infrastructure climate adaptation. This study aims to foster collaboration between private and public capital to enable a more scientific, rational, and actionable implementation of integrated carbon markets, thus supporting financial backing for infrastructure climate adaptation.</description>
      <guid isPermaLink="false">oai:arXiv.org:2501.08004v1</guid>
      <category>econ.GN</category>
      <category>cs.CE</category>
      <category>q-fin.EC</category>
      <pubDate>Wed, 15 Jan 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Chao Li, Xing Su, Chao Fan, Jun Wang, Xiangyu Wang</dc:creator>
    </item>
    <item>
      <title>Data-driven inventory management for new products: A warm-start and adjusted Dyna-$Q$ approach</title>
      <link>https://arxiv.org/abs/2501.08109</link>
      <description>arXiv:2501.08109v1 Announce Type: cross 
Abstract: In this paper, we propose a novel reinforcement learning algorithm for inventory management of newly launched products with no or limited historical demand information. The algorithm follows the classic Dyna-$Q$ structure, balancing the model-based and model-free approaches, while accelerating the training process of Dyna-$Q$ and mitigating the model discrepancy generated by the model-based feedback. Warm-start information from the demand data of existing similar products can be incorporated into the algorithm to further stabilize the early-stage training and reduce the variance of the estimated optimal policy. Our approach is validated through a case study of bakery inventory management with real data. The adjusted Dyna-$Q$ shows up to a 23.7\% reduction in average daily cost compared with $Q$-learning, and up to a 77.5\% reduction in training time within the same horizon compared with classic Dyna-$Q$. By incorporating the warm-start information, it can be found that the adjusted Dyna-$Q$ has the lowest total cost, lowest variance in total cost, and relatively low shortage percentages among all the algorithms under a 30-day testing.</description>
      <guid isPermaLink="false">oai:arXiv.org:2501.08109v1</guid>
      <category>cs.LG</category>
      <category>cs.AI</category>
      <category>cs.CE</category>
      <pubDate>Wed, 15 Jan 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Xinyu Qu, Longxiao Liu, Wenjie Huang</dc:creator>
    </item>
    <item>
      <title>A Multi-Modal AI Copilot for Single-Cell Analysis with Instruction Following</title>
      <link>https://arxiv.org/abs/2501.08187</link>
      <description>arXiv:2501.08187v1 Announce Type: cross 
Abstract: Large language models excel at interpreting complex natural language instructions, enabling them to perform a wide range of tasks. In the life sciences, single-cell RNA sequencing (scRNA-seq) data serves as the "language of cellular biology", capturing intricate gene expression patterns at the single-cell level. However, interacting with this "language" through conventional tools is often inefficient and unintuitive, posing challenges for researchers. To address these limitations, we present InstructCell, a multi-modal AI copilot that leverages natural language as a medium for more direct and flexible single-cell analysis. We construct a comprehensive multi-modal instruction dataset that pairs text-based instructions with scRNA-seq profiles from diverse tissues and species. Building on this, we develop a multi-modal cell language architecture capable of simultaneously interpreting and processing both modalities. InstructCell empowers researchers to accomplish critical tasks-such as cell type annotation, conditional pseudo-cell generation, and drug sensitivity prediction-using straightforward natural language commands. Extensive evaluations demonstrate that InstructCell consistently meets or exceeds the performance of existing single-cell foundation models, while adapting to diverse experimental conditions. More importantly, InstructCell provides an accessible and intuitive tool for exploring complex single-cell data, lowering technical barriers and enabling deeper biological insights.</description>
      <guid isPermaLink="false">oai:arXiv.org:2501.08187v1</guid>
      <category>cs.CL</category>
      <category>cs.AI</category>
      <category>cs.CE</category>
      <category>cs.HC</category>
      <category>cs.LG</category>
      <category>q-bio.CB</category>
      <pubDate>Wed, 15 Jan 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Yin Fang, Xinle Deng, Kangwei Liu, Ningyu Zhang, Jingyang Qian, Penghui Yang, Xiaohui Fan, Huajun Chen</dc:creator>
    </item>
    <item>
      <title>Deep learning reveals key predictors of thermal conductivity in covalent organic frameworks</title>
      <link>https://arxiv.org/abs/2409.06457</link>
      <description>arXiv:2409.06457v2 Announce Type: replace 
Abstract: The thermal conductivity of covalent organic frameworks (COFs), an emerging class of nanoporous polymeric materials, is crucial for many applications, yet the link between their structure and thermal properties remains poorly understood. Analysis of a dataset containing over 2,400 COFs reveals that conventional features such as density, pore size, void fraction, and surface area do not reliably predict thermal conductivity. To address this, an attention-based machine learning model was trained, accurately predicting thermal conductivities even for structures outside the training set. The attention mechanism was then utilized to investigate the model's success. The analysis identified dangling molecular branches as a key predictor of thermal conductivity, a discovery supported by feature importance assessments conducted on regression models. These findings indicate that COFs with dangling functional groups exhibit lower thermal transfer capabilities. Molecular dynamics simulations support this observation, revealing significant mismatches in the vibrational density of states due to the presence of dangling branches.</description>
      <guid isPermaLink="false">oai:arXiv.org:2409.06457v2</guid>
      <category>cs.CE</category>
      <pubDate>Wed, 15 Jan 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Prakash Thakolkaran, Yiwen Zheng, Yaqi Guo, Aniruddh Vashisth, Siddhant Kumar</dc:creator>
    </item>
    <item>
      <title>Can AI Help with Your Personal Finances?</title>
      <link>https://arxiv.org/abs/2412.19784</link>
      <description>arXiv:2412.19784v4 Announce Type: replace-cross 
Abstract: In recent years, Large Language Models (LLMs) have emerged as a transformative development in artificial intelligence (AI), drawing significant attention from industry and academia. Trained on vast datasets, these sophisticated AI systems exhibit impressive natural language processing and content generation capabilities. This paper explores the potential of LLMs to address key challenges in personal finance, focusing on the United States. We evaluate several leading LLMs, including OpenAI's ChatGPT, Google's Gemini, Anthropic's Claude, and Meta's Llama, to assess their effectiveness in providing accurate financial advice on topics such as mortgages, taxes, loans, and investments. Our findings show that while these models achieve an average accuracy rate of approximately 70%, they also display notable limitations in certain areas. Specifically, LLMs struggle to provide accurate responses for complex financial queries, with performance varying significantly across different topics. Despite these limitations, the analysis reveals notable improvements in newer versions of these models, highlighting their growing utility for individuals and financial advisors. As these AI systems continue to evolve, their potential for advancing AI-driven applications in personal finance becomes increasingly promising.</description>
      <guid isPermaLink="false">oai:arXiv.org:2412.19784v4</guid>
      <category>cs.AI</category>
      <category>cs.CE</category>
      <category>cs.LG</category>
      <category>econ.GN</category>
      <category>q-fin.EC</category>
      <pubDate>Wed, 15 Jan 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <arxiv:DOI>10.1080/00036846.2025.2450384</arxiv:DOI>
      <dc:creator>Oudom Hean, Utsha Saha, Binita Saha</dc:creator>
    </item>
  </channel>
</rss>
