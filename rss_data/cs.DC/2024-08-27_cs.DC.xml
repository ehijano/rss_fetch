<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>cs.DC updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/cs.DC</link>
    <description>cs.DC updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/cs.DC" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Wed, 28 Aug 2024 04:00:23 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Wed, 28 Aug 2024 00:00:00 -0400</pubDate>
    <skipDays>
      <day>Sunday</day>
      <day>Saturday</day>
    </skipDays>
    <item>
      <title>A sparsity-aware distributed-memory algorithm for sparse-sparse matrix multiplication</title>
      <link>https://arxiv.org/abs/2408.14558</link>
      <description>arXiv:2408.14558v1 Announce Type: new 
Abstract: Multiplying two sparse matrices (SpGEMM) is a common computational primitive used in many areas including graph algorithms, bioinformatics, algebraic multigrid solvers, and randomized sketching. Distributed-memory parallel algorithms for SpGEMM have mainly focused on sparsity-oblivious approaches that use 2D and 3D partitioning. Sparsity-aware 1D algorithms can theoretically reduce communication by not fetching nonzeros of the sparse matrices that do not participate in the multiplication.
  Here, we present a distributed-memory 1D SpGEMM algorithm and implementation. It uses MPI RDMA operations to mitigate the cost of packing/unpacking submatrices for communication, and it uses a block fetching strategy to avoid excessive fine-grained messaging. Our results show that our 1D implementation outperforms state-of-the-art 2D and 3D implementations within CombBLAS for many configurations, inputs, and use cases, while remaining conceptually simpler.</description>
      <guid isPermaLink="false">oai:arXiv.org:2408.14558v1</guid>
      <category>cs.DC</category>
      <pubDate>Wed, 28 Aug 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Yuxi Hong, Aydin Buluc</dc:creator>
    </item>
    <item>
      <title>Scalable, reproducible, and cost-effective processing of large-scale medical imaging datasets</title>
      <link>https://arxiv.org/abs/2408.14611</link>
      <description>arXiv:2408.14611v1 Announce Type: new 
Abstract: Curating, processing, and combining large-scale medical imaging datasets from national studies is a non-trivial task due to the intense computation and data throughput required, variability of acquired data, and associated financial overhead. Existing platforms or tools for large-scale data curation, processing, and storage have difficulty achieving a viable cost-to-scale ratio of computation speed for research purposes, either being too slow or too expensive. Additionally, management and consistency of processing large data in a team-driven manner is a non-trivial task. We design a BIDS-compliant method for an efficient and robust data processing pipeline of large-scale diffusion-weighted and T1-weighted MRI data compatible with low-cost, high-efficiency computing systems. Our method accomplishes automated querying of data available for processing and process running in a consistent and reproducible manner that has long-term stability, while using heterogenous low-cost computational resources and storage systems for efficient processing and data transfer. We demonstrate how our organizational structure permits efficiency in a semi-automated data processing pipeline and show how our method is comparable in processing time to cloud-based computation while being almost 20 times more cost-effective. Our design allows for fast data throughput speeds and low latency to reduce the time for data transfer between storage servers and computation servers, achieving an average of 0.60 Gb/s compared to 0.33 Gb/s for using cloud-based processing methods. The design of our workflow engine permits quick process running while maintaining flexibility to adapt to newly acquired data.</description>
      <guid isPermaLink="false">oai:arXiv.org:2408.14611v1</guid>
      <category>cs.DC</category>
      <category>cs.DB</category>
      <pubDate>Wed, 28 Aug 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Michael E. Kim, Karthik Ramadass, Chenyu Gao, Praitayini Kanakaraj, Nancy R. Newlin, Gaurav Rudravaram, Kurt G. Schilling, Blake E. Dewey, Derek Archer, Timothy J. Hohman, Zhiyuan Li, Shunxing Bao, Bennett A. Landman, Nazirah Mohd Khairi</dc:creator>
    </item>
    <item>
      <title>Bandwidth-Aware and Overlap-Weighted Compression for Communication-Efficient Federated Learning</title>
      <link>https://arxiv.org/abs/2408.14736</link>
      <description>arXiv:2408.14736v1 Announce Type: new 
Abstract: Current data compression methods, such as sparsification in Federated Averaging (FedAvg), effectively enhance the communication efficiency of Federated Learning (FL). However, these methods encounter challenges such as the straggler problem and diminished model performance due to heterogeneous bandwidth and non-IID (Independently and Identically Distributed) data. To address these issues, we introduce a bandwidth-aware compression framework for FL, aimed at improving communication efficiency while mitigating the problems associated with non-IID data. First, our strategy dynamically adjusts compression ratios according to bandwidth, enabling clients to upload their models at a close pace, thus exploiting the otherwise wasted time to transmit more data. Second, we identify the non-overlapped pattern of retained parameters after compression, which results in diminished client update signals due to uniformly averaged weights. Based on this finding, we propose a parameter mask to adjust the client-averaging coefficients at the parameter level, thereby more closely approximating the original updates, and improving the training convergence under heterogeneous environments. Our evaluations reveal that our method significantly boosts model accuracy, with a maximum improvement of 13% over the uncompressed FedAvg. Moreover, it achieves a $3.37\times$ speedup in reaching the target accuracy compared to FedAvg with a Top-K compressor, demonstrating its effectiveness in accelerating convergence with compression. The integration of common compression techniques into our framework further establishes its potential as a versatile foundation for future cross-device, communication-efficient FL research, addressing critical challenges in FL and advancing the field of distributed machine learning.</description>
      <guid isPermaLink="false">oai:arXiv.org:2408.14736v1</guid>
      <category>cs.DC</category>
      <category>cs.LG</category>
      <pubDate>Wed, 28 Aug 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <arxiv:DOI>10.1145/3673038.3673142</arxiv:DOI>
      <dc:creator>Zichen Tang, Junlin Huang, Rudan Yan, Yuxin Wang, Zhenheng Tang, Shaohuai Shi, Amelie Chi Zhou, Xiaowen Chu</dc:creator>
    </item>
    <item>
      <title>Partition Detection in Byzantine Networks</title>
      <link>https://arxiv.org/abs/2408.14814</link>
      <description>arXiv:2408.14814v1 Announce Type: new 
Abstract: Detecting and handling network partitions is a fundamental requirement of distributed systems. Although existing partition detection methods in arbitrary graphs tolerate unreliable networks, they either assume that all nodes are correct or that a limited number of nodes might crash. In particular, Byzantine behaviors are out of the scope of these algorithms despite Byzantine fault tolerance being an active research topic for important problems such as consensus. Moreover, Byzantinetolerant protocols, such as broadcast or consensus, always rely on the assumption of connected networks. This paper addresses the problem of detecting partition in Byzantine networks (without connectivity assumption). We present a novel algorithm, which we call NECTAR, that safely detects partitioned and possibly partitionable networks and prove its correctness. NECTAR allows all correct nodes to detect whether a network could suffer from Byzantine nodes. We evaluate NECTAR's performance and compare it to two existing baselines using up to 100 nodes running real code, on various realistic topologies. Our results confirm that NECTAR maintains a 100% accuracy while the accuracy of the various existing baselines decreases by at least 40% as soon as one participant is Byzantine. Although NECTAR's network cost increases with the number of nodes and decreases with the network's diameter, it does not go above around 500KB in the worst cases.</description>
      <guid isPermaLink="false">oai:arXiv.org:2408.14814v1</guid>
      <category>cs.DC</category>
      <pubDate>Wed, 28 Aug 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <arxiv:DOI>10.1109/ICDCS60910.2024.00022</arxiv:DOI>
      <arxiv:journal_reference>2024 IEEE 44th International Conference on Distributed Computing Systems (ICDCS), Jul 2024, Jersey City, France. pp.139-150</arxiv:journal_reference>
      <dc:creator>Y\'erom-David Bromberg (IRISA, UR), J\'er\'emie Decouchant (TU Delft), Manon Sourisseau (IRISA, UR), Fran\c{c}ois Ta\"iani (IRISA, UR)</dc:creator>
    </item>
    <item>
      <title>SLA Conceptual Model for IoT Applications</title>
      <link>https://arxiv.org/abs/2408.15013</link>
      <description>arXiv:2408.15013v1 Announce Type: new 
Abstract: Since SLAs specify the contractual terms that are formally used between consumers and providers, there is a need to aggregate QoS requirements from the perspectives of Clouds, networks, and devices to deliver the promised IoT functionalities. Therefore, the main objective of this chapter is to provide a conceptual model of SLA for the IoT as well as rich vocabularies to describe the QoS and domain-specific configuration parameters of the IoT on an end-to-end basis. We first propose a conceptual model that identifies the main concepts that play a role in specifying end-to-end SLAs. Then, we identify some of the most common QoS metrics and configuration parameters related to each concept. We evaluated the proposed conceptual model using a goal-oriented approach, and the participants in the study reported a high level of satisfaction regarding the proposed conceptual model and its ability to capture main concepts in a general way.</description>
      <guid isPermaLink="false">oai:arXiv.org:2408.15013v1</guid>
      <category>cs.DC</category>
      <category>cs.ET</category>
      <category>cs.NI</category>
      <pubDate>Wed, 28 Aug 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <arxiv:DOI>10.1049/PBPC027E_ch5</arxiv:DOI>
      <arxiv:journal_reference>Managing Internet of Things Applications across Edge and Cloud Data Centres, IET, 2024</arxiv:journal_reference>
      <dc:creator>Awatif Alqahtani, Ellis Solaiman, Rajiv Ranjan</dc:creator>
    </item>
    <item>
      <title>IoT Monitoring with Blockchain: Generating Smart Contracts from Service Level Agreements</title>
      <link>https://arxiv.org/abs/2408.15016</link>
      <description>arXiv:2408.15016v1 Announce Type: new 
Abstract: A Service Level Agreement (SLA) is a commitment between a client and provider that assures the quality of service (QoS) a client can expect to receive when purchasing a service. However, evidence of SLA violations in Internet of Things (IoT) service monitoring data can be manipulated by the provider or consumer, resulting in an issue of trust between contracted parties. The following research aims to explore the use of blockchain technology in monitoring IoT systems using smart contracts so that SLA violations captured are irrefutable amongst service providers and clients. The research focuses on the development of a Java library that is capable of generating a smart contract from a given SLA. A smart contract generated by this library is validated through a mock scenario presented in the form of a Remote Patient Monitoring IoT system. In this scenario, the findings demonstrate a 100 percent success rate in capturing all emulated violations.</description>
      <guid isPermaLink="false">oai:arXiv.org:2408.15016v1</guid>
      <category>cs.DC</category>
      <category>cs.CR</category>
      <category>cs.ET</category>
      <category>cs.NI</category>
      <pubDate>Wed, 28 Aug 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <arxiv:DOI>10.1049/PBPC027E_ch7</arxiv:DOI>
      <arxiv:journal_reference>Managing Internet of Things Applications across Edge and Cloud Data Centres, IET, 2024</arxiv:journal_reference>
      <dc:creator>Adam Booth, Awatif Alqahtani, Ellis Solaiman</dc:creator>
    </item>
    <item>
      <title>On the Encoding Process in Decentralized Systems</title>
      <link>https://arxiv.org/abs/2408.15203</link>
      <description>arXiv:2408.15203v1 Announce Type: new 
Abstract: We consider the problem of encoding information in a system of N=K+R processors that operate in a decentralized manner, i.e., without a central processor which orchestrates the operation. The system involves K source processors, each holding some data modeled as a vector over a finite field. The remaining R processors are sinks, and each of which requires a linear combination of all data vectors. These linear combinations are distinct from one sink processor to another, and are specified by a generator matrix of a systematic linear error correcting code. To capture the communication cost of decentralized encoding, we adopt a linear network model in which the process proceeds in consecutive communication rounds. In every round, every processor sends and receives one message through each one of its p ports. Moreover, inspired by linear network coding literature, we allow processors to transfer linear combinations of their own data and previously received data. We propose a framework that addresses the decentralized encoding problem on two levels. On the universal level, we provide a solution to the decentralized encoding problem for any possible linear code. On the specific level, we further optimize our solution towards systematic Reed-Solomon codes, as well as their variant, Lagrange codes, for their prevalent use in coded storage and computation systems. Our solutions are based on a newly-defined collective communication operation we call all-to-all encode.</description>
      <guid isPermaLink="false">oai:arXiv.org:2408.15203v1</guid>
      <category>cs.DC</category>
      <category>cs.IT</category>
      <category>math.IT</category>
      <pubDate>Wed, 28 Aug 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Canran Wang, Netanel Raviv</dc:creator>
    </item>
    <item>
      <title>Adaptive Resolution Inference (ARI): Energy-Efficient Machine Learning for Internet of Things</title>
      <link>https://arxiv.org/abs/2408.14528</link>
      <description>arXiv:2408.14528v1 Announce Type: cross 
Abstract: The implementation of machine learning in Internet of Things devices poses significant operational challenges due to limited energy and computation resources. In recent years, significant efforts have been made to implement simplified ML models that can achieve reasonable performance while reducing computation and energy, for example by pruning weights in neural networks, or using reduced precision for the parameters and arithmetic operations. However, this type of approach is limited by the performance of the ML implementation, i.e., by the loss for example in accuracy due to the model simplification. In this article, we present adaptive resolution inference (ARI), a novel approach that enables to evaluate new tradeoffs between energy dissipation and model performance in ML implementations. The main principle of the proposed approach is to run inferences with reduced precision (quantization) and use the margin over the decision threshold to determine if either the result is reliable, or the inference must run with the full model. The rationale is that quantization only introduces small deviations in the inference scores, such that if the scores have a sufficient margin over the decision threshold, it is unlikely that the full model would have a different result. Therefore, we can run the quantized model first, and only when the scores do not have a sufficient margin, the full model is run. This enables most inferences to run with the reduced precision model and only a small fraction requires the full model, so significantly reducing computation and energy while not affecting model performance. The proposed ARI approach is presented, analyzed in detail, and evaluated using different data sets for floating-point and stochastic computing implementations. The results show that ARI can significantly reduce the energy for inference in different configurations with savings between 40% and 85%.</description>
      <guid isPermaLink="false">oai:arXiv.org:2408.14528v1</guid>
      <category>cs.LG</category>
      <category>cs.DC</category>
      <pubDate>Wed, 28 Aug 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <arxiv:DOI>10.1109/JIOT.2023.3339623</arxiv:DOI>
      <arxiv:journal_reference>IEEE Internet of Things Journal 2023 Volume:11, Issue:8</arxiv:journal_reference>
      <dc:creator>Ziheng Wang, Pedro Reviriego, Farzad Niknia, Javier Conde, Shanshan Liu, Fabrizio Lombardi</dc:creator>
    </item>
    <item>
      <title>PPVF: An Efficient Privacy-Preserving Online Video Fetching Framework with Correlated Differential Privacy</title>
      <link>https://arxiv.org/abs/2408.14735</link>
      <description>arXiv:2408.14735v1 Announce Type: cross 
Abstract: Online video streaming has evolved into an integral component of the contemporary Internet landscape. Yet, the disclosure of user requests presents formidable privacy challenges. As users stream their preferred online videos, their requests are automatically seized by video content providers, potentially leaking users' privacy.
  Unfortunately, current protection methods are not well-suited to preserving user request privacy from content providers while maintaining high-quality online video services. To tackle this challenge, we introduce a novel Privacy-Preserving Video Fetching (PPVF) framework, which utilizes trusted edge devices to pre-fetch and cache videos, ensuring the privacy of users' requests while optimizing the efficiency of edge caching. More specifically, we design PPVF with three core components: (1) \textit{Online privacy budget scheduler}, which employs a theoretically guaranteed online algorithm to select non-requested videos as candidates with assigned privacy budgets. Alternative videos are chosen by an online algorithm that is theoretically guaranteed to consider both video utilities and available privacy budgets. (2) \textit{Noisy video request generator}, which generates redundant video requests (in addition to original ones) utilizing correlated differential privacy to obfuscate request privacy. (3) \textit{Online video utility predictor}, which leverages federated learning to collaboratively evaluate video utility in an online fashion, aiding in video selection in (1) and noise generation in (2). Finally, we conduct extensive experiments using real-world video request traces from Tencent Video. The results demonstrate that PPVF effectively safeguards user request privacy while upholding high video caching performance.</description>
      <guid isPermaLink="false">oai:arXiv.org:2408.14735v1</guid>
      <category>cs.MM</category>
      <category>cs.CR</category>
      <category>cs.DC</category>
      <pubDate>Wed, 28 Aug 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Xianzhi Zhang, Yipeng Zhou, Di Wu, Quan Z. Sheng, Miao Hu, Linchang Xiao</dc:creator>
    </item>
    <item>
      <title>CoopASD: Cooperative Machine Anomalous Sound Detection with Privacy Concerns</title>
      <link>https://arxiv.org/abs/2408.14753</link>
      <description>arXiv:2408.14753v1 Announce Type: cross 
Abstract: Machine anomalous sound detection (ASD) has emerged as one of the most promising applications in the Industrial Internet of Things (IIoT) due to its unprecedented efficacy in mitigating risks of malfunctions and promoting production efficiency. Previous works mainly investigated the machine ASD task under centralized settings. However, developing the ASD system under decentralized settings is crucial in practice, since the machine data are dispersed in various factories and the data should not be explicitly shared due to privacy concerns. To enable these factories to cooperatively develop a scalable ASD model while preserving their privacy, we propose a novel framework named CoopASD, where each factory trains an ASD model on its local dataset, and a central server aggregates these local models periodically. We employ a pre-trained model as the backbone of the ASD model to improve its robustness and develop specialized techniques to stabilize the model under a completely non-iid and domain shift setting. Compared with previous state-of-the-art (SOTA) models trained in centralized settings, CoopASD showcases competitive results with negligible degradation of 0.08%. We also conduct extensive ablation studies to demonstrate the effectiveness of CoopASD.</description>
      <guid isPermaLink="false">oai:arXiv.org:2408.14753v1</guid>
      <category>cs.SD</category>
      <category>cs.AI</category>
      <category>cs.DC</category>
      <category>eess.AS</category>
      <pubDate>Wed, 28 Aug 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Anbai Jiang, Yuchen Shi, Pingyi Fan, Wei-Qiang Zhang, Jia Liu</dc:creator>
    </item>
    <item>
      <title>DRL-Based Federated Self-Supervised Learning for Task Offloading and Resource Allocation in ISAC-Enabled Vehicle Edge Computing</title>
      <link>https://arxiv.org/abs/2408.14831</link>
      <description>arXiv:2408.14831v1 Announce Type: cross 
Abstract: Intelligent Transportation Systems (ITS) leverage Integrated Sensing and Communications (ISAC) to enhance data exchange between vehicles and infrastructure in the Internet of Vehicles (IoV). This integration inevitably increases computing demands, risking real-time system stability. Vehicle Edge Computing (VEC) addresses this by offloading tasks to Road Side Unit (RSU), ensuring timely services. Our previous work FLSimCo algorithm, which uses local resources for Federated Self-Supervised Learning (SSL), though vehicles often can't complete all iterations task. Our improved algorithm offloads partial task to RSU and optimizes energy consumption by adjusting transmission power, CPU frequency, and task assignment ratios, balancing local and RSU-based training. Meanwhile, setting an offloading threshold further prevents inefficiencies. Simulation results show that the enhanced algorithm reduces energy consumption, improves offloading efficiency and the accuracy of Federated SSL.</description>
      <guid isPermaLink="false">oai:arXiv.org:2408.14831v1</guid>
      <category>cs.LG</category>
      <category>cs.DC</category>
      <category>cs.NI</category>
      <pubDate>Wed, 28 Aug 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Xueying Gu, Qiong Wu, Pingyi Fan, Nan Cheng, Wen Chen, Khaled B. Letaief</dc:creator>
    </item>
    <item>
      <title>Faster Cycle Detection in the Congested Clique</title>
      <link>https://arxiv.org/abs/2408.15132</link>
      <description>arXiv:2408.15132v1 Announce Type: cross 
Abstract: We provide a fast distributed algorithm for detecting $h$-cycles in the \textsf{Congested Clique} model, whose running time decreases as the number of $h$-cycles in the graph increases. In undirected graphs, constant-round algorithms are known for cycles of even length. Our algorithm greatly improves upon the state of the art for odd values of $h$. Moreover, our running time applies also to directed graphs, in which case the improvement is for all values of $h$. Further, our techniques allow us to obtain a triangle detection algorithm in the quantum variant of this model, which is faster than prior work.
  A key technical contribution we develop to obtain our fast cycle detection algorithm is a new algorithm for computing the product of many pairs of small matrices in parallel, which may be of independent interest.</description>
      <guid isPermaLink="false">oai:arXiv.org:2408.15132v1</guid>
      <category>cs.DS</category>
      <category>cs.DC</category>
      <pubDate>Wed, 28 Aug 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Keren Censor-Hillel, Tomer Even, Virginia Vassilevska Williams</dc:creator>
    </item>
    <item>
      <title>Oblivious Robots Performing Different Tasks on Grid Without Knowing their Team Members</title>
      <link>https://arxiv.org/abs/2210.00567</link>
      <description>arXiv:2210.00567v2 Announce Type: replace 
Abstract: Two fundamental problems of distributed computing are Gathering and Arbitrary pattern formation (\textsc{Apf}). These two tasks are different in nature as in gathering robots meet at a point but in \textsc{Apf} robots form a fixed pattern in distinct positions.
  In most of the current literature on swarm robot algorithms, it is assumed that all robots in the system perform one single task together. Two teams of oblivious robots deployed in the same system and different teams of robots performing two different works simultaneously where no robot knows the team of another robot is a new concept in the literature introduced by Bhagat et al. [ICDCN'2020].
  In this work, a swarm of silent and oblivious robots are deployed on an infinite grid under an asynchronous scheduler. The robots do not have access to any global coordinates. Some of the robots are given input of an arbitrary but unique pattern. The set of robots with the given pattern is assigned the task of forming the given pattern on the grid. The remaining robots are assigned with the task of gathering to a vertex of the grid (not fixed from earlier and not any point where a robot that is forming a pattern terminates). Each robot knows to which team it belongs, but can not recognize the team of another robot. Considering weak multiplicity detection, a distributed algorithm is presented in this paper which leads the robots with the input pattern into forming it and other robots into gathering on a vertex of the grid on which no other robot forming the pattern, terminates.</description>
      <guid isPermaLink="false">oai:arXiv.org:2210.00567v2</guid>
      <category>cs.DC</category>
      <pubDate>Wed, 28 Aug 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Satakshi Ghosh, Avisek Sharma, Pritam Goswami, Buddhadeb Sau</dc:creator>
    </item>
    <item>
      <title>Styx: Transactional Stateful Functions on Streaming Dataflows</title>
      <link>https://arxiv.org/abs/2312.06893</link>
      <description>arXiv:2312.06893v3 Announce Type: replace 
Abstract: Developing stateful cloud applications, such as low-latency workflows and microservices with strict consistency requirements, remains arduous for programmers. The Stateful Functions-as-a-Service (SFaaS) paradigm aims to serve these use cases. However, existing approaches either provide serializable transactional guarantees at the level of individual functions, or separate application logic from the state and use inefficient transactional protocols. These design choices increase the execution latency, limiting the adoption of SFaaS systems.
  In this paper, we present Styx, a novel SFaaS runtime that executes serializable transactions across functions with exactly-once guarantees. Styx extends a deterministic transactional protocol to support an arbitrary call graph of stateful functions. It introduces a transaction-execution acknowledgment scheme that allows tracking a transactional workflow's SFaaS calls, guaranteeing atomicity and exactly-once processing. Finally, Styx features a function-execution caching mechanism and early transactional commit replies for optimized performance. Experiments with the YCSB-T, TPC-C, and Deathstar benchmarks show that Styx outperforms state-of-the-art approaches by achieving at least one order of magnitude higher throughput while exhibiting near-linear scalability and low latency.</description>
      <guid isPermaLink="false">oai:arXiv.org:2312.06893v3</guid>
      <category>cs.DC</category>
      <category>cs.DB</category>
      <pubDate>Wed, 28 Aug 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Kyriakos Psarakis, George Siachamis, George Christodoulou, Marios Fragkoulis, Asterios Katsifodimos</dc:creator>
    </item>
    <item>
      <title>Compressed Federated Reinforcement Learning with a Generative Model</title>
      <link>https://arxiv.org/abs/2404.10635</link>
      <description>arXiv:2404.10635v5 Announce Type: replace 
Abstract: Reinforcement learning has recently gained unprecedented popularity, yet it still grapples with sample inefficiency. Addressing this challenge, federated reinforcement learning (FedRL) has emerged, wherein agents collaboratively learn a single policy by aggregating local estimations. However, this aggregation step incurs significant communication costs. In this paper, we propose CompFedRL, a communication-efficient FedRL approach incorporating both \textit{periodic aggregation} and (direct/error-feedback) compression mechanisms. Specifically, we consider compressed federated $Q$-learning with a generative model setup, where a central server learns an optimal $Q$-function by periodically aggregating compressed $Q$-estimates from local agents. For the first time, we characterize the impact of these two mechanisms (which have remained elusive) by providing a finite-time analysis of our algorithm, demonstrating strong convergence behaviors when utilizing either direct or error-feedback compression. Our bounds indicate improved solution accuracy concerning the number of agents and other federated hyperparameters while simultaneously reducing communication costs. To corroborate our theory, we also conduct in-depth numerical experiments to verify our findings, considering Top-$K$ and Sparsified-$K$ sparsification operators.</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.10635v5</guid>
      <category>cs.DC</category>
      <category>cs.LG</category>
      <category>cs.MA</category>
      <pubDate>Wed, 28 Aug 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Ali Beikmohammadi, Sarit Khirirat, Sindri Magn\'usson</dc:creator>
    </item>
    <item>
      <title>HPAC-ML: A Programming Model for Embedding ML Surrogates in Scientific Applications</title>
      <link>https://arxiv.org/abs/2407.18352</link>
      <description>arXiv:2407.18352v2 Announce Type: replace 
Abstract: Recent advancements in Machine Learning (ML) have substantially improved its predictive and computational abilities, offering promising opportunities for surrogate modeling in scientific applications. By accurately approximating complex functions with low computational cost, ML-based surrogates can accelerate scientific applications by replacing computationally intensive components with faster model inference. However, integrating ML models into these applications remains a significant challenge, hindering the widespread adoption of ML surrogates as an approximation technique in modern scientific computing.
  We propose an easy-to-use directive-based programming model that enables developers to seamlessly describe the use of ML models in scientific applications. The runtime support, as instructed by the programming model, performs data assimilation using the original algorithm and can replace the algorithm with model inference. Our evaluation across five benchmarks, testing over 5000 ML models, shows up to 83.6x speed improvements with minimal accuracy loss (as low as 0.01 RMSE).</description>
      <guid isPermaLink="false">oai:arXiv.org:2407.18352v2</guid>
      <category>cs.DC</category>
      <pubDate>Wed, 28 Aug 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Zane Fink, Konstantinos Parasyris, Praneet Rathi, Giorgis Georgakoudis, Harshitha Menon, Peer-Timo Bremer</dc:creator>
    </item>
    <item>
      <title>Fast Matrix Multiplications for Lookup Table-Quantized LLMs</title>
      <link>https://arxiv.org/abs/2407.10960</link>
      <description>arXiv:2407.10960v2 Announce Type: replace-cross 
Abstract: The deployment of large language models (LLMs) is often constrained by memory bandwidth, where the primary bottleneck is the cost of transferring model parameters from the GPU's global memory to its registers. When coupled with custom kernels that fuse the dequantization and matmul operations, weight-only quantization can thus enable faster inference by reducing the amount of memory movement. However, developing high-performance kernels for weight-quantized LLMs presents substantial challenges, especially when the weights are compressed to non-evenly-divisible bit widths (e.g., 3 bits) with non-uniform, lookup table (LUT) quantization. This paper describes FLUTE, a flexible lookup table engine for LUT-quantized LLMs, which uses offline restructuring of the quantized weight matrix to minimize bit manipulations associated with unpacking, and vectorization and duplication of the lookup table to mitigate shared memory bandwidth constraints. At batch sizes &lt; 32 and quantization group size of 128 (typical in LLM inference), the FLUTE kernel can be 2-4x faster than existing GEMM kernels. As an application of FLUTE, we explore a simple extension to lookup table-based NormalFloat quantization and apply it to quantize LLaMA3 to various configurations, obtaining competitive quantization performance against strong baselines while obtaining an end-to-end throughput increase of 1.5 to 2 times.</description>
      <guid isPermaLink="false">oai:arXiv.org:2407.10960v2</guid>
      <category>cs.LG</category>
      <category>cs.CL</category>
      <category>cs.DC</category>
      <pubDate>Wed, 28 Aug 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Han Guo, William Brandon, Radostin Cholakov, Jonathan Ragan-Kelley, Eric P. Xing, Yoon Kim</dc:creator>
    </item>
  </channel>
</rss>
