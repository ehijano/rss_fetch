<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>cs.ET updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/cs.ET</link>
    <description>cs.ET updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/cs.ET" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Fri, 15 Aug 2025 04:01:21 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Fri, 15 Aug 2025 00:00:00 -0400</pubDate>
    <skipDays>
      <day>Saturday</day>
      <day>Sunday</day>
    </skipDays>
    <item>
      <title>zERExtractor:An Automated Platform for Enzyme-Catalyzed Reaction Data Extraction from Scientific Literature</title>
      <link>https://arxiv.org/abs/2508.09995</link>
      <description>arXiv:2508.09995v1 Announce Type: cross 
Abstract: The rapid expansion of enzyme kinetics literature has outpaced the curation capabilities of major biochemical databases, creating a substantial barrier to AI-driven modeling and knowledge discovery. We present zERExtractor, an automated and extensible platform for comprehensive extraction of enzyme-catalyzed reaction and activity data from scientific literature. zERExtractor features a unified, modular architecture that supports plug-and-play integration of state-of-the-art models, including large language models (LLMs), as interchangeable components, enabling continuous system evolution alongside advances in AI. Our pipeline combines domain-adapted deep learning, advanced OCR, semantic entity recognition, and prompt-driven LLM modules, together with human expert corrections, to extract kinetic parameters (e.g., kcat, Km), enzyme sequences, substrate SMILES, experimental conditions, and molecular diagrams from heterogeneous document formats. Through active learning strategies integrating AI-assisted annotation, expert validation, and iterative refinement, the system adapts rapidly to new data sources. We also release a large benchmark dataset comprising over 1,000 annotated tables and 5,000 biological fields from 270 P450-related enzymology publications. Benchmarking demonstrates that zERExtractor consistently outperforms existing baselines in table recognition (Acc 89.9%), molecular image interpretation (up to 99.1%), and relation extraction (accuracy 94.2%). zERExtractor bridges the longstanding data gap in enzyme kinetics with a flexible, plugin-ready framework and high-fidelity extraction, laying the groundwork for future AI-powered enzyme modeling and biochemical knowledge discovery.</description>
      <guid isPermaLink="false">oai:arXiv.org:2508.09995v1</guid>
      <category>q-bio.BM</category>
      <category>cs.ET</category>
      <category>cs.LG</category>
      <pubDate>Fri, 15 Aug 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Rui Zhou, Haohui Ma, Tianle Xin, Lixin Zou, Qiuyue Hu, Hongxi Cheng, Mingzhi Lin, Jingjing Guo, Sheng Wang, Guoqing Zhang, Yanjie Wei, Liangzhen Zheng</dc:creator>
    </item>
    <item>
      <title>An Intelligent Infrastructure as a Foundation for Modern Science</title>
      <link>https://arxiv.org/abs/2508.10051</link>
      <description>arXiv:2508.10051v1 Announce Type: cross 
Abstract: Infrastructure shapes societies and scientific discovery. Traditional scientific infrastructure, often static and fragmented, leads to issues like data silos, lack of interoperability and reproducibility, and unsustainable short-lived solutions. Our current technical inability and social reticence to connect and coordinate scientific research and engineering leads to inefficiencies and impedes progress. With AI technologies changing how we interact with the world around us, there is an opportunity to transform scientific processes. Neuroscience's exponential growth of multimodal and multiscale data, and urgent clinical relevance demand an infrastructure itself learns, coordinates, and improves. Using neuroscience as a stress test, this perspective argues for a paradigm shift: infrastructure must evolve into a dynamic, AI-aligned ecosystem to accelerate science. Building on several existing principles for data, collective benefit, and digital repositories, I recommend operational guidelines for implementing them to create this dynamic ecosystem, aiming to foster a decentralized, self-learning, and self-correcting system where humans and AI can collaborate seamlessly. Addressing the chronic underfunding of scientific infrastructure, acknowledging diverse contributions beyond publications, and coordinating global efforts are critical steps for this transformation. By prioritizing an intelligent infrastructure as a central scientific instrument for knowledge generation, we can overcome current limitations, accelerate discovery, ensure reproducibility and ethical practices, and ultimately translate neuroscientific understanding into tangible societal benefits, setting a blueprint for other scientific domains.</description>
      <guid isPermaLink="false">oai:arXiv.org:2508.10051v1</guid>
      <category>q-bio.NC</category>
      <category>cs.ET</category>
      <pubDate>Fri, 15 Aug 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Satrajit S. Ghosh</dc:creator>
    </item>
    <item>
      <title>Approximating Entanglement Based on Abstract Interpretation</title>
      <link>https://arxiv.org/abs/2508.10056</link>
      <description>arXiv:2508.10056v1 Announce Type: cross 
Abstract: Entanglement is a fundamental property of quantum systems, essential for non-trivial quantum programs. Identifying when qubits become entangled is critical for circuit optimization, and for arguing for the correctness of quantum algorithms. This paper presents a static analysis method for approximating entanglement by extending an already existing abstract interpretation, thus avoiding the exponential slowdown of an exact analysis. The approach is shown to be sound and an implementation is provided in Standard ML with linear-time scalability.</description>
      <guid isPermaLink="false">oai:arXiv.org:2508.10056v1</guid>
      <category>quant-ph</category>
      <category>cs.ET</category>
      <pubDate>Fri, 15 Aug 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Aske Nord Raahauge, Martin Bom Marchioro, Rasmus Ross Nylandsted</dc:creator>
    </item>
    <item>
      <title>Improving watermelon (Citrullus lanatus) disease classification with generative artificial intelligence (GenAI)-based synthetic and real-field images via a custom EfficientNetV2-L model</title>
      <link>https://arxiv.org/abs/2508.10156</link>
      <description>arXiv:2508.10156v1 Announce Type: cross 
Abstract: The current advancements in generative artificial intelligence (GenAI) models have paved the way for new possibilities for generating high-resolution synthetic images, thereby offering a promising alternative to traditional image acquisition for training computer vision models in agriculture. In the context of crop disease diagnosis, GenAI models are being used to create synthetic images of various diseases, potentially facilitating model creation and reducing the dependency on resource-intensive in-field data collection. However, limited research has been conducted on evaluating the effectiveness of integrating real with synthetic images to improve disease classification performance. Therefore, this study aims to investigate whether combining a limited number of real images with synthetic images can enhance the prediction accuracy of an EfficientNetV2-L model for classifying watermelon \textit{(Citrullus lanatus)} diseases. The training dataset was divided into five treatments: H0 (only real images), H1 (only synthetic images), H2 (1:1 real-to-synthetic), H3 (1:10 real-to-synthetic), and H4 (H3 + random images to improve variability and model generalization). All treatments were trained using a custom EfficientNetV2-L architecture with enhanced fine-tuning and transfer learning techniques. Models trained on H2, H3, and H4 treatments demonstrated high precision, recall, and F1-score metrics. Additionally, the weighted F1-score increased from 0.65 (on H0) to 1.00 (on H3-H4) signifying that the addition of a small number of real images with a considerable volume of synthetic images improved model performance and generalizability. Overall, this validates the findings that synthetic images alone cannot adequately substitute for real images; instead, both must be used in a hybrid manner to maximize model performance for crop disease classification.</description>
      <guid isPermaLink="false">oai:arXiv.org:2508.10156v1</guid>
      <category>cs.CV</category>
      <category>cs.AI</category>
      <category>cs.ET</category>
      <pubDate>Fri, 15 Aug 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Nitin Rai, Nathan S. Boyd, Gary E. Vallad, Arnold W. Schumann</dc:creator>
    </item>
    <item>
      <title>SynSpill: Improved Industrial Spill Detection With Synthetic Data</title>
      <link>https://arxiv.org/abs/2508.10171</link>
      <description>arXiv:2508.10171v1 Announce Type: cross 
Abstract: Large-scale Vision-Language Models (VLMs) have transformed general-purpose visual recognition through strong zero-shot capabilities. However, their performance degrades significantly in niche, safety-critical domains such as industrial spill detection, where hazardous events are rare, sensitive, and difficult to annotate. This scarcity -- driven by privacy concerns, data sensitivity, and the infrequency of real incidents -- renders conventional fine-tuning of detectors infeasible for most industrial settings.
  We address this challenge by introducing a scalable framework centered on a high-quality synthetic data generation pipeline. We demonstrate that this synthetic corpus enables effective Parameter-Efficient Fine-Tuning (PEFT) of VLMs and substantially boosts the performance of state-of-the-art object detectors such as YOLO and DETR. Notably, in the absence of synthetic data (SynSpill dataset), VLMs still generalize better to unseen spill scenarios than these detectors. When SynSpill is used, both VLMs and detectors achieve marked improvements, with their performance becoming comparable.
  Our results underscore that high-fidelity synthetic data is a powerful means to bridge the domain gap in safety-critical applications. The combination of synthetic generation and lightweight adaptation offers a cost-effective, scalable pathway for deploying vision systems in industrial environments where real data is scarce/impractical to obtain.
  Project Page: https://synspill.vercel.app</description>
      <guid isPermaLink="false">oai:arXiv.org:2508.10171v1</guid>
      <category>cs.CV</category>
      <category>cs.ET</category>
      <pubDate>Fri, 15 Aug 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Aaditya Baranwal, Abdul Mueez, Jason Voelker, Guneet Bhatia, Shruti Vyas</dc:creator>
    </item>
    <item>
      <title>Training Spatial Ability in Virtual Reality</title>
      <link>https://arxiv.org/abs/2508.10195</link>
      <description>arXiv:2508.10195v1 Announce Type: cross 
Abstract: Background: Spatial reasoning has been identified as a critical skill for success in STEM. Unfortunately, under-represented groups often have lower incoming spatial ability. Courses that improve spatial skills exist but are not widely used. Virtual reality (VR) has been suggested as a possible tool for teaching spatial reasoning since students are more accurate and complete spatial tasks more quickly in three dimensions. However, no prior work has developed or evaluated a fully-structured VR spatial skills course. Objectives: We seek to assess the effectiveness of teaching spatial reasoning in VR, both in isolation as a structured training curriculum and also in comparison to traditional methods. Methods: We adapted three modules of an existing pencil-and-paper course to VR, leveraging educational scaffolding and real-time feedback in the design. We evaluated our three-week course in a study with $n=24$ undergraduate introductory STEM students, capturing both quantitative spatial ability gains (using pre- and post test scores on validated assessments) and qualitative insights (from a post-study questionnaire). We also compared our VR course to an offering of a baseline non-VR course (using data collected in a previous study). Results and Conclusions: Students who took our VR course had significant spatial ability gains. Critically, we find no significant difference in outcomes between our VR course (3 meetings of 120 minutes each) and a baseline pencil and paper course (10 meetings of 90 minutes each), suggesting that spatial reasoning can be very efficiently taught in VR. We observed cybersickness at lower rates than are generally reported and most students reported enjoying learning in VR.</description>
      <guid isPermaLink="false">oai:arXiv.org:2508.10195v1</guid>
      <category>cs.HC</category>
      <category>cs.ET</category>
      <pubDate>Fri, 15 Aug 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Yiannos Demetriou, Manasvi Parikh, Sara Eskandari, Westley Weimer, Madeline Endres</dc:creator>
    </item>
    <item>
      <title>Simulating Mass-Dependent Decoherence in Quantum Computers: Baseline Signatures for Testing Gravity-Induced Collapse</title>
      <link>https://arxiv.org/abs/2508.10590</link>
      <description>arXiv:2508.10590v1 Announce Type: cross 
Abstract: We present a quantum computing simulation study of mass-dependent decoherence models inspired by Penrose's gravity-induced collapse hypothesis. According to objective reduction (OR) theory, quantum superpositions become unstable when the gravitational self-energy difference between branches exceeds a certain threshold, leading to a collapse time $\tau \approx \hbar / E_G$. In this work, we implement a mass-dependent dephasing noise channel, $p(m) = 1 - e^{-k m^{\alpha}}$, within the Qiskit AerSimulator, where $m$ is a proxy for the effective mass of a superposition, mapped to circuit parameters such as the number of entangled qubits or branch size. We apply this model to three canonical quantum computing experiments: GHZ state parity measurements, branch-mass entanglement tests, and Grover's search to generate distinctive collapse signatures that differ qualitatively from constant-rate dephasing. The resulting patterns serve as a baseline reference: if future hardware experiments exhibit the same scaling trends under ideal isolation, this could indicate a contribution from mass-dependent collapse processes. Conversely, deviation toward constant-noise behaviour would suggest the absence of such gravitationally induced effects. Our results provide a reproducible protocol and reference for using quantum computers as potential testbeds for probing fundamental questions in quantum mechanics.</description>
      <guid isPermaLink="false">oai:arXiv.org:2508.10590v1</guid>
      <category>quant-ph</category>
      <category>cs.ET</category>
      <category>physics.comp-ph</category>
      <pubDate>Fri, 15 Aug 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Viswak R Balaji, Samuel Punch</dc:creator>
    </item>
    <item>
      <title>Molecule Mixture Detection and Alphabet Design for Non-linear, Cross-reactive Receiver Arrays in MC</title>
      <link>https://arxiv.org/abs/2508.10856</link>
      <description>arXiv:2508.10856v1 Announce Type: cross 
Abstract: Air-based molecular communication (MC) has the potential to be one of the first MC systems to be deployed in real-world applications, enabled by existing sensor technologies such as metal-oxide semi-conductor (MOS) sensors. However, commercially available sensors usually exhibit non-linear and cross-reactive behavior, contrary to the idealizing assumptions about linear and perfectly molecule type-specific sensing often made in the MC literature. To address this gap, we propose a detector for molecule mixture communication with a general non-linear, cross-reactive receiver (RX) array that performs approximate maximum likelihood detection on the sensor outputs. Additionally, we introduce an algorithm for the design of mixture alphabets that accounts for the RX characteristics. We evaluate our detector and alphabet design algorithm through simulations that are based on measurements reported for two commercial MOS sensors. Our simulations demonstrate that the proposed detector achieves similar symbol error rates as data-driven methods without requiring large numbers of training samples and that the alphabet design algorithm outperforms methods that do not account for the RX characteristics. Since the proposed detector and alphabet design algorithm are also applicable to other chemical sensors, they pave the way for reliable air-based MC.</description>
      <guid isPermaLink="false">oai:arXiv.org:2508.10856v1</guid>
      <category>eess.SP</category>
      <category>cs.ET</category>
      <pubDate>Fri, 15 Aug 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Bastian Heinlein, Kaikai Zhu, S\"umeyye Carkit-Yilmaz, Sebastian Lotter, Helene M. Loos, Andrea Buettner, Yansha Deng, Robert Schober, Vahid Jamali</dc:creator>
    </item>
    <item>
      <title>Bootstrapping, Autonomous Testing, and Initialization System for Si/SiGe Multi-quantum Dot Devices</title>
      <link>https://arxiv.org/abs/2412.07676</link>
      <description>arXiv:2412.07676v3 Announce Type: replace-cross 
Abstract: Semiconductor quantum dot (QD) devices have become central to advancements in spin-based quantum computing. However, the increasing complexity of modern QD devices makes calibration and control -- particularly at elevated temperatures -- a bottleneck to progress, highlighting the need for robust and scalable autonomous solutions. A major hurdle arises from trapped charges within the oxide layers, which induce random offset voltage shifts on gate electrodes, with a standard deviation of approximately 83~\si{\milli\volt} of variation within state-of-the-art present-day devices. Efficient characterization and tuning of large arrays of QD qubits depend on choices of automated protocols. Here, we introduce a physically intuitive framework for a bootstrapping, autonomous testing, and initialization system (BATIS) designed to streamline QD device evaluation and calibration. BATIS navigates high-dimensional gate voltage spaces, automating essential steps such as leakage testing, formation of all current channels, and gate characterization in the presence of trapped charges. For forming the current channels, BATIS follows a non-standard approach that requires a single set of measurements regardless of the number of channels. Demonstrated at $1.3$~\si{\kelvin} on a quad-QD Si/Si$_x$Ge$_{1-x}$ device, BATIS eliminates the need for deep cryogenic environments during initial device diagnostics, significantly enhancing scalability and reducing setup times. By requiring only minimal prior knowledge of the device architecture, BATIS represents a platform-agnostic solution, adaptable to various QD systems, which bridges a critical gap in QD autotuning.</description>
      <guid isPermaLink="false">oai:arXiv.org:2412.07676v3</guid>
      <category>cond-mat.mes-hall</category>
      <category>cs.CV</category>
      <category>cs.ET</category>
      <category>quant-ph</category>
      <pubDate>Fri, 15 Aug 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Tyler J. Kovach, Daniel Schug, M. A. Wolfe, E. R. MacQuarrie, Patrick J. Walsh, Owen M. Eskandari, Jared Benson, Mark Friesen, M. A. Eriksson, Justyna P. Zwolak</dc:creator>
    </item>
    <item>
      <title>Hallucination vs interpretation: rethinking accuracy and precision in AI-assisted data extraction for knowledge synthesis</title>
      <link>https://arxiv.org/abs/2508.09458</link>
      <description>arXiv:2508.09458v2 Announce Type: replace-cross 
Abstract: Knowledge syntheses (literature reviews) are essential to health professions education (HPE), consolidating findings to advance theory and practice. However, they are labor-intensive, especially during data extraction. Artificial Intelligence (AI)-assisted extraction promises efficiency but raises concerns about accuracy, making it critical to distinguish AI 'hallucinations' (fabricated content) from legitimate interpretive differences. We developed an extraction platform using large language models (LLMs) to automate data extraction and compared AI to human responses across 187 publications and 17 extraction questions from a published scoping review. AI-human, human-human, and AI-AI consistencies were measured using interrater reliability (categorical) and thematic similarity ratings (open-ended). Errors were identified by comparing extracted responses to source publications. AI was highly consistent with humans for concrete, explicitly stated questions (e.g., title, aims) and lower for questions requiring subjective interpretation or absent in text (e.g., Kirkpatrick's outcomes, study rationale). Human-human consistency was not higher than AI-human and showed the same question-dependent variability. Discordant AI-human responses (769/3179 = 24.2%) were mostly due to interpretive differences (18.3%); AI inaccuracies were rare (1.51%), while humans were nearly three times more likely to state inaccuracies (4.37%). Findings suggest AI variability depends more on interpretability than hallucination. Repeating AI extraction can identify interpretive complexity or ambiguity, refining processes before human review. AI can be a transparent, trustworthy partner in knowledge synthesis, though caution is needed to preserve critical human insights.</description>
      <guid isPermaLink="false">oai:arXiv.org:2508.09458v2</guid>
      <category>cs.HC</category>
      <category>cs.AI</category>
      <category>cs.ET</category>
      <pubDate>Fri, 15 Aug 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Xi Long, Christy Boscardin, Lauren A. Maggio, Joseph A. Costello, Ralph Gonzales, Rasmyah Hammoudeh, Ki Lai, Yoon Soo Park, Brian C. Gin</dc:creator>
    </item>
  </channel>
</rss>
