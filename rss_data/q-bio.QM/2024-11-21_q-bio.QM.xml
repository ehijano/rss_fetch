<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>q-bio.QM updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/q-bio.QM</link>
    <description>q-bio.QM updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/q-bio.QM" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Thu, 21 Nov 2024 05:00:36 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Thu, 21 Nov 2024 00:00:00 -0500</pubDate>
    <skipDays>
      <day>Saturday</day>
      <day>Sunday</day>
    </skipDays>
    <item>
      <title>Cancer incidence estimation from mortality data: a validation study within a population-based cancer registry</title>
      <link>https://arxiv.org/abs/2411.12784</link>
      <description>arXiv:2411.12784v1 Announce Type: new 
Abstract: We assessed the validity of one of the most frequently used methods to estimate cancer incidence, on the basis of cancer mortality data and the incidence-to-mortality ratio IMR, the IMR method. Using the previous 15 year cancer mortality time series, we derived the expected yearly number of cancer cases in the period 2004 to 2013 for six cancer sites for each sex. Generalized linear mixed models, including a polynomial function for the year of death and smoothing splines for age, were adjusted. Models were fitted under a Bayesian framework based on Markov chain Monte Carlo methods. The IMR method was applied to five scenarios reflecting different assumptions regarding the behavior of the IMR. We compared incident cases estimated with the IMR method to observed cases diagnosed in 2004 to 2013 in Granada. A goodness-of-fit GOF indicator was formulated to determine the best estimation scenario. The relative differences between the observed and predicted numbers of cancer cases were less than 10 percent for most cancer sites. The constant assumption for the IMR trend provided the best GOF for colon, rectal, lung, bladder, and stomach cancers in men and colon, rectum, breast, and corpus uteri in women.</description>
      <guid isPermaLink="false">oai:arXiv.org:2411.12784v1</guid>
      <category>q-bio.QM</category>
      <pubDate>Thu, 21 Nov 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <arxiv:DOI>10.1186/s12963-021-00248-1</arxiv:DOI>
      <arxiv:journal_reference>Population Health Metrics, Volume 19, 18, 2021</arxiv:journal_reference>
      <dc:creator>Daniel Redondo-S\'anchez, Miguel Rodr\'iguez-Barranco, Alberto Ameijide, Francisco J. Alonso, Pablo Fern\'andez-Navarro, Jose Juan Jim\'enez-Mole\'on, Mar\'ia-Jos\'e S\'anchez</dc:creator>
    </item>
    <item>
      <title>Estimating the tails of the spectrum of the Hessian of the log-likelihood for \textit{ab-initio} single-particle reconstruction in electron cryomicroscopy</title>
      <link>https://arxiv.org/abs/2411.13263</link>
      <description>arXiv:2411.13263v1 Announce Type: new 
Abstract: Electron cryomicroscopy (cryo-EM) is a technique in structural biology used to reconstruct accurate volumetric maps of molecules. One step of the cryo-EM pipeline involves solving an inverse-problem. This inverse-problem, referred to as \textit{ab-initio} single-particle reconstruction, takes as input a collection of 2d-images -- each a projection of a molecule from an unknown viewing-angle -- and attempts to reconstruct the 3d-volume representing the underlying molecular density.
  Most methods for solving this inverse-problem search for a solution which optimizes a posterior likelihood of generating the observed image-data, given the reconstructed volume. Within this framework, it is natural to study the Hessian of the log-likelihood: the eigenvectors and eigenvalues of the Hessian determine how the likelihood changes with respect to perturbations in the solution, and can give insight into the sensitivity of the solution to aspects of the input.
  In this paper we describe a simple strategy for estimating the smallest eigenvalues and eigenvectors (i.e., the `softest modes') of the Hessian of the log-likelihood for the \textit{ab-initio} single-particle reconstruction problem. This strategy involves rewriting the log-likelihood as a 3d-integral. This interpretation holds in the low-noise limit, as well as in many practical scenarios which allow for noise-marginalization.
  Once we have estimated the softest modes, we can use them to perform many kinds of sensitivity analysis. For example, we can determine which parts of the reconstructed volume are trustworthy, and which are unreliable, and how this unreliability might depend on the data-set and the imaging parameters. We believe that this kind of analysis can be used alongside more traditional strategies for sensitivity analysis, as well as in other applications, such as free-energy estimation.</description>
      <guid isPermaLink="false">oai:arXiv.org:2411.13263v1</guid>
      <category>q-bio.QM</category>
      <pubDate>Thu, 21 Nov 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Aaditya V. Rangan, Wai-Shing Tang, Pilar Cossio, Kexin Zhang, Nikolaus Grigorieff</dc:creator>
    </item>
    <item>
      <title>NPGPT: Natural Product-Like Compound Generation with GPT-based Chemical Language Models</title>
      <link>https://arxiv.org/abs/2411.12886</link>
      <description>arXiv:2411.12886v1 Announce Type: cross 
Abstract: Natural products are substances produced by organisms in nature and often possess biological activity and structural diversity. Drug development based on natural products has been common for many years. However, the intricate structures of these compounds present challenges in terms of structure determination and synthesis, particularly compared to the efficiency of high-throughput screening of synthetic compounds. In recent years, deep learning-based methods have been applied to the generation of molecules. In this study, we trained chemical language models on a natural product dataset and generated natural product-like compounds. The results showed that the distribution of the compounds generated was similar to that of natural products. We also evaluated the effectiveness of the generated compounds as drug candidates. Our method can be used to explore the vast chemical space and reduce the time and cost of drug discovery of natural products.</description>
      <guid isPermaLink="false">oai:arXiv.org:2411.12886v1</guid>
      <category>q-bio.BM</category>
      <category>cs.LG</category>
      <category>q-bio.QM</category>
      <category>stat.ML</category>
      <pubDate>Thu, 21 Nov 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Koh Sakano, Kairi Furui, Masahito Ohue</dc:creator>
    </item>
    <item>
      <title>A Real-Time Suite of Biological Cell Image Analysis Software for Computers, Smartphones, and Smart Glasses, Suitable for Resource-Constrained Computing</title>
      <link>https://arxiv.org/abs/2407.15735</link>
      <description>arXiv:2407.15735v4 Announce Type: replace 
Abstract: Introduction: Methods for personalizing medical treatment are the focal point of contemporary clinical research. In cancer care, for instance, we can analyze the effects of therapies at the level of individual cells. Complete characterization of treatment efficacy and evaluation of why some individuals respond to specific regimens, whereas others do not, requires additional approaches to genetic sequencing at single time points. Methods for the continuous analysis of changes in phenotype, such as morphology and motion tracking of cellular proteins and organelles over time frames spanning the minute-hour scales, can provide important insight to patient treatment options. The integration of measurements of intracellular dynamics and the contribution of multiple genetic pathways in degenerative diseases is vital for the development of biomarkers for the early detection of pathogenesis and therapy efficacy.
  Methods: We have developed a software suite (DataSet Tracker) for real-time analysis designed to run on computers, smartphones, and smart glasses hardware and suitable for resource-constrained, on-the-fly computing in microscopes without internet connectivity; a demo is available for viewing at datasetanalysis.com.
  Results: Our objective is to present the community with an integrated, easy to use by all, tool for resolving the complex dynamics of the cytoskeletal meshworks, intracytoplasmic membranous networks, and vesicle trafficking. It is our goal to have this integrated tool approved for use in the clinical practice.</description>
      <guid isPermaLink="false">oai:arXiv.org:2407.15735v4</guid>
      <category>q-bio.QM</category>
      <pubDate>Thu, 21 Nov 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Alexandre Matov</dc:creator>
    </item>
    <item>
      <title>Decomposing force fields as flows on graphs reconstructed from stochastic trajectories</title>
      <link>https://arxiv.org/abs/2409.07479</link>
      <description>arXiv:2409.07479v3 Announce Type: replace-cross 
Abstract: Disentangling irreversible and reversible forces from random fluctuations is a challenging problem in the analysis of stochastic trajectories measured from real-world dynamical systems. We present an approach to approximate the dynamics of a stationary Langevin process as a discrete-state Markov process evolving over a graph-representation of phase-space, reconstructed from stochastic trajectories. Next, we utilise the analogy of the Helmholtz-Hodge decomposition of an edge-flow on a contractible simplicial complex with the associated decomposition of a stochastic process into its irreversible and reversible parts. This allows us to decompose our reconstructed flow and to differentiate between the irreversible currents and reversible gradient flows underlying the stochastic trajectories. We validate our approach on a range of solvable and nonlinear systems and apply it to derive insight into the dynamics of flickering red-blood cells and healthy and arrhythmic heartbeats. In particular, we capture the difference in irreversible circulating currents between healthy and passive cells and healthy and arrhythmic heartbeats. Our method breaks new ground at the interface of data-driven approaches to stochastic dynamics and graph signal processing, with the potential for further applications in the analysis of biological experiments and physiological recordings. Finally, it prompts future analysis of the convergence of the Helmholtz-Hodge decomposition in discrete and continuous spaces.</description>
      <guid isPermaLink="false">oai:arXiv.org:2409.07479v3</guid>
      <category>cond-mat.stat-mech</category>
      <category>math.DS</category>
      <category>physics.data-an</category>
      <category>q-bio.QM</category>
      <pubDate>Thu, 21 Nov 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Ram\'on Nartallo-Kaluarachchi, Paul Expert, David Beers, Alexander Strang, Morten L. Kringelbach, Renaud Lambiotte, Alain Goriely</dc:creator>
    </item>
  </channel>
</rss>
