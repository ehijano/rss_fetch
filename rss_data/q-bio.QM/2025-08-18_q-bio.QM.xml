<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>q-bio.QM updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/q-bio.QM</link>
    <description>q-bio.QM updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/q-bio.QM" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Tue, 19 Aug 2025 04:00:43 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Tue, 19 Aug 2025 00:00:00 -0400</pubDate>
    <skipDays>
      <day>Saturday</day>
      <day>Sunday</day>
    </skipDays>
    <item>
      <title>BeeNet: Reconstructing Flower Shapes from Electric Fields using Deep Learning</title>
      <link>https://arxiv.org/abs/2508.11724</link>
      <description>arXiv:2508.11724v1 Announce Type: new 
Abstract: Arthropods, including pollinators, respond to environmental electrical fields. Here, we show that electric field information can be decoded to reconstruct environmental features. We develop an algorithm capable of inferring the shapes of polarisable flowers from the electric field generated by a nearby charged bee. We simulated electric fields arising from bee flower interactions for flowers with varying petal geometries. These simulated data were used to train a deep learning UNet model to recreate petal shapes. The model accurately reconstructed diverse flower shapes including more complex flower shapes not included in training. Reconstruction performance peaked at an optimal bee flower distance, indicating distance-dependent encoding of shape information. These findings show that electroreception can impart rich spatial detail, offering insights into arthropod environmental perception.</description>
      <guid isPermaLink="false">oai:arXiv.org:2508.11724v1</guid>
      <category>q-bio.QM</category>
      <category>cs.CV</category>
      <pubDate>Tue, 19 Aug 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Jake Turley, Ryan A. Palmer, Isaac V. Chenchiah, Daniel Robert</dc:creator>
    </item>
    <item>
      <title>On the Importance of Behavioral Nuances: Amplifying Non-Obvious Motor Noise Under True Empirical Considerations May Lead to Briefer Assays and Faster Classification Processes</title>
      <link>https://arxiv.org/abs/2508.12742</link>
      <description>arXiv:2508.12742v1 Announce Type: new 
Abstract: There is a tradeoff between attaining statistical power with large, difficult to gather data sets, and producing highly scalable assays that register brief data samples. Often, as grand-averaging techniques a priori assume normally-distributed parameters and linear, stationary processes in biorhythmic, time series data, important information is lost, averaged out as gross data. We developed an affective computing platform that enables taking brief data samples while maintaining personalized statistical power. This is achieved by combining a new data type derived from the micropeaks present in time series data registered from brief (5-second-long) face videos with recent advances in AI-driven face-grid estimation methods. By adopting geometric and nonlinear dynamical systems approaches to analyze the kinematics, especially the speed data, the new methods capture all facial micropeaks. These include as well the nuances of different affective micro expressions. We offer new ways to differentiate dynamical and geometric patterns present in autistic individuals from those found more commonly in neurotypical development.</description>
      <guid isPermaLink="false">oai:arXiv.org:2508.12742v1</guid>
      <category>q-bio.QM</category>
      <category>cs.CV</category>
      <category>cs.LG</category>
      <category>eess.SP</category>
      <category>nlin.CD</category>
      <pubDate>Tue, 19 Aug 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Theodoros Bermperidis, Joe Vero, Elizabeth B Torres</dc:creator>
    </item>
    <item>
      <title>BaMANI: Bayesian Multi-Algorithm causal Network Inference</title>
      <link>https://arxiv.org/abs/2508.11741</link>
      <description>arXiv:2508.11741v1 Announce Type: cross 
Abstract: Improved computational power has enabled different disciplines to predict causal relationships among modeled variables using Bayesian network inference. While many alternative algorithms have been proposed to improve the efficiency and reliability of network prediction, the predicted causal networks reflect the generative process but also bear an opaque imprint of the specific computational algorithm used. Following a ``wisdom of the crowds" strategy, we developed an ensemble learning approach to marginalize the impact of a single algorithm on Bayesian causal network inference. To introduce the approach, we first present the theoretical foundation of this framework. Next, we present a comprehensive implementation of the framework in terms of a new software tool called BaMANI (Bayesian Multi-Algorithm causal Network Inference). Finally, we describe a BaMANI use-case from biology, particularly within human breast cancer studies.</description>
      <guid isPermaLink="false">oai:arXiv.org:2508.11741v1</guid>
      <category>stat.ML</category>
      <category>cs.LG</category>
      <category>q-bio.QM</category>
      <pubDate>Tue, 19 Aug 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Habibolla Latifizadeh, Anika C. Pirkey, Alanna Gould, David J. Klinke II</dc:creator>
    </item>
    <item>
      <title>ProtTeX-CC: Activating In-Context Learning in Protein LLM via Two-Stage Instruction Compression</title>
      <link>https://arxiv.org/abs/2508.12212</link>
      <description>arXiv:2508.12212v1 Announce Type: cross 
Abstract: Recent advances in protein large language models, such as ProtTeX, represent both side-chain amino acids and backbone structure as discrete token sequences of residue length. While this design enables unified modeling of multimodal protein information, it suffers from two major limitations: (1) The concatenation of sequence and structure tokens approximately doubles the protein length and breaks the intrinsic residue-level alignment between modalities. (2) Constrained by the training corpus and limited context window, ProtTeX is typically trained on single-protein inputs, rendering it incompatible with in-context learning (ICL) and thus limiting its generalization capability. To address these issues, we propose ProtTeX-CC, a lightweight two-stage compression framework designed to enhance ProtTeX under few-shot settings. We first design a joint embedding compression mechanism that fuses sequence and structure representations at the residue level, effectively reducing the protein input length by half without sacrificing performance. Then we propose a self-compression module that aggregates each full demonstration into the latent space of the last few linguistic tokens, reducing the average demonstration length from 751 tokens to less than 16 tokens. Compared to the original ProtTeX, our self-compression approach achieves a compression ratio of approximately 93.68% in the total prompt length under the 16-shot setting. Without modifying the backbone model, ProtTeX-CC introduces only a small number of additional parameters through PEFT-based tuning in the joint embedding compression stage and a single trainable projection layer in the self-compression stage. Extensive experiments on protein function prediction show that ProtTeX-CC improves performance on the in-domain benchmark by 2%, and generalizes well to the out-of-domain dataset with a performance gain of 11%.</description>
      <guid isPermaLink="false">oai:arXiv.org:2508.12212v1</guid>
      <category>cs.LG</category>
      <category>cs.AI</category>
      <category>q-bio.QM</category>
      <pubDate>Tue, 19 Aug 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Chuanliu Fan, Zicheng Ma, Jun Gao, Nan Yu, Jun Zhang, Ziqiang Cao, Yi Qin Gao, Guohong Fu</dc:creator>
    </item>
    <item>
      <title>Mantis: A Simulation-Grounded Foundation Model for Disease Forecasting</title>
      <link>https://arxiv.org/abs/2508.12260</link>
      <description>arXiv:2508.12260v1 Announce Type: cross 
Abstract: Infectious disease forecasting in novel outbreaks or low resource settings has been limited by the need for disease-specific data, bespoke training, and expert tuning. We introduce Mantis, a foundation model trained entirely on mechanistic simulations, which enables out-of-the-box forecasting across diseases, regions, and outcomes, even in settings with limited historical data. Mantis is built on over 400 million simulated days of outbreak dynamics spanning diverse pathogens, transmission modes, interventions, and surveillance artifacts. Despite requiring no real-world data during training, Mantis outperformed 39 expert-tuned models we tested across six diseases, including all models in the CDC's COVID-19 Forecast Hub. Mantis generalized to novel epidemiological regimes, including diseases with held-out transmission mechanisms, demonstrating that it captures fundamental contagion dynamics. Critically, Mantis is mechanistically interpretable, enabling public health decision-makers to identify the latent drivers behind its predictions. Finally, Mantis delivers accurate forecasts at 8-week horizons, more than doubling the actionable range of most models, enabling proactive public health planning. Together, these capabilities position Mantis as a foundation for next-generation disease forecasting systems: general, interpretable, and deployable where traditional models fail.</description>
      <guid isPermaLink="false">oai:arXiv.org:2508.12260v1</guid>
      <category>cs.AI</category>
      <category>q-bio.QM</category>
      <pubDate>Tue, 19 Aug 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <dc:creator>Carson Dudley, Reiden Magdaleno, Christopher Harding, Ananya Sharma, Emily Martin, Marisa Eisenberg</dc:creator>
    </item>
    <item>
      <title>A stochastic agent-based model for simulating tumor-immune dynamics and evaluating therapeutic strategies</title>
      <link>https://arxiv.org/abs/2508.12297</link>
      <description>arXiv:2508.12297v1 Announce Type: cross 
Abstract: Tumor-immune interactions are central to cancer progression and treatment outcomes. In this study, we present a stochastic agent-based model that integrates cellular heterogeneity, spatial cell-cell interactions, and drug resistance evolution to simulate tumor growth and immune response in a two-dimensional microenvironment. The model captures dynamic behaviors of four major cell types--tumor cells, cytotoxic T lymphocytes, helper T cells, and regulatory T cells--and incorporates key biological processes such as proliferation, apoptosis, migration, and immune regulation. Using this framework, we simulate tumor progression under different therapeutic interventions, including radiotherapy, targeted therapy, and immune checkpoint blockade. Our simulations reproduce emergent phenomena such as immune privilege and spatial immune exclusion. Quantitative analyses show that all therapies suppress tumor growth to varying degrees and reshape the tumor microenvironment. Notably, combination therapies--especially targeted therapy with immunotherapy--achieve the most effective tumor control and delay the emergence of resistance. Additionally, sensitivity analyses reveal a nonlinear relationship between treatment intensity and therapeutic efficacy, highlighting the existence of optimal dosing thresholds. This work demonstrates the utility of agent-based modeling in capturing complex tumor-immune dynamics and provides a computational platform for optimizing cancer treatment strategies. The model is extensible, biologically interpretable, and well-suited for future integration with experimental or clinical data.</description>
      <guid isPermaLink="false">oai:arXiv.org:2508.12297v1</guid>
      <category>q-bio.TO</category>
      <category>q-bio.QM</category>
      <pubDate>Tue, 19 Aug 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Yuhong Zhang, Chenghang Li, Boya Wang, Jinzhi Lei</dc:creator>
    </item>
    <item>
      <title>Root Cause Analysis of Hydrogen Bond Separation in Spatio-Temporal Molecular Dynamics using Causal Models</title>
      <link>https://arxiv.org/abs/2508.12500</link>
      <description>arXiv:2508.12500v1 Announce Type: cross 
Abstract: Molecular dynamics simulations (MDS) face challenges, including resource-heavy computations and the need to manually scan outputs to detect "interesting events," such as the formation and persistence of hydrogen bonds between atoms of different molecules. A critical research gap lies in identifying the underlying causes of hydrogen bond formation and separation -understanding which interactions or prior events contribute to their emergence over time. With this challenge in mind, we propose leveraging spatio-temporal data analytics and machine learning models to enhance the detection of these phenomena. In this paper, our approach is inspired by causal modeling and aims to identify the root cause variables of hydrogen bond formation and separation events. Specifically, we treat the separation of hydrogen bonds as an "intervention" occurring and represent the causal structure of the bonding and separation events in the MDS as graphical causal models. These causal models are built using a variational autoencoder-inspired architecture that enables us to infer causal relationships across samples with diverse underlying causal graphs while leveraging shared dynamic information. We further include a step to infer the root causes of changes in the joint distribution of the causal models. By constructing causal models that capture shifts in the conditional distributions of molecular interactions during bond formation or separation, this framework provides a novel perspective on root cause analysis in molecular dynamic systems. We validate the efficacy of our model empirically on the atomic trajectories that used MDS for chiral separation, demonstrating that we can predict many steps in the future and also find the variables driving the observed changes in the system.</description>
      <guid isPermaLink="false">oai:arXiv.org:2508.12500v1</guid>
      <category>cs.AI</category>
      <category>cs.LG</category>
      <category>q-bio.QM</category>
      <pubDate>Tue, 19 Aug 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Rahmat K. Adesunkanmi, Ashfaq Khokhar, Goce Trajcevski, Sohail Murad</dc:creator>
    </item>
    <item>
      <title>Segmenting Thalamic Nuclei: T1 Maps Provide a Reliable and Efficient Solution</title>
      <link>https://arxiv.org/abs/2508.12508</link>
      <description>arXiv:2508.12508v1 Announce Type: cross 
Abstract: Accurate thalamic nuclei segmentation is crucial for understanding neurological diseases, brain functions, and guiding clinical interventions. However, the optimal inputs for segmentation remain unclear. This study systematically evaluates multiple MRI contrasts, including MPRAGE and FGATIR sequences, quantitative PD and T1 maps, and multiple T1-weighted images at different inversion times (multi-TI), to determine the most effective inputs. For multi-TI images, we employ a gradient-based saliency analysis with Monte Carlo dropout and propose an Overall Importance Score to select the images contributing most to segmentation. A 3D U-Net is trained on each of these configurations. Results show that T1 maps alone achieve strong quantitative performance and superior qualitative outcomes, while PD maps offer no added value. These findings underscore the value of T1 maps as a reliable and efficient input among the evaluated options, providing valuable guidance for optimizing imaging protocols when thalamic structures are of clinical or research interest.</description>
      <guid isPermaLink="false">oai:arXiv.org:2508.12508v1</guid>
      <category>eess.IV</category>
      <category>cs.CV</category>
      <category>q-bio.QM</category>
      <pubDate>Tue, 19 Aug 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Anqi Feng, Zhangxing Bian, Samuel W. Remedios, Savannah P. Hays, Blake E. Dewey, Jiachen Zhuo, Dan Benjamini, Jerry L. Prince</dc:creator>
    </item>
    <item>
      <title>Deep Learning Model for Amyloidogenicity Prediction using a Pre-trained Protein LLM</title>
      <link>https://arxiv.org/abs/2508.12575</link>
      <description>arXiv:2508.12575v1 Announce Type: cross 
Abstract: The prediction of amyloidogenicity in peptides and proteins remains a focal point of ongoing bioinformatics. The crucial step in this field is to apply advanced computational methodologies. Many recent approaches to predicting amyloidogenicity within proteins are highly based on evolutionary motifs and the individual properties of amino acids. It is becoming increasingly evident that the sequence information-based features show high predictive performance. Consequently, our study evaluated the contextual features of protein sequences obtained from a pretrained protein large language model leveraging bidirectional LSTM and GRU to predict amyloidogenic regions in peptide and protein sequences. Our method achieved an accuracy of 84.5% on 10-fold cross-validation and an accuracy of 83% in the test dataset. Our results demonstrate competitive performance, highlighting the potential of LLMs in enhancing the accuracy of amyloid prediction.</description>
      <guid isPermaLink="false">oai:arXiv.org:2508.12575v1</guid>
      <category>cs.LG</category>
      <category>cs.AI</category>
      <category>q-bio.QM</category>
      <pubDate>Tue, 19 Aug 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <arxiv:DOI>10.2991/978-94-6463-805-9_22</arxiv:DOI>
      <dc:creator>Zohra Yagoub, Hafida Bouziane</dc:creator>
    </item>
    <item>
      <title>Diagnostic performance of deep learning for predicting glioma isocitrate dehydrogenase and 1p/19q co-deletion in MRI: a systematic review and meta-analysis</title>
      <link>https://arxiv.org/abs/2411.02426</link>
      <description>arXiv:2411.02426v2 Announce Type: replace 
Abstract: Objectives We aimed to evaluate the diagnostic performance of deep learning (DL)-based radiomics models for the noninvasive prediction of isocitrate dehydrogenase (IDH) mutation and 1p/19q co-deletion status in glioma patients using MRI sequences, and to identify methodological factors influencing accuracy and generalizability.
  Materials and methods Following PRISMA guidelines, we systematically searched major databases (PubMed, Scopus, Embase, Web of Science, and Google Scholar) up to March 2025, screening studies that utilized DL to predict IDH and 1p/19q co-deletion status from MRI data. We assessed study quality and risk of bias using the Radiomics Quality Score and the QUADAS-2 tool. Our meta-analysis employed a bivariate model to compute pooled sensitivity and specificity, and meta-regression to assess interstudy heterogeneity.
  Results Among the 1517 unique publications, 104 were included in the qualitative synthesis, and 72 underwent meta-analysis. Pooled estimates for IDH prediction in test cohorts yielded a sensitivity of 0.80 and specificity of 0.85. For 1p/19q co-deletion, sensitivity was 0.75 and specificity was 0.82. Meta-regression identified the tumor segmentation method and the extent of DL integration into the radiomics pipeline as significant contributors to interstudy variability.
  Conclusion Although DL models demonstrate strong potential for noninvasive molecular classification of gliomas, clinical translation requires several critical steps: harmonization of multi-center MRI data using techniques such as histogram matching and DL-based style transfer; adoption of standardized and automated segmentation protocols; extensive multi-center external validation; and prospective clinical validation.</description>
      <guid isPermaLink="false">oai:arXiv.org:2411.02426v2</guid>
      <category>q-bio.QM</category>
      <category>cs.AI</category>
      <category>cs.LG</category>
      <category>eess.IV</category>
      <pubDate>Tue, 19 Aug 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <arxiv:DOI>10.1007/s00330-025-11898-2</arxiv:DOI>
      <dc:creator>Somayeh Farahani, Marjaneh Hejazi, Mehnaz Tabassum, Antonio Di Ieva, Neda Mahdavifar, Sidong Liu</dc:creator>
    </item>
    <item>
      <title>Revisiting convolutive blind source separation for identifying spiking motor neuron activity: From theory to practice</title>
      <link>https://arxiv.org/abs/2502.04065</link>
      <description>arXiv:2502.04065v2 Announce Type: replace 
Abstract: Objective: Identifying the activity of motor neurons (MNs) non-invasively is possible by decomposing signals from muscles, e.g., surface electromyography (EMG) or ultrasound. The theoretical background of MN identification is convolutive blind source separation (cBSS), and different algorithms have been developed and validated. Yet, the existence and identifiability of inverse solutions and the corresponding estimation errors are not fully understood. Further, the guidelines for selecting appropriate parameters are often built on empirical observations, limiting the translation to clinical applications and other modalities. Approach: We revisited the cBSS model for MN identification, augmented it with new theoretical insights and derived a framework that can predict the existence of inverse solutions. This framework allows the quantification of estimation errors due to the imperfect inversion of the motor unit action potentials (MUAP), noise sources, and the ill-conditioning of the inverse problem. To bridge the gap between theory and practice, we used computer simulations. Main results: (1) Increasing the similarity of MUAPs or correlation between spike trains increases the bias for detecting high amplitude MUs. (2) The optimal objective function depends on the expected spike amplitude, spike amplitude statistics and the amplitude of background spikes. (3) There is some wiggle room for MN detection given non-stationary MUAPs. (4) There is no connection between MUAP duration and extension factor, in contrast to previous guidelines. (5) Source quality metrics like the silhouette score (SIL) or the pulse-to-noise ratio (PNR) are highly correlated with a source's objective function output. (6) SIL is superior to PNR. Significance: These findings will guide cBSS algorithm developments tailored to MN identification and clinical application translation.</description>
      <guid isPermaLink="false">oai:arXiv.org:2502.04065v2</guid>
      <category>q-bio.QM</category>
      <category>q-bio.CB</category>
      <category>q-bio.NC</category>
      <category>q-bio.TO</category>
      <pubDate>Tue, 19 Aug 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <arxiv:DOI>10.1088/1741-2552/adf886</arxiv:DOI>
      <dc:creator>Thomas Klotz, Robin Rohl\'en</dc:creator>
    </item>
  </channel>
</rss>
