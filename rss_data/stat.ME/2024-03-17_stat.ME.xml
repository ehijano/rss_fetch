<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>stat.ME updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/stat.ME</link>
    <description>stat.ME updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/stat.ME" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Mon, 18 Mar 2024 04:00:47 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Mon, 18 Mar 2024 00:00:00 -0400</pubDate>
    <skipDays>
      <day>Sunday</day>
      <day>Saturday</day>
    </skipDays>
    <item>
      <title>Inference for non-probability samples using the calibration approach for quantiles</title>
      <link>https://arxiv.org/abs/2403.09726</link>
      <description>arXiv:2403.09726v1 Announce Type: new 
Abstract: Non-probability survey samples are examples of data sources that have become increasingly popular in recent years, also in official statistics. However, statistical inference based on non-probability samples is much more difficult because they are biased and are not representative of the target population (Wu, 2022). In this paper we consider a method of joint calibration for totals (Deville &amp; S\"arndal, 1992) and quantiles (Harms &amp; Duchesne, 2006) and use the proposed approach to extend existing inference methods for non-probability samples, such as inverse probability weighting, mass imputation and doubly robust estimators. By including quantile information in the estimation process non-linear relationships between the target and auxiliary variables can be approximated the way it is done in step-wise (constant) regression. Our simulation study has demonstrated that the estimators in question are more robust against model mis-specification and, as a result, help to reduce bias and improve estimation efficiency. Variance estimation for our proposed approach is also discussed. We show that existing inference methods can be used and that the resulting confidence intervals are at nominal levels. Finally, we applied the proposed methods to estimate the share of vacancies aimed at Ukrainian workers in Poland using an integrated set of administrative and survey data about job vacancies. The proposed approaches have been implemented in two R packages (nonprobsvy and jointCalib), which were used to conduct the simulation and empirical study</description>
      <guid isPermaLink="false">oai:arXiv.org:2403.09726v1</guid>
      <category>stat.ME</category>
      <category>stat.AP</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Maciej Ber\k{e}sewicz, Marcin Szymkowiak</dc:creator>
    </item>
    <item>
      <title>Quantifying Distributional Input Uncertainty via Inflated Kolmogorov-Smirnov Confidence Band</title>
      <link>https://arxiv.org/abs/2403.09877</link>
      <description>arXiv:2403.09877v1 Announce Type: new 
Abstract: In stochastic simulation, input uncertainty refers to the propagation of the statistical noise in calibrating input models to impact output accuracy, in addition to the Monte Carlo simulation noise. The vast majority of the input uncertainty literature focuses on estimating target output quantities that are real-valued. However, outputs of simulation models are random and real-valued targets essentially serve only as summary statistics. To provide a more holistic assessment, we study the input uncertainty problem from a distributional view, namely we construct confidence bands for the entire output distribution function. Our approach utilizes a novel test statistic whose asymptotic consists of the supremum of the sum of a Brownian bridge and a suitable mean-zero Gaussian process, which generalizes the Kolmogorov-Smirnov statistic to account for input uncertainty. Regarding implementation, we also demonstrate how to use subsampling to efficiently estimate the covariance function of the Gaussian process, thereby leading to an implementable estimation of the quantile of the test statistic and a statistically valid confidence band. Numerical results demonstrate how our new confidence bands provide valid coverage for output distributions under input uncertainty that is not achievable by conventional approaches.</description>
      <guid isPermaLink="false">oai:arXiv.org:2403.09877v1</guid>
      <category>stat.ME</category>
      <category>math.ST</category>
      <category>stat.TH</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Motong Chen, Henry Lam, Zhenyuan Liu</dc:creator>
    </item>
    <item>
      <title>Multi-Layer Kernel Machines: Fast and Optimal Nonparametric Regression with Uncertainty Quantification</title>
      <link>https://arxiv.org/abs/2403.09907</link>
      <description>arXiv:2403.09907v1 Announce Type: new 
Abstract: Kernel ridge regression (KRR) is widely used for nonparametric regression over reproducing kernel Hilbert spaces. It offers powerful modeling capabilities at the cost of significant computational costs, which typically require $O(n^3)$ computational time and $O(n^2)$ storage space, with the sample size n. We introduce a novel framework of multi-layer kernel machines that approximate KRR by employing a multi-layer structure and random features, and study how the optimal number of random features and layer sizes can be chosen while still preserving the minimax optimality of the approximate KRR estimate. For various classes of random features, including those corresponding to Gaussian and Matern kernels, we prove that multi-layer kernel machines can achieve $O(n^2\log^2n)$ computational time and $O(n\log^2n)$ storage space, and yield fast and minimax optimal approximations to the KRR estimate for nonparametric regression. Moreover, we construct uncertainty quantification for multi-layer kernel machines by using conformal prediction techniques with robust coverage properties. The analysis and theoretical predictions are supported by simulations and real data examples.</description>
      <guid isPermaLink="false">oai:arXiv.org:2403.09907v1</guid>
      <category>stat.ME</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Xiaowu Dai, Huiying Zhong</dc:creator>
    </item>
    <item>
      <title>Identification and estimation of mediational effects of longitudinal modified treatment policies</title>
      <link>https://arxiv.org/abs/2403.09928</link>
      <description>arXiv:2403.09928v1 Announce Type: new 
Abstract: We demonstrate a comprehensive semiparametric approach to causal mediation analysis, addressing the complexities inherent in settings with longitudinal and continuous treatments, confounders, and mediators. Our methodology utilizes a nonparametric structural equation model and a cross-fitted sequential regression technique based on doubly robust pseudo-outcomes, yielding an efficient, asymptotically normal estimator without relying on restrictive parametric modeling assumptions. We are motivated by a recent scientific controversy regarding the effects of invasive mechanical ventilation (IMV) on the survival of COVID-19 patients, considering acute kidney injury (AKI) as a mediating factor. We highlight the possibility of "inconsistent mediation," in which the direct and indirect effects of the exposure operate in opposite directions. We discuss the significance of mediation analysis for scientific understanding and its potential utility in treatment decisions.</description>
      <guid isPermaLink="false">oai:arXiv.org:2403.09928v1</guid>
      <category>stat.ME</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Brian Gilbert, Katherine L. Hoffman, Nicholas Williams, Kara E. Rudolph, Edward J. Schenck, Iv\'an D\'iaz</dc:creator>
    </item>
    <item>
      <title>On the distribution of isometric log-ratio transformations under extra-multinomial count data</title>
      <link>https://arxiv.org/abs/2403.09956</link>
      <description>arXiv:2403.09956v1 Announce Type: new 
Abstract: Compositional data arise when count observations are normalised into proportions adding up to unity. To allow use of standard statistical methods, compositional proportions can be mapped from the simplex into the Euclidean space through the isometric log-ratio (ilr) transformation. When the counts follow a multinomial distribution with fixed class-specific probabilities, the distribution of the ensuing ilr coordinates has been shown to be asymptotically multivariate normal. We here derive an asymptotic normal approximation to the distribution of the ilr coordinates when the counts show overdispersion under the Dirichlet-multinomial mixture model. Using a simulation study, we then investigate the practical applicability of the approximation against the empirical distribution of the ilr coordinates under varying levels of extra-multinomial variation and the total count. The approximation works well, except with a small total count or high amount of overdispersion. These empirical results remain even under population-level heterogeneity in the total count. Our work is motivated by microbiome data, which often exhibit considerable extra-multinomial variation and are increasingly treated as compositional through scaling taxon-specific counts into proportions. We conclude that if the analysis of empirical data relies on normality of the ilr coordinates, it may be advisable to choose a taxonomic level where counts are less sparse so that the distribution of taxon-specific class probabilities remains unimodal.</description>
      <guid isPermaLink="false">oai:arXiv.org:2403.09956v1</guid>
      <category>stat.ME</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Noora Kartiosuo, Joni Virta, Jaakko Nevalainen, Olli Raitakari, Kari Auranen</dc:creator>
    </item>
    <item>
      <title>Repro Samples Method for High-dimensional Logistic Model</title>
      <link>https://arxiv.org/abs/2403.09984</link>
      <description>arXiv:2403.09984v1 Announce Type: new 
Abstract: This paper presents a novel method to make statistical inferences for both the model support and regression coefficients in a high-dimensional logistic regression model. Our method is based on the repro samples framework, in which we conduct statistical inference by generating artificial samples mimicking the actual data-generating process. The proposed method has two major advantages. Firstly, for model support, we introduce the first method for constructing model confidence set in a high-dimensional setting and the proposed method only requires a weak signal strength assumption. Secondly, in terms of regression coefficients, we establish confidence sets for any group of linear combinations of regression coefficients. Our simulation results demonstrate that the proposed method produces valid and small model confidence sets and achieves better coverage for regression coefficients than the state-of-the-art debiasing methods. Additionally, we analyze single-cell RNA-seq data on the immune response. Besides identifying genes previously proved as relevant in the literature, our method also discovers a significant gene that has not been studied before, revealing a potential new direction in understanding cellular immune response mechanisms.</description>
      <guid isPermaLink="false">oai:arXiv.org:2403.09984v1</guid>
      <category>stat.ME</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Xiaotian Hou, Linjun Zhang, Peng Wang, Min-ge Xie</dc:creator>
    </item>
    <item>
      <title>Inference for Heterogeneous Graphical Models using Doubly High-Dimensional Linear-Mixed Models</title>
      <link>https://arxiv.org/abs/2403.10034</link>
      <description>arXiv:2403.10034v1 Announce Type: new 
Abstract: Motivated by the problem of inferring the graph structure of functional connectivity networks from multi-level functional magnetic resonance imaging data, we develop a valid inference framework for high-dimensional graphical models that accounts for group-level heterogeneity. We introduce a neighborhood-based method to learn the graph structure and reframe the problem as that of inferring fixed effect parameters in a doubly high-dimensional linear mixed model. Specifically, we propose a LASSO-based estimator and a de-biased LASSO-based inference framework for the fixed effect parameters in the doubly high-dimensional linear mixed model, leveraging random matrix theory to deal with challenges induced by the identical fixed and random effect design matrices arising in our setting. Moreover, we introduce consistent estimators for the variance components to identify subject-specific edges in the inferred graph. To illustrate the generality of the proposed approach, we also adapt our method to account for serial correlation by learning heterogeneous graphs in the setting of a vector autoregressive model. We demonstrate the performance of the proposed framework using real data and benchmark simulation studies.</description>
      <guid isPermaLink="false">oai:arXiv.org:2403.10034v1</guid>
      <category>stat.ME</category>
      <category>stat.AP</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Kun Yue, Eardi Lila, Ali Shojaie</dc:creator>
    </item>
    <item>
      <title>Response Style Characterization for Repeated Measures Using the Visual Analogue Scale</title>
      <link>https://arxiv.org/abs/2403.10136</link>
      <description>arXiv:2403.10136v1 Announce Type: new 
Abstract: Self-report measures (e.g., Likert scales) are widely used to evaluate subjective health perceptions. Recently, the visual analog scale (VAS), a slider-based scale, has become popular owing to its ability to precisely and easily assess how people feel. These data can be influenced by the response style (RS), a user-dependent systematic tendency that occurs regardless of questionnaire instructions. Despite its importance, especially in between-individual analysis, little attention has been paid to handling the RS in the VAS (denoted as response profile (RP)), as it is mainly used for within-individual monitoring and is less affected by RP. However, VAS measurements often require repeated self-reports of the same questionnaire items, making it difficult to apply conventional methods on a Likert scale. In this study, we developed a novel RP characterization method for various types of repeatedly measured VAS data. This approach involves the modeling of RP as distributional parameters ${\theta}$ through a mixture of RS-like distributions, and addressing the issue of unbalanced data through bootstrap sampling for treating repeated measures. We assessed the effectiveness of the proposed method using simulated pseudo-data and an actual dataset from an empirical study. The assessment of parameter recovery showed that our method accurately estimated the RP parameter ${\theta}$, demonstrating its robustness. Moreover, applying our method to an actual VAS dataset revealed the presence of individual RP heterogeneity, even in repeated VAS measurements, similar to the findings of the Likert scale. Our proposed method enables RP heterogeneity-aware VAS data analysis, similar to Likert-scale data analysis.</description>
      <guid isPermaLink="false">oai:arXiv.org:2403.10136v1</guid>
      <category>stat.ME</category>
      <category>cs.AI</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Shunsuke Minusa, Tadayuki Matsumura, Kanako Esaki, Yang Shao, Chihiro Yoshimura, Hiroyuki Mizuno</dc:creator>
    </item>
    <item>
      <title>Finite mixture copulas for modeling dependence in longitudinal count data</title>
      <link>https://arxiv.org/abs/2403.10165</link>
      <description>arXiv:2403.10165v1 Announce Type: new 
Abstract: Dependence modeling of multivariate count data has been receiving a considerable attention in recent times. Multivariate elliptical copulas are typically preferred in statistical literature to analyze dependence between repeated measurements of longitudinal data since they allow for different choices of the correlation structure. But these copulas lack in flexibility to model dependence and inference is only feasible under parametric restrictions. In this article, we propose the use of finite mixture of elliptical copulas in order to capture complex and hidden temporal dependency of discrete longitudinal data. With guaranteed model identifiability, our approach permits to use different correlation matrices in each component of the mixture copula. We theoretically examine the dependence properties of finite mixture of copulas, before applying them for constructing regression models for count longitudinal data. The inference of the proposed class of models is based on composite likelihood approach and the finite sample performance of the parameter estimates are investigated through extensive simulation studies. For model validation, besides the standard techniques we extended the t-plot method to accommodate finite mixture of elliptical copulas. Finally, our models are applied to analyze the temporal dependency of two real world longitudinal data sets and shown to provide improvements if compared against standard elliptical copulas.</description>
      <guid isPermaLink="false">oai:arXiv.org:2403.10165v1</guid>
      <category>stat.ME</category>
      <category>stat.AP</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Subhajit Chattopadhyay</dc:creator>
    </item>
    <item>
      <title>Towards a power analysis for PLS-based methods</title>
      <link>https://arxiv.org/abs/2403.10289</link>
      <description>arXiv:2403.10289v1 Announce Type: new 
Abstract: In recent years, power analysis has become widely used in applied sciences, with the increasing importance of the replicability issue. When distribution-free methods, such as Partial Least Squares (PLS)-based approaches, are considered, formulating power analysis turns out to be challenging. In this study, we introduce the methodological framework of a new procedure for performing power analysis when PLS-based methods are used. Data are simulated by the Monte Carlo method, assuming the null hypothesis of no effect is false and exploiting the latent structure estimated by PLS in the pilot data. In this way, the complex correlation data structure is explicitly considered in power analysis and sample size estimation. The paper offers insights into selecting statistical tests for the power analysis procedure, comparing accuracy-based tests and those based on continuous parameters estimated by PLS. Simulated and real datasets are investigated to show how the method works in practice.</description>
      <guid isPermaLink="false">oai:arXiv.org:2403.10289v1</guid>
      <category>stat.ME</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Angela Andreella, Livio Fino, Bruno Scarpa, Matteo Stocchero</dc:creator>
    </item>
    <item>
      <title>Multivariate Bayesian models with flexible shared interactions for analyzing spatio-temporal patterns of rare cancers</title>
      <link>https://arxiv.org/abs/2403.10440</link>
      <description>arXiv:2403.10440v1 Announce Type: new 
Abstract: Rare cancers affect millions of people worldwide each year. However, estimating incidence or mortality rates associated with rare cancers presents important difficulties and poses new statistical methodological challenges. In this paper, we expand the collection of multivariate spatio-temporal models by introducing adaptable shared interactions to enable a comprehensive analysis of both incidence and cancer mortality in rare cancer cases. These models allow the modulation of spatio-temporal interactions between incidence and mortality, allowing for changes in their relationship over time. The new models have been implemented in INLA using r-generic constructions. We conduct a simulation study to evaluate the performance of the new spatio-temporal models in terms of sensitivity and specificity. Results show that multivariate spatio-temporal models with flexible shared interaction outperform conventional multivariate spatio-temporal models with independent interactions. We use these models to analyze incidence and mortality data for pancreatic cancer and leukaemia among males across 142 administrative healthcare districts of Great Britain over a span of nine biennial periods (2002-2019).</description>
      <guid isPermaLink="false">oai:arXiv.org:2403.10440v1</guid>
      <category>stat.ME</category>
      <category>stat.AP</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Garazi Retegui, Jaione Etxeberria, Mar\'ia Dolores Ugarte</dc:creator>
    </item>
    <item>
      <title>Multilevel functional distributional models with application to continuous glucose monitoring in diabetes clinical trials</title>
      <link>https://arxiv.org/abs/2403.10514</link>
      <description>arXiv:2403.10514v1 Announce Type: new 
Abstract: Continuous glucose monitoring (CGM) is a minimally invasive technology that allows continuous monitoring of an individual's blood glucose. We focus on a large clinical trial that collected CGM data every few minutes for 26 weeks and assumes that the basic observation unit is the distribution of CGM observations in a four-week interval. The resulting data structure is multilevel (because each individual has multiple months of data) and distributional (because the data for each four-week interval is represented as a distribution). The scientific goals are to: (1) identify and quantify the effects of factors that affect glycemic control in type 1 diabetes (T1D) patients; and (2) identify and characterize the patients who respond to treatment. To address these goals, we propose a new multilevel functional model that treats the CGM distributions as a response. Methods are motivated by and applied to data collected by The Juvenile Diabetes Research Foundation Continuous Glucose Monitoring Group. Reproducible code for the methods introduced here is available on GitHub.</description>
      <guid isPermaLink="false">oai:arXiv.org:2403.10514v1</guid>
      <category>stat.ME</category>
      <category>stat.AP</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Marcos Matabuena, Ciprian M. Crainiceanu</dc:creator>
    </item>
    <item>
      <title>Should the choice of BOIN design parameter p.tox only depend on the target DLT rate?</title>
      <link>https://arxiv.org/abs/2403.09667</link>
      <description>arXiv:2403.09667v1 Announce Type: cross 
Abstract: When the early stopping parameter n.earlystop is relatively small or the cohortsize value is not optimized via simulation, it may be better to use p.tox &lt; 1.4 * target.DLT.rate, or try out different cohort sizes, or increase n.earlystop, whichever is both feasible and provides better operating characteristics. This is because if the cohortsize was not optimized via simulation, even when n.earlystop = 12, the BOIN escalation/de-escalation rules generated using p.tox = 1.4 * target.DLT.rate could be exactly the same as those calculated using p.tox &gt; 3 * target.DLT.rate, which might not be acceptable for some pediatric trials targeting 10% DLT rate. The traditional 3+3 design stops the dose finding process when 3 patients have been treated at the current dose level, 0 DLT has been observed, and the next higher dose has already been eliminated. If additional 3 patients were required to be treated at the current dose in the situation described above, the corresponding boundary table could be generated using BOIN design with target DLT rates ranging from 18% to 29%, p.saf ranging from 8% to 26%, and p.tox ranging from 39% to 99%. To generate the boundary table of this 3+3 design variant, BOIN parameters also need to satisfy a set of conditions.</description>
      <guid isPermaLink="false">oai:arXiv.org:2403.09667v1</guid>
      <category>physics.med-ph</category>
      <category>stat.ME</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Rong Lu</dc:creator>
    </item>
    <item>
      <title>Mind the GAP: Improving Robustness to Subpopulation Shifts with Group-Aware Priors</title>
      <link>https://arxiv.org/abs/2403.09869</link>
      <description>arXiv:2403.09869v1 Announce Type: cross 
Abstract: Machine learning models often perform poorly under subpopulation shifts in the data distribution. Developing methods that allow machine learning models to better generalize to such shifts is crucial for safe deployment in real-world settings. In this paper, we develop a family of group-aware prior (GAP) distributions over neural network parameters that explicitly favor models that generalize well under subpopulation shifts. We design a simple group-aware prior that only requires access to a small set of data with group information and demonstrate that training with this prior yields state-of-the-art performance -- even when only retraining the final layer of a previously trained non-robust model. Group aware-priors are conceptually simple, complementary to existing approaches, such as attribute pseudo labeling and data reweighting, and open up promising new avenues for harnessing Bayesian inference to enable robustness to subpopulation shifts.</description>
      <guid isPermaLink="false">oai:arXiv.org:2403.09869v1</guid>
      <category>stat.ML</category>
      <category>cs.AI</category>
      <category>cs.LG</category>
      <category>stat.ME</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Tim G. J. Rudner, Ya Shi Zhang, Andrew Gordon Wilson, Julia Kempe</dc:creator>
    </item>
    <item>
      <title>Interpretable Machine Learning for Survival Analysis</title>
      <link>https://arxiv.org/abs/2403.10250</link>
      <description>arXiv:2403.10250v1 Announce Type: cross 
Abstract: With the spread and rapid advancement of black box machine learning models, the field of interpretable machine learning (IML) or explainable artificial intelligence (XAI) has become increasingly important over the last decade. This is particularly relevant for survival analysis, where the adoption of IML techniques promotes transparency, accountability and fairness in sensitive areas, such as clinical decision making processes, the development of targeted therapies, interventions or in other medical or healthcare related contexts. More specifically, explainability can uncover a survival model's potential biases and limitations and provide more mathematically sound ways to understand how and which features are influential for prediction or constitute risk factors. However, the lack of readily available IML methods may have deterred medical practitioners and policy makers in public health from leveraging the full potential of machine learning for predicting time-to-event data. We present a comprehensive review of the limited existing amount of work on IML methods for survival analysis within the context of the general IML taxonomy. In addition, we formally detail how commonly used IML methods, such as such as individual conditional expectation (ICE), partial dependence plots (PDP), accumulated local effects (ALE), different feature importance measures or Friedman's H-interaction statistics can be adapted to survival outcomes. An application of several IML methods to real data on data on under-5 year mortality of Ghanaian children from the Demographic and Health Surveys (DHS) Program serves as a tutorial or guide for researchers, on how to utilize the techniques in practice to facilitate understanding of model decisions or predictions.</description>
      <guid isPermaLink="false">oai:arXiv.org:2403.10250v1</guid>
      <category>stat.ML</category>
      <category>cs.LG</category>
      <category>stat.ME</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Sophie Hanna Langbein, Mateusz Krzyzi\'nski, Miko{\l}aj Spytek, Hubert Baniecki, Przemys{\l}aw Biecek, Marvin N. Wright</dc:creator>
    </item>
    <item>
      <title>Exact Consistency Tests for Gaussian Mixture Filters using Normalized Deviation Squared Statistics</title>
      <link>https://arxiv.org/abs/2312.17420</link>
      <description>arXiv:2312.17420v2 Announce Type: replace 
Abstract: We consider the problem of evaluating dynamic consistency in discrete time probabilistic filters that approximate stochastic system state densities with Gaussian mixtures. Dynamic consistency means that the estimated probability distributions correctly describe the actual uncertainties. As such, the problem of consistency testing naturally arises in applications with regards to estimator tuning and validation. However, due to the general complexity of the density functions involved, straightforward approaches for consistency testing of mixture-based estimators have remained challenging to define and implement. This paper derives a new exact result for Gaussian mixture consistency testing within the framework of normalized deviation squared (NDS) statistics. It is shown that NDS test statistics for generic multivariate Gaussian mixture models exactly follow mixtures of generalized chi-square distributions, for which efficient computational tools are available. The accuracy and utility of the resulting consistency tests are numerically demonstrated on static and dynamic mixture estimation examples.</description>
      <guid isPermaLink="false">oai:arXiv.org:2312.17420v2</guid>
      <category>stat.ME</category>
      <category>cs.CV</category>
      <category>cs.RO</category>
      <category>cs.SY</category>
      <category>eess.SY</category>
      <category>stat.AP</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Nisar Ahmed, Luke Burks, Kailah Cabral, Alyssa Bekai Rose</dc:creator>
    </item>
    <item>
      <title>Metrics on Markov Equivalence Classes for Evaluating Causal Discovery Algorithms</title>
      <link>https://arxiv.org/abs/2402.04952</link>
      <description>arXiv:2402.04952v2 Announce Type: replace 
Abstract: Many state-of-the-art causal discovery methods aim to generate an output graph that encodes the graphical separation and connection statements of the causal graph that underlies the data-generating process. In this work, we argue that an evaluation of a causal discovery method against synthetic data should include an analysis of how well this explicit goal is achieved by measuring how closely the separations/connections of the method's output align with those of the ground truth. We show that established evaluation measures do not accurately capture the difference in separations/connections of two causal graphs, and we introduce three new measures of distance called s/c-distance, Markov distance and Faithfulness distance that address this shortcoming. We complement our theoretical analysis with toy examples, empirical experiments and pseudocode.</description>
      <guid isPermaLink="false">oai:arXiv.org:2402.04952v2</guid>
      <category>stat.ME</category>
      <category>stat.ML</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Jonas Wahl, Jakob Runge</dc:creator>
    </item>
    <item>
      <title>Self-Compatibility: Evaluating Causal Discovery without Ground Truth</title>
      <link>https://arxiv.org/abs/2307.09552</link>
      <description>arXiv:2307.09552v2 Announce Type: replace-cross 
Abstract: As causal ground truth is incredibly rare, causal discovery algorithms are commonly only evaluated on simulated data. This is concerning, given that simulations reflect preconceptions about generating processes regarding noise distributions, model classes, and more. In this work, we propose a novel method for falsifying the output of a causal discovery algorithm in the absence of ground truth. Our key insight is that while statistical learning seeks stability across subsets of data points, causal learning should seek stability across subsets of variables. Motivated by this insight, our method relies on a notion of compatibility between causal graphs learned on different subsets of variables. We prove that detecting incompatibilities can falsify wrongly inferred causal relations due to violation of assumptions or errors from finite sample effects. Although passing such compatibility tests is only a necessary criterion for good performance, we argue that it provides strong evidence for the causal models whenever compatibility entails strong implications for the joint distribution. We also demonstrate experimentally that detection of incompatibilities can aid in causal model selection.</description>
      <guid isPermaLink="false">oai:arXiv.org:2307.09552v2</guid>
      <category>cs.LG</category>
      <category>stat.ME</category>
      <category>stat.ML</category>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Philipp M. Faller, Leena Chennuru Vankadara, Atalanti A. Mastakouri, Francesco Locatello, Dominik Janzing</dc:creator>
    </item>
    <item>
      <title>Beyond expected values: Making environmental decisions using value of information analysis when measurement outcome matters</title>
      <link>https://arxiv.org/abs/2309.09452</link>
      <description>arXiv:2309.09452v2 Announce Type: replace-cross 
Abstract: In ecological and environmental contexts, management actions must sometimes be chosen urgently. Value of information (VoI) analysis provides a quantitative toolkit for projecting the improved management outcomes expected after making additional measurements. However, traditional VoI analysis reports metrics as expected values (i.e. risk-neutral). This can be problematic because expected values hide uncertainties in projections. The true value of a measurement will only be known after the measurement's outcome is known, leaving large uncertainty in the measurement's value before it is performed. As a result, the expected value metrics produced in traditional VoI analysis may not align with the priorities of a risk-averse decision-maker who wants to avoid low-value measurement outcomes. In the present work, we introduce four new VoI metrics that can address a decision-maker's risk-aversion to different measurement outcomes. We demonstrate the benefits of the new metrics with two ecological case studies for which traditional VoI analysis has been previously applied. Using the new metrics, we also demonstrate a clear mathematical link between the often-separated environmental decision-making disciplines of VoI and optimal design of experiments. This mathematical link has the potential to catalyse future collaborations between ecologists and statisticians to work together to quantitatively address environmental decision-making questions of fundamental importance. Overall, the introduced VoI metrics complement existing metrics to provide decision-makers with a comprehensive view of the value of, and risks associated with, a proposed monitoring or measurement activity. This is critical for improved environmental outcomes when decisions must be urgently made.</description>
      <guid isPermaLink="false">oai:arXiv.org:2309.09452v2</guid>
      <category>stat.AP</category>
      <category>stat.ME</category>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <arxiv:DOI>10.1016/j.ecolind.2024.111828</arxiv:DOI>
      <arxiv:journal_reference>Ecological Indicators 160 (2024) 111828</arxiv:journal_reference>
      <dc:creator>Morenikeji D. Akinlotan, David J. Warne, Kate J. Helmstedt, Sarah A. Vollert, Iadine Chad\`es, Ryan F. Heneghan, Hui Xiao, Matthew P. Adams</dc:creator>
    </item>
    <item>
      <title>Signed Diverse Multiplex Networks: Clustering and Inference</title>
      <link>https://arxiv.org/abs/2402.10242</link>
      <description>arXiv:2402.10242v2 Announce Type: replace-cross 
Abstract: The paper introduces a Signed Generalized Random Dot Product Graph (SGRDPG) model, which is a variant of the Generalized Random Dot Product Graph (GRDPG), where, in addition, edges can be positive or negative. The setting is extended to a multiplex version, where all layers have the same collection of nodes and follow the SGRDPG. The only common feature of the layers of the network is that they can be partitioned into groups with common subspace structures, while otherwise matrices of connection probabilities can be all different. The setting above is extremely flexible and includes a variety of existing multiplex network models as its particular cases. The paper fulfills two objectives. First, it shows that keeping signs of the edges in the process of network construction leads to a better precision of estimation and clustering and, hence, is beneficial for tackling real world problems such as, for example, analysis of brain networks. Second, by employing novel algorithms, our paper ensures strongly consistent clustering of layers and high accuracy of subspace estimation. In addition to theoretical guarantees, both of those features are demonstrated using numerical simulations and a real data example.</description>
      <guid isPermaLink="false">oai:arXiv.org:2402.10242v2</guid>
      <category>cs.SI</category>
      <category>cs.LG</category>
      <category>stat.ME</category>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Marianna Pensky</dc:creator>
    </item>
    <item>
      <title>Ensemble Kalman filter in geoscience meets model predictive control</title>
      <link>https://arxiv.org/abs/2403.06371</link>
      <description>arXiv:2403.06371v2 Announce Type: replace-cross 
Abstract: Although data assimilation originates from control theory, the relationship between modern data assimilation methods in geoscience and model predictive control has not been extensively explored. In the present paper, I discuss that the modern data assimilation methods in geoscience and model predictive control essentially minimize the similar quadratic cost functions. Inspired by this similarity, I propose a new ensemble Kalman filter (EnKF)-based method for controlling spatio-temporally chaotic systems, which can readily be applied to high-dimensional and nonlinear Earth systems. In this method, the reference vector, which serves as the control target, is assimilated into the state space as a pseudo-observation by ensemble Kalman smoother to obtain the appropriate perturbation to be added to a system. A proof-of-concept experiment using the Lorenz 63 model is presented. The system is constrained in one wing of the butterfly attractor without tipping to the other side by reasonably small control perturbations which are comparable with previous works.</description>
      <guid isPermaLink="false">oai:arXiv.org:2403.06371v2</guid>
      <category>physics.geo-ph</category>
      <category>stat.ME</category>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Yohei Sawada</dc:creator>
    </item>
  </channel>
</rss>
