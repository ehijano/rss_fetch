<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>econ.EM updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/econ.EM</link>
    <description>econ.EM updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/econ.EM" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Thu, 15 Jan 2026 05:00:44 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Thu, 15 Jan 2026 00:00:00 -0500</pubDate>
    <skipDays>
      <day>Saturday</day>
      <day>Sunday</day>
    </skipDays>
    <item>
      <title>Warp speed price moves: Jumps after earnings announcements</title>
      <link>https://arxiv.org/abs/2601.08962</link>
      <description>arXiv:2601.08962v1 Announce Type: new 
Abstract: Corporate earnings announcements unpack large bundles of public information that should, in efficient markets, trigger jumps in stock prices. Testing this implication is difficult in practice, as it requires noisy high-frequency data from after-hours markets, where most earnings announcements are released. Using a unique dataset and a new microstructure noise-robust jump test, we show that earnings announcements almost always induce jumps in the stock price of announcing firms. They also significantly raise the probability of price co-jumps in non-announcing firms and the market. We find that returns from a post-announcement trading strategy are consistent with efficient price formation after 2016.</description>
      <guid isPermaLink="false">oai:arXiv.org:2601.08962v1</guid>
      <category>econ.EM</category>
      <pubDate>Thu, 15 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/publicdomain/zero/1.0/</dc:rights>
      <arxiv:DOI>10.1016/j.jfineco.2025.104010</arxiv:DOI>
      <dc:creator>Kim Christensen, Allan Timmermann, Bezirgen Veliyev</dc:creator>
    </item>
    <item>
      <title>The drift burst hypothesis</title>
      <link>https://arxiv.org/abs/2601.08974</link>
      <description>arXiv:2601.08974v1 Announce Type: new 
Abstract: The drift burst hypothesis postulates the existence of short-lived locally explosive trends in the price paths of financial assets. The recent U.S. equity and treasury flash crashes can be viewed as two high-profile manifestations of such dynamics, but we argue that drift bursts of varying magnitude are an expected and regular occurrence in financial markets that can arise through established mechanisms of liquidity provision. We show how to build drift bursts into the continuous-time It\^o semimartingale model, elaborate on the conditions required for the process to remain arbitrage-free, and propose a nonparametric test statistic that identifies drift bursts from noisy high-frequency data. We apply the test and demonstrate that drift bursts are a stylized fact of the price dynamics across equities, fixed income, currencies and commodities. Drift bursts occur once a week on average, and the majority of them are accompanied by subsequent price reversion and can thus be regarded as "flash crashes." The reversal is found to be stronger for negative drift bursts with large trading volume, which is consistent with endogenous demand for immediacy during market crashes.</description>
      <guid isPermaLink="false">oai:arXiv.org:2601.08974v1</guid>
      <category>econ.EM</category>
      <pubDate>Thu, 15 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/publicdomain/zero/1.0/</dc:rights>
      <arxiv:DOI>10.1016/j.jeconom.2020.11.004</arxiv:DOI>
      <dc:creator>Kim Christensen, Roel C. A. Oomen, Roberto Ren\`o</dc:creator>
    </item>
    <item>
      <title>Lee Bounds for Random Objects</title>
      <link>https://arxiv.org/abs/2601.09453</link>
      <description>arXiv:2601.09453v1 Announce Type: new 
Abstract: In applied research, Lee (2009) bounds are widely applied to bound the average treatment effect in the presence of selection bias. This paper extends the methodology of Lee bounds to accommodate outcomes in a general metric space, such as compositional and distributional data. By exploiting a representation of the Fr\'echet mean of the potential outcome via embedding in an Euclidean or Hilbert space, we present a feasible characterization of the identified set of the causal effect of interest, and then propose its analog estimator and bootstrap confidence region. The proposed method is illustrated by numerical examples on compositional and distributional data.</description>
      <guid isPermaLink="false">oai:arXiv.org:2601.09453v1</guid>
      <category>econ.EM</category>
      <pubDate>Thu, 15 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Daisuke Kurisu, Yuta Okamoto, Taisuke Otsu</dc:creator>
    </item>
    <item>
      <title>Journal Impact Factor and Federal Reserve Monetary Policy: An Econometric Analysis Based on 1975-2026</title>
      <link>https://arxiv.org/abs/2601.09618</link>
      <description>arXiv:2601.09618v1 Announce Type: new 
Abstract: The Journal Impact Factor (IF), as a core indicator of academic evaluation, has not been systematically studied in relation to its historical evolution and global macroeconomic environment. This paper employs a period-based regression analysis using long-term time series data from 1975-2026 to examine the statistical relationship between IF and Federal Reserve monetary policy (using real interest rate as a proxy variable). The study estimates three nested models using Ordinary Least Squares (OLS): (1) a baseline linear model, (2) a linear model controlling for time trends, and (3) a log-transformed model. Empirical results show that: (i) in the early period (1975-2000), there is no significant statistical relationship between IF and real interest rate ($p&gt;0.1$); (ii) during the quantitative easing period (2001-2020), they exhibit a significant negative correlation ($\beta=-0.069$, $p&lt;0.01$), meaning that for every 1 percentage point decrease in real interest rate, IF increases by approximately 6.9\%; (iii) the adjusted $R^2$ of the full-sample model reaches 0.893, indicating that real interest rate and time trends can explain 89.3\% of IF variation. This finding reveals the indirect impact of monetary policy on the academic publishing system through multiple channels such as research funding and journal pricing power, providing econometric evidence for understanding the phenomenon of "financialization of academic capital." This study not only enriches the literature on monetary policy transmission mechanisms but also provides a new perspective for valuation analysis of the academic publishing industry.</description>
      <guid isPermaLink="false">oai:arXiv.org:2601.09618v1</guid>
      <category>econ.EM</category>
      <pubDate>Thu, 15 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Alex Huang</dc:creator>
    </item>
    <item>
      <title>Local Projection Inference is Simpler and More Robust Than You Think</title>
      <link>https://arxiv.org/abs/2007.13888</link>
      <description>arXiv:2007.13888v4 Announce Type: replace 
Abstract: Applied macroeconomists often compute confidence intervals for impulse responses using local projections, i.e., direct linear regressions of future outcomes on current covariates. This paper proves that local projection inference robustly handles two issues that commonly arise in applications: highly persistent data and the estimation of impulse responses at long horizons. We consider local projections that control for lags of the variables in the regression. We show that lag-augmented local projections with normal critical values are asymptotically valid uniformly over (i) both stationary and non-stationary data, and also over (ii) a wide range of response horizons. Moreover, lag augmentation obviates the need to correct standard errors for serial correlation in the regression residuals. Hence, local projection inference is arguably both simpler than previously thought and more robust than standard autoregressive inference, whose validity is known to depend sensitively on the persistence of the data and on the length of the horizon.</description>
      <guid isPermaLink="false">oai:arXiv.org:2007.13888v4</guid>
      <category>econ.EM</category>
      <pubDate>Thu, 15 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <arxiv:DOI>10.3982/ECTA18756</arxiv:DOI>
      <arxiv:journal_reference>Econometrica, July 2021, Volume 89, Issue 4, Pages 1789-1823</arxiv:journal_reference>
      <dc:creator>Jos\'e Luis Montiel Olea, Mikkel Plagborg-M{\o}ller</dc:creator>
    </item>
    <item>
      <title>Recidivism and Peer Influence with LLM Text Embeddings in Low Security Correctional Facilities</title>
      <link>https://arxiv.org/abs/2509.20634</link>
      <description>arXiv:2509.20634v2 Announce Type: replace 
Abstract: Studying peer effects in language is critical because they often reflect behavioral and personality traits that are important determinants of economic outcomes. However, language is unstructured, non-numeric, and high-dimensional. We combine Large Language Model (LLM) embeddings with structural econometric identification to provide a unified framework for identifying peer effects in language. This unified framework is applied to 80,000-120,000 written exchanges among residents of low security correctional facilities. The LLM language profiles predict three-year recidivism 30\% more accurately than pre-entry covariates alone, showing that text representations capture meaningful signals. We analyze peer effects on multidimensional language embeddings while addressing network endogeneity. We develop novel instrumental variable estimators for peer effects that accommodate multivariate outcomes, sparse networks, and multidimensional latent variables. Our methods achieve root-N consistency and asymptotic normality under realistic sparsity conditions, relaxing the dense-network assumption. Results reveal significant peer effects in residents' language profiles.</description>
      <guid isPermaLink="false">oai:arXiv.org:2509.20634v2</guid>
      <category>econ.EM</category>
      <category>cs.AI</category>
      <category>econ.GN</category>
      <category>q-fin.EC</category>
      <category>stat.ME</category>
      <pubDate>Thu, 15 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Shanjukta Nath, Jiwon Hong, Jae Ho Chang, Keith Warren, Subhadeep Paul</dc:creator>
    </item>
    <item>
      <title>Adaptive Neyman Allocation</title>
      <link>https://arxiv.org/abs/2309.08808</link>
      <description>arXiv:2309.08808v5 Announce Type: replace-cross 
Abstract: In the experimental design literature, Neyman allocation refers to the practice of allocating units into treated and control groups, potentially in unequal numbers proportional to their respective standard deviations, with the objective of minimizing the variance of the treatment effect estimator. This widely recognized approach increases statistical power in scenarios where the treated and control groups have different standard deviations, as is often the case in social experiments, clinical trials, marketing research, and online A/B testing. However, Neyman allocation cannot be implemented unless the standard deviations are known in advance. Fortunately, the multi-stage nature of the aforementioned applications allows the use of earlier stage observations to estimate the standard deviations, which further guide allocation decisions in later stages. In this paper, we introduce a competitive analysis framework to study this multi-stage experimental design problem. We propose a simple adaptive Neyman allocation algorithm, which almost matches the information-theoretic limit of conducting experiments. We provide theory for estimation and inference using data collected from our adaptive Neyman allocation algorithm. We demonstrate the effectiveness of our adaptive Neyman allocation algorithm using both online A/B testing data from a social media site and synthetic data.</description>
      <guid isPermaLink="false">oai:arXiv.org:2309.08808v5</guid>
      <category>stat.ME</category>
      <category>econ.EM</category>
      <pubDate>Thu, 15 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Jinglong Zhao</dc:creator>
    </item>
    <item>
      <title>Extremal Quantiles under Two-Way Clustering</title>
      <link>https://arxiv.org/abs/2402.19268</link>
      <description>arXiv:2402.19268v3 Announce Type: replace-cross 
Abstract: This paper studies extremal quantiles under two-way clustered dependence. We show that the limiting distribution of unconditional intermediate-order tail quantiles is Gaussian. This result is notable because two-way clustering typically leads to non-Gaussian limiting behavior. Remarkably, extremal quantiles remain asymptotically Gaussian even in degenerate cases. Building on this insight, we extend our analysis to extremal quantile regression at intermediate orders. Simulation results corroborate our theoretical findings. Finally, we provide an empirical application to growth-at-risk, showing that earlier empirical conclusions remain robust even after accounting for two-way clustered dependence in panel data and the focus on extreme quantiles.</description>
      <guid isPermaLink="false">oai:arXiv.org:2402.19268v3</guid>
      <category>math.ST</category>
      <category>econ.EM</category>
      <category>stat.TH</category>
      <pubDate>Thu, 15 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Harold D. Chiang, Ryutah Kato, Yuya Sasaki</dc:creator>
    </item>
    <item>
      <title>Proper Correlation Coefficients for Nominal Random Variables</title>
      <link>https://arxiv.org/abs/2505.00785</link>
      <description>arXiv:2505.00785v2 Announce Type: replace-cross 
Abstract: This paper develops an intuitive concept of perfect dependence between two variables of which at least one has a nominal scale. Perfect dependence is attainable for all marginal distributions. It furthermore proposes a set of dependence measures that are 1 if and only if this perfect dependence is satisfied. The advantages of these dependence measures relative to classical dependence measures like contingency coefficients, Goodman-Kruskal's lambda and tau and the so-called uncertainty coefficient are twofold. Firstly, they are defined if one of the variables exhibits continuities. Secondly, they satisfy the property of attainability. That is, they can take all values in the interval [0,1] irrespective of the marginals involved. Both properties are not shared by classical dependence measures which need two discrete marginal distributions and can in some situations yield values close to 0 even though the dependence is strong or even perfect. Additionally, the paper provides a consistent estimator for one of the new dependence measures together with its asymptotic distribution under independence as well as in the general case. This allows to construct confidence intervals and an independence test with good finite sample properties, as a subsequent simulation study shows. Finally, two applications on the dependence between the variables country and income, and country and religion, respectively, illustrate the use of the new measure.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.00785v2</guid>
      <category>stat.ME</category>
      <category>econ.EM</category>
      <pubDate>Thu, 15 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Jan-Lukas Wermuth</dc:creator>
    </item>
  </channel>
</rss>
