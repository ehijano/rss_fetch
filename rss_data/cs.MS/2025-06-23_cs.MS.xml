<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>cs.MS updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/cs.MS</link>
    <description>cs.MS updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/cs.MS" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Tue, 24 Jun 2025 02:20:18 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Mon, 23 Jun 2025 00:00:00 -0400</pubDate>
    <skipDays>
      <day>Sunday</day>
      <day>Saturday</day>
    </skipDays>
    <item>
      <title>Transformations of Computational Meshes</title>
      <link>https://arxiv.org/abs/2506.16341</link>
      <description>arXiv:2506.16341v1 Announce Type: new 
Abstract: Computational meshes, as a way to partition space, form the basis of much of PDE simulation technology, for instance for the finite element and finite volume discretization methods. In complex simulations, we are often driven to modify an input mesh, for example, to refine, coarsen, extrude, change cell types, or filter it. Mesh manipulation code can be voluminous, error-prone, spread over many special cases, and hard to understand and maintain by subsequent developers. We present a simple, table-driven paradigm for mesh transformation which can execute a large variety of transformations in a performant, parallel manner, along with experiments in the open source library PETSc which can be run by the reader.</description>
      <guid isPermaLink="false">oai:arXiv.org:2506.16341v1</guid>
      <category>cs.MS</category>
      <category>cs.NA</category>
      <category>math.NA</category>
      <pubDate>Mon, 23 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Matthew G. Knepley</dc:creator>
    </item>
    <item>
      <title>Adaptive Sketching Based Construction of H2 Matrices on GPUs</title>
      <link>https://arxiv.org/abs/2506.16759</link>
      <description>arXiv:2506.16759v1 Announce Type: new 
Abstract: We develop a novel linear-complexity bottom-up sketching-based algorithm for constructing a $H^2$ matrix, and present its high performance GPU implementation. The construction algorithm requires both a black-box sketching operator and an entry evaluation function. The novelty of our GPU approach centers around the design and implementation of the above two operations in batched mode on GPU with accommodation for variable-size data structures in a batch. The batch algorithms minimize the number of kernel launches and maximize the GPU throughput. When applied to covariance matrices, volume IE matrices and $H^2$ update operations, our proposed GPU implementation achieves up to $13\times$ speedup over our CPU implementation, and up to $1000\times$ speedup over an existing GPU implementation of the top-down sketching-based algorithm from the H2Opus library. It also achieves a $660\times$ speedup over an existing sketching-based $H$ construction algorithm from the ButterflyPACK library. Our work represents the first GPU implementation of the class of bottom-up sketching-based $H^2$ construction algorithms.</description>
      <guid isPermaLink="false">oai:arXiv.org:2506.16759v1</guid>
      <category>cs.MS</category>
      <pubDate>Mon, 23 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Wajih Halim Boukaram, Yang Liu, Pieter Ghysels, Xiaoye Sherry Li</dc:creator>
    </item>
    <item>
      <title>A Sparse Tensor Generator with Efficient Feature Extraction</title>
      <link>https://arxiv.org/abs/2405.04944</link>
      <description>arXiv:2405.04944v3 Announce Type: replace 
Abstract: Sparse tensor operations are increasingly important in diverse applications such as social networks, deep learning, diagnosis, crime, and review analysis. However, a major obstacle in sparse tensor research is the lack of large-scale sparse tensor datasets. Another challenge lies in analyzing sparse tensor features, which are essential not only for understanding the nonzero pattern but also for selecting the most suitable storage format, decomposition algorithm, and reordering methods. However, due to the large size of real-world tensors, even extracting these features can be computationally expensive without careful optimization. To address these limitations, we have developed a smart sparse tensor generator that replicates key characteristics of real sparse tensors. Additionally, we propose efficient methods for extracting a comprehensive set of sparse tensor features. The effectiveness of our generator is validated through the quality of extracted features and the performance of decomposition on the generated tensors. Both the sparse tensor feature extractor and the tensor generator are open source with all the artifacts available at https://github.com/sparcityeu/FeaTensor and https://github.com/sparcityeu/GenTensor, respectively.</description>
      <guid isPermaLink="false">oai:arXiv.org:2405.04944v3</guid>
      <category>cs.MS</category>
      <category>cs.LG</category>
      <pubDate>Mon, 23 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Tugba Torun, Ameer Taweel, Didem Unat</dc:creator>
    </item>
  </channel>
</rss>
