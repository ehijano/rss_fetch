<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>cs.IT updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/cs.IT</link>
    <description>cs.IT updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/cs.IT" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Wed, 21 Jan 2026 05:00:30 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Wed, 21 Jan 2026 00:00:00 -0500</pubDate>
    <skipDays>
      <day>Sunday</day>
      <day>Saturday</day>
    </skipDays>
    <item>
      <title>Age-Based Scheduling for a Memory-Constrained Quantum Switch</title>
      <link>https://arxiv.org/abs/2601.11698</link>
      <description>arXiv:2601.11698v1 Announce Type: new 
Abstract: In a time-slotted system, we study the problem of scheduling multipartite entanglement requests in a quantum switch with a finite number of quantum memory registers. Specifically, we consider probabilistic link-level entanglement (LLE) generation for each user, probabilistic entanglement swapping, and one-slot decoherence. To evaluate the performance of the proposed scheduling policies, we introduce a novel age-based metric, coined age of entanglement establishment (AoEE). We consider two families of low-complexity policies for which we obtain closed-form expressions for their corresponding AoEE performance. Optimizing over each family, we obtain two policies. Further, we propose one more low-complexity policy and provide its performance guarantee. Finally, we numerically compare the performance of the proposed policies.</description>
      <guid isPermaLink="false">oai:arXiv.org:2601.11698v1</guid>
      <category>cs.IT</category>
      <category>cs.NI</category>
      <category>cs.SY</category>
      <category>eess.SY</category>
      <category>math.IT</category>
      <pubDate>Wed, 21 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Stavros Mitrolaris, Subhankar Banerjee, Sennur Ulukus</dc:creator>
    </item>
    <item>
      <title>Asymptotically Optimal Tests for One- and Two-Sample Problems</title>
      <link>https://arxiv.org/abs/2601.11727</link>
      <description>arXiv:2601.11727v1 Announce Type: new 
Abstract: In this work, we revisit the one- and two-sample testing problems: binary hypothesis testing in which one or both distributions are unknown. For the one-sample test, we provide a more streamlined proof of the asymptotic optimality of Hoeffding's likelihood ratio test, which is equivalent to the threshold test of the relative entropy between the empirical distribution and the nominal distribution. The new proof offers an intuitive interpretation and naturally extends to the two-sample test where we show that a similar form of Hoeffding's test, namely a threshold test of the relative entropy between the two empirical distributions is also asymptotically optimal. A strong converse for the two-sample test is also obtained.</description>
      <guid isPermaLink="false">oai:arXiv.org:2601.11727v1</guid>
      <category>cs.IT</category>
      <category>math.IT</category>
      <pubDate>Wed, 21 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Arick Grootveld, Biao Chen, Venkata Gandikota</dc:creator>
    </item>
    <item>
      <title>The Noisy Quantitative Group Testing Problem</title>
      <link>https://arxiv.org/abs/2601.11797</link>
      <description>arXiv:2601.11797v1 Announce Type: new 
Abstract: In this paper, we study the problem of quantitative group testing (QGT) and analyze the performance of three models: the noiseless model, the additive Gaussian noise model, and the noisy Z-channel model. For each model, we analyze two algorithmic approaches: a linear estimator based on correlation scores, and a least squares estimator (LSE). We derive upper bounds on the number of tests required for exact recovery with vanishing error probability, and complement these results with information-theoretic lower bounds. In the additive Gaussian noise setting, our lower and upper bounds match in order.</description>
      <guid isPermaLink="false">oai:arXiv.org:2601.11797v1</guid>
      <category>cs.IT</category>
      <category>math.IT</category>
      <pubDate>Wed, 21 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Tenghao Li, Neha Sangwan, Xiaxin Li, Arya Mazumdar</dc:creator>
    </item>
    <item>
      <title>Bayesian ICA for Causal Discovery</title>
      <link>https://arxiv.org/abs/2601.11815</link>
      <description>arXiv:2601.11815v1 Announce Type: new 
Abstract: Causal discovery based on Independent Component Analysis (ICA) has achieved remarkable success through the LiNGAM framework, which exploits non-Gaussianity and independence of noise variables to identify causal order. However, classical LiNGAM methods rely on the strong assumption that there exists an ordering under which the noise terms are exactly independent, an assumption that is often violated in the presence of confounding. In this paper, we propose a general information-theoretic framework for causal order estimation that remains applicable under arbitrary confounding. Rather than imposing independence as a hard constraint, we quantify the degree of confounding by the multivariate mutual information among the noise variables. This quantity is decomposed into a sum of mutual information terms along a causal order and is estimated using Bayesian marginal likelihoods. The resulting criterion can be interpreted as Bayesian ICA for causal discovery, where causal order selection is formulated as a model selection problem over permutations. Under standard regularity conditions, we show that the proposed Bayesian mutual information estimator is consistent, with redundancy of order $O(\log n)$. To avoid non-identifiability caused by Gaussian noise, we employ non-Gaussian predictive models, including multivariate $t$ distributions, whose marginal likelihoods can be evaluated via MCMC. The proposed method recovers classical LiNGAM and DirectLiNGAM as limiting cases in the absence of confounding, while providing a principled ranking of causal orders when confounding is present. This establishes a unified, confounding-aware, and information-theoretically grounded extension of ICA-based causal discovery.</description>
      <guid isPermaLink="false">oai:arXiv.org:2601.11815v1</guid>
      <category>cs.IT</category>
      <category>math.IT</category>
      <pubDate>Wed, 21 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Joe Suzuki</dc:creator>
    </item>
    <item>
      <title>On the R\'enyi Rate-Distortion-Perception Function and Functional Representations</title>
      <link>https://arxiv.org/abs/2601.11862</link>
      <description>arXiv:2601.11862v1 Announce Type: new 
Abstract: We extend the Rate-Distortion-Perception (RDP) framework to the R\'enyi information-theoretic regime, utilizing Sibson's $\alpha$-mutual information to characterize the fundamental limits under distortion and perception constraints. For scalar Gaussian sources, we derive closed-form expressions for the R\'enyi RDP function, showing that the perception constraint induces a feasible interval for the reproduction variance. Furthermore, we establish a R\'enyi-generalized version of the Strong Functional Representation Lemma. Our analysis reveals a phase transition in the complexity of optimal functional representations: for $0.5&lt;\alpha &lt; 1$, the coding cost is bounded by the $\alpha$-divergence of order $\alpha+1$, necessitating a codebook with heavy-tailed polynomial decay; conversely, for $\alpha &gt; 1$, the representation collapses to one with finite support, offering new insights into the compression of shared randomness under generalized notions of mutual information.</description>
      <guid isPermaLink="false">oai:arXiv.org:2601.11862v1</guid>
      <category>cs.IT</category>
      <category>math.IT</category>
      <pubDate>Wed, 21 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Jiahui Wei, Marios Kountouris</dc:creator>
    </item>
    <item>
      <title>Rate-Distortion-Classification Representation Theory for Bernoulli Sources</title>
      <link>https://arxiv.org/abs/2601.11919</link>
      <description>arXiv:2601.11919v1 Announce Type: new 
Abstract: We study task-oriented lossy compression through the lens of rate-distortion-classification (RDC) representations. The source is Bernoulli, the distortion measure is Hamming, and the binary classification variable is coupled to the source via a binary symmetric model. Building on the one-shot common-randomness formulation, we first derive closed-form characterizations of the one-shot RDC and the dual distortion-rate-classification (DRC) tradeoffs. We then use a representation-based viewpoint and characterize the achievable distortion-classification (DC) region induced by a fixed representation by deriving its lower boundary via a linear program. Finally, we study universal encoders that must support a family of DC operating points and derive computable lower and upper bounds on the minimum asymptotic rate required for universality, thereby yielding bounds on the corresponding rate penalty. Numerical examples are provided to illustrate the achievable regions and the resulting universal RDC/DRC curves.</description>
      <guid isPermaLink="false">oai:arXiv.org:2601.11919v1</guid>
      <category>cs.IT</category>
      <category>math.IT</category>
      <pubDate>Wed, 21 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Nam Nguyen, Thinh Nguyen, Bella Bose</dc:creator>
    </item>
    <item>
      <title>Exact Redundancy for Symmetric Rate-Distortion</title>
      <link>https://arxiv.org/abs/2601.11927</link>
      <description>arXiv:2601.11927v1 Announce Type: new 
Abstract: For variable-length coding with an almost-sure distortion constraint, Zhang et al. show that for discrete sources the redundancy is upper bounded by $\log n/n$ and lower bounded (in most cases) by $\log n/(2n)$, ignoring lower order terms. For a uniform source with a distortion measure satisfying certain symmetry conditions, we show that $\log n/(2n)$ is achievable and that this cannot be improved even if one relaxes the distortion constraint to be in expectation rather than with probability one.</description>
      <guid isPermaLink="false">oai:arXiv.org:2601.11927v1</guid>
      <category>cs.IT</category>
      <category>math.IT</category>
      <pubDate>Wed, 21 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Sharang M. Sriramu, Aaron B. Wagner</dc:creator>
    </item>
    <item>
      <title>Small-Error Cascaded Group Testing</title>
      <link>https://arxiv.org/abs/2601.11945</link>
      <description>arXiv:2601.11945v1 Announce Type: new 
Abstract: Group testing concerns itself with the accurate recovery of a set of "defective" items from a larger population via a series of tests. While most works in this area have considered the classical group testing model, where tests are binary and indicate the presence of at least one defective item in the test, we study the cascaded group testing model. In cascaded group testing, tests admit an ordering, and test outcomes indicate the first defective item in the test under this ordering. Under this model, we establish various achievability bounds for several different recovery criteria using both non-adaptive and adaptive (with "few" stages) test designs.</description>
      <guid isPermaLink="false">oai:arXiv.org:2601.11945v1</guid>
      <category>cs.IT</category>
      <category>math.IT</category>
      <pubDate>Wed, 21 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Daniel McMorrow, Nikhil Karamchandani, Sidharth Jaggi</dc:creator>
    </item>
    <item>
      <title>Generalizing the Fano inequality further</title>
      <link>https://arxiv.org/abs/2601.12027</link>
      <description>arXiv:2601.12027v1 Announce Type: new 
Abstract: Interactive statistical decision making (ISDM) features algorithm-dependent data generated through interaction. Existing information-theoretic lower bounds in ISDM largely target expected risk, while tail-sensitive objectives are less developed. We generalize the interactive Fano framework of Chen et al. by replacing the hard success event with a randomized one-bit statistic representing an arbitrary bounded transform of the loss. This yields a Bernoulli f-divergence inequality, which we invert to obtain a two-sided interval for the transform, recovering the previous result as a special case. Instantiating the transform with a bounded hinge and using the Rockafellar-Uryasev representation, we derive lower bounds on the prior-predictive (Bayesian) CVaR of bounded losses. For KL divergence with the mixture reference distribution, the bound becomes explicit in terms of mutual information via Pinsker's inequality.</description>
      <guid isPermaLink="false">oai:arXiv.org:2601.12027v1</guid>
      <category>cs.IT</category>
      <category>math.IT</category>
      <pubDate>Wed, 21 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Raghav Bongole, Tobias J. Oechtering, Mikael Skoglund</dc:creator>
    </item>
    <item>
      <title>Function Computation Over Multiple Access Channels via Hierarchical Constellations</title>
      <link>https://arxiv.org/abs/2601.12050</link>
      <description>arXiv:2601.12050v1 Announce Type: new 
Abstract: We study function computation over a Gaussian multiple-access channel (MAC), where multiple transmitters aim at computing a function of their values at a common receiver. To this end, we propose a novel coded-modulation framework for over-the-air computation (OAC) based on hierarchical constellation design, which supports reliable computation of multiple function outputs using a single channel use. Moreover, we characterize the achievable computation rate and show that the proposed hierarchical constellations can compute R output functions with decoding error probability epsilon while the gap to the optimal computation rate scales as O(\log_2(1/\epsilon)/K) for independent source symbols, where K denotes the number of transmitters. Consequently, this gap vanishes as the network size grows, and the optimal rate is asymptotically attained.
  Furthermore, we introduce a shielding mechanism based on variable-length block coding that mitigates noise-induced error propagation across constellation levels while preserving the superposition structure of the MAC. We show that the shielding technique improves reliability, yielding a gap that scales optimally as O(\log_2\ln{(1/\epsilon)}), regardless of the source distribution. Together, these results identify the regimes in which uncoded or lightly coded OAC is information-theoretically optimal, providing a unified framework for low-latency, channel-agnostic function computation.</description>
      <guid isPermaLink="false">oai:arXiv.org:2601.12050v1</guid>
      <category>cs.IT</category>
      <category>math.IT</category>
      <pubDate>Wed, 21 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <dc:creator>Saeed Razavikia, Mohammad Kazemi, Deniz G\"und\"uz, Carlo Fischione</dc:creator>
    </item>
    <item>
      <title>On the Construction and Correlation Properties of Permutation-Interleaved Zadoff-Chu Sequences</title>
      <link>https://arxiv.org/abs/2601.12107</link>
      <description>arXiv:2601.12107v1 Announce Type: new 
Abstract: Constant amplitude zero auto-correlation (CAZAC) sequences are widely applied in waveforms for radar and communication systems. Motivated by a recent work [Berggren and Popovi\'c, IEEE Trans. Inf. Theory 70(8), 6068-6075 (2024)], this paper further investigates the approach to generating CAZAC sequences by interleaving Zadoff-Chu (ZC) sequences with permutation polynomials (PPs). We propose one class of high-degree PPs over the integer ring Z N , and utilize them and their inverses to interleave ZC sequences for constructing CAZAC sequences. It is known that a CAZAC sequence can be extended to an equivalence class by five basic opertations. We further show that the obtained CAZAC sequences are not covered by the equivalence classes of ZC sequences and interleaved ZC sequences by quadratic PPs and their inverses, and prove the sufficiency of the conjecture by Berggren and Popovi\'c in the aforementioned work. In addition, we also evaluate the aperiodic auto-correlation of certain ZC sequences from quadratic PPs.</description>
      <guid isPermaLink="false">oai:arXiv.org:2601.12107v1</guid>
      <category>cs.IT</category>
      <category>math.IT</category>
      <pubDate>Wed, 21 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Qin Yuan, Chunlei Li, Xiangyong Zeng</dc:creator>
    </item>
    <item>
      <title>Coherent Comparison as Information Cost: A Cost-First Ledger Framework for Discrete Dynamics</title>
      <link>https://arxiv.org/abs/2601.12194</link>
      <description>arXiv:2601.12194v1 Announce Type: new 
Abstract: We develop an information-theoretic framework for discrete dynamics grounded in a comparison-cost functional on ratios. Given two quantities compared via their ratio \(x=a/b\), we assign a cost \(F(x)\) measuring deviation from equilibrium (\(x=1\)). Requiring coherent composition under multiplicative chaining imposes a d'Alembert functional equation; together with normalization (\(F(1)=0\)) and quadratic calibration at unity, this yields a unique reciprocal cost functional (proved in a companion paper): \[ J(x) = \tfrac{1}{2}\bigl(x + x^{-1}\bigr) - 1. \] This cost exhibits reciprocity \(J(x)=J(x^{-1})\), vanishes only at \(x=1\), and diverges at boundary regimes \(x\to 0^+\) and \(x\to\infty\), excluding ``nothingness'' configurations. Using \(J\) as input, we introduce a discrete ledger as a minimal lossless encoding of recognition events on directed graphs. Under deterministic update semantics and minimality (no intra-tick ordering metadata), we derive atomic ticks (at most one event per tick). Explicit structural assumptions (conservation, no sources/sinks, pairwise locality, quantization in \(\delta\mathbb{Z}\)) force balanced double-entry postings and discrete ledger units. To obtain scalar potentials on graphs with cycles while retaining single-edge impulses per tick, we impose time-aggregated cycle closure (no-arbitrage/clearing over finite windows). Under this hypothesis, cycle closure is equivalent to path-independence, and the cleared cumulative flow admits a unique scalar potential on each connected component (up to additive constant), via a discrete Poincar\'e lemma. On hypercube graphs \(Q_d\), atomicity imposes a \(2^d\)-tick minimal period, with explicit Gray-code realization at \(d=3\). The framework connects ratio-based divergences, conservative graph flows, and discrete potential theory through a coherence-forced cost structure.</description>
      <guid isPermaLink="false">oai:arXiv.org:2601.12194v1</guid>
      <category>cs.IT</category>
      <category>math.IT</category>
      <pubDate>Wed, 21 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Sebastian Pardo-Guerra, Megan Simons, Anil Thapa, Jonathan Washburn</dc:creator>
    </item>
    <item>
      <title>Classical-Quantum Channel Resolvability Using Matrix Multiplicative Weight Update Algorithm</title>
      <link>https://arxiv.org/abs/2601.12230</link>
      <description>arXiv:2601.12230v1 Announce Type: new 
Abstract: We study classical-quantum (C-Q) channel resolvability. C-Q channel resolvability has been proved by only random coding in the literature. In our previous study, we proved channel resolvability by deterministic coding, using multiplicative weight update algorithm. We extend this approach to C-Q channels and prove C-Q channel resolvability by deterministic coding, using the matrix multiplicative weight update algorithm. This is the first approach to C-Q channel resolvability using deterministic coding.</description>
      <guid isPermaLink="false">oai:arXiv.org:2601.12230v1</guid>
      <category>cs.IT</category>
      <category>math.IT</category>
      <category>quant-ph</category>
      <pubDate>Wed, 21 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Koki Takahashi, Shun Watanabe</dc:creator>
    </item>
    <item>
      <title>On the Minimum Length of Functional Batch Codes with Small Recovery Sets</title>
      <link>https://arxiv.org/abs/2601.12302</link>
      <description>arXiv:2601.12302v1 Announce Type: new 
Abstract: Batch codes are of potential use for load balancing and private information retrieval in distributed data storage systems. Recently, a special case of batch codes, termed functional batch codes, was proposed in the literature. In functional batch codes, users can query linear combinations of the information symbols, and not only the information symbols themselves, as is the case for standard batch codes. In this work, we consider linear functional batch codes with the additional property that every query is answered by using only a small number of coded symbols. We derive bounds on the minimum length of such codes, and evaluate the results by numerical computations.</description>
      <guid isPermaLink="false">oai:arXiv.org:2601.12302v1</guid>
      <category>cs.IT</category>
      <category>math.IT</category>
      <pubDate>Wed, 21 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Kristiina Oksner, Henk D. L. Hollmann, Ago-Erik Riet, Vitaly Skachek</dc:creator>
    </item>
    <item>
      <title>$2$-quasi-perfect Lee codes and abelian Ramanujan graphs: a new construction and relationship</title>
      <link>https://arxiv.org/abs/2601.12393</link>
      <description>arXiv:2601.12393v1 Announce Type: new 
Abstract: In this paper, we obtain a new explicit family of $2$-quasi-perfect Lee codes of arbitrarily large length. Our construction is based on generating sets of abelian (almost) Ramanujan graphs obtained by Forey, Fres\'{a}n, Kowalski and Wigderson. Also, we develop a relationship between certain abelian Ramanujan graphs and $2$-quasi-perfect Lee codes obtained by Mesnager, Tang and Qi.</description>
      <guid isPermaLink="false">oai:arXiv.org:2601.12393v1</guid>
      <category>cs.IT</category>
      <category>math.CO</category>
      <category>math.IT</category>
      <pubDate>Wed, 21 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Shohei Satake</dc:creator>
    </item>
    <item>
      <title>Privacy via Modulation Rotation and Inter-Symbol Interference</title>
      <link>https://arxiv.org/abs/2601.12394</link>
      <description>arXiv:2601.12394v1 Announce Type: new 
Abstract: Two physical-layer mechanisms for achieving user-side differential privacy in communication systems are proposed. Focusing on binary phase-shift keying (BPSK) modulation, differential privacy (DP) is first studied under a deterministic phase rotation applied on the BPSK modulation at the transmitter, while the receiver is assumed to be unaware of the rotation angle. In this setting, privacy is achieved through an effective reduction in the decision distance, resulting in a controlled increase in the bit error rate (BER) without explicit noise injection. Next, a BPSK transmission scheme with intentionally induced inter-symbol interference (ISI) is studied, where the receiver is likewise unaware of the deterministic timing offset that generates the ISI. Unlike the rotated BPSK scheme, the DP obtained via ISI is shown to depend explicitly on the input data distribution. In particular, numerical results demonstrate that, for a fixed ISI parameter, the privacy loss is maximized when the binary input symbols are equiprobable. While conventional DP mechanisms rely on artificially added noise, often incurring additional energy or communication costs, it is shown that structured modifications, such as modulation rotation or induced ISI inherent to realistic communication channels can itself provide DP guarantees. While the analysis focuses on deterministic transmitter modifications unknown to the receiver, it is noted that real-world devices naturally introduce unintentional rotations or ISI due to hardware nonidealities and implementation errors. These effects can therefore provide a level of privacy without requiring explicit noise injection. Hence, it is possible to avoid deliberately perturbing the data, instead leveraging inherent device imperfections to achieve privacy guarantees with no additional privacy cost.</description>
      <guid isPermaLink="false">oai:arXiv.org:2601.12394v1</guid>
      <category>cs.IT</category>
      <category>math.IT</category>
      <pubDate>Wed, 21 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Morteza Varasteh, Pegah Sharifi</dc:creator>
    </item>
    <item>
      <title>Counterexamples, Constructions, and Nonexistence Results for Optimal Ternary Cyclic Codes</title>
      <link>https://arxiv.org/abs/2601.12427</link>
      <description>arXiv:2601.12427v1 Announce Type: new 
Abstract: Cyclic codes are an important subclass of linear codes with wide applications in communication systems and data storage systems. In 2013, Ding and Helleseth presented nine open problems on optimal ternary cyclic codes $\mathcal{C}_{(1,e)}$. While the first two and the sixth problems have been fully solved, others remain open. In this paper, we advance the study of the third and fourth open problems by providing the first counterexamples to both and constructing two families of optimal codes under certain conditions, thereby partially solving the third problem. Furthermore, we investigate the cyclic codes $\mathcal{C}_{(1,e)}$ where $e(3^h\pm 1)\equiv\frac{3^m-a}{2}\pmod{3^m-1}$ and $a$ is odd. For $a\equiv 3\pmod{4}$, we present two new families of optimal codes with parameters $[3^m-1,3^m-1-2m,4]$, generalizing known constructions. For $a\equiv 1\pmod{4}$, we obtain several nonexistence results on optimal codes $\mathcal{C}_{(1,e)}$ with the aforementioned parameters revealing the constraints of such codes.</description>
      <guid isPermaLink="false">oai:arXiv.org:2601.12427v1</guid>
      <category>cs.IT</category>
      <category>math.CO</category>
      <category>math.IT</category>
      <pubDate>Wed, 21 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Jingjun Bao, Hanlin Zou</dc:creator>
    </item>
    <item>
      <title>The Origin of the Inaccessible Game</title>
      <link>https://arxiv.org/abs/2601.12576</link>
      <description>arXiv:2601.12576v1 Announce Type: new 
Abstract: The inaccessible game is an information-geometric framework where dynamics of information loss emerge from maximum entropy production under marginal-entropy conservation.
  We study the game's starting state, the origin. Classical Shannon entropy forbids a representation with zero joint entropy and positive marginal entropies: non-negativity of conditional entropy rules this out. Replacing Shannon with von Neumann entropy within the Baez Fritz Leinster Parzygnat categorical framework removes this obstruction and admits a well-defined origin: a globally pure state with maximally mixed marginals, selected up to local-unitary equivalence. At this LME origin, marginal-entropy conservation becomes a second-order geometric condition. Because the marginal-entropy sum is saturated termwise, the constraint gradient vanishes and first-order tangency is vacuous; admissible directions are selected by the kernel of the constraint Hessian, characterised by the marginal-preserving tangent space.
  We derive the constrained gradient flow in the matrix exponential family and show that, as the origin is approached, the affine time parameter degenerates. This motivates an axiomatically distinguished reparametrisation, entropy time $t$, defined by $dH/dt = c$ for fixed constant $c&gt;0$. In this parametrisation, the infinite affine-time approach to the boundary maps to a finite entropy-time interval. The constrained dynamics split into a symmetric dissipative component realising SEA and a reversible component represented as unitary evolution.
  As in the classical game, marginal-entropy conservation is equivalent to conservation of a sum of local modular Hamiltonian expectations, a state-dependent "modular energy"; in Gibbs regimes where local modular generators become approximately parameter-invariant, this reduces to familiar fixed-energy constraints from nonequilibrium thermodynamics.</description>
      <guid isPermaLink="false">oai:arXiv.org:2601.12576v1</guid>
      <category>cs.IT</category>
      <category>math.IT</category>
      <pubDate>Wed, 21 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Neil D. Lawrence</dc:creator>
    </item>
    <item>
      <title>Beyond Identification: Computing Boolean Functions via Channels</title>
      <link>https://arxiv.org/abs/2601.12640</link>
      <description>arXiv:2601.12640v1 Announce Type: new 
Abstract: Consider a point-to-point communication system in which the transmitter holds a binary message of length $m$ and transmits a corresponding codeword of length $n$. The receiver's goal is to recover a Boolean function of that message, where the function is unknown to the transmitter, but chosen from a known class $F$. We are interested in the asymptotic relationship of $m$ and $n$: given $n$, how large can $m$ be (asymptotically), such that the value of the Boolean function can be recovered reliably? This problem generalizes the identification-via-channels framework introduced by Ahlswede and Dueck. We formulate the notion of computation capacity, and derive achievability and converse results for selected classes of functions $F$, characterized by the Hamming weight of functions. Our obtained results are tight in the sense of the scaling behavior for all cases of $F$ considered in the paper.</description>
      <guid isPermaLink="false">oai:arXiv.org:2601.12640v1</guid>
      <category>cs.IT</category>
      <category>math.IT</category>
      <pubDate>Wed, 21 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Jingge Zhu, Matthias Frey</dc:creator>
    </item>
    <item>
      <title>Explicit Entropic Constructions for Coverage, Facility Location, and Graph Cuts</title>
      <link>https://arxiv.org/abs/2601.12724</link>
      <description>arXiv:2601.12724v1 Announce Type: new 
Abstract: Shannon entropy is a polymatroidal set function and lies at the foundation of information theory, yet the class of entropic polymatroids is strictly smaller than the class of all submodular functions. In parallel, submodular and combinatorial information measures (SIMs) have recently been proposed as a principled framework for extending entropy, mutual information, and conditional mutual information to general submodular functions, and have been used extensively in data subset selection, active learning, domain adaptation, and representation learning. This raises a natural and fundamental question: are the monotone submodular functions most commonly used in practice entropic?
  In this paper, we answer this question in the affirmative for a broad class of widely used polymatroid functions. We provide explicit entropic constructions for set cover and coverage functions, facility location, saturated coverage, concave-over-modular functions via truncations, and monotone graph-cut-type objectives. Our results show that these functions can be realized exactly as Shannon entropies of appropriately constructed random variables. As a consequence, for these functions, submodular mutual information coincides with classical mutual information, conditional gain specializes to conditional entropy, and submodular conditional mutual information reduces to standard conditional mutual information in the entropic sense. These results establish a direct bridge between combinatorial information measures and classical information theory for many of the most common submodular objectives used in applications.</description>
      <guid isPermaLink="false">oai:arXiv.org:2601.12724v1</guid>
      <category>cs.IT</category>
      <category>math.CO</category>
      <category>math.IT</category>
      <pubDate>Wed, 21 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Rishabh Iyer</dc:creator>
    </item>
    <item>
      <title>Extended Gabidulin-Kronecker Product Codes and Their Application to Cryptosystems</title>
      <link>https://arxiv.org/abs/2601.12780</link>
      <description>arXiv:2601.12780v1 Announce Type: new 
Abstract: In this paper, we initiate the study of Extended Gabidulin codes with a Kronecker product structure and propose three enhanced variants of the Rank Quasi-Cyclic (RQC) (Melchor et.al., IEEE IT, 2018) cryptosystem. First, we establish precise bounds on the minimum rank distance of Gabidulin-Kronecker product codes under two distinct parameter regimes. Specifically, when $n_{1}=k_{1}$ and $n_{2}=m&lt;n_{1}n_{2}$, the minimum rank distance is exactly $n_{2}-k_{2}+1$. This yields a new family of Maximum Rank Distance (MRD) codes, which are distinct from classical Gabidulin codes. For the case of $k_{1}\leq n_{1},k_{2}\leq n_{2},n_{1}n_{2}\leq m$, the minimum rank distance $d$ of Gabidulin-Kronecker product codes satisfies a tight upper and lower bound, i.e., $n_{2}-k_{2}+1 \leq d \leq (n_{1}-k_{1}+1)(n_{2}-k_{2}+1)$. Second, we introduce a new class of decodable rank-metric codes, namely Extended Gabidulin-Kronecker product (EGK) codes, which generalize the structure of Gabidulin-Kronecker product (GK) codes. We also propose a decoding algorithm that directly retrieves the codeword without recovering the error vector, thus improving efficiency. This algorithm achieves zero decoding failure probability when the error weight is within its correction capability. Third, we propose three enhanced variants of the RQC cryptosystem based on EGK codes, each offering a distinct trade-off between security and efficiency. For 128-bit security, all variants achieve significant reductions in public key size compared to the Multi-UR-AG (Bidoux et.al., IEEE IT, 2024) while ensuring zero decryption failure probability--a key security advantage over many existing rank-based schemes.</description>
      <guid isPermaLink="false">oai:arXiv.org:2601.12780v1</guid>
      <category>cs.IT</category>
      <category>math.IT</category>
      <pubDate>Wed, 21 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <dc:creator>Zhe Sun, Terry Shue Chien Lau, Mengying Zhao, Zimeng Zhou, Fang-Wei Fu</dc:creator>
    </item>
    <item>
      <title>Joint Source-Channel-Generation Coding: From Distortion-oriented Reconstruction to Semantic-consistent Generation</title>
      <link>https://arxiv.org/abs/2601.12808</link>
      <description>arXiv:2601.12808v1 Announce Type: new 
Abstract: Conventional communication systems, including both separation-based coding and AI-driven joint source-channel coding (JSCC), are largely guided by Shannon's rate-distortion theory. However, relying on generic distortion metrics fails to capture complex human visual perception, often resulting in blurred or unrealistic reconstructions. In this paper, we propose Joint Source-Channel-Generation Coding (JSCGC), a novel paradigm that shifts the focus from deterministic reconstruction to probabilistic generation. JSCGC leverages a generative model at the receiver as a generator rather than a conventional decoder to parameterize the data distribution, enabling direct maximization of mutual information under channel constraints while controlling stochastic sampling to produce outputs residing on the authentic data manifold with high fidelity. We further derive a theoretical lower bound on the maximum semantic inconsistency with given transmitted mutual information, elucidating the fundamental limits of communication in controlling the generative process. Extensive experiments on image transmission demonstrate that JSCGC substantially improves perceptual quality and semantic fidelity, significantly outperforming conventional distortion-oriented JSCC methods.</description>
      <guid isPermaLink="false">oai:arXiv.org:2601.12808v1</guid>
      <category>cs.IT</category>
      <category>cs.CV</category>
      <category>cs.LG</category>
      <category>math.IT</category>
      <pubDate>Wed, 21 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Tong Wu, Zhiyong Chen, Guo Lu, Li Song, Feng Yang, Meixia Tao, Wenjun Zhang</dc:creator>
    </item>
    <item>
      <title>On the Concavity of Tsallis Entropy along the Heat Flow</title>
      <link>https://arxiv.org/abs/2601.12944</link>
      <description>arXiv:2601.12944v1 Announce Type: new 
Abstract: We demonstrate the concavity of the Tsallis entropy along the heat flow for general dimensions, expanding upon the findings of Wu et al 2025 and Hung 2022, which were previously limited to the one-dimensional case. The core of the proof is a novel estimate of the terms in the second-order time derivative, and a rigorous validation of integration by parts. The resulting bound establishes a new functional inequality, which may be of interest for other areas of mathematical analysis.</description>
      <guid isPermaLink="false">oai:arXiv.org:2601.12944v1</guid>
      <category>cs.IT</category>
      <category>math.IT</category>
      <pubDate>Wed, 21 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Lukang Sun</dc:creator>
    </item>
    <item>
      <title>Codes Correcting Few Restricted Errors</title>
      <link>https://arxiv.org/abs/2601.12959</link>
      <description>arXiv:2601.12959v1 Announce Type: new 
Abstract: We consider linear codes over a field in which the error values are restricted to a subgroup of its unit group. This scenario captures Lee distance codes as well as codes over the Gaussian or Eisenstein integers. Codes correcting restricted errors gained increased attention recently in the context of code-based cryptography.
  In this work we provide new constructions of codes over the Gaussian or Eisenstein integers correcting two or three errors. We adapt some techniques from Roth and Siegel's work on codes for the Lee metric. We propose two construction methods, which may be seen of geometric and algebraic flavor, respectively.</description>
      <guid isPermaLink="false">oai:arXiv.org:2601.12959v1</guid>
      <category>cs.IT</category>
      <category>math.IT</category>
      <pubDate>Wed, 21 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Jens Zumbr\"agel</dc:creator>
    </item>
    <item>
      <title>Weighted-Hamming Metric: Bounds and Codes</title>
      <link>https://arxiv.org/abs/2601.12998</link>
      <description>arXiv:2601.12998v1 Announce Type: new 
Abstract: The weighted-Hamming metric generalizes the Hamming metric by assigning different weights to blocks of coordinates. It is well-suited for applications such as coding over independent parallel channels, each of which has a different level of importance or noise. From a coding-theoretic perspective, the actual error-correction capability of a code under this metric can exceed half its minimum distance. In this work, we establish direct bounds on this capability, tightening those obtained via minimum-distance arguments. We also propose a flexible code construction based on generalized concatenation and show that these codes can be efficiently decoded up to a lower bound on the error-correction capability.</description>
      <guid isPermaLink="false">oai:arXiv.org:2601.12998v1</guid>
      <category>cs.IT</category>
      <category>math.IT</category>
      <pubDate>Wed, 21 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Sebastian Bitzer, Alberto Ravagnani, Violetta Weger</dc:creator>
    </item>
    <item>
      <title>Two-timescale Optimization for Hybrid Mechanically and Electronically Tunable 6DMA Aided Communication</title>
      <link>https://arxiv.org/abs/2601.13064</link>
      <description>arXiv:2601.13064v1 Announce Type: new 
Abstract: This letter proposes a hybrid mechanically and electronically tunable six-dimensional movable antenna (6DMA) base station (BS) architecture for future wireless communication networks. Such BS consists of multiple antenna arrays that are mechanically movable along a circular rail to adapt to the horizontal user hotspots, and each array is equipped with pattern reconfigurable antennas (PRAs) that are capable of electronically switching among a set of specified beam patterns to cater to the instantaneous user channels. The mechanical adjustment provides wide-angle coverage but suffers from slow response, while the electronic tuning enables rapid beam reconfiguration but with limited angular range. To effectively combine their complementary advantages, we propose to jointly design both mechanical and electronic configurations to maximize the average sum-rate of users via a two-timescale optimization approach, in which the array positions are optimized on the long timescale according to large-scale user distribution statistics, and the pattern selection vectors are optimized on the short timescale to enable fast beam alignment based on the instantaneous user locations. An alternating optimization algorithm based on the Monte Carlo sampling method is developed to solve the problem efficiently. Finally, simulation results show that our proposed design achieves significant performance gains over various benchmark schemes.</description>
      <guid isPermaLink="false">oai:arXiv.org:2601.13064v1</guid>
      <category>cs.IT</category>
      <category>math.IT</category>
      <pubDate>Wed, 21 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Yuyan Zhou, Haocheng Hua, Jie Xu, Rui Zhang</dc:creator>
    </item>
    <item>
      <title>An AMP-Based Asymptotic Analysis For Nonlinear One-Bit Precoding</title>
      <link>https://arxiv.org/abs/2601.13214</link>
      <description>arXiv:2601.13214v1 Announce Type: new 
Abstract: This paper focuses on the asymptotic analysis of a class of nonlinear one-bit precoding schemes under Rayleigh fading channels. The considered scheme employs a convex-relaxation-then-quantization (CRQ) approach to the well-known minimum mean square error (MMSE) model, which includes the classical one-bit precoder SQUID as a special case. To analyze its asymptotic behavior, we develop a novel analytical framework based on approximate message passing (AMP). We show that, the statistical properties of the considered scheme can be asymptotically characterized by a scalar ``signal plus Gaussian noise'' model. Based on this, we further derive a closed-form expression for the symbol error probability (SEP) in the large-system limit, which quantitatively characterizes the impact of both system and model parameters on SEP performance. Simulation results validate our analysis and also demonstrate that performance gains over SQUID can be achieved by appropriately tuning the parameters involved in the considered model.</description>
      <guid isPermaLink="false">oai:arXiv.org:2601.13214v1</guid>
      <category>cs.IT</category>
      <category>eess.SP</category>
      <category>math.IT</category>
      <pubDate>Wed, 21 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Zheyu Wu, Junjie Ma, Ya-Feng Liu, Bruno Clerckx</dc:creator>
    </item>
    <item>
      <title>On the Reliability of Estimation Bounds in Low-SNR Bistatic ISAC</title>
      <link>https://arxiv.org/abs/2601.13216</link>
      <description>arXiv:2601.13216v1 Announce Type: new 
Abstract: This paper explores a bistatic Integrated Sensing and Communication (ISAC) framework, where a base station transmits communication signal that serve both direct communication with a user and multi-target parameter estimation through reflections captured by a separate sensing receiver. We assume that the instantaneous knowledge of the transmit signal at the sensing receiver is not available, and the sensing receiver only has knowledge of the statistical properties of the received signal. Unlike prior research that focuses on power allocation or optimal beamforming design for ISAC, we emphasize the inadequacy of the Cram\'er-Rao Bound (and its variant) in low Signal-to-Noise Ratio (SNR) regimes, particularly in passive sensing scenarios. Due to severe path loss and other impairments, the received sensing SNR is often significantly lower than that of direct Line-of-Sight communication, making CRB-based performance evaluation unreliable. To address this, we adopt the Ziv-Zakai Bound (ZZB) for Angle of Arrival estimation, which provides a more meaningful lower bound on estimation error. We derive analytical expressions for the ZZB and the achievable ergodic communication rate as functions of SNR. Through numerical simulations, we analyze the pareto-front between communication and sensing performance, demonstrating why ZZB serves as a better metric in low sensing SNR ISAC where traditional CRB-based approaches fail.</description>
      <guid isPermaLink="false">oai:arXiv.org:2601.13216v1</guid>
      <category>cs.IT</category>
      <category>math.IT</category>
      <pubDate>Wed, 21 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Ataher Sams, Besma Smida</dc:creator>
    </item>
    <item>
      <title>Elias-type Bounds for Codes in the Symmetric Limited-Magnitude Error Channel</title>
      <link>https://arxiv.org/abs/2601.13477</link>
      <description>arXiv:2601.13477v1 Announce Type: new 
Abstract: We study perfect error-correcting codes in $\mathbb{Z}^n$ for the symmetric limited-magnitude error channel, where at most $e$ coordinates of an integer vector may be altered by a value whose magnitude is at most $s$. Geometrically, such codes correspond to tilings of $\mathbb{Z}^n$ by the symmetric limited-magnitude error ball $\mathcal{B}(n,e,s,s)$. Given $n$ and $s$, we adapt the geometric ideas underlying the Elias bound for the Hamming metric to the distance $d_s$ tailed for this channel, and derive new necessary conditions on $e$ for the existence of perfect codes / tilings, without assuming any lattice structure. Our main results identify two distinct regimes depending on the error magnitude. For small error magnitudes ($s \in \{1, 2\}$), we prove that if the number of correctable errors does not exceed a certain fraction of $n$, then it is asymptotically bounded by $e = \mathcal{O}(\sqrt{n \log n})$. In contrast, for larger magnitudes ($s \geq 3$), we establish a significantly sharper bound of $e &lt; \sqrt{12.36n}$, which holds without any restriction on $e$ being below a given fraction of $n$. Finally, by extending our method to non-perfect codes, we derive an upper bound on packing density, showing that for codes correcting a linear or $\Omega(\sqrt{n})$ number of errors, the density is bounded by a factor inversely proportional to the error magnitude $s$.</description>
      <guid isPermaLink="false">oai:arXiv.org:2601.13477v1</guid>
      <category>cs.IT</category>
      <category>math.IT</category>
      <pubDate>Wed, 21 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Zhihao Guan, Hengjia Wei</dc:creator>
    </item>
    <item>
      <title>Group Relative Policy Optimization for Robust Blind Interference Alignment with Fluid Antennas</title>
      <link>https://arxiv.org/abs/2601.13506</link>
      <description>arXiv:2601.13506v1 Announce Type: new 
Abstract: Fluid antenna system (FAS) leverages dynamic reconfigurability to unlock spatial degrees of freedom and reshape wireless channels. This paper proposes, for the first time, a robust fluid antenna-driven blind interference alignment (BIA) framework for a K-user MISO downlink under imperfect channel state information (CSI). We formulate a robust sum-rate maximization problem through optimizing fluid antenna positions. To solve this challenging non-convex problem, we employ group relative policy optimization (GRPO), a novel deep reinforcement learning algorithm that eliminates the critic network. This robust design reduces model size and floating point operations (FLOPs) by nearly half compared to proximal policy optimization (PPO) while significantly enhancing performance through group-based exploration that escapes bad local optima. Simulation results demonstrate that GRPO outperforms PPO by 4.17%, and a 100K-step pre-trained PPO by 30.29%. Due to error distribution learning, GRPO exceeds heuristic MaximumGain and RandomGain by 200.78% and 465.38%, respectively.</description>
      <guid isPermaLink="false">oai:arXiv.org:2601.13506v1</guid>
      <category>cs.IT</category>
      <category>math.IT</category>
      <pubDate>Wed, 21 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Jianqiu Peng, Tong Zhang, Shuai Wang, Mingjie Shao, Hao Xu, Rui Wang</dc:creator>
    </item>
    <item>
      <title>An Elementary Approach to Scheduling in Generative Diffusion Models</title>
      <link>https://arxiv.org/abs/2601.13602</link>
      <description>arXiv:2601.13602v1 Announce Type: new 
Abstract: An elementary approach to characterizing the impact of noise scheduling and time discretization in generative diffusion models is developed. Considering a simplified model where the source distribution is multivariate Gaussian with a given covariance matrix, the explicit closed-form evolution trajectory of the distributions across reverse sampling steps is derived, and consequently, the Kullback-Leibler (KL) divergence between the source distribution and the reverse sampling output is obtained. The effect of the number of time discretization steps on the convergence of this KL divergence is studied via the Euler-Maclaurin expansion. An optimization problem is formulated, and its solution noise schedule is obtained via calculus of variations, shown to follow a tangent law whose coefficient is determined by the eigenvalues of the source covariance matrix. For an alternative scenario, more realistic in practice, where pretrained models have been obtained for some given noise schedules, the KL divergence also provides a measure to compare different time discretization strategies in reverse sampling. Experiments across different datasets and pretrained models demonstrate that the time discretization strategy selected by our approach consistently outperforms baseline and search-based strategies, particularly when the budget on the number of function evaluations is very tight.</description>
      <guid isPermaLink="false">oai:arXiv.org:2601.13602v1</guid>
      <category>cs.IT</category>
      <category>cs.LG</category>
      <category>math.IT</category>
      <pubDate>Wed, 21 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Qiang Sun, H. Vincent Poor, Wenyi Zhang</dc:creator>
    </item>
    <item>
      <title>Reflections over the Sea: Reconfigurable Intelligent Surface for Maritime Self-Powered Communications</title>
      <link>https://arxiv.org/abs/2601.13618</link>
      <description>arXiv:2601.13618v1 Announce Type: new 
Abstract: Maritime communication is becoming a vital component of 6G networks, driven by the rapid expansion of the maritime economy. However, existing technologies face critical challenges in signal coverage, availability, and robustness, especially under harsh sea conditions. This paper proposes a novel framework for the maritime Internet-of-Things (IoT) communications that leverages the reconfigurable intelligent surface (RIS) mounted on offshore infrastructures, such as wind turbines, to enhance coverage and reliability. To capture dynamic maritime environment, a near-ocean-surface channel model is developed considering the impact of sea waves. In addition, a wave energy harvesting (EH) system is designed to self-power IoT sensors for data acquisition, processing, and transmission. To support real-time adaptation, channel state information is continuously measured to optimize RIS reflection parameters and maximize multi-user communication rates. Simulation results show that the proposed system significantly improves IoT communication performance by over 20%, under harsh sea conditions.</description>
      <guid isPermaLink="false">oai:arXiv.org:2601.13618v1</guid>
      <category>cs.IT</category>
      <category>math.IT</category>
      <pubDate>Wed, 21 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Qianqian Zhang, Long Wang, Ben Wu, Jia Mi</dc:creator>
    </item>
    <item>
      <title>Constrained MARL for Coexisting TN-NTN Resource Allocation: Scalability and Flexibility</title>
      <link>https://arxiv.org/abs/2601.13883</link>
      <description>arXiv:2601.13883v1 Announce Type: new 
Abstract: This paper considers the joint TN-NTN constrained resource allocation, where terrestrial base stations and non-terrestrial base stations coexist in the spectrum. We focus on large-scale and practical scenarios characterized by large numbers of transmission channels and users, alongside highly dynamic user behaviors. As common learning solutions fail to address these challenges, we propose a decomposition solution based on the special properties of the cross-segment interference, and then tackle the original problem via solving subproblems in a sequential learning manner. Furthermore, to enhance the flexibility of the learned policies, we design a stochastic training environment that captures the key characteristics of real-world systems. Simulation results tested on the full 20MHz bandwidth with various numerologies show that our solution significantly improves scalability compared to existing solutions and remains robust in highly dynamic scenarios.</description>
      <guid isPermaLink="false">oai:arXiv.org:2601.13883v1</guid>
      <category>cs.IT</category>
      <category>math.IT</category>
      <pubDate>Wed, 21 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Cuong Le, Thang X. Vu, Stefano Andrenacci, Symeon Chatzinotas</dc:creator>
    </item>
    <item>
      <title>Proactive Coded Caching Scheme for D2D Networks</title>
      <link>https://arxiv.org/abs/2601.13929</link>
      <description>arXiv:2601.13929v1 Announce Type: new 
Abstract: Coded caching and device-to-device (D2D) communication are two effective techniques for alleviating network traffic. Secure transmission and file privacy have also become critical concerns in these domains. However, prevailing coded caching schemes typically assume that a user's cached content is inaccessible to others, overlooking the risk of file privacy leakage due to attacks targeting the cache itself. In this paper, we propose a secure coded caching scheme for D2D networks that guarantees both file privacy and secure delivery. We demonstrate that the proposed scheme achieves order-optimal performance when the file size is sufficiently large and the cache memory is ample.</description>
      <guid isPermaLink="false">oai:arXiv.org:2601.13929v1</guid>
      <category>cs.IT</category>
      <category>math.IT</category>
      <pubDate>Wed, 21 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Qiaoling Zhang, Changlu Lin, Minquan Cheng</dc:creator>
    </item>
    <item>
      <title>Utilizing the Perceived Age to Maximize Freshness in Query-Based Update Systems</title>
      <link>https://arxiv.org/abs/2601.14075</link>
      <description>arXiv:2601.14075v1 Announce Type: new 
Abstract: Query-based sampling has become an increasingly popular technique for monitoring Markov sources in pull-based update systems. However, most of the contemporary literature on this assumes an exponential distribution for query delay and often relies on the assumption that the feedback or replies to the queries are instantaneous. In this work, we relax both of these assumptions and find optimal sampling policies for monitoring continuous-time Markov chains (CTMC) under generic delay distributions. In particular, we show that one can obtain significant gains in terms of mean binary freshness (MBF) by employing a waiting based strategy for query-based sampling.</description>
      <guid isPermaLink="false">oai:arXiv.org:2601.14075v1</guid>
      <category>cs.IT</category>
      <category>cs.SY</category>
      <category>eess.SY</category>
      <category>math.IT</category>
      <pubDate>Wed, 21 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Sahan Liyanaarachchi, Sennur Ulukus, Nail Akar</dc:creator>
    </item>
    <item>
      <title>Near Optimal Code Construction for the Adversarial Torn Paper Channel With Edit Errors</title>
      <link>https://arxiv.org/abs/2601.14088</link>
      <description>arXiv:2601.14088v1 Announce Type: new 
Abstract: Motivated by DNA storage systems and 3D fingerprinting, this work studies the adversarial torn paper channel with edit errors. This channel first applies at most $t_e$ edit errors (i.e., insertions, deletions, and substitutions) to the transmitted word and then breaks it into $t+1$ fragments at arbitrary positions. In this paper, we construct a near optimal error correcting code for this channel, which will be referred to as a $t$-breaks $t_e$-edit-errors resilient code. This code enables reconstructing the transmitted codeword from the $t+1$ noisy fragments. Moreover, we study list decoding of the torn paper channel by deriving bounds on the size of the list (of codewords) obtained from cutting a codeword of a $t$-breaks resilient code $t'$ times, where $t' &gt; t$.</description>
      <guid isPermaLink="false">oai:arXiv.org:2601.14088v1</guid>
      <category>cs.IT</category>
      <category>math.IT</category>
      <pubDate>Wed, 21 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Maria Abu-Sini, Reinhard Heckel</dc:creator>
    </item>
    <item>
      <title>Vector Coded Caching Multiplicatively Boosts MU-MIMO Systems Under Practical Considerations</title>
      <link>https://arxiv.org/abs/2601.14142</link>
      <description>arXiv:2601.14142v1 Announce Type: new 
Abstract: This work presents a first comprehensive analysis of the impact of vector coded caching (VCC) in multi-user multiple-input multiple-output (MU-MIMO) systems with multiple receive antennas and variable pathloss -- two key factors that critically influence systems with inherent MU unicasting behavior. We investigate two widely adopted precoding strategies: (i) blockdiagonalization (BD) at the transmitter combined with maximal ratio combining (MRC) at the receivers, and (ii) zero-forcing (ZF) precoding. Our analysis explicitly accounts for practical considerations such as channel fading, channel state information (CSI) acquisition overhead, and fairness-oriented power allocation.
  Our contributions span both analytical and simulation-based fronts. On the analytical side, we derive analytical expressions for the achievable throughput under BD-MRC and ZF, highlighting the performance benefits of equipping multi-antenna users with cache-aided interference management. Specifically, we develop a low-complexity BD-MRC optimization method that leverages matrix structure to significantly reduce the dimensionality involved in precoding computation, followed by solving the associated maxmin fairness problem through an efficient one-dimensional search. In the massive MIMO regime, an asymptotic expression for the achievable throughput over Rayleigh fading channels is also derived. Simulations validate our theoretical results, confirming that VCC delivers substantial performance gains over optimized cacheless MU-MIMO systems. For example, with 32 transmit antennas and 2 receive antennas per user, VCC yields throughput improvements exceeding 300%. These gains are further amplified under imperfect CSI at the transmitter, where VCC's ability to offload interference mitigation to the receivers ensures robust performance even in the face of degraded CSI quality and elevated acquisition costs.</description>
      <guid isPermaLink="false">oai:arXiv.org:2601.14142v1</guid>
      <category>cs.IT</category>
      <category>math.IT</category>
      <pubDate>Wed, 21 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Hui Zhao, Petros Elia</dc:creator>
    </item>
    <item>
      <title>Storage-Rate Trade-off in A-XPIR</title>
      <link>https://arxiv.org/abs/2601.14202</link>
      <description>arXiv:2601.14202v1 Announce Type: new 
Abstract: We consider the storage problem in an asymmetric $X$-secure private information retrieval (A-XPIR) setting. The A-XPIR setting considers the $X$-secure PIR problem (XPIR) when a given arbitrary set of servers is communicating. We focus on the trade-off region between the average storage at the servers and the average download cost. In the case of $N=4$ servers and two non-overlapping sets of communicating servers with $K=2$ messages, we characterize the achievable region and show that the three main inequalities compared to the no-security case collapse to two inequalities in the asymmetric security case. In the general case, we derive bounds that need to be satisfied for the general achievable region for an arbitrary number of servers and messages. In addition, we provide the storage and retrieval scheme for the case of $N=4$ servers with $K=2$ messages and two non-overlapping sets of communicating servers, such that the messages are not replicated (in the sense of a coded version of each symbol) and at the same time achieve the optimal achievable rate for the case of replication. Finally, we derive the exact capacity for the case of asymmetric security and asymmetric collusion for $N=4$ servers, with the communication links $\{1,2\}$ and $\{3,4\}$, which splits the servers into two groups, i.e., $g=2$, and with the collusion links $\{1,3\}$, $\{2,4\}$, as $C=\frac{1}{3}$. More generally, we derive a capacity result for a certain family of asymmetric collusion and asymmetric security cases.</description>
      <guid isPermaLink="false">oai:arXiv.org:2601.14202v1</guid>
      <category>cs.IT</category>
      <category>cs.CR</category>
      <category>cs.NI</category>
      <category>eess.SP</category>
      <category>math.IT</category>
      <pubDate>Wed, 21 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Mohamed Nomeir, Sennur Ulukus</dc:creator>
    </item>
    <item>
      <title>Stabilizer-Assisted Inactivation Decoding of Quantum Error-Correcting Codes with Erasures</title>
      <link>https://arxiv.org/abs/2601.14236</link>
      <description>arXiv:2601.14236v1 Announce Type: new 
Abstract: In this work, we develop a reduced complexity maximum likelihood (ML) decoder for quantum low-density parity-check (QLDPC) codes over erasures. Our decoder combines classical inactivation decoding, which integrates peeling with symbolic guessing, with a new dual peeling procedure. In the dual peeling stage, we perform row operations on the stabilizer matrix to efficiently reveal stabilizer generators and their linear combinations whose support lies entirely on the erased set. Each such stabilizer identified allows us to freely fix a bit in its support without affecting the logical state of the decoded result. This removes one degree of freedom that would otherwise require a symbolic guess, reducing the number of inactivated variables and decreasing the size of the final linear system that must be solved. We further show that dual peeling combined with standard peeling alone, without inactivation, is sufficient to achieve ML for erasure decoding of surface codes. Simulations across several QLDPC code families confirm that our decoder matches ML logical failure performance while significantly reducing the complexity of inactivation decoding, including more than a 20% reduction in symbolic guesses for the B1 lifted product code at high erasure rates.</description>
      <guid isPermaLink="false">oai:arXiv.org:2601.14236v1</guid>
      <category>cs.IT</category>
      <category>math.IT</category>
      <pubDate>Wed, 21 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Giulio Pech, Mert G\"okduman, Hanwen Yao, Henry D. Pfister</dc:creator>
    </item>
    <item>
      <title>Identification capacity and rate-query tradeoffs in classification systems</title>
      <link>https://arxiv.org/abs/2601.14252</link>
      <description>arXiv:2601.14252v1 Announce Type: new 
Abstract: We study a one-shot identification analogue of rate-distortion for discrete classification under three resources: tag rate L (bits of side information stored per entity), identification cost W (attribute-membership queries per identification, excluding global preprocessing and amortized caching), and distortion D (misclassification probability). The question is to characterize achievable triples (L,W,D) when a decoder must recover an entity's class from limited observations. Zero-error barrier. If two distinct classes induce the same attribute profile, then the observation pi(V) is identical for both and no decoder can identify the class from attribute queries alone. Thus, if the profile map pi is not injective on classes, zero-error identification without tags is impossible (a zero-error feasibility threshold). Achievability and converse at D=0. With k classes, nominal tags of L = ceil(log2 k) bits enable O(1) identification cost with D=0. Conversely, any scheme with D=0 must satisfy L &gt;= log2 k bits (tight). Without tags (L=0), identification requires Omega(n) queries in the worst case and may incur D&gt;0. Combinatorial structure. Minimal sufficient query families form the bases of a matroid; the induced distinguishing dimension is well-defined and links to zero-error source coding via graph entropy. We illustrate implications for type systems, databases, and biological taxonomy. All results are mechanized in Lean4 (6000+ lines, 0 sorry).</description>
      <guid isPermaLink="false">oai:arXiv.org:2601.14252v1</guid>
      <category>cs.IT</category>
      <category>cs.PL</category>
      <category>math.IT</category>
      <pubDate>Wed, 21 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Tristan Simas</dc:creator>
    </item>
    <item>
      <title>From HNSW to Information-Theoretic Binarization: Rethinking the Architecture of Scalable Vector Search</title>
      <link>https://arxiv.org/abs/2601.11557</link>
      <description>arXiv:2601.11557v1 Announce Type: cross 
Abstract: Modern semantic search and retrieval-augmented generation (RAG) systems rely predominantly on in-memory approximate nearest neighbor (ANN) indexes over high-precision floating-point vectors, resulting in escalating operational cost and inherent trade-offs between latency, throughput, and retrieval accuracy. This paper analyzes the architectural limitations of the dominant "HNSW + float32 + cosine similarity" stack and evaluates existing cost-reduction strategies, including storage disaggregation and lossy vector quantization, which inevitably sacrifice either performance or accuracy. We introduce and empirically evaluate an alternative information-theoretic architecture based on maximally informative binarization (MIB), efficient bitwise distance metrics, and an information-theoretic scoring (ITS) mechanism. Unlike conventional ANN systems, this approach enables exhaustive search over compact binary representations, allowing deterministic retrieval and eliminating accuracy degradation under high query concurrency. Using the MAIR benchmark across 14 datasets and 10,038 queries, we compare this architecture against Elasticsearch, Pinecone, PGVector, and Qdrant. Results demonstrate retrieval quality comparable to full-precision systems, while achieving substantially lower latency and maintaining constant throughput at high request rates. We show that this architectural shift enables a truly serverless, cost-per-query deployment model, challenging the necessity of large in-memory ANN indexes for high-quality semantic search.</description>
      <guid isPermaLink="false">oai:arXiv.org:2601.11557v1</guid>
      <category>cs.DB</category>
      <category>cs.IR</category>
      <category>cs.IT</category>
      <category>cs.PF</category>
      <category>math.IT</category>
      <pubDate>Wed, 21 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-sa/4.0/</dc:rights>
      <dc:creator>Seyed Moein Abtahi, Majid Fekri, Tara Khani, Akramul Azim</dc:creator>
    </item>
    <item>
      <title>Necessity of Cooperative Transmissions for Wireless MapReduce</title>
      <link>https://arxiv.org/abs/2601.11844</link>
      <description>arXiv:2601.11844v1 Announce Type: cross 
Abstract: The paper presents an improved upper bound (achievability result) on the optimal tradeoff between Normalized Delivery Time (NDT) and computation load for distributed computing MapReduce systems in certain ranges of the parameters. The upper bound is based on interference alignment combined with zero-forcing. The paper further provides a lower bound (converse) on the optimal NDT-computation tradeoff that can be achieved when IVAs are partitioned into sub-IVAs, and these sub-IVAs are then transmitted (in an arbitrary form) by a single node, without cooperation among nodes. For appropriate linear functions (e.g., XORs), such non-cooperative schemes can achieve some of the best NDT-computation tradeoff points so far obtained in the literature. However, as our lower bound shows, any non-cooperative scheme achieves a worse NDT-computation tradeoff than our new proposed scheme for certain parameters, thus proving the necessity of cooperative schemes like zero-forcing to attain the optimal NDT-computation tradeoff.</description>
      <guid isPermaLink="false">oai:arXiv.org:2601.11844v1</guid>
      <category>eess.SP</category>
      <category>cs.IT</category>
      <category>math.IT</category>
      <pubDate>Wed, 21 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Yue Bi, Mich\`ele Wigger</dc:creator>
    </item>
    <item>
      <title>DeepRAHT: Learning Predictive RAHT for Point Cloud Attribute Compression</title>
      <link>https://arxiv.org/abs/2601.12255</link>
      <description>arXiv:2601.12255v1 Announce Type: cross 
Abstract: Regional Adaptive Hierarchical Transform (RAHT) is an effective point cloud attribute compression (PCAC) method. However, its application in deep learning lacks research. In this paper, we propose an end-to-end RAHT framework for lossy PCAC based on the sparse tensor, called DeepRAHT. The RAHT transform is performed within the learning reconstruction process, without requiring manual RAHT for preprocessing. We also introduce the predictive RAHT to reduce bitrates and design a learning-based prediction model to enhance performance. Moreover, we devise a bitrate proxy that applies run-length coding to entropy model, achieving seamless variable-rate coding and improving robustness. DeepRAHT is a reversible and distortion-controllable framework, ensuring its lower bound performance and offering significant application potential. The experiments demonstrate that DeepRAHT is a high-performance, faster, and more robust solution than the baseline methods. Project Page: https://github.com/zb12138/DeepRAHT.</description>
      <guid isPermaLink="false">oai:arXiv.org:2601.12255v1</guid>
      <category>eess.IV</category>
      <category>cs.CV</category>
      <category>cs.IT</category>
      <category>cs.MM</category>
      <category>math.IT</category>
      <pubDate>Wed, 21 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Chunyang Fu, Tai Qin, Shiqi Wang, Zhu Li</dc:creator>
    </item>
    <item>
      <title>Analyzing Collection Strategies: A Computational Perspective on the Coupon Collector Problem</title>
      <link>https://arxiv.org/abs/2601.12351</link>
      <description>arXiv:2601.12351v1 Announce Type: cross 
Abstract: The Coupon Collector Problem (CCP) is a well-known combinatorial problem that seeks to estimate the number of random draws required to complete a collection of $n$ distinct coupon types. Various generalizations of this problem have been applied in numerous engineering domains. However, practical applications are often hindered by the computational challenges associated with deriving numerical results for moments and distributions. In this work, we present three algorithms for solving the most general form of the CCP, where coupons are collected under any arbitrary drawing probability, with the objective of obtaining $t$ copies of a subset of $k$ coupons from a total of $n$. The First algorithm provides the base model to compute the expectation, variance, and the second moment of the collection process. The second algorithm utilizes the construction of the base model and computes the same values in polynomial time with respect to $n$ under the uniform drawing distribution, and the third algorithm extends to any general drawing distribution. All algorithms leverage Markov models specifically designed to address computational challenges, ensuring exact computation of the expectation and variance of the collection process. Their implementation uses a dynamic programming approach that follows from the Markov models framework, and their time complexity is analyzed accordingly.</description>
      <guid isPermaLink="false">oai:arXiv.org:2601.12351v1</guid>
      <category>cs.DS</category>
      <category>cs.IT</category>
      <category>math.IT</category>
      <pubDate>Wed, 21 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Hadas Abraham, Ido Feldman, Eitan Yaakobi</dc:creator>
    </item>
    <item>
      <title>A Mixture of Experts Vision Transformer for High-Fidelity Surface Code Decoding</title>
      <link>https://arxiv.org/abs/2601.12483</link>
      <description>arXiv:2601.12483v1 Announce Type: cross 
Abstract: Quantum error correction is a key ingredient for large scale quantum computation, protecting logical information from physical noise by encoding it into many physical qubits. Topological stabilizer codes are particularly appealing due to their geometric locality and practical relevance. In these codes, stabilizer measurements yield a syndrome that must be decoded into a recovery operation, making decoding a central bottleneck for scalable real time operation. Existing decoders are commonly classified into two categories. Classical algorithmic decoders provide strong and well established baselines, but may incur substantial computational overhead at large code distances or under stringent latency constraints. Machine learning based decoders offer fast GPU inference and flexible function approximation, yet many approaches do not explicitly exploit the lattice geometry and local structure of topological codes, which can limit performance. In this work, we propose QuantumSMoE, a quantum vision transformer based decoder that incorporates code structure through plus shaped embeddings and adaptive masking to capture local interactions and lattice connectivity, and improves scalability via a mixture of experts layer with a novel auxiliary loss. Experiments on the toric code demonstrate that QuantumSMoE outperforms state-of-the-art machine learning decoders as well as widely used classical baselines.</description>
      <guid isPermaLink="false">oai:arXiv.org:2601.12483v1</guid>
      <category>quant-ph</category>
      <category>cs.IT</category>
      <category>cs.LG</category>
      <category>math.IT</category>
      <pubDate>Wed, 21 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Hoang Viet Nguyen, Manh Hung Nguyen, Hoang Ta, Van Khu Vu, Yeow Meng Chee</dc:creator>
    </item>
    <item>
      <title>Relativistic Hamiltonian as an emergent structure from information geometry</title>
      <link>https://arxiv.org/abs/2601.12764</link>
      <description>arXiv:2601.12764v1 Announce Type: cross 
Abstract: We show that the relativistic energy-momentum relation can emerge as an effective ensemble-averaged structure from a multiplicative Hamiltonian when fluctuations of an auxiliary parameter are treated using maximum entropy inference. The resulting probability distribution is uniquely fixed by scale-invariant constraints, which are shown to arise naturally from the Fisher-Rao geometry of the associated statistical manifold. Within this information-geometric framework, the relativistic dispersion relation appears without initially imposing Lorentz symmetry, but as a consequence of statistical averaging and geometric invariance.</description>
      <guid isPermaLink="false">oai:arXiv.org:2601.12764v1</guid>
      <category>math-ph</category>
      <category>cs.IT</category>
      <category>math.IT</category>
      <category>math.MP</category>
      <category>physics.class-ph</category>
      <pubDate>Wed, 21 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Sikarin Yoo-Kong</dc:creator>
    </item>
    <item>
      <title>Sensing-Limited Control of Noiseless Linear Systems Under Nonlinear Observations</title>
      <link>https://arxiv.org/abs/2601.12782</link>
      <description>arXiv:2601.12782v1 Announce Type: cross 
Abstract: This paper investigates the fundamental information-theoretic limits for the control and sensing of noiseless linear dynamical systems subject to a broad class of nonlinear observations. We analyze the interactions between the control and sensing components by characterizing the minimum information flow required for stability. Specifically, we derive necessary conditions for mean-square observability and stabilizability, demonstrating that the average directed information rate from the state to the observations must exceed the intrinsic expansion rate of the unstable dynamics. Furthermore, to address the challenges posed by non-Gaussian distributions inherent to nonlinear observation channels, we establish sufficient conditions by imposing regularity assumptions, specifically log-concavity, on the system's probabilistic components. We show that under these conditions, the divergence of differential entropy implies the convergence of the estimation error, thereby closing the gap between information-theoretic bounds and estimation performance. By establishing these results, we unveil the fundamental performance limits imposed by the sensing layer, extending classical data-rate constraints to the more challenging regime of nonlinear observation models.</description>
      <guid isPermaLink="false">oai:arXiv.org:2601.12782v1</guid>
      <category>eess.SY</category>
      <category>cs.IT</category>
      <category>cs.SY</category>
      <category>math.IT</category>
      <pubDate>Wed, 21 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Ming Li, Fan Liu, Yifeng Xiong, Jie Xu, Tao Liu</dc:creator>
    </item>
    <item>
      <title>Perfect codes in weakly metric association schemes</title>
      <link>https://arxiv.org/abs/2601.12818</link>
      <description>arXiv:2601.12818v1 Announce Type: cross 
Abstract: The Lloyd Theorem of (Sol\'e, 1989) is combined with the Schwartz-Zippel Lemma of theoretical computer science to derive non-existence results for perfect codes in the Lee metric, NRT metric, mixed Hamming metric, and for the sum-rank distance. The proofs are based on asymptotic enumeration of integer partitions. The framework is the new concept of {\em polynomial} weakly metric association schemes.
  A connection between this notion and the recent theory of multivariate P-polynomial schemes of ( Bannai et al. 2025) and of $m$-distance regular graphs ( Bernard et al 2025) is pointed out.</description>
      <guid isPermaLink="false">oai:arXiv.org:2601.12818v1</guid>
      <category>math.CO</category>
      <category>cs.IT</category>
      <category>math.IT</category>
      <pubDate>Wed, 21 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Minjia Shi, Jing Wang, Patrick Sol\'e</dc:creator>
    </item>
    <item>
      <title>Angular Sensing by Highly Reconfigurable Pixel Antennas with Joint Radiating Aperture and Feeding Ports Reconfiguration</title>
      <link>https://arxiv.org/abs/2601.12867</link>
      <description>arXiv:2601.12867v1 Announce Type: cross 
Abstract: Angular sensing capability is realized using highly reconfigurable pixel antenna (HRPA) with joint radiating aperture and feeding ports reconfiguration. Pixel antennas represent a general class of reconfigurable antenna designs in which the radiating surface, regardless of its shape or size, is divided into sub-wavelength elements called pixels. Each pixel is connected to its neighboring elements through radio frequency switches. By controlling pixel connections, the pixel antenna topology can be flexibly adjusted so that the resulting radiation pattern can be reconfigured. However, conventional pixel antennas have only a single, fixed-position feeding port, which is not efficient for angular sensing. Therefore, in this work, we further extend the reconfigurability of pixel antennas by introducing the HRPA, which enables both geometry control of the pixel antenna and switching of its feeding ports. The model of the proposed HRPA, including both circuit and radiation parameters, is derived. A codebook is then defined, consisting of pixel connection states and feeding port positions for each sensing area. Based on this codebook, an efficient optimization approach is developed to minimize the Cram\acute{\mathrm{\mathbf{e}}}r-Rao lower bound (CRLB) and obtain the optimal HRPA geometries for angular sensing within a given area. Numerical results show that the HRPA reduces the angle estimation error by more than 50% across the full three-dimensional sphere when compared with a conventional uniform planar array of the same size. This demonstrates the effectiveness of the proposed approach and highlights the potential of HRPA for integrated sensing and communication systems.</description>
      <guid isPermaLink="false">oai:arXiv.org:2601.12867v1</guid>
      <category>eess.SP</category>
      <category>cs.IT</category>
      <category>math.IT</category>
      <pubDate>Wed, 21 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Zixiang Han, Hanning Wang, Shiwen Tang, Yujie Zhang</dc:creator>
    </item>
    <item>
      <title>When Is Distributed Nonlinear Aggregation Private? Optimality and Information-Theoretical Bounds</title>
      <link>https://arxiv.org/abs/2601.13001</link>
      <description>arXiv:2601.13001v1 Announce Type: cross 
Abstract: Nonlinear aggregation is central to modern distributed systems, yet its privacy behavior is far less understood than that of linear aggregation. Unlike linear aggregation where mature mechanisms can often suppress information leakage, nonlinear operators impose inherent structural limits on what privacy guarantees are theoretically achievable when the aggregate must be computed exactly. This paper develops a unified information-theoretic framework to characterize privacy leakage in distributed nonlinear aggregation under a joint adversary that combines passive (honest-but-curious) corruption and eavesdropping over communication channels.
  We cover two broad classes of nonlinear aggregates: order-based operators (maximum/minimum and top-$K$) and robust aggregation (median/quantiles and trimmed mean). We first derive fundamental lower bounds on leakage that hold without sacrificing accuracy, thereby identifying the minimum unavoidable information revealed by the computation and the transcript. We then propose simple yet effective privacy-preserving distributed algorithms, and show that with appropriate randomized initialization and parameter choices, our proposed approaches can attach the derived optimal bounds for the considered operators. Extensive experiments validate the tightness of the bounds and demonstrate that network topology and key algorithmic parameters (including the stepsize) govern the observed leakage in line with the theoretical analysis, yielding actionable guidelines for privacy-preserving nonlinear aggregation.</description>
      <guid isPermaLink="false">oai:arXiv.org:2601.13001v1</guid>
      <category>eess.SP</category>
      <category>cs.IT</category>
      <category>math.IT</category>
      <pubDate>Wed, 21 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Wenrui Yu, Jaron Skovsted Gundersen, Richard Heusdens, Qiongxiu Li</dc:creator>
    </item>
    <item>
      <title>Post-Quantum Secure Aggregation via Code-Based Homomorphic Encryption</title>
      <link>https://arxiv.org/abs/2601.13031</link>
      <description>arXiv:2601.13031v1 Announce Type: cross 
Abstract: Secure aggregation enables aggregation of inputs from multiple parties without revealing individual contributions to the server or other clients. Existing post-quantum approaches based on homomorphic encryption offer practical efficiency but predominantly rely on lattice-based hardness assumptions. We present a code-based alternative for secure aggregation by instantiating a general framework based on key- and message-additive homomorphic encryption under the Learning Parity with Noise (LPN) assumption. Our construction employs a committee-based decryptor realized via secret sharing and incorporates a Chinese Remainder Theorem (CRT)-based optimization to reduce the communication costs of LPN-based instantiations. We analyze the security of the proposed scheme under a new Hint-LPN assumption and show that it is equivalent to standard LPN for suitable parameters. Finally, we evaluate performance and identify regimes in which our approach outperforms information-theoretically secure aggregation protocols.</description>
      <guid isPermaLink="false">oai:arXiv.org:2601.13031v1</guid>
      <category>cs.CR</category>
      <category>cs.IT</category>
      <category>math.IT</category>
      <pubDate>Wed, 21 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Sebastian Bitzer, Maximilian Egger, Mumin Liu, Antonia Wachter-Zeh</dc:creator>
    </item>
    <item>
      <title>xBound: Join Size Lower Bounds</title>
      <link>https://arxiv.org/abs/2601.13117</link>
      <description>arXiv:2601.13117v1 Announce Type: cross 
Abstract: Cloud database vendors invest substantial resources into their query optimizers, and for good reason. Cardinality estimation, a cornerstone of the optimizer, is critical for the selection of efficient query plans, as well as downstream tasks such as resource allocation and query scheduling. Yet, as many practitioners and researchers have noted, it is also the optimizer's Achilles heel. Prior studies on a number of industrial-strength databases show substantial cardinality estimation errors on all tested systems, with a far greater tendency to underestimate than to overestimate. Unfortunately, cardinality underestimation is more problematic than overestimation, as it misleads the optimizer to choose plans designed for small data, leading to underprovisioned CPU and memory.
  While previous work on pessimistic cardinality estimation has proposed provable join size upper bounds, such methods can only correct overestimation, leaving the more harmful problem of underestimation unaddressed. To fill this critical gap, we introduce xBound, the very first framework for deriving provable join size lower bounds. xBound successfully reduces underestimation in real systems: On the JOBlight benchmark, it corrects 17.5% of subexpression underestimates in DuckDB and 8.7% in PostgreSQL, while on a Microsoft enterprise workload, it fixes 36.1% of Fabric Data Warehouse's underestimates, demonstrating a significant step towards solving this long-standing problem.</description>
      <guid isPermaLink="false">oai:arXiv.org:2601.13117v1</guid>
      <category>cs.DB</category>
      <category>cs.IT</category>
      <category>math.IT</category>
      <pubDate>Wed, 21 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-sa/4.0/</dc:rights>
      <dc:creator>Mihail Stoian, Tiemo Bang, Hangdong Zhao, Jes\'us Camacho-Rodr\'iguez, Yuanyuan Tian, Andreas Kipf</dc:creator>
    </item>
    <item>
      <title>Decentralized Cooperative Beamforming for BDRIS-Assisted Cell-Free MIMO OFDM Systems</title>
      <link>https://arxiv.org/abs/2601.13201</link>
      <description>arXiv:2601.13201v1 Announce Type: cross 
Abstract: In this paper, a wideband cell-free multi-stream multi-user Multiple-Input Multiple-Output (MIMO) Orthogonal Frequency Division Multiplexing (OFDM) system is considered operating within a smart wireless environment enabled by multiple Beyond Diagonal Reconfigurable Intelligent Surfaces (BDRISs). A novel decentralized active and passive beamforming framework, robust to imperfect channel state availability and with minimal cooperation among the system's multiple Base Stations (BSs) for deciding the final configurations of the shared BDRISs, is proposed, which aims to substantially reduce the overhead inherent in centralized solutions necessitating a central processing unit of high computational power. By considering a Dynamic Group-Connected (DGC) BDRIS architecture with frequency-selective responses per unit element, we formulate the system's sum-rate maximization problem with respect to the tunable capacitances and permutation matrices of the BDRISs as well as the precoding matrices of the BSs, which is solved via successive concave approximation and alternating projections as well as consensus-based updates for the BDRISs' design. Through extensive simulation results, it is showcased that the proposed robust decentralized cooperative approach with diverse BDRIS architectures outperforms non-cooperation benchmarks. It is also demonstrated that the considered DGC BDRIS architecture is able to provide sum-rate performance gains sufficiently close to the more complex fully-connected BDRIS structure.</description>
      <guid isPermaLink="false">oai:arXiv.org:2601.13201v1</guid>
      <category>eess.SP</category>
      <category>cs.ET</category>
      <category>cs.IT</category>
      <category>math.IT</category>
      <pubDate>Wed, 21 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Konstantinos D. Katsanos, George C. Alexandropoulos</dc:creator>
    </item>
    <item>
      <title>Hierarchical Sparse Vector Transmission for Ultra Reliable and Low Latency Communications</title>
      <link>https://arxiv.org/abs/2601.13204</link>
      <description>arXiv:2601.13204v1 Announce Type: cross 
Abstract: Sparse vector transmission (SVT) is a promising candidate technology for achieving ultra-reliable low-latency communication (URLLC). In this paper, a hierarchical SVT scheme is proposed for multi-user URLLC scenarios. The hierarchical SVT scheme partitions the transmitted bits into common and private parts. The common information is conveyed by the indices of non-zero sections in a sparse vector, while each user's private information is embedded into non-zero blocks with specific block lengths. At the receiver, the common bits are first recovered from the detected non-zero sections, followed by user-specific private bits decoding based on the corresponding non-zero block indices. Simulation results show the proposed scheme outperforms state-of-the-art SVT schemes in terms of block error rate.</description>
      <guid isPermaLink="false">oai:arXiv.org:2601.13204v1</guid>
      <category>eess.SP</category>
      <category>cs.IT</category>
      <category>eess.IV</category>
      <category>math.IT</category>
      <pubDate>Wed, 21 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Yanfeng Zhang, Xi'an Fan, Jinkai Zheng, Xiaoye Jing, Weiwei Yang, Xu Zhu</dc:creator>
    </item>
    <item>
      <title>Near-field Physical Layer Security: Robust Beamforming under Location Uncertainty</title>
      <link>https://arxiv.org/abs/2601.13549</link>
      <description>arXiv:2601.13549v1 Announce Type: cross 
Abstract: In this paper, we study robust beamforming design for near-field physical-layer-security (PLS) systems, where a base station (BS) equipped with an extremely large-scale array (XL-array) serves multiple near-field legitimate users (Bobs) in the presence of multiple near-field eavesdroppers (Eves). Unlike existing works that mostly assume perfect channel state information (CSI) or location information of Eves, we consider a more practical and challenging scenario, where the locations of Bobs are perfectly known, while only imperfect location information of Eves is available at the BS. We first formulate a robust optimization problem to maximize the sum-rate of Bobs while guaranteeing a worst-case limit on the eavesdropping rate under location uncertainty. By transforming Cartesian position errors into the polar domain, we reveal an important near-field angular-error amplification effect: for the same location error, the closer the Eve, the larger the angle error, severely degrading the performance of conventional robust beamforming methods based on imperfect channel state information. To address this issue, we first establish the conditions for which the first-order Taylor approximation of the near-field channel steering vector under location uncertainty is largely accurate. Then, we propose a two-stage robust beamforming method, which first partitions the uncertainty region into multiple fan-shaped sub-regions, followed by the second stage to formulate and solve a refined linear-matrix-inequality (LMI)-based robust beamforming optimization problem. In addition, the proposed method is further extended to scenarios with multiple Bobs and multiple Eves. Finally, numerical results validate that the proposed method achieves a superior trade-off between rate performance and secrecy robustness, hence significantly outperforming existing benchmarks under Eve location uncertainty.</description>
      <guid isPermaLink="false">oai:arXiv.org:2601.13549v1</guid>
      <category>eess.SP</category>
      <category>cs.IT</category>
      <category>math.IT</category>
      <pubDate>Wed, 21 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Chao Zhou, Changsheng You, Cong Zhou, Chengwen Xing, Jianhua Zhang</dc:creator>
    </item>
    <item>
      <title>Does Privacy Always Harm Fairness? Data-Dependent Trade-offs via Chernoff Information Neural Estimation</title>
      <link>https://arxiv.org/abs/2601.13698</link>
      <description>arXiv:2601.13698v1 Announce Type: cross 
Abstract: Fairness and privacy are two vital pillars of trustworthy machine learning. Despite extensive research on these individual topics, the relationship between fairness and privacy has received significantly less attention. In this paper, we utilize the information-theoretic measure Chernoff Information to highlight the data-dependent nature of the relationship among the triad of fairness, privacy, and accuracy. We first define Noisy Chernoff Difference, a tool that allows us to analyze the relationship among the triad simultaneously. We then show that for synthetic data, this value behaves in 3 distinct ways (depending on the distribution of the data). We highlight the data distributions involved in these cases and explore their fairness and privacy implications. Additionally, we show that Noisy Chernoff Difference acts as a proxy for the steepness of the fairness-accuracy curves. Finally, we propose a method for estimating Chernoff Information on data from unknown distributions and utilize this framework to examine the triad dynamic on real datasets. This work builds towards a unified understanding of the fairness-privacy-accuracy relationship and highlights its data-dependent nature.</description>
      <guid isPermaLink="false">oai:arXiv.org:2601.13698v1</guid>
      <category>cs.LG</category>
      <category>cs.AI</category>
      <category>cs.IT</category>
      <category>math.IT</category>
      <category>stat.ML</category>
      <pubDate>Wed, 21 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Arjun Nichani (Richard), Hsiang Hsu (Richard),  Chun-Fu (Richard),  Chen, Haewon Jeong</dc:creator>
    </item>
    <item>
      <title>Achieving Full Multipath Diversity by Random Constellation Rotation: a Theoretical Perspective</title>
      <link>https://arxiv.org/abs/2601.13997</link>
      <description>arXiv:2601.13997v1 Announce Type: cross 
Abstract: Diversity is an essential concept associated with communication reliability in multipath channels since it determines the slope of bit error rate performance in the medium to high signal-to-noise ratio regions. However, most of the existing analytical frameworks were developed for specific modulation schemes while the efficient validation of full multipath diversity for general modulation schemes remains an open problem. To fill this research gap, we propose to utilize random constellation rotation to ease the conditions for full-diversity modulation designs. For linearly precoded cyclic-prefix orthogonal frequency division multiplexing (OFDM) systems, we prove that maximum multipath diversity can be attained as long as the spread matrix does not have zero entries, which is a sufficient but easily satisfied condition. Furthermore, we derive the sufficient and necessary condition for general modulation schemes, whose verification can be divided into validation tasks for each column of the modulation matrix. Based on the proposed conditions, maximum diversity order can be attained with the probability of 1 by enabling a randomly generated rotation pattern for both time and doubly dispersive channels. The theoretical analysis in this paper also demonstrates that the diversity evaluation can be concentrated on the pairwise error probability when the number of error symbols is one, which reduces the complexity of diversity-driven design and performance analysis for novel modulation schemes significantly in both time and doubly dispersive channels. Finally, numerical results for various modulation schemes confirm that the theoretical analysis holds in both time and doubly dispersive channels. Furthermore, when employing practical detectors, the random constellation rotation technique consistently enhance the transmission reliability for both coded and uncoded systems.</description>
      <guid isPermaLink="false">oai:arXiv.org:2601.13997v1</guid>
      <category>eess.SP</category>
      <category>cs.IT</category>
      <category>math.IT</category>
      <pubDate>Wed, 21 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Xuehan Wang, Jinhong Yuan, Jintao Wang, Kehan Huang</dc:creator>
    </item>
    <item>
      <title>Multiperiodic Processes: Ergodic Sources with a Sublinear Entropy</title>
      <link>https://arxiv.org/abs/2302.09049</link>
      <description>arXiv:2302.09049v5 Announce Type: replace 
Abstract: We construct multiperiodic processes -- a simple example of stationary ergodic (but not mixing) processes over natural numbers that enjoy the vanishing entropy rate under a mild condition. Multiperiodic processes are supported on randomly shifted deterministic sequences called multiperiodic sequences, which can be efficiently generated using an algorithm called the Infinite Clock. Under a suitable parameterization, multiperiodic sequences exhibit relative frequencies of particular numbers given by Zipf's law. Exactly in the same setting, the respective multiperiodic processes satisfy an asymptotic power-law growth of block entropy, called Hilberg's law. Hilberg's law is deemed to hold for statistical language models, in particular.</description>
      <guid isPermaLink="false">oai:arXiv.org:2302.09049v5</guid>
      <category>cs.IT</category>
      <category>cs.LG</category>
      <category>math.IT</category>
      <category>math.ST</category>
      <category>stat.TH</category>
      <pubDate>Wed, 21 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>{\L}ukasz D\k{e}bowski</dc:creator>
    </item>
    <item>
      <title>D2D Coded Caching from Two Classes of Optimal DPDAs using Cross Resolvable Designs</title>
      <link>https://arxiv.org/abs/2409.14350</link>
      <description>arXiv:2409.14350v2 Announce Type: replace 
Abstract: Device to device (D2D) communication is one of the most promising techniques for fifth-generation and beyond wireless communication systems. This paper considers coded caching in a wireless D2D network, in which a central server initially places the data in the user cache memories, and all user demands are served through inter-user coded multicast transmissions. D2D placement delivery array (DPDA) was proposed as a tool for designing coded caching schemes with reduced subpacketization levels in a D2D network. In this paper, we first constructed three classes of DPDAs using a cross resolvable design, a group divisible design, and a newly developed block design. The resulting D2D schemes achieve low subpacketization levels while meeting the known lower bound on the transmission load of a DPDA. These classes of constructed DPDAs either simplify or generalize all existing DPDA constructions that achieve the known lower bound and have low subpacketization levels. Furthermore, a new lower bound on the transmission load of a DPDA is proposed. Two new classes of DPDAs are then constructed using a cross resolvable design and a newly developed block design, respectively. These constructions yield low-subpacketization D2D schemes and achieve the proposed lower bound on the transmission load. Compared to existing schemes with the same system parameters as those obtained from the proposed DPDAs, the proposed schemes have an advantage in either transmission load or subpacketization level or both.</description>
      <guid isPermaLink="false">oai:arXiv.org:2409.14350v2</guid>
      <category>cs.IT</category>
      <category>math.IT</category>
      <pubDate>Wed, 21 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Rashid Ummer N. T., B. Sundar Rajan</dc:creator>
    </item>
    <item>
      <title>D2D Coded Caching Schemes for Multiaccess Networks with Combinatorial Access Topology</title>
      <link>https://arxiv.org/abs/2501.10756</link>
      <description>arXiv:2501.10756v2 Announce Type: replace 
Abstract: This paper considers wireless device-to-device (D2D) coded caching in a multiaccess network, where the users communicate with each other and each user can access multiple cache nodes. Access topologies derived from two combinatorial designs known as the $t$-design and $t$-group divisible design ($t$-GDD), referred to as the $t$-design and $t$-GDD topologies respectively, which subsume a few other known topologies, have been studied for the multiaccess coded caching (MACC) network by Cheng \textit{et al.} in \cite{MACC_des}. These access topologies are extended to a multiaccess D2D coded caching (MADCC) network and novel MADCC schemes are proposed. MADCC network has been studied so far only for the cyclic wrap-around topology. Apart from the proposed novel MADCC schemes, MADCC schemes are also derived from the existing MACC schemes in \cite{MACC_des}. To compare the performance of different MADCC schemes, the metrics of load per user and subpacketization level are used while keeping the number of caches and cache memory size same. The proposed MADCC scheme with $t$-design topology performs better in terms of subpacketization level while achieving the same load per user compared to the MADCC scheme derived from the MACC scheme with $t$-design topology in \cite{MACC_des}. The proposed MADCC scheme with $t$-GDD topology performs better in terms of load per user while achieving the same subpacketization level compared to the MADCC scheme derived from the MACC scheme with $t$-GDD topology in \cite{MACC_des} in some cases. Compared to the existing MADCC scheme with cyclic wrap-around topology, the proposed MADCC scheme with $t$-design topology performs better in terms of load per user, and the proposed MADCC scheme with $t$-GDD topology performs better in terms of subpacketization level at the expense of an increase in load per user.</description>
      <guid isPermaLink="false">oai:arXiv.org:2501.10756v2</guid>
      <category>cs.IT</category>
      <category>math.IT</category>
      <pubDate>Wed, 21 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Rashid Ummer N. T., B. Sundar Rajan</dc:creator>
    </item>
    <item>
      <title>Linear complementary dual quasi-cyclic codes of index 2</title>
      <link>https://arxiv.org/abs/2504.09126</link>
      <description>arXiv:2504.09126v3 Announce Type: replace 
Abstract: We provide a polynomial approach to investigate linear complementary dual (LCD) quasi-cyclic codes over finite fields. We establish necessary and sufficient conditions for LCD quasi-cyclic codes of index 2 with respect to the Euclidean, Hermitian, and symplectic inner products. As a consequence of these characterizations, we derive necessary and sufficient conditions for LCD one-generator quasi-cyclic codes. Furthermore, using these characterizations, we construct some new quasi-cyclic LCD codes over small fields.</description>
      <guid isPermaLink="false">oai:arXiv.org:2504.09126v3</guid>
      <category>cs.IT</category>
      <category>math.IT</category>
      <pubDate>Wed, 21 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Kanat Abdukhalikov, Duy Ho, San Ling, Gyanendra K. Verma</dc:creator>
    </item>
    <item>
      <title>Linear Complementary Pairs of Quasi-Cyclic and Quasi-Twisted Codes</title>
      <link>https://arxiv.org/abs/2504.15231</link>
      <description>arXiv:2504.15231v2 Announce Type: replace 
Abstract: In this paper, we provide a polynomial characterization of linear complementary pairs of quasi-cyclic and quasi-twisted codes of index 2. We also give several examples of linear complementary pairs of quasi-cyclic and quasi-twisted codes with optimal security parameters.</description>
      <guid isPermaLink="false">oai:arXiv.org:2504.15231v2</guid>
      <category>cs.IT</category>
      <category>math.IT</category>
      <pubDate>Wed, 21 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Kanat Abdukhalikov, Duy Ho, San Ling, Gyanendra K. Verma</dc:creator>
    </item>
    <item>
      <title>Rydberg Atomic Receivers for Multi-Band Communications and Sensing</title>
      <link>https://arxiv.org/abs/2505.24168</link>
      <description>arXiv:2505.24168v3 Announce Type: replace 
Abstract: Harnessing multi-level electron transitions, Rydberg Atomic REceivers (RAREs) can detect wireless signals across a wide range of frequency bands, from Megahertz to Terahertz. This capability enables multi-band wireless communications and sensing (CommunSense). Existing research on multi-band RAREs primarily focuses on experimental demonstrations, lacking a tractable model to mathematically characterize their mechanisms. This issue leaves the multi-band RARE as a black box and poses challenges in its practical applications. To fill in this gap, this paper investigates the underlying mechanism of multiband RAREs and explores their optimal performance. For the first time, an analytical transfer function with a closed-form expression for multi-band RAREs is derived by solving the quantum response of Rydberg atoms. It shows that a multiband RARE simultaneously serves as a multi-band atomic mixer for down-converting multi-band signals and a multi-band atomic amplifier that reflects its sensitivity to each band. Further analysis of the atomic amplifier unveils that the intrinsic gain at each frequency band can be decoupled into a global gain term and a Rabi attention term. The former determines the overall sensitivity of a RARE to all frequency bands of wireless signals. The latter influences the allocation of the overall sensitivity to each frequency band, representing a unique attention mechanism of multi-band RAREs. The optimal design of the global gain is provided to maximize the overall sensitivity of multi-band RAREs. Subsequently, the optimal Rabi attentions are also derived to maximize the practical multi-band CommunSense performance. An experiment platform is built to validate the effectiveness of the derived transfer function, and numerical results confirm the superiority of multi-band RAREs.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.24168v3</guid>
      <category>cs.IT</category>
      <category>eess.SP</category>
      <category>math.IT</category>
      <pubDate>Wed, 21 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/publicdomain/zero/1.0/</dc:rights>
      <dc:creator>Mingyao Cui, Qunsong Zeng, Minze Chen, Zhanwei Wang, Tianqi Mao, Dezhi Zheng, Kaibin Huang</dc:creator>
    </item>
    <item>
      <title>Rejection-Sampled Linear Codes for Lossy Compression and Channel Simulation</title>
      <link>https://arxiv.org/abs/2506.09239</link>
      <description>arXiv:2506.09239v2 Announce Type: replace 
Abstract: We show that linear codes combined with rejection sampling can yield a capacity-achieving scheme for simulating additive exchangeable noise channels. Specifically, our scheme achieves an amount of communication within $\log e + 1$ bits from the excess functional information lower bound. Hence, it can be used in lossy source coding to achieve the rate-distortion function. We discuss practical implementations based on BCH codes and polar codes. For the simulation of binary symmetric channels, the BCH-based construction with a blocklength of $n = 63$ attains a rate comparable to the PolarSim with $n = 4096$, while significantly reducing the latency. The polar-based construction asymptotically achieves the channel capacity with polynomial average complexity. Furthermore, using the idea from greedy rejection sampling, we propose an algorithm to construct capacity-achieving schemes based on any linear codes. Experiments reveal that our construction can outperform conventional covering codes for lossy source coding with Hamming distortion for a certain range of distortion levels, and performs well even when the blocklength is small (e.g., $n = 24$).</description>
      <guid isPermaLink="false">oai:arXiv.org:2506.09239v2</guid>
      <category>cs.IT</category>
      <category>math.IT</category>
      <pubDate>Wed, 21 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Jianguo Zhao, Cheuk Ting Li</dc:creator>
    </item>
    <item>
      <title>Large AI Models for Wireless Physical Layer</title>
      <link>https://arxiv.org/abs/2508.02314</link>
      <description>arXiv:2508.02314v2 Announce Type: replace 
Abstract: Large artificial intelligence models (LAMs) are transforming wireless physical layer technologies through their robust generalization, multitask processing, and multimodal capabilities. This article reviews recent advancements in applying LAMs to physical layer communications, addressing obstacles of conventional AI-based approaches. LAM-based solutions are classified into two strategies: leveraging pre-trained LAMs and developing native LAMs designed specifically for physical layer tasks. The motivations and key frameworks of these approaches are comprehensively examined through multiple use cases. Both strategies significantly improve performance and adaptability across diverse wireless scenarios. Future research directions, including efficient architectures, interpretability, standardized datasets, and collaboration between large and small models, are proposed to advance LAM-based physical layer solutions for next-generation communication systems.</description>
      <guid isPermaLink="false">oai:arXiv.org:2508.02314v2</guid>
      <category>cs.IT</category>
      <category>cs.AI</category>
      <category>math.IT</category>
      <pubDate>Wed, 21 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Jiajia Guo, Yiming Cui, Shi Jin, Jun Zhang</dc:creator>
    </item>
    <item>
      <title>Optimum 1-Step Majority-Logic Decoding of Binary Reed-Muller Codes</title>
      <link>https://arxiv.org/abs/2508.08736</link>
      <description>arXiv:2508.08736v3 Announce Type: replace 
Abstract: The classical majority-logic decoder proposed by Reed for Reed-Muller codes RM(r, m) of order r and length 2^m, unfolds in r+1 sequential steps, decoding message symbols from highest to lowest degree. Several follow-up decoding algorithms reduced the number of steps, but for a limited set of parameters, or at the expense of reduced performance, or relying on the existence of some combinatorial structures. We show that any one-step majority-logic decoder-that is, a decoder performing all majority votes in one step simultaneously without sequential processing-can correct at most d_min/4 errors for all values of r and m, where d_min denotes the code's minimum distance. We then introduce a new hard-decision decoder that completes the decoding in a single step and attains this error-correction limit. It applies to all r and m, and can be viewed as a parallel realization of Reed's original algorithm, decoding all message symbols simultaneously. Remarkably, we also prove that the decoder is optimum in the erasure setting: it recovers the message from any erasure pattern of up to d_min-1 symbols-the theoretical limit. To our knowledge, this is the first 1-step decoder for RM codes that achieves both optimal erasure correction and the maximum one-step error correction capability.</description>
      <guid isPermaLink="false">oai:arXiv.org:2508.08736v3</guid>
      <category>cs.IT</category>
      <category>math.CO</category>
      <category>math.IT</category>
      <pubDate>Wed, 21 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Hoang Ly, Emina Soljanin</dc:creator>
    </item>
    <item>
      <title>High-Capacity and Low-PAPR BICM-OFDM Systems Using Non-Equiprobable and Non-Uniform Constellation Shaping With Clipping and Filtering</title>
      <link>https://arxiv.org/abs/2508.15639</link>
      <description>arXiv:2508.15639v2 Announce Type: replace 
Abstract: We address a design of high-capacity and low-peak-to-average power ratio (PAPR) orthogonal frequency-division multiplexing (OFDM) systems based on bit-interleaved coded modulation (BICM) utilizing non-equiprobable and non-uniform (NENU) constellations as well as clipping and filtering (CAF). The proposed constellations are generated using a truncated Gaussian distribution and the merging of constellation points, where the former creates a non-uniform constellation (NUC), and the latter adjusts the number of signal points for further improving the total bit-wise mutual information (BMI). Unlike other exhaustive search-based approaches, the proposed constellations are uniquely determined by only two parameters associated with NUC and cardinality. Due to this property of limited degrees of freedom, the complexity required for the numerical optimization process can be significantly low. We focus on the constellation design based on one dimension, i.e., pulse amplitude modulation (PAM), which facilitates the reduction of demapping complexity for the BICM receiver. The use of CAF at the transmitter can efficiently reduce the PAPR of OFDM signals; however, it introduces clipping noise that may degrade error rate performance, making the application of clipping noise cancellation (CNC) at the receiver essential. Therefore, we optimize the NENU constellations in the presence of CAF and CNC. Simulation results demonstrate that the combination of constellation shaping with CAF and CNC enables BICM-OFDM systems to simultaneously achieve low PAPR and high spectral efficiency over additive white Gaussian noise (AWGN) as well as frequency-selective fading channels. Furthermore, comparative studies confirm that the proposed system significantly outperforms the single-carrier counterpart (i.e., DFT-precoded BICM-OFDM) in terms of PAPR and bit error rate (BER) performance over fading channels.</description>
      <guid isPermaLink="false">oai:arXiv.org:2508.15639v2</guid>
      <category>cs.IT</category>
      <category>eess.SP</category>
      <category>math.IT</category>
      <pubDate>Wed, 21 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Eito Kurihara, Hideki Ochiai</dc:creator>
    </item>
    <item>
      <title>Learning the Influence Graph of a Markov Process that Randomly Resets to the Past</title>
      <link>https://arxiv.org/abs/2509.16129</link>
      <description>arXiv:2509.16129v2 Announce Type: replace 
Abstract: Learning the influence graph G of a high-dimensional Markov process is central to many application domains, including social networks, neuroscience, and financial risk analysis. However, in many of these applications, future states of the process are occasionally and unpredictably influenced by a distant past state, thus destroying the Markovianity. To study this practical issue, we propose the past influence model (PIM), which captures the occasional "random resets to past" by modifying the Markovian dynamics in [1], which, in turn, is a non-linear generalization of the dynamics studied in [2], [3]. The recursive greedy algorithm proposed in this paper recovers any bounded degree $G$ when the number of ``jumps back in time" is order-wise smaller than the total number of samples, and the algorithm does not require memory.</description>
      <guid isPermaLink="false">oai:arXiv.org:2509.16129v2</guid>
      <category>cs.IT</category>
      <category>math.IT</category>
      <pubDate>Wed, 21 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Sudharsan Senthil, Avhishek Chatterjee</dc:creator>
    </item>
    <item>
      <title>Universal Maximum Likelihood (List) Decoding via Fast Vector-Matrix Multiplication</title>
      <link>https://arxiv.org/abs/2510.21414</link>
      <description>arXiv:2510.21414v3 Announce Type: replace 
Abstract: Maximum-likelihood (ML) decoding for arbitrary block codes remains fundamentally hard, with worst-case time complexity-measured by the total number of multiplications-being no better than straightforward exhaustive search, which requires $q^{k} n$ operations for an $[n,k]_q$ code. This paper introduces a simple, code-agnostic framework that reduces the worst-case complexity by a factor of $n$, down to $q^{k}$ operations, a highly desirable reduction in practice. The result holds for both linear and nonlinear block codes over general memoryless channels and under both hard-decision and soft-decision decoding. It naturally extends to intersymbol-interference (ISI) channels and ML list decoding with only a negligible increase in complexity. Our core insight is that, upon receipt of each sequence at the receiver, the conditional probability of that sequence for each codeword in the codebook (i.e., the \emph{likelihood}) can be expressed as the inner product of two carefully constructed vectors -- the first depending on the received sequence, and the second on that codeword itself. As a result, evaluating the likelihoods for all codewords in the codebook reduces to a single vector-matrix multiplication, and ML decoding (MLD) becomes the simple task of picking the maximum entry in the resulting vector. The only non-trivial cost lies in the vector-matrix product. However, our matrix construction allows the use of the Mailman algorithm to reduce this cost. This time reduction is achieved at the cost of high space complexity, requiring $\mathcal{O}(q^{k+1} n)$ space to store the pre-computed codebook matrix.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.21414v3</guid>
      <category>cs.IT</category>
      <category>cs.DS</category>
      <category>math.IT</category>
      <pubDate>Wed, 21 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Hoang Ly, Emina Soljanin, Michael Schleppy</dc:creator>
    </item>
    <item>
      <title>Ergodic Rate Analysis of Two-State Pinching-Antenna Systems</title>
      <link>https://arxiv.org/abs/2511.01798</link>
      <description>arXiv:2511.01798v2 Announce Type: replace 
Abstract: Flexible Antenna Systems (FAS) are a key enabler of next-generation wireless networks, allowing the antenna aperture to be dynamically reconfigured to adapt to channel conditions and service requirements. In this context, pinching-antenna systems (PASs) implemented on software-controllable dielectric waveguides provide the ability to reconfigure both channel characteristics and path loss by selectively exciting discrete radiation points. Existing works, however, typically assume continuously adjustable pinching positions, neglecting the spatial discreteness imposed by practical implementations. This paper develops a closed-form analytical framework for the ergodic rate of two-state PASs, where pinching antennas are fixed and only their activation states are controlled. To quantify the impact of spatial discretization, pinching discretization efficiency is introduced, characterizing the performance gap relative to the ideal continuous case. Finally, numerical results show that near-continuous performance can be achieved with a limited number of pinching points, providing design insights for scalable PASs.</description>
      <guid isPermaLink="false">oai:arXiv.org:2511.01798v2</guid>
      <category>cs.IT</category>
      <category>math.IT</category>
      <pubDate>Wed, 21 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Dimitrios Tyrovolas, Sotiris A. Tegos, Yue Xiao, Panagiotis D. Diamantoulakis, Sotiris Ioannidis, Christos Liaskos, George K. Karagiannidis, Stylianos D. Asimonis</dc:creator>
    </item>
    <item>
      <title>SCL Decoding of Non-Binary Linear Block Codes</title>
      <link>https://arxiv.org/abs/2511.11256</link>
      <description>arXiv:2511.11256v2 Announce Type: replace 
Abstract: Non-binary linear block codes (NB-LBCs) are an important class of error-correcting codes that are especially competent in correcting burst errors. They have broad applications in modern communications and storage systems. However, efficient soft-decision decoding of these codes remains to be further developed. This paper proposes successive cancellation list (SCL) decoding for NB-LBCs that are defined over a finite field of characteristic two, i.e., F_{2^r}, where r is the extension degree. By establishing a one-to-r mapping between the binary composition of each non-binary codeword and $r$ binary polar codewords, SCL decoding of the r polar codes can be performed with a complexity that is sub-quadratic in the codeword length. A simplified path sorting is further proposed to facilitate the decoding. Simulation results on short-length extended Reed-Solomon (eRS) and non-binary extended BCH (NB-eBCH) codes show that SCL decoding can outperform their state-of-the-art soft-decision decoding with fewer finite field arithmetic operations. For length-16 eRS codes, their maximum-likelihood (ML) decoding performances can be approached with a moderate list size.</description>
      <guid isPermaLink="false">oai:arXiv.org:2511.11256v2</guid>
      <category>cs.IT</category>
      <category>math.IT</category>
      <pubDate>Wed, 21 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Jingyu Lin, Li Chen, Xiaoqian Ye</dc:creator>
    </item>
    <item>
      <title>Function-Correcting Codes With Data Protection</title>
      <link>https://arxiv.org/abs/2511.18420</link>
      <description>arXiv:2511.18420v2 Announce Type: replace 
Abstract: Function-correcting codes (FCCs) are designed to provide error protection for the value of a function computed on the data. Existing work typically focuses solely on protecting the function value and not the underlying data. In this work, we propose a general framework that offers protection for both the data and the function values. Since protecting the data inherently contributes to protecting the function value, we focus on scenarios where the function value requires stronger protection than the data itself. We first introduce a more general approach and a framework for function-correcting codes that incorporates data protection along with protection of function values. A two-step construction procedure for such codes is proposed, and bounds on the optimal redundancy of general FCCs with data protection are reported. Using these results, we exhibit examples that show that data protection can be added to existing FCCs without increasing redundancy. Using our two-step construction procedure, we present explicit constructions of FCCs with data protection for specific families of functions, such as locally bounded functions and the Hamming weight function. We associate a graph called minimum-distance graph to a code and use it to show that perfect codes and maximum distance separable (MDS) codes cannot provide additional protection to function values over and above the amount of protection for data for any function. Then we focus on linear FCCs and provide some results for linear functions, leveraging their inherent structural properties. To the best of our knowledge, this is the first instance of FCCs with a linear structure. Finally, we generalize the Plotkin and Hamming bounds well known in classical error-correcting coding theory to FCCs with data protection.</description>
      <guid isPermaLink="false">oai:arXiv.org:2511.18420v2</guid>
      <category>cs.IT</category>
      <category>math.IT</category>
      <pubDate>Wed, 21 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Charul Rajput, B. Sundar Rajan, Ragnar Freij-Hollanti, Camilla Hollanti</dc:creator>
    </item>
    <item>
      <title>Covering in Hamming and Grassmann Spaces: New Bounds and Reed--Solomon-Based Constructions</title>
      <link>https://arxiv.org/abs/2512.22911</link>
      <description>arXiv:2512.22911v2 Announce Type: replace 
Abstract: We study covering problems in Hamming and Grassmann spaces through a unified coding-theoretic and information-theoretic framework. Viewing covering as a form of quantization in general metric spaces, we introduce the notion of the average covering radius as a natural measure of average distortion, complementing the classical worst-case covering radius. By leveraging tools from one-shot rate-distortion theory, we derive explicit non-asymptotic random-coding bounds on the average covering radius in both spaces, which serve as fundamental performance benchmarks.
  On the construction side, we develop efficient puncturing-based covering algorithms for generalized Reed--Solomon (GRS) codes in the Hamming space and extend them to a new family of subspace codes, termed character-Reed--Solomon (CRS) codes, for Grassmannian quantization under the chordal distance. Our results reveal that, despite poor worst-case covering guarantees, these structured codes exhibit strong average covering performance. In particular, numerical results in the Hamming space demonstrate that RS-based constructions often outperform random codebooks in terms of average covering radius. In the one-dimensional Grassmann space, we numerically show that CRS codes over prime fields asymptotically achieve average covering radii within a constant factor of the random-coding bound in the high-rate regime. Together, these results provide new insights into the role of algebraic structure in covering problems and high-dimensional quantization.</description>
      <guid isPermaLink="false">oai:arXiv.org:2512.22911v2</guid>
      <category>cs.IT</category>
      <category>eess.SP</category>
      <category>math.IT</category>
      <pubDate>Wed, 21 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Samin Riasat, Hessam Mahdavifar</dc:creator>
    </item>
    <item>
      <title>Algorithmic Information Theory for Graph Edge Grouping and Substructure Analysis</title>
      <link>https://arxiv.org/abs/2601.01760</link>
      <description>arXiv:2601.01760v3 Announce Type: replace 
Abstract: Understanding natural phenomenon through the interactions of different complex systems has become an increasing focus in scientific inquiry. Defining complexity and actually measuring it is an ongoing debate and no standard framework has been established that is both theoretically sound and computationally practical to use. Currently, one of the fields which attempts to formally define complexity is in the realm of Algorithmic Information Theory. The field has shown advances by studying the complexity values of binary strings and 2-dimensional binary matrices using 1-dimensional and 2-dimensional Turing machines, respectively. Using these complexity values, an algorithm called the Block Decomposition Method developed by Zenil, et al. in 2018, has been created to approximate the complexity of adjacency matrices of graphs which have found relative success in grouping graphs based on their complexity values. We use this method along with another method called edge perturbation to exhaustively determine if an edge can be identified to connect two subgraphs within a graph using the entire symmetric group of its vertices permutation and via unique permutations we call automorphic subsets, which are a special subset of the symmetric group. We also analyze if edges will be grouped closer to their respective subgraphs in terms of the average algorithmic information contribution. This analysis ascertains if Algorithmic Information Theory can serve as a viable theory for understanding graph substructures and as a foundation for frameworks measuring and analyzing complexity. The study found that the connecting edge was successfully identified as having the highest average information contribution in 29 out of 30 graphs, and in 16 of these, the distance to the next edge was greater than log_2(2). Furthermore, the symmetric group outperformed automorphic subsets in edge grouping.</description>
      <guid isPermaLink="false">oai:arXiv.org:2601.01760v3</guid>
      <category>cs.IT</category>
      <category>math.IT</category>
      <pubDate>Wed, 21 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Gabriel Potestades</dc:creator>
    </item>
    <item>
      <title>On the Sequence Reconstruction Problem for the Single-Deletion Two-Substitution Channel</title>
      <link>https://arxiv.org/abs/2601.07547</link>
      <description>arXiv:2601.07547v2 Announce Type: replace 
Abstract: The Levenshtein sequence reconstruction problem studies the reconstruction of a transmitted sequence from multiple erroneous copies of it. A fundamental question in this field is to determine the minimum number of erroneous copies required to guarantee correct reconstruction of the original sequence. This problem is equivalent to determining the maximum possible intersection size of two error balls associated with the underlying channel. Existing research on the sequence reconstruction problem has largely focused on channels with a single type of error, such as insertions, deletions, or substitutions alone. However, relatively little is known for channels that involve a mixture of error types, for instance, channels allowing both deletions and substitutions. In this work, we study the sequence reconstruction problem for the single-deletion two-substitution channel, which allows one deletion and at most two substitutions applied to the transmitted sequence. Specifically, we prove that if two $q$-ary length-$n$ sequences have the Hamming distance $d\geq 2$, where $q\geq 2$ is any fixed integer, then the intersection size of their error balls under the single-deletion two-substitution channel is upper bounded by $(q^2-1)n^2-(3q^2+5q-5)n+O_q(1)$, where $O_q(1)$ is a constant independent from $n$ but dependent on $q$. Moreover, we show that this upper bound is tight up to an additive constant.</description>
      <guid isPermaLink="false">oai:arXiv.org:2601.07547v2</guid>
      <category>cs.IT</category>
      <category>math.IT</category>
      <pubDate>Wed, 21 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Wentu Song, Kui Cai, Tony Q. S. Quek</dc:creator>
    </item>
    <item>
      <title>On the Generalization Error of Differentially Private Algorithms Via Typicality</title>
      <link>https://arxiv.org/abs/2601.08386</link>
      <description>arXiv:2601.08386v2 Announce Type: replace 
Abstract: We study the generalization error of stochastic learning algorithms from an information-theoretic perspective, with a particular emphasis on deriving sharper bounds for differentially private algorithms. It is well known that the generalization error of stochastic learning algorithms can be bounded in terms of mutual information and maximal leakage, yielding in-expectation and high-probability guarantees, respectively. In this work, we further upper bound mutual information and maximal leakage by explicit, easily computable formulas, using typicality-based arguments and exploiting the stability properties of private algorithms. In the first part of the paper, we strictly improve the mutual-information bounds by Rodr\'iguez-G\'alvez et al. (IEEE Trans. Inf. Theory, 2021). In the second part, we derive new upper bounds on the maximal leakage of learning algorithms. In both cases, the resulting bounds on information measures translate directly into generalization error guarantees.</description>
      <guid isPermaLink="false">oai:arXiv.org:2601.08386v2</guid>
      <category>cs.IT</category>
      <category>math.IT</category>
      <pubDate>Wed, 21 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Yanxiao Liu, Chun Hei Michael Shiu, Lele Wang, Deniz G\"und\"uz</dc:creator>
    </item>
    <item>
      <title>Two-dimensional Entanglement-assisted Quantum Quasi-cyclic Low-density Parity-check Codes</title>
      <link>https://arxiv.org/abs/2601.08927</link>
      <description>arXiv:2601.08927v2 Announce Type: replace 
Abstract: For any positive integer $g \ge 2$, we derive general condition for the existence of a $2g$-cycle in the Tanner graph of two-dimensional ($2$-D) classical quasi-cyclic (QC) low-density parity-check (LDPC) codes. Depending on whether $p$ is an odd prime or a composite number, we construct two distinct families of $2$-D classical QC-LDPC codes with girth $&gt;4$ by stacking $p \times p \times p$ tensors. Furthermore, using generalized Behrend sequences, we propose an additional family of $2$-D classical QC-LDPC codes with girth $&gt;6$, constructed via a similar tensor-stacking approach. All the proposed $2\text{-D}$ classical QC-LDPC codes exhibit an erasure correction capability of at least $p \times p$. Based on the constructed $2\text{-D}$ classical QC-LDPC codes, we derive two families of $2\text{-D}$ entanglement-assisted (EA) quantum low-density parity-check (QLDPC) codes. The first family of $2\text{-D}$ EA-QLDPC codes is obtained from a pair of $2\text{-D}$ classical QC-LDPC codes and is designed such that the unassisted part of the Tanner graph of the resulting EA-QLDPC code is free of $4$-cycles, while requiring only a single ebit to be shared across the quantum transceiver. The second family is constructed from a single $2\text{-D}$ classical QC-LDPC code whose Tanner graph is free from $4$-cycles. Moreover, the constructed EA-QLDPC codes inherit an erasure correction capability of $p \times p$, as the underlying classical codes possess the same erasure correction property.</description>
      <guid isPermaLink="false">oai:arXiv.org:2601.08927v2</guid>
      <category>cs.IT</category>
      <category>math.IT</category>
      <pubDate>Wed, 21 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Pavan Kumar, Shayan Srinivasa Garani</dc:creator>
    </item>
    <item>
      <title>On Polar Coding with Feedback</title>
      <link>https://arxiv.org/abs/2601.09222</link>
      <description>arXiv:2601.09222v2 Announce Type: replace 
Abstract: In this work, we investigate the performance of polar codes with the assistance of feedback in communication systems. Although it is well known that feedback does not improve the capacity of memoryless channels, we show that the finite length performance of polar codes can be significantly improved as feedback enables genie-aided decoding and allows more flexible thresholds for the polar coding construction. To analyze the performance under the new construction, we then propose an accurate characterization of the distribution of the error event under the genie-aided successive cancellation (SC) decoding. This characterization can be also used to predict the performance of the standard SC decoding of polar codes with rates close to capacity.</description>
      <guid isPermaLink="false">oai:arXiv.org:2601.09222v2</guid>
      <category>cs.IT</category>
      <category>math.IT</category>
      <pubDate>Wed, 21 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <dc:creator>Ling Liu, Qi Cao, Liping Li, Baoming Bai</dc:creator>
    </item>
    <item>
      <title>A Finite-Sample Strong Converse for Binary Hypothesis Testing via (Reverse) R\'enyi Divergence</title>
      <link>https://arxiv.org/abs/2601.09550</link>
      <description>arXiv:2601.09550v2 Announce Type: replace 
Abstract: This work investigates binary hypothesis testing between $H_0\sim P_0$ and $H_1\sim P_1$ in the finite-sample regime under asymmetric error constraints. By employing the ``reverse" R\'enyi divergence, we derive novel non-asymptotic bounds on the Type II error probability which naturally establish a strong converse result. Furthermore, when the Type I error is constrained to decay exponentially with a rate $c$, we show that the Type II error converges to 1 exponentially fast if $c$ exceeds the Kullback-Leibler divergence $D(P_1\|P_0)$, and vanishes exponentially fast if $c$ is smaller. Finally, we present numerical examples demonstrating that the proposed converse bounds strictly improve upon existing finite-sample results in the literature.</description>
      <guid isPermaLink="false">oai:arXiv.org:2601.09550v2</guid>
      <category>cs.IT</category>
      <category>math.IT</category>
      <pubDate>Wed, 21 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Roberto Bruno, Adrien Vandenbroucque, Amedeo Roberto Esposito</dc:creator>
    </item>
    <item>
      <title>Counting and Entropy Bounds for Structure-Avoiding Spatially-Coupled LDPC Constructions</title>
      <link>https://arxiv.org/abs/2601.09674</link>
      <description>arXiv:2601.09674v2 Announce Type: replace 
Abstract: Designing large coupling memory quasi-cyclic spatially-coupled LDPC (QC-SC-LDPC) codes with low error floors requires eliminating specific harmful substructures (e.g., short cycles) induced by edge spreading and lifting. Building on our work~\cite{r15} that introduced a Clique Lov\'asz Local Lemma (CLLL)-based design principle and a Moser--Tardos (MT)-type constructive approach, this work quantifies the size and structure of the feasible design space. Using the quantitative CLLL, we derive explicit lower bounds on the number of feasible edge-spreading and lifting assignments satisfying a given family of structure-avoidance constraints, and further obtain bounds on the number of non-equivalent solutions under row/column permutations. Moreover, via R\'enyi entropy bounds for the MT distribution, we provide a computable lower bound on the number of distinct solutions that the MT algorithm can output, giving a concrete diversity guarantee for randomized constructions. Specializations for eliminating 4-cycles yield closed-form bounds as functions of system parameters, offering a principled way to select the memory and lifting degree and to estimate the remaining search space.</description>
      <guid isPermaLink="false">oai:arXiv.org:2601.09674v2</guid>
      <category>cs.IT</category>
      <category>math.IT</category>
      <pubDate>Wed, 21 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Lei Huang</dc:creator>
    </item>
    <item>
      <title>On the Leaky Private Information Retrieval with Side Information</title>
      <link>https://arxiv.org/abs/2601.09960</link>
      <description>arXiv:2601.09960v2 Announce Type: replace 
Abstract: This paper investigates the problem of Leaky Private Information Retrieval with Side Information (L-PIR-SI), providing a fundamental characterization of the trade-off among leaky privacy, side information, and download cost. We propose a unified probabilistic framework to design L-PIR-SI schemes under $\varepsilon$-differential privacy variants of both $W$-privacy and $(W, S)$-privacy. Explicit upper bounds on the download cost are derived, which strictly generalize existing results: our bounds recover the capacity of perfect PIR-SI as $\varepsilon \to 0$, and reduce to the known $\varepsilon$-leaky PIR rate in the absence of side information. Furthermore, we conduct a refined analysis of the privacy--utility trade-off at the scaling-law level, demonstrating that the leakage ratio exponent scales as $\mathcal{O}(\log \frac{K}{M + 1})$ under leaky $W$-privacy, and as $\mathcal{O}(\log K)$ under leaky $(W, S)$-privacy in the minimal non-trivial setting $M = 1$, where $K$ and $M$ denote the number of messages and the side information size, respectively.</description>
      <guid isPermaLink="false">oai:arXiv.org:2601.09960v2</guid>
      <category>cs.IT</category>
      <category>math.IT</category>
      <pubDate>Wed, 21 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Yingying Huangfu, Tian Bai</dc:creator>
    </item>
    <item>
      <title>A Hybrid Reliability--Weight Framework for Construction of Polar Codes</title>
      <link>https://arxiv.org/abs/2601.10376</link>
      <description>arXiv:2601.10376v2 Announce Type: replace 
Abstract: Polar codes are usually constructed by ranking synthetic bit-channels according to reliability, which guarantees capacity-achieving behavior but can yield poor low-weight spectra at short and moderate lengths. Recent algebraic results express the contribution of individual bit-channels to the multiplicities of minimum and near-minimum weight codewords in closed form. In this work we combine these insights into a mixed (reliability--weight) bit-channel ordering. We define a per-bit cost whose distance term is derived from orbit enumeration of minimum-weight codewords and scaled by a Bhattacharyya-type factor, and show that the resulting mixed construction minimises a truncated SC/ML union-bound surrogate within a class of decreasing monomial codes. We relate the mixed metric to error events in SCL decoding via a pruning/ML decomposition, and prove that mixed designs act as local perturbations of reliability-based constructions whose asymptotic impact vanishes as code-length approaches infinity. Numerical results for short and moderate lengths on BPSK-AWGN, implemented via Gaussian approximation and closed-form weight contributions, illustrate the trade-off between pure reliability-based and mixed constructions in terms of minimum distance, multiplicity, and union-bound approximations. All proofs are deferred to the appendices.</description>
      <guid isPermaLink="false">oai:arXiv.org:2601.10376v2</guid>
      <category>cs.IT</category>
      <category>math.IT</category>
      <pubDate>Wed, 21 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Mohammad Rowshan, Vlad-Florin Dragoi</dc:creator>
    </item>
    <item>
      <title>Energy-Efficient Probabilistic Semantic Communication Over Visible Light Networks With Rate Splitting</title>
      <link>https://arxiv.org/abs/2601.10452</link>
      <description>arXiv:2601.10452v2 Announce Type: replace 
Abstract: Visible light communication (VLC) is emerging as a key technology for future wireless communication systems due to its unique physical-layer advantages over traditional radio-frequency (RF)-based systems. However, its integration with higher-layer techniques, such as semantic communication, remains underexplored. This paper investigates the energy efficiency maximization problem in a resource-constrained VLC-based probabilistic semantic communication (PSCom) system. In the considered model, light-emitting diode (LED) transmitters perform semantic compression to reduce data size, which incurs additional computation overhead. The compressed semantic information is transmitted to the users for semantic inference using a shared knowledge base that requires periodic updates to ensure synchronization. In the PSCom system, the knowledge base is represented by probabilistic graphs. To enable simultaneous transmission of both knowledge and information data, rate splitting multiple access (RSMA) is employed. The optimization problem focuses on maximizing energy efficiency by jointly optimizing transmit beamforming, direct current (DC) bias, common rate allocation, and semantic compression ratio, while accounting for both communication and computation costs. To solve this problem, an alternating optimization algorithm based on successive convex approximation (SCA) and Dinkelbach method is developed. Simulation results demonstrate the effectiveness of the proposed approach.</description>
      <guid isPermaLink="false">oai:arXiv.org:2601.10452v2</guid>
      <category>cs.IT</category>
      <category>math.IT</category>
      <pubDate>Wed, 21 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Zhouxiang Zhao, Zhaohui Yang, Chen Zhu, Xin Tong, Zhaoyang Zhang</dc:creator>
    </item>
    <item>
      <title>Basis-Spline Assisted Coded Computing: Strategies and Error Bounds</title>
      <link>https://arxiv.org/abs/2601.10616</link>
      <description>arXiv:2601.10616v2 Announce Type: replace 
Abstract: Coded computing has emerged as a key framework for addressing the impact of stragglers in distributed computation. While polynomial functions often admit exact recovery under existing coded computing schemes, non-polynomial functions require approximate reconstruction from a finite number of evaluations, posing significant challenges. Consequently, interpolation-based methods for non-polynomial coded computing have gained attention, with Berrut approximated coded computing emerging as a state-of-the-art approach. However, due to the global support of Berrut interpolants, the reconstruction accuracy degrades significantly as the number of stragglers increases. To address this challenge, we propose a coded computing framework based on cubic B-spline interpolation. In our approach, server-side function evaluations are reconstructed at the master using B-splines, exploiting their local support and smoothness properties to enhance stability and accuracy. We provide a systematic methodology for integrating B-spline interpolation into coded computing and derive theoretical bounds on approximation error for certain class of smooth functions. Our analysis demonstrates that the error bounds of our approach exhibit a faster decay with respect to the number of workers compared to the Berrut-based method. Experimental results also confirm that our method offers improved accuracy over Berrut-based methods for various smooth non-polynomial functions.</description>
      <guid isPermaLink="false">oai:arXiv.org:2601.10616v2</guid>
      <category>cs.IT</category>
      <category>math.IT</category>
      <pubDate>Wed, 21 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Rimpi Borah, J. Harshan, V. Lalitha</dc:creator>
    </item>
    <item>
      <title>One-Shot Broadcast Joint Source-Channel Coding with Codebook Diversity</title>
      <link>https://arxiv.org/abs/2601.10648</link>
      <description>arXiv:2601.10648v2 Announce Type: replace 
Abstract: We study a one-shot joint source-channel coding setting where the source is encoded once and broadcast to $K$ decoders through independent channels. Success is predicated on at least one decoder recovering the source within a maximum distortion constraint. We find that in the one-shot regime, utilizing disjoint codebooks at each decoder yields a codebook diversity gain, distinct from the channel diversity gain that may be expected when several decoders observe independent realizations of the channel's output but share the same codebook. Coding schemes are introduced that leverage this phenomenon, where first- and second-order achievability bounds are derived via an adaptation of the Poisson matching lemma (Li and Anantharam, 2021) which allows for multiple decoders using disjoint codebooks. We further propose a hybrid coding scheme that partitions decoders into groups to optimally balance codebook and channel diversity. Numerical results on the binary symmetric channel demonstrate that the hybrid approach outperforms strategies where the decoders' codebooks are either fully shared or disjoint.</description>
      <guid isPermaLink="false">oai:arXiv.org:2601.10648v2</guid>
      <category>cs.IT</category>
      <category>math.IT</category>
      <pubDate>Wed, 21 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Joseph Rowan, Buu Phan, Ashish Khisti</dc:creator>
    </item>
    <item>
      <title>Perfect Secret Key Generation for a class of Hypergraphical Sources</title>
      <link>https://arxiv.org/abs/2601.10697</link>
      <description>arXiv:2601.10697v2 Announce Type: replace 
Abstract: Nitinawarat and Narayan proposed a perfect secret key generation scheme for the so-called \emph{pairwise independent network (PIN) model} by exploiting the combinatorial properties of the underlying graph, namely the spanning tree packing rate. This work considers a generalization of the PIN model where the underlying graph is replaced with a hypergraph, and makes progress towards designing similar perfect secret key generation schemes by exploiting the combinatorial properties of the hypergraph.
  Our contributions are two-fold. We first provide a capacity achieving scheme for a complete $t$-uniform hypergraph on $m$ vertices by leveraging a packing of the complete $t$-uniform hypergraphs by what we refer to as star hypergraphs, and designing a scheme that gives $\binom{m-2}{t-2}$ bits of perfect secret key per star graph. Our second contribution is a 2-bit perfect secret key generation scheme for 3-uniform star hypergraphs whose projections are cycles. This scheme is then extended to a perfect secret key generation scheme for generic 3-uniform hypergraphs by exploiting star graph packing of 3-uniform hypergraphs and Hamiltonian packings of graphs. The scheme is then shown to be capacity achieving for certain classes of hypergraphs.</description>
      <guid isPermaLink="false">oai:arXiv.org:2601.10697v2</guid>
      <category>cs.IT</category>
      <category>math.IT</category>
      <pubDate>Wed, 21 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Manuj Mukherjee, Sagnik Chatterjee, Alhad Sethi</dc:creator>
    </item>
    <item>
      <title>Efficient Channel Autoencoders for Wideband Communications leveraging Walsh-Hadamard interleaving</title>
      <link>https://arxiv.org/abs/2601.11407</link>
      <description>arXiv:2601.11407v2 Announce Type: replace 
Abstract: This paper investigates how end-to-end (E2E) channel autoencoders (AEs) can achieve energy-efficient wideband communications by leveraging Walsh-Hadamard (WH) interleaved converters. WH interleaving enables high sampling rate analog-digital conversion with reduced power consumption using an analog WH transformation. We demonstrate that E2E-trained neural coded modulation can transparently adapt to the WH-transceiver hardware without requiring algorithmic redesign. Focusing on the short block length regime, we train WH-domain AEs and benchmark them against standard neural and conventional baselines, including 5G Polar codes. We quantify the system-level energy tradeoffs among baseband compute, channel signal-to-noise ratio (SNR), and analog converter power. Our analysis shows that the proposed WH-AE system can approach conventional Polar code SNR performance within 0.14dB while consuming comparable or lower system power. Compared to the best neural baseline, WH-AE achieves, on average, 29% higher energy efficiency (in bit/J) for the same reliability. These findings establish WH-domain learning as a viable path to energy-efficient, high-throughput wideband communications by explicitly balancing compute complexity, SNR, and analog power consumption.</description>
      <guid isPermaLink="false">oai:arXiv.org:2601.11407v2</guid>
      <category>cs.IT</category>
      <category>eess.SP</category>
      <category>math.IT</category>
      <pubDate>Wed, 21 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-sa/4.0/</dc:rights>
      <dc:creator>Cel Thys, Rodney Martinez Alonso, Sofie Pollin</dc:creator>
    </item>
    <item>
      <title>Machine Learning Decoder for 5G NR PUCCH Format 0</title>
      <link>https://arxiv.org/abs/2209.07861</link>
      <description>arXiv:2209.07861v2 Announce Type: replace-cross 
Abstract: 5G cellular systems depend on the timely exchange of feedback control information between the user equipment and the base station. Proper decoding of this control information is necessary to set up and sustain high throughput radio links. This paper makes the first attempt at using Machine Learning techniques to improve the decoding performance of the Physical Uplink Control Channel Format 0. We use fully connected neural networks to classify the received samples based on the uplink control information content embedded within them. The trained neural network, tested on real-time wireless captures, shows significant improvement in accuracy over conventional DFT-based decoders, even at low SNR. The obtained accuracy results also demonstrate conformance with 3GPP requirements.</description>
      <guid isPermaLink="false">oai:arXiv.org:2209.07861v2</guid>
      <category>cs.NI</category>
      <category>cs.IT</category>
      <category>cs.LG</category>
      <category>math.IT</category>
      <pubDate>Wed, 21 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-sa/4.0/</dc:rights>
      <arxiv:DOI>10.1109/NCC56989.2023.10067950</arxiv:DOI>
      <dc:creator>Anil Kumar Yerrapragada, Jeeva Keshav S, Ankit Gautam, Radha Krishna Ganti</dc:creator>
    </item>
    <item>
      <title>The distribution of Ridgeless least squares interpolators</title>
      <link>https://arxiv.org/abs/2307.02044</link>
      <description>arXiv:2307.02044v2 Announce Type: replace-cross 
Abstract: The Ridgeless minimum $\ell_2$-norm interpolator in overparametrized linear regression has attracted considerable attention in recent years in both machine learning and statistics communities. While it seems to defy conventional wisdom that overfitting leads to poor prediction, recent theoretical research on its $\ell_2$-type risks reveals that its norm minimizing property induces an `implicit regularization' that helps prediction in spite of interpolation.
  This paper takes a further step that aims at understanding its precise stochastic behavior as a statistical estimator. Specifically, we characterize the distribution of the Ridgeless interpolator in high dimensions, in terms of a Ridge estimator in an associated Gaussian sequence model with positive regularization, which provides a precise quantification of the prescribed implicit regularization in the most general distributional sense. Our distributional characterizations hold for general non-Gaussian random designs and extend uniformly to positively regularized Ridge estimators.
  As a direct application, we obtain a complete characterization for a general class of weighted $\ell_q$ risks of the Ridge(less) estimators that are previously only known for $q=2$ by random matrix methods. These weighted $\ell_q$ risks not only include the standard prediction and estimation errors, but also include the non-standard covariate shift settings. Our uniform characterizations further reveal a surprising feature of the commonly used generalized and $k$-fold cross-validation schemes: tuning the estimated $\ell_2$ prediction risk by these methods alone lead to simultaneous optimal $\ell_2$ in-sample, prediction and estimation risks, as well as the optimal length of debiased confidence intervals.</description>
      <guid isPermaLink="false">oai:arXiv.org:2307.02044v2</guid>
      <category>math.ST</category>
      <category>cs.IT</category>
      <category>math.IT</category>
      <category>stat.TH</category>
      <pubDate>Wed, 21 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Qiyang Han, Xiaocong Xu</dc:creator>
    </item>
    <item>
      <title>Covert Entanglement Generation and Secrecy</title>
      <link>https://arxiv.org/abs/2503.21002</link>
      <description>arXiv:2503.21002v4 Announce Type: replace-cross 
Abstract: We determine the covert capacity for entanglement generation over a noisy quantum channel. While secrecy guarantees that the transmitted information remains inaccessible to an adversary, covert communication ensures that the transmission itself remains undetectable. The entanglement dimension follows a square root law (SRL) in the covert setting, i.e., $O(\sqrt{n})$ EPR pairs can be distributed covertly and reliably over $n$ channel uses. We begin with covert communication of classical information under a secrecy constraint. We then leverage this result to construct a coding scheme for covert entanglement generation.</description>
      <guid isPermaLink="false">oai:arXiv.org:2503.21002v4</guid>
      <category>quant-ph</category>
      <category>cs.IT</category>
      <category>math.IT</category>
      <pubDate>Wed, 21 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Ohad Kimelfeld, Boulat A. Bash, Uzi Pereg</dc:creator>
    </item>
    <item>
      <title>Adaptive Entanglement Distillation</title>
      <link>https://arxiv.org/abs/2504.11670</link>
      <description>arXiv:2504.11670v2 Announce Type: replace-cross 
Abstract: Quantum network applications impose a variety of requirements on entanglement resources in terms of rate, fidelity, latency, and more. The repeaters in the quantum network must combine good methods for entanglement generation, effective entanglement distillation, and smart routing protocols to satisfy these application requirements. In this work, we focus on entanglement distillation in a linear chain of quantum repeaters. While conventional approaches reuse the same distillation scheme over multiple hop lengths after entanglement swaps, we propose a novel adaptive quantum error correction (QEC) scheme that boosts end-to-end metrics. Specifically, depending on the network operating point, we adapt the code used in distillation over successive rounds to monotonically increase the rate while also improving fidelity. We demonstrate the effectiveness of this strategy using three codes, with parameters [[9,1,3]], [[9,2,3]], [[9,3,3]], and a new performance metric, efficiency, that incorporates both overall rate and fidelity. Since the minimum input fidelity for QEC-based distillation is high, we then extend our study to include non-QEC-based purification protocols, specifically DEJMPS since it outperforms others. We compare the performance of end-to-end DEJMPS against adapting from DEJMPS to QEC once DEJMPS improves the initial fidelity to the threshold for QEC. Through a refined efficiency metric, we illuminate the regime where QEC is beneficial. These results provide a detailed outlook for entanglement purification and distillation in first and second generation quantum repeaters.</description>
      <guid isPermaLink="false">oai:arXiv.org:2504.11670v2</guid>
      <category>quant-ph</category>
      <category>cs.IT</category>
      <category>math.IT</category>
      <pubDate>Wed, 21 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Sijie Cheng, Narayanan Rengaswamy</dc:creator>
    </item>
    <item>
      <title>Flagged Extensions and Numerical Simulations for Quantum Channel Capacity: Bridging Theory and Computation</title>
      <link>https://arxiv.org/abs/2506.03429</link>
      <description>arXiv:2506.03429v2 Announce Type: replace-cross 
Abstract: I will investigate the capacities of noisy quantum channels through a combined analytical and numerical approach. First, I introduce novel flagged extension techniques that embed a channel into a higher-dimensional space, enabling single-letter upper bounds on quantum and private capacities. My results refine previous bounds and clarify noise thresholds beyond which quantum transmission vanishes. Second, I present a simulation framework that uses coherent information to estimate channel capacities in practice, focusing on two canonical examples: the amplitude damping channel (which we confirm is degradable and thus single-letter) and the depolarizing channel (whose capacity requires multi-letter superadditivity). By parameterizing input qubit states on the Bloch sphere, I numerically pinpoint the maximum coherent information for each channel and validate the flagged extension bounds. Notably, I capture the abrupt transition to zero capacity at high noise and observe superadditivity for moderate noise levels.</description>
      <guid isPermaLink="false">oai:arXiv.org:2506.03429v2</guid>
      <category>quant-ph</category>
      <category>cs.IT</category>
      <category>math.IT</category>
      <pubDate>Wed, 21 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Vahid Nourozi</dc:creator>
    </item>
    <item>
      <title>Optimal Hamiltonian for a quantum state with finite entropy</title>
      <link>https://arxiv.org/abs/2508.16575</link>
      <description>arXiv:2508.16575v3 Announce Type: replace-cross 
Abstract: We consider the following task: how for a given quantum state $\rho$ to find a grounded Hamiltonian $H$ satisfying the condition $\mathrm{Tr} H\rho\leq E_0&lt;+\infty$ in such a way that the von Neumann entropy of the Gibbs state $\gamma_H(E)$ corresponding to a given energy $E&gt;0$ be as small as possible.
  We show that for any mixed state $\rho$ with finite entropy and any $E&gt;0$ there exists a solution $H(\rho,E_0,E)$ of the above problem (unique in the non-degenerate case) which we call optimal Hamiltonian for the state $\rho$. Explicit expressions for $H(\rho,E_0,E)$, $\gamma_{H(\rho,E_0,E)}(E)$ and $S(\gamma_{H(\rho,E_0,E)}(E))$ are obtained. Analytical properties of the function $E\mapsto S(\gamma_{H(\rho,E_0,E)}(E))$ are explored. Several examples are considered.
  We also consider a modification of the above task in which arbitrary Hamiltonians (not necessarily grounded) are considered.
  The basic application motivated this research is described. As examples, new semicontinuity bounds for the von Neumann entropy and for the entanglement of formation are obtained and briefly discussed (with the intention to give a detailed analysis in a separate article).</description>
      <guid isPermaLink="false">oai:arXiv.org:2508.16575v3</guid>
      <category>quant-ph</category>
      <category>cs.IT</category>
      <category>math-ph</category>
      <category>math.IT</category>
      <category>math.MP</category>
      <pubDate>Wed, 21 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>M. E. Shirokov</dc:creator>
    </item>
    <item>
      <title>TCitH- and VOLEitH-based Signatures from Restricted Decoding</title>
      <link>https://arxiv.org/abs/2510.11224</link>
      <description>arXiv:2510.11224v2 Announce Type: replace-cross 
Abstract: Threshold-Computation-in-the-Head (TCitH) and VOLE-in-the-Head (VOLEitH), two recent developments of the MPC-in-the-Head (MPCitH) paradigm, have significantly improved the performance of digital signature schemes. This work embeds the restricted decoding problem within these frameworks: we propose a structurally simple modeling that achieves competitive signature sizes. Specifically, by instantiating the restricted decoding problem with the same hardness assumption underlying CROSS, we reduce sizes by more than a factor of two compared to the NIST submission. Moreover, we observe that ternary full-weight decoding, closely related to the hardness assumption underlying WAVE, is a restricted decoding problem. Using ternary full-weight decoding, we obtain signature sizes comparable to the smallest MPCitH-based candidates in the NIST competition.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.11224v2</guid>
      <category>cs.CR</category>
      <category>cs.IT</category>
      <category>math.IT</category>
      <pubDate>Wed, 21 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Sebastian Bitzer, Michele Battagliola, Antonia Wachter-Zeh, Violetta Weger</dc:creator>
    </item>
    <item>
      <title>Forgetting-MarI: LLM Unlearning via Marginal Information Regularization</title>
      <link>https://arxiv.org/abs/2511.11914</link>
      <description>arXiv:2511.11914v3 Announce Type: replace-cross 
Abstract: As AI models are trained on ever-expanding datasets, the ability to remove the influence of specific data from trained models has become essential for privacy protection and regulatory compliance. Unlearning addresses this challenge by selectively removing parametric knowledge from the trained models without retraining from scratch, which is critical for resource-intensive models such as Large Language Models (LLMs). Existing unlearning methods often degrade model performance by removing more information than necessary when attempting to ''forget'' specific data. We introduce Forgetting-MarI, an LLM unlearning framework that provably removes only the additional (marginal) information contributed by the data to be unlearned, while preserving the information supported by the data to be retained. By penalizing marginal information, our method yields an explicit upper bound on the unlearn dataset's residual influence in the trained models, providing provable undetectability. Extensive experiments confirm that our approach outperforms current state-of-the-art unlearning methods, delivering reliable forgetting and better preserved general model performance across diverse benchmarks. This advancement represents an important step toward making AI systems more controllable and compliant with privacy and copyright regulations without compromising their effectiveness.</description>
      <guid isPermaLink="false">oai:arXiv.org:2511.11914v3</guid>
      <category>cs.AI</category>
      <category>cs.CL</category>
      <category>cs.CR</category>
      <category>cs.IT</category>
      <category>cs.LG</category>
      <category>math.IT</category>
      <pubDate>Wed, 21 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Shizhou Xu, Yuan Ni, Stefan Broecker, Thomas Strohmer</dc:creator>
    </item>
    <item>
      <title>Normalized Conditional Mutual Information Surrogate Loss for Deep Neural Classifiers</title>
      <link>https://arxiv.org/abs/2601.02543</link>
      <description>arXiv:2601.02543v3 Announce Type: replace-cross 
Abstract: In this paper, we propose a novel information theoretic surrogate loss; normalized conditional mutual information (NCMI); as a drop in alternative to the de facto cross-entropy (CE) for training deep neural network (DNN) based classifiers. We first observe that the model's NCMI is inversely proportional to its accuracy. Building on this insight, we introduce an alternating algorithm to efficiently minimize the NCMI. Across image recognition and whole-slide imaging (WSI) subtyping benchmarks, NCMI-trained models surpass state of the art losses by substantial margins at a computational cost comparable to that of CE. Notably, on ImageNet, NCMI yields a 2.77% top-1 accuracy improvement with ResNet-50 comparing to the CE; on CAMELYON-17, replacing CE with NCMI improves the macro-F1 by 8.6% over the strongest baseline. Gains are consistent across various architectures and batch sizes, suggesting that NCMI is a practical and competitive alternative to CE.</description>
      <guid isPermaLink="false">oai:arXiv.org:2601.02543v3</guid>
      <category>cs.LG</category>
      <category>cs.AI</category>
      <category>cs.CV</category>
      <category>cs.IT</category>
      <category>math.IT</category>
      <pubDate>Wed, 21 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Linfeng Ye, Zhixiang Chi, Konstantinos N. Plataniotis, En-hui Yang</dc:creator>
    </item>
    <item>
      <title>Breaking the Orthogonality Barrier in Quantum LDPC Codes</title>
      <link>https://arxiv.org/abs/2601.08824</link>
      <description>arXiv:2601.08824v3 Announce Type: replace-cross 
Abstract: Classical low-density parity-check (LDPC) codes are a widely deployed and well-established technology, forming the backbone of modern communication and storage systems. It is well known that, in this classical setting, increasing the girth of the Tanner graph while maintaining regular degree distributions leads simultaneously to good belief-propagation (BP) decoding performance and large minimum distance. In the quantum setting, however, this principle does not directly apply because quantum LDPC codes must satisfy additional orthogonality constraints between their parity-check matrices. When one enforces both orthogonality and regularity in a straightforward manner, the girth is typically reduced and the minimum distance becomes structurally upper bounded. In this work, we overcome this limitation by using permutation matrices with controlled commutativity and by restricting the orthogonality constraints to only the active part of the construction, while preserving regular check-matrix structures. This design circumvents conventional structural distance limitations induced by parent-matrix orthogonality, and enables the construction of quantum LDPC codes with large girth while avoiding latent low-weight logical operators. As a concrete demonstration, we construct a girth-8, (3,12)-regular $[[9216,4612, \leq 48]]$ quantum LDPC code and show that, under BP decoding combined with a low-complexity post-processing algorithm, it achieves a frame error rate as low as $10^{-8}$ on the depolarizing channel with error probability $4 \%$.</description>
      <guid isPermaLink="false">oai:arXiv.org:2601.08824v3</guid>
      <category>quant-ph</category>
      <category>cs.IT</category>
      <category>math.IT</category>
      <pubDate>Wed, 21 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Kenta Kasai</dc:creator>
    </item>
    <item>
      <title>Hybrid Encryption with Certified Deletion in Preprocessing Model</title>
      <link>https://arxiv.org/abs/2601.10542</link>
      <description>arXiv:2601.10542v2 Announce Type: replace-cross 
Abstract: Certified deletion allows Alice to outsource data to Bob and, at a later time, obtain a verifiable guarantee that the file has been irreversibly deleted at her request. The functionality, while impossible using classical information alone, can be achieved using quantum information. Existing approaches rely either on one-time pad (OTP) encryption, or on computational hardness assumptions that may be vulnerable to future advances in classical or quantum computing. In this work, we introduce and formalize hybrid encryption with certified deletion in the preprocessing model (pHE-CD) and propose two constructions. Each construction composes an information-theoretic key encapsulation mechanism (iKEM) with a data encapsulation mechanism that provides certified deletion (DEM-CD) security, offering different types of security depending on the security properties of DEM-CD. When DEM-CD is one-time information theoretically secure, the composition provides {\em information-theoretic security} for both encryption and certified deletion. When DEM-CD is computationally secure, the composed construction offers computationally secure (post-quantum) encryption and {\em everlasting certified deletion} where confidentiality is computational up to the point that the deletion certificate is verified, and after successful verification of the certificate, becomes unconditional. That is, successful verification of deletion certificate guarantees that the data has been removed information-theoretically from the adversary's view. Both pHE-CD schemes are for encryption of arbitrarily long messages. Construction 2 is key efficient and uses a DEM-CD that is constructed using quantum coding and AES, providing quantum-safe security for encryption. We discuss our results and directions for future work.</description>
      <guid isPermaLink="false">oai:arXiv.org:2601.10542v2</guid>
      <category>cs.CR</category>
      <category>cs.IT</category>
      <category>math.IT</category>
      <pubDate>Wed, 21 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Kunal Dey, Reihaneh Safavi-Naini</dc:creator>
    </item>
  </channel>
</rss>
