<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>econ.EM updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/econ.EM</link>
    <description>econ.EM updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/econ.EM" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Mon, 13 Oct 2025 04:01:01 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Mon, 13 Oct 2025 00:00:00 -0400</pubDate>
    <skipDays>
      <day>Saturday</day>
      <day>Sunday</day>
    </skipDays>
    <item>
      <title>Sensitivity Analysis for Treatment Effects in Difference-in-Differences Models using Riesz Representation</title>
      <link>https://arxiv.org/abs/2510.09064</link>
      <description>arXiv:2510.09064v1 Announce Type: new 
Abstract: Difference-in-differences (DiD) is one of the most popular approaches for empirical research in economics, political science, and beyond. Identification in these models is based on the conditional parallel trends assumption: In the absence of treatment, the average outcome of the treated and untreated group are assumed to evolve in parallel over time, conditional on pre-treatment covariates. We introduce a novel approach to sensitivity analysis for DiD models that assesses the robustness of DiD estimates to violations of this assumption due to unobservable confounders, allowing researchers to transparently assess and communicate the credibility of their causal estimation results. Our method focuses on estimation by Double Machine Learning and extends previous work on sensitivity analysis based on Riesz Representation in cross-sectional settings. We establish asymptotic bounds for point estimates and confidence intervals in the canonical $2\times2$ setting and group-time causal parameters in settings with staggered treatment adoption. Our approach makes it possible to relate the formulation of parallel trends violation to empirical evidence from (1) pre-testing, (2) covariate benchmarking and (3) standard reporting statistics and visualizations. We provide extensive simulation experiments demonstrating the validity of our sensitivity approach and diagnostics and apply our approach to two empirical applications.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.09064v1</guid>
      <category>econ.EM</category>
      <pubDate>Mon, 13 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Philipp Bach, Sven Klaassen, Jannis Kueck, Mara Mattes, Martin Spindler</dc:creator>
    </item>
    <item>
      <title>Sensitivity Analysis for Causal ML: A Use Case at Booking.com</title>
      <link>https://arxiv.org/abs/2510.09109</link>
      <description>arXiv:2510.09109v1 Announce Type: new 
Abstract: Causal Machine Learning has emerged as a powerful tool for flexibly estimating causal effects from observational data in both industry and academia. However, causal inference from observational data relies on untestable assumptions about the data-generating process, such as the absence of unobserved confounders. When these assumptions are violated, causal effect estimates may become biased, undermining the validity of research findings. In these contexts, sensitivity analysis plays a crucial role, by enabling data scientists to assess the robustness of their findings to plausible violations of unconfoundedness. This paper introduces sensitivity analysis and demonstrates its practical relevance through a (simulated) data example based on a use case at Booking.com. We focus our presentation on a recently proposed method by Chernozhukov et al. (2023), which derives general non-parametric bounds on biases due to omitted variables, and is fully compatible with (though not limited to) modern inferential tools of Causal Machine Learning. By presenting this use case, we aim to raise awareness of sensitivity analysis and highlight its importance in real-world scenarios.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.09109v1</guid>
      <category>econ.EM</category>
      <pubDate>Mon, 13 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Philipp Bach, Victor Chernozhukov, Carlos Cinelli, Lin Jia, Sven Klaassen, Nils Skotara, Martin Spindler</dc:creator>
    </item>
    <item>
      <title>Flexibility without foresight: the predictive limitations of mixture models</title>
      <link>https://arxiv.org/abs/2510.09185</link>
      <description>arXiv:2510.09185v1 Announce Type: new 
Abstract: Models allowing for random heterogeneity, such as mixed logit and latent class, are generally observed to obtain superior model fit and yield detailed insights into unobserved preference heterogeneity. Using theoretical arguments and two case studies on revealed and stated choice data, this paper highlights that these advantages do not translate into any benefits in forecasting, whether looking at prediction performance or the recovery of market shares. The only exception arises when using conditional distributions in making predictions for the same individuals included in the estimation sample, which obviously precludes any out-of-sample forecasting.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.09185v1</guid>
      <category>econ.EM</category>
      <pubDate>Mon, 13 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Stephane Hess, Sander van Cranenburgh</dc:creator>
    </item>
    <item>
      <title>Boundary estimation in the regression-discontinuity design: Evidence for a merit- and need-based financial aid program</title>
      <link>https://arxiv.org/abs/2510.09257</link>
      <description>arXiv:2510.09257v1 Announce Type: new 
Abstract: In the conventional regression-discontinuity (RD) design, the probability that units receive a treatment changes discontinuously as a function of one covariate exceeding a threshold or cutoff point. This paper studies an extended RD design where assignment rules simultaneously involve two or more continuous covariates. We show that assignment rules with more than one variable allow the estimation of a more comprehensive set of treatment effects, relaxing in a research-driven style the local and sometimes limiting nature of univariate RD designs. We then propose a flexible nonparametric approach to estimate the multidimensional discontinuity by univariate local linear regression and compare its performance to existing methods. We present an empirical application to a large-scale and countrywide financial aid program for low-income students in Colombia. The program uses a merit-based (academic achievement) and need-based (wealth index) assignment rule to select students for the program. We show that our estimation strategy fully exploits the multidimensional assignment rule and reveals heterogeneous effects along the treatment boundaries.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.09257v1</guid>
      <category>econ.EM</category>
      <pubDate>Mon, 13 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Eugenio Felipe Merlano</dc:creator>
    </item>
    <item>
      <title>Blackwell without Priors</title>
      <link>https://arxiv.org/abs/2510.08709</link>
      <description>arXiv:2510.08709v1 Announce Type: cross 
Abstract: This paper proposes a fully prior-free model of experimentation in which the decision maker observes the entire distribution of signals generated by a known experiment under an unknown distribution of the state of the world. One experiment is robustly more informative than another if the decision maker's maxmin expected utility after observing the output of the former is always at least her maxmin expected utility after observing the latter. We show that this ranking holds if and only if the less informative experiment is a linear transformation of the more informative experiment; equivalently, the null space of the more informative experiment is a subset of the null space of the less informative experiment. Our criterion is implied by Blackwell's order but does not imply it, and we show by example that our ranking admits strictly more comparable pairs of experiments than the classical ranking.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.08709v1</guid>
      <category>econ.TH</category>
      <category>econ.EM</category>
      <pubDate>Mon, 13 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Maxwell Rosenthal</dc:creator>
    </item>
    <item>
      <title>Ranking Policies Under Loss Aversion and Inequality Aversion</title>
      <link>https://arxiv.org/abs/2510.09590</link>
      <description>arXiv:2510.09590v1 Announce Type: cross 
Abstract: Strong empirical evidence from laboratory experiments, and more recently from population surveys, shows that individuals, when evaluating their situations, pay attention to whether they experience gains or losses, with losses weighing more heavily than gains. The electorate's loss aversion, in turn, influences politicians' choices. We propose a new framework for welfare analysis of policy outcomes that, in addition to the traditional focus on post-policy incomes, also accounts for individuals' gains and losses resulting from policies. We develop several bivariate stochastic dominance criteria for ranking policy outcomes that are sensitive to features of the joint distribution of individuals' income changes and absolute incomes. The main social objective assumes that individuals are loss averse with respect to income gains and losses, inequality averse with respect to absolute incomes, and hold varying preferences regarding the association between incomes and income changes. We translate these and other preferences into functional inequalities that can be tested using sample data. The concepts and methods are illustrated using data from an income support experiment conducted in Connecticut.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.09590v1</guid>
      <category>econ.TH</category>
      <category>econ.EM</category>
      <pubDate>Mon, 13 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <dc:creator>Martyna Kobus, Rados{\l}aw Kurek, Thomas Parker</dc:creator>
    </item>
    <item>
      <title>Learning the Effect of Persuasion via Difference-In-Differences</title>
      <link>https://arxiv.org/abs/2410.14871</link>
      <description>arXiv:2410.14871v3 Announce Type: replace 
Abstract: We develop a difference-in-differences framework to measure the persuasive impact of informational treatments on behavior. We introduce two causal parameters, the forward and backward average persuasion rates on the treated, which refine the average treatment effect on the treated. The forward rate excludes cases of "preaching to the converted," while the backward rate omits "talking to a brick wall" cases. We propose both regression-based and semiparametrically efficient estimators. The framework applies to both two-period and staggered treatment settings, including event studies, and we demonstrate its usefulness with applications to a British election and a Chinese curriculum reform.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.14871v3</guid>
      <category>econ.EM</category>
      <category>stat.ME</category>
      <pubDate>Mon, 13 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Sung Jae Jun, Sokbae Lee</dc:creator>
    </item>
    <item>
      <title>Team Networks with Partially Observed Links</title>
      <link>https://arxiv.org/abs/2505.08405</link>
      <description>arXiv:2505.08405v2 Announce Type: replace 
Abstract: This paper studies a linear production model in team networks with missing links. In the model, heterogeneous workers, represented as nodes, produce jointly and repeatedly within teams, represented as links. Links are omitted when their associated outcome variables fall below a threshold, resulting in partial observability of the network. To address this, I propose a Generalized Method of Moments estimator under normally distributed errors and develop a distribution-free test for detecting link truncation. Applied to academic publication data, the estimator reveals and corrects a substantial downward bias in the estimated scaling factor that aggregates individual fixed effects into team-specific fixed effects. This finding suggests that the collaboration premium may be systematically underestimated when missing links are not properly accounted for.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.08405v2</guid>
      <category>econ.EM</category>
      <pubDate>Mon, 13 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Yang Xu</dc:creator>
    </item>
    <item>
      <title>Hypothesis testing on invariant subspaces of non-diagonalizable matrices with applications to network statistics</title>
      <link>https://arxiv.org/abs/2303.18233</link>
      <description>arXiv:2303.18233v5 Announce Type: replace-cross 
Abstract: We generalise the inference procedure for eigenvectors of symmetrizable matrices of Tyler (1981) to that of invariant and singular subspaces of non-diagonalizable matrices. Wald tests for invariant vectors and $t$-tests for their individual coefficients perform well in simulations, despite the matrix being not symmetric. Using these results, it is now possible to perform inference on network statistics that depend on eigenvectors of non-symmetric adjacency matrices as they arise in empirical applications from directed networks. Further, we find that statisticians only need control over the first-order Davis-Kahan bound to control convergence rates of invariant subspace estimators to higher-orders. For general invariant subspaces, the minimal eigenvalue separation dominates the first-order bound potentially slowing convergence rates considerably. In an example, we find that accounting for uncertainty in network estimates changes empirical conclusions about the ranking of nodes' popularity.</description>
      <guid isPermaLink="false">oai:arXiv.org:2303.18233v5</guid>
      <category>math.ST</category>
      <category>econ.EM</category>
      <category>stat.ML</category>
      <category>stat.TH</category>
      <pubDate>Mon, 13 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>J\'er\^ome R. Simons</dc:creator>
    </item>
    <item>
      <title>A Hybrid Framework Combining Autoregression and Common Factors for Matrix Time Series Modeling</title>
      <link>https://arxiv.org/abs/2503.05340</link>
      <description>arXiv:2503.05340v2 Announce Type: replace-cross 
Abstract: Matrix-valued time series are increasingly common in economics and finance, but existing approaches such as matrix autoregressive and dynamic matrix factor models often impose restrictive assumptions and fail to capture complex dependencies. We propose a hybrid framework that integrates autoregressive dynamics with a shared low-rank common factor structure, enabling flexible modeling of temporal dependence and cross-sectional correlation while achieving dimension reduction. The model captures dynamic relationships through lagged matrix terms and leverages low-rank structures across predictor and response matrices, with connections between their row and column subspaces established via common latent bases to improve interpretability and efficiency. We develop a computationally efficient gradient-based estimation method and establish theoretical guarantees for statistical consistency and algorithmic convergence. Extensive simulations show robust performance under various data-generating processes, and in an application to multinational macroeconomic data, the model outperforms existing methods in forecasting and reveals meaningful interactions among economic factors and countries. The proposed framework provides a practical, interpretable, and theoretically grounded tool for analyzing high-dimensional matrix time series.</description>
      <guid isPermaLink="false">oai:arXiv.org:2503.05340v2</guid>
      <category>stat.ME</category>
      <category>econ.EM</category>
      <pubDate>Mon, 13 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Zhiyun Fan, Xiaoyu Zhang, Mingyang Chen, Di Wang</dc:creator>
    </item>
  </channel>
</rss>
