<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>cs.GT updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/cs.GT</link>
    <description>cs.GT updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/cs.GT" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Wed, 21 Jan 2026 05:00:29 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Wed, 21 Jan 2026 00:00:00 -0500</pubDate>
    <skipDays>
      <day>Sunday</day>
      <day>Saturday</day>
    </skipDays>
    <item>
      <title>Temporal Fair Division of Indivisible Goods with Scheduling</title>
      <link>https://arxiv.org/abs/2601.12835</link>
      <description>arXiv:2601.12835v1 Announce Type: new 
Abstract: We study temporal fair division, where agents receive goods over multiple rounds and cumulative fairness is required. We investigate Temporal Envy-Freeness Up to One Good (TEF1) and Up to Any Good (TEFX), its approximation $\alpha$-TEFX, and Temporal Maximin Share (TMMS). Motivated by known impossibilities in standard settings, we consider the model in various restricted settings and extend it by introducing scheduling.
  Our main contributions draw the boundary between possibility and impossibility. First, regarding temporal fair division without scheduling, we prove that while constant-factor $\alpha$-TEFX is impossible in general, a $1/2$-approximation is achievable for generalized binary valuations and identical days with two agents. Second, regarding temporal fair division with scheduling, we demonstrate that a scheduling buffer of size at least $n/2$ enables TEF1 for identical days. However, we establish that TEFX and TMMS remain largely impossible even with scheduling or restricted domains. These results highlight the inherent difficulty of strict temporal fairness and quantify the trade-offs required to achieve approximation guarantees.</description>
      <guid isPermaLink="false">oai:arXiv.org:2601.12835v1</guid>
      <category>cs.GT</category>
      <pubDate>Wed, 21 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Kui Wang Choi, Minming LI</dc:creator>
    </item>
    <item>
      <title>The Cost of EFX: Generalized-Mean Welfare and Complexity Dichotomies with Few Surplus Items</title>
      <link>https://arxiv.org/abs/2601.12849</link>
      <description>arXiv:2601.12849v1 Announce Type: new 
Abstract: Envy-freeness up to any good (EFX) is a central fairness notion for allocating indivisible goods, yet its existence is unresolved in general. In the setting with few surplus items, where the number of goods exceeds the number of agents by a small constant (at most three), EFX allocations are guaranteed to exist, shifting the focus from existence to efficiency and computation. We study how EFX interacts with generalized-mean ($p$-mean) welfare, which subsumes commonly-studied utilitarian ($p=1$), Nash ($p=0$), and egalitarian ($p \rightarrow -\infty$) objectives. We establish sharp complexity dichotomies at $p=0$: for any fixed $p \in (0,1]$, both deciding whether EFX can attain the global $p$-mean optimum and computing an EFX allocation maximizing $p$-mean welfare are NP-hard, even with at most three surplus goods; in contrast, for any fixed $p \leq 0$, we give polynomial-time algorithms that optimize $p$-mean welfare within the space of EFX allocations and efficiently certify when EFX attains the global optimum. We further quantify the welfare loss of enforcing EFX via the price of fairness framework, showing that for $p &gt; 0$, the loss can grow linearly with the number of agents, whereas for $p \leq 0$, it is bounded by a constant depending on the surplus (and for Nash welfare it vanishes asymptotically). Finally we show that requiring Pareto-optimality alongside EFX is NP-hard (and becomes $\Sigma_2^P$-complete for a stronger variant of EFX). Overall, our results delineate when EFX is computationally costly versus structurally aligned with welfare maximization in the setting with few surplus items.</description>
      <guid isPermaLink="false">oai:arXiv.org:2601.12849v1</guid>
      <category>cs.GT</category>
      <category>cs.AI</category>
      <category>cs.MA</category>
      <category>econ.TH</category>
      <pubDate>Wed, 21 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Eugene Lim, Tzeh Yuan Neoh, Nicholas Teh</dc:creator>
    </item>
    <item>
      <title>The Cost of Failure: On The Complexity of Recampaigning under Fixed Districts</title>
      <link>https://arxiv.org/abs/2601.13246</link>
      <description>arXiv:2601.13246v1 Announce Type: new 
Abstract: Redistricting efforts have gathered contemporary attention in both quotidian and scholarly debates, particularly in the United States where efforts to redraw congressional districts to favor either of the two major parties in 12 states -- such as California, Texas, and Ohio -- have captured the public eye. The treatment of redistricting in computational social choice has essentially focused on the process of determining "appropriate" districts. In this work, we are interested in understanding the gamut of options left for the "losing" party, and so we consider the flip side of the problem: Given fixed/predetermined districts, can a given party still make their candidates win by strategically placing them in certain districts? We dub this as "recampaigning" to capture the intuition that a party would redirect their campaigning efforts from one district to another. We model recampaigning as a computational problem, consider natural variations of the model, and study those new models through the lens of (1) (polynomial-time many-one) interreducibilities, (2) separations/collapses (both unconditional and axiomatic-sufficient), and (3) both worst-case and parametrized complexity.</description>
      <guid isPermaLink="false">oai:arXiv.org:2601.13246v1</guid>
      <category>cs.GT</category>
      <pubDate>Wed, 21 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Michael C. Chavrimootoo, Aidan Jeansonne</dc:creator>
    </item>
    <item>
      <title>Tight Asymptotic Bounds for Fair Division With Externalities</title>
      <link>https://arxiv.org/abs/2601.13287</link>
      <description>arXiv:2601.13287v1 Announce Type: new 
Abstract: We study the problem of allocating a set of indivisible items among agents whose preferences include externalities. Unlike the standard fair division model, agents may derive positive or negative utility not only from items allocated directly to them, but also from items allocated to other agents. Since exact envy-freeness cannot be guaranteed, prior work has focused on its relaxations. However, two central questions remained open: does there always exist an allocation that is envy-free up to one item (EF1), and if not, what is the optimal relaxation EF-$k$ that can always be attained?
  We settle both questions by deriving tight asymptotic bounds on the number of items sufficient to eliminate envy. We show that for any instance with $n$ agents, an allocation that is envy-free up to $O(\sqrt{n})$ items always exists and can be found in polynomial time, and we prove a matching $\Omega(\sqrt{n})$ lower bound showing that this result is tight even for binary valuations, which rules out the existence of EF1 allocations when agents have externalities.</description>
      <guid isPermaLink="false">oai:arXiv.org:2601.13287v1</guid>
      <category>cs.GT</category>
      <pubDate>Wed, 21 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Frank Connor, Max Dupr\'e la Tour, Vishnu V. Narayan, \v{S}imon Schierreich</dc:creator>
    </item>
    <item>
      <title>Bridging the Gap Between Estimated and True Regret Towards Reliable Regret Estimation in Deep Learning based Mechanism Design</title>
      <link>https://arxiv.org/abs/2601.13489</link>
      <description>arXiv:2601.13489v1 Announce Type: new 
Abstract: Recent advances, such as RegretNet, ALGnet, RegretFormer and CITransNet, use deep learning to approximate optimal multi item auctions by relaxing incentive compatibility (IC) and measuring its violation via ex post regret. However, the true accuracy of these regret estimates remains unclear. Computing exact regret is computationally intractable, and current models rely on gradient based optimizers whose outcomes depend heavily on hyperparameter choices. Through extensive experiments, we reveal that existing methods systematically underestimate actual regret (In some models, the true regret is several hundred times larger than the reported regret), leading to overstated claims of IC and revenue. To address this issue, we derive a lower bound on regret and introduce an efficient item wise regret approximation. Building on this, we propose a guided refinement procedure that substantially improves regret estimation accuracy while reducing computational cost. Our method provides a more reliable foundation for evaluating incentive compatibility in deep learning based auction mechanisms and highlights the need to reassess prior performance claims in this area.</description>
      <guid isPermaLink="false">oai:arXiv.org:2601.13489v1</guid>
      <category>cs.GT</category>
      <category>cs.LG</category>
      <category>econ.GN</category>
      <category>q-fin.EC</category>
      <pubDate>Wed, 21 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Shuyuan You, Zhiqiang Zhuang, Kewen Wang, Zhe Wang</dc:creator>
    </item>
    <item>
      <title>Concurrent Permissive Strategy Templates</title>
      <link>https://arxiv.org/abs/2601.13500</link>
      <description>arXiv:2601.13500v1 Announce Type: new 
Abstract: Two-player games on finite graphs provide a rigorous foundation for modeling the strategic interaction between reactive systems and their environment. While concurrent game semantics naturally capture the synchronous interactions characteristic of many cyber-physical systems (CPS), their adoption in CPS design remains limited. Building on the concept of permissive strategy templates (PeSTels) for turn-based games, we introduce concurrent (permissive) strategy templates (ConSTels) -- a novel representation for sets of randomized winning strategies in concurrent games with Safety, B\"uchi, and Co-B\"uchi objectives. ConSTels compactly encode infinite families of strategies, thereby supporting both offline and online adaptation. Offline, we exploit compositionality to enable incremental synthesis: combining ConSTels for simpler objectives into non-conflicting templates for more complex combined objectives. Online, we demonstrate how ConSTels facilitate runtime adaptation, adjusting action probabilities in response to observed opponent behavior to optimize performance while preserving correctness. We implemented ConSTel synthesis and adaptation in a prototype tool and experimentally show its potential.</description>
      <guid isPermaLink="false">oai:arXiv.org:2601.13500v1</guid>
      <category>cs.GT</category>
      <pubDate>Wed, 21 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Ashwani Anand, Christel Baier, Calvin Chau, Sascha Kl\"uppelholz, Ali Mirzaei, Satya Prakash Nayak, Anne-Kathrin Schmuck</dc:creator>
    </item>
    <item>
      <title>Stochastic Dynamic Pricing of Electric Vehicle Charging with Heterogeneous User Behavior: A Stackelberg Game Framework</title>
      <link>https://arxiv.org/abs/2601.13571</link>
      <description>arXiv:2601.13571v1 Announce Type: new 
Abstract: The rapid adoption of electric vehicles (EVs) introduces complex spatiotemporal demand management challenges for charging station operators (CSOs), exacerbated by demand imbalances, behavioral heterogeneity, and system uncertainty. Traditional dynamic pricing models, often relying on deterministic EV-CS pairings and network equilibrium assumptions, frequently oversimplify user behavior and lack scalability. This study proposes a stochastic, behaviorally heterogeneous dynamic pricing framework formulated as a bi-level Stackelberg game. The upper level optimizes time-varying pricing to maximize system-wide utility, while the lower level models decentralized EV users via a multinomial logit (MNL) choice model incorporating price sensitivity, battery aging, risk attitudes, and network travel costs. Crucially, the model avoids network equilibrium constraints to enhance scalability, with congestion effects represented via queuing-theoretic approximations. To efficiently solve the resulting large-scale optimization problem, a rolling-horizon approach combining the Dynamic Probabilistic Sensitivity Analysis-guided Cross-Entropy Method (PSA-CEM) with the Method of Successive Averages (MSA) is implemented. A real-world case study in Clayton, Melbourne, validates the framework using 22 charging stations. Simulation results demonstrate that the proposed mechanism substantially reduces queuing penalties and improves user utility compared to fixed and time-of-use pricing. The framework provides a robust, scalable tool for strategic EV charging management, balancing realism with computational efficiency.</description>
      <guid isPermaLink="false">oai:arXiv.org:2601.13571v1</guid>
      <category>cs.GT</category>
      <pubDate>Wed, 21 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Yongqi Zhang, Dong Ngoduy, Li Duan, Mingchang Zhu, Zhuo Chen</dc:creator>
    </item>
    <item>
      <title>Asymmetric regularization mechanism for GAN training with Variational Inequalities</title>
      <link>https://arxiv.org/abs/2601.13920</link>
      <description>arXiv:2601.13920v1 Announce Type: new 
Abstract: We formulate the training of generative adversarial networks (GANs) as a Nash equilibrium seeking problem. To stabilize the training process and find a Nash equilibrium, we propose an asymmetric regularization mechanism based on the classic Tikhonov step and on a novel zero-centered gradient penalty. Under smoothness and a local identifiability condition induced by a Gauss-Newton Gramian, we obtain explicit Lipschitz and (strong)-monotonicity constants for the regularized operator. These constants ensure last-iterate linear convergence of a single-call Extrapolation-from-the-Past (EFTP) method. Empirical simulations on an academic example show that, even when strong monotonicity cannot be achieved, the asymmetric regularization is enough to converge to an equilibrium and stabilize the trajectory.</description>
      <guid isPermaLink="false">oai:arXiv.org:2601.13920v1</guid>
      <category>cs.GT</category>
      <category>cs.AI</category>
      <category>cs.LG</category>
      <pubDate>Wed, 21 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Spyridon C. Giagtzoglou, Mark H. M. Winands, Barbara Franci</dc:creator>
    </item>
    <item>
      <title>BallotRank: A Condorcet Completion Method for Graphs</title>
      <link>https://arxiv.org/abs/2601.14015</link>
      <description>arXiv:2601.14015v1 Announce Type: new 
Abstract: We introduce BallotRank, a ranked preference aggregation method derived from a modified PageRank algorithm. It is a Condorcet-consistent method without damping, and empirical examination of nearly 2,000 ranked choice elections and over 20,000 internet polls confirms that BallotRank always identifies the Condorcet winner at conventional values of the damping parameter. We also prove that the method satisfies many of the same social choice criteria as other well-known Condorcet completion methods, but it has the advantage of being a natural social welfare function that provides a full ranking of the candidates.</description>
      <guid isPermaLink="false">oai:arXiv.org:2601.14015v1</guid>
      <category>cs.GT</category>
      <category>econ.GN</category>
      <category>q-fin.EC</category>
      <pubDate>Wed, 21 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Ismar Volic, Jason Douglas Todd</dc:creator>
    </item>
    <item>
      <title>Collective intelligence in science: direct elicitation of diverse information from experts with unknown information structure</title>
      <link>https://arxiv.org/abs/2601.14047</link>
      <description>arXiv:2601.14047v1 Announce Type: new 
Abstract: Suppose we need a deep collective analysis of an open scientific problem: there is a complex scientific hypothesis and a large online group of mutually unrelated experts with relevant private information of a diverse and unpredictable nature. This information may be results of experts' individual experiments, original reasoning of some of them, results of AI systems they use, etc. We propose a simple mechanism based on a self-resolving play-money prediction market entangled with a chat. We show that such a system can easily be brought to an equilibrium where participants directly share their private information on the hypothesis through the chat and trade as if the market were resolved in accordance with the truth of the hypothesis. This approach will lead to efficient aggregation of relevant information in a completely interpretable form even if the ground truth cannot be established and experts initially know nothing about each other and cannot perform complex Bayesian calculations. Finally, by rewarding the experts with some real assets proportionally to the play money they end up with, we can get an innovative way to fund large-scale collaborative studies of any type.</description>
      <guid isPermaLink="false">oai:arXiv.org:2601.14047v1</guid>
      <category>cs.GT</category>
      <category>cs.AI</category>
      <category>cs.MA</category>
      <category>cs.SI</category>
      <category>econ.TH</category>
      <pubDate>Wed, 21 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Alexey V. Osipov, Nikolay N. Osipov</dc:creator>
    </item>
    <item>
      <title>A Minimax Perspective on Almost-Stable Matchings</title>
      <link>https://arxiv.org/abs/2601.14195</link>
      <description>arXiv:2601.14195v1 Announce Type: new 
Abstract: Stability is crucial in matching markets, yet in many real-world settings - from hospital residency allocations to roommate assignments - full stability is either impossible to achieve or can come at the cost of leaving many agents unmatched. When stability cannot be achieved, algorithmicists and market designers face a critical question: how should instability be measured and distributed among participants? Existing approaches to "almost-stable" matchings focus on aggregate measures, minimising either the total number of blocking pairs or the count of agents involved in blocking pairs. However, such aggregate objectives can result in concentrated instability on a few individual agents, raising concerns about fairness and incentives to deviate. We introduce a fairness-oriented approach to approximate stability based on the minimax principle: we seek matchings that minimise the maximum number of blocking pairs any agent is in. Equivalently, we minimise the maximum number of agents that anyone has justified envy towards. This distributional objective protects the worst-off agents from a disproportionate amount of instability. We characterise the computational complexity of this notion across fundamental matching settings. Surprisingly, even very modest guarantees prove computationally intractable: we show that it is NP-complete to decide whether a matching exists in which no agent is in more than one blocking pair, even when preference lists have constant-bounded length. This hardness applies to both Stable Roommates and maximum-cardinality Stable Marriage. On the positive side, we provide polynomial-time algorithms when agents rank at most two others, and present approximation algorithms and integer programs. Our results map the algorithmic landscape and reveal fundamental trade-offs between distributional guarantees and computational feasibility.</description>
      <guid isPermaLink="false">oai:arXiv.org:2601.14195v1</guid>
      <category>cs.GT</category>
      <category>cs.DS</category>
      <pubDate>Wed, 21 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Frederik Glitzner, David Manlove</dc:creator>
    </item>
    <item>
      <title>Robust Verification of Concurrent Stochastic Games</title>
      <link>https://arxiv.org/abs/2601.12003</link>
      <description>arXiv:2601.12003v1 Announce Type: cross 
Abstract: Autonomous systems often operate in multi-agent settings and need to make concurrent, strategic decisions, typically in uncertain environments. Verification and control problems for these systems can be tackled with concurrent stochastic games (CSGs), but this model requires transition probabilities to be precisely specified - an unrealistic requirement in many real-world settings. We introduce *robust CSGs* and their subclass *interval CSGs* (ICSGs), which capture epistemic uncertainty about transition probabilities in CSGs. We propose a novel framework for *robust* verification of these models under worst-case assumptions about transition uncertainty. Specifically, we develop the underlying theoretical foundations and efficient algorithms, for finite- and infinite-horizon objectives in both zero-sum and nonzero-sum settings, the latter based on (social-welfare optimal) Nash equilibria. We build an implementation in the PRISM-games model checker and demonstrate the feasibility of robust verification of ICSGs across a selection of large benchmarks.</description>
      <guid isPermaLink="false">oai:arXiv.org:2601.12003v1</guid>
      <category>cs.LO</category>
      <category>cs.AI</category>
      <category>cs.GT</category>
      <category>cs.MA</category>
      <category>cs.SY</category>
      <category>eess.SY</category>
      <pubDate>Wed, 21 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Angel Y. He, David Parker</dc:creator>
    </item>
    <item>
      <title>Irreversible Failure Reverses the Value of Information</title>
      <link>https://arxiv.org/abs/2601.12046</link>
      <description>arXiv:2601.12046v1 Announce Type: cross 
Abstract: We study dynamic games with hidden states and absorbing failure, where belief-driven actions can trigger irreversible collapse. In such environments, equilibria that sustain activity generically operate at the boundary of viability. We show that this geometry endogenously reverses the value of information: greater informational precision increases the probability of collapse on every finite horizon. We formalize this mechanism through a limit-viability criterion, and model opacity as a strategic choice of the information structure via Blackwell garbling. When failure is absorbing, survival values become locally concave in beliefs, implying that transparency destroys equilibrium viability while sufficient opacity restores it. In an extended game where agents choose the information structure ex ante, strictly positive opacity is necessary for equilibrium survival. The results identify irreversible failure--not coordination, misspecification, or ambiguity--as a primitive force generating an endogenous demand for opacity in dynamic games.</description>
      <guid isPermaLink="false">oai:arXiv.org:2601.12046v1</guid>
      <category>econ.TH</category>
      <category>cs.GT</category>
      <pubDate>Wed, 21 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Nicholas H. Kirk</dc:creator>
    </item>
    <item>
      <title>Nemesis, an Escape Game in Graphs</title>
      <link>https://arxiv.org/abs/2601.13841</link>
      <description>arXiv:2601.13841v1 Announce Type: cross 
Abstract: We define a new escape game in graphs that we call Nemesis. The game is played on a graph having a subset of vertices labeled as exits and the goal of one of the two players, called the fugitive, is to reach one of these exit vertices. The second player, i.e. the fugitive adversary, is called the Nemesis. Her goal is to trap the fugitive in a connected component which does not contain any exit. At each round of the game, the fugitive moves from one vertex to an adjacent vertex. Then the Nemesis deletes one edge anywhere in the graph. The game ends when either the fugitive reached an exit or when he is in a connected component that does not contain any exit. In trees and graphs of maximum degree bounded by 3, Nemesis can be solved in linear time. We also show that a variant of the game called Blizzard where only edges adjacent to the position of the fugitive can be deleted also admits a linear time solution. For arbitrary graphs, we show that Nemesis is PSPACE-complete, and that it is NP-hard on planar multigraphs. We extend our results to the related Cat Herding problem, proving its PSPACE-completeness. We also prove that finding a strategy based on a full binary escape tree whose leaves are exists is NP-complete.</description>
      <guid isPermaLink="false">oai:arXiv.org:2601.13841v1</guid>
      <category>cs.DS</category>
      <category>cs.CC</category>
      <category>cs.GT</category>
      <pubDate>Wed, 21 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <dc:creator>Pierre Berg\'e, Antoine Dailly, Yan Gerard</dc:creator>
    </item>
    <item>
      <title>Institutional AI: Governing LLM Collusion in Multi-Agent Cournot Markets via Public Governance Graphs</title>
      <link>https://arxiv.org/abs/2601.11369</link>
      <description>arXiv:2601.11369v2 Announce Type: replace 
Abstract: Multi-agent LLM ensembles can converge on coordinated, socially harmful equilibria. This paper advances an experimental framework for evaluating Institutional AI, our system-level approach to AI alignment that reframes alignment from preference engineering in agent-space to mechanism design in institution-space. Central to this approach is the governance graph, a public, immutable manifest that declares legal states, transitions, sanctions, and restorative paths; an Oracle/Controller runtime interprets this manifest, attaching enforceable consequences to evidence of coordination while recording a cryptographically keyed, append-only governance log for audit and provenance. We apply the Institutional AI framework to govern the Cournot collusion case documented by prior work and compare three regimes: Ungoverned (baseline incentives from the structure of the Cournot market), Constitutional (a prompt-only policy-as-prompt prohibition implemented as a fixed written anti-collusion constitution, and Institutional (governance-graph-based). Across six model configurations including cross-provider pairs (N=90 runs/condition), the Institutional regime produces large reductions in collusion: mean tier falls from 3.1 to 1.8 (Cohen's d=1.28), and severe-collusion incidence drops from 50% to 5.6%. The prompt-only Constitutional baseline yields no reliable improvement, illustrating that declarative prohibitions do not bind under optimisation pressure. These results suggest that multi-agent alignment may benefit from being framed as an institutional design problem, where governance graphs can provide a tractable abstraction for alignment-relevant collective behavior.</description>
      <guid isPermaLink="false">oai:arXiv.org:2601.11369v2</guid>
      <category>cs.GT</category>
      <category>cs.AI</category>
      <pubDate>Wed, 21 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Marcantonio Bracale Syrnikov, Federico Pierucci, Marcello Galisai, Matteo Prandi, Piercosma Bisconti, Francesco Giarrusso, Olga Sorokoletova, Vincenzo Suriani, Daniele Nardi</dc:creator>
    </item>
    <item>
      <title>EconEvals: Benchmarks and Litmus Tests for Economic Decision-Making by LLM Agents</title>
      <link>https://arxiv.org/abs/2503.18825</link>
      <description>arXiv:2503.18825v3 Announce Type: replace-cross 
Abstract: We develop evaluation methods for measuring the economic decision-making capabilities and tendencies of LLMs. First, we develop benchmarks derived from key problems in economics -- procurement, scheduling, and pricing -- that test an LLM's ability to learn from the environment in context. Second, we develop the framework of litmus tests, evaluations that quantify an LLM's choice behavior on a stylized decision-making task with multiple conflicting objectives. Each litmus test outputs a litmus score, which quantifies an LLM's tradeoff response, a reliability score, which measures the coherence of an LLM's choice behavior, and a competency score, which measures an LLM's capability at the same task when the conflicting objectives are replaced by a single, well-specified objective. Evaluating a broad array of frontier LLMs, we (1) investigate changes in LLM capabilities and tendencies over time, (2) derive economically meaningful insights from the LLMs' choice behavior and chain-of-thought, (3) validate our litmus test framework by testing self-consistency, robustness, and generalizability. Overall, this work provides a foundation for evaluating LLM agents as they are further integrated into economic decision-making.</description>
      <guid isPermaLink="false">oai:arXiv.org:2503.18825v3</guid>
      <category>cs.AI</category>
      <category>cs.CL</category>
      <category>cs.GT</category>
      <pubDate>Wed, 21 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Sara Fish, Julia Shephard, Minkai Li, Ran I. Shorrer, Yannai A. Gonczarowski</dc:creator>
    </item>
    <item>
      <title>Geographical Centralization Resilience in Ethereum's Block-Building Paradigms</title>
      <link>https://arxiv.org/abs/2509.21475</link>
      <description>arXiv:2509.21475v2 Announce Type: replace-cross 
Abstract: Decentralization has an important geographic dimension that conventional metrics, such as stake distribution, often overlook. Where validators operate affects resilience to regional shocks (e.g., outages, natural disasters, or government intervention) as well as fairness in reward access. Yet in permissionless systems, validator locations cannot be prescribed by protocol rules; instead, they emerge endogenously from economic incentives. When certain locations offer systematic advantages, validators may strategically co-locate to maximize expected rewards, as observed in Ethereum, where validators cluster along the Atlantic corridor, which exhibits structurally favorable latency.
  In this paper, we design and implement an agent-based simulation framework to study how Ethereum's protocol design, particularly its block-building paradigms of local and external block building, interacts with validator and information-source distributions to shape geographical positioning incentives. Our simulations show that Ethereum's block-building architecture is not geographically neutral: both paradigms induce location-dependent payoffs and migration incentives, with asymmetric access to information sources amplifying geographical centralization. We further demonstrate that consensus parameters, such as attestation thresholds and slot times, modulate latency sensitivity and can amplify these effects, acting as protocol-level levers. Finally, we discuss the implications of our findings for protocol design and outline potential mitigation directions informed by our analysis.</description>
      <guid isPermaLink="false">oai:arXiv.org:2509.21475v2</guid>
      <category>cs.CR</category>
      <category>cs.CE</category>
      <category>cs.GT</category>
      <pubDate>Wed, 21 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Sen Yang, Burak \"Oz, Fei Wu, Fan Zhang</dc:creator>
    </item>
    <item>
      <title>Determining the Winner in Alternating-Move Games</title>
      <link>https://arxiv.org/abs/2601.08359</link>
      <description>arXiv:2601.08359v2 Announce Type: replace-cross 
Abstract: We provide a criterion for determining the winner in two-player win-lose alternating-move games on trees, in terms of the Hausdorff dimension of the target set. We focus our study on special cases, including the Gale-Stewart game on the complete binary tree and a family of Schmidt games. Building on the Hausdorff dimension games originally introduced by Das, Fishman, Simmons, and Urba\'nski, which provide a game-theoretic approach for computing Hausdorff dimensions, we employ a generalized family of these games, and show that they are useful for analyzing sets underlying the win-lose games we study.</description>
      <guid isPermaLink="false">oai:arXiv.org:2601.08359v2</guid>
      <category>math.DS</category>
      <category>cs.GT</category>
      <category>math.LO</category>
      <category>math.OC</category>
      <pubDate>Wed, 21 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Itamar Bella\"iche, Auriel Rosenzweig</dc:creator>
    </item>
  </channel>
</rss>
