<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>cs.DS updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/cs.DS</link>
    <description>cs.DS updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/cs.DS" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Tue, 04 Mar 2025 05:00:09 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Tue, 04 Mar 2025 00:00:00 -0500</pubDate>
    <skipDays>
      <day>Saturday</day>
      <day>Sunday</day>
    </skipDays>
    <item>
      <title>On the time complexity of finding a well-spread perfect matching in bridgeless cubic graphs</title>
      <link>https://arxiv.org/abs/2503.00263</link>
      <description>arXiv:2503.00263v1 Announce Type: new 
Abstract: We present an algorithm for finding a perfect matching in a $3$-edge-connected cubic graph that intersects every $3$-edge cut in exactly one edge. Specifically, we propose an algorithm with a time complexity of $O(n \log^4 n)$, which significantly improves upon the previously known $O(n^3)$-time algorithms for the same problem. The technique we use for the improvement is efficient use of cactus model of 3-edge cuts. As an application, we use our algorithm to compute embeddings of $3$-edge-connected cubic graphs with limited number of singular edges (i.e., edges that are twice in the boundary of one face) in $O(n \log^4 n)$ time; this application contributes to the study of the well-known Cycle Double Cover conjecture.</description>
      <guid isPermaLink="false">oai:arXiv.org:2503.00263v1</guid>
      <category>cs.DS</category>
      <category>cs.DM</category>
      <category>math.CO</category>
      <pubDate>Tue, 04 Mar 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Babak Ghanbari, Robert \v{S}\'amal</dc:creator>
    </item>
    <item>
      <title>An FPT Constant-Factor Approximation Algorithm for Correlation Clustering</title>
      <link>https://arxiv.org/abs/2503.00281</link>
      <description>arXiv:2503.00281v1 Announce Type: new 
Abstract: The Correlation Clustering problem is one of the most extensively studied clustering formulations due to its wide applications in machine learning, data mining, computational biology and other areas. We consider the Correlation Clustering problem on general graphs, where given an undirected graph (maybe not complete) with each edge being labeled with $\langle + \rangle$ or $\langle - \rangle$, the goal is to partition the vertices into clusters to minimize the number of the disagreements with the edge labeling: the number of $\langle - \rangle$ edges within clusters plus the number of $\langle + \rangle$ edges between clusters. Hereby, a $\langle + \rangle$ (or $\langle - \rangle$) edge means that its end-vertices are similar (or dissimilar) and should belong to the same cluster (or different clusters), and ``missing'' edges are used to denote that we do not know if those end-vertices are similar or dissimilar.
  Correlation Clustering is NP-hard, even if the input graph is complete, and Unique-Games hard to obtain polynomial-time constant approximation on general graphs. With a complete graph as input, Correlation Clustering admits a $(1.994+\varepsilon )$-approximation. We investigate Correlation Clustering on general graphs from the perspective of parameterized approximability. We set the parameter $k$ as the minimum number of vertices whose removal results in a complete graph, and obtain the first FPT constant-factor approximation for Correlation Clustering on general graphs which runs in $2^{O(k^3)} \cdot \textrm{poly}(n)$ time.</description>
      <guid isPermaLink="false">oai:arXiv.org:2503.00281v1</guid>
      <category>cs.DS</category>
      <pubDate>Tue, 04 Mar 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Jianqi Zhou, Zhongyi Zhang, Jiong Guo</dc:creator>
    </item>
    <item>
      <title>Streaming Algorithms for Network Design</title>
      <link>https://arxiv.org/abs/2503.00712</link>
      <description>arXiv:2503.00712v1 Announce Type: new 
Abstract: We consider the Survivable Network Design problem (SNDP) in the single-pass insertion-only streaming model. The input to SNDP is an edge-weighted graph $G = (V, E)$ and an integer connectivity requirement $r(uv)$ for each $u, v \in V$. The objective is to find a min-weight subgraph $H \subseteq G$ s.t., for every $u, v \in V$, $u$ and $v$ are $r(uv)$-edge/vertex-connected. Recent work by [JKMV24] obtained approximation algorithms for edge-connectivity augmentation, and via that, also derived algorithms for edge-connectivity SNDP (EC-SNDP). We consider vertex-connectivity setting (VC-SNDP) and obtain several results for it as well as improved bounds for EC-SNDP.
  * We provide a general framework for solving connectivity problems in streaming; this is based on a connection to fault-tolerant spanners. For VC-SNDP we provide an $O(tk)$-approximation in $\tilde O(k^{1-1/t}n^{1 + 1/t})$ space, where $k$ is the maximum connectivity requirement, assuming an exact algorithm at the end of the stream. Using a refined LP-based analysis, we provide an $O(\beta t)$-approximation in polynomial time, where $\beta$ is the best polytime approximation w.r.t. the optimal fractional solution to a natural LP relaxation. When applied to EC-SNDP, our framework provides an $O(t)$-approximation in $\tilde O(k^{1-1/t}n^{1 + 1/t})$ space, improving the $O(t \log k)$-approximation of [JKMV24]; this also extends to element-connectivity SNDP.
  * We consider vertex connectivity-augmentation in the link-arrival model. The input is a $k$-vertex-connected subgraph $G$, and the weighted links $L$ arrive in the stream; the goal is to store the min-weight set of links s.t. $G \cup L$ is $(k+1)$-vertex-connected. We obtain $O(1)$ approximations in near-linear space for $k = 1, 2$. Our result for $k=2$ is based on SPQR tree, a novel application for this well-known representation of $2$-connected graphs.</description>
      <guid isPermaLink="false">oai:arXiv.org:2503.00712v1</guid>
      <category>cs.DS</category>
      <pubDate>Tue, 04 Mar 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Chandra chekuri, Rhea Jain, Sepideh Mahabadi, Ali Vakilian</dc:creator>
    </item>
    <item>
      <title>A framework for boosting matching approximation: parallel, distributed, and dynamic</title>
      <link>https://arxiv.org/abs/2503.01147</link>
      <description>arXiv:2503.01147v1 Announce Type: new 
Abstract: This work designs a framework for boosting the approximation guarantee of maximum matching algorithms. As input, the framework receives a parameter $\epsilon &gt; 0$ and an oracle access to a $\Theta(1)$-approximate maximum matching algorithm $\mathcal{A}$. Then, by invoking $\mathcal{A}$ for $\text{poly}(1/\epsilon)$ many times, the framework outputs a $1+\epsilon$ approximation of a maximum matching. Our approach yields several improvements in terms of the number of invocations to $\mathcal{A}$:
  (1) In MPC and CONGEST, our framework invokes $\mathcal{A}$ for $O(1/\epsilon^7 \cdot \log(1/\epsilon))$ times, substantially improving on $O(1/\epsilon^{39})$ invocations following from [Fischer et al., STOC'22] and [Mitrovic et al., arXiv:2412.19057].
  (2) In both online and offline fully dynamic settings, our framework yields an improvement in the dependence on $1/\epsilon$ from exponential [Assadi et al., SODA25 and Liu, FOCS24] to polynomial.</description>
      <guid isPermaLink="false">oai:arXiv.org:2503.01147v1</guid>
      <category>cs.DS</category>
      <pubDate>Tue, 04 Mar 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Slobodan Mitrovi\'c, Wen-Horng Sheu</dc:creator>
    </item>
    <item>
      <title>Faster ED-String Matching with $k$ Mismatches</title>
      <link>https://arxiv.org/abs/2503.01388</link>
      <description>arXiv:2503.01388v1 Announce Type: new 
Abstract: We revisit the complexity of approximate pattern matching in an elastic-degenerate string. Such a string is a sequence of $n$ finite sets of strings of total length $N$, and compactly describes a collection of strings obtained by first choosing exactly one string in every set, and then concatenating them together. This is motivated by the need of storing a collection of highly similar DNA sequences.
  The basic algorithmic question on elastic-degenerate strings is pattern matching: given such an elastic-degenerate string and a standard pattern of length $m$, check if the pattern occurs in one of the strings in the described collection. Bernardini et al.~[SICOMP 2022] showed how to leverage fast matrix multiplication to obtain an $\tilde{\mathcal{O}}(nm^{\omega-1})+\mathcal{O}(N)$-time complexity for this problem, where $w$ is the matrix multiplication exponent. However, the best result so far for finding occurrences with $k$ mismatches, where $k$ is a constant, is the $\tilde{\mathcal{O}}(nm^{2}+N)$-time algorithm of Pissis et al.~[CPM 2025]. This brings the question whether increasing the dependency on $m$ from $m^{\omega-1}$ to quadratic is necessary when moving from $k=0$ to larger (but still constant) $k$.
  We design an $\tilde{\mathcal{O}}(nm^{1.5}+N)$-time algorithm for pattern matching with $k$ mismatches in an elastic-degenerate string, for any constant $k$. To obtain this time bound, we leverage the structural characterization of occurrences with $k$ mismatches of Charalampopoulos et al.~[FOCS 2020] together with fast Fourier transform. We need to work with multiple patterns at the same time, instead of a single pattern, which requires refining the original characterization. This might be of independent interest.</description>
      <guid isPermaLink="false">oai:arXiv.org:2503.01388v1</guid>
      <category>cs.DS</category>
      <pubDate>Tue, 04 Mar 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Pawe{\l} Gawrychowski, Adam G\'orkiewicz, Pola Marciniak, Solon P. Pissis, Karol Pokorski</dc:creator>
    </item>
    <item>
      <title>Binary $k$-Center with Missing Entries: Structure Leads to Tractability</title>
      <link>https://arxiv.org/abs/2503.01445</link>
      <description>arXiv:2503.01445v1 Announce Type: new 
Abstract: $\kC$ clustering is a fundamental classification problem, where the task is to categorize the given collection of entities into $k$ clusters and come up with a representative for each cluster, so that the maximum distance between an entity and its representative is minimized. In this work, we focus on the setting where the entities are represented by binary vectors with missing entries, which model incomplete categorical data. This version of the problem has wide applications, from predictive analytics to bioinformatics.
  Our main finding is that the problem, which is notoriously hard from the classical complexity viewpoint, becomes tractable as soon as the known entries are sparse and exhibit a certain structure. Formally, we show fixed-parameter tractable algorithms for the parameters vertex cover, fracture number, and treewidth of the row-column graph, which encodes the positions of the known entries of the matrix. Additionally, we tie the complexity of the 1-cluster variant of the problem, which is famous under the name Closest String, to the complexity of solving integer linear programs with few constraints. This implies, in particular, that improving upon the running times of our algorithms would lead to more efficient algorithms for integer linear programming in general.</description>
      <guid isPermaLink="false">oai:arXiv.org:2503.01445v1</guid>
      <category>cs.DS</category>
      <pubDate>Tue, 04 Mar 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Farehe Soheil, Kirill Simonov, Tobias Friedrich</dc:creator>
    </item>
    <item>
      <title>Scanning HTML at Tens of Gigabytes per Second on ARM Processors</title>
      <link>https://arxiv.org/abs/2503.01662</link>
      <description>arXiv:2503.01662v1 Announce Type: new 
Abstract: Modern processors have instructions to process 16 bytes or more at once. These instructions are called SIMD, for single instruction, multiple data. Recent advances have leveraged SIMD instructions to accelerate parsing of common Internet formats such as JSON and base64. During HTML parsing, they quickly identify specific characters with a strategy called vectorized classification. We review their techniques and compare them with a faster alternative. We measure a 20-fold performance improvement in HTML scanning compared to traditional methods on recent ARM processors. Our findings highlight the potential of SIMD-based algorithms for optimizing Web browser performance.</description>
      <guid isPermaLink="false">oai:arXiv.org:2503.01662v1</guid>
      <category>cs.DS</category>
      <category>cs.AR</category>
      <pubDate>Tue, 04 Mar 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Daniel Lemire</dc:creator>
    </item>
    <item>
      <title>Optimal Differentially Private Sampling of Unbounded Gaussians</title>
      <link>https://arxiv.org/abs/2503.01766</link>
      <description>arXiv:2503.01766v1 Announce Type: new 
Abstract: We provide the first $\widetilde{\mathcal{O}}\left(d\right)$-sample algorithm for sampling from unbounded Gaussian distributions under the constraint of $\left(\varepsilon, \delta\right)$-differential privacy. This is a quadratic improvement over previous results for the same problem, settling an open question of Ghazi, Hu, Kumar, and Manurangsi.</description>
      <guid isPermaLink="false">oai:arXiv.org:2503.01766v1</guid>
      <category>cs.DS</category>
      <category>cs.CR</category>
      <category>cs.IT</category>
      <category>cs.LG</category>
      <category>math.IT</category>
      <category>stat.ML</category>
      <pubDate>Tue, 04 Mar 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Valentio Iverson, Gautam Kamath, Argyris Mouzakis</dc:creator>
    </item>
    <item>
      <title>Interval H-graphs : Recognition and forbidden obstructions</title>
      <link>https://arxiv.org/abs/2503.00672</link>
      <description>arXiv:2503.00672v1 Announce Type: cross 
Abstract: We introduce the class of interval $H$-graphs, which is the generalization of interval graphs, particularly interval bigraphs. For a fixed graph $H$ with vertices $a_1,a_2,\dots,a_k$, we say that an input graph $G$ with given partition $V_1,\dots,V_k$ of its vertices is an interval $H$-graph if each vertex $v \in G$ can be represented by an interval $I_v$ from a real line so that $u \in V_i$ and $v \in V_j$ are adjacent if and only if $a_ia_j$ is an edge of $H$ and intervals $I_u$ and $I_v$ intersect. $G$ is called interval $k$-graph if $H$ is a complete graph on $k$ vertices. and interval bigraph when $k=2$. We study the ordering characterization and forbidden obstructions of interval $k$-graphs and present a polynomial-time recognition algorithm for them. Additionally, we discuss how this algorithm can be extended to recognize general interval $H$-graphs. Special cases of interval $k$-graphs, particularly comparability interval $k$-graphs, were previously studied in [2], where the complexity interval $k$-graph recognition was posed as an open problem.</description>
      <guid isPermaLink="false">oai:arXiv.org:2503.00672v1</guid>
      <category>cs.DM</category>
      <category>cs.DS</category>
      <category>math.CO</category>
      <pubDate>Tue, 04 Mar 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Haiko M\"uller, Arash Rafiey</dc:creator>
    </item>
    <item>
      <title>Learning-Augmented Frequent Directions</title>
      <link>https://arxiv.org/abs/2503.00937</link>
      <description>arXiv:2503.00937v1 Announce Type: cross 
Abstract: An influential paper of Hsu et al. (ICLR'19) introduced the study of learning-augmented streaming algorithms in the context of frequency estimation. A fundamental problem in the streaming literature, the goal of frequency estimation is to approximate the number of occurrences of items appearing in a long stream of data using only a small amount of memory. Hsu et al. develop a natural framework to combine the worst-case guarantees of popular solutions such as CountMin and CountSketch with learned predictions of high frequency elements. They demonstrate that learning the underlying structure of data can be used to yield better streaming algorithms, both in theory and practice.
  We simplify and generalize past work on learning-augmented frequency estimation. Our first contribution is a learning-augmented variant of the Misra-Gries algorithm which improves upon the error of learned CountMin and learned CountSketch and achieves the state-of-the-art performance of randomized algorithms (Aamand et al., NeurIPS'23) with a simpler, deterministic algorithm. Our second contribution is to adapt learning-augmentation to a high-dimensional generalization of frequency estimation corresponding to finding important directions (top singular vectors) of a matrix given its rows one-by-one in a stream. We analyze a learning-augmented variant of the Frequent Directions algorithm, extending the theoretical and empirical understanding of learned predictions to matrix streaming.</description>
      <guid isPermaLink="false">oai:arXiv.org:2503.00937v1</guid>
      <category>cs.LG</category>
      <category>cs.DS</category>
      <pubDate>Tue, 04 Mar 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Anders Aamand, Justin Y. Chen, Siddharth Gollapudi, Sandeep Silwal, Hao Wu</dc:creator>
    </item>
    <item>
      <title>Optimal Trickle-Down Theorems for Path Complexes via $\mathcal{C}$-Lorentzian Polynomials with Applications to Sampling and Log-Concave Sequences</title>
      <link>https://arxiv.org/abs/2503.01005</link>
      <description>arXiv:2503.01005v1 Announce Type: cross 
Abstract: Let $X$ be a $d$-partite $d$-dimensional simplicial complex with parts $T_1,\dots,T_d$ and let $\mu$ be a distribution on the facets of $X$. We say $(X,\mu)$ is a path complex if for any $i&lt;j&lt;k$ and $F \in T_i,G \in T_j, K\in T_k$, we have $\mathbb{P}_\mu[F,K | G]=\mathbb{P}_\mu[F|G]\cdot\mathbb{P}_\mu[K|G].$ We develop a new machinery with $\mathcal{C}$-Lorentzian polynomials to show that if all links of $X$ of co-dimension 2 have spectral expansion at most $1/2$, then $X$ is a $\alpha$-local spectral expander for some $\alpha\leq \pi/2-1$. We then prove that one can derive fast-mixing results and log-concavity statements for top link spectral expanders.
  We use our machinery to prove fast mixing results for sampling maximal flags of flats of distributive lattices (a.k.a. linear extensions of posets) subject to external fields, and to sample maximal flags of flats of "typical" modular lattices. We also use it to re-prove the Heron-Rota-Welsh conjecture and to prove a conjecture of Chan and Pak which gives a generalization of Stanley's log-concavity theorem. Lastly, we use it to prove near optimal trickle-down theorems for Ramanujan path complexes such as constructions by Lubotzky-Samuels-Vishen, Kaufman-Oppenheim, and O'Donnell-Pratt.</description>
      <guid isPermaLink="false">oai:arXiv.org:2503.01005v1</guid>
      <category>math.CO</category>
      <category>cs.CC</category>
      <category>cs.DS</category>
      <pubDate>Tue, 04 Mar 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Jonathan Leake, Kasper Lindberg, Shayan Oveis Gharan</dc:creator>
    </item>
    <item>
      <title>The Complexity of Extending Fair Allocations of Indivisible Goods</title>
      <link>https://arxiv.org/abs/2503.01368</link>
      <description>arXiv:2503.01368v1 Announce Type: cross 
Abstract: We initiate the study of computing envy-free allocations of indivisible items in the extension setting, i.e., when some part of the allocation is fixed and the task is to allocate the remaining items. Given the known NP-hardness of the problem, we investigate whether -- and under which conditions -- one can obtain fixed-parameter algorithms for computing a solution in settings where most of the allocation is already fixed. Our results provide a broad complexity-theoretic classification of the problem which includes: (a) fixed-parameter algorithms tailored to settings with few distinct types of agents or items; (b) lower bounds which exclude the generalization of these positive results to more general settings. We conclude by showing that -- unlike when computing allocations from scratch -- the non-algorithmic question of whether more relaxed EFX allocations exist can be completely resolved in the extension setting.</description>
      <guid isPermaLink="false">oai:arXiv.org:2503.01368v1</guid>
      <category>cs.GT</category>
      <category>cs.DS</category>
      <pubDate>Tue, 04 Mar 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Argyrios Deligkas, Eduard Eiben, Robert Ganian, Tiger-Lily Goldsmith, Stavros D. Ioannidis</dc:creator>
    </item>
    <item>
      <title>Provably optimal decision trees with arbitrary splitting rules in polynomial time</title>
      <link>https://arxiv.org/abs/2503.01455</link>
      <description>arXiv:2503.01455v1 Announce Type: cross 
Abstract: In this paper, we introduce a generic data structure called decision trees, which integrates several well-known data structures, including binary search trees, K-D trees, binary space partition trees, and decision tree models from machine learning. We provide the first axiomatic definition of decision trees. These axioms establish a firm mathematical foundation for studying decision tree problems. We refer to decision trees that satisfy the axioms as proper decision trees. We prove that only proper decision trees can be uniquely characterized as K-permutations. Since permutations are among the most well-studied combinatorial structures, this characterization provides a fundamental basis for analyzing the combinatorial and algorithmic properties of decision trees. As a result of this advancement, we develop the first provably correct polynomial-time algorithm for solving the optimal decision tree problem. Our algorithm is derived using a formal program derivation framework, which enables step-by-step equational reasoning to construct side-effect-free programs with guaranteed correctness. The derived algorithm is correct by construction and is applicable to decision tree problems defined by any splitting rules that adhere to the axioms and any objective functions that can be specified in a given form. Examples include the decision tree problems where splitting rules are defined by axis-parallel hyperplanes, arbitrary hyperplanes, and hypersurfaces. By extending the axioms, we can potentially address a broader range of problems. Moreover, the derived algorithm can easily accommodate various constraints, such as tree depth and leaf size, and is amenable to acceleration techniques such as thinning method.</description>
      <guid isPermaLink="false">oai:arXiv.org:2503.01455v1</guid>
      <category>cs.LG</category>
      <category>cs.DS</category>
      <pubDate>Tue, 04 Mar 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-sa/4.0/</dc:rights>
      <dc:creator>Xi He, Max A. Little</dc:creator>
    </item>
    <item>
      <title>Noisy-enhanced quantum search on complex networks</title>
      <link>https://arxiv.org/abs/2503.01762</link>
      <description>arXiv:2503.01762v1 Announce Type: cross 
Abstract: The task of finding an element in an unstructured database is known as spatial search and can be expressed as a quantum walk evolution on a graph. In this Letter, we modify the usual search problem by adding an extra trapping vertex to the graph, which is only connected to the target element. The walker evolution is a mix between classical and quantum walk search dynamics. The balance between unitary and non-unitary dynamics is tuned with a parameter, and we numerically show that depending on the graph topology and the connectivity of the target element, this hybrid approach can outperform a purely classical or quantum evolution for reaching the trapping site. We show that this behavior is only observed in the presence of an extra trapping site, and that depending on the topology, the increase of non-unitary operations can be compensated by increasing the strength of the quantum walk exploration. This compensation comes at the cost of reducing the searching feature of the evolution induced by the Hamiltonian. We also relate the optimal hybrid regime to the entropy's decay rate. As the introduction of non-unitary operations may be considered as noise, we interpret this phenomena as a noisy-assisted quantum evolution.</description>
      <guid isPermaLink="false">oai:arXiv.org:2503.01762v1</guid>
      <category>quant-ph</category>
      <category>cs.DS</category>
      <pubDate>Tue, 04 Mar 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Ugo Nzongani, Andrea Simonetto, Giuseppe Di Molfetta</dc:creator>
    </item>
    <item>
      <title>All-Pairs Suffix-Prefix on Fully Dynamic Set of Strings</title>
      <link>https://arxiv.org/abs/2407.17814</link>
      <description>arXiv:2407.17814v2 Announce Type: replace 
Abstract: The all-pairs suffix-prefix (APSP) problem is a classical problem in string processing which has important applications in bioinformatics. Given a set $\mathcal{S} = \{S_1, \ldots, S_k\}$ of $k$ strings, the APSP problem asks one to compute the longest suffix of $S_i$ that is a prefix of $S_j$ for all $k^2$ ordered pairs $\langle S_i, S_j \rangle$ of strings in $\mathcal{S}$. In this paper, we consider the dynamic version of the APSP problem that allows for insertions of new strings to the set of strings. Our objective is, each time a new string $S_i$ arrives to the current set $\mathcal{S}_{i-1} = \{S_1, \ldots, S_{i-1}\}$ of $i-1$ strings, to compute (1) the longest suffix of $S_i$ that is a prefix of $S_j$ and (2) the longest prefix of $S_i$ that is a suffix of $S_j$ for all $1 \leq j \leq i$. We propose an $O(n)$-space data structure which computes (1) and (2) in $O(|S_i| \log \sigma + i)$ time for each new given string $S_i$, where $n$ is the total length of the strings. Further, we show how to extend our methods to the fully dynamic version of the APSP problem allowing for both insertions and deletions of strings.</description>
      <guid isPermaLink="false">oai:arXiv.org:2407.17814v2</guid>
      <category>cs.DS</category>
      <pubDate>Tue, 04 Mar 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Masaru Kikuchi, Shunsuke Inenaga</dc:creator>
    </item>
    <item>
      <title>Packing-Inspired Algorithms for Periodic Scheduling Problems with Harmonic Periods</title>
      <link>https://arxiv.org/abs/2410.14756</link>
      <description>arXiv:2410.14756v2 Announce Type: replace 
Abstract: We tackle the problem of non-preemptive periodic scheduling with a harmonic set of periods. Problems of this kind arise within domains of periodic manufacturing and maintenance, and also during the design of industrial, automotive, and avionics communication protocols, where efficient scheduling of messages is crucial for the performance of a time-triggered network. We consider the decision variant of the periodic scheduling problem on a single highly-utilized machine. We first prove a bijection between periodic scheduling and a particular (so-called height-divisible) 2D packing of rectangles. We formulate the problem using Constraint Programming and compare it with equivalent state-of-the-art Integer Linear Programming formulation, showing the former's superiority on difficult instances. Furthermore, we develop a packing-inspired first fit heuristic, which we compare with methods described in the literature. We justify our proposed methods on synthetically generated problem instances inspired by the communication of messages on one channel.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.14756v2</guid>
      <category>cs.DS</category>
      <pubDate>Tue, 04 Mar 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <arxiv:DOI>10.5220/0012325800003639</arxiv:DOI>
      <arxiv:journal_reference>Proceedings of the 13th ICORES 2024; ISBN 978-989-758-681-1; ISSN 2184-4372</arxiv:journal_reference>
      <dc:creator>Josef Grus, Claire Hanen, Zden\v{e}k Hanz\'alek</dc:creator>
    </item>
    <item>
      <title>New simple and fastest quicksort algorithm for equal keys</title>
      <link>https://arxiv.org/abs/2502.06461</link>
      <description>arXiv:2502.06461v2 Announce Type: replace 
Abstract: This paper introduces a novel and efficient partitioning technique for quicksort, specifically designed for real-world data with duplicate elements (50-year-old problem). The method is referred to as "equal quicksort" or "eqsort". Based on the experimental findings, it has been determined that the newly developed algorithm, eqsort, is competitive with the best current implementations,such as fat partitioning algorithms and dual-pivot quicksort. This method offers several advantages over the commonly used dual-pivot method and pdqsort partitioning, making it a potential replacement.</description>
      <guid isPermaLink="false">oai:arXiv.org:2502.06461v2</guid>
      <category>cs.DS</category>
      <pubDate>Tue, 04 Mar 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Parviz Afereidoon</dc:creator>
    </item>
    <item>
      <title>Output-sensitive Complexity of Multi-Objective Integer Network Flow Problems</title>
      <link>https://arxiv.org/abs/2312.01786</link>
      <description>arXiv:2312.01786v2 Announce Type: replace-cross 
Abstract: This paper addresses the output-sensitive complexity for linear multi-objective integer minimum cost flow (MOIMCF) problems and provides insights about the time complexity for enumerating all supported nondominated vectors. The paper shows that there can not exist an output-polynomial time algorithm for the enumeration of all supported nondominated vectors that determine the vectors in an ordered way in the outcome space unless NP = P. Moreover, novel methods for identifying supported nondominated vectors in bi-objective minimum cost flow (BOIMCF) problems are proposed, accompanied by a numerical comparison between decision- and objective-space methods. A novel, equivalent and more compact formulation of the minimum cost flow ILP formulation used in the e-constrained-scalarization approach is introduced, demonstrating enhanced efficiency in the numerical tests</description>
      <guid isPermaLink="false">oai:arXiv.org:2312.01786v2</guid>
      <category>cs.CC</category>
      <category>cs.DM</category>
      <category>cs.DS</category>
      <category>math.CO</category>
      <pubDate>Tue, 04 Mar 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>David K\"onen, Michael Stiglmayr</dc:creator>
    </item>
    <item>
      <title>Improving LSH via Tensorized Random Projection</title>
      <link>https://arxiv.org/abs/2402.07189</link>
      <description>arXiv:2402.07189v2 Announce Type: replace-cross 
Abstract: Locality sensitive hashing (LSH) is a fundamental algorithmic toolkit used by data scientists for approximate nearest neighbour search problems that have been used extensively in many large scale data processing applications such as near duplicate detection, nearest neighbour search, clustering, etc. In this work, we aim to propose faster and space efficient locality sensitive hash functions for Euclidean distance and cosine similarity for tensor data. Typically, the naive approach for obtaining LSH for tensor data involves first reshaping the tensor into vectors, followed by applying existing LSH methods for vector data $E2LSH$ and $SRP$. However, this approach becomes impractical for higher order tensors because the size of the reshaped vector becomes exponential in the order of the tensor. Consequently, the size of LSH parameters increases exponentially. To address this problem, we suggest two methods for LSH for Euclidean distance and cosine similarity, namely $CP-E2LSH$, $TT-E2LSH$, and $CP-SRP$, $TT-SRP$, respectively, building on $CP$ and tensor train $(TT)$ decompositions techniques. Our approaches are space efficient and can be efficiently applied to low rank $CP$ or $TT$ tensors. We provide a rigorous theoretical analysis of our proposal on their correctness and efficacy.</description>
      <guid isPermaLink="false">oai:arXiv.org:2402.07189v2</guid>
      <category>stat.ML</category>
      <category>cs.DS</category>
      <category>cs.LG</category>
      <pubDate>Tue, 04 Mar 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Bhisham Dev Verma, Rameshwar Pratap</dc:creator>
    </item>
    <item>
      <title>Utilizing ChatGPT in a Data Structures and Algorithms Course: A Teaching Assistant's Perspective</title>
      <link>https://arxiv.org/abs/2410.08899</link>
      <description>arXiv:2410.08899v2 Announce Type: replace-cross 
Abstract: Integrating large language models (LLMs) like ChatGPT into computer science education offers transformative potential for complex courses such as data structures and algorithms (DSA). This study examines ChatGPT as a supplementary tool for teaching assistants (TAs), guided by structured prompts and human oversight, to enhance instruction and student outcomes. A controlled experiment compared traditional TA-led instruction with a hybrid approach where TAs used ChatGPT-4o and ChatGPT o1 to generate exercises, clarify concepts, and provide feedback. Structured prompts emphasized problem decomposition, real-world context, and code examples, enabling tailored support while mitigating over-reliance on AI. Results demonstrated the hybrid approach's efficacy, with students in the ChatGPT-assisted group scoring 16.50 points higher on average and excelling in advanced topics. However, ChatGPT's limitations necessitated TA verification. This framework highlights the dual role of LLMs: augmenting TA efficiency while ensuring accuracy through human oversight, offering a scalable solution for human-AI collaboration in education.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.08899v2</guid>
      <category>cs.HC</category>
      <category>cs.AI</category>
      <category>cs.DS</category>
      <pubDate>Tue, 04 Mar 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <arxiv:DOI>10.1145/3706599.3720291</arxiv:DOI>
      <dc:creator>Pooriya Jamie, Reyhaneh Hajihashemi, Sharareh Alipour</dc:creator>
    </item>
    <item>
      <title>Efficiency in the Roommates Problem</title>
      <link>https://arxiv.org/abs/2502.16960</link>
      <description>arXiv:2502.16960v2 Announce Type: replace-cross 
Abstract: We propose an $O(n^2)$-time algorithm to determine whether a given matching is efficient in the roommates problem.</description>
      <guid isPermaLink="false">oai:arXiv.org:2502.16960v2</guid>
      <category>cs.GT</category>
      <category>cs.DS</category>
      <category>econ.TH</category>
      <pubDate>Tue, 04 Mar 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Keita Kuwahara</dc:creator>
    </item>
  </channel>
</rss>
