<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>eess.SP updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/eess.SP</link>
    <description>eess.SP updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/eess.SP" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Fri, 30 Jan 2026 05:00:14 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Fri, 30 Jan 2026 00:00:00 -0500</pubDate>
    <skipDays>
      <day>Saturday</day>
      <day>Sunday</day>
    </skipDays>
    <item>
      <title>Sparse Grassmannian Design for Noncoherent Codes via Schubert Cell Decomposition</title>
      <link>https://arxiv.org/abs/2601.21009</link>
      <description>arXiv:2601.21009v1 Announce Type: new 
Abstract: In this paper, we propose a method for designing sparse Grassmannian codes for noncoherent multiple-input multiple-output systems. Conventional pairwise error probability formulations under uncorrelated Rayleigh fading channels fail to account for rank deficiency induced by sparse configurations. We revise these formulations to handle such cases in a unified manner. Furthermore, we derive a closed-form metric that effectively maximizes the noncoherent average mutual information (AMI) at a given signal-to-noise ratio. We focus on the fact that the Schubert cell decomposition of the Grassmann manifold provides a mathematically sparse property, and establish design criteria for sparse noncoherent codes based on our analyses. In numerical results, the proposed sparse noncoherent codes outperform conventional methods in terms of both symbol error rate and AMI, and asymptotically approach the performance of the optimal Grassmannian constellations in the high-signal-to-noise ratio regime. Moreover, they reduce the time and space complexity, which does not scale with the number of transmit antennas.</description>
      <guid isPermaLink="false">oai:arXiv.org:2601.21009v1</guid>
      <category>eess.SP</category>
      <category>cs.IT</category>
      <category>math.IT</category>
      <pubDate>Fri, 30 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Joe Asano, Yuto Hama, Hiroki Iimori, Chandan Pradhan, Szabolcs Malomsoky, Naoki Ishikawa</dc:creator>
    </item>
    <item>
      <title>Impact of Pointing Error on Coverage Performance of 3D Indoor Terahertz Communication Systems</title>
      <link>https://arxiv.org/abs/2601.21303</link>
      <description>arXiv:2601.21303v1 Announce Type: new 
Abstract: In this paper, we develop a tractable analytical framework for a three-dimensional (3D) indoor terahertz (THz) communication system to theoretically assess the impact of the pointing error on its coverage performance. Specifically, we model the locations of access points (APs) using a Poisson point process, human blockages as random cylinder processes, and wall blockages through a Boolean straight line process. A pointing error refers to beamforming gain and direction mismatch between the transmitter and receiver. We characterize it based on the inaccuracy of location estimate. We then analyze the impact of this pointing error on the received signal power and derive a tractable expression for the coverage probability, incorporating the multi-cluster fluctuating two-ray distribution to accurately model small-scale fading in THz communications. Aided by simulation results, we corroborate our analysis and demonstrate that the pointing error has a pronounced impact on the coverage probability. Specifically, we find that merely increasing the antenna array size is insufficient to improve the coverage probability and mitigate the detrimental impact of the pointing error, highlighting the necessity of advanced estimation techniques in THz communication systems.</description>
      <guid isPermaLink="false">oai:arXiv.org:2601.21303v1</guid>
      <category>eess.SP</category>
      <pubDate>Fri, 30 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Zhifeng Tang, Nan Yang, Xiangyun Zhou, Salman Durrani, Markku Juntti, Josep Miquel Jornet</dc:creator>
    </item>
    <item>
      <title>A Time-Domain Dual-Edge Asynchronous Pipelined SAR ADC Featuring Reset-Free Quantization at Multi-GS/s</title>
      <link>https://arxiv.org/abs/2601.21308</link>
      <description>arXiv:2601.21308v1 Announce Type: new 
Abstract: Time-domain ADCs are attractive for high-speed wireline receivers, as time resolution scales favorably with advanced CMOS technologies, enabling multi-GS/s single-channel sampling rates. However, conventional time-domain ADCs require explicit reset of voltage-to-time and time-domain signal paths between samples, introducing dead time that fundamentally limits resolution, speed, and energy efficiency. This paper introduces a dual-edge reset-free quantization concept for asynchronous pipelined SAR time-domain ADCs, in which both rising and falling signal edges are exploited to enable reset-free quantization within a single conversion period. By eliminating explicit reset phases, the proposed approach expands the effective conversion window and relaxes the resolution-speed tradeoff at high sampling rates. An 8-bit dual-edge asynchronous pipelined SAR time-domain ADC is implemented in 22-nm FD-SOI, incorporating a linearity-compensated dual-edge voltage-to-time converter and a dual-edge time-to-digital converter with independently tunable rising- and falling-edge delays. The prototype occupies a core area of 0.0089 mm^2 and achieves continuous single-channel operation at 3.5 GS/s, with architectural scalability demonstrated through intermittent operation at 10.5 GS/s and higher. At 3.5 GS/s, the ADC achieves 21.6 dB SNDR and 32.2 dB SFDR. The measured performance is primarily limited by identifiable implementation-level factors rather than by architectural constraints, demonstrating the feasibility of dual-edge reset-free quantization for high-speed time-domain ADCs.</description>
      <guid isPermaLink="false">oai:arXiv.org:2601.21308v1</guid>
      <category>eess.SP</category>
      <category>cs.SY</category>
      <category>eess.SY</category>
      <pubDate>Fri, 30 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Richard Zeng, Anthony Chan Carusone, Xilin Liu</dc:creator>
    </item>
    <item>
      <title>A Linearization of DFT Spectrum for Precision Power Measurement in Presence of Interharmonics</title>
      <link>https://arxiv.org/abs/2601.21397</link>
      <description>arXiv:2601.21397v1 Announce Type: new 
Abstract: The presence of interharmonics in power systems can lead to asynchronous sampling, a phenomenon further aggravated by shifts in the fundamental frequency, which significantly degrades the accuracy of power measurements. Under such asynchronous conditions, interharmonics lose orthogonality with the fundamental and harmonic components, giving rise to additional power components. To address these challenges, this paper introduces a linearization algorithm based on DFT spectrum analysis for precise power measurement in systems containing interharmonics. The proposed approach constructs a system of linear equations from the DFT spectrum and solves it through efficient matrix operations, enabling accurate extraction of interharmonic components near the fundamental and harmonic frequencies (with a frequency interval $\geq$1 Hz). This allows for precise measurement of power across the fundamental, harmonic, interharmonic, and cross-power bands, as well as total power. Test results demonstrate that the proposed method accurately computes various power components under diverse conditions--including varying interharmonic/fundamental/harmonic intervals, fundamental frequency deviations, and noise. Compared to existing methods such as fast Fourier transform (FFT), Windowed interpolation FFT, and Matrix pencil-Singular value decomposition, the proposed technique reduces estimation error by several times to multiple folds and exhibits improved robustness, while maintaining a computational time of only 7 ms for processing 10-power-line-cycle (200 ms) data.</description>
      <guid isPermaLink="false">oai:arXiv.org:2601.21397v1</guid>
      <category>eess.SP</category>
      <pubDate>Fri, 30 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Jian Liu, Wei Zhao, Jianting Zhao, Shisong Li</dc:creator>
    </item>
    <item>
      <title>Interference Detection and Exploitation for Multi-User Radar Sensing</title>
      <link>https://arxiv.org/abs/2601.21429</link>
      <description>arXiv:2601.21429v1 Announce Type: new 
Abstract: Integrated sensing and communication is a key feature in next-generation wireless networks, enabling joint data transmission and environmental radar sensing on shared spectrum. In multi-user scenarios, simultaneous transmissions cause mutual interference on overlapping frequencies, leading to spurious target detections and degraded sensing accuracy. This paper proposes an interference detection and exploitation algorithm for sensing using spectrally interleaved orthogonal frequency division multiplexing. A statistically rigorous procedure is introduced to detect interference while controlling the familywise error rate. We propose an algorithm that estimates the angle by exploiting interference, while estimating the delay by avoiding the interference. Numerical experiments demonstrate that the proposed method reliably detects interference, and that the delay and angle estimation error approaches the Cram\'er-Rao lower bound.</description>
      <guid isPermaLink="false">oai:arXiv.org:2601.21429v1</guid>
      <category>eess.SP</category>
      <pubDate>Fri, 30 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Laurits Randers, Martin Voigt Vejling, Petar Popovski</dc:creator>
    </item>
    <item>
      <title>Compressed Sensing-Driven Near-Field Localization Exploiting Array of Subarrays</title>
      <link>https://arxiv.org/abs/2601.21481</link>
      <description>arXiv:2601.21481v1 Announce Type: new 
Abstract: Near-field localization for ISAC requires large-aperture arrays, making fully-digital implementations prohibitively complex and costly. While sparse subarray architectures can reduce cost, they introduce severe estimation ambiguity from grating lobes. To address both issues, we propose SHARE (Sparse Hierarchical Angle-Range Estimation), a novel two-stage sparse recovery algorithm. SHARE operates in two stages. It first performs coarse, unambiguous angle estimation using individual subarrays to resolve the grating lobe ambiguity. It then leverages the full sparse aperture to perform a localized joint angle-range search. This hierarchical approach avoids an exhaustive and computationally intensive two-dimensional grid search while preserving the high resolution of the large aperture. Simulation results show that SHARE significantly outperforms conventional one-shot sparse recovery methods, such as Orthogonal Matching Pursuit (OMP), in both localization accuracy and robustness. Furthermore, we show that SHARE's overall localization accuracy is comparable to or even surpasses that of the fully-digital 2D-MUSIC algorithm, despite MUSIC having access to the complete, uncompressed data from every antenna element. SHARE therefore provides a practical path for high-resolution near-field ISAC systems.</description>
      <guid isPermaLink="false">oai:arXiv.org:2601.21481v1</guid>
      <category>eess.SP</category>
      <category>cs.ET</category>
      <pubDate>Fri, 30 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Sai Pavan Deram, Jacopo Pegoraro, Javier Lorca Hernando, Jesus O. Lacruz, Joerg Widmer</dc:creator>
    </item>
    <item>
      <title>Channel Extrapolation for MIMO Systems with the Assistance of Multi-path Information Induced from Channel State Information</title>
      <link>https://arxiv.org/abs/2601.21524</link>
      <description>arXiv:2601.21524v1 Announce Type: new 
Abstract: Acquiring channel state information (CSI) through traditional methods, such as channel estimation, is increasingly challenging for the emerging sixth generation (6G) mobile networks due to high overhead. To address this issue, channel extrapolation techniques have been proposed to acquire complete CSI from a limited number of known CSIs. To improve extrapolation accuracy, environmental information, such as visual images or radar data, has been utilized, which poses challenges including additional hardware, privacy and multi-modal alignment concerns. To this end, this paper proposes a novel channel extrapolation framework by leveraging environment-related multi-path characteristics induced directly from CSI without integrating additional modalities. Specifically, we propose utilizing the multi-path characteristics in the form of power-delay profile (PDP), which is acquired using a CSI-to-PDP module. CSI-to-PDP module is trained in an AE-based framework by reconstructing the PDPs and constraining the latent low-dimensional features to represent the CSI. We further extract the total power &amp; power-weighted delay of all the identified paths in PDP as the multi-path information. Building on this, we proposed a MAE architecture trained in a self-supervised manner to perform channel extrapolation. Unlike standard MAE approaches, our method employs separate encoders to extract features from the masked CSI and the multi-path information, which are then fused by a cross-attention module. Extensive simulations demonstrate that this framework improves extrapolation performance dramatically, with a minor increase in inference time (around 0.1 ms). Furthermore, our model shows strong generalization capabilities, particularly when only a small portion of the CSI is known, outperforming existing benchmarks.</description>
      <guid isPermaLink="false">oai:arXiv.org:2601.21524v1</guid>
      <category>eess.SP</category>
      <pubDate>Fri, 30 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Yuan Gao, Xinyi Wu, Jiang Jun, Zitian Zhang, Zhaohui Yang, Shugong Xu, Cheng-Xiang Wang, Zhu Han</dc:creator>
    </item>
    <item>
      <title>Near-Field Positioning for XL-MIMO Uniform Circular Arrays: An Attention-Enhanced Deep Learning Approach</title>
      <link>https://arxiv.org/abs/2601.21550</link>
      <description>arXiv:2601.21550v1 Announce Type: new 
Abstract: In the evolving landscape of sixth-generation (6G) mobile communication, multiple-input multiple-output (MIMO) systems are incorporating an unprecedented number of antenna elements, advancing towards Extremely large-scale multiple-input-multiple-output (XL-MIMO) systems. This enhancement significantly increases the spatial degrees of freedom, offering substantial benefits for wireless positioning. However, the expansion of the near-field range in XL-MIMO challenges the traditional far-field assumptions used in previous MIMO models. Among various configurations, uniform circular arrays (UCAs) demonstrate superior performance by maintaining constant angular resolution, unlike linear planar arrays. Addressing how to leverage the expanded aperture and harness the near-field effects in XL-MIMO systems remains an area requiring further investigation. In this paper, we introduce an attention-enhanced deep learning approach for precise positioning. We employ a dual-path channel attention mechanism and a spatial attention mechanism to effectively integrate channel-level and spatial-level features. Our comprehensive simulations show that this model surpasses existing benchmarks such as attention-based positioning networks (ABPN), near-field positioning networks (NFLnet), convolutional neural networks (CNN), and multilayer perceptrons (MLP). The proposed model achieves superior positioning accuracy by utilizing covariance metrics of the input signal. Also, simulation results reveal that covariance metric is advantageous for positioning over channel state information (CSI) in terms of positioning accuracy and model efficiency.</description>
      <guid isPermaLink="false">oai:arXiv.org:2601.21550v1</guid>
      <category>eess.SP</category>
      <pubDate>Fri, 30 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Yuan Gao, Xinyu Guo, Han Li, Jianbo Du, Shugong Xu</dc:creator>
    </item>
    <item>
      <title>VSE: Variational state estimation of complex model-free process</title>
      <link>https://arxiv.org/abs/2601.21887</link>
      <description>arXiv:2601.21887v1 Announce Type: new 
Abstract: We design a variational state estimation (VSE) method that provides a closed-form Gaussian posterior of an underlying complex dynamical process from (noisy) nonlinear measurements. The complex process is model-free. That is, we do not have a suitable physics-based model characterizing the temporal evolution of the process state. The closed-form Gaussian posterior is provided by a recurrent neural network (RNN). The use of RNN is computationally simple in the inference phase. For learning the RNN, an additional RNN is used in the learning phase. Both RNNs help each other learn better based on variational inference principles. The VSE is demonstrated for a tracking application - state estimation of a stochastic Lorenz system (a benchmark process) using a 2-D camera measurement model. The VSE is shown to be competitive against a particle filter that knows the Lorenz system model and a recently proposed data-driven state estimation method that does not know the Lorenz system model.</description>
      <guid isPermaLink="false">oai:arXiv.org:2601.21887v1</guid>
      <category>eess.SP</category>
      <category>cs.LG</category>
      <category>stat.ML</category>
      <pubDate>Fri, 30 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Gustav Nor\'en, Anubhab Ghosh, Fredrik Cumlin, Saikat Chatterjee</dc:creator>
    </item>
    <item>
      <title>Joint Laser Inter-Satellite Link Matching and Traffic Flow Routing in LEO Mega-Constellations via Lagrangian Duality</title>
      <link>https://arxiv.org/abs/2601.21914</link>
      <description>arXiv:2601.21914v1 Announce Type: new 
Abstract: Low Earth orbit (LEO) mega-constellations greatly extend the coverage and resilience of future wireless systems. Within the mega-constellations, laser inter-satellite links (LISLs) enable high-capacity, long-range connectivity. Existing LISL schemes often overlook mechanical limitations of laser communication terminals (LCTs) and non-uniform global traffic profiles caused by uneven user and gateway distributions, leading to suboptimal throughput and underused LCTs/LISLs -- especially when each satellite carries only a few LCTs. This paper investigates the joint optimization of LCT connections and traffic routing to maximize the constellation throughput, considering the realistic LCT mechanics and the global traffic profile. The problem is formulated as an NP-hard mixed-integer program coupling LCT connections with flow-rate variables under link capacity constraints. Due to its intractability, we resort to relaxing the coupling constraints via Lagrangian duality, decomposing the problem into a weighted graph-matching for LCT connections, weighted shortest-path routing tasks, and a linear program for rate allocation. Here, Lagrange multipliers reflect congestion weights between satellites, jointly guiding the matching, routing, and rate allocation. Subgradient descent optimizes the multipliers, with provable convergence. Simulations using real-world constellation and terrestrial data show that our methods substantially improve network throughput by up to $35\%$--$145\%$ over existing non-joint approaches.</description>
      <guid isPermaLink="false">oai:arXiv.org:2601.21914v1</guid>
      <category>eess.SP</category>
      <pubDate>Fri, 30 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Zhouyou Gu, Jihong Park, Jinho Choi</dc:creator>
    </item>
    <item>
      <title>Duality-Guided Graph Learning for Real-Time Joint Connectivity and Routing in LEO Mega-Constellations</title>
      <link>https://arxiv.org/abs/2601.21921</link>
      <description>arXiv:2601.21921v1 Announce Type: new 
Abstract: Laser inter-satellite links (LISLs) of low Earth orbit (LEO) mega-constellations enable high-capacity backbone connectivity in non-terrestrial networks, but their management is challenged by limited laser communication terminals, mechanical pointing constraints, and rapidly time-varying network topologies. This paper studies the joint problem of LISL connection establishment, traffic routing, and flow-rate allocation under heterogeneous global traffic demand and gateway availability. We formulate the problem as a mixed-integer optimization over large-scale, time-varying constellation graphs and develop a Lagrangian dual decomposition that interprets per-link dual variables as congestion prices coordinating connectivity and routing decisions. To overcome the prohibitive latency of iterative dual updates, we propose DeepLaDu, a Lagrangian duality-guided deep learning framework that trains a graph neural network (GNN) to directly infer per-link (edge-level) congestion prices from the constellation state in a single forward pass. We enable scalable and stable training using a subgradient-based edge-level loss in DeepLaDu. We analyze the convergence and computational complexity of the proposed approach and evaluate it using realistic Starlink-like constellations with optical and traffic constraints. Simulation results show that DeepLaDu achieves up to 20\% higher network throughput than non-joint or heuristic baselines, while matching the performance of iterative dual optimization with orders-of-magnitude lower computation time, suitable for real-time operation in dynamic LEO networks.</description>
      <guid isPermaLink="false">oai:arXiv.org:2601.21921v1</guid>
      <category>eess.SP</category>
      <pubDate>Fri, 30 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Zhouyou Gu, Jinho Choi, Tony Q. S. Quek, Jihong Park</dc:creator>
    </item>
    <item>
      <title>Optimal Placement of Movable Antennas for Angle-of-Departure Estimation Under User Location Uncertainty</title>
      <link>https://arxiv.org/abs/2601.21997</link>
      <description>arXiv:2601.21997v1 Announce Type: new 
Abstract: Movable antennas (MA) have gained significant attention in recent years to overcome the limitations of extremely large antenna arrays in terms of cost and power consumption. In this paper, we investigate the use of MA arrays at the base station (BS) for angle-of-departure (AoD) estimation under uncertainty in the user equipment (UE) location. Specifically, we (i) derive the theoretical performance limits through the Cram\'er-Rao bound (CRB) and (ii) optimize the antenna positions to ensure robust performance within the UE's uncertainty region. Numerical results show that dynamically optimizing antenna placement by explicitly considering the uncertainty region yields superior performance compared to fixed arrays, demonstrating the ability of MA systems to adapt and outperform conventional arrays.</description>
      <guid isPermaLink="false">oai:arXiv.org:2601.21997v1</guid>
      <category>eess.SP</category>
      <pubDate>Fri, 30 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Luc\'ia Pallar\'es-Rodr\'iguez, Angelo Coluccia, Alessio Fascista, Musa Furkan Keskin, Henk Wymeersch, Jos\'e A. L\'opez-Salcedo, Gonzalo Seco-Granados</dc:creator>
    </item>
    <item>
      <title>Towards Joint Optimization for UAV-Integrated RIS-Assisted Fluid Antenna Systems</title>
      <link>https://arxiv.org/abs/2601.22109</link>
      <description>arXiv:2601.22109v1 Announce Type: new 
Abstract: Unmanned aerial vehicles (UAVs) integrated into cellular networks face significant challenges from air-to-ground interference. To address this, we propose a downlink UAV communication system that leverages a fluid antenna system (FAS)- assisted reconfigurable intelligent surface (RIS) to enhance signal quality. By jointly optimizing the FAS port positions and RIS phase shifts, we maximize the achievable rate. The resulting nonconvex optimization problem is solved using successive convex approximation (SCA) based on second-order cone programming (SOCP), which reformulates the constraints into a tractable form. Simulation results show that the proposed algorithm significantly improves both outage probability and achievable rate over conventional fixed-position antenna (FPA) schemes, with particularly large gains in large-scale RIS configurations. Moreover, the algorithm converges rapidly, making it suitable for real-time applications</description>
      <guid isPermaLink="false">oai:arXiv.org:2601.22109v1</guid>
      <category>eess.SP</category>
      <pubDate>Fri, 30 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <arxiv:DOI>10.1109/TVT.2026.3658088</arxiv:DOI>
      <arxiv:journal_reference>IEEE Transactions on Vehicular Technology, 2026</arxiv:journal_reference>
      <dc:creator>Ali Reda, Tamer Mekkawy, Theodoros A. Tsiftsis, Chan-Byoung Chae, Kai-Kit Wong</dc:creator>
    </item>
    <item>
      <title>Denoising and Baseline Correction of Low-Scan FTIR Spectra: A Benchmark of Deep Learning Models Against Traditional Signal Processing</title>
      <link>https://arxiv.org/abs/2601.20905</link>
      <description>arXiv:2601.20905v1 Announce Type: cross 
Abstract: High-quality Fourier Transform Infrared (FTIR) imaging usually needs extensive signal averaging to reduce noise and drift which severely limits clinical speed. Deep learning can accelerate imaging by reconstructing spectra from rapid, single-scan inputs. However, separating noise and baseline drift simultaneously without ground truth is an ill-posed inverse problem. Standard black-box architectures often rely on statistical approximations that introduce spectral hallucinations or fail to generalize to unstable atmospheric conditions. To solve these issues we propose a physics-informed cascade Unet that separates denoising and baseline correction tasks using a new, deterministic Physics Bridge. This architecture forces the network to separate random noise from chemical signals using an embedded SNIP layer to enforce spectroscopic constraints instead of learning statistical approximations. We benchmarked this approach against a standard single Unet and a traditional Savitzky-Golay/SNIP workflow. We used a dataset of human hypopharyngeal carcinoma cells (FaDu). The cascade model outperformed all other methods, achieving a 51.3% reduction in RMSE compared to raw single-scan inputs, surpassing both the single Unet (40.2%) and the traditional workflow (33.7%). Peak-aware metrics show that the cascade architecture eliminates spectral hallucinations found in standard deep learning. It also preserves peak intensity with much higher fidelity than traditional smoothing. These results show that the cascade Unet is a robust solution for diagnostic-grade FTIR imaging. It enables imaging speeds 32 times faster than current methods.</description>
      <guid isPermaLink="false">oai:arXiv.org:2601.20905v1</guid>
      <category>eess.IV</category>
      <category>cs.AI</category>
      <category>cs.CV</category>
      <category>cs.LG</category>
      <category>eess.SP</category>
      <pubDate>Fri, 30 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Azadeh Mokari, Shravan Raghunathan, Artem Shydliukh, Oleg Ryabchykov, Christoph Krafft, Thomas Bocklitz</dc:creator>
    </item>
    <item>
      <title>Temporal Context and Architecture: A Benchmark for Naturalistic EEG Decoding</title>
      <link>https://arxiv.org/abs/2601.21215</link>
      <description>arXiv:2601.21215v1 Announce Type: cross 
Abstract: We study how model architecture and temporal context interact in naturalistic EEG decoding. Using the HBN movie-watching dataset, we benchmark five architectures, CNN, LSTM, a stabilized Transformer (EEGXF), S4, and S5, on a 4-class task across segment lengths from 8s to 128s. Accuracy improves with longer context: at 64s, S5 reaches 98.7%+/-0.6 and CNN 98.3%+/-0.3, while S5 uses ~20x fewer parameters than CNN. To probe real-world robustness, we evaluate zero-shot cross-frequency shifts, cross-task OOD inputs, and leave-one-subject-out generalization. S5 achieves stronger cross-subject accuracy but makes over-confident errors on OOD tasks; EEGXF is more conservative and stable under frequency shifts, though less calibrated in-distribution. These results reveal a practical efficiency-robustness trade-off: S5 for parameter-efficient peak accuracy; EEGXF when robustness and conservative uncertainty are critical.</description>
      <guid isPermaLink="false">oai:arXiv.org:2601.21215v1</guid>
      <category>cs.LG</category>
      <category>cs.AI</category>
      <category>eess.SP</category>
      <pubDate>Fri, 30 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <arxiv:journal_reference>ICASSP 2026</arxiv:journal_reference>
      <dc:creator>Mehmet Ergezer</dc:creator>
    </item>
    <item>
      <title>Collective Noise Filtering in Complex Networks</title>
      <link>https://arxiv.org/abs/2601.21299</link>
      <description>arXiv:2601.21299v1 Announce Type: cross 
Abstract: Complex networks are powerful representations of complex systems across scales and domains, and the field is experiencing unprecedented growth in data availability. However, real-world network data often suffer from noise, biases, and missing data in the edge weights, which undermine the reliability of downstream network analyses. Standard noise filtering approaches, whether treating individual edges one-by-one or assuming a uniform global noise level, are suboptimal, because in reality both signal and noise can be heterogeneous and correlated across multiple edges. As a solution, we introduce the Network Wiener Filter, a principled method for collective edge-level noise filtering that leverages both network topology and noise characteristics, to reduce error in the observed edge weights and to infer missing edge weights. We demonstrate the broad practical efficacy of the Network Wiener Filter in two distinct settings, the genetic interaction network of the yeast S. cerevisiae and the Enron Corpus email network, noting compelling evidence of successful noise suppression in both applications. With the Network Wiener Filter, we advocate for a shift toward error-aware network science, one that embraces data imperfection as an inherent feature and learns to navigate it effectively.</description>
      <guid isPermaLink="false">oai:arXiv.org:2601.21299v1</guid>
      <category>cs.CE</category>
      <category>eess.SP</category>
      <category>stat.AP</category>
      <pubDate>Fri, 30 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Tingyu Zhao, Istv\'an A. Kov\'acs</dc:creator>
    </item>
    <item>
      <title>Opinion Consensus Formation Among Networked Large Language Models</title>
      <link>https://arxiv.org/abs/2601.21540</link>
      <description>arXiv:2601.21540v1 Announce Type: cross 
Abstract: Can classical consensus models predict the group behavior of large language models (LLMs)? We examine multi-round interactions among LLM agents through the DeGroot framework, where agents exchange text-based messages over diverse communication graphs. To track opinion evolution, we map each message to an opinion score via sentiment analysis. We find that agents typically reach consensus and the disagreement between the agents decays exponentially. However, the limiting opinion departs from DeGroot's network-centrality-weighted forecast. The consensus between LLM agents turns out to be largely insensitive to initial conditions and instead depends strongly on the discussion subject and inherent biases. Nevertheless, transient dynamics align with classical graph theory and the convergence rate of opinions is closely related to the second-largest eigenvalue of the graph's combination matrix. Together, these findings can be useful for LLM-driven social-network simulations and the design of resource-efficient multi-agent LLM applications.</description>
      <guid isPermaLink="false">oai:arXiv.org:2601.21540v1</guid>
      <category>cs.SI</category>
      <category>cs.MA</category>
      <category>eess.SP</category>
      <pubDate>Fri, 30 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Iris Yazici, Mert Kayaalp, Stefan Taga, Ali H. Sayed</dc:creator>
    </item>
    <item>
      <title>A Low-Complexity Plug-and-Play Deep Learning Model for Generalizable Massive MIMO Precoding</title>
      <link>https://arxiv.org/abs/2601.21897</link>
      <description>arXiv:2601.21897v1 Announce Type: cross 
Abstract: Massive multiple-input multiple-output (mMIMO) downlink precoding offers high spectral efficiency but remains challenging to deploy in practice because near-optimal algorithms such as the weighted minimum mean squared error (WMMSE) are computationally expensive, and sensitive to SNR and channel-estimation quality, while existing deep learning (DL)-based solutions often lack robustness and require retraining for each deployment site. This paper proposes a plug-and-play precoder (PaPP), a DL framework with a backbone that can be trained for either fully digital (FDP) or hybrid beamforming (HBF) precoding and reused across sites, transmit-power levels, and with varying amounts of channel estimation error, avoiding the need to train a new model from scratch at each deployment. PaPP combines a high-capacity teacher and a compact student with a self-supervised loss that balances teacher imitation and normalized sum-rate, trained using meta-learning domain-generalization and transmit-power-aware input normalization. Numerical results on ray-tracing data from three unseen sites show that the PaPP FDP and HBF models both outperform conventional and deep learning baselines, after fine-tuning with a small set of local unlabeled samples. Across both architectures, PaPP achieves more than 21$\times$ reduction in modeled computation energy and maintains good performance under channel-estimation errors, making it a practical solution for energy-efficient mMIMO precoding.</description>
      <guid isPermaLink="false">oai:arXiv.org:2601.21897v1</guid>
      <category>cs.LG</category>
      <category>eess.SP</category>
      <pubDate>Fri, 30 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <dc:creator>Ali Hasanzadeh Karkan, Ahmed Ibrahim, Jean-Fran\c{c}ois Frigon, Fran\c{c}ois Leduc-Primeau</dc:creator>
    </item>
    <item>
      <title>Wrapper-Aware Rate-Distortion Optimization in Feature Coding for Machines</title>
      <link>https://arxiv.org/abs/2601.22070</link>
      <description>arXiv:2601.22070v1 Announce Type: cross 
Abstract: Feature coding for machines (FCM) is a lossy compression paradigm for split-inference. The transmitter encodes the outputs of the first part of a neural network before sending them to the receiver for completing the inference. Practical FCM methods ``sandwich'' a traditional codec between pre- and post-processing neural networks, called wrappers, to make features easier to compress using video codecs. Since traditional codecs are non-differentiable, the wrappers are trained using a proxy codec, which is later replaced by a standard codec after training. These codecs perform rate-distortion optimization (RDO) based on the sum of squared errors (SSE). Because the RDO does not consider the post-processing wrapper, the inner codec can invest bits in preserving information that the post-processing later discards. In this paper, we modify the bit-allocation in the inner codec via a wrapper-aware weighted SSE metric. To make wrapper-aware RDO (WA-RDO) practical for FCM, we propose: 1) temporal reuse of weights across a group of pictures and 2) fixed, architecture- and task-dependent weights trained offline. Under MPEG test conditions, our methods implemented on HEVC match the VVC-based FCM state-of-the-art, effectively bridging a codec generation gap with minimal runtime overhead relative to SSE-RDO HEVC.</description>
      <guid isPermaLink="false">oai:arXiv.org:2601.22070v1</guid>
      <category>eess.IV</category>
      <category>eess.SP</category>
      <pubDate>Fri, 30 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Samuel Fern\'andez-Mendui\~na, Hyomin Choi, Fabien Racap\'e, Eduardo Pavez, Antonio Ortega</dc:creator>
    </item>
    <item>
      <title>Fundamental Trade-offs in Quantized Hybrid Radar Fusion: A CRB-Rate Perspective</title>
      <link>https://arxiv.org/abs/2411.00496</link>
      <description>arXiv:2411.00496v4 Announce Type: replace 
Abstract: Hybrid radar fusion (HRF), which combines monostatic and bistatic sensing in a common spectrum, offers enhanced spatial diversity, but is particularly vulnerable to quantization error effects due to the large power imbalance between the direct and reflected uplink signals. Although finite-resolution analog-to-digital converters (ADCs) have been considered in the existing literature on integrated sensing and communication (ISAC), their role in HRF architectures has not yet been characterized. This paper develops a finite-resolution quantized sensing-communication framework for HRF systems by deriving a Cramer-Rao bound (CRB) and achievable uplink rate. Tight lower bounds on the Fisher information matrix and the communication rate are obtained, enabling a tractable characterization of finite-resolution quantized HRF. The fundamental sensing-communication trade-off is then characterized through two complementary constrained formulations: CRB minimization subject to per-user uplink rate requirements, and sum-rate maximization subject to a CRB constraint, whose solutions trace the CRB-rate trade-offs in HRF. Numerical results reveal how ADC resolution, dynamic range, and system configuration jointly shape this boundary and show that HRF performance can degrade sharply under coarse quantization due to the weak bistatic component, providing design guidelines for selecting ADC architectures and operating regimes in future HRF-enabled ISAC systems.</description>
      <guid isPermaLink="false">oai:arXiv.org:2411.00496v4</guid>
      <category>eess.SP</category>
      <pubDate>Fri, 30 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Akhileswar Chowdary, Ahmad Bazzi, Vaibhav Kumar, Roberto Bomfin, Marwa Chafii</dc:creator>
    </item>
    <item>
      <title>Cellular, Cell-less, and Everything in Between: A Unified Framework for Utility Region Analysis in Wireless Networks</title>
      <link>https://arxiv.org/abs/2507.23707</link>
      <description>arXiv:2507.23707v3 Announce Type: replace 
Abstract: We introduce a unified framework for analyzing utility regions of wireless networks, with a focus on signal-to-interference-plus-noise-ratio (SINR) and achievable rate regions. The framework provides valuable insights into interference patterns of modern network architectures, including extremely large MIMO and cell-less networks. A central contribution is a simple characterization of feasible utility regions using the concept of spectral radius of nonlinear mappings. This characterization provides a powerful mathematical tool for wireless system design and analysis. For example, it allows us to generalize existing characterizations of the weak Pareto boundary using compact notation. It also allows us to derive tractable sufficient conditions for the identification of convex utility regions. This property is particularly important because, on the weak Pareto boundary, it guarantees that time sharing (or user grouping) cannot simultaneously improve the utilities of all users. Beyond geometrical insights, these sufficient conditions have two key implications. First, they identify a family of (weighted) sum-rate maximization problems that are inherently convex, thus paving the way for the development of efficient, provably optimal solvers for this family. Second, they provide justification for formulating sum-rate maximization problems directly in terms of achievable rates, rather than SINR levels. Our theoretical insights also motivate an alternative to the concept of favorable propagation in the massive MIMO literature -- one that explicitly accounts for self-interference and the beamforming strategy.</description>
      <guid isPermaLink="false">oai:arXiv.org:2507.23707v3</guid>
      <category>eess.SP</category>
      <category>cs.IT</category>
      <category>math.IT</category>
      <pubDate>Fri, 30 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Renato Luis Garrido Cavalcante, Tomasz Piotrowski, Slawomir Stanczak</dc:creator>
    </item>
    <item>
      <title>Applying the Spectral Method for Modeling Linear Filters: Butterworth, Linkwitz-Riley, and Chebyshev filters</title>
      <link>https://arxiv.org/abs/2508.07206</link>
      <description>arXiv:2508.07206v2 Announce Type: replace 
Abstract: This paper proposes a new technique for computer modeling linear filters based on the spectral form of mathematical description of linear systems. It assumes the representation of input and output signals of the filter as orthogonal expansions, while filters themselves are described by two-dimensional non-stationary transfer functions. This technique allows one to model the output signal in continuous time, and it is successfully tested on the Butterworth, Linkwitz-Riley, and Chebyshev filters with different orders.</description>
      <guid isPermaLink="false">oai:arXiv.org:2508.07206v2</guid>
      <category>eess.SP</category>
      <category>cs.NA</category>
      <category>cs.SY</category>
      <category>eess.SY</category>
      <category>math.NA</category>
      <pubDate>Fri, 30 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <arxiv:DOI>10.1016/j.fraope.2026.100508</arxiv:DOI>
      <arxiv:journal_reference>Franklin Open 2026, 14, 100508</arxiv:journal_reference>
      <dc:creator>Konstantin A. Rybakov, Egor D. Shermatov</dc:creator>
    </item>
    <item>
      <title>Temporally-Similar Structure-Aware Spatiotemporal Fusion of Satellite Images</title>
      <link>https://arxiv.org/abs/2508.11259</link>
      <description>arXiv:2508.11259v2 Announce Type: replace 
Abstract: This paper proposes a spatiotemporal (ST) fusion framework robust against diverse noise for satellite images, named Temporally-Similar Structure-Aware ST fusion (TSSTF). ST fusion is a promising approach to address the trade-off between the spatial and temporal resolution of satellite images. In real-world scenarios, observed satellite images are severely degraded by noise due to measurement equipment and environmental conditions. Consequently, some recent studies have focused on enhancing the robustness of ST fusion methods against noise. However, existing noise-robust ST fusion approaches often fail to capture fine spatial structure, leading to oversmoothing and artifacts. To address this issue, TSSTF introduces two key mechanisms: Temporally-Guided Total Variation (TGTV) and Temporally-Guided Edge Constraint (TGEC). TGTV is a weighted total variation-based regularization that promotes spatial piecewise smoothness while preserving structural details, guided by a reference high spatial resolution image acquired on a nearby date. TGEC enforces consistency in edge locations between two temporally adjacent images, while allowing for spectral variations. We formulate the ST fusion task as a constrained optimization problem incorporating TGTV and TGEC, and develop an efficient algorithm based on a preconditioned primal-dual splitting method. Experimental results demonstrate that TSSTF performs comparably to state-of-the-art methods under noise-free conditions and outperforms them under noisy conditions.</description>
      <guid isPermaLink="false">oai:arXiv.org:2508.11259v2</guid>
      <category>eess.SP</category>
      <category>cs.CV</category>
      <pubDate>Fri, 30 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Ryosuke Isono, Shunsuke Ono</dc:creator>
    </item>
    <item>
      <title>Non-Identical Diffusion Models in MIMO-OFDM Channel Generation</title>
      <link>https://arxiv.org/abs/2509.01641</link>
      <description>arXiv:2509.01641v2 Announce Type: replace 
Abstract: We propose a novel diffusion model, termed the non-identical diffusion model, and investigate its application to wireless orthogonal frequency division multiplexing (OFDM) channel generation. Unlike the standard diffusion model that uses a scalar-valued time index to represent the global noise level, we extend this notion to an element-wise time indicator to capture local error variations more accurately. Non-identical diffusion enables us to characterize the reliability of each element (e.g., subcarriers in OFDM) within the noisy input, leading to improved generation results when the initialization is biased. Specifically, we focus on the recovery of wireless multi-input multi-output (MIMO) OFDM channel matrices, where the initial channel estimates exhibit highly uneven reliability across elements due to the pilot scheme. Conventional time embeddings, which assume uniform noise progression, fail to capture such variability across pilot schemes and noise levels. We introduce a matrix that matches the input size to control element-wise noise progression. Following a similar diffusion procedure to existing methods, we show the correctness and effectiveness of the proposed non-identical diffusion scheme both theoretically and numerically. For MIMO-OFDM channel generation, we propose a dimension-wise time embedding strategy. We also develop and evaluate multiple training and generation methods and compare them through numerical experiments.</description>
      <guid isPermaLink="false">oai:arXiv.org:2509.01641v2</guid>
      <category>eess.SP</category>
      <category>cs.AI</category>
      <category>cs.LG</category>
      <pubDate>Fri, 30 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <dc:creator>Yuzhi Yang, Omar Alhussein, M\'erouane Debbah</dc:creator>
    </item>
    <item>
      <title>Beyond the Use-and-then-Forget (UatF) Bound: Fixed Point Algorithms for Statistical Max-Min Power Control</title>
      <link>https://arxiv.org/abs/2510.11582</link>
      <description>arXiv:2510.11582v3 Announce Type: replace 
Abstract: We introduce mathematical tools and fixed point algorithms for optimal statistical max-min power control in cellular and cell-less massive MIMO systems. Unlike previous studies that rely on the use-and-then-forget (UatF) lower bound on Shannon achievable (ergodic) rates, our proposed framework can deal with alternative bounds that explicitly consider perfect or imperfect channel state information (CSI) at the decoder. In doing so, we address limitations of UatF-based power control algorithms, which inherit the shortcomings of the UatF bound. For example, the UatF bound can be overly conservative: in extreme cases, under fully statistical (nonadaptive) beamforming in zero-mean channels, the UatF bound produces trivial (zero) rate bounds. It also lacks scale invariance: merely scaling the beamformers can change the bound drastically. In contrast, our framework is compatible with information-theoretic bounds that do not suffer from the above drawbacks. We illustrate the framework by solving a max-min power control problem considering a standard bound that exploits instantaneous CSI at the decoder.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.11582v3</guid>
      <category>eess.SP</category>
      <category>cs.IT</category>
      <category>math.IT</category>
      <pubDate>Fri, 30 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Renato Luis Garrido Cavalcante, Noor Ul Ain, Lorenzo Miretti, Slawomir Stanczak</dc:creator>
    </item>
    <item>
      <title>Increasing Data Rate through Shaping on Wireless Channels Subject to Mobility and Delay Spread</title>
      <link>https://arxiv.org/abs/2512.06494</link>
      <description>arXiv:2512.06494v2 Announce Type: replace 
Abstract: This letter describes how to improve performance of cellular systems by combining non-equiprobable signaling with low-density parity check (LDPC) coding for an orthogonal frequency division multiplexing system. We focus on improving performance of wireless transmission with rate $3/4$ LDPC codes employing $4$-QAM at the cell edge. We double the size of the $4$-QAM constellation by introducing a second shell of signal points, and we implement non-equiprobable signaling through a shaping code which selects the high energy shell less frequently than the low energy shell. We emphasize that the shaping code is also used to transmit information. We employ rate $1/2$ LDPC coding and select the rate of the shaping code to match that of rate $3/4$ LDPC coding using $4$-QAM. We describe how to combine coding and shaping by integrating shaping into the calculation of log-likelihood ratios (LLRs) necessary for decoding LDPC codes. We present simulation results for a representative Veh-A channel showing gains of $4$ dB at a bit error rate (BER) of $10^{-3}$. Our results suggest that it is better to increase rate at the cell edge by introducing shaping, rather than by increasing the rate of the LDPC code.</description>
      <guid isPermaLink="false">oai:arXiv.org:2512.06494v2</guid>
      <category>eess.SP</category>
      <category>cs.IT</category>
      <category>math.IT</category>
      <pubDate>Fri, 30 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Sandesh Rao Mattu, Nishant Mehrotra, Robert Calderbank</dc:creator>
    </item>
    <item>
      <title>RIS-Enabled Spoofing Against Adversary Sensing: CRB-Maximizing Design and Decoying Analysis</title>
      <link>https://arxiv.org/abs/2601.17320</link>
      <description>arXiv:2601.17320v3 Announce Type: replace 
Abstract: This paper studies the capability of a Reconfigurable Intelligent Surface (RIS), when transparently covering a User Equipment (UE), to deceive an adversary monostatic radar system. A compact RIS kernel model that explicitly links the radar's angular response to the RIS phase profile is introduced, enabling an analytical investigation of the Angle of Arrival (AoA) estimation accuracy with respect to the kernel's power. This model is also leveraged to formulate an RIS-based spoofing design with the dual objective to enforce strict nulls around the UE's true reflection AoA and maximize the channel gain towards a decoy direction. The RIS's deception capability is quantified using point-wise and angle-range robust criteria, and a configuration-independent placement score guiding decoy selection is proposed. Selected numerical results confirm deep nulls at the true reflection AoA together with a pronounced decoy peak, rendering maximum-likelihood sensing at the adversary radar unreliable.</description>
      <guid isPermaLink="false">oai:arXiv.org:2601.17320v3</guid>
      <category>eess.SP</category>
      <pubDate>Fri, 30 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Ioannis Gavras, Giuseppe Thadeu Freitas de Abreu, George C. Alexandropoulos</dc:creator>
    </item>
    <item>
      <title>User Localization via Active Sensing with Electromagnetically Reconfigurable Antennas</title>
      <link>https://arxiv.org/abs/2601.20501</link>
      <description>arXiv:2601.20501v2 Announce Type: replace 
Abstract: This paper presents an end-to-end deep learning framework for electromagnetically reconfigurable antenna (ERA)-aided user localization with active sensing, where ERAs provide additional electromagnetic reconfigurability to diversify the received measurements and enhance localization informativeness. To balance sensing flexibility and overhead, we adopt a two-timescale design: the digital combiner is updated at each stage, while the ERA patterns are reconfigured at each substage via a spherical-harmonic representation. The proposed mechanism integrates attention-based feature extraction and LSTM-based temporal learning, enabling the system to learn an optimized sensing strategy and progressively refine the UE position estimate from sequential observations. Simulation results show that the proposed approach consistently outperforms conventional digital beamforming-only and single-stage sensing baselines in terms of localization accuracy. These results highlight the effectiveness of ERA-enabled active sensing for user localization in future wireless systems.</description>
      <guid isPermaLink="false">oai:arXiv.org:2601.20501v2</guid>
      <category>eess.SP</category>
      <pubDate>Fri, 30 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Ruizhi Zhang, Yuchen Zhang, Ying Zhang</dc:creator>
    </item>
    <item>
      <title>Mitigating data replication in text-to-audio generative diffusion models through anti-memorization guidance</title>
      <link>https://arxiv.org/abs/2509.14934</link>
      <description>arXiv:2509.14934v2 Announce Type: replace-cross 
Abstract: A persistent challenge in generative audio models is data replication, where the model unintentionally generates parts of its training data during inference. In this work, we address this issue in text-to-audio diffusion models by exploring the use of anti-memorization strategies. We adopt Anti-Memorization Guidance (AMG), a technique that modifies the sampling process of pre-trained diffusion models to discourage memorization. Our study explores three types of guidance within AMG, each designed to reduce replication while preserving generation quality. We use Stable Audio Open as our backbone, leveraging its fully open-source architecture and training dataset. Our comprehensive experimental analysis suggests that AMG significantly mitigates memorization in diffusion-based text-to-audio generation without compromising audio fidelity or semantic alignment.</description>
      <guid isPermaLink="false">oai:arXiv.org:2509.14934v2</guid>
      <category>eess.AS</category>
      <category>cs.LG</category>
      <category>cs.SD</category>
      <category>eess.SP</category>
      <pubDate>Fri, 30 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-sa/4.0/</dc:rights>
      <dc:creator>Francisco Messina, Francesca Ronchini, Luca Comanducci, Paolo Bestagini, Fabio Antonacci</dc:creator>
    </item>
    <item>
      <title>On the Adversarial Robustness of Learning-based Conformal Novelty Detection</title>
      <link>https://arxiv.org/abs/2510.00463</link>
      <description>arXiv:2510.00463v2 Announce Type: replace-cross 
Abstract: This paper studies the adversarial robustness of conformal novelty detection. In particular, we focus on two powerful learning-based frameworks that come with finite-sample false discovery rate (FDR) control: one is AdaDetect (by Marandon et al., 2024) that is based on the positive-unlabeled classifier, and the other is a one-class classifier-based approach (by Bates et al., 2023). While they provide rigorous statistical guarantees under benign conditions, their behavior under adversarial perturbations remains underexplored. We first formulate an oracle attack setup, under the AdaDetect formulation, that quantifies the worst-case degradation of FDR, deriving an upper bound that characterizes the statistical cost of attacks. This idealized formulation directly motivates a practical and effective attack scheme that only requires query access to the output labels of both frameworks. Coupling these formulations with two popular and complementary black-box adversarial algorithms, we systematically evaluate the vulnerability of both frameworks on synthetic and real-world datasets. Our results show that adversarial perturbations can significantly increase the FDR while maintaining high detection power, exposing fundamental limitations of current error-controlled novelty detection methods and motivating the development of more robust alternatives.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.00463v2</guid>
      <category>stat.ML</category>
      <category>cs.LG</category>
      <category>eess.SP</category>
      <category>stat.ME</category>
      <pubDate>Fri, 30 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Daofu Zhang, Mehrdad Pournaderi, Hanne M. Clifford, Yu Xiang, Pramod K. Varshney</dc:creator>
    </item>
    <item>
      <title>Expectations in Expectation Propagation</title>
      <link>https://arxiv.org/abs/2512.08034</link>
      <description>arXiv:2512.08034v2 Announce Type: replace-cross 
Abstract: Expectation Propagation (EP) is a widely used message-passing algorithm that decomposes a global inference problem into multiple local ones. It approximates marginal distributions (beliefs) using intermediate functions (messages). While beliefs must be proper probability distributions that integrate to one, messages may have infinite integral values. In Gaussian-projected EP, such messages take a Gaussian form and appear as if they have "negative" variances. Although allowed within the EP framework, these negative-variance messages can impede algorithmic progress.
  In this paper, we investigate EP in linear models and analyze the relationship between the corresponding beliefs. Based on the analysis, we propose both non-persistent and persistent approaches that prevent the algorithm from being blocked by messages with infinite integral values.
  Furthermore, by examining the relationship between the EP messages in linear models, we develop an additional approach that avoids the occurrence of messages with infinite integral values.</description>
      <guid isPermaLink="false">oai:arXiv.org:2512.08034v2</guid>
      <category>cs.IT</category>
      <category>eess.SP</category>
      <category>math.IT</category>
      <category>stat.CO</category>
      <pubDate>Fri, 30 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Zilu Zhao, Fangqing Xiao, Dirk Slock</dc:creator>
    </item>
    <item>
      <title>Large Language Models for Detecting Cyberattacks on Smart Grid Protective Relays</title>
      <link>https://arxiv.org/abs/2601.04443</link>
      <description>arXiv:2601.04443v2 Announce Type: replace-cross 
Abstract: This paper presents a large language model (LLM)-based framework that adapts and fine-tunes compact LLMs for detecting cyberattacks on transformer current differential relays (TCDRs), which can otherwise cause false tripping of critical power transformers. The core idea is to textualize multivariate time-series current measurements from TCDRs, across phases and input/output sides, into structured natural-language prompts that are then processed by compact, locally deployable LLMs. Using this representation, we fine-tune DistilBERT, GPT-2, and DistilBERT+LoRA to distinguish cyberattacks from genuine fault-induced disturbances while preserving relay dependability. The proposed framework is evaluated against a broad set of state-of-the-art machine learning and deep learning baselines under nominal conditions, complex cyberattack scenarios, and measurement noise. Our results show that LLM-based detectors achieve competitive or superior cyberattack detection performance, with DistilBERT detecting up to 97.62% of attacks while maintaining perfect fault detection accuracy. Additional evaluations demonstrate robustness to prompt formulation variations, resilience under combined time-synchronization and false-data injection attacks, and stable performance under realistic measurement noise levels. The attention mechanisms of LLMs further enable intrinsic interpretability by highlighting the most influential time-phase regions of relay measurements. These results demonstrate that compact LLMs provide a practical, interpretable, and robust solution for enhancing cyberattack detection in modern digital substations. We provide the full dataset used in this study for reproducibility.</description>
      <guid isPermaLink="false">oai:arXiv.org:2601.04443v2</guid>
      <category>cs.CR</category>
      <category>cs.LG</category>
      <category>eess.SP</category>
      <pubDate>Fri, 30 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Ahmad Mohammad Saber, Saeed Jafari, Zhengmao Ouyang, Paul Budnarain, Amr Youssef, Deepa Kundur</dc:creator>
    </item>
  </channel>
</rss>
