<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>cs.GT updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/cs.GT</link>
    <description>cs.GT updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/cs.GT" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Mon, 01 Apr 2024 04:00:15 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Mon, 01 Apr 2024 00:00:00 -0400</pubDate>
    <skipDays>
      <day>Sunday</day>
      <day>Saturday</day>
    </skipDays>
    <item>
      <title>TASR: A Novel Trust-Aware Stackelberg Routing Algorithm to Mitigate Traffic Congestion</title>
      <link>https://arxiv.org/abs/2403.19831</link>
      <description>arXiv:2403.19831v1 Announce Type: new 
Abstract: Stackelberg routing platforms (SRP) reduce congestion in one-shot traffic networks by proposing optimal route recommendations to selfish travelers. Traditionally, Stackelberg routing is cast as a partial control problem where a fraction of traveler flow complies with route recommendations, while the remaining respond as selfish travelers. In this paper, a novel Stackelberg routing framework is formulated where the agents exhibit \emph{probabilistic compliance} by accepting SRP's route recommendations with a \emph{trust} probability. A greedy \emph{\textbf{T}rust-\textbf{A}ware \textbf{S}tackelberg \textbf{R}outing} algorithm (in short, TASR) is proposed for SRP to compute unique path recommendations to each traveler flow with a unique demand. Simulation experiments are designed with random travel demands with diverse trust values on real road networks such as Sioux Falls, Chicago Sketch, and Sydney networks for both single-commodity and multi-commodity flows. The performance of TASR is compared with state-of-the-art Stackelberg routing methods in terms of traffic congestion and trust dynamics over repeated interaction between the SRP and the travelers. Results show that TASR improves network congestion without causing a significant reduction in trust towards the SRP, when compared to most well-known Stackelberg routing strategies.</description>
      <guid isPermaLink="false">oai:arXiv.org:2403.19831v1</guid>
      <category>cs.GT</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Doris E. M. Brown, Venkata Sriram Siddhardh Nadendla, Sajal K. Das</dc:creator>
    </item>
    <item>
      <title>Regular Games with Imperfect Information Are Not That Regular</title>
      <link>https://arxiv.org/abs/2403.20133</link>
      <description>arXiv:2403.20133v1 Announce Type: new 
Abstract: We consider two-player games with imperfect information and the synthesis of a randomized strategy for one player that ensures the objective is satisfied almost-surely (i.e., with probability 1), regardless of the strategy of the other player. Imperfect information is modeled by an indistinguishability relation %that describing the pairs of histories that the first player cannot distinguish, a generalization of the traditional model with partial observations. The game is regular if it admits a regular function whose kernel commutes with the indistinguishability relation.
  The synthesis of pure strategies that ensure all possible outcomes satisfy the objective is possible in regular games, by a generic reduction that holds for all objectives. While the solution for pure strategies extends to randomized strategies in the traditional model with partial observations (which is always regular), we show that a similar reduction does not exist in the more general model. Despite that, we show that in regular games with Buechi objectives the synthesis problem is decidable for randomized strategies that ensure the outcome satisfies the objective almost-surely.</description>
      <guid isPermaLink="false">oai:arXiv.org:2403.20133v1</guid>
      <category>cs.GT</category>
      <category>cs.LO</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Laurent Doyen, Thomas Soullard</dc:creator>
    </item>
    <item>
      <title>Existence and Verification of Nash Equilibria in Non-Cooperative Contribution Games with Resource Contention</title>
      <link>https://arxiv.org/abs/2403.20161</link>
      <description>arXiv:2403.20161v1 Announce Type: new 
Abstract: In resource contribution games, a class of non-cooperative games, the players want to obtain a bundle of resources and are endowed with bags of bundles of resources that they can make available into a common for all to enjoy. Available resources can then be used towards their private goals. A player is potentially satisfied with a profile of contributed resources when his bundle could be extracted from the contributed resources. Resource contention occurs when the players who are potentially satisfied, cannot actually all obtain their bundle. The player's preferences are always single-minded (they consider a profile good or they do not) and parsimonious (between two profiles that are equally good, they prefer the profile where they contribute less). What makes a profile of contributed resources good for a player depends on their attitude towards resource contention. We study the problem of deciding whether an outcome is a pure Nash equilibrium for three kinds of players' attitudes towards resource contention: public contention-aversity, private contention-aversity, and contention-tolerance. In particular, we demonstrate that in the general case when the players are contention-averse, then the problem is harder than when they are contention-tolerant. We then identify a natural class of games where, in presence of contention-averse preferences, it becomes tractable, and where there is always a Nash equilibrium.</description>
      <guid isPermaLink="false">oai:arXiv.org:2403.20161v1</guid>
      <category>cs.GT</category>
      <category>cs.MA</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <arxiv:DOI>10.1007/s10472-023-09905-7</arxiv:DOI>
      <dc:creator>Nicolas Troquard</dc:creator>
    </item>
    <item>
      <title>Computing a Fixed Point of Contraction Maps in Polynomial Queries</title>
      <link>https://arxiv.org/abs/2403.19911</link>
      <description>arXiv:2403.19911v1 Announce Type: cross 
Abstract: We give an algorithm for finding an $\epsilon$-fixed point of a contraction map $f:[0,1]^k\mapsto[0,1]^k$ under the $\ell_\infty$-norm with query complexity $O (k^2\log (1/\epsilon ) )$.</description>
      <guid isPermaLink="false">oai:arXiv.org:2403.19911v1</guid>
      <category>cs.CC</category>
      <category>cs.DS</category>
      <category>cs.GT</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Xi Chen, Yuhao Li, Mihalis Yannakakis</dc:creator>
    </item>
    <item>
      <title>The Power of Two-sided Recruitment in Two-sided Markets</title>
      <link>https://arxiv.org/abs/2307.03844</link>
      <description>arXiv:2307.03844v2 Announce Type: replace 
Abstract: We consider the problem of maximizing the gains from trade (GFT) in two-sided markets. The seminal impossibility result by Myerson and Satterthwaite shows that even for bilateral trade, there is no individually rational (IR), Bayesian incentive compatible (BIC) and budget balanced (BB) mechanism that can achieve the full GFT. Moreover, the optimal BIC, IR and BB mechanism that maximizes the GFT is known to be complex and heavily depends on the prior. In this paper, we pursue a Bulow-Klemperer-style question, i.e., does augmentation allow for prior-independent mechanisms to compete against the optimal mechanism? Our first main result shows that in the double auction setting with $m$ i.i.d. buyers and $n$ i.i.d. sellers, by augmenting $O(1)$ buyers and sellers to the market, the GFT of a simple, dominant strategy incentive compatible (DSIC), and prior-independent mechanism in the augmented market is at least the optimal in the original market, when the buyers' distribution first-order stochastically dominates the sellers' distribution. Next, we go beyond the i.i.d. setting and study the power of two-sided recruitment in more general markets. Our second main result is that for any $\epsilon &gt; 0$ and any set of $O(1/\epsilon)$ buyers and sellers where the buyers' value exceeds the sellers' value with constant probability, if we add these additional agents into any market with arbitrary correlations, the Trade Reduction mechanism obtains a $(1-\epsilon)$-approximation of the GFT of the augmented market. Importantly, the newly recruited agents are agnostic to the original market.</description>
      <guid isPermaLink="false">oai:arXiv.org:2307.03844v2</guid>
      <category>cs.GT</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Yang Cai, Christopher Liaw, Aranyak Mehta, Mingfei Zhao</dc:creator>
    </item>
    <item>
      <title>Socially Optimal Energy Usage via Adaptive Pricing</title>
      <link>https://arxiv.org/abs/2310.13254</link>
      <description>arXiv:2310.13254v2 Announce Type: replace 
Abstract: A central challenge in using price signals to coordinate the electricity consumption of a group of users is the operator's lack of knowledge of the users due to privacy concerns. In this paper, we develop a two-time-scale incentive mechanism that alternately updates between the users and a system operator. As long as the users can optimize their own consumption subject to a given price, the operator does not need to know or attempt to learn any private information of the users for price design. Users adjust their consumption following the price and the system redesigns the price based on the users' consumption. We show that under mild assumptions, this iterative process converges to the social welfare solution. In particular, the cost of the users need not always be convex and its consumption can be the output of a machine learning-based load control algorithm.</description>
      <guid isPermaLink="false">oai:arXiv.org:2310.13254v2</guid>
      <category>cs.GT</category>
      <category>cs.SY</category>
      <category>eess.SY</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Jiayi Li, Matthew Motoki, Baosen Zhang</dc:creator>
    </item>
    <item>
      <title>Adaptive, Doubly Optimal No-Regret Learning in Strongly Monotone and Exp-Concave Games with Gradient Feedback</title>
      <link>https://arxiv.org/abs/2310.14085</link>
      <description>arXiv:2310.14085v4 Announce Type: replace 
Abstract: Online gradient descent (OGD) is well known to be doubly optimal under strong convexity or monotonicity assumptions: (1) in the single-agent setting, it achieves an optimal regret of $\Theta(\log T)$ for strongly convex cost functions; and (2) in the multi-agent setting of strongly monotone games, with each agent employing OGD, we obtain last-iterate convergence of the joint action to a unique Nash equilibrium at an optimal rate of $\Theta(\frac{1}{T})$. While these finite-time guarantees highlight its merits, OGD has the drawback that it requires knowing the strong convexity/monotonicity parameters. In this paper, we design a fully adaptive OGD algorithm, \textsf{AdaOGD}, that does not require a priori knowledge of these parameters. In the single-agent setting, our algorithm achieves $O(\log^2(T))$ regret under strong convexity, which is optimal up to a log factor. Further, if each agent employs \textsf{AdaOGD} in strongly monotone games, the joint action converges in a last-iterate sense to a unique Nash equilibrium at a rate of $O(\frac{\log^3 T}{T})$, again optimal up to log factors. We illustrate our algorithms in a learning version of the classical newsvendor problem, where due to lost sales, only (noisy) gradient feedback can be observed. Our results immediately yield the first feasible and near-optimal algorithm for both the single-retailer and multi-retailer settings. We also extend our results to the more general setting of exp-concave cost functions and games, using the online Newton step (ONS) algorithm.</description>
      <guid isPermaLink="false">oai:arXiv.org:2310.14085v4</guid>
      <category>cs.GT</category>
      <category>cs.LG</category>
      <category>math.OC</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Michael I. Jordan, Tianyi Lin, Zhengyuan Zhou</dc:creator>
    </item>
    <item>
      <title>Complexity of Manipulation and Bribery in Premise-Based Judgment Aggregation with Simple Formulas</title>
      <link>https://arxiv.org/abs/2402.16016</link>
      <description>arXiv:2402.16016v2 Announce Type: replace 
Abstract: Judgment aggregation is a framework to aggregate individual opinions on multiple, logically connected issues into a collective outcome. These opinions are cast by judges, which can be for example referees, experts, advisors or jurors, depending on the application and context. It is open to manipulative attacks such as \textsc{Manipulation} where judges cast their judgments strategically. Previous works have shown that most computational problems corresponding to these manipulative attacks are \NP-hard. This desired computational barrier, however, often relies on formulas that are either of unbounded size or of complex structure.
  We revisit the computational complexity for various \textsc{Manipulation} and \textsc{Bribery} problems in premise-based judgment aggregation, now focusing on simple and realistic formulas. We restrict all formulas to be clauses that are (positive) monotone, Horn-clauses, or have bounded length. For basic variants of \textsc{Manipulation}, we show that these restrictions make several variants, which were in general known to be \NP-hard, polynomial-time solvable. Moreover, we provide a P vs.\ NP dichotomy for a large class of clause restrictions (generalizing monotone and Horn clauses) by showing a close relationship between variants of \textsc{Manipulation} and variants of \textsc{Satisfiability}. For Hamming distance based \textsc{Manipulation}, we show that \NP-hardness even holds for positive monotone clauses of length three, but the problem becomes polynomial-time solvable for positive monotone clauses of length two. For \textsc{Bribery}, we show that \NP-hardness even holds for positive monotone clauses of length two, but it becomes polynomial-time solvable for the same clause set if there is a constant budget.</description>
      <guid isPermaLink="false">oai:arXiv.org:2402.16016v2</guid>
      <category>cs.GT</category>
      <category>cs.CC</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <arxiv:DOI>10.1016/j.ic.2023.105128</arxiv:DOI>
      <arxiv:journal_reference>Information and Computation, 2024, 296: 105128</arxiv:journal_reference>
      <dc:creator>Robert Bredereck, Junjie Luo</dc:creator>
    </item>
    <item>
      <title>Doubly Optimal No-Regret Online Learning in Strongly Monotone Games with Bandit Feedback</title>
      <link>https://arxiv.org/abs/2112.02856</link>
      <description>arXiv:2112.02856v4 Announce Type: replace-cross 
Abstract: We consider online no-regret learning in unknown games with bandit feedback, where each player can only observe its reward at each time -- determined by all players' current joint action -- rather than its gradient. We focus on the class of \textit{smooth and strongly monotone} games and study optimal no-regret learning therein. Leveraging self-concordant barrier functions, we first construct a new bandit learning algorithm and show that it achieves the single-agent optimal regret of $\tilde{\Theta}(n\sqrt{T})$ under smooth and strongly concave reward functions ($n \geq 1$ is the problem dimension). We then show that if each player applies this no-regret learning algorithm in strongly monotone games, the joint action converges in the \textit{last iterate} to the unique Nash equilibrium at a rate of $\tilde{\Theta}(nT^{-1/2})$. Prior to our work, the best-known convergence rate in the same class of games is $\tilde{O}(n^{2/3}T^{-1/3})$ (achieved by a different algorithm), thus leaving open the problem of optimal no-regret learning algorithms (since the known lower bound is $\Omega(nT^{-1/2})$). Our results thus settle this open problem and contribute to the broad landscape of bandit game-theoretical learning by identifying the first doubly optimal bandit learning algorithm, in that it achieves (up to log factors) both optimal regret in the single-agent learning and optimal last-iterate convergence rate in the multi-agent learning. We also present preliminary numerical results on several application problems to demonstrate the efficacy of our algorithm in terms of iteration count.</description>
      <guid isPermaLink="false">oai:arXiv.org:2112.02856v4</guid>
      <category>cs.LG</category>
      <category>cs.GT</category>
      <category>math.OC</category>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Wenjia Ba, Tianyi Lin, Jiawei Zhang, Zhengyuan Zhou</dc:creator>
    </item>
  </channel>
</rss>
