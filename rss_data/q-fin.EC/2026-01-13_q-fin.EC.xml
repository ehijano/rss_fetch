<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>q-fin.EC updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/q-fin.EC</link>
    <description>q-fin.EC updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/q-fin.EC" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Tue, 13 Jan 2026 05:02:18 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Tue, 13 Jan 2026 00:00:00 -0500</pubDate>
    <skipDays>
      <day>Sunday</day>
      <day>Saturday</day>
    </skipDays>
    <item>
      <title>Resolving the automation paradox: falling labor share, rising wages</title>
      <link>https://arxiv.org/abs/2601.06343</link>
      <description>arXiv:2601.06343v1 Announce Type: new 
Abstract: A central socioeconomic concern about Artificial Intelligence is that it will lower wages by depressing the labor share - the fraction of economic output paid to labor. We show that declining labor share is more likely to raise wages. In a competitive economy with constant returns to scale, we prove that the wage-maximizing labor share depends only on the capital-to-labor ratio, implying a non-monotonic relationship between labor share and wages. When labor share exceeds this wage-maximizing level, further automation increases wages even while reducing labor's output share. Using data from the United States and eleven other industrialized countries, we estimate that labor share is too high in all twelve, implying that further automation should raise wages. Moreover, we find that falling labor share accounted for 16\% of U.S. real wage growth between 1954 and 2019. These wage gains notwithstanding, automation-driven shifts in labor share are likely to pose significant social and political challenges.</description>
      <guid isPermaLink="false">oai:arXiv.org:2601.06343v1</guid>
      <category>econ.GN</category>
      <category>q-fin.EC</category>
      <pubDate>Tue, 13 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>David Autor, B. N. Kausik</dc:creator>
    </item>
    <item>
      <title>Modelling Distributional Impacts of Carbon Taxation: a Systematic Review and Meta-Analysis</title>
      <link>https://arxiv.org/abs/2601.07713</link>
      <description>arXiv:2601.07713v1 Announce Type: new 
Abstract: Carbon taxes are increasingly popular among policymakers but remain politically contentious. A key challenge relates to their distributional impacts; the extent to which tax burdens differ across population groups. As a response, a growing number of studies analyse their distributional impact ex-ante, commonly relying on microsimulation models. However, distributional impact estimates differ across models due to differences in simulated tax designs, assumptions, modelled components, data sources, and outcome metrics. This study comprehensively reviews methodological choices made in constructing microsimulation models designed to simulate the impacts of carbon taxation and discusses how these choices affect the interpretation of results. It conducts a meta-analysis to assess the influence of modelling choices on distributional impact estimates by estimating a probit model on a sample of 217 estimates across 71 countries. The literature review highlights substantial diversity in modelling choices, with no standard practice emerging. The meta-analysis shows that studies modelling carbon taxes on imported emissions are significantly less likely to find regressive results, while indirect emission coverage has ambiguous effects on regressivity, suggesting that a carbon border adjustment mechanism may reduce carbon tax regressivity. Further, we find that estimates using older datasets, using explicit tax progressivity or income inequality measures, and accounting for household behaviour are associated with a lower likelihood of finding regressive estimates, while the inclusion of general equilibrium effects increases this likelihood.</description>
      <guid isPermaLink="false">oai:arXiv.org:2601.07713v1</guid>
      <category>econ.GN</category>
      <category>q-fin.EC</category>
      <pubDate>Tue, 13 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Jules Linden, Cathal O'Donoghue, Denisa Sologon</dc:creator>
    </item>
    <item>
      <title>Who sets the range? Funding mechanics and 4h context in crypto markets</title>
      <link>https://arxiv.org/abs/2601.06084</link>
      <description>arXiv:2601.06084v1 Announce Type: cross 
Abstract: Financial markets often appear chaotic, yet ranges are rarely accidental. They emerge from structured interactions between market context and capital conditions. The four-hour timeframe provides a critical lens for observing this equilibrium zone where institutional positioning, leveraged exposure, and liquidity management converge. Funding mechanisms, especially in perpetual futures, act as disciplinary forces that regulate trader behavior, impose economic costs, and shape directional commitment. When funding aligns with the prevailing 4H context, price expansion becomes possible; when it diverges, compression and range-bound behavior dominate. Ranges therefore represent controlled balance rather than indecision, reflecting strategic positioning by informed participants. Understanding how 4H context and funding operate as market governors is essential for interpreting cryptocurrency price action as a rational, power-mediated process.</description>
      <guid isPermaLink="false">oai:arXiv.org:2601.06084v1</guid>
      <category>q-fin.GN</category>
      <category>econ.GN</category>
      <category>q-fin.EC</category>
      <pubDate>Tue, 13 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Habib Badawi, Mohamed Hani, Taufikin Taufikin</dc:creator>
    </item>
    <item>
      <title>Managing Situations of Complexity and Uncertainty : The Contribution of Research and Development</title>
      <link>https://arxiv.org/abs/2601.06203</link>
      <description>arXiv:2601.06203v1 Announce Type: cross 
Abstract: The second industrial revolution saw the development of management methods tailored to the challenges of the times: firstly, the need for mass production, and then, the pursuit of improved quality and customer satisfaction, followed by a push to improve operational performances in response to market globalization. If these approaches were initially inspired by rational mechanistic thinking, they have since gradually broadened to integrate other dimensions such as psychology, sociology and systemic analysis. Business enterprises underwent a profound rethink in the 1990s introducing increasingly refined modi operandi, only to find their environment disrupted by the appearance of two new parameters: complexity and uncertainty. Enterprises of the third industrial revolution were able to integrate these parameters at the outset, introducing new styles of management. However, these may well be deficient with regard to activities where an error may be fatal, or a failure intolerable. Caught between the precautionary principle and the principle of experimentation, the third industrial revolution falters to find the right approach, whereas the fourth industrial revolution is almost already upon us, bringing its lot of upheavals. In this regard, faced with increasing complexities and uncertainties, Research and Development is of particular interest since its vocation consists precisely in confronting the complex and the uncertain. This article examines the fundamental principles of the R&amp;D process, and analyses how these may act as a benchmark for contemporary management by providing sources of inspiration.</description>
      <guid isPermaLink="false">oai:arXiv.org:2601.06203v1</guid>
      <category>physics.soc-ph</category>
      <category>econ.GN</category>
      <category>q-fin.EC</category>
      <pubDate>Tue, 13 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <arxiv:journal_reference>Jitipee 2018 (in French)</arxiv:journal_reference>
      <dc:creator>Brunet Luc E., Longc\^ot\'e \'Eric</dc:creator>
    </item>
    <item>
      <title>Evaluating Impacts of Traffic Regulations in Complex Mobility Systems Using Scenario-Based Simulations</title>
      <link>https://arxiv.org/abs/2601.07735</link>
      <description>arXiv:2601.07735v1 Announce Type: cross 
Abstract: Urban traffic regulation policies are increasingly used to address congestion, emissions, and accessibility in cities, yet their impacts are difficult to assess due to the socio-technical complexity of urban mobility systems. Recent advances in data availability and computational power enable new forms of model-driven, simulation-based decision support for transportation policy design. This paper proposes a novel simulation paradigm for the ex-ante evaluation of both direct impacts (e.g., traffic conditions, modal shift, emissions) and indirect impacts spanning transportation-related effects, social equity, and economic accessibility. The approach integrates a multi-layer urban mobility model combining a physical layer of networks, flows, and emissions with a social layer capturing behavioral responses and adaptation to policy changes. Real-world data are used to instantiate the current "as-is" scenario, while policy alternatives and behavioral assumptions are encoded as model parameters to generate multiple "what-if" scenarios. The framework supports systematic comparison across scenarios by analyzing variations in simulated outcomes induced by policy interventions. The proposed approach is illustrated through a case study aims to assess the impacts of the introduction of broad urban traffic restriction schemes. Results demonstrate the framework's ability to explore alternative regulatory designs and user responses, supporting informed and anticipatory evaluation of urban traffic policies.</description>
      <guid isPermaLink="false">oai:arXiv.org:2601.07735v1</guid>
      <category>cs.CY</category>
      <category>cs.CE</category>
      <category>econ.GN</category>
      <category>q-fin.EC</category>
      <pubDate>Tue, 13 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Arianna Burzacchi, Marco Pistore</dc:creator>
    </item>
    <item>
      <title>Regulation and Frontier Housing Supply</title>
      <link>https://arxiv.org/abs/2208.01969</link>
      <description>arXiv:2208.01969v5 Announce Type: replace 
Abstract: Regulation is a major driver of housing supply, yet often difficult to observe directly. This paper estimates frontier cost, the non-land cost of producing housing absent regulation, and regulatory tax, which quantifies regulation in money terms. Working within an urban environment of multi-floor, multi-family housing and using only apartment prices and building heights, we show that the frontier is identified from the support of supply and demand shocks without recourse to instrumental variables. In an application to new Israeli residential construction, and accounting for random housing quality, the estimated mean regulatory tax is 48% of housing prices, with substantial variation across locations. The regulatory tax is positively correlated with centrality, density, and prices. We construct a lower bound for the regulatory tax that allows quality to differ systematically over location and time, by assuming (weak) complementarity between quality and demand. At the end of our sample, when prices are highest and our bound is most informative, we bound the regulatory tax between 40% (using a 2km radius) and 53%.</description>
      <guid isPermaLink="false">oai:arXiv.org:2208.01969v5</guid>
      <category>econ.GN</category>
      <category>q-fin.EC</category>
      <pubDate>Tue, 13 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Dan Ben-Moshe, David Genesove</dc:creator>
    </item>
    <item>
      <title>New Compensating and Equivalent Variation Closed-form Solutions for Non-Separable Public Goods</title>
      <link>https://arxiv.org/abs/2401.15493</link>
      <description>arXiv:2401.15493v3 Announce Type: replace 
Abstract: This study finds exact closed-form solutions for compensating variation (CV) and equivalent variation (EV) for both marginal and non-marginal changes in public goods given homothetic, but non-separable, utility where a single sufficient statistic summarizes consumer preferences. The closed-form CV and EV expressions identify three economic mechanisms that determine magnitudes. One of these mechanisms, the relative preference effect, helps explain the disparity between willingness to pay (WTP) and willingness to accept (WTA) for public goods. We also show how our closed-form solutions can be employed to calculate WTP and WTA across income groups using estimates from existing empirical studies.</description>
      <guid isPermaLink="false">oai:arXiv.org:2401.15493v3</guid>
      <category>econ.GN</category>
      <category>q-fin.EC</category>
      <pubDate>Tue, 13 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Daniel H. Karney, Khyati Malik</dc:creator>
    </item>
    <item>
      <title>On Causal Inference with Model-Based Outcomes</title>
      <link>https://arxiv.org/abs/2403.19563</link>
      <description>arXiv:2403.19563v5 Announce Type: replace 
Abstract: We study the estimation of causal effects on group-level parameters identified from microdata (e.g., child penalties). We demonstrate that standard one-step methods (such as pooled OLS and IV regressions) are generally inconsistent due to an endogenous weighting bias, where the policy affects the implicit weights (e.g., altering fertility rates). In contrast, we advocate for a two-step Minimum Distance (MD) framework that explicitly separates parameter identification from policy evaluation. This approach eliminates the endogenous weighting bias and requires explicitly confronting sample selection when groups are small, thereby improving transparency. We show that the MD estimator performs well when parameters can be estimated for most groups, and propose a robust alternative that uses auxiliary information in settings with limited data. To illustrate the importance of this methodological choice, we evaluate the effect of the 2005 Dutch childcare reform on child penalties and find that the conventional one-step approach yields estimates that are substantially larger than those from the two-step method.</description>
      <guid isPermaLink="false">oai:arXiv.org:2403.19563v5</guid>
      <category>econ.GN</category>
      <category>q-fin.EC</category>
      <pubDate>Tue, 13 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Dmitry Arkhangelsky, Kazuharu Yanagimoto, Tom Zohar</dc:creator>
    </item>
    <item>
      <title>Simulation in discrete choice models evaluation: SDCM, a simulation tool for performance evaluation of DCMs</title>
      <link>https://arxiv.org/abs/2407.17014</link>
      <description>arXiv:2407.17014v3 Announce Type: replace 
Abstract: Discrete choice models (DCMs) have been widely utilized in various scientific fields, especially economics, for many years. These models consider a stochastic environment influencing each decision maker's choices. Extensive research has shown that the agents' socioeconomic characteristics, the chosen options' properties, and the conditions characterizing the decision-making environment all impact these models. However, the complex interactions between these factors, confidentiality concerns, time constraints, and costs, have made real experimentation impractical and undesirable. To address this, simulations have gained significant popularity among academics, allowing the study of these models in a controlled setting using simulated data. This paper presents multidisciplinary research to bridge the gap between DCMs, experimental design, and simulation. By reviewing related literature, the authors explore these interconnected areas. We then introduce a simulation method integrated with experimental design to generate synthetic data based on behavioral models of agents. A utility function is used to describe the developed simulation tool. The paper investigates the discrepancy between simulated data and real-world data.</description>
      <guid isPermaLink="false">oai:arXiv.org:2407.17014v3</guid>
      <category>econ.GN</category>
      <category>q-fin.EC</category>
      <pubDate>Tue, 13 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Amirreza Talebi</dc:creator>
    </item>
    <item>
      <title>Floods do not sink prices, historical memory does: How flood risk impacts the Italian housing market</title>
      <link>https://arxiv.org/abs/2502.12116</link>
      <description>arXiv:2502.12116v3 Announce Type: replace 
Abstract: Do home prices incorporate flood risk in the immediate aftermath of specific flood events, or is it the repeated exposure over the years that plays a more significant role? We address this question through the first systematic study of the Italian housing market, which is an ideal case study because it is highly exposed to floods, though unevenly distributed across the national territory. Using a novel dataset containing about 550,000 mortgage-financed transactions between 2016 and 2024, as well as hedonic regressions and a difference-in-difference design, we find that: (i) specific floods do not decrease home prices in areas at risk; (ii) the repeated exposure to floods in flood-prone areas leads to a price decline, up to 4\% in the most frequently flooded regions; (iii) responses are heterogeneous by buyers' income and age. Young buyers (with limited exposure to prior floods) do not obtain any price reduction for settling in risky areas, while experienced buyers do. At the same time, buyers who settle in risky areas have lower incomes than buyers in safe areas in the most affected regions. Our results emphasize the importance of cultural and institutional factors in understanding how flood risk affects the housing market and socioeconomic outcomes.</description>
      <guid isPermaLink="false">oai:arXiv.org:2502.12116v3</guid>
      <category>econ.GN</category>
      <category>q-fin.EC</category>
      <pubDate>Tue, 13 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Anna Bellaver, Lorenzo Costantini, Ariadna Fosch, Anna Monticelli, David Scala, Marco Pangallo</dc:creator>
    </item>
    <item>
      <title>The heterogeneous causal effects of the EU's Cohesion Fund</title>
      <link>https://arxiv.org/abs/2504.13223</link>
      <description>arXiv:2504.13223v2 Announce Type: replace 
Abstract: This paper estimates the causal effect of EU cohesion policy on regional output and investment, focusing on the Cohesion Fund (CF), a comparatively understudied instrument. Departing from standard approaches such as regression discontinuity (RDD) and instrumental variables (IV), we use a recently developed causal inference method based on matrix completion within a factor model framework. This yields a new framework to evaluate the CF and to characterize the time-varying distribution of its causal effects across EU regions, along with distributional metrics relevant for policy assessment. Our results show that average treatment effects conceal substantial heterogeneity and may lead to misleading conclusions about policy effectiveness. The CF's impact is front-loaded, peaking within the first seven years after a region's initial inclusion. During this first seven-year funding cycle, the distribution of effects is right-skewed with relatively thick tails, indicating generally positive but uneven gains across regions. Effects are larger for regions that are relatively poorer at baseline, and we find a non-linear, diminishing-returns relationship: beyond a threshold, the impact declines as the ratio of CF receipts to regional gross value added (GVA) increases.</description>
      <guid isPermaLink="false">oai:arXiv.org:2504.13223v2</guid>
      <category>econ.GN</category>
      <category>econ.EM</category>
      <category>q-fin.EC</category>
      <pubDate>Tue, 13 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Angelos Alexopoulos, Ilias Kostarakos, Christos Mylonakis, Petros Varthalitis</dc:creator>
    </item>
    <item>
      <title>Quantile Selection in the Gender Pay Gap</title>
      <link>https://arxiv.org/abs/2511.16187</link>
      <description>arXiv:2511.16187v2 Announce Type: replace-cross 
Abstract: We propose a new approach to estimate selection-corrected quantiles of the gender wage gap. Our method employs instrumental variables that explain variation in the latent variable but, conditional on the latent process, do not directly affect selection. We provide semiparametric identification of the quantile parameters without imposing parametric restrictions on the selection probability, derive the asymptotic distribution of the proposed estimator based on constrained selection probability weighting, and demonstrate how the approach applies to the Roy model of labor supply. Using German administrative data, we analyze the distribution of the gender gap in full-time earnings. We find pronounced positive selection among women at the lower end, especially those with less education, which widens the gender gap in this segment, and strong positive selection among highly educated men at the top, which narrows the gender wage gap at upper quantiles.</description>
      <guid isPermaLink="false">oai:arXiv.org:2511.16187v2</guid>
      <category>econ.EM</category>
      <category>econ.GN</category>
      <category>q-fin.EC</category>
      <pubDate>Tue, 13 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Egshiglen Batbayar, Christoph Breunig, Peter Haan, Boryana Ilieva</dc:creator>
    </item>
  </channel>
</rss>
