<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>physics.data-an updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/physics.data-an</link>
    <description>physics.data-an updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/physics.data-an" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Fri, 23 Aug 2024 01:36:11 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Thu, 22 Aug 2024 00:00:00 -0400</pubDate>
    <skipDays>
      <day>Sunday</day>
      <day>Saturday</day>
    </skipDays>
    <item>
      <title>A short introduction to Neural Networks and their application to Earth and Materials Science Science</title>
      <link>https://arxiv.org/abs/2408.11395</link>
      <description>arXiv:2408.11395v1 Announce Type: new 
Abstract: Neural networks are gaining widespread relevance for their versatility, holding the promise to yield a significant methodological shift in different domain of applied research. Here, we provide a simple pedagogical account of the basic functioning of a feedforward neural network. Then we move forward to reviewing two recent applications of machine learning to Earth and Materials Science. We will in particular begin by discussing a neural network based geothermobarometer, which returns reliable predictions of the pressure/temperature conditions of magma storage. Further, we will turn to illustrate how machine learning tools, tested on the list of minerals from the International Mineralogical Association, can help in the search for novel superconducting materials.</description>
      <guid isPermaLink="false">oai:arXiv.org:2408.11395v1</guid>
      <category>physics.data-an</category>
      <category>cond-mat.dis-nn</category>
      <category>cond-mat.mtrl-sci</category>
      <category>physics.geo-ph</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Duccio Fanelli, Luca Bindi, Lorenzo Chicchi, Claudio Pereti, Roberta Sessoli, Simone Tommasini</dc:creator>
    </item>
    <item>
      <title>Statistical Patterns in the Equations of Physics and the Emergence of a Meta-Law of Nature</title>
      <link>https://arxiv.org/abs/2408.11065</link>
      <description>arXiv:2408.11065v1 Announce Type: cross 
Abstract: Physics, as a fundamental science, aims to understand the laws of Nature and describe them in mathematical equations. While the physical reality manifests itself in a wide range of phenomena with varying levels of complexity, the equations that describe them display certain statistical regularities and patterns, which we begin to explore here. By drawing inspiration from linguistics, where Zipf's law states that the frequency of any word in a large corpus of text is roughly inversely proportional to its rank in the frequency table, we investigate whether similar patterns for the distribution of operators emerge in the equations of physics. We analyse three corpora of formulae and find, using sophisticated implicit-likelihood methods, that the frequency of operators as a function of their rank in the frequency table is best described by an exponential law with a stable exponent, in contrast with Zipf's inverse power-law. Understanding the underlying reasons behind this statistical pattern may shed light on Nature's modus operandi or reveal recurrent patterns in physicists' attempts to formalise the laws of Nature. It may also provide crucial input for symbolic regression, potentially augmenting language models to generate symbolic models for physical phenomena. By pioneering the study of statistical regularities in the equations of physics, our results open the door for a meta-law of Nature, a (probabilistic) law that all physical laws obey.</description>
      <guid isPermaLink="false">oai:arXiv.org:2408.11065v1</guid>
      <category>physics.soc-ph</category>
      <category>cs.CL</category>
      <category>hep-th</category>
      <category>physics.data-an</category>
      <category>physics.hist-ph</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Andrei Constantin, Deaglan Bartlett, Harry Desmond, Pedro G. Ferreira</dc:creator>
    </item>
    <item>
      <title>Active Learning of Molecular Data for Task-Specific Objectives</title>
      <link>https://arxiv.org/abs/2408.11191</link>
      <description>arXiv:2408.11191v1 Announce Type: cross 
Abstract: Active learning (AL) has shown promise for being a particularly data-efficient machine learning approach. Yet, its performance depends on the application and it is not clear when AL practitioners can expect computational savings. Here, we carry out a systematic AL performance assessment for three diverse molecular datasets and two common scientific tasks: compiling compact, informative datasets and targeted molecular searches. We implemented AL with Gaussian processes (GP) and used the many-body tensor as molecular representation. For the first task, we tested different data acquisition strategies, batch sizes and GP noise settings. AL was insensitive to the acquisition batch size and we observed the best AL performance for the acquisition strategy that combines uncertainty reduction with clustering to promote diversity. However, for optimal GP noise settings, AL did not outperform randomized selection of data points. Conversely, for targeted searches, AL outperformed random sampling and achieved data savings up to 64%. Our analysis provides insight into this task-specific performance difference in terms of target distributions and data collection strategies. We established that the performance of AL depends on the relative distribution of the target molecules in comparison to the total dataset distribution, with the largest computational savings achieved when their overlap is minimal.</description>
      <guid isPermaLink="false">oai:arXiv.org:2408.11191v1</guid>
      <category>cs.LG</category>
      <category>physics.data-an</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Kunal Ghosh, Milica Todorovi\'c, Aki Vehtari, Patrick Rinke</dc:creator>
    </item>
    <item>
      <title>Probability-turbulence divergence: A tunable allotaxonometric instrument for comparing heavy-tailed categorical distributions</title>
      <link>https://arxiv.org/abs/2008.13078</link>
      <description>arXiv:2008.13078v2 Announce Type: replace-cross 
Abstract: Real-world complex systems often comprise many distinct types of elements as well as many more types of networked interactions between elements. When the relative abundances of types can be measured well, we further observe heavy-tailed categorical distributions for type frequencies. For the comparison of type frequency distributions of two systems or a system with itself at different time points in time -- a facet of allotaxonometry -- a great range of probability divergences are available. Here, we introduce and explore `probability-turbulence divergence', a tunable, straightforward, and interpretable instrument for comparing normalizable categorical frequency distributions. We model probability-turbulence divergence (PTD) after rank-turbulence divergence (RTD). While probability-turbulence divergence is more limited in application than rank-turbulence divergence, it is more sensitive to changes in type frequency. We build allotaxonographs to display probability turbulence, incorporating a way to visually accommodate zero probabilities for `exclusive types' which are types that appear in only one system. We explore comparisons of example distributions taken from literature, social media, and ecology. We show how probability-turbulence divergence either explicitly or functionally generalizes many existing kinds of distances and measures, including, as special cases, $L^{(p)}$ norms, the S{\o}rensen-Dice coefficient (the $F_1$ statistic), and the Hellinger distance. We discuss similarities with the generalized entropies of R{\'e}nyi and Tsallis, and the diversity indices (or Hill numbers) from ecology. We close with thoughts on open problems concerning the optimization of the tuning of rank- and probability-turbulence divergence.</description>
      <guid isPermaLink="false">oai:arXiv.org:2008.13078v2</guid>
      <category>physics.soc-ph</category>
      <category>cs.IR</category>
      <category>physics.data-an</category>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>P. S. Dodds, J. R. Minot, M. V. Arnold, T. Alshaabi, J. L. Adams, A. J. Reagan, C. M. Danforth</dc:creator>
    </item>
    <item>
      <title>Ab initio uncertainty quantification in scattering analysis of microscopy</title>
      <link>https://arxiv.org/abs/2309.02468</link>
      <description>arXiv:2309.02468v3 Announce Type: replace-cross 
Abstract: Estimating parameters from data is a fundamental problem in physics, customarily done by minimizing a loss function between a model and observed statistics. In scattering-based analysis, researchers often employ their domain expertise to select a specific range of wavevectors for analysis, a choice that can vary depending on the specific case. We introduce another paradigm that defines a probabilistic generative model from the beginning of data processing and propagates the uncertainty for parameter estimation, termed ab initio uncertainty quantification (AIUQ). As an illustrative example, we demonstrate this approach with differential dynamic microscopy (DDM) that extracts dynamical information through Fourier analysis at a selected range of wavevectors. We first show that DDM is equivalent to fitting a temporal variogram in the reciprocal space using a latent factor model as the generative model. Then we derive the maximum marginal likelihood estimator, which optimally weighs information at all wavevectors, therefore eliminating the need to select the range of wavevectors. Furthermore, we substantially reduce the computational cost by utilizing the generalized Schur algorithm for Toeplitz covariances without approximation. Simulated studies validate that AIUQ significantly improves estimation accuracy and enables model selection with automated analysis. The utility of AIUQ is also demonstrated by three distinct sets of experiments: first in an isotropic Newtonian fluid, pushing limits of optically dense systems compared to multiple particle tracking; next in a system undergoing a sol-gel transition, automating the determination of gelling points and critical exponent; and lastly, in discerning anisotropic diffusive behavior of colloids in a liquid crystal. These outcomes collectively underscore AIUQ's versatility to capture system dynamics in an efficient and automated manner.</description>
      <guid isPermaLink="false">oai:arXiv.org:2309.02468v3</guid>
      <category>physics.comp-ph</category>
      <category>cond-mat.soft</category>
      <category>physics.data-an</category>
      <category>stat.AP</category>
      <category>stat.ME</category>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Mengyang Gu, Yue He, Xubo Liu, Yimin Luo</dc:creator>
    </item>
    <item>
      <title>Diversity and stylization of the contemporary user-generated visual arts in the complexity-entropy plane</title>
      <link>https://arxiv.org/abs/2408.10356</link>
      <description>arXiv:2408.10356v2 Announce Type: replace-cross 
Abstract: The advent of computational and numerical methods in recent times has provided new avenues for analyzing art historiographical narratives and tracing the evolution of art styles therein. Here, we investigate an evolutionary process underpinning the emergence and stylization of contemporary user-generated visual art styles using the complexity-entropy (C-H) plane, which quantifies local structures in paintings. Informatizing 149,780 images curated in DeviantArt and Behance platforms from 2010 to 2020, we analyze the relationship between local information of the C-H space and multi-level image features generated by a deep neural network and a feature extraction algorithm. The results reveal significant statistical relationships between the C-H information of visual artistic styles and the dissimilarities of the multi-level image features over time within groups of artworks. By disclosing a particular C-H region where the diversity of image representations is noticeably manifested, our analyses reveal an empirical condition of emerging styles that are both novel in the C-H plane and characterized by greater stylistic diversity. Our research shows that visual art analyses combined with physics-inspired methodologies and machine learning, can provide macroscopic insights into quantitatively mapping relevant characteristics of an evolutionary process underpinning the creative stylization of uncharted visual arts of given groups and time.</description>
      <guid isPermaLink="false">oai:arXiv.org:2408.10356v2</guid>
      <category>cs.CV</category>
      <category>physics.data-an</category>
      <category>physics.soc-ph</category>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Seunghwan Kim, Byunghwee Lee, Wonjae Lee</dc:creator>
    </item>
  </channel>
</rss>
