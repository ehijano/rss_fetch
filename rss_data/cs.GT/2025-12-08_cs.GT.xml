<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>cs.GT updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/cs.GT</link>
    <description>cs.GT updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/cs.GT" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Tue, 09 Dec 2025 03:39:08 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Mon, 08 Dec 2025 00:00:00 -0500</pubDate>
    <skipDays>
      <day>Sunday</day>
      <day>Saturday</day>
    </skipDays>
    <item>
      <title>Strategyproof Tournament Rules for Teams with a Constant Degree of Selfishness</title>
      <link>https://arxiv.org/abs/2512.05235</link>
      <description>arXiv:2512.05235v1 Announce Type: new 
Abstract: We revisit the well-studied problem of designing fair and manipulation-resistant tournament rules. In this problem, we seek a mechanism that (probabilistically) identifies the winner of a tournament after observing round-robin play among $n$ teams in a league. Such a mechanism should satisfy the natural properties of monotonicity and Condorcet consistency. Moreover, from the league's perspective, the winner-determination tournament rule should be strategyproof, meaning that no team can do better by losing a game on purpose.
  Past work considered settings in which each team is fully selfish, caring only about its own probability of winning, and settings in which each team is fully selfless, caring only about the total winning probability of itself and the team to which it deliberately loses. More recently, researchers considered a mixture of these two settings with a parameter $\lambda$. Intermediate selfishness $\lambda$ means that a team will not lose on purpose unless its pair gains at least $\lambda s$ winning probability, where $s$ is the individual team's sacrifice from its own winning probability. All of the dozens of previously known tournament rules require $\lambda = \Omega(n)$ to be strategyproof, and it has been an open problem to find such a rule with the smallest $\lambda$.
  In this work, we make significant progress by designing a tournament rule that is strategyproof with $\lambda = 11$. Along the way, we propose a new notion of multiplicative pairwise non-manipulability that ensures that two teams cannot manipulate the outcome of a game to increase the sum of their winning probabilities by more than a multiplicative factor $\delta$ and provide a rule which is multiplicatively pairwise non-manipulable for $\delta = 3.5$.</description>
      <guid isPermaLink="false">oai:arXiv.org:2512.05235v1</guid>
      <category>cs.GT</category>
      <pubDate>Mon, 08 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <dc:creator>David Pennock, Daniel Schoepflin, Kangning Wang</dc:creator>
    </item>
    <item>
      <title>Robust forecast aggregation via additional queries</title>
      <link>https://arxiv.org/abs/2512.05271</link>
      <description>arXiv:2512.05271v1 Announce Type: new 
Abstract: We study the problem of robust forecast aggregation: combining expert forecasts with provable accuracy guarantees compared to the best possible aggregation of the underlying information. Prior work shows strong impossibility results, e.g. that even under natural assumptions, no aggregation of the experts' individual forecasts can outperform simply following a random expert (Neyman and Roughgarden, 2022).
  In this paper, we introduce a more general framework that allows the principal to elicit richer information from experts through structured queries. Our framework ensures that experts will truthfully report their underlying beliefs, and also enables us to define notions of complexity over the difficulty of asking these queries. Under a general model of independent but overlapping expert signals, we show that optimal aggregation is achievable in the worst case with each complexity measure bounded above by the number of agents $n$. We further establish tight tradeoffs between accuracy and query complexity: aggregation error decreases linearly with the number of queries, and vanishes when the "order of reasoning" and number of agents relevant to a query is $\omega(\sqrt{n})$. These results demonstrate that modest extensions to the space of expert queries dramatically strengthen the power of robust forecast aggregation. We therefore expect that our new query framework will open up a fruitful line of research in this area.</description>
      <guid isPermaLink="false">oai:arXiv.org:2512.05271v1</guid>
      <category>cs.GT</category>
      <category>cs.LG</category>
      <pubDate>Mon, 08 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Rafael Frongillo, Mary Monroe, Eric Neyman, Bo Waggoner</dc:creator>
    </item>
    <item>
      <title>Correlation of Rankings in Matching Markets</title>
      <link>https://arxiv.org/abs/2512.05304</link>
      <description>arXiv:2512.05304v1 Announce Type: new 
Abstract: We study the role of correlation in matching markets, where multiple decision-makers simultaneously face selection problems from the same pool of candidates. We propose a model in which a candidate's priority scores across different decision-makers exhibit varying levels of correlation dependent on the candidate's sociodemographic group. Such differential correlation can arise in school choice due to the varying prevalence of selection criteria, in college admissions due to test-optional policies, or due to algorithmic monoculture, that is, when decision-makers rely on the same algorithms and data sets to evaluate candidates. We show that higher correlation for one of the groups generally improves the outcome for all groups, leading to higher efficiency. However, students from a given group are more likely to remain unmatched as their own correlation level increases. This implies that it is advantageous to belong to a low-correlation group. Finally, we extend the tie-breaking literature to multiple priority classes and intermediate levels of correlation. Overall, our results point to differential correlation as a previously overlooked systemic source of group inequalities in school, university, and job admissions.</description>
      <guid isPermaLink="false">oai:arXiv.org:2512.05304v1</guid>
      <category>cs.GT</category>
      <category>physics.soc-ph</category>
      <pubDate>Mon, 08 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <arxiv:DOI>10.1287/mnsc.2024.06067</arxiv:DOI>
      <dc:creator>R\'emi Castera, Patrick Loiseau, Bary S. R. Pradelski</dc:creator>
    </item>
    <item>
      <title>On Dynamic Programming Theory for Leader-Follower Stochastic Games</title>
      <link>https://arxiv.org/abs/2512.05667</link>
      <description>arXiv:2512.05667v1 Announce Type: new 
Abstract: Leader-follower general-sum stochastic games (LF-GSSGs) model sequential decision-making under asymmetric commitment, where a leader commits to a policy and a follower best responds, yielding a strong Stackelberg equilibrium (SSE) with leader-favourable tie-breaking. This paper introduces a dynamic programming (DP) framework that applies Bellman recursion over credible sets-state abstractions formally representing all rational follower best responses under partial leader commitments-to compute SSEs. We first prove that any LF-GSSG admits a lossless reduction to a Markov decision process (MDP) over credible sets. We further establish that synthesising an optimal memoryless deterministic leader policy is NP-hard, motivating the development of {\epsilon}-optimal DP algorithms with provable guarantees on leader exploitability. Experiments on standard mixed-motive benchmarks-including security games, resource allocation, and adversarial planning-demonstrate empirical gains in leader value and runtime scalability over state-of-the-art methods.</description>
      <guid isPermaLink="false">oai:arXiv.org:2512.05667v1</guid>
      <category>cs.GT</category>
      <category>cs.AI</category>
      <pubDate>Mon, 08 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Jilles Steeve Dibangoye, Thibaut Le Marre, Ocan Sankur, Fran\c{c}ois Schwarzentruber</dc:creator>
    </item>
    <item>
      <title>Invariant Price of Anarchy: a Metric for Welfarist Traffic Control</title>
      <link>https://arxiv.org/abs/2512.05843</link>
      <description>arXiv:2512.05843v1 Announce Type: new 
Abstract: The Price of Anarchy (PoA) is a standard metric for quantifying inefficiency in socio-technical systems, widely used to guide policies like traffic tolling. Conventional PoA analysis relies on exact numerical costs. However, in many settings, costs represent agents' preferences and may be defined only up to possibly arbitrary scaling and shifting, representing informational and modeling ambiguities. We observe that while such transformations preserve equilibrium and optimal outcomes, they change the PoA value. To resolve this issue, we rely on results from Social Choice Theory and define the Invariant PoA. By connecting admissible transformations to degrees of comparability of agents' costs, we derive the specific social welfare functions which ensure that efficiency evaluations do not depend on arbitrary rescalings or translations of individual costs. Case studies on a toy example and the Zurich network demonstrate that identical tolling strategies can lead to substantially different efficiency estimates depending on the assumed comparability. Our framework thus demonstrates that explicit axiomatic foundations are necessary in order to define efficiency metrics and to appropriately guide policy in large-scale infrastructure design robustly and effectively.</description>
      <guid isPermaLink="false">oai:arXiv.org:2512.05843v1</guid>
      <category>cs.GT</category>
      <category>cs.MA</category>
      <pubDate>Mon, 08 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Ilia Shilov, Mingjia He, Heinrich H. Nax, Emilio Frazzoli, Gioele Zardini, Saverio Bolognani</dc:creator>
    </item>
    <item>
      <title>$\alpha$-Potential Games for Decentralized Control of Connected and Automated Vehicles</title>
      <link>https://arxiv.org/abs/2512.05712</link>
      <description>arXiv:2512.05712v1 Announce Type: cross 
Abstract: Designing scalable and safe control strategies for large populations of connected and automated vehicles (CAVs) requires accounting for strategic interactions among heterogeneous agents under decentralized information. While dynamic games provide a natural modeling framework, computing Nash equilibria (NEs) in large-scale settings remains challenging, and existing mean-field game approximations rely on restrictive assumptions that fail to capture collision avoidance and heterogeneous behaviors. This paper proposes an $\alpha$-potential game framework for decentralized CAV control. We show that computing $\alpha$-NE reduces to solving a decentralized control problem, and derive tight bounds of the parameter $\alpha$ based on interaction intensity and asymmetry. We further develop scalable policy gradient algorithms for computing $\alpha$-NEs using decentralized neural-network policies. Numerical experiments demonstrate that the proposed framework accommodates diverse traffic flow models and effectively captures collision avoidance, obstacle avoidance, and agent heterogeneity.</description>
      <guid isPermaLink="false">oai:arXiv.org:2512.05712v1</guid>
      <category>math.OC</category>
      <category>cs.GT</category>
      <category>cs.MA</category>
      <pubDate>Mon, 08 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Xuan Di, Anran Hu, Zhexin Wang, Yufei Zhang</dc:creator>
    </item>
    <item>
      <title>Egyptian Ratscrew: Discovering Dominant Strategies with Computational Game Theory</title>
      <link>https://arxiv.org/abs/2304.01007</link>
      <description>arXiv:2304.01007v2 Announce Type: replace 
Abstract: "Egyptian Ratscrew" (ERS) is a modern American card game enjoyed by millions of players worldwide. A game of ERS is won by collecting all of the cards in the deck. Typically this game is won by the player with the fastest reflexes, since the most common strategy for collecting cards is being the first to slap the pile in the center whenever legal combinations of cards are placed down. Most players assume that the dominant strategy is to develop a faster reaction time than your opponents, and no academic inquiry has been levied against this assumption. This thesis investigates the hypothesis that a "risk slapping" strategist who relies on practical economic decision making will win an overwhelming majority of games against players who rely on quick reflexes alone. It is theorized that this can be done by exploiting the "burn rule," a penalty that is too low-cost to effectively dissuade players from slapping illegally when it benefits them. Using the Ruby programming language, we construct an Egyptian Ratscrew simulator from scratch. Our model allows us to simulate the behavior of 8 strategically unique players within easily adjustable parameters including simulation type, player count, and burn amount. We simulate 100k iterations of 67 different ERS games, totaling 6.7 million games of ERS, and use win percentage data in order to determine which strategies are dominant under each set of parameters. We then confirm our hypothesis that risk slapping is a dominant strategy, discover that there is no strictly dominant approach to risk slapping, and elucidate a deeper understanding of different ERS mechanics such as the burn rule. Finally, we assess the implications of our findings and suggest potential improvements to the rules of the game. We also touch on the real-world applications of our research and make recommendations for the future of Egyptian Ratscrew modeling.</description>
      <guid isPermaLink="false">oai:arXiv.org:2304.01007v2</guid>
      <category>cs.GT</category>
      <category>econ.TH</category>
      <pubDate>Mon, 08 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Justin Diamond, Ben Garcia</dc:creator>
    </item>
    <item>
      <title>Truthful and Almost Envy-Free Mechanism of Allocating Indivisible Goods: the Power of Randomness</title>
      <link>https://arxiv.org/abs/2407.13634</link>
      <description>arXiv:2407.13634v3 Announce Type: replace 
Abstract: We study the problem of fairly and truthfully allocating $m$ indivisible items to $n$ agents with additive preferences. Specifically, we consider truthful mechanisms outputting allocations that satisfy EF$^{+u}_{-v}$, where, in an EF$^{+u}_{-v}$ allocation, for any pair of agents $i$ and $j$, agent $i$ will not envy agent $j$ if $u$ items were added to $i$'s bundle and $v$ items were removed from $j$'s bundle. Previous work easily indicates that, when restricted to deterministic mechanisms, truthfulness will lead to a poor guarantee of fairness: even with two agents, for any $u$ and $v$, EF$^{+u}_{-v}$ cannot be guaranteed by truthful mechanisms when the number of items is large enough. In this work, we focus on randomized mechanisms, where we consider ex-ante truthfulness and ex-post fairness. For two agents, we present a truthful mechanism that achieves EF$^{+0}_{-1}$ (i.e., the well-studied fairness notion EF$1$). For three agents, we present a truthful mechanism that achieves EF$^{+1}_{-1}$. For $n$ agents in general, we show that there exists a truthful mechanism that achieves EF$^{+0}_{-O(\sqrt{n})}$. On the negative side, when considering the stronger notion EF$_{-v}^{+u}$X, we show that it cannot be achieved by any randomized truthful mechanism for any $u, v$, and any fixed number of agents.
  We further consider fair and truthful mechanisms that also satisfy the standard efficiency guarantee: Pareto-optimality. We provide a mechanism that simultaneously achieves truthfulness, EF$1$, and Pareto-optimality for bi-valued utilities (where agents' valuation on each item is either $p$ or $q$ for some $p&gt;q\geq0$). For tri-valued utilities (where agents' valuations on each item belong to $\{p,q,r\}$ for some $p&gt;q&gt;r\geq0$) and any $u,v$, we show that truthfulness is incompatible with EF$^{+u}_{-v}$ and Pareto-optimality even for two agents.</description>
      <guid isPermaLink="false">oai:arXiv.org:2407.13634v3</guid>
      <category>cs.GT</category>
      <pubDate>Mon, 08 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Xiaolin Bu, Biaoshuai Tao</dc:creator>
    </item>
    <item>
      <title>Learning the Value of Value Learning</title>
      <link>https://arxiv.org/abs/2511.17714</link>
      <description>arXiv:2511.17714v3 Announce Type: replace-cross 
Abstract: Standard decision frameworks addresses uncertainty about facts but assumes fixed values. We extend the Jeffrey-Bolker framework to model refinements in values and prove a value-of-information theorem for axiological refinement. In multi-agent settings, we establish that mutual refinement will characteristically transform zero-sum games into positive-sum interactions and yields Pareto-improving Nash bargains. These results show that a framework of rational choice can be extended to model value refinement and its associated benefits. By unifying epistemic and axiological refinement under a single formalism, we broaden the conceptual foundations of rational choice and illuminate the normative status of ethical deliberation.</description>
      <guid isPermaLink="false">oai:arXiv.org:2511.17714v3</guid>
      <category>cs.AI</category>
      <category>cs.GT</category>
      <pubDate>Mon, 08 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Alex John London, Aydin Mohseni</dc:creator>
    </item>
  </channel>
</rss>
