<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>physics.geo-ph updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/physics.geo-ph</link>
    <description>physics.geo-ph updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/physics.geo-ph" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Mon, 14 Oct 2024 04:00:30 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Mon, 14 Oct 2024 00:00:00 -0400</pubDate>
    <skipDays>
      <day>Sunday</day>
      <day>Saturday</day>
    </skipDays>
    <item>
      <title>EarthquakeNPP: Benchmark Datasets for Earthquake Forecasting with Neural Point Processes</title>
      <link>https://arxiv.org/abs/2410.08226</link>
      <description>arXiv:2410.08226v1 Announce Type: new 
Abstract: Classical point process models, such as the epidemic-type aftershock sequence (ETAS) model, have been widely used for forecasting the event times and locations of earthquakes for decades. Recent advances have led to Neural Point Processes (NPPs), which promise greater flexibility and improvements over classical models. However, the currently-used benchmark dataset for NPPs does not represent an up-to-date challenge in the seismological community since it lacks a key earthquake sequence from the region and improperly splits training and testing data. Furthermore, initial earthquake forecast benchmarking lacks a comparison to state-of-the-art earthquake forecasting models typically used by the seismological community. To address these gaps, we introduce EarthquakeNPP: a collection of benchmark datasets to facilitate testing of NPPs on earthquake data, accompanied by a credible implementation of the ETAS model. The datasets cover a range of small to large target regions within California, dating from 1971 to 2021, and include different methodologies for dataset generation. In a benchmarking experiment, we compare three spatio-temporal NPPs against ETAS and find that none outperform ETAS in either spatial or temporal log-likelihood. These results indicate that current NPP implementations are not yet suitable for practical earthquake forecasting. However, EarthquakeNPP will serve as a platform for collaboration between the seismology and machine learning communities with the goal of improving earthquake predictability.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.08226v1</guid>
      <category>physics.geo-ph</category>
      <category>cs.LG</category>
      <category>stat.AP</category>
      <category>stat.ML</category>
      <pubDate>Mon, 14 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Samuel Stockman, Daniel Lawson, Maximilian Werner</dc:creator>
    </item>
    <item>
      <title>A Real Benchmark Swell Noise Dataset for Performing Seismic Data Denoising via Deep Learning</title>
      <link>https://arxiv.org/abs/2410.08231</link>
      <description>arXiv:2410.08231v1 Announce Type: new 
Abstract: The recent development of deep learning (DL) methods for computer vision has been driven by the creation of open benchmark datasets on which new algorithms can be tested and compared with reproducible results. Although DL methods have many applications in geophysics, few real seismic datasets are available for benchmarking DL models, especially for denoising real data, which is one of the main problems in seismic data processing scenarios in the oil and gas industry. This article presents a benchmark dataset composed of synthetic seismic data corrupted with noise extracted from a filtering process implemented on real data. In this work, a comparison between two well-known DL-based denoising models is conducted on this dataset, which is proposed as a benchmark for accelerating the development of new solutions for seismic data denoising. This work also introduces a new evaluation metric that can capture small variations in model results. The results show that DL models are effective at denoising seismic data, but some issues remain to be solved.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.08231v1</guid>
      <category>physics.geo-ph</category>
      <category>cs.CV</category>
      <category>cs.LG</category>
      <pubDate>Mon, 14 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Pablo M. Barros, Roosevelt de L. Sardinha, Giovanny A. M. Arboleda, Lessandro de S. S. Valente, Isabelle R. V. de Melo, Albino Aveleda, Andr\'e Bulc\~ao, Sergio L. Netto, Alexandre G. Evsukoff</dc:creator>
    </item>
    <item>
      <title>May 11-12 Extreme Space Weather Events Brief and Dose Rate Model Response</title>
      <link>https://arxiv.org/abs/2410.08254</link>
      <description>arXiv:2410.08254v1 Announce Type: new 
Abstract: In this brief paper, we analyze space weather events that occurred on May 11 and 12, 2024, from the perspective of an operational space weather center that provides advisories for civil aviation. One of the key metrics monitored by the center is the radiation dose rate at operational flight altitudes. A model implemented by the center provides the dose rate in real time. The model showed that dangerous levels were momentarily exceeded just above the usual 30,000 feet level during the events. This paper highlights differences in models used by various space weather centers, emphasizing the need for harmonization.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.08254v1</guid>
      <category>physics.geo-ph</category>
      <category>physics.space-ph</category>
      <pubDate>Mon, 14 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Vyacheslav Burov, Kirill Kholodkov, Igor Aleshin</dc:creator>
    </item>
    <item>
      <title>GPR Full-Waveform Inversion through Adaptive Filtering of Model Parameters and Gradients Using CNN</title>
      <link>https://arxiv.org/abs/2410.08568</link>
      <description>arXiv:2410.08568v1 Announce Type: new 
Abstract: GPR full-waveform inversion optimizes the subsurface property model iteratively to match the entire waveform information. However, the model gradients derived from wavefield continuation often contain errors, such as ghost values and excessively large values at transmitter and receiver points. Furthermore, models updated based on these gradients frequently exhibit unclear characterization of anomalous bodies or false anomalies, making it challenging to obtain accurate inversion results. To address these issues, we introduced a novel full-waveform inversion (FWI) framework that incorporates an embedded convolutional neural network (CNN) to adaptively filter model parameters and gradients. Specifically, we embedded the CNN module before the forward modeling process and ensured the entire FWI process remains differentiable. This design leverages the auto-grad tool of the deep learning library, allowing model values to pass through the CNN module during forward computation and model gradients to pass through the CNN module during backpropagation. Experiments have shown that filtering the model parameters during forward computation and the model gradients during backpropagation can ultimately yield high-quality inversion results.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.08568v1</guid>
      <category>physics.geo-ph</category>
      <category>cs.LG</category>
      <pubDate>Mon, 14 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Peng Jiang, Kun Wang, Jiaxing Wang, Zeliang Feng, Shengjie Qiao, Runhuai Deng, Fengkai Zhang</dc:creator>
    </item>
    <item>
      <title>WaveDiffusion: Exploring Full Waveform Inversion via Joint Diffusion in the Latent Space</title>
      <link>https://arxiv.org/abs/2410.09002</link>
      <description>arXiv:2410.09002v1 Announce Type: new 
Abstract: Full Waveform Inversion (FWI) is a vital technique for reconstructing high-resolution subsurface velocity maps from seismic waveform data, governed by partial differential equations (PDEs) that model wave propagation. Traditional machine learning approaches typically map seismic data to velocity maps by encoding seismic waveforms into latent embeddings and decoding them into velocity maps. In this paper, we introduce a novel framework that reframes FWI as a joint diffusion process in a shared latent space, bridging seismic waveform data and velocity maps. Our approach has two key components: first, we merge the bottlenecks of two separate autoencoders-one for seismic data and one for velocity maps-into a unified latent space using vector quantization to establish a shared codebook. Second, we train a diffusion model in this latent space, enabling the simultaneous generation of seismic and velocity map pairs by sampling and denoising the latent representations, followed by decoding each modality with its respective decoder. Remarkably, our jointly generated seismic-velocity pairs approximately satisfy the governing PDE without any additional constraint, offering a new geometric interpretation of FWI. The diffusion process learns to score the latent space according to its deviation from the PDE, with higher scores representing smaller deviations from the true solutions. By following this diffusion process, the model traces a path from random initialization to a valid solution of the governing PDE. Our experiments on the OpenFWI dataset demonstrate that the generated seismic and velocity map pairs not only exhibit high fidelity and diversity but also adhere to the physical constraints imposed by the governing PDE.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.09002v1</guid>
      <category>physics.geo-ph</category>
      <pubDate>Mon, 14 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Hanchen Wang, Yinpeng Chen, Jeeun Kang, Yixuan Wu, Young Jin Kim, Youzuo Lin</dc:creator>
    </item>
    <item>
      <title>Solid-liquid phase change in planetary cores</title>
      <link>https://arxiv.org/abs/2410.08685</link>
      <description>arXiv:2410.08685v1 Announce Type: cross 
Abstract: The ubiquitous phenomena of crystallization and melting occur in various geophysical contexts across many spatial and temporal scales. In particular, they take place in the iron core of terrestrial planets and moons, profoundly influencing their dynamics and magnetic field generation. Crystallization and melting entail intricate multiphase flows, buoyancy effects, and out-of-equilibrium thermodynamics, posing challenges for theoretical modeling and numerical simulations. Besides, due to the inaccessible nature of the planetary deep interior, our understanding relies on indirect data from seismology, mineral physics, geochemistry, and magnetism. Consequently, phase-change-driven flows in planetary cores constitute a compelling yet challenging area of research. This paper provides an overview of the role of laboratory fluid dynamics experiments in elucidating the solid-liquid phase change phenomena occurring thousands of kilometers beneath our feet and within other planetary depths, along with their dynamic repercussions. Drawing parallel with metallurgy, it navigates through all scales of phase change dynamics, from microscopic processes (nucleation and crystal growth) to macroscopic consequences (solid-liquid segregation and large-scale flows). The review delves into the two primary planetary solidification regimes, top-down and bottom-up, and elucidates the formation of mushy and/or slurry layers in the various relevant configurations. Additionally, it outlines remaining challenges, including insights from ongoing space missions poised to unveil the diverse planetary regimes.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.08685v1</guid>
      <category>astro-ph.EP</category>
      <category>physics.geo-ph</category>
      <pubDate>Mon, 14 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <dc:creator>Ludovic Huguet, Quentin Kriaa, Thierry Alboussi\`ere, Michael Le Bars</dc:creator>
    </item>
    <item>
      <title>Data-driven Characterization of Near-Surface Velocity in the San Francisco Bay Area: A Stationary and Spatially Varying Approach</title>
      <link>https://arxiv.org/abs/2409.18856</link>
      <description>arXiv:2409.18856v2 Announce Type: replace-cross 
Abstract: This study presents the development of two new sedimentary velocity models for the San Francisco Bay Area (SFBA) to improve the near-surface representation of shear-wave velocity ($V_S$) for large-scale, broadband numerical simulations, with the ultimate goal of enhancing the representation of the sedimentary layers in the Bay Area community velocity model. The first velocity model is stationary and is based solely on $V_{S30}$; the second velocity model is spatially varying and has location-specific adjustments. They were developed using a dataset of 200 measured $V_S$ profiles. Both models were formulated within a hierarchical Bayesian framework, using a parameterization that ensures robust scaling. The spatially varying model includes a slope adjustment term modeled as a Gaussian process to capture site-specific effects based on location. Residual analysis shows that both models are unbiased for $V_S$ values up to 1000 m/sec. Along-depth variability models were also developed using within-profile residuals. The proposed models show higher $V_S$ in the San Jose area and Livermore Valley compared to the USGS Bay Area community velocity model by a factor of two or more in some cases. Goodness-of-fit (GOF) comparisons using one-dimensional linear site-response analysis at selected sites demonstrate that the proposed models outperform the USGS model in capturing near-surface amplification across a broad frequency range. Incorporating along-depth variability further improves the GOF scores by reducing over-amplification at high frequencies. These results underscore the importance of integrating data-driven models of the shallow crust, like the ones presented here, in coarser regional community velocity models to enhance regional seismic hazard assessments.</description>
      <guid isPermaLink="false">oai:arXiv.org:2409.18856v2</guid>
      <category>stat.AP</category>
      <category>physics.geo-ph</category>
      <pubDate>Mon, 14 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Grigorios Lavrentiadis, Elnaz Seylabi, Feiruo Xia, Hesam Tehrani, Domniki Asimaki, David McCallen</dc:creator>
    </item>
  </channel>
</rss>
