<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>math.IT updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/math.IT</link>
    <description>math.IT updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/math.IT" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Fri, 05 Apr 2024 04:03:09 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Fri, 05 Apr 2024 00:00:00 -0400</pubDate>
    <skipDays>
      <day>Sunday</day>
      <day>Saturday</day>
    </skipDays>
    <item>
      <title>Multiple UAV-Assisted Cooperative DF Relaying in Multi-User Massive MIMO IoT Systems</title>
      <link>https://arxiv.org/abs/2404.03068</link>
      <description>arXiv:2404.03068v1 Announce Type: new 
Abstract: This work considers a multi-user massive multiple-input multiple-output (MU-mMIMO) Internet-of-Things (IoT) system, where multiple unmanned aerial vehicles (UAVs) operating as decode-and-forward (DF) relays connect the base station (BS) to a large number of IoT devices. To maximize the total achievable rate, we propose a novel joint optimization problem of hybrid beamforming (HBF), multiple UAV relay positioning, and power allocation (PA) to multiple IoT users. The study adopts a geometry-based millimeter-wave (mmWave) channel model for both links and utilizes sequential optimization based on K-means UAV-user association. The radio frequency (RF) stages are designed based on the slow time-varying angular information, while the baseband (BB) stages are designed utilizing the reduced-dimension effective channel matrices. The illustrative results show that multiple UAV-assisted cooperative relaying systems outperform a single UAV system in practical user distributions. Moreover, compared to fixed positions and equal PA of UAVs and BS, the joint optimization of UAV location and PA substantially enhances the total achievable rate.</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.03068v1</guid>
      <category>cs.IT</category>
      <category>eess.SP</category>
      <category>math.IT</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Mobeen Mahmood, Yicheng Yuan, Tho Le-Ngoc</dc:creator>
    </item>
    <item>
      <title>Semantic Compression with Information Lattice Learning</title>
      <link>https://arxiv.org/abs/2404.03131</link>
      <description>arXiv:2404.03131v1 Announce Type: new 
Abstract: Data-driven artificial intelligence (AI) techniques are becoming prominent for learning in support of data compression, but are focused on standard problems such as text compression. To instead address the emerging problem of semantic compression, we argue that the lattice theory of information is particularly expressive and mathematically precise in capturing notions of abstraction as a form of lossy semantic compression. As such, we demonstrate that a novel AI technique called information lattice learning, originally developed for knowledge discovery and creativity, is powerful for learning to compress in a semantically-meaningful way. The lattice structure further implies the optimality of group codes and the successive refinement property for progressive transmission.</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.03131v1</guid>
      <category>cs.IT</category>
      <category>math.IT</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Haizi Yu, Lav R. Varshney</dc:creator>
    </item>
    <item>
      <title>MMSE Channel Estimation in Large-Scale MIMO: Improved Robustness with Reduced Complexity</title>
      <link>https://arxiv.org/abs/2404.03279</link>
      <description>arXiv:2404.03279v1 Announce Type: new 
Abstract: Large-scale MIMO systems with a massive number N of individually controlled antennas pose significant challenges for minimum mean square error (MMSE) channel estimation, based on uplink pilots. The major ones arise from the computational complexity, which scales with $N^3$, and from the need for accurate knowledge of the channel statistics. This paper aims to address both challenges by introducing reduced-complexity channel estimation methods that achieve the performance of MMSE in terms of estimation accuracy and uplink spectral efficiency while demonstrating improved robustness in practical scenarios where channel statistics must be estimated. This is achieved by exploiting the inherent structure of the spatial correlation matrix induced by the array geometry. Specifically, we use a Kronecker decomposition for uniform planar arrays and a well-suited circulant approximation for uniform linear arrays. By doing so, a significantly lower computational complexity is achieved, scaling as $N\sqrt{N}$ and $N\log N$ for squared planar arrays and linear arrays, respectively.</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.03279v1</guid>
      <category>cs.IT</category>
      <category>eess.SP</category>
      <category>math.IT</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Giacomo Bacci, Antonio Alberto D'Amico, Luca Sanguinetti</dc:creator>
    </item>
    <item>
      <title>Combined DL-UL Distributed Beamforming Design for Cell-Free Massive MIMO</title>
      <link>https://arxiv.org/abs/2404.03285</link>
      <description>arXiv:2404.03285v1 Announce Type: new 
Abstract: We consider a cell-free massive multiple-input multiple-output system with multi-antenna access points (APs) and user equipments (UEs), where the UEs can be served in both the downlink (DL) and uplink (UL) within a resource block. We tackle the combined optimization of the DL precoders and combiners at the APs and DL UEs, respectively, together with the UL combiners and precoders at the APs and UL UEs, respectively. To this end, we propose distributed beamforming designs enabled by iterative bi-directional training (IBT) and based on the minimum mean squared error criterion. To reduce the IBT overhead and thus enhance the effective DL and UL rates, we carry out the distributed beamforming design by assuming that all the UEs are served solely in the DL and then utilize the obtained beamformers for the DL and UL data transmissions after proper scaling. Numerical results show the superiority of the proposed combined DL-UL distributed beamforming design over separate DL and UL designs, especially with short resource blocks.</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.03285v1</guid>
      <category>cs.IT</category>
      <category>eess.SP</category>
      <category>math.IT</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Bikshapathi Gouda, Antti Arvola, Italo Atzeni, Antti T\"olli</dc:creator>
    </item>
    <item>
      <title>On the solutions of linear systems over additively idempotent semirings</title>
      <link>https://arxiv.org/abs/2404.03294</link>
      <description>arXiv:2404.03294v1 Announce Type: new 
Abstract: The aim of this article is to solve the system $XA=Y$ where $A=(a_{ij})\in M_{m\times n}(S)$, $Y\in S^{m}$ and $X$ is an unknown vector of size $n$, being $S$ an additively idempotent semiring. If the system has solutions then we completely characterize its maximal one, and in the particular case where $S$ is a generalized tropical semiring a complete characterization of its solutions is provided as well as an explicit bound of the computational cost associated to its computation. Finally, when $S$ is finite, we give a cryptographic application by presenting an attack to the key exchange protocol proposed by Maze, Monico and Rosenthal.</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.03294v1</guid>
      <category>cs.IT</category>
      <category>math.IT</category>
      <category>math.RA</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>\'Alvaro Otero S\'anchez, Daniel Camaz\'on, Juan Antonio L\'opez Ramos</dc:creator>
    </item>
    <item>
      <title>Movable Antennas-Assisted Secure Transmission Without Eavesdroppers' Instantaneous CSI</title>
      <link>https://arxiv.org/abs/2404.03395</link>
      <description>arXiv:2404.03395v1 Announce Type: new 
Abstract: Movable antenna (MA) technology is highly promising for improving communication performance, due to its advantage of flexibly adjusting positions of antennas to reconfigure channel conditions. In this paper, we investigate MAs-assisted secure transmission under a legitimate transmitter Alice, a legitimate receiver Bob and multiple eavesdroppers. Specifically, we consider a practical scenario where Alice has no any knowledge about the instantaneous non-line-of-sight component of the wiretap channel. Under this setup, we evaluate the secrecy performance by adopting the secrecy outage probability metric, the tight approximation of which is first derived by interpreting the Rician fading as a special case of Nakagami fading and concurrently exploiting the Laguerre series approximation. Then, we minimize the secrecy outage probability by jointly optimizing the transmit beamforming and positions of antennas at Alice. However, the problem is highly non-convex because the objective includes the complex incomplete gamma function. To tackle this challenge, we, for the first time, effectively approximate the inverse of the incomplete gamma function as a simple linear model. Based on this approximation, we arrive at a simplified problem with a clear structure, which can be solved via the developed alternating projected gradient ascent (APGA) algorithm. Considering the high complexity of the APGA, we further design another scheme where the zero-forcing based beamforming is adopted by Alice, and then we transform the problem into minimizing a simple function which is only related to positions of antennas at Alice.As demonstrated by simulations, our proposed schemes achieve significant performance gains compared to conventional schemes based on fixed-position antennas.</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.03395v1</guid>
      <category>cs.IT</category>
      <category>cs.ET</category>
      <category>math.IT</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Guojie Hu, Qingqing Wu, Donghui Xu, Kui Xu, Jiangbo Si, Yunlong Cai, Naofal Al-Dhahir</dc:creator>
    </item>
    <item>
      <title>Design and Optimization of Cooperative Sensing With Limited Backhaul Capacity</title>
      <link>https://arxiv.org/abs/2404.03440</link>
      <description>arXiv:2404.03440v1 Announce Type: new 
Abstract: This paper introduces a cooperative sensing framework designed for integrated sensing and communication cellular networks. The framework comprises one base station (BS) functioning as the sensing transmitter, while several nearby BSs act as sensing receivers. The primary objective is to facilitate cooperative target localization by enabling each receiver to share specific information with a fusion center (FC) over a limited capacity backhaul link. To achieve this goal, we propose an advanced cooperative sensing design that enhances the communication process between the receivers and the FC. Each receiver independently estimates the time delay and the reflecting coefficient associated with the reflected path from the target. Subsequently, each receiver transmits the estimated values and the received signal samples centered around the estimated time delay to the FC. To efficiently quantize the signal samples, a Karhunen-Lo\`eve Transform coding scheme is employed. Furthermore, an optimization problem is formulated to allocate backhaul resources for quantizing different samples, improving target localization. Numerical results validate the effectiveness of our proposed advanced design and demonstrate its superiority over a baseline design, where only the locally estimated values are transmitted from each receiver to the FC.</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.03440v1</guid>
      <category>cs.IT</category>
      <category>eess.SP</category>
      <category>math.IT</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <arxiv:DOI>10.1109/VTC2023-Fall60731.2023.10333715</arxiv:DOI>
      <dc:creator>Wenrui Li, Min Li, An Liu, Tony Xiao Han</dc:creator>
    </item>
    <item>
      <title>Synergy as the failure of distributivity</title>
      <link>https://arxiv.org/abs/2404.03455</link>
      <description>arXiv:2404.03455v1 Announce Type: new 
Abstract: A physical system is synergistic if it cannot be reduced to its constituents. Intuitively this is paraphrased into the common statement that 'the whole is greater than the sum of its parts'. In this manner, many basic parts in combination may give rise to some unexpected collective behavior. A paradigmatic example of such phenomenon is information. Several sources, which are already known individually, may provide some new knowledge when joined together. Here we take the trivial case of discrete random variables and explore whether and how it is possible to get more information out of lesser parts. Our approach is inspired by set theory as the fundamental description of part-whole relations. If taken unaltered, synergistic behavior is forbidden by the set theoretical axioms. Indeed, the union of sets cannot contain extra elements not found in any particular set. However, random variables are not a perfect analogy of sets. We formalise the distinction, finding a single broken axiom - union/intersection distributivity. Nevertheless, it remains possible to describe information using Venn-type diagrams. We directly connect the existence of synergy to the failure of distributivity for random variables. When compared to the partial information decomposition framework (PID), our technique fully reproduces previous results while resolving the self-contradictions that plagued them and providing additional constraints on the solutions. This opens the way towards quantifying emergence in large systems.</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.03455v1</guid>
      <category>cs.IT</category>
      <category>math.IT</category>
      <category>physics.bio-ph</category>
      <category>physics.data-an</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Ivan A. Sevostianov, Ofer Feinerman</dc:creator>
    </item>
    <item>
      <title>Hierarchy Selection: New team ranking indicators for cyclist multi-stage races</title>
      <link>https://arxiv.org/abs/2404.02910</link>
      <description>arXiv:2404.02910v1 Announce Type: cross 
Abstract: In this paper, I report some investigation discussing team selection, whence hierarchy, through ranking indicators, for example when measuring professional cyclist team's sportive value, in particular in multistage races. A logical, it seems, constraint is introduced on the riders: they must finish the race. Several new indicators are defined, justified, and compared. These indicators are mainly based on the arriving place of (the best 3) riders instead of their time needed for finishing the stage or the race, - as presently classically used. A case study, serving as an illustration containing the necessary ingredients for a wider discussion, is the 2023 Vuelta de San Juan, but without loss of generality.
  It is shown that the new indicators offer some new viewpoint for distinguishing the ranking through the cumulative sums of the places of riders rather than their finishing times. On the other hand, the indicators indicate a different team hierarchy if only the finishing riders are considered. Some consideration on the distance between ranking indicators is presented.
  Moreover, it is argued that these new ranking indicators should hopefully promote more competitive races, not only till the end of the race, but also until the end of each stage. Generalizations and other applications within operational research topics, like in academia, are suggested.</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.02910v1</guid>
      <category>physics.soc-ph</category>
      <category>cs.IT</category>
      <category>math.IT</category>
      <category>nlin.AO</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <arxiv:DOI>10.1016/j.ejor.2023.10.044</arxiv:DOI>
      <arxiv:journal_reference>European Journal of Operational Research 314 (2024) 807-816</arxiv:journal_reference>
      <dc:creator>Marcel Ausloos</dc:creator>
    </item>
    <item>
      <title>Learning in Convolutional Neural Networks Accelerated by Transfer Entropy</title>
      <link>https://arxiv.org/abs/2404.02943</link>
      <description>arXiv:2404.02943v1 Announce Type: cross 
Abstract: Recently, there is a growing interest in applying Transfer Entropy (TE) in quantifying the effective connectivity between artificial neurons. In a feedforward network, the TE can be used to quantify the relationships between neuron output pairs located in different layers. Our focus is on how to include the TE in the learning mechanisms of a Convolutional Neural Network (CNN) architecture. We introduce a novel training mechanism for CNN architectures which integrates the TE feedback connections. Adding the TE feedback parameter accelerates the training process, as fewer epochs are needed. On the flip side, it adds computational overhead to each epoch. According to our experiments on CNN classifiers, to achieve a reasonable computational overhead--accuracy trade-off, it is efficient to consider only the inter-neural information transfer of a random subset of the neuron pairs from the last two fully connected layers. The TE acts as a smoothing factor, generating stability and becoming active only periodically, not after processing each input sample. Therefore, we can consider the TE is in our model a slowly changing meta-parameter.</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.02943v1</guid>
      <category>cs.LG</category>
      <category>cs.AI</category>
      <category>cs.IT</category>
      <category>math.IT</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <arxiv:DOI>10.3390/e23091218</arxiv:DOI>
      <arxiv:journal_reference>Entropy - MDPI, Year 2021, Number 9, Article Number 1218, PubMedID 34573843, ISSN 1099-4300</arxiv:journal_reference>
      <dc:creator>Adrian Moldovan, Angel Ca\c{t}aron, R\u{a}zvan Andonie</dc:creator>
    </item>
    <item>
      <title>BCAmirs at SemEval-2024 Task 4: Beyond Words: A Multimodal and Multilingual Exploration of Persuasion in Memes</title>
      <link>https://arxiv.org/abs/2404.03022</link>
      <description>arXiv:2404.03022v1 Announce Type: cross 
Abstract: Memes, combining text and images, frequently use metaphors to convey persuasive messages, shaping public opinion. Motivated by this, our team engaged in SemEval-2024 Task 4, a hierarchical multi-label classification task designed to identify rhetorical and psychological persuasion techniques embedded within memes. To tackle this problem, we introduced a caption generation step to assess the modality gap and the impact of additional semantic information from images, which improved our result. Our best model utilizes GPT-4 generated captions alongside meme text to fine-tune RoBERTa as the text encoder and CLIP as the image encoder. It outperforms the baseline by a large margin in all 12 subtasks. In particular, it ranked in top-3 across all languages in Subtask 2a, and top-4 in Subtask 2b, demonstrating quantitatively strong performance. The improvement achieved by the introduced intermediate step is likely attributable to the metaphorical essence of images that challenges visual encoders. This highlights the potential for improving abstract visual semantics encoding.</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.03022v1</guid>
      <category>cs.CL</category>
      <category>cs.CV</category>
      <category>cs.IT</category>
      <category>cs.LG</category>
      <category>math.IT</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Amirhossein Abaskohi, Amirhossein Dabiriaghdam, Lele Wang, Giuseppe Carenini</dc:creator>
    </item>
    <item>
      <title>Composite Bayesian Optimization In Function Spaces Using NEON -- Neural Epistemic Operator Networks</title>
      <link>https://arxiv.org/abs/2404.03099</link>
      <description>arXiv:2404.03099v1 Announce Type: cross 
Abstract: Operator learning is a rising field of scientific computing where inputs or outputs of a machine learning model are functions defined in infinite-dimensional spaces. In this paper, we introduce NEON (Neural Epistemic Operator Networks), an architecture for generating predictions with uncertainty using a single operator network backbone, which presents orders of magnitude less trainable parameters than deep ensembles of comparable performance. We showcase the utility of this method for sequential decision-making by examining the problem of composite Bayesian Optimization (BO), where we aim to optimize a function $f=g\circ h$, where $h:X\to C(\mathcal{Y},\mathbb{R}^{d_s})$ is an unknown map which outputs elements of a function space, and $g: C(\mathcal{Y},\mathbb{R}^{d_s})\to \mathbb{R}$ is a known and cheap-to-compute functional. By comparing our approach to other state-of-the-art methods on toy and real world scenarios, we demonstrate that NEON achieves state-of-the-art performance while requiring orders of magnitude less trainable parameters.</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.03099v1</guid>
      <category>cs.LG</category>
      <category>cs.AI</category>
      <category>cs.CE</category>
      <category>cs.IT</category>
      <category>math.IT</category>
      <category>stat.ML</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <dc:creator>Leonardo Ferreira Guilhoto, Paris Perdikaris</dc:creator>
    </item>
    <item>
      <title>Information-Theoretic Generalization Bounds for Deep Neural Networks</title>
      <link>https://arxiv.org/abs/2404.03176</link>
      <description>arXiv:2404.03176v1 Announce Type: cross 
Abstract: Deep neural networks (DNNs) exhibit an exceptional capacity for generalization in practical applications. This work aims to capture the effect and benefits of depth for supervised learning via information-theoretic generalization bounds. We first derive two hierarchical bounds on the generalization error in terms of the Kullback-Leibler (KL) divergence or the 1-Wasserstein distance between the train and test distributions of the network internal representations. The KL divergence bound shrinks as the layer index increases, while the Wasserstein bound implies the existence of a layer that serves as a generalization funnel, which attains a minimal 1-Wasserstein distance. Analytic expressions for both bounds are derived under the setting of binary Gaussian classification with linear DNNs. To quantify the contraction of the relevant information measures when moving deeper into the network, we analyze the strong data processing inequality (SDPI) coefficient between consecutive layers of three regularized DNN models: Dropout, DropConnect, and Gaussian noise injection. This enables refining our generalization bounds to capture the contraction as a function of the network architecture parameters. Specializing our results to DNNs with a finite parameter space and the Gibbs algorithm reveals that deeper yet narrower network architectures generalize better in those examples, although how broadly this statement applies remains a question.</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.03176v1</guid>
      <category>cs.LG</category>
      <category>cs.IT</category>
      <category>math.IT</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Haiyun He, Christina Lee Yu, Ziv Goldfeld</dc:creator>
    </item>
    <item>
      <title>Early warning systems for financial markets of emerging economies</title>
      <link>https://arxiv.org/abs/2404.03319</link>
      <description>arXiv:2404.03319v1 Announce Type: cross 
Abstract: We develop and apply a new online early warning system (EWS) for what is known in machine learning as concept drift, in economics as a regime shift and in statistics as a change point. The system goes beyond linearity assumed in many conventional methods, and is robust to heavy tails and tail-dependence in the data, making it particularly suitable for emerging markets. The key component is an effective change-point detection mechanism for conditional entropy of the data, rather than for a particular indicator of interest. Combined with recent advances in machine learning methods for high-dimensional random forests, the mechanism is capable of finding significant shifts in information transfer between interdependent time series when traditional methods fail. We explore when this happens using simulations and we provide illustrations by applying the method to Uzbekistan's commodity and equity markets as well as to Russia's equity market in 2021-2023.</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.03319v1</guid>
      <category>econ.EM</category>
      <category>cs.IT</category>
      <category>math.IT</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Artem Kraevskiy, Artem Prokhorov, Evgeniy Sokolovskiy</dc:creator>
    </item>
    <item>
      <title>Approximate Gradient Coding for Privacy-Flexible Federated Learning with Non-IID Data</title>
      <link>https://arxiv.org/abs/2404.03524</link>
      <description>arXiv:2404.03524v1 Announce Type: cross 
Abstract: This work focuses on the challenges of non-IID data and stragglers/dropouts in federated learning. We introduce and explore a privacy-flexible paradigm that models parts of the clients' local data as non-private, offering a more versatile and business-oriented perspective on privacy. Within this framework, we propose a data-driven strategy for mitigating the effects of label heterogeneity and client straggling on federated learning. Our solution combines both offline data sharing and approximate gradient coding techniques. Through numerical simulations using the MNIST dataset, we demonstrate that our approach enables achieving a deliberate trade-off between privacy and utility, leading to improved model convergence and accuracy while using an adaptable portion of non-private data.</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.03524v1</guid>
      <category>cs.LG</category>
      <category>cs.CR</category>
      <category>cs.DC</category>
      <category>cs.IT</category>
      <category>math.IT</category>
      <category>stat.ML</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Okko Makkonen, Sampo Niemel\"a, Camilla Hollanti, Serge Kas Hanna</dc:creator>
    </item>
    <item>
      <title>Circuit Knitting Faces Exponential Sampling Overhead Scaling Bounded by Entanglement Cost</title>
      <link>https://arxiv.org/abs/2404.03619</link>
      <description>arXiv:2404.03619v1 Announce Type: cross 
Abstract: Circuit knitting, a method for connecting quantum circuits across multiple processors to simulate nonlocal quantum operations, is a promising approach for distributed quantum computing. While various techniques have been developed for circuit knitting, we uncover fundamental limitations to the scalability of this technology. We prove that the sampling overhead of circuit knitting is exponentially lower bounded by the exact entanglement cost of the target bipartite dynamic, even for asymptotic overhead in the parallel cut regime. Specifically, we prove that the regularized sampling overhead assisted with local operations and classical communication (LOCC), of any bipartite quantum channel is lower bounded by the exponential of its exact entanglement cost under separable preserving operations. Furthermore, we show that the regularized sampling overhead for simulating a general bipartite channel via LOCC is lower bounded by $\kappa$-entanglement and max-Rains information, providing efficiently computable benchmarks. Our work reveals a profound connection between virtual quantum information processing via quasi-probability decomposition and quantum Shannon theory, highlighting the critical role of entanglement in distributed quantum computing.</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.03619v1</guid>
      <category>quant-ph</category>
      <category>cs.IT</category>
      <category>math.IT</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Mingrui Jing, Chengkai Zhu, Xin Wang</dc:creator>
    </item>
    <item>
      <title>An Implementation of the Optimal Scheme for Energy Efficient Bus Encoding</title>
      <link>https://arxiv.org/abs/2303.06409</link>
      <description>arXiv:2303.06409v2 Announce Type: replace 
Abstract: In computer system buses, most of the energy is spent to change the voltage of each line from high to low or vice versa. Bus encoding schemes aim to improve energy efficiency by limiting the number of transitions between successive uses of the bus. We propose an implementation of the optimal code with reduced number of clock cycles.</description>
      <guid isPermaLink="false">oai:arXiv.org:2303.06409v2</guid>
      <category>cs.IT</category>
      <category>math.IT</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Lorenzo Valentini, Marco Chiani</dc:creator>
    </item>
    <item>
      <title>Optimal Two-Dimensional Reed--Solomon Codes Correcting Insertions and Deletions</title>
      <link>https://arxiv.org/abs/2311.02771</link>
      <description>arXiv:2311.02771v2 Announce Type: replace 
Abstract: Constructing Reed--Solomon (RS) codes that can correct insertions and deletions (insdel errors) has been considered in numerous recent works. For the special case of two-dimensional RS-codes, it is known [CST23] that an $[n,2]_q$ RS-code that can correct from $n-3$ insdel errors satisfies that $q=\Omega(n^3)$. On the other hand, there are several known constructions of $[n,2]_q$ RS-codes that can correct from $n-3$ insdel errors, where the smallest field size is $q=O(n^4)$. In this short paper, we construct $[n,2]_q$ Reed--Solomon codes that can correct $n-3$ insdel errors with $q=O(n^3)$, thereby resolving the minimum field size needed for such codes.</description>
      <guid isPermaLink="false">oai:arXiv.org:2311.02771v2</guid>
      <category>cs.IT</category>
      <category>math.IT</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Roni Con, Amir Shpilka, Itzhak Tamo</dc:creator>
    </item>
    <item>
      <title>Construction and Fast Decoding of Binary Linear Sum-Rank-Metric Codes</title>
      <link>https://arxiv.org/abs/2311.03619</link>
      <description>arXiv:2311.03619v2 Announce Type: replace 
Abstract: Sum-rank-metric codes have wide applications in the multishot network coding and the distributed storage. Linearized Reed-Solomon codes, sum-rank BCH codes and their Welch-Berlekamp type decoding algorithms were proposed and studied. They are sum-rank versions of Reed-Solomon codes and BCH codes in the Hamming metric. In this paper, we construct binary linear sum-rank-metric codes of the matrix size $2 \times 2$, from BCH, Goppa and additive quaternary Hamming metric codes. Larger sum-rank-metric codes than these sum-rank BCH codes of the same minimum sum-rank distances are obtained. Then a reduction of the decoding in the sum-rank-metric to the decoding in the Hamming metric is given. Fast decoding algorithms of BCH and Goppa type binary linear sum-rank-metric codes of the block length $t$ and the matrix size $2 \times 2$, which are better than these sum-rank BCH codes, are presented. These fast decoding algorithms for BCH and Goppa type binary linear sum-rank-metric codes of the matrix size $2 \times 2$ need at most $O(t^2)$ operations in the field ${\bf F}_4$. Asymptotically good sequences of quadratic-time encodable and decodable binary linear sum-rank-metric codes of the matrix size $2 \times 2$ satisfying $$R_{sr}(\delta_{sr}) \geq 1-\frac{1}{2}(H_4(\frac{4}{3}\delta_{sr})+H_4(2\delta_{sr})),$$ can be constructed from Goppa codes.</description>
      <guid isPermaLink="false">oai:arXiv.org:2311.03619v2</guid>
      <category>cs.IT</category>
      <category>math.IT</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/publicdomain/zero/1.0/</dc:rights>
      <dc:creator>Hao Chen, Yanfeng Qi, Zhiqiang Cheng</dc:creator>
    </item>
    <item>
      <title>Semantic Information in MC: Chemotaxis Beyond Shannon</title>
      <link>https://arxiv.org/abs/2402.18465</link>
      <description>arXiv:2402.18465v2 Announce Type: replace 
Abstract: The recently emerged molecular communication (MC) paradigm intends to leverage communication engineering tools for the design of synthetic chemical communication systems. These systems are envisioned to operate at nanoscale and in biological environments, such as the human body, and catalyze the emergence of revolutionary applications in the context of early disease monitoring and drug targeting. Despite the abundance of theoretical (and recently also experimental) MC system designs proposed over the past years, some fundamental questions remain unresolved, hindering the breakthrough of MC in real-world applications. One of these questions is: What can be a useful measure of information in the context of MC applications? While most existing works on MC build upon the concept of syntactic information as introduced by Shannon, in this paper, we explore the framework of semantic information as introduced by Kolchinsky and Wolpert for the information-theoretic analysis of a natural MC system, namely bacterial chemotaxis. Exploiting computational agent-based modeling (ABM), we are able to quantify, for the first time, the amount of information that the considered chemotactic bacterium (CB) utilizes to adapt to and survive in a dynamic environment. In other words, we show how the flow of information between the environment and the CB is related to the effectiveness of communication. Effectiveness here refers to the adaptation of the CB to the dynamic environment in order to ensure survival. Our analysis reveals that it highly depends on the environmental conditions how much information the CB can effectively utilize for improving their survival chances. Encouraged by our results, we envision that the proposed semantic information framework can open new avenues for the development of theoretical and experimental MC system designs for future nanoscale applications.</description>
      <guid isPermaLink="false">oai:arXiv.org:2402.18465v2</guid>
      <category>cs.IT</category>
      <category>math.IT</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Lukas Brand, Yan Wang, Maurizio Magarini, Robert Schober, Sebastian Lotter</dc:creator>
    </item>
    <item>
      <title>A Progressive Codebook Optimization Scheme for Sparse Code Multiple Access in Downlink Channels</title>
      <link>https://arxiv.org/abs/2403.16826</link>
      <description>arXiv:2403.16826v2 Announce Type: replace 
Abstract: Sparse code multiple access (SCMA) is a promising technique for enabling massive connectivity and high spectrum efficiency in future machine-type communication networks. However, its performance crucially depends on well-designed multi-dimensional codebooks. In this paper, we propose a novel progressive codebook optimization scheme that can achieve near-optimal performance over downlink fading channels. By examining the pair-wise error probability (PEP), we first derive the symbol error rate (SER) performance of the sparse codebook in downlink channels, which is considered as the design criterion for codebook optimization. Then, the benchmark constellation group at a single resource element is optimized with a sequential quadratic programming approach. Next, we propose a constellation group reconstruction process to assign the sub-constellations in each resource element (RE) progressively. For the current RE, the assignment of the sub-constellations is designed by minimizing the error performance of the product distance of the superimposed codewords in previous REs. The design process involves both permutation and labeling of the sub-constellations in the benchmark constellation group. Simulation results show that the proposed codebooks exhibit significant performance gains over state-of-the-art codebooks in the low signal-to-noise ratio (SNR) region over various downlink fading channels.</description>
      <guid isPermaLink="false">oai:arXiv.org:2403.16826v2</guid>
      <category>cs.IT</category>
      <category>math.IT</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Tuofeng Lei, Qu Luo, Shuyan Ni, Shimiao Chen, Xin Song, Pei Xiao</dc:creator>
    </item>
    <item>
      <title>Random Reed-Solomon Codes are List Recoverable with Optimal List Size</title>
      <link>https://arxiv.org/abs/2404.00206</link>
      <description>arXiv:2404.00206v2 Announce Type: replace 
Abstract: We prove that Reed-Solomon (RS) codes with random evaluation points are list recoverable up to capacity with optimal output list size, for any input list size.
  Namely, given an input list size $\ell$, a designated rate $R$, and any $\varepsilon &gt; 0$, we show that a random RS code is list recoverable from $1-R-\varepsilon$ fraction of errors with output list size $L = O(\ell/\varepsilon)$, for field size $q=\exp(\ell,1/\varepsilon) \cdot n^2$. In particular, this shows that random RS codes are list recoverable beyond the "list recovery Johnson bound". Such a result was not even known for arbitrary random linear codes. Our technique follows and extends the recent line of work on list decoding of random RS codes, specifically the works of Brakensiek, Gopi, and Makam (STOC 2023), and of Guo and Zhang (FOCS 2023).</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.00206v2</guid>
      <category>cs.IT</category>
      <category>cs.CC</category>
      <category>math.CO</category>
      <category>math.IT</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Dean Doron, S. Venkitesh</dc:creator>
    </item>
    <item>
      <title>An Error-Bounded Lossy Compression Method with Bit-Adaptive Quantization for Particle Data</title>
      <link>https://arxiv.org/abs/2404.02826</link>
      <description>arXiv:2404.02826v2 Announce Type: replace 
Abstract: This paper presents error-bounded lossy compression tailored for particle datasets from diverse scientific applications in cosmology, fluid dynamics, and fusion energy sciences. As today's high-performance computing capabilities advance, these datasets often reach trillions of points, posing significant visualization, analysis, and storage challenges. While error-bounded lossy compression makes it possible to represent floating-point values with strict pointwise accuracy guarantees, the lack of correlations in particle data's storage ordering often limits the compression ratio. Inspired by quantization-encoding schemes in SZ lossy compressors, we dynamically determine the number of bits to encode particles of the dataset to increase the compression ratio. Specifically, we utilize a k-d tree to partition particles into subregions and generate ``bit boxes'' centered at particles for each subregion to encode their positions. These bit boxes ensure error control while reducing the bit count used for compression. We comprehensively evaluate our method against state-of-the-art compressors on cosmology, fluid dynamics, and fusion plasma datasets.</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.02826v2</guid>
      <category>cs.IT</category>
      <category>astro-ph.IM</category>
      <category>cs.GR</category>
      <category>math.IT</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Congrong Ren, Sheng Di, Longtao Zhang, Kai Zhao, Hanqi Guo</dc:creator>
    </item>
    <item>
      <title>Quantum Talagrand, KKL and Friedgut's theorems and the learnability of quantum Boolean functions</title>
      <link>https://arxiv.org/abs/2209.07279</link>
      <description>arXiv:2209.07279v3 Announce Type: replace-cross 
Abstract: We extend three related results from the analysis of influences of Boolean functions to the quantum setting, namely the KKL Theorem, Friedgut's Junta Theorem and Talagrand's variance inequality for geometric influences. Our results are derived by a joint use of recently studied hypercontractivity and gradient estimates. These generic tools also allow us to derive generalizations of these results in a general von Neumann algebraic setting beyond the case of the quantum hypercube, including examples in infinite dimensions relevant to quantum information theory such as continuous variables quantum systems. Finally, we comment on the implications of our results as regards to noncommutative extensions of isoperimetric type inequalities, quantum circuit complexity lower bounds and the learnability of quantum observables.</description>
      <guid isPermaLink="false">oai:arXiv.org:2209.07279v3</guid>
      <category>math.FA</category>
      <category>cs.IT</category>
      <category>math-ph</category>
      <category>math.IT</category>
      <category>math.MP</category>
      <category>quant-ph</category>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Cambyse Rouz\'e, Melchior Wirth, Haonan Zhang</dc:creator>
    </item>
  </channel>
</rss>
