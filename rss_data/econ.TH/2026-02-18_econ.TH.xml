<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>econ.TH updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/econ.TH</link>
    <description>econ.TH updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/econ.TH" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Thu, 19 Feb 2026 02:32:21 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Wed, 18 Feb 2026 00:00:00 -0500</pubDate>
    <skipDays>
      <day>Saturday</day>
      <day>Sunday</day>
    </skipDays>
    <item>
      <title>Learning Against Nature: Minimax Regret and the Price of Robustness</title>
      <link>https://arxiv.org/abs/2602.15246</link>
      <description>arXiv:2602.15246v1 Announce Type: new 
Abstract: We study how a decision-maker (DM) learns from data of unknown quality to form robust, ''general-purpose'' posterior beliefs. We develop a framework for robust learning and belief formation under a minimax-regret criterion, cast as a zero-sum game: the DM chooses posterior beliefs to minimize ex-ante regret, while an adversarial Nature selects the data-generating process (DGP). We show that, in large samples of $n$ signal draws, Nature optimally induces ambiguity by choosing a process whose precision converges to the uninformative signals at the rate $1/\sqrt{n}$. As a result, learning against the adversarial DGP is nontrivial as well as incomplete: the DM's ex-ante regret remains strictly positive even with an infinite amount of data. However, when the true DGP is fixed and informative (even if only slightly), our DM with a robust updating rule eventually learns the state with enough data. Still, learning occurs at a sub-exponential rate -- quantifying the asymptotic price of robustness -- and it exhibits ''under-inference'' bias. Our framework provides a decision-theoretic dual to the local alternatives method in asymptotic statistics, deriving the characteristic $1/\sqrt{n}$-scaling endogenously from the signal ambiguity.</description>
      <guid isPermaLink="false">oai:arXiv.org:2602.15246v1</guid>
      <category>econ.TH</category>
      <pubDate>Wed, 18 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Yeon-Koo Che, Longjian Li, Tianling Luo</dc:creator>
    </item>
    <item>
      <title>Complexity and Misspecification</title>
      <link>https://arxiv.org/abs/2602.15674</link>
      <description>arXiv:2602.15674v1 Announce Type: new 
Abstract: We propose a tractable unified framework to study the evolution and interaction of model-misspecification concerns and complexity aversion in repeated decision problems. This aims to capture environments where decision makers worry that their models are misspecified while also disliking overly complex models. We find that pathological cycles caused by endogenous concerns for misspecification can be eliminated by penalizing complex models and show that such preferences for simplicity tend to favor safety, which can enhance welfare in the long run. We use our framework to provide new microfoundations for pervasive empirical phenomena such as "scale heterogeneity" in discrete-choice analysis, "probability neglect" in behavioral economics, and "home bias" in international finance.</description>
      <guid isPermaLink="false">oai:arXiv.org:2602.15674v1</guid>
      <category>econ.TH</category>
      <pubDate>Wed, 18 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <dc:creator>Drew Fudenberg, Florian Mudekereza</dc:creator>
    </item>
    <item>
      <title>Minimizing Volatility: Optimal Adjustment with Evolving Feasibility Constraints</title>
      <link>https://arxiv.org/abs/2602.15686</link>
      <description>arXiv:2602.15686v1 Announce Type: new 
Abstract: Minimizing volatility and adjustment costs is of central importance in many economic environments, yet it is often complicated by evolving feasibility constraints. We study a decision maker who repeatedly selects an action from a stochastically evolving interval of feasible actions in order to minimize either average adjustment costs or variance. We show that for strictly convex adjustment costs (such as quadratic variation), the optimal decision rule is a reference rule in which the decision maker minimizes the distance to a target action. In general, the optimal target depends both on the previous action and the expectation of future constraints; but for the special case where the constraints follow a random walk, the optimal mechanism is to simply target the previous action. If the decision maker minimizes variance, the optimal policy is also a reference rule, but the target is a constant, which is not necessarily equal to the long-term average action. Compared to mid-point heuristics, these optimal rules may substantially reduce quadratic variation and variance, in natural environments by $50\%$ or more. Applied to stock market auctions, our results provide an explanation for the wide-spread use of reference price rules. We also apply our results to bilateral trade in over-the-counter markets, capacity planning in supply chains, and positioning in political agenda setting.</description>
      <guid isPermaLink="false">oai:arXiv.org:2602.15686v1</guid>
      <category>econ.TH</category>
      <pubDate>Wed, 18 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Simon Jantschgi, Heinrich H. Nax, Bary S. R. Pradelski, Marek Pycia</dc:creator>
    </item>
    <item>
      <title>Optimal Auction Design for Dynamic Stochastic Environments: Myerson Meets Naor</title>
      <link>https://arxiv.org/abs/2505.22862</link>
      <description>arXiv:2505.22862v3 Announce Type: replace 
Abstract: Motivated by applications such as cloud computing, gig platforms, and blockchain auctions, we study optimal selling mechanisms for dynamic markets with stochastic supply and demand. In our model, buyers with private valuations and homogeneous goods arrive stochastically and can be held in queues at a cost. The optimal mechanism pairs allocative efficiency with dynamic admission control: goods are assigned to the highest-value buyer, while entry is restricted by value thresholds that strictly increase with the queue length and decrease with available inventory. This policy smooths competitive pressure across time and is implemented in dominant strategies via auctions with dynamic reserve prices.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.22862v3</guid>
      <category>econ.TH</category>
      <pubDate>Wed, 18 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Yeon-Koo Che, Andrew B. Choi</dc:creator>
    </item>
    <item>
      <title>Posterior-Separable Costs and Menu Preferences</title>
      <link>https://arxiv.org/abs/2511.09424</link>
      <description>arXiv:2511.09424v3 Announce Type: replace 
Abstract: We consider an agent with a rationally inattentive preference over menus of acts, as in de Oliveira et al (2017). We show that two axioms, Independence of Irrelevant Alternatives and Ignorance Equivalence, are necessary and sufficient for this agent to have a posterior-separable cost satisfying a mild smoothness condition, called joint-directional differentiability. Viewing the decision-maker's problem as a Bayesian persuasion problem, we also show that these axioms are necessary and sufficient for solvability by a unique hyperplane. When the cost function remains invariant for different priors, we show that these axioms imply uniformly posterior separable costs that are differentiable.</description>
      <guid isPermaLink="false">oai:arXiv.org:2511.09424v3</guid>
      <category>econ.TH</category>
      <pubDate>Wed, 18 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Henrique de Oliveira, Jeffrey Mensch</dc:creator>
    </item>
    <item>
      <title>On Smithson's fixed point theorem for order preserving multifunctions</title>
      <link>https://arxiv.org/abs/2303.15483</link>
      <description>arXiv:2303.15483v4 Announce Type: replace-cross 
Abstract: Fixed point theorems are ubiquitous in economic research. Many studies cite Smithson (1971) ``Fixed points of order preserving multifunctions,'' yet the original proof contains errors. This note presents a new, concise proof and explains why Smithson's argument is invalid. It also contains new results on the structure of the set of fixed points and monotone comparative statics.</description>
      <guid isPermaLink="false">oai:arXiv.org:2303.15483v4</guid>
      <category>math.CO</category>
      <category>econ.TH</category>
      <pubDate>Wed, 18 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Haruki Kono, Mark Voorneveld</dc:creator>
    </item>
  </channel>
</rss>
