<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>math.OC updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/math.OC</link>
    <description>math.OC updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/math.OC" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Thu, 01 Aug 2024 04:00:12 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Thu, 01 Aug 2024 00:00:00 -0400</pubDate>
    <skipDays>
      <day>Saturday</day>
      <day>Sunday</day>
    </skipDays>
    <item>
      <title>Convergence rates for the Adam optimizer</title>
      <link>https://arxiv.org/abs/2407.21078</link>
      <description>arXiv:2407.21078v1 Announce Type: new 
Abstract: Stochastic gradient descent (SGD) optimization methods are nowadays the method of choice for the training of deep neural networks (DNNs) in artificial intelligence systems. In practically relevant training problems, usually not the plain vanilla standard SGD method is the employed optimization scheme but instead suitably accelerated and adaptive SGD optimization methods are applied. As of today, maybe the most popular variant of such accelerated and adaptive SGD optimization methods is the famous Adam optimizer proposed by Kingma &amp; Ba in 2014. Despite the popularity of the Adam optimizer in implementations, it remained an open problem of research to provide a convergence analysis for the Adam optimizer even in the situation of simple quadratic stochastic optimization problems where the objective function (the function one intends to minimize) is strongly convex. In this work we solve this problem by establishing optimal convergence rates for the Adam optimizer for a large class of stochastic optimization problems, in particular, covering simple quadratic stochastic optimization problems. The key ingredient of our convergence analysis is a new vector field function which we propose to refer to as the Adam vector field. This Adam vector field accurately describes the macroscopic behaviour of the Adam optimization process but differs from the negative gradient of the objective function (the function we intend to minimize) of the considered stochastic optimization problem. In particular, our convergence analysis reveals that the Adam optimizer does typically not converge to critical points of the objective function (zeros of the gradient of the objective function) of the considered optimization problem but converges with rates to zeros of this Adam vector field.</description>
      <guid isPermaLink="false">oai:arXiv.org:2407.21078v1</guid>
      <category>math.OC</category>
      <category>cs.LG</category>
      <category>math.PR</category>
      <category>stat.ML</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Steffen Dereich, Arnulf Jentzen</dc:creator>
    </item>
    <item>
      <title>Optimal breakpoint selection method for piecewise linear approximation</title>
      <link>https://arxiv.org/abs/2407.21081</link>
      <description>arXiv:2407.21081v1 Announce Type: new 
Abstract: Piecewise linearization is a key technique for solving nonlinear problems in transportation network design and other optimization fields, in which generating breakpoints is a fundamental task. This paper proposes an optimal breakpoint selection method, rotational adjusting method (RAM), to minimize the approximation error between the original function and the piecewise linear function with limited number of pieces, applicable to both convex or concave function. RAM rotationally adjusts the location of breakpoints based on its adjacent breakpoints, and the optimal positions would be reached after several iterations. The optimality of the method is proved. Numerical experiments are conducted on the logarithmic function.</description>
      <guid isPermaLink="false">oai:arXiv.org:2407.21081v1</guid>
      <category>math.OC</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Shaojun Liu</dc:creator>
    </item>
    <item>
      <title>A decomposition algorithm for two-stage stochastic programs with approximate rotational invariance</title>
      <link>https://arxiv.org/abs/2407.21215</link>
      <description>arXiv:2407.21215v1 Announce Type: new 
Abstract: We propose an algorithm of approximating the optimal objective value of a two-stage stochastic program under an assumption of {\it approximate rotational invariance} of the technology matrix, and compare the method with the L-shaped decomposition.</description>
      <guid isPermaLink="false">oai:arXiv.org:2407.21215v1</guid>
      <category>math.OC</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Marzieh Bakhshi, Konstantin Tikhomirov</dc:creator>
    </item>
    <item>
      <title>A Fast Algorithm for Convex Composite Bi-Level Optimization</title>
      <link>https://arxiv.org/abs/2407.21221</link>
      <description>arXiv:2407.21221v1 Announce Type: new 
Abstract: In this paper, we study convex bi-level optimization problems where both the inner and outer levels are given as a composite convex minimization. We propose the Fast Bi-level Proximal Gradient (FBi-PG) algorithm, which can be interpreted as applying FISTA to a dynamic regularized composite objective function. The dynamic nature of the regularization parameters allows to achieve an optimal fast convergence rate of $O(1/k^{2})$ in terms of the inner objective function. This is the fastest known convergence rate under no additional restrictive assumptions. We also show that FBi-PG achieves sub-linear simultaneous rates in terms of both the inner and outer objective functions. Moreover, we show that under an H\"olderian type error bound assumption on the inner objective function, the FBi-PG algorithm converges to an optimal solution of the bi-level optimization problem. Finally, we present numerical experiments demonstrating the performances of the proposed scheme.</description>
      <guid isPermaLink="false">oai:arXiv.org:2407.21221v1</guid>
      <category>math.OC</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Roey Merchav, Shoham Sabach, Marc Teboulle</dc:creator>
    </item>
    <item>
      <title>On Approximating Volumes of Clipped Hypercubes</title>
      <link>https://arxiv.org/abs/2407.21365</link>
      <description>arXiv:2407.21365v1 Announce Type: new 
Abstract: We give a method of sub-exponential complexity to approximate the volume of the intersection of the unit hypercube with two specific sets. Our method can be applied (without loosing the sub-exponential complexity) to compute the volume of the hypercube intersected with a fixed number of sets, described by the equations of the form $\sum_{q=1}^n a_q(x_q) = b$, where $a_q : \mathbb{R} \to \mathbb{R}$ are polynomial functions and $b \in \mathbb{R}$. Note that the resulting sets are not necessarily convex. However, this type of equations describe, among others, half-spaces, balls and ellipsoids.</description>
      <guid isPermaLink="false">oai:arXiv.org:2407.21365v1</guid>
      <category>math.OC</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Marius Costandin</dc:creator>
    </item>
    <item>
      <title>Two Completely Parameter-Free Alternating Gradient Projection Algorithms for Nonconvex-(strongly) Concave Minimax Problems</title>
      <link>https://arxiv.org/abs/2407.21372</link>
      <description>arXiv:2407.21372v1 Announce Type: new 
Abstract: Due to their importance in various emerging applications, efficient algorithms for solving minimax problems have recently received increasing attention. However, many existing algorithms require prior knowledge of the problem parameters in order to achieve optimal iteration complexity. In this paper, we propose a completely parameter-free alternating gradient projection (PF-AGP) algorithm to solve the smooth nonconvex-(strongly) concave minimax problems using a backtracking strategy, which does not require prior knowledge of parameters such as the Lipschtiz constant $L$ or the strongly concave constant $\mu$. The PF-AGP algorithm utilizes a parameter-free gradient projection step to alternately update the outer and inner variables in each iteration. We show that the total number of gradient calls of the PF-AGP algorithm to obtain an $\varepsilon$-stationary point for nonconvex-strongly concave minimax problems is upper bounded by $\mathcal{O}\left( L\kappa^3\varepsilon^{-2} \right)$ where $\kappa$ is the condition number, while the total number of gradient calls to obtain an $\varepsilon$-stationary point for nonconvex-concave minimax problems is upper bounded by $\mathcal{O}\left( L^4\varepsilon^{-4} \right)$. As far as we know, this is the first completely parameter-free algorithm for solving nonconvex-strongly concave minimax problems, and it is also the completely parameter-free algorithm which achieves the best iteration complexity in single loop method for solving nonconvex-concave minimax problems. Numerical results validate the efficiency of the proposed PF-AGP algorithm.</description>
      <guid isPermaLink="false">oai:arXiv.org:2407.21372v1</guid>
      <category>math.OC</category>
      <category>cs.LG</category>
      <category>stat.ML</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Junnan Yang, Huiling Zhang, Zi Xu</dc:creator>
    </item>
    <item>
      <title>Peer-to-Peer (P2P) Electricity Markets for Low Voltage Networks</title>
      <link>https://arxiv.org/abs/2407.21403</link>
      <description>arXiv:2407.21403v1 Announce Type: new 
Abstract: We develop a clearance and settlement model for Peer-to-Peer (P2P) energy trading in low-voltage networks. The model enables direct transactions between parties within an open and distributed system and integrates unused capacity while respecting network constraints. We evaluate the model through simulations of different scenarios (normal operating conditions and extreme conditions) for 24-hour time blocks. Our simulations highlight the benefits of our model in a decentralized energy system, notably its ability to deal with high-trade volumes.</description>
      <guid isPermaLink="false">oai:arXiv.org:2407.21403v1</guid>
      <category>math.OC</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Diana Vieira Fernandes, Nicolas Christin, Soummya Kar</dc:creator>
    </item>
    <item>
      <title>Long-term investment and energy procurement risk management under uncertainty for an electrolytic green hydrogen producer</title>
      <link>https://arxiv.org/abs/2407.21574</link>
      <description>arXiv:2407.21574v1 Announce Type: new 
Abstract: Green hydrogen production by electrolysis is considered essential for global climate ambitions, however development of the industry is lagging behind expectations due to the perceived financial risk for individual projects. For new bilateral Hydrogen Purchase Agreements (HPA's), green hydrogen project proponents will seek to manage operating cost risks using investment in flexible assets, and energy hedging - two sets of decisions that are usually considered separately, but are co-optimised in this study to form a comprehensive asset sizing and procurement strategy. A 2-stage market-focused stochastic program is developed to model a hydrogen producer supplying an industrial customer, including hydrogen storage, and energy hedging using Power Purchase Agreements (PPA's) and power futures. The effects of uncertainty in renewable production, market prices, and hydrogen demand are studied. Several planning methods are tested on the model, benchmarking stochastic methods against simpler methods that are common in literature and in industry. Finally, the model is applied to several regulatory contexts discernible in the European green hydrogen classification rules (Renewable Fuel of Non-Biological Origin, RFNBO). The results show that in less complex cases, simple rule-based hedging methods can be effective, while in cases with demand uncertainty stochastic models are advantageous. The results also suggest that new green hydrogen subsidies are likely to stimulate demand for technologically and geographically diverse PPA portfolios.</description>
      <guid isPermaLink="false">oai:arXiv.org:2407.21574v1</guid>
      <category>math.OC</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Owen Palmer, Hugo Radet, Simon Camal, Robin Girard</dc:creator>
    </item>
    <item>
      <title>Nonlinear Derivative-free Constrained Optimization with a Mixed Penalty-Logarithmic Barrier Approach and Direct Search</title>
      <link>https://arxiv.org/abs/2407.21634</link>
      <description>arXiv:2407.21634v1 Announce Type: new 
Abstract: In this work, we propose the joint use of a mixed penalty-logarithmic barrier approach and generating set search, for addressing nonlinearly constrained derivative-free optimization problems. A merit function is considered, wherein the set of inequality constraints is divided into two groups: one treated with a logarithmic barrier approach, and another, along with the equality constraints, addressed using a penalization term. This strategy, initially proposed in the framework of LOG-DFL [12], is adapted and incorporated into SID-PSM [14,15] algorithm, a generalized pattern search method, allowing to effectively handle general nonlinear constraints. Under reasonable assumptions regarding the smoothness of the functions, convergence is established, without any convexity assumptions. Using CUTEst test problems, numerical experiments demonstrate the robustness, efficiency, and overall effectiveness of the proposed method, when compared with state-of-art solvers and with the original SID-PSM and LOG-DFL implementations.</description>
      <guid isPermaLink="false">oai:arXiv.org:2407.21634v1</guid>
      <category>math.OC</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Andrea Brilli, Ana L. Cust\'odio, Giampaolo Liuzzi, Everton J. Silva</dc:creator>
    </item>
    <item>
      <title>Long-Term Energy Management for Microgrid with Hybrid Hydrogen-Battery Energy Storage: A Prediction-Free Coordinated Optimization Framework</title>
      <link>https://arxiv.org/abs/2407.21698</link>
      <description>arXiv:2407.21698v1 Announce Type: new 
Abstract: This paper studies the long-term energy management of a microgrid coordinating hybrid hydrogen-battery energy storage. We develop an approximate semi-empirical hydrogen storage model to accurately capture the power-dependent efficiency of hydrogen storage. We introduce a prediction-free two-stage coordinated optimization framework, which generates the annual state-of-charge (SoC) reference for hydrogen storage offline. During online operation, it updates the SoC reference online using kernel regression and makes operation decisions based on the proposed adaptive virtual-queue-based online convex optimization (OCO) algorithm. We innovatively incorporate penalty terms for long-term pattern tracking and expert-tracking for step size updates. We provide theoretical proof to show that the proposed OCO algorithm achieves a sublinear bound of dynamic regret without using prediction information. Numerical studies based on the Elia and North China datasets show that the proposed framework significantly outperforms the existing online optimization approaches by reducing the operational costs and loss of load by around 30% and 80%, respectively. These benefits can be further enhanced with optimized settings for the penalty coefficient and step size of OCO, as well as more historical references.</description>
      <guid isPermaLink="false">oai:arXiv.org:2407.21698v1</guid>
      <category>math.OC</category>
      <category>cs.SY</category>
      <category>eess.SY</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Ning Qi, Kaidi Huang, Zhiyuan Fan, Bolun Xu</dc:creator>
    </item>
    <item>
      <title>Quasi-Regression Monte-Carlo scheme for semi-linear PDEs and BSDEs with large scale parallelization on GPUs</title>
      <link>https://arxiv.org/abs/2407.21084</link>
      <description>arXiv:2407.21084v1 Announce Type: cross 
Abstract: In this article we design a novel quasi-regression Monte Carlo algorithm in order to approximate the solution of discrete time backward stochastic differential equations (BSDEs), and we analyze the convergence of the proposed method. The algorithm also approximates the solution to the related semi-linear parabolic partial differential equation (PDE) obtained through the well-known Feynman-Kac representation. For the sake of enriching the algorithm with high-order convergence a weighted approximation of the solution is computed and appropriate conditions on the parameters of the method are inferred. With the challenge of tackling problems in high dimensions we propose suitable projections of the solution and efficient parallelizations of the algorithm taking advantage of powerful many-core processors such as graphics processing units (GPUs).</description>
      <guid isPermaLink="false">oai:arXiv.org:2407.21084v1</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <category>math.OC</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <arxiv:DOI>10.1007/s11831-019-09335-x</arxiv:DOI>
      <dc:creator>E. Gobet, J. G. L\'opez-Salas, C. V\'azquez</dc:creator>
    </item>
    <item>
      <title>The Stochastic Conjugate Subgradient Algorithm For Kernel Support Vector Machines</title>
      <link>https://arxiv.org/abs/2407.21091</link>
      <description>arXiv:2407.21091v1 Announce Type: cross 
Abstract: Stochastic First-Order (SFO) methods have been a cornerstone in addressing a broad spectrum of modern machine learning (ML) challenges. However, their efficacy is increasingly questioned, especially in large-scale applications where empirical evidence indicates potential performance limitations. In response, this paper proposes an innovative method specifically designed for kernel support vector machines (SVMs). This method not only achieves faster convergence per iteration but also exhibits enhanced scalability when compared to conventional SFO techniques. Diverging from traditional sample average approximation strategies that typically frame kernel SVM as an 'all-in-one' Quadratic Program (QP), our approach adopts adaptive sampling. This strategy incrementally refines approximation accuracy on an 'as-needed' basis. Crucially, this approach also inspires a decomposition-based algorithm, effectively decomposing parameter selection from error estimation, with the latter being independently determined for each data point. To exploit the quadratic nature of the kernel matrix, we introduce a stochastic conjugate subgradient method. This method preserves many benefits of first-order approaches while adeptly handling both nonlinearity and non-smooth aspects of the SVM problem. Thus, it extends beyond the capabilities of standard SFO algorithms for non-smooth convex optimization. The convergence rate of this novel method is thoroughly analyzed within this paper. Our experimental results demonstrate that the proposed algorithm not only maintains but potentially exceeds the scalability of SFO methods. Moreover, it significantly enhances both speed and accuracy of the optimization process.</description>
      <guid isPermaLink="false">oai:arXiv.org:2407.21091v1</guid>
      <category>cs.LG</category>
      <category>math.OC</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Di Zhang, Suvrajeet Sen</dc:creator>
    </item>
    <item>
      <title>Randomized Controlled Trials of Service Interventions: The Impact of Capacity Constraints</title>
      <link>https://arxiv.org/abs/2407.21322</link>
      <description>arXiv:2407.21322v1 Announce Type: cross 
Abstract: Randomized controlled trials (RCTs), or experiments, are the gold standard for intervention evaluation. However, the main appeal of RCTs, the clean identification of causal effects, can be compromised by interference, when one subject's treatment assignment can influence another subject's behavior or outcomes. In this paper, we formalise and study a type of interference stemming from the operational implementation of a subclass of interventions we term Service Interventions (SIs): interventions that include an on-demand service component provided by a costly and limited resource (e.g., healthcare providers or teachers).
  We show that in such a system, the capacity constraints induce dependencies across experiment subjects, where an individual may need to wait before receiving the intervention. By modeling these dependencies using a queueing system, we show how increasing the number of subjects without increasing the capacity of the system can lead to a nonlinear decrease in the treatment effect size. This has implications for conventional power analysis and recruitment strategies: increasing the sample size of an RCT without appropriately expanding capacity can decrease the study's power. To address this issue, we propose a method to jointly select the system capacity and number of users using the square root staffing rule from queueing theory. We show how incorporating knowledge of the queueing structure can help an experimenter reduce the amount of capacity and number of subjects required while still maintaining high power. In addition, our analysis of congestion-driven interference provides one concrete mechanism to explain why similar protocols can result in different RCT outcomes and why promising interventions at the RCT stage may not perform well at scale.</description>
      <guid isPermaLink="false">oai:arXiv.org:2407.21322v1</guid>
      <category>stat.ME</category>
      <category>math.OC</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Justin Boutilier, Jonas Oddur Jonasson, Hannah Li, Erez Yoeli</dc:creator>
    </item>
    <item>
      <title>A network based approach for unbalanced optimal transport on surfaces</title>
      <link>https://arxiv.org/abs/2407.21346</link>
      <description>arXiv:2407.21346v1 Announce Type: cross 
Abstract: In this paper, we present a neural network approach to address the dynamic unbalanced optimal transport problem on surfaces with point cloud representation. For surfaces with point cloud representation, traditional method is difficult to apply due to the difficulty of mesh generating. Neural network is easy to implement even for complicate geometry. Moreover, instead of solving the original dynamic formulation, we consider the Hamiltonian flow approach, i.e. Karush-Kuhn-Tucker system. Based on this approach, we can exploit mathematical structure of the optimal transport to construct the neural network and the loss function can be simplified. Extensive numerical experiments are conducted for surfaces with different geometry. We also test the method for point cloud with noise, which shows stability of this method. This method is also easy to generalize to diverse range of problems.</description>
      <guid isPermaLink="false">oai:arXiv.org:2407.21346v1</guid>
      <category>math-ph</category>
      <category>math.MP</category>
      <category>math.OC</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Jiangong Pan, Wei Wan, Yuejin Zhang, Chenlong Bao, Zuoqiang Shi</dc:creator>
    </item>
    <item>
      <title>Fisher-Rao distance between truncated distributions and robustness analysis in uncertainty quantification</title>
      <link>https://arxiv.org/abs/2407.21542</link>
      <description>arXiv:2407.21542v1 Announce Type: cross 
Abstract: Input variables in numerical models are often subject to several levels of uncertainty, usually modeled by probability distributions. In the context of uncertainty quantification applied to these models, studying the robustness of output quantities with respect to the input distributions requires: (a) defining variational classes for these distributions; (b) calculating boundary values for the output quantities of interest with respect to these variational classes. The latter should be defined in a way that is consistent with the information structure defined by the ``baseline'' choice of input distributions. Considering parametric families, the variational classes are defined using the geodesic distance in their Riemannian manifold, a generic approach to such problems. Theoretical results and application tools are provided to justify and facilitate the implementation of such robustness studies, in concrete situations where these distributions are truncated -- a setting frequently encountered in applications. The feasibility of our approach is illustrated in a simplified industrial case study.</description>
      <guid isPermaLink="false">oai:arXiv.org:2407.21542v1</guid>
      <category>math.MG</category>
      <category>math.OC</category>
      <category>math.PR</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Baalu Belay Ketema (EDF R\&amp;D PRISME, IMT), Nicolas Bousquet (EDF R\&amp;D PRISME, LPSM), Francesco Costantino (IMT), Fabrice Gamboa (IMT), Bertrand Iooss (EDF R\&amp;D PRISME, IMT, SINCLAIR AI Lab), Roman Sueur (EDF R\&amp;D PRISME)</dc:creator>
    </item>
    <item>
      <title>On odd powers of nonnegative polynomials that are not sums of squares</title>
      <link>https://arxiv.org/abs/2407.21779</link>
      <description>arXiv:2407.21779v1 Announce Type: cross 
Abstract: We initiate a systematic study of nonnegative polynomials $P$ such that $P^k$ is not a sum of squares for any odd $k\geq 1$, calling such $P$ \emph{stubborn}. We develop a new invariant of a real isolated zero of a nonnegative polynomial in the plane, that we call \emph{the SOS-invariant}, and relate it to the well-known delta invariant of a plane curve singularity. Using the SOS-invariant we show that any polynomial that spans an extreme ray of the convex cone of nonnegative ternary forms of degree 6 is stubborn. We also show how to use the SOS-invariant to prove stubbornness of ternary forms in higher degree. Furthermore, we prove that in a given degree and number of variables, nonnegative polynomials that are not stubborn form a convex cone, whose interior consists of all strictly positive polynomials.</description>
      <guid isPermaLink="false">oai:arXiv.org:2407.21779v1</guid>
      <category>math.AG</category>
      <category>math.OC</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Grigoriy Blekherman, Khazhgali Kozhasov, Bruce Reznick</dc:creator>
    </item>
    <item>
      <title>Tracking Control for $(x,u)$-Flat Systems by Quasi-Static Feedback of Classical States</title>
      <link>https://arxiv.org/abs/2110.12995</link>
      <description>arXiv:2110.12995v4 Announce Type: replace 
Abstract: It is well known that for flat systems the tracking control problem can be solved by utilizing a linearizing quasi-static feedback of generalized states. If measurements (or estimates) of a so-called generalized Brunovsk\'y state are available, a linear, decoupled and asymptotically stable tracking error dynamics can be achieved. However, from a practical point of view, it is often desirable to achieve the same tracking error dynamics by feedback of a classical state instead of a generalized one. This is due to the fact that the components of a classical state typically correspond to measurable physical quantities, whereas a generalized Brunovsk\'y state often contains higher order time derivatives of the (fictitious) flat output which are not directly accessible by measurements. In this paper, a systematic solution for the tracking control problem based on quasi-static feedback and measurements of classical states only is derived for the subclass of $(x,u)$-flat systems.</description>
      <guid isPermaLink="false">oai:arXiv.org:2110.12995v4</guid>
      <category>math.OC</category>
      <category>math.DG</category>
      <category>math.DS</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-sa/4.0/</dc:rights>
      <arxiv:DOI>10.3842/SIGMA.2024.071</arxiv:DOI>
      <arxiv:journal_reference>SIGMA 20 (2024), 071, 27 pages</arxiv:journal_reference>
      <dc:creator>Conrad Gst\"ottner, Bernd Kolar, Markus Sch\"oberl</dc:creator>
    </item>
    <item>
      <title>The Subspace Flatness Conjecture and Faster Integer Programming</title>
      <link>https://arxiv.org/abs/2303.14605</link>
      <description>arXiv:2303.14605v4 Announce Type: replace 
Abstract: In a seminal paper, Kannan and Lov\'asz (1988) considered a quantity $\mu_{KL}(\Lambda,K)$ which denotes the best volume-based lower bound on the covering radius $\mu(\Lambda,K)$ of a convex body $K$ with respect to a lattice $\Lambda$. Kannan and Lov\'asz proved that $\mu(\Lambda,K) \leq n \cdot \mu_{KL}(\Lambda,K)$ and the Subspace Flatness Conjecture by Dadush (2012) claims a $O(\log(2n))$ factor suffices, which would match the lower bound from the work of Kannan and Lov\'asz.
  We settle this conjecture up to a constant in the exponent by proving that $\mu(\Lambda,K) \leq O(\log^{3}(2n)) \cdot \mu_{KL} (\Lambda,K)$. Our proof is based on the Reverse Minkowski Theorem due to Regev and Stephens-Davidowitz (2017). Following the work of Dadush (2012, 2019), we obtain a $(\log(2n))^{O(n)}$-time randomized algorithm to solve integer programs in $n$ variables. Another implication of our main result is a near-optimal flatness constant of $O(n \log^{3}(2n))$.</description>
      <guid isPermaLink="false">oai:arXiv.org:2303.14605v4</guid>
      <category>math.OC</category>
      <category>cs.CC</category>
      <category>cs.DM</category>
      <category>cs.DS</category>
      <category>math.CO</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Victor Reis, Thomas Rothvoss</dc:creator>
    </item>
    <item>
      <title>The Hard-Constraint PINNs for Interface Optimal Control Problems</title>
      <link>https://arxiv.org/abs/2308.06709</link>
      <description>arXiv:2308.06709v2 Announce Type: replace 
Abstract: We show that the physics-informed neural networks (PINNs), in combination with some recently developed discontinuity capturing neural networks, can be applied to solve optimal control problems subject to partial differential equations (PDEs) with interfaces and some control constraints. The resulting algorithm is mesh-free and scalable to different PDEs, and it ensures the control constraints rigorously. Since the boundary and interface conditions, as well as the PDEs, are all treated as soft constraints by lumping them into a weighted loss function, it is necessary to learn them simultaneously and there is no guarantee that the boundary and interface conditions can be satisfied exactly. This immediately causes difficulties in tuning the weights in the corresponding loss function and training the neural networks. To tackle these difficulties and guarantee the numerical accuracy, we propose to impose the boundary and interface conditions as hard constraints in PINNs by developing a novel neural network architecture. The resulting hard-constraint PINNs approach guarantees that both the boundary and interface conditions can be satisfied exactly or with a high degree of accuracy, and they are decoupled from the learning of the PDEs. Its efficiency is promisingly validated by some elliptic and parabolic interface optimal control problems.</description>
      <guid isPermaLink="false">oai:arXiv.org:2308.06709v2</guid>
      <category>math.OC</category>
      <category>cs.LG</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Ming-Chih Lai, Yongcun Song, Xiaoming Yuan, Hangrui Yue, Tianyou Zeng</dc:creator>
    </item>
    <item>
      <title>Average Cost Optimality of Partially Observed MDPS: Contraction of Non-linear Filters, Optimal Solutions and Approximations</title>
      <link>https://arxiv.org/abs/2312.14111</link>
      <description>arXiv:2312.14111v3 Announce Type: replace 
Abstract: The average cost optimality is known to be a challenging problem for partially observable stochastic control, with few results available beyond the finite state, action, and measurement setup, for which somewhat restrictive conditions are available. In this paper, we present explicit and easily testable conditions for the existence of solutions to the average cost optimality equation where the state space is compact. In particular, we present a new contraction based analysis, which is new to the literature to our knowledge, building on recent regularity results for non-linear filters. Beyond establishing existence, we also present several implications of our analysis that are new to the literature: (i) robustness to incorrect priors (ii) near optimality of policies based on quantized approximations, (iii) near optimality of policies with finite memory, and (iv) convergence in Q-learning. In addition to our main theorem, each of these represents a novel contribution for average cost criteria.</description>
      <guid isPermaLink="false">oai:arXiv.org:2312.14111v3</guid>
      <category>math.OC</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Yunus Emre Demirci, Ali Devran Kara, Serdar Y\"uksel</dc:creator>
    </item>
    <item>
      <title>Convergence of the deep BSDE method for stochastic control problems formulated through the stochastic maximum principle</title>
      <link>https://arxiv.org/abs/2401.17472</link>
      <description>arXiv:2401.17472v3 Announce Type: replace 
Abstract: It is well-known that decision-making problems from stochastic control can be formulated by means of a forward-backward stochastic differential equation (FBSDE). Recently, the authors of Ji et al. 2022 proposed an efficient deep learning algorithm based on the stochastic maximum principle (SMP). In this paper, we provide a convergence result for this deep SMP-BSDE algorithm and compare its performance with other existing methods. In particular, by adopting a strategy as in Han and Long 2020, we derive a-posteriori estimate, and show that the total approximation error can be bounded by the value of the loss functional and the discretization error. We present numerical examples for high-dimensional stochastic control problems, both in case of drift- and diffusion control, which showcase superior performance compared to existing algorithms.</description>
      <guid isPermaLink="false">oai:arXiv.org:2401.17472v3</guid>
      <category>math.OC</category>
      <category>cs.NA</category>
      <category>math.NA</category>
      <category>q-fin.CP</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Zhipeng Huang, Balint Negyesi, Cornelis W. Oosterlee</dc:creator>
    </item>
    <item>
      <title>Asymptotic, Exponential, and Prescribed-Time Unbiasing in Seeking of Time-Varying Extrema</title>
      <link>https://arxiv.org/abs/2403.16294</link>
      <description>arXiv:2403.16294v2 Announce Type: replace 
Abstract: Our recently developed "unbiased" extremum seeking (uES) algorithms ensure perfect convergence to the optimum at a user-assigned exponential rate or, more powerfully, within a user-prescribed time. Unlike classical approach, these algorithms use time-varying adaptation and controller gains, along with constant or time-varying probing frequencies (chirp signals). This paper advances our earlier uES designs from strongly convex maps with static optima to a broader class of convex cost functions with time-varying optima diverging at arbitrary rates, even in finite time. This advancement first motivates the use of Lie bracket averaging instead of classical averaging due to the average system system, which doesn't necessarily need to be exponentially convergent, and the existence of non-periodic time-varying parameters; second, it necessitates the formulation of non-trivial and key feasibility conditions for the choice of time-varying design parameters and their decay/growth rates in relation to the convexity of the map and the divergence rate of optima. These conditions indicate that, for constant-frequency probing, the user-defined asymptotic rate of unbiasing is limited by the convexity of the map. However, this rate can be made arbitrarily fast (including asymptotic, exponential, and prescribed time) using chirpy probing, which requires sufficiently rapid frequency and adaptation growth to enable tracking of faster-diverging optima. In addition to numerical simulations of the designs, we experimentally test the feasibility of exponential uES for tuning the angular velocity of a unicycle to seek a static light source.</description>
      <guid isPermaLink="false">oai:arXiv.org:2403.16294v2</guid>
      <category>math.OC</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Cemal Tugrul Yilmaz, Mamadou Diagne, Miroslav Krstic</dc:creator>
    </item>
    <item>
      <title>Pole Placement and Feedback Stabilization for Discrete Linear Ensemble Systems</title>
      <link>https://arxiv.org/abs/2403.19017</link>
      <description>arXiv:2403.19017v4 Announce Type: replace 
Abstract: We consider discrete ensembles of linear, scalar control systems with single-inputs. Assuming that all the individual systems are unstable, we investigate whether there exist linear feedback control laws that can asymptotically stabilize the ensemble system. We provide necessary/sufficient conditions for feasibility of pole placement in the left half plane and for feedback stabilizability of the ensemble systems.</description>
      <guid isPermaLink="false">oai:arXiv.org:2403.19017v4</guid>
      <category>math.OC</category>
      <category>math.DS</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Xudong Chen</dc:creator>
    </item>
    <item>
      <title>Optimal distributed control with stability guarantees by training a network of neural closed-loop maps</title>
      <link>https://arxiv.org/abs/2404.02820</link>
      <description>arXiv:2404.02820v2 Announce Type: replace 
Abstract: This paper proposes a novel approach to improve the performance of distributed nonlinear control systems while preserving stability by leveraging Deep Neural Networks (DNNs). We build upon the Neural System Level Synthesis (Neur-SLS) framework and introduce a method to parameterize stabilizing control policies that are distributed across a network topology. A distinctive feature is that we iteratively minimize an arbitrary control cost function through an unconstrained optimization algorithm, all while preserving the stability of the overall network architecture by design. This is achieved through two key steps. First, we establish a method to parameterize interconnected Recurrent Equilibrium Networks (RENs) that guarantees a bounded $\mathcal{L}_2$ gain at the network level. This ensures stability. Second, we demonstrate how the information flow within the network is preserved, enabling a fully distributed implementation where each subsystem only communicates with its neighbors. To showcase the effectiveness of our approach, we present a simulation of a distributed formation control problem for a fleet of vehicles. The simulation demonstrates how the proposed neural controller enables the vehicles to maintain a desired formation while navigating obstacles and avoiding collisions, all while guaranteeing network stability.</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.02820v2</guid>
      <category>math.OC</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Danilo Saccani, Leonardo Massai, Luca Furieri, Giancarlo Ferrari-Trecate</dc:creator>
    </item>
    <item>
      <title>Control in the coefficients of an elliptic differential operator: topological derivatives and Pontryagin maximum principle</title>
      <link>https://arxiv.org/abs/2405.04204</link>
      <description>arXiv:2405.04204v2 Announce Type: replace 
Abstract: We consider optimal control problems, where the control appears in the main part of the operator. We derive the Pontryagin maximum principle as a necessary optimality condition. The proof uses the concept of topological derivatives. In contrast to earlier works, we do not need continuity assumptions for the coefficient or gradients of solutions of partial differential equations. Following classical proofs, we consider perturbations of optimal controls by multiples of characteristic functions of sets, whose scaling factor is send to zero. For $2d$ problems, we can perform an optimization over the elliptic shapes of such sets leading to stronger optimality conditions involving a variational inequality of a new type.</description>
      <guid isPermaLink="false">oai:arXiv.org:2405.04204v2</guid>
      <category>math.OC</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-sa/4.0/</dc:rights>
      <dc:creator>Daniel Wachsmuth</dc:creator>
    </item>
    <item>
      <title>Application of the Lov\'asz-Schrijver Lift-and-Project Operator to Compact Stable Set Integer Programs</title>
      <link>https://arxiv.org/abs/2407.19290</link>
      <description>arXiv:2407.19290v2 Announce Type: replace 
Abstract: The Lov\'asz theta function $\theta(G)$ provides a very good upper bound on the stability number of a graph $G$. It can be computed in polynomial time by solving a semidefinite program (SDP), which also turns out to be fairly tractable in practice. Consequently, $\theta(G)$ achieves a hard-to-beat trade-off between computational effort and strength of the bound. Indeed, several attempts to improve the theta bound are documented, mainly based on playing around the application of the $N_+(\cdot)$ lifting operator of Lov\'asz and Schrijver to the classical formulation of the maximum stable set problem. Experience shows that solving such SDP-s often struggles against practical intractability and requires highly specialized methods. We investigate the application of such an operator to two different linear formulations based on clique and nodal inequalities, respectively. Fewer inequalities describe these two and yet guarantee that the resulting SDP bound is at least as strong as $\theta(G)$. Our computational experience, including larger graphs than those previously documented, shows that upper bounds stronger than $\theta(G)$ can be accessed by a reasonable additional effort using the clique-based formulation on sparse graphs and the nodal-based one on dense graphs.</description>
      <guid isPermaLink="false">oai:arXiv.org:2407.19290v2</guid>
      <category>math.OC</category>
      <category>cs.IT</category>
      <category>math.IT</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <dc:creator>Federico Battista, Fabrizio Rossi, Stefano Smriglio</dc:creator>
    </item>
    <item>
      <title>Accelerated Primal-Dual Proximal Gradient Splitting Methods for Convex-Concave Saddle-Point Problems</title>
      <link>https://arxiv.org/abs/2407.20195</link>
      <description>arXiv:2407.20195v2 Announce Type: replace 
Abstract: In this paper, based a novel primal-dual dynamical model with adaptive scaling parameters and Bregman divergences, we propose new accelerated primal-dual proximal gradient splitting methods for solving bilinear saddle-point problems with provable optimal nonergodic convergence rates. For the first, using the spectral analysis, we show that a naive extension of acceleration model for unconstrained optimization problems to a quadratic game is unstable. Motivated by this, we present an accelerated primal-dual hybrid gradient (APDHG) flow which combines acceleration with careful velocity correction. To work with non-Euclidean distances, we also equip our APDHG model with general Bregman divergences and prove the exponential decay of a Lyapunov function. Then, new primal-dual splitting methods are developed based on proper semi-implicit Euler schemes of the continuous model, and the theoretical convergence rates are nonergodic and optimal with respect to the matrix norms,\, Lipschitz constants and convexity parameters. Thanks to the primal and dual scaling parameters, both the algorithm designing and convergence analysis cover automatically the convex and (partially) strongly convex objectives. Moreover, the use of Bregman divergences not only unifies the standard Euclidean distances and general cases in an elegant way, but also makes our methods more flexible and adaptive to problem-dependent metrics.</description>
      <guid isPermaLink="false">oai:arXiv.org:2407.20195v2</guid>
      <category>math.OC</category>
      <category>cs.NA</category>
      <category>math.NA</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Hao Luo</dc:creator>
    </item>
    <item>
      <title>K-Deep Simplex: Deep Manifold Learning via Local Dictionaries</title>
      <link>https://arxiv.org/abs/2012.02134</link>
      <description>arXiv:2012.02134v4 Announce Type: replace-cross 
Abstract: We propose K-Deep Simplex(KDS) which, given a set of data points, learns a dictionary comprising synthetic landmarks, along with representation coefficients supported on a simplex. KDS employs a local weighted $\ell_1$ penalty that encourages each data point to represent itself as a convex combination of nearby landmarks. We solve the proposed optimization program using alternating minimization and design an efficient, interpretable autoencoder using algorithm unrolling. We theoretically analyze the proposed program by relating the weighted $\ell_1$ penalty in KDS to a weighted $\ell_0$ program. Assuming that the data are generated from a Delaunay triangulation, we prove the equivalence of the weighted $\ell_1$ and weighted $\ell_0$ programs. We further show the stability of the representation coefficients under mild geometrical assumptions. If the representation coefficients are fixed, we prove that the sub-problem of minimizing over the dictionary yields a unique solution. Further, we show that low-dimensional representations can be efficiently obtained from the covariance of the coefficient matrix. Experiments show that the algorithm is highly efficient and performs competitively on synthetic and real data sets.</description>
      <guid isPermaLink="false">oai:arXiv.org:2012.02134v4</guid>
      <category>cs.LG</category>
      <category>cs.IT</category>
      <category>eess.SP</category>
      <category>math.IT</category>
      <category>math.OC</category>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <dc:creator>Pranay Tankala, Abiy Tasissa, James M. Murphy, Demba Ba</dc:creator>
    </item>
    <item>
      <title>Comparative Statics for Optimal Stopping Problems in Nonstationary Environments</title>
      <link>https://arxiv.org/abs/2402.06999</link>
      <description>arXiv:2402.06999v2 Announce Type: replace-cross 
Abstract: How do decisions change with the economic environment and with time? This paper studies general nonstationary stopping problems and provides the methodological tools to answer these questions. First, we identify conditions that ensure a monotone relation between decisions' timing and outcomes. These conditions apply to a prevalent class of economic environments. Second, we develop a theory of monotone comparative statics for stopping problems, offering general and unifying qualitative insights into the decision-maker's value and stopping behavior. We apply our results to models of information acquisition, bankruptcy, irreversible investment, and option pricing to explain documented patterns at odds with current theories.</description>
      <guid isPermaLink="false">oai:arXiv.org:2402.06999v2</guid>
      <category>econ.TH</category>
      <category>math.AP</category>
      <category>math.OC</category>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <dc:creator>Th\'eo Durandard, Matteo Camboni</dc:creator>
    </item>
    <item>
      <title>Model order reduction for the TASEP Master equation</title>
      <link>https://arxiv.org/abs/2402.10234</link>
      <description>arXiv:2402.10234v2 Announce Type: replace-cross 
Abstract: The totally asymmetric simple exclusion process (TASEP) is a stochastic model for the unidirectional dynamics of interacting particles on a $1$D-lattice that is much used in systems biology and statistical physics. Its master equation describes the evolution of the probability distribution on the state space. The size of the master equation grows exponentially with the length of the lattice. It is known that the complexity of the system may be reduced using mean field approximations. We provide a rigorous derivation and a stochastic interpretation of these approximations and present numerical results on their accuracy for a number of relevant cases.</description>
      <guid isPermaLink="false">oai:arXiv.org:2402.10234v2</guid>
      <category>cond-mat.stat-mech</category>
      <category>math.OC</category>
      <category>math.PR</category>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Kilian Pioch, Thomas Kriecherbauer, Michael Margaliot, Lars Gr\"une</dc:creator>
    </item>
    <item>
      <title>FedADMM-InSa: An Inexact and Self-Adaptive ADMM for Federated Learning</title>
      <link>https://arxiv.org/abs/2402.13989</link>
      <description>arXiv:2402.13989v3 Announce Type: replace-cross 
Abstract: Federated learning (FL) is a promising framework for learning from distributed data while maintaining privacy. The development of efficient FL algorithms encounters various challenges, including heterogeneous data and systems, limited communication capacities, and constrained local computational resources. Recently developed FedADMM methods show great resilience to both data and system heterogeneity. However, they still suffer from performance deterioration if the hyperparameters are not carefully tuned. To address this issue, we propose an inexact and self-adaptive FedADMM algorithm, termed FedADMM-InSa. First, we design an inexactness criterion for the clients' local updates to eliminate the need for empirically setting the local training accuracy. This inexactness criterion can be assessed by each client independently based on its unique condition, thereby reducing the local computational cost and mitigating the undesirable straggle effect. The convergence of the resulting inexact ADMM is proved under the assumption of strongly convex loss functions. Additionally, we present a self-adaptive scheme that dynamically adjusts each client's penalty parameter, enhancing algorithm robustness by mitigating the need for empirical penalty parameter choices for each client. Extensive numerical experiments on both synthetic and real-world datasets are conducted. As validated by some numerical tests, our proposed algorithm can reduce the clients' local computational load significantly and also accelerate the learning process compared to the vanilla FedADMM.</description>
      <guid isPermaLink="false">oai:arXiv.org:2402.13989v3</guid>
      <category>cs.LG</category>
      <category>cs.CR</category>
      <category>cs.DC</category>
      <category>math.OC</category>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <dc:creator>Yongcun Song, Ziqi Wang, Enrique Zuazua</dc:creator>
    </item>
    <item>
      <title>cDVAE: Multimodal Generative Conditional Diffusion Guided by Variational Autoencoder Latent Embedding for Virtual 6D Phase Space Diagnostics</title>
      <link>https://arxiv.org/abs/2407.20218</link>
      <description>arXiv:2407.20218v3 Announce Type: replace-cross 
Abstract: Imaging the 6D phase space of a beam in a particle accelerator in a single shot is currently impossible. Single shot beam measurements only exist for certain 2D beam projections and these methods are destructive. A virtual diagnostic that can generate an accurate prediction of a beam's 6D phase space would be incredibly useful for precisely controlling the beam. In this work, a generative conditional diffusion-based approach to creating a virtual diagnostic of all 15 unique 2D projections of a beam's 6D phase space is developed. The diffusion process is guided by a combination of scalar parameters and images that are converted to low-dimensional latent vector representation by a variational autoencoder (VAE). We demonstrate that conditional diffusion guided by VAE (cDVAE) can accurately reconstruct all 15 of the unique 2D projections of a charge particle beam's 6 phase space for the HiRES compact accelerator.</description>
      <guid isPermaLink="false">oai:arXiv.org:2407.20218v3</guid>
      <category>physics.acc-ph</category>
      <category>math.OC</category>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Alexander Scheinker</dc:creator>
    </item>
  </channel>
</rss>
