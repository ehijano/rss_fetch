<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>physics.data-an updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/physics.data-an</link>
    <description>physics.data-an updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/physics.data-an" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Thu, 04 Sep 2025 04:00:52 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Thu, 04 Sep 2025 00:00:00 -0400</pubDate>
    <skipDays>
      <day>Sunday</day>
      <day>Saturday</day>
    </skipDays>
    <item>
      <title>Confidence intervals for the Poisson distribution</title>
      <link>https://arxiv.org/abs/2509.02852</link>
      <description>arXiv:2509.02852v1 Announce Type: new 
Abstract: The Poisson probability distribution is frequently encountered in physical science measurements. In spite of the simplicity and familiarity of this distribution, there is considerable confusion among physicists concerning the description of results obtained via Poisson sampling. The goal of this paper is to mitigate this confusion by examining and comparing the properties of both conventional and popular alternative techniques. We concern ourselves in particular with the description of results, as opposed to interpretation. After considering performance with respect to several desirable properties we recommend summarizing the results of Poisson sampling with confidence intervals proposed by Garwood. We note that the $p$ values obtained from these intervals are well-behaved and intuitive, providing for a consistent treatment. We also find that averaging intervals can be problematic if the underlying Poisson distributions are not used. The considerations here provide a basis for describing results from other distributions as well.</description>
      <guid isPermaLink="false">oai:arXiv.org:2509.02852v1</guid>
      <category>physics.data-an</category>
      <pubDate>Thu, 04 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Frank C. Porter</dc:creator>
    </item>
    <item>
      <title>Eigendecompositions of temporal networks</title>
      <link>https://arxiv.org/abs/2509.03135</link>
      <description>arXiv:2509.03135v1 Announce Type: new 
Abstract: Temporal networks, defined as sequences of time-aggregated adjacency matrices, sample latent graph dynamics and trace trajectories in graph space. By interpreting each adjacency matrix as a different time snapshot of a scalar field, fluid-mechanics theories can be applied to construct two distinct eigendecompositions of temporal networks. The first builds on the proper orthogonal decomposition (POD) of flowfields and decomposes the evolution of a network in terms of a basis of orthogonal network eigenmodes which are ordered in terms of their relative importance, hence enabling compression of temporal networks as well as their reconstruction from low-dimensional embeddings. The second proposes a numerical approximation of the Koopman operator, a linear operator acting on a suitable observable of the graph space which provides the best linear approximation of the latent graph dynamics. Its eigendecomposition provides a data-driven spectral description of the temporal network dynamics, in terms of dynamic modes which grow, decay or oscillate over time. Both eigendecompositions are illustrated and validated in a suite of synthetic generative models of temporal networks with varying complexity.</description>
      <guid isPermaLink="false">oai:arXiv.org:2509.03135v1</guid>
      <category>physics.data-an</category>
      <category>physics.soc-ph</category>
      <pubDate>Thu, 04 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Lucas Lacasa</dc:creator>
    </item>
    <item>
      <title>The Future of Artificial Intelligence and the Mathematical and Physical Sciences (AI+MPS)</title>
      <link>https://arxiv.org/abs/2509.02661</link>
      <description>arXiv:2509.02661v1 Announce Type: cross 
Abstract: This community paper developed out of the NSF Workshop on the Future of Artificial Intelligence (AI) and the Mathematical and Physics Sciences (MPS), which was held in March 2025 with the goal of understanding how the MPS domains (Astronomy, Chemistry, Materials Research, Mathematical Sciences, and Physics) can best capitalize on, and contribute to, the future of AI. We present here a summary and snapshot of the MPS community's perspective, as of Spring/Summer 2025, in a rapidly developing field. The link between AI and MPS is becoming increasingly inextricable; now is a crucial moment to strengthen the link between AI and Science by pursuing a strategy that proactively and thoughtfully leverages the potential of AI for scientific discovery and optimizes opportunities to impact the development of AI by applying concepts from fundamental science. To achieve this, we propose activities and strategic priorities that: (1) enable AI+MPS research in both directions; (2) build up an interdisciplinary community of AI+MPS researchers; and (3) foster education and workforce development in AI for MPS researchers and students. We conclude with a summary of suggested priorities for funding agencies, educational institutions, and individual researchers to help position the MPS community to be a leader in, and take full advantage of, the transformative potential of AI+MPS.</description>
      <guid isPermaLink="false">oai:arXiv.org:2509.02661v1</guid>
      <category>cs.AI</category>
      <category>astro-ph.IM</category>
      <category>cond-mat.mtrl-sci</category>
      <category>cs.LG</category>
      <category>physics.data-an</category>
      <pubDate>Thu, 04 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Andrew Ferguson, Marisa LaFleur, Lars Ruthotto, Jesse Thaler, Yuan-Sen Ting, Pratyush Tiwary, Soledad Villar, E. Paulo Alves, Jeremy Avigad, Simon Billinge, Camille Bilodeau, Keith Brown, Emmanuel Candes, Arghya Chattopadhyay, Bingqing Cheng, Jonathan Clausen, Connor Coley, Andrew Connolly, Fred Daum, Sijia Dong, Chrisy Xiyu Du, Cora Dvorkin, Cristiano Fanelli, Eric B. Ford, Luis Manuel Frutos, Nicol\'as Garc\'ia Trillos, Cecilia Garraffo, Robert Ghrist, Rafael Gomez-Bombarelli, Gianluca Guadagni, Sreelekha Guggilam, Sergei Gukov, Juan B. Guti\'errez, Salman Habib, Johannes Hachmann, Boris Hanin, Philip Harris, Murray Holland, Elizabeth Holm, Hsin-Yuan Huang, Shih-Chieh Hsu, Nick Jackson, Olexandr Isayev, Heng Ji, Aggelos Katsaggelos, Jeremy Kepner, Yannis Kevrekidis, Michelle Kuchera, J. Nathan Kutz, Branislava Lalic, Ann Lee, Matt LeBlanc, Josiah Lim, Rebecca Lindsey, Yongmin Liu, Peter Y. Lu, Sudhir Malik, Vuk Mandic, Vidya Manian, Emeka P. Mazi, Pankaj Mehta, Peter Melchior, Brice M\'enard, Jennifer Ngadiuba, Stella Offner, Elsa Olivetti, Shyue Ping Ong, Christopher Rackauckas, Philippe Rigollet, Chad Risko, Philip Romero, Grant Rotskoff, Brett Savoie, Uros Seljak, David Shih, Gary Shiu, Dima Shlyakhtenko, Eva Silverstein, Taylor Sparks, Thomas Strohmer, Christopher Stubbs, Stephen Thomas, Suriyanarayanan Vaikuntanathan, Rene Vidal, Francisco Villaescusa-Navarro, Gregory Voth, Benjamin Wandelt, Rachel Ward, Melanie Weber, Risa Wechsler, Stephen Whitelam, Olaf Wiest, Mike Williams, Zhuoran Yang, Yaroslava G. Yingling, Bin Yu, Shuwen Yue, Ann Zabludoff, Huimin Zhao, Tong Zhang</dc:creator>
    </item>
    <item>
      <title>Deep Variational Multivariate Information Bottleneck -- A Framework for Variational Losses</title>
      <link>https://arxiv.org/abs/2310.03311</link>
      <description>arXiv:2310.03311v4 Announce Type: replace-cross 
Abstract: Variational dimensionality reduction methods are widely used for their accuracy, generative capabilities, and robustness. We introduce a unifying framework that generalizes both such as traditional and state-of-the-art methods. The framework is based on an interpretation of the multivariate information bottleneck, trading off the information preserved in an encoder graph (defining what to compress) against that in a decoder graph (defining a generative model for data). Using this approach, we rederive existing methods, including the deep variational information bottleneck, variational autoencoders, and deep multiview information bottleneck. We naturally extend the deep variational CCA (DVCCA) family to beta-DVCCA and introduce a new method, the deep variational symmetric information bottleneck (DVSIB). DSIB, the deterministic limit of DVSIB, connects to modern contrastive learning approaches such as Barlow Twins, among others. We evaluate these methods on Noisy MNIST and Noisy CIFAR-100, showing that algorithms better matched to the structure of the problem like DVSIB and beta-DVCCA produce better latent spaces as measured by classification accuracy, dimensionality of the latent variables, sample efficiency, and consistently outperform other approaches under comparable conditions. Additionally, we benchmark against state-of-the-art models, achieving superior or competitive accuracy. Our results demonstrate that this framework can seamlessly incorporate diverse multi-view representation learning algorithms, providing a foundation for designing novel, problem-specific loss functions.</description>
      <guid isPermaLink="false">oai:arXiv.org:2310.03311v4</guid>
      <category>cs.LG</category>
      <category>cond-mat.stat-mech</category>
      <category>cs.IT</category>
      <category>math.IT</category>
      <category>physics.data-an</category>
      <pubDate>Thu, 04 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Eslam Abdelaleem, Ilya Nemenman, K. Michael Martini</dc:creator>
    </item>
    <item>
      <title>Principled model selection for stochastic dynamics</title>
      <link>https://arxiv.org/abs/2501.10339</link>
      <description>arXiv:2501.10339v3 Announce Type: replace-cross 
Abstract: Complex dynamical systems, from macromolecules to ecosystems, are often modeled by stochastic differential equations. To learn such models from data, a common approach involves sparse selection among a large function library. However, we show that overfitting arises not just from individual model complexity, but also from the combinatorial growth of possible models. To address this, we introduce Parsimonious Stochastic Inference (PASTIS), a principled method combining likelihood-estimation statistics with extreme value theory to suppress superfluous parameters. PASTIS outperforms existing methods and reliably identifies minimal models, even with low sampling rates or measurement error. It extends to stochastic partial differential equations, and applies to ecological networks and reaction-diffusion dynamics.</description>
      <guid isPermaLink="false">oai:arXiv.org:2501.10339v3</guid>
      <category>cond-mat.soft</category>
      <category>cond-mat.stat-mech</category>
      <category>physics.data-an</category>
      <category>stat.ML</category>
      <pubDate>Thu, 04 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Andonis Gerardos, Pierre Ronceray</dc:creator>
    </item>
    <item>
      <title>Fast, accurate, and predictive method for atom detection in site-resolved images of microtrap arrays</title>
      <link>https://arxiv.org/abs/2502.08511</link>
      <description>arXiv:2502.08511v3 Announce Type: replace-cross 
Abstract: We introduce a new method, rooted in estimation theory, to detect individual atoms in site-resolved images of microtrap arrays, such as optical lattices or optical tweezers arrays. Using labelled test images, we demonstrate drastic improvement of the detection accuracy compared to the popular method based on Wiener deconvolution when the inter-site distance is comparable to the radius of the point spread function. The runtime of our method scales approximately linearly with the number of sites, and remains well below 100 ms for an array of 100 x 100 sites on a desktop computer. It is therefore fully compatible with a real-time usage. Finally, we propose a rigorous definition for the signal-to-noise ratio of the problem, and show that it can be used as a predictor for the detection error rate. Our work opens the prospect for future experiments with increased array sizes, or reduced inter-site distances.</description>
      <guid isPermaLink="false">oai:arXiv.org:2502.08511v3</guid>
      <category>quant-ph</category>
      <category>physics.data-an</category>
      <pubDate>Thu, 04 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-sa/4.0/</dc:rights>
      <dc:creator>Marc Cheneau, Romaric Journet, Matthieu Boffety, Fran\c{c}ois Goudail, Caroline Kulcs\'ar, Pauline Trouv\'e-Peloux</dc:creator>
    </item>
    <item>
      <title>Learning and Interpreting Gravitational-Wave Features from CNNs with a Random Forest Approach</title>
      <link>https://arxiv.org/abs/2505.20357</link>
      <description>arXiv:2505.20357v2 Announce Type: replace-cross 
Abstract: Convolutional neural networks (CNNs) have become widely adopted in gravitational wave (GW) detection pipelines due to their ability to automatically learn hierarchical features from raw strain data. However, the physical meaning of these learned features remains underexplored, limiting the interpretability of such models. In this work, we propose a hybrid architecture that combines a CNN-based feature extractor with a random forest (RF) classifier to improve both detection performance and interpretability. Unlike prior approaches that directly connect classifiers to CNN outputs, our method introduces four physically interpretable metrics - variance, signal-to-noise ratio (SNR), waveform overlap, and peak amplitude - computed from the final convolutional layer. These are jointly used with the CNN output in the RF classifier to enable more informed decision boundaries. Tested on long-duration strain datasets, our hybrid model outperforms a baseline CNN model, achieving a relative improvement of 21\% in sensitivity at a fixed false alarm rate of 10 events per month. Notably, it also shows improved detection of low-SNR signals (SNR $\le$ 10), which are especially vulnerable to misclassification in noisy environments. Feature attribution via the RF model reveals that both CNN-extracted and handcrafted features contribute significantly to classification decisions, with learned variance and CNN outputs ranked among the most informative. These findings suggest that physically motivated post-processing of CNN feature maps can serve as a valuable tool for interpretable and efficient GW detection, bridging the gap between deep learning and domain knowledge.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.20357v2</guid>
      <category>cs.LG</category>
      <category>gr-qc</category>
      <category>physics.data-an</category>
      <pubDate>Thu, 04 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <arxiv:DOI>10.1088/2632-2153/adfc27</arxiv:DOI>
      <arxiv:journal_reference>2025 Mach. Learn.: Sci. Technol. 6 035045</arxiv:journal_reference>
      <dc:creator>Jun Tian, He Wang, Jibo He, Yu Pan, Shuo Cao, Qingquan Jiang</dc:creator>
    </item>
    <item>
      <title>Reentrant localization in a quasiperiodic chain with correlated hopping sequences</title>
      <link>https://arxiv.org/abs/2506.02716</link>
      <description>arXiv:2506.02716v2 Announce Type: replace-cross 
Abstract: Quasiperiodic systems are known to exhibit localization transitions in low dimensions, wherein all electronic states become localized beyond a critical disorder strength. Interestingly, recent studies have uncovered a reentrant localization (RL) phenomenon: upon further increasing the quasiperiodic modulation strength beyond the localization threshold, a subset of previously localized states can become delocalized again within a specific parameter window. While RL transitions have been primarily explored in systems with simple periodic modulations, such as dimerized or long-range hopping integrals, the impact of more intricate or correlated hopping structures on RL behavior remains largely elusive. In this work, we investigate the localization behavior in a one-dimensional lattice featuring staggered, correlated on-site potentials following the Aubry-Andr\'{e}-Harper model, along with off-diagonal hopping modulations structured according to quasiperiodic Fibonacci and Bronze Mean sequences. By systematically analyzing the fractal dimension, inverse participation ratio, and normalized participation ratio, we demonstrate the occurrence of RL transitions induced purely by the interplay between quasiperiodic on-site disorder and correlated hopping. We further examine the parameter space to determine the specific regimes that give rise to RL. Our findings highlight the crucial role of underlying structural correlations in governing localization-delocalization transitions in low-dimensional quasiperiodic systems, where the correlated disorder manifests in both diagonal and off-diagonal terms.</description>
      <guid isPermaLink="false">oai:arXiv.org:2506.02716v2</guid>
      <category>cond-mat.dis-nn</category>
      <category>cond-mat.mes-hall</category>
      <category>cond-mat.str-el</category>
      <category>physics.comp-ph</category>
      <category>physics.data-an</category>
      <pubDate>Thu, 04 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <arxiv:DOI>10.1088/1361-648X/ae025a</arxiv:DOI>
      <dc:creator>Sourav Karmakar, Sudin Ganguly, Santanu K. Maiti</dc:creator>
    </item>
  </channel>
</rss>
