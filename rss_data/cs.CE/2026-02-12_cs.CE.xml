<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>cs.CE updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/cs.CE</link>
    <description>cs.CE updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/cs.CE" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Fri, 13 Feb 2026 02:49:24 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Thu, 12 Feb 2026 00:00:00 -0500</pubDate>
    <skipDays>
      <day>Saturday</day>
      <day>Sunday</day>
    </skipDays>
    <item>
      <title>Multi-objective computational design optimization of a Total Disc Replacement implant</title>
      <link>https://arxiv.org/abs/2602.10304</link>
      <description>arXiv:2602.10304v1 Announce Type: new 
Abstract: While cervical arthroplasty using Total Disc Replacement (TDR) implants is an established treatment for persistent neck and arm pain, revision rates limit it from reaching its full potential. To address the underlying complications, we developed finite element simulation-driven design optimizations for a TDR's bone-implant interface and motion-preservation features. These automated processes explored high-dimensional design spaces iteratively through analysis of design variations interplay with spinal structures. The optimizations were metamodel-based using artificial neural networks and a hybrid optimizer. They optimized the motion-preservation zone towards replicating the asymptomatic spinal segment's ligaments strain profiles and its facet joint force profiles during main motions. This design process aims to minimize the risk for postoperative pain, avoidable degeneration and to restore segmental biomechanics, to prevent adjacent segment effects. Designs with single articulation and with dual articulation (with a mobile insert) were optimized. The bone-implant interface was optimized with the aim to minimize the risk for subsidence and implant migration. The optimizations improved the multi-objective value of the bone-implant interface by 14.6% and that of the motion-preservation zone by 36.1%. Implant migration, the leading cause of revisions, was reduced by 24.8%. With this, we show the potential of simulation-driven implant design optimization for addressing complex clinical challenges.</description>
      <guid isPermaLink="false">oai:arXiv.org:2602.10304v1</guid>
      <category>cs.CE</category>
      <pubDate>Thu, 12 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Lucia K\"olle, Victor Oei, Ida M\'onus, Syn Schmitt, Daniel Haschtmann, Fabio Galbusera, Stephen J. Ferguson, Benedikt Helgason</dc:creator>
    </item>
    <item>
      <title>Navigating heterogeneous protein landscapes through geometry-aware smoothing</title>
      <link>https://arxiv.org/abs/2602.10422</link>
      <description>arXiv:2602.10422v1 Announce Type: new 
Abstract: The evolutionary fitness landscape of biological molecules is extremely sparse and heterogeneous, with functional sequences forming isolated dense ``islands'' within a vast combinatorial space of largely non-functional variants. Protein sequences, in particular, exemplify this structure, yet most generative artificial intelligence models implicitly assume a homogeneous data distribution. We show that this assumption fundamentally breaks down in heterogeneous biological sequence spaces: fixed global noise levels impose a destructive trade-off, either oversmoothing dense functional clusters or fragmenting sparse regions and producing non-functional hallucinations. To address this limitation, we introduce \emph{Density-Dependent Smoothing} (DDS), a geometry-aware generative framework that adapts stochastic smoothing to the local density of the underlying sequence landscape. By inversely coupling diffusion noise to estimated sequence density, DDS enables gentle refinement in high-density functional regions while promoting controlled exploration across sparse regions. Implemented as a plug-in mechanism for discrete molecular sampling, DDS consistently outperforms state-of-the-art diffusion and autoregressive models across antibody repertoires, therapeutic antibody design, antimicrobial peptide generation and coronavirus antibody design. Together, these results show that fixed global smoothing assumptions fundamentally limit generative modeling in sparse biological sequence spaces, and that geometry-aware smoothing removes this constraint, enabling reliable exploration and design previously unattainable with fixed-noise generative models.</description>
      <guid isPermaLink="false">oai:arXiv.org:2602.10422v1</guid>
      <category>cs.CE</category>
      <pubDate>Thu, 12 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Srinivas Anumasa, Barath Chandran, Tingting Chen, Nuwaisir Mohammad Rahman, Yingtao Zhu, Rushi Shah, Hongyu He, Peisong Zhang, Yizhen Liao, Yiming Tang, Yong Shen, Tianfan Fu, Rui Qing, Xiao Li, Sebastian Maurer-Stroh, Xinyi Su, Zhizhuo Zhang, Dianbo Liu</dc:creator>
    </item>
    <item>
      <title>Multiconfiguration Pair-Density Functional Theory Calculations of Ground and Excited States of Complex Chemical Systems with Quantum Computers</title>
      <link>https://arxiv.org/abs/2602.10435</link>
      <description>arXiv:2602.10435v1 Announce Type: new 
Abstract: Accurately describing strong electron correlation in complex systems remains a prominent challenge in computational chemistry as near-term quantum algorithms treating total correlation often require prohibitively deep circuits. Here we present a hybrid strategy combining the Variational Quantum Eigensolver with Multiconfiguration Pair-Density Functional Theory to efficiently decouple correlation effects. This approach confines static correlation to a compact multireference quantum state while recovering dynamic correlation through a classical on-top density functional using reduced-density information. By enabling self-consistent orbital optimization, the method significantly reduces quantum resource overheads without sacrificing physical rigor. We demonstrate chemical accuracy on standard benchmarks by reproducing C$_2$ equilibrium bond lengths and benzene excitation energies with mean absolute errors of 0.006 {\AA} and 0.048 eV respectively. Most notably, for the strongly correlated Cr$_2$ dimer requiring a large complete active space (48e, 42o), the framework yields a bound potential-energy curve and recovers qualitative dissociation behavior despite realistic hardware noise. These results establish that separating correlation types provides a practical route to reliable predictions on near-term quantum hardware.</description>
      <guid isPermaLink="false">oai:arXiv.org:2602.10435v1</guid>
      <category>cs.CE</category>
      <pubDate>Thu, 12 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Zhanou Liu, Yuhao Chen, Yingjin Ma, Xiao He, Yuxin Deng</dc:creator>
    </item>
    <item>
      <title>Cross-Sectional Asset Retrieval via Future-Aligned Soft Contrastive Learning</title>
      <link>https://arxiv.org/abs/2602.10711</link>
      <description>arXiv:2602.10711v1 Announce Type: new 
Abstract: Asset retrieval--finding similar assets in a financial universe--is central to quantitative investment decision-making. Existing approaches define similarity through historical price patterns or sector classifications, but such backward-looking criteria provide no guarantee about future behavior. We argue that effective asset retrieval should be future-aligned: the retrieved assets should be those most likely to exhibit correlated future returns. To this end, we propose Future-Aligned Soft Contrastive Learning (FASCL), a representation learning framework whose soft contrastive loss uses pairwise future return correlations as continuous supervision targets. We further introduce an evaluation protocol designed to directly assess whether retrieved assets share similar future trajectories. Experiments on 4,229 US equities demonstrate that FASCL consistently outperforms 13 baselines across all future-behavior metrics. The source code will be available soon.</description>
      <guid isPermaLink="false">oai:arXiv.org:2602.10711v1</guid>
      <category>cs.CE</category>
      <category>cs.AI</category>
      <pubDate>Thu, 12 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Hyeongmin Lee, Chanyeol Choi, Jihoon Kwon, Yoon Kim, Alejandro Lopez-Lira, Wonbin Ahn, Yongjae Lee</dc:creator>
    </item>
    <item>
      <title>AntigenLM: Structure-Aware DNA Language Modeling for Influenza</title>
      <link>https://arxiv.org/abs/2602.09067</link>
      <description>arXiv:2602.09067v1 Announce Type: cross 
Abstract: Language models have advanced sequence analysis, yet DNA foundation models often lag behind task-specific methods for unclear reasons. We present AntigenLM, a generative DNA language model pretrained on influenza genomes with intact, aligned functional units. This structure-aware pretraining enables AntigenLM to capture evolutionary constraints and generalize across tasks. Fine-tuned on time-series hemagglutinin (HA) and neuraminidase (NA) sequences, AntigenLM accurately forecasts future antigenic variants across regions and subtypes, including those unseen during training, outperforming phylogenetic and evolution-based models. It also achieves near-perfect subtype classification. Ablation studies show that disrupting genomic structure through fragmentation or shuffling severely degrades performance, revealing the importance of preserving functional-unit integrity in DNA language modeling. AntigenLM thus provides both a powerful framework for antigen evolution prediction and a general principle for building biologically grounded DNA foundation models.</description>
      <guid isPermaLink="false">oai:arXiv.org:2602.09067v1</guid>
      <category>q-bio.GN</category>
      <category>cs.AI</category>
      <category>cs.CE</category>
      <category>cs.CL</category>
      <pubDate>Thu, 12 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Yue Pei, Xuebin Chi, Yu Kang</dc:creator>
    </item>
    <item>
      <title>The CLEF-2026 FinMMEval Lab: Multilingual and Multimodal Evaluation of Financial AI Systems</title>
      <link>https://arxiv.org/abs/2602.10886</link>
      <description>arXiv:2602.10886v1 Announce Type: cross 
Abstract: We present the setup and the tasks of the FinMMEval Lab at CLEF 2026, which introduces the first multilingual and multimodal evaluation framework for financial Large Language Models (LLMs). While recent advances in financial natural language processing have enabled automated analysis of market reports, regulatory documents, and investor communications, existing benchmarks remain largely monolingual, text-only, and limited to narrow subtasks. FinMMEval 2026 addresses this gap by offering three interconnected tasks that span financial understanding, reasoning, and decision-making: Financial Exam Question Answering, Multilingual Financial Question Answering (PolyFiQA), and Financial Decision Making. Together, these tasks provide a comprehensive evaluation suite that measures models' ability to reason, generalize, and act across diverse languages and modalities. The lab aims to promote the development of robust, transparent, and globally inclusive financial AI systems, with datasets and evaluation resources publicly released to support reproducible research.</description>
      <guid isPermaLink="false">oai:arXiv.org:2602.10886v1</guid>
      <category>cs.CL</category>
      <category>cs.AI</category>
      <category>cs.CE</category>
      <pubDate>Thu, 12 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Zhuohan Xie, Rania Elbadry, Fan Zhang, Georgi Georgiev, Xueqing Peng, Lingfei Qian, Jimin Huang, Dimitar Dimitrov, Vanshikaa Jani, Yuyang Dai, Jiahui Geng, Yuxia Wang, Ivan Koychev, Veselin Stoyanov, Preslav Nakov</dc:creator>
    </item>
    <item>
      <title>Integrating granular data into a multilayer network: an interbank model of the euro area for systemic risk assessment</title>
      <link>https://arxiv.org/abs/2602.10960</link>
      <description>arXiv:2602.10960v1 Announce Type: cross 
Abstract: Micro-structural models of contagion and systemic risk emphasize that shock propagation is inherently multi-channel, spanning counterparty exposures, short-term funding and roll-over risk, securities cross-holdings, and common-asset (fire-sale) spillovers. Empirical implementations, however, often rely on stylized or simulated networks, or focus on a single exposure dimension, reflecting the practical difficulty of reconciling heterogeneous granular collections into a coherent representation with consistent identifiers and consolidation rules. We close part of this gap by constructing an empirically grounded multilayer network for euro area significant banking groups that integrates several supervisory and statistical datasets into layer-consistent exposure matrices defined on a common node set. Each layer corresponds to a distinct transmission channel, long- and short-term credit, securities cross-holdings, short-term secured funding, and overlapping external portfolios, and nodes are enriched with balance-sheet information to support model calibration. We document pronounced cross-layer heterogeneity in connectivity and centrality, and show that an aggregated (flattened) representation can mask economically relevant structure and misidentify the institutions that are systemically important in specific markets. We then illustrate how the resulting network disciplines standard systemic-risk analytics by implementing a centrality-based propagation measure and a micro-structural agent-based framework on real exposures. The approach provides a data-grounded basis for layer-aware systemic-risk assessment and stress testing across multiple dimensions of the banking network.</description>
      <guid isPermaLink="false">oai:arXiv.org:2602.10960v1</guid>
      <category>q-fin.ST</category>
      <category>cs.CE</category>
      <category>econ.EM</category>
      <category>q-fin.RM</category>
      <category>stat.CO</category>
      <pubDate>Thu, 12 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <arxiv:DOI>10.1007/s11634-026-00668-7</arxiv:DOI>
      <arxiv:journal_reference>Adv Data Anal Classif (2026)</arxiv:journal_reference>
      <dc:creator>Ilias Aarab, Thomas Gottron, Andrea Colombo, J\"org Reddig, Annalauro Ianiro</dc:creator>
    </item>
    <item>
      <title>Direct Learning of Calibration-Aware Uncertainty for Neural PDE Surrogates</title>
      <link>https://arxiv.org/abs/2602.11090</link>
      <description>arXiv:2602.11090v1 Announce Type: cross 
Abstract: Neural PDE surrogates are often deployed in data-limited or partially observed regimes where downstream decisions depend on calibrated uncertainty in addition to low prediction error. Existing approaches obtain uncertainty through ensemble replication, fixed stochastic noise such as dropout, or post hoc calibration. Cross-regularized uncertainty learns uncertainty parameters during training using gradients routed through a held-out regularization split. The predictor is optimized on the training split for fit, while low-dimensional uncertainty controls are optimized on the regularization split to reduce train-test mismatch, yielding regime-adaptive uncertainty without per-regime noise tuning. The framework can learn continuous noise levels at the output head, within hidden features, or within operator-specific components such as spectral modes. We instantiate the approach in Fourier Neural Operators and evaluate on APEBench sweeps over observed fraction and training-set size. Across these sweeps, the learned predictive distributions are better calibrated on held-out splits and the resulting uncertainty fields concentrate in high-error regions in one-step spatial diagnostics.</description>
      <guid isPermaLink="false">oai:arXiv.org:2602.11090v1</guid>
      <category>cs.LG</category>
      <category>cs.AI</category>
      <category>cs.CE</category>
      <category>stat.CO</category>
      <pubDate>Thu, 12 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Carlos Stein Brito</dc:creator>
    </item>
    <item>
      <title>Deformation-Recovery Diffusion Model (DRDM): Instance Deformation for Image Manipulation and Synthesis</title>
      <link>https://arxiv.org/abs/2407.07295</link>
      <description>arXiv:2407.07295v3 Announce Type: replace-cross 
Abstract: In medical imaging, the diffusion models have shown great potential for synthetic image generation tasks. However, these approaches often lack the interpretable connections between the generated and real images and can create anatomically implausible structures or illusions. To address these limitations, we propose the Deformation-Recovery Diffusion Model (DRDM), a novel diffusion-based generative model that emphasises morphological transformation through deformation fields rather than direct image synthesis. DRDM introduces a topology-preserving deformation field generation strategy, which randomly samples and integrates multi-scale Deformation Velocity Fields (DVFs). DRDM is trained to learn to recover unrealistic deformation components, thus restoring randomly deformed images to a realistic distribution. This formulation enables the generation of diverse yet anatomically plausible deformations that preserve structural integrity, thereby improving data augmentation and synthesis for downstream tasks such as few-shot learning and image registration. Experiments on cardiac Magnetic Resonance Imaging and pulmonary Computed Tomography show that DRDM is capable of creating diverse, large-scale deformations, while maintaining anatomical plausibility of deformation fields. Additional evaluations on 2D image segmentation and 3D image registration tasks indicate notable performance gains, underscoring DRDM's potential to enhance both image manipulation and generative modelling in medical imaging applications.
  Project page: https://jianqingzheng.github.io/def_diff_rec/</description>
      <guid isPermaLink="false">oai:arXiv.org:2407.07295v3</guid>
      <category>eess.IV</category>
      <category>cs.CE</category>
      <category>cs.CV</category>
      <pubDate>Thu, 12 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <arxiv:DOI>10.1016/j.media.2026.103987</arxiv:DOI>
      <dc:creator>Jian-Qing Zheng, Yuanhan Mo, Yang Sun, Jiahua Li, Fuping Wu, Ziyang Wang, Tonia Vincent, Bart{\l}omiej W. Papie\.z</dc:creator>
    </item>
    <item>
      <title>Semantic-Enhanced Time-Series Forecasting via Large Language Models</title>
      <link>https://arxiv.org/abs/2508.07697</link>
      <description>arXiv:2508.07697v4 Announce Type: replace-cross 
Abstract: Time series forecasting plays a significant role in finance, energy, meteorology, and IoT applications. Recent studies have leveraged the generalization capabilities of large language models (LLMs) to adapt to time series forecasting, achieving promising performance. However, existing studies focus on token-level modal alignment, instead of bridging the intrinsic modality gap between linguistic knowledge structures and time series data patterns, greatly limiting the semantic representation. To address this issue, we propose a novel Semantic-Enhanced LLM (SE-LLM) that explores the inherent periodicity and anomalous characteristics of time series to embed into the semantic space to enhance the token embedding. This process enhances the interpretability of tokens for LLMs, thereby activating the potential of LLMs for temporal sequence analysis. Moreover, existing Transformer-based LLMs excel at capturing long-range dependencies but are weak at modeling short-term anomalies in time-series data. Hence, we propose a plugin module embedded within self-attention that models long-term and short-term dependencies to effectively adapt LLMs to time-series analysis. Our approach freezes the LLM and reduces the sequence dimensionality of tokens, greatly reducing computational consumption. Experiments demonstrate the superiority performance of our SE-LLM against the state-of-the-art (SOTA) methods.</description>
      <guid isPermaLink="false">oai:arXiv.org:2508.07697v4</guid>
      <category>cs.LG</category>
      <category>cs.CE</category>
      <pubDate>Thu, 12 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Hao Liu, Chun Yang, Zhang xiaoxing, Xiaobin Zhu</dc:creator>
    </item>
    <item>
      <title>CostNav: A Navigation Benchmark for Real-World Economic-Cost Evaluation of Physical AI Agents</title>
      <link>https://arxiv.org/abs/2511.20216</link>
      <description>arXiv:2511.20216v4 Announce Type: replace-cross 
Abstract: While current navigation benchmarks prioritize task success in simplified settings, they neglect the multidimensional economic constraints essential for the real-world commercialization of autonomous delivery systems. We introduce CostNav, an Economic Navigation Benchmark that evaluates physical AI agents through comprehensive economic cost-revenue analysis aligned with real-world business operations. By integrating industry-standard data - such as SEC filings and AIS injury reports - with Isaac Sim's detailed collision and cargo dynamics, CostNav transcends simple task completion to accurately evaluate business value in complex, real-world scenarios. To our knowledge, CostNav is the first work to quantitatively expose the gap between navigation research metrics and commercial viability, revealing that optimizing for task success on a simplified task fundamentally differs from optimizing for real-world economic deployment. Our evaluation of rule-based Nav2 navigation shows that current approaches are not economically viable: the contribution margin is -22.81/run (AMCL) and -12.87/run (GPS), resulting in no break-even point. We challenge the community to develop navigation policies that achieve economic viability on CostNav. We remain method-agnostic, evaluating success solely on the metric of cost rather than the underlying architecture. All resources are available at https://github.com/worv-ai/CostNav.</description>
      <guid isPermaLink="false">oai:arXiv.org:2511.20216v4</guid>
      <category>cs.AI</category>
      <category>cs.CE</category>
      <category>cs.CV</category>
      <category>cs.LG</category>
      <category>cs.RO</category>
      <pubDate>Thu, 12 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Haebin Seong, Sungmin Kim, Yongjun Cho, Myunchul Joe, Geunwoo Kim, Yubeen Park, Sunhoo Kim, Yoonshik Kim, Suhwan Choi, Jaeyoon Jung, Jiyong Youn, Jinmyung Kwak, Sunghee Ahn, Jaemin Lee, Younggil Do, Seungyeop Yi, Woojin Cheong, Minhyeok Oh, Minchan Kim, Seongjae Kang, Samwoo Seong, Youngjae Yu, Yunsung Lee</dc:creator>
    </item>
  </channel>
</rss>
