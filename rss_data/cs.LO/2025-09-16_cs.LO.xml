<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>cs.LO updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/cs.LO</link>
    <description>cs.LO updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/cs.LO" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Wed, 17 Sep 2025 01:35:34 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Tue, 16 Sep 2025 00:00:00 -0400</pubDate>
    <skipDays>
      <day>Sunday</day>
      <day>Saturday</day>
    </skipDays>
    <item>
      <title>Proceedings 9th edition of Working Formal Methods Symposium</title>
      <link>https://arxiv.org/abs/2509.11877</link>
      <description>arXiv:2509.11877v1 Announce Type: new 
Abstract: This volume contains the proceedings of the 9th Working Formal Methods Symposium, which was held at the Alexandru Ioan Cuza University, Ia\c{s}i, Romania on September 17-19, 2025. </description>
      <guid isPermaLink="false">oai:arXiv.org:2509.11877v1</guid>
      <category>cs.LO</category>
      <category>cs.PL</category>
      <category>cs.SE</category>
      <pubDate>Tue, 16 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <arxiv:DOI>10.4204/EPTCS.427</arxiv:DOI>
      <arxiv:journal_reference>EPTCS 427, 2025</arxiv:journal_reference>
      <dc:creator>Andrei Arusoaie (Alexandru Ioan Cuza University of Ia\c{s}i), Hora\c{t}iu Cheval (University of Bucharest), Radu Iosif (Verimag, CNRS, University of Grenoble Alpes)</dc:creator>
    </item>
    <item>
      <title>Efficient Decrease-and-Conquer Linearizability Monitoring</title>
      <link>https://arxiv.org/abs/2410.04581</link>
      <description>arXiv:2410.04581v5 Announce Type: cross 
Abstract: Linearizability has become the de facto correctness specification for implementations of concurrent data structures. While formally verifying such implementations remains challenging, linearizability monitoring has emerged as a promising first step to rule out early problems in the development of custom implementations, and serves as a key component in approaches that stress test such implementations. In this work, we investigate linearizability monitoring -- check if an execution history of an implementation is linearizable. While this problem is intractable in general, a systematic understanding of when it becomes tractable has remained elusive. We revisit this problem and first present a unified `decrease-and-conquer' algorithmic framework for linearizability monitoring. At its heart, this framework asks to identify special linearizability-preserving values in a given history -- values whose presence yields an equilinearizable sub-history when removed, and whose absence indicates non-linearizability. We prove that a polynomial time algorithm for the problem of identifying linearizability-preserving values, yields a polynomial time algorithm for linearizability monitoring, while conversely, intractability of this problem implies intractability of the monitoring problem. We demonstrate our framework's effectiveness by instantiating it for several popular data types -- sets, stacks, queues and priority queues -- deriving polynomial time algorithms for each, with the unambiguity restriction, where each insertion to the underlying data structure adds a distinct value. We optimize these algorithms to achieve the optimal log-linear time complexity by amortizing the cost of solving sub-problems through efficient data structures. Our implementation and evaluation on publicly available implementations show that our approach scales to large histories and outperforms existing tools.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.04581v5</guid>
      <category>cs.PL</category>
      <category>cs.DS</category>
      <category>cs.LO</category>
      <category>cs.SE</category>
      <pubDate>Tue, 16 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Lee Zheng Han, Umang Mathur</dc:creator>
    </item>
    <item>
      <title>Enhanced Data Race Prediction Through Modular Reasoning</title>
      <link>https://arxiv.org/abs/2504.10813</link>
      <description>arXiv:2504.10813v1 Announce Type: cross 
Abstract: There are two orthogonal methodologies for efficient prediction of data races from concurrent program runs: commutativity and prefix reasoning. There are several instances of each methodology in the literature, with the goal of predicting data races using a streaming algorithm where the required memory does not grow proportional to the length of the observed run, but these instances were mostly created in an ad hoc manner, without much attention to their unifying underlying principles. In this paper, we identify and formalize these principles for each category with the ultimate goal of paving the way for combining them into a new algorithm which shares their efficiency characteristics but offers strictly more prediction power. In particular, we formalize three distinct classes of races predictable using commutativity reasoning, and compare them. We identify three different styles of prefix reasoning, and prove that they predict the same class of races, which provably contains all races predictable by any commutativity reasoning technique.
  Our key contribution is combining prefix reasoning and commutativity reasoning in a modular way to introduce a new class of races, granular prefix races, that are predictable in constant-space and linear time, in a streaming fashion. This class of races includes all races predictable using commutativity and prefix reasoning techniques. We present an improved constant-space algorithm for prefix reasoning alone based on the idea of antichains (from language theory). This improved algorithm is the stepping stone that is required to devise an efficient algorithm for prediction of granular prefix races. We present experimental results to demonstrate the expressive power and performance of our new algorithm.</description>
      <guid isPermaLink="false">oai:arXiv.org:2504.10813v1</guid>
      <category>cs.PL</category>
      <category>cs.FL</category>
      <category>cs.LO</category>
      <category>cs.SE</category>
      <pubDate>Tue, 16 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Zhendong Ang, Azadeh Farzan, Umang Mathur</dc:creator>
    </item>
    <item>
      <title>Finding Photonics Circuits via $\delta$-weakening SMT</title>
      <link>https://arxiv.org/abs/2509.11678</link>
      <description>arXiv:2509.11678v1 Announce Type: cross 
Abstract: For quantum computers based on photonics, one main problem is the synthesis of a photonic circuit that emulates quantum computing gates. The problem requires using photonic components to build a circuit that act like a quantum computing gate with some probability of success. This involves not only finding a circuit that can correctly act like a quantum gate, but also optimizing the probability of success. Whilst many approaches have been given in the past and applied to specific gates, they often lack ease of reusability. We present a tool that uses dReal, a {\delta}-weakening SMT solver, to find such photonic circuits, optimize the likelihood of occurring, and provide some guarantee that the result is optimal. We demonstrate the usage of our tool by recreating known results in the literature, extending upon them, and presenting new results for Givens rotation gates.</description>
      <guid isPermaLink="false">oai:arXiv.org:2509.11678v1</guid>
      <category>quant-ph</category>
      <category>cs.LO</category>
      <pubDate>Tue, 16 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Marco Lewis, Beno\^it Valiron</dc:creator>
    </item>
    <item>
      <title>Statistical Model Checking Beyond Means: Quantiles, CVaR, and the DKW Inequality (extended version)</title>
      <link>https://arxiv.org/abs/2509.11859</link>
      <description>arXiv:2509.11859v1 Announce Type: cross 
Abstract: Statistical model checking (SMC) randomly samples probabilistic models to approximate quantities of interest with statistical error guarantees. It is traditionally used to estimate probabilities and expected rewards, i.e. means of different random variables on paths. In this paper, we develop methods using the Dvoretzky-Kiefer-Wolfowitz-Massart inequality (DKW) to extend SMC beyond means to compute quantities such as quantiles, conditional value-at-risk, and entropic risk. The DKW provides confidence bounds on the random variable's entire cumulative distribution function, a much more versatile guarantee compared to the statistical methods prevalent in SMC today. We have implemented support for computing new quantities via the DKW in the 'modes' simulator of the Modest Toolset. We highlight the implementation and its versatility on benchmarks from the quantitative verification literature.</description>
      <guid isPermaLink="false">oai:arXiv.org:2509.11859v1</guid>
      <category>stat.ME</category>
      <category>cs.DM</category>
      <category>cs.LO</category>
      <pubDate>Tue, 16 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Carlos E. Budde, Arnd Hartmanns, Tobias Meggendorfer, Maximilian Weininger, Patrick Wienh\"oft</dc:creator>
    </item>
    <item>
      <title>Expressive Power of One-Shot Control Operators and Coroutines</title>
      <link>https://arxiv.org/abs/2509.11901</link>
      <description>arXiv:2509.11901v1 Announce Type: cross 
Abstract: Control operators, such as exceptions and effect handlers, provide a means of representing computational effects in programs abstractly and modularly. While most theoretical studies have focused on multi-shot control operators, one-shot control operators -- which restrict the use of captured continuations to at most once -- are gaining attention for their balance between expressiveness and efficiency. This study aims to fill the gap. We present a mathematically rigorous comparison of the expressive power among one-shot control operators, including effect handlers, delimited continuations, and even asymmetric coroutines. Following previous studies on multi-shot control operators, we adopt Felleisen's macro-expressiveness as our measure of expressiveness. We verify the folklore that one-shot effect handlers and one-shot delimited-control operators can be macro-expressed by asymmetric coroutines, but not vice versa. We explain why a previous informal argument fails, and how to revise it to make a valid macro-translation.</description>
      <guid isPermaLink="false">oai:arXiv.org:2509.11901v1</guid>
      <category>cs.PL</category>
      <category>cs.LO</category>
      <pubDate>Tue, 16 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Kentaro Kobayashi, Yukiyoshi Kameyama</dc:creator>
    </item>
    <item>
      <title>Neuro-Symbolic Agents with Modal Logic for Autonomous Diagnostics</title>
      <link>https://arxiv.org/abs/2509.11943</link>
      <description>arXiv:2509.11943v1 Announce Type: cross 
Abstract: The development of intelligent agents, particularly those powered by language models (LMs), has shown the critical role in various environments that require intelligent and autonomous decision. Environments are not passive testing grounds and they represent the data required for agents to learn and exhibit very challenging conditions that require adaptive, complex and autonomous capacity to make decisions. While the paradigm of scaling models and datasets has led to remarkable emergent capabilities, we argue that scaling the structure, fidelity, and logical consistency of agent reasoning within these environments is a crucial, yet underexplored, dimension of AI research. This paper introduces a neuro-symbolic multi-agent architecture where the belief states of individual agents are formally represented as Kripke models. This foundational choice enables them to reason about known concepts of \emph{possibility} and \emph{necessity} using the formal language of modal logic. In this work, we use of immutable, domain-specific knowledge to make infere information, which is encoded as logical constraints essential for proper diagnosis. In the proposed model, we show constraints that actively guide the hypothesis generation of LMs, effectively preventing them from reaching physically or logically untenable conclusions. In a high-fidelity simulated particle accelerator environment, our system successfully diagnoses complex, cascading failures by combining the powerful semantic intuition of LMs with the rigorous, verifiable validation of modal logic and a factual world model and showcasing a viable path toward more robust, reliable, and verifiable autonomous agents.</description>
      <guid isPermaLink="false">oai:arXiv.org:2509.11943v1</guid>
      <category>cs.AI</category>
      <category>cs.LG</category>
      <category>cs.LO</category>
      <category>cs.MA</category>
      <pubDate>Tue, 16 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Antonin Sulc, Thorsten Hellert</dc:creator>
    </item>
    <item>
      <title>SMT(LIA) Sampling with High Diversity</title>
      <link>https://arxiv.org/abs/2503.04782</link>
      <description>arXiv:2503.04782v2 Announce Type: replace 
Abstract: Satisfiability Modulo Linear Integer Arithmetic, SMT(LIA) for short, is pivotal across various critical domains. Previous research has primarily focused on SMT solving techniques. However, in practical applications such as software and hardware testing, there is a need to generate a diverse set of solutions for use as test inputs. We have developed the first sampling framework that integrates local search with CDCL(T) techniques, named HighDiv, capable of generating a highly diverse set of solutions for constraints under linear integer theory. Initially, in the local search phase, we introduced a novel operator called boundary-aware movement. This operator performs random moves by considering the current state's constraints on variables, thereby enhancing the diversity of variables during the search process. Furthermore, we have conducted an in-depth study of the preprocessing and variable initialization mechanisms within the framework, which significantly enhances the efficiency of subsequent local searches. Lastly, we use the solutions obtained from local search sampling as additional constraints to further explore the solution space using the stochastic CDCL(T) method. Experimental results demonstrate that \HighDiv generates solutions with greater diversity compared to the state-of-the-art SMT(LIA) sampling tool, MeGASampler.</description>
      <guid isPermaLink="false">oai:arXiv.org:2503.04782v2</guid>
      <category>cs.LO</category>
      <category>cs.AI</category>
      <pubDate>Tue, 16 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Yong Lai, Junjie Li, Chuan Luo</dc:creator>
    </item>
    <item>
      <title>ChemLog: Making MSOL Viable for Ontological Classification and Learning</title>
      <link>https://arxiv.org/abs/2507.13987</link>
      <description>arXiv:2507.13987v2 Announce Type: replace 
Abstract: Despite its prevalence, in many domains, OWL is not expressive enough to define ontology classes. In this paper, we present an approach that allows to use monadic second-order formalisations for ontology classification. As a case study, we have applied our approach to 14 peptide-related classes from the chemistry ontology ChEBI. For these classes, a monadic second-order logic formalisation has been developed and applied both to ChEBI as well as to 119 million molecules from the chemistry database PubChem. While this logical approach alone is limited to classification for the specified classes (in our case, (sub)classes of peptides), transformer deep learning models scale classification to the whole of the ChEBI ontology. We show that when using the classifications obtained by the logical approach as training data, the performance of the deep learning models can be significantly enhanced.</description>
      <guid isPermaLink="false">oai:arXiv.org:2507.13987v2</guid>
      <category>cs.LO</category>
      <pubDate>Tue, 16 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Simon Fl\"ugel, Martin Glauer, Till Mossakowski, Fabian Neuhaus</dc:creator>
    </item>
    <item>
      <title>Automating the Derivation of Unification Algorithms: A Case Study in Deductive Program Synthesis</title>
      <link>https://arxiv.org/abs/2508.11136</link>
      <description>arXiv:2508.11136v2 Announce Type: replace 
Abstract: The unification algorithm has long been a target for program synthesis research, but a fully automatic derivation remains a research goal. In deductive program synthesis, computer programming is phrased as a task in theorem proving; a declarative specification is expressed in logical form and presented to an automatic theorem prover, and a program meeting the specification is extracted from the proof. The correctness of the program is supported by the proof, which also provides an explanation of how the program works. The proof is conducted in an appropriate axiomatic subject-domain theory, which defines the concepts in the specification and the constructs in the target programming language and provides the background knowledge necessary to connect them.
  For the unification proof, we generalize and automate the manual proof presented in Manna and Waldinger [1981]. The new program unifies two given symbolic expressions (s-expressions) relative to a given "environment" substitution. The proof establishes the existence of an output substitution that is a most-general idempotent unifier of the given expressions and is an "extension" of the environment substitution. If no such substitution exists and the expressions are not unifiable, the program is to produce a failure indicator.
  Initially the environment substitution is the empty substitution, which makes no replacements at all; during execution of recursive calls, the environment substitution records the replacements that have been found so far. Our own unification algorithm employs an environment, and such algorithms appear in the literature [e.g., Luger and Stubblefield, 1997]. We suspect, in addition to being more efficient, the three-argument algorithm with an environment is easier to synthesize automatically than the two-argument version from the Manna-Waldinger paper.</description>
      <guid isPermaLink="false">oai:arXiv.org:2508.11136v2</guid>
      <category>cs.LO</category>
      <pubDate>Tue, 16 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Richard Waldinger</dc:creator>
    </item>
    <item>
      <title>Tabular intermediate logics comparison</title>
      <link>https://arxiv.org/abs/2509.06841</link>
      <description>arXiv:2509.06841v2 Announce Type: replace 
Abstract: Tabular intermediate logics are intermediate logics characterized by finite posets treated as Kripke frames. For a poset $\mathbb{P}$, let $L(\mathbb{P})$ denote the corresponding tabular intermediate logic. We investigate the complexity of the following decision problem $\mathsf{LogContain}$: given two finite posets $\mathbb P$ and $\mathbb Q$, decide whether $L(\mathbb P) \subseteq L(\mathbb Q)$.
  By Jankov's and de Jongh's theorem, the problem $\mathsf{LogContain}$ is related to the problem $\mathsf{SPMorph}$: given two finite posets $\mathbb P$ and $\mathbb Q$, decide whether there exists a surjective $p$-morphism from $\mathbb P$ onto $\mathbb Q$. Both problems belong to the complexity class NP.
  We present two contributions. First, we describe a construction which, starting with a graph $\mathbb{G}$, gives a poset $\mathsf{Pos}(\mathbb{G})$ such that there is a surjective locally surjective homomorphism (the graph-theoretic analog of a $p$-morphism) from $\mathbb{G}$ onto $\mathbb{H}$ if and only if there is a surjective $p$-morphism from $\mathsf{Pos}(\mathbb{G})$ onto $\mathsf{Pos}(\mathbb{H})$. This allows us to translate some hardness results from graph theory and obtain that several restricted versions of the problems $\mathsf{LogContain}$ and $\mathsf{SPMorph}$ are NP-complete. Among other results, we present a 18-element poset $\mathbb{Q}$ such that the problem to decide, for a given poset $\mathbb{P}$, whether $L(\mathbb{P})\subseteq L(\mathbb{Q})$ is NP-complete.
  Second, we describe a polynomial-time algorithm that decides $\mathsf{LogContain}$ and $\mathsf{SPMorph}$ for posets $\mathbb{T}$ and $\mathbb{Q}$, when $\mathbb{T}$ is a tree.</description>
      <guid isPermaLink="false">oai:arXiv.org:2509.06841v2</guid>
      <category>cs.LO</category>
      <pubDate>Tue, 16 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <arxiv:DOI>10.1007/978-3-031-99536-1_20</arxiv:DOI>
      <dc:creator>Pawe{\l} Rz\k{a}\.zewski, Micha{\l} Stronkowski</dc:creator>
    </item>
    <item>
      <title>A Hierarchy of Nondeterminism</title>
      <link>https://arxiv.org/abs/2209.09866</link>
      <description>arXiv:2209.09866v5 Announce Type: replace-cross 
Abstract: We study three levels in a hierarchy of nondeterminism: A nondeterministic automaton $\mathcal{A}$ is determinizable by pruning (DBP) if we can obtain a deterministic automaton equivalent to $\mathcal{A}$ by removing some of its transitions. Then, $\mathcal{A}$ is history deterministic (HD) if its nondeterministic choices can be resolved in a way that only depends on the past. Finally, $\mathcal{A}$ is semantically deterministic (SD) if different nondeterministic choices in $\mathcal{A}$ lead to equivalent states. Some applications of automata in formal methods require deterministic automata, yet in fact can use automata with some level of nondeterminism. For example, DBP automata are useful in the analysis of online algorithms, and HD automata are useful in synthesis and control. For automata on finite words, the three levels in the hierarchy coincide. We study the hierarchy for B\"uchi, co-B\"uchi, and weak automata on infinite words. We show that the hierarchy is strict, study the expressive power of the different levels in it, as well as the complexity of deciding the membership of a language in a given level. Finally, we describe a probability-based analysis of the hierarchy, which relates the level of nondeterminism with the probability that a random run on a word in the language is accepting. We relate the latter to nondeterministic automata that can be used when reasoning about probabilistic systems.</description>
      <guid isPermaLink="false">oai:arXiv.org:2209.09866v5</guid>
      <category>cs.FL</category>
      <category>cs.LO</category>
      <pubDate>Tue, 16 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Bader Abu Radi, Orna Kupferman, Ofer Leshkowitz</dc:creator>
    </item>
    <item>
      <title>Towards a Unification of Logic and Information Theory</title>
      <link>https://arxiv.org/abs/2301.10414</link>
      <description>arXiv:2301.10414v4 Announce Type: replace-cross 
Abstract: Today, the vast majority of the world's digital information is represented using the fundamental assumption, introduced by Claude Shannon in 1948, that ``...the semantic aspects of communication are irrelevant to the engineering problem (of the design of communication systems)...''. Consider, nonetheless, the observation that we often combine a message with other information in order to deduce new facts, thereby expanding the value of such a message. It is noteworthy that to-date, no rigorous theory of communication has been put forth which postulates the existence of deductive capabilities on the receiver's side.
  The purpose of this paper is to present such a theory. We formally model such deductive capabilities using logic reasoning, and present a rigorous theory which covers the following generic scenario: Alice and Bob each have knowledge of some logic sentence, and they wish to communicate as efficiently as possible with the shared goal that, following their communication, Bob should be able to deduce a particular logic sentence that Alice knows to be true, but that Bob currently cannot prove. Many variants of this general setup are considered in this article; in all cases we are able to provide sharp upper and lower bounds. Our contribution includes the identification of the most fundamental requirements that we place on a logic and associated logical language for all of our results to apply. Practical algorithms that are in some cases asymptotically optimal are provided, and we illustrate the potential practical value of the design of communication systems that incorporate the assumption of deductive capabilities at the receiver using experimental results that suggest significant possible gains compared to classical systems.</description>
      <guid isPermaLink="false">oai:arXiv.org:2301.10414v4</guid>
      <category>cs.IT</category>
      <category>cs.LO</category>
      <category>math.IT</category>
      <pubDate>Tue, 16 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Luis A. Lastras, Barry Trager, Jonathan Lenchner, Wojtek Szpankowski, Chai Wah Wu, Mark Squillante, Ron Fagin, Alex Gray</dc:creator>
    </item>
    <item>
      <title>On guarded extensions of MMSNP</title>
      <link>https://arxiv.org/abs/2305.04234</link>
      <description>arXiv:2305.04234v5 Announce Type: replace-cross 
Abstract: Feder and Vardi showed that the class Monotone Monadic SNP without inequality (MMSNP) has a P vs NP-complete dichotomy if and only if such a dichotomy holds for finite-domain Constraint Satisfaction Problems (CSPs). Moreover, they showed that none of the three classes obtained by removing one of the defining properties of MMSNP (monotonicity, monadicity, no inequality) has a dichotomy. The overall objective of this paper is to study the gaps between MMSNP and each of these three superclasses, where the existence of a dichotomy remains unknown. For the gap between MMSNP and Monotone SNP without inequality, we study the class Guarded Monotone SNP without inequality (GMSNP) introduced by Bienvenu, ten Cate, Lutz, and Wolter, and prove that GMSNP has a dichotomy if and only if a dichotomy holds for GMSNP problems over signatures consisting of a unique relation symbol. For the gap between MMSNP and MMSNP with inequality, we introduce a new class MMSNP with guarded inequality, that lies between MMSNP and MMSNP with inequality and that is strictly more expressive than the former and still has a dichotomy. For the gap between MMSNP and Monadic SNP without inequality, we introduce a logic that extends the class of Matrix Partitions in a similar way how MMSNP extends finite-domain CSP, and pose an open question about the existence of a dichotomy for this class. Finally, we revisit the theorem of Feder and Vardi, which claims that the class NP embeds into MMSNP with inequality. We give a detailed proof of this theorem as it ensures no dichotomy for the right-hand side class of each of the three gaps.</description>
      <guid isPermaLink="false">oai:arXiv.org:2305.04234v5</guid>
      <category>cs.CC</category>
      <category>cs.LO</category>
      <pubDate>Tue, 16 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Alexey Barsukov, Florent R. Madelaine</dc:creator>
    </item>
    <item>
      <title>Absolute continuity, supports and idempotent splitting in categorical probability</title>
      <link>https://arxiv.org/abs/2308.00651</link>
      <description>arXiv:2308.00651v3 Announce Type: replace-cross 
Abstract: Markov categories have recently turned out to be a powerful high-level framework for probability and statistics. They accommodate purely categorical definitions of notions like conditional probability and almost sure equality, as well as proofs of fundamental results such as the Hewitt--Savage 0/1 Law, the de Finetti Theorem and the Ergodic Decomposition Theorem.
  In this work, we develop additional relevant notions from probability theory in the setting of Markov categories. This comprises improved versions of previously introduced definitions of absolute continuity and supports, as well as a detailed study of idempotents and idempotent splitting in Markov categories. Our main result on idempotent splitting is that every idempotent measurable Markov kernel between standard Borel spaces splits through another standard Borel space, and we derive this as an instance of a general categorical criterion for idempotent splitting in Markov categories.</description>
      <guid isPermaLink="false">oai:arXiv.org:2308.00651v3</guid>
      <category>math.PR</category>
      <category>cs.LO</category>
      <category>math.CT</category>
      <pubDate>Tue, 16 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-sa/4.0/</dc:rights>
      <dc:creator>Tobias Fritz, Tom\'a\v{s} Gonda, Antonio Lorenzin, Paolo Perrone, Dario Stein</dc:creator>
    </item>
    <item>
      <title>Characterizations of Monadic Second Order Definable Context-Free Sets of Graphs</title>
      <link>https://arxiv.org/abs/2310.04764</link>
      <description>arXiv:2310.04764v5 Announce Type: replace-cross 
Abstract: We give a characterization of the sets of graphs that are both
  \emph{definable} in Counting Monadic Second Order Logic (CMSO) and
  \emph{context-free}, i.e., least solutions of Hyperedge-Replacement
  (HR) grammars introduced by Courcelle and Engelfriet
  \cite{courcelle_engelfriet_2012}. We prove the equivalence of these
  sets with:
  %
  (a) \emph{recognizable} sets (in the algebra of graphs with
  HR-operations) of bounded tree-width; we refine this condition
  further and show equivalence with recognizability in a finitely
  generated subalgebra of the HR-algebra of graphs;
  %
  (b) \emph{parsable} sets, for which there is a definable transduction from
  graphs to a set of derivation trees labelled by HR operations, such
  that the set of graphs is the image of the set of derivation trees
  under the canonical evaluation of the HR operations;
  %
  (c) images of recognizable unranked sets of trees under a definable
  transduction, whose inverse is also definable.
  %
  We rely on a novel connection between two seminal results, a logical
  characterization of context-free graph languages in terms of
  tree-to-graph definable transductions, by Courcelle and
  Engelfriet and a proof that an
  optimal-width tree decomposition of a graph can be built by an
  definable transduction, by Boja\'{n}czyk and
  Pilipczuk.</description>
      <guid isPermaLink="false">oai:arXiv.org:2310.04764v5</guid>
      <category>cs.FL</category>
      <category>cs.LO</category>
      <pubDate>Tue, 16 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Radu Iosif, Florian Zuleger</dc:creator>
    </item>
    <item>
      <title>On the theory of exponential integer parts</title>
      <link>https://arxiv.org/abs/2404.06888</link>
      <description>arXiv:2404.06888v2 Announce Type: replace-cross 
Abstract: We axiomatize the first-order theories of exponential integer parts of real-closed exponential fields in a language with $2^x$, in a language with a predicate for powers of 2, and in the basic language of ordered rings. In particular, the last theory extends IOpen by sentences expressing the existence of winning strategies in a certain game on integers; we show that it is a proper extension of IOpen, and give upper and lower bounds on the required number of rounds needed to win the game.</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.06888v2</guid>
      <category>math.LO</category>
      <category>cs.LO</category>
      <pubDate>Tue, 16 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Emil Je\v{r}\'abek</dc:creator>
    </item>
  </channel>
</rss>
