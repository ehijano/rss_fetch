<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>cs.SE updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/cs.SE</link>
    <description>cs.SE updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/cs.SE" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Thu, 11 Jul 2024 04:00:40 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Thu, 11 Jul 2024 00:00:00 -0400</pubDate>
    <skipDays>
      <day>Saturday</day>
      <day>Sunday</day>
    </skipDays>
    <item>
      <title>Service Colonies: A Novel Architectural Style for Developing Software Systems with Autonomous and Cooperative Services</title>
      <link>https://arxiv.org/abs/2407.07267</link>
      <description>arXiv:2407.07267v1 Announce Type: new 
Abstract: This paper presents the concept of a service colony and its characteristics. A service colony is a novel architectural style for developing a software system as a group of autonomous software services co-operating to fulfill the objectives of the system. Each inhabitant service in the colony implements a specific system functionality, collaborates with the other services, and makes proactive decisions that impact its performance and interaction patterns with other inhabitants. By increasing the level of self-awareness and autonomy available to individual system components, the resulting system is increasingly more decentralized, distributed, flexible, adaptable, distributed, modular, robust, and fault-tolerant.</description>
      <guid isPermaLink="false">oai:arXiv.org:2407.07267v1</guid>
      <category>cs.SE</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Thakshila Imiya Mohottige (University of Melbourne), Artem Polyvyanyy (University of Melbourne), Rajkumar Buyya (University of Melbourne), Colin Fidge (Queensland University of Technology), Alistair Barros (Queensland University of Technology)</dc:creator>
    </item>
    <item>
      <title>Model-based Maintenance and Evolution with GenAI: A Look into the Future</title>
      <link>https://arxiv.org/abs/2407.07269</link>
      <description>arXiv:2407.07269v1 Announce Type: new 
Abstract: Model-Based Engineering (MBE) has streamlined software development by focusing on abstraction and automation. The adoption of MBE in Maintenance and Evolution (MBM&amp;E), however, is still limited due to poor tool support and a lack of perceived benefits. We argue that Generative Artificial Intelligence (GenAI) can be used as a means to address the limitations of MBM&amp;E. In this sense, we argue that GenAI, driven by Foundation Models, offers promising potential for enhancing MBM&amp;E tasks. With this possibility in mind, we introduce a research vision that contains a classification scheme for GenAI approaches in MBM&amp;E considering two main aspects: (i) the level of augmentation provided by GenAI and (ii) the experience of the engineers involved. We propose that GenAI can be used in MBM&amp;E for: reducing engineers' learning curve, maximizing efficiency with recommendations, or serving as a reasoning tool to understand domain problems. Furthermore, we outline challenges in this field as a research agenda to drive scientific and practical future solutions. With this proposed vision, we aim to bridge the gap between GenAI and MBM&amp;E, presenting a structured and sophisticated way for advancing MBM&amp;E practices.</description>
      <guid isPermaLink="false">oai:arXiv.org:2407.07269v1</guid>
      <category>cs.SE</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Luciano Marchezan, Wesley K. G. Assun\c{c}\~ao, Edvin Herac, Alexander Egyed</dc:creator>
    </item>
    <item>
      <title>Employing Software Diversity in Cloud Microservices to Engineer Reliable and Performant Systems</title>
      <link>https://arxiv.org/abs/2407.07287</link>
      <description>arXiv:2407.07287v1 Announce Type: new 
Abstract: In the ever-shifting landscape of software engineering, we recognize the need for adaptation and evolution to maintain system dependability. As each software iteration potentially introduces new challenges, from unforeseen bugs to performance anomalies, it becomes paramount to understand and address these intricacies to ensure robust system operations during the lifetime. This work proposes employing software diversity to enhance system reliability and performance simultaneously. A cornerstone of our work is the derivation of a reliability metric. This metric encapsulates the reliability and performance of each software version under adverse conditions. Using the calculated reliability score, we implemented a dynamic controller responsible for adjusting the population of each software version. The goal is to maintain a higher replica count for more reliable versions while preserving the diversity of versions as much as possible. This balance is crucial for ensuring not only the reliability but also the performance of the system against a spectrum of potential failures. In addition, we designed and implemented a diversity-aware autoscaling algorithm that maintains the reliability and performance of the system at the same time and at any scale. Our extensive experiments on realistic cloud microservice-based applications show the effectiveness of the proposed approach in this paper in promoting both reliability and performance.</description>
      <guid isPermaLink="false">oai:arXiv.org:2407.07287v1</guid>
      <category>cs.SE</category>
      <category>cs.PF</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Nazanin Akhtarian, Hamzeh Khazaei, Marin Litoiu</dc:creator>
    </item>
    <item>
      <title>Integrating Human-Centric Approaches into Undergraduate Software Engineering Education: A Scoping Review and Curriculum Analysis in the Australian Context</title>
      <link>https://arxiv.org/abs/2407.07322</link>
      <description>arXiv:2407.07322v1 Announce Type: new 
Abstract: Human-Centric Software Engineering (HCSE) refers to the software engineering (SE) processes that put human needs and requirements as core practice throughout the software development life cycle. A large majority of software projects fail to cater to human needs and consequently run into budget, delivery, and usability issues. To support human-centric software engineering practices, it is important for universities to train their students on how to consider human needs. But what topics from HCSE should be provided in the undergraduate curriculum? Curriculum guidelines for software engineering are available, however do not represent update to date considerations for human-factors. To address this issue, this paper presents a scoping review to identify the topics and curriculum approaches suitable for teaching HCSE to undergraduate software engineering students. The scoping review was conducted according to the protocol by PRISMA-ScR (Preferred Reporting Items for Systematic reviews and Meta-Analyses extension for Scoping Reviews). Through PRISMA-ScR, a total of 36 conference or journal papers were identified as viable for analysis,with 5 common themes found that describe topics and curriculum approaches relevant for teaching software engineering. Using the outcomes of the scoping review, this paper also analyses the Australian Software Engineering curriculum to understand the extent at which human centred software engineering topics are scaffolded into course structures. This paper concludes by suggesting topic scaffolding for the undergraduate curriculum that aligns with the software engineering process. Overall, by providing a focus on HCSE topics and curriculum approaches, the education of HCSE among current and future software engineers can increase, leading to long-term impact on the success of software projects for all stakeholders.</description>
      <guid isPermaLink="false">oai:arXiv.org:2407.07322v1</guid>
      <category>cs.SE</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <dc:creator>Sophie McKenzie, Xiao Lui</dc:creator>
    </item>
    <item>
      <title>A Conceptual Framework for API Refactoring in Enterprise Application Architectures</title>
      <link>https://arxiv.org/abs/2407.07428</link>
      <description>arXiv:2407.07428v1 Announce Type: new 
Abstract: Enterprise applications are often built as service-oriented architectures, where the individual services are designed to perform specific functions and interact with each other by means of well-defined APIs (Application Programming Interfaces). The architecture of an enterprise application evolves over time, in order to adapt to changing business requirements. This evolution might require changes to the APIs offered by services, which can be achieved through appropriate API refactorings.
  Previous studies on API refactoring focused on the effects on API definitions, with general considerations on related forces and smells. So far, instead, the development strategy for realising these refactorings has received little attention. This paper addresses exactly this aspect.
  We introduce a conceptual framework for the implementation of API refactorings. Our framework elicits that there are important trade-offs and choices, which significantly affect the efficiency, maintainability, and isolation properties of the resulting architecture. We validate our framework by implementing several refactorings that introduce established API patterns with different choices, which illustrates the guiding principles offered by our framework. Our work also elicits, for the first time, how certain programming language features can reduce friction in applying API refactoring and open up more architectural choices.</description>
      <guid isPermaLink="false">oai:arXiv.org:2407.07428v1</guid>
      <category>cs.SE</category>
      <category>cs.PL</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Fabrizio Montesi, Marco Peressotti, Valentino Picotti, Olaf Zimmermann</dc:creator>
    </item>
    <item>
      <title>Development of an automatic modification system for generated programs using ChatGPT</title>
      <link>https://arxiv.org/abs/2407.07469</link>
      <description>arXiv:2407.07469v1 Announce Type: new 
Abstract: In recent years, the field of artificial intelligence has been rapidly developing. Among them, OpenAI's ChatGPT excels at natural language processing tasks and can also generate source code. However, the generated code often has problems with consistency and program rules. Therefore, in this research, we developed a system that tests the code generated by ChatGPT, automatically corrects it if it is inappropriate, and presents the appropriate code to the user. This study aims to address the challenge of reducing the manual effort required for the human feedback and modification process for generated code. When we ran the system, we were able to automatically modify the code as intended.</description>
      <guid isPermaLink="false">oai:arXiv.org:2407.07469v1</guid>
      <category>cs.SE</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Jun Yoshida, Oh Sato, Hane Kondo, Hiroaki Hashiura, Atsuo Hazeyama</dc:creator>
    </item>
    <item>
      <title>Rectifier: Code Translation with Corrector via LLMs</title>
      <link>https://arxiv.org/abs/2407.07472</link>
      <description>arXiv:2407.07472v1 Announce Type: new 
Abstract: Software migration is garnering increasing attention with the evolution of software and society. Early studies mainly relied on handcrafted translation rules to translate between two languages, the translation process is error-prone and time-consuming. In recent years, researchers have begun to explore the use of pre-trained large language models (LLMs) in code translation. However, code translation is a complex task that LLMs would generate mistakes during code translation, they all produce certain types of errors when performing code translation tasks, which include (1) compilation error, (2) runtime error, (3) functional error, and (4) non-terminating execution. We found that the root causes of these errors are very similar (e.g. failure to import packages, errors in loop boundaries, operator errors, and more). In this paper, we propose a general corrector, namely Rectifier, which is a micro and universal model for repairing translation errors. It learns from errors generated by existing LLMs and can be widely applied to correct errors generated by any LLM. The experimental results on translation tasks between C++, Java, and Python show that our model has effective repair ability, and cross experiments also demonstrate the robustness of our method.</description>
      <guid isPermaLink="false">oai:arXiv.org:2407.07472v1</guid>
      <category>cs.SE</category>
      <category>cs.AI</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Xin Yin, Chao Ni, Tien N. Nguyen, Shaohua Wang, Xiaohu Yang</dc:creator>
    </item>
    <item>
      <title>Co-designing heterogeneous models: a distributed systems approach</title>
      <link>https://arxiv.org/abs/2407.07656</link>
      <description>arXiv:2407.07656v1 Announce Type: new 
Abstract: The nature of information security has been, and probably will continue to be, marked by the asymmetric competition of attackers and defenders over the control of an uncertain environment. The reduction of this degree of uncertainty via an increase in understanding of that environment is a primary objective for both sides. Models are useful tools in this context because they provide a way to understand and experiment with their targets without the usual operational constraints. However, given the technological and social advancements of today, the object of modelling has increased in complexity. Such objects are no longer singular entities, but heterogeneous socio-technical systems interlinked to form large-scale ecosystems. Furthermore, the underlying components of a system might be based on very different epistemic assumptions and methodologies for construction and use. Naturally, consistent, rigorous reasoning about such systems is hard, but necessary for achieving both security and resilience. The goal of this paper is to present a modelling approach tailored for heterogeneous systems based on three elements: an inferentialist interpretation of what a model is, a distributed systems metaphor to structure that interpretation and a co-design cycle to describe the practical design and construction of the model. The underlying idea is that an open world interpretation, supported by a formal, yet generic abstraction facilitating knowledge translation and providing properties for structured reasoning and, used in practice according to the co-design cycle could lead to models that are more likely to achieve their pre-stated goals. We explore the suitability of this method in the context of three different security-oriented models: a physical data loss model, an organisational recovery under ransomware model and an surge capacity trauma unit model.</description>
      <guid isPermaLink="false">oai:arXiv.org:2407.07656v1</guid>
      <category>cs.SE</category>
      <category>cs.CR</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Marius-Constantin Ilau, Tristan Caulfield, David Pym</dc:creator>
    </item>
    <item>
      <title>Call Graph Soundness in Android Static Analysis</title>
      <link>https://arxiv.org/abs/2407.07804</link>
      <description>arXiv:2407.07804v1 Announce Type: new 
Abstract: Static analysis is sound in theory, but an implementation may unsoundly fail to analyze all of a program's code. Any such omission is a serious threat to the validity of the tool's output. Our work is the first to measure the prevalence of these omissions. Previously, researchers and analysts did not know what is missed by static analysis, what sort of code is missed, or the reasons behind these omissions. To address this gap, we ran 13 static analysis tools and a dynamic analysis on 1000 Android apps. Any method in the dynamic analysis but not in a static analysis is an unsoundness.
  Our findings include the following. (1) Apps built around external frameworks challenge static analyzers. On average, the 13 static analysis tools failed to capture 61% of the dynamically-executed methods. (2) A high level of precision in call graph construction is a synonym for a high level of unsoundness; (3) No existing approach significantly improves static analysis soundness. This includes those specifically tailored for a given mechanism, such as DroidRA to address reflection. It also includes systematic approaches, such as EdgeMiner, capturing all callbacks in the Android framework systematically. (4) Modeling entry point methods challenges call graph construction which jeopardizes soundness.</description>
      <guid isPermaLink="false">oai:arXiv.org:2407.07804v1</guid>
      <category>cs.SE</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Jordan Samhi, Ren\'e Just, Tegawend\'e F. Bissyand\'e, Michael D. Ernst, Jacques Klein</dc:creator>
    </item>
    <item>
      <title>Daisy: An integrated repeat protein curation service</title>
      <link>https://arxiv.org/abs/2407.07817</link>
      <description>arXiv:2407.07817v1 Announce Type: new 
Abstract: Tandem repeats in proteins identification, classification and curation is a complex process that requires manual processing from experts, processing power and time. There are recent and relevant advances applying machine learning for protein structure prediction and repeat classification that are useful for this process. However, no service contemplates required databases and software to supplement researching on repeat proteins. In this publication we present Daisy, an integrated repeat protein curation web service. This service can process Protein Data Bank (PDB) and the AlphaFold Database entries for tandem repeats identification. In addition, it uses an algorithm to search a sequence against a library of Pfam hidden Markov model (HMM). Repeat classifications are associated with the identified families through RepeatsDB. This prediction is considered for enhancing the ReUPred algorithm execution and hastening the repeat units identification process. The service can also operate every associated PDB and AlphaFold structure with a UniProt proteome registry. Availability: The Daisy web service is freely accessible at daisy.bioinformatica.org.</description>
      <guid isPermaLink="false">oai:arXiv.org:2407.07817v1</guid>
      <category>cs.SE</category>
      <category>cs.DB</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <arxiv:DOI>10.1016/j.jsb.2023.108033</arxiv:DOI>
      <arxiv:journal_reference>Journal of Structural Biology, Volume 215, Issue 4, December 2023, 108033</arxiv:journal_reference>
      <dc:creator>Manuel Bezerra-Brandao, Ronaldo Romario Tunque Cahui, Layla Hirsh</dc:creator>
    </item>
    <item>
      <title>UEFI Vulnerability Signature Generation using Static and Symbolic Analysis</title>
      <link>https://arxiv.org/abs/2407.07166</link>
      <description>arXiv:2407.07166v1 Announce Type: cross 
Abstract: Since its major release in 2006, the Unified Extensible Firmware Interface (UEFI) has become the industry standard for interfacing a computer's hardware and operating system, replacing BIOS. UEFI has higher privileged security access to system resources than any other software component, including the system kernel. Hence, identifying and characterizing vulnerabilities in UEFI is extremely important for computer security. However, automated detection and characterization of UEFI vulnerabilities is a challenging problem. Static vulnerability analysis techniques are scalable but lack precision (reporting many false positives), whereas symbolic analysis techniques are precise but are hampered by scalability issues due to path explosion and the cost of constraint solving. In this paper, we introduce a technique called STatic Analysis guided Symbolic Execution (STASE), which integrates both analysis approaches to leverage their strengths and minimize their weaknesses. We begin with a rule-based static vulnerability analysis on LLVM bitcode to identify potential vulnerability targets for symbolic execution. We then focus symbolic execution on each target to achieve precise vulnerability detection and signature generation. STASE relies on the manual specification of reusable vulnerability rules and attacker-controlled inputs. However, it automates the generation of harnesses that guide the symbolic execution process, addressing the usability and scalability of symbolic execution, which typically requires manual harness generation to reduce the state space. We implemented and applied STASE to the implementations of UEFI code base. STASE detects and generates vulnerability signatures for 5 out of 9 recently reported PixieFail vulnerabilities and 13 new vulnerabilities in Tianocore's EDKII codebase.</description>
      <guid isPermaLink="false">oai:arXiv.org:2407.07166v1</guid>
      <category>cs.CR</category>
      <category>cs.SE</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Md Shafiuzzaman, Achintya Desai, Laboni Sarker, Tevfik Bultan</dc:creator>
    </item>
    <item>
      <title>Instrumentation and Analysis of Native ML Pipelines via Logical Query Plans</title>
      <link>https://arxiv.org/abs/2407.07560</link>
      <description>arXiv:2407.07560v1 Announce Type: cross 
Abstract: Machine Learning (ML) is increasingly used to automate impactful decisions, which leads to concerns regarding their correctness, reliability, and fairness. We envision highly-automated software platforms to assist data scientists with developing, validating, monitoring, and analysing their ML pipelines. In contrast to existing work, our key idea is to extract "logical query plans" from ML pipeline code relying on popular libraries. Based on these plans, we automatically infer pipeline semantics and instrument and rewrite the ML pipelines to enable diverse use cases without requiring data scientists to manually annotate or rewrite their code.
  First, we developed such an abstract ML pipeline representation together with machinery to extract it from Python code. Next, we used this representation to efficiently instrument static ML pipelines and apply provenance tracking, which enables lightweight screening for common data preparation issues. Finally, we built machinery to automatically rewrite ML pipelines to perform more advanced what-if analyses and proposed using multi-query optimisation for the resulting workloads. In future work, we aim to interactively assist data scientists as they work on their ML pipelines.</description>
      <guid isPermaLink="false">oai:arXiv.org:2407.07560v1</guid>
      <category>cs.DB</category>
      <category>cs.LG</category>
      <category>cs.SE</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Stefan Grafberger</dc:creator>
    </item>
    <item>
      <title>Evaluating the Role of Security Assurance Cases in Agile Medical Device Development</title>
      <link>https://arxiv.org/abs/2407.07704</link>
      <description>arXiv:2407.07704v1 Announce Type: cross 
Abstract: Cybersecurity issues in medical devices threaten patient safety and can cause harm if exploited. Standards and regulations therefore require vendors of such devices to provide an assessment of the cybersecurity risks as well as a description of their mitigation. Security assurance cases (SACs) capture these elements as a structured argument. Compiling an SAC requires taking domain-specific regulations and requirements as well as the way of working into account. In this case study, we evaluate CASCADE, an approach for building SAC in the context of a large medical device manufacturer with an established agile development workflow. We investigate the regulatory context as well as the adaptations needed in the development process. Our results show the suitability of SACs in the medical device industry. We identified 17 use cases in which an SAC supports internal and external needs. The connection to safety assurance can be achieved by incorporating information from the risk assessment matrix into the SAC. Integration into the development process can be achieved by introducing a new role and rules for the design review and the release to production as well as additional criteria for the definition of done. We also show that SACs built with CASCADE fulfill the requirements of relevant standards in the medical domain such as ISO 14971.</description>
      <guid isPermaLink="false">oai:arXiv.org:2407.07704v1</guid>
      <category>cs.CR</category>
      <category>cs.SE</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Max Fransson, Adam Andersson, Mazen Mohamad, Jan-Philipp Stegh\"ofer</dc:creator>
    </item>
    <item>
      <title>An investigation of the Online Payment and Banking System Apps in Bangladesh</title>
      <link>https://arxiv.org/abs/2407.07766</link>
      <description>arXiv:2407.07766v1 Announce Type: cross 
Abstract: Presently, Bangladesh is expending substantial efforts to digitize its national infrastructure, with a significant emphasis on achieving this goal through mobile applications that facilitate online payments and banking system advancements. Despite the lack of knowledge about the security level of these systems, they are currently in frequent use without much consideration. To observe whether they follow the minimum global set standards, we choose to conduct static and dynamic analysis of the applications using available open-source analyzers and open-source tools. This allows us to attempt to extract sensitive information, if possible, and determine whether the applications adhere to the standards of MASVS set by OWASP. We show how we analyzed 17 .apks and a SDK using open source scanner and discover security flaws to the applications, such as weaknesses related to data storage, vulnerable cryptographic elements, insecure network communications, and unsafe utilization of WebViews, detected by the scanner. These outputs demonstrate the need for extensive manual analysis of the application through source code review and dynamic analysis. We further implement reverse engineering and dynamic approach to verify the outputs and expose some applications do not comply with the standard method of network communication. Moreover, we attempt to verify the rest of the potential vulnerabilities in the next phase of our ongoing investigation.</description>
      <guid isPermaLink="false">oai:arXiv.org:2407.07766v1</guid>
      <category>cs.CR</category>
      <category>cs.AR</category>
      <category>cs.SE</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Shahriar Hasan Mickey, Muhammad Nur Yanhaona</dc:creator>
    </item>
    <item>
      <title>Mimicking Production Behavior with Generated Mocks</title>
      <link>https://arxiv.org/abs/2208.01321</link>
      <description>arXiv:2208.01321v3 Announce Type: replace 
Abstract: Mocking in the context of automated software tests allows testing program units in isolation. Designing realistic interactions between a unit and its environment, and understanding the expected impact of these interactions on the behavior of the unit, are two key challenges that software testers face when developing tests with mocks. In this paper, we propose to monitor an application in production to generate tests that mimic realistic execution scenarios through mocks. Our approach operates in three phases. First, we instrument a set of target methods for which we want to generate tests, as well as the methods that they invoke, which we refer to as mockable method calls. Second, in production, we collect data about the context in which target methods are invoked, as well as the parameters and the returned value for each mockable method call. Third, offline, we analyze the production data to generate test cases with realistic inputs and mock interactions. The approach is automated and implemented in an open-source tool called RICK. We evaluate our approach with 3 real-world, open-source Java applications. RICK monitors the invocation of 128 methods in production across the 3 applications and captures their behavior. Based on this captured data, RICK generates test cases that include realistic initial states and test inputs, mocks, and stubs. The three kinds of mock-based oracles generated by RICK verify the actual interactions between the method and its environment. All the generated test cases are executable, and 52.4% of them successfully mimic the complete execution context of the methods observed in production. The mock-based oracles are effective at detecting regressions within the target methods, complementing each other in their fault-finding ability. We interview 5 developers from the industry who confirm the relevance of using production observations to design mocks and stubs.</description>
      <guid isPermaLink="false">oai:arXiv.org:2208.01321v3</guid>
      <category>cs.SE</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Deepika Tiwari, Martin Monperrus, Benoit Baudry</dc:creator>
    </item>
    <item>
      <title>Understanding the Influence of Motivation on Requirements Engineering-related Activities</title>
      <link>https://arxiv.org/abs/2304.08074</link>
      <description>arXiv:2304.08074v2 Announce Type: replace 
Abstract: Requirements Engineering (RE)-related activities are critical in developing quality software and one of the most human-dependent processes in software engineering (SE). Hence, identifying the impact of diverse human-related aspects on RE is crucial in the SE context. Our study explores the impact of one of the most influential human aspects, motivation on RE, aiming to deepen understanding and provide practical guidance. Through semi-structured interviews with 21 RE-involved practitioners, we used socio-technical grounded theory (STGT) to develop a theory that explains the contextual, causal, and intervening conditions influencing motivation in RE-related activities. We identified strategies to enhance motivating situations or mitigate demotivating ones, along with the outcomes of these strategies. Our findings offer actionable insights for software practitioners to manage the influence of motivation on RE and help researchers further investigate its role across various SE contexts</description>
      <guid isPermaLink="false">oai:arXiv.org:2304.08074v2</guid>
      <category>cs.SE</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Dulaji Hidellaarachchi, John Grundy, Rashina Hoda, Ingo Mueller</dc:creator>
    </item>
    <item>
      <title>Vulnerability Detection with Code Language Models: How Far Are We?</title>
      <link>https://arxiv.org/abs/2403.18624</link>
      <description>arXiv:2403.18624v2 Announce Type: replace 
Abstract: In the context of the rising interest in code language models (code LMs) and vulnerability detection, we study the effectiveness of code LMs for detecting vulnerabilities. Our analysis reveals significant shortcomings in existing vulnerability datasets, including poor data quality, low label accuracy, and high duplication rates, leading to unreliable model performance in realistic vulnerability detection scenarios. Additionally, the evaluation methods used with these datasets are not representative of real-world vulnerability detection.
  To address these challenges, we introduce PrimeVul, a new dataset for training and evaluating code LMs for vulnerability detection. PrimeVul incorporates a novel set of data labeling techniques that achieve comparable label accuracy to human-verified benchmarks while significantly expanding the dataset. It also implements a rigorous data de-duplication and chronological data splitting strategy to mitigate data leakage issues, alongside introducing more realistic evaluation metrics and settings. This comprehensive approach aims to provide a more accurate assessment of code LMs' performance in real-world conditions.
  Evaluating code LMs on PrimeVul reveals that existing benchmarks significantly overestimate the performance of these models. For instance, a state-of-the-art 7B model scored 68.26% F1 on BigVul but only 3.09% F1 on PrimeVul. Attempts to improve performance through advanced training techniques and larger models like GPT-3.5 and GPT-4 were unsuccessful, with results akin to random guessing in the most stringent settings. These findings underscore the considerable gap between current capabilities and the practical requirements for deploying code LMs in security roles, highlighting the need for more innovative research in this domain.</description>
      <guid isPermaLink="false">oai:arXiv.org:2403.18624v2</guid>
      <category>cs.SE</category>
      <category>cs.CL</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Yangruibo Ding, Yanjun Fu, Omniyyah Ibrahim, Chawin Sitawarin, Xinyun Chen, Basel Alomair, David Wagner, Baishakhi Ray, Yizheng Chen</dc:creator>
    </item>
    <item>
      <title>CodeGeeX: A Pre-Trained Model for Code Generation with Multilingual Benchmarking on HumanEval-X</title>
      <link>https://arxiv.org/abs/2303.17568</link>
      <description>arXiv:2303.17568v2 Announce Type: replace-cross 
Abstract: Large pre-trained code generation models, such as OpenAI Codex, can generate syntax- and function-correct code, making the coding of programmers more productive and our pursuit of artificial general intelligence closer. In this paper, we introduce CodeGeeX, a multilingual model with 13 billion parameters for code generation. CodeGeeX is pre-trained on 850 billion tokens of 23 programming languages as of June 2022. Our extensive experiments suggest that CodeGeeX outperforms multilingual code models of similar scale for both the tasks of code generation and translation on HumanEval-X. Building upon HumanEval (Python only), we develop the HumanEval-X benchmark for evaluating multilingual models by hand-writing the solutions in C++, Java, JavaScript, and Go. In addition, we build CodeGeeX-based extensions on Visual Studio Code, JetBrains, and Cloud Studio, generating 4.7 billion tokens for tens of thousands of active users per week. Our user study demonstrates that CodeGeeX can help to increase coding efficiency for 83.4% of its users. Finally, CodeGeeX is publicly accessible and in Sep. 2022, we open-sourced its code, model weights (the version of 850B tokens), API, extensions, and HumanEval-X at https://github.com/THUDM/CodeGeeX.</description>
      <guid isPermaLink="false">oai:arXiv.org:2303.17568v2</guid>
      <category>cs.LG</category>
      <category>cs.AI</category>
      <category>cs.SE</category>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Qinkai Zheng, Xiao Xia, Xu Zou, Yuxiao Dong, Shan Wang, Yufei Xue, Zihan Wang, Lei Shen, Andi Wang, Yang Li, Teng Su, Zhilin Yang, Jie Tang</dc:creator>
    </item>
  </channel>
</rss>
