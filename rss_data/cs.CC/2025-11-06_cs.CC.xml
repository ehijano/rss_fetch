<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>cs.CC updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/cs.CC</link>
    <description>cs.CC updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/cs.CC" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Thu, 06 Nov 2025 08:19:00 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Thu, 06 Nov 2025 00:00:00 -0500</pubDate>
    <skipDays>
      <day>Sunday</day>
      <day>Saturday</day>
    </skipDays>
    <item>
      <title>An Analytical Approach to Parallel Repetition via CSP Inverse Theorems</title>
      <link>https://arxiv.org/abs/2511.03083</link>
      <description>arXiv:2511.03083v1 Announce Type: new 
Abstract: Let $\mathcal{G}$ be a $k$-player game with value $&lt;1$, whose query distribution is such that no marginal on $k-1$ players admits a non-trivial Abelian embedding. We show that for every $n\geq N$, the value of the $n$-fold parallel repetition of $\mathcal{G}$ is $$ \text{val}(\mathcal{G}^{\otimes n}) \leq \frac{1}{\underbrace{\log\log\cdots\log}_{C\text{ times}} n}, $$ where $N=N(\mathcal{G})$ and $1\leq C\leq k^{O(k)}$ are constants. As a consequence, we obtain a parallel repetition theorem for all $3$-player games whose query distribution is pairwise-connected. Prior to our work, only inverse Ackermann decay bounds were known for such games [Ver96].
  As additional special cases, we obtain a unified proof for all known parallel repetition theorems, albeit with weaker bounds: (1) A new analytic proof of parallel repetition for all 2-player games [Raz98, Hol09, DS14]. (2) A new proof of parallel repetition for all $k$-player playerwise connected games [DHVY17, GHMRZ22]. (3) Parallel repetition for all $3$-player games (in particular $3$-XOR games) whose query distribution has no non-trivial Abelian embedding into $(\mathbb{Z}, +)$ [BKM23c, BBKLM25]. (4) Parallel repetition for all 3-player games with binary inputs [HR20, GHMRZ21, GHMRZ22, GMRZ22].</description>
      <guid isPermaLink="false">oai:arXiv.org:2511.03083v1</guid>
      <category>cs.CC</category>
      <pubDate>Thu, 06 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Amey Bhangale, Mark Braverman, Subhash Khot, Yang P. Liu, Dor Minzer, Kunal Mittal</dc:creator>
    </item>
    <item>
      <title>Monotone Bounded Depth Formula Complexity of Graph Homomorphism Polynomials</title>
      <link>https://arxiv.org/abs/2511.03388</link>
      <description>arXiv:2511.03388v1 Announce Type: new 
Abstract: We characterize the monotone bounded depth formula complexity for graph homomorphism and colored isomorphism polynomials using a graph parameter called the cost of bounded product depth baggy elimination tree. Using this characterization, we show an almost optimal separation between monotone circuits and monotone formulas using constant-degree polynomials for all fixed product depths, and an almost optimal separation between monotone formulas of product depths $\Delta$ and $\Delta$ + 1 for all $\Delta$ $\ge$ 1.</description>
      <guid isPermaLink="false">oai:arXiv.org:2511.03388v1</guid>
      <category>cs.CC</category>
      <pubDate>Thu, 06 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Balagopal Komarath (Indian Institute of Technology Gandhinagar), Rohit Narayanan (Indian Institute of Technology Gandhinagar)</dc:creator>
    </item>
    <item>
      <title>Efficient Testing Implies Structured Symmetry</title>
      <link>https://arxiv.org/abs/2511.03653</link>
      <description>arXiv:2511.03653v1 Announce Type: new 
Abstract: Given a small random sample of $n$-bit strings labeled by an unknown Boolean function, which properties of this function can be tested computationally efficiently? We show an equivalence between properties that are efficiently testable from few samples and properties with structured symmetry, which depend only on the function's average values on parts of a low-complexity partition of the domain. Without the efficiency constraint, a similar characterization in terms of unstructured symmetry was obtained by Blais and Yoshida (2019). Our main technical tool is supersimulation, which builds on methods from the algorithmic fairness literature to approximate arbitrarily complex functions by small-circuit simulators that fool significantly larger distinguishers.
  We extend the characterization along other axes as well. We show that allowing parts to overlap exponentially reduces their required number, broadening the scope of the construction from properties testable with $O(\log n)$ samples to properties testable with $O(n)$ samples. For larger sample sizes, we show that any efficient tester is essentially checking for indistinguishability from a bounded collection of small circuits, in the spirit of a characterization of testable graph properties. Finally, we show that our results for Boolean function testing generalize to high-entropy distribution testing on arbitrary domains.</description>
      <guid isPermaLink="false">oai:arXiv.org:2511.03653v1</guid>
      <category>cs.CC</category>
      <category>cs.DS</category>
      <category>cs.LG</category>
      <pubDate>Thu, 06 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Cynthia Dwork, Pranay Tankala</dc:creator>
    </item>
    <item>
      <title>Ideals, Gr\"obner Bases, and PCPs</title>
      <link>https://arxiv.org/abs/2511.03703</link>
      <description>arXiv:2511.03703v1 Announce Type: new 
Abstract: All known proofs of the PCP theorem rely on multiple "composition" steps, where PCPs over large alphabets are turned into PCPs over much smaller alphabets at a (relatively) small price in the soundness error of the PCP. Algebraic proofs, starting with the work of Arora, Lund, Motwani, Sudan, and Szegedy use at least 2 such composition steps, whereas the "Gap amplification" proof of Dinur uses $\Theta(\log n)$ such composition steps. In this work, we present the first PCP construction using just one composition step. The key ingredient, missing in previous work and finally supplied in this paper, is a basic PCP (of Proximity) of size $2^{n^\epsilon}$, for any $\epsilon &gt; 0$, that makes $O_\epsilon(1)$ queries.
  At the core of our new construction is a new class of alternatives to "sum-check" protocols. As used in past PCPs, these provide a method by which to verify that an $m$-variate degree $d$ polynomial $P$ evaluates to zero at every point of some set $S \subseteq \mathbb{F}_q^m$. Previous works had shown how to check this condition for sets of the form $S = H^m$ using $O(m)$ queries with alphabet $\mathbb{F}_q^d$ assuming $d \geq |H|$. Our work improves this basic protocol in two ways: First we extend it to broader classes of sets $S$ (ones closer to Hamming balls rather than cubes). Second, it reduces the number of queries from $O(m)$ to an absolute constant for the settings of $S$ we consider. Specifically when $S = (\{0,1\}^{m/c}_{\leq 1})^c$, we give such an alternate to the sum-check protocol with $O(1)$ queries with alphabet $\mathbb{F}_q^{O(c+d)}$, using proofs of size $q^{O(m^2/c)}$. Our new protocols use insights from the powerful theory of Gr\"obner bases to extend previously known protocols to these new settings with surprising ease. In doing so, they highlight why these theories from algebra may be of further use in complexity theory.</description>
      <guid isPermaLink="false">oai:arXiv.org:2511.03703v1</guid>
      <category>cs.CC</category>
      <pubDate>Thu, 06 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Prashanth Amireddy, Amik Raj Behera, Srikanth Srinivasan, Madhu Sudan, Sophus Valentin Willumsgaard</dc:creator>
    </item>
    <item>
      <title>Hesse's Redemption: Efficient Convex Polynomial Programming</title>
      <link>https://arxiv.org/abs/2511.03440</link>
      <description>arXiv:2511.03440v1 Announce Type: cross 
Abstract: Efficient algorithms for convex optimization, such as the ellipsoid method, require an a priori bound on the radius of a ball around the origin guaranteed to contain an optimal solution if one exists. For linear and convex quadratic programming, such solution bounds follow from classical characterizations of optimal solutions by systems of linear equations. For other programs, e.g., semidefinite ones, examples due to Khachiyan show that optimal solutions may require huge coefficients with an exponential number of bits, even if we allow approximations. Correspondingly, semidefinite programming is not even known to be in NP. The unconstrained minimization of convex polynomials of degree four and higher has remained a fundamental open problem between these two extremes: its optimal solutions do not admit a linear characterization and, at the same time, Khachiyan-type examples do not apply. We resolve this problem by developing new techniques to prove solution bounds when no linear characterizations are available. Even for programs minimizing a convex polynomial (of arbitrary degree) over a polyhedron, we prove that the existence of an optimal solution implies that an approximately optimal one with polynomial bit length also exists. These solution bounds, combined with the ellipsoid method, yield the first polynomial-time algorithm for convex polynomial programming, settling a question posed by Nesterov (Math. Program., 2019). Before, no polynomial-time algorithm was known even for unconstrained minimization of a convex polynomial of degree four.</description>
      <guid isPermaLink="false">oai:arXiv.org:2511.03440v1</guid>
      <category>cs.DS</category>
      <category>cs.CC</category>
      <category>math.AG</category>
      <category>math.OC</category>
      <pubDate>Thu, 06 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Lucas Slot, David Steurer, Manuel Wiedmer</dc:creator>
    </item>
    <item>
      <title>A note reviewing Turing's 1936</title>
      <link>https://arxiv.org/abs/1308.0497</link>
      <description>arXiv:1308.0497v4 Announce Type: replace 
Abstract: By closely rereading the original Turing's 1936 article, we can gain insight about that it is based on the claim to have defined a number which is not computable, arguing that there can be no machine computing the diagonal on the enumeration of the computable sequences. This article provides a careful analysis of Turing's original argument, demonstrating that it cannot be regarded as a conclusive proof. Furthermore, it shows that there is no evidence supporting the existence of a defined number that is not computable.</description>
      <guid isPermaLink="false">oai:arXiv.org:1308.0497v4</guid>
      <category>cs.CC</category>
      <category>cs.LO</category>
      <pubDate>Thu, 06 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Paola Cattabriga</dc:creator>
    </item>
    <item>
      <title>A Courcelle-Type Metatheorem for Rank-Bounded Unconstrained Binary Optimization</title>
      <link>https://arxiv.org/abs/2510.15168</link>
      <description>arXiv:2510.15168v2 Announce Type: replace 
Abstract: We present the first uniform XP exact algorithm for unconstrained binary optimization of quadratic, polynomial, fractional, and other objectives under a single parameter, the differentially affine (DA) rank $r$. An objective $f: \{0,1\}^n \to \mathbb{R}$ has DA rank $r$ if there is a feature map $\psi: \{0,1\}^n \to \mathbb{R}^r$ such that each coordinate flip has finite gain $\Delta_{\pm e_i}f(x)=\langle v_{\pm e_i},\psi(x)\rangle+\beta_{\pm e_i}$. Our algorithm enumerates the $O((2n)^r)$ chambers of the induced hyperplane arrangement and applies a two-sided local-optimality test: a solution exists on a chamber and is unique iff $\operatorname{sign}\Delta_{+e_i}=-\operatorname{sign}\Delta_{-e_i}$ for all $i$, in which case $x_i^\star=1$ iff $\Delta_{+e_i}&gt;0$. This yields $n^{O(r)}$ time with $O(n)$ decoding per chamber. The framework uniformly covers a wide range of nonlinear functions, including all rank-$r$ quadratics, low-Waring-rank pseudo-Boolean polynomials, finite products/ratios on positive domains, finite-basis separable sums via explicit lifts, Taylor-series approximations of analytic functions, and compositions of all the foregoing. Applications include Ising spin models, optimal experimental design, portfolio optimization, and robust statistics. Prior to our work, only specialized subcases involving sparsity, convexity, submodularity, etc. were known to be tractable. Analogous in spirit to Courcelle's theorem (MSO on bounded treewidth graphs) and Grohe's meta-theorems for constraint satisfaction, our result replaces logical width with analytic rank for nonlinear pseudo-Boolean optimization.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.15168v2</guid>
      <category>cs.CC</category>
      <category>cs.DM</category>
      <pubDate>Thu, 06 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Marc Harary</dc:creator>
    </item>
    <item>
      <title>PCF Learned Sort: a Learning Augmented Sort Algorithm with $O(n \log\log n)$ Expected Complexity</title>
      <link>https://arxiv.org/abs/2405.07122</link>
      <description>arXiv:2405.07122v2 Announce Type: replace-cross 
Abstract: Sorting is one of the most fundamental algorithms in computer science. Recently, Learned Sorts, which use machine learning to improve sorting speed, have attracted attention. While existing studies show that Learned Sort is empirically faster than classical sorting algorithms, they do not provide theoretical guarantees about its computational complexity. We propose Piecewise Constant Function (PCF) Learned Sort, a theoretically guaranteed Learned Sort algorithm. We prove that the expected complexity of PCF Learned Sort is $\mathcal{O}(n \log \log n)$ under mild assumptions on the data distribution. We also confirm empirically that PCF Learned Sort has a computational complexity of $\mathcal{O}(n \log \log n)$ on both synthetic and real datasets. This is the first study to theoretically support the empirical success of Learned Sort, and provides evidence for why Learned Sort is fast. The code is available at https://github.com/atsukisato/PCF_Learned_Sort .</description>
      <guid isPermaLink="false">oai:arXiv.org:2405.07122v2</guid>
      <category>cs.DS</category>
      <category>cs.CC</category>
      <pubDate>Thu, 06 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Atsuki Sato, Yusuke Matsui</dc:creator>
    </item>
    <item>
      <title>New aspects of quantum topological data analysis: Betti number estimation, and testing and tracking of homology and cohomology classes</title>
      <link>https://arxiv.org/abs/2506.01432</link>
      <description>arXiv:2506.01432v3 Announce Type: replace-cross 
Abstract: We present new quantum algorithms for estimating homological invariants, specifically Betti and persistent Betti numbers, of a simplicial complex given through structured classical data. Our approach efficiently constructs block-encodings of (persistent) Laplacians, enabling estimation via stochastic rank methods with complexity polylogarithmic in the number of simplices across both sparse and dense regimes.
  Unlike prior spectral algorithms that suffer when Betti numbers are small, we introduce homology tracking and property testing techniques achieving exponential speedups under natural sparsity and structure assumptions. We also formulate homology triviality and equivalence testing as property testing problems, giving nearly linear-time quantum algorithms when the boundary rank is large. A cohomological formulation further yields rank-independent testing and polylog-time manipulation of $r$-cocycles via block-encoded projections. These results open a new direction in quantum topological data analysis and demonstrate provable quantum advantages in computing topological invariants.</description>
      <guid isPermaLink="false">oai:arXiv.org:2506.01432v3</guid>
      <category>quant-ph</category>
      <category>cs.CC</category>
      <category>cs.CG</category>
      <category>cs.DS</category>
      <category>math.AT</category>
      <pubDate>Thu, 06 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Junseo Lee, Nhat A. Nghiem</dc:creator>
    </item>
    <item>
      <title>A weak regularity lemma for polynomials</title>
      <link>https://arxiv.org/abs/2509.21536</link>
      <description>arXiv:2509.21536v2 Announce Type: replace-cross 
Abstract: A regularity lemma for polynomials provides a decomposition in terms of a bounded number of approximately independent polynomials. Such regularity lemmas play an important role in numerous results, yet suffer from the familiar shortcoming of having tower-type bounds or worse. In this paper we design a new, weaker regularity lemma with strong bounds. The new regularity lemma in particular provides means to quantitatively study the curves contained in the image of a polynomial map, which is beyond the reach of standard methods.
  Applications include strong bounds for a problem of Karam on generalized rank, as well as a new method to obtain upper bounds for fan-in parameters in arithmetic circuits. For example, we show that if the image of a polynomial map $\mathbf{P} \colon \mathbb{F}^n \to \mathbb{F}^m$ of degree $d$ does not contain a line, then $\mathbf{P}$ can be computed by a depth-$4$ arithmetic formula with bottom fan-in at most $d/2$ and top fan-in at most $(2m)^{C(d)}$ (with $C(d)=2^{(1+o(1))d}$). One implication of our work is a certain ``barrier'' to arithmetic circuit lower bounds, in terms of the smallest degree of a polynomial curve contained in the image of the given polynomial map.</description>
      <guid isPermaLink="false">oai:arXiv.org:2509.21536v2</guid>
      <category>math.CO</category>
      <category>cs.CC</category>
      <category>math.AC</category>
      <pubDate>Thu, 06 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Guy Moshkovitz, Dora Woodruff</dc:creator>
    </item>
  </channel>
</rss>
