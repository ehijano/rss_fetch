<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>stat.AP updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/stat.AP</link>
    <description>stat.AP updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/stat.AP" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Thu, 10 Oct 2024 04:03:12 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Thu, 10 Oct 2024 00:00:00 -0400</pubDate>
    <skipDays>
      <day>Sunday</day>
      <day>Saturday</day>
    </skipDays>
    <item>
      <title>Scalable Inference for Bayesian Multinomial Logistic-Normal Dynamic Linear Models</title>
      <link>https://arxiv.org/abs/2410.05548</link>
      <description>arXiv:2410.05548v1 Announce Type: new 
Abstract: Many scientific fields collect longitudinal count compositional data. Each observation is a multivariate count vector, where the total counts are arbitrary, and the information lies in the relative frequency of the counts. Multiple authors have proposed Bayesian Multinomial Logistic-Normal Dynamic Linear Models (MLN-DLMs) as a flexible approach to modeling these data. However, adoption of these methods has been limited by computational challenges. This article develops an efficient and accurate approach to posterior state estimation, called $\textit{Fenrir}$. Our approach relies on a novel algorithm for MAP estimation and an accurate approximation to a key posterior marginal of the model. As there are no equivalent methods against which we can compare, we also develop an optimized Stan implementation of MLN-DLMs. Our experiments suggest that Fenrir can be three orders of magnitude more efficient than Stan and can even be incorporated into larger sampling schemes for joint inference of model hyperparameters. Our methods are made available to the community as a user-friendly software library written in C++ with an R interface.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.05548v1</guid>
      <category>stat.AP</category>
      <category>stat.ME</category>
      <category>stat.ML</category>
      <pubDate>Thu, 10 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Manan Saxena, Tinghua Chen, Justin D. Silverman</dc:creator>
    </item>
    <item>
      <title>A time warping model for seasonal data with application to age estimation from narwhal tusks</title>
      <link>https://arxiv.org/abs/2410.05843</link>
      <description>arXiv:2410.05843v1 Announce Type: new 
Abstract: Signals with varying periodicity frequently appear in real-world phenomena, necessitating the development of efficient modelling techniques to map the measured nonlinear timeline to linear time. Here we propose a regression model that allows for a representation of periodic and dynamic patterns observed in time series data. The model incorporates a hidden strictly increasing stochastic process that represents the instantaneous frequency, allowing the model to adapt and accurately capture varying time scales. A case study focusing on age estimation of narwhal tusks is presented, where cyclic element signals associated with annual growth layer groups are analyzed. We apply the methodology to data from one such tusk collected in West Greenland and use the fitted model to estimate the age of the narwhal. The proposed method is validated using simulated signals with known cycle counts and practical considerations and modelling challenges are discussed in detail. This research contributes to the field of time series analysis, providing a tool and valuable insights for understanding and modeling complex cyclic patterns in diverse domains.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.05843v1</guid>
      <category>stat.AP</category>
      <category>stat.ME</category>
      <pubDate>Thu, 10 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Lars Reiter Nielsen, Mads Peter Heide-J{\o}rgensen, Eva Garde, Adeline Samson, Susanne Ditlevsen</dc:creator>
    </item>
    <item>
      <title>Adjusting for publication bias in meta-analysis with continuous outcomes: a comparative study</title>
      <link>https://arxiv.org/abs/2410.06309</link>
      <description>arXiv:2410.06309v1 Announce Type: new 
Abstract: Abstract Publication bias has been a problem facing meta-analysts. Methods adjusting for publication bias have been proposed in the literature. Comparative studies for methods adjusting for publication bias are found in the literature, but these studies are limited. We investigated and compared the performance of five methods adjusting for publication bias for the case of continuous outcomes. The methods studied are Copas, PET-PEESE, p-uniform, Trim &amp; Fill and the limit meta-analysis. In addition, the performance of the random-effects meta-analysis using the DerSimonian estimator is also investigated. The analysis was done using a case-study and an extensive simulation study including different scenario's. The Copas and the PET-PEESE were found to be the least biased methods adjusting for publication bias. However, the Copas method, like other Likelihood-based methods, can have convergence issues. In addition, the PET-PEESE method is robust in case of heteroscedasticity, making the PET-PEESE method a preferable technique to adjust for publication bias.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.06309v1</guid>
      <category>stat.AP</category>
      <pubDate>Thu, 10 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Osama Almalik</dc:creator>
    </item>
    <item>
      <title>Challenges and Possible Strategies to Address Them in Rare Disease Drug Development: A Statistical Perspective</title>
      <link>https://arxiv.org/abs/2410.06585</link>
      <description>arXiv:2410.06585v1 Announce Type: new 
Abstract: Developing drugs for rare diseases presents unique challenges from a statistical perspective. These challenges may include slowly progressive diseases with unmet medical needs, poorly understood natural history, small population size, diversified phenotypes and geneotypes within a disorder, and lack of appropriate surrogate endpoints to measure clinical benefits. The Real-World Evidence (RWE) Scientific Working Group of the American Statistical Association Biopharmaceutical Section has assembled a research team to assess the landscape including challenges and possible strategies to address these challenges and the role of real-world data (RWD) and RWE in rare disease drug development. This paper first reviews the current regulations by regulatory agencies worldwide and then discusses in more details the challenges from a statistical perspective in the design, conduct, and analysis of rare disease clinical trials. After outlining an overall development pathway for rare disease drugs, corresponding strategies to address the aforementioned challenges are presented. Other considerations are also discussed for generating relevant evidence for regulatory decision-making on drugs for rare diseases. The accompanying paper discusses how RWD and RWE can be used to improve the efficiency of rare disease drug development.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.06585v1</guid>
      <category>stat.AP</category>
      <pubDate>Thu, 10 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/publicdomain/zero/1.0/</dc:rights>
      <dc:creator>Jie Chen, Lei Nie, Shiowjen Lee, Haitao Chu, Haijun Tian, Yan Wang, Weili He, Thomas Jemielita, Susan Gruber, Yang Song, Roy Tamura, Lu Tian, Yihua Zhao, Yong Chen, Mark van der Laan, Hana Lee</dc:creator>
    </item>
    <item>
      <title>Use of Real-World Data and Real-World Evidence in Rare Disease Drug Development: A Statistical Perspective</title>
      <link>https://arxiv.org/abs/2410.06586</link>
      <description>arXiv:2410.06586v1 Announce Type: new 
Abstract: Real-world data (RWD) and real-world evidence (RWE) have been increasingly used in medical product development and regulatory decision-making, especially for rare diseases. After outlining the challenges and possible strategies to address the challenges in rare disease drug development (see the accompanying paper), the Real-World Evidence (RWE) Scientific Working Group of the American Statistical Association Biopharmaceutical Section reviews the roles of RWD and RWE in clinical trials for drugs treating rare diseases. This paper summarizes relevant guidance documents and frameworks by selected regulatory agencies and the current practice on the use of RWD and RWE in natural history studies and the design, conduct, and analysis of rare disease clinical trials. A targeted learning roadmap for rare disease trials is described, followed by case studies on the use of RWD and RWE to support a natural history study and marketing applications in various settings.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.06586v1</guid>
      <category>stat.AP</category>
      <pubDate>Thu, 10 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/publicdomain/zero/1.0/</dc:rights>
      <dc:creator>Jie Chen, Susan Gruber, Hana Lee, Haitao Chu, Shiowjen Lee, Haijun Tian, Yan Wang, Weili He, Thomas Jemielita, Yang Song, Roy Tamura, Lu Tian, Yihua Zhao, Yong Chen, Mark van der Laan, Lei Nie</dc:creator>
    </item>
    <item>
      <title>Decentralized Clinical Trials in the Era of Real-World Evidence: A Statistical Perspective</title>
      <link>https://arxiv.org/abs/2410.06591</link>
      <description>arXiv:2410.06591v1 Announce Type: new 
Abstract: There has been a growing trend that activities relating to clinical trials take place at locations other than traditional trial sites (hence decentralized clinical trials or DCTs), some of which are at settings of real-world clinical practice. Although there are numerous benefits of DCTs, this also brings some implications on a number of issues relating to the design, conduct, and analysis of DCTs. The Real-World Evidence Scientific Working Group of the American Statistical Association Biopharmaceutical Section has been reviewing the field of DCTs and provides in this paper considerations for decentralized trials from a statistical perspective. This paper first discusses selected critical decentralized elements that may have statistical implications on the trial and then summarizes regulatory guidance, framework, and initiatives on DCTs. More discussions are presented by focusing on the design (including construction of estimand), implementation, statistical analysis plan (including missing data handling), and reporting of safety events. Some additional considerations (e.g., ethical considerations, technology infrastructure, study oversight, data security and privacy, and regulatory compliance) are also briefly discussed. This paper is intended to provide statistical considerations for decentralized trials of medical products to support regulatory decision-making.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.06591v1</guid>
      <category>stat.AP</category>
      <pubDate>Thu, 10 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/publicdomain/zero/1.0/</dc:rights>
      <dc:creator>Jie Chen, Junrui Di, Nadia Daizadeh, Ying Lu, Hongwei Wang, Yuan-Li Shen, Jennifer Kirk, Frank W. Rockhold, Herbert Pang, Jing Zhao, Weili He, Andrew Potter, Hana Lee</dc:creator>
    </item>
    <item>
      <title>Retrieved dropout imputation considering administrative study withdrawal</title>
      <link>https://arxiv.org/abs/2410.06774</link>
      <description>arXiv:2410.06774v1 Announce Type: new 
Abstract: The International Council for Harmonisation of Technical Requirements for Pharmaceuticals for Human Use (ICH) E9 (R1) Addendum provides a framework for defining estimands in clinical trials. Treatment policy strategy is the mostly used approach to handle intercurrent events in defining estimands. Imputing missing values for potential outcomes under the treatment policy strategy has been discussed in the literature. Missing values as a result of administrative study withdrawals (such as site closures due to business reasons, COVID-19 control measures, and geopolitical conflicts, etc.) are often imputed in the same way as other missing values occurring after intercurrent events related to safety or efficacy. Some research suggests using a hypothetical strategy to handle the treatment discontinuations due to administrative study withdrawal in defining the estimands and imputing the missing values based on completer data assuming missing at random, but this approach ignores the fact that subjects might experience other intercurrent events had they not had the administrative study withdrawal. In this article, we consider the administrative study withdrawal censors the normal real-world like intercurrent events and propose two methods for handling the corresponding missing values under the retrieved dropout imputation framework. Simulation shows the two methods perform well. We also applied the methods to actual clinical trial data evaluating an anti-diabetes treatment.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.06774v1</guid>
      <category>stat.AP</category>
      <category>stat.ME</category>
      <pubDate>Thu, 10 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Rong Liu, Yongming Qu</dc:creator>
    </item>
    <item>
      <title>Causal Inference with Double/Debiased Machine Learning for Evaluating the Health Effects of Multiple Mismeasured Pollutants</title>
      <link>https://arxiv.org/abs/2410.07135</link>
      <description>arXiv:2410.07135v1 Announce Type: new 
Abstract: One way to quantify exposure to air pollution and its constituents in epidemiologic studies is to use an individual's nearest monitor. This strategy results in potential inaccuracy in the actual personal exposure, introducing bias in estimating the health effects of air pollution and its constituents, especially when evaluating the causal effects of correlated multi-pollutant constituents measured with correlated error. This paper addresses estimation and inference for the causal effect of one constituent in the presence of other PM2.5 constituents, accounting for measurement error and correlations. We used a linear regression calibration model, fitted with generalized estimating equations in an external validation study, and extended a double/debiased machine learning (DML) approach to correct for measurement error and estimate the effect of interest in the main study. We demonstrated that the DML estimator with regression calibration is consistent and derived its asymptotic variance. Simulations showed that the proposed estimator reduced bias and attained nominal coverage probability across most simulation settings. We applied this method to assess the causal effects of PM2.5 constituents on cognitive function in the Nurses' Health Study and identified two PM2.5 constituents, Br and Mn, that showed a negative causal effect on cognitive function after measurement error correction.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.07135v1</guid>
      <category>stat.AP</category>
      <category>cs.LG</category>
      <category>stat.ML</category>
      <pubDate>Thu, 10 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Gang Xu, Xin Zhou, Molin Wang, Boya Zhang, Wenhao Jiang, Francine Laden, Helen H. Suh, Adam A. Szpiro, Donna Spiegelman, Zuoheng Wang</dc:creator>
    </item>
    <item>
      <title>A Functional Extension of Semi-Structured Networks</title>
      <link>https://arxiv.org/abs/2410.05430</link>
      <description>arXiv:2410.05430v1 Announce Type: cross 
Abstract: Semi-structured networks (SSNs) merge the structures familiar from additive models with deep neural networks, allowing the modeling of interpretable partial feature effects while capturing higher-order non-linearities at the same time. A significant challenge in this integration is maintaining the interpretability of the additive model component. Inspired by large-scale biomechanics datasets, this paper explores extending SSNs to functional data. Existing methods in functional data analysis are promising but often not expressive enough to account for all interactions and non-linearities and do not scale well to large datasets. Although the SSN approach presents a compelling potential solution, its adaptation to functional data remains complex. In this work, we propose a functional SSN method that retains the advantageous properties of classical functional regression approaches while also improving scalability. Our numerical experiments demonstrate that this approach accurately recovers underlying signals, enhances predictive performance, and performs favorably compared to competing methods.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.05430v1</guid>
      <category>cs.LG</category>
      <category>stat.AP</category>
      <category>stat.CO</category>
      <category>stat.ML</category>
      <pubDate>Thu, 10 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>David R\"ugamer, and Bernard X. W. Liew, Zainab Altai, Almond St\"ocker</dc:creator>
    </item>
    <item>
      <title>GlucoBench: Curated List of Continuous Glucose Monitoring Datasets with Prediction Benchmarks</title>
      <link>https://arxiv.org/abs/2410.05780</link>
      <description>arXiv:2410.05780v1 Announce Type: cross 
Abstract: The rising rates of diabetes necessitate innovative methods for its management. Continuous glucose monitors (CGM) are small medical devices that measure blood glucose levels at regular intervals providing insights into daily patterns of glucose variation. Forecasting of glucose trajectories based on CGM data holds the potential to substantially improve diabetes management, by both refining artificial pancreas systems and enabling individuals to make adjustments based on predictions to maintain optimal glycemic range.Despite numerous methods proposed for CGM-based glucose trajectory prediction, these methods are typically evaluated on small, private datasets, impeding reproducibility, further research, and practical adoption. The absence of standardized prediction tasks and systematic comparisons between methods has led to uncoordinated research efforts, obstructing the identification of optimal tools for tackling specific challenges. As a result, only a limited number of prediction methods have been implemented in clinical practice.
  To address these challenges, we present a comprehensive resource that provides (1) a consolidated repository of curated publicly available CGM datasets to foster reproducibility and accessibility; (2) a standardized task list to unify research objectives and facilitate coordinated efforts; (3) a set of benchmark models with established baseline performance, enabling the research community to objectively gauge new methods' efficacy; and (4) a detailed analysis of performance-influencing factors for model development. We anticipate these resources to propel collaborative research endeavors in the critical domain of CGM-based glucose predictions. {Our code is available online at github.com/IrinaStatsLab/GlucoBench.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.05780v1</guid>
      <category>q-bio.QM</category>
      <category>cs.LG</category>
      <category>stat.AP</category>
      <pubDate>Thu, 10 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Renat Sergazinov, Elizabeth Chun, Valeriya Rogovchenko, Nathaniel Fernandes, Nicholas Kasman, Irina Gaynanova</dc:creator>
    </item>
    <item>
      <title>Dynamic graphical models: Theory, structure and counterfactual forecasting</title>
      <link>https://arxiv.org/abs/2410.06125</link>
      <description>arXiv:2410.06125v1 Announce Type: cross 
Abstract: Simultaneous graphical dynamic linear models (SGDLMs) provide advances in flexibility, parsimony and scalability of multivariate time series analysis, with proven utility in forecasting. Core theoretical aspects of such models are developed, including new results linking dynamic graphical and latent factor models. Methodological developments extend existing Bayesian sequential analyses for model marginal likelihood evaluation and counterfactual forecasting. The latter, involving new Bayesian computational developments for missing data in SGDLMs, is motivated by causal applications. A detailed example illustrating the models and new methodology concerns global macroeconomic time series with complex, time-varying cross-series relationships and primary interests in potential causal effects.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.06125v1</guid>
      <category>stat.ME</category>
      <category>stat.AP</category>
      <pubDate>Thu, 10 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Mike West, Luke Vrotsos</dc:creator>
    </item>
    <item>
      <title>False Discovery Rate Control via Data Splitting for Testing-after-Clustering</title>
      <link>https://arxiv.org/abs/2410.06451</link>
      <description>arXiv:2410.06451v1 Announce Type: cross 
Abstract: Testing for differences in features between clusters in various applications often leads to inflated false positives when practitioners use the same dataset to identify clusters and then test features, an issue commonly known as ``double dipping''. To address this challenge, inspired by data-splitting strategies for controlling the false discovery rate (FDR) in regressions \parencite{daiFalseDiscoveryRate2023}, we present a novel method that applies data-splitting to control FDR while maintaining high power in unsupervised clustering. We first divide the dataset into two halves, then apply the conventional testing-after-clustering procedure to each half separately and combine the resulting test statistics to form a new statistic for each feature. The new statistic can help control the FDR due to its property of having a sampling distribution that is symmetric around zero for any null feature. To further enhance stability and power, we suggest multiple data splitting, which involves repeatedly splitting the data and combining results. Our proposed data-splitting methods are mathematically proven to asymptotically control FDR in Gaussian settings. Through extensive simulations and analyses of single-cell RNA sequencing (scRNA-seq) datasets, we demonstrate that the data-splitting methods are easy to implement, adaptable to existing single-cell data analysis pipelines, and often outperform other approaches when dealing with weak signals and high correlations among features.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.06451v1</guid>
      <category>stat.ME</category>
      <category>stat.AP</category>
      <pubDate>Thu, 10 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Lijun Wang, Yingxin Lin, Hongyu Zhao</dc:creator>
    </item>
    <item>
      <title>Green bubbles: a four-stage paradigm for detection and propagation</title>
      <link>https://arxiv.org/abs/2410.06564</link>
      <description>arXiv:2410.06564v1 Announce Type: cross 
Abstract: Climate change has emerged as a significant global concern, attracting increasing attention worldwide. While green bubbles may be examined through a social bubble hypothesis, it is essential not to neglect a Climate Minsky moment triggered by sudden asset price changes. The significant increase in green investments highlights the urgent need for a comprehensive understanding of these market dynamics. Therefore, the current paper introduces a novel paradigm for studying such phenomena. Focusing on the renewable energy sector, Statistical Process Control (SPC) methodologies are employed to identify green bubbles within time series data. Furthermore, search volume indexes and social factors are incorporated into established econometric models to reveal potential implications for the financial system. Inspired by Joseph Schumpeter's perspectives on business cycles, this study recognizes green bubbles as a necessary evil for facilitating a successful transition towards a more sustainable future.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.06564v1</guid>
      <category>econ.EM</category>
      <category>stat.AP</category>
      <pubDate>Thu, 10 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Gian Luca Vriz, Luigi Grossi</dc:creator>
    </item>
    <item>
      <title>Optimized Magnetic Resonance Fingerprinting Using Ziv-Zakai Bound</title>
      <link>https://arxiv.org/abs/2410.06624</link>
      <description>arXiv:2410.06624v1 Announce Type: cross 
Abstract: Magnetic Resonance Fingerprinting (MRF) has emerged as a promising quantitative imaging technique within the field of Magnetic Resonance Imaging (MRI), offers comprehensive insights into tissue properties by simultaneously acquiring multiple tissue parameter maps in a single acquisition. Sequence optimization is crucial for improving the accuracy and efficiency of MRF. In this work, a novel framework for MRF sequence optimization is proposed based on the Ziv-Zakai bound (ZZB). Unlike the Cram\'er-Rao bound (CRB), which aims to enhance the quality of a single fingerprint signal with deterministic parameters, ZZB provides insights into evaluating the minimum mismatch probability for pairs of fingerprint signals within the specified parameter range in MRF. Specifically, the explicit ZZB is derived to establish a lower bound for the discrimination error in the fingerprint signal matching process within MRF. This bound illuminates the intrinsic limitations of MRF sequences, thereby fostering a deeper understanding of existing sequence performance. Subsequently, an optimal experiment design problem based on ZZB was formulated to ascertain the optimal scheme of acquisition parameters, maximizing discrimination power of MRF between different tissue types. Preliminary numerical experiments show that the optimized ZZB scheme outperforms both the conventional and CRB schemes in terms of the reconstruction accuracy of multiple parameter maps.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.06624v1</guid>
      <category>eess.IV</category>
      <category>q-bio.QM</category>
      <category>stat.AP</category>
      <pubDate>Thu, 10 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Chaoguang Gong, Yue Hu, Peng Li, Lixian Zou, Congcong Liu, Yihang Zhou, Yanjie Zhu, Dong Liang, Haifeng Wang</dc:creator>
    </item>
    <item>
      <title>Direct measurement of darkness using a standard single-photon avalanche photodiode</title>
      <link>https://arxiv.org/abs/2410.06691</link>
      <description>arXiv:2410.06691v1 Announce Type: cross 
Abstract: In experiments requiring extreme darkness, such as experiments probing the limits of human vision, assessment of the background photon flux is essential. However, direct measurement thereof with standard single photon detectors is challenged by dark counts and their fluctuations. Here we report an experiment and detailed statistical analysis of a direct measurement of darkness in a dedicated dark chamber suitable for human vision experiments, only using a standard single photon detector and a mechanical shutter. From a Bayesian analysis of $616$ h of data, we find substantial to decisive evidence for absolute darkness (depending on choice of prior distribution) based on the Savage-Dickey ratio, and a light level $&lt;0.039$ cnt/s (posterior $0.95$-highest density interval).</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.06691v1</guid>
      <category>quant-ph</category>
      <category>physics.data-an</category>
      <category>physics.optics</category>
      <category>stat.AP</category>
      <pubDate>Thu, 10 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>T. H. A. van der Reep, D. Molenaar, W. L\"offler</dc:creator>
    </item>
    <item>
      <title>Classification of Buried Objects from Ground Penetrating Radar Images by using Second Order Deep Learning Models</title>
      <link>https://arxiv.org/abs/2410.07117</link>
      <description>arXiv:2410.07117v1 Announce Type: cross 
Abstract: In this paper, a new classification model based on covariance matrices is built in order to classify buried objects. The inputs of the proposed models are the hyperbola thumbnails obtained with a classical Ground Penetrating Radar (GPR) system. These thumbnails are entered in the first layers of a classical CNN which results in a covariance matrix by using the outputs of the convolutional filters. Next, the covariance matrix is given to a network composed of specific layers to classify Symmetric Positive Definite (SPD) matrices. We show in a large database that our approach outperform shallow networks designed for GPR data and conventional CNNs typically used in computer vision applications, particularly when the number of training data decreases and in the presence of mislabeled data. We also illustrate the interest of our models when training data and test sets are obtained from different weather modes or considerations.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.07117v1</guid>
      <category>cs.CV</category>
      <category>cs.LG</category>
      <category>stat.AP</category>
      <pubDate>Thu, 10 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Douba Jafuno, Ammar Mian, Guillaume Ginolhac, Nickolas Stelzenmuller</dc:creator>
    </item>
    <item>
      <title>Analysis of vessel traffic flow characteristics in inland restricted waterways using multi-source data</title>
      <link>https://arxiv.org/abs/2410.07130</link>
      <description>arXiv:2410.07130v1 Announce Type: cross 
Abstract: To effectively manage vessel traffic and alleviate congestion on busy inland waterways, a comprehensive understanding of vessel traffic flow characteristics is crucial. However, limited data availability has resulted in minimal research on the traffic flow characteristics of inland waterway vessels. This study addresses this gap by conducting vessel-following experiments and fixed-point video monitoring in inland waterways, collecting multi-source data to analyze vessel traffic flow characteristics. First, the analysis of vessel speed distribution identifies the economic speed for vessels operating in these environments. Next, the relationship between microscopic vessel speed and gap distance is examined, with the logarithmic model emerging as the most accurate among various tested models. Additionally, the study explores the relationships among macroscopic speed, density, and flow rate, proposing a novel piecewise fundamental diagram model to describe these relationships. Lastly, the inland vessel traffic states are categorized using K-means clustering algorithm and applied to vessel navigation services. These findings provide valuable insights for enhancing inland waterway transportation and advancing the development of an integrated waterway transportation system.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.07130v1</guid>
      <category>cs.CE</category>
      <category>stat.AP</category>
      <pubDate>Thu, 10 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Wenzhang Yang, Peng Liao, Shangkun Jiang, Hao Wang</dc:creator>
    </item>
    <item>
      <title>Diagnosis and Pathogenic Analysis of Autism Spectrum Disorder Using Fused Brain Connection Graph</title>
      <link>https://arxiv.org/abs/2410.07138</link>
      <description>arXiv:2410.07138v1 Announce Type: cross 
Abstract: We propose a model for diagnosing Autism spectrum disorder (ASD) using multimodal magnetic resonance imaging (MRI) data. Our approach integrates brain connectivity data from diffusion tensor imaging (DTI) and functional MRI (fMRI), employing graph neural networks (GNNs) for fused graph classification. To improve diagnostic accuracy, we introduce a loss function that maximizes inter-class and minimizes intra-class margins. We also analyze network node centrality, calculating degree, subgraph, and eigenvector centralities on a bimodal fused brain graph to identify pathological regions linked to ASD. Two non-parametric tests assess the statistical significance of these centralities between ASD patients and healthy controls. Our results reveal consistency between the tests, yet the identified regions differ significantly across centralities, suggesting distinct physiological interpretations. These findings enhance our understanding of ASD's neurobiological basis and offer new directions for clinical diagnosis.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.07138v1</guid>
      <category>q-bio.NC</category>
      <category>cs.LG</category>
      <category>stat.AP</category>
      <pubDate>Thu, 10 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <dc:creator>Lu Wei, Yi Huang, Guosheng Yin, Fode Zhang, Manxue Zhang, Bin Liu</dc:creator>
    </item>
    <item>
      <title>Spatiotemporal Modeling and Forecasting at Scale with Dynamic Generalized Linear Models</title>
      <link>https://arxiv.org/abs/2410.07161</link>
      <description>arXiv:2410.07161v1 Announce Type: cross 
Abstract: Spatiotemporal data consisting of timestamps, GPS coordinates, and IDs occurs in many settings. Modeling approaches for this type of data must address challenges in terms of sensor noise, uneven sampling rates, and non-persistent IDs. In this work, we characterize and forecast human mobility at scale with dynamic generalized linear models (DGLMs). We represent mobility data as occupancy counts of spatial cells over time and use DGLMs to model the occupancy counts for each spatial cell in an area of interest. DGLMs are flexible to varying numbers of occupancy counts across spatial cells, are dynamic, and easily incorporate daily and weekly seasonality in the aggregate-level behavior. Our overall approach is robust to various types of noise and scales linearly in the number of spatial cells, time bins, and agents. Our results show that DGLMs provide accurate occupancy count forecasts over a variety of spatial resolutions and forecast horizons. We also present scaling results for spatiotemporal data consisting of hundreds of millions of observations. Our approach is flexible to support several downstream applications, including characterizing human mobility, forecasting occupancy counts, and anomaly detection for aggregate-level behaviors.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.07161v1</guid>
      <category>stat.ME</category>
      <category>stat.AP</category>
      <pubDate>Thu, 10 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <arxiv:DOI>10.1145/3681765.3698449</arxiv:DOI>
      <arxiv:journal_reference>In 1st ACM SIGSPATIAL International Workshop on Geospatial Anomaly Detection (GeoAnomalies'24), October 29, 2024, Atlanta, GA, USA</arxiv:journal_reference>
      <dc:creator>Pranay Pherwani, Nicholas Hass, Anna K. Yanchenko</dc:creator>
    </item>
    <item>
      <title>Multivariate cluster point process to quantify and explore multi-entity configurations: Application to biofilm image data</title>
      <link>https://arxiv.org/abs/2202.04198</link>
      <description>arXiv:2202.04198v4 Announce Type: replace 
Abstract: Clusters of similar or dissimilar objects are encountered in many fields. Frequently used approaches treat the central object of each cluster as latent. Yet, often objects of one or more types cluster around objects of another type. Such arrangements are common in biomedical images of cells, in which nearby cell types likely interact. Quantifying spatial relationships may elucidate biological mechanisms. Parent-offspring statistical frameworks can be usefully applied even when central objects (parents) differ from peripheral ones (offspring). We propose the novel multivariate cluster point process (MCPP) to quantify multi-object (e.g., multi-cellular) arrangements. Unlike commonly used approaches, the MCPP exploits locations of the central parent object in clusters. It accounts for possibly multilayered, multivariate clustering. The model formulation requires specification of which object types function as cluster centers and which reside peripherally. If such information is unknown, the relative roles of object types may be explored by comparing fit of different models via the deviance information criterion (DIC). In simulated data, we compared DIC of a series of models; the MCPP correctly identified simulated relationships. It also produced more accurate and precise parameter estimates than the classical univariate Neyman-Scott process model. We also used the MCPP to quantify proposed configurations and explore new ones in human dental plaque biofilm image data. MCPP models quantified simultaneous clustering of Streptococcus and Porphyromonas around Corynebacterium and of Pasteurellaceae around Streptococcus and successfully captured hypothesized structures for all taxa. Further exploration suggested the presence of clustering between Fusobacterium and Leptotrichia, a previously unreported relationship.</description>
      <guid isPermaLink="false">oai:arXiv.org:2202.04198v4</guid>
      <category>stat.AP</category>
      <pubDate>Thu, 10 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Suman Majumder, Brent A. Coull, Jessica L. Mark Welch, Patrick J. La Riviere, Floyd E. Dewhirst, Jacqueline R. Starr, Kyu Ha Lee</dc:creator>
    </item>
    <item>
      <title>Testing for the Network Small-World Property</title>
      <link>https://arxiv.org/abs/2103.08035</link>
      <description>arXiv:2103.08035v2 Announce Type: replace-cross 
Abstract: Researchers have long observed that the ``small-world" property, which combines the concepts of high transitivity or clustering with a low average path length, is ubiquitous for networks obtained from a variety of disciplines, including social sciences, biology, neuroscience, and ecology. However, we find several shortcomings of the currently prevalent definition and detection methods rendering the concept less powerful. First, the widely used \textit{small world coefficient} metric combines high transitivity with a low average path length in a single measure that confounds the two separate aspects. We find that the value of the metric is dominated by transitivity, and in several cases, networks get flagged as ``small world" solely because of their high transitivity. Second, the detection methods lack a formal statistical inference. Third, the comparison is typically performed against simplistic random graph models as the baseline, ignoring well-known network characteristics and risks confounding the small world property with other network properties. We decouple the properties of high transitivity and low average path length as separate events to test for. Then we define the property as a statistical test between a suitable null hypothesis and a superimposed alternative hypothesis. We propose a parametric bootstrap test with several null hypothesis models to allow a wide range of background structures in the network. In addition to the bootstrap tests, we also propose an asymptotic test under the Erd\"{o}s-Ren\'{y}i null model for which we provide theoretical guarantees on the asymptotic level and power. Our theoretical results include asymptotic distributions of clustering coefficient for various asymptotic growth rates on the probability of an edge. Applying the proposed methods to a large number of network datasets, we uncover new insights about their small-world property.</description>
      <guid isPermaLink="false">oai:arXiv.org:2103.08035v2</guid>
      <category>stat.ME</category>
      <category>stat.AP</category>
      <pubDate>Thu, 10 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Kartik Lovekar, Srijan Sengupta, Subhadeep Paul</dc:creator>
    </item>
    <item>
      <title>Digital Divide: Empirical Study of CIUS 2020</title>
      <link>https://arxiv.org/abs/2301.07855</link>
      <description>arXiv:2301.07855v3 Announce Type: replace-cross 
Abstract: As Canada and other major economies consider implementing "digital money" or Central Bank Digital Currencies, understanding how demographic and geographic factors influence public engagement with digital technologies becomes increasingly important. This paper uses data from the 2020 Canadian Internet Use Survey and employs survey-adapted Lasso inference methods to identify individual socio-economic and demographic characteristics determining the digital divide in Canada. We also introduce a score to measure and compare the digital literacy of various segments of Canadian population. Our findings reveal that disparities in the use of e.g. online banking, emailing, and digital payments exist across different demographic and socio-economic groups. In addition, we document the effects of COVID-19 pandemic on internet use in Canada and describe changes in the characteristics of Canadian internet users over the last decade.</description>
      <guid isPermaLink="false">oai:arXiv.org:2301.07855v3</guid>
      <category>econ.EM</category>
      <category>stat.AP</category>
      <pubDate>Thu, 10 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Joann Jasiak, Peter MacKenzie, Purevdorj Tuvaandorj</dc:creator>
    </item>
    <item>
      <title>Enhancing Interpretability and Generalizability in Extended Isolation Forests</title>
      <link>https://arxiv.org/abs/2310.05468</link>
      <description>arXiv:2310.05468v3 Announce Type: replace-cross 
Abstract: Anomaly Detection (AD) focuses on identifying unusual behaviors in complex datasets. Machine Learning (ML) algorithms and Decision Support Systems (DSSs) provide effective solutions for AD, but detecting anomalies alone may not be enough, especially in engineering, where diagnostics and maintenance are crucial. Users need clear explanations to support root cause analysis and build trust in the model. The unsupervised nature of AD, however, makes interpretability a challenge. This paper introduces Extended Isolation Forest Feature Importance (ExIFFI), a method that explains predictions made by Extended Isolation Forest (EIF) models, which split data using hyperplanes. ExIFFI provides explanations at both global and local levels by leveraging feature importance.
  We also present an improved version, Enhanced Extended Isolation Forest (EIF+), designed to enhance the model's ability to detect unseen anomalies through a revised splitting strategy. Using five synthetic and eleven real-world datasets, we conduct a comparative analysis, evaluating unsupervised AD methods with the Average Precision metric. EIF+ consistently outperforms EIF across all datasets when trained without anomalies, demonstrating better generalization.
  To assess ExIFFI's interpretability, we introduce the Area Under the Curve of Feature Selection (AUC\_FS), a novel metric using feature selection as a proxy task. ExIFFI outperforms other unsupervised interpretability methods on 8 of 11 real-world datasets and successfully identifies anomalous features in synthetic datasets. When trained only on inliers, ExIFFI also outperforms competing models on real-world data and accurately detects anomalous features in synthetic datasets. We provide open-source code to encourage further research and reproducibility.</description>
      <guid isPermaLink="false">oai:arXiv.org:2310.05468v3</guid>
      <category>stat.ML</category>
      <category>cs.LG</category>
      <category>stat.AP</category>
      <pubDate>Thu, 10 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Alessio Arcudi, Davide Frizzo, Chiara Masiero, Gian Antonio Susto</dc:creator>
    </item>
    <item>
      <title>European Football Player Valuation: Integrating Financial Models and Network Theory</title>
      <link>https://arxiv.org/abs/2312.16179</link>
      <description>arXiv:2312.16179v2 Announce Type: replace-cross 
Abstract: This paper presents a new framework for player valuation in European football by fusing principles from financial mathematics and network theory. The valuation model leverages a "passing matrix" to encapsulate player interactions on the field, utilizing centrality measures to quantify individual influence. Unlike traditional approaches, this model is both metric-driven and cohort-free, providing a dynamic and individualized framework for ascertaining a player's fair market value. The methodology is empirically validated through a case study in European football, employing real-world match and financial data. The paper advances the disciplines of sports analytics and financial mathematics by offering a cross-disciplinary mechanism for player valuation, and also links together two well-known econometric methods in marginal revenue product and expected present valuation.</description>
      <guid isPermaLink="false">oai:arXiv.org:2312.16179v2</guid>
      <category>physics.soc-ph</category>
      <category>q-fin.CP</category>
      <category>q-fin.PR</category>
      <category>stat.AP</category>
      <pubDate>Thu, 10 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Albert Cohen, Jimmy Risk</dc:creator>
    </item>
    <item>
      <title>Effects of model misspecification on small area estimators</title>
      <link>https://arxiv.org/abs/2403.11276</link>
      <description>arXiv:2403.11276v2 Announce Type: replace-cross 
Abstract: Nested error regression models are commonly used to incorporate observational unit specific auxiliary variables to improve small area estimates. When the mean structure of this model is misspecified, there is generally an increase in the mean square prediction error (MSPE) of Empirical Best Linear Unbiased Predictors (EBLUP). Observed Best Prediction (OBP) method has been proposed with the intent to improve on the MSPE over EBLUP. We conduct a Monte Carlo simulation experiment to understand the effect of mispsecification of mean structures on different small area estimators. Our simulation results lead to an unexpected result that OBP may perform very poorly when observational unit level auxiliary variables are used and that OBP can be improved significantly when population means of those auxiliary variables (area level auxiliary variables) are used in the nested error regression model or when a corresponding area level model is used. Our simulation also indicates that the MSPE of OBP in an increasing function of the difference between the sample and population means of the auxiliary variables.</description>
      <guid isPermaLink="false">oai:arXiv.org:2403.11276v2</guid>
      <category>stat.ME</category>
      <category>stat.AP</category>
      <pubDate>Thu, 10 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Yuting Chen, Partha Lahiri, Nicola Salvati</dc:creator>
    </item>
    <item>
      <title>The Uneven Access to COVID-19 Research for Women in Science</title>
      <link>https://arxiv.org/abs/2404.04707</link>
      <description>arXiv:2404.04707v2 Announce Type: replace-cross 
Abstract: The COVID-19 pandemic has exacerbated gender disparities in medical and academic careers. In this study, we examine the impact of COVID-19 as a new research topic on the presence of women in key authorship positions in biomedical research. We determine author's gender based on the names listed on their scientific publications and analyze the changes in the composition of the scientific teams after the COVID-19 outbreak. Using a Difference-in-Differences approach, we find that although the share of female authorships has increased overall, women are less likely to be first or last authors (the most prestigious positions) on COVID-19-related research papers and more likely to be found in middle author positions. Stay-at-home mandates, the journal importance and funding opportunities do not fully account for the decline of women in key author positions. The main difference in first authorship is due to the composition of the team and the experience of the lead authors in COVID-19 related research. First authorship by women declined after teams of novices emerged, where lead authors have no prior experience in COVID-related research. Discretionality in first-author appointments for newcomers, combined with high pressure to publish quickly, may have led to discriminatory biases. Conversely, there may also be differences in risk-taking attitudes in doing research in unfamiliar domains. Monitoring gender inequality in scientific production is crucial for reducing gender inequalities and for implementing timely policies that ensure equal access to emerging research topics.</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.04707v2</guid>
      <category>econ.GN</category>
      <category>q-fin.EC</category>
      <category>stat.AP</category>
      <pubDate>Thu, 10 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Carolina Biliotti, Luca Verginer, Massimo Riccaboni</dc:creator>
    </item>
    <item>
      <title>UAVDB: Trajectory-Guided Adaptable Bounding Boxes for UAV Detection</title>
      <link>https://arxiv.org/abs/2409.06490</link>
      <description>arXiv:2409.06490v3 Announce Type: replace-cross 
Abstract: The rapid advancement of drone technology has made accurate Unmanned Aerial Vehicle (UAV) detection essential for surveillance, security, and airspace management. This paper presents a novel trajectory-guided approach, the Patch Intensity Convergence (PIC) technique, which generates high-fidelity bounding boxes for UAV detection without manual labeling. This technique forms the foundation of UAVDB, a dedicated database designed specifically for UAV detection. Unlike datasets that often focus on large UAVs or simple backgrounds, UAVDB utilizes high-resolution RGB video to capture UAVs at various scales, from hundreds of pixels to near-single-digit sizes. This extensive scale variation enables robust evaluation of detection algorithms under diverse conditions. Using the PIC technique, bounding boxes can be efficiently generated from trajectory or position data. We benchmark UAVDB using state-of-the-art (SOTA) YOLO series detectors, providing a comprehensive performance analysis. Our results demonstrate UAVDB's potential as a critical resource for advancing UAV detection, particularly in high-resolution and long-distance tracking scenarios.</description>
      <guid isPermaLink="false">oai:arXiv.org:2409.06490v3</guid>
      <category>cs.CV</category>
      <category>stat.AP</category>
      <pubDate>Thu, 10 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Yu-Hsi Chen</dc:creator>
    </item>
    <item>
      <title>Adaptive radar detection of subspace-based distributed target in power heterogeneous clutter</title>
      <link>https://arxiv.org/abs/2409.14049</link>
      <description>arXiv:2409.14049v2 Announce Type: replace-cross 
Abstract: This paper investigates the problem of adaptive detection of distributed targets in power heterogeneous clutter. In the considered scenario, all the data share the identical structure of clutter covariance matrix, but with varying and unknown power mismatches. To address this problem, we iteratively estimate all the unknowns, including the coordinate matrix of the target, the clutter covariance matrix, and the corresponding power mismatches, and propose three detectors based on the generalized likelihood ratio test (GLRT), Rao and the Wald tests. The results from simulated and real data both illustrate that the detectors based on GLRT and Rao test have higher probabilities of detection (PDs) than the existing competitors. Among them, the Rao test-based detector exhibits the best overall detection performance. We also analyze the impact of the target extended dimensions, the signal subspace dimensions, and the number of training samples on the detection performance. Furthermore, simulation experiments also demonstrate that the proposed detectors have a constant false alarm rate (CFAR) property for the structure of clutter covariance matrix.</description>
      <guid isPermaLink="false">oai:arXiv.org:2409.14049v2</guid>
      <category>stat.ME</category>
      <category>stat.AP</category>
      <category>stat.OT</category>
      <pubDate>Thu, 10 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <arxiv:DOI>10.1109/JSEN.2024.3472040</arxiv:DOI>
      <dc:creator>Daipeng Xiao, Weijian Liu, Jun Liu, Lingyan Dai, Xueli Fang, Jianjun Ge</dc:creator>
    </item>
    <item>
      <title>Spatial Hyperspheric Models for Compositional Data</title>
      <link>https://arxiv.org/abs/2410.03648</link>
      <description>arXiv:2410.03648v2 Announce Type: replace-cross 
Abstract: Compositional data are an increasingly prevalent data source in spatial statistics. Analysis of such data is typically done on log-ratio transformations or via Dirichlet regression. However, these approaches often make unnecessarily strong assumptions (e.g., strictly positive components, exclusively negative correlations). An alternative approach uses square-root transformed compositions and directional distributions. Such distributions naturally allow for zero-valued components and positive correlations, yet they may include support outside the non-negative orthant and are not generative for compositional data. To overcome this challenge, we truncate the elliptically symmetric angular Gaussian (ESAG) distribution to the non-negative orthant. Additionally, we propose a spatial hyperspheric regression that contains fixed and random multivariate spatial effects. The proposed method also contains a term that can be used to propagate uncertainty that may arise from precursory stochastic models (i.e., machine learning classification). We demonstrate our method on a simulation study and on classified bioacoustic signals of the Dryobates pubescens (downy woodpecker).</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.03648v2</guid>
      <category>stat.ME</category>
      <category>stat.AP</category>
      <category>stat.CO</category>
      <pubDate>Thu, 10 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Michael R. Schwob, Mevin B. Hooten, Nicholas M. Calzada</dc:creator>
    </item>
  </channel>
</rss>
