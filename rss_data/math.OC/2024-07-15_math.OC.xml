<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>math.OC updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/math.OC</link>
    <description>math.OC updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/math.OC" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Tue, 16 Jul 2024 04:00:10 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Tue, 16 Jul 2024 00:00:00 -0400</pubDate>
    <skipDays>
      <day>Saturday</day>
      <day>Sunday</day>
    </skipDays>
    <item>
      <title>Computation of Generalized Derivatives for Abs-Smooth Functions by Backward Mode Algorithmic Differentiation and Implications to Deep Learning</title>
      <link>https://arxiv.org/abs/2407.09639</link>
      <description>arXiv:2407.09639v1 Announce Type: new 
Abstract: Algorithmic differentiation (AD) tools allow to obtain gradient information of a continuously differentiable objective function in a computationally cheap way using the so-called backward mode. It is common practice to use the same tools even in the absence of differentiability, although the resulting vectors may not be generalized gradients in the sense of Clarke. The paper at hand focuses on objectives in which the non-differentiability arises solely from the evaluation of the absolute value function. In that case, an algebraic condition based on the evaluation procedure of the objective is identified, that guarantees that Clarke gradients are correctly computed without requiring any modifications of the AD tool in question. The analysis allows to prove that any standard AD tool is adequate to drive a stochastic generalized gradient descent method for training a dense neural network with ReLU activations. The same is true for generalized batch gradients or the full generalized gradient, provided that the AD tool makes a deterministic and agnostic choice for the derivative information of the absolute value at 0.</description>
      <guid isPermaLink="false">oai:arXiv.org:2407.09639v1</guid>
      <category>math.OC</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Lukas Baumg\"artner, Franz Bethke</dc:creator>
    </item>
    <item>
      <title>An Insensitizing control problem involving tangential gradient terms for a reaction-diffusion equation with dynamic boundary conditions</title>
      <link>https://arxiv.org/abs/2407.09882</link>
      <description>arXiv:2407.09882v1 Announce Type: new 
Abstract: In this article, we study the existence of insensitizing controls for a nonlinear reaction-diffusion equation with dynamic boundary conditions. Here, we have a partially unknown data of the system, and the problem consists in finding controls such that a specific functional is insensitive for small perturbations of the initial data. More precisely, the functional considered here depends on the norm of the state in a subset of the bulk together with the norm of the tangential gradient of the state on the boundary. This problem is equivalent to a (relaxed) null controllability problem for an optimality system of cascade type, with a zeroth-order coupling term in the bulk and a second-order coupling term on the boundary. To achieve this result, we linearize the system around the origin and analyze it by the duality approach and we prove a new Carleman estimate for the corresponding adjoint system. Then, a local null controllability result for the nonlinear system is proven by using an inverse function theorem.</description>
      <guid isPermaLink="false">oai:arXiv.org:2407.09882v1</guid>
      <category>math.OC</category>
      <category>math.AP</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Mauricio C. Santos, Nicol\'as Carre\~no, Roberto Morales</dc:creator>
    </item>
    <item>
      <title>An Adaptive Proximal ADMM for Nonconvex Linearly-Constrained Composite Programs</title>
      <link>https://arxiv.org/abs/2407.09927</link>
      <description>arXiv:2407.09927v1 Announce Type: new 
Abstract: This paper develops an adaptive Proximal Alternating Direction Method of Multipliers (P-ADMM) for solving linearly-constrained, weakly convex, composite optimization problems. This method is adaptive to all problem parameters, including smoothness and weak convexity constants. It is assumed that the smooth component of the objective is weakly convex and possibly nonseparable, while the non-smooth component is convex and block-separable. The proposed method is tolerant to the inexact solution of its block proximal subproblem so it does not require that the non-smooth component has easily computable block proximal maps. Each iteration of our adaptive P-ADMM consists of two steps: (1) the sequential solution of each block proximal subproblem, and (2) adaptive tests to decide whether to perform a full Lagrange multiplier and/or penalty parameter update(s). Without any rank assumptions on the constraint matrices, it is shown that the adaptive P-ADMM obtains an approximate first-order stationary point of the constrained problem in a number of iterations that matches the state-of-the-art complexity for the class of P-ADMMs. The two proof-of-concept numerical experiments that conclude the paper suggest our adaptive P-ADMM enjoys significant computational benefits.</description>
      <guid isPermaLink="false">oai:arXiv.org:2407.09927v1</guid>
      <category>math.OC</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Leandro Farias Maia, David H. Gutman, Renato D. C. Monteiro, Gilson N. Silva</dc:creator>
    </item>
    <item>
      <title>An Optimal Pricing Formula for Smart Grid based on Stackelberg Game</title>
      <link>https://arxiv.org/abs/2407.09948</link>
      <description>arXiv:2407.09948v1 Announce Type: new 
Abstract: The dynamic pricing of electricity is one of the most crucial demand response (DR) strategies in smart grid, where the utility company typically adjust electricity prices to influence user electricity demand. This paper models the relationship between the utility company and flexible electricity users as a Stackelberg game. Based on this model, we present a series of analytical results under certain conditions. First, we give an analytical Stackelberg equilibrium, namely the optimal pricing formula for utility company, as well as the unique and strict Nash equilibrium for users' electricity demand under this pricing scheme. To our best knowledge, it is the first optimal pricing formula in the research of price-based DR strategies. Also, if there exist prediction errors for the supply and demand of electricity, we provide an analytical expression for the energy supply cost of utility company. Moreover, a sufficient condition has been proposed that all electricity demands can be supplied by renewable energy. When the conditions for analytical results are not met, we provide a numerical solution algorithm for the Stackelberg equilibrium and verify its efficiency by simulation.</description>
      <guid isPermaLink="false">oai:arXiv.org:2407.09948v1</guid>
      <category>math.OC</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Jiangjiang Cheng, Ge Chen, Zhouming Wu, Yifen Mu</dc:creator>
    </item>
    <item>
      <title>An Efficient High-dimensional Gradient Estimator for Stochastic Differential Equations</title>
      <link>https://arxiv.org/abs/2407.10065</link>
      <description>arXiv:2407.10065v1 Announce Type: new 
Abstract: Overparameterized stochastic differential equation (SDE) models have achieved remarkable success in various complex environments, such as PDE-constrained optimization, stochastic control and reinforcement learning, financial engineering, and neural SDEs. These models often feature system evolution coefficients that are parameterized by a high-dimensional vector $\theta \in \mathbb{R}^n$, aiming to optimize expectations of the SDE, such as a value function, through stochastic gradient ascent. Consequently, designing efficient gradient estimators for which the computational complexity scales well with $n$ is of significant interest. This paper introduces a novel unbiased stochastic gradient estimator--the generator gradient estimator--for which the computation time remains stable in $n$. In addition to establishing the validity of our methodology for general SDEs with jumps, we also perform numerical experiments that test our estimator in linear-quadratic control problems parameterized by high-dimensional neural networks. The results show a significant improvement in efficiency compared to the widely used pathwise differentiation method: Our estimator achieves near-constant computation times, increasingly outperforms its counterpart as $n$ increases, and does so without compromising estimation variance. These empirical findings highlight the potential of our proposed methodology for optimizing SDEs in contemporary applications.</description>
      <guid isPermaLink="false">oai:arXiv.org:2407.10065v1</guid>
      <category>math.OC</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Shengbo Wang, Jose Blanchet, Peter Glynn</dc:creator>
    </item>
    <item>
      <title>Universal subgradient and proximal bundle methods for convex and strongly convex hybrid composite optimization</title>
      <link>https://arxiv.org/abs/2407.10073</link>
      <description>arXiv:2407.10073v1 Announce Type: new 
Abstract: This paper develops two parameter-free methods for solving convex and strongly convex hybrid composite optimization problems, namely, a composite subgradient type method and a proximal bundle type method. Both functional and stationary complexity bounds for the two methods are established in terms of the unknown strong convexity parameter. To the best of our knowledge, the two proposed methods are the first universal methods for strongly convex optimization problems that do not rely on any restart scheme nor require the knowledge of the optimal value.</description>
      <guid isPermaLink="false">oai:arXiv.org:2407.10073v1</guid>
      <category>math.OC</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Vincent Guigues, Jiaming Liang, Renato D. C. Monteiro</dc:creator>
    </item>
    <item>
      <title>Two-Player Zero-Sum Hybrid Games</title>
      <link>https://arxiv.org/abs/2407.10107</link>
      <description>arXiv:2407.10107v1 Announce Type: new 
Abstract: In this paper, we formulate a two-player zero-sum game under dynamic constraints defined by hybrid dynamical equations. The game consists of a min-max problem involving a cost functional that depends on the actions and resulting solutions to the hybrid system, defined as functions of hybrid time and, hence, can flow or jump. We present sufficient conditions given in terms of Hamilton-Jacobi-Bellman-Isaacs-like equations to guarantee to attain a solution to the game. It is shown that when the players select the optimal strategy, the value function can be evaluated without computing solutions to the hybrid system. Under additional conditions, we show that the optimal state-feedback laws render a set of interest asymptotically stable for the resulting hybrid closed-loop system. Applications of this problem, as presented here, include a disturbance rejection scenario for which the effect of the perturbation is upper bounded, and a security scenario in which we formulate an optimal control problem under the presence of the maximizing adversarial action.</description>
      <guid isPermaLink="false">oai:arXiv.org:2407.10107v1</guid>
      <category>math.OC</category>
      <category>cs.SY</category>
      <category>eess.SY</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <dc:creator>Santiago J. Leudo, Ricardo G. Sanfelice</dc:creator>
    </item>
    <item>
      <title>A Coalitional Game for Demand-Side Management in a Low-Voltage Resistive Micro-Grid with Multiple Electricity Retailers</title>
      <link>https://arxiv.org/abs/2407.10144</link>
      <description>arXiv:2407.10144v1 Announce Type: new 
Abstract: An existing challenge in power systems is the implementation of optimal demand management through dynamic pricing. This paper encompasses the design, analysis and implementation of a novel on-line pricing scheme based on coalitional game theory. The setting consists of a network with multiple energy retailers competing to attract consumers by announcing a price in a hierarchical leader-follower structure. The process of coalition formation under such a pricing scheme can be viewed as a game for which we show that a Stackelberg equilibrium exists, \ie given a price, consumers will respond by conforming to a reciprocal power consumption quantity. We propose a coalition formation algorithm and perform a game-theoretic stability analysis on the resulting coalitions. We integrate the pricing setting with a resistive micro-grid dynamic model. In this context we analyse the behaviour of the integrated system, bridging the gap between market and physical layers of the problem. Simulations provide a comparison of profits generated by the proposed scheme against a more traditional single retailer scheme, while simultaneously showing convergence towards a steady-state equilibrium. Additionally, we shed light into the system's physical response when subject to our proposed pricing scheme.</description>
      <guid isPermaLink="false">oai:arXiv.org:2407.10144v1</guid>
      <category>math.OC</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Fernando Genis Mendoza, Pablo R Baldivieso Monasterios, Dario Bauso, George Konstantopoulos</dc:creator>
    </item>
    <item>
      <title>Formulas for the $h$-mass on $1$-currents with coefficients in $\mathbb{R}^m$</title>
      <link>https://arxiv.org/abs/2407.10158</link>
      <description>arXiv:2407.10158v1 Announce Type: new 
Abstract: We consider the minimization of the $h$-mass over normal $1$-currents in $\mathbb{R}^n$ with coefficients in $\mathbb{R}^m$ and prescribed boundary. This optimization is known as multi-material transport problem and used in the context of logistics of multiple commodities, but also as a relaxation of nonconvex optimal transport tasks such as so-called branched transport problems. The $h$-mass with norm $h$ can be defined in different ways, resulting in three functionals $\mathcal{M}_h,|\cdot|_H$, and $\mathbb{M}_h$, whose equality is the main result of this article: $\mathcal{M}_h$ is a functional on $1$-currents in the spirit of Federer and Fleming, norm $|\cdot|_H$ denotes the total variation of a Radon measure with respect to $H$ induced by $h$, and $\mathbb{M}_h$ is a mass on flat $1$-chains in the sense of Whitney. On top we introduce a new and improved notion of calibrations for the multi-material transport problem: we identify calibrations with (weak) Jacobians of optimizers of the associated convex dual problem, which yields their existence and natural regularity.</description>
      <guid isPermaLink="false">oai:arXiv.org:2407.10158v1</guid>
      <category>math.OC</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Julius Lohmann, Bernhard Schmitzer, Benedikt Wirth</dc:creator>
    </item>
    <item>
      <title>Consensus and Flocking under Communication Failure</title>
      <link>https://arxiv.org/abs/2407.10306</link>
      <description>arXiv:2407.10306v1 Announce Type: new 
Abstract: For networked systems, Persistent Excitation and Integral Scrambling Condition are conditions ensuring that communication failures between agents can occur, but a minimal level of service is ensured. We consider cooperative multi-agent systems satisfying either of such conditions. For first-order systems, we prove that consensus is attained. For second-order systems, flocking is attained under a standard condition of nonintegrability of the interaction function. In both cases and under both conditions, the original goal is reached under no additional hypotheses on the system with respect to the case of no communication failures.</description>
      <guid isPermaLink="false">oai:arXiv.org:2407.10306v1</guid>
      <category>math.OC</category>
      <category>cs.SY</category>
      <category>eess.SY</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Fabio Ancona, Mohamed Bentaibi, Francesco Rossi</dc:creator>
    </item>
    <item>
      <title>A proximal-gradient inertial algorithm with Tikhonov regularization: strong convergence to the minimal norm solution</title>
      <link>https://arxiv.org/abs/2407.10350</link>
      <description>arXiv:2407.10350v1 Announce Type: new 
Abstract: We investigate the strong convergence properties of a proximal-gradient inertial algorithm with two Tikhonov regularization terms in connection to the minimization problem of the sum of a convex lower semi-continuous function $f$ and a smooth convex function $g$. For the appropriate setting of the parameters we provide strong convergence of the generated sequence $(x_k)$ to the minimum norm minimizer of our objective function $f+g$. Further, we obtain fast convergence to zero of the objective function values in a generated sequence but also for the discrete velocity and the sub-gradient of the objective function. We also show that for another settings of the parameters the optimal rate of order $\mathcal{O}(k^{-2})$ for the potential energy $(f+g)(x_k)-\min(f+g)$ can be obtained.</description>
      <guid isPermaLink="false">oai:arXiv.org:2407.10350v1</guid>
      <category>math.OC</category>
      <category>cs.NA</category>
      <category>math.NA</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Szil\'ard Csaba L\'aszl\'o</dc:creator>
    </item>
    <item>
      <title>On pairs of spectrum maximizing products with different numbers of the same name factors</title>
      <link>https://arxiv.org/abs/2407.10513</link>
      <description>arXiv:2407.10513v1 Announce Type: new 
Abstract: Recently, J. Bochi and P. Laskawiec constructed an example of a set of matrices $\{A,B\}$ having two different (up to cyclic permutations of factors) spectrum maximizing products, $AABABB$ and $BBABAA$. In this paper, we identify a class of matrix sets for which the existence of at least one spectrum maximizing product with an odd number of factors automatically entails the existence of another spectrum maximizing product. Moreover, in addition to Bochi--Laskawiec's example, the number of factors of the same name (factors of the form $A$ or $B$) in these matrix products turns out to be different. The efficiency of the proposed approach is confirmed by constructing an example of a set of $2\times2$ matrices $\{A,B\}$ that has spectrum maximizing products of the form $BAA$ and $BBA$.</description>
      <guid isPermaLink="false">oai:arXiv.org:2407.10513v1</guid>
      <category>math.OC</category>
      <category>math.DS</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Victor Kozyakin</dc:creator>
    </item>
    <item>
      <title>Metric extrapolation in the Wasserstein space</title>
      <link>https://arxiv.org/abs/2407.10516</link>
      <description>arXiv:2407.10516v1 Announce Type: new 
Abstract: In this article we study a variational problem providing a way to extend for all times minimizing geodesics connecting two given probability measures, in the Wasserstein space. This is simply obtained by allowing for negative coefficients in the classical variational characterization of Wasserstein barycenters. We show that this problem admits two equivalent convex formulations: the first can be seen as particular instance of Toland duality and the second is a barycentric optimal transport problem. We propose an efficient numerical scheme to solve this latter formulation based on entropic regularization and a variant of Sinkhorn algorithm.</description>
      <guid isPermaLink="false">oai:arXiv.org:2407.10516v1</guid>
      <category>math.OC</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Thomas O. Gallou\"et (PARMA), Andrea Natale (RAPSODI, LPP), Gabriele Todeschi</dc:creator>
    </item>
    <item>
      <title>Port-Hamiltonian Modeling and Control of Electric Vehicle Charging Stations</title>
      <link>https://arxiv.org/abs/2407.10544</link>
      <description>arXiv:2407.10544v1 Announce Type: new 
Abstract: Electric vehicles (EV) are an important part of future sustainable transportation. The increasing integration of EV charging stations (EVCSs) in the existing power grids require new scaleable control algorithms that maintain the stability and resilience of the grid. Here, we present such a control approach using an averaged port-Hamiltonian model. In this approach, the underlying switching behavior of the power converters is approximated by an averaged non-linear system. The averaged models are used to derive various types of stabilizing controllers, including the typically used PI controllers. The pH modeling is showcased by means of a generic setup of an EVCS, where the battery of the vehicle is connected to an AC grid via power lines, converters, and filters. Finally, the control design methods are compared for the averaged pH system and validated using a simulation model of the switched charging station.</description>
      <guid isPermaLink="false">oai:arXiv.org:2407.10544v1</guid>
      <category>math.OC</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Hannes Gernandt, Bernardo Severino, Xinyi Zhang, Volker Mehrmann, Kai Strunz</dc:creator>
    </item>
    <item>
      <title>Multilevel Regularized Newton Methods with Fast Convergence Rates</title>
      <link>https://arxiv.org/abs/2407.10597</link>
      <description>arXiv:2407.10597v1 Announce Type: new 
Abstract: We introduce new multilevel methods for solving large-scale unconstrained optimization problems. Specifically, the philosophy of multilevel methods is applied to Newton-type methods that regularize the Newton sub-problem using second order information from a coarse (low dimensional) sub-problem. The new \emph{regularized multilevel methods} provably converge from any initialization point and enjoy faster convergence rates than Gradient Descent. In particular, for arbitrary functions with Lipschitz continuous Hessians, we show that their convergence rate interpolates between the rate of Gradient Descent and that of the cubic Newton method. If, additionally, the objective function is assumed to be convex, then the proposed method converges with the fast $\mathcal{O}(k^{-2})$ rate. Hence, since the updates are generated using a \emph{coarse} model in low dimensions, the theoretical results of this paper significantly speed-up the convergence of Newton-type or preconditioned gradient methods in practical applications. Preliminary numerical results suggest that the proposed multilevel algorithms are significantly faster than current state-of-the-art methods.</description>
      <guid isPermaLink="false">oai:arXiv.org:2407.10597v1</guid>
      <category>math.OC</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Nick Tsipinakis, Panos Parpas</dc:creator>
    </item>
    <item>
      <title>Probing-Enhanced Stochastic Programming</title>
      <link>https://arxiv.org/abs/2407.10669</link>
      <description>arXiv:2407.10669v1 Announce Type: new 
Abstract: We consider a two-stage stochastic decision problem where the decision-maker has the opportunity to obtain information about the distribution of the random variables $\xi$ that appear in the problem through a set of discrete actions that we refer to as \emph{probing}. Probing components of a random vector $\eta$ that is jointly-distributed with $\xi$ allows the decision-maker to learn about the conditional distribution of $\xi$ given the observed components of $\eta$. We propose a three-stage optimization model for this problem, where in the first stage some components of $\eta$ are chosen to be observed, and decisions in subsequent stages must be consistent with the obtained information. In the case that $\eta$ and $\xi$ have finite support, Goel and Grossmann gave a mixed-integer programming (MIP) formulation of this problem whose size is proportional to the square of cardinality of the sample space of the random variables. We propose to solve the model using bounds obtained from an information-based relaxation, combined with a branching scheme that enforces the consistency of decisions with observed information. The branch-and-bound approach can naturally be combined with sampling in order to estimate both lower and upper bounds on the optimal solution value and does not require $\eta$ or $\xi$ to have finite support. We conduct a computational study of our method on instances of a stochastic facility location and sizing problem with the option to probe customers to learn about their demands before building facilities. We find that on instances with finite support, our approach scales significantly better than the MIP formulation and also demonstrate that our method can compute statistical bounds on instances with continuous distributions that improve upon the perfect information bounds.</description>
      <guid isPermaLink="false">oai:arXiv.org:2407.10669v1</guid>
      <category>math.OC</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Zhichao Ma, Youngdae Kim, Jeff Linderoth, James R. Luedtke, Logan R. Matthews</dc:creator>
    </item>
    <item>
      <title>Generalization Bounds for Contextual Stochastic Optimization using Kernel Regression</title>
      <link>https://arxiv.org/abs/2407.10764</link>
      <description>arXiv:2407.10764v1 Announce Type: new 
Abstract: In this paper, we consider contextual stochastic optimization using Nadaraya-Watson kernel regression, which is one of the most common approaches in nonparametric regression. Recent studies have explored the asymptotic convergence behavior of using Nadaraya-Watson kernel regression in contextual stochastic optimization; however, the performance guarantee under finite samples remains an open question. This paper derives a finite-sample generalization bound of the Nadaraya-Watson estimator with a spherical kernel under a generic loss function. Based on the generalization bound, we further establish a suboptimality bound for the solution of the Nadaraya-Watson approximation problem relative to the optimal solution. Finally, we derive the optimal kernel bandwidth and provide a sample complexity analysis of the Nadaraya-Watson approximation problem.</description>
      <guid isPermaLink="false">oai:arXiv.org:2407.10764v1</guid>
      <category>math.OC</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Yijie Wang, Grani A. Hanasusanto, Chin Pang Ho</dc:creator>
    </item>
    <item>
      <title>Globally-Constrained Decentralized Optimization with Variable Coupling</title>
      <link>https://arxiv.org/abs/2407.10770</link>
      <description>arXiv:2407.10770v1 Announce Type: new 
Abstract: Many realistic decision-making problems in networked scenarios, such as formation control and collaborative task offloading, often involve complicatedly entangled local decisions, which, however, have not been sufficiently investigated yet. Motivated by this, we study a class of decentralized optimization problems with a variable coupling structure that is new to the literature. Specifically, we consider a network of nodes collaborating to minimize a global objective subject to a collection of global inequality and equality constraints, which are formed by the local objective and constraint functions of the nodes. On top of that, we allow such local functions of each node to depend on not only its own decision variable but the decisions of its neighbors as well. To address this problem, we propose a decentralized projected primal-dual algorithm. It first incorporates a virtual-queue technique with a primal-dual-primal scheme, and then linearizes the non-separable objective and constraint functions to enable decentralized implementation. Under mild conditions, we derive $O(1/k)$ convergence rates for both objective error and constraint violations. Finally, two numerical experiments corroborate our theoretical results and illustrate the competitive performance of the proposed algorithm.</description>
      <guid isPermaLink="false">oai:arXiv.org:2407.10770v1</guid>
      <category>math.OC</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Dandan Wang, Xuyang Wu, Zichong Ou, Jie Lu</dc:creator>
    </item>
    <item>
      <title>Private Heterogeneous Federated Learning Without a Trusted Server Revisited: Error-Optimal and Communication-Efficient Algorithms for Convex Losses</title>
      <link>https://arxiv.org/abs/2407.09690</link>
      <description>arXiv:2407.09690v1 Announce Type: cross 
Abstract: We revisit the problem of federated learning (FL) with private data from people who do not trust the server or other silos/clients. In this context, every silo (e.g. hospital) has data from several people (e.g. patients) and needs to protect the privacy of each person's data (e.g. health records), even if the server and/or other silos try to uncover this data. Inter-Silo Record-Level Differential Privacy (ISRL-DP) prevents each silo's data from being leaked, by requiring that silo i's communications satisfy item-level differential privacy. Prior work arXiv:2203.06735 characterized the optimal excess risk bounds for ISRL-DP algorithms with homogeneous (i.i.d.) silo data and convex loss functions. However, two important questions were left open: (1) Can the same excess risk bounds be achieved with heterogeneous (non-i.i.d.) silo data? (2) Can the optimal risk bounds be achieved with fewer communication rounds? In this paper, we give positive answers to both questions. We provide novel ISRL-DP FL algorithms that achieve the optimal excess risk bounds in the presence of heterogeneous silo data. Moreover, our algorithms are more communication-efficient than the prior state-of-the-art. For smooth loss functions, our algorithm achieves the optimal excess risk bound and has communication complexity that matches the non-private lower bound. Additionally, our algorithms are more computationally efficient than the previous state-of-the-art.</description>
      <guid isPermaLink="false">oai:arXiv.org:2407.09690v1</guid>
      <category>cs.LG</category>
      <category>cs.CR</category>
      <category>math.OC</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Changyu Gao, Andrew Lowy, Xingyu Zhou, Stephen J. Wright</dc:creator>
    </item>
    <item>
      <title>Fine-grained Analysis of In-context Linear Estimation: Data, Architecture, and Beyond</title>
      <link>https://arxiv.org/abs/2407.10005</link>
      <description>arXiv:2407.10005v1 Announce Type: cross 
Abstract: Recent research has shown that Transformers with linear attention are capable of in-context learning (ICL) by implementing a linear estimator through gradient descent steps. However, the existing results on the optimization landscape apply under stylized settings where task and feature vectors are assumed to be IID and the attention weights are fully parameterized. In this work, we develop a stronger characterization of the optimization and generalization landscape of ICL through contributions on architectures, low-rank parameterization, and correlated designs: (1) We study the landscape of 1-layer linear attention and 1-layer H3, a state-space model. Under a suitable correlated design assumption, we prove that both implement 1-step preconditioned gradient descent. We show that thanks to its native convolution filters, H3 also has the advantage of implementing sample weighting and outperforming linear attention in suitable settings. (2) By studying correlated designs, we provide new risk bounds for retrieval augmented generation (RAG) and task-feature alignment which reveal how ICL sample complexity benefits from distributional alignment. (3) We derive the optimal risk for low-rank parameterized attention weights in terms of covariance spectrum. Through this, we also shed light on how LoRA can adapt to a new distribution by capturing the shift between task covariances. Experimental results corroborate our theoretical findings. Overall, this work explores the optimization and risk landscape of ICL in practically meaningful settings and contributes to a more thorough understanding of its mechanics.</description>
      <guid isPermaLink="false">oai:arXiv.org:2407.10005v1</guid>
      <category>cs.LG</category>
      <category>cs.AI</category>
      <category>cs.CL</category>
      <category>math.OC</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Yingcong Li, Ankit Singh Rawat, Samet Oymak</dc:creator>
    </item>
    <item>
      <title>Have ASkotch: Fast Methods for Large-scale, Memory-constrained Kernel Ridge Regression</title>
      <link>https://arxiv.org/abs/2407.10070</link>
      <description>arXiv:2407.10070v1 Announce Type: cross 
Abstract: Kernel ridge regression (KRR) is a fundamental computational tool, appearing in problems that range from computational chemistry to health analytics, with a particular interest due to its starring role in Gaussian process regression. However, it is challenging to scale KRR solvers to large datasets: with $n$ training points, a direct solver (i.e., Cholesky decomposition) uses $O(n^2)$ storage and $O(n^3)$ flops. Iterative methods for KRR, such as preconditioned conjugate gradient (PCG), avoid the cubic scaling of direct solvers and often use low-rank preconditioners; a rank $r$ preconditioner uses $O(rn)$ storage and each iteration requires $O(n^2)$ flops. To reduce the storage and iteration complexity of iterative solvers for KRR, we propose ASkotch ($\textbf{A}$ccelerated $\textbf{s}$calable $\textbf{k}$ernel $\textbf{o}$p$\textbf{t}$imization using block $\textbf{c}$oordinate descent with $\textbf{H}$essian preconditioning). For a given block size $|b| &lt;&lt; n$, each iteration of ASkotch uses $O(r|b| + n)$ storage and $O(n|b|)$ flops, so ASkotch scales better than Cholesky decomposition and PCG. We prove that ASkotch obtains linear convergence to the optimum, with the convergence rate depending on the square roots of the $\textit{preconditioned}$ block condition numbers. Furthermore, we solve KRR problems that were considered to be impossibly large while using limited computational resources: we show that ASkotch outperforms PCG methods with respect to generalization error on large-scale KRR (up to $n = 10^8$) and KRR classification tasks (up to $n = 10^7$) while running each of our experiments on $\textit{a single 12 GB Titan V GPU}$. Our work opens up the possibility of as-yet-unimagined applications of KRR across a wide range of disciplines.</description>
      <guid isPermaLink="false">oai:arXiv.org:2407.10070v1</guid>
      <category>cs.LG</category>
      <category>math.OC</category>
      <category>stat.ML</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Pratik Rathore, Zachary Frangella, Madeleine Udell</dc:creator>
    </item>
    <item>
      <title>Communication- and Computation-Efficient Distributed Decision-Making in Multi-Robot Networks</title>
      <link>https://arxiv.org/abs/2407.10382</link>
      <description>arXiv:2407.10382v1 Announce Type: cross 
Abstract: We provide a distributed coordination paradigm that enables scalable and near-optimal joint motion planning among multiple robots. Our coordination paradigm contrasts with current paradigms that are either near-optimal but impractical for replanning times or real-time but offer no near-optimality guarantees. We are motivated by the future of collaborative mobile autonomy, where distributed teams of robots will coordinate via vehicle-to-vehicle (v2v) communication to execute information-heavy tasks like mapping, surveillance, and target tracking. To enable rapid distributed coordination, we must curtail the explosion of information-sharing across the network, thus limiting robot coordination. However, this can lead to suboptimal plans, causing overlapping trajectories instead of complementary ones. We make theoretical and algorithmic contributions to balance the trade-off between decision speed and optimality. We introduce tools for distributed submodular optimization, a diminishing returns property in information-gathering tasks. Theoretically, we analyze how local network topology affects near-optimality at the global level. Algorithmically, we provide a communication- and computation-efficient coordination algorithm for agents to balance the trade-off. Our algorithm is up to two orders faster than competitive near-optimal algorithms. In simulations of surveillance tasks with up to 45 robots, it enables real-time planning at the order of 1 Hz with superior coverage performance. To enable the simulations, we provide a high-fidelity simulator that extends AirSim by integrating a collaborative autonomy pipeline and simulating v2v communication delays.</description>
      <guid isPermaLink="false">oai:arXiv.org:2407.10382v1</guid>
      <category>cs.RO</category>
      <category>cs.AI</category>
      <category>cs.MA</category>
      <category>cs.SY</category>
      <category>eess.SY</category>
      <category>math.OC</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Zirui Xu, Sandilya Sai Garimella, Vasileios Tzoumas</dc:creator>
    </item>
    <item>
      <title>Deflated Dynamics Value Iteration</title>
      <link>https://arxiv.org/abs/2407.10454</link>
      <description>arXiv:2407.10454v1 Announce Type: cross 
Abstract: The Value Iteration (VI) algorithm is an iterative procedure to compute the value function of a Markov decision process, and is the basis of many reinforcement learning (RL) algorithms as well. As the error convergence rate of VI as a function of iteration $k$ is $O(\gamma^k)$, it is slow when the discount factor $\gamma$ is close to $1$. To accelerate the computation of the value function, we propose Deflated Dynamics Value Iteration (DDVI). DDVI uses matrix splitting and matrix deflation techniques to effectively remove (deflate) the top $s$ dominant eigen-structure of the transition matrix $\mathcal{P}^{\pi}$. We prove that this leads to a $\tilde{O}(\gamma^k |\lambda_{s+1}|^k)$ convergence rate, where $\lambda_{s+1}$is $(s+1)$-th largest eigenvalue of the dynamics matrix. We then extend DDVI to the RL setting and present Deflated Dynamics Temporal Difference (DDTD) algorithm. We empirically show the effectiveness of the proposed algorithms.</description>
      <guid isPermaLink="false">oai:arXiv.org:2407.10454v1</guid>
      <category>cs.LG</category>
      <category>math.OC</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Jongmin Lee, Amin Rakhsha, Ernest K. Ryu, Amir-massoud Farahmand</dc:creator>
    </item>
    <item>
      <title>A pragmatic policy learning approach to account for users' fatigue in repeated auctions</title>
      <link>https://arxiv.org/abs/2407.10504</link>
      <description>arXiv:2407.10504v1 Announce Type: cross 
Abstract: Online advertising banners are sold in real-time through auctions.Typically, the more banners a user is shown, the smaller the marginalvalue of the next banner for this user is. This fact can be detected bybasic ML models, that can be used to predict how previously won auctionsdecrease the current opportunity value. However, learning is not enough toproduce a bid that correctly accounts for how winning the current auctionimpacts the future values. Indeed, a policy that uses this prediction tomaximize the expected payoff of the current auction could be dubbedimpatient because such policy does not fully account for the repeatednature of the auctions. Under this perspective, it seems that most biddersin the literature are impatient. Unsurprisingly, impatience induces a cost.We provide two empirical arguments for the importance of this cost ofimpatience. First, an offline counterfactual analysis and, second, a notablebusiness metrics improvement by mitigating the cost of impatience withpolicy learning</description>
      <guid isPermaLink="false">oai:arXiv.org:2407.10504v1</guid>
      <category>cs.GT</category>
      <category>cs.LG</category>
      <category>math.OC</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Benjamin Heymann (FAIRPLAY), R\'emi Chan--Renous-Legoubin, Alexandre Gilotte</dc:creator>
    </item>
    <item>
      <title>ABB theorems: Results and limitations in infinite dimensions</title>
      <link>https://arxiv.org/abs/2407.10509</link>
      <description>arXiv:2407.10509v1 Announce Type: cross 
Abstract: We construct a weakly compact convex subset of $\ell^2$ with nonempty interior that has an isolated maximal element, with respect to the lattice order $\ell _+^2$. Moreover, the maximal point cannot be supported by any strictly positive functional, showing that the Arrow-Barankin-Blackwell theorem fails. This example discloses the pertinence of the assumption that the cone has a bounded base for the validity of the result in infinite dimensions. Under this latter assumption, the equivalence of the notions of strict maximality and maximality is established</description>
      <guid isPermaLink="false">oai:arXiv.org:2407.10509v1</guid>
      <category>math.FA</category>
      <category>math.OC</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Aris Daniilidis (TU Wien), Alberto Carlo (Unicatt), Enrico de Bernardi (Unicatt)</dc:creator>
    </item>
    <item>
      <title>On the small-time bilinear control of a nonlinear heat equation: global approximate controllability and exact controllability to trajectories</title>
      <link>https://arxiv.org/abs/2407.10521</link>
      <description>arXiv:2407.10521v1 Announce Type: cross 
Abstract: In this work we analyse the small-time reachability properties of a nonlinear parabolic equation, by means of a bilinear control, posed on a torus of arbitrary dimension $d$. Under a saturation hypothesis on the control operators, we show the small-time approximate controllability between states sharing the same sign. Moreover, in the one-dimensional case $d=1$, we combine this property with a local exact controllability result, and prove the small-time exact controllability of any positive states towards the ground state of the evolution operator.</description>
      <guid isPermaLink="false">oai:arXiv.org:2407.10521v1</guid>
      <category>math.AP</category>
      <category>math.OC</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Alessandro Duca, Eugenio Pozzoli, Cristina Urbani</dc:creator>
    </item>
    <item>
      <title>NPA Hierarchy for Quantum Isomorphism and Homomorphism Indistinguishability</title>
      <link>https://arxiv.org/abs/2407.10635</link>
      <description>arXiv:2407.10635v1 Announce Type: cross 
Abstract: Man\v{c}inska and Roberson~[FOCS'20] showed that two graphs are quantum isomorphic if and only if they are homomorphism indistinguishable over the class of planar graphs. Atserias et al.~[JCTB'19] proved that quantum isomorphism is undecidable in general. The NPA hierarchy gives a sequence of semidefinite programming relaxations of quantum isomorphism. Recently, Roberson and Seppelt~[ICALP'23] obtained a homomorphism indistinguishability characterization of the feasibility of each level of the Lasserre hierarchy of semidefinite programming relaxations of graph isomorphism. We prove a quantum analogue of this result by showing that each level of the NPA hierarchy of SDP relaxations for quantum isomorphism of graphs is equivalent to homomorphism indistinguishability over an appropriate class of planar graphs. By combining the convergence of the NPA hierarchy with the fact that the union of these graph classes is the set of all planar graphs, we are able to give a new proof of the result of Man\v{c}inska and Roberson~[FOCS'20] that avoids the use of the theory of quantum groups. This homomorphism indistinguishability characterization also allows us to give a randomized polynomial-time algorithm deciding exact feasibility of each fixed level of the NPA hierarchy of SDP relaxations for quantum isomorphism.</description>
      <guid isPermaLink="false">oai:arXiv.org:2407.10635v1</guid>
      <category>quant-ph</category>
      <category>cs.DM</category>
      <category>cs.DS</category>
      <category>math.CO</category>
      <category>math.OC</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Prem Nigam Kar, David E. Roberson, Tim Seppelt, Peter Zeman</dc:creator>
    </item>
    <item>
      <title>Single-cell 3D genome reconstruction in the haploid setting using rigidity theory</title>
      <link>https://arxiv.org/abs/2407.10700</link>
      <description>arXiv:2407.10700v1 Announce Type: cross 
Abstract: This article considers the problem of 3-dimensional genome reconstruction for single-cell data, and the uniqueness of such reconstructions in the setting of haploid organisms. We consider multiple graph models as representations of this problem, and use techniques from graph rigidity theory to determine identifiability. Biologically, our models come from Hi-C data, microscopy data, and combinations thereof. Mathematically, we use unit ball and sphere packing models, as well as models consisting of distance and inequality constraints. In each setting, we describe and/or derive new results on realisability and uniqueness. We then propose a 3D reconstruction method based on semidefinite programming and apply it to synthetic and real data sets using our models.</description>
      <guid isPermaLink="false">oai:arXiv.org:2407.10700v1</guid>
      <category>q-bio.GN</category>
      <category>math.CO</category>
      <category>math.MG</category>
      <category>math.OC</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Sean Dewar, Georg Grasegger, Kaie Kubjas, Fatemeh Mohammadi, Anthony Nixon</dc:creator>
    </item>
    <item>
      <title>Control of Kawahara equation using flat outputs</title>
      <link>https://arxiv.org/abs/2407.10942</link>
      <description>arXiv:2407.10942v1 Announce Type: cross 
Abstract: In this study we focused on the linear Kawahara equation in a bounded domain, employing two boundary controls. The controllability of this system has been previously demonstrated over the past decade using the Hilbert uniqueness method which involves proving an observability inequality, in general, demonstrated via Carleman estimates. Here, we extend this understanding by achieving the exact controllability within a space of analytic functions, employing the flatness approach which is a new approach for higher-order dispersive systems.</description>
      <guid isPermaLink="false">oai:arXiv.org:2407.10942v1</guid>
      <category>math.AP</category>
      <category>math.OC</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/publicdomain/zero/1.0/</dc:rights>
      <dc:creator>Roberto de A. Capistrano-Filho (DMat/UFPE), Jandeilson Santos da Silva (DMat/UFPE)</dc:creator>
    </item>
    <item>
      <title>High Probability Convergence Bounds for Non-convex Stochastic Gradient Descent with Sub-Weibull Noise</title>
      <link>https://arxiv.org/abs/2006.05610</link>
      <description>arXiv:2006.05610v5 Announce Type: replace 
Abstract: Stochastic gradient descent is one of the most common iterative algorithms used in machine learning and its convergence analysis is a rich area of research. Understanding its convergence properties can help inform what modifications of it to use in different settings. However, most theoretical results either assume convexity or only provide convergence results in mean. This paper, on the other hand, proves convergence bounds in high probability without assuming convexity. Assuming strong smoothness, we prove high probability convergence bounds in two settings: (1) assuming the Polyak-{\L}ojasiewicz inequality and norm sub-Gaussian gradient noise and (2) assuming norm sub-Weibull gradient noise. In the second setting, as an intermediate step to proving convergence, we prove a sub-Weibull martingale difference sequence self-normalized concentration inequality of independent interest. It extends Freedman-type concentration beyond the sub-exponential threshold to heavier-tailed martingale difference sequences. We also provide a post-processing method that picks a single iterate with a provable convergence guarantee as opposed to the usual bound for the unknown best iterate. Our convergence result for sub-Weibull noise extends the regime where stochastic gradient descent has equal or better convergence guarantees than stochastic gradient descent with modifications such as clipping, momentum, and normalization.</description>
      <guid isPermaLink="false">oai:arXiv.org:2006.05610v5</guid>
      <category>math.OC</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Liam Madden, Emiliano Dall'Anese, Stephen Becker</dc:creator>
    </item>
    <item>
      <title>Model-Free Nonlinear Feedback Optimization</title>
      <link>https://arxiv.org/abs/2201.02395</link>
      <description>arXiv:2201.02395v3 Announce Type: replace 
Abstract: Feedback optimization is a control paradigm that enables physical systems to autonomously reach efficient operating points. Its central idea is to interconnect optimization iterations in closed-loop with the physical plant. Since iterative gradient-based methods are extensively used to achieve optimality, feedback optimization controllers typically require the knowledge of the steady-state sensitivity of the plant, which may not be easily accessible in some applications. In contrast, in this paper, we develop a model-free feedback controller for efficient steady-state operation of general dynamical systems. The proposed design consists of updating control inputs via gradient estimates constructed from evaluations of the nonconvex objective at the current input and at the measured output. We study the dynamic interconnection of the proposed iterative controller with a stable nonlinear discrete-time plant. For this setup, we characterize the optimality and stability of the closed-loop behavior as functions of the problem dimension, the number of iterations, and the rate of convergence of the physical plant. To handle general constraints that affect multiple inputs, we enhance the controller with Frank-Wolfe-type updates.</description>
      <guid isPermaLink="false">oai:arXiv.org:2201.02395v3</guid>
      <category>math.OC</category>
      <category>cs.SY</category>
      <category>eess.SY</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-sa/4.0/</dc:rights>
      <arxiv:DOI>10.1109/TAC.2023.3341752</arxiv:DOI>
      <dc:creator>Zhiyu He, Saverio Bolognani, Jianping He, Florian D\"orfler, Xinping Guan</dc:creator>
    </item>
    <item>
      <title>Efficient Algorithms for A Class of Stochastic Hidden Convex Optimization and Its Applications in Network Revenue Management</title>
      <link>https://arxiv.org/abs/2205.01774</link>
      <description>arXiv:2205.01774v3 Announce Type: replace 
Abstract: We study a class of stochastic nonconvex optimization in the form of $\min_{x\in\mathcal{X}} F(x):=\mathbb{E}_\xi [f(\phi(x,\xi))]$, i.e., $F$ is a composition of a convex function $f$ and a random function $\phi$. Leveraging an (implicit) convex reformulation via a variable transformation $u=\mathbb{E}[\phi(x,\xi)]$, we develop stochastic gradient-based algorithms and establish their sample and gradient complexities for achieving an $\epsilon$-global optimal solution. Interestingly, our proposed Mirror Stochastic Gradient (MSG) method operates only in the original $x$-space using gradient estimators of the original nonconvex objective $F$ and achieves $\tilde{\mathcal{O}}(\epsilon^{-2})$ complexities, which matches the lower bounds for solving stochastic convex optimization problems. Under booking limits control, we formulate the air-cargo network revenue management (NRM) problem with random two-dimensional capacity, random consumption, and routing flexibility as a special case of the stochastic nonconvex optimization, where the random function $\phi(x,\xi)=x\wedge\xi$, i.e., the random demand $\xi$ truncates the booking limit decision $x$. Extensive numerical experiments demonstrate the superior performance of our proposed MSG algorithm for booking limit control with higher revenue and lower computation cost than state-of-the-art bid-price-based control policies, especially when the variance of random capacity is large.
  KEYWORDS: stochastic nonconvex optimization, hidden convexity, gradient methods, passenger network revenue management, air-cargo network revenue management</description>
      <guid isPermaLink="false">oai:arXiv.org:2205.01774v3</guid>
      <category>math.OC</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <dc:creator>Xin Chen, Niao He, Yifan Hu, Zikun Ye</dc:creator>
    </item>
    <item>
      <title>Region-free explicit model predictive control for linear systems on Hilbert spaces</title>
      <link>https://arxiv.org/abs/2205.02881</link>
      <description>arXiv:2205.02881v3 Announce Type: replace 
Abstract: We extend discrete-time explicit model predictive control (MPC) rigorously to linear distributed parameter systems. After formulating an MPC framework and giving a relevant KKT theorem, we realize fast regionless explicit MPC by using the dual active set method QPKWIK. A Timoshenko beam with input and state constraints is used to demonstrate the efficacy of the design at controlling a continuous-time hyperbolic PDE with constraints, using a discrete-time explicit MPC controller.</description>
      <guid isPermaLink="false">oai:arXiv.org:2205.02881v3</guid>
      <category>math.OC</category>
      <category>cs.SY</category>
      <category>eess.SY</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Mikael Kurula, Jukka-Pekka Humaloja, Stevan Dubljevic</dc:creator>
    </item>
    <item>
      <title>Sample Average Approximation for Stochastic Programming with Equality Constraints</title>
      <link>https://arxiv.org/abs/2206.09963</link>
      <description>arXiv:2206.09963v3 Announce Type: replace 
Abstract: We revisit the sample average approximation (SAA) approach for non-convex stochastic programming. We show that applying the SAA approach to problems with expected value equality constraints does not necessarily result in asymptotic optimality guarantees as the sample size increases. To address this issue, we relax the equality constraints. Then, we prove the asymptotic optimality of the modified SAA approach under mild smoothness and boundedness conditions on the equality constraint functions. Our analysis uses random set theory and concentration inequalities to characterize the approximation error from the sampling procedure. We apply our approach and analysis to the problem of stochastic optimal control for nonlinear dynamical systems under external disturbances modeled by a Wiener process. Numerical results on relevant stochastic programs show the reliability of the proposed approach. Results on a rocket-powered descent problem show that our computed solutions allow for significant uncertainty reduction compared to a deterministic baseline.</description>
      <guid isPermaLink="false">oai:arXiv.org:2206.09963v3</guid>
      <category>math.OC</category>
      <category>cs.SY</category>
      <category>eess.SY</category>
      <category>math.ST</category>
      <category>stat.TH</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Thomas Lew, Riccardo Bonalli, Marco Pavone</dc:creator>
    </item>
    <item>
      <title>Continuous Equality Knapsack with Probit-Style Objectives</title>
      <link>https://arxiv.org/abs/2211.02237</link>
      <description>arXiv:2211.02237v2 Announce Type: replace 
Abstract: We study continuous, equality knapsack problems with uniform separable, non-convex objective functions that are continuous, antisymmetric about a point, and have concave and convex regions. For example, this model captures a simple allocation problem with the goal of optimizing an expected value where the objective is a sum of cumulative distribution functions of identically distributed normal distributions (i.e., a sum of inverse probit functions). We prove structural results of this model under general assumptions and provide two algorithms for efficient optimization: (1) running in linear time and (2) running in a constant number of operations given preprocessing of the objective function.</description>
      <guid isPermaLink="false">oai:arXiv.org:2211.02237v2</guid>
      <category>math.OC</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Jamie Fravel, Robert Hildebrand, Laurel Travis</dc:creator>
    </item>
    <item>
      <title>Twice epi-differentiablity and parabolic regularity of a class of non-amenable functions</title>
      <link>https://arxiv.org/abs/2212.00303</link>
      <description>arXiv:2212.00303v4 Announce Type: replace 
Abstract: This paper concerns the twice epi-differentiability and parabolic regularity of a class of non-amenable functions, the composition of a piecewise twice differentiable (PWTD) function and a parabolically semidifferentiable mapping. Such composite functions often appear in composite optimization problems, disjunctive optimization problems, and low-rank and/or sparsity optimization problems. By establishing the proper twice epi-differentiability and parabolic epi-differentiability of PWTD functions, we prove the parabolic epi-differentiability of this class of composite functions, and its twice epi-differentiability under the parabolic regularity assumption. Then, we identify a condition to ensure its parabolic regularity with the help of an upper and lower estimate of its second subderivative, and demonstrate that this condition holds for several classes of specific non-amenable functions.</description>
      <guid isPermaLink="false">oai:arXiv.org:2212.00303v4</guid>
      <category>math.OC</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Yulan Liu, Shaohua Pan</dc:creator>
    </item>
    <item>
      <title>Collaborative Safety-Critical Control for Dynamically Coupled Networked Systems</title>
      <link>https://arxiv.org/abs/2310.03289</link>
      <description>arXiv:2310.03289v3 Announce Type: replace 
Abstract: As modern systems become ever more connected with complex dynamic coupling relationships, developing safe control methods becomes paramount. In this paper, we discuss the relationship of node-level safety definitions for individual agents with local neighborhood dynamics. We define a collaborative control barrier function (CCBF) and provide conditions under which sets defined by these functions will be forward invariant. We use collaborative node-level control barrier functions to construct a novel \edit{decentralized} algorithm for the safe control of collaborating network agents and provide conditions under which the algorithm is guaranteed to converge to a viable set of safe control actions for all agents. We illustrate these results on a networked susceptible-infected-susceptible (SIS) model.</description>
      <guid isPermaLink="false">oai:arXiv.org:2310.03289v3</guid>
      <category>math.OC</category>
      <category>cs.MA</category>
      <category>cs.SY</category>
      <category>eess.SY</category>
      <category>math.DS</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Brooks A. Butler, Philip E. Par\'e</dc:creator>
    </item>
    <item>
      <title>Compressed Gradient Tracking Algorithms for Distributed Nonconvex Optimization</title>
      <link>https://arxiv.org/abs/2310.18871</link>
      <description>arXiv:2310.18871v2 Announce Type: replace 
Abstract: In this paper, we study the distributed nonconvex optimization problem, which aims to minimize the average value of the local nonconvex cost functions using local information exchange. To reduce the communication overhead, we introduce three general classes of compressors, i.e., compressors with bounded relative compression error, compressors with globally bounded absolute compression error, and compressors with locally bounded absolute compression error. By integrating them with distributed gradient tracking algorithm, we then propose three compressed distributed nonconvex optimization algorithms. For each algorithm, we design a novel Lyapunov function to demonstrate its sublinear convergence to a stationary point if the local cost functions are smooth. Furthermore, when the global cost function satisfies the Polyak--{\L}ojasiewicz (P--{\L}) condition, we show that our proposed algorithms linearly converge to a global optimal point. It is worth noting that, for compressors with bounded relative compression error and globally bounded absolute compression error, our proposed algorithms' parameters do not require prior knowledge of the P--{\L} constant. The theoretical results are illustrated by numerical examples, which demonstrate the effectiveness of the proposed algorithms in significantly reducing the communication burden while maintaining the convergence performance. Moreover, simulation results show that the proposed algorithms outperform state-of-the-art compressed distributed nonconvex optimization algorithms.</description>
      <guid isPermaLink="false">oai:arXiv.org:2310.18871v2</guid>
      <category>math.OC</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Lei Xu, Xinlei Yi, Guanghui Wen, Yang Shi, Karl H. Johansson, Tao Yang</dc:creator>
    </item>
    <item>
      <title>The Anytime Convergence of Stochastic Gradient Descent with Momentum: From a Continuous-Time Perspective</title>
      <link>https://arxiv.org/abs/2310.19598</link>
      <description>arXiv:2310.19598v3 Announce Type: replace 
Abstract: In this paper, we study the stochastic optimization problem from a continuous-time perspective, with a focus on the Stochastic Gradient Descent with Momentum (SGDM) method. We show that the trajectory of SGDM, despite its stochastic nature, converges to a deterministic second-order Ordinary Differential Equation (ODE) in $L_2$-norm, as the stepsize goes to zero. The connection between the ODE and the algorithm results in delightful patterns in the discrete-time convergence analysis. More specifically, we develop convergence results for the ODE through a Lyapunov function, and translate the whole argument to the discrete-time case. This approach yields a novel anytime convergence guarantee for stochastic gradient methods. Precisely, we prove that the sequence $\{ x_k \}$ governed by running SGDM on a smooth convex function $f$ satisfies \begin{align*}
  \mathbb{P}\left(\text{for any $k$},\;f (x_k) - f^* \le C\left(1+\log\frac{1}{\beta}\right)\frac{\log k}{\sqrt{k}}\right)\ge 1-\beta \end{align*} for any $\beta$, where $f^*=\min_{x\in\mathbb{R}^n} f(x)$, and $C$ is a constant. Our contribution is significant in that it better captures the convergence behavior across the entire trajectory of the algorithm, rather than at a single iterate.</description>
      <guid isPermaLink="false">oai:arXiv.org:2310.19598v3</guid>
      <category>math.OC</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Yasong Feng, Yifan Jiang, Tianyu Wang, Zhiliang Ying</dc:creator>
    </item>
    <item>
      <title>Conditional gradients for total variation regularization with PDE constraints: a graph cuts approach</title>
      <link>https://arxiv.org/abs/2310.19777</link>
      <description>arXiv:2310.19777v2 Announce Type: replace 
Abstract: Total variation regularization has proven to be a valuable tool in the context of optimal control of differential equations. This is particularly attributed to the observation that TV-penalties often favor piecewise constant minimizers with well-behaved jumpsets. On the downside, their intricate properties significantly complicate every aspect of their analysis, from the derivation of first-order optimality conditions to their discrete approximation and the choice of a suitable solution algorithm. In this paper, we investigate a general class of minimization problems with TV-regularization, comprising both continuous and discretized control spaces, from a convex geometry perspective. This leads to a variety of novel theoretical insights on minimization problems with total variation regularization as well as tools for their practical realization. First, by studying the extremal points of the respective total variation unit balls, we enable their efficient solution by geometry exploiting algorithms, e.g. fully-corrective generalized conditional gradient methods. We give a detailed account on the practical realization of such a method for piecewise constant finite element approximations of the control on triangulations of the spatial domain. Second, in the same setting and for suitable sequences of uniformly refined meshes, it is shown that minimizers to discretized PDE-constrained optimal control problems approximate solutions to a continuous limit problem involving an anisotropic total variation reflecting the fine-scale geometry of the mesh.</description>
      <guid isPermaLink="false">oai:arXiv.org:2310.19777v2</guid>
      <category>math.OC</category>
      <category>cs.NA</category>
      <category>math.AP</category>
      <category>math.NA</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Giacomo Cristinelli, Jos\'e A. Iglesias, Daniel Walter</dc:creator>
    </item>
    <item>
      <title>Low-rank optimization on Tucker tensor varieties</title>
      <link>https://arxiv.org/abs/2311.18324</link>
      <description>arXiv:2311.18324v2 Announce Type: replace 
Abstract: In the realm of tensor optimization, the low-rank Tucker decomposition is crucial for reducing the number of parameters and for saving storage. We explore the geometry of Tucker tensor varieties -- the set of tensors with bounded Tucker rank -- which is notably more intricate than the well-explored matrix varieties. We give an explicit parametrization of the tangent cone of Tucker tensor varieties and leverage its geometry to develop provable gradient-related line-search methods for optimization on Tucker tensor varieties. To the best of our knowledge, this is the first work concerning geometry and optimization on Tucker tensor varieties. In practice, low-rank tensor optimization suffers from the difficulty of choosing a reliable rank parameter. To this end, we incorporate the established geometry and propose a Tucker rank-adaptive method that aims to identify an appropriate rank with guaranteed convergence. Numerical experiments on tensor completion reveal that the proposed methods are in favor of recovering performance over other state-of-the-art methods. The rank-adaptive method performs the best across various rank parameter selections and is indeed able to find an appropriate rank.</description>
      <guid isPermaLink="false">oai:arXiv.org:2311.18324v2</guid>
      <category>math.OC</category>
      <category>cs.NA</category>
      <category>math.NA</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Bin Gao, Renfeng Peng, Ya-xiang Yuan</dc:creator>
    </item>
    <item>
      <title>Optimal Decentralized Composite Optimization for Convex Functions</title>
      <link>https://arxiv.org/abs/2312.15845</link>
      <description>arXiv:2312.15845v3 Announce Type: replace 
Abstract: In this paper, we focus on the decentralized composite optimization for convex functions. Because of advantages such as robust to the network and no communication bottle-neck in the central server, the decentralized optimization has attracted much research attention in signal processing, control, and optimization communities. Many optimal algorithms have been proposed for the objective function is smooth and (strongly)-convex in the past years. However, it is still an open question whether one can design an optimal algorithm when there is a non-smooth regularization term. In this paper, we fill the gap between smooth decentralized optimization and decentralized composite optimization and propose the first algorithm which can achieve both the optimal computation and communication complexities. Our experiments also validate the effectiveness and efficiency of our algorithm both in computation and communication.</description>
      <guid isPermaLink="false">oai:arXiv.org:2312.15845v3</guid>
      <category>math.OC</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Haishan Ye, Xiangyu Chang</dc:creator>
    </item>
    <item>
      <title>Zeroth-order Random Subspace Algorithm for Non-smooth Convex Optimization</title>
      <link>https://arxiv.org/abs/2401.13944</link>
      <description>arXiv:2401.13944v2 Announce Type: replace 
Abstract: Zeroth-order optimization, which does not use derivative information, is one of the significant research areas in the field of mathematical optimization and machine learning. Although various studies have explored zeroth-order algorithms, one of the theoretical limitations is that oracle complexity depends on the dimension, i.e., on the number of variables, of the optimization problem. In this paper, to reduce the dependency of the dimension in oracle complexity, we propose a zeroth-order random subspace algorithm by combining a gradient-free algorithm (specifically, Gaussian randomized smoothing with central differences) with random projection. We derive the worst-case oracle complexity of our proposed method in non-smooth and convex settings; {\color{black} it is equivalent to standard results for full-dimensional non-smooth convex algorithms. Furthermore,} we prove that ours also has a local convergence rate independent of the original dimension under additional assumptions. In addition to the theoretical results, numerical experiments show that when an objective function has a specific structure, the proposed method can become experimentally more efficient due to random projection.</description>
      <guid isPermaLink="false">oai:arXiv.org:2401.13944v2</guid>
      <category>math.OC</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Ryota Nozawa, Pierre-Louis Poirion, Akiko Takeda</dc:creator>
    </item>
    <item>
      <title>Retractions on closed sets</title>
      <link>https://arxiv.org/abs/2402.08536</link>
      <description>arXiv:2402.08536v2 Announce Type: replace 
Abstract: On a manifold or a closed subset of a Euclidean vector space, a retraction enables to move in the direction of a tangent vector while staying on the set. Retractions are a versatile tool to perform computational tasks such as optimization, interpolation, and numerical integration. This paper studies two known definitions of retraction on a closed subset of a Euclidean vector space, one being weaker than the other. Specifically, it shows that, in the context of constrained optimization, the weaker definition should be preferred as it inherits the main property of the other while being less restrictive.</description>
      <guid isPermaLink="false">oai:arXiv.org:2402.08536v2</guid>
      <category>math.OC</category>
      <category>cs.NA</category>
      <category>math.NA</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Guillaume Olikier</dc:creator>
    </item>
    <item>
      <title>Fundamental Benefit of Alternating Updates in Minimax Optimization</title>
      <link>https://arxiv.org/abs/2402.10475</link>
      <description>arXiv:2402.10475v2 Announce Type: replace 
Abstract: The Gradient Descent-Ascent (GDA) algorithm, designed to solve minimax optimization problems, takes the descent and ascent steps either simultaneously (Sim-GDA) or alternately (Alt-GDA). While Alt-GDA is commonly observed to converge faster, the performance gap between the two is not yet well understood theoretically, especially in terms of global convergence rates. To address this theory-practice gap, we present fine-grained convergence analyses of both algorithms for strongly-convex-strongly-concave and Lipschitz-gradient objectives. Our new iteration complexity upper bound of Alt-GDA is strictly smaller than the lower bound of Sim-GDA; i.e., Alt-GDA is provably faster. Moreover, we propose Alternating-Extrapolation GDA (Alex-GDA), a general algorithmic framework that subsumes Sim-GDA and Alt-GDA, for which the main idea is to alternately take gradients from extrapolations of the iterates. We show that Alex-GDA satisfies a smaller iteration complexity bound, identical to that of the Extra-gradient method, while requiring less gradient computations. We also prove that Alex-GDA enjoys linear convergence for bilinear problems, for which both Sim-GDA and Alt-GDA fail to converge at all.</description>
      <guid isPermaLink="false">oai:arXiv.org:2402.10475v2</guid>
      <category>math.OC</category>
      <category>cs.LG</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Jaewook Lee, Hanseul Cho, Chulhee Yun</dc:creator>
    </item>
    <item>
      <title>Integer Points in Arbitrary Convex Cones: The Case of the PSD and SOC Cones</title>
      <link>https://arxiv.org/abs/2403.09927</link>
      <description>arXiv:2403.09927v2 Announce Type: replace 
Abstract: We investigate the semigroup of integer points inside a convex cone. We extend classical results in integer linear programming to integer conic programming. We show that the semigroup associated with nonpolyhedral cones can sometimes have a notion of finite generating set. We show this is true for the cone of positive semidefinite matrices (PSD) and the second-order cone (SOC). Both cones have a finite generating set of integer points, similar in spirit to Hilbert bases, under the action of a finitely generated group. We also extend notions of total dual integrality, Gomory-Chv\'{a}tal closure, and Carath\'{e}odory rank to integer points in arbitrary cones.</description>
      <guid isPermaLink="false">oai:arXiv.org:2403.09927v2</guid>
      <category>math.OC</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Jes\'us A. De Loera, Brittney Marsters, Luze Xu, Shixuan Zhang</dc:creator>
    </item>
    <item>
      <title>A Globally Convergent Gradient Method with Momentum</title>
      <link>https://arxiv.org/abs/2403.17613</link>
      <description>arXiv:2403.17613v2 Announce Type: replace 
Abstract: In this work, we consider smooth unconstrained optimization problems and we deal with the class of gradient methods with momentum, i.e., descent algorithms where the search direction is defined as a linear combination of the current gradient and the preceding search direction. This family of algorithms includes nonlinear conjugate gradient methods and Polyak's heavy-ball approach, and is thus of high practical and theoretical interest in large-scale nonlinear optimization. We propose a general framework where the scalars of the linear combination defining the search direction are computed simultaneously by minimizing the approximate quadratic model in the 2 dimensional subspace. This strategy allows us to define a class of gradient methods with momentum enjoying global convergence guarantees and an optimal worst-case complexity bound in the nonconvex setting. Differently than all related works in the literature, the convergence conditions are stated in terms of the Hessian matrix of the bi-dimensional quadratic model. To the best of our knowledge, these results are novel to the literature. Moreover, extensive computational experiments show that the gradient methods with momentum here presented outperform classical conjugate gradient methods and are (at least) competitive with the state-of-art method for unconstrained optimization, i.e, L-BFGS method.</description>
      <guid isPermaLink="false">oai:arXiv.org:2403.17613v2</guid>
      <category>math.OC</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Matteo Lapucci, Giampaolo Liuzzi, Stefano Lucidi, Marco Sciandrone</dc:creator>
    </item>
    <item>
      <title>Output Feedback Periodic-Event and Self-Triggered Control of Coupled $2\times 2$ Linear Hyperbolic PDEs</title>
      <link>https://arxiv.org/abs/2404.02298</link>
      <description>arXiv:2404.02298v2 Announce Type: replace 
Abstract: In this paper, we expand recently introduced observer-based periodic event-triggered control (PETC) and self-triggered control (STC) schemes for reaction-diffusion PDEs to boundary control of $2\times2$ coupled hyperbolic PDEs in canonical form and with anti-collocated measurement and actuation processes. The class of problem under study governs transport phenomena arising in water management systems, oil drilling, and traffic flow, to name a few. Relative to the state of the art in observer-based event-triggered control of hyperbolic PDEs, our contribution goes two steps further by proposing observer-based PETC and STC for the considered class of systems. These designs arise from a non-trivial redesign of an existing continuous-time event-triggered control (CETC) scheme. PETC and STC eliminate the need for constant monitoring of an event-triggering function as in CETC; PETC requires only periodic evaluations of the triggering function for event detection, whereas STC is a predictor-feedback that anticipates the next event time at the current event exploiting continuously accessible output measurements. The introduced resource-aware designs act as input holding mechanisms allowing for the update of the input signal only at events. Subject to the designed boundary output feedback PETC and STC control laws characterized by a set of event-trigger design parameters, the resulting closed-loop systems, which are inherently Zeno-free by design, achieve exponential convergence to zero in the spatial $L^2$ norm. We illustrate the feasibility of the approach by applying the control laws to the linearized Saint-Venant model, which describes the dynamics of shallow water waves in a canal and is used to design flow stabilizer feedback laws via gate actuation. The provided simulation results illustrate the proposed theory.</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.02298v2</guid>
      <category>math.OC</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Eranda Somathilake, Bhathiya Rathnayake, Mamadou Diagne</dc:creator>
    </item>
    <item>
      <title>Scalarisation-based risk concepts for robust multi-objective optimisation</title>
      <link>https://arxiv.org/abs/2405.10221</link>
      <description>arXiv:2405.10221v2 Announce Type: replace 
Abstract: Robust optimisation is a well-established framework for optimising functions in the presence of uncertainty. The inherent goal of this problem is to identify a collection of inputs whose outputs are both desirable for the decision maker, whilst also being robust to the underlying uncertainties in the problem. In this work, we study the multi-objective case of this problem. We identify that the majority of all robust multi-objective algorithms rely on two key operations: robustification and scalarisation. Robustification refers to the strategy that is used to account for the uncertainty in the problem. Scalarisation refers to the procedure that is used to encode the relative importance of each objective to a scalar-valued reward. As these operations are not necessarily commutative, the order that they are performed in has an impact on the resulting solutions that are identified and the final decisions that are made. The purpose of this work is to give a thorough exposition on the effects of these different orderings and in particular highlight when one should opt for one ordering over the other. As part of our analysis, we showcase how many existing risk concepts can be integrated into the specification and solution of a robust multi-objective optimisation problem. Besides this, we also demonstrate how one can principally define the notion of a robust Pareto front and a robust performance metric based on our ``robustify and scalarise'' methodology. To illustrate the efficacy of these new ideas, we present two insightful case studies which are based on real-world data sets.</description>
      <guid isPermaLink="false">oai:arXiv.org:2405.10221v2</guid>
      <category>math.OC</category>
      <category>cs.LG</category>
      <category>stat.ML</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Ben Tu, Nikolas Kantas, Robert M. Lee, Behrang Shafei</dc:creator>
    </item>
    <item>
      <title>The Role of Level-Set Geometry on the Performance of PDHG for Conic Linear Optimization</title>
      <link>https://arxiv.org/abs/2406.01942</link>
      <description>arXiv:2406.01942v3 Announce Type: replace 
Abstract: We consider solving huge-scale instances of (convex) conic linear optimization problems, at the scale where matrix-factorization-free methods are attractive or necessary. The restarted primal-dual hybrid gradient method (rPDHG) -- with heuristic enhancements and GPU implementation -- has been very successful in solving huge-scale linear programming (LP) problems; however its application to more general conic convex optimization problems is not so well-studied. We analyze the theoretical and practical performance of rPDHG for general (convex) conic linear optimization, and LP as a special case thereof. We show a relationship between the geometry of the primal-dual (sub-)level sets $W_\varepsilon$ and the convergence rate of rPDHG. Specifically, we prove a bound on the convergence rate of rPDHG that improves when there is a primal-dual (sub-)level set $W_\varepsilon$ for which (i) $W_\varepsilon$ is close to the optimal solution set (in Hausdorff distance), and (ii) the ratio of the diameter to the "conic radius" of $W_\varepsilon$ is small. And in the special case of LP problems, the performance of rPDHG is bounded only by this ratio applied to the (sub-)level set corresponding to the best non-optimal extreme point. Depending on the problem instance, this ratio can take on extreme values and can result in poor performance of rPDHG both in theory and in practice. To address this issue, we show how central-path-based linear transformations -- including conic rescaling -- can markedly enhance the convergence rate of rPDHG. Furthermore, we present computational results that demonstrate how such rescalings can accelerate convergence to high-accuracy solutions, and lead to more efficient methods for huge-scale linear optimization problems.</description>
      <guid isPermaLink="false">oai:arXiv.org:2406.01942v3</guid>
      <category>math.OC</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Zikai Xiong, Robert M. Freund</dc:creator>
    </item>
    <item>
      <title>Using Stochastic Gradient Descent to Smooth Nonconvex Functions: Analysis of Implicit Graduated Optimization with Optimal Noise Scheduling</title>
      <link>https://arxiv.org/abs/2311.08745</link>
      <description>arXiv:2311.08745v4 Announce Type: replace-cross 
Abstract: The graduated optimization approach is a heuristic method for finding globally optimal solutions for nonconvex functions and has been theoretically analyzed in several studies. This paper defines a new family of nonconvex functions for graduated optimization, discusses their sufficient conditions, and provides a convergence analysis of the graduated optimization algorithm for them. It shows that stochastic gradient descent (SGD) with mini-batch stochastic gradients has the effect of smoothing the objective function, the degree of which is determined by the learning rate, batch size, and variance of the stochastic gradient. This finding provides theoretical insights on why large batch sizes fall into sharp local minima, why decaying learning rates and increasing batch sizes are superior to fixed learning rates and batch sizes, and what the optimal learning rate scheduling is. To the best of our knowledge, this is the first paper to provide a theoretical explanation for these aspects. In addition, we show that the degree of smoothing introduced is strongly correlated with the generalization performance of the model. Moreover, a new graduated optimization framework that uses a decaying learning rate and increasing batch size is analyzed and experimental results of image classification are reported that support our theoretical findings.</description>
      <guid isPermaLink="false">oai:arXiv.org:2311.08745v4</guid>
      <category>cs.LG</category>
      <category>math.OC</category>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Naoki Sato, Hideaki Iiduka</dc:creator>
    </item>
    <item>
      <title>Estimation Sample Complexity of a Class of Nonlinear Continuous-time Systems</title>
      <link>https://arxiv.org/abs/2312.05382</link>
      <description>arXiv:2312.05382v3 Announce Type: replace-cross 
Abstract: We present a method of parameter estimation for large class of nonlinear systems, namely those in which the state consists of output derivatives and the flow is linear in the parameter. The method, which solves for the unknown parameter by directly inverting the dynamics using regularized linear regression, is based on new design and analysis ideas for differentiation filtering and regularized least squares. Combined in series, they yield a novel finite-sample bound on mean absolute error of estimation.</description>
      <guid isPermaLink="false">oai:arXiv.org:2312.05382v3</guid>
      <category>eess.SY</category>
      <category>cs.SY</category>
      <category>math.OC</category>
      <category>stat.ML</category>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Simon Kuang, Xinfan Lin</dc:creator>
    </item>
    <item>
      <title>Optimal Investment with Herd Behaviour Using Rational Decision Decomposition</title>
      <link>https://arxiv.org/abs/2401.07183</link>
      <description>arXiv:2401.07183v2 Announce Type: replace-cross 
Abstract: In this paper, we study the optimal investment problem considering the herd behaviour between two agents, including one leading expert and one following agent whose decisions are influenced by those of the leading expert. In the objective functional of the optimal investment problem, we introduce the average deviation term to measure the distance between the two agents' decisions and use the variational method to find its analytical solution. To theoretically analyze the impact of the following agent's herd behaviour on his/her decision, we decompose his/her optimal decision into a convex linear combination of the two agents' rational decisions, which we call the rational decision decomposition. Furthermore, we define the weight function in the rational decision decomposition as the following agent's investment opinion to measure the preference of his/her own rational decision over that of the leading expert. We use the investment opinion to quantitatively analyze the impact of the herd behaviour, the following agent's initial wealth, the excess return, and the volatility of the risky asset on the optimal decision. We validate our analyses through numerical experiments on real stock data. This study is crucial to understanding investors' herd behaviour in decision-making and designing effective mechanisms to guide their decisions.</description>
      <guid isPermaLink="false">oai:arXiv.org:2401.07183v2</guid>
      <category>eess.SY</category>
      <category>cs.SY</category>
      <category>math.OC</category>
      <category>q-fin.MF</category>
      <category>q-fin.PM</category>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Huisheng Wang, H. Vicky Zhao</dc:creator>
    </item>
    <item>
      <title>Approximation of sea surface velocity field by fitting surrogate two-dimensional flow to scattered measurements</title>
      <link>https://arxiv.org/abs/2401.12746</link>
      <description>arXiv:2401.12746v4 Announce Type: replace-cross 
Abstract: In this paper, a rapid approximation method is introduced to estimate the sea surface velocity field based on scattered measurements. The method uses a simplified two-dimensional flow model as a surrogate model, which mimics the real submesoscale flow. The proposed approach treats the interpolation of the flow velocities as an optimization problem, aiming to fit the flow model to the scattered measurements. To ensure consistency between the simulated velocity field and the measured values, the boundary conditions in the numerical simulations are adjusted during the optimization process. Additionally, the relevance of quantity and quality of the scattered measurements is assessed, emphasizing the importance of the measurement locations within the domain as well as explaining how these measurements contribute to the accuracy and reliability of the sea surface velocity field approximation. The proposed methodology has been successfully tested in both synthetic and real-world scenarios, leveraging measurements obtained from Global Positioning System (GPS) drifters and high-frequency (HF) radar systems. The adaptability of this approach for different domains, measurement types, and conditions implies that it is suitable for real-world submesoscale scenarios where only an approximation of the sea surface velocity field is sufficient.</description>
      <guid isPermaLink="false">oai:arXiv.org:2401.12746v4</guid>
      <category>physics.flu-dyn</category>
      <category>math.OC</category>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Karlo Jakac, Luka Lan\v{c}a, Ante Sikirica, Stefan Ivi\'c</dc:creator>
    </item>
    <item>
      <title>Group Projected Subspace Pursuit for Block Sparse Signal Reconstruction: Convergence Analysis and Applications</title>
      <link>https://arxiv.org/abs/2407.07707</link>
      <description>arXiv:2407.07707v2 Announce Type: replace-cross 
Abstract: In this paper, we present a convergence analysis of the Group Projected Subspace Pursuit (GPSP) algorithm proposed by He et al. [HKL+23] (Group Projected subspace pursuit for IDENTification of variable coefficient differential equations (GP-IDENT), Journal of Computational Physics, 494, 112526) and extend its application to general tasks of block sparse signal recovery. We prove that when the sampling matrix satisfies the Block Restricted Isometry Property (BRIP) with a sufficiently small Block Restricted Isometry Constant (BRIC), GPSP exactly recovers the true block sparse signals. When the observations are noisy, this convergence property of GPSP remains valid if the magnitude of true signal is sufficiently large. GPSP selects the features by subspace projection criterion (SPC) for candidate inclusion and response magnitude criterion (RMC) for candidate exclusion. We compare these criteria with counterparts of other state-of-the-art greedy algorithms. Our theoretical analysis and numerical ablation studies reveal that SPC is critical to the superior performances of GPSP, and that RMC can enhance the robustness of feature identification when observations contain noises. We test and compare GPSP with other methods in diverse settings, including heterogeneous random block matrices, inexact observations, face recognition, and PDE identification. We find that GPSP outperforms the other algorithms in most cases for various levels of block sparsity and block sizes, justifying its effectiveness for general applications.</description>
      <guid isPermaLink="false">oai:arXiv.org:2407.07707v2</guid>
      <category>cs.IT</category>
      <category>math.IT</category>
      <category>math.OC</category>
      <category>stat.ML</category>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Roy Y. He, Haixia Liu, Hao Liu</dc:creator>
    </item>
  </channel>
</rss>
