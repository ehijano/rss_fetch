<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>cs.IT updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/cs.IT</link>
    <description>cs.IT updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/cs.IT" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Fri, 15 Mar 2024 04:00:51 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Fri, 15 Mar 2024 00:00:00 -0400</pubDate>
    <skipDays>
      <day>Sunday</day>
      <day>Saturday</day>
    </skipDays>
    <item>
      <title>Properties of Shannon and R\'{e}nyi entropies of the Poisson distribution as the functions of intensity parameter</title>
      <link>https://arxiv.org/abs/2403.08805</link>
      <description>arXiv:2403.08805v1 Announce Type: new 
Abstract: We consider two types of entropy, namely, Shannon and R\'{e}nyi entropies of the Poisson distribution, and establish their properties as the functions of intensity parameter. More precisely, we prove that both entropies increase with intensity. While for Shannon entropy the proof is comparatively simple, for R\'{e}nyi entropy, which depends on additional parameter $\alpha&gt;0$, we can characterize it as nontrivial. The proof is based on application of Karamata's inequality to the terms of Poisson distribution.</description>
      <guid isPermaLink="false">oai:arXiv.org:2403.08805v1</guid>
      <category>cs.IT</category>
      <category>math.IT</category>
      <category>math.PR</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Volodymyr Braiman, Anatoliy Malyarenko, Yuliya Mishura, Yevheniia Anastasiia Rudyk</dc:creator>
    </item>
    <item>
      <title>Handoffs in User-Centric Cell-Free MIMO Networks: A POMDP Framework</title>
      <link>https://arxiv.org/abs/2403.08900</link>
      <description>arXiv:2403.08900v1 Announce Type: new 
Abstract: We study the problem of managing handoffs (HOs) in user-centric cell-free massive MIMO (UC-mMIMO) networks. Motivated by the importance of controlling the number of HOs and by the correlation between efficient HO decisions and the temporal evolution of the channel conditions, we formulate a partially observable Markov decision process (POMDP) with the state space representing the discrete versions of the large-scale fading and the action space representing the association decisions of the user with the access points (APs). We develop a novel algorithm that employs this model to derive a HO policy for a mobile user based on current and future rewards. To alleviate the high complexity of our POMDP, we follow a divide-and-conquer approach by breaking down the POMDP formulation into sub-problems, each solved separately. Then, the policy and the candidate pool of APs for the sub-problem that produced the best total expected reward are used to perform HOs within a specific time horizon. We then introduce modifications to our algorithm to decrease the number of HOs. The results show that half of the number of HOs in the UC-mMIMO networks can be eliminated. Namely, our novel solution can control the number of HOs while maintaining a rate guarantee, where a 47%-70% reduction of the cumulative number of HOs is observed in networks with a density of 125 APs per km2. Most importantly, our results show that a POMDP-based HO scheme is promising to control HOs.</description>
      <guid isPermaLink="false">oai:arXiv.org:2403.08900v1</guid>
      <category>cs.IT</category>
      <category>cs.DC</category>
      <category>cs.NI</category>
      <category>cs.SY</category>
      <category>eess.SP</category>
      <category>eess.SY</category>
      <category>math.IT</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Hussein A. Ammar, Raviraj Adve, Shahram Shahbazpanahi, Gary Boudreau, Kothapalli Venkata Srinivas</dc:creator>
    </item>
    <item>
      <title>Electrochemical Communication in Bacterial Biofilms: A Study on Potassium Stimulation and Signal Transmission</title>
      <link>https://arxiv.org/abs/2403.08926</link>
      <description>arXiv:2403.08926v1 Announce Type: new 
Abstract: Electrochemical communication is a mechanism that enables intercellular interaction among bacteria within communities. Bacteria achieves synchronization and coordinates collective actions at the population level through the utilization of electrochemical signals. In this work, we investigate the response of bacterial biofilms to artificial potassium concentration stimulation. We introduce signal inputs at a specific location within the biofilm and observe their transmission to other regions, facilitated by intermediary cells that amplify and relay the signal. We analyze the output signals when biofilm regions are subjected to different input signal types and explore their impact on biofilm growth. Furthermore, we investigate how the temporal gap between input pulses influences output signal characteristics, demonstrating that an appropriate gap yields distinct and well-defined output signals. Our research sheds light on the potential of bacterial biofilms as communication nodes in electrochemical communication networks.</description>
      <guid isPermaLink="false">oai:arXiv.org:2403.08926v1</guid>
      <category>cs.IT</category>
      <category>math.IT</category>
      <category>physics.bio-ph</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Nithin V. Sabu, Bige Deniz Unluturk</dc:creator>
    </item>
    <item>
      <title>Maximum Channel Coding Rate of Finite Block Length MIMO Faster-Than-Nyquist Signaling</title>
      <link>https://arxiv.org/abs/2403.08989</link>
      <description>arXiv:2403.08989v1 Announce Type: new 
Abstract: The pursuit of higher data rates and efficient spectrum utilization in modern communication technologies necessitates novel solutions. In order to provide insights into improving spectral efficiency and reducing latency, this study investigates the maximum channel coding rate (MCCR) of finite block length (FBL) multiple-input multiple-output (MIMO) faster-than-Nyquist (FTN) channels. By optimizing power allocation, we derive the system's MCCR expression. Simulation results are compared with the existing literature to reveal the benefits of FTN in FBL transmission.</description>
      <guid isPermaLink="false">oai:arXiv.org:2403.08989v1</guid>
      <category>cs.IT</category>
      <category>eess.SP</category>
      <category>math.IT</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Zichao Zhang, Melda Yuksel, Halim Yanikomeroglu, Benjamin K. Ng, Chan-Tong Lam</dc:creator>
    </item>
    <item>
      <title>Meta-Learning-Based Fronthaul Compression for Cloud Radio Access Networks</title>
      <link>https://arxiv.org/abs/2403.09004</link>
      <description>arXiv:2403.09004v1 Announce Type: new 
Abstract: This paper investigates the fronthaul compression problem in a user-centric cloud radio access network, in which single-antenna users are served by a central processor (CP) cooperatively via a cluster of remote radio heads (RRHs). To satisfy the fronthaul capacity constraint, this paper proposes a transform-compress-forward scheme, which consists of well-designed transformation matrices and uniform quantizers. The transformation matrices perform dimension reduction in the uplink and dimension expansion in the downlink. To reduce the communication overhead for designing the transformation matrices, this paper further proposes a deep learning framework to first learn a suboptimal transformation matrix at each RRH based on the local channel state information (CSI), and then to refine it iteratively. To facilitate the refinement process, we propose an efficient signaling scheme that only requires the transmission of low-dimensional effective CSI and its gradient between the CP and RRH, and further, a meta-learning based gated recurrent unit network to reduce the number of signaling transmission rounds. For the sum-rate maximization problem, simulation results show that the proposed two-stage neural network can perform close to the fully cooperative global CSI based benchmark with significantly reduced communication overhead for both the uplink and the downlink. Moreover, using the first stage alone can already outperform the existing local CSI based benchmark.</description>
      <guid isPermaLink="false">oai:arXiv.org:2403.09004v1</guid>
      <category>cs.IT</category>
      <category>eess.SP</category>
      <category>math.IT</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Ruihua Qiao, Tao Jiang, Wei Yu</dc:creator>
    </item>
    <item>
      <title>Smart Resource Allocation at mmWave/THz Frequencies with Cooperative Rate-Splitting</title>
      <link>https://arxiv.org/abs/2403.09022</link>
      <description>arXiv:2403.09022v1 Announce Type: new 
Abstract: In this paper, we propose algorithms to minimize the energy consumption in millimeter wave/terahertz multi-user downlink communication systems. To ensure coverage in blockage-vulnerable high frequency systems, we consider cooperative rate-splitting (CRS) and transmission over multiple time blocks, where via CRS, multiple users cooperate to assist a blocked user. Moreover, we show that transmission over multiple time blocks provides benefits through smart resource allocation. We first propose a communication framework named improved distinct extraction-based CRS (iDeCRS) that utilizes the benefits of rate-splitting. With our transmission framework, we derive a performance benchmark assuming genie channel state information (CSI), i.e., the channels of the present and future time blocks are known, denoted as GENIE. Using the results from GENIE, we derive a novel efficiency constrained optimization (ECO) algorithm assuming instantaneous CSI. In addition, a simple but effective even data transmission (EDT) algorithm that promotes steady transmission along the time blocks is proposed. Simulation results show that ECO and EDT have satisfactory performances compared to GENIE. The results also show that ECO outperforms EDT when many users are cooperating, and vise versa.</description>
      <guid isPermaLink="false">oai:arXiv.org:2403.09022v1</guid>
      <category>cs.IT</category>
      <category>eess.SP</category>
      <category>math.IT</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Hyesang Cho, Junil Choi</dc:creator>
    </item>
    <item>
      <title>Performance Analysis on RIS-Aided Wideband Massive MIMO OFDM Systems with Low-Resolution ADCs</title>
      <link>https://arxiv.org/abs/2403.09058</link>
      <description>arXiv:2403.09058v1 Announce Type: new 
Abstract: This paper investigates a reconfigurable intelligent surface (RIS)-aided wideband massive multiple-input multiple-output (MIMO) orthogonal frequency division multiplexing (OFDM) system with low-resolution analog-to-digital converters (ADCs). Frequency-selective Rician fading channels are considered, and the OFDM data transmission process is presented in time domain. This paper derives the closed-form approximate expression of the uplink achievable rate, based on which the asymptotic system performance is analyzed when the number of the antennas at the base station and the number of reflecting elements at the RIS grow to infinity. Besides, the power scaling laws of the considered system are revealed to provide energy-saving insights. Furthermore, this paper proposes a gradient ascent-based algorithm to design the phase shifts of the RIS for maximizing the minimum user rate. Finally, numerical results are presented to verify the correctness of analytical conclusions and draw insights.</description>
      <guid isPermaLink="false">oai:arXiv.org:2403.09058v1</guid>
      <category>cs.IT</category>
      <category>eess.SP</category>
      <category>math.IT</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Xianzhe Chen, Hong Ren, Cunhua Pan, Zhangjie Peng, Kangda Zhi, Yong Liu, Xiaojun Xi, Ana Garcia Armada, Cheng-Xiang Wang</dc:creator>
    </item>
    <item>
      <title>Reverse em-problem based on Bregman divergence and its application to classical and quantum information theory</title>
      <link>https://arxiv.org/abs/2403.09252</link>
      <description>arXiv:2403.09252v1 Announce Type: new 
Abstract: The recent paper (IEEE Trans. IT 69, 1680) introduced an analytical method for calculating the channel capacity without the need for iteration. This method has certain limitations that restrict its applicability. Furthermore, the paper does not provide an explanation as to why the channel capacity can be solved analytically in this particular case. In order to broaden the scope of this method and address its limitations, we turn our attention to the reverse em-problem, proposed by Toyota (Information Geometry, 3, 1355 (2020)). This reverse em-problem involves iteratively applying the inverse map of the em iteration to calculate the channel capacity, which represents the maximum mutual information. However, several open problems remained unresolved in Toyota's work. To overcome these challenges, we formulate the reverse em-problem based on Bregman divergence and provide solutions to these open problems. Building upon these results, we transform the reverse em-problem into em-problems and derive a non-iterative formula for the reverse em-problem. This formula can be viewed as a generalization of the aforementioned analytical calculation method. Importantly, this derivation sheds light on the information geometrical structure underlying this special case. By effectively addressing the limitations of the previous analytical method and providing a deeper understanding of the underlying information geometrical structure, our work significantly expands the applicability of the proposed method for calculating the channel capacity without iteration.</description>
      <guid isPermaLink="false">oai:arXiv.org:2403.09252v1</guid>
      <category>cs.IT</category>
      <category>math.IT</category>
      <category>math.OC</category>
      <category>quant-ph</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Masahito Hayashi</dc:creator>
    </item>
    <item>
      <title>A Deep Reinforcement Learning Approach for Autonomous Reconfigurable Intelligent Surfaces</title>
      <link>https://arxiv.org/abs/2403.09270</link>
      <description>arXiv:2403.09270v1 Announce Type: new 
Abstract: A reconfigurable intelligent surface (RIS) is a prospective wireless technology that enhances wireless channel quality. An RIS is often equipped with passive array of elements and provides cost and power-efficient solutions for coverage extension of wireless communication systems. Without any radio frequency (RF) chains or computing resources, however, the RIS requires control information to be sent to it from an external unit, e.g., a base station (BS). The control information can be delivered by wired or wireless channels, and the BS must be aware of the RIS and the RIS-related channel conditions in order to effectively configure its behavior. Recent works have introduced hybrid RIS structures possessing a few active elements that can sense and digitally process received data. Here, we propose the operation of an entirely autonomous RIS that operates without a control link between the RIS and BS. Using a few sensing elements, the autonomous RIS employs a deep Q network (DQN) based on reinforcement learning in order to enhance the sum rate of the network. Our results illustrate the potential of deploying autonomous RISs in wireless networks with essentially no network overhead.</description>
      <guid isPermaLink="false">oai:arXiv.org:2403.09270v1</guid>
      <category>cs.IT</category>
      <category>eess.SP</category>
      <category>math.IT</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Hyuckjin Choi, Ly V. Nguyen, Junil Choi, A. Lee Swindlehurst</dc:creator>
    </item>
    <item>
      <title>Static Grouping Strategy Design for Beyond Diagonal Reconfigurable Intelligent Surfaces</title>
      <link>https://arxiv.org/abs/2403.09275</link>
      <description>arXiv:2403.09275v1 Announce Type: new 
Abstract: Beyond diagonal reconfigurable intelligent surface (BD-RIS) extends conventional RIS through novel architectures, such as group-connected RIS, with scattering matrix not restricted to being diagonal. However, it remains unexplored how to optimally group the elements in group-connected RISs to maximize the performance while maintaining a low-complexity circuit. In this study, we propose and model BD-RIS with a static grouping strategy optimized based on the channel statistics. After formulating the corresponding problems, we design the grouping in single- and multi-user systems. Numerical results reveal the benefits of grouping optimization, i.e., up to 60% sum rate improvement, especially in highly correlated channels.</description>
      <guid isPermaLink="false">oai:arXiv.org:2403.09275v1</guid>
      <category>cs.IT</category>
      <category>eess.SP</category>
      <category>math.IT</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Matteo Nerini, Shanpu Shen, Bruno Clerckx</dc:creator>
    </item>
    <item>
      <title>Joint Port Selection and Beamforming Design for Fluid Antenna Assisted Integrated Data and Energy Transfer</title>
      <link>https://arxiv.org/abs/2403.09357</link>
      <description>arXiv:2403.09357v1 Announce Type: new 
Abstract: Integrated data and energy transfer (IDET) has been of fundamental importance for providing both wireless data transfer (WDT) and wireless energy transfer (WET) services towards low-power devices. Fluid antenna (FA) is capable of exploiting the huge spatial diversity of the wireless channel to enhance the receive signal strength, which is more suitable for the tiny-size low-power devices having the IDET requirements. In this letter, a multiuser FA assisted IDET system is studied and the weighted energy harvesting power at energy receivers (ERs) is maximized by jointly optimizing the port selection and transmit beamforming design under imperfect channel state information (CSI), while the signal-to-interference-plus-noise ratio (SINR) constraint for each data receiver (DR) is satisfied. An efficient algorithm is proposed to obtain the suboptimal solutions for the non-convex problem. Simulation results evaluate the performance of the FA-IDET system, while also demonstrate that FA outperforms the multi-input-multi-output (MIMO) counterpart in terms of the IDET performance, as long as the port number is large enough.</description>
      <guid isPermaLink="false">oai:arXiv.org:2403.09357v1</guid>
      <category>cs.IT</category>
      <category>eess.SP</category>
      <category>math.IT</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Long Zhang, Halvin Yang, Yizhe Zhao, Jie Hu</dc:creator>
    </item>
    <item>
      <title>Localization in Digital Twin MIMO Networks: A Case for Massive Fingerprinting</title>
      <link>https://arxiv.org/abs/2403.09614</link>
      <description>arXiv:2403.09614v1 Announce Type: new 
Abstract: Localization in outdoor wireless systems typically requires transmitting specific reference signals to estimate distance (trilateration methods) or angle (triangulation methods). These cause overhead on communication, need a LoS link to work well, and require multiple base stations, often imposing synchronization or specific hardware requirements. Fingerprinting has none of these drawbacks, but building its database requires high human effort to collect real-world measurements. For a long time, this issue limited the size of databases and thus their performance. This work proposes significantly reducing human effort in building fingerprinting databases by populating them with \textit{digital twin RF maps}. These RF maps are built from ray-tracing simulations on a digital replica of the environment across several frequency bands and beamforming configurations. Online user fingerprints are then matched against this spatial database. The approach was evaluated with practical simulations using realistic propagation models and user measurements. Our experiments show sub-meter localization errors on a NLoS location 95\% of the time using sensible user measurement report sizes. Results highlight the promising potential of the proposed digital twin approach for ubiquitous wide-area 6G localization.</description>
      <guid isPermaLink="false">oai:arXiv.org:2403.09614v1</guid>
      <category>cs.IT</category>
      <category>eess.SP</category>
      <category>math.IT</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <dc:creator>Jo\~ao Morais, Ahmed Alkhateeb</dc:creator>
    </item>
    <item>
      <title>Comparison of edge computing methods in Internet of Things architectures for efficient estimation of indoor environmental parameters with Machine Learning</title>
      <link>https://arxiv.org/abs/2403.08810</link>
      <description>arXiv:2403.08810v1 Announce Type: cross 
Abstract: The large increase in the number of Internet of Things (IoT) devices have revolutionised the way data is processed, which added to the current trend from cloud to edge computing has resulted in the need for efficient and reliable data processing near the data sources using energy-efficient devices. Two methods based on low-cost edge-IoT architectures are proposed to implement lightweight Machine Learning (ML) models that estimate indoor environmental quality (IEQ) parameters, such as Artificial Neural Networks of Multilayer Perceptron type. Their implementation is based on centralised and distributed parallel IoT architectures, connected via wireless, which share commercial off-the-self modules for data acquisition and sensing, such as sensors for temperature, humidity, illuminance, CO2, and other gases. The centralised method uses a Graphics Processing Unit and the Message Queuing Telemetry Transport protocol, but the distributed method utilises low performance ARM-based devices and the Message Passing Interface protocol. Although multiple IEQ parameters are measured, the training and testing of ML models is accomplished with experiments focused on small temperature and illuminance datasets to reduce data processing load, obtained from sudden spikes, square profiles and sawteeth test cases. The results show a high estimation performance with F-score and Accuracy values close to 0.95, and an almost theorical Speedup with a reduction in power consumption close to 37% in the distributed parallel approach. In addition, similar or slightly better performance is achieved compared to equivalent IoT architectures from related research, but error reduction of 35 to 76% is accomplished with an adequate balance between performance and energy efficiency.</description>
      <guid isPermaLink="false">oai:arXiv.org:2403.08810v1</guid>
      <category>cs.NI</category>
      <category>cs.AI</category>
      <category>cs.AR</category>
      <category>cs.DC</category>
      <category>cs.IT</category>
      <category>cs.LG</category>
      <category>math.IT</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <arxiv:DOI>10.1016/j.engappai.2023.107149</arxiv:DOI>
      <arxiv:journal_reference>Engineering Applications of Artificial Intelligence, 2023, vol. 126, Part D, no. 107149, pp. 1-27, ISSN 0952-1976</arxiv:journal_reference>
      <dc:creator>Jose-Carlos Gamazo-Real, Raul Torres Fernandez, Adrian Murillo Armas</dc:creator>
    </item>
    <item>
      <title>From "um" to "yeah": Producing, predicting, and regulating information flow in human conversation</title>
      <link>https://arxiv.org/abs/2403.08890</link>
      <description>arXiv:2403.08890v1 Announce Type: cross 
Abstract: Conversation demands attention. Speakers must call words to mind, listeners must make sense of them, and both together must negotiate this flow of information, all in fractions of a second. We used large language models to study how this works in a large-scale dataset of English-language conversation, the CANDOR corpus. We provide a new estimate of the information density of unstructured conversation, of approximately 13 bits/second, and find significant effects associated with the cognitive load of both retrieving, and presenting, that information. We also reveal a role for backchannels -- the brief yeahs, uh-huhs, and mhmms that listeners provide -- in regulating the production of novelty: the lead-up to a backchannel is associated with declining information rate, while speech downstream rebounds to previous rates. Our results provide new insights into long-standing theories of how we respond to fluctuating demands on cognitive resources, and how we negotiate those demands in partnership with others.</description>
      <guid isPermaLink="false">oai:arXiv.org:2403.08890v1</guid>
      <category>cs.CL</category>
      <category>cs.IT</category>
      <category>math.IT</category>
      <category>q-bio.NC</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Claire Augusta Bergey, Simon DeDeo</dc:creator>
    </item>
    <item>
      <title>Optimal Top-Two Method for Best Arm Identification and Fluid Analysis</title>
      <link>https://arxiv.org/abs/2403.09123</link>
      <description>arXiv:2403.09123v1 Announce Type: cross 
Abstract: Top-$2$ methods have become popular in solving the best arm identification (BAI) problem. The best arm, or the arm with the largest mean amongst finitely many, is identified through an algorithm that at any sequential step independently pulls the empirical best arm, with a fixed probability $\beta$, and pulls the best challenger arm otherwise. The probability of incorrect selection is guaranteed to lie below a specified $\delta &gt;0$. Information theoretic lower bounds on sample complexity are well known for BAI problem and are matched asymptotically as $\delta \rightarrow 0$ by computationally demanding plug-in methods. The above top 2 algorithm for any $\beta \in (0,1)$ has sample complexity within a constant of the lower bound. However, determining the optimal $\beta$ that matches the lower bound has proven difficult. In this paper, we address this and propose an optimal top-2 type algorithm. We consider a function of allocations anchored at a threshold. If it exceeds the threshold then the algorithm samples the empirical best arm. Otherwise, it samples the challenger arm. We show that the proposed algorithm is optimal as $\delta \rightarrow 0$. Our analysis relies on identifying a limiting fluid dynamics of allocations that satisfy a series of ordinary differential equations pasted together and that describe the asymptotic path followed by our algorithm. We rely on the implicit function theorem to show existence and uniqueness of these fluid ode's and to show that the proposed algorithm remains close to the ode solution.</description>
      <guid isPermaLink="false">oai:arXiv.org:2403.09123v1</guid>
      <category>cs.LG</category>
      <category>cs.IT</category>
      <category>math.IT</category>
      <category>stat.ML</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Agniv Bandyopadhyay, Sandeep Juneja, Shubhada Agrawal</dc:creator>
    </item>
    <item>
      <title>Near-Field Channel Modeling for Holographic MIMO Communications</title>
      <link>https://arxiv.org/abs/2403.09411</link>
      <description>arXiv:2403.09411v1 Announce Type: cross 
Abstract: Empowered by the latest progress on innovative metamaterials/metasurfaces and advanced antenna technologies, holographic multiple-input multiple-output (H-MIMO) emerges as a promising technology to fulfill the extreme goals of the sixth-generation (6G) wireless networks. The antenna arrays utilized in H-MIMO comprise massive (possibly to extreme extent) numbers of antenna elements, densely spaced less than half-a-wavelength and integrated into a compact space, realizing an almost continuous aperture. Thanks to the expected low cost, size, weight, and power consumption, such apertures are expected to be largely fabricated for near-field communications. In addition, the physical features of H-MIMO enable manipulations directly on the electromagnetic (EM) wave domain and spatial multiplexing. To fully leverage this potential, near-field H-MIMO channel modeling, especially from the EM perspective, is of paramount significance. In this article, we overview near-field H-MIMO channel models elaborating on the various modeling categories and respective features, as well as their challenges and evaluation criteria. We also present EM-domain channel models that address the inherit computational and measurement complexities. Finally, the article is concluded with a set of future research directions on the topic.</description>
      <guid isPermaLink="false">oai:arXiv.org:2403.09411v1</guid>
      <category>eess.SP</category>
      <category>cs.IT</category>
      <category>math.IT</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Tierui Gong, Li Wei, Chongwen Huang, George C. Alexandropoulos, M\'erouane Debbah, Chau Yuen</dc:creator>
    </item>
    <item>
      <title>Multi-Fidelity Bayesian Optimization With Across-Task Transferable Max-Value Entropy Search</title>
      <link>https://arxiv.org/abs/2403.09570</link>
      <description>arXiv:2403.09570v1 Announce Type: cross 
Abstract: In many applications, ranging from logistics to engineering, a designer is faced with a sequence of optimization tasks for which the objectives are in the form of black-box functions that are costly to evaluate. For example, the designer may need to tune the hyperparameters of neural network models for different learning tasks over time. Rather than evaluating the objective function for each candidate solution, the designer may have access to approximations of the objective functions, for which higher-fidelity evaluations entail a larger cost. Existing multi-fidelity black-box optimization strategies select candidate solutions and fidelity levels with the goal of maximizing the information accrued about the optimal value or solution for the current task. Assuming that successive optimization tasks are related, this paper introduces a novel information-theoretic acquisition function that balances the need to acquire information about the current task with the goal of collecting information transferable to future tasks. The proposed method includes shared inter-task latent variables, which are transferred across tasks by implementing particle-based variational Bayesian updates. Experimental results across synthetic and real-world examples reveal that the proposed provident acquisition strategy that caters to future tasks can significantly improve the optimization efficiency as soon as a sufficient number of tasks is processed.</description>
      <guid isPermaLink="false">oai:arXiv.org:2403.09570v1</guid>
      <category>cs.LG</category>
      <category>cs.IT</category>
      <category>eess.SP</category>
      <category>math.IT</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Yunchuan Zhang, Sangwoo Park, Osvaldo Simeone</dc:creator>
    </item>
    <item>
      <title>Uncertainty-Aware and Reliable Neural MIMO Receivers via Modular Bayesian Deep Learning</title>
      <link>https://arxiv.org/abs/2302.02436</link>
      <description>arXiv:2302.02436v3 Announce Type: replace 
Abstract: Deep learning is envisioned to play a key role in the design of future wireless receivers. A popular approach to design learning-aided receivers combines deep neural networks (DNNs) with traditional model-based receiver algorithms, realizing hybrid model-based data-driven architectures. Such architectures typically include multiple modules, each carrying out a different functionality dictated by the model-based receiver workflow. Conventionally trained DNN-based modules are known to produce poorly calibrated, typically overconfident, decisions. Consequently, incorrect decisions may propagate through the architecture without any indication of their insufficient accuracy. To address this problem, we present a novel combination of Bayesian deep learning with hybrid model-based data-driven architectures for wireless receiver design. The proposed methodology, referred to as modular Bayesian deep learning, is designed to yield calibrated modules, which in turn improves both accuracy and calibration of the overall receiver. We specialize this approach for two fundamental tasks in multiple-input multiple-output (MIMO) receivers - equalization and decoding. In the presence of scarce data, the ability of modular Bayesian deep learning to produce reliable uncertainty measures is consistently shown to directly translate into improved performance of the overall MIMO receiver chain.</description>
      <guid isPermaLink="false">oai:arXiv.org:2302.02436v3</guid>
      <category>cs.IT</category>
      <category>eess.SP</category>
      <category>math.IT</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Tomer Raviv, Sangwoo Park, Osvaldo Simeone, Nir Shlezinger</dc:creator>
    </item>
    <item>
      <title>Assembly Theory is an approximation to algorithmic complexity based on LZ compression that does not explain selection or evolution</title>
      <link>https://arxiv.org/abs/2403.06629</link>
      <description>arXiv:2403.06629v3 Announce Type: replace 
Abstract: We demonstrate that Assembly Theory, pathway complexity, the assembly index, and the assembly number are subsumed and constitute a weak version of algorithmic (Kolmogorov-Solomonoff-Chaitin) complexity reliant on an approximation method based upon statistical compression, their results obtained due to the use of methods strictly equivalent to the LZ family of compression algorithms used in compressing algorithms such as ZIP, GZIP, or JPEG. Such popular algorithms have been shown to empirically reproduce the results of AT that were reported before in successful application to separating organic from non-organic molecules and in the context of the study of selection and evolution. We prove the connections and full equivalence of Assembly Theory to Shannon Entropy and statistical compression, and AT's disconnection as a statistical approach from causality. We demonstrate that formulating a traditional statistically compressed description of molecules, or the theory underlying it, does not imply an explanation or quantification of biases in generative (physical or biological) processes, including those brought about by selection and evolution, when lacking in logical consistency and empirical evidence. We argue that in their basic arguments, the authors of AT conflate how objects may assemble with causal directionality, and conclude that Assembly Theory does not explain selection or evolution beyond known and previously established connections, some of which are reviewed.</description>
      <guid isPermaLink="false">oai:arXiv.org:2403.06629v3</guid>
      <category>cs.IT</category>
      <category>math.IT</category>
      <category>q-bio.BM</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Felipe S. Abrah\~ao, Santiago Hern\'andez-Orozco, Narsis A. Kiani, Jesper Tegn\'er, Hector Zenil</dc:creator>
    </item>
    <item>
      <title>Fractal spatio-temporal scale-free messaging: amplitude modulation of self-executable carriers given by the Weierstrass function's components</title>
      <link>https://arxiv.org/abs/2403.06633</link>
      <description>arXiv:2403.06633v2 Announce Type: replace 
Abstract: In many communication contexts, the capabilities of the involved actors cannot be known beforehand, whether it is a cell, a plant, an insect, or even a life form unknown to Earth. Regardless of the recipient, the message space and time scale could be too fast, too slow, too large, or too small and may never be decoded. Therefore, it pays to devise a way to encode messages agnostic of space and time scales. We propose the use of fractal functions as self-executable infinite-frequency carriers for sending messages, given their properties of structural self-similarity and scale invariance. We call it `fractal messaging'. Starting from a spatial embedding, we introduce a framework for a space-time scale-free messaging approach to this challenge. When considering a space and time-agnostic framework for message transmission, it would be interesting to encode a message such that it could be decoded at several spatio-temporal scales. Hence, the core idea of the framework proposed herein is to encode a binary message as waves along infinitely many frequencies (in power-like distributions) and amplitudes, transmit such a message, and then decode and reproduce it. To do so, the components of the Weierstrass function, a known fractal, are used as carriers of the message. Each component will have its amplitude modulated to embed the binary stream, allowing for a space-time-agnostic approach to messaging.</description>
      <guid isPermaLink="false">oai:arXiv.org:2403.06633v2</guid>
      <category>cs.IT</category>
      <category>math.IT</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Hector Zenil, Luan Carlos de Sena Monteiro</dc:creator>
    </item>
    <item>
      <title>D$^2$-JSCC: Digital Deep Joint Source-channel Coding for Semantic Communications</title>
      <link>https://arxiv.org/abs/2403.07338</link>
      <description>arXiv:2403.07338v3 Announce Type: replace 
Abstract: Semantic communications (SemCom) have emerged as a new paradigm for supporting sixth-generation applications, where semantic features of data are transmitted using artificial intelligence algorithms to attain high communication efficiencies. Most existing SemCom techniques utilize deep neural networks (DNNs) to implement analog source-channel mappings, which are incompatible with existing digital communication architectures. To address this issue, this paper proposes a novel framework of digital deep joint source-channel coding (D$^2$-JSCC) targeting image transmission in SemCom. The framework features digital source and channel codings that are jointly optimized to reduce the end-to-end (E2E) distortion. First, deep source coding with an adaptive density model is designed to encode semantic features according to their distributions. Second, digital channel coding is employed to protect encoded features against channel distortion. To facilitate their joint design, the E2E distortion is characterized as a function of the source and channel rates via the analysis of the Bayesian model and Lipschitz assumption on the DNNs. Then to minimize the E2E distortion, a two-step algorithm is proposed to control the source-channel rates for a given channel signal-to-noise ratio. Simulation results reveal that the proposed framework outperforms classic deep JSCC and mitigates the cliff and leveling-off effects, which commonly exist for separation-based approaches.</description>
      <guid isPermaLink="false">oai:arXiv.org:2403.07338v3</guid>
      <category>cs.IT</category>
      <category>cs.MM</category>
      <category>eess.SP</category>
      <category>math.IT</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Jianhao Huang, Kai Yuan, Chuan Huang, Kaibin Huang</dc:creator>
    </item>
    <item>
      <title>Low-Complexity Beam Training for Multi-RIS-Assisted Multi-User Communications</title>
      <link>https://arxiv.org/abs/2403.08339</link>
      <description>arXiv:2403.08339v2 Announce Type: replace 
Abstract: In this paper, we investigate the beam training problem in the multi-user millimeter wave (mmWave) communication system, where multiple reconfigurable intelligent surfaces (RISs) are deployed to improve the coverage and the achievable rate. However, existing beam training techniques in mmWave systems suffer from the high complexity (i.e., exponential order) and low identification accuracy. To address these problems, we propose a novel hashing multi-arm beam (HMB) training scheme that reduces the training complexity to the logarithmic order with the high accuracy. Specifically, we first design a generation mechanism for HMB codebooks. Then, we propose a demultiplexing algorithm based on the soft decision to distinguish signals from different RIS reflective links. Finally, we utilize a multi-round voting mechanism to align the beams. Simulation results show that the proposed HMB training scheme enables simultaneous training for multiple RISs and multiple users, and reduces the beam training overhead to the logarithmic level. Moreover, it also shows that our proposed scheme can significantly improve the identification accuracy by at least 20% compared to existing beam training techniques.</description>
      <guid isPermaLink="false">oai:arXiv.org:2403.08339v2</guid>
      <category>cs.IT</category>
      <category>eess.SP</category>
      <category>math.IT</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Yuan Xu, Chongwen Huang, Wei Li, Zhaohui Yang, Xiaoming Chen, Zhaoyang Zhang, Chau Yuen, M\'erouane Debbah</dc:creator>
    </item>
    <item>
      <title>A lower bound on the space overhead of fault-tolerant quantum computation</title>
      <link>https://arxiv.org/abs/2202.00119</link>
      <description>arXiv:2202.00119v2 Announce Type: replace-cross 
Abstract: The threshold theorem is a fundamental result in the theory of fault-tolerant quantum computation stating that arbitrarily long quantum computations can be performed with a polylogarithmic overhead provided the noise level is below a constant level. A recent work by Fawzi, Grospellier and Leverrier (FOCS 2018) building on a result by Gottesman (QIC 2013) has shown that the space overhead can be asymptotically reduced to a constant independent of the circuit provided we only consider circuits with a length bounded by a polynomial in the width. In this work, using a minimal model for quantum fault tolerance, we establish a general lower bound on the space overhead required to achieve fault tolerance.
  For any non-unitary qubit channel $\mathcal{N}$ and any quantum fault tolerance schemes against $\mathrm{i.i.d.}$ noise modeled by $\mathcal{N}$, we prove a lower bound of $\max\left\{\mathrm{Q}(\mathcal{N})^{-1}n,\alpha_\mathcal{N} \log T\right\}$ on the number of physical qubits, for circuits of length $T$ and width $n$. Here, $\mathrm{Q}(\mathcal{N})$ denotes the quantum capacity of $\mathcal{N}$ and $\alpha_\mathcal{N}&gt;0$ is a constant only depending on the channel $\mathcal{N}$. In our model, we allow for qubits to be replaced by fresh ones during the execution of the circuit and we allow classical computation to be free and perfect. This improves upon results that assumed classical computations to be also affected by noise, and that sometimes did not allow for fresh qubits to be added. Along the way, we prove an exponential upper bound on the maximal length of fault-tolerant quantum computation with amplitude damping noise resolving a conjecture by Ben-Or, Gottesman, and Hassidim (2013).</description>
      <guid isPermaLink="false">oai:arXiv.org:2202.00119v2</guid>
      <category>quant-ph</category>
      <category>cs.IT</category>
      <category>math.IT</category>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <arxiv:DOI>10.4230/LIPIcs.ITCS.2022.68</arxiv:DOI>
      <dc:creator>Omar Fawzi, Alexander M\"uller-Hermes, Ala Shayeghi</dc:creator>
    </item>
    <item>
      <title>Model-free Reinforcement Learning of Semantic Communication by Stochastic Policy Gradient</title>
      <link>https://arxiv.org/abs/2305.03571</link>
      <description>arXiv:2305.03571v2 Announce Type: replace-cross 
Abstract: Following the recent success of Machine Learning tools in wireless communications, the idea of semantic communication by Weaver from 1949 has gained attention. It breaks with Shannon's classic design paradigm by aiming to transmit the meaning, i.e., semantics, of a message instead of its exact version, allowing for information rate savings. In this work, we apply the Stochastic Policy Gradient (SPG) to design a semantic communication system by reinforcement learning, separating transmitter and receiver, and not requiring a known or differentiable channel model -- a crucial step towards deployment in practice. Further, we derive the use of SPG for both classic and semantic communication from the maximization of the mutual information between received and target variables. Numerical results show that our approach achieves comparable performance to a model-aware approach based on the reparametrization trick, albeit with a decreased convergence rate.</description>
      <guid isPermaLink="false">oai:arXiv.org:2305.03571v2</guid>
      <category>eess.SP</category>
      <category>cs.IT</category>
      <category>cs.LG</category>
      <category>math.IT</category>
      <category>stat.ML</category>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Edgar Beck, Carsten Bockelmann, Armin Dekorsy</dc:creator>
    </item>
  </channel>
</rss>
