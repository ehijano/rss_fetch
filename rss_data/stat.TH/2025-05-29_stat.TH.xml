<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>stat.TH updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/stat.TH</link>
    <description>stat.TH updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/stat.TH" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Thu, 29 May 2025 04:03:30 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Thu, 29 May 2025 00:00:00 -0400</pubDate>
    <skipDays>
      <day>Saturday</day>
      <day>Sunday</day>
    </skipDays>
    <item>
      <title>Directional $\rho$-coefficients</title>
      <link>https://arxiv.org/abs/2505.22206</link>
      <description>arXiv:2505.22206v1 Announce Type: new 
Abstract: In this paper we obtain advances for the concept of directional $\rho$-coefficients, originally defined for the trivariate case in [Nelsen, R.B., \'Ubeda-Flores, M. (2011). Directional dependence in multivariate distributions. Ann. Inst. Stat. Math 64, 677-685] by extending it to encompass arbitrary dimensions and directions in multivariate space. We provide a generalized definition and establish its fundamental properties. Moreover, we resolve a conjecture from the aforementioned work by proving a more general result applicable to any dimension, correcting a result in [Garc\'ia, J.E., Gonz\'alez-L\'opez, V.A., Nelsen, R.B. (2013). A new index to measure positive dependence in trivariate distributions. J. Multivariate Anal. 115, 481-495] an erratum in the current literature. Our findings contribute to a deeper understanding of multivariate dependence and association, offering novel tools for detecting directional dependencies in high-dimensional settings. Finally, we introduce nonparametric estimators, based on ranks, for estimating directional $\rho$-coefficients from a sample.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.22206v1</guid>
      <category>math.ST</category>
      <category>stat.TH</category>
      <pubDate>Thu, 29 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Enrique de Amo, David Garc\'ia-Fern\'andez, Manuel \'Ubeda-Flores</dc:creator>
    </item>
    <item>
      <title>High-Dimensional Binary Variates: Maximum Likelihood Estimation with Nonstationary Covariates and Factors</title>
      <link>https://arxiv.org/abs/2505.22417</link>
      <description>arXiv:2505.22417v1 Announce Type: new 
Abstract: This paper introduces a high-dimensional binary variate model that accommodates nonstationary covariates and factors, and studies their asymptotic theory. This framework encompasses scenarios where single indices are nonstationary or cointegrated. For nonstationary single indices, the maximum likelihood estimator (MLE) of the coefficients has dual convergence rates and is collectively consistent under the condition $T^{1/2}/N\to0$, as both the cross-sectional dimension $N$ and the time horizon $T$ approach infinity. The MLE of all nonstationary factors is consistent when $T^{\delta}/N\to0$, where $\delta$ depends on the link function. The limiting distributions of the factors depend on time $t$, governed by the convergence of the Hessian matrix to zero. In the case of cointegrated single indices, the MLEs of both factors and coefficients converge at a higher rate of $\min(\sqrt{N},\sqrt{T})$. A distinct feature compared to nonstationary single indices is that the dual rate of convergence of the coefficients increases from $(T^{1/4},T^{3/4})$ to $(T^{1/2},T)$. Moreover, the limiting distributions of the factors do not depend on $t$ in the cointegrated case. Monte Carlo simulations verify the accuracy of the estimates. In an empirical application, we analyze jump arrivals in financial markets using this model, extract jump arrival factors, and demonstrate their efficacy in large-cross-section asset pricing.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.22417v1</guid>
      <category>math.ST</category>
      <category>stat.TH</category>
      <pubDate>Thu, 29 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Xinbing Kong, Bin Wu, Wuyi Ye</dc:creator>
    </item>
    <item>
      <title>Max-laws of large numbers for weakly dependent high dimensional arrays with applications</title>
      <link>https://arxiv.org/abs/2505.22423</link>
      <description>arXiv:2505.22423v1 Announce Type: new 
Abstract: We derive so-called weak and strong \textit{max-laws of large numbers} for $% \max_{1\leq i\leq k_{n}}|1/n\sum_{t=1}^{n}x_{i,n,t}|$ for zero mean stochastic triangular arrays $\{x_{i,n,t}$ $:$ $1$ $\leq $ $t$ $\leq n\}_{n\geq 1}$, with dimension counter $i$ $=$ $1,...,k_{n}$ and dimension $% k_{n}$ $\rightarrow $ $\infty $. Rates of convergence are also analyzed based on feasible sequences $\{k_{n}\}$. We work in three dependence settings: independence, Dedecker and Prieur's (2004) $\tau $-mixing and Wu's (2005) physical dependence. We initially ignore cross-coordinate $i$ dependence as a benchmark. We then work with martingale, nearly martingale, and mixing coordinates to deliver improved bounds on $k_{n}$. Finally, we use the results in three applications, each representing a key novelty: we ($i$) bound $k_{n}$\ for a max-correlation statistic for regression residuals under $\alpha $-mixing or physical dependence; ($ii$) extend correlation screening, or marginal regressions, to physical dependent data with diverging dimension $k_{n}$ $\rightarrow $ $\infty $; and ($iii$) test a high dimensional parameter after partialling out a fixed dimensional nuisance parameter in a linear time series regression model under $\tau $% -mixing.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.22423v1</guid>
      <category>math.ST</category>
      <category>stat.TH</category>
      <pubDate>Thu, 29 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Jonathan B. Hill</dc:creator>
    </item>
    <item>
      <title>GLAMP: An Approximate Message Passing Framework for Transfer Learning with Applications to Lasso-based Estimators</title>
      <link>https://arxiv.org/abs/2505.22594</link>
      <description>arXiv:2505.22594v1 Announce Type: new 
Abstract: Approximate Message Passing (AMP) algorithms enable precise characterization of certain classes of random objects in the high-dimensional limit, and have found widespread applications in fields such as statistics, deep learning, genetics, and communications. However, existing AMP frameworks cannot simultaneously handle matrix-valued iterates and non-separable denoising functions. This limitation prevents them from precisely characterizing estimators that draw information from multiple data sources with distribution shifts. In this work, we introduce Generalized Long Approximate Message Passing (GLAMP), a novel extension of AMP that addresses this limitation. We rigorously prove state evolution for GLAMP. GLAMP significantly broadens the scope of AMP, enabling the analysis of transfer learning estimators that were previously out of reach. We demonstrate the utility of GLAMP by precisely characterizing the risk of three Lasso-based transfer learning estimators: the Stacked Lasso, the Model Averaging Estimator, and the Second Step Estimator. We also demonstrate the remarkable finite sample accuracy of our theory via extensive simulations.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.22594v1</guid>
      <category>math.ST</category>
      <category>stat.ML</category>
      <category>stat.TH</category>
      <pubDate>Thu, 29 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Longlin Wang, Yanke Song, Kuanhao Jiang, Pragya Sur</dc:creator>
    </item>
    <item>
      <title>Path-Dependent SDEs: Solutions and Parameter Estimation</title>
      <link>https://arxiv.org/abs/2505.22646</link>
      <description>arXiv:2505.22646v1 Announce Type: new 
Abstract: We develop a consistent method for estimating the parameters of a rich class of path-dependent SDEs, called signature SDEs, which can model general path-dependent phenomena. Path signatures are iterated integrals of a given path with the property that any sufficiently nice function of the path can be approximated by a linear functional of its signatures. This is why we model the drift and diffusion of our signature SDE as linear functions of path signatures. We provide conditions that ensure the existence and uniqueness of solutions to a general signature SDE. We then introduce the Expected Signature Matching Method (ESMM) for linear signature SDEs, which enables inference of the signature-dependent drift and diffusion coefficients from observed trajectories. Furthermore, we prove that ESMM is consistent: given sufficiently many samples and Picard iterations used by the method, the parameters estimated by the ESMM approach the true parameter with arbitrary precision. Finally, we demonstrate on a variety of empirical simulations that our ESMM accurately infers the drift and diffusion parameters from observed trajectories. While parameter estimation is often restricted by the need for a suitable parametric model, this work makes progress toward a completely general framework for SDE parameter estimation, using signature terms to model arbitrary path-independent and path-dependent processes.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.22646v1</guid>
      <category>math.ST</category>
      <category>math.PR</category>
      <category>stat.TH</category>
      <pubDate>Thu, 29 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Pardis Semnani, Vincent Guan, Elina Robeva, Darrick Lee</dc:creator>
    </item>
    <item>
      <title>A Kernelised Stein Discrepancy for Assessing the Fit of Inhomogeneous Random Graph Models</title>
      <link>https://arxiv.org/abs/2505.21580</link>
      <description>arXiv:2505.21580v1 Announce Type: cross 
Abstract: Complex data are often represented as a graph, which in turn can often be viewed as a realisation of a random graph, such as of an inhomogeneous random graph model (IRG). For general fast goodness-of-fit tests in high dimensions, kernelised Stein discrepancy (KSD) tests are a powerful tool. Here, we develop, test, and analyse a KSD-type goodness-of-fit test for IRG models that can be carried out with a single observation of the network. The test is applicable to a network of any size and does not depend on the asymptotic distribution of the test statistic. We also provide theoretical guarantees.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.21580v1</guid>
      <category>stat.ML</category>
      <category>cs.LG</category>
      <category>math.ST</category>
      <category>stat.TH</category>
      <pubDate>Thu, 29 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Anum Fatima, Gesine Reinert</dc:creator>
    </item>
    <item>
      <title>Langevin SDEs have unique transient dynamics</title>
      <link>https://arxiv.org/abs/2505.21770</link>
      <description>arXiv:2505.21770v1 Announce Type: cross 
Abstract: The overdamped Langevin stochastic differential equation (SDE) is a classical physical model used for chemical, genetic, and hydrological dynamics. In this work, we prove that the drift and diffusion terms of a Langevin SDE are jointly identifiable from temporal marginal distributions if and only if the process is observed out of equilibrium. This complete characterization of structural identifiability removes the long-standing assumption that the diffusion must be known to identify the drift. We then complement our theory with experiments in the finite sample setting and study the practical identifiability of the drift and diffusion, in order to propose heuristics for optimal data collection.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.21770v1</guid>
      <category>math.PR</category>
      <category>math.ST</category>
      <category>stat.ML</category>
      <category>stat.TH</category>
      <pubDate>Thu, 29 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Vincent Guan, Joseph Janssen, Nicolas Lanzetti, Antonio Terpin, Geoffrey Schiebinger, Elina Robeva</dc:creator>
    </item>
    <item>
      <title>Reconstruction of the Probability Measure and the Coupling Parameters in a Curie-Weiss Model</title>
      <link>https://arxiv.org/abs/2505.21778</link>
      <description>arXiv:2505.21778v1 Announce Type: cross 
Abstract: The Curie-Weiss model is used to study phase transitions in statistical mechanics and has been the object of rigorous analysis in mathematical physics. We analyse the problem of reconstructing the probability measure of a multi-group Curie-Weiss model from a sample of data by employing the maximum likelihood estimator for the coupling parameters of the model, under the assumption that there is interaction within each group but not across group boundaries. The estimator has a number of positive properties, such as consistency, asymptotic normality, and exponentially decaying probabilities of large deviations of the estimator with respect to the true parameter value. A shortcoming in practice is the necessity to calculate the partition function of the Curie-Weiss model, which scales exponentially with respect to the population size. There are a number of applications of the estimator in political science, sociology, and automated voting, centred on the idea of identifying the degree of social cohesion in a population. In these applications, the coupling parameter is a natural way to quantify social cohesion. We treat the estimation of the optimal weights in a two-tier voting system, which requires the estimation of the coupling parameter.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.21778v1</guid>
      <category>math.PR</category>
      <category>math-ph</category>
      <category>math.MP</category>
      <category>math.ST</category>
      <category>stat.TH</category>
      <pubDate>Thu, 29 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Miguel Ballesteros, Rams\'es H. Mena, Arno Siri-J\'egousse, Gabor Toth</dc:creator>
    </item>
    <item>
      <title>Random irregular histograms</title>
      <link>https://arxiv.org/abs/2505.22034</link>
      <description>arXiv:2505.22034v1 Announce Type: cross 
Abstract: We propose a new method of histogram construction, providing the first fully Bayesian approach to irregular histograms. Our procedure applies Bayesian model selection to a piecewise constant model of the underlying distribution, resulting in a method that selects both the number of bins as well as their location based on the data in a fully automatic fashion. We show that the histogram estimate is consistent with respect to the Hellinger metric under mild regularity conditions, and that it attains a convergence rate equal to the minimax rate (up to a logarithmic factor) for H\"{o}lder continuous densities. Simulation studies indicate that the new method performs comparably to other histogram procedures, both for minimizing the estimation error and for identifying modes. A software implementation is included as supplementary material.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.22034v1</guid>
      <category>stat.ME</category>
      <category>math.ST</category>
      <category>stat.TH</category>
      <pubDate>Thu, 29 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Oskar H{\o}gberg Simensen, Dennis Christensen, Nils Lid Hjort</dc:creator>
    </item>
    <item>
      <title>Handling bounded response in high dimensions: a Horseshoe prior Bayesian Beta regression approach</title>
      <link>https://arxiv.org/abs/2505.22211</link>
      <description>arXiv:2505.22211v1 Announce Type: cross 
Abstract: Bounded continuous responses -- such as proportions -- arise frequently in diverse scientific fields including climatology, biostatistics, and finance. Beta regression is a widely adopted framework for modeling such data, due to the flexibility of the Beta distribution over the unit interval. While Bayesian extensions of Beta regression have shown promise, existing methods are limited to low-dimensional settings and lack theoretical guarantees. In this work, we propose a novel Bayesian approach for high-dimensional sparse Beta regression framework that employs a tempered posterior. Our method incorporates the Horseshoe prior for effective shrinkage and variable selection. Most notable, we propose a novel Gibbs sampling algorithm using P\'olya-Gamma augmentation for efficient inference in Beta regression model. We also provide the first theoretical results establishing posterior consistency and convergence rates for Bayesian Beta regression. Through extensive simulation studies in both low- and high-dimensional scenarios, we demonstrate that our approach outperforms existing alternatives, offering improved estimation accuracy and model interpretability.
  Our method is implemented in the R package ``betaregbayes" available on Github.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.22211v1</guid>
      <category>stat.ME</category>
      <category>math.ST</category>
      <category>stat.ML</category>
      <category>stat.TH</category>
      <pubDate>Thu, 29 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <dc:creator>The Tien Mai</dc:creator>
    </item>
    <item>
      <title>Adaptive tail index estimation: minimal assumptions and non-asymptotic guarantees</title>
      <link>https://arxiv.org/abs/2505.22371</link>
      <description>arXiv:2505.22371v1 Announce Type: cross 
Abstract: A notoriously difficult challenge in extreme value theory is the choice of the number $k\ll n$, where $n$ is the total sample size, of extreme data points to consider for inference of tail quantities.
  Existing theoretical guarantees for adaptive methods typically require second-order assumptions or von Mises assumptions that are difficult to verify and often come with tuning parameters that are challenging to calibrate. This paper revisits the problem of adaptive selection of $k$ for the Hill estimator. Our goal is not an `optimal' $k$ but one that is `good enough', in the sense that we strive for non-asymptotic guarantees that might be sub-optimal but are explicit and require minimal conditions. We propose a transparent adaptive rule that does not require preliminary calibration of constants, inspired by `adaptive validation' developed in high-dimensional statistics. A key feature of our approach is the consideration of a grid for $k$ of size $ \ll n $, which aligns with common practice among practitioners
  but has remained unexplored in theoretical analysis. Our rule only involves an explicit expression of a variance-type term; in particular, it does not require controlling or estimating a biasterm.
  Our theoretical analysis is valid for all heavy-tailed distributions, specifically for all regularly varying survival functions. Furthermore, when von Mises conditions hold, our method achieves `almost' minimax optimality with a rate of
  $\sqrt{\log \log n}~ n^{-|\rho|/(1+2|\rho|)}$ when the grid size is of order $\log n$, in contrast to the
  $ (\log \log (n)/n)^{|\rho|/(1+2|\rho|)} $ rate in existing work. Our simulations show that our approach performs particularly well for ill-behaved distributions.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.22371v1</guid>
      <category>stat.OT</category>
      <category>math.ST</category>
      <category>stat.TH</category>
      <pubDate>Thu, 29 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Johannes Lederer, Anne Sabourin, Mahsa Taheri</dc:creator>
    </item>
    <item>
      <title>Principled Out-of-Distribution Generalization via Simplicity</title>
      <link>https://arxiv.org/abs/2505.22622</link>
      <description>arXiv:2505.22622v1 Announce Type: cross 
Abstract: Modern foundation models exhibit remarkable out-of-distribution (OOD) generalization, solving tasks far beyond the support of their training data. However, the theoretical principles underpinning this phenomenon remain elusive. This paper investigates this problem by examining the compositional generalization abilities of diffusion models in image generation. Our analysis reveals that while neural network architectures are expressive enough to represent a wide range of models -- including many with undesirable behavior on OOD inputs -- the true, generalizable model that aligns with human expectations typically corresponds to the simplest among those consistent with the training data.
  Motivated by this observation, we develop a theoretical framework for OOD generalization via simplicity, quantified using a predefined simplicity metric. We analyze two key regimes: (1) the constant-gap setting, where the true model is strictly simpler than all spurious alternatives by a fixed gap, and (2) the vanishing-gap setting, where the fixed gap is replaced by a smoothness condition ensuring that models close in simplicity to the true model yield similar predictions. For both regimes, we study the regularized maximum likelihood estimator and establish the first sharp sample complexity guarantees for learning the true, generalizable, simple model.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.22622v1</guid>
      <category>stat.ML</category>
      <category>cs.LG</category>
      <category>math.ST</category>
      <category>stat.TH</category>
      <pubDate>Thu, 29 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Jiawei Ge, Amanda Wang, Shange Tang, Chi Jin</dc:creator>
    </item>
    <item>
      <title>Optimal convex $M$-estimation via score matching</title>
      <link>https://arxiv.org/abs/2403.16688</link>
      <description>arXiv:2403.16688v2 Announce Type: replace 
Abstract: In the context of linear regression, we construct a data-driven convex loss function with respect to which empirical risk minimisation yields optimal asymptotic variance in the downstream estimation of the regression coefficients. At the population level, the negative derivative of the optimal convex loss is the best decreasing approximation of the derivative of the log-density of the noise distribution. This motivates a fitting process via a nonparametric extension of score matching, corresponding to a log-concave projection of the noise distribution with respect to the Fisher divergence. At the sample level, our semiparametric estimator is computationally efficient, and we prove that it attains the minimal asymptotic covariance among all convex $M$-estimators. As an example of a non-log-concave setting, the optimal convex loss function for Cauchy errors is Huber-like, and our procedure yields asymptotic efficiency greater than $0.87$ relative to the maximum likelihood estimator of the regression coefficients that uses oracle knowledge of this error distribution. In this sense, we provide robustness and facilitate computation without sacrificing much statistical efficiency. Numerical experiments using our accompanying R package 'asm' confirm the practical merits of our proposal.</description>
      <guid isPermaLink="false">oai:arXiv.org:2403.16688v2</guid>
      <category>math.ST</category>
      <category>stat.ME</category>
      <category>stat.ML</category>
      <category>stat.TH</category>
      <pubDate>Thu, 29 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Oliver Y. Feng, Yu-Chun Kao, Min Xu, Richard J. Samworth</dc:creator>
    </item>
    <item>
      <title>Stochastic comparison of series and parallel systems lifetime in Archimedean copula under random shock</title>
      <link>https://arxiv.org/abs/2406.05834</link>
      <description>arXiv:2406.05834v2 Announce Type: replace 
Abstract: In this paper, we studied the stochastic ordering behavior of series as well as parallel systems' lifetimes comprising dependent and heterogeneous components, experiencing random shocks, and exhibiting distinct dependency structures. We establish certain conditions on the lifetime of individual components where the dependency among components defined by Archimedean copulas, and the impact of random shocks on the overall system lifetime to get the results. We consider components whose survival functions are either increasing log-concave or decreasing log-convex functions of the parameters involved. These conditions make it possible to compare the lifetimes of two systems using the usual stochastic order framework. Additionally, we provide examples and graphical representations to elucidate our theoretical findings.</description>
      <guid isPermaLink="false">oai:arXiv.org:2406.05834v2</guid>
      <category>math.ST</category>
      <category>math.PR</category>
      <category>stat.AP</category>
      <category>stat.TH</category>
      <pubDate>Thu, 29 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Sarikul Islam, Nitin Gupta</dc:creator>
    </item>
    <item>
      <title>Spectrally Robust Covariance Shrinkage for Hotelling's $T^2$ in High Dimension</title>
      <link>https://arxiv.org/abs/2502.02006</link>
      <description>arXiv:2502.02006v2 Announce Type: replace 
Abstract: We investigate covariance shrinkage for Hotelling's $T^2$ in the regime where the data dimension $p$ and the sample size $n$ grow in a fixed ratio -- without assuming that the population covariance matrix is spiked or well-conditioned. When $p/n\to\phi \in (0,1)$, we propose a practical finite-sample shrinker that, for any maximum-entropy signal prior and any fixed significance level, (a) asymptotically maximizes power under Gaussian data, and (b) asymptotically saturates the Hanson--Wright lower bound on power in the more general sub-Gaussian case. Our approach is to formulate and solve a variational problem characterizing the optimal limiting shrinker, and to show that our finite-sample method consistently approximates this limit by extending recent local random matrix laws. Empirical studies on simulated and real-world data, including the Crawdad UMich/RSS data set, demonstrate up to a $50\%$ gain in power over leading linear and nonlinear competitors at a significance level of $10^{-4}$.</description>
      <guid isPermaLink="false">oai:arXiv.org:2502.02006v2</guid>
      <category>math.ST</category>
      <category>math.PR</category>
      <category>stat.ME</category>
      <category>stat.TH</category>
      <pubDate>Thu, 29 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Benjamin D. Robinson, Van Latimer</dc:creator>
    </item>
    <item>
      <title>Robust Representation and Estimation of Barycenters and Modes of Probability Measures on Metric Spaces</title>
      <link>https://arxiv.org/abs/2505.09609</link>
      <description>arXiv:2505.09609v2 Announce Type: replace 
Abstract: This paper is concerned with the problem of defining and estimating statistics for distributions on spaces such as Riemannian manifolds and more general metric spaces. The challenge comes, in part, from the fact that statistics such as means and modes may be unstable: for example, a small perturbation to a distribution can lead to a large change in Fr\'echet means on spaces as simple as a circle. We address this issue by introducing a new merge tree representation of barycenters called the barycentric merge tree (BMT), which takes the form of a measured metric graph and summarizes features of the distribution in a multiscale manner. Modes are treated as special cases of barycenters through diffusion distances. In contrast to the properties of classical means and modes, we prove that BMTs are stable -- this is quantified as a Lipschitz estimate involving optimal transport metrics. This stability allows us to derive a consistency result for approximating BMTs from empirical measures, with explicit convergence rates. We also give a provably accurate method for discretely approximating the BMT construction and use this to provide numerical examples for distributions on spheres and shape spaces.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.09609v2</guid>
      <category>math.ST</category>
      <category>math.MG</category>
      <category>stat.ME</category>
      <category>stat.TH</category>
      <pubDate>Thu, 29 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/publicdomain/zero/1.0/</dc:rights>
      <dc:creator>Washington Mio, Tom Needham</dc:creator>
    </item>
    <item>
      <title>Regularizing Fairness in Optimal Policy Learning with Distributional Targets</title>
      <link>https://arxiv.org/abs/2401.17909</link>
      <description>arXiv:2401.17909v2 Announce Type: replace-cross 
Abstract: A decision maker typically (i) incorporates training data to learn about the relative effectiveness of treatments, and (ii) chooses an implementation mechanism that implies an ``optimal'' predicted outcome distribution according to some target functional. Nevertheless, a fairness-aware decision maker may not be satisfied achieving said optimality at the cost of being ``unfair" against a subgroup of the population, in the sense that the outcome distribution in that subgroup deviates too strongly from the overall optimal outcome distribution. We study a framework that allows the decision maker to regularize such deviations, while allowing for a wide range of target functionals and fairness measures to be employed. We establish regret and consistency guarantees for empirical success policies with (possibly) data-driven preference parameters, and provide numerical results. Furthermore, we briefly illustrate the methods in two empirical settings.</description>
      <guid isPermaLink="false">oai:arXiv.org:2401.17909v2</guid>
      <category>econ.EM</category>
      <category>math.ST</category>
      <category>stat.TH</category>
      <pubDate>Thu, 29 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Anders Bredahl Kock, David Preinerstorfer</dc:creator>
    </item>
    <item>
      <title>PUATE: Efficient Average Treatment Effect Estimation from Treated (Positive) and Unlabeled Units</title>
      <link>https://arxiv.org/abs/2501.19345</link>
      <description>arXiv:2501.19345v2 Announce Type: replace-cross 
Abstract: The estimation of average treatment effects (ATEs), defined as the difference in expected outcomes between treatment and control groups, is a central topic in causal inference. This study develops semiparametric efficient estimators for ATE in a setting where only a treatment group and an unlabeled group, consisting of units whose treatment status is unknown, are observed. This scenario constitutes a variant of learning from positive and unlabeled data (PU learning) and can be viewed as a special case of ATE estimation with missing data. For this setting, we derive the semiparametric efficiency bounds, which characterize the lowest achievable asymptotic variance for regular estimators. We then construct semiparametric efficient ATE estimators that attain these bounds. Our results contribute to the literature on causal inference with missing data and weakly supervised learning.</description>
      <guid isPermaLink="false">oai:arXiv.org:2501.19345v2</guid>
      <category>cs.LG</category>
      <category>econ.EM</category>
      <category>math.ST</category>
      <category>stat.ME</category>
      <category>stat.ML</category>
      <category>stat.TH</category>
      <pubDate>Thu, 29 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Masahiro Kato, Fumiaki Kozai, Ryo Inokuchi</dc:creator>
    </item>
  </channel>
</rss>
