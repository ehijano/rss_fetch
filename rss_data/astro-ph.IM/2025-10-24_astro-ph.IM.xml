<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>astro-ph.IM updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/astro-ph.IM</link>
    <description>astro-ph.IM updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/astro-ph.IM" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Fri, 24 Oct 2025 04:01:02 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Fri, 24 Oct 2025 00:00:00 -0400</pubDate>
    <skipDays>
      <day>Saturday</day>
      <day>Sunday</day>
    </skipDays>
    <item>
      <title>Ly{\alpha}NNA II: Field-level inference with noisy Ly{\alpha} forest spectra</title>
      <link>https://arxiv.org/abs/2510.19899</link>
      <description>arXiv:2510.19899v1 Announce Type: new 
Abstract: Deep learning (DL) has been shown to outperform traditional, human-defined summary statistics of the Ly{\alpha} forest in constraining key astrophysical and cosmological parameters owing to its ability to tap into the realm of non-Gaussian information. An understanding of the impact of nuisance effects such as noise on such field-level frameworks, however, still remains elusive. In this work we conduct a systematic investigation into the efficacy of DL inference from noisy Ly{\alpha} forest spectra. Building upon our previous, proof-of-concept framework (Nayak et al. 2024) for pure spectra, we constructed and trained a ResNet neural network using labeled mock data from hydrodynamical simulations with a range of noise levels to optimally compress noisy spectra into a novel summary statistic that is exclusively sensitive to the power-law temperature-density relation of the intergalactic medium. We fit a Gaussian mixture surrogate with 23 components through our labels and summaries to estimate the joint data-parameter distribution for likelihood free inference, in addition to performing inference with a Gaussian likelihood. The posterior contours in the two cases agree well with each other. We compared the precision and accuracy of our posterior constraints with a combination of two human defined summaries (the 1D power spectrum and PDF of the Ly{\alpha} transmission) that have been corrected for noise, over a wide range of continuum-to-noise ratios (CNR) in the likelihood case. We found a gain in precision in terms of posterior contour area with our pipeline over the said combination of 65% (at a CNR of 20 per 6 km/s) to 112% (at 200 per 6 km/s). While the improvement in posterior precision is not as large as in the noiseless case, these results indicate that DL still remains a powerful tool for inference even with noisy, real-world datasets.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.19899v1</guid>
      <category>astro-ph.IM</category>
      <category>astro-ph.CO</category>
      <pubDate>Fri, 24 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Parth Nayak, Michael Walther, Daniel Gruen</dc:creator>
    </item>
    <item>
      <title>On-sky Demonstration of Subdiffraction-limited Astronomical Measurement Using a Photonic Lantern</title>
      <link>https://arxiv.org/abs/2510.19911</link>
      <description>arXiv:2510.19911v1 Announce Type: new 
Abstract: Resolving fine details of astronomical objects provides critical insights into their underlying physical processes. This drives in part the desire to construct ever-larger telescopes and interferometer arrays and to observe at shorter wavelength to lower the diffraction limit of angular resolution. Alternatively, one can aim to overcome the diffraction limit by extracting more information from a single telescope's aperture. A promising way to do this is spatial mode-based imaging, which projects focal-plane field onto a set of spatial modes before detection, retaining focal-plane phase information crucial at small angular scales but typically lost in intensity imaging. However, the practical implementation of mode-based imaging in astronomy from the ground has been challenged by atmospheric turbulence. Here, we present the first on-sky demonstration of a subdiffraction-limited, mode-based measurement using a photonic lantern (PL)-fed spectrometer installed on the SCExAO instrument at the Subaru Telescope. We introduce a novel calibration strategy that mitigates time-varying wavefront error and misalignment effects, leveraging simultaneously recorded focal-plane images and using a spectral-differential technique that self-calibrates the data. Observing the classical Be star $\beta$ CMi, we detected spectral-differential spatial signals and reconstructed images of its H$\alpha$-emitting disk. We achieved an unprecedented H$\alpha$ photocenter precision of 50$\mu$as in about 10-minute observation with a single telescope, measuring the disk's near-far side asymmetry for the first time. This work demonstrates the high precision, efficiency, and practicality of photonic mode-based imaging techniques to recover subdiffraction-limited information, opening new avenues for high angular resolution spectroscopic studies in astronomy.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.19911v1</guid>
      <category>astro-ph.IM</category>
      <category>physics.optics</category>
      <pubDate>Fri, 24 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <arxiv:DOI>10.3847/2041-8213/ae0739</arxiv:DOI>
      <arxiv:journal_reference>The Astrophysical Journal Letters, Volume 993 (2025), Number 1</arxiv:journal_reference>
      <dc:creator>Yoo Jung Kim, Michael P. Fitzgerald, S\'ebastien Vievard, Jonathan Lin, Yinzi Xin, Miles Lucas, Olivier Guyon, Julien Lozi, Vincent Deo, Elsa Huby, Sylvestre Lacour, Manon Lallement, Rodrigo Amezcua-Correa, Sergio Leon-Saval, Barnaby Norris, Mathias Nowak, Steph Sallum, Jehanne Sarrazin, Adam Taras, Stephanos Yerolatsitis, Nemanja Jovanovic</dc:creator>
    </item>
    <item>
      <title>Living on the edge: Testing for compact population features at the edges of parameter space</title>
      <link>https://arxiv.org/abs/2510.20010</link>
      <description>arXiv:2510.20010v1 Announce Type: new 
Abstract: Many astrophysical population studies involve parameters that exist on a bounded domain, such as the dimensionless spins of black holes or the eccentricities of planetary orbits, both of which are confined to $[0, 1]$. In such scenarios, we often wish to test for distributions clustered near a boundary, e.g., vanishing spin or orbital eccentricity. Conventional approaches -- whether based on Monte Carlo, kernel density estimators, or machine-learning techniques -- often suffer biases at the boundaries. These biases stem from sparse sampling near the edge, kernel-related smoothing, or artifacts introduced by domain transformations. We introduce a truncated Gaussian mixture model framework that substantially mitigates these issues, enabling accurate inference of narrow, edge-dominated population features. While our method has broad applications to many astronomical domains, we consider gravitational wave catalogs as a concrete example to demonstrate its power. In particular, we maintain agreement with published constraints on the fraction of zero-spin binary black hole systems in the GWTC-3 catalog -- results originally derived at much higher computational cost through dedicated reanalysis of individual events in the catalog. Our method can achieve similarly reliable results with a much lower computational cost. The method is publicly available in the open-source packages gravpop and truncatedgaussianmixtures.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.20010v1</guid>
      <category>astro-ph.IM</category>
      <category>astro-ph.HE</category>
      <pubDate>Fri, 24 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Asad Hussain, Maximiliano Isi, Aaron Zimmerman</dc:creator>
    </item>
    <item>
      <title>Performance analysis of a Hadamard Transform Spectral Imaging system</title>
      <link>https://arxiv.org/abs/2510.20195</link>
      <description>arXiv:2510.20195v1 Announce Type: new 
Abstract: Hadamard Transform Spectral Imaging (HTSI) is a multiplexing technique used to recover spectra via encoding with multi-slit masks, and is particularly useful in low photon flux applications where signal-independent noise is the dominant noise source. This work focuses on the procedure that is used to recover spectra encoded with multi-slit masks generated from a Hadamard matrix; the decoding process involves multiplying the output encoded spectral images by the inverse of the Hadamard matrix, which separates any spectra that were overlapping in the target object. The output from HTSI is compared to direct measurement methods, such as single-slit scanning, to evaluate its performance and identify under which conditions it can provide an advantage or disadvantage. HTSI resulted in an increase in the average signal-to-noise (SNR) ratio of spectra when signal-independent noise, such as detector read noise, is present, and has no average net effect when signal dependent-noise, such as Poisson photon noise, is the only noise source present. The SNR of emission lines was found to be greater with HTSI than with single-slit scanning under both signal-independent and signal-dependent noise, and increases as the ratio of read-to-shot noise increases.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.20195v1</guid>
      <category>astro-ph.IM</category>
      <pubDate>Fri, 24 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>John Nijim (Rochester Institute of Technology), Zoran Ninkov (Rochester Institute of Technology), Dmitry Vorobiev (Laboratory for Atmospheric and Space Physics, University of Colorado), Kevin Kearney (Rochester Institute of Technology, Starris Optimax Space Systems)</dc:creator>
    </item>
    <item>
      <title>Satellite Underflight Utility for Thermal Sensor Harmonization</title>
      <link>https://arxiv.org/abs/2510.20248</link>
      <description>arXiv:2510.20248v1 Announce Type: new 
Abstract: Underflight maneuvers provide a unique opportunity to harmonize calibration of on-orbit sensors. Due to their similar sensor technologies, their near-identical transmission profiles, orbital properties and platform operations, the underflight data of Landsat 8 and 9 instruments stand out as a qualifier to test proposed metrics, methods, and the extent over which to compare two independently calibrated sensors across their similar operating bandpasses. This study performed a pixel-to-pixel comparison of thermal imagery of TIRS and TIRS-2 (aboard Landsat 8 and 9, respectively) during their five-day underflight maneuver in November 2021, with the ultimate goal of identifying the key site/scene-selection criteria for a subset of images that are suitable for radiative calibration validation purposes. If a group of near-coincidentally observed images by two identical underflying sensors fail to show consistent Top-of-Atmosphere (TOA) Brightness Temperatures for the same exact geographical locations, then the scenes with those shared properties and/or observing conditions will prove unreliable for cross calibration validation of less-similar underflying sensor pairs. This study demonstrates that near-coincidental images with Root Mean Square Deviations (RMSDs) of less than 5\% between their TOA radiances are optimum candidates for cross-validation of radiative calibration between two independently calibrated sensors. This criterion is shown to be reliable for coincidental acquisitions with a wide range of overlapping area, terrain type, land-to-water fraction and cloud coverage. Important considerations include any time gap between near-coincident acquisitions as well as the application of pixel quality masks. The analysis of the selected underflight scenes demonstrated an agreement between the TIRS on Landsat 8 and 9 to within 0.123 K and 0.066 K for the 10.9um and 12.0um bands respectively.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.20248v1</guid>
      <category>astro-ph.IM</category>
      <pubDate>Fri, 24 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Sarah E. Kay, Brian N. Wenny</dc:creator>
    </item>
    <item>
      <title>Capability of using the normalizing flows for extraction rare gamma events in the TAIGA experiment</title>
      <link>https://arxiv.org/abs/2510.20334</link>
      <description>arXiv:2510.20334v1 Announce Type: new 
Abstract: The objective of this work is to develop a method for detecting rare gamma quanta against the background of charged particles in the fluxes from sources in the Universe with the help of the deep learning and normalizing flows based method designed for anomaly detection. It is shown that the suggested method has a potential for the gamma detection. The method was tested on model data from the TAIGA-IACT experiment. The obtained quantitative performance indicators are still inferior to other approaches, and therefore possible ways to improve the implementation of the method are proposed.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.20334v1</guid>
      <category>astro-ph.IM</category>
      <category>astro-ph.HE</category>
      <category>cs.LG</category>
      <pubDate>Fri, 24 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>A. P. Kryukov, A. Yu. Razumov, A. P. Demichev, J. J. Dubenskaya, E. O. Gres, S. P. Polyakov, E. B. Postnikov, P. A. Volchugov, D. P. Zhurov</dc:creator>
    </item>
    <item>
      <title>Characterising the properties of the atmospheric emission at Teide Observatory in the 10-20 GHz range with QUIJOTE data</title>
      <link>https://arxiv.org/abs/2510.19878</link>
      <description>arXiv:2510.19878v1 Announce Type: cross 
Abstract: QUIJOTE is a CMB experiment composed of two telescopes, QT1 and QT2, located at the Teide Observatory in Tenerife, Spain. The MFI instrument (2012-2018), installed on QT1, observed the sky at four frequency bands (11, 13, 17, and 19 GHz) with one degree angular resolution. Its successor, MFI2, began operations in 2024 and operates in the same bands. This paper has two main goals: first, to characterise the atmospheric conditions at Teide Observatory to improve existing models at these frequencies, and second, to empirically characterise atmospheric turbulence using QUIJOTE MFI and MFI2 observations. This work has implications for both atmospheric physics and CMB studies and can support future reanalyses of MFI data or the preparation of upcoming instruments such as the Tenerife Microwave Spectrometer. We used data from GPS antennas, the STELLA observatory, and radio soundings to derive median profiles and distributions of key atmospheric parameters for 2012-2018. MFI data were analysed to compute atmospheric structure functions at 17 and 19 GHz and to study the correlation properties of the atmospheric signal through cross-correlation between horns at the same frequency. MFI2 observations were used to estimate the atmospheric power spectrum and compare it with the structure function derived from MFI data. The water vapour density profile follows an exponential decay with a characteristic half-height of about 1000 m. Median PWV in 2012-2018 is 3.3 mm. For high PWV conditions, the structure function agrees with the Kolmogorov turbulence model. The slope of the power spectrum also matches the model prediction, within the frequency range limited by the outer scale and instrument noise. Finally, from the correlation function, we find that atmospheric conditions remain stable for about 1-2 hours.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.19878v1</guid>
      <category>physics.ao-ph</category>
      <category>astro-ph.CO</category>
      <category>astro-ph.IM</category>
      <pubDate>Fri, 24 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Apolline Chappard, Jos\'e Alberto Rubi\~no-Mart\'in, Ricardo Tanaus\'u G\'enova Santos</dc:creator>
    </item>
    <item>
      <title>Systematics mitigation for catalogue-based angular power spectra</title>
      <link>https://arxiv.org/abs/2510.19912</link>
      <description>arXiv:2510.19912v1 Announce Type: cross 
Abstract: Recent work has developed a formalism for computing angular power spectra directly from catalogues containing field values at discrete positions on the sky, thereby circumventing the need to create pixelised maps of the fields, as well as avoiding aliasing and finite-resolution effects. Here, we adapt this formalism to incorporate template deprojection as a means of mitigating systematic biases in the measured angular power spectra. We also introduce and validate an alternative method of mitigating the so-called `deprojection bias', caused by the loss of modes after deprojection, employing the use of simple simulations to compute a transfer function. We find that this approach performs at least as well as existing methods, and is relatively insensitive to how well one can guess the true power spectrum of the observed field, except at the largest scales ($\ell \lesssim 3$). Additionally, we develop exact expressions for the bias introduced by deprojection in the shot-noise component, which further improves the accuracy of this approach. We test our formalism on simulated datasets, demonstrating its applicability both to discretely sampled fields, and to the special case of galaxy clustering, with the survey selection function defined in terms of a random catalogue or as a continuous sky map. After computing and removing the bias in the shot noise and using a transfer function to correct for the remaining mode loss, our formalism is able to produce unbiased measurements of the angular power spectrum in all scenarios tested here. Finally, we apply our formalism to real data and demonstrate that it produces results consistent with the standard map-based pseudo-$C_\ell$ formalism. We implement our method in the publicly available code NaMaster.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.19912v1</guid>
      <category>astro-ph.CO</category>
      <category>astro-ph.IM</category>
      <pubDate>Fri, 24 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Thomas Cornish, David Alonso, Boris Leistedt, Kevin Wolz</dc:creator>
    </item>
    <item>
      <title>Eppur non si trovano: Comments on the Primordial Black Hole Limits in the Galactic Halo</title>
      <link>https://arxiv.org/abs/2510.20005</link>
      <description>arXiv:2510.20005v1 Announce Type: cross 
Abstract: In a recent arXiv post, Hawkins &amp; Garcia-Bellido raised doubts on the results of 20-yr long OGLE photometric monitoring, which did not find a large number of gravitational microlensing events in the direction of the Magellanic Clouds. These results implied that primordial black holes and other compact objects with masses from 10^{-8} to 10^3 M_solar cannot comprise a substantial fraction of the Milky Way dark matter halo. Unfortunately, the Hawkins &amp; Garcia-Bellido post contained a number of scientific misrepresentations of our work. Here, we demonstrate that their arguments lack a solid basis or are simply incorrect. As we show below, "and yet they are not found" - compact objects (including primordial black holes) in the dark halo of the Milky Way remain undetected, despite extensive searches.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.20005v1</guid>
      <category>astro-ph.CO</category>
      <category>astro-ph.GA</category>
      <category>astro-ph.IM</category>
      <category>gr-qc</category>
      <pubDate>Fri, 24 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>P. Mr\'oz, A. Udalski, M. K. Szyma\'nski, I. Soszy\'nski, {\L}. Wyrzykowski, P. Pietrukowicz, S. Koz{\l}owski, R. Poleski, J. Skowron, D. Skowron, K. Ulaczyk, M. Gromadzki, K. Rybicki, P. Iwanek, M. Wrona, M. Ratajczak</dc:creator>
    </item>
    <item>
      <title>Comparative Analysis of Thermal Models for Test Masses in Next-Generation Gravitational Wave Interferometers</title>
      <link>https://arxiv.org/abs/2510.20338</link>
      <description>arXiv:2510.20338v1 Announce Type: cross 
Abstract: Accurate thermal modeling of Terminal Test Masses (TTMs) is crucial for optimizing the sensitivity of gravitational wave interferometers like Virgo. In fact, in such gravitational wave detectors even minimal laser power absorption can induce performance-limiting thermal effects. This paper presents a detailed investigation into the steady-state thermal behavior of TTMs. In particular, future scenarios of increased intracavity laser beam power and optical coating absorption are considered. We develop and compare two numerical models: a comprehensive model incorporating volumetric heat absorption in both the multilayer coating and the bulk substrate, and a simplified reduced model where the coating's thermal impact is represented as an effective surface boundary condition on the substrate. Our simulations were focused on a ternary coating design, which is a candidate for use in next-generation detectors. Results reveal that higher coating absorption localizes peak temperatures near the coating--vacuum interface. Importantly, the comparative analysis demonstrates that temperature predictions from the reduced model differ from the detailed model by only milli-Kelvins, a discrepancy often within the experimental uncertainties of the system's thermo-physical parameters. This finding suggests that computationally efficient reduced models can provide sufficiently accurate results for thermal management and first-order distortion analyses. Moreover, the critical role of accurately characterizing the total power absorbed by the coating is emphasized.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.20338v1</guid>
      <category>physics.app-ph</category>
      <category>astro-ph.IM</category>
      <category>gr-qc</category>
      <category>physics.optics</category>
      <pubDate>Fri, 24 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <arxiv:DOI>10.3390/app152010975</arxiv:DOI>
      <arxiv:journal_reference>Applied Sciences Vol. 15, Issue 20, pag. 10975, 2025</arxiv:journal_reference>
      <dc:creator>Vincenzo Pierro, Vincenzo Fiumara, Guerino Avallone, Giovanni Carapella, Francesco Chiadini, Roberta De Simone, Rosalba Fittipaldi, Gerardo Iannone, Alessandro Magalotti, Enrico Silva, Veronica Granata</dc:creator>
    </item>
    <item>
      <title>FAST-SBF: an automatic procedure for the measurement of Surface Brightness Fluctuations for large sky surveys</title>
      <link>https://arxiv.org/abs/2510.20373</link>
      <description>arXiv:2510.20373v1 Announce Type: cross 
Abstract: The Surface Brightness Fluctuation method is one of the most reliable and efficient ways of measuring distances to galaxies within 100 Mpc. While recent implementations have increasingly relied on space-based observations, SBF remains effective when applied to ground-based data. In particular, deep, wide-field imaging surveys with sub-arcsecond seeing conditions allows us for accurate SBF measurements across large samples of galaxies. With the upcoming next generation wide-area imaging surveys, the thousands of galaxies suitable for SBF measurements will give us the opportunity to constrain the 3D structure of the local universe. We present FAST-SBF, a new Python-based pipeline for measuring SBF, developed to support the analysis of large datasets from upcoming wide-field imaging surveys such as LSST, Euclid, and Roman. The procedure, still in the testing and development stage, is designed for automation and minimal user intervention, offering a fast and flexible approach to SBF distance estimation. We validate the performance of the procedure on high-quality imaging data from the Hyper Suprime-Cam Subaru Strategic Program (HSC-SSP), a precursor to LSST, analyzing a sample of both luminous early-type galaxies and fainter dwarfs. Our measurements are also compared with recent results from the Next Generation Virgo Cluster Survey (NGVS) and with the SPoT stellar population synthesis models. The results show excellent agreement with published distances, with the capability of measuring the SBF signal also for faint dwarf galaxies. The pipeline allows the user to completely analyze a galaxy in relatively short time ($\approx$ minutes) and significantly reduces the need for user intervention. reduces at minimum the user intervention. The FAST-SBF tool is planned for public release to support the community in using SBF as a distance indicator in next-generation surveys.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.20373v1</guid>
      <category>astro-ph.GA</category>
      <category>astro-ph.IM</category>
      <pubDate>Fri, 24 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Gabriele Riccio, Michele Cantiello, Rebecca Habas, Nandini Hazra, Giuseppe D'Ago, Gabriella Raimondo, John P. Blakeslee, Joseph B. Jensen, Marco Mirabile, Enzo Brocato, Massimo Brescia, Claudia M. Raiteri</dc:creator>
    </item>
    <item>
      <title>Addressing wavelength-correlated systematics in exoplanet transmission spectroscopy: a 2D Gaussian Process approach</title>
      <link>https://arxiv.org/abs/2510.20423</link>
      <description>arXiv:2510.20423v1 Announce Type: cross 
Abstract: Ground-based transmission spectroscopy is often dominated by systematics, which obstructs our ability to leverage the advantages of larger aperture sizes compared to space-based observations. These systematics could be time-correlated, uniform across all spectroscopic light curves, or wavelength-correlated, which could significantly affect the characterization of exoplanet atmospheres. Gaussian Processes were introduced in transmission spectroscopy by Gibson et al. (2012) to model correlated systematics in a non-parametric way. The technique uses auxiliary information about the observation and independently fits each spectroscopic light curve to provide robust atmospheric retrievals. However, this method assumes that the uncertainties in the transmission spectrum are uncorrelated in wavelength, which can cause discrepancies and degrade the precision of atmospheric retrievals. To address this limitation, we explore a 2D GP framework formulated by Fortune et al. (2024) to simultaneously model time- and wavelength-correlated systematics. We present its application to ground-based observations of TOI-4153b obtained using the 2-m Himalayan Chandra Telescope (HCT). As we move towards detecting smaller and cooler planets, developing new methods to address complex systematics becomes increasingly essential.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.20423v1</guid>
      <category>astro-ph.EP</category>
      <category>astro-ph.IM</category>
      <pubDate>Fri, 24 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <arxiv:DOI>10.1117/12.3063572</arxiv:DOI>
      <dc:creator>Lokesh Manickavasaham, Manjunath Bestha, Sivarani Thirupathi, Arun Surya, Athira Unni</dc:creator>
    </item>
    <item>
      <title>Detection of ultra-high-energy cosmic rays in the southern hemisphere with FAST: data acquisition and preliminary results</title>
      <link>https://arxiv.org/abs/2510.20522</link>
      <description>arXiv:2510.20522v1 Announce Type: cross 
Abstract: Ultra-high-energy cosmic rays (UHECRs) remain one of the greatest mysteries in astroparticle physics. The Fluorescence detector Array of Single-pixel Telescopes (FAST) is a next-generation cosmic ray experiment which utilizes ground-based fluorescence telescopes designed to detect these extremely rare particles at energies exceeding 30 EeV. FAST offers a cost-effective and low-maintenance solution to cover the huge detection areas required for UHECR observation. FAST telescopes are currently installed and remotely operated in both hemispheres, at the Pierre Auger Observatory and the Telescope Array experiment. To enable fully autonomous operation, a sophisticated trigger for data acquisition is essential. In this paper, we present two novel triggering algorithms inspired by those used at the largest observatories, but improved to meet the specific requirements imposed by the FAST design. Their performance is validated using Monte Carlo simulations of extensive air showers and UHECR events detected by the FAST telescope in the southern hemisphere. Finally, we present the sensitivity analysis estimate for FAST.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.20522v1</guid>
      <category>astro-ph.HE</category>
      <category>astro-ph.IM</category>
      <pubDate>Fri, 24 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Jakub Kmec, Petr Boril, Fraser Bradfield, Karel Cerny, Ladislav Chytka, Toshihiro Fujii, Pavel Horvath, Miroslav Hrabovsky, Vlastimil Jilek, Jiri Kvita, Max Malacari, Massimo Mastrodicasa, John N. Matthews, Stanislav Michal, Marcus Niechciol, Libor Nozka, Miroslav Palatka, Miroslav Pech, Paolo Privitera, Francesco Salamida, Shunsuke Sakurai, Petr Schovanek, Radomir Smida, Zuzana Svozilikova, Haruka Tachibana, Akimichi Taketa, Stan B. Thomas, Petr Travnicek, Martin Vacula, Jiri Zahora, Dusan Mandat, Petr Hamal</dc:creator>
    </item>
    <item>
      <title>Are heuristic switches necessary to control artificial viscosity in modern smoothed particle hydrodynamics ?</title>
      <link>https://arxiv.org/abs/2510.20534</link>
      <description>arXiv:2510.20534v1 Announce Type: cross 
Abstract: Artificial viscosity is commonly employed in Smoothed Particle Hydrodynamics (SPH) to model dissipation in hydrodynamic simulations. However, its practical implementation relies on complex numerical switches to restrict its application to regions where dissipation is physically warranted, such as shocks. These switches, while essential, are imperfect and can introduce additional numerical noise. In this work we develop and validate a more efficient artificial viscosity scheme for SPH that does not rely on heuristic switches. Recent studies have proposed that subtracting the linear component of the velocity field can suppress spurious dissipation in shear-dominated regions. Building on this idea, we implement a velocity-reconstruction technique that removes the bulk linear motion from the local velocity field and uses the Balsara correction to modulate the dissipation. The presented methodology yields a balanced dissipation scheme that performs well across a range of regimes, including subsonic instabilities, shear flows, and strong shocks. We demonstrate that this approach yields improved accuracy and lower spurious dissipation compared to conventional artificial viscosity switches</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.20534v1</guid>
      <category>physics.flu-dyn</category>
      <category>astro-ph.IM</category>
      <pubDate>Fri, 24 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <dc:creator>Domingo Garc\'ia-Senz, Rub\'en M. Cabez\'on</dc:creator>
    </item>
    <item>
      <title>High-Resolution Echelle Spectroscopy for Solar System Planets: A Planet-as-Point-Source Analogy</title>
      <link>https://arxiv.org/abs/2510.20559</link>
      <description>arXiv:2510.20559v1 Announce Type: cross 
Abstract: Transmission spectroscopy has proven to be an effective technique for characterizing exoplanet atmospheres. However, transmission spectroscopy requires planetary transits, which occur for only a small fraction of planetary systems due to geometric alignment constraints; hence, characterizing exoplanets through their reflected spectrum of host stars will be helpful for a large number of exoplanets. The upcoming extremely large telescopes (ELTs) will be able to study the reflected spectra of exoplanets. Here, we present a preliminary optical design and a detailed throughput analysis of the instrumentation that interfaces the 2.34 m Vainu Bappu Telescope prime focus to an existing high-resolution echelle spectrograph with disk-integrated light from solar system objects. One of the primary objectives is to obtain high-resolution, high signal-to-noise reflected spectra from the solar system objects.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.20559v1</guid>
      <category>astro-ph.EP</category>
      <category>astro-ph.IM</category>
      <pubDate>Fri, 24 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <arxiv:DOI>10.1117/12.3064459</arxiv:DOI>
      <dc:creator>Parvathy Menon, Sivarani T, Sriram S, Manjunath Bestha, Devika K Divakar, Rajaguru S P, Arun Surya</dc:creator>
    </item>
    <item>
      <title>Strong Lensing Model and Dust Extinction Maps of the Host Galaxy of Type Ia Supernova H0pe</title>
      <link>https://arxiv.org/abs/2510.20561</link>
      <description>arXiv:2510.20561v1 Announce Type: cross 
Abstract: Strong gravitational lensing by massive galaxy clusters offers particularly rare opportunities to observe multiple images of distant ($z\gtrsim2$) Type Ia supernovae (SNe) and resolve the properties of their host galaxies. A recent outstanding example is the Type Ia SN "H0pe" ($z=1.78$), discovered in James Webb Space Telescope (JWST) NIRCam images when it was still triply imaged by the galaxy cluster PLCK G165.7+67.0 (G165, $z=0.35$). In this work we build a new strong lensing model of G165, first by using only the position of multiple images of background galaxies. We then increase significantly the number of constraints around the position of SN H0pe by modeling the extended surface brightness of the SN host galaxy. The average uncertainty on mass model parameters is reduced by more than an order of magnitude. We also study the spatial distribution of dust in the arc to estimate the dust extinction at the position of SN H0pe. We find good statistical agreement of the extinction estimate at $\lesssim1\sigma$ with three fully independent methods based on spectral energy distribution fitting. Moreover, our extended-image lens model of G165 allows us to map the dust distribution of the host galaxy from the image plane to the source plane. Supernova H0pe exploded in a region with a relatively high extinction of $A_V \approx 0.9\ {\rm mag}$ at around $\sim 1\ {\rm kpc}$ from its host center. This work shows that extended image modeling in lensing clusters simultaneously reduces the uncertainty on lens model parameters and enables spatially resolved analyses of lensed transients host galaxies. Such modeling advances are expected to play an important role in future cosmological analyses using strongly lensed SNe.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.20561v1</guid>
      <category>astro-ph.GA</category>
      <category>astro-ph.CO</category>
      <category>astro-ph.IM</category>
      <pubDate>Fri, 24 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>A. Galan, S. Schuldt, G. B. Caminha, S. H. Suyu, R. Ca\~nameras, S. Ertl, C. Grillo, A. Acebron, B. Frye, A. M. Koekemoer, R. Windhorst, J. M. Diego, N. Foo</dc:creator>
    </item>
    <item>
      <title>Iskay2: Signal Extraction of the Kinematic Sunyaev-Zel'dovich Effect Through The Pairwise Estimator. Pipeline and Validation</title>
      <link>https://arxiv.org/abs/2510.20715</link>
      <description>arXiv:2510.20715v1 Announce Type: cross 
Abstract: The peculiar motions of massive halos probe the distribution of matter in the universe, the gravitational potential, and the history of cosmic structure growth. The kinematic Sunyaev-Zeldovich (kSZ) effect offers a robust observational window into these properties. The pairwise kSZ estimator probes the pairwise momentum of groups of galaxies by cross-correlating cosmic microwave background (CMB) maps with spectroscopic galaxy catalogs, using galaxies to trace the positions of dark matter halos. This note introduces iskay2, an efficient pipeline designed to apply the pairwise kSZ estimator to maps of the CMB and large galaxy catalogs. Pairwise kSZ measurements obtained using this pipeline are compared to previously published results and are shown to be consistent within statistical expectations. This pipeline will enable high-precision measurements of the pairwise kSZ utilizing galaxy catalogs like DESI combined with past, current and next-generation high-resolution CMB experiments such as ACT, SPT and the Simons Observatory.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.20715v1</guid>
      <category>astro-ph.CO</category>
      <category>astro-ph.IM</category>
      <pubDate>Fri, 24 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Patricio A. Gallardo, Yulin Gong, Boryana Hadzhiyska, Yun-Hsin Hsu</dc:creator>
    </item>
    <item>
      <title>Roman Observations Time Allocation Committee: Final Report and Recommendations</title>
      <link>https://arxiv.org/abs/2505.10574</link>
      <description>arXiv:2505.10574v2 Announce Type: replace 
Abstract: The Nancy Grace Roman Space Telescope is poised to revolutionize our scientific understanding of exoplanets, dark matter, dark energy, and general astrophysics, including through an innovative community approach to defining and executing sky surveys. The Roman Observations Time Allocation Committee (ROTAC) was convened to recommend time allocations for the three Core Community Surveys (CCS) using the Wide Field Instrument (WFI): the High Latitude Wide Area Survey, the High Latitude Time Domain Survey, and the Galactic Bulge Time Domain Survey, as well as balance the time allocation for the General Astrophysics Surveys. Each CCS had a corresponding Definition Committee that collected community input and designed proposals for a nominal (in-guide) survey, as well as underguide and overguide options with smaller and larger time allocations, respectively. These options explored different ways of fulfilling the mission science requirements while maximizing general astrophysics science goals enabled by the surveys. In this report, the ROTAC lays out its recommendations for the three CCS observing designs and the WFI time allotment for CCS (74.5%) and the General Astrophysics Surveys (25.5%).</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.10574v2</guid>
      <category>astro-ph.IM</category>
      <category>astro-ph.CO</category>
      <category>astro-ph.EP</category>
      <category>astro-ph.GA</category>
      <category>astro-ph.HE</category>
      <category>astro-ph.SR</category>
      <pubDate>Fri, 24 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <dc:creator>Gail Zasowski, Saurabh W. Jha, Laura Chomiuk, Xiaohui Fan, Ryan Hickox, Dan Huber, Eamonn Kerins, Chip Kobulnicky, Tod Lauer, Masao Sako, Alice Shapley, Denise Stephens, David Weinberg, Ben Williams</dc:creator>
    </item>
    <item>
      <title>Tracking electron capture processes in classical molecular dynamics simulations for spectral line broadening in plasmas</title>
      <link>https://arxiv.org/abs/2502.04808</link>
      <description>arXiv:2502.04808v2 Announce Type: replace-cross 
Abstract: Plasma spectroscopy is a fundamental tool for diagnosing laboratory and astrophysical plasmas. Accurate interpretation of spectra depends upon precise modeling and comprehension of Stark broadening and other mechanisms affecting spectral lines. In this context, computer simulations have emerged as valuable tools, offering idealized experiments with well-defined conditions. Molecular dynamics simulations, in particular, excel at replicating the particle interactions within the plasma and their impact on the state of a radiating atom or ion. However, these simulations present challenges in tracking electron capture processes, since setting an unambiguous criterion to distinguish between bound and free electrons is not trivial. In this paper we introduce a new algorithm that, within a classical framework, precisely identifies the scenario in which an electron is captured by an ion and then follows a stable orbit around it. The algorithm's applicability extends to emitters with charges Z &gt;= 1. The procedure enables the correct identification of valid time-histories of the electric microfield perturbing the emitting ion, which will be used for subsequent line shape calculations. The ionization balance results obtained from the application of this algorithm are compared with an additional method based on the potential energy of the particles in the simulations, finding good agreement, therefore validating the use of this approach.</description>
      <guid isPermaLink="false">oai:arXiv.org:2502.04808v2</guid>
      <category>physics.plasm-ph</category>
      <category>astro-ph.IM</category>
      <category>physics.atom-ph</category>
      <category>physics.comp-ph</category>
      <category>physics.optics</category>
      <pubDate>Fri, 24 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>D. Gonz\'alez-Herrero, G. P\'erez-Callejo, R. Florido, M. A. Gigosos</dc:creator>
    </item>
    <item>
      <title>DIPLI: Deep Image Prior Lucky Imaging for Blind Astronomical Image Restoration</title>
      <link>https://arxiv.org/abs/2503.15984</link>
      <description>arXiv:2503.15984v2 Announce Type: replace-cross 
Abstract: Modern image restoration and super-resolution methods utilize deep learning due to its superior performance compared to traditional algorithms. However, deep learning typically requires large training datasets, which are rarely available in astrophotography. Deep Image Prior (DIP) bypasses this constraint by performing blind training on a single image. Although effective in some cases, DIP often suffers from overfitting, artifact generation, and instability. To overcome these issues and improve general performance, this work proposes DIPLI - a framework that shifts from single-frame to multi-frame training using the Back Projection technique, combined with optical flow estimation via the TVNet model, and replaces deterministic predictions with unbiased Monte Carlo estimation obtained through Langevin dynamics. A comprehensive evaluation compares the method against Lucky Imaging, a classical computer vision technique still widely used in astronomical image reconstruction, DIP, the transformer-based model RVRT, and the diffusion-based model DiffIR2VR-Zero. Experiments on synthetic datasets demonstrate consistent improvements, with the method outperforming baselines for SSIM, PSNR, LPIPS, and DISTS metrics in the majority of cases. In addition to superior reconstruction quality, the model also requires far fewer input images than Lucky Imaging and is less prone to overfitting or artifact generation. Evaluation on real-world astronomical data, where domain shifts typically hinder generalization, shows that the method maintains high reconstruction quality, confirming practical robustness.</description>
      <guid isPermaLink="false">oai:arXiv.org:2503.15984v2</guid>
      <category>cs.CV</category>
      <category>astro-ph.IM</category>
      <category>cs.AI</category>
      <category>eess.IV</category>
      <pubDate>Fri, 24 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <dc:creator>Suraj Singh, Anastasia Batsheva, Oleg Y. Rogov, Ahmed Bouridane</dc:creator>
    </item>
    <item>
      <title>Microlensing optical depth, event rate, and limits on compact objects in dark matter based on 20 yr of OGLE observations of the Small Magellanic Cloud</title>
      <link>https://arxiv.org/abs/2507.13794</link>
      <description>arXiv:2507.13794v2 Announce Type: replace-cross 
Abstract: Some previous studies have suggested that massive and intermediate-mass primordial black holes (PBHs) could comprise a substantial fraction of dark matter in the Universe. Such black holes, if they existed in the Milky Way halo, would give rise to long-duration microlensing events that may potentially last for years. However, earlier searches were not sufficiently sensitive to detect such events. Here, we present the results of searches for long-timescale gravitational microlensing events toward the Small Magellanic Cloud (SMC) using nearly 20 years of photometric observations collected by the Optical Gravitational Lensing Experiment (OGLE) from 2001 to 2020. We found six events, three of which are new discoveries. We use a sample of five events to measure the microlensing optical depth toward the SMC $\tau = (0.32 \pm 0.18) \times 10^{-7}$ and the event rate $\Gamma = (1.18 \pm 0.57) \times 10^{-7}\,\mathrm{yr}^{-1}\,\mathrm{star}^{-1}$. The properties of the detected events are consistent with lenses originating from known stellar populations within the SMC or in the Milky Way disk. No events with timescales longer than 1 yr were detected, which provides competitive limits on the fraction of massive compact objects, including PBHs, in the Milky Way dark matter halo. Together with the earlier OGLE studies of microlensing events in the direction of the Large Magellanic Cloud, these observations rule out PBHs and other compact objects with masses ranging from $10^{-8}$ to $10^3\,M_{\odot}$ as dominant components of dark matter.</description>
      <guid isPermaLink="false">oai:arXiv.org:2507.13794v2</guid>
      <category>astro-ph.GA</category>
      <category>astro-ph.CO</category>
      <category>astro-ph.IM</category>
      <category>gr-qc</category>
      <category>hep-ex</category>
      <pubDate>Fri, 24 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <arxiv:DOI>10.3847/1538-4365/adf842</arxiv:DOI>
      <arxiv:journal_reference>ApJS 280, 49 (2025)</arxiv:journal_reference>
      <dc:creator>P. Mr\'oz, A. Udalski, M. K. Szyma\'nski, I. Soszy\'nski, P. Pietrukowicz, S. Koz{\l}owski, R. Poleski, J. Skowron, D. Skowron, K. Ulaczyk, M. Gromadzki, K. Rybicki, P. Iwanek, M. Wrona, M. Ratajczak</dc:creator>
    </item>
  </channel>
</rss>
