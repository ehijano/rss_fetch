<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>cs.CC updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/cs.CC</link>
    <description>cs.CC updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/cs.CC" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Fri, 07 Jun 2024 04:00:01 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Fri, 07 Jun 2024 00:00:00 -0400</pubDate>
    <skipDays>
      <day>Sunday</day>
      <day>Saturday</day>
    </skipDays>
    <item>
      <title>ActionReasoningBench: Reasoning about Actions with and without Ramification Constraints</title>
      <link>https://arxiv.org/abs/2406.04046</link>
      <description>arXiv:2406.04046v1 Announce Type: new 
Abstract: Reasoning about actions and change (RAC) has historically driven the development of many early AI challenges, such as the frame problem, and many AI disciplines, including non-monotonic and commonsense reasoning. The role of RAC remains important even now, particularly for tasks involving dynamic environments, interactive scenarios, and commonsense reasoning. Despite the progress of Large Language Models (LLMs) in various AI domains, their performance on RAC is underexplored. To address this gap, we introduce a new benchmark, ActionReasoningBench, encompassing 13 domains and rigorously evaluating LLMs across eight different areas of RAC. These include - Object Tracking, Fluent Tracking, State Tracking, Action Executability, Effects of Actions, Numerical RAC, Hallucination Detection, and Composite Questions. Furthermore, we also investigate the indirect effect of actions due to ramification constraints for every domain. Finally, we evaluate our benchmark using open-sourced and commercial state-of-the-art LLMs, including GPT-4o, Gemini-1.0-Pro, Llama2-7b-chat, Llama2-13b-chat, Llama3-8b-instruct, Gemma-2b-instruct, and Gemma-7b-instruct. Our findings indicate that these models face significant challenges across all categories included in our benchmark.</description>
      <guid isPermaLink="false">oai:arXiv.org:2406.04046v1</guid>
      <category>cs.CC</category>
      <category>cs.AI</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Divij Handa, Pavel Dolin, Shrinidhi Kumbhar, Chitta Baral, Tran Cao Son</dc:creator>
    </item>
    <item>
      <title>Punctured Low-Bias Codes Behave Like Random Linear Codes</title>
      <link>https://arxiv.org/abs/2109.11725</link>
      <description>arXiv:2109.11725v5 Announce Type: replace 
Abstract: Random linear codes are a workhorse in coding theory, and are used to show the existence of codes with the best known or even near-optimal trade-offs in many noise models. However, they have little structure besides linearity, and are not amenable to tractable error-correction algorithms.
  In this work, we prove a general derandomization result applicable to random linear codes. Namely, in settings where the coding-theoretic property of interest is "local" (in the sense of forbidding certain bad configurations involving few vectors -- code distance and list-decodability being notable examples), one can replace random linear codes (RLCs) with a significantly derandomized variant with essentially no loss in parameters. Specifically, instead of randomly sampling coordinates of the (long) Hadamard code (which is an equivalent way to describe RLCs), one can randomly sample coordinates of any code with low bias. Over large alphabets, the low bias requirement can be weakened to just large distance. Furthermore, large distance suffices even with a small alphabet in order to match the current best known bounds for RLC list-decodability.
  In particular, by virtue of our result, all current (and future) achievability bounds for list-decodability of random linear codes extend automatically to random puncturings of any low-bias (or large alphabet) "mother" code. We also show that our punctured codes emulate the behavior of RLCs on stochastic channels, thus giving a derandomization of RLCs in the context of achieving Shannon capacity as well. Thus, we have a randomness-efficient way to sample codes achieving capacity in both worst-case and stochastic settings that can further inherit algebraic or other algorithmically useful structural properties of the mother code.</description>
      <guid isPermaLink="false">oai:arXiv.org:2109.11725v5</guid>
      <category>cs.CC</category>
      <category>cs.IT</category>
      <category>math.CO</category>
      <category>math.IT</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Venkatesan Guruswami, Jonathan Mosheiff</dc:creator>
    </item>
    <item>
      <title>Knapsack with Vertex Cover, Set Cover, and Hitting Set</title>
      <link>https://arxiv.org/abs/2406.01057</link>
      <description>arXiv:2406.01057v2 Announce Type: replace-cross 
Abstract: Given an undirected graph $\GG=(\VV,\EE)$, with vertex weights $(w(u))_{u\in\VV}$, vertex values $(\alpha(u))_{u\in\VV}$, a knapsack size $s$, and a target value $d$, the \vcknapsack problem is to determine if there exists a subset $\UU\subseteq\VV$ of vertices such that \UU forms a vertex cover, $w(\UU)=\sum_{u\in\UU} w(u) \le s$, and $\alpha(\UU)=\sum_{u\in\UU} \alpha(u) \ge d$. In this paper, we closely study the \vcknapsack problem and its variations, such as \vcknapsackbudget, \minimalvcknapsack, and \minimumvcknapsack, for both general graphs and trees. We first prove that the \vcknapsack problem belongs to the complexity class \NPC and then study the complexity of the other variations. We generalize the problem to \setc and \hs versions and design polynomial time $H_g$-factor approximation algorithm for the \setckp problem and d-factor approximation algorithm for \hstp using primal dual method. We further show that \setcks and \hsmb are hard to approximate in polynomial time. Additionally, we develop a fixed parameter tractable algorithm running in time $8^{\OO(\tw)}\cdot n\cdot {\sf min}\{s,d\}$ where $\tw,s,d,n$ are respectively treewidth of the graph, the size of the knapsack, the target value of the knapsack, and the number of items for the \minimalvcknapsack problem.</description>
      <guid isPermaLink="false">oai:arXiv.org:2406.01057v2</guid>
      <category>cs.DS</category>
      <category>cs.CC</category>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Palash Dey, Ashlesha Hota, Sudeshna Kolay, Sipra Singh</dc:creator>
    </item>
  </channel>
</rss>
