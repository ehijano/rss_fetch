<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>q-bio.NC updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/q-bio.NC</link>
    <description>q-bio.NC updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/q-bio.NC" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Thu, 05 Sep 2024 04:00:22 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Thu, 05 Sep 2024 00:00:00 -0400</pubDate>
    <skipDays>
      <day>Sunday</day>
      <day>Saturday</day>
    </skipDays>
    <item>
      <title>What makes a face looks like a hat: Decoupling low-level and high-level Visual Properties with Image Triplets</title>
      <link>https://arxiv.org/abs/2409.02241</link>
      <description>arXiv:2409.02241v1 Announce Type: new 
Abstract: In visual decision making, high-level features, such as object categories, have a strong influence on choice. However, the impact of low-level features on behavior is less understood partly due to the high correlation between high- and low-level features in the stimuli presented (e.g., objects of the same category are more likely to share low-level features). To disentangle these effects, we propose a method that de-correlates low- and high-level visual properties in a novel set of stimuli. Our method uses two Convolutional Neural Networks (CNNs) as candidate models of the ventral visual stream: the CORnet-S that has high neural predictivity in high-level, IT-like responses and the VGG-16 that has high neural predictivity in low-level responses. Triplets (root, image1, image2) of stimuli are parametrized by the level of low- and high-level similarity of images extracted from the different layers. These stimuli are then used in a decision-making task where participants are tasked to choose the most similar-to-the-root image. We found that different networks show differing abilities to predict the effects of low-versus-high-level similarity: while CORnet-S outperforms VGG-16 in explaining human choices based on high-level similarity, VGG-16 outperforms CORnet-S in explaining human choices based on low-level similarity. Using Brain-Score, we observed that the behavioral prediction abilities of different layers of these networks qualitatively corresponded to their ability to explain neural activity at different levels of the visual hierarchy. In summary, our algorithm for stimulus set generation enables the study of how different representations in the visual stream affect high-level cognitive behaviors.</description>
      <guid isPermaLink="false">oai:arXiv.org:2409.02241v1</guid>
      <category>q-bio.NC</category>
      <category>cs.CV</category>
      <pubDate>Thu, 05 Sep 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Maytus Piriyajitakonkij, Sirawaj Itthipuripat, Ian Ballard, Ioannis Pappas</dc:creator>
    </item>
    <item>
      <title>Fibration symmetry-breaking supports functional transitions in a brain network engaged in language</title>
      <link>https://arxiv.org/abs/2409.02674</link>
      <description>arXiv:2409.02674v1 Announce Type: new 
Abstract: In his book 'A Beautiful Question', physicist Frank Wilczek argues that symmetry is 'nature's deep design,' governing the behavior of the universe, from the smallest particles to the largest structures. While symmetry is a cornerstone of physics, it has not yet been found widespread applicability to describe biological systems, particularly the human brain. In this context, we study the human brain network engaged in language and explore the relationship between the structural connectivity (connectome or structural network) and the emergent synchronization of the mesoscopic regions of interest (functional network). We explain this relationship through a different kind of symmetry than physical symmetry, derived from the categorical notion of Grothendieck fibrations. This introduces a new understanding of the human brain by proposing a local symmetry theory of the connectome, which accounts for how the structure of the brain's network determines its coherent activity. Among the allowed patterns of structural connectivity, synchronization elicits different symmetry subsets according to the functional engagement of the brain. We show that the resting state is a particular realization of the cerebral synchronization pattern characterized by a fibration symmetry that is broken in the transition from rest to language. Our findings suggest that the brain's network symmetry at the local level determines its coherent function, and we can understand this relationship from theoretical principles.</description>
      <guid isPermaLink="false">oai:arXiv.org:2409.02674v1</guid>
      <category>q-bio.NC</category>
      <category>physics.app-ph</category>
      <pubDate>Thu, 05 Sep 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Tommaso Gili, Bryant Avila, Luca Pasquini, Andrei Holodny, David Phillips, Paolo Boldi, Andrea Gabrielli, Guido Caldarelli, Manuel Zimmer, Hern\'an A. Makse</dc:creator>
    </item>
    <item>
      <title>Symmetries and synchronization from whole-neural activity in {\it C. elegans} connectome: Integration of functional and structural networks</title>
      <link>https://arxiv.org/abs/2409.02682</link>
      <description>arXiv:2409.02682v1 Announce Type: new 
Abstract: Understanding the dynamical behavior of complex systems from their underlying network architectures is a long-standing question in complexity theory. Therefore, many metrics have been devised to extract network features like motifs, centrality, and modularity measures. It has previously been proposed that network symmetries are of particular importance since they are expected to underly the synchronization of a system's units, which is ubiquitously observed in nervous system activity patterns. However, perfectly symmetrical structures are difficult to assess in noisy measurements of biological systems, like neuronal connectomes. Here, we devise a principled method to infer network symmetries from combined connectome and neuronal activity data. Using nervous system-wide population activity recordings of the \textit{C.elegans} backward locomotor system, we infer structures in the connectome called fibration symmetries, which can explain which group of neurons synchronize their activity. Our analysis suggests functional building blocks in the animal's motor periphery, providing new testable hypotheses on how descending interneuron circuits communicate with the motor periphery to control behavior. Our approach opens a new door to exploring the structure-function relations in other complex systems, like the nervous systems of larger animals.</description>
      <guid isPermaLink="false">oai:arXiv.org:2409.02682v1</guid>
      <category>q-bio.NC</category>
      <category>physics.app-ph</category>
      <pubDate>Thu, 05 Sep 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Bryant Avila, Pedro Augusto, David Phillips, Tommaso Gili, Manuel Zimmer, Hern\'an A. Makse</dc:creator>
    </item>
    <item>
      <title>Neural timescales from a computational perspective</title>
      <link>https://arxiv.org/abs/2409.02684</link>
      <description>arXiv:2409.02684v1 Announce Type: new 
Abstract: Timescales of neural activity are diverse across and within brain areas, and experimental observations suggest that neural timescales reflect information in dynamic environments. However, these observations do not specify how neural timescales are shaped, nor whether particular timescales are necessary for neural computations and brain function. Here, we take a complementary perspective and synthesize three directions where computational methods can distill the broad set of empirical observations into quantitative and testable theories: We review (i) how data analysis methods allow us to capture different timescales of neural dynamics across different recording modalities, (ii) how computational models provide a mechanistic explanation for the emergence of diverse timescales, and (iii) how task-optimized models in machine learning uncover the functional relevance of neural timescales. This integrative computational approach, combined with empirical findings, would provide a more holistic understanding of how neural timescales capture the relationship between brain structure, dynamics, and behavior.</description>
      <guid isPermaLink="false">oai:arXiv.org:2409.02684v1</guid>
      <category>q-bio.NC</category>
      <category>cs.LG</category>
      <category>stat.ML</category>
      <pubDate>Thu, 05 Sep 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Roxana Zeraati, Anna Levina, Jakob H. Macke, Richard Gao</dc:creator>
    </item>
    <item>
      <title>How does the brain compute with probabilities?</title>
      <link>https://arxiv.org/abs/2409.02709</link>
      <description>arXiv:2409.02709v1 Announce Type: new 
Abstract: This perspective piece is the result of a Generative Adversarial Collaboration (GAC) tackling the question `How does neural activity represent probability distributions?'. We have addressed three major obstacles to progress on answering this question: first, we provide a unified language for defining competing hypotheses. Second, we explain the fundamentals of three prominent proposals for probabilistic computations -- Probabilistic Population Codes (PPCs), Distributed Distributional Codes (DDCs), and Neural Sampling Codes (NSCs) -- and describe similarities and differences in that common language. Third, we review key empirical data previously taken as evidence for at least one of these proposal, and describe how it may or may not be explainable by alternative proposals. Finally, we describe some key challenges in resolving the debate, and propose potential directions to address them through a combination of theory and experiments.</description>
      <guid isPermaLink="false">oai:arXiv.org:2409.02709v1</guid>
      <category>q-bio.NC</category>
      <category>cs.LG</category>
      <pubDate>Thu, 05 Sep 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Ralf M. Haefner, Jeff Beck, Cristina Savin, Mehrdad Salmasi, Xaq Pitkow</dc:creator>
    </item>
    <item>
      <title>A Lesion-aware Edge-based Graph Neural Network for Predicting Language Ability in Patients with Post-stroke Aphasia</title>
      <link>https://arxiv.org/abs/2409.02303</link>
      <description>arXiv:2409.02303v1 Announce Type: cross 
Abstract: We propose a lesion-aware graph neural network (LEGNet) to predict language ability from resting-state fMRI (rs-fMRI) connectivity in patients with post-stroke aphasia. Our model integrates three components: an edge-based learning module that encodes functional connectivity between brain regions, a lesion encoding module, and a subgraph learning module that leverages functional similarities for prediction. We use synthetic data derived from the Human Connectome Project (HCP) for hyperparameter tuning and model pretraining. We then evaluate the performance using repeated 10-fold cross-validation on an in-house neuroimaging dataset of post-stroke aphasia. Our results demonstrate that LEGNet outperforms baseline deep learning methods in predicting language ability. LEGNet also exhibits superior generalization ability when tested on a second in-house dataset that was acquired under a slightly different neuroimaging protocol. Taken together, the results of this study highlight the potential of LEGNet in effectively learning the relationships between rs-fMRI connectivity and language ability in a patient cohort with brain lesions for improved post-stroke aphasia evaluation.</description>
      <guid isPermaLink="false">oai:arXiv.org:2409.02303v1</guid>
      <category>cs.LG</category>
      <category>eess.SP</category>
      <category>q-bio.NC</category>
      <pubDate>Thu, 05 Sep 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Zijian Chen, Maria Varkanitsa, Prakash Ishwar, Janusz Konrad, Margrit Betke, Swathi Kiran, Archana Venkataraman</dc:creator>
    </item>
    <item>
      <title>Neural Dynamics Model of Visual Decision-Making: Learning from Human Experts</title>
      <link>https://arxiv.org/abs/2409.02390</link>
      <description>arXiv:2409.02390v1 Announce Type: cross 
Abstract: Uncovering the fundamental neural correlates of biological intelligence, developing mathematical models, and conducting computational simulations are critical for advancing new paradigms in artificial intelligence (AI). In this study, we implemented a comprehensive visual decision-making model that spans from visual input to behavioral output, using a neural dynamics modeling approach. Drawing inspiration from the key components of the dorsal visual pathway in primates, our model not only aligns closely with human behavior but also reflects neural activities in primates, and achieving accuracy comparable to convolutional neural networks (CNNs). Moreover, magnetic resonance imaging (MRI) identified key neuroimaging features such as structural connections and functional connectivity that are associated with performance in perceptual decision-making tasks. A neuroimaging-informed fine-tuning approach was introduced and applied to the model, leading to performance improvements that paralleled the behavioral variations observed among subjects. Compared to classical deep learning models, our model more accurately replicates the behavioral performance of biological intelligence, relying on the structural characteristics of biological neural networks rather than extensive training data, and demonstrating enhanced resilience to perturbation.</description>
      <guid isPermaLink="false">oai:arXiv.org:2409.02390v1</guid>
      <category>cs.NE</category>
      <category>cs.AI</category>
      <category>cs.CV</category>
      <category>q-bio.NC</category>
      <pubDate>Thu, 05 Sep 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Jie Su, Fang Cai, Shu-Kuo Zhao, Xin-Yi Wang, Tian-Yi Qian, Da-Hui Wang, Bo Hong</dc:creator>
    </item>
  </channel>
</rss>
