<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>cs.GT updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/cs.GT</link>
    <description>cs.GT updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/cs.GT" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Fri, 11 Oct 2024 02:24:31 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Thu, 10 Oct 2024 00:00:00 -0400</pubDate>
    <skipDays>
      <day>Sunday</day>
      <day>Saturday</day>
    </skipDays>
    <item>
      <title>Information Design with Unknown Prior</title>
      <link>https://arxiv.org/abs/2410.05533</link>
      <description>arXiv:2410.05533v1 Announce Type: new 
Abstract: Classical information design models (e.g., Bayesian persuasion and cheap talk) require players to have perfect knowledge of the prior distribution of the state of the world. Our paper studies repeated persuasion problems in which the information designer does not know the prior. The information designer learns to design signaling schemes from repeated interactions with the receiver. We design learning algorithms for the information designer to achieve no regret compared to using the optimal signaling scheme with known prior, under two models of the receiver's decision-making. (1) The first model assumes that the receiver knows the prior and can perform posterior update and best respond to signals. In this model, we design a learning algorithm for the information designer with $O(\log T)$ regret in the general case, and another algorithm with $\Theta(\log \log T)$ regret in the case where the receiver has only two actions. (2) The second model assumes that the receiver does not know the prior and employs a no-regret learning algorithm to take actions. We show that the information designer can achieve regret $O(\sqrt{\mathrm{rReg}(T) T})$, where $\mathrm{rReg}(T)=o(T)$ is an upper bound on the receiver's learning regret. Our work thus provides a learning foundation for the problem of information design with unknown prior.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.05533v1</guid>
      <category>cs.GT</category>
      <category>cs.DS</category>
      <category>cs.LG</category>
      <category>econ.TH</category>
      <pubDate>Thu, 10 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Tao Lin, Ce Li</dc:creator>
    </item>
    <item>
      <title>Aggregating Quantitative Relative Judgments: From Social Choice to Ranking Prediction</title>
      <link>https://arxiv.org/abs/2410.05550</link>
      <description>arXiv:2410.05550v1 Announce Type: new 
Abstract: Quantitative Relative Judgment Aggregation (QRJA) is a new research topic in (computational) social choice. In the QRJA model, agents provide judgments on the relative quality of different candidates, and the goal is to aggregate these judgments across all agents. In this work, our main conceptual contribution is to explore the interplay between QRJA in a social choice context and its application to ranking prediction. We observe that in QRJA, judges do not have to be people with subjective opinions; for example, a race can be viewed as a "judgment" on the contestants' relative abilities. This allows us to aggregate results from multiple races to evaluate the contestants' true qualities. At a technical level, we introduce new aggregation rules for QRJA and study their structural and computational properties. We evaluate the proposed methods on data from various real races and show that QRJA-based methods offer effective and interpretable ranking predictions.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.05550v1</guid>
      <category>cs.GT</category>
      <pubDate>Thu, 10 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Yixuan Even Xu, Hanrui Zhang, Yu Cheng, Vincent Conitzer</dc:creator>
    </item>
    <item>
      <title>Learning Equilibria in Adversarial Team Markov Games: A Nonconvex-Hidden-Concave Min-Max Optimization Problem</title>
      <link>https://arxiv.org/abs/2410.05673</link>
      <description>arXiv:2410.05673v1 Announce Type: new 
Abstract: We study the problem of learning a Nash equilibrium (NE) in Markov games which is a cornerstone in multi-agent reinforcement learning (MARL). In particular, we focus on infinite-horizon adversarial team Markov games (ATMGs) in which agents that share a common reward function compete against a single opponent, the adversary. These games unify two-player zero-sum Markov games and Markov potential games, resulting in a setting that encompasses both collaboration and competition. Kalogiannis et al. (2023a) provided an efficient equilibrium computation algorithm for ATMGs which presumes knowledge of the reward and transition functions and has no sample complexity guarantees. We contribute a learning algorithm that utilizes MARL policy gradient methods with iteration and sample complexity that is polynomial in the approximation error $\epsilon$ and the natural parameters of the ATMG, resolving the main caveats of the solution by (Kalogiannis et al., 2023a). It is worth noting that previously, the existence of learning algorithms for NE was known for Markov two-player zero-sum and potential games but not for ATMGs.
  Seen through the lens of min-max optimization, computing a NE in these games consists a nonconvex-nonconcave saddle-point problem. Min-max optimization has received extensive study. Nevertheless, the case of nonconvex-nonconcave landscapes remains elusive: in full generality, finding saddle-points is computationally intractable (Daskalakis et al., 2021). We circumvent the aforementioned intractability by developing techniques that exploit the hidden structure of the objective function via a nonconvex-concave reformulation. However, this introduces the challenge of a feasibility set with coupled constraints. We tackle these challenges by establishing novel techniques for optimizing weakly-smooth nonconvex functions, extending the framework of (Devolder et al., 2014).</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.05673v1</guid>
      <category>cs.GT</category>
      <pubDate>Thu, 10 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Fivos Kalogiannis, Jingming Yan, Ioannis Panageas</dc:creator>
    </item>
    <item>
      <title>The Cyber Alliance Game: How Alliances Influence Cyber-Warfare</title>
      <link>https://arxiv.org/abs/2410.05953</link>
      <description>arXiv:2410.05953v1 Announce Type: new 
Abstract: Cyber-warfare has become the norm in current ongoing military conflicts. Over the past decade, numerous examples have shown the extent to which nation-states become vulnerable if they do not focus on building their cyber capacities. Adding to the inherent complexity of cyberwar scenarios, a state is usually a member of one or more alliances. Alliance policies and internal struggles could shape the individual actions of member states; intuitively, this also holds for the cyber domain.
  In this paper, we define and study a simple Cyber Alliance Game with the objective of understanding the fundamental influence of alliances on cyber conflicts between nation-states. Specifically, we focus on the decision of whether to exploit a newly found vulnerability individually or share it with the alliance. First, we characterize the impact of vulnerability-sharing rewards on the resulting equilibrium. Second, we study the implications of the internal power structure of alliances on cyberwar outcomes and infer the expected behavior of Dictator, Veto, and Dummy players. Finally, we investigate how alliances can nudge their members via rewards and punishments to adhere to their defensive or offensive cyber policy. We believe that our results contribute to the fundamental understanding of real-world cyber-conflicts by characterizing the impact of alliances.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.05953v1</guid>
      <category>cs.GT</category>
      <category>cs.CR</category>
      <pubDate>Thu, 10 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Gergely Benk\H{o}, Gergely Bicz\'ok</dc:creator>
    </item>
    <item>
      <title>Packing a Knapsack with Items Owned by Strategic Agents</title>
      <link>https://arxiv.org/abs/2410.06080</link>
      <description>arXiv:2410.06080v1 Announce Type: new 
Abstract: This paper considers a scenario within the field of mechanism design without money where a mechanism designer is interested in selecting items with maximum total value under a knapsack constraint. The items, however, are controlled by strategic agents who aim to maximize the total value of their items in the knapsack. This is a natural setting, e.g., when agencies select projects for funding, companies select products for sale in their shops, or hospitals schedule MRI scans for the day. A mechanism governing the packing of the knapsack is strategyproof if no agent can benefit from hiding items controlled by them to the mechanism. We are interested in mechanisms that are strategyproof and $\alpha$-approximate in the sense that they always approximate the maximum value of the knapsack by a factor of $\alpha \in [0,1]$. First, we give a deterministic mechanism that is $\frac{1}{3}$-approximate. For the special case where all items have unit density, we design a $\frac{1}{\phi}$-approximate mechanism where $1/\phi \approx 0.618$ is the inverse of the golden ratio. This result is tight as we show that no deterministic strategyproof mechanism with a better approximation exists. We further give randomized mechanisms with approximation guarantees of $1/2$ for the general case and $2/3$ for the case of unit densities. For both cases, no strategyproof mechanism can achieve an approximation guarantee better than $1/(5\phi -7)\approx 0.917$.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.06080v1</guid>
      <category>cs.GT</category>
      <category>econ.TH</category>
      <category>math.OC</category>
      <pubDate>Thu, 10 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Javier Cembrano, Max Klimm, Martin Knaack</dc:creator>
    </item>
    <item>
      <title>Barter Exchange with Bounded Trading Cycles</title>
      <link>https://arxiv.org/abs/2410.06683</link>
      <description>arXiv:2410.06683v1 Announce Type: new 
Abstract: Consider a barter exchange problem over a finite set of agents, where each agent owns an item and is also associated with a (privately known) wish list of items belonging to the other agents. An outcome of the problem is a (re)allocation of the items to the agents such that each agent either keeps her own item or receives an item from her (reported) wish list, subject to the constraint that the length of the trading cycles induced by the allocation is up-bounded by a prespecified length bound k. The utility of an agent from an allocation is 1 if she receives an item from her (true) wish list and 0 if she keeps her own item (the agent incurs a large dis-utility if she receives an item that is neither hers nor belongs to her wish list).
  In this paper, we investigate the aforementioned barter exchange problem from the perspective of mechanism design without money, aiming for truthful (and individually rational) mechanisms whose objective is to maximize the social welfare. As the construction of a social welfare maximizing allocation is computationally intractable for length bounds k \geq 3, this paper focuses on (computationally efficient) truthful mechanisms that approximate the (combinatorially) optimal social welfare.We also study a more general version of the barter exchange problem, where the utility of an agent from participating in a trading cycle of length 2 \leq \ell \leq k is lambda(\ell), where \lambda is a general (monotonically non-increasing) length function. Our results include upper and lower bounds on the guaranteed approximation ratio, expressed in terms of the length bound k and the length function \lambda. On the technical side, our main contribution is an algorithmic tool that can be viewed as a truthful version of the local search paradigm. As it turns out, this tool can be applied to more general (bounded size) coalition formation problems.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.06683v1</guid>
      <category>cs.GT</category>
      <pubDate>Thu, 10 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Yuval Emek, Matan-El Shpiro</dc:creator>
    </item>
    <item>
      <title>Cooperate or Compete: Coalition Formation in Congestion Games</title>
      <link>https://arxiv.org/abs/2410.06797</link>
      <description>arXiv:2410.06797v1 Announce Type: new 
Abstract: This paper investigates the potential benefits of cooperation in scenarios where finitely many agents compete for shared resources, leading to congestion and thereby reduced rewards. By appropriate coordination the members of the cooperating group (a.k.a., coalition) can minimize the congestion losses due to inmates, while efficiently facing the competition from outsiders (coalitions indulge in a non-cooperative congestion game). The quest in this paper is to identify the stable partition of coalitions that are not challenged by a new coalition. In contrast to the traditional cooperative games, the worth of a coalition in our game also depends upon the arrangement of the opponents. Every arrangement leads to a partition and a corresponding congestion game; the resultant Nash equilibria (NEs) dictate the `worth'. The analysis is further complicated due to the presence of multiple NEs for each such game.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.06797v1</guid>
      <category>cs.GT</category>
      <pubDate>Thu, 10 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <dc:creator>Riya Sultana, Veeraruna Kavitha</dc:creator>
    </item>
    <item>
      <title>Best-of-Both-Worlds Fair Allocation of Indivisible and Mixed Goods</title>
      <link>https://arxiv.org/abs/2410.06877</link>
      <description>arXiv:2410.06877v1 Announce Type: new 
Abstract: We study the problem of fairly allocating either a set of indivisible goods or a set of mixed divisible and indivisible goods (i.e., mixed goods) to agents with additive utilities, taking the best-of-both-worlds perspective of guaranteeing fairness properties both ex ante and ex post. The ex-post fairness notions considered in this paper are relaxations of envy-freeness, specifically, EFX for indivisible-goods allocation, and EFM for mixed-goods allocation. For two agents, we show that there is a polynomial-time randomized algorithm that achieves ex-ante envy-freeness and ex-post EFX / EFM simultaneously. For $n$ agents with bi-valued utilities, we show there exist randomized allocations that are (i) ex-ante proportional and ex-post EFM, and (ii) ex-ante envy-free, ex-post EFX, and ex-post fractionally Pareto optimal.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.06877v1</guid>
      <category>cs.GT</category>
      <pubDate>Thu, 10 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Xiaolin Bu, Zihao Li, Shengxin Liu, Xinhang Lu, Biaoshuai Tao</dc:creator>
    </item>
    <item>
      <title>Mechanism Design for Exchange Markets</title>
      <link>https://arxiv.org/abs/2410.07023</link>
      <description>arXiv:2410.07023v1 Announce Type: new 
Abstract: Exchange markets are a significant type of market economy, in which each agent holds a budget and certain (divisible) resources available for trading. Most research on equilibrium in exchange economies is based on an environment of completely free competition. However, the orderly operation of markets also relies on effective economic regulatory mechanisms. This paper initiates the study of the mechanism design problem in exchange markets, exploring the potential to establish truthful market rules and mechanisms. This task poses a significant challenge as unlike auctioneers in auction design, the mechanism designer in exchange markets lacks centralized authority to fully control the allocation of resources. In this paper, the mechanism design problem is formalized as a two-stage game. In stage 1, agents submit their private information to the manager, who then formulates market trading rules based on the submitted information. In stage 2, agents are free to engage in transactions within these rules, ultimately reaching an equilibrium. We generalize the concept of liquid welfare from classical budget-feasible auctions and use market liquid welfare as a measure to evaluate the performance of the designed mechanism. Moreover, an extra concept called profitability is introduced to assess whether the market is money-making (profitable) or money-losing (unprofitable). Our goal is to design a truthful mechanism that achieves an (approximate) optimal welfare while minimizing unprofitability as much as possible. Two mechanisms for the problem are proposed. The first one guarantees truthfulness and profitability while approaching an approximation ratio of 1/2 in large markets. The second one is also truthful and achieves 1/2 approximation in general markets but incurs bounded unprofitability. Our aim is for both mechanisms to provide valuable insights into the truthful market design problem.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.07023v1</guid>
      <category>cs.GT</category>
      <pubDate>Thu, 10 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Yusen Zheng, Yukun Cheng, Chenyang Xu, Xiaotie Deng</dc:creator>
    </item>
    <item>
      <title>Intuitions of Compromise: Utilitarianism vs. Contractualism</title>
      <link>https://arxiv.org/abs/2410.05496</link>
      <description>arXiv:2410.05496v1 Announce Type: cross 
Abstract: What is the best compromise in a situation where different people value different things? The most commonly accepted method for answering this question -- in fields across the behavioral and social sciences, decision theory, philosophy, and artificial intelligence development -- is simply to add up utilities associated with the different options and pick the solution with the largest sum. This ``utilitarian'' approach seems like the obvious, theory-neutral way of approaching the problem. But there is an important, though often-ignored, alternative: a ``contractualist'' approach, which advocates for an agreement-driven method of deciding. Remarkably, no research has presented empirical evidence directly comparing the intuitive plausibility of these two approaches. In this paper, we systematically explore the proposals suggested by each algorithm (the ``Utilitarian Sum'' and the contractualist ''Nash Product''), using a paradigm that applies those algorithms to aggregating preferences across groups in a social decision-making context. While the dominant approach to value aggregation up to now has been utilitarian, we find that people strongly prefer the aggregations recommended by the contractualist algorithm. Finally, we compare the judgments of large language models (LLMs) to that of our (human) participants, finding important misalignment between model and human preferences.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.05496v1</guid>
      <category>cs.AI</category>
      <category>cs.GT</category>
      <pubDate>Thu, 10 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Jared Moore, Yejin Choi, Sydney Levine</dc:creator>
    </item>
    <item>
      <title>Mis\`ere Connect Four is Solved</title>
      <link>https://arxiv.org/abs/2410.05551</link>
      <description>arXiv:2410.05551v1 Announce Type: cross 
Abstract: Connect Four is a two-player game where each player attempts to be the first to create a sequence of four of their pieces, arranged horizontally, vertically, or diagonally, by dropping pieces into the columns of a grid of width seven and height six, in alternating turns. Mis\`ere Connect Four is played by the same rules, but with the opposite objective: do not connect four. This paper announces that Mis\`ere Connect Four is solved: perfect play by both sides leads to a second-player win. More generally, this paper also announces that Mis\`ere Connect $k$ played on a $w \times h$ board is also solved, but the outcome depends on the game's parameters $k$, $w$, and $h$, and may be a first-player win, a second-player win, or a draw. These results are constructive, meaning that we provide explicit strategies, thus enabling readers to impress their friends and foes alike with provably optimal play in the mis\`ere form of a table-top game for children.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.05551v1</guid>
      <category>math.CO</category>
      <category>cs.GT</category>
      <pubDate>Thu, 10 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <dc:creator>Robert Steele, Daniel B. Larremore</dc:creator>
    </item>
    <item>
      <title>Online Matching Meets Sampling Without Replacement</title>
      <link>https://arxiv.org/abs/2410.06868</link>
      <description>arXiv:2410.06868v1 Announce Type: cross 
Abstract: Sampling without replacement is a natural online rounding strategy for converting fractional bipartite matching into an integral one. In Online Bipartite Matching, we can use the Balance algorithm to fractionally match each online vertex, and then sample an unmatched offline neighbor with probability proportional to the fractional matching. In Online Stochastic Matching, we can take the solution to a linear program relaxation as a reference, and then match each online vertex to an unmatched offline neighbor with probability proportional to the fractional matching of the online vertex's type. On the one hand, we find empirical evidence that online matching algorithms based on sampling without replacement outperform existing algorithms. On the other hand, the literature offers little theoretical understanding of the power of sampling without replacement in online matching problems.
  This paper fills the gap in the literature by giving the first non-trivial competitive analyses of sampling without replacement for online matching problems. In Online Stochastic Matching, we develop a potential function analysis framework to show that sampling without replacement is at least $0.707$-competitive. The new analysis framework further allows us to derandomize the algorithm to obtain the first polynomial-time deterministic algorithm that breaks the $1-\frac{1}{e}$ barrier. In Online Bipartite Matching, we show that sampling without replacement provides provable online correlated selection guarantees when the selection probabilities correspond to the fractional matching chosen by the Balance algorithm. As a result, we prove that sampling without replacement is at least $0.513$-competitive for Online Bipartite Matching.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.06868v1</guid>
      <category>cs.DS</category>
      <category>cs.GT</category>
      <pubDate>Thu, 10 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Zhiyi Huang, Chui Shan Lee, Jianqiao Lu, Xinkai Shu</dc:creator>
    </item>
    <item>
      <title>Bicriteria Multidimensional Mechanism Design with Side Information</title>
      <link>https://arxiv.org/abs/2302.14234</link>
      <description>arXiv:2302.14234v4 Announce Type: replace 
Abstract: We develop a versatile methodology for multidimensional mechanism design that incorporates side information about agents to generate high welfare and high revenue simultaneously. Side information sources include advice from domain experts, predictions from machine learning models, and even the mechanism designer's gut instinct. We design a tunable mechanism that integrates side information with an improved VCG-like mechanism based on weakest types, which are agent types that generate the least welfare. We show that our mechanism, when carefully tuned, generates welfare and revenue competitive with the prior-free total social surplus, and its performance decays gracefully as the side information quality decreases. We consider a number of side information formats including distribution-free predictions, predictions that express uncertainty, agent types constrained to low-dimensional subspaces of the ambient type space, and the traditional setting with known priors over agent types. In each setting we design mechanisms based on weakest types and prove performance guarantees.</description>
      <guid isPermaLink="false">oai:arXiv.org:2302.14234v4</guid>
      <category>cs.GT</category>
      <category>econ.TH</category>
      <pubDate>Thu, 10 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Maria-Florina Balcan, Siddharth Prasad, Tuomas Sandholm</dc:creator>
    </item>
    <item>
      <title>Concurrent Stochastic Games with Stateful-discounted and Parity Objectives: Complexity and Algorithms</title>
      <link>https://arxiv.org/abs/2405.02486</link>
      <description>arXiv:2405.02486v2 Announce Type: replace 
Abstract: We study two-player zero-sum concurrent stochastic games with finite state and action space played for an infinite number of steps. In every step, the two players simultaneously and independently choose an action. Given the current state and the chosen actions, the next state is obtained according to a stochastic transition function. An objective is a measurable function on plays (or infinite trajectories) of the game, and the value for an objective is the maximal expectation that the player can guarantee against the adversarial player. We consider: (a) stateful-discounted objectives, which are similar to the classical discounted-sum objectives, but states are associated with different discount factors rather than a single discount factor; and (b) parity objectives, which are a canonical representation for $\omega$-regular objectives. For stateful-discounted objectives, given an ordering of the discount factors, the limit value is the limit of the value of the stateful-discounted objectives, as the discount factors approach zero according to the given order.
  The computational problem we consider is the approximation of the value within an arbitrary additive error. The above problem is known to be in EXPSPACE for the limit value of stateful-discounted objectives and in PSPACE for parity objectives. The best-known algorithms for both the above problems are at least exponential time, with an exponential dependence on the number of states and actions. Our main results for the value approximation problem for the limit value of stateful-discounted objectives and parity objectives are as follows: (a) we establish TFNP[NP] complexity; and (b) we present algorithms that improve the dependency on the number of actions in the exponent from linear to logarithmic. In particular, if the number of states is constant, our algorithms run in polynomial time.</description>
      <guid isPermaLink="false">oai:arXiv.org:2405.02486v2</guid>
      <category>cs.GT</category>
      <pubDate>Thu, 10 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Ali Asadi, Krishnendu Chatterjee, Raimundo Saona, Jakub Svoboda</dc:creator>
    </item>
    <item>
      <title>Truthful Aggregation of LLMs with an Application to Online Advertising</title>
      <link>https://arxiv.org/abs/2405.05905</link>
      <description>arXiv:2405.05905v4 Announce Type: replace 
Abstract: The next frontier of online advertising is revenue generation from LLM-generated content. We consider a setting where advertisers aim to influence the responses of an LLM to align with their interests, while platforms seek to maximize advertiser value and ensure user satisfaction. The challenge is that advertisers' preferences generally conflict with those of the user, and advertisers may misreport their preferences. To address this, we introduce MOSAIC, an auction mechanism that ensures that truthful reporting is a dominant strategy for advertisers and that aligns the utility of each advertiser with their contribution to social welfare. Importantly, the mechanism operates without LLM fine-tuning or access to model weights and provably converges to the output of the optimally fine-tuned LLM as computational resources increase. Additionally, it can incorporate contextual information about advertisers, which significantly improves social welfare. Through experiments with a publicly available LLM, we show that MOSAIC leads to high advertiser value and platform revenue with low computational overhead. While our motivating application is online advertising, our mechanism can be applied in any setting with monetary transfers, making it a general-purpose solution for truthfully aggregating the preferences of self-interested agents over LLM-generated replies.</description>
      <guid isPermaLink="false">oai:arXiv.org:2405.05905v4</guid>
      <category>cs.GT</category>
      <category>cs.AI</category>
      <pubDate>Thu, 10 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Ermis Soumalias, Michael J. Curry, Sven Seuken</dc:creator>
    </item>
    <item>
      <title>Learning in Games with Progressive Hiding</title>
      <link>https://arxiv.org/abs/2409.03875</link>
      <description>arXiv:2409.03875v2 Announce Type: replace 
Abstract: When learning to play an imperfect information game, it is often easier to first start with the basic mechanics of the game rules. For example, one can play several example rounds with private cards revealed to all players to better understand the basic actions and their effects. Building on this intuition, this paper introduces {\it progressive hiding}, an algorithm that learns to play imperfect information games by first learning the basic mechanics and then progressively adding information constraints over time. Progressive hiding is inspired by methods from stochastic multistage optimization such as scenario decomposition and progressive hedging. We prove that it enables the adaptation of counterfactual regret minimization to games where perfect recall is not satisfied. Numerical experiments illustrate that progressive hiding can achieve optimal payoff in a benchmark of emergent communication trading game.</description>
      <guid isPermaLink="false">oai:arXiv.org:2409.03875v2</guid>
      <category>cs.GT</category>
      <pubDate>Thu, 10 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Benjamin Heymann, Marc Lanctot</dc:creator>
    </item>
    <item>
      <title>Last Iterate Convergence in Monotone Mean Field Games</title>
      <link>https://arxiv.org/abs/2410.05127</link>
      <description>arXiv:2410.05127v2 Announce Type: replace 
Abstract: Mean Field Game (MFG) is a framework utilized to model and approximate the behavior of a large number of agents, and the computation of equilibria in MFG has been a subject of interest. Despite the proposal of methods to approximate the equilibria, algorithms where the sequence of updated policy converges to equilibrium, specifically those exhibiting last-iterate convergence, have been limited. We propose the use of a simple, proximal-point-type algorithm to compute equilibria for MFGs. Subsequently, we provide the first last-iterate convergence guarantee under the Lasry--Lions-type monotonicity condition. We further employ the Mirror Descent algorithm for the regularized MFG to efficiently approximate the update rules of the proximal point method for MFGs. We demonstrate that the algorithm can approximate with an accuracy of $\varepsilon$ after $\mathcal{O}({\log(1/\varepsilon)})$ iterations. This research offers a tractable approach for large-scale and large-population games.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.05127v2</guid>
      <category>cs.GT</category>
      <category>cs.AI</category>
      <pubDate>Thu, 10 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Noboru Isobe, Kenshi Abe, Kaito Ariu</dc:creator>
    </item>
    <item>
      <title>Breaking the Curse of Multiagency in Robust Multi-Agent Reinforcement Learning</title>
      <link>https://arxiv.org/abs/2409.20067</link>
      <description>arXiv:2409.20067v2 Announce Type: replace-cross 
Abstract: Standard multi-agent reinforcement learning (MARL) algorithms are vulnerable to sim-to-real gaps. To address this, distributionally robust Markov games (RMGs) have been proposed to enhance robustness in MARL by optimizing the worst-case performance when game dynamics shift within a prescribed uncertainty set. Solving RMGs remains under-explored, from problem formulation to the development of sample-efficient algorithms. A notorious yet open challenge is if RMGs can escape the curse of multiagency, where the sample complexity scales exponentially with the number of agents. In this work, we propose a natural class of RMGs where the uncertainty set of each agent is shaped by both the environment and other agents' strategies in a best-response manner. We first establish the well-posedness of these RMGs by proving the existence of game-theoretic solutions such as robust Nash equilibria and coarse correlated equilibria (CCE). Assuming access to a generative model, we then introduce a sample-efficient algorithm for learning the CCE whose sample complexity scales polynomially with all relevant parameters. To the best of our knowledge, this is the first algorithm to break the curse of multiagency for RMGs.</description>
      <guid isPermaLink="false">oai:arXiv.org:2409.20067v2</guid>
      <category>cs.LG</category>
      <category>cs.GT</category>
      <category>cs.MA</category>
      <category>stat.ML</category>
      <pubDate>Thu, 10 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Laixi Shi, Jingchu Gai, Eric Mazumdar, Yuejie Chi, Adam Wierman</dc:creator>
    </item>
    <item>
      <title>Large Language Models Overcome the Machine Penalty When Acting Fairly but Not When Acting Selfishly or Altruistically</title>
      <link>https://arxiv.org/abs/2410.03724</link>
      <description>arXiv:2410.03724v2 Announce Type: replace-cross 
Abstract: In social dilemmas where the collective and self-interests are at odds, people typically cooperate less with machines than with fellow humans, a phenomenon termed the machine penalty. Overcoming this penalty is critical for successful human-machine collectives, yet current solutions often involve ethically-questionable tactics, like concealing machines' non-human nature. In this study, with 1,152 participants, we explore the possibility of closing this research question by using Large Language Models (LLMs), in scenarios where communication is possible between interacting parties. We design three types of LLMs: (i) Cooperative, aiming to assist its human associate; (ii) Selfish, focusing solely on maximizing its self-interest; and (iii) Fair, balancing its own and collective interest, while slightly prioritizing self-interest. Our findings reveal that, when interacting with humans, fair LLMs are able to induce cooperation levels comparable to those observed in human-human interactions, even when their non-human nature is fully disclosed. In contrast, selfish and cooperative LLMs fail to achieve this goal. Post-experiment analysis shows that all three types of LLMs succeed in forming mutual cooperation agreements with humans, yet only fair LLMs, which occasionally break their promises, are capable of instilling a perception among humans that cooperating with them is the social norm, and eliciting positive views on their trustworthiness, mindfulness, intelligence, and communication quality. Our findings suggest that for effective human-machine cooperation, bot manufacturers should avoid designing machines with mere rational decision-making or a sole focus on assisting humans. Instead, they should design machines capable of judiciously balancing their own interest and the interest of humans.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.03724v2</guid>
      <category>cs.HC</category>
      <category>cs.AI</category>
      <category>cs.GT</category>
      <category>econ.GN</category>
      <category>q-fin.EC</category>
      <pubDate>Thu, 10 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <dc:creator>Zhen Wang, Ruiqi Song, Chen Shen, Shiya Yin, Zhao Song, Balaraju Battu, Lei Shi, Danyang Jia, Talal Rahwan, Shuyue Hu</dc:creator>
    </item>
  </channel>
</rss>
