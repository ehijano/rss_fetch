<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>cs.ET updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/cs.ET</link>
    <description>cs.ET updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/cs.ET" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Fri, 09 Jan 2026 05:00:09 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Fri, 09 Jan 2026 00:00:00 -0500</pubDate>
    <skipDays>
      <day>Sunday</day>
      <day>Saturday</day>
    </skipDays>
    <item>
      <title>Privacy at Scale in Networked Healthcare</title>
      <link>https://arxiv.org/abs/2601.04298</link>
      <description>arXiv:2601.04298v1 Announce Type: cross 
Abstract: Digitized, networked healthcare promises earlier detection, precision therapeutics, and continuous care; yet, it also expands the surface for privacy loss and compliance risk. We argue for a shift from siloed, application-specific protections to privacy-by-design at scale, centered on decision-theoretic differential privacy (DP) across the full healthcare data lifecycle; network-aware privacy accounting for interdependence in people, sensors, and organizations; and compliance-as-code tooling that lets health systems share evidence while demonstrating regulatory due care. We synthesize the privacy-enhancing technology (PET) landscape in health (federated analytics, DP, cryptographic computation), identify practice gaps, and outline a deployable agenda involving privacy-budget ledgers, a control plane to coordinate PET components across sites, shared testbeds, and PET literacy, to make lawful, trustworthy sharing the default. We illustrate with use cases (multi-site trials, genomics, disease surveillance, mHealth) and highlight distributed inference as a workhorse for multi-institution learning under explicit privacy budgets.</description>
      <guid isPermaLink="false">oai:arXiv.org:2601.04298v1</guid>
      <category>cs.CR</category>
      <category>cs.CY</category>
      <category>cs.ET</category>
      <category>cs.SE</category>
      <pubDate>Fri, 09 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>M. Amin Rahimian, Benjamin Panny, James Joshi</dc:creator>
    </item>
    <item>
      <title>Energy-Time-Accuracy Tradeoffs in Thermodynamic Computing</title>
      <link>https://arxiv.org/abs/2601.04358</link>
      <description>arXiv:2601.04358v1 Announce Type: cross 
Abstract: In the paradigm of thermodynamic computing, instead of behaving deterministically, hardware undergoes a stochastic process in order to sample from a distribution of interest. While it has been hypothesized that thermodynamic computers may achieve better energy efficiency and performance, a theoretical characterization of the resource cost of thermodynamic computations is still lacking. Here, we analyze the fundamental trade-offs between computational accuracy, energy dissipation, and time in thermodynamic computing. Using geometric bounds on entropy production, we derive general limits on the energy-delay-deficiency product (EDDP), a stochastic generalization of the traditional energy-delay product (EDP). While these limits can in principle be saturated, the corresponding optimal driving protocols require full knowledge of the final equilibrium distribution, i.e., the solution itself. To overcome this limitation, we develop quasi-optimal control schemes that require no prior information of the solution and demonstrate their performance for matrix inversion in overdamped quadratic systems. The derived bounds extend beyond this setting to more general potentials, being directly relevant to recent proposals based on non-equilibrium Langevin dynamics.</description>
      <guid isPermaLink="false">oai:arXiv.org:2601.04358v1</guid>
      <category>cond-mat.stat-mech</category>
      <category>cs.AR</category>
      <category>cs.ET</category>
      <pubDate>Fri, 09 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Alberto Rolandi, Paolo Abiuso, Patryk Lipka-Bartosik, Maxwell Aifer, Patrick J. Coles, Mart\'i Perarnau-Llobet</dc:creator>
    </item>
    <item>
      <title>Fast Phase Logic Family for Achieving Very Large Scale Integration in Superconductor Electronics</title>
      <link>https://arxiv.org/abs/2601.04363</link>
      <description>arXiv:2601.04363v1 Announce Type: cross 
Abstract: Fast Phase Logic (FPL) is a novel digital superconductor electronic (SCE) logic family specifically designed to address critical challenges in state-of-the-art SCE, such as low device density and integration levels. The FPL family improves circuit performance by employing various Josephson junction (JJ) structures, including high-$J_c$ self-shunted 0-JJ stacks, $\pi$-JJs, and 0/$\pi$-JJ stacks. FPL utilizes 0- and $\pi$-JJs to replace the bulky geometric inductors required in single flux quantum (SFQ) logic families like RSFQ. The proposed FPL family can deliver up to two orders of magnitude improvement in integration density over RSFQ logic with a five-fold reduction in the bias current requirements. Circuit performance is enhanced with reduced latency and increased throughput. Furthermore, the FPL family provides a higher output voltage level and higher impedance, which better match those of CMOS circuits. The much smaller flux storage loops in FPL greatly reduce susceptibility to trapped flux and crosstalk. Advancements in fabrication processes that would further benefit FPL implementation include the use of NbTiN-based JJs with higher critical current density and fabrication temperature range up to 400~$^\circ$C, or the use of stacked JJ structures. The resulting increased density makes very large-scale integration (VLSI) more practical. The FPL family has the potential to significantly advance SCE technology. Near-term applications are envisioned in accelerator cores for signal processing and artificial intelligence, with long-term potential in supercomputing applications. The advantages of FPL were demonstrated through an architectural study of a fast Fourier transform (FFT) circuit, comparing it with CMOS and SFQ technologies.</description>
      <guid isPermaLink="false">oai:arXiv.org:2601.04363v1</guid>
      <category>cond-mat.supr-con</category>
      <category>cs.ET</category>
      <pubDate>Fri, 09 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Sasan Razmkhah, Massoud Pedram</dc:creator>
    </item>
    <item>
      <title>5G NR Non-Terrestrial Networks: From Early Results to the Road Ahead</title>
      <link>https://arxiv.org/abs/2601.04882</link>
      <description>arXiv:2601.04882v1 Announce Type: cross 
Abstract: This paper overviews the 3GPP 5G NR-NTN standard, detailing the evolution from Rel. 18 to 19 and innovations for Rel. 20. Using realistic ns-3 simulations validated against 3GPP calibration data, we evaluate various satellite network configurations. The results highlight the potential of NTNs to extend wireless connectivity to remote areas, serve requests during emergency, and alleviate terrestrial network congestion.</description>
      <guid isPermaLink="false">oai:arXiv.org:2601.04882v1</guid>
      <category>cs.NI</category>
      <category>cs.ET</category>
      <pubDate>Fri, 09 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Mattia Figaro, Francesco Rossato, Marco Giordani, Alessandro Traspadini, Takayuki Shimizu, Chinmay Mahabal, Sanjeewa Herath, Chunghan Lee, Dogan Kutay Pekcan, Michele Zorzi</dc:creator>
    </item>
    <item>
      <title>Quantum Neural Network Training and Inference with Low Resolution Control Electronics</title>
      <link>https://arxiv.org/abs/2601.04983</link>
      <description>arXiv:2601.04983v1 Announce Type: cross 
Abstract: Scaling quantum computers requires tight integration of cryogenic control electronics with quantum processors, where Digital-to-Analog Converters (DACs) face severe power and area constraints. We investigate quantum neural network (QNN) training and inference under finite DAC resolution constraints across various DAC resolutions. Pre-trained QNNs achieve accuracy nearly indistinguishable from infinite-precision baselines when deployed on quantum systems with 6-bit DAC control electronics, exhibiting an elbow curve with diminishing returns beyond 4 bits. However, training under quantization reveals gradient deadlock below 12-bit resolution as gradient magnitudes fall below quantization step sizes. We introduce temperature-controlled stochasticity that overcomes this through probabilistic parameter updates, enabling successful training at 4-10 bit resolutions that remarkably matches or exceeds infinite-precision baseline performance. Our findings demonstrate that low-resolution control electronics need not compromise QML performance, enabling significant power and area reduction in cryogenic control systems for practical deployment as quantum hardware scales.</description>
      <guid isPermaLink="false">oai:arXiv.org:2601.04983v1</guid>
      <category>quant-ph</category>
      <category>cs.ET</category>
      <pubDate>Fri, 09 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Rupayan Bhattacharjee, Sergi Abadal, Carmen G. Almudever, Eduard Alarcon</dc:creator>
    </item>
    <item>
      <title>Driver-Intention Prediction with Deep Learning: Real-Time Brain-to-Vehicle Communication</title>
      <link>https://arxiv.org/abs/2601.05084</link>
      <description>arXiv:2601.05084v1 Announce Type: cross 
Abstract: Brain-computer interfaces (BCIs) allow direct communication between the brain and electronics without the need for speech or physical movement. Such interfaces can be particularly beneficial in applications requiring rapid response times, such as driving, where a vehicle's advanced driving assistance systems could benefit from immediate understanding of a driver's intentions. This study presents a novel method for predicting a driver's intention to steer using electroencephalography (EEG) signals through deep learning. A driving simulator created a controlled environment in which participants imagined controlling a vehicle during various driving scenarios, including left and right turns, as well as straight driving. A convolutional neural network (CNN) classified the detected EEG data with minimal pre-processing. Our model achieved an accuracy of 83.7% in distinguishing between the three steering intentions and demonstrated the ability of CNNs to process raw EEG data effectively. The classification accuracy was highest for right-turn segments, which suggests a potential spatial bias in brain activity. This study lays the foundation for more intuitive brain-to-vehicle communication systems.</description>
      <guid isPermaLink="false">oai:arXiv.org:2601.05084v1</guid>
      <category>cs.HC</category>
      <category>cs.AI</category>
      <category>cs.ET</category>
      <category>cs.SY</category>
      <category>eess.SP</category>
      <category>eess.SY</category>
      <pubDate>Fri, 09 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Niloufar Alavi, Swati Shah, Rezvan Alamian, Stefan Goetz</dc:creator>
    </item>
    <item>
      <title>Enhancing Expressivity of Quantum Neural Networks Based on the SWAP test</title>
      <link>https://arxiv.org/abs/2506.16938</link>
      <description>arXiv:2506.16938v3 Announce Type: replace-cross 
Abstract: Quantum neural networks (QNNs) based on parametrized quantum circuits are promising candidates for machine learning applications, yet many architectures lack clear connections to classical models, potentially limiting their ability to leverage established classical neural network techniques. We examine QNNs built from SWAP test circuits and discuss their equivalence to classical two-layer feedforward networks with quadratic activations under amplitude encoding. Evaluation on real-world and synthetic datasets shows that while this architecture learns many practical binary classification tasks, it has fundamental expressivity limitations: polynomial activation functions do not satisfy the universal approximation theorem, and we show analytically that the architecture cannot learn the parity check function beyond two dimensions, regardless of network size. To address this, we introduce generalized SWAP test circuits with multiple Fredkin gates sharing an ancilla, implementing product layers with polynomial activations of arbitrary even degree. This modification enables successful learning of parity check functions in arbitrary dimensions as well as binary n-spiral tasks, and we provide numerical evidence that the expressivity enhancement extends to alternative encoding schemes such as angle (Z) and ZZ feature maps. We validate the practical feasibility of our proposed architecture by implementing a classically pretrained instance on the IBM Torino quantum processor, achieving 84% classification accuracy on the three-dimensional parity check despite hardware noise. Our work establishes a framework for analyzing and enhancing QNN expressivity through correspondence with classical architectures, and demonstrates that SWAP test-based QNNs possess broad representational capacity relevant to both classical and potentially quantum learning tasks.</description>
      <guid isPermaLink="false">oai:arXiv.org:2506.16938v3</guid>
      <category>quant-ph</category>
      <category>cs.ET</category>
      <category>cs.LG</category>
      <pubDate>Fri, 09 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Sebastian Nagies, Emiliano Tolotti, Davide Pastorello, Enrico Blanzieri</dc:creator>
    </item>
  </channel>
</rss>
