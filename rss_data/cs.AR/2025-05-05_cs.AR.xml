<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>cs.AR updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/cs.AR</link>
    <description>cs.AR updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/cs.AR" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Tue, 06 May 2025 02:29:32 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Mon, 05 May 2025 00:00:00 -0400</pubDate>
    <skipDays>
      <day>Saturday</day>
      <day>Sunday</day>
    </skipDays>
    <item>
      <title>Heterogeneous Memory Benchmarking Toolkit</title>
      <link>https://arxiv.org/abs/2505.00901</link>
      <description>arXiv:2505.00901v1 Announce Type: new 
Abstract: This paper presents an open-source kernel-level heterogeneous memory characterization framework (MemScope) for embedded systems that enables users to understand and precisely characterize the temporal behavior of all available memory modules under configurable contention stress scenarios. Since kernel-level provides a high degree of control over allocation, cache maintenance, $CPUs$, interrupts, and I/O device activity, seeking the most accurate way to benchmark heterogeneous memory subsystems, would be achieved by implementing it in the kernel. This gives us the privilege to directly map pieces of contiguous physical memory and instantiate allocators, allowing us to finely control cores to create and eliminate interference. Additionally, we can minimize noise and interruptions, guaranteeing more consistent and precise results compared to equivalent user-space solutions. Running our Framework on a Xilinx Zynq UltraScale+ ZCU102 CPU_FPGA platform, demonstrates its capability to precisely benchmark bandwidth and latency across various memory types, including PL-side DRAM and BRAM, in a multi-core system.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.00901v1</guid>
      <category>cs.AR</category>
      <category>cs.PF</category>
      <pubDate>Mon, 05 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <dc:creator>Golsana Ghaemi, Kazem Taram, Renato Mancuso</dc:creator>
    </item>
    <item>
      <title>The Open-Source BlackParrot-BedRock Cache Coherence System</title>
      <link>https://arxiv.org/abs/2505.00962</link>
      <description>arXiv:2505.00962v1 Announce Type: new 
Abstract: This dissertation revisits the topic of programmable cache coherence engines in the context of modern shared-memory multicore processors. First, the open-source BedRock cache coherence protocol is described. BedRock employs the canonical MOESIF coherence states and reduces implementation burden by eliminating transient coherence states from the protocol. The protocol's design complexity, concurrency, and verification effort are analyzed and compared to a canonical directory-based invalidate coherence protocol. Second, the architecture and microarchitecture of three separate cache coherence directories implementing the BedRock protocol within the BlackParrot 64-bit RISC-V multicore processor, collectively called BlackParrot-BedRock (BP-BedRock), are described. A fixed-function coherence directory engine implementation provides a baseline design for performance and area comparisons. A microcode-programmable coherence directory implementation demonstrates the feasibility of implementing a programmable coherence engine capable of maintaining sufficient protocol processing performance. A hybrid fixed-function and programmable coherence directory blends the protocol processing performance of the fixed-function design with the programmable flexibility of the microcode-programmable design. Collectively, the BedRock coherence protocol and its three BP-BedRock implementations demonstrate the feasibility and challenges of including programmable logic within the coherence system of modern shared-memory multicore processors, paving the way for future research into the application- and system-level benefits of programmable coherence engines.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.00962v1</guid>
      <category>cs.AR</category>
      <pubDate>Mon, 05 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Mark Unruh Wyse</dc:creator>
    </item>
    <item>
      <title>CIMFlow: An Integrated Framework for Systematic Design and Evaluation of Digital CIM Architectures</title>
      <link>https://arxiv.org/abs/2505.01107</link>
      <description>arXiv:2505.01107v1 Announce Type: new 
Abstract: Digital Compute-in-Memory (CIM) architectures have shown great promise in Deep Neural Network (DNN) acceleration by effectively addressing the "memory wall" bottleneck. However, the development and optimization of digital CIM accelerators are hindered by the lack of comprehensive tools that encompass both software and hardware design spaces. Moreover, existing design and evaluation frameworks often lack support for the capacity constraints inherent in digital CIM architectures. In this paper, we present CIMFlow, an integrated framework that provides an out-of-the-box workflow for implementing and evaluating DNN workloads on digital CIM architectures. CIMFlow bridges the compilation and simulation infrastructures with a flexible instruction set architecture (ISA) design, and addresses the constraints of digital CIM through advanced partitioning and parallelism strategies in the compilation flow. Our evaluation demonstrates that CIMFlow enables systematic prototyping and optimization of digital CIM architectures across diverse configurations, providing researchers and designers with an accessible platform for extensive design space exploration.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.01107v1</guid>
      <category>cs.AR</category>
      <category>cs.LG</category>
      <pubDate>Mon, 05 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Yingjie Qi, Jianlei Yang, Yiou Wang, Yikun Wang, Dayu Wang, Ling Tang, Cenlin Duan, Xiaolin He, Weisheng Zhao</dc:creator>
    </item>
    <item>
      <title>Enhancing Realism in Holographic Augmented Reality Displays through Occlusion Handling</title>
      <link>https://arxiv.org/abs/2505.00942</link>
      <description>arXiv:2505.00942v1 Announce Type: cross 
Abstract: In this paper, an occlusion-capable holographic augmented-reality (AR) display is proposed, and its ability to enhance AR imagery through occlusion is demonstrated. Holographic displays can generate ideal three-dimensional (3D) virtual images and have recently shown rapid advancements, particularly in noise reduction through learning-based approaches. However, these displays still face challenges in improving image quality for AR scenarios because holographic virtual images are simply superimposed onto the real world, leading to a loss of contrast and visibility. To address this, an occlusion optics, which can mask designated areas of the real world, is incorporated into holographic AR displays. The proposed system employs a folded 4f system with a digital micromirror device and sequentially operates as both a real-world mask and an active Fourier filter. This approach transforms traditionally translucent holographic images into perceptually opaque ones while simultaneously eliminating unwanted noise terms from pixelated holographic displays. Furthermore, active Fourier filtering expands the virtual image field of view through time-multiplexed operation and supports a novel binary hologram optimization algorithm that performs especially well for sparse virtual content. The implementation successfully achieves opaque holographic 3D image presentation, significantly improving contrast and image quality while producing highly realistic 3D AR scenes with optically cast shadows.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.00942v1</guid>
      <category>physics.optics</category>
      <category>cs.AR</category>
      <pubDate>Mon, 05 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Woongseob Han, Chanseul Lee, Jae-Hyeung Park</dc:creator>
    </item>
    <item>
      <title>Carbon Aware Transformers Through Joint Model-Hardware Optimization</title>
      <link>https://arxiv.org/abs/2505.01386</link>
      <description>arXiv:2505.01386v1 Announce Type: cross 
Abstract: The rapid growth of machine learning (ML) systems necessitates a more comprehensive evaluation of their environmental impact, particularly their carbon footprint, which comprises operational carbon from training and inference execution and embodied carbon from hardware manufacturing and its entire life-cycle. Despite the increasing importance of embodied emissions, there is a lack of tools and frameworks to holistically quantify and optimize the total carbon footprint of ML systems. To address this, we propose CATransformers, a carbon-aware architecture search framework that enables sustainability-driven co-optimization of ML models and hardware architectures. By incorporating both operational and embodied carbon metrics into early design space exploration of domain-specific hardware accelerators, CATransformers demonstrates that optimizing for carbon yields design choices distinct from those optimized solely for latency or energy efficiency. We apply our framework to multi-modal CLIP-based models, producing CarbonCLIP, a family of CLIP models achieving up to 17% reduction in total carbon emissions while maintaining accuracy and latency compared to state-of-the-art edge small CLIP baselines. This work underscores the need for holistic optimization methods to design high-performance, environmentally sustainable AI systems.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.01386v1</guid>
      <category>cs.LG</category>
      <category>cs.AR</category>
      <pubDate>Mon, 05 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Irene Wang, Newsha Ardalani, Mostafa Elhoushi, Daniel Jiang, Samuel Hsia, Ekin Sumbul, Divya Mahajan, Carole-Jean Wu, Bilge Acun</dc:creator>
    </item>
    <item>
      <title>On Reducing the Execution Latency of Superconducting Quantum Processors via Quantum Job Scheduling</title>
      <link>https://arxiv.org/abs/2404.07882</link>
      <description>arXiv:2404.07882v2 Announce Type: replace 
Abstract: Quantum computing has gained considerable attention, especially after the arrival of the Noisy Intermediate-Scale Quantum (NISQ) era. Quantum processors and cloud services have been made world-wide increasingly available. Unfortunately, jobs on existing quantum processors are often executed in series, and the workload could be heavy to the processor. Typically, one has to wait for hours or even longer to obtain the result of a single quantum job on public quantum cloud due to long queue time. In fact, as the scale grows, the qubit utilization rate of the serial execution mode will further diminish, causing the waste of quantum resources. In this paper, to our best knowledge for the first time, the Quantum Job Scheduling Problem (QJSP) is formulated and introduced, and we accordingly aim to improve the utility efficiency of quantum resources. Specifically, a noise-aware quantum job scheduler (NAQJS) concerning the circuit width, number of measurement shots, and submission time of quantum jobs is proposed to reduce the execution latency. We conduct extensive experiments on a simulated Qiskit noise model, as well as on the Xiaohong (from QuantumCTek) superconducting quantum processor. Numerical results show the effectiveness in both the QPU time and turnaround time.</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.07882v2</guid>
      <category>cs.AR</category>
      <category>quant-ph</category>
      <pubDate>Mon, 05 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <arxiv:DOI>10.1145/3676536.3676678</arxiv:DOI>
      <dc:creator>Wenjie Wu, Yiquan Wang, Ge Yan, Yuming Zhao, Bo Zhang, Junchi Yan</dc:creator>
    </item>
  </channel>
</rss>
