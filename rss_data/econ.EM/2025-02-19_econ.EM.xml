<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>econ.EM updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/econ.EM</link>
    <description>econ.EM updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/econ.EM" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Thu, 20 Feb 2025 02:46:30 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Wed, 19 Feb 2025 00:00:00 -0500</pubDate>
    <skipDays>
      <day>Sunday</day>
      <day>Saturday</day>
    </skipDays>
    <item>
      <title>Assortative Marriage and Geographic Sorting</title>
      <link>https://arxiv.org/abs/2502.12867</link>
      <description>arXiv:2502.12867v1 Announce Type: new 
Abstract: Between 1980 and 2000, the U.S. experienced a significant rise in geographic sorting and educational homogamy, with college graduates increasingly concentrating in high-skill cities and marrying similarly educated spouses. We develop and estimate a spatial equilibrium model with local labor, housing, and marriage markets, incorporating a marriage matching framework with transferable utility. Using the model, we estimate trends in assortative preferences, quantify the interplay between marital and geographic sorting, and assess their combined impact on household inequality. Welfare analyses show that after accounting for marriage, the college well-being gap grew substantially more than the college wage gap.</description>
      <guid isPermaLink="false">oai:arXiv.org:2502.12867v1</guid>
      <category>econ.EM</category>
      <pubDate>Wed, 19 Feb 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Jiaming Mao, Jiayi Wen</dc:creator>
    </item>
    <item>
      <title>Imputation Strategies for Rightcensored Wages in Longitudinal Datasets</title>
      <link>https://arxiv.org/abs/2502.12967</link>
      <description>arXiv:2502.12967v1 Announce Type: new 
Abstract: Censoring from above is a common problem with wage information as the reported wages are typically top-coded for confidentiality reasons. In administrative databases the information is often collected only up to a pre-specified threshold, for example, the contribution limit for the social security system. While directly accounting for the censoring is possible for some analyses, the most flexible solution is to impute the values above the censoring point. This strategy offers the advantage that future users of the data no longer need to implement possibly complicated censoring estimators. However, standard cross-sectional imputation routines relying on the classical Tobit model to impute right-censored data have a high risk of introducing bias from uncongeniality (Meng, 1994) as future analyses to be conducted on the imputed data are unknown to the imputer. Furthermore, as we show using a large-scale administrative database from the German Federal Employment agency, the classical Tobit model offers a poor fit to the data. In this paper, we present some strategies to address these problems. Specifically, we use leave-one-out means as suggested by Card et al. (2013) to avoid biases from uncongeniality and rely on quantile regression or left censoring to improve the model fit. We illustrate the benefits of these modeling adjustments using the German Structure of Earnings Survey, which is (almost) unaffected by censoring and can thus serve as a testbed to evaluate the imputation procedures.</description>
      <guid isPermaLink="false">oai:arXiv.org:2502.12967v1</guid>
      <category>econ.EM</category>
      <pubDate>Wed, 19 Feb 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <dc:creator>J\"org Drechsler, Johannes Ludsteck</dc:creator>
    </item>
    <item>
      <title>Identification of Incomplete Preferences</title>
      <link>https://arxiv.org/abs/2108.06282</link>
      <description>arXiv:2108.06282v4 Announce Type: replace 
Abstract: We provide a sharp identification region for discrete choice models where consumers' preferences are not necessarily complete even if only aggregate choice data is available. Behavior is modeled using an upper and a lower utility for each alternative so that non-comparability can arise. The identification region places intuitive bounds on the probability distribution of upper and lower utilities. We show that the existence of an instrumental variable can be used to reject the hypothesis that the preferences of all consumers are complete. We apply our methods to data from the 2018 mid-term elections in Ohio.</description>
      <guid isPermaLink="false">oai:arXiv.org:2108.06282v4</guid>
      <category>econ.EM</category>
      <category>econ.TH</category>
      <pubDate>Wed, 19 Feb 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Luca Rigotti, Arie Beresteanu</dc:creator>
    </item>
    <item>
      <title>Statistical Inference for Fisher Market Equilibrium</title>
      <link>https://arxiv.org/abs/2209.15422</link>
      <description>arXiv:2209.15422v3 Announce Type: replace 
Abstract: Statistical inference under market equilibrium effects has attracted increasing attention recently. In this paper we focus on the specific case of linear Fisher markets. They have been widely use in fair resource allocation of food/blood donations and budget management in large-scale Internet ad auctions. In resource allocation, it is crucial to quantify the variability of the resource received by the agents (such as blood banks and food banks) in addition to fairness and efficiency properties of the systems. For ad auction markets, it is important to establish statistical properties of the platform's revenues in addition to their expected values. To this end, we propose a statistical framework based on the concept of infinite-dimensional Fisher markets. In our framework, we observe a market formed by a finite number of items sampled from an underlying distribution (the "observed market") and aim to infer several important equilibrium quantities of the underlying long-run market. These equilibrium quantities include individual utilities, social welfare, and pacing multipliers. Through the lens of sample average approximation (SSA), we derive a collection of statistical results and show that the observed market provides useful statistical information of the long-run market. In other words, the equilibrium quantities of the observed market converge to the true ones of the long-run market with strong statistical guarantees. These include consistency, finite sample bounds, asymptotics, and confidence. As an extension, we discuss revenue inference in quasilinear Fisher markets.</description>
      <guid isPermaLink="false">oai:arXiv.org:2209.15422v3</guid>
      <category>econ.EM</category>
      <category>cs.GT</category>
      <pubDate>Wed, 19 Feb 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Luofeng Liao, Yuan Gao, Christian Kroer</dc:creator>
    </item>
    <item>
      <title>Adjustment with Many Regressors Under Covariate-Adaptive Randomizations</title>
      <link>https://arxiv.org/abs/2304.08184</link>
      <description>arXiv:2304.08184v5 Announce Type: replace 
Abstract: Our paper discovers a new trade-off of using regression adjustments (RAs) in causal inference under covariate-adaptive randomizations (CARs). On one hand, RAs can improve the efficiency of causal estimators by incorporating information from covariates that are not used in the randomization. On the other hand, RAs can degrade estimation efficiency due to their estimation errors, which are not asymptotically negligible when the number of regressors is of the same order as the sample size. Ignoring the estimation errors of RAs may result in serious over-rejection of causal inference under the null hypothesis. To address the issue, we construct a new ATE estimator by optimally linearly combining the estimators with and without RAs. We then develop a unified inference theory for this estimator under CARs. It has two features: (1) the Wald test based on it achieves the exact asymptotic size under the null hypothesis, regardless of whether the number of covariates is fixed or diverges no faster than the sample size; and (2) it guarantees weak efficiency improvement over estimators both with and without RAs.</description>
      <guid isPermaLink="false">oai:arXiv.org:2304.08184v5</guid>
      <category>econ.EM</category>
      <category>stat.ME</category>
      <pubDate>Wed, 19 Feb 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Liang Jiang, Liyao Li, Ke Miao, Yichong Zhang</dc:creator>
    </item>
    <item>
      <title>Asymptotically Unbiased Synthetic Control Methods by Density Matching</title>
      <link>https://arxiv.org/abs/2307.11127</link>
      <description>arXiv:2307.11127v4 Announce Type: replace 
Abstract: Synthetic Control Methods (SCMs) have become a fundamental tool for comparative case studies. The core idea behind SCMs is to estimate treatment effects by predicting counterfactual outcomes for a treated unit using a weighted combination of observed outcomes from untreated units. The accuracy of these predictions is crucial for evaluating the treatment effect of a policy intervention. Subsequent research has therefore focused on estimating SC weights. In this study, we highlight a key endogeneity issue in existing SCMs-namely, the correlation between the outcomes of untreated units and the error term of the synthetic control, which leads to bias in both counterfactual outcome prediction and treatment effect estimation. To address this issue, we propose a novel SCM based on density matching, assuming that the outcome density of the treated unit can be approximated by a weighted mixture of the joint density of untreated units. Under this assumption, we estimate SC weights by matching the moments of the treated outcomes with the weighted sum of the moments of the untreated outcomes. Our method offers three advantages: first, under the mixture model assumption, our estimator is asymptotically unbiased; second, this asymptotic unbiasedness reduces the mean squared error in counterfactual predictions; and third, our method provides full densities of the treatment effect rather than just expected values, thereby broadening the applicability of SCMs. Finally, we present experimental results that demonstrate the effectiveness of our approach.</description>
      <guid isPermaLink="false">oai:arXiv.org:2307.11127v4</guid>
      <category>econ.EM</category>
      <category>cs.LG</category>
      <category>stat.ME</category>
      <pubDate>Wed, 19 Feb 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Masahiro Kato, Akari Ohda</dc:creator>
    </item>
    <item>
      <title>When does IV identification not restrict outcomes?</title>
      <link>https://arxiv.org/abs/2406.02835</link>
      <description>arXiv:2406.02835v5 Announce Type: replace 
Abstract: Many identification results in instrumental variables (IV) models hold without requiring any restrictions on the distribution of potential outcomes, or how those outcomes are correlated with selection behavior. This enables IV models to allow for arbitrary heterogeneity in treatment effects and the possibility of selection on gains in the outcome. I provide a necessary and sufficient condition for treatment effects to be point identified in a manner that does not restrict outcomes, when the instruments take a finite number of values. The condition generalizes the well-known LATE monotonicity assumption, and unifies a wide variety of other known IV identification results. The result also yields a brute-force approach to reveal all selection models that allow for point identification of treatment effects without restricting outcomes, and then enumerate all of the identified parameters within each such selection model. The search uncovers new selection models that yield identification, provides impossibility results for others, and offers opportunities to relax assumptions on selection used in existing literature. An application considers the identification of complementarities between two cross-randomized treatments, obtaining a necessary and sufficient condition on selection for local average complementarities among compliers to be identified in a manner that does not restrict outcomes. I use this result to revisit two empirical settings, one in which the data are incompatible with this restriction on selection, and another in which the data are compatible with the restriction.</description>
      <guid isPermaLink="false">oai:arXiv.org:2406.02835v5</guid>
      <category>econ.EM</category>
      <pubDate>Wed, 19 Feb 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Leonard Goff</dc:creator>
    </item>
    <item>
      <title>Sharp Testable Implications of Encouragement Designs</title>
      <link>https://arxiv.org/abs/2411.09808</link>
      <description>arXiv:2411.09808v2 Announce Type: replace 
Abstract: This paper studies a potential outcome model with a continuous or discrete outcome, a discrete multi-valued treatment, and a discrete multi-valued instrument. We derive sharp, closed-form testable implications for a class of restrictions on potential treatments where each value of the instrument only encourages towards one choice. Borrowing the terminology used in randomized experiments, we call such a setting an encouragement design. The testable implications are inequalities in terms of the conditional distributions given the instrument. Through a novel constructive argument, we further show these inequalities are sharp in the sense that any distribution of the observed data that satisfies these inequalities is compatible with this class of restrictions on potential treatments. Based on the implications, we propose tests of the restrictions and demonstrate their practical relevance through a simulation study and an empirical application.</description>
      <guid isPermaLink="false">oai:arXiv.org:2411.09808v2</guid>
      <category>econ.EM</category>
      <pubDate>Wed, 19 Feb 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Yuehao Bai, Shunzhuang Huang, Max Tabord-Meehan</dc:creator>
    </item>
    <item>
      <title>Selective Reviews of Bandit Problems in AI via a Statistical View</title>
      <link>https://arxiv.org/abs/2412.02251</link>
      <description>arXiv:2412.02251v3 Announce Type: replace-cross 
Abstract: Reinforcement Learning (RL) is a widely researched area in artificial intelligence that focuses on teaching agents decision-making through interactions with their environment. A key subset includes stochastic multi-armed bandit (MAB) and continuum-armed bandit (SCAB) problems, which model sequential decision-making under uncertainty. This review outlines the foundational models and assumptions of bandit problems, explores non-asymptotic theoretical tools like concentration inequalities and minimax regret bounds, and compares frequentist and Bayesian algorithms for managing exploration-exploitation trade-offs. Additionally, we explore K-armed contextual bandits and SCAB, focusing on their methodologies and regret analyses. We also examine the connections between SCAB problems and functional data analysis. Finally, we highlight recent advances and ongoing challenges in the field.</description>
      <guid isPermaLink="false">oai:arXiv.org:2412.02251v3</guid>
      <category>stat.ML</category>
      <category>cs.AI</category>
      <category>cs.LG</category>
      <category>econ.EM</category>
      <category>math.PR</category>
      <pubDate>Wed, 19 Feb 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Pengjie Zhou, Haoyu Wei, Huiming Zhang</dc:creator>
    </item>
    <item>
      <title>A Non-Parametric Approach to Heterogeneity Analysis</title>
      <link>https://arxiv.org/abs/2501.13721</link>
      <description>arXiv:2501.13721v2 Announce Type: replace-cross 
Abstract: This paper introduces a network-based method to capture heterogeneity in consumer microdata. We develop a permutation-based approach that repeatedly combines random samples of all agents' decisions, and partitions agents into jointly rational types. Aggregating these partitions yields a network that captures unobserved heterogeneity, where edges measure how often two agents share the same type across partitions. To evaluate how observable characteristics align with the heterogeneity, we implement permutation tests that shuffle covariate labels across network nodes, thereby generating a null distribution of alignment. We show that this test is exact, with asymptotic power of one. We further propose network-based measures that quantify whether nodes with the same observable attributes are disproportionately linked or clustered, along with standardized effect sizes that gauge each covariate's global influence. This yields a flexible, nonparametric measure of the heterogeneity structure. Finally, we apply our method to grocery expenditure data from the Stanford Basket Dataset.</description>
      <guid isPermaLink="false">oai:arXiv.org:2501.13721v2</guid>
      <category>econ.TH</category>
      <category>econ.EM</category>
      <pubDate>Wed, 19 Feb 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Avner Seror</dc:creator>
    </item>
  </channel>
</rss>
