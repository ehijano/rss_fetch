<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>math.OC updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/math.OC</link>
    <description>math.OC updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/math.OC" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Tue, 04 Feb 2025 04:07:30 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Mon, 03 Feb 2025 00:00:00 -0500</pubDate>
    <skipDays>
      <day>Saturday</day>
      <day>Sunday</day>
    </skipDays>
    <item>
      <title>Beyond Short Steps in Frank-Wolfe Algorithms</title>
      <link>https://arxiv.org/abs/2501.18773</link>
      <description>arXiv:2501.18773v1 Announce Type: new 
Abstract: We introduce novel techniques to enhance Frank-Wolfe algorithms by leveraging function smoothness beyond traditional short steps. Our study focuses on Frank-Wolfe algorithms with step sizes that incorporate primal-dual guarantees, offering practical stopping criteria. We present a new Frank-Wolfe algorithm utilizing an optimistic framework and provide a primal-dual convergence proof. Additionally, we propose a generalized short-step strategy aimed at optimizing a computable primal-dual gap. Interestingly, this new generalized short-step strategy is also applicable to gradient descent algorithms beyond Frank-Wolfe methods. As a byproduct, our work revisits and refines primal-dual techniques for analyzing Frank-Wolfe algorithms, achieving tighter primal-dual convergence rates. Empirical results demonstrate that our optimistic algorithm outperforms existing methods, highlighting its practical advantages.</description>
      <guid isPermaLink="false">oai:arXiv.org:2501.18773v1</guid>
      <category>math.OC</category>
      <category>cs.LG</category>
      <pubDate>Mon, 03 Feb 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>David Mart\'inez-Rubio, Sebastian Pokutta</dc:creator>
    </item>
    <item>
      <title>Secant Line Search for Frank-Wolfe Algorithms</title>
      <link>https://arxiv.org/abs/2501.18775</link>
      <description>arXiv:2501.18775v1 Announce Type: new 
Abstract: We present a new step-size strategy based on the secant method for Frank-Wolfe algorithms. This strategy, which requires mild assumptions about the function under consideration, can be applied to any Frank-Wolfe algorithm. It is as effective as full line search and, in particular, allows for adapting to the local smoothness of the function, such as in (Pedregosa et al., 2020), but comes with a significantly reduced computational cost, leading to higher effective rates of convergence. We provide theoretical guarantees and demonstrate the effectiveness of the strategy through numerical experiments.</description>
      <guid isPermaLink="false">oai:arXiv.org:2501.18775v1</guid>
      <category>math.OC</category>
      <pubDate>Mon, 03 Feb 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Deborah Hendrych, Mathieu Besan\c{c}on, David Mart\'inez-Rubio, Sebastian Pokutta</dc:creator>
    </item>
    <item>
      <title>A two-stage stochastic MINLP model to design and operate a multi-energy microgrid by addressing carbon emission regulatory policies uncertainty</title>
      <link>https://arxiv.org/abs/2501.18988</link>
      <description>arXiv:2501.18988v1 Announce Type: new 
Abstract: This study suggests a novel two-stage Mixed-Integer Nonlinear Programming model considering uncertainty related to implementation of carbon dioxide emission regulatory policies, which are carbon trading and emission taxing and can change over the years, for the purpose of optimal equipment selection from candidate equipment to design, size and operate a multi-energy microgrid. The uncertain sources are air temperature, wind speed, solar radiation, carbon dioxide trading price or tax, and natural gas price. Candidate equipment are wind turbines, PV arrays, a biomass-fired generator, biomass combined cycles, combined heat and power generators, conventional generators, an electricity storage unit, integrated gasification combined cycles, a heat pump, and a power-to-synthetic natural gas (P2G) system. Three case studies are investigated. In the first case, the model selects the optimal equipment for meeting the electricity and heat demands only. In the second case, the optimal equipment selections are determined to couple with the P2G system to meet the electricity, heat, and natural gas demands. In the third case, the model selects the optimal equipment to run with sustainable energy generators: wind turbines and solar panels. The optimal selections are compared between deterministic and stochastic forms of the optimization models.</description>
      <guid isPermaLink="false">oai:arXiv.org:2501.18988v1</guid>
      <category>math.OC</category>
      <pubDate>Mon, 03 Feb 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Handan Ak\"ulker, Burak Alakent, Erdal Aydin</dc:creator>
    </item>
    <item>
      <title>Assessing the effectiveness of park-and-ride facilities on multimodal networks in smart cities</title>
      <link>https://arxiv.org/abs/2501.18999</link>
      <description>arXiv:2501.18999v1 Announce Type: new 
Abstract: This paper presents an optimization procedure to choose a parking facility according to different criteria: total travel time including transfers, parking fee and a factor depending on the risk of not having an available spot in the parking facility at the arrival time. An integer programming formulation is proposed to determine an optimal strategy of minimum cost considering the available information, different scenarios, and each user profile. To evaluate the performance, a computational experience has been carried out on Seville (Spain), where a historical city center restricts the traffic of private vehicles and encourages the use of parking facilities.</description>
      <guid isPermaLink="false">oai:arXiv.org:2501.18999v1</guid>
      <category>math.OC</category>
      <pubDate>Mon, 03 Feb 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <arxiv:DOI>10.1080/01605682.2020.1854628</arxiv:DOI>
      <arxiv:journal_reference>Journal of the Operational Research Society 2022</arxiv:journal_reference>
      <dc:creator>Juan A Mesa, Francisco A Ortega, Miguel A Pozo, Ram\'on Piedra-de-la-Cuadra</dc:creator>
    </item>
    <item>
      <title>Bilevel optimization for the deployment of refuelling stations for electric vehicles on road networks</title>
      <link>https://arxiv.org/abs/2501.19000</link>
      <description>arXiv:2501.19000v1 Announce Type: new 
Abstract: This work consists of a procedure to optimally select, among a group of candidate sites where gas stations were already located, a sufficient number of charging points in order to guarantee that an electric vehicle can make its journey without a problem of energy autonomy and that each selected charging station has another one that serves as useful support in case of failure (reinforced coverage service). For this purpose, we propose a bilevel model that, in a former level, minimizes the number of refuelling points necessary to guarantee a reinforced service coverage for all users who transit from their origin to destination and, as a second level, maximize the volume of demand that can be satisfied subject to budgetary restrictions. With the first of the objectives we are addressing the typical requirement of the administration, which consists of guaranteeing the viability of the solutions, and the second of the objectives is a criterion typically used by the private sector initiative, compatible with the profit maximization.</description>
      <guid isPermaLink="false">oai:arXiv.org:2501.19000v1</guid>
      <category>math.OC</category>
      <pubDate>Mon, 03 Feb 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <arxiv:DOI>10.1016/j.cor.2023.106460</arxiv:DOI>
      <arxiv:journal_reference>Computers &amp; Operations Research 2024</arxiv:journal_reference>
      <dc:creator>Ram\'on Piedra-de-la-Cuadra, Francisco Ortega</dc:creator>
    </item>
    <item>
      <title>A heuristic for the deployment of collecting routes for urban recycle stations (eco-points)</title>
      <link>https://arxiv.org/abs/2501.19007</link>
      <description>arXiv:2501.19007v1 Announce Type: new 
Abstract: The rapid and constant increase in urban population has led to a drastic rise in urban solid waste production with worrying consequences for the environment and society. In many cities, an efficient waste management combined with a suitable design of vehicle routes (VR) can lead to benefits in the environmental, economic, and social impacts. The general population is becoming increasingly aware of the need for the separation of the various categories of municipal solid waste. The numerous materials collected include glass, PET or batteries, and electric components, which are sorted at the eco-points. The management of eco-points gives rise to several problems that can be formulated analytically. The location and number of eco-point containers, the determination of the fleet size for picking up the collected waste, and the design of itineraries are all intertwined, and present computationally difficult problems, and therefore must be solved in a sequential way. In this paper, a mathematical model has been formulated, based on the Bin Packing (BP) and VR schemes, for the deployment of routes of mobile containers in the selective collection of urban solid waste. A heuristic algorithm has also been developed, which considers two different configurations of the containers to solve the proposed mathematical programming model. The results obtained from the numerical simulations show the validation of the proposed methodology carried out for the benchmark of the Sioux Falls network and the specific real case study.</description>
      <guid isPermaLink="false">oai:arXiv.org:2501.19007v1</guid>
      <category>math.OC</category>
      <pubDate>Mon, 03 Feb 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <arxiv:DOI>10.1016/j.seps.2021.101222</arxiv:DOI>
      <arxiv:journal_reference>Socio-Economic Planning Sciences 2022</arxiv:journal_reference>
      <dc:creator>Guido Marseglia, Juan Antonio Mesa, Francisco A Ortega, Ram\'on Piedra-de-la-Cuadra</dc:creator>
    </item>
    <item>
      <title>Epi-Consistent Approximation of Stochastic Dynamic Programs</title>
      <link>https://arxiv.org/abs/2501.19028</link>
      <description>arXiv:2501.19028v1 Announce Type: new 
Abstract: We study the consistency of stochastic dynamic programs under converging probability distributions and other approximations. Utilising results on the epi-convergence of expectation functions with varying measures and integrands, and the Attouch-Wets distance, we show that appropriate equi-semicontinuity assumptions assure epi-consistency. A number of examples illustrate the approach. In particular, we permit both unbounded and simultaneously-approximated stage-cost functions, and treat an example with approximated constraints.</description>
      <guid isPermaLink="false">oai:arXiv.org:2501.19028v1</guid>
      <category>math.OC</category>
      <pubDate>Mon, 03 Feb 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Dominic S. T. Keehan, Johannes O. Royset</dc:creator>
    </item>
    <item>
      <title>On the Computation of the Efficient Frontier in Advanced Portfolio Optimization</title>
      <link>https://arxiv.org/abs/2501.19199</link>
      <description>arXiv:2501.19199v1 Announce Type: new 
Abstract: In this work, we deal with the problem of computing a comprehensive front of efficient solutions in multi-objective portfolio optimization problems in presence of sparsity constraints. We start the discussion pointing out some weaknesses of the classical scalarization approach when applied to the considered class of problems. We are then motivated to propose a suitable algorithmic framework that is designed to overcome these limitations: the novel algorithm combines a gradient-based exploration-refinement strategy with a tailored initialization scheme based on memetic or multi-start descent procedures. Thorough computational experiments highlight how the proposed method is far superior to both scalarization and popular genetic algorithms.</description>
      <guid isPermaLink="false">oai:arXiv.org:2501.19199v1</guid>
      <category>math.OC</category>
      <pubDate>Mon, 03 Feb 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Arturo Annunziata, Matteo Lapucci, Pieluigi Mansueto, Davide Pucci</dc:creator>
    </item>
    <item>
      <title>A single-loop SPIDER-type stochastic subgradient method for expectation-constrained nonconvex nonsmooth optimization</title>
      <link>https://arxiv.org/abs/2501.19214</link>
      <description>arXiv:2501.19214v1 Announce Type: new 
Abstract: Many real-world problems, such as those with fairness constraints, involve complex expectation constraints and large datasets, necessitating the design of efficient stochastic methods to solve them. Most existing research focuses on cases with no {constraint} or easy-to-project constraints or deterministic constraints. In this paper, we consider nonconvex nonsmooth stochastic optimization problems with expectation constraints, for which we build a novel exact penalty model. We first show the relationship between the penalty model and the original problem. Then on solving the penalty problem, we present a single-loop SPIDER-type stochastic subgradient method, which utilizes the subgradients of both the objective and constraint functions, as well as the constraint function value at each iteration. Under certain regularity conditions (weaker than Slater-type constraint qualification or strong feasibility assumed in existing works), we establish an iteration complexity result of $O(\epsilon^{-4})$ to reach a near-$\epsilon$ stationary point of the penalized problem in expectation, matching the lower bound for such tasks. Building on the exact penalization, an $(\epsilon,\epsilon)$-KKT point of the original problem is obtained. For a few scenarios, our complexity of either the {objective} sample subgradient or the constraint sample function values can be lower than the state-of-the-art results by a factor of $\epsilon^{-2}$. Moreover, on solving two fairness-constrained problems, our method is significantly (up to 466 times) faster than the state-of-the-art algorithms, including switching subgradient method and inexact proximal point methods.</description>
      <guid isPermaLink="false">oai:arXiv.org:2501.19214v1</guid>
      <category>math.OC</category>
      <category>cs.CC</category>
      <category>cs.LG</category>
      <category>cs.NA</category>
      <category>math.NA</category>
      <pubDate>Mon, 03 Feb 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Wei Liu, Yangyang Xu</dc:creator>
    </item>
    <item>
      <title>How to project onto SL($n$)</title>
      <link>https://arxiv.org/abs/2501.19310</link>
      <description>arXiv:2501.19310v1 Announce Type: new 
Abstract: We consider the closest-point projection with respect to the Frobenius norm of a general real square matrix to the set SL($n$) of matrices with unit determinant. As it turns out, it is sufficient to consider diagonal matrices only. We investigate the structure of the problem both in Euclidean coordinates and in an $n$-dimensional generalization of the classical hyperbolic coordinates of the positive quadrant. Using symmetry arguments we show that the global minimizer is contained in a particular cone. Based on different views of the problem, we propose four different iterative algorithms, and we give convergence results for all of them. Numerical tests show that computing the projection costs essentially as much as a singular value decomposition. Finally, we give an explicit formula for the first derivative of the projection.</description>
      <guid isPermaLink="false">oai:arXiv.org:2501.19310v1</guid>
      <category>math.OC</category>
      <pubDate>Mon, 03 Feb 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Patrick Jaap, Oliver Sander</dc:creator>
    </item>
    <item>
      <title>Differentially Private Linear Programming: Reduced Sub-Optimality and Guaranteed Constraint Satisfaction</title>
      <link>https://arxiv.org/abs/2501.19315</link>
      <description>arXiv:2501.19315v1 Announce Type: new 
Abstract: Linear programming is a fundamental tool in a wide range of decision systems. However, without privacy protections, sharing the solution to a linear program may reveal information about the underlying data used to formulate it, which may be sensitive. Therefore, in this paper, we introduce an approach for protecting sensitive data while formulating and solving a linear program. First, we prove that this method perturbs objectives and constraints in a way that makes them differentially private. Then, we show that (i) privatized problems always have solutions, and (ii) their solutions satisfy the constraints in their corresponding original, non-private problems. The latter result solves an open problem in the literature. Next, we analytically bound the expected sub-optimality of solutions that is induced by privacy. Numerical simulations show that, under a typical privacy setup, the solution produced by our method yields a $65\%$ reduction in sub-optimality compared to the state of the art.</description>
      <guid isPermaLink="false">oai:arXiv.org:2501.19315v1</guid>
      <category>math.OC</category>
      <pubDate>Mon, 03 Feb 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Alexander Benvenuti, Brendan Bialy, Miriam Dennis, Matthew Hale</dc:creator>
    </item>
    <item>
      <title>Global and local approaches for the minimization of a sum of pointwise minima of convex functions</title>
      <link>https://arxiv.org/abs/2501.19372</link>
      <description>arXiv:2501.19372v1 Announce Type: new 
Abstract: Numerous machine learning and industrial problems can be modeled as the minimization of a sum of $N$ so-called clipped convex functions (SCC), i.e. each term of the sum stems as the pointwise minimum between a constant and a convex function. In this work, we extend this framework to capture more problems of interest. Specifically, we allow each term of the sum to be a pointwise minimum of an arbitrary number of convex functions, called components, turning the objective into a sum of pointwise minima of convex functions (SMC).
  Problem (SCC) is NP-hard, highlighting an appeal for scalable local heuristics. In this spirit, one can express (SMC) objectives as the difference between two convex functions to leverage the possibility to apply (DC) algorithms to compute critical points of the problem. Our approach relies on a bi-convex reformulation of the problem. From there, we derive a family of local methods, dubbed as relaxed alternating minimization (r-AM) methods, that include classical alternating minimization (AM) as a special case. We prove that every accumulation point of r-AM is critical. In addition, we show the empirical superiority of r-AM, compared to traditional AM and (DC) approaches, on piecewise-linear regression and restricted facility location problems.
  Under mild assumptions, (SCC) can be cast as a mixed-integer convex program (MICP) using perspective functions. This approach can be generalized to (SMC) but introduces many copies of the primal variable. In contrast, we suggest a compact big-M based (MICP) equivalent formulation of (SMC), free of these extra variables. Finally, we showcase practical examples where solving our (MICP), restricted to a neighbourhood of a given candidate (i.e. output iterate of a local method), will either certify the candidate's optimality on that neighbourhood or providing a new point, strictly better, to restart the local method.</description>
      <guid isPermaLink="false">oai:arXiv.org:2501.19372v1</guid>
      <category>math.OC</category>
      <pubDate>Mon, 03 Feb 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Guillaume Van Dessel, Fran\c{c}ois Glineur</dc:creator>
    </item>
    <item>
      <title>From a Frequency-Domain Willems' Lemma to Data-Driven Predictive Control</title>
      <link>https://arxiv.org/abs/2501.19390</link>
      <description>arXiv:2501.19390v1 Announce Type: new 
Abstract: Willems' fundamental lemma has recently received an impressive amount of attention from the (data-driven) control community. In this paper, we formulate a version of this celebrated result based on frequency-domain data. In doing so, we bridge the gap between recent developments in data-driven analysis and control, and the readily-available techniques and extensive expertise for non-parametric frequency-domain identification in academia and industry. In addition, we generalize our results to allow multiple frequency-domain data sets to be carefully combined to form a sufficiently rich data set. Building on these results, we propose a data-driven predictive control scheme based on measured frequency-domain data of the plant. This novel scheme provides a frequency-domain counterpart of the well-known data-enabled predictive control scheme DeePC based on time-domain data. We prove that, under appropriate conditions, the new frequency-domain data-driven predictive control (FreePC) scheme is equivalent to the corresponding DeePC scheme, and we demonstrate the benefits of FreePC and the use of frequency-domain data in a numerical case study. These benefits include the ability to collect data in closed loop with a pre-stabilizing controller, dealing with noisy data, without increasing computational complexity, and intuitively visualizing the uncertainty in the frequency-domain data. In addition, we further showcase the potential of our frequency-domain Willems' fundamental lemma in applications to data-driven simulation, and the linear-quadratic regulator (LQR) problem. Finally, we show that our results can be used to evaluate the transfer function of the system at a desired frequency based on a finite amount of frequency-domain data.</description>
      <guid isPermaLink="false">oai:arXiv.org:2501.19390v1</guid>
      <category>math.OC</category>
      <category>cs.SY</category>
      <category>eess.SY</category>
      <pubDate>Mon, 03 Feb 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>T. J. Meijer, K. J. A. Scheres, S. A. N. Nouwens, V. S. Dolk, W. P. M. H. Heemels</dc:creator>
    </item>
    <item>
      <title>Distributed Offloading in Multi-Access Edge Computing Systems: A Mean-Field Perspective</title>
      <link>https://arxiv.org/abs/2501.18718</link>
      <description>arXiv:2501.18718v1 Announce Type: cross 
Abstract: Multi-access edge computing (MEC) technology is a promising solution to assist power-constrained IoT devices by providing additional computing resources for time-sensitive tasks. In this paper, we consider the problem of optimal task offloading in MEC systems with due consideration of the timeliness and scalability issues under two scenarios of equitable and priority access to the edge server (ES). In the first scenario, we consider a MEC system consisting of $N$ devices assisted by one ES, where the devices can split task execution between a local processor and the ES, with equitable access to the ES. In the second scenario, we consider a MEC system consisting of one primary user, $N$ secondary users and one ES. The primary user has priority access to the ES while the secondary users have equitable access to the ES amongst themselves. In both scenarios, due to the power consumption associated with utilizing the local resource and task offloading, the devices must optimize their actions. Additionally, since the ES is a shared resource, other users' offloading activity serves to increase latency incurred by each user. We thus model both scenarios using a non-cooperative game framework. However, the presence of a large number of users makes it nearly impossible to compute the equilibrium offloading policies for each user, which would require a significant information exchange overhead between users. Thus, to alleviate such scalability issues, we invoke the paradigm of mean-field games to compute approximate Nash equilibrium policies for each user using their local information, and further study the trade-offs between increasing information freshness and reducing power consumption for each user. Using numerical evaluations, we show that our approach can recover the offloading trends displayed under centralized solutions, and provide additional insights into the results obtained.</description>
      <guid isPermaLink="false">oai:arXiv.org:2501.18718v1</guid>
      <category>cs.IT</category>
      <category>cs.MA</category>
      <category>cs.SY</category>
      <category>eess.SY</category>
      <category>math.IT</category>
      <category>math.OC</category>
      <pubDate>Mon, 03 Feb 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Shubham Aggarwal, Muhammad Aneeq uz Zaman, Melih Bastopcu, Sennur Ulukus, Tamer Ba\c{s}ar</dc:creator>
    </item>
    <item>
      <title>Optimizing Bidding Curves for Renewable Energy in Two-Settlement Electricity Markets</title>
      <link>https://arxiv.org/abs/2501.18732</link>
      <description>arXiv:2501.18732v1 Announce Type: cross 
Abstract: Coordination of day-ahead and real-time electricity markets is imperative for cost-effective electricity supply and also to provide efficient incentives for the energy transition. Although stochastic market designs feature the least-cost coordination, they are incompatible with current deterministic markets. This paper proposes a new approach for compatible coordination in two-settlement markets based on benchmark bidding curves for variable renewable energy. These curves are optimized based on a bilevel optimization problem, anticipating per-scenario responses of deterministic market-clearing problems and ultimately minimizing the expected cost across day-ahead and real-time markets. Although the general bilevel model is challenging to solve, we theoretically prove that a single-segment bidding curve with a zero bidding price is sufficient to achieve system optimality if the marginal cost of variable renewable energy is zero, thus addressing the computational challenge. In practice, variable renewable energy producers can be allowed to bid multi-segment curves with non-zero prices. We test the bilevel framework for both single- and multiple-segment bidding curves under the assumption of fixed bidding prices. We leverage duality theory and McCormick envelopes to derive the linear programming approximation of the bilevel problem, which scales to practical systems such as a 1576-bus NYISO system. We benchmark the proposed coordination and find absolute dominance over the baseline solution, which assumes that renewables agnostically bid their expected forecasts. We also demonstrate that our proposed scheme provides a good approximation of the least-cost, yet unattainable in practice, stochastic market outcome.</description>
      <guid isPermaLink="false">oai:arXiv.org:2501.18732v1</guid>
      <category>eess.SY</category>
      <category>cs.SY</category>
      <category>math.OC</category>
      <pubDate>Mon, 03 Feb 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Dongwei Zhao, Stefanos Delikaraogloub, Vladimir Dvorkin Alberto J. Lamadrid L., Audun Botterud</dc:creator>
    </item>
    <item>
      <title>A Unified Framework for Entropy Search and Expected Improvement in Bayesian Optimization</title>
      <link>https://arxiv.org/abs/2501.18756</link>
      <description>arXiv:2501.18756v1 Announce Type: cross 
Abstract: Bayesian optimization is a widely used method for optimizing expensive black-box functions, with Expected Improvement being one of the most commonly used acquisition functions. In contrast, information-theoretic acquisition functions aim to reduce uncertainty about the function's optimum and are often considered fundamentally distinct from EI. In this work, we challenge this prevailing perspective by introducing a unified theoretical framework, Variational Entropy Search, which reveals that EI and information-theoretic acquisition functions are more closely related than previously recognized. We demonstrate that EI can be interpreted as a variational inference approximation of the popular information-theoretic acquisition function, named Max-value Entropy Search. Building on this insight, we propose VES-Gamma, a novel acquisition function that balances the strengths of EI and MES. Extensive empirical evaluations across both low- and high-dimensional synthetic and real-world benchmarks demonstrate that VES-Gamma is competitive with state-of-the-art acquisition functions and in many cases outperforms EI and MES.</description>
      <guid isPermaLink="false">oai:arXiv.org:2501.18756v1</guid>
      <category>stat.ML</category>
      <category>cs.LG</category>
      <category>math.OC</category>
      <pubDate>Mon, 03 Feb 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Nuojin Cheng, Leonard Papenmeier, Stephen Becker, Luigi Nardi</dc:creator>
    </item>
    <item>
      <title>Tuning Event Camera Biases Heuristic for Object Detection Applications in Staring Scenarios</title>
      <link>https://arxiv.org/abs/2501.18788</link>
      <description>arXiv:2501.18788v1 Announce Type: cross 
Abstract: One of the main challenges in unlocking the potential of neuromorphic cameras, also called 'event cameras', is the development of novel methods that solve the multi-parameter problem of adjusting their bias parameters to accommodate a desired task. Actually, it is very difficult to find in the literature a systematic heuristic that solves the problem for any desired application.
  In this paper we present a tuning parametes heuristic for the biases of event cameras, for tasks that require small objects detection in staring scenarios. The main purpose of the heuristic is to squeeze the camera's potential, optimize its performance, and expand its detection capabilities as much as possible.
  In the presentation, we translate the experimental properties of event camera and systemic constrains into mathematical terms, and show, under certain assumptions, how the multi-variable problem collapses into a two-parameter problem that can be solved experimentally.
  A main conclusion that will be demonstrated is that for certain desired signals, such as the one provided by an incandescent lamp powered by the periodic electrical grid, the optimal values of the camera are very far from the default values recommended by the manufacturer.</description>
      <guid isPermaLink="false">oai:arXiv.org:2501.18788v1</guid>
      <category>cs.CV</category>
      <category>math.OC</category>
      <pubDate>Mon, 03 Feb 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>David El-Chai Ben-Ezra, Daniel Brisk</dc:creator>
    </item>
    <item>
      <title>Bayesian Optimization with Preference Exploration by Monotonic Neural Network Ensemble</title>
      <link>https://arxiv.org/abs/2501.18792</link>
      <description>arXiv:2501.18792v1 Announce Type: cross 
Abstract: Many real-world black-box optimization problems have multiple conflicting objectives. Rather than attempting to approximate the entire set of Pareto-optimal solutions, interactive preference learning allows to focus the search on the most relevant subset. However, few previous studies have exploited the fact that utility functions are usually monotonic. In this paper, we address the Bayesian Optimization with Preference Exploration (BOPE) problem and propose using a neural network ensemble as a utility surrogate model. This approach naturally integrates monotonicity and supports pairwise comparison data. Our experiments demonstrate that the proposed method outperforms state-of-the-art approaches and exhibits robustness to noise in utility evaluations. An ablation study highlights the critical role of monotonicity in enhancing performance.</description>
      <guid isPermaLink="false">oai:arXiv.org:2501.18792v1</guid>
      <category>cs.LG</category>
      <category>math.OC</category>
      <category>stat.ML</category>
      <pubDate>Mon, 03 Feb 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Hanyang Wang, Juergen Branke, Matthias Poloczek</dc:creator>
    </item>
    <item>
      <title>Deceptive Sequential Decision-Making via Regularized Policy Optimization</title>
      <link>https://arxiv.org/abs/2501.18803</link>
      <description>arXiv:2501.18803v1 Announce Type: cross 
Abstract: Autonomous systems are increasingly expected to operate in the presence of adversaries, though an adversary may infer sensitive information simply by observing a system, without even needing to interact with it. Therefore, in this work we present a deceptive decision-making framework that not only conceals sensitive information, but in fact actively misleads adversaries about it. We model autonomous systems as Markov decision processes, and we consider adversaries that attempt to infer their reward functions using inverse reinforcement learning. To counter such efforts, we present two regularization strategies for policy synthesis problems that actively deceive an adversary about a system's underlying rewards. The first form of deception is ``diversionary'', and it leads an adversary to draw any false conclusion about what the system's reward function is. The second form of deception is ``targeted'', and it leads an adversary to draw a specific false conclusion about what the system's reward function is. We then show how each form of deception can be implemented in policy optimization problems, and we analytically bound the loss in total accumulated reward that is induced by deception. Next, we evaluate these developments in a multi-agent sequential decision-making problem with one real agent and multiple decoys. We show that diversionary deception can cause the adversary to believe that the most important agent is the least important, while attaining a total accumulated reward that is $98.83\%$ of its optimal, non-deceptive value. Similarly, we show that targeted deception can make any decoy appear to be the most important agent, while still attaining a total accumulated reward that is $99.25\%$ of its optimal, non-deceptive value.</description>
      <guid isPermaLink="false">oai:arXiv.org:2501.18803v1</guid>
      <category>cs.LG</category>
      <category>math.OC</category>
      <pubDate>Mon, 03 Feb 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Yerin Kim, Alexander Benvenuti, Bo Chen, Mustafa Karabag, Abhishek Kulkarni, Nathaniel D. Bastian, Ufuk Topcu, Matthew Hale</dc:creator>
    </item>
    <item>
      <title>Continuous-Time Analysis of Federated Averaging</title>
      <link>https://arxiv.org/abs/2501.18870</link>
      <description>arXiv:2501.18870v1 Announce Type: cross 
Abstract: Federated averaging (FedAvg) is a popular algorithm for horizontal federated learning (FL), where samples are gathered across different clients and are not shared with each other or a central server. Extensive convergence analysis of FedAvg exists for the discrete iteration setting, guaranteeing convergence for a range of loss functions and varying levels of data heterogeneity. We extend this analysis to the continuous-time setting where the global weights evolve according to a multivariate stochastic differential equation (SDE), which is the first time FedAvg has been studied from the continuous-time perspective. We use techniques from stochastic processes to establish convergence guarantees under different loss functions, some of which are more general than existing work in the discrete setting. We also provide conditions for which FedAvg updates to the server weights can be approximated as normal random variables. Finally, we use the continuous-time formulation to reveal generalization properties of FedAvg.</description>
      <guid isPermaLink="false">oai:arXiv.org:2501.18870v1</guid>
      <category>cs.LG</category>
      <category>cs.DC</category>
      <category>math.OC</category>
      <pubDate>Mon, 03 Feb 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Tom Overman, Diego Klabjan</dc:creator>
    </item>
    <item>
      <title>Fully Distributed and Quantized Algorithm for MPC-based Autonomous Vehicle Platooning Optimization</title>
      <link>https://arxiv.org/abs/2501.18889</link>
      <description>arXiv:2501.18889v1 Announce Type: cross 
Abstract: Intelligent transportation systems have recently emerged to address the growing interest for safer, more efficient, and sustainable transportation solutions. In this direction, this paper presents distributed algorithms for control and optimization over vehicular networks. First, we formulate the autonomous vehicle platooning framework based on model-predictive-control (MPC) strategies and present its objective optimization as a cooperative quadratic cost function. Then, we propose a distributed algorithm to locally optimize this objective at every vehicle subject to data quantization over the communication network of vehicles. In contrast to most existing literature that assumes ideal communication channels, log-scale data quantization over the network is addressed in this work, which is more realistic and practical. In particular, we show by simulation that the proposed log-quantized algorithm reaches optimal convergence with less residual and optimality gap. This outperforms the existing literature considering uniform quantization which leads to a large optimality gap and residual.</description>
      <guid isPermaLink="false">oai:arXiv.org:2501.18889v1</guid>
      <category>eess.SY</category>
      <category>cs.MA</category>
      <category>cs.SY</category>
      <category>eess.SP</category>
      <category>math.OC</category>
      <pubDate>Mon, 03 Feb 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Mohammadreza Doostmohammadian, Alireza Aghasi, Hamid R. Rabiee</dc:creator>
    </item>
    <item>
      <title>Distributed Observer Design for Tracking Platoon of Connected and Autonomous Vehicles</title>
      <link>https://arxiv.org/abs/2501.18890</link>
      <description>arXiv:2501.18890v1 Announce Type: cross 
Abstract: Intelligent transportation systems (ITS) aim to advance innovative strategies relating to different modes of transport, traffic management, and autonomous vehicles. This paper studies the platoon of connected and autonomous vehicles (CAV) and proposes a distributed observer to track the state of the CAV dynamics. First, we model the CAV dynamics via an LTI interconnected system. Then, a consensus-based strategy is proposed to infer the state of the CAV dynamics based on local information exchange over the communication network of vehicles. A linear-matrix-inequality (LMI) technique is adopted for the block-diagonal observer gain design such that this gain is associated in a distributed way and locally to every vehicle. The distributed observer error dynamics is then shown to follow the structure of the Kronecker matrix product of the system dynamics and the adjacency matrix of the CAV network. The notions of survivable network design and redundant observer scheme are further discussed in the paper to address resilience to link and node failure. Finally, we verify our theoretical contributions via numerical simulations.</description>
      <guid isPermaLink="false">oai:arXiv.org:2501.18890v1</guid>
      <category>eess.SY</category>
      <category>cs.MA</category>
      <category>cs.SY</category>
      <category>eess.SP</category>
      <category>math.OC</category>
      <pubDate>Mon, 03 Feb 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Mohammadreza Doostmohammadian, Hamid R. Rabiee</dc:creator>
    </item>
    <item>
      <title>Minimum Time Strategies for a Differential Drive Robot Escaping from a Circular Detection Region</title>
      <link>https://arxiv.org/abs/2501.18899</link>
      <description>arXiv:2501.18899v1 Announce Type: cross 
Abstract: A Differential Drive Robot (DDR) located inside a circular detection region in the plane wants to escape from it in minimum time. Various robotics applications can be modeled like the previous problem, such as a DDR escaping as soon as possible from a forbidden/dangerous region in the plane or running out from the sensor footprint of an unmanned vehicle flying at a constant altitude. In this paper, we find the motion strategies to accomplish its goal under two scenarios. In one, the detection region moves slower than the DDR and seeks to prevent escape; in another, its position is fixed. We formulate the problem as a zero-sum pursuit-evasion game, and using differential games theory, we compute the players' time-optimal motion strategies. Given the DDR's speed advantage, it can always escape by translating away from the center of the detection region at maximum speed. In this work, we show that the previous strategy could be optimal in some cases; however, other motion strategies emerge based on the player's speed ratio and the players' initial configurations.</description>
      <guid isPermaLink="false">oai:arXiv.org:2501.18899v1</guid>
      <category>cs.RO</category>
      <category>math.OC</category>
      <pubDate>Mon, 03 Feb 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Ubaldo Ruiz</dc:creator>
    </item>
    <item>
      <title>Solving Inverse Problem for Multi-armed Bandits via Convex Optimization</title>
      <link>https://arxiv.org/abs/2501.18945</link>
      <description>arXiv:2501.18945v1 Announce Type: cross 
Abstract: We consider the inverse problem of multi-armed bandits (IMAB) that are widely used in neuroscience and psychology research for behavior modelling. We first show that the IMAB problem is not convex in general, but can be relaxed to a convex problem via variable transformation. Based on this result, we propose a two-step sequential heuristic for (approximately) solving the IMAB problem. We discuss a condition where our method provides global solution to the IMAB problem with certificate, as well as approximations to further save computing time. Numerical experiments indicate that our heuristic method is more robust than directly solving the IMAB problem via repeated local optimization, and can achieve the performance of Monte Carlo methods within a significantly decreased running time. We provide the implementation of our method based on CVXPY, which allows straightforward application by users not well versed in convex optimization.</description>
      <guid isPermaLink="false">oai:arXiv.org:2501.18945v1</guid>
      <category>cs.CE</category>
      <category>cs.LG</category>
      <category>math.OC</category>
      <category>q-bio.NC</category>
      <pubDate>Mon, 03 Feb 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Hao Zhu, Joschka Boedecker</dc:creator>
    </item>
    <item>
      <title>The Surprising Agreement Between Convex Optimization Theory and Learning-Rate Scheduling for Large Model Training</title>
      <link>https://arxiv.org/abs/2501.18965</link>
      <description>arXiv:2501.18965v1 Announce Type: cross 
Abstract: We show that learning-rate schedules for large model training behave surprisingly similar to a performance bound from non-smooth convex optimization theory. We provide a bound for the constant schedule with linear cooldown; in particular, the practical benefit of cooldown is reflected in the bound due to the absence of logarithmic terms. Further, we show that this surprisingly close match between optimization theory and practice can be exploited for learning-rate tuning: we achieve noticeable improvements for training 124M and 210M Llama-type models by (i) extending the schedule for continued training with optimal learning-rate, and (ii) transferring the optimal learning-rate across schedules.</description>
      <guid isPermaLink="false">oai:arXiv.org:2501.18965v1</guid>
      <category>cs.LG</category>
      <category>math.OC</category>
      <category>stat.ML</category>
      <pubDate>Mon, 03 Feb 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Fabian Schaipp, Alexander H\"agele, Adrien Taylor, Umut Simsekli, Francis Bach</dc:creator>
    </item>
    <item>
      <title>A Bias-Correction Decentralized Stochastic Gradient Algorithm with Momentum Acceleration</title>
      <link>https://arxiv.org/abs/2501.19082</link>
      <description>arXiv:2501.19082v1 Announce Type: cross 
Abstract: Distributed stochastic optimization algorithms can handle large-scale data simultaneously and accelerate model training. However, the sparsity of distributed networks and the heterogeneity of data limit these advantages. This paper proposes a momentum-accelerated distributed stochastic gradient algorithm, referred to as Exact-Diffusion with Momentum (EDM), which can correct the bias caused by data heterogeneity and introduces the momentum method commonly used in deep learning to accelerate the convergence of the algorithm. We theoretically demonstrate that this algorithm converges to the neighborhood of the optimum sub-linearly irrelevant to data heterogeneity when applied to non-convex objective functions and linearly under the Polyak-{\L}ojasiewicz condition (a weaker assumption than $\mu$-strongly convexity). Finally, we evaluate the performance of the proposed algorithm by simulation, comparing it with a range of existing decentralized optimization algorithms to demonstrate its effectiveness in addressing data heterogeneity and network sparsity.</description>
      <guid isPermaLink="false">oai:arXiv.org:2501.19082v1</guid>
      <category>cs.LG</category>
      <category>cs.DC</category>
      <category>math.OC</category>
      <category>stat.ML</category>
      <pubDate>Mon, 03 Feb 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Yuchen Hu, Xi Chen, Weidong Liu, Xiaojun Mao</dc:creator>
    </item>
    <item>
      <title>Learning While Repositioning in On-Demand Vehicle Sharing Networks</title>
      <link>https://arxiv.org/abs/2501.19208</link>
      <description>arXiv:2501.19208v1 Announce Type: cross 
Abstract: We consider a network inventory problem motivated by one-way, on-demand vehicle sharing services. Due to uncertainties in both demand and returns, as well as a fixed number of rental units across an $n$-location network, the service provider must periodically reposition vehicles to match supply with demand spatially while minimizing costs. The optimal repositioning policy under a general $n$-location network is intractable without knowing the optimal value function. We introduce the best base-stock repositioning policy as a generalization of the classical inventory control policy to $n$ dimensions, and establish its asymptotic optimality in two distinct limiting regimes under general network structures. We present reformulations to efficiently compute this best base-stock policy in an offline setting with pre-collected data.
  In the online setting, we show that a natural Lipschitz-bandit approach achieves a regret guarantee of $\widetilde{O}(T^{\frac{n}{n+1}})$, which suffers from the exponential dependence on $n$. We illustrate the challenges of learning with censored data in networked systems through a regret lower bound analysis and by demonstrating the suboptimality of alternative algorithmic approaches. Motivated by these challenges, we propose an Online Gradient Repositioning algorithm that relies solely on censored demand. Under a mild cost-structure assumption, we prove that it attains an optimal regret of $O(n^{2.5} \sqrt{T})$, which matches the regret lower bound in $T$ and achieves only polynomial dependence on $n$. The key algorithmic innovation involves proposing surrogate costs to disentangle intertemporal dependencies and leveraging dual solutions to find the gradient of policy change. Numerical experiments demonstrate the effectiveness of our proposed methods.</description>
      <guid isPermaLink="false">oai:arXiv.org:2501.19208v1</guid>
      <category>stat.ML</category>
      <category>cs.LG</category>
      <category>math.OC</category>
      <pubDate>Mon, 03 Feb 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Hansheng Jiang, Chunlin Sun, Zuo-Jun Max Shen, Shunan Jiang</dc:creator>
    </item>
    <item>
      <title>Port-Hamiltonian Realizations of Nonminimal Linear Time Invariant Systems</title>
      <link>https://arxiv.org/abs/2201.05355</link>
      <description>arXiv:2201.05355v2 Announce Type: replace 
Abstract: The question when a general linear time invariant control system is equivalent to a port-Hamiltonian system is answered. Several equivalent characterizations are derived which extend the characterizations of Willems to the general non-minimal case and to the case where the feedthrough term does not have an invertible symmetric part. An explicit construction of the transformation matrices is presented in terms of the computation of invariant subspaces of even matrix pencils. {\color{black} This construction includes the potential of incorporating a perturbation to a nearby port-Hamiltonian system, when such a transformation does not otherwise exist.} Results are illustrated via numerical examples.</description>
      <guid isPermaLink="false">oai:arXiv.org:2201.05355v2</guid>
      <category>math.OC</category>
      <category>cs.NA</category>
      <category>math.NA</category>
      <pubDate>Mon, 03 Feb 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Christopher Beattie, Volker Mehrmann, Hongguo Xu</dc:creator>
    </item>
    <item>
      <title>Discrete-time gradient flows in Gromov hyperbolic spaces</title>
      <link>https://arxiv.org/abs/2205.03156</link>
      <description>arXiv:2205.03156v3 Announce Type: replace 
Abstract: We investigate fundamental properties of the proximal point algorithm for Lipschitz convex functions on (proper, geodesic) Gromov hyperbolic spaces. We show that the proximal point algorithm from an arbitrary initial point can find a point close to a minimizer of the function. Moreover, we establish contraction estimates (akin to trees) for the proximal (resolvent) operator. Our results can be applied to small perturbations of trees.</description>
      <guid isPermaLink="false">oai:arXiv.org:2205.03156v3</guid>
      <category>math.OC</category>
      <category>math.MG</category>
      <pubDate>Mon, 03 Feb 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Shin-ichi Ohta</dc:creator>
    </item>
    <item>
      <title>Asymptotic Dynamics of Alternating Minimization for Bilinear Regression</title>
      <link>https://arxiv.org/abs/2402.04751</link>
      <description>arXiv:2402.04751v3 Announce Type: replace 
Abstract: This study investigates the dynamics of alternating minimization applied to a bilinear regression task with normally distributed covariates, under the asymptotic system size limit where the number of parameters and observations diverge at the same rate. This is achieved by employing the replica method to a multi-temperature glassy system which unfolds the algorithm's time evolution. Our results show that the dynamics can be described effectively by a two-dimensional discrete stochastic process, where each step depends on all previous time steps, revealing the structure of the memory dependence in the evolution of alternating minimization. The theoretical framework developed in this work can be applied to the analysis of various iterative algorithms, extending beyond the scope of alternating minimization.</description>
      <guid isPermaLink="false">oai:arXiv.org:2402.04751v3</guid>
      <category>math.OC</category>
      <category>cond-mat.dis-nn</category>
      <category>stat.ML</category>
      <pubDate>Mon, 03 Feb 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Koki Okajima, Takashi Takahashi</dc:creator>
    </item>
    <item>
      <title>Robust Solutions of Nonlinear Least Squares Problems via Min-max Optimization</title>
      <link>https://arxiv.org/abs/2402.12679</link>
      <description>arXiv:2402.12679v2 Announce Type: replace 
Abstract: This paper considers robust solutions to a class of nonlinear least squares problems using min-max optimization approach.
  We give an explicit formula for the value function of the inner maximization problem and show the existence of global minimax points. We establish error bounds from any solution of the nonlinear least squares problem to the solution set of the robust nonlinear least squares problem. Moreover, we propose a smoothing method for finding a global minimax point of the min-max problem by using the formula and show that finding an $\epsilon$ minimax critical point of the min-max problem needs at most $O(\epsilon^{-2} +\delta^2 \epsilon^{-3})$ evaluations of the function value and gradients of the objective function, where $\delta$ is the tolerance of the noise. Numerical results of integral equations with uncertain data demonstrate the robustness of solutions of our approach and unstable behaviour of least squares solutions disregarding uncertainties in the data.</description>
      <guid isPermaLink="false">oai:arXiv.org:2402.12679v2</guid>
      <category>math.OC</category>
      <pubDate>Mon, 03 Feb 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Xiaojun Chen, Carl Kelley</dc:creator>
    </item>
    <item>
      <title>Frictionless Hamiltonian Descent and Coordinate Hamiltonian Descent for Strongly Convex Quadratic Problems and Beyond</title>
      <link>https://arxiv.org/abs/2402.13988</link>
      <description>arXiv:2402.13988v3 Announce Type: replace 
Abstract: We propose an optimization algorithm called Frictionless Hamiltonian Descent, which is a direct counterpart of classical Hamiltonian Monte Carlo in sampling. We find that Frictionless Hamiltonian Descent for solving strongly convex quadratic problems exhibits a novel update scheme that involves matrix-power-vector products. We also propose Frictionless Coordinate Hamiltonian Descent and its parallelizable variant, which turns out to encapsulate the classical Gauss-Seidel method, Successive Over-relaxation, Jacobi method, and more, for solving a linear system of equations. The result not only offers a new perspective on these existing algorithms but also leads to a broader class of update schemes that guarantee the convergence. Finally, we also highlight the potential of Frictionless Hamiltonian Descent beyond quadratics by studying solving certain non-convex functions, where Frictionless Hamiltonian Descent can find a global optimal point.</description>
      <guid isPermaLink="false">oai:arXiv.org:2402.13988v3</guid>
      <category>math.OC</category>
      <pubDate>Mon, 03 Feb 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Jun-Kun Wang</dc:creator>
    </item>
    <item>
      <title>Energetic Resilience of Linear Driftless Systems</title>
      <link>https://arxiv.org/abs/2410.00323</link>
      <description>arXiv:2410.00323v2 Announce Type: replace 
Abstract: When a malfunction causes a control system to lose authority over a subset of its actuators, achieving a task may require spending additional energy in order to compensate for the effect of uncontrolled inputs. To understand this increase in energy, we introduce energetic resilience metrics that quantify the maximal additional energy required to achieve finite-time regulation in linear driftless systems that lose authority over some of their actuators. We first derive optimal control signals and minimum energies to achieve this task in both the nominal and malfunctioning systems. We then obtain a bound on the worst-case energy used by the malfunctioning system, and its exact expression in the special case of loss of authority over one actuator. Further considering this special case, we derive bounds on additive and multiplicative metrics for energetic resilience. A simulation example on a model of an underwater robot demonstrates that these bounds are useful in quantifying the increased energy used by a system suffering a partial loss of control authority.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.00323v2</guid>
      <category>math.OC</category>
      <category>cs.SY</category>
      <category>eess.SY</category>
      <pubDate>Mon, 03 Feb 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Ram Padmanabhan, Melkior Ornik</dc:creator>
    </item>
    <item>
      <title>Beyond hypergraph acyclicity: limits of tractability for pseudo-Boolean optimization</title>
      <link>https://arxiv.org/abs/2410.23045</link>
      <description>arXiv:2410.23045v2 Announce Type: replace 
Abstract: In this paper, we study the problem of minimizing a polynomial function with literals over all binary points, often referred to as pseudo-Boolean optimization. We investigate the fundamental limits of computation for this problem by providing new necessary conditions and sufficient conditions for tractability. On the one hand, we obtain the first intractability results, in the best-case sense, for pseudo-Boolean optimization problems on signed hypergraphs with bounded rank, in terms of the treewidth of the intersection graph. Namely, first, under some mild assumptions, we show that for every sequence of hypergraphs indexed by the treewidth and with bounded rank, the complexity of solving the associated pseudo-Boolean optimization problem grows super-polynomially in the treewidth. Second, we show that any hypergraph of bounded rank is the underlying hypergraph of some signed hypergraph for which the corresponding pseudo-Boolean polytope has an exponential extension complexity in the treewidth. On the other hand, we introduce the nest-set gap, a new hypergraph-theoretic notion that enables us to define a notion of "distance" from the hypergaph acyclicity. We prove that if this distance is bounded, the pseudo-Boolean polytope admits a polynomial-size extended formulation. This in turn enables us to obtain a polynomial-time algorithm for a large class of pseudo-Boolean optimization problems whose underlying hypergraphs contain beta-cycles.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.23045v2</guid>
      <category>math.OC</category>
      <category>cs.DM</category>
      <pubDate>Mon, 03 Feb 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Alberto Del Pia, Aida Khajavirad</dc:creator>
    </item>
    <item>
      <title>Stochastic Optimal Control of an Industrial Power-to-Heat System with High-Temperature Heat Pump and Thermal Energy Storage</title>
      <link>https://arxiv.org/abs/2411.02211</link>
      <description>arXiv:2411.02211v2 Announce Type: replace 
Abstract: The optimal control of sustainable energy supply systems, including renewable energies and energy storage, takes a central role in the decarbonization of industrial systems. However, the use of fluctuating renewable energies leads to fluctuations in energy generation and requires a suitable control strategy for the complex systems in order to ensure energy supply. In this paper, we consider an electrified power-to-heat system which is designed to supply heat in form of superheated steam for industrial processes. The system consists of a high-temperature heat pump for heat supply, a wind turbine for power generation, a sensible thermal energy storage for storing excess heat and a steam generator for providing steam. If the system's energy demand cannot be covered by electricity from the wind turbine, additional electricity must be purchased from the power grid. For this system, we investigate the cost-optimal operation aiming to minimize the electricity cost from the grid by a suitable system control depending on the available wind power and the amount of stored thermal energy. This is a decision making problem under uncertainties about the future prices for electricity from the grid and the future generation of wind power. The resulting stochastic optimal control problem is treated as finite-horizon Markov decision process for a multi-dimensional controlled state process. We first consider the classical backward recursion techniques for solving the associated dynamic programming equation for the value function and compute the optimal decision rule. Since that approach suffers from the curse of dimensionality we also apply Q-learning techniques that are able to provide a good approximate solution to the optimization problem within reasonable time.</description>
      <guid isPermaLink="false">oai:arXiv.org:2411.02211v2</guid>
      <category>math.OC</category>
      <category>q-fin.CP</category>
      <pubDate>Mon, 03 Feb 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Eric Pilling, Martin B\"ahr, Ralf Wunderlich</dc:creator>
    </item>
    <item>
      <title>Positivstellens\"atze for polynomial matrices with universal quantifiers</title>
      <link>https://arxiv.org/abs/2501.03470</link>
      <description>arXiv:2501.03470v2 Announce Type: replace 
Abstract: This paper studies Positivstellens\"atze for a polynomial matrix subject to polynomial matrix inequality constraints with universal quantifiers. We first present a Scherer-Hol-type Positivstellensatz under the Archimedean condition. When the objective is a scalar polynomial, we further provide a sparse Scherer-Hol-type Positivstellensatz in the presence of correlative sparsity. Next, without assuming the Archimedean condition, we derive Putinar-Vasilescu-type, P\'olya-type, and Lasserre-Netzer-type Positivstellens\"atze under the same setting. These results can be viewed as common generalizations of corresponding Positivstellens\"atze in the cases of polynomials, polynomials with universal quantifiers, and polynomial matrices. For the proofs, techniques from *-algebra, real algebraic geometry, operator theory, and convex optimization are employed. Applications of the established Positivstellens\"atze to robust polynomial matrix optimization are also discussed.</description>
      <guid isPermaLink="false">oai:arXiv.org:2501.03470v2</guid>
      <category>math.OC</category>
      <pubDate>Mon, 03 Feb 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Feng Guo, Jie Wang</dc:creator>
    </item>
    <item>
      <title>Sharp estimates for fundamental frequencies of elliptic operators generated by asymmetric seminorms in low dimensions</title>
      <link>https://arxiv.org/abs/2501.12939</link>
      <description>arXiv:2501.12939v2 Announce Type: replace 
Abstract: We establish new sharp asymmetric Poincare inequalities in one-dimension with the computation of optimal constants and characterization of extremizers. Using the one-dimensional theory we develop a comprehensive study on fundamental frequencies in the plane and related spectral optimization in the very general setting of positively homogeneous anisotropies.</description>
      <guid isPermaLink="false">oai:arXiv.org:2501.12939v2</guid>
      <category>math.OC</category>
      <category>math.AP</category>
      <pubDate>Mon, 03 Feb 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Julian Haddad, Raul Fernandes Horta, Marcos Montenegro</dc:creator>
    </item>
    <item>
      <title>Controllability scores of linear time-varying network systems</title>
      <link>https://arxiv.org/abs/2501.13345</link>
      <description>arXiv:2501.13345v2 Announce Type: replace 
Abstract: For large-scale network systems, network centrality based on control theory plays a crucial role in understanding their properties and controlling them efficiently. The controllability score is such a centrality index and can give a physically meaningful measure. Nevertheless, the existing work is limited to linear time-invariant (LTI) systems and the controllability score cannot be applied to linear time-varying (LTV) systems, which include essential models such as temporal networks for real application. This paper extends it to apply to LTV systems. Since it is defined as an optimal solution to some optimization problem, it is not necessarily uniquely determined. Its uniqueness must be guaranteed for reproducibility and interpretability. This paper also shows its uniqueness in most practical cases, which guarantees its use as a network centrality. In addition, we propose a data-driven method to compute it for its practical use. Finally, in numerical experiments, we compare controllability scores between LTI and LTV systems and assess the performance of the proposed data-driven method.</description>
      <guid isPermaLink="false">oai:arXiv.org:2501.13345v2</guid>
      <category>math.OC</category>
      <pubDate>Mon, 03 Feb 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Kota Umezu, Kazuhiro Sato</dc:creator>
    </item>
    <item>
      <title>Higher-Order Stochastic Dominance Constraints in Optimization</title>
      <link>https://arxiv.org/abs/2501.14565</link>
      <description>arXiv:2501.14565v2 Announce Type: replace 
Abstract: This contribution examines optimization problems that involve stochastic dominance constraints. These problems have uncountably many constraints. We develop methods to solve the optimization problem by reducing the constraints to a finite set of test points needed to verify stochastic dominance. This improves both theoretical understanding and computational efficiency. Our approach introduces two formulations of stochastic dominance$\unicode{x2013}$one employs expectation operators and another based on risk measures$\unicode{x2013}$allowing for efficient verification processes. Additionally, we develop an optimization framework incorporating these stochastic dominance constraints. Numerical results validate the robustness of our method, showcasing its effectiveness for solving higher-order stochastic dominance problems, with applications to fields such as portfolio optimization.</description>
      <guid isPermaLink="false">oai:arXiv.org:2501.14565v2</guid>
      <category>math.OC</category>
      <pubDate>Mon, 03 Feb 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Rajmadan Lakshmanan, Alois Pichler, Milo\v{s} Kopa</dc:creator>
    </item>
    <item>
      <title>Consensus Based Stochastic Control</title>
      <link>https://arxiv.org/abs/2501.17801</link>
      <description>arXiv:2501.17801v2 Announce Type: replace 
Abstract: We propose a gradient-free deep reinforcement learning algorithm to solve high-dimensional, finite-horizon stochastic control problems. Although the recently developed deep reinforcement learning framework has achieved great success in solving these problems, direct estimation of policy gradients from Monte Carlo sampling often suffers from high variance. To address this, we introduce the Momentum Consensus-Based Optimization (M-CBO) and Adaptive Momentum Consensus-Based Optimization (Adam-CBO) frameworks. These methods optimize policies using Monte Carlo estimates of the value function, rather than its gradients. Adjustable Gaussian noise supports efficient exploration, helping the algorithm converge to optimal policies in complex, nonconvex environments. Numerical results confirm the accuracy and scalability of our approach across various problem dimensions and show the potential for extension to mean-field control problems. Theoretically, we prove that M-CBO can converge to the optimal policy under some assumptions.</description>
      <guid isPermaLink="false">oai:arXiv.org:2501.17801v2</guid>
      <category>math.OC</category>
      <pubDate>Mon, 03 Feb 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <dc:creator>Liyao Lyu, Jingrun Chen</dc:creator>
    </item>
    <item>
      <title>Generator Sets for the Minkowski Sum Problem -- Theory and Insights</title>
      <link>https://arxiv.org/abs/2501.18420</link>
      <description>arXiv:2501.18420v2 Announce Type: replace 
Abstract: This paper considers a class of multi-objective optimization problems known as Minkowski sum problems. Minkowski sum problems have a decomposable structure, where the global nondominated (Pareto) set corresponds to the Minkowski sum of several local nondominated sets. In some cases, the vectors of local sets does not contribute to the generation of the global nondominated set, and may therefore lead to wasted computational efforts. Therefore, we investigate theoretical properties of both necessary and redundant vectors, and propose an algorithm based on bounding sets for identifying unnecessary local vectors. We conduct extensive numerical experiments to test the the impact of varying characteristics of the instances on the resulting global nondominated set and the number of redundant vectors.</description>
      <guid isPermaLink="false">oai:arXiv.org:2501.18420v2</guid>
      <category>math.OC</category>
      <pubDate>Mon, 03 Feb 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <dc:creator>Mark Lyngesen, Sune Lauth Gadegaard, Lars Relund Nielsen</dc:creator>
    </item>
    <item>
      <title>Near-Optimal Algorithms for Group Distributionally Robust Optimization and Beyond</title>
      <link>https://arxiv.org/abs/2212.13669</link>
      <description>arXiv:2212.13669v2 Announce Type: replace-cross 
Abstract: Distributionally robust optimization (DRO) can improve the robustness and fairness of learning methods. In this paper, we devise stochastic algorithms for a class of DRO problems including group DRO, subpopulation fairness, and empirical conditional value at risk (CVaR) optimization. Our new algorithms achieve faster convergence rates than existing algorithms for multiple DRO settings. We also provide a new information-theoretic lower bound that implies our bounds are tight for group DRO. Empirically, too, our algorithms outperform known methods.</description>
      <guid isPermaLink="false">oai:arXiv.org:2212.13669v2</guid>
      <category>cs.LG</category>
      <category>math.OC</category>
      <pubDate>Mon, 03 Feb 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Tasuku Soma, Khashayar Gatmiry, Sharut Gupta, Stefanie Jegelka</dc:creator>
    </item>
    <item>
      <title>Probabilistic reachable sets of stochastic nonlinear systems with contextual uncertainties</title>
      <link>https://arxiv.org/abs/2403.12379</link>
      <description>arXiv:2403.12379v2 Announce Type: replace-cross 
Abstract: Validating and controlling safety-critical systems in uncertain environments necessitates probabilistic reachable sets of future state evolutions. The existing methods of computing probabilistic reachable sets normally assume that stochastic uncertainties are independent of system states, inputs, and other environment variables. However, this assumption falls short in many real-world applications, where the probability distribution governing uncertainties depends on these variables, referred to as contextual uncertainties. This paper addresses the challenge of computing probabilistic reachable sets of stochastic nonlinear states with contextual uncertainties by seeking minimum-volume polynomial sublevel sets with contextual chance constraints. The formulated problem cannot be solved by the existing sample-based approximation method since the existing methods do not consider conditional probability densities. To address this, we propose a consistent sample approximation of the original problem by leveraging conditional density estimation and resampling. The obtained approximate problem is a tractable optimization problem. Additionally, we prove the proposed sample-based approximation's almost uniform convergence, showing that it gives the optimal solution almost consistently with the original ones. Through a numerical example, we evaluate the effectiveness of the proposed method against existing approaches, highlighting its capability to significantly reduce the bias inherent in sample-based approximation without considering a conditional probability density.</description>
      <guid isPermaLink="false">oai:arXiv.org:2403.12379v2</guid>
      <category>eess.SY</category>
      <category>cs.SY</category>
      <category>math.DS</category>
      <category>math.OC</category>
      <pubDate>Mon, 03 Feb 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Xun Shen, Ye Wang, Kazumune Hashimoto, Yuhu Wu, Sebastien Gros</dc:creator>
    </item>
    <item>
      <title>Policy Gradient Methods for Risk-Sensitive Distributional Reinforcement Learning with Provable Convergence</title>
      <link>https://arxiv.org/abs/2405.14749</link>
      <description>arXiv:2405.14749v2 Announce Type: replace-cross 
Abstract: Risk-sensitive reinforcement learning (RL) is crucial for maintaining reliable performance in high-stakes applications. While traditional RL methods aim to learn a point estimate of the random cumulative cost, distributional RL (DRL) seeks to estimate the entire distribution of it, which leads to a unified framework for handling different risk measures. However, developing policy gradient methods for risk-sensitive DRL is inherently more complex as it involves finding the gradient of a probability measure. This paper introduces a new policy gradient method for risk-sensitive DRL with general coherent risk measures, where we provide an analytical form of the probability measure's gradient for any distribution. For practical use, we design a categorical distributional policy gradient algorithm (CDPG) that approximates any distribution by a categorical family supported on some fixed points. We further provide a finite-support optimality guarantee and a finite-iteration convergence guarantee under inexact policy evaluation and gradient estimation. Through experiments on stochastic Cliffwalk and CartPole environments, we illustrate the benefits of considering a risk-sensitive setting in DRL.</description>
      <guid isPermaLink="false">oai:arXiv.org:2405.14749v2</guid>
      <category>cs.LG</category>
      <category>cs.AI</category>
      <category>math.OC</category>
      <pubDate>Mon, 03 Feb 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Minheng Xiao, Xian Yu, Lei Ying</dc:creator>
    </item>
    <item>
      <title>Communication- and Computation-Efficient Distributed Submodular Optimization in Robot Mesh Networks</title>
      <link>https://arxiv.org/abs/2407.10382</link>
      <description>arXiv:2407.10382v2 Announce Type: replace-cross 
Abstract: We provide a communication- and computation-efficient method for distributed submodular optimization in robot mesh networks. Submodularity is a property of diminishing returns that arises in active information gathering such as mapping, surveillance, and target tracking. Our method, Resource-Aware distributed Greedy (RAG), introduces a new distributed optimization paradigm that enables scalable and near-optimal action coordination. To this end, RAG requires each robot to make decisions based only on information received from and about their neighbors. In contrast, the current paradigms allow the relay of information about all robots across the network. As a result, RAG's decision-time scales linearly with the network size, while state-of-the-art near-optimal submodular optimization algorithms scale cubically. We also characterize how the designed mesh-network topology affects RAG's approximation performance. Our analysis implies that sparser networks favor scalability without proportionally compromising approximation performance: while RAG's decision time scales linearly with network size, the gain in approximation performance scales sublinearly. We demonstrate RAG's performance in simulated scenarios of area detection with up to 45 robots, simulating realistic robot-to-robot (r2r) communication speeds such as the 0.25 Mbps speed of the Digi XBee 3 Zigbee 3.0. In the simulations, RAG enables real-time planning, up to three orders of magnitude faster than competitive near-optimal algorithms, while also achieving superior mean coverage performance. To enable the simulations, we extend the high-fidelity and photo-realistic simulator AirSim by integrating a scalable collaborative autonomy pipeline to tens of robots and simulating r2r communication delays. Our code is available at https://github.com/UM-iRaL/Resource-Aware-Coordination-AirSim.</description>
      <guid isPermaLink="false">oai:arXiv.org:2407.10382v2</guid>
      <category>cs.RO</category>
      <category>cs.AI</category>
      <category>cs.MA</category>
      <category>cs.SY</category>
      <category>eess.SY</category>
      <category>math.OC</category>
      <pubDate>Mon, 03 Feb 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Zirui Xu, Sandilya Sai Garimella, Vasileios Tzoumas</dc:creator>
    </item>
    <item>
      <title>Infrequent Resolving Algorithm for Online Linear Programming</title>
      <link>https://arxiv.org/abs/2408.00465</link>
      <description>arXiv:2408.00465v5 Announce Type: replace-cross 
Abstract: Online linear programming (OLP) has gained significant attention from both researchers and practitioners due to its extensive applications, such as online auction, network revenue management, order fulfillment and advertising. Existing OLP algorithms fall into two categories: LP-based algorithms and LP-free algorithms. The former one typically guarantees better performance, even offering a constant regret, but requires solving a large number of LPs, which could be computationally expensive. In contrast, LP-free algorithm only requires first-order computations but induces a worse performance, lacking a constant regret bound. In this work, we bridge the gap between these two extremes by proposing a well-performing algorithm, that solves LPs at a few selected time points and conducts first-order computations at other time points. Specifically, for the case where the inputs are drawn from an unknown finite-support distribution, the proposed algorithm achieves a constant regret (even for the hard "degenerate" case) while solving LPs only $\mathcal{O}(\log\log T)$ times over the time horizon $T$. Moreover, when we are allowed to solve LPs only $M$ times, we design the corresponding schedule such that the proposed algorithm can guarantee a nearly $\mathcal{O}\left(T^{(1/2)^{M-1}}\right)$ regret. Our work highlights the value of resolving both at the beginning and the end of the selling horizon, and provides a novel framework to prove the performance guarantee of the proposed policy under different infrequent resolving schedules. Furthermore, when the arrival probabilities are known at the beginning, our algorithm can guarantee a constant regret by solving LPs $\mathcal{O}(\log\log T)$ times, and a nearly $\mathcal{O}\left(T^{(1/2)^{M}}\right)$ regret by solving LPs only $M$ times. Numerical experiments are conducted to demonstrate the efficiency of the proposed algorithms.</description>
      <guid isPermaLink="false">oai:arXiv.org:2408.00465v5</guid>
      <category>cs.DS</category>
      <category>cs.LG</category>
      <category>math.OC</category>
      <pubDate>Mon, 03 Feb 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Guokai Li, Zizhuo Wang, Jingwei Zhang</dc:creator>
    </item>
    <item>
      <title>SplitVAEs: Decentralized scenario generation from siloed data for stochastic optimization problems</title>
      <link>https://arxiv.org/abs/2409.12328</link>
      <description>arXiv:2409.12328v2 Announce Type: replace-cross 
Abstract: Stochastic optimization problems in large-scale multi-stakeholder networked systems (e.g., power grids and supply chains) rely on data-driven scenarios to encapsulate complex spatiotemporal interdependencies. However, centralized aggregation of stakeholder data is challenging due to the existence of data silos resulting from computational and logistical bottlenecks. In this paper, we present SplitVAEs, a decentralized scenario generation framework that leverages variational autoencoders to generate high-quality scenarios without moving stakeholder data. With the help of experiments on distributed memory systems, we demonstrate the broad applicability of SplitVAEs in a variety of domain areas that are dominated by a large number of stakeholders. Our experiments indicate that SplitVAEs can learn spatial and temporal interdependencies in large-scale networks to generate scenarios that match the joint historical distribution of stakeholder data in a decentralized manner. Our experiments show that SplitVAEs deliver robust performance compared to centralized, state-of-the-art benchmark methods while significantly reducing data transmission costs, leading to a scalable, privacy-enhancing alternative to scenario generation.</description>
      <guid isPermaLink="false">oai:arXiv.org:2409.12328v2</guid>
      <category>cs.LG</category>
      <category>math.OC</category>
      <category>stat.ME</category>
      <pubDate>Mon, 03 Feb 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <arxiv:DOI>10.1109/BigData62323.2024.10826070</arxiv:DOI>
      <dc:creator>H M Mohaimanul Islam, Huynh Q. N. Vo, Paritosh Ramanan</dc:creator>
    </item>
    <item>
      <title>Beyond Minimax Rates in Group Distributionally Robust Optimization via a Novel Notion of Sparsity</title>
      <link>https://arxiv.org/abs/2410.00690</link>
      <description>arXiv:2410.00690v2 Announce Type: replace-cross 
Abstract: The minimax sample complexity of group distributionally robust optimization (GDRO) has been determined up to a $\log(K)$ factor, where $K$ is the number of groups. In this work, we venture beyond the minimax perspective via a novel notion of sparsity that we dub $(\lambda, \beta)$-sparsity. In short, this condition means that at any parameter $\theta$, there is a set of at most $\beta$ groups whose risks at $\theta$ all are at least $\lambda$ larger than the risks of the other groups. To find an $\epsilon$-optimal $\theta$, we show via a novel algorithm and analysis that the $\epsilon$-dependent term in the sample complexity can swap a linear dependence on $K$ for a linear dependence on the potentially much smaller $\beta$. This improvement leverages recent progress in sleeping bandits, showing a fundamental connection between the two-player zero-sum game optimization framework for GDRO and per-action regret bounds in sleeping bandits. We next show an adaptive algorithm which, up to log factors, gets a sample complexity bound that adapts to the best $(\lambda, \beta)$-sparsity condition that holds. We also show how to get a dimension-free semi-adaptive sample complexity bound with a computationally efficient method. Finally, we demonstrate the practicality of the $(\lambda, \beta)$-sparsity condition and the improved sample efficiency of our algorithms on both synthetic and real-life datasets.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.00690v2</guid>
      <category>cs.LG</category>
      <category>cs.AI</category>
      <category>math.OC</category>
      <pubDate>Mon, 03 Feb 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Quan Nguyen, Nishant A. Mehta, Crist\'obal Guzm\'an</dc:creator>
    </item>
    <item>
      <title>Edge of Stochastic Stability: Revisiting the Edge of Stability for SGD</title>
      <link>https://arxiv.org/abs/2412.20553</link>
      <description>arXiv:2412.20553v2 Announce Type: replace-cross 
Abstract: Recent findings by Cohen et al., 2021, demonstrate that when training neural networks with full-batch gradient descent with a step size of $\eta$, the largest eigenvalue $\lambda_{\max}$ of the full-batch Hessian consistently stabilizes at $\lambda_{\max} = 2/\eta$. These results have significant implications for convergence and generalization. This, however, is not the case of mini-batch stochastic gradient descent (SGD), limiting the broader applicability of its consequences. We show that SGD trains in a different regime we term Edge of Stochastic Stability (EoSS). In this regime, what stabilizes at $2/\eta$ is *Batch Sharpness*: the expected directional curvature of mini-batch Hessians along their corresponding stochastic gradients. As a consequence $\lambda_{\max}$--which is generally smaller than Batch Sharpness--is suppressed, aligning with the long-standing empirical observation that smaller batches and larger step sizes favor flatter minima. We further discuss implications for mathematical modeling of SGD trajectories.</description>
      <guid isPermaLink="false">oai:arXiv.org:2412.20553v2</guid>
      <category>cs.LG</category>
      <category>math.OC</category>
      <category>stat.ML</category>
      <pubDate>Mon, 03 Feb 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Arseniy Andreyev, Pierfrancesco Beneventano</dc:creator>
    </item>
  </channel>
</rss>
