<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>cs.LO updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/cs.LO</link>
    <description>cs.LO updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/cs.LO" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Tue, 29 Oct 2024 04:00:19 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Tue, 29 Oct 2024 00:00:00 -0400</pubDate>
    <skipDays>
      <day>Sunday</day>
      <day>Saturday</day>
    </skipDays>
    <item>
      <title>Cobblestone: Iterative Automation for Formal Verification</title>
      <link>https://arxiv.org/abs/2410.19940</link>
      <description>arXiv:2410.19940v1 Announce Type: new 
Abstract: Formal verification using proof assistants, such as Coq, is an effective way of improving software quality, but it is expensive. Writing proofs manually requires both significant effort and expertise. Recent research has used machine learning to automatically synthesize proofs, reducing verification effort, but these tools are able to prove only a fraction of the desired software properties. We introduce Cobblestone, a new proof-synthesis approach that improves on the state of the art by taking advantage of partial progress in proof synthesis attempts. Unlike prior tools, Cobblestone can produce multiple unsuccessful proofs using a large language model (LLM), identify the working portions of those proofs, and combine them into a single, successful proof, taking advantage of internal partial progress. We evaluate Cobblestone on two benchmarks of open-source Coq projects, controlling for training data leakage in LLM datasets. Fully automatically, Cobblestone can prove 48% of the theorems, while Proverbot9001, the previous state-of-the-art, learning-based, proof-synthesis tool, can prove 17%. Cobblestone establishes a new state of the art for fully automated proof synthesis tools for Coq. We also evaluate Cobblestone in a setting where it is given external partial proof progress from oracles, serving as proxies for a human proof engineer or another tool. When the theorem is broken down into a set of subgoals and Cobblestone is given a set of relevant lemmas already proven in the project, it can prove up to 58% of the theorems. We qualitatively study the theorems Cobblestone is and is not able to prove to outline potential future research directions to further improve proof synthesis, including developing interactive, semi-automated tools. Our research shows that tools can make better use of partial progress made during proof synthesis to more effectively automate formal verification.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.19940v1</guid>
      <category>cs.LO</category>
      <category>cs.AI</category>
      <category>cs.PL</category>
      <pubDate>Tue, 29 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Saketh Ram Kasibatla, Arpan Agarwal, Yuriy Brun, Sorin Lerner, Talia Ringer, Emily First</dc:creator>
    </item>
    <item>
      <title>Soundness Correction of Data Petri Nets</title>
      <link>https://arxiv.org/abs/2410.21188</link>
      <description>arXiv:2410.21188v1 Announce Type: new 
Abstract: A process model is called sound if it always terminates properly and each model activity can occur in a process instance. Conducting soundness verification right after process design allows to detect and eliminate design errors in a process to be implemented. Deadlocks, livelocks, and unlimited resource growth are examples of critical design errors that must be addressed before process implementation.However, eliminating such failure points is usually a time-consuming and error-prone task even for modeling experts. This task becomes even more complicated in a data-aware setting when both control and data flows are represented in a model. In this paper, we introduce an algorithm that allows to repair soundness property of data-aware process models, represented as data Petri nets (DPNs), that preserves the correct behavior of the source model. In DPNs, each transition is associated with a guard that includes input and output conditions on process variables.Our algorithm restricts transition guards of a DPN so that executions that previously led to improper termination become prohibited.The algorithm does not require the underlying control flow of the net to be sound and can be applied to the models that have at least one execution leading to the final marking. The algorithm is implemented and results of the preliminary evaluation demonstrate its applicability on process models of moderate sizes.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.21188v1</guid>
      <category>cs.LO</category>
      <pubDate>Tue, 29 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Nikolai M. Suvorov, Irina A. Lomazova, Andrey Rivkin</dc:creator>
    </item>
    <item>
      <title>Policies for Fair Exchanges of Resources</title>
      <link>https://arxiv.org/abs/2410.21214</link>
      <description>arXiv:2410.21214v1 Announce Type: new 
Abstract: People increasingly use digital platforms to exchange resources in accordance to some policies stating what resources users offer and what they require in return. In this paper, we propose a formal model of these environments, focussing on how users' policies are defined and enforced, so ensuring that malicious users cannot take advantage of honest ones. To that end, we introduce the declarative policy language MuAC and equip it with a formal semantics. To determine if a resource exchange is fair, i.e., if it respects the MuAC policies in force, we introduce the non-standard logic MuACL that combines non-linear, linear and contractual aspects, and prove it decidable. Notably, the operator for contractual implication of MuACL is not expressible in linear logic. We define a semantics preserving compilation of MuAC policies into MuACL, thus establishing that exchange fairness is reduced to finding a proof in MuACL. Finally, we show how this approach can be put to work on a blockchain to exchange non-fungible tokens.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.21214v1</guid>
      <category>cs.LO</category>
      <pubDate>Tue, 29 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Lorenzo Ceragioli, Pierpaolo Degano, Letterio Galletta, Luca Vigan\`o</dc:creator>
    </item>
    <item>
      <title>Combining LLM Code Generation with Formal Specifications and Reactive Program Synthesis</title>
      <link>https://arxiv.org/abs/2410.19736</link>
      <description>arXiv:2410.19736v1 Announce Type: cross 
Abstract: In the past few years, Large Language Models (LLMs) have exploded in usefulness and popularity for code generation tasks. However, LLMs still struggle with accuracy and are unsuitable for high-risk applications without additional oversight and verification. In particular, they perform poorly at generating code for highly complex systems, especially with unusual or out-of-sample logic. For such systems, verifying the code generated by the LLM may take longer than writing it by hand. We introduce a solution that divides the code generation into two parts; one to be handled by an LLM and one to be handled by formal methods-based program synthesis. We develop a benchmark to test our solution and show that our method allows the pipeline to solve problems previously intractable for LLM code generation.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.19736v1</guid>
      <category>cs.SE</category>
      <category>cs.LG</category>
      <category>cs.LO</category>
      <pubDate>Tue, 29 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <dc:creator>William Murphy, Nikolaus Holzer, Feitong Qiao, Leyi Cui, Raven Rothkopf, Nathan Koenig, Mark Santolucito</dc:creator>
    </item>
    <item>
      <title>Integrating Reasoning Systems for Trustworthy AI, Proceedings of the 4th Workshop on Logic and Practice of Programming (LPOP)</title>
      <link>https://arxiv.org/abs/2410.19738</link>
      <description>arXiv:2410.19738v1 Announce Type: cross 
Abstract: This proceedings contains abstracts and position papers for the work to be presented at the fourth Logic and Practice of Programming (LPOP) Workshop. The workshop is to be held in Dallas, Texas, USA, and as a hybrid event, on October 13, 2024, in conjunction with the 40th International Conference on Logic Programming (ICLP). The focus of this workshop is integrating reasoning systems for trustworthy AI, especially including integrating diverse models of programming with rules and constraints.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.19738v1</guid>
      <category>cs.AI</category>
      <category>cs.LO</category>
      <category>cs.PL</category>
      <pubDate>Tue, 29 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Anil Nerode, Yanhong A. Liu</dc:creator>
    </item>
    <item>
      <title>Infectious Disease Forecasting in India using LLM's and Deep Learning</title>
      <link>https://arxiv.org/abs/2410.20168</link>
      <description>arXiv:2410.20168v1 Announce Type: cross 
Abstract: Many uncontrollable disease outbreaks of the past exposed several vulnerabilities in the healthcare systems worldwide. While advancements in technology assisted in the rapid creation of the vaccinations, there needs to be a pressing focus on the prevention and prediction of such massive outbreaks. Early detection and intervention of an outbreak can drastically reduce its impact on public health while also making the healthcare system more resilient. The complexity of disease transmission dynamics, influence of various directly and indirectly related factors and limitations of traditional approaches are the main bottlenecks in taking preventive actions. Specifically, this paper implements deep learning algorithms and LLM's to predict the severity of infectious disease outbreaks. Utilizing the historic data of several diseases that have spread in India and the climatic data spanning the past decade, the insights from our research aim to assist in creating a robust predictive system for any outbreaks in the future.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.20168v1</guid>
      <category>cs.LG</category>
      <category>cs.LO</category>
      <pubDate>Tue, 29 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Chaitya Shah, Kashish Gandhi, Javal Shah, Kreena Shah, Nilesh Patil, Kiran Bhowmick</dc:creator>
    </item>
    <item>
      <title>Cyberbullying or just Sarcasm? Unmasking Coordinated Networks on Reddit</title>
      <link>https://arxiv.org/abs/2410.20170</link>
      <description>arXiv:2410.20170v1 Announce Type: cross 
Abstract: With the rapid growth of social media usage, a common trend has emerged where users often make sarcastic comments on posts. While sarcasm can sometimes be harmless, it can blur the line with cyberbullying, especially when used in negative or harmful contexts. This growing issue has been exacerbated by the anonymity and vast reach of the internet, making cyberbullying a significant concern on platforms like Reddit. Our research focuses on distinguishing cyberbullying from sarcasm, particularly where online language nuances make it difficult to discern harmful intent. This study proposes a framework using natural language processing (NLP) and machine learning to differentiate between the two, addressing the limitations of traditional sentiment analysis in detecting nuanced behaviors. By analyzing a custom dataset scraped from Reddit, we achieved a 95.15% accuracy in distinguishing harmful content from sarcasm. Our findings also reveal that teenagers and minority groups are particularly vulnerable to cyberbullying. Additionally, our research uncovers coordinated graphs of groups involved in cyberbullying, identifying common patterns in their behavior. This research contributes to improving detection capabilities for safer online communities.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.20170v1</guid>
      <category>cs.SI</category>
      <category>cs.LG</category>
      <category>cs.LO</category>
      <pubDate>Tue, 29 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Pinky Pamecha, Chaitya Shah, Divyam Jain, Kashish Gandhi, Kiran Bhowmick, Meera Narvekar</dc:creator>
    </item>
    <item>
      <title>Revisiting Differential Verification: Equivalence Verification with Confidence</title>
      <link>https://arxiv.org/abs/2410.20207</link>
      <description>arXiv:2410.20207v1 Announce Type: cross 
Abstract: When validated neural networks (NNs) are pruned (and retrained) before deployment, it is desirable to prove that the new NN behaves equivalently to the (original) reference NN. To this end, our paper revisits the idea of differential verification which performs reasoning on differences between NNs: On the one hand, our paper proposes a novel abstract domain for differential verification admitting more efficient reasoning about equivalence. On the other hand, we investigate empirically and theoretically which equivalence properties are (not) efficiently solved using differential reasoning. Based on the gained insights, and following a recent line of work on confidence-based verification, we propose a novel equivalence property that is amenable to Differential Verification while providing guarantees for large parts of the input space instead of small-scale guarantees constructed w.r.t. predetermined input points. We implement our approach in a new tool called VeryDiff and perform an extensive evaluation on numerous old and new benchmark families, including new pruned NNs for particle jet classification in the context of CERN's LHC where we observe median speedups &gt;300x over the State-of-the-Art verifier alpha,beta-CROWN.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.20207v1</guid>
      <category>cs.LG</category>
      <category>cs.LO</category>
      <pubDate>Tue, 29 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Samuel Teuber, Philipp Kern, Marvin Janzen, Bernhard Beckert</dc:creator>
    </item>
    <item>
      <title>Combining Logic with Large Language Models for Automatic Debugging and Repair of ASP Programs</title>
      <link>https://arxiv.org/abs/2410.20962</link>
      <description>arXiv:2410.20962v1 Announce Type: cross 
Abstract: Logic programs are a powerful approach for solving NP-Hard problems. However, due to their declarative nature, debugging logic programs poses significant challenges. Unlike procedural paradigms, which allow for step-by-step inspection of program state, logic programs require reasoning about logical statements for fault localization. This complexity is amplified in learning environments due to students' inexperience.
  We introduce FormHe, a novel tool that combines logic-based techniques and Large Language Models to identify and correct issues in Answer Set Programming submissions. FormHe consists of two components: a fault localization module and a program repair module. First, the fault localizer identifies a set of faulty program statements requiring modification. Subsequently, FormHe employs program mutation techniques and Large Language Models to repair the flawed ASP program. These repairs can then serve as guidance for students to correct their programs.
  Our experiments with real buggy programs submitted by students show that FormHe accurately detects faults in 94% of cases and successfully repairs 58% of incorrect submissions.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.20962v1</guid>
      <category>cs.SE</category>
      <category>cs.LO</category>
      <pubDate>Tue, 29 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <dc:creator>Ricardo Brancas, Vasco Manquinho, Ruben Martins</dc:creator>
    </item>
    <item>
      <title>Type Theory with Explicit Universe Polymorphism (revised and extended version)</title>
      <link>https://arxiv.org/abs/2212.03284</link>
      <description>arXiv:2212.03284v5 Announce Type: replace 
Abstract: The aim of this paper is to refine and extend proposals by Sozeau and Tabareau and by Voevodsky for universe polymorphism in type theory. In those systems judgments can depend on explicit constraints between universe levels. We here present a system where we also have products indexed by universe levels and by constraints. Our theory has judgments for internal universe levels, built up from level variables by a successor operation and a binary supremum operation, and also judgments for equality of universe levels.</description>
      <guid isPermaLink="false">oai:arXiv.org:2212.03284v5</guid>
      <category>cs.LO</category>
      <pubDate>Tue, 29 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <arxiv:DOI>10.4230/LIPIcs.TYPES.2022.13</arxiv:DOI>
      <arxiv:journal_reference>LIPIcs, volume 269, 2023</arxiv:journal_reference>
      <dc:creator>Marc Bezem, Thierry Coquand, Peter Dybjer, Mart\'in Escard\'o</dc:creator>
    </item>
    <item>
      <title>Sum and Tensor of Quantitative Effects</title>
      <link>https://arxiv.org/abs/2212.11784</link>
      <description>arXiv:2212.11784v4 Announce Type: replace 
Abstract: Inspired by the seminal work of Hyland, Plotkin, and Power on the combination of algebraic computational effects via sum and tensor, we develop an analogous theory for the combination of quantitative algebraic effects. Quantitative algebraic effects are monadic computational effects on categories of metric spaces, which, moreover, have an algebraic presentation in the form of quantitative equational theories, a logical framework introduced by Mardare, Panangaden, and Plotkin that generalises equational logic to account for a concept of approximate equality. As our main result, we show that the sum and tensor of two quantitative equational theories correspond to the categorical sum (i.e., coproduct) and tensor, respectively, of their effects qua monads. We further give a theory of quantitative effect transformers based on these two operations, essentially providing quantitative analogues to the following monad transformers due to Moggi: exception, resumption, reader, and writer transformers. Finally, as an application, we provide the first quantitative algebraic axiomatizations to the following coalgebraic structures: Markov processes, labelled Markov processes, Mealy machines, and Markov decision processes, each endowed with their respective bisimilarity metrics. Apart from the intrinsic interest in these axiomatizations, it is pleasing they have been obtained as the composition, via sum and tensor, of simpler quantitative equational theories.</description>
      <guid isPermaLink="false">oai:arXiv.org:2212.11784v4</guid>
      <category>cs.LO</category>
      <pubDate>Tue, 29 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Giorgio Bacci, Radu Mardare, Prakash Panangaden, Gordon Plotkin</dc:creator>
    </item>
    <item>
      <title>Strong Faithfulness for ELH Ontology Embeddings</title>
      <link>https://arxiv.org/abs/2310.02198</link>
      <description>arXiv:2310.02198v2 Announce Type: replace 
Abstract: Ontology embedding methods are powerful approaches to represent and reason over structured knowledge in various domains. One advantage of ontology embeddings over knowledge graph embeddings is their ability to capture and impose an underlying schema to which the model must conform. Despite advances, most current approaches do not guarantee that the resulting embedding respects the axioms the ontology entails. In this work, we formally prove that normalized ${\cal ELH}$ has the strong faithfulness property on convex geometric models, which means that there is an embedding that precisely captures the original ontology. We present a region-based geometric model for embedding normalized ${\cal ELH}$ ontologies into a continuous vector space. To prove strong faithfulness, our construction takes advantage of the fact that normalized ${\cal ELH}$ has a finite canonical model. We first prove the statement assuming (possibly) non-convex regions, allowing us to keep the required dimensions low. Then, we impose convexity on the regions and show the property still holds. Finally, we consider reasoning tasks on geometric models and analyze the complexity in the class of convex geometric models used for proving strong faithfulness.</description>
      <guid isPermaLink="false">oai:arXiv.org:2310.02198v2</guid>
      <category>cs.LO</category>
      <pubDate>Tue, 29 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Victor Lacerda, Ana Ozaki, Ricardo Guimar\~aes</dc:creator>
    </item>
    <item>
      <title>A General Framework for Verification and Control of Dynamical Models via Certificate Synthesis</title>
      <link>https://arxiv.org/abs/2309.06090</link>
      <description>arXiv:2309.06090v3 Announce Type: replace-cross 
Abstract: An emerging branch of control theory specialises in certificate learning, concerning the specification of a desired (possibly complex) system behaviour for an autonomous or control model, which is then analytically verified by means of a function-based proof. However, the synthesis of controllers abiding by these complex requirements is in general a non-trivial task and may elude the most expert control engineers. This results in a need for automatic techniques that are able to design controllers and to analyse a wide range of elaborate specifications. In this paper, we provide a general framework to encode system specifications and define corresponding certificates, and we present an automated approach to formally synthesise controllers and certificates. Our approach contributes to the broad field of safe learning for control, exploiting the flexibility of neural networks to provide candidate control and certificate functions, whilst using SMT-solvers to offer a formal guarantee of correctness. We test our framework by developing a prototype software tool, and assess its efficacy at verification via control and certificate synthesis over a large and varied suite of benchmarks.</description>
      <guid isPermaLink="false">oai:arXiv.org:2309.06090v3</guid>
      <category>eess.SY</category>
      <category>cs.LG</category>
      <category>cs.LO</category>
      <category>cs.SY</category>
      <pubDate>Tue, 29 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Alec Edwards, Andrea Peruffo, Alessandro Abate</dc:creator>
    </item>
    <item>
      <title>On a fibrational construction for optics, lenses, and Dialectica categories</title>
      <link>https://arxiv.org/abs/2403.16388</link>
      <description>arXiv:2403.16388v3 Announce Type: replace-cross 
Abstract: Categories of lenses/optics and Dialectica categories are both comprised of bidirectional morphisms of basically the same form. In this work we show how they can be considered a special case of an overarching fibrational construction, generalizing Hofstra's construction of Dialectica fibrations and Spivak's construction of generalized lenses. This construction turns a tower of Grothendieck fibrations into another tower of fibrations by iteratively twisting each of the components, using the opposite fibration construction.</description>
      <guid isPermaLink="false">oai:arXiv.org:2403.16388v3</guid>
      <category>math.CT</category>
      <category>cs.IT</category>
      <category>cs.LO</category>
      <category>math.IT</category>
      <pubDate>Tue, 29 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Matteo Capucci, Bruno Gavranovi\'c, Abdullah Malik, Francisco Rios, Jonathan Weinberger</dc:creator>
    </item>
    <item>
      <title>Abstract Operational Methods for Call-by-Push-Value</title>
      <link>https://arxiv.org/abs/2410.17045</link>
      <description>arXiv:2410.17045v2 Announce Type: replace-cross 
Abstract: Levy's call-by-push-value is a comprehensive programming paradigm that combines elements from functional and imperative programming, supports computational effects and subsumes both call-by-value and call-by-name evaluation strategies. In the present work, we develop modular methods to reason about program equivalence in call-by-push-value, and in fine-grain call-by-value, which is a popular lightweight call-by-value sublanguage of the former. Our approach is based on the fundamental observation that presheaf categories of sorted sets are suitable universes to model call-by-(push)-value languages, and that natural, coalgebraic notions of program equivalence such as applicative similarity and logical relations can be developed within. Starting from this observation, we formalize fine-grain call-by-value and call-by-push-value in the higher-order abstract GSOS framework, reduce their key congruence properties to simple syntactic conditions by leveraging existing theory and argue that introducing changes to either language incurs minimal proof overhead.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.17045v2</guid>
      <category>cs.PL</category>
      <category>cs.LO</category>
      <pubDate>Tue, 29 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Sergey Goncharov, Stelios Tsampas, Henning Urbat</dc:creator>
    </item>
  </channel>
</rss>
