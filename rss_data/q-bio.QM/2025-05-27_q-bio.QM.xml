<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>q-bio.QM updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/q-bio.QM</link>
    <description>q-bio.QM updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/q-bio.QM" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Tue, 27 May 2025 04:00:01 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Tue, 27 May 2025 00:00:00 -0400</pubDate>
    <skipDays>
      <day>Saturday</day>
      <day>Sunday</day>
    </skipDays>
    <item>
      <title>Sensitivity analysis-guided model reduction of a mathematical model of pembrolizumab therapy for de novo metastatic MSI-H/dMMR colorectal cancer</title>
      <link>https://arxiv.org/abs/2505.18920</link>
      <description>arXiv:2505.18920v1 Announce Type: new 
Abstract: Colorectal cancer (CRC) is the third most commonly diagnosed cancer worldwide and the leading cause of cancer-related deaths in adults under 55, involving a complex interplay of biological processes such as dendritic cell (DC) maturation and migration, T cell activation and proliferation, cytokine production, and T cell and natural killer (NK) cell-mediated cancer cell killing. Microsatellite instability-high (MSI-H) CRC and deficient mismatch repair (dMMR) CRC constitute 15% of all CRC, and 4% of metastatic CRC, and exhibit remarkable responsiveness to immunotherapy, especially with PD-1 inhibitors such as pembrolizumab. Mathematical models of the underlying immunobiology and the interactions underpinning immune checkpoint blockade offer mechanistic insights into tumour-immune dynamics and provide avenues for treatment optimisation and the identification of novel therapeutic targets. We used our data-driven model of de novo metastatic MSI-H/dMMR CRC (dnmMCRC) and performed sensitivity analysis-guided model reduction using the FAST and EFAST methods. In this work, we constructed two simplified models of dnmMCRC: one that faithfully reproduces all of the original model's trajectories, and a second, minimal model that accurately replicates the original dynamics while being highly extensible for future inclusion of additional components to explore various aspects of the anti-tumour immune response.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.18920v1</guid>
      <category>q-bio.QM</category>
      <category>q-bio.CB</category>
      <pubDate>Tue, 27 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Georgio Hawi, Peter S. Kim, Peter P. Lee</dc:creator>
    </item>
    <item>
      <title>Rapid Development of Efficient Participant-Specific Computational Models of the Wrist</title>
      <link>https://arxiv.org/abs/2505.19282</link>
      <description>arXiv:2505.19282v1 Announce Type: new 
Abstract: While computational modeling may help to develop new treatment options for hand and wrist injuries, at present, few models exist. The time and expertise required to develop and use these models is considerable. Moreover, most do not allow for variation of material properties, instead relying on literature reported averages. We have developed a novel automated workflow combining non-linear morphing techniques with various algorithmic techniques to create participant-specific finite element models. Using this workflow, three participant-specific models were created from our existing four-dimensional computed tomography (4DCT) data. These were then used to perform two analyses to demonstrate the usefulness of the models to investigate clinical questions, namely optimization of ligament properties to participant-specific kinematics, and Monte Carlo (MC) analysis of the impacts of ligament injury on joint contact pressure, as an analogue for joint injury that may lead to osteoarthritis. Participant-specific models can be created in 2 hours and individual simulations performed in 45 seconds. This work lays the groundwork for future patient-specific modeling of the hand and wrist.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.19282v1</guid>
      <category>q-bio.QM</category>
      <category>cs.CE</category>
      <category>cs.NA</category>
      <category>math.NA</category>
      <pubDate>Tue, 27 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Thor E. Andreassen, Taylor P. Trentadue, Andrew R. Thoreson, Kai-Nan An, Sanjeev Kakar, Kristin D. Zhao</dc:creator>
    </item>
    <item>
      <title>Applications of Modular Co-Design for De Novo 3D Molecule Generation</title>
      <link>https://arxiv.org/abs/2505.18392</link>
      <description>arXiv:2505.18392v1 Announce Type: cross 
Abstract: De novo 3D molecule generation is a pivotal task in drug discovery. However, many recent geometric generative models struggle to produce high-quality 3D structures, even if they maintain 2D validity and topological stability. To tackle this issue and enhance the learning of effective molecular generation dynamics, we present Megalodon-a family of scalable transformer models. These models are enhanced with basic equivariant layers and trained using a joint continuous and discrete denoising co-design objective. We assess Megalodon's performance on established molecule generation benchmarks and introduce new 3D structure benchmarks that evaluate a model's capability to generate realistic molecular structures, particularly focusing on energetics. We show that Megalodon achieves state-of-the-art results in 3D molecule generation, conditional structure generation, and structure energy benchmarks using diffusion and flow matching. Furthermore, doubling the number of parameters in Megalodon to 40M significantly enhances its performance, generating up to 49x more valid large molecules and achieving energy levels that are 2-10x lower than those of the best prior generative models.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.18392v1</guid>
      <category>cs.LG</category>
      <category>cs.AI</category>
      <category>q-bio.QM</category>
      <pubDate>Tue, 27 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-sa/4.0/</dc:rights>
      <dc:creator>Danny Reidenbach, Filipp Nikitin, Olexandr Isayev, Saee Paliwal</dc:creator>
    </item>
    <item>
      <title>C3R: Channel Conditioned Cell Representations for unified evaluation in microscopy imaging</title>
      <link>https://arxiv.org/abs/2505.18745</link>
      <description>arXiv:2505.18745v1 Announce Type: cross 
Abstract: Immunohistochemical (IHC) images reveal detailed information about structures and functions at the subcellular level. However, unlike natural images, IHC datasets pose challenges for deep learning models due to their inconsistencies in channel count and configuration, stemming from varying staining protocols across laboratories and studies. Existing approaches build channel-adaptive models, which unfortunately fail to support out-of-distribution (OOD) evaluation across IHC datasets and cannot be applied in a true zero-shot setting with mismatched channel counts. To address this, we introduce a structured view of cellular image channels by grouping them into either context or concept, where we treat the context channels as a reference to the concept channels in the image. We leverage this context-concept principle to develop Channel Conditioned Cell Representations (C3R), a framework designed for unified evaluation on in-distribution (ID) and OOD datasets. C3R is a two-fold framework comprising a channel-adaptive encoder architecture and a masked knowledge distillation training strategy, both built around the context-concept principle. We find that C3R outperforms existing benchmarks on both ID and OOD tasks, while a trivial implementation of our core idea also outperforms the channel-adaptive methods reported on the CHAMMI benchmark. Our method opens a new pathway for cross-dataset generalization between IHC datasets, without requiring dataset-specific adaptation or retraining.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.18745v1</guid>
      <category>cs.CV</category>
      <category>cs.LG</category>
      <category>q-bio.QM</category>
      <pubDate>Tue, 27 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Umar Marikkar, Syed Sameed Husain, Muhammad Awais, Sara Atito</dc:creator>
    </item>
    <item>
      <title>Tokenizing Electron Cloud in Protein-Ligand Interaction Learning</title>
      <link>https://arxiv.org/abs/2505.19014</link>
      <description>arXiv:2505.19014v1 Announce Type: cross 
Abstract: The affinity and specificity of protein-molecule binding directly impact functional outcomes, uncovering the mechanisms underlying biological regulation and signal transduction. Most deep-learning-based prediction approaches focus on structures of atoms or fragments. However, quantum chemical properties, such as electronic structures, are the key to unveiling interaction patterns but remain largely underexplored. To bridge this gap, we propose ECBind, a method for tokenizing electron cloud signals into quantized embeddings, enabling their integration into downstream tasks such as binding affinity prediction. By incorporating electron densities, ECBind helps uncover binding modes that cannot be fully represented by atom-level models. Specifically, to remove the redundancy inherent in electron cloud signals, a structure-aware transformer and hierarchical codebooks encode 3D binding sites enriched with electron structures into tokens. These tokenized codes are then used for specific tasks with labels. To extend its applicability to a wider range of scenarios, we utilize knowledge distillation to develop an electron-cloud-agnostic prediction model. Experimentally, ECBind demonstrates state-of-the-art performance across multiple tasks, achieving improvements of 6.42\% and 15.58\% in per-structure Pearson and Spearman correlation coefficients, respectively.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.19014v1</guid>
      <category>cs.LG</category>
      <category>physics.chem-ph</category>
      <category>q-bio.QM</category>
      <pubDate>Tue, 27 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Haitao Lin, Odin Zhang, Jia Xu, Yunfan Liu, Zheng Cheng, Lirong Wu, Yufei Huang, Zhifeng Gao, Stan Z. Li</dc:creator>
    </item>
    <item>
      <title>ADGSyn: Dual-Stream Learning for Efficient Anticancer Drug Synergy Prediction</title>
      <link>https://arxiv.org/abs/2505.19144</link>
      <description>arXiv:2505.19144v1 Announce Type: cross 
Abstract: Drug combinations play a critical role in cancer therapy by significantly enhancing treatment efficacy and overcoming drug resistance. However, the combinatorial space of possible drug pairs grows exponentially, making experimental screening highly impractical. Therefore, developing efficient computational methods to predict promising drug combinations and guide experimental validation is of paramount importance. In this work, we propose ADGSyn, an innovative method for predicting drug synergy. The key components of our approach include: (1) shared projection matrices combined with attention mechanisms to enable cross-drug feature alignment; (2) automatic mixed precision (AMP)-optimized graph operations that reduce memory consumption by 40\% while accelerating training speed threefold; and (3) residual pathways stabilized by LayerNorm to ensure stable gradient propagation during training. Evaluated on the O'Neil dataset containing 13,243 drug--cell line combinations, ADGSyn demonstrates superior performance over eight baseline methods. Moreover, the framework supports full-batch processing of up to 256 molecular graphs on a single GPU, setting a new standard for efficiency in drug synergy prediction within the field of computational oncology.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.19144v1</guid>
      <category>cs.LG</category>
      <category>q-bio.QM</category>
      <pubDate>Tue, 27 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Yuxuan Nie, Yutong Song, Hong Peng</dc:creator>
    </item>
    <item>
      <title>A likelihood-based Bayesian inference framework for the calibration of and selection between stochastic velocity-jump models</title>
      <link>https://arxiv.org/abs/2505.19292</link>
      <description>arXiv:2505.19292v1 Announce Type: cross 
Abstract: Advances in experimental techniques allow the collection of high-resolution spatio-temporal data that track individual motile entities over time. These tracking data can be used to calibrate mathematical models of individual motility. However, experimental data is intrinsically discrete and noisy, and complicating the calibration of models for individual motion. We consider motion of individual agents that can be described by velocity-jump models in one spatial dimension. These agents transition according to a Poisson process between an n-state network, in which each state is associated with a fixed velocity and fixed rates of switching to every other state. Exploiting an approximate solution to the resultant stochastic process, in this work we develop a corresponding Bayesian inference framework to calibrate these models to discrete-time noisy data. We first demonstrate the ability of our framework to effectively recover the model parameters of data simulated from two-state and three-state models. Moreover, we use the framework to select between three-state models with distinct networks of states. Finally, we explore the question of model selection by calibrating three-state and four-state models to data simulated from a number of different four-state models. Overall, the framework works effectively and efficiently in calibrating and selecting between velocity-jump models.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.19292v1</guid>
      <category>stat.ME</category>
      <category>q-bio.QM</category>
      <pubDate>Tue, 27 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Arianna Ceccarelli, Alexander P. Browning, Ruth E. Baker</dc:creator>
    </item>
    <item>
      <title>Prompting Decision Transformers for Zero-Shot Reach-Avoid Policies</title>
      <link>https://arxiv.org/abs/2505.19337</link>
      <description>arXiv:2505.19337v1 Announce Type: cross 
Abstract: Offline goal-conditioned reinforcement learning methods have shown promise for reach-avoid tasks, where an agent must reach a target state while avoiding undesirable regions of the state space. Existing approaches typically encode avoid-region information into an augmented state space and cost function, which prevents flexible, dynamic specification of novel avoid-region information at evaluation time. They also rely heavily on well-designed reward and cost functions, limiting scalability to complex or poorly structured environments. We introduce RADT, a decision transformer model for offline, reward-free, goal-conditioned, avoid region-conditioned RL. RADT encodes goals and avoid regions directly as prompt tokens, allowing any number of avoid regions of arbitrary size to be specified at evaluation time. Using only suboptimal offline trajectories from a random policy, RADT learns reach-avoid behavior through a novel combination of goal and avoid-region hindsight relabeling. We benchmark RADT against 3 existing offline goal-conditioned RL models across 11 tasks, environments, and experimental settings. RADT generalizes in a zero-shot manner to out-of-distribution avoid region sizes and counts, outperforming baselines that require retraining. In one such zero-shot setting, RADT achieves 35.7% improvement in normalized cost over the best retrained baseline while maintaining high goal-reaching success. We apply RADT to cell reprogramming in biology, where it reduces visits to undesirable intermediate gene expression states during trajectories to desired target states, despite stochastic transitions and discrete, structured state dynamics.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.19337v1</guid>
      <category>cs.LG</category>
      <category>cs.AI</category>
      <category>q-bio.QM</category>
      <pubDate>Tue, 27 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Kevin Li, Marinka Zitnik</dc:creator>
    </item>
    <item>
      <title>Ankh3: Multi-Task Pretraining with Sequence Denoising and Completion Enhances Protein Representations</title>
      <link>https://arxiv.org/abs/2505.20052</link>
      <description>arXiv:2505.20052v1 Announce Type: cross 
Abstract: Protein language models (PLMs) have emerged as powerful tools to detect complex patterns of protein sequences. However, the capability of PLMs to fully capture information on protein sequences might be limited by focusing on single pre-training tasks. Although adding data modalities or supervised objectives can improve the performance of PLMs, pre-training often remains focused on denoising corrupted sequences. To push the boundaries of PLMs, our research investigated a multi-task pre-training strategy. We developed Ankh3, a model jointly optimized on two objectives: masked language modeling with multiple masking probabilities and protein sequence completion relying only on protein sequences as input. This multi-task pre-training demonstrated that PLMs can learn richer and more generalizable representations solely from protein sequences. The results demonstrated improved performance in downstream tasks, such as secondary structure prediction, fluorescence, GB1 fitness, and contact prediction. The integration of multiple tasks gave the model a more comprehensive understanding of protein properties, leading to more robust and accurate predictions.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.20052v1</guid>
      <category>cs.LG</category>
      <category>q-bio.QM</category>
      <pubDate>Tue, 27 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <dc:creator>Hazem Alsamkary, Mohamed Elshaffei, Mohamed Elkerdawy, Ahmed Elnaggar</dc:creator>
    </item>
    <item>
      <title>Transformer in Protein: A Survey</title>
      <link>https://arxiv.org/abs/2505.20098</link>
      <description>arXiv:2505.20098v1 Announce Type: cross 
Abstract: As protein informatics advances rapidly, the demand for enhanced predictive accuracy, structural analysis, and functional understanding has intensified. Transformer models, as powerful deep learning architectures, have demonstrated unprecedented potential in addressing diverse challenges across protein research. However, a comprehensive review of Transformer applications in this field remains lacking. This paper bridges this gap by surveying over 100 studies, offering an in-depth analysis of practical implementations and research progress of Transformers in protein-related tasks. Our review systematically covers critical domains, including protein structure prediction, function prediction, protein-protein interaction analysis, functional annotation, and drug discovery/target identification. To contextualize these advancements across various protein domains, we adopt a domain-oriented classification system. We first introduce foundational concepts: the Transformer architecture and attention mechanisms, categorize Transformer variants tailored for protein science, and summarize essential protein knowledge. For each research domain, we outline its objectives and background, critically evaluate prior methods and their limitations, and highlight transformative contributions enabled by Transformer models. We also curate and summarize pivotal datasets and open-source code resources to facilitate reproducibility and benchmarking. Finally, we discuss persistent challenges in applying Transformers to protein informatics and propose future research directions. This review aims to provide a consolidated foundation for the synergistic integration of Transformer and protein informatics, fostering further innovation and expanded applications in the field.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.20098v1</guid>
      <category>cs.LG</category>
      <category>cs.CR</category>
      <category>q-bio.QM</category>
      <pubDate>Tue, 27 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Xiaowen Ling, Zhiqiang Li, Yanbin Wang, Zhuhong You</dc:creator>
    </item>
    <item>
      <title>MolEditRL: Structure-Preserving Molecular Editing via Discrete Diffusion and Reinforcement Learning</title>
      <link>https://arxiv.org/abs/2505.20131</link>
      <description>arXiv:2505.20131v1 Announce Type: cross 
Abstract: Molecular editing aims to modify a given molecule to optimize desired chemical properties while preserving structural similarity. However, current approaches typically rely on string-based or continuous representations, which fail to adequately capture the discrete, graph-structured nature of molecules, resulting in limited structural fidelity and poor controllability. In this paper, we propose MolEditRL, a molecular editing framework that explicitly integrates structural constraints with precise property optimization. Specifically, MolEditRL consists of two stages: (1) a discrete graph diffusion model pretrained to reconstruct target molecules conditioned on source structures and natural language instructions; (2) an editing-aware reinforcement learning fine-tuning stage that further enhances property alignment and structural preservation by explicitly optimizing editing decisions under graph constraints. For comprehensive evaluation, we construct MolEdit-Instruct, the largest and most property-rich molecular editing dataset, comprising 3 million diverse examples spanning single- and multi-property tasks across 10 chemical attributes. Experimental results demonstrate that MolEditRL significantly outperforms state-of-the-art methods in both property optimization accuracy and structural fidelity, achieving a 74\% improvement in editing success rate while using 98\% fewer parameters.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.20131v1</guid>
      <category>cs.LG</category>
      <category>q-bio.QM</category>
      <pubDate>Tue, 27 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Yuanxin Zhuang, Dazhong Shen, Ying Sun</dc:creator>
    </item>
    <item>
      <title>Uncovering complementary information sharing in spider monkey collective foraging using higher-order spatial networks</title>
      <link>https://arxiv.org/abs/2505.01167</link>
      <description>arXiv:2505.01167v2 Announce Type: replace 
Abstract: Collectives are often able to process information in a distributed fashion, surpassing each individual member's processing capacity. In fission-fusion dynamics, where group members come together and split from others often, sharing complementary information about uniquely known foraging areas could allow a group to track a heterogenous foraging environment better than any group member on its own. We analyse the partial overlaps between individual core ranges, which we assume represent the knowledge of an individual during a given season. We identify sets of individuals whose overlap shows a balance between redundantly and uniquely known portions and we use simplicial complexes to represent these higher-order interactions. The structure of the simplicial complexes shows holes in various dimensions, revealing complementarity in the foraging information that is being shared. We propose that the complex spatial networks arising from fission-fusion dynamics allow for adaptive, collective processing of foraging information in dynamic environments.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.01167v2</guid>
      <category>q-bio.QM</category>
      <category>cond-mat.dis-nn</category>
      <category>cond-mat.stat-mech</category>
      <category>cs.SI</category>
      <category>physics.soc-ph</category>
      <pubDate>Tue, 27 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Gabriel Ramos-Fernandez, Ross S. Walker, Matthew J. Silk, Denis Boyer, Sandra E. Smith-Aguilar</dc:creator>
    </item>
    <item>
      <title>Identifying perturbation targets through causal differential networks</title>
      <link>https://arxiv.org/abs/2410.03380</link>
      <description>arXiv:2410.03380v3 Announce Type: replace-cross 
Abstract: Identifying variables responsible for changes to a biological system enables applications in drug target discovery and cell engineering. Given a pair of observational and interventional datasets, the goal is to isolate the subset of observed variables that were the targets of the intervention. Directly applying causal discovery algorithms is challenging: the data may contain thousands of variables with as few as tens of samples per intervention, and biological systems do not adhere to classical causality assumptions. We propose a causality-inspired approach to address this practical setting. First, we infer noisy causal graphs from the observational and interventional data. Then, we learn to map the differences between these graphs, along with additional statistical features, to sets of variables that were intervened upon. Both modules are jointly trained in a supervised framework, on simulated and real data that reflect the nature of biological interventions. This approach consistently outperforms baselines for perturbation modeling on seven single-cell transcriptomics datasets. We also demonstrate significant improvements over current causal discovery methods for predicting soft and hard intervention targets across a variety of synthetic data.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.03380v3</guid>
      <category>cs.LG</category>
      <category>cs.AI</category>
      <category>q-bio.QM</category>
      <pubDate>Tue, 27 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <arxiv:journal_reference>Proceedings of the 42nd International Conference on Machine Learning, Vancouver, Canada. PMLR 267, 2025</arxiv:journal_reference>
      <dc:creator>Menghua Wu, Umesh Padia, Sean H. Murphy, Regina Barzilay, Tommi Jaakkola</dc:creator>
    </item>
    <item>
      <title>Bayesian Comparisons Between Representations</title>
      <link>https://arxiv.org/abs/2411.08739</link>
      <description>arXiv:2411.08739v3 Announce Type: replace-cross 
Abstract: Which neural networks are similar is a fundamental question for both machine learning and neuroscience. Here, it is proposed to base comparisons on the predictive distributions of linear readouts from intermediate representations. In Bayesian statistics, the prior predictive distribution is a full description of the inductive bias and generalization of a model, making it a great basis for comparisons. This distribution directly gives the evidence a dataset would provide in favor of the model. If we want to compare multiple models to each other, we can use a metric for probability distributions like the Jensen-Shannon distance or the total variation distance. As these are metrics, this induces pseudo-metrics for representations, which measure how well two representations could be distinguished based on a linear read out. For a linear readout with a Gaussian prior on the read-out weights and Gaussian noise, we can analytically compute the (prior and posterior) predictive distributions without approximations. These distributions depend only on the linear kernel matrix of the representations in the model. Thus, the Bayesian metrics connect to both linear read-out based comparisons and kernel based metrics like centered kernel alignment and representational similarity analysis. The new methods are demonstrated with deep neural networks trained on ImageNet-1k comparing them to each other and a small subset of the Natural Scenes Dataset. The Bayesian comparisons are correlated to but distinct from existing metrics. Evaluations vary slightly less across random image samples and yield informative results with full uncertainty information. Thus the proposed Bayesian metrics nicely extend our toolkit for comparing representations.</description>
      <guid isPermaLink="false">oai:arXiv.org:2411.08739v3</guid>
      <category>cs.LG</category>
      <category>q-bio.QM</category>
      <pubDate>Tue, 27 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Heiko H. Sch\"utt</dc:creator>
    </item>
    <item>
      <title>The classification of Alzheimer's disease and mild cognitive impairment improved by dynamic functional network analysis</title>
      <link>https://arxiv.org/abs/2505.03458</link>
      <description>arXiv:2505.03458v2 Announce Type: replace-cross 
Abstract: Brain network analysis using functional MRI has advanced our understanding of cortical activity and its changes in neurodegenerative disorders that cause dementia. Recently, research in brain connectivity has focused on dynamic (time-varying) brain networks that capture both spatial and temporal information on cortical, regional co-activity patterns. However, this approach has been largely unexplored within the Alzheimer's spectrum. We analysed age- and sex-matched static and dynamic fMRI brain networks from 315 individuals with Alzheimer's Disease (AD), Mild Cognitive Impairment (MCI), and cognitively-normal Healthy Elderly (HE), using data from the ADNI-3 protocol. We examined both similarities and differences between these groups, employing the Juelich brain atlas for network nodes, sliding-window correlations for time-varying network links, and non-parametric statistics to assess between-group differences at the link or the node centrality level. While the HE and MCI groups show similar static and dynamic networks at the link level, significant differences emerge compared to AD participants. We found stable (stationary) differences in patterns of functional connections between the white matter regions and the parietal lobe's, and somatosensory cortices, while metastable (temporal) networks' differences were consistently found between the amygdala and hippocampal formation. In addition, our node centrality analysis showed that the white matter connectivity patterns are local in nature. Our results highlight shared and unique functional connectivity patterns in both stationary and dynamic functional networks, emphasising the need to include dynamic information in brain network analysis in studies of Alzheimer's spectrum.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.03458v2</guid>
      <category>q-bio.NC</category>
      <category>q-bio.QM</category>
      <pubDate>Tue, 27 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Nicolas Rubido, Venia Batziou, Marwan Fuad, Vesna Vuksanovic</dc:creator>
    </item>
    <item>
      <title>Virtual Cells: Predict, Explain, Discover</title>
      <link>https://arxiv.org/abs/2505.14613</link>
      <description>arXiv:2505.14613v2 Announce Type: replace-cross 
Abstract: Drug discovery is fundamentally a process of inferring the effects of treatments on patients, and would therefore benefit immensely from computational models that can reliably simulate patient responses, enabling researchers to generate and test large numbers of therapeutic hypotheses safely and economically before initiating costly clinical trials. Even a more specific model that predicts the functional response of cells to a wide range of perturbations would be tremendously valuable for discovering safe and effective treatments that successfully translate to the clinic. Creating such virtual cells has long been a goal of the computational research community that unfortunately remains unachieved given the daunting complexity and scale of cellular biology. Nevertheless, recent advances in AI, computing power, lab automation, and high-throughput cellular profiling provide new opportunities for reaching this goal. In this perspective, we present a vision for developing and evaluating virtual cells that builds on our experience at Recursion. We argue that in order to be a useful tool to discover novel biology, virtual cells must accurately predict the functional response of a cell to perturbations and explain how the predicted response is a consequence of modifications to key biomolecular interactions. We then introduce key principles for designing therapeutically-relevant virtual cells, describe a lab-in-the-loop approach for generating novel insights with them, and advocate for biologically-grounded benchmarks to guide virtual cell development. Finally, we make the case that our approach to virtual cells provides a useful framework for building other models at higher levels of organization, including virtual patients. We hope that these directions prove useful to the research community in developing virtual models optimized for positive impact on drug discovery outcomes.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.14613v2</guid>
      <category>cs.LG</category>
      <category>q-bio.QM</category>
      <pubDate>Tue, 27 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <dc:creator>Emmanuel Noutahi, Jason Hartford, Prudencio Tossou, Shawn Whitfield, Alisandra K. Denton, Cas Wognum, Kristina Ulicna, Michael Craig, Jonathan Hsu, Michael Cuccarese, Emmanuel Bengio, Dominique Beaini, Christopher Gibson, Daniel Cohen, Berton Earnshaw</dc:creator>
    </item>
  </channel>
</rss>
