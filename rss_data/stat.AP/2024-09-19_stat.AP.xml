<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>stat.AP updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/stat.AP</link>
    <description>stat.AP updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/stat.AP" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Fri, 20 Sep 2024 04:00:19 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Fri, 20 Sep 2024 00:00:00 -0400</pubDate>
    <skipDays>
      <day>Sunday</day>
      <day>Saturday</day>
    </skipDays>
    <item>
      <title>International Trade Network: Statistical Analysis and Modeling</title>
      <link>https://arxiv.org/abs/2409.12358</link>
      <description>arXiv:2409.12358v1 Announce Type: new 
Abstract: Globalization has rapidly advanced but exposed countries to supply chain disruptions, highlighted by the COVID-19 pandemic. This study exhaustively analyzes bilateral export data for 186 countries from 2018, 2020, and 2022, using Exponential Random Graph Models (ERGMs), to identify determinants of trade relationships, as well as Stochastic Block Models (SBMs), to characterize countries' roles in the trade network. Our findings show persistent, significant nodal characteristics driving bilateral trade and reveal no major structural changes in the trade network due to the pandemic.</description>
      <guid isPermaLink="false">oai:arXiv.org:2409.12358v1</guid>
      <category>stat.AP</category>
      <pubDate>Fri, 20 Sep 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Juan Sosa, Andr\'es Felipe Ar\'evalo-Ar\'evalo, Juan Pablo Torres-Clavijo</dc:creator>
    </item>
    <item>
      <title>Marked Cox Models for IBNR Claims Count: Continuous and Discretized Approaches with Dirichlet-Driven Reporting Delays</title>
      <link>https://arxiv.org/abs/2409.12896</link>
      <description>arXiv:2409.12896v1 Announce Type: new 
Abstract: Accurate loss reserving is crucial in Property and Casualty (P&amp;C) insurance for financial stability, regulatory compliance, and effective risk management. We propose a novel micro-level Cox model based on hidden Markov models (HMMs). Initially formulated as a continuous-time model, it addresses the complexity of incorporating temporal dependencies and policyholder risk attributes. However, the continuous-time model faces significant challenges in maximizing the likelihood and fitting right-truncated reporting delays. To overcome these issues, we introduce two discrete-time versions: one incorporating unsystematic randomness in reporting delays through a Dirichlet distribution and one without.
  We provide the EM algorithm for parameter estimation for all three models and apply them to an auto-insurance dataset to estimate IBNR claim counts. Our results show that while all models perform well, the discrete-time versions demonstrate superior performance by jointly modeling delay and frequency, with the Dirichlet-based model capturing additional variability in reporting delays. This approach enhances the accuracy and reliability of IBNR reserving, offering a flexible framework adaptable to different levels of granularity within an insurance portfolio.</description>
      <guid isPermaLink="false">oai:arXiv.org:2409.12896v1</guid>
      <category>stat.AP</category>
      <pubDate>Fri, 20 Sep 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Hassan Abdelrahman, Andrei Badescu, Radu Craiu, Sheldon Lin</dc:creator>
    </item>
    <item>
      <title>A Simple Model to Estimate Sharing Effects in Social Networks</title>
      <link>https://arxiv.org/abs/2409.12203</link>
      <description>arXiv:2409.12203v1 Announce Type: cross 
Abstract: Randomised Controlled Trials (RCTs) are the gold standard for estimating treatment effects across many fields of science. Technology companies have adopted A/B-testing methods as a modern RCT counterpart, where end-users are randomly assigned various system variants and user behaviour is tracked continuously. The objective is then to estimate the causal effect that the treatment variant would have on certain metrics of interest to the business.
  When the outcomes for randomisation units -- end-users in this case -- are not statistically independent, this obfuscates identifiability of treatment effects, and harms decision-makers' observability of the system. Social networks exemplify this, as they are designed to promote inter-user interactions. This interference by design notoriously complicates measurement of, e.g., the effects of sharing. In this work, we propose a simple Markov Decision Process (MDP)-based model describing user sharing behaviour in social networks. We derive an unbiased estimator for treatment effects under this model, and demonstrate through reproducible synthetic experiments that it outperforms existing methods by a significant margin.</description>
      <guid isPermaLink="false">oai:arXiv.org:2409.12203v1</guid>
      <category>cs.SI</category>
      <category>cs.IR</category>
      <category>cs.LG</category>
      <category>stat.AP</category>
      <pubDate>Fri, 20 Sep 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Olivier Jeunen</dc:creator>
    </item>
    <item>
      <title>CLE-SH: Comprehensive Literal Explanation package for SHapley values by statistical validity</title>
      <link>https://arxiv.org/abs/2409.12578</link>
      <description>arXiv:2409.12578v1 Announce Type: cross 
Abstract: Recently, SHapley Additive exPlanations (SHAP) has been widely utilized in various research domains. This is particularly evident in medical applications, where SHAP analysis serves as a crucial tool for identifying biomarkers and assisting in result validation. However, despite its frequent usage, SHAP is often not applied in a manner that maximizes its potential contributions. A review of recent papers employing SHAP reveals that many studies subjectively select a limited number of features as 'important' and analyze SHAP values by approximately observing plots without assessing statistical significance. Such superficial application may hinder meaningful contributions to the applied fields. To address this, we propose a library package designed to simplify the interpretation of SHAP values. By simply inputting the original data and SHAP values, our library provides: 1) the number of important features to analyze, 2) the pattern of each feature via univariate analysis, and 3) the interaction between features. All information is extracted based on its statistical significance and presented in simple, comprehensible sentences, enabling users of all levels to understand the interpretations. We hope this library fosters a comprehensive understanding of statistically valid SHAP results.</description>
      <guid isPermaLink="false">oai:arXiv.org:2409.12578v1</guid>
      <category>stat.CO</category>
      <category>stat.AP</category>
      <pubDate>Fri, 20 Sep 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Youngro Lee, Kyungjin Kim, Jongmo Seo</dc:creator>
    </item>
    <item>
      <title>Scaleable Dynamic Forecast Reconciliation</title>
      <link>https://arxiv.org/abs/2409.12856</link>
      <description>arXiv:2409.12856v1 Announce Type: cross 
Abstract: We introduce a dynamic approach to probabilistic forecast reconciliation at scale. Our model differs from the existing literature in this area in several important ways. Firstly we explicitly allow the weights allocated to the base forecasts in forming the combined, reconciled forecasts to vary over time. Secondly we drop the assumption, near ubiquitous in the literature, that in-sample base forecasts are appropriate for determining these weights, and use out of sample forecasts instead. Most existing probabilistic reconciliation approaches rely on time consuming sampling based techniques, and therefore do not scale well (or at all) to large data sets. We address this problem in two main ways, firstly by utilising a closed from estimator of covariance structure appropriate to hierarchical forecasting problems, and secondly by decomposing large hierarchies in to components which can be reconciled separately.</description>
      <guid isPermaLink="false">oai:arXiv.org:2409.12856v1</guid>
      <category>stat.ME</category>
      <category>stat.AP</category>
      <pubDate>Fri, 20 Sep 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Ross Hollyman, Fotios Petropoulos, Michael E. Tipping</dc:creator>
    </item>
    <item>
      <title>Multiscale scanning with nuisance parameters</title>
      <link>https://arxiv.org/abs/2307.13301</link>
      <description>arXiv:2307.13301v3 Announce Type: replace 
Abstract: We develop a multiscale scanning method to find anomalies in a $d$-dimensional random field in the presence of nuisance parameters. This covers the common situation that either the baseline-level or additional parameters such as the variance are unknown and have to be estimated from the data. We argue that state of the art approaches to determine asymptotically correct critical values for multiscale scanning statistics will in general fail when such parameters are naively replaced by plug-in estimators. Instead, we suggest to estimate the nuisance parameters on the largest scale and to use (only) smaller scales for multiscale scanning. We prove a uniform invariance principle for the resulting adjusted multiscale statistic (AMS), which is widely applicable and provides a computationally feasible way to simulate asymptotically correct critical values. We illustrate the implications of our theoretical results in a simulation study and in a real data example from super-resolution STED microscopy. This allows us to identify interesting regions inside a specimen in a pre-scan with controlled family-wise error rate.</description>
      <guid isPermaLink="false">oai:arXiv.org:2307.13301v3</guid>
      <category>stat.AP</category>
      <pubDate>Fri, 20 Sep 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Claudia K\"onig, Axel Munk, Frank Werner</dc:creator>
    </item>
    <item>
      <title>UAVDB: Trajectory-Guided Adaptable Bounding Boxes for UAV Detection</title>
      <link>https://arxiv.org/abs/2409.06490</link>
      <description>arXiv:2409.06490v2 Announce Type: replace-cross 
Abstract: The rapid advancement of drone technology has made accurate Unmanned Aerial Vehicle (UAV) detection essential for surveillance, security, and airspace management. This paper presents a novel trajectory-guided approach, the Patch Intensity Convergence (PIC) technique, which generates high-fidelity bounding boxes for UAV detection without manual labeling. This technique forms the foundation of UAVDB, a dedicated database designed specifically for UAV detection. Unlike datasets that often focus on large UAVs or simple backgrounds, UAVDB utilizes high-resolution RGB video to capture UAVs at various scales, from hundreds of pixels to near-single-digit sizes. This extensive scale variation enables robust evaluation of detection algorithms under diverse conditions. Using the PIC technique, bounding boxes can be efficiently generated from trajectory or position data. We benchmark UAVDB using state-of-the-art (SOTA) YOLO series detectors, providing a comprehensive performance analysis. Our results demonstrate UAVDB's potential as a critical resource for advancing UAV detection, particularly in high-resolution and long-distance tracking scenarios.</description>
      <guid isPermaLink="false">oai:arXiv.org:2409.06490v2</guid>
      <category>cs.CV</category>
      <category>stat.AP</category>
      <pubDate>Fri, 20 Sep 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Yu-Hsi Chen</dc:creator>
    </item>
    <item>
      <title>Exploring Dimensionality Reduction of SDSS Spectral Abundances</title>
      <link>https://arxiv.org/abs/2409.09227</link>
      <description>arXiv:2409.09227v2 Announce Type: replace-cross 
Abstract: High-resolution stellar spectra offer valuable insights into atmospheric parameters and chemical compositions. However, their inherent complexity and high-dimensionality present challenges in fully utilizing the information they contain. In this study, we utilize data from the Apache Point Observatory Galactic Evolution Experiment (APOGEE) within the Sloan Digital Sky Survey IV (SDSS-IV) to explore latent representations of chemical abundances by applying five dimensionality reduction techniques: PCA, t-SNE, UMAP, Autoencoder, and VAE. Through this exploration, we evaluate the preservation of information and compare reconstructed outputs with the original 19 chemical abundance data. Our findings reveal a performance ranking of PCA &lt; UMAP &lt; t-SNE &lt; VAE &lt; Autoencoder, through comparing their explained variance under optimized MSE. The performance of non-linear (Autoencoder and VAE) algorithms has approximately 10\% improvement compared to linear (PCA) algorithm. This difference can be referred to as the "non-linearity gap." Future work should focus on incorporating measurement errors into extension VAEs, thereby enhancing the reliability and interpretability of chemical abundance exploration in astronomical spectra.</description>
      <guid isPermaLink="false">oai:arXiv.org:2409.09227v2</guid>
      <category>astro-ph.IM</category>
      <category>stat.AP</category>
      <pubDate>Fri, 20 Sep 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/publicdomain/zero/1.0/</dc:rights>
      <dc:creator>Qianyu Fan</dc:creator>
    </item>
  </channel>
</rss>
