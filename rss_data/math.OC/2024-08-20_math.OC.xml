<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>math.OC updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/math.OC</link>
    <description>math.OC updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/math.OC" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Wed, 21 Aug 2024 04:01:52 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Wed, 21 Aug 2024 00:00:00 -0400</pubDate>
    <skipDays>
      <day>Sunday</day>
      <day>Saturday</day>
    </skipDays>
    <item>
      <title>Finite-time input-to-state stability for infinite-dimensional systems</title>
      <link>https://arxiv.org/abs/2408.10378</link>
      <description>arXiv:2408.10378v1 Announce Type: new 
Abstract: In this paper, we extend the notion of finite-time input-to-state stability (FTISS) for finite-dimensional systems to infinite-dimensional systems. More specifically, we first prove an FTISS Lyapunov theorem for a class of infinite-dimensional systems, namely, the existence of an FTISS Lyapunov functional (FTISS-LF) implies the FTISS of the system, and then, provide a sufficient condition for ensuring the existence of an FTISS-LF for a class of abstract infinite-dimensional systems under the framework of compact semigroup theory and Hilbert spaces. As an application of the FTISS Lyapunov theorem, we verify the FTISS for a class of parabolic PDEs involving sublinear terms and distributed in-domain disturbances. Since the nonlinear terms of the corresponding abstract system are not Lipschitz continuous, the well-posedness is proved based on the application of compact semigroup theory and the FTISS is assessed by using the Lyapunov method with the aid of an interpolation inequality. Numerical simulations are conducted to confirm the theoretical results.</description>
      <guid isPermaLink="false">oai:arXiv.org:2408.10378v1</guid>
      <category>math.OC</category>
      <category>cs.SY</category>
      <category>eess.SY</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Xiaorong Sun, Jun Zheng, Guchuan Zhu</dc:creator>
    </item>
    <item>
      <title>Empirical risk minimization for risk-neutral composite optimal control with applications to bang-bang control</title>
      <link>https://arxiv.org/abs/2408.10384</link>
      <description>arXiv:2408.10384v1 Announce Type: new 
Abstract: Nonsmooth composite optimization problems under uncertainty are prevalent in various scientific and engineering applications. We consider risk-neutral composite optimal control problems, where the objective function is the sum of a potentially nonconvex expectation function and a nonsmooth convex function. To approximate the risk-neutral optimization problems, we use a Monte Carlo sample-based approach, study its asymptotic consistency, and derive nonasymptotic sample size estimates. Our analyses leverage problem structure commonly encountered in PDE-constrained optimization problems, including compact embeddings and growth conditions. We apply our findings to bang-bang-type optimal control problems and propose the use of a conditional gradient method to solve them effectively. We present numerical illustrations.</description>
      <guid isPermaLink="false">oai:arXiv.org:2408.10384v1</guid>
      <category>math.OC</category>
      <category>cs.NA</category>
      <category>math.NA</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Johannes Milz, Daniel Walter</dc:creator>
    </item>
    <item>
      <title>Maximum principle for stochastic optimal control problem under convex expectation</title>
      <link>https://arxiv.org/abs/2408.10587</link>
      <description>arXiv:2408.10587v1 Announce Type: new 
Abstract: In this paper, we study a stochastic optimal control problem under a type of consistent convex expectation dominated by G-expectation. By the separation theorem for convex sets, we get the representation theorems for this convex expectation and conditional convex expectation. Based on these results, we obtain the variational equation for cost functional by weak convergence and discretization methods. Furthermore, we establish the maximum principle which is sufficient under usual convex assumptions. Finally, we study the linear quadratic control problem by using the obtained maximum principle.</description>
      <guid isPermaLink="false">oai:arXiv.org:2408.10587v1</guid>
      <category>math.OC</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Xiaojuan Li, Mingshang Hu</dc:creator>
    </item>
    <item>
      <title>Regularization of Stationary Second-order Mean Field Game Partial Differential Inclusions</title>
      <link>https://arxiv.org/abs/2408.10810</link>
      <description>arXiv:2408.10810v1 Announce Type: new 
Abstract: Mean field Game (MFG) Partial Differential Inclusions (PDI) are generalizations of the system of Partial Differential Equations (PDE) of Lasry and Lions to situations where players in the game may have possibly nonunique optimal controls, and the resulting Hamiltonian is not required to be differentiable. We study second-order MFG PDI with convex, Lipschitz continuous, but possibly nondifferentiable Hamiltonians, and their approximation by systems of classical MFG PDE with regularized Hamiltonians. Under very broad conditions on the problem data, we show that, up to subsequences, the solutions of the regularized problems converge to solutions of the MFG PDI. In particular, we show the convergence of the value functions in the $H^1$-norm and of the densities in $L^q$-norms. Under stronger hypotheses on the problem data, we also show rates of convergence between the solutions of the original and regularized problems, without requiring any higher regularity of the solutions. We give concrete examples that demonstrate the sharpness of several aspects of the analysis.</description>
      <guid isPermaLink="false">oai:arXiv.org:2408.10810v1</guid>
      <category>math.OC</category>
      <category>math.AP</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Yohance A. P. Osborne, Iain Smears</dc:creator>
    </item>
    <item>
      <title>Assortment Planning Under History-Dependent Effects</title>
      <link>https://arxiv.org/abs/2408.10967</link>
      <description>arXiv:2408.10967v1 Announce Type: new 
Abstract: This paper examines how to plan multi-period assortments when customer utility depends on historical assortments. We formulate this problem as a nonlinear integer programming problem and propose solution methodologies for different regimes of this problem. First, we present a sequential revenue-ordered policy and show that it is optimal when historical assortments positively affect customer utility. Second, we show that the problem is NP-hard under the presence of a negative history-dependent effect (such as a satiation effect). In this case, we propose using a lifting-based framework to reformulate the problem as a mixed-integer exponential cone program that state-of-the-art solvers can solve. Additionally, we identify an optimal cyclic policy for an asymptotic regime, and we also relate its length to the customer's memory length. Finally, we present a case study using a catering service dataset that shows that our model demonstrates good fitness and can effectively balance variety and revenue.</description>
      <guid isPermaLink="false">oai:arXiv.org:2408.10967v1</guid>
      <category>math.OC</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Taotao He, Yating Zhang, Huan Zheng</dc:creator>
    </item>
    <item>
      <title>A new perspective on the learning dynamics for a class of learning problems via averaged gradient systems coupled with diffusion-transmutation processes</title>
      <link>https://arxiv.org/abs/2408.11005</link>
      <description>arXiv:2408.11005v1 Announce Type: new 
Abstract: In the first part of this paper, we consider a family of continuous-time dynamical systems coupled with diffusion-transmutation processes. Under certain conditions, such randomly perturbed dynamical systems can be interpreted as an averaged dynamical system, whose weighting coefficients, that depend on the state trajectory of the underlying averaged system, are assumed to be strictly positive with sum unity. Here, we provide a large deviation result for the corresponding family of processes, i.e., a variational problem formulation modeling the most likely sample path leading to certain noise-induced rare-events. This remarkably allows us to provide a computational algorithm for solving the corresponding variational problem. In the second part of the paper, we use some of the insights from the first part and provide a new perspective on the learning dynamics for a class of learning problems, whose averaged gradient dynamical systems, from continuous-time perspective, are guided by a set of subsampled datasets that are obtained from the original dataset via bootstrapping or other related resampling-based techniques. Finally, we present some numerical results for a typical nonlinear regression problem, where the corresponding averaged gradient system is interpreted as random walks on a graph, whose outgoing edges are uniformly chosen at random.</description>
      <guid isPermaLink="false">oai:arXiv.org:2408.11005v1</guid>
      <category>math.OC</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Getachew K. Befekadu</dc:creator>
    </item>
    <item>
      <title>Improved global performance guarantees of second-order methods in convex minimization</title>
      <link>https://arxiv.org/abs/2408.11022</link>
      <description>arXiv:2408.11022v1 Announce Type: new 
Abstract: In this paper, we attempt to compare two distinct branches of research on second-order optimization methods. The first one studies self-concordant functions and barriers, the main assumption being that the third derivative of the objective is bounded by the second derivative. The second branch studies cubic regularized Newton methods (CRNMs) with the main assumption that the second derivative is Lipschitz continuous. We develop a new theoretical analysis for a path-following scheme (PFS) for general self-concordant functions, as opposed to the classical path-following scheme developed for self-concordant barriers. We show that the complexity bound for this scheme is better than that of the Damped Newton Method (DNM) and show that our method has global superlinear convergence. We propose also a new predictor-corrector path-following scheme (PCPFS) that leads to further improvement of constant factors in the complexity guarantees for minimizing general self-concordant functions. We also apply path-following schemes to different classes of constrained optimization problems and obtain the resulting complexity bounds. Finally, we analyze an important subclass of general self-concordant functions, namely a class of strongly convex functions with Lipschitz continuous second derivative, and show that for this subclass CRNMs give even better complexity bounds.</description>
      <guid isPermaLink="false">oai:arXiv.org:2408.11022v1</guid>
      <category>math.OC</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Pavel Dvurechensky, Yurii Nesterov</dc:creator>
    </item>
    <item>
      <title>Solving the Convex Flow Problem</title>
      <link>https://arxiv.org/abs/2408.11040</link>
      <description>arXiv:2408.11040v1 Announce Type: new 
Abstract: In this paper, we introduce the solver ConvexFlows for the convex flow problem first defined in the authors' previous work. In this problem, we aim to optimize a concave utility function depending on the flows over a graph. However, unlike the classic network flows literature, we also allow for a concave relationship between the input and output flows of edges. This nonlinear gain describes many physical phenomena, including losses in power network transmission lines. We outline an efficient algorithm for solving this problem which parallelizes over the graph edges. We provide an open source implementation of this algorithm in the Julia programming language package ConvexFlows.jl. This package includes an interface to easily specify these flow problems. We conclude by walking through an example of solving for an optimal power flow using ConvexFlows.</description>
      <guid isPermaLink="false">oai:arXiv.org:2408.11040v1</guid>
      <category>math.OC</category>
      <category>cs.MS</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Theo Diamandis, Guillermo Angeris</dc:creator>
    </item>
    <item>
      <title>In-Context Learning with Representations: Contextual Generalization of Trained Transformers</title>
      <link>https://arxiv.org/abs/2408.10147</link>
      <description>arXiv:2408.10147v1 Announce Type: cross 
Abstract: In-context learning (ICL) refers to a remarkable capability of pretrained large language models, which can learn a new task given a few examples during inference. However, theoretical understanding of ICL is largely under-explored, particularly whether transformers can be trained to generalize to unseen examples in a prompt, which will require the model to acquire contextual knowledge of the prompt for generalization. This paper investigates the training dynamics of transformers by gradient descent through the lens of non-linear regression tasks. The contextual generalization here can be attained via learning the template function for each task in-context, where all template functions lie in a linear space with $m$ basis functions. We analyze the training dynamics of one-layer multi-head transformers to in-contextly predict unlabeled inputs given partially labeled prompts, where the labels contain Gaussian noise and the number of examples in each prompt are not sufficient to determine the template. Under mild assumptions, we show that the training loss for a one-layer multi-head transformer converges linearly to a global minimum. Moreover, the transformer effectively learns to perform ridge regression over the basis functions. To our knowledge, this study is the first provable demonstration that transformers can learn contextual (i.e., template) information to generalize to both unseen examples and tasks when prompts contain only a small number of query-answer pairs.</description>
      <guid isPermaLink="false">oai:arXiv.org:2408.10147v1</guid>
      <category>cs.LG</category>
      <category>cs.CL</category>
      <category>cs.IT</category>
      <category>math.IT</category>
      <category>math.OC</category>
      <category>stat.ML</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Tong Yang, Yu Huang, Yingbin Liang, Yuejie Chi</dc:creator>
    </item>
    <item>
      <title>Inference of Heterogeneous Material Properties via Infinite-Dimensional Integrated DIC</title>
      <link>https://arxiv.org/abs/2408.10217</link>
      <description>arXiv:2408.10217v1 Announce Type: cross 
Abstract: We present a scalable and efficient framework for the inference of spatially-varying parameters of continuum materials from image observations of their deformations. Our goal is the nondestructive identification of arbitrary damage, defects, anomalies and inclusions without knowledge of their morphology or strength. Since these effects cannot be directly observed, we pose their identification as an inverse problem. Our approach builds on integrated digital image correlation (IDIC, Besnard Hild, Roux, 2006), which poses the image registration and material inference as a monolithic inverse problem, thereby enforcing physical consistency of the image registration using the governing PDE. Existing work on IDIC has focused on low-dimensional parameterizations of materials. In order to accommodate the inference of heterogeneous material propertes that are formally infinite dimensional, we present $\infty$-IDIC, a general formulation of the PDE-constrained coupled image registration and inversion posed directly in the function space setting. This leads to several mathematical and algorithmic challenges arising from the ill-posedness and high dimensionality of the inverse problem. To address ill-posedness, we consider various regularization schemes, namely $H^1$ and total variation for the inference of smooth and sharp features, respectively. To address the computational costs associated with the discretized problem, we use an efficient inexact-Newton CG framework for solving the regularized inverse problem. In numerical experiments, we demonstrate the ability of $\infty$-IDIC to characterize complex, spatially varying Lam\'e parameter fields of linear elastic and hyperelastic materials. Our method exhibits (i) the ability to recover fine-scale and sharp material features, (ii) mesh-independent convergence performance and hyperparameter selection, (iii) robustness to observational noise.</description>
      <guid isPermaLink="false">oai:arXiv.org:2408.10217v1</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <category>math.OC</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Joseph Kirchhoff, Dingcheng Luo, Thomas O'Leary-Roseberry, Omar Ghattas</dc:creator>
    </item>
    <item>
      <title>SDP bounds on quantum codes</title>
      <link>https://arxiv.org/abs/2408.10323</link>
      <description>arXiv:2408.10323v1 Announce Type: cross 
Abstract: This paper provides a semidefinite programming hierarchy based on state polynomial optimization to determine the existence of quantum codes with given parameters. The hierarchy is complete, in the sense that if a $(\!(n,K,\delta)\!)_2$ code does not exist then a level of the hierarchy is infeasible. It is not limited to stabilizer codes and thus applicable generally. While it is formally dimension-free, we restrict it to qubit codes through quasi-Clifford algebras. We derive the quantum analog of a range of classical results: first, from an intermediate level a Lov\'asz bound for self-dual quantum codes is recovered. Second, a symmetrization of a minor variation of this Lov\'asz bound recovers the quantum Delsarte bound. Third, a symmetry reduction using the Terwilliger algebra leads to semidefinite programming bounds of size $O(n^4)$. With this we give an alternative proof that there is no $(\!(7,1,4)\!)_2$ quantum code, and show that $(\!(8,9,3)\!)_2$ and $(\!(10,5,4)\!)_2$ codes do not exist.</description>
      <guid isPermaLink="false">oai:arXiv.org:2408.10323v1</guid>
      <category>quant-ph</category>
      <category>cs.IT</category>
      <category>math.IT</category>
      <category>math.OC</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Gerard Angl\`es Munn\'e, Andrew Nemec, Felix Huber</dc:creator>
    </item>
    <item>
      <title>Convergence analysis of Levenberg-Marquardt method with Singular Scaling for nonzero residue nonlinear least-squares problems</title>
      <link>https://arxiv.org/abs/2408.10370</link>
      <description>arXiv:2408.10370v1 Announce Type: cross 
Abstract: This paper addresses the convergence analysis of a variant of the LevenbergMarquardt method (LMM) designed for nonlinear least-squares problems with non-zero residue. This variant, called LMM with Singular Scaling (LMMSS), allows the LMM scaling matrix to be singular, encompassing a broader class of regularizers, which has proven useful in certain applications. In order to establish local convergence results, a careful choice of the LMM parameter is made based on the gradient linearization error, dictated by the nonlinearity and size of the residual. Under completeness and local error bound assumptions we prove that the distance from an iterate to the set of stationary points goes to zero superlinearly and that the iterative sequence converges. Furthermore, we also study a globalized version of the method obtained using linesearch and prove that any limit point of the generated sequence is stationary. Some examples are provided to illustrate our theoretical results.</description>
      <guid isPermaLink="false">oai:arXiv.org:2408.10370v1</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <category>math.OC</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Rafaela Filippozzi, Everton Boos, Douglas Soares Gon\c{c}alves, Fermin Bazan</dc:creator>
    </item>
    <item>
      <title>Semi-on-Demand Off-Peak Transit Services with Shared Autonomous Vehicles -- Service Planning, Simulation, and Analysis in Munich, Germany</title>
      <link>https://arxiv.org/abs/2408.10547</link>
      <description>arXiv:2408.10547v1 Announce Type: cross 
Abstract: This study investigates the implementation of semi-on-demand (SoD) hybrid-route services using Shared Autonomous Vehicles (SAVs) on existing transit lines. SoD services combine the cost efficiency of fixed-route buses with the flexibility of on-demand services. SAVs first serve all scheduled fixed-route stops, then drop off and pick up passengers in the pre-determined flexible-route portion, and return to the fixed route. This study addresses four key questions: optimal fleet and vehicle sizes for peak-hour fixed-route services with SAVs and during transition (from drivers to autonomous vehicles), optimal off-peak SoD service planning, and suitable use cases. The methodology combines analytical modeling for service planning with agent-based simulation for operational analysis. We examine ten bus routes in Munich, Germany, considering full SAV and transition scenarios with varying proportions of drivers. Our findings demonstrate that the lower operating costs of SAVs improve service quality through increased frequency and smaller vehicles, even in transition scenarios. The reduced headway lowers waiting time and also favors more flexible-route operation in SoD services. The optimal SoD settings range from fully flexible to hybrid routes, where higher occupancy from the terminus favors shorter flexible routes. During the transition phase, limited fleet size and higher headways constrain the benefits of flexible-route operations. The simulation results corroborate the SoD benefits of door-to-door convenience, attracting more passengers without excessive detours and operator costs at moderate flexible-route lengths, and validate the analytical model.</description>
      <guid isPermaLink="false">oai:arXiv.org:2408.10547v1</guid>
      <category>eess.SY</category>
      <category>cs.SY</category>
      <category>math.OC</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-sa/4.0/</dc:rights>
      <dc:creator>Max T. M. Ng, Roman Engelhardt, Florian Dandl, Vasileios Volakakis, Hani S. Mahmassani, Klaus Bogenberger</dc:creator>
    </item>
    <item>
      <title>Synchronization behind Learning in Periodic Zero-Sum Games Triggers Divergence from Nash equilibrium</title>
      <link>https://arxiv.org/abs/2408.10595</link>
      <description>arXiv:2408.10595v1 Announce Type: cross 
Abstract: Learning in zero-sum games studies a situation where multiple agents competitively learn their strategy. In such multi-agent learning, we often see that the strategies cycle around their optimum, i.e., Nash equilibrium. When a game periodically varies (called a ``periodic'' game), however, the Nash equilibrium moves generically. How learning dynamics behave in such periodic games is of interest but still unclear. Interestingly, we discover that the behavior is highly dependent on the relationship between the two speeds at which the game changes and at which players learn. We observe that when these two speeds synchronize, the learning dynamics diverge, and their time-average does not converge. Otherwise, the learning dynamics draw complicated cycles, but their time-average converges. Under some assumptions introduced for the dynamical systems analysis, we prove that this behavior occurs. Furthermore, our experiments observe this behavior even if removing these assumptions. This study discovers a novel phenomenon, i.e., synchronization, and gains insight widely applicable to learning in periodic games.</description>
      <guid isPermaLink="false">oai:arXiv.org:2408.10595v1</guid>
      <category>cs.GT</category>
      <category>cs.MA</category>
      <category>math.OC</category>
      <category>nlin.CD</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Yuma Fujimoto, Kaito Ariu, Kenshi Abe</dc:creator>
    </item>
    <item>
      <title>How Much Reserve Fuel: Quantifying the Maximal Energy Cost of System Disturbances</title>
      <link>https://arxiv.org/abs/2408.10913</link>
      <description>arXiv:2408.10913v1 Announce Type: cross 
Abstract: Motivated by the design question of additional fuel needed to complete a task in an uncertain environment, this paper introduces metrics to quantify the maximal additional energy used by a control system in the presence of bounded disturbances when compared to a nominal, disturbance-free system. In particular, we consider the task of finite-time stabilization for a linear time-invariant system. We first derive the nominal energy required to achieve this task in a disturbance-free system, and then the worst-case energy over all feasible disturbances. The latter leads to an optimal control problem with a least-squares solution, and then an infinite-dimensional optimization problem where we derive an upper bound on the solution. The comparison of these energies is accomplished using additive and multiplicative metrics, and we derive analytical bounds on these metrics. Simulation examples on an ADMIRE fighter jet model demonstrate the practicability of these metrics, and their variation with the task hardness, a combination of the distance of the initial condition from the origin and the task completion time.</description>
      <guid isPermaLink="false">oai:arXiv.org:2408.10913v1</guid>
      <category>eess.SY</category>
      <category>cs.SY</category>
      <category>math.OC</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Ram Padmanabhan, Craig Bakker, Siddharth Abhijit Dinkar, Melkior Ornik</dc:creator>
    </item>
    <item>
      <title>A deep learning method for solving stochastic optimal control problems driven by fully-coupled FBSDEs</title>
      <link>https://arxiv.org/abs/2204.05796</link>
      <description>arXiv:2204.05796v2 Announce Type: replace 
Abstract: In this paper,we mainly focus on the numerical solution of high-dimensional stochastic optimal control problem driven by fully-coupled forward-backward stochastic differential equations (FBSDEs in short) through deep learning. We first transform the problem into a stochastic Stackelberg differential game problem (leader-follower problem), then a bi-level optimization method is developed where the leader's cost functional and the follower's cost functional are optimized alternatively via deep neural networks. As for the numerical results, we compute two examples of the investment-consumption problem solved through stochastic recursive utility models, and the results of both examples demonstrate the effectiveness of our proposed algorithm.</description>
      <guid isPermaLink="false">oai:arXiv.org:2204.05796v2</guid>
      <category>math.OC</category>
      <category>cs.AI</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Shaolin Ji, Shige Peng, Ying Peng, Xichuan Zhang</dc:creator>
    </item>
    <item>
      <title>Nonconvex quasi-variational inequalities: stability analysis and application to numerical optimization</title>
      <link>https://arxiv.org/abs/2210.02531</link>
      <description>arXiv:2210.02531v2 Announce Type: replace 
Abstract: We consider a parametric quasi-variational inequality (QVI) without any convexity assumption. Using the concept of \emph{optimal value function}, we transform the problem into that of solving a nonsmooth system of inequalities. Based on this reformulation, new coderivative estimates as well as robust stability conditions for the optimal solution map of this QVI are developed. Also, for an optimization problem with QVI constraint, necessary optimality conditions are constructed and subsequently, a tailored semismooth Newton-type method is designed, implemented, and tested on a wide range of optimization examples from the literature. In addition to the fact that our approach does not require convexity, its coderivative and stability analysis do not involve second order derivatives, and subsequently, the proposed Newton scheme does not need third order derivatives, as it is the case for some previous works in the literature.</description>
      <guid isPermaLink="false">oai:arXiv.org:2210.02531v2</guid>
      <category>math.OC</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Joydeep Dutta, Lahoussine Lafhim, Alain Zemkoho, Shenglong Zhou</dc:creator>
    </item>
    <item>
      <title>Limited Communications Distributed Optimization via Deep Unfolded Distributed ADMM</title>
      <link>https://arxiv.org/abs/2309.14353</link>
      <description>arXiv:2309.14353v2 Announce Type: replace 
Abstract: Distributed optimization is a fundamental framework for collaborative inference and decision making in decentralized multi-agent systems. The operation is modeled as the joint minimization of a shared objective which typically depends on observations gathered locally by each agent. Distributed optimization algorithms, such as the common D-ADMM, tackle this task by iteratively combining local computations and message exchanges. One of the main challenges associated with distributed optimization, and particularly with D-ADMM, is that it requires a large number of communications, i.e., messages exchanged between the agents, to reach consensus. This can make D-ADMM costly in power, latency, and channel resources. In this work we propose unfolded D-ADMM, which follows the emerging deep unfolding methodology to enable D-ADMM to operate reliably with a predefined and small number of messages exchanged by each agent. Unfolded D-ADMM fully preserves the operation of D-ADMM, while leveraging data to tune the hyperparameters of each iteration of the algorithm. These hyperparameters can either be agent-specific, aiming at achieving the best performance within a fixed number of iterations over a given network, or shared among the agents, allowing to learn to distributedly optimize over different networks. For both settings, our unfolded D-ADMM operates with limited communications, while preserving the interpretability and flexibility of the original D-ADMM algorithm. We specialize unfolded D-ADMM for two representative settings: a distributed estimation task, considering a sparse recovery setup, and a distributed learning scenario, where multiple agents collaborate in learning a machine learning model. Our numerical results demonstrate that the proposed approach dramatically reduces the number of communications utilized by D-ADMM, without compromising on its performance.</description>
      <guid isPermaLink="false">oai:arXiv.org:2309.14353v2</guid>
      <category>math.OC</category>
      <category>cs.LG</category>
      <category>eess.SP</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Yoav Noah, Nir Shlezinger</dc:creator>
    </item>
    <item>
      <title>Homotopy trust-region method for phase-field approximations in perimeter-regularized binary optimal control</title>
      <link>https://arxiv.org/abs/2310.12478</link>
      <description>arXiv:2310.12478v3 Announce Type: replace 
Abstract: We consider optimal control problems that have binary-valued control input functions and a perimeter regularization. We develop and analyze a trust-region algorithm that solves a sequence of subproblems in which the regularization term and the binarity constraint are relaxed by a non-convex energy functional. We show how the parameter that controls the distinctiveness of the resulting phase field can be coupled to the trust-region radius updates and be driven to zero over the course of the iterations in order to obtain convergence to stationary points of the limit problem under suitable regularity assumptions. Finally, we highlight and discuss the assumptions and restrictions of our approach and provide the first computational results for a motivating application in the field of control of acoustic waves in dissipative media.</description>
      <guid isPermaLink="false">oai:arXiv.org:2310.12478v3</guid>
      <category>math.OC</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Paul Manns, Vanja Nikoli\'c</dc:creator>
    </item>
    <item>
      <title>Extended formulations for the integer hull of strictly $\Delta$-modular cographic polyhedral cones</title>
      <link>https://arxiv.org/abs/2311.06017</link>
      <description>arXiv:2311.06017v2 Announce Type: replace 
Abstract: Conforti et al. give a compact extended formulation for a class of bimodular-constrained integer programs, namely those that model the stable set polytope of a graph with no disjoint odd cycles. We extend their techniques to design compact extended formulations for the integer hull of translated polyhedral cones whose constraint matrix is strictly $\Delta$-modular and has rows that represent a cographic matroid. Our work generalizes the important special case from Conforti et al. concerning $4$-connected graphs with odd cycle transversal number at least $4$. We also discuss the necessity of our assumptions.</description>
      <guid isPermaLink="false">oai:arXiv.org:2311.06017v2</guid>
      <category>math.OC</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Joseph Paat, Zach Walsh, Luze Xu</dc:creator>
    </item>
    <item>
      <title>A Physics-Informed Indirect Method for Trajectory Optimization</title>
      <link>https://arxiv.org/abs/2402.00339</link>
      <description>arXiv:2402.00339v2 Announce Type: replace 
Abstract: This work presents a Physics-Informed Indirect Method (PIIM) that propagates the dynamics of both states and co-states backward in time for trajectory optimization problems. In the case of a Time-Optimal Soft Landing Problem (TOSLP), based on the initial co-state vector normalization technique, we show that the initial guess of the mass co-state and the numerical factor can be eliminated from the shooting procedure. As a result, the initial guess of the unknown co-states can be constrained to lie on a unit 3-D hypersphere. Then, using the PIIM allows one to exploit the physical significance of the optimal control law, which further narrows down the solution space to a unit 3-D octant sphere. Meanwhile, the analytical estimations of the fuel consumption and final time are provided. Additionally, a usually overlooked issue that results in an infeasible solution with a negative final time, is fixed by a simple remedy strategy. Consequently, the reduced solution space becomes sufficiently small to ensure fast, robust, and guaranteed convergence for the TOSLP. Then, we extend the PIIM to solve the Fuel-Optimal Soft Landing Problem (FOSLP) with a homotopy approach. The numerical simulations show that compared with the conventional indirect method with a success rate of 89.35%, it takes a shorter time for the proposed method to find the feasible solution to the FOSLP with a success rate of 100%.</description>
      <guid isPermaLink="false">oai:arXiv.org:2402.00339v2</guid>
      <category>math.OC</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <arxiv:DOI>10.1109/TAES.2024.3438687</arxiv:DOI>
      <arxiv:journal_reference>IEEE T-AES 1-14,2024</arxiv:journal_reference>
      <dc:creator>Kun Wang, Fangmin Lu, Zheng Chen, Jun Li</dc:creator>
    </item>
    <item>
      <title>Synchronization Games</title>
      <link>https://arxiv.org/abs/2402.08842</link>
      <description>arXiv:2402.08842v3 Announce Type: replace 
Abstract: We propose a new mean-field game model with two states to study synchronization phenomena, and we provide a comprehensive characterization of stationary and dynamic equilibria along with their stability properties. The game undergoes a phase transition with increasing interaction strength. In the subcritical regime, the uniform distribution, representing incoherence, is the unique and stable stationary equilibrium. Above the critical interaction threshold, the uniform equilibrium becomes unstable and there is a multiplicity of stationary equilibria that are self-organizing. Under a discounted cost, dynamic equilibria spiral around the uniform distribution before converging to the self-organizing equilibria. With an ergodic cost, however, unexpected periodic equilibria around the uniform distribution emerge.</description>
      <guid isPermaLink="false">oai:arXiv.org:2402.08842v3</guid>
      <category>math.OC</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Felix H\"ofer, H. Mete Soner</dc:creator>
    </item>
    <item>
      <title>Continuous Approximations of Projected Dynamical Systems via Control Barrier Functions</title>
      <link>https://arxiv.org/abs/2403.00447</link>
      <description>arXiv:2403.00447v3 Announce Type: replace 
Abstract: Projected Dynamical Systems (PDSs) form a class of discontinuous constrained dynamical systems, and have been used widely to solve optimization problems and variational inequalities. Recently, they have also gained significant attention for control purposes, such as high-performance integrators, saturated control and feedback optimization. In this work, we establish that locally Lipschitz continuous dynamics, involving Control Barrier Functions (CBFs), namely CBF-based dynamics, approximate PDSs. Specifically, we prove that trajectories of CBF-based dynamics uniformly converge to trajectories of PDSs, as a CBF-parameter approaches infinity. Towards this, we also prove that CBF-based dynamics are perturbations of PDSs, with quantitative bounds on the perturbation. Our results pave the way to implement discontinuous PDS-based controllers in a continuous fashion, employing CBFs. We demonstrate this on numerical examples on feedback optimization and synchronverter control. Moreover, our results can be employed to numerically simulate PDSs, overcoming disadvantages of existing discretization schemes, such as computing projections to possibly non-convex sets. Finally, this bridge between CBFs and PDSs may yield other potential benefits, including novel insights on stability.</description>
      <guid isPermaLink="false">oai:arXiv.org:2403.00447v3</guid>
      <category>math.OC</category>
      <category>cs.SY</category>
      <category>eess.SY</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Giannis Delimpaltadakis, Jorge Cort\'es, W. P. M. H. Heemels</dc:creator>
    </item>
    <item>
      <title>Coefficient identification of the regularized p-Stokes equations</title>
      <link>https://arxiv.org/abs/2404.01766</link>
      <description>arXiv:2404.01766v2 Announce Type: replace 
Abstract: The Antarctic and Greenland ice sheet simulation is challenging due to unknown parameters in the $p$-Stokes equations. In this work, we prove the existence of a solution to a parameter identification for the ice rheology and the friction coefficient. Additionally, we verify G\^ateaux differentiability of the coefficient-to-state operator by extending a similar result for distributed control. Moreover, we have more complicated boundary conditions. We only have to add a small diffusion term and assume the nonlinear exponent, which is given in applications, to be small enough to obtain the results. Finally, we state the adjoint equation and prove existence and uniqueness of a solution for this equation.</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.01766v2</guid>
      <category>math.OC</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <arxiv:DOI>10.1016/j.nonrwa.2024.104197</arxiv:DOI>
      <arxiv:journal_reference>Nonlinear Analysis: Real World Applications, Volume 81, February 2025, 104197</arxiv:journal_reference>
      <dc:creator>Niko Schmidt</dc:creator>
    </item>
    <item>
      <title>Tikhonov regularization of monotone operator flows not only ensures strong convergence of the trajectories but also speeds up the vanishing of the residuals</title>
      <link>https://arxiv.org/abs/2406.00852</link>
      <description>arXiv:2406.00852v2 Announce Type: replace 
Abstract: In the framework of real Hilbert spaces, we investigate first-order dynamical systems governed by monotone and continuous operators. We demonstrate that when the monotone operator flow is augmented with a Tikhonov regularization term, the resulting trajectory converges strongly to the element of the set of zeros with minimal norm. In addition, rates of convergence in norm for the trajectory's velocity and the operator along the trajectory can be derived in terms of the regularization function. In some particular cases, these rates of convergence can outperform the ones of the coercive operator flows and can be as fast as $O(\frac{1}{t})$ as $t \rightarrow +\infty$. In this way, we emphasize a surprising acceleration feature of the Tikhonov regularization. Additionally, we explore these properties for monotone operator flows that incorporate time rescaling and an anchor point and show that they are closely linked to second-order dynamics with a vanishing damping term. The convergence and convergence rate results we achieve for these systems complement recent findings for the Fast Optimistic Gradient Descent Ascent (OGDA) dynamics.
  When the monotone operator is defined as the identity minus a nonexpansive operator, the monotone equations transform into a fixed point problem. In such cases, explicitly discretizing the system with Tikhonov regularization, enhanced by an anchor point, leads to the Halpern fixed point iteration. We identify two regimes for the regularization sequence which ensure that the generated sequence of iterates converges strongly to the fixed point nearest to the anchor point. Furthermore, we establish a general theoretical framework that provides convergence rates for the vanishing of the discrete velocity and the fixed point residual. For certain regularization sequences, we derive specific convergence rates that align with those observed in continuous time.</description>
      <guid isPermaLink="false">oai:arXiv.org:2406.00852v2</guid>
      <category>math.OC</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Radu Ioan Bot, Dang-Khoa Nguyen</dc:creator>
    </item>
    <item>
      <title>Two-Timescale Optimization Framework for Decentralized Linear-Quadratic Optimal Control</title>
      <link>https://arxiv.org/abs/2406.11168</link>
      <description>arXiv:2406.11168v2 Announce Type: replace 
Abstract: This study investigates a decentralized linear-quadratic optimal control problem, and several approximate separable constrained optimization problems are formulated for the first time based on the selection of sparsity promoting functions. First, for the optimization problem with weighted $\ell_1$ sparsity promoting function, a two-timescale algorithm is adopted that is based on the BSUM (Block Successive Upper-bound Minimization) framework and a differential equation solver. Second, a piecewise quadratic sparsity promoting function is introduced, and the induced optimization problem demonstrates an accelerated convergence rate by performing the same two-timescale algorithm. Finally, the optimization problem with $\ell_0$ sparsity promoting function is considered that is nonconvex and discontinuous, and can be approximated by successive coordinatewise convex optimization problems.</description>
      <guid isPermaLink="false">oai:arXiv.org:2406.11168v2</guid>
      <category>math.OC</category>
      <category>cs.LG</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Lechen Feng, Yuan-Hua Ni, Xuebo Zhang</dc:creator>
    </item>
    <item>
      <title>A Convex-Nonconvex Framework for Enhancing Minimization Induced Penalties</title>
      <link>https://arxiv.org/abs/2407.14819</link>
      <description>arXiv:2407.14819v2 Announce Type: replace 
Abstract: This paper presents a novel framework for nonconvex enhancement of minimization induced (MI) penalties while preserving the overall convexity of associated regularization models. MI penalties enable the adaptation to certain signal structures via minimization, but often underestimate significant components owing to convexity. To overcome this shortcoming, we design a generalized Moreau enhanced minimization induced (GME-MI) penalty by subtracting from the MI penalty its generalized Moreau envelope. While the proposed GME-MI penalty is nonconvex in general, we derive an overall convexity condition for the GME-MI regularized least-squares model. Moreover, we present a proximal splitting algorithm with guaranteed convergence to a globally optimal solution of the GME-MI model under the overall convexity condition. Numerical examples illustrate the effectiveness of the proposed framework.</description>
      <guid isPermaLink="false">oai:arXiv.org:2407.14819v2</guid>
      <category>math.OC</category>
      <category>eess.SP</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Hiroki Kuroda</dc:creator>
    </item>
    <item>
      <title>Entropic Semi-Martingale Optimal Transport</title>
      <link>https://arxiv.org/abs/2408.09361</link>
      <description>arXiv:2408.09361v2 Announce Type: replace 
Abstract: Entropic Optimal Transport (EOT), also referred to as the Schr\"odinger problem, seeks to find a random processes with prescribed initial/final marginals and with minimal relative entropy with respect to a reference measure. The relative entropy forces the two measures to share the same support and only the drift of the controlled process can be adjusted, the diffusion being imposed by the reference measure. Therefore, at first sight, Semi-Martingale Optimal Transport (SMOT) problems (see [1]) seem out of the scope of applications of Entropic regularization techniques, which are otherwise very attractive from a computational point of view. However, when the process is observed only at discrete times, and become therefore a Markov chain, its relative entropy can remain finite even with variable diffusion coefficients, and discrete semi-martingales can be obtained as solutions of (multi-marginal) EOT problems.Given a (smooth) semi-martingale, the limit of the relative entropy of its time discretizations, scaled by the time step converges to the so-called ``specific relative entropy'', a convex functional of its variance process, similar to those used in SMOT.In this paper we use this observation to build an entropic time discretization of continuous SMOT problems. This allows to compute discrete approximations of solutions to continuous SMOT problems by a multi-marginal Sinkhorn algorithm, without the need of solving the non-linear Hamilton-Jacobi-Bellman pde's associated to the dual problem, as done for example in [1, 2]. We prove a convergence result of the time discrete entropic problem to the continuous time problem, we propose an implementation and provide numerical experiments supporting the theoretical convergence.</description>
      <guid isPermaLink="false">oai:arXiv.org:2408.09361v2</guid>
      <category>math.OC</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Jean-David Benamou, Guillaume Chazareix, Marc Hoffmann, Gr\'egoire Loeper, Fran\c{c}ois-Xavier Vialard</dc:creator>
    </item>
    <item>
      <title>Enhanced Barrier-Smoothing Technique for Bilevel Optimization with Nonsmooth Mappings</title>
      <link>https://arxiv.org/abs/2408.09661</link>
      <description>arXiv:2408.09661v2 Announce Type: replace 
Abstract: Bilevel optimization problems, encountered in fields such as economics, engineering, and machine learning, pose significant computational challenges due to their hierarchical structure and constraints at both upper and lower levels. Traditional gradient-based methods are effective for unconstrained bilevel programs with unique lower level solutions, but struggle with constrained bilevel problems due to the nonsmoothness of lower level solution mappings. To overcome these challenges, this paper introduces the Enhanced Barrier-Smoothing Algorithm (EBSA), a novel approach that integrates gradient-based techniques with an augmented Lagrangian framework. EBSA utilizes innovative smoothing functions to approximate the primal-dual solution mapping of the lower level problem, and then transforms the bilevel problem into a sequence of smooth single-level problems. This approach not only addresses the nonsmoothness but also enhances convergence properties. Theoretical analysis demonstrates its superiority in achieving Clarke and, under certain conditions, Bouligand stationary points for bilevel problems. Both theoretical analysis and preliminary numerical experiments confirm the robustness and efficiency of EBSA.</description>
      <guid isPermaLink="false">oai:arXiv.org:2408.09661v2</guid>
      <category>math.OC</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Mengwei Xu, Yu-Hong Dai, Xin-Wei Liu, Bo Wang</dc:creator>
    </item>
    <item>
      <title>Almost Tight Approximation Hardness for Single-Source Directed k-Edge-Connectivity</title>
      <link>https://arxiv.org/abs/2202.13088</link>
      <description>arXiv:2202.13088v2 Announce Type: replace-cross 
Abstract: In the $k$-connected directed Steiner tree problem ($k$-DST), we are given an $n$-vertex directed graph $G=(V,E)$ with edge costs, a connectivity requirement $k$, a root $r\in V$ and a set of terminals $T\subseteq V$. The goal is to find a minimum-cost subgraph $H\subseteq G$ that has $k$ internally disjoint paths from the root vertex $r$ to every terminal $t\in T$.
  In this paper, we show the approximation hardness of $k$-DST for various parameters, which thus close some long-standing open problems.
  - $\Omega\left(|T|/\log |T|\right)$-approximation hardness, which holds under the standard assumption $\mathrm{NP}\neq \mathrm{ZPP}$. The inapproximability ratio is tightened to $\Omega\left(|T|\right)$ under the Strongish Planted Clique Hypothesis [Manurangsi, Rubinstein and Schramm, ITCS 2021].
  The latter hardness result matches the approximation ratio of $|T|$ obtained by a trivial approximation algorithm, thus closing the long-standing open problem.
  - $\Omega\left(\sqrt{2}^k / k\right)$-approximation hardness for the general case of $k$-DST under the assumption $\mathrm{NP}\neq\mathrm{ZPP}$. This is the first hardness result known for survivable network design problems with an inapproximability ratio exponential in $k$.
  - $\Omega\left((k/L)^{L/4}\right)$-approximation hardness for $k$-DST on $L$-layered graphs for $L\le O\left(\log n\right)$. This almost matches the approximation ratio of $O(k^{L-1}\cdot L \cdot \log |T|)$ achieving in $O\left(n^L\right)$-time due to Laekhanukit [ICALP`16].</description>
      <guid isPermaLink="false">oai:arXiv.org:2202.13088v2</guid>
      <category>cs.DS</category>
      <category>cs.CC</category>
      <category>math.OC</category>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Chao Liao, Qingyun Chen, Bundit Laekhanukit, Yuhao Zhang</dc:creator>
    </item>
    <item>
      <title>International Vaccine Allocation: An Optimization Framework</title>
      <link>https://arxiv.org/abs/2303.05917</link>
      <description>arXiv:2303.05917v3 Announce Type: replace-cross 
Abstract: As observed during the COVID-19 pandemic, high-income countries, such as the U.S., may exhibit vaccine nationalism during a pandemic: stockpiling doses of vaccine for their own citizens and being reluctant to distribute doses of the vaccine to lower-income countries. While many cite moral objections to vaccine nationalism, vaccine inequity during a pandemic could possibly worsen the global effects of the pandemic, including in the high-income countries themselves, through the evolution of new variants of the virus. This paper uses the COVID-19 pandemic as a case study to identify scenarios under which it might be in a high-income nation's own interest to donate vaccine doses to another country before its own population has been fully vaccinated. We develop an extended SEIR (susceptible-exposed-infectious-recovered) epidemiological model embedded in an optimization framework and examine scenarios involving a single donor and multiple recipient (nondonor) geographic areas. We find that policies other than donor-first can delay the emergence of a more-contagious variant compared to donor-first, sometimes reducing donor-country deaths in addition to total deaths. Thus, vaccine distribution is not a zero-sum game between donor and nondonor countries: an optimization approach can achieve a dramatic reduction in total deaths with only a small increase in donor-country deaths. The iterative linear programming approximation approach we develop can help confirm those instances when a priority policy is optimal and, when not optimal, can identify superior policies. This optimization framework can be used to guide equitable vaccine distribution in future pandemics.</description>
      <guid isPermaLink="false">oai:arXiv.org:2303.05917v3</guid>
      <category>q-bio.PE</category>
      <category>math.OC</category>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Abraham Holleran, Susan E. Martonosi, Michael Veatch</dc:creator>
    </item>
    <item>
      <title>Effective Bilevel Optimization via Minimax Reformulation</title>
      <link>https://arxiv.org/abs/2305.13153</link>
      <description>arXiv:2305.13153v3 Announce Type: replace-cross 
Abstract: Bilevel optimization has found successful applications in various machine learning problems, including hyper-parameter optimization, data cleaning, and meta-learning. However, its huge computational cost presents a significant challenge for its utilization in large-scale problems. This challenge arises due to the nested structure of the bilevel formulation, where each hyper-gradient computation necessitates a costly inner optimization procedure. To address this issue, we propose a reformulation of bilevel optimization as a minimax problem, effectively decoupling the outer-inner dependency. Under mild conditions, we show these two problems are equivalent. Furthermore, we introduce a multi-stage gradient descent and ascent (GDA) algorithm to solve the resulting minimax problem with convergence guarantees. Extensive experimental results demonstrate that our method outperforms state-of-the-art bilevel methods while significantly reducing the computational cost.</description>
      <guid isPermaLink="false">oai:arXiv.org:2305.13153v3</guid>
      <category>cs.LG</category>
      <category>math.OC</category>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Xiaoyu Wang, Rui Pan, Renjie Pi, Tong Zhang</dc:creator>
    </item>
    <item>
      <title>On the Stochastic (Variance-Reduced) Proximal Gradient Method for Regularized Expected Reward Optimization</title>
      <link>https://arxiv.org/abs/2401.12508</link>
      <description>arXiv:2401.12508v2 Announce Type: replace-cross 
Abstract: We consider a regularized expected reward optimization problem in the non-oblivious setting that covers many existing problems in reinforcement learning (RL). In order to solve such an optimization problem, we apply and analyze the classical stochastic proximal gradient method. In particular, the method has shown to admit an $O(\epsilon^{-4})$ sample complexity to an $\epsilon$-stationary point, under standard conditions. Since the variance of the classical stochastic gradient estimator is typically large, which slows down the convergence, we also apply an efficient stochastic variance-reduce proximal gradient method with an importance sampling based ProbAbilistic Gradient Estimator (PAGE). Our analysis shows that the sample complexity can be improved from $O(\epsilon^{-4})$ to $O(\epsilon^{-3})$ under additional conditions. Our results on the stochastic (variance-reduced) proximal gradient method match the sample complexity of their most competitive counterparts for discounted Markov decision processes under similar settings. To the best of our knowledge, the proposed methods represent a novel approach in addressing the general regularized reward optimization problem.</description>
      <guid isPermaLink="false">oai:arXiv.org:2401.12508v2</guid>
      <category>cs.LG</category>
      <category>math.OC</category>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Ling Liang, Haizhao Yang</dc:creator>
    </item>
    <item>
      <title>Nash Equilibrium and Learning Dynamics in Three-Player Matching $m$-Action Games</title>
      <link>https://arxiv.org/abs/2402.10825</link>
      <description>arXiv:2402.10825v2 Announce Type: replace-cross 
Abstract: Learning in games discusses the processes where multiple players learn their optimal strategies through the repetition of game plays. The dynamics of learning between two players in zero-sum games, such as matching pennies, where their benefits are competitive, have already been well analyzed. However, it is still unexplored and challenging to analyze the dynamics of learning among three players. In this study, we formulate a minimalistic game where three players compete to match their actions with one another. Although interaction among three players diversifies and complicates the Nash equilibria, we fully analyze the equilibria. We also discuss the dynamics of learning based on some famous algorithms categorized into Follow the Regularized Leader. From both theoretical and experimental aspects, we characterize the dynamics by categorizing three-player interactions into three forces to synchronize their actions, switch their actions rotationally, and seek competition.</description>
      <guid isPermaLink="false">oai:arXiv.org:2402.10825v2</guid>
      <category>cs.GT</category>
      <category>cs.MA</category>
      <category>math.OC</category>
      <category>nlin.CD</category>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Yuma Fujimoto, Kaito Ariu, Kenshi Abe</dc:creator>
    </item>
    <item>
      <title>How to Make the Gradients Small Privately: Improved Rates for Differentially Private Non-Convex Optimization</title>
      <link>https://arxiv.org/abs/2402.11173</link>
      <description>arXiv:2402.11173v2 Announce Type: replace-cross 
Abstract: We provide a simple and flexible framework for designing differentially private algorithms to find approximate stationary points of non-convex loss functions. Our framework is based on using a private approximate risk minimizer to "warm start" another private algorithm for finding stationary points. We use this framework to obtain improved, and sometimes optimal, rates for several classes of non-convex loss functions. First, we obtain improved rates for finding stationary points of smooth non-convex empirical loss functions. Second, we specialize to quasar-convex functions, which generalize star-convex functions and arise in learning dynamical systems and training some neural nets. We achieve the optimal rate for this class. Third, we give an optimal algorithm for finding stationary points of functions satisfying the Kurdyka-Lojasiewicz (KL) condition. For example, over-parameterized neural networks often satisfy this condition. Fourth, we provide new state-of-the-art rates for stationary points of non-convex population loss functions. Fifth, we obtain improved rates for non-convex generalized linear models. A modification of our algorithm achieves nearly the same rates for second-order stationary points of functions with Lipschitz Hessian, improving over the previous state-of-the-art for each of the above problems.</description>
      <guid isPermaLink="false">oai:arXiv.org:2402.11173v2</guid>
      <category>cs.LG</category>
      <category>cs.CR</category>
      <category>math.OC</category>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Andrew Lowy, Jonathan Ullman, Stephen J. Wright</dc:creator>
    </item>
    <item>
      <title>Inferring Dynamic Networks from Marginals with Iterative Proportional Fitting</title>
      <link>https://arxiv.org/abs/2402.18697</link>
      <description>arXiv:2402.18697v2 Announce Type: replace-cross 
Abstract: A common network inference problem, arising from real-world data constraints, is how to infer a dynamic network from its time-aggregated adjacency matrix and time-varying marginals (i.e., row and column sums). Prior approaches to this problem have repurposed the classic iterative proportional fitting (IPF) procedure, also known as Sinkhorn's algorithm, with promising empirical results. However, the statistical foundation for using IPF has not been well understood: under what settings does IPF provide principled estimation of a dynamic network from its marginals, and how well does it estimate the network? In this work, we establish such a setting, by identifying a generative network model whose maximum likelihood estimates are recovered by IPF. Our model both reveals implicit assumptions on the use of IPF in such settings and enables new analyses, such as structure-dependent error bounds on IPF's parameter estimates. When IPF fails to converge on sparse network data, we introduce a principled algorithm that guarantees IPF converges under minimal changes to the network structure. Finally, we conduct experiments with synthetic and real-world data, which demonstrate the practical value of our theoretical and algorithmic contributions.</description>
      <guid isPermaLink="false">oai:arXiv.org:2402.18697v2</guid>
      <category>stat.ML</category>
      <category>cs.LG</category>
      <category>cs.SI</category>
      <category>math.OC</category>
      <category>math.ST</category>
      <category>stat.TH</category>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <arxiv:journal_reference>Proceedings of the 41st International Conference on Machine Learning, PMLR 235:6202-6252, 2024</arxiv:journal_reference>
      <dc:creator>Serina Chang, Frederic Koehler, Zhaonan Qu, Jure Leskovec, Johan Ugander</dc:creator>
    </item>
    <item>
      <title>A Correlation-induced Finite Difference Estimator</title>
      <link>https://arxiv.org/abs/2405.05638</link>
      <description>arXiv:2405.05638v4 Announce Type: replace-cross 
Abstract: Finite difference (FD) approximation is a classic approach to stochastic gradient estimation when only noisy function realizations are available. In this paper, we first provide a sample-driven method via the bootstrap technique to estimate the optimal perturbation, and then propose an efficient FD estimator based on correlated samples at the estimated optimal perturbation. Furthermore, theoretical analyses of both the perturbation estimator and the FD estimator reveal that, {\it surprisingly}, the correlation enables the proposed FD estimator to achieve a reduction in variance and, in some cases, a decrease in bias compared to the traditional optimal FD estimator. Numerical results confirm the efficiency of our estimators and align well with the theory presented, especially in scenarios with small sample sizes. Finally, we apply the estimator to solve derivative-free optimization (DFO) problems, and numerical studies show that DFO problems with 100 dimensions can be effectively solved.</description>
      <guid isPermaLink="false">oai:arXiv.org:2405.05638v4</guid>
      <category>stat.ME</category>
      <category>cs.LG</category>
      <category>cs.NA</category>
      <category>math.NA</category>
      <category>math.OC</category>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Guo Liang, Guangwu Liu, Kun Zhang</dc:creator>
    </item>
  </channel>
</rss>
