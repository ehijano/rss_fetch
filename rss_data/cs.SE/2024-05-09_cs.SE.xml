<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>cs.SE updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/cs.SE</link>
    <description>cs.SE updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/cs.SE" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Thu, 09 May 2024 04:00:14 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Thu, 09 May 2024 00:00:00 -0400</pubDate>
    <skipDays>
      <day>Saturday</day>
      <day>Sunday</day>
    </skipDays>
    <item>
      <title>A Reference Model for Information Quality in an IT Governance Context</title>
      <link>https://arxiv.org/abs/2405.04558</link>
      <description>arXiv:2405.04558v1 Announce Type: new 
Abstract: IT Governance systems are increasingly required to keep todays organizations functioning. IT Governance requires a holistic system of interacting components, including processes, organizational structures, information, and others. Performance management of IT Governance systems is of utmost importance to maintain their effectiveness. Capability models are used to assess and manage IT Governance process performance, whereas similar mechanisms are lacking for other types of IT Governance system components, e.g. information. In this paper, we focus on how to define the quality of IT Governance information, as a proxy for the performance of the information component of the IT Governance system. Using a Design Science approach, we iteratively develop, based on theory, and empirically evaluate, based on expert validation, a reference model for IT Governance information quality, i.e., the Information Quality Reference Model that can be used for assessing the quality of IT Governance information items. The model is comprehensive yet manageable and provides a basis for building a capability model for IT Governance information.</description>
      <guid isPermaLink="false">oai:arXiv.org:2405.04558v1</guid>
      <category>cs.SE</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Dirk Steuperaert, Geert Poels, Jan Devos</dc:creator>
    </item>
    <item>
      <title>Contextual API Completion for Unseen Repositories Using LLMs</title>
      <link>https://arxiv.org/abs/2405.04600</link>
      <description>arXiv:2405.04600v1 Announce Type: new 
Abstract: Large language models have made substantial progress in addressing diverse code-related tasks. However, their adoption is hindered by inconsistencies in generating output due to the lack of real-world, domain-specific information, such as for intra-repository API calls for unseen software projects. We introduce a novel technique to mitigate hallucinations by leveraging global and local contextual information within a code repository for API completion tasks. Our approach is tailored to refine code completion tasks, with a focus on optimizing local API completions. We examine relevant import statements during API completion to derive insights into local APIs, drawing from their method signatures. For API token completion, we analyze the inline variables and correlate them with the appropriate imported modules, thereby allowing our approach to rank the most contextually relevant suggestions from the available local APIs. Further, for conversational API completion, we gather APIs that are most relevant to the developer query with a retrieval-based search across the project. We employ our tool, LANCE, within the framework of our proposed benchmark, APIEval, encompassing two different programming languages. Our evaluation yields an average accuracy of 82.6% for API token completion and 76.9% for conversational API completion tasks. On average, LANCE surpasses Copilot by 143% and 142% for API token completion and conversational API completion, respectively. The implications of our findings are substantial for developers, suggesting that our lightweight context analysis can be applied to multilingual environments without language-specific training or fine-tuning, allowing for efficient implementation with minimal examples and effort.</description>
      <guid isPermaLink="false">oai:arXiv.org:2405.04600v1</guid>
      <category>cs.SE</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Noor Nashid, Taha Shabani, Parsa Alian, Ali Mesbah</dc:creator>
    </item>
    <item>
      <title>An Empirical Study of Kotlin-Java Interactions</title>
      <link>https://arxiv.org/abs/2405.04602</link>
      <description>arXiv:2405.04602v1 Announce Type: new 
Abstract: Background: Since Google introduced Kotlin as an official programming language for developing Android apps in 2017, Kotlin has gained widespread adoption in Android development. The interoperability of Java and Kotlin's design nature allows them to coexist and interact with each other smoothly within a project. Aims: However, there is limited research on how Java and Kotlin interact with each other in real-world projects and what challenges are faced during these interactions. The answers to these questions are key to understanding these kinds of cross-language software systems. Methods: In this paper, we implemented a tool named DependExtractor, which can extract 11 kinds of Kotlin-Java dependencies, and conducted an empirical study of 23 Kotlin-Java real-world projects with 3,227 Java and 8,630 Kotlin source files. Results: Our findings revealed that Java and Kotlin frequently interact with each other in these cross-language projects, with access and call dependency types being the most dominant. Compared to files interacting with other files in the same language, Java/Kotlin source files, which participate in the cross-language interactions, undergo more commits. Additionally, among all Kotlin-Java problematic interactions, we identified seven common mistakes, along with their fixing strategies. Conclusions: The findings of this study can help developers understand and address the challenges in Kotlin-Java projects.</description>
      <guid isPermaLink="false">oai:arXiv.org:2405.04602v1</guid>
      <category>cs.SE</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Qiong Feng, Huan Ji, Xiaotian Ma, Peng Liang</dc:creator>
    </item>
    <item>
      <title>The Impact of Human Aspects on the Interactions Between Software Developers and End-Users in Software Engineering: A Systematic Literature Review</title>
      <link>https://arxiv.org/abs/2405.04787</link>
      <description>arXiv:2405.04787v1 Announce Type: new 
Abstract: Context: Research on human aspects within the field of software engineering (SE) has been steadily gaining prominence in recent years. These human aspects have a significant impact on SE due to the inherently interactive and collaborative nature of the discipline.
  Objective: In this paper, we present a systematic literature review (SLR) on human aspects affecting developer-user interactions. The objective of this SLR is to plot the current landscape of primary studies by examining the human aspects that influence developer-user interactions, their implications, interrelationships, and how existing studies address these implications.
  Method: We conducted this SLR following the guidelines proposed by Kitchenham et al. We performed a comprehensive search in six digital databases, and an exhaustive backward and forward snowballing process. We selected 46 primary studies for data extraction.
  Results: We identified various human aspects affecting developer-user interactions in SE, assessed their interrelationships, identified their positive impacts and mitigation strategies for negative effects. We present specific recommendations derived from the identified research gaps.
  Conclusion: Our findings suggest the importance of leveraging positive effects and addressing negative effects in developer-user interactions through the implementation of effective mitigation strategies. These insights may benefit software practitioners for effective user interactions, and the recommendations proposed by this SLR may aid the research community in further human aspects related studies.</description>
      <guid isPermaLink="false">oai:arXiv.org:2405.04787v1</guid>
      <category>cs.SE</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Hashini Gunatilake, John Grundy, Rashina Hoda, Ingo Mueller</dc:creator>
    </item>
    <item>
      <title>Concolic Testing of Quantum Programs</title>
      <link>https://arxiv.org/abs/2405.04860</link>
      <description>arXiv:2405.04860v1 Announce Type: new 
Abstract: This paper presents the first concolic testing framework specifically designed for quantum programs. The framework defines quantum conditional statements that quantify quantum states and presents a symbolization method for quantum variables. Utilizing this framework, we generate path constraints for each concrete execution path of a quantum program. These constraints guide the exploration of new paths, with a quantum constraint solver determining the outcomes to generate novel input samples and enhance branch coverage. We implemented this framework in Python and integrated it with Qiskit for practical evaluation. Experimental results demonstrate that our concolic testing framework significantly improves branch coverage and the quality of quantum input samples, demonstrating its effectiveness and efficiency in quantum software testing.</description>
      <guid isPermaLink="false">oai:arXiv.org:2405.04860v1</guid>
      <category>cs.SE</category>
      <category>quant-ph</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Shangzhou Xia, Jianjun Zhao, Fuyuan Zhang, Xiaoyu Guo</dc:creator>
    </item>
    <item>
      <title>Insights into Deep Learning Refactoring: Bridging the Gap Between Practices and Expectations</title>
      <link>https://arxiv.org/abs/2405.04861</link>
      <description>arXiv:2405.04861v1 Announce Type: new 
Abstract: With the rapid development of deep learning, the implementation of intricate algorithms and substantial data processing have become standard elements of deep learning projects. As a result, the code has become progressively complex as the software evolves, which is difficult to maintain and understand. Existing studies have investigated the impact of refactoring on software quality within traditional software. However, the insight of code refactoring in the context of deep learning is still unclear. This study endeavors to fill this knowledge gap by empirically examining the current state of code refactoring in deep learning realm, and practitioners' views on refactoring. We first manually analyzed the commit history of five popular and well-maintained deep learning projects (e.g., PyTorch). We mined 4,921 refactoring practices in historical commits and measured how different types and elements of refactoring operations are distributed and found that refactoring operation types' distribution in deep learning projects is different from it in traditional Java software. We then surveyed 159 practitioners about their views of code refactoring in deep learning projects and their expectations of current refactoring tools. The result of the survey showed that refactoring research and the development of related tools in the field of deep learning are crucial for improving project maintainability and code quality, and that current refactoring tools do not adequately meet the needs of practitioners. Lastly, we provided our perspective on the future advancement of refactoring tools and offered suggestions for developers' development practices.</description>
      <guid isPermaLink="false">oai:arXiv.org:2405.04861v1</guid>
      <category>cs.SE</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>SiQi Wang, Xing Hu, Bei Wang, WenXin Yao, Xin Xia, XingYu Wang</dc:creator>
    </item>
    <item>
      <title>Prototype2Code: End-to-end Front-end Code Generation from UI Design Prototypes</title>
      <link>https://arxiv.org/abs/2405.04975</link>
      <description>arXiv:2405.04975v1 Announce Type: new 
Abstract: UI-to-code technology has streamlined the front-end development process, reducing repetitive tasks for engineers. prior research mainly use design prototypes as inputs, with the effectiveness of the generated code heavily dependent on these prototypes' quality, leading to compromised robustness. Moreover, these approaches also exhibit shortcomings in code quality, including issues such as disorganized UI structures and the inability to support responsive layouts. To address these challenges, we introduce Prototype2Code, which achieves end-to-end front-end code generation with business demands. For Prototype2Code, we incorporate design linting into the workflow, addressing the detection of fragmented elements and perceptual groups, enhancing the robustness of the generated outcomes. By optimizing the hierarchical structure and intelligently recognizing UI element types, Prototype2Code generates code that is more readable and structurally clearer. To meet responsive design requirements, Prototype2Code primarily supports flexbox layout model, ensuring code compatibility across various device sizes. To validate the efficacy, we compare Prototype2Code with the commercial code generation platform CodeFun and Screenshot-to-code based on GPT-4 with vision. Employing structural similarity index measure (SSIM), peak signal-to-noise ratio (PSNR), and mean squared error (MSE) for visual similarity assessment, Prototype2Code's rendered UI effects align most closely with the design prototypes, exhibiting the minimal errors. We also conduct a user study with five experienced front-end engineers, inviting them to review and revise code generated by the three methods. As a result, Prototype2Code surpasses other methods in readability, usability, and maintainability, better meeting the business needs of industrial development.</description>
      <guid isPermaLink="false">oai:arXiv.org:2405.04975v1</guid>
      <category>cs.SE</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Shuhong Xiao, Yunnong Chen, Jiazhi Li, Liuqing Chen, Lingyun Sun, Tingting Zhou</dc:creator>
    </item>
    <item>
      <title>NAVRepair: Node-type Aware C/C++ Code Vulnerability Repair</title>
      <link>https://arxiv.org/abs/2405.04994</link>
      <description>arXiv:2405.04994v1 Announce Type: new 
Abstract: The rapid advancement of deep learning has led to the development of Large Language Models (LLMs). In the field of vulnerability repair, previous research has leveraged rule-based fixing, pre-trained models, and LLM's prompt engineering. However, existing approaches have limitations in terms of the integration of code structure with error types. Besides, due to certain features of C/C++ language, vulnerability repair in C/C++ proves to be exceptionally challenging. To address these challenges, we propose NAVRepair, a novel framework that combines the node-type information extracted from Abstract Syntax Trees (ASTs) with error types, specifically targeting C/C++ vulnerabilities. Specifically, our approach employs type analysis to localize the minimum edit node (MEN) and customizes context information collection based on different error types. In the offline stage, NAVRepair parses code patches to locate MENs and designs rules to extract relevant contextual information for each MEN type. In the online repairing stage, it analyzes the suspicious code, combines it with vulnerability type templates derived from the Common Weakness Enumeration (CWE), and generates targeted repair prompts. We evaluate NAVRepair on multiple popular LLMs and demonstrate its effectiveness in improving the performance of code vulnerability repair. Notably, our framework is independent of any specific LLMs and can quickly adapt to new vulnerability types. Extensive experiments validate that NAVRepair achieves excellent results in assisting LLMs to accurately detect and fix C/C++ vulnerabilities. We achieve a 26% higher accuracy compared to an existing LLM-based C/C++ vulnerability repair method. We believe our node type-aware approach has promising application prospects for enhancing real-world C/C++ code security.</description>
      <guid isPermaLink="false">oai:arXiv.org:2405.04994v1</guid>
      <category>cs.SE</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Ruoke Wang, Zongjie Li, Chaozheng Wang, Yang Xiao, Cuiyun Gao</dc:creator>
    </item>
    <item>
      <title>6G Software Engineering: A Systematic Mapping Study</title>
      <link>https://arxiv.org/abs/2405.05017</link>
      <description>arXiv:2405.05017v1 Announce Type: new 
Abstract: 6G will revolutionize the software world allowing faster cellular communications and a massive number of connected devices. 6G will enable a shift towards a continuous edge-to-cloud architecture. Current cloud solutions, where all the data is transferred and computed in the cloud, are not sustainable in such a large network of devices. Current technologies, including development methods, software architectures, and orchestration and offloading systems, still need to be prepared to cope with such requirements. In this paper, we conduct a Systematic Mapping Study to investigate the current research status of 6G Software Engineering. Results show that 18 research papers have been proposed in software process, software architecture, orchestration and offloading methods. Of these, software architecture and software-defined networks are respectively areas and topics that have received the most attention in 6G Software Engineering. In addition, the main types of results of these papers are methods, architectures, platforms, frameworks and algorithms. For the five tools/frameworks proposed, they are new and not currently studied by other researchers. The authors of these findings are mainly from China, India and Saudi Arabia. The results will enable researchers and practitioners to further research and extend for 6G Software Engineering.</description>
      <guid isPermaLink="false">oai:arXiv.org:2405.05017v1</guid>
      <category>cs.SE</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <dc:creator>Ruoyu Su, Xiaozhou Li, Davide Taibi</dc:creator>
    </item>
    <item>
      <title>Quantum Circuit Ansatz: Abstraction and Reuse of Quantum Algorithm Design</title>
      <link>https://arxiv.org/abs/2405.05021</link>
      <description>arXiv:2405.05021v1 Announce Type: new 
Abstract: Quantum computing holds the potential to revolutionize various fields by efficiently tackling complex problems. At its core are quantum circuits, sequences of quantum gates manipulating quantum states. The selection of the right quantum circuit ansatz, which defines initial circuit structures and serves as the basis for optimization techniques, is crucial in quantum algorithm design.This paper presents a categorized catalog of quantum circuit ansatzes aimed at supporting quantum algorithm design and implementation. Each ansatz is described with details such as intent, motivation, applicability, circuit diagram, implementation, example, and see also. Practical examples are provided to illustrate their application in quantum algorithm design.The catalog aims to assist quantum algorithm designers by offering insights into the strengths and limitations of different ansatzes, thereby facilitating decision-making for specific tasks.</description>
      <guid isPermaLink="false">oai:arXiv.org:2405.05021v1</guid>
      <category>cs.SE</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Xiaoyu Guo, Takahiro Muta, Jianjun Zhao</dc:creator>
    </item>
    <item>
      <title>Lessons from the Use of Natural Language Inference (NLI) in Requirements Engineering Tasks</title>
      <link>https://arxiv.org/abs/2405.05135</link>
      <description>arXiv:2405.05135v1 Announce Type: new 
Abstract: We investigate the use of Natural Language Inference (NLI) in automating requirements engineering tasks. In particular, we focus on three tasks: requirements classification, identification of requirements specification defects, and detection of conflicts in stakeholders' requirements. While previous research has demonstrated significant benefit in using NLI as a universal method for a broad spectrum of natural language processing tasks, these advantages have not been investigated within the context of software requirements engineering. Therefore, we design experiments to evaluate the use of NLI in requirements analysis. We compare the performance of NLI with a spectrum of approaches, including prompt-based models, conventional transfer learning, Large Language Models (LLMs)-powered chatbot models, and probabilistic models. Through experiments conducted under various learning settings including conventional learning and zero-shot, we demonstrate conclusively that our NLI method surpasses classical NLP methods as well as other LLMs-based and chatbot models in the analysis of requirements specifications. Additionally, we share lessons learned characterizing the learning settings that make NLI a suitable approach for automating requirements engineering tasks.</description>
      <guid isPermaLink="false">oai:arXiv.org:2405.05135v1</guid>
      <category>cs.SE</category>
      <category>cs.CL</category>
      <category>cs.LG</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Mohamad Fazelnia, Viktoria Koscinski, Spencer Herzog, Mehdi Mirakhorli</dc:creator>
    </item>
    <item>
      <title>Gamification in Software Engineering Education: a Tertiary Study</title>
      <link>https://arxiv.org/abs/2405.05209</link>
      <description>arXiv:2405.05209v1 Announce Type: new 
Abstract: As the significance of Software Engineering (SE) professionals continues to grow in the industry, the adoption of gamification techniques for training purposes has gained traction due to its potential to enhance class appeal through game-derived elements. This paper presents a tertiary study investigating the application of gamification in Software Engineering (SE) education. The study was conducted in response to recent systematic literature reviews and mappings on the topic. The findings reveal that the areas of SE most frequently gamified are Software Testing and Software Quality, with competition and cooperation being the most commonly utilized gamification elements. Additionally, the majority of studies focus on structural gamification, where game elements are employed to modify the learning environment without altering the content. The results demonstrate the potential of gamification to improve students' engagement and motivation throughout the SE learning process, while also impacting other aspects such as performance improvement, skill development, and fostering good SE practices. However, caution is advised as unplanned and incorrectly applied gamification measures may lead to significant declines in performance and motivation. (English Version of the paper in Portuguese available here: HTTP://doi.org/10.1145/3613372.3614193</description>
      <guid isPermaLink="false">oai:arXiv.org:2405.05209v1</guid>
      <category>cs.SE</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Simone Tonh\~ao, Marcelo Shigenaga, Julio Herculani, Andressa Medeiros, Aline Amaral, Williamson Silva, Thelma Colanzi, Igor Steinmacher</dc:creator>
    </item>
    <item>
      <title>Patterns of Multi-Container Composition for Service Orchestration with Docker Compose</title>
      <link>https://arxiv.org/abs/2305.11293</link>
      <description>arXiv:2305.11293v2 Announce Type: replace 
Abstract: Software design patterns present general code solutions to common software design problems. Modern software systems rely heavily on containers for running their constituent service components. Yet, despite the prevalence of ready-to-use Docker service images ready to participate in multi-container service compositions of applications, developers do not have much guidance on how to compose their own Docker service orchestrations. Thus in this work, we curate a dataset of successful projects that employ Docker Compose as an orchestration tool to run multiple service containers; then, we engage in qualitative and quantitative analysis of Docker Compose configurations. The collection of data and analysis enables the identification and naming of repeating multi-container composition patterns that are used in numerous successful open-source projects, much like software design patterns. These patterns highlight how software systems are orchestrated in the real-world and can give examples to anybody wishing to compose their own service orchestrations. These contributions also advance empirical research in software engineering patterns as evidence is provided about how Docker Compose is used.</description>
      <guid isPermaLink="false">oai:arXiv.org:2305.11293v2</guid>
      <category>cs.SE</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <arxiv:DOI>10.1007/s10664-024-10462-8</arxiv:DOI>
      <dc:creator>Kalvin Eng, Abram Hindle, Eleni Stroulia</dc:creator>
    </item>
    <item>
      <title>Prompting Is All You Need: Automated Android Bug Replay with Large Language Models</title>
      <link>https://arxiv.org/abs/2306.01987</link>
      <description>arXiv:2306.01987v3 Announce Type: replace 
Abstract: Bug reports are vital for software maintenance that allow users to inform developers of the problems encountered while using the software. As such, researchers have committed considerable resources toward automating bug replay to expedite the process of software maintenance. Nonetheless, the success of current automated approaches is largely dictated by the characteristics and quality of bug reports, as they are constrained by the limitations of manually-crafted patterns and pre-defined vocabulary lists. Inspired by the success of Large Language Models (LLMs) in natural language understanding, we propose AdbGPT, a new lightweight approach to automatically reproduce the bugs from bug reports through prompt engineering, without any training and hard-coding effort. AdbGPT leverages few-shot learning and chain-of-thought reasoning to elicit human knowledge and logical reasoning from LLMs to accomplish the bug replay in a manner similar to a developer. Our evaluations demonstrate the effectiveness and efficiency of our AdbGPT to reproduce 81.3% of bug reports in 253.6 seconds, outperforming the state-of-the-art baselines and ablation studies. We also conduct a small-scale user study to confirm the usefulness of AdbGPT in enhancing developers' bug replay capabilities.</description>
      <guid isPermaLink="false">oai:arXiv.org:2306.01987v3</guid>
      <category>cs.SE</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Sidong Feng, Chunyang Chen</dc:creator>
    </item>
    <item>
      <title>Isolating Compiler Bugs by Generating Effective Witness Programs with Large Language Models</title>
      <link>https://arxiv.org/abs/2307.00593</link>
      <description>arXiv:2307.00593v3 Announce Type: replace 
Abstract: Compiler bugs pose a significant threat to safety-critical applications, and promptly as well as effectively isolating these bugs is crucial for assuring the quality of compilers. However, the limited availability of debugging information on reported bugs complicates the compiler bug isolation task. Existing compiler bug isolation approaches convert the problem into a test program mutation problem, but they are still limited by ineffective mutation strategies or high human effort requirements. Drawing inspiration from the recent progress of pre-trained Large Language Models (LLMs), such as ChatGPT, in code generation, we propose a new approach named LLM4CBI to utilize LLMs to generate effective test programs for compiler bug isolation. However, using LLMs directly for test program mutation may not yield the desired results due to the challenges associated with formulating precise prompts and selecting specialized prompts. To overcome the challenges, three new components are designed in LLM4CBI. First, LLM4CBI utilizes a program complexity-guided prompt production component, which leverages data and control flow analysis to identify the most valuable variables and locations in programs for mutation. Second, LLM4CBI employs a memorized prompt selection component, which adopts reinforcement learning to select specialized prompts for mutating test programs continuously. Third, a test program validation component is proposed to select specialized feedback prompts to avoid repeating the same mistakes during the mutation process. Compared with state-of-the-art approaches over 120 real bugs from GCC and LLVM, our evaluation demonstrates the advantages of LLM4CBI: It can isolate 69.70%/21.74% and 24.44%/8.92% more bugs than DiWi and RecBi within Top-1/Top-5 ranked results. We also demonstrate that the LLMs component used in LLM4CBI can be easily replaced while still achieving reasonable results.</description>
      <guid isPermaLink="false">oai:arXiv.org:2307.00593v3</guid>
      <category>cs.SE</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <arxiv:DOI>10.1109/TSE.2024.3397822</arxiv:DOI>
      <dc:creator>Haoxin Tu, Zhide Zhou, He Jiang, Imam Nur Bani Yusuf, Yuxian Li, Lingxiao Jiang</dc:creator>
    </item>
    <item>
      <title>Individual context-free online community health indicators fail to identify open source software sustainability</title>
      <link>https://arxiv.org/abs/2309.12120</link>
      <description>arXiv:2309.12120v2 Announce Type: replace 
Abstract: Software is often abandoned or shut down, for one reason or another, and whilst research on academic open source software is sparse, there seems little reason to assume it is any different. While some reasons may be straightforward, e.g. a sole maintainer has moved on, or grant funding has ceased - some projects are able to withstand these barriers and may remain active and maintained despite adversity. This study monitored open source projects over the period of a year, measuring common performance indicators, using both subjective and qualitative measures (participant surveys), as well as using scripts to analyse indicators associated with these projects' online source control codebases. We find that these health indicators can not be used as cross project benchmarks, due to the significant variation in context for each project. They can, however, often be useful in signifying changes in a single project's health, providing they are not used to compare between different unrelated projects.</description>
      <guid isPermaLink="false">oai:arXiv.org:2309.12120v2</guid>
      <category>cs.SE</category>
      <category>cs.CY</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Yo Yehudi, Carole Goble, Caroline Jay</dc:creator>
    </item>
    <item>
      <title>Energy and Time Complexity for Sorting Algorithms in Java</title>
      <link>https://arxiv.org/abs/2311.07298</link>
      <description>arXiv:2311.07298v2 Announce Type: replace 
Abstract: The article investigates the relationship between time complexity and energy consumption in sorting algorithms, focusing on commonly-used algorithms implemented in Java: Bubble Sort, Counting Sort, Merge Sort, and Quick Sort. The significance of understanding this relationship is driven by the increasing energy demands of Information and Communication Technology systems and the potential for software optimization to contribute to energy efficiency. If we find a strong correlation between time complexity and energy usage, it would enhance the ability of software developers to create energy-efficient applications.
  This quantitative study researches the execution of four selected sorting algorithms with input varying over input sizes (25000 to 1 million) and input order types (best, worst, and random cases) on a single kernel in a Java-enabled system. The input size is adjusted according to the type's maximum execution time, resulting in 136 combinations, totalling 12960 measurements. Wall time and the CPU energy consumption is measured using Intel's RAPL. Statistical analysis are used to examine the correlations between time complexity, wall time, and energy consumption.
  The study finds a strong correlation between time complexity and energy consumption for the sorting algorithms tested. More than 99% of the variance in energy consumption for Counting Sort, Merge Sort, and Quick Sort depend on their time complexities. More than 94% of the variance in energy consumption for Bubble Sort depends on its time complexity. The results affirm that time complexity can serve as a reliable predictor of energy consumption in sequential sorting algorithms. This discovery could guide software developers in choosing energy-efficient algorithms by considering time complexities.</description>
      <guid isPermaLink="false">oai:arXiv.org:2311.07298v2</guid>
      <category>cs.SE</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Kristina Carter, Su Mei Gwen Ho, Mathias Marquar Arhipenko Larsen, Martin Sundman, Maja H. Kirkeby</dc:creator>
    </item>
    <item>
      <title>CodeBenchGen: Creating Scalable Execution-based Code Generation Benchmarks</title>
      <link>https://arxiv.org/abs/2404.00566</link>
      <description>arXiv:2404.00566v3 Announce Type: replace 
Abstract: To facilitate evaluation of code generation systems across diverse scenarios, we present CodeBenchGen, a framework to create scalable execution-based benchmarks that only requires light guidance from humans. Specifically, we leverage a large language model (LLM) to convert an arbitrary piece of code into an evaluation example, including test cases for execution-based evaluation. We illustrate the usefulness of our framework by creating a dataset, Exec-CSN, which includes 1,931 examples involving 293 libraries revised from code in 367 GitHub repositories taken from the CodeSearchNet dataset. To demonstrate the complexity and solvability of examples in Exec-CSN, we present a human study demonstrating that 81.3% of the examples can be solved by humans and 61% are rated as "requires effort to solve". We conduct code generation experiments on open-source and proprietary models and analyze the performance of both humans and models. We provide the code at https://github.com/Veronicium/CodeBenchGen.</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.00566v3</guid>
      <category>cs.SE</category>
      <category>cs.CL</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Yiqing Xie, Alex Xie, Divyanshu Sheth, Pengfei Liu, Daniel Fried, Carolyn Rose</dc:creator>
    </item>
    <item>
      <title>Fast Abstracts and Student Forum Proceedings -- EDCC 2024 -- 19th European Dependable Computing Conference</title>
      <link>https://arxiv.org/abs/2404.17465</link>
      <description>arXiv:2404.17465v4 Announce Type: replace 
Abstract: The goal of the Fast Abstracts track is to bring together researchers and practitioners working on dependable computing to discuss work in progress or opinion pieces. Contributions are welcome from academia and industry. Fast Abstracts aim to serve as a rapid and flexible mechanism to: (i) Report on current work that may or may not be complete; (ii) Introduce new ideas to the community; (iii) State positions on controversial issues or open problems; (iv) Share lessons learnt from real-word dependability engineering; and (v) Debunk or question results from other papers based on contra-indications. The Student Forum aims at creating a vibrant and friendly environment where students can present and discuss their work, and exchange ideas and experiences with other students, researchers and industry. One of the key goals of the Forum is to provide students with feedback on their preliminary results that might help with their future research directions.</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.17465v4</guid>
      <category>cs.SE</category>
      <category>cs.CY</category>
      <category>cs.DC</category>
      <category>cs.LG</category>
      <category>cs.RO</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <dc:creator>Simona Bernardi, Tommaso Zoppi</dc:creator>
    </item>
    <item>
      <title>Enhancing High-Level Synthesis with Automated Pragma Insertion and Code Transformation Framework</title>
      <link>https://arxiv.org/abs/2405.03058</link>
      <description>arXiv:2405.03058v2 Announce Type: replace 
Abstract: High-level synthesis, source-to-source compilers, and various Design Space Exploration techniques for pragma insertion have significantly improved the Quality of Results of generated designs. These tools offer benefits such as reduced development time and enhanced performance. However, achieving high-quality results often requires additional manual code transformations and tiling selections, which are typically performed separately or as pre-processing steps. Although DSE techniques enable code transformation upfront, the vastness of the search space often limits the exploration of all possible code transformations, making it challenging to determine which transformations are necessary. Additionally, ensuring correctness remains challenging, especially for complex transformations and optimizations.
  To tackle this obstacle, we first propose a comprehensive framework leveraging HLS compilers. Our system streamlines code transformation, pragma insertion, and tiles size selection for on-chip data caching through a unified optimization problem, aiming to enhance parallelization, particularly beneficial for computation-bound kernels. Them employing a novel Non-Linear Programming (NLP) approach, we simultaneously ascertain transformations, pragmas, and tile sizes, focusing on regular loop-based kernels. Our evaluation demonstrates that our framework adeptly identifies the appropriate transformations, including scenarios where no transformation is necessary, and inserts pragmas to achieve a favorable Quality of Results.</description>
      <guid isPermaLink="false">oai:arXiv.org:2405.03058v2</guid>
      <category>cs.SE</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>St\'ephane Pouget, Louis-No\"el Pouchet, Jason Cong</dc:creator>
    </item>
    <item>
      <title>Distribution-aware Fairness Test Generation</title>
      <link>https://arxiv.org/abs/2305.13935</link>
      <description>arXiv:2305.13935v4 Announce Type: replace-cross 
Abstract: Ensuring that all classes of objects are detected with equal accuracy is essential in AI systems. For instance, being unable to identify any one class of objects could have fatal consequences in autonomous driving systems. Hence, ensuring the reliability of image recognition systems is crucial. This work addresses how to validate group fairness in image recognition software. We propose a distribution-aware fairness testing approach (called DistroFair) that systematically exposes class-level fairness violations in image classifiers via a synergistic combination of out-of-distribution (OOD) testing and semantic-preserving image mutation. DistroFair automatically learns the distribution (e.g., number/orientation) of objects in a set of images. Then it systematically mutates objects in the images to become OOD using three semantic-preserving image mutations - object deletion, object insertion and object rotation. We evaluate DistroFair using two well-known datasets (CityScapes and MS-COCO) and three major, commercial image recognition software (namely, Amazon Rekognition, Google Cloud Vision and Azure Computer Vision). Results show that about 21% of images generated by DistroFair reveal class-level fairness violations using either ground truth or metamorphic oracles. DistroFair is up to 2.3x more effective than two main baselines, i.e., (a) an approach which focuses on generating images only within the distribution (ID) and (b) fairness analysis using only the original image dataset. We further observed that DistroFair is efficient, it generates 460 images per hour, on average. Finally, we evaluate the semantic validity of our approach via a user study with 81 participants, using 30 real images and 30 corresponding mutated images generated by DistroFair. We found that images generated by DistroFair are 80% as realistic as real-world images.</description>
      <guid isPermaLink="false">oai:arXiv.org:2305.13935v4</guid>
      <category>cs.CV</category>
      <category>cs.LG</category>
      <category>cs.SE</category>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <dc:creator>Sai Sathiesh Rajan, Ezekiel Soremekun, Yves Le Traon, Sudipta Chattopadhyay</dc:creator>
    </item>
    <item>
      <title>Personal LLM Agents: Insights and Survey about the Capability, Efficiency and Security</title>
      <link>https://arxiv.org/abs/2401.05459</link>
      <description>arXiv:2401.05459v2 Announce Type: replace-cross 
Abstract: Since the advent of personal computing devices, intelligent personal assistants (IPAs) have been one of the key technologies that researchers and engineers have focused on, aiming to help users efficiently obtain information and execute tasks, and provide users with more intelligent, convenient, and rich interaction experiences. With the development of smartphones and IoT, computing and sensing devices have become ubiquitous, greatly expanding the boundaries of IPAs. However, due to the lack of capabilities such as user intent understanding, task planning, tool using, and personal data management etc., existing IPAs still have limited practicality and scalability. Recently, the emergence of foundation models, represented by large language models (LLMs), brings new opportunities for the development of IPAs. With the powerful semantic understanding and reasoning capabilities, LLM can enable intelligent agents to solve complex problems autonomously. In this paper, we focus on Personal LLM Agents, which are LLM-based agents that are deeply integrated with personal data and personal devices and used for personal assistance. We envision that Personal LLM Agents will become a major software paradigm for end-users in the upcoming era. To realize this vision, we take the first step to discuss several important questions about Personal LLM Agents, including their architecture, capability, efficiency and security. We start by summarizing the key components and design choices in the architecture of Personal LLM Agents, followed by an in-depth analysis of the opinions collected from domain experts. Next, we discuss several key challenges to achieve intelligent, efficient and secure Personal LLM Agents, followed by a comprehensive survey of representative solutions to address these challenges.</description>
      <guid isPermaLink="false">oai:arXiv.org:2401.05459v2</guid>
      <category>cs.HC</category>
      <category>cs.AI</category>
      <category>cs.SE</category>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Yuanchun Li, Hao Wen, Weijun Wang, Xiangyu Li, Yizhen Yuan, Guohong Liu, Jiacheng Liu, Wenxing Xu, Xiang Wang, Yi Sun, Rui Kong, Yile Wang, Hanfei Geng, Jian Luan, Xuefeng Jin, Zilong Ye, Guanjing Xiong, Fan Zhang, Xiang Li, Mengwei Xu, Zhijun Li, Peng Li, Yang Liu, Ya-Qin Zhang, Yunxin Liu</dc:creator>
    </item>
    <item>
      <title>From Quantum Mechanics to Quantum Software Engineering: A Historical Review</title>
      <link>https://arxiv.org/abs/2404.19428</link>
      <description>arXiv:2404.19428v2 Announce Type: replace-cross 
Abstract: Victor Hugo's timeless observation, "Nothing is more powerful than an idea whose time has come", resonates today as Quantum Computing, once only a dream of a physicist, stands at the threshold of reality with the potential to revolutionise the world. To comprehend the surge of attention it commands today, one must delve into the motivations that birthed and nurtured Quantum Computing. While the past of Quantum Computing provides insights into the present, the future could unfold through the lens of Quantum Software Engineering. Quantum Software Engineering, guided by its principles and methodologies investigates the most effective ways to interact with Quantum Computers to unlock their true potential and usher in a new era of possibilities. To gain insight into the present landscape and anticipate the trajectory of Quantum Computing and Quantum Software Engineering, this paper embarks on a journey through their evolution and outlines potential directions for future research. By doing so, we aim to equip readers (ideally software engineers and computer scientists not necessarily with quantum expertise) with the insights necessary to navigate the ever-evolving landscape of Quantum Computing and anticipate the trajectories that lie ahead.</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.19428v2</guid>
      <category>quant-ph</category>
      <category>cs.SE</category>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-sa/4.0/</dc:rights>
      <dc:creator>Giuseppe Bisicchia, Jose Garcia-Alonso, Juan M. Murillo, Antonio Brogi</dc:creator>
    </item>
  </channel>
</rss>
