<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>physics.data-an updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/physics.data-an</link>
    <description>physics.data-an updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/physics.data-an" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Wed, 10 Sep 2025 01:34:06 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Tue, 09 Sep 2025 00:00:00 -0400</pubDate>
    <skipDays>
      <day>Sunday</day>
      <day>Saturday</day>
    </skipDays>
    <item>
      <title>TPCpp-10M: Simulated proton-proton collisions in a Time Projection Chamber for AI Foundation Models</title>
      <link>https://arxiv.org/abs/2509.05792</link>
      <description>arXiv:2509.05792v1 Announce Type: new 
Abstract: Scientific foundation models hold great promise for advancing nuclear and particle physics by improving analysis precision and accelerating discovery. Yet, progress in this field is often limited by the lack of openly available large scale datasets, as well as standardized evaluation tasks and metrics. Furthermore, the specialized knowledge and software typically required to process particle physics data pose significant barriers to interdisciplinary collaboration with the broader machine learning community.
  This work introduces a large, openly accessible dataset of 10 million simulated proton-proton collisions, designed to support self-supervised training of foundation models. To facilitate ease of use, the dataset is provided in a common NumPy format. In addition, it includes 70,000 labeled examples spanning three well defined downstream tasks: track finding, particle identification, and noise tagging, to enable systematic evaluation of the foundation model's adaptability.
  The simulated data are generated using the Pythia Monte Carlo event generator at a center of mass energy of sqrt(s) = 200 GeV and processed with Geant4 to include realistic detector conditions and signal emulation in the sPHENIX Time Projection Chamber at the Relativistic Heavy Ion Collider, located at Brookhaven National Laboratory.
  This dataset resource establishes a common ground for interdisciplinary research, enabling machine learning scientists and physicists alike to explore scaling behaviors, assess transferability, and accelerate progress toward foundation models in nuclear and high energy physics. The complete simulation and reconstruction chain is reproducible with the sPHENIX software stack. All data and code locations are provided under Data Accessibility.</description>
      <guid isPermaLink="false">oai:arXiv.org:2509.05792v1</guid>
      <category>physics.data-an</category>
      <pubDate>Tue, 09 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Shuhang Li, Yi Huang, David Park, Xihaier Luo, Haiwang Yu, Yeonju Go, Christopher Pinkenburg, Yuewei Lin, Shinjae Yoo, Joseph Osborn, Christof Roland, Jin Huang, Yihui Ren</dc:creator>
    </item>
    <item>
      <title>Nonnegative matrix factorization and the principle of the common cause</title>
      <link>https://arxiv.org/abs/2509.03652</link>
      <description>arXiv:2509.03652v1 Announce Type: cross 
Abstract: Nonnegative matrix factorization (NMF) is a known unsupervised data-reduction method. The principle of the common cause (PCC) is a basic methodological approach in probabilistic causality, which seeks an independent mixture model for the joint probability of two dependent random variables. It turns out that these two concepts are closely related. This relationship is explored reciprocally for several datasets of gray-scale images, which are conveniently mapped into probability models. On one hand, PCC provides a predictability tool that leads to a robust estimation of the effective rank of NMF. Unlike other estimates (e.g., those based on the Bayesian Information Criteria), our estimate of the rank is stable against weak noise. We show that NMF implemented around this rank produces features (basis images) that are also stable against noise and against seeds of local optimization, thereby effectively resolving the NMF nonidentifiability problem. On the other hand, NMF provides an interesting possibility of implementing PCC in an approximate way, where larger and positively correlated joint probabilities tend to be explained better via the independent mixture model. We work out a clustering method, where data points with the same common cause are grouped into the same cluster. We also show how NMF can be employed for data denoising.</description>
      <guid isPermaLink="false">oai:arXiv.org:2509.03652v1</guid>
      <category>cs.LG</category>
      <category>cs.AI</category>
      <category>physics.data-an</category>
      <category>stat.ML</category>
      <pubDate>Tue, 09 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>E. Khalafyan, A. E. Allahverdyan, A. Hovhannisyan</dc:creator>
    </item>
    <item>
      <title>Cryo-EM as a Stochastic Inverse Problem</title>
      <link>https://arxiv.org/abs/2509.05541</link>
      <description>arXiv:2509.05541v1 Announce Type: cross 
Abstract: Cryo-electron microscopy (Cryo-EM) enables high-resolution imaging of biomolecules, but structural heterogeneity remains a major challenge in 3D reconstruction. Traditional methods assume a discrete set of conformations, limiting their ability to recover continuous structural variability. In this work, we formulate cryo-EM reconstruction as a stochastic inverse problem (SIP) over probability measures, where the observed images are modeled as the push-forward of an unknown distribution over molecular structures via a random forward operator. We pose the reconstruction problem as the minimization of a variational discrepancy between observed and simulated image distributions, using statistical distances such as the KL divergence and the Maximum Mean Discrepancy. The resulting optimization is performed over the space of probability measures via a Wasserstein gradient flow, which we numerically solve using particles to represent and evolve conformational ensembles. We validate our approach using synthetic examples, including a realistic protein model, which demonstrates its ability to recover continuous distributions over structural states. We analyze the connection between our formulation and Maximum A Posteriori (MAP) approaches, which can be interpreted as instances of the discretize-then-optimize (DTO) framework. We further provide a consistency analysis, establishing conditions under which DTO methods, such as MAP estimation, converge to the solution of the underlying infinite-dimensional continuous problem. Beyond cryo-EM, the framework provides a general methodology for solving SIPs involving random forward operators.</description>
      <guid isPermaLink="false">oai:arXiv.org:2509.05541v1</guid>
      <category>stat.ML</category>
      <category>cs.LG</category>
      <category>cs.NA</category>
      <category>math.NA</category>
      <category>math.OC</category>
      <category>physics.data-an</category>
      <pubDate>Tue, 09 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <dc:creator>Diego Sanchez Espinosa, Erik H Thiede, Yunan Yang</dc:creator>
    </item>
    <item>
      <title>Recursive Hierarchical Networks and the Law of Functional Evolution: A Universal Framework for Complex Systems</title>
      <link>https://arxiv.org/abs/2509.05567</link>
      <description>arXiv:2509.05567v1 Announce Type: cross 
Abstract: Understanding and predicting the evolution of across complex systems remains a fundamental challenge due to the absence of unified and computationally testable frameworks. Here we propose the Recursive Hierarchical Network(RHN), conceptualizing evolution as recursive encapsulation along a trajectory of node $\to$ module $\to$ system $\to$ new node, governed by gradual accumulation and abrupt transition. Theoretically, we formalize and prove the law of functional evolution, revealing an irreversible progression from structure-dominated to regulation-dominated to intelligence-dominated stages. Empirically, we operationalize functional levels and align life, cosmic, informational, and social systems onto this scale. The resulting trajectories are strictly monotonic and exhibit strong cross-system similarity, with high pairwise cosine similarities and robust stage resonance. We locate current system states and project future transitions. RHN provides a mathematically rigorous, multi-scale framework for reconstructing and predicting system evolution, offering theoretical guidance for designing next-generation intelligent systems.</description>
      <guid isPermaLink="false">oai:arXiv.org:2509.05567v1</guid>
      <category>physics.soc-ph</category>
      <category>cs.SI</category>
      <category>nlin.AO</category>
      <category>physics.data-an</category>
      <pubDate>Tue, 09 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Hui Li, Yanxin Li</dc:creator>
    </item>
    <item>
      <title>Variational Garrote for Statistical Physics-based Sparse and Robust Variable Selection</title>
      <link>https://arxiv.org/abs/2509.06383</link>
      <description>arXiv:2509.06383v1 Announce Type: cross 
Abstract: Selecting key variables from high-dimensional data is increasingly important in the era of big data. Sparse regression serves as a powerful tool for this purpose by promoting model simplicity and explainability. In this work, we revisit a valuable yet underutilized method, the statistical physics-based Variational Garrote (VG), which introduces explicit feature selection spin variables and leverages variational inference to derive a tractable loss function. We enhance VG by incorporating modern automatic differentiation techniques, enabling scalable and efficient optimization. We evaluate VG on both fully controllable synthetic datasets and complex real-world datasets. Our results demonstrate that VG performs especially well in highly sparse regimes, offering more consistent and robust variable selection than Ridge and LASSO regression across varying levels of sparsity. We also uncover a sharp transition: as superfluous variables are admitted, generalization degrades abruptly and the uncertainty of the selection variables increases. This transition point provides a practical signal for estimating the correct number of relevant variables, an insight we successfully apply to identify key predictors in real-world data. We expect that VG offers strong potential for sparse modeling across a wide range of applications, including compressed sensing and model pruning in machine learning.</description>
      <guid isPermaLink="false">oai:arXiv.org:2509.06383v1</guid>
      <category>cs.LG</category>
      <category>physics.data-an</category>
      <pubDate>Tue, 09 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Hyungjoon Soh, Dongha Lee, Vipul Periwal, Junghyo Jo</dc:creator>
    </item>
    <item>
      <title>Learning to detect continuous gravitational waves: an open data-analysis competition</title>
      <link>https://arxiv.org/abs/2509.06445</link>
      <description>arXiv:2509.06445v1 Announce Type: cross 
Abstract: We report results of a public data-analysis challenge, hosted on the open data-science platform Kaggle, to detect simulated continuous gravitational-wave signals. These are weak signals from rapidly spinning neutron stars that remain undetected despite extensive searches. The competition dataset consisted of a population of CW signals using both simulated and real LIGO detector data matching the conditions of actual CW searches. The competition attracted more than 1,000 participants to develop realistic CW search algorithms. We describe the top 10 approaches and discuss their applicability as a pre-processing step compared to standard CW-search approaches. For the competition's dataset, we find that top approaches can reduce the computing cost by 1 to 3 orders of magnitude at a 2% dismissal probability. Additionally, the competition drove the development of new GPU-accelerated detection pipelines and extended CW-inspired statistics to other domains. We release the associated dataset, which constitutes the first open standardized benchmark for CW detection, to enable reproducible method comparisons and to encourage further developments toward the first detection of these elusive signals.</description>
      <guid isPermaLink="false">oai:arXiv.org:2509.06445v1</guid>
      <category>gr-qc</category>
      <category>astro-ph.HE</category>
      <category>astro-ph.IM</category>
      <category>physics.data-an</category>
      <category>physics.soc-ph</category>
      <pubDate>Tue, 09 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Rodrigo Tenorio, Michael J. Williams, Joseph Bayley, Christopher Messenger, Maggie Demkin, Walter Reade, Kaggle Competitors</dc:creator>
    </item>
    <item>
      <title>Real-Time Analysis of Unstructured Data with Machine Learning on Heterogeneous Architectures</title>
      <link>https://arxiv.org/abs/2508.07423</link>
      <description>arXiv:2508.07423v3 Announce Type: replace 
Abstract: As the particle physics community needs higher and higher precisions in order to test our current model of the subatomic world, larger and larger datasets are necessary. With upgrades scheduled for the detectors of colliding-beam experiments around the world, and specifically at the Large Hadron Collider at CERN, more collisions and more complex interactions are expected. This directly implies an increase in data produced and consequently in the computational resources needed to process them. At CERN, the amount of data produced is gargantuan. This is why the data have to be heavily filtered and selected in real time before being permanently stored. This data can then be used to perform physics analyses, in order to expand our current understanding of the universe and improve the Standard Model of physics. This real-time filtering, known as triggering, involves complex processing happening often at frequencies as high as 40 MHz. This thesis contributes to understanding how machine learning models can be efficiently deployed in such environments, in order to maximize throughput and minimize energy consumption. Inevitably, modern hardware designed for such tasks and contemporary algorithms are needed in order to meet the challenges posed by the stringent, high-frequency data rates. In this work, I present our graph neural network-based pipeline, developed for charged particle track reconstruction at the LHCb experiment at CERN. The pipeline was implemented end-to-end inside LHCb's first-level trigger, entirely on GPUs. Its performance was compared against the classical tracking algorithms currently in production at LHCb. The pipeline was also accelerated on the FPGA architecture, and its performance in terms of power consumption and processing speed was compared against the GPU implementation.</description>
      <guid isPermaLink="false">oai:arXiv.org:2508.07423v3</guid>
      <category>physics.data-an</category>
      <category>cs.AI</category>
      <category>cs.DC</category>
      <category>cs.LG</category>
      <category>hep-ex</category>
      <pubDate>Tue, 09 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Fotis I. Giasemis</dc:creator>
    </item>
    <item>
      <title>Universal emergence of local Zipf's law</title>
      <link>https://arxiv.org/abs/2407.15946</link>
      <description>arXiv:2407.15946v3 Announce Type: replace-cross 
Abstract: A plethora of natural and socio-economic phenomena share a striking statistical regularity, that is the magnitude of elements decreases with a power law as a function of their position in a ranking of magnitude. Such regularity is known as Zipf-Mandelbrot law (ZM), and plenty of problem-specific explanations for its emergence have been provided in different fields. Yet, an explanation for ZM ubiquity is currently lacking. In this paper we first provide an analytical expression for the cumulants of any ranked sample of i.i.d. random variables once sorted in decreasing order. Then we make use of this result to rigorously demonstrate that, whenever a small fraction of such ranked dataset is considered, it becomes statistically indistinguishable from a ZM law. We finally validate our results against several relevant examples.</description>
      <guid isPermaLink="false">oai:arXiv.org:2407.15946v3</guid>
      <category>physics.soc-ph</category>
      <category>physics.data-an</category>
      <pubDate>Tue, 09 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Davide Cugini, Andr\'e Timpanaro, Giacomo Livan, Giacomo Guarnieri</dc:creator>
    </item>
    <item>
      <title>FAIR Universe HiggsML Uncertainty Challenge Competition</title>
      <link>https://arxiv.org/abs/2410.02867</link>
      <description>arXiv:2410.02867v3 Announce Type: replace-cross 
Abstract: The FAIR Universe -- HiggsML Uncertainty Challenge focuses on measuring the physics properties of elementary particles with imperfect simulators due to differences in modelling systematic errors. Additionally, the challenge is leveraging a large-compute-scale AI platform for sharing datasets, training models, and hosting machine learning competitions. Our challenge brings together the physics and machine learning communities to advance our understanding and methodologies in handling systematic (epistemic) uncertainties within AI techniques.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.02867v3</guid>
      <category>hep-ph</category>
      <category>cs.LG</category>
      <category>hep-ex</category>
      <category>physics.data-an</category>
      <pubDate>Tue, 09 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Wahid Bhimji, Paolo Calafiura, Ragansu Chakkappai, Po-Wen Chang, Yuan-Tang Chou, Sascha Diefenbacher, Jordan Dudley, Steven Farrell, Aishik Ghosh, Isabelle Guyon, Chris Harris, Shih-Chieh Hsu, Elham E Khoda, R\'emy Lyscar, Alexandre Michon, Benjamin Nachman, Peter Nugent, Mathis Reymond, David Rousseau, Benjamin Sluijter, Benjamin Thorne, Ihsan Ullah, Yulei Zhang</dc:creator>
    </item>
    <item>
      <title>Diffusion with stochastic resetting on a lattice</title>
      <link>https://arxiv.org/abs/2505.19903</link>
      <description>arXiv:2505.19903v2 Announce Type: replace-cross 
Abstract: We provide an exact formula for the mean first-passage time (MFPT) to a target at the origin for a single particle diffusing on a $d$-dimensional hypercubic {\em lattice} starting from a fixed initial position $\vec R_0$ and resetting to $\vec R_0$ with a rate $r$. Previously known results in the continuous space are recovered in the scaling limit $r\to 0$, $R_0=|\vec R_0|\to \infty$ with the product $\sqrt{r}\, R_0$ fixed. However, our formula is valid for any $r$ and any $\vec R_0$ that enables us to explore a much wider region of the parameter space that is inaccessible in the continuum limit. For example, we have shown that the MFPT, as a function of $r$ for fixed $\vec R_0$, diverges in the two opposite limits $r\to 0$ and $r\to \infty$ with a unique minimum in between, provided the starting point is not a nearest neighbour of the target. In this case, the MFPT diverges as a power law $\sim r^{\phi}$ as $r\to \infty$, but very interestingly with an exponent $\phi= (|m_1|+|m_2|+\ldots +|m_d|)-1$ that depends on the starting point $\vec R_0= a\, (m_1,m_2,\ldots, m_d)$ where $a$ is the lattice spacing and $m_i$'s are integers. If, on the other hand, the starting point happens to be a nearest neighbour of the target, then the MFPT decreases monotonically with increasing $r$, approaching a universal limiting value $1$ as $r\to \infty$, indicating that the optimal resetting rate in this case is infinity. We provide a simple physical reason and a simple Markov-chain explanation behind this somewhat unexpected universal result. Our analytical predictions are verified in numerical simulations on lattices up to $50$ dimensions. Finally, in the absence of a target, we also compute exactly the position distribution of the walker in the nonequlibrium stationary state that also displays interesting lattice effects not captured by the continuum theory.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.19903v2</guid>
      <category>cond-mat.stat-mech</category>
      <category>physics.data-an</category>
      <pubDate>Tue, 09 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <arxiv:DOI>10.1103/1xkk-7q63</arxiv:DOI>
      <arxiv:journal_reference>Phys. Rev. E 112, 034102 (2025)</arxiv:journal_reference>
      <dc:creator>Alexander K. Hartmann, Satya N. Majumdar</dc:creator>
    </item>
  </channel>
</rss>
