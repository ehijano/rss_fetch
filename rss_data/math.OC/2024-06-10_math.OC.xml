<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>math.OC updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/math.OC</link>
    <description>math.OC updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/math.OC" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Mon, 10 Jun 2024 04:00:11 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Mon, 10 Jun 2024 00:00:00 -0400</pubDate>
    <skipDays>
      <day>Sunday</day>
      <day>Saturday</day>
    </skipDays>
    <item>
      <title>An Enhanced Approach for the Dial a ride problem with drivers preferences</title>
      <link>https://arxiv.org/abs/2406.04506</link>
      <description>arXiv:2406.04506v1 Announce Type: new 
Abstract: The paper addresses a variant of the Dial-A-Ride problem with additional features. It is referred to as the DARP with driver preferences, which attempts to determine a solution more driver-oriented by designing a short trip in a specific direction that has to be finished at a destination of interest within a restricted time window. For this purpose, two solutions are considered. The first involves solving the new MILP exactly using the CPLEX software. The second is a new approach that employs an iterated local search as a general framework and exploits many heuristics. Numerical experiments indicate that the approach can efficiently solve the generated DARPDP instances in a reasonable time.</description>
      <guid isPermaLink="false">oai:arXiv.org:2406.04506v1</guid>
      <category>math.OC</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Sana Ouasaid, Mohammed Saddoune</dc:creator>
    </item>
    <item>
      <title>A majorized PAM method with subspace correction for low-rank composite factorization model</title>
      <link>https://arxiv.org/abs/2406.04588</link>
      <description>arXiv:2406.04588v1 Announce Type: new 
Abstract: This paper concerns a class of low-rank composite factorization models arising from matrix completion. For this nonconvex and nonsmooth optimization problem, we propose a proximal alternating minimization algorithm (PAMA) with subspace correction, in which a subspace correction step is imposed on every proximal subproblem so as to guarantee that the corrected proximal subproblem has a closed-form solution. For this subspace correction PAMA, we prove the subsequence convergence of the iterate sequence, and establish the convergence of the whole iterate sequence and the column subspace sequences of factor pairs under the KL property of objective function and a restrictive condition that holds automatically for the column $\ell_{2,0}$-norm function. Numerical comparison with the proximal alternating linearized minimization method on one-bit matrix completion problems indicates that PAMA has an advantage in seeking lower relative error within less time.</description>
      <guid isPermaLink="false">oai:arXiv.org:2406.04588v1</guid>
      <category>math.OC</category>
      <category>stat.ML</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Ting Tao, Yitian Qian, Shaohua Pan</dc:creator>
    </item>
    <item>
      <title>Convergence Analysis of Adaptive Gradient Methods under Refined Smoothness and Noise Assumptions</title>
      <link>https://arxiv.org/abs/2406.04592</link>
      <description>arXiv:2406.04592v1 Announce Type: new 
Abstract: Adaptive gradient methods are arguably the most successful optimization algorithms for neural network training. While it is well-known that adaptive gradient methods can achieve better dimensional dependence than stochastic gradient descent (SGD) under favorable geometry for stochastic convex optimization, the theoretical justification for their success in stochastic non-convex optimization remains elusive. In this paper, we aim to close this gap by analyzing the convergence rates of AdaGrad measured by the $\ell_1$-norm of the gradient. Specifically, when the objective has $L$-Lipschitz gradient and the stochastic gradient variance is bounded by $\sigma^2$, we prove a worst-case convergence rate of $\tilde{\mathcal{O}}(\frac{\sqrt{d}L}{\sqrt{T}} + \frac{\sqrt{d} \sigma}{T^{1/4}})$, where $d$ is the dimension of the problem.We also present a lower bound of ${\Omega}(\frac{\sqrt{d}}{\sqrt{T}})$ for minimizing the gradient $\ell_1$-norm in the deterministic setting, showing the tightness of our upper bound in the noiseless case. Moreover, under more fine-grained assumptions on the smoothness structure of the objective and the gradient noise and under favorable gradient $\ell_1/\ell_2$ geometry, we show that AdaGrad can potentially shave a factor of $\sqrt{d}$ compared to SGD. To the best of our knowledge, this is the first result for adaptive gradient methods that demonstrates a provable gain over SGD in the non-convex setting.</description>
      <guid isPermaLink="false">oai:arXiv.org:2406.04592v1</guid>
      <category>math.OC</category>
      <category>cs.LG</category>
      <category>stat.ML</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Devyani Maladkar, Ruichen Jiang, Aryan Mokhtari</dc:creator>
    </item>
    <item>
      <title>Mean-field stochastic linear quadratic control problem with random coefficients</title>
      <link>https://arxiv.org/abs/2406.04621</link>
      <description>arXiv:2406.04621v1 Announce Type: new 
Abstract: In this paper, we first prove that the mean-field stochastic linear quadratic (MFSLQ) control problem with random coefficients has a unique optimal control and derive a preliminary stochastic maximum principle to characterize this optimal control by an optimality system. However, because of the term of the form $\mathbb{E}[A(\cdot)X(\cdot)] $ in the adjoint equation, which cannot be represented in the form $\mathbb{E}[A(\cdot)]\mathbb{E} [X(\cdot)] $, we cannot solve this optimality system explicitly. To this end, we decompose the MFSLQ control problem into two constrained SLQ control problems without the mean-field terms. These constrained SLQ control problems can be solved explicitly by an extended LaGrange multiplier method developed in this article.</description>
      <guid isPermaLink="false">oai:arXiv.org:2406.04621v1</guid>
      <category>math.OC</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Jie Xiong, Wen Xu</dc:creator>
    </item>
    <item>
      <title>An Inexact Bregman Proximal Difference-of-Convex Algorithm with Two Types of Relative Stopping Criteria</title>
      <link>https://arxiv.org/abs/2406.04646</link>
      <description>arXiv:2406.04646v1 Announce Type: new 
Abstract: In this paper, we consider a class of difference-of-convex (DC) optimization problems, where the global Lipschitz gradient continuity assumption on the smooth part of the objective function is not required. Such problems are prevalent in many contemporary applications such as compressed sensing, statistical regression, and machine learning, and can be solved by a general Bregman proximal DC algorithm (BPDCA). However, the existing BPDCA is developed based on the stringent requirement that the involved subproblems must be solved exactly, which is often impractical and limits the applicability of the BPDCA. To facilitate the practical implementations and wider applications of the BPDCA, we develop an inexact Bregman proximal difference-of-convex algorithm (iBPDCA) by incorporating two types of relative-type stopping criteria for solving the subproblems. The proposed inexact framework has considerable flexibility to encompass many existing exact and inexact methods, and can accommodate different types of errors that may occur when solving the subproblem. This enables the potential application of our inexact framework across different DC decompositions to facilitate the design of a more efficient DCA scheme in practice. The global subsequential convergence and the global sequential convergence of our iBPDCA are established under suitable conditions including the Kurdyka-{\L}ojasiewicz property. Some numerical experiments on the $\ell_{1-2}$ regularized least squares problem and the constrained $\ell_{1-2}$ sparse optimization problem are conducted to show the superior performance of our iBPDCA in comparison to existing algorithms. These results also empirically verify the necessity of developing different types of stopping criteria to facilitate the efficient computation of the subproblem in each iteration of our iBPDCA.</description>
      <guid isPermaLink="false">oai:arXiv.org:2406.04646v1</guid>
      <category>math.OC</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Lei Yang, Jingjing Hu, Kim-Chuan Toh</dc:creator>
    </item>
    <item>
      <title>Monotone Lipschitz-Gradient Denoiser: Explainability of Operator Regularization Approaches and Convergence to Optimal Point</title>
      <link>https://arxiv.org/abs/2406.04676</link>
      <description>arXiv:2406.04676v1 Announce Type: new 
Abstract: This paper addresses explainability of the operator-regularization approach under the use of monotone Lipschitz-gradient (MoL-Grad) denoiser -- an operator that can be expressed as the Lipschitz continuous gradient of a differentiable convex function. We prove that an operator is a MoL-Grad denoiser if and only if it is the ``single-valued'' proximity operator of a weakly convex function. An extension of Moreau's decomposition is also shown with respect to a weakly convex function and the conjugate of its convexified function. Under these arguments, two specific algorithms, the forward-backward splitting algorithm and the primal-dual splitting algorithm, are considered, both employing MoL-Grad denoisers. These algorithms generate a sequence of vectors converging weakly, under conditions, to a minimizer of a certain cost function which involves an ``implicit regularizer'' induced by the denoiser. The theoretical findings are supported by simulations.</description>
      <guid isPermaLink="false">oai:arXiv.org:2406.04676v1</guid>
      <category>math.OC</category>
      <category>eess.SP</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <dc:creator>Masahiro Yukawa, Isao Yamada</dc:creator>
    </item>
    <item>
      <title>Whitney Stratification of Algebraic Boundaries of Convex Semi-algebraic Sets</title>
      <link>https://arxiv.org/abs/2406.04681</link>
      <description>arXiv:2406.04681v1 Announce Type: new 
Abstract: Algebraic boundaries of convex semi-algebraic sets are closely related to polynomial optimization problems. Building upon Rainer Sinn's work, we refine the stratification of iterated singular loci to a Whitney (a) stratification, which gives a list of candidates of varieties whose dual is an irreducible component of the algebraic boundary of the dual convex body. We also present an algorithm based on Teissier's criterion to compute Whitney (a) stratifications, which employs conormal spaces and prime decomposition.</description>
      <guid isPermaLink="false">oai:arXiv.org:2406.04681v1</guid>
      <category>math.OC</category>
      <category>cs.SC</category>
      <category>math.AG</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <arxiv:DOI>10.1145/3666000.3669702</arxiv:DOI>
      <dc:creator>Zihao Dai, Zijia Li, Zhi-Hong Yang, Lihong Zhi</dc:creator>
    </item>
    <item>
      <title>Nonlinear Optimal Guidance with Constraints on Impact Time and Impact Angle</title>
      <link>https://arxiv.org/abs/2406.04707</link>
      <description>arXiv:2406.04707v1 Announce Type: new 
Abstract: This paper aims to address the nonlinear optimal guidance problem with impact-time and impact-angle constraints, which is fundamentally important for multiple pursuers to collaboratively achieve a target. Addressing such a guidance problem is equivalent to solving a nonlinear minimum-effort control problem in real time. To this end, the Pontryagain's maximum principle is employed to convert extremal trajectories as the solutions of a parameterized differential system. The geometric property for the solution of the parameterized system is analyzed, leading to an additional optimality condition. By incorporating this optimality condition and the usual disconjugacy condition into the parameterized system, the dataset for optimal trajectories can be generated by propagating the parameterized system without using any optimization methods. In addition, a scaling invariance property is found for the solutions of the parameterized system. As a consequence of this scaling invariance property, a simple feedforward neural network trained by the solution of the parameterized system, selected at any fixed time, can be used to generate the nonlinear optimal guidance within milliseconds. Finally, numerical examples are presented, showing that the nonlinear optimal guidance command generated by the trained network can not only ensure the expected impact angle and impact time are precisely met but also requires less control effort compared with existing guidance methods.</description>
      <guid isPermaLink="false">oai:arXiv.org:2406.04707v1</guid>
      <category>math.OC</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Fanchen Wu (School of Aeronautics and Astronautics, Zhejiang University, Hangzhou, China), Zheng Chen (School of Aeronautics and Astronautics, Zhejiang University, Hangzhou, China, State Key Laboratory of Fluid Power Mechatronic Systems, Hangzhou, China), Xueming Shao (School of Aeronautics and Astronautics, Zhejiang University, Hangzhou, China, State Key Laboratory of Fluid Power Mechatronic Systems, Hangzhou, China), Kun Wang (School of Aeronautics and Astronautics, Zhejiang University, Hangzhou, China)</dc:creator>
    </item>
    <item>
      <title>Efficient Continual Finite-Sum Minimization</title>
      <link>https://arxiv.org/abs/2406.04731</link>
      <description>arXiv:2406.04731v1 Announce Type: new 
Abstract: Given a sequence of functions $f_1,\ldots,f_n$ with $f_i:\mathcal{D}\mapsto \mathbb{R}$, finite-sum minimization seeks a point ${x}^\star \in \mathcal{D}$ minimizing $\sum_{j=1}^n f_j(x)/n$. In this work, we propose a key twist into the finite-sum minimization, dubbed as continual finite-sum minimization, that asks for a sequence of points ${x}_1^\star,\ldots,{x}_n^\star \in \mathcal{D}$ such that each ${x}^\star_i \in \mathcal{D}$ minimizes the prefix-sum $\sum_{j=1}^if_j(x)/i$. Assuming that each prefix-sum is strongly convex, we develop a first-order continual stochastic variance reduction gradient method ($\mathrm{CSVRG}$) producing an $\epsilon$-optimal sequence with $\mathcal{\tilde{O}}(n/\epsilon^{1/3} + 1/\sqrt{\epsilon})$ overall first-order oracles (FO). An FO corresponds to the computation of a single gradient $\nabla f_j(x)$ at a given $x \in \mathcal{D}$ for some $j \in [n]$. Our approach significantly improves upon the $\mathcal{O}(n/\epsilon)$ FOs that $\mathrm{StochasticGradientDescent}$ requires and the $\mathcal{O}(n^2 \log (1/\epsilon))$ FOs that state-of-the-art variance reduction methods such as $\mathrm{Katyusha}$ require. We also prove that there is no natural first-order method with $\mathcal{O}\left(n/\epsilon^\alpha\right)$ gradient complexity for $\alpha &lt; 1/4$, establishing that the first-order complexity of our method is nearly tight.</description>
      <guid isPermaLink="false">oai:arXiv.org:2406.04731v1</guid>
      <category>math.OC</category>
      <category>cs.LG</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Ioannis Mavrothalassitis, Stratis Skoulakis, Leello Tadesse Dadi, Volkan Cevher</dc:creator>
    </item>
    <item>
      <title>Asymptotically Optimal Policies for Weakly Coupled Markov Decision Processes</title>
      <link>https://arxiv.org/abs/2406.04751</link>
      <description>arXiv:2406.04751v1 Announce Type: new 
Abstract: We consider the problem of maximizing the expected average reward obtained over an infinite time horizon by $n$ weakly coupled Markov decision processes. Our setup is a substantial generalization of the multi-armed restless bandit problem that allows for multiple actions and constraints. We establish a connection with a deterministic and continuous-variable control problem where the objective is to maximize the average reward derived from an occupancy measure that represents the empirical distribution of the processes when $n \to \infty$. We show that a solution of this fluid problem can be used to construct policies for the weakly coupled processes that achieve the maximum expected average reward as $n \to \infty$, and we give sufficient conditions for the existence of solutions. Under certain assumptions on the constraints, we prove that these conditions are automatically satisfied if the unconstrained single-process problem admits a suitable unichain and aperiodic policy. In particular, the assumptions include multi-armed restless bandits and a broad class of problems with multiple actions and inequality constraints. Also, the policies can be constructed in an explicit way in these cases. Our theoretical results are complemented by several concrete examples and numerical experiments, which include multichain setups that are covered by the theoretical results.</description>
      <guid isPermaLink="false">oai:arXiv.org:2406.04751v1</guid>
      <category>math.OC</category>
      <category>math.PR</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Diego Goldsztajn, Konstantin Avrachenkov</dc:creator>
    </item>
    <item>
      <title>Ensuring Grid-Safe Forwarding of Distributed Flexibility in Sequential DSO-TSO Markets</title>
      <link>https://arxiv.org/abs/2406.04889</link>
      <description>arXiv:2406.04889v1 Announce Type: new 
Abstract: This paper investigates sequential flexibility markets consisting of a first market layer for distribution system operators (DSOs) to procure local flexibility to resolve their own needs (e.g., congestion management) followed by a second layer, in which the transmission system operator (TSO) procures remaining flexibility forwarded from the distribution system layer as well as flexibility from its own system for providing system services. As the TSO does not necessarily have full knowledge of the distribution grid constraints, this bid forwarding can cause an infeasibility problem for distribution systems, i.e., cleared distribution-level bids in the TSO layer might not satisfy local network constraints. To address this challenge, we introduce and examine three methods aiming to enable the grid-safe use of distribution-located resources in markets for system services, namely: a corrective three-layer market scheme, a bid prequalification/filtering method, and a bid aggregation method. Technically, we provide conditions under which these methods can produce a grid-safe use of distributed flexibility. We also characterize the efficiency of the market outcome under these methods. Finally, we carry out a representative case study to evaluate the performances of the three methods, focusing on economic efficiency, grid-safety, and computational load.</description>
      <guid isPermaLink="false">oai:arXiv.org:2406.04889v1</guid>
      <category>math.OC</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Wicak Ananduta, Anibal Sanjab, Luciana Marques</dc:creator>
    </item>
    <item>
      <title>Column generation for multistage stochastic mixed-integer nonlinear programs with discrete state variables</title>
      <link>https://arxiv.org/abs/2406.05052</link>
      <description>arXiv:2406.05052v1 Announce Type: new 
Abstract: Stochastic programming provides a natural framework for modeling sequential optimization problems under uncertainty; however, the efficient solution of large-scale multistage stochastic programs remains a challenge, especially in the presence of discrete decisions and nonlinearities. In this work, we consider multistage stochastic mixed-integer nonlinear programs (MINLPs) with discrete state variables, which exhibit a decomposable structure that allows its solution using a column generation approach. Following a Dantzig-Wolfe reformulation, we apply column generation such that each pricing subproblem is an MINLP of much smaller size, making it more amenable to global MINLP solvers. We further propose a method for generating additional columns that satisfy the nonanticipativity constraints, leading to significantly improved convergence and optimal or near-optimal solutions for many large-scale instances in a reasonable computation time. The effectiveness of the tailored column generation algorithm is demonstrated via computational case studies on a multistage blending problem and a problem involving the routing of mobile generators in a power distribution network.</description>
      <guid isPermaLink="false">oai:arXiv.org:2406.05052v1</guid>
      <category>math.OC</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Tushar Rathi, Benjamin P. Riley, Angela Flores-Quiroz, Qi Zhang</dc:creator>
    </item>
    <item>
      <title>Robust Reward Design for Markov Decision Processes</title>
      <link>https://arxiv.org/abs/2406.05086</link>
      <description>arXiv:2406.05086v1 Announce Type: new 
Abstract: The problem of reward design examines the interaction between a leader and a follower, where the leader aims to shape the follower's behavior to maximize the leader's payoff by modifying the follower's reward function. Current approaches to reward design rely on an accurate model of how the follower responds to reward modifications, which can be sensitive to modeling inaccuracies. To address this issue of sensitivity, we present a solution that offers robustness against uncertainties in modeling the follower, including 1) how the follower breaks ties in the presence of nonunique best responses, 2) inexact knowledge of how the follower perceives reward modifications, and 3) bounded rationality of the follower. Our robust solution is guaranteed to exist under mild conditions and can be obtained numerically by solving a mixed-integer linear program. Numerical experiments on multiple test cases demonstrate that our solution improves robustness compared to the standard approach without incurring significant additional computing costs.</description>
      <guid isPermaLink="false">oai:arXiv.org:2406.05086v1</guid>
      <category>math.OC</category>
      <category>cs.AI</category>
      <category>cs.GT</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Shuo Wu, Haoxiang Ma, Jie Fu, Shuo Han</dc:creator>
    </item>
    <item>
      <title>On Regularization via Early Stopping for Least Squares Regression</title>
      <link>https://arxiv.org/abs/2406.04425</link>
      <description>arXiv:2406.04425v1 Announce Type: cross 
Abstract: A fundamental problem in machine learning is understanding the effect of early stopping on the parameters obtained and the generalization capabilities of the model. Even for linear models, the effect is not fully understood for arbitrary learning rates and data. In this paper, we analyze the dynamics of discrete full batch gradient descent for linear regression. With minimal assumptions, we characterize the trajectory of the parameters and the expected excess risk. Using this characterization, we show that when training with a learning rate schedule $\eta_k$, and a finite time horizon $T$, the early stopped solution $\beta_T$ is equivalent to the minimum norm solution for a generalized ridge regularized problem. We also prove that early stopping is beneficial for generic data with arbitrary spectrum and for a wide variety of learning rate schedules. We provide an estimate for the optimal stopping time and empirically demonstrate the accuracy of our estimate.</description>
      <guid isPermaLink="false">oai:arXiv.org:2406.04425v1</guid>
      <category>cs.LG</category>
      <category>math.OC</category>
      <category>math.ST</category>
      <category>stat.ML</category>
      <category>stat.TH</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Rishi Sonthalia, Jackie Lok, Elizaveta Rebrova</dc:creator>
    </item>
    <item>
      <title>Gradient Clipping Improves AdaGrad when the Noise Is Heavy-Tailed</title>
      <link>https://arxiv.org/abs/2406.04443</link>
      <description>arXiv:2406.04443v1 Announce Type: cross 
Abstract: Methods with adaptive stepsizes, such as AdaGrad and Adam, are essential for training modern Deep Learning models, especially Large Language Models. Typically, the noise in the stochastic gradients is heavy-tailed for the later ones. Gradient clipping provably helps to achieve good high-probability convergence for such noises. However, despite the similarity between AdaGrad/Adam and Clip-SGD, the high-probability convergence of AdaGrad/Adam has not been studied in this case. In this work, we prove that AdaGrad (and its delayed version) can have provably bad high-probability convergence if the noise is heavy-tailed. To fix this issue, we propose a new version of AdaGrad called Clip-RAdaGradD (Clipped Reweighted AdaGrad with Delay) and prove its high-probability convergence bounds with polylogarithmic dependence on the confidence level for smooth convex/non-convex stochastic optimization with heavy-tailed noise. Our empirical evaluations, including NLP model fine-tuning, highlight the superiority of clipped versions of AdaGrad/Adam in handling the heavy-tailed noise.</description>
      <guid isPermaLink="false">oai:arXiv.org:2406.04443v1</guid>
      <category>cs.LG</category>
      <category>math.OC</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Savelii Chezhegov, Yaroslav Klyukin, Andrei Semenov, Aleksandr Beznosikov, Alexander Gasnikov, Samuel Horv\'ath, Martin Tak\'a\v{c}, Eduard Gorbunov</dc:creator>
    </item>
    <item>
      <title>A general framework for floating point error analysis of simplex derivatives</title>
      <link>https://arxiv.org/abs/2406.04530</link>
      <description>arXiv:2406.04530v1 Announce Type: cross 
Abstract: Gradient approximations are a class of numerical approximation techniques that are of central importance in numerical optimization. In derivative-free optimization, most of the gradient approximations, including the simplex gradient, centred simplex gradient, and adapted centred simplex gradient, are in the form of simplex derivatives. Owing to machine precision, the approximation accuracy of any numerical approximation technique is subject to the influence of floating point errors. In this paper, we provide a general framework for floating point error analysis of simplex derivatives. Our framework is independent of the choice of the simplex derivative as long as it satisfies a general form. We review the definition and approximation accuracy of the generalized simplex gradient and generalized centred simplex gradient. We define and analyze the accuracy of a generalized version of the adapted centred simplex gradient. As examples, we apply our framework to the generalized simplex gradient, generalized centred simplex gradient, and generalized adapted centred simplex gradient. Based on the results, we give suggestions on the minimal choice of approximate diameter of the sample set.</description>
      <guid isPermaLink="false">oai:arXiv.org:2406.04530v1</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <category>math.OC</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Yiwen Chen, Warren Hare, Amy Wiebe</dc:creator>
    </item>
    <item>
      <title>On PI Controllers for Updating Lagrange Multipliers in Constrained Optimization</title>
      <link>https://arxiv.org/abs/2406.04558</link>
      <description>arXiv:2406.04558v1 Announce Type: cross 
Abstract: Constrained optimization offers a powerful framework to prescribe desired behaviors in neural network models. Typically, constrained problems are solved via their min-max Lagrangian formulations, which exhibit unstable oscillatory dynamics when optimized using gradient descent-ascent. The adoption of constrained optimization techniques in the machine learning community is currently limited by the lack of reliable, general-purpose update schemes for the Lagrange multipliers. This paper proposes the $\nu$PI algorithm and contributes an optimization perspective on Lagrange multiplier updates based on PI controllers, extending the work of Stooke, Achiam and Abbeel (2020). We provide theoretical and empirical insights explaining the inability of momentum methods to address the shortcomings of gradient descent-ascent, and contrast this with the empirical success of our proposed $\nu$PI controller. Moreover, we prove that $\nu$PI generalizes popular momentum methods for single-objective minimization. Our experiments demonstrate that $\nu$PI reliably stabilizes the multiplier dynamics and its hyperparameters enjoy robust and predictable behavior.</description>
      <guid isPermaLink="false">oai:arXiv.org:2406.04558v1</guid>
      <category>cs.LG</category>
      <category>math.OC</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Motahareh Sohrabi, Juan Ramirez, Tianyue H. Zhang, Simon Lacoste-Julien, Jose Gallego-Posada</dc:creator>
    </item>
    <item>
      <title>Reinforcement Learning and Regret Bounds for Admission Control</title>
      <link>https://arxiv.org/abs/2406.04766</link>
      <description>arXiv:2406.04766v1 Announce Type: cross 
Abstract: The expected regret of any reinforcement learning algorithm is lower bounded by $\Omega\left(\sqrt{DXAT}\right)$ for undiscounted returns, where $D$ is the diameter of the Markov decision process, $X$ the size of the state space, $A$ the size of the action space and $T$ the number of time steps. However, this lower bound is general. A smaller regret can be obtained by taking into account some specific knowledge of the problem structure. In this article, we consider an admission control problem to an $M/M/c/S$ queue with $m$ job classes and class-dependent rewards and holding costs. Queuing systems often have a diameter that is exponential in the buffer size $S$, making the previous lower bound prohibitive for any practical use. We propose an algorithm inspired by UCRL2, and use the structure of the problem to upper bound the expected total regret by $O(S\log T + \sqrt{mT \log T})$ in the finite server case. In the infinite server case, we prove that the dependence of the regret on $S$ disappears.</description>
      <guid isPermaLink="false">oai:arXiv.org:2406.04766v1</guid>
      <category>cs.LG</category>
      <category>math.OC</category>
      <category>stat.ML</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Lucas Weber, Ana Bu\v{s}i\'c, Jiamin Zhu</dc:creator>
    </item>
    <item>
      <title>Primitive Agentic First-Order Optimization</title>
      <link>https://arxiv.org/abs/2406.04841</link>
      <description>arXiv:2406.04841v1 Announce Type: cross 
Abstract: Efficient numerical optimization methods can improve performance and reduce the environmental impact of computing in many applications. This work presents a proof-of-concept study combining primitive state representations and agent-environment interactions as first-order optimizers in the setting of budget-limited optimization. Through reinforcement learning (RL) over a set of training instances of an optimization problem class, optimal policies for sequential update selection of algorithmic iteration steps are approximated in generally formulated low-dimensional partial state representations that consider aspects of progress and resource use. For the investigated case studies, deployment of the trained agents to unseen instances of the quadratic optimization problem classes outperformed conventional optimal algorithms with optimized hyperparameters. The results show that elementary RL methods combined with succinct partial state representations can be used as heuristics to manage complexity in RL-based optimization, paving the way for agentic optimization approaches.</description>
      <guid isPermaLink="false">oai:arXiv.org:2406.04841v1</guid>
      <category>cs.LG</category>
      <category>cs.AI</category>
      <category>cs.SY</category>
      <category>eess.SY</category>
      <category>math.OC</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>R. Sala</dc:creator>
    </item>
    <item>
      <title>Gradient Descent on Logistic Regression with Non-Separable Data and Large Step Sizes</title>
      <link>https://arxiv.org/abs/2406.05033</link>
      <description>arXiv:2406.05033v1 Announce Type: cross 
Abstract: We study gradient descent (GD) dynamics on logistic regression problems with large, constant step sizes. For linearly-separable data, it is known that GD converges to the minimizer with arbitrarily large step sizes, a property which no longer holds when the problem is not separable. In fact, the behaviour can be much more complex -- a sequence of period-doubling bifurcations begins at the critical step size $2/\lambda$, where $\lambda$ is the largest eigenvalue of the Hessian at the solution. Using a smaller-than-critical step size guarantees convergence if initialized nearby the solution: but does this suffice globally? In one dimension, we show that a step size less than $1/\lambda$ suffices for global convergence. However, for all step sizes between $1/\lambda$ and the critical step size $2/\lambda$, one can construct a dataset such that GD converges to a stable cycle. In higher dimensions, this is actually possible even for step sizes less than $1/\lambda$. Our results show that although local convergence is guaranteed for all step sizes less than the critical step size, global convergence is not, and GD may instead converge to a cycle depending on the initialization.</description>
      <guid isPermaLink="false">oai:arXiv.org:2406.05033v1</guid>
      <category>cs.LG</category>
      <category>math.OC</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Si Yi Meng, Antonio Orvieto, Daniel Yiming Cao, Christopher De Sa</dc:creator>
    </item>
    <item>
      <title>New results on biorthogonal families in cylindrical domains and controllability consequences</title>
      <link>https://arxiv.org/abs/2406.05104</link>
      <description>arXiv:2406.05104v1 Announce Type: cross 
Abstract: In this article we consider moment problems equivalent to null controllability of some linear parabolic partial differential equations in space dimension higher than one. For these moment problems, we prove existence of an associated biorthogonal family and estimate its norm. The considered setting requires the space domain to be a cylinder and the evolution operator to be tensorized. Roughly speaking, we assume that the so-called Lebeau-Robbiano spectral inequality holds but only for the eigenvectors of the transverse operator. In the one dimensional tangent variable we assume the solvability of block moment problem as introduced in [Benabdallah, Boyer and Morancey - \textit{Ann. H. Lebesgue.} 3 (2020)]. We apply this abstract construction of biorthogonal families to the characterization of the minimal time for simultaneous null controllability of two heat-like equations in a cylindrical domain. To the best of our knowledge, this result is unattainable with other known techniques.</description>
      <guid isPermaLink="false">oai:arXiv.org:2406.05104v1</guid>
      <category>math.AP</category>
      <category>math.FA</category>
      <category>math.OC</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>F. Ammar Khodja, A. Benabdallah, M. Gonz\'alez-Burgos, M. Morancey, L. de Teresa</dc:creator>
    </item>
    <item>
      <title>An inexact LPA for DC composite optimization and application to matrix completions with outliers</title>
      <link>https://arxiv.org/abs/2303.16822</link>
      <description>arXiv:2303.16822v4 Announce Type: replace 
Abstract: This paper concerns a class of DC composite optimization problems which, as an extension of convex composite optimization problems and DC programs with nonsmooth components, often arises in robust factorization models of low-rank matrix recovery. For this class of nonconvex and nonsmooth problems, we propose an inexact linearized proximal algorithm (iLPA) by computing in each step an inexact minimizer of a strongly convex majorization constructed with a partial linearization of their objective functions at the current iterate, and establish the convergence of the generated iterate sequence under the Kurdyka-\L\"ojasiewicz (KL) property of a potential function. In particular, by leveraging the composite structure, we provide a verifiable condition for the potential function to have the KL property of exponent $1/2$ at the limit point, so for the iterate sequence to have a local R-linear convergence rate. Finally, we apply the proposed iLPA to a robust factorization model for matrix completions with outliers and non-uniform sampling, and numerical comparison with a proximal alternating minimization (PAM) method confirms iLPA yields the comparable relative errors or NMAEs within less running time, especially for large-scale real data.</description>
      <guid isPermaLink="false">oai:arXiv.org:2303.16822v4</guid>
      <category>math.OC</category>
      <category>stat.ML</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Ting Tao, Ruyu Liu, Shaohua Pan</dc:creator>
    </item>
    <item>
      <title>A bilevel approach for compensation and routing decisions in last-mile delivery</title>
      <link>https://arxiv.org/abs/2304.09170</link>
      <description>arXiv:2304.09170v3 Announce Type: replace 
Abstract: In last-mile delivery logistics, peer-to-peer logistic platforms play an important role in connecting senders, customers, and independent carriers to fulfill delivery requests. Since the carriers are not under the platform's control, the platform has to anticipate their reactions, while deciding how to allocate the delivery operations. Indeed, carriers' decisions largely affect the platform's revenue. In this paper, we model this problem using bilevel programming. At the upper level, the platform decides how to assign the orders to the carriers; at the lower level, each carrier solves a profitable tour problem to determine which offered requests to accept, based on her own profit maximization. Possibly, the platform can influence carriers' decisions by determining also the compensation paid for each accepted request. The two considered settings result in two different formulations: the bilevel profitable tour problem with fixed compensation margins and with margin decisions, respectively. For each of them, we propose single-level reformulations and alternative formulations where the lower-level routing variables are projected out. A branch-and-cut algorithm is proposed to solve the bilevel models, with a tailored warm-start heuristic used to speed up the solution process. Extensive computational tests are performed to compare the proposed formulations and analyze solution characteristics.</description>
      <guid isPermaLink="false">oai:arXiv.org:2304.09170v3</guid>
      <category>math.OC</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Martina Cerulli, Claudia Archetti, Elena Fernandez, Ivana Ljubic</dc:creator>
    </item>
    <item>
      <title>On the longest chain of faces of the completely positive and copositive cones</title>
      <link>https://arxiv.org/abs/2305.13640</link>
      <description>arXiv:2305.13640v2 Announce Type: replace 
Abstract: We consider a wide class of closed convex cones $K$ in the space of real $n\times n$ symmetric matrices and establish the existence of a chain of faces of $K$, the length of which is maximized at $\frac{n(n+1)}{2} + 1$. Examples of such cones include, but are not limited to, the completely positive and the copositive cones. Using this chain, we prove that the distance to polyhedrality of any closed convex cone $K$ that is sandwiched between the completely positive cone and the doubly nonnegative cone of order $n \ge 2$, as well as its dual, is at least $\frac{n(n+1)}{2} - 2$, which is also the worst-case scenario.</description>
      <guid isPermaLink="false">oai:arXiv.org:2305.13640v2</guid>
      <category>math.OC</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Mitsuhiro Nishijima</dc:creator>
    </item>
    <item>
      <title>Funnel control -- a survey</title>
      <link>https://arxiv.org/abs/2310.03449</link>
      <description>arXiv:2310.03449v2 Announce Type: replace 
Abstract: The methodology of funnel control was introduced in the early 2000s, and it has developed since then in many respects achieving a level of mathematical maturity balanced by practical applications. Its fundamental tenet is the attainment of prescribed transient and asymptotic behaviour for continuous-time controlled dynamical processes encompassing linear and nonlinear systems described by functional differential equations, differential-algebraic systems, and partial differential equations. Considered are classes of systems specified by structural properties - such as relative degree and stable internal dynamics - of the systems only, the precise systems' data are in general unknown; the latter reflects the property that in general any model of a dynamical process is not precise.
  Prespecified are: a funnel shaped through the choice of a smooth function and freely chosen by the designer, a fairly large class of smooth reference signals, and a system class satisfying certain structural properties. The aim is to design, based on the structural assumptions and the input and output information only, a single `simple' control strategy -- called the funnel controller -- so that its application to any system of the given class and to any reference signal results in feasibility of the funnel control objective: that is solutions of the closed-loop system do not exhibit blow-up in finite time, all variables are bounded, and -- most importantly -- the evolution of the error between the system's output and the reference signal remains within the prespecified funnel.
  In the Introduction, we describe the genesis of funnel control. After that, we investigate diverse system classes amenable to funnel control. Funnel control is shown for systems with arbitrary relative degree and systems described by partial differential equations. Finally, we discuss input constraints and applications.</description>
      <guid isPermaLink="false">oai:arXiv.org:2310.03449v2</guid>
      <category>math.OC</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Thomas Berger, Achim Ilchmann, Eugene P. Ryan</dc:creator>
    </item>
    <item>
      <title>cuPDLP.jl: A GPU Implementation of Restarted Primal-Dual Hybrid Gradient for Linear Programming in Julia</title>
      <link>https://arxiv.org/abs/2311.12180</link>
      <description>arXiv:2311.12180v4 Announce Type: replace 
Abstract: In this paper, we provide an affirmative answer to the long-standing question: Are GPUs useful in solving linear programming? We present cuPDLP.jl, a GPU implementation of restarted primal-dual hybrid gradient (PDHG) for solving linear programming (LP). We show that this prototype implementation in Julia has comparable numerical performance on standard LP benchmark sets to Gurobi, a highly optimized implementation of the simplex and interior-point methods. This demonstrates the power of using GPUs in linear programming, which, for the first time, showcases that GPUs and first-order methods can lead to performance comparable to state-of-the-art commercial optimization LP solvers on standard benchmark sets.</description>
      <guid isPermaLink="false">oai:arXiv.org:2311.12180v4</guid>
      <category>math.OC</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Haihao Lu, Jinwen Yang</dc:creator>
    </item>
    <item>
      <title>Speed limits in traffic emission models using multi-objective optimization</title>
      <link>https://arxiv.org/abs/2311.12744</link>
      <description>arXiv:2311.12744v3 Announce Type: replace 
Abstract: Climate change compels a reduction of greenhouse gas emissions, yet vehicular traffic still contributes significantly to the emission of air pollutants. Hence, in this paper we focus on the optimization of traffic flow while simultaneously minimizing air pollution using speed limits as controllable parameters. We introduce a framework of traffic emission models to simulate the traffic dynamic as well as the production and spread of air pollutants. We formulate a multi-objective optimization problem for the optimization of multiple aspects of vehicular traffic. The results show that multi-objective optimization can be a valuable tool in traffic emission modeling as it allows to find optimal compromises between ecological and economic objectives.</description>
      <guid isPermaLink="false">oai:arXiv.org:2311.12744v3</guid>
      <category>math.OC</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Simone G\"ottlich, Michael Herty, Alena Ulke</dc:creator>
    </item>
    <item>
      <title>Algebraic Constraints and Algorithms for Common Lines in Cryo-EM</title>
      <link>https://arxiv.org/abs/2403.16879</link>
      <description>arXiv:2403.16879v3 Announce Type: replace 
Abstract: We revisit the topic of common lines between projection images in single particle cryo-electron microscopy (cryo-EM). We derive a novel low-rank constraint on a certain $2n \times n$ matrix storing properly-scaled basis vectors for the common lines between $n$ projection images of one molecular conformation. Using this algebraic constraint and others, we give optimization algorithms to denoise common lines and recover the unknown 3D rotations associated to the images. As an application, we develop a clustering algorithm to partition a set of noisy images into homogeneous communities using common lines, in the case of discrete heterogeneity in cryo-EM. We demonstrate the methods on synthetic and experimental datasets.</description>
      <guid isPermaLink="false">oai:arXiv.org:2403.16879v3</guid>
      <category>math.OC</category>
      <category>math.AG</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <arxiv:DOI>10.1017/S2633903X24000072</arxiv:DOI>
      <arxiv:journal_reference>Biological Imaging, 1-30 (2024)</arxiv:journal_reference>
      <dc:creator>Tommi Muller, Adriana L. Duncan, Eric J. Verbeke, Joe Kileel</dc:creator>
    </item>
    <item>
      <title>Battery Degradation Heuristics for Predictive Energy Management in Shipboard Power Systems</title>
      <link>https://arxiv.org/abs/2405.18633</link>
      <description>arXiv:2405.18633v2 Announce Type: replace 
Abstract: The presence of Pulse Power Loads (PPLs) in the Notional Shipboard Power System (SPS) presents a challenge in the form of meeting their high ramp rate requirements. Considering the ramp rate limitations on the generators, this might hinder the power flow in the grid. Failure to meet the ramp rate requirements might cause instability. Aggregating generators with energy storage elements usually addresses the ramp requirements while ensuring the power demand is achieved. This paper proposes an energy management strategy that adaptively splits the power demand between the generators and the batteries while simultaneously considering the battery degradation and the generator's efficient operation. Since it is challenging to incorporate the battery degradation model directly into the optimization problem due to its complex structure and the degradation time scale which is not practical for real-time implementation, two reasonable heuristics in terms of minimizing the absolute battery power and minimizing the battery state of charge are proposed and compared to manage the battery degradation. A model predictive energy management strategy is then developed to coordinate the power split considering the generator efficiency and minimizing the battery degradation based on the two heuristic approaches. The designed strategy is tested via a simulation of a lumped notional shipboard power system. The results show the impact of the battery degradation heuristics for energy management strategy in mitigating battery degradation and its health management.</description>
      <guid isPermaLink="false">oai:arXiv.org:2405.18633v2</guid>
      <category>math.OC</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Satish Vedula, Ayobami Olajube, Koto Omiloli, Olugbenga Moses Anubi</dc:creator>
    </item>
    <item>
      <title>Schr\"{o}dinger Bridge with Quadratic State Cost is Exactly Solvable</title>
      <link>https://arxiv.org/abs/2406.00503</link>
      <description>arXiv:2406.00503v2 Announce Type: replace 
Abstract: Schr\"odinger bridge is a diffusion process that steers a given distribution to another in a prescribed time while minimizing the effort to do so. It can be seen as the stochastic dynamical version of the optimal mass transport, and has growing applications in generative diffusion models and stochastic optimal control. In this work, we propose a regularized variant of the Schr\"odinger bridge with a quadratic state cost-to-go that incentivizes the optimal sample paths to stay close to a nominal level. Unlike the conventional Schr\"odinger bridge, the regularization induces a state-dependent rate of killing and creation of probability mass, and its solution requires determining the Markov kernel of a reaction-diffusion partial differential equation. We derive this Markov kernel in closed form. Our solution recovers the heat kernel in the vanishing regularization (i.e., diffusion without reaction) limit, thereby recovering the solution of the conventional Schr\"odinger bridge. Our results enable the use of dynamic Sinkhorn recursion for computing the Schr\"odinger bridge with a quadratic state cost-to-go, which would otherwise be challenging to use in this setting. We deduce properties of the new kernel and explain its connections with certain exactly solvable models in quantum mechanics.</description>
      <guid isPermaLink="false">oai:arXiv.org:2406.00503v2</guid>
      <category>math.OC</category>
      <category>cs.LG</category>
      <category>cs.SY</category>
      <category>eess.SY</category>
      <category>math-ph</category>
      <category>math.MP</category>
      <category>stat.ML</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Alexis M. H. Teter, Wenqing Wang, Abhishek Halder</dc:creator>
    </item>
    <item>
      <title>Decentralized Stochastic Gradient Descent Ascent for Finite-Sum Minimax Problems</title>
      <link>https://arxiv.org/abs/2212.02724</link>
      <description>arXiv:2212.02724v2 Announce Type: replace-cross 
Abstract: Minimax optimization problems have attracted significant attention in recent years due to their widespread application in numerous machine learning models. To solve the minimax problem, a wide variety of stochastic optimization methods have been proposed. However, most of them ignore the distributed setting where the training data is distributed on multiple workers. In this paper, we developed a novel decentralized stochastic gradient descent ascent method for the finite-sum minimax problem. In particular, by employing the variance-reduced gradient, our method can achieve $O(\frac{\sqrt{n}\kappa^3}{(1-\lambda)^2\epsilon^2})$ sample complexity and $O(\frac{\kappa^3}{(1-\lambda)^2\epsilon^2})$ communication complexity for the nonconvex-strongly-concave minimax problem. As far as we know, our work is the first one to achieve such theoretical complexities for this kind of minimax problem. At last, we apply our method to AUC maximization, and the experimental results confirm the effectiveness of our method.</description>
      <guid isPermaLink="false">oai:arXiv.org:2212.02724v2</guid>
      <category>cs.LG</category>
      <category>math.OC</category>
      <category>stat.ML</category>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Hongchang Gao</dc:creator>
    </item>
    <item>
      <title>A Bregman Proximal Perspective on Classical and Quantum Blahut-Arimoto Algorithms</title>
      <link>https://arxiv.org/abs/2306.04492</link>
      <description>arXiv:2306.04492v3 Announce Type: replace-cross 
Abstract: The Blahut-Arimoto algorithm is a well-known method to compute classical channel capacities and rate-distortion functions. Recent works have extended this algorithm to compute various quantum analogs of these quantities. In this paper, we show how these Blahut-Arimoto algorithms are special instances of mirror descent, which is a type of Bregman proximal method, and a well-studied generalization of gradient descent for constrained convex optimization. Using recently developed convex analysis tools, we show how analysis based on relative smoothness and strong convexity recovers known sublinear and linear convergence rates for Blahut-Arimoto algorithms. This Bregman proximal viewpoint allows us to derive related algorithms with similar convergence guarantees to solve problems in information theory for which Blahut-Arimoto-type algorithms are not directly applicable. We apply this framework to compute energy-constrained classical and quantum channel capacities, classical and quantum rate-distortion functions, and approximations of the relative entropy of entanglement, all with provable convergence guarantees.</description>
      <guid isPermaLink="false">oai:arXiv.org:2306.04492v3</guid>
      <category>cs.IT</category>
      <category>math.IT</category>
      <category>math.OC</category>
      <category>quant-ph</category>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Kerry He, James Saunderson, Hamza Fawzi</dc:creator>
    </item>
    <item>
      <title>Byzantine Robustness and Partial Participation Can Be Achieved at Once: Just Clip Gradient Differences</title>
      <link>https://arxiv.org/abs/2311.14127</link>
      <description>arXiv:2311.14127v2 Announce Type: replace-cross 
Abstract: Distributed learning has emerged as a leading paradigm for training large machine learning models. However, in real-world scenarios, participants may be unreliable or malicious, posing a significant challenge to the integrity and accuracy of the trained models. Byzantine fault tolerance mechanisms have been proposed to address these issues, but they often assume full participation from all clients, which is not always practical due to the unavailability of some clients or communication constraints. In our work, we propose the first distributed method with client sampling and provable tolerance to Byzantine workers. The key idea behind the developed method is the use of gradient clipping to control stochastic gradient differences in recursive variance reduction. This allows us to bound the potential harm caused by Byzantine workers, even during iterations when all sampled clients are Byzantine. Furthermore, we incorporate communication compression into the method to enhance communication efficiency. Under general assumptions, we prove convergence rates for the proposed method that match the existing state-of-the-art (SOTA) theoretical results. We also propose a heuristic on adjusting any Byzantine-robust method to a partial participation scenario via clipping.</description>
      <guid isPermaLink="false">oai:arXiv.org:2311.14127v2</guid>
      <category>cs.LG</category>
      <category>cs.AI</category>
      <category>cs.DC</category>
      <category>math.OC</category>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Grigory Malinovsky, Peter Richt\'arik, Samuel Horv\'ath, Eduard Gorbunov</dc:creator>
    </item>
    <item>
      <title>Threshold Decision-Making Dynamics Adaptive to Physical Constraints and Changing Environment</title>
      <link>https://arxiv.org/abs/2312.06395</link>
      <description>arXiv:2312.06395v3 Announce Type: replace-cross 
Abstract: We propose a threshold decision-making framework for controlling the physical dynamics of an agent switching between two spatial tasks. Our framework couples a nonlinear opinion dynamics model that represents the evolution of an agent's preference for a particular task with the physical dynamics of the agent. We prove the bifurcation that governs the behavior of the coupled dynamics. We show by means of the bifurcation behavior how the coupled dynamics are adaptive to the physical constraints of the agent. We also show how the bifurcation can be modulated to allow the agent to switch tasks based on thresholds adaptive to environmental conditions. We illustrate the benefits of the approach through a decentralized multi-robot task allocation application for trash collection.</description>
      <guid isPermaLink="false">oai:arXiv.org:2312.06395v3</guid>
      <category>cs.RO</category>
      <category>math.DS</category>
      <category>math.OC</category>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Giovanna Amorim, Mar\'ia Santos, Shinkyu Park, Alessio Franci, Naomi Ehrich Leonard</dc:creator>
    </item>
    <item>
      <title>Solving Dense Linear Systems Faster Than via Preconditioning</title>
      <link>https://arxiv.org/abs/2312.08893</link>
      <description>arXiv:2312.08893v2 Announce Type: replace-cross 
Abstract: We give a stochastic optimization algorithm that solves a dense $n\times n$ real-valued linear system $Ax=b$, returning $\tilde x$ such that $\|A\tilde x-b\|\leq \epsilon\|b\|$ in time: $$\tilde O((n^2+nk^{\omega-1})\log1/\epsilon),$$ where $k$ is the number of singular values of $A$ larger than $O(1)$ times its smallest positive singular value, $\omega &lt; 2.372$ is the matrix multiplication exponent, and $\tilde O$ hides a poly-logarithmic in $n$ factor. When $k=O(n^{1-\theta})$ (namely, $A$ has a flat-tailed spectrum, e.g., due to noisy data or regularization), this improves on both the cost of solving the system directly, as well as on the cost of preconditioning an iterative method such as conjugate gradient. In particular, our algorithm has an $\tilde O(n^2)$ runtime when $k=O(n^{0.729})$. We further adapt this result to sparse positive semidefinite matrices and least squares regression.
  Our main algorithm can be viewed as a randomized block coordinate descent method, where the key challenge is simultaneously ensuring good convergence and fast per-iteration time. In our analysis, we use theory of majorization for elementary symmetric polynomials to establish a sharp convergence guarantee when coordinate blocks are sampled using a determinantal point process. We then use a Markov chain coupling argument to show that similar convergence can be attained with a cheaper sampling scheme, and accelerate the block coordinate descent update via matrix sketching.</description>
      <guid isPermaLink="false">oai:arXiv.org:2312.08893v2</guid>
      <category>cs.DS</category>
      <category>cs.LG</category>
      <category>cs.NA</category>
      <category>math.NA</category>
      <category>math.OC</category>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Micha{\l} Derezi\'nski, Jiaming Yang</dc:creator>
    </item>
    <item>
      <title>A Survey of Recent Advances in Optimization Methods for Wireless Communications</title>
      <link>https://arxiv.org/abs/2401.12025</link>
      <description>arXiv:2401.12025v3 Announce Type: replace-cross 
Abstract: Mathematical optimization is now widely regarded as an indispensable modeling and solution tool for the design of wireless communications systems. While optimization has played a significant role in the revolutionary progress in wireless communication and networking technologies from 1G to 5G and onto the future 6G, the innovations in wireless technologies have also substantially transformed the nature of the underlying mathematical optimization problems upon which the system designs are based and have sparked significant innovations in the development of methodologies to understand, to analyze, and to solve those problems. In this paper, we provide a comprehensive survey of recent advances in mathematical optimization theory and algorithms for wireless communication system design. We begin by illustrating common features of mathematical optimization problems arising in wireless communication system design. We discuss various scenarios and use cases and their associated mathematical structures from an optimization perspective. We then provide an overview of recently developed optimization techniques in areas ranging from nonconvex optimization, global optimization, and integer programming, to distributed optimization and learning-based optimization. The key to successful solution of mathematical optimization problems is in carefully choosing or developing suitable algorithms (or neural network architectures) that can exploit the underlying problem structure. We conclude the paper by identifying several open research challenges and outlining future research directions.</description>
      <guid isPermaLink="false">oai:arXiv.org:2401.12025v3</guid>
      <category>cs.IT</category>
      <category>eess.SP</category>
      <category>math.IT</category>
      <category>math.OC</category>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Ya-Feng Liu, Tsung-Hui Chang, Mingyi Hong, Zheyu Wu, Anthony Man-Cho So, Eduard A. Jorswieck, Wei Yu</dc:creator>
    </item>
    <item>
      <title>Learning mirror maps in policy mirror descent</title>
      <link>https://arxiv.org/abs/2402.05187</link>
      <description>arXiv:2402.05187v2 Announce Type: replace-cross 
Abstract: Policy Mirror Descent (PMD) is a popular framework in reinforcement learning, serving as a unifying perspective that encompasses numerous algorithms. These algorithms are derived through the selection of a mirror map and enjoy finite-time convergence guarantees. Despite its popularity, the exploration of PMD's full potential is limited, with the majority of research focusing on a particular mirror map -- namely, the negative entropy -- which gives rise to the renowned Natural Policy Gradient (NPG) method. It remains uncertain from existing theoretical studies whether the choice of mirror map significantly influences PMD's efficacy. In our work, we conduct empirical investigations to show that the conventional mirror map choice (NPG) often yields less-than-optimal outcomes across several standard benchmark environments. Using evolutionary strategies, we identify more efficient mirror maps that enhance the performance of PMD. We first focus on a tabular environment, i.e. Grid-World, where we relate existing theoretical bounds with the performance of PMD for a few standard mirror maps and the learned one. We then show that it is possible to learn a mirror map that outperforms the negative entropy in more complex environments, such as the MinAtar suite. Our results suggest that mirror maps generalize well across various environments, raising questions about how to best match a mirror map to an environment's structure and characteristics.</description>
      <guid isPermaLink="false">oai:arXiv.org:2402.05187v2</guid>
      <category>stat.ML</category>
      <category>cs.LG</category>
      <category>math.OC</category>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Carlo Alfano, Sebastian Towers, Silvia Sapora, Chris Lu, Patrick Rebeschini</dc:creator>
    </item>
    <item>
      <title>Dealing with unbounded gradients in stochastic saddle-point optimization</title>
      <link>https://arxiv.org/abs/2402.13903</link>
      <description>arXiv:2402.13903v2 Announce Type: replace-cross 
Abstract: We study the performance of stochastic first-order methods for finding saddle points of convex-concave functions. A notorious challenge faced by such methods is that the gradients can grow arbitrarily large during optimization, which may result in instability and divergence. In this paper, we propose a simple and effective regularization technique that stabilizes the iterates and yields meaningful performance guarantees even if the domain and the gradient noise scales linearly with the size of the iterates (and is thus potentially unbounded). Besides providing a set of general results, we also apply our algorithm to a specific problem in reinforcement learning, where it leads to performance guarantees for finding near-optimal policies in an average-reward MDP without prior knowledge of the bias span.</description>
      <guid isPermaLink="false">oai:arXiv.org:2402.13903v2</guid>
      <category>cs.LG</category>
      <category>math.OC</category>
      <category>stat.ML</category>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Gergely Neu, Nneka Okolo</dc:creator>
    </item>
    <item>
      <title>Bilinear optimal control for the Stokes-Brinkman equations: a priori and a posteriori error analyses</title>
      <link>https://arxiv.org/abs/2404.18348</link>
      <description>arXiv:2404.18348v3 Announce Type: replace-cross 
Abstract: We analyze a bilinear optimal control problem for the Stokes--Brinkman equations: the control variable enters the state equations as a coefficient. In two- and three-dimensional Lipschitz domains, we perform a complete continuous analysis that includes the existence of solutions and first- and second-order optimality conditions. We also develop two finite element methods that differ fundamentally in whether the admissible control set is discretized or not. For each of the proposed methods, we perform a convergence analysis and derive a priori error estimates; the latter under the assumption that the domain is convex. Finally, assuming that the domain is Lipschitz, we develop an a posteriori error estimator for each discretization scheme, obtain a global reliability bound, and investigate local efficiency estimates.</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.18348v3</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <category>math.OC</category>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Alejandro Allendes, Gilberto Campa\~na, Enrique Otarola</dc:creator>
    </item>
    <item>
      <title>Towards a universal QAOA protocol: Evidence of a scaling advantage in solving some combinatorial optimization problems</title>
      <link>https://arxiv.org/abs/2405.09169</link>
      <description>arXiv:2405.09169v2 Announce Type: replace-cross 
Abstract: The quantum approximate optimization algorithm (QAOA) is a promising algorithm for solving combinatorial optimization problems (COPs). In this algorithm, there are alternating layers consisting of a mixer and a problem Hamiltonian. Each layer $i=0,\ldots,p-1$ is parameterized by $\beta_i$ and $\gamma_i$. How to find these parameters has been an open question with the majority of the research focused on finding them using classical algorithms. In this work, we present evidence that fixed linear ramp schedules constitute a universal set of QAOA parameters, i.e., a set of $\gamma$ and $\beta$ parameters that rapidly approximate the optimal solution, $x^*$, independently of the COP selected, and that the success probability of finding it, $probability(x^*)$, increases with the number of QAOA layers $p$. We simulate linear ramp QAOA protocols (LR-QAOA) involving up to $N_q=42$ qubits and $p = 400$ layers on random instances of 9 different COPs. The results suggest that $probability(x^*) \approx 1/2^{(\eta N_q / p)}$ for a constant $\eta$. For example, when implementing LR-QAOA with $p=42$, the $probability(x^*)$ for 42-qubit Weighted MaxCut problems (W-MaxCut) increases from $2/2^{42}\approx 10^{-13}$ to an average of 0.13. We compare LR-QAOA, simulated annealing (SA), and branch-and-bound (B\&amp;B) finding a scaling improvement in LR-QAOA. We test LR-QAOA on real hardware using IonQ Aria, Quantinuum H2-1, IBM Brisbane, IBM Kyoto, and IBM Osaka, encoding random weighted MaxCut (W-MaxCut) problems from 5 to 109 qubits and $p=3$ to $100$. Even for the largest case, $N_q=109$ qubits and $p=100$, information about the LR-QAOA optimization protocol is present. The circuit involved requires 21200 CNOT gates. These results show that LR-QAOA effectively finds high-quality solutions for a large variety of COPs and suggest a scaling advantage of quantum computation for combinatorial optimization.</description>
      <guid isPermaLink="false">oai:arXiv.org:2405.09169v2</guid>
      <category>quant-ph</category>
      <category>math.OC</category>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>J. A. Montanez-Barrera, Kristel Michielsen</dc:creator>
    </item>
  </channel>
</rss>
