<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>cs.SI updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/cs.SI</link>
    <description>cs.SI updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/cs.SI" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Mon, 04 Nov 2024 05:00:27 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Mon, 04 Nov 2024 00:00:00 -0500</pubDate>
    <skipDays>
      <day>Sunday</day>
      <day>Saturday</day>
    </skipDays>
    <item>
      <title>GraphC: Parameter-free Hierarchical Clustering of Signed Graph Networks v2</title>
      <link>https://arxiv.org/abs/2411.00249</link>
      <description>arXiv:2411.00249v1 Announce Type: new 
Abstract: Spectral clustering methodologies, when extended to accommodate signed graphs, have encountered notable limitations in effectively encapsulating inherent grouping relationships. Recent findings underscore a substantial deterioration in the efficacy of spectral clustering methods when applied to expansive signed networks. We introduce a scalable hierarchical Graph Clustering algorithm denominated GraphC. This algorithm excels at discerning optimal clusters within signed networks of varying magnitudes. GraphC aims to preserve the positive edge fractions within communities during partitioning while concurrently maximizing the negative edge fractions between communities. Importantly, GraphC does not require a predetermined cluster count (denoted as k). Empirical substantiation of GraphC 's efficacy is provided through a comprehensive evaluation involving fourteen datasets juxtaposed against ten baseline signed graph clustering algorithms. The algorithm's scalability is demonstrated through its application to extensive signed graphs drawn from Amazon-sourced datasets, each comprising tens of millions of vertices and edges. A noteworthy accomplishment is evidenced, with an average cumulative enhancement of 18.64% (consisting of the summation of positive edge fractions within communities and negative edge fractions between communities) over the second-best baseline for each respective signed graph. It is imperative to note that this evaluation excludes instances wherein all baseline algorithms failed to execute comprehensively.</description>
      <guid isPermaLink="false">oai:arXiv.org:2411.00249v1</guid>
      <category>cs.SI</category>
      <pubDate>Mon, 04 Nov 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Muhieddine Shebaro, Lucas Rusnak, Martin Burtscher, Jelena Te\v{s}i\'c</dc:creator>
    </item>
    <item>
      <title>Content Aware Analysis of Scholarly Networks: A Case Study on CORD19 Dataset</title>
      <link>https://arxiv.org/abs/2411.00262</link>
      <description>arXiv:2411.00262v1 Announce Type: new 
Abstract: This paper investigates the relationships among key elements of scientific research network, namely articles, researchers, and journals. We introduce a novel approach to use semantic information through the HITS algorithm based propagation of topic information in the network. The topic information is derived by using the Named Entity Recognition and Entity Linkage. In our case, MedCAT is used to extract the topics from the CORD19 Dataset, which is a corpus of academic articles about COVID-19 and coronavirus scientific network. Our approach focuses on the COVID-19 domain, utilizing the CORD-19 dataset to demonstrate the efficacy of integrating topic-related information within the citation framework. Through the application of a hybrid HITS algorithm, we show that incorporating topic data significantly influences article rankings, revealing deeper insights into the structure of the academic community.</description>
      <guid isPermaLink="false">oai:arXiv.org:2411.00262v1</guid>
      <category>cs.SI</category>
      <category>cs.IR</category>
      <category>physics.soc-ph</category>
      <pubDate>Mon, 04 Nov 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Mehmet Emre Akbulut, Yusuf Erdem Nacar</dc:creator>
    </item>
    <item>
      <title>A Public Dataset Tracking Social Media Discourse about the 2024 U.S. Presidential Election on Twitter/X</title>
      <link>https://arxiv.org/abs/2411.00376</link>
      <description>arXiv:2411.00376v1 Announce Type: new 
Abstract: In this paper, we introduce the first release of a large-scale dataset capturing discourse on $\mathbb{X}$ (a.k.a., Twitter) related to the upcoming 2024 U.S. Presidential Election. Our dataset comprises 22 million publicly available posts on X.com, collected from May 1, 2024, to July 31, 2024, using a custom-built scraper, which we describe in detail. By employing targeted keywords linked to key political figures, events, and emerging issues, we aligned data collection with the election cycle to capture evolving public sentiment and the dynamics of political engagement on social media. This dataset offers researchers a robust foundation to investigate critical questions about the influence of social media in shaping political discourse, the propagation of election-related narratives, and the spread of misinformation. We also present a preliminary analysis that highlights prominent hashtags and keywords within the dataset, offering initial insights into the dominant themes and conversations occurring in the lead-up to the election. Our dataset is available at: url{https://github.com/sinking8/usc-x-24-us-election</description>
      <guid isPermaLink="false">oai:arXiv.org:2411.00376v1</guid>
      <category>cs.SI</category>
      <pubDate>Mon, 04 Nov 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Ashwin Balasubramanian, Vito Zou, Hitesh Narayana, Christina You, Luca Luceri, Emilio Ferrara</dc:creator>
    </item>
    <item>
      <title>Domain-Informed Negative Sampling Strategies for Dynamic Graph Embedding in Meme Stock-Related Social Networks</title>
      <link>https://arxiv.org/abs/2411.00606</link>
      <description>arXiv:2411.00606v1 Announce Type: new 
Abstract: Social network platforms like Reddit are increasingly impacting real-world economics. Meme stocks are a recent phenomena where price movements are driven by retail investors organising themselves via social networks. To study the impact of social networks on meme stocks, the first step is to analyse these networks. Going forward, predicting meme stocks' returns would require to predict dynamic interactions first. This is different from conventional link prediction, frequently applied in e.g. recommendation systems. For this task, it is essential to predict more complex interaction dynamics, such as the exact timing and interaction types like loops. These are crucial for linking the network to meme stock price movements. Dynamic graph embedding (DGE) has recently emerged as a promising approach for modeling dynamic graph-structured data. However, current negative sampling strategies, an important component of DGE, are designed for conventional dynamic link prediction and do not capture the specific patterns present in meme stock-related social networks. This limits the training and evaluation of DGE models in analysing such social networks. To overcome this drawback, we propose novel negative sampling strategies based on the analysis of real meme stock-related social networks and financial knowledge. Our experiments show that the proposed negative sampling strategy can better evaluate and train DGE models targeted at meme stock-related social networks compared to existing baselines.</description>
      <guid isPermaLink="false">oai:arXiv.org:2411.00606v1</guid>
      <category>cs.SI</category>
      <pubDate>Mon, 04 Nov 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Yunming Hui, Inez Maria Zwetsloot, Simon Trimborn, Stevan Rudinac</dc:creator>
    </item>
    <item>
      <title>How to Bridge Spatial and Temporal Heterogeneity in Link Prediction? A Contrastive Method</title>
      <link>https://arxiv.org/abs/2411.00612</link>
      <description>arXiv:2411.00612v1 Announce Type: new 
Abstract: Temporal Heterogeneous Networks play a crucial role in capturing the dynamics and heterogeneity inherent in various real-world complex systems, rendering them a noteworthy research avenue for link prediction. However, existing methods fail to capture the fine-grained differential distribution patterns and temporal dynamic characteristics, which we refer to as spatial heterogeneity and temporal heterogeneity. To overcome such limitations, we propose a novel \textbf{C}ontrastive Learning-based \textbf{L}ink \textbf{P}rediction model, \textbf{CLP}, which employs a multi-view hierarchical self-supervised architecture to encode spatial and temporal heterogeneity. Specifically, aiming at spatial heterogeneity, we develop a spatial feature modeling layer to capture the fine-grained topological distribution patterns from node- and edge-level representations, respectively. Furthermore, aiming at temporal heterogeneity, we devise a temporal information modeling layer to perceive the evolutionary dependencies of dynamic graph topologies from time-level representations. Finally, we encode the spatial and temporal distribution heterogeneity from a contrastive learning perspective, enabling a comprehensive self-supervised hierarchical relation modeling for the link prediction task. Extensive experiments conducted on four real-world dynamic heterogeneous network datasets verify that our \mymodel consistently outperforms the state-of-the-art models, demonstrating an average improvement of 10.10\%, 13.44\% in terms of AUC and AP, respectively.</description>
      <guid isPermaLink="false">oai:arXiv.org:2411.00612v1</guid>
      <category>cs.SI</category>
      <category>cs.AI</category>
      <pubDate>Mon, 04 Nov 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Yu Tai, Xinglong Wu, Hongwei Yang, Hui He, Duanjing Chen, Yuanming Shao, Weizhe Zhang</dc:creator>
    </item>
    <item>
      <title>Synergizing LLM Agents and Knowledge Graph for Socioeconomic Prediction in LBSN</title>
      <link>https://arxiv.org/abs/2411.00028</link>
      <description>arXiv:2411.00028v1 Announce Type: cross 
Abstract: The fast development of location-based social networks (LBSNs) has led to significant changes in society, resulting in popular studies of using LBSN data for socioeconomic prediction, e.g., regional population and commercial activity estimation. Existing studies design various graphs to model heterogeneous LBSN data, and further apply graph representation learning methods for socioeconomic prediction. However, these approaches heavily rely on heuristic ideas and expertise to extract task-relevant knowledge from diverse data, which may not be optimal for specific tasks. Additionally, they tend to overlook the inherent relationships between different indicators, limiting the prediction accuracy. Motivated by the remarkable abilities of large language models (LLMs) in commonsense reasoning, embedding, and multi-agent collaboration, in this work, we synergize LLM agents and knowledge graph for socioeconomic prediction. We first construct a location-based knowledge graph (LBKG) to integrate multi-sourced LBSN data. Then we leverage the reasoning power of LLM agent to identify relevant meta-paths in the LBKG for each type of socioeconomic prediction task, and design a semantic-guided attention module for knowledge fusion with meta-paths. Moreover, we introduce a cross-task communication mechanism to further enhance performance by enabling knowledge sharing across tasks at both LLM agent and KG levels. On the one hand, the LLM agents for different tasks collaborate to generate more diverse and comprehensive meta-paths. On the other hand, the embeddings from different tasks are adaptively merged for better socioeconomic prediction. Experiments on two datasets demonstrate the effectiveness of the synergistic design between LLM and KG, providing insights for information sharing across socioeconomic prediction tasks.</description>
      <guid isPermaLink="false">oai:arXiv.org:2411.00028v1</guid>
      <category>cs.CL</category>
      <category>cs.AI</category>
      <category>cs.LG</category>
      <category>cs.SI</category>
      <pubDate>Mon, 04 Nov 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Zhilun Zhou, Jingyang Fan, Yu Liu, Fengli Xu, Depeng Jin, Yong Li</dc:creator>
    </item>
    <item>
      <title>What can we learn from marketing skills as a bipartite network from accredited programs?</title>
      <link>https://arxiv.org/abs/2411.00644</link>
      <description>arXiv:2411.00644v1 Announce Type: cross 
Abstract: The relationship between professional skills and higher education programs is modeled as a non-directed bipartite network with binary entries representing the links between 28 skills (as captured by the occupational information network, O*NET) and 258 graduate program summaries (as captured by commercial brochures of graduate programs in marketing with accreditation standards of the Association to Advance Collegiate Schools of Business). While descriptive analysis for skills suggests a qualitative lack of alignment between the job demands captured by O*NET, inferential analyses based on exponential random graph model estimates show that skills' popularity and homophily coexist with a systematic yet weak alignment to job demands for marketing managers.</description>
      <guid isPermaLink="false">oai:arXiv.org:2411.00644v1</guid>
      <category>stat.ME</category>
      <category>cs.SI</category>
      <category>physics.soc-ph</category>
      <pubDate>Mon, 04 Nov 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <dc:creator>Maria del Pilar Garcia-Chitiva, Silvana Dakduk, Juan C. Correa</dc:creator>
    </item>
    <item>
      <title>A graph-based approach to extracting narrative signals from public discourse</title>
      <link>https://arxiv.org/abs/2411.00702</link>
      <description>arXiv:2411.00702v1 Announce Type: cross 
Abstract: Narratives are key interpretative devices by which humans make sense of political reality. As the significance of narratives for understanding current societal issues such as polarization and misinformation becomes increasingly evident, there is a growing demand for methods that support their empirical analysis. To this end, we propose a graph-based formalism and machine-guided method for extracting, representing, and analyzing selected narrative signals from digital textual corpora, based on Abstract Meaning Representation (AMR). The formalism and method introduced here specifically cater to the study of political narratives that figure in texts from digital media such as archived political speeches, social media posts, political manifestos and transcripts of parliamentary debates. We conceptualize these political narratives as a type of ontological narratives: stories by which actors position themselves as political beings, and which are akin to political worldviews in which actors present their normative vision of the world, or aspects thereof. We approach the study of such political narratives as a problem of information retrieval: starting from a textual corpus, we first extract a graph-like representation of the meaning of each sentence in the corpus using AMR. Drawing on transferable concepts from narratology, we then apply a set of heuristics to filter these graphs for representations of 1) actors, 2) the events in which these actors figure, and 3) traces of the perspectivization of these events. We approach these references to actors, events, and instances of perspectivization as core narrative signals that initiate a further analysis by alluding to larger political narratives. By means of a case study of State of the European Union addresses, we demonstrate how the formalism can be used to inductively surface signals of political narratives from public discourse.</description>
      <guid isPermaLink="false">oai:arXiv.org:2411.00702v1</guid>
      <category>cs.CL</category>
      <category>cs.CY</category>
      <category>cs.IR</category>
      <category>cs.SI</category>
      <pubDate>Mon, 04 Nov 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Armin Pournaki, Tom Willaert</dc:creator>
    </item>
    <item>
      <title>Self-reinforcing cascades: A spreading model for beliefs or products of varying intensity or quality</title>
      <link>https://arxiv.org/abs/2411.00714</link>
      <description>arXiv:2411.00714v1 Announce Type: cross 
Abstract: Models of how things spread often assume that transmission mechanisms are fixed over time. However, social contagions--the spread of ideas, beliefs, innovations--can lose or gain in momentum as they spread: ideas can get reinforced, beliefs strengthened, products refined. We study the impacts of such self-reinforcement mechanisms in cascade dynamics. We use different mathematical modeling techniques to capture the recursive, yet changing nature of the process. We find a critical regime with a range of power-law cascade size distributions with varying scaling exponents. This regime clashes with classic models, where criticality requires fine tuning at a precise critical point. Self-reinforced cascades produce critical-like behavior over a wide range of parameters, which may help explain the ubiquity of power-law distributions in empirical social data.</description>
      <guid isPermaLink="false">oai:arXiv.org:2411.00714v1</guid>
      <category>physics.soc-ph</category>
      <category>cs.SI</category>
      <pubDate>Mon, 04 Nov 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Laurent H\'ebert-Dufresne, Juniper Lovato, Giulio Burgio, James P. Gleeson, S. Redner, P. L. Krapivsky</dc:creator>
    </item>
    <item>
      <title>Fairness in Social Influence Maximization via Optimal Transport</title>
      <link>https://arxiv.org/abs/2406.17736</link>
      <description>arXiv:2406.17736v2 Announce Type: replace 
Abstract: We study fairness in social influence maximization, whereby one seeks to select seeds that spread a given information throughout a network, ensuring balanced outreach among different communities (e.g. demographic groups). In the literature, fairness is often quantified in terms of the expected outreach within individual communities. In this paper, we demonstrate that such fairness metrics can be misleading since they overlook the stochastic nature of information diffusion processes. When information diffusion occurs in a probabilistic manner, multiple outreach scenarios can occur. As such, outcomes such as ``In 50\% of the cases, no one in group 1 gets the information, while everyone in group 2 does, and in the other 50%, it is the opposite'', which always results in largely unfair outcomes, are classified as fair by a variety of fairness metrics in the literature. We tackle this problem by designing a new fairness metric, mutual fairness, that captures variability in outreach through optimal transport theory. We propose a new seed-selection algorithm that optimizes both outreach and mutual fairness, and we show its efficacy on several real datasets. We find that our algorithm increases fairness with only a minor decrease (and at times, even an increase) in efficiency.</description>
      <guid isPermaLink="false">oai:arXiv.org:2406.17736v2</guid>
      <category>cs.SI</category>
      <category>cs.MA</category>
      <pubDate>Mon, 04 Nov 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Shubham Chowdhary, Giulia De Pasquale, Nicolas Lanzetti, Ana-Andreea Stoica, Florian Dorfler</dc:creator>
    </item>
    <item>
      <title>Theoretical and Empirical Insights into the Origins of Degree Bias in Graph Neural Networks</title>
      <link>https://arxiv.org/abs/2404.03139</link>
      <description>arXiv:2404.03139v2 Announce Type: replace-cross 
Abstract: Graph Neural Networks (GNNs) often perform better for high-degree nodes than low-degree nodes on node classification tasks. This degree bias can reinforce social marginalization by, e.g., privileging celebrities and other high-degree actors in social networks during social and content recommendation. While researchers have proposed numerous hypotheses for why GNN degree bias occurs, we find via a survey of 38 degree bias papers that these hypotheses are often not rigorously validated, and can even be contradictory. Thus, we provide an analysis of the origins of degree bias in message-passing GNNs with different graph filters. We prove that high-degree test nodes tend to have a lower probability of misclassification regardless of how GNNs are trained. Moreover, we show that degree bias arises from a variety of factors that are associated with a node's degree (e.g., homophily of neighbors, diversity of neighbors). Furthermore, we show that during training, some GNNs may adjust their loss on low-degree nodes more slowly than on high-degree nodes; however, with sufficiently many epochs of training, message-passing GNNs can achieve their maximum possible training accuracy, which is not significantly limited by their expressive power. Throughout our analysis, we connect our findings to previously-proposed hypotheses for the origins of degree bias, supporting and unifying some while drawing doubt to others. We validate our theoretical findings on 8 common real-world networks, and based on our theoretical and empirical insights, describe a roadmap to alleviate degree bias.</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.03139v2</guid>
      <category>cs.LG</category>
      <category>cs.SI</category>
      <pubDate>Mon, 04 Nov 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Arjun Subramonian, Jian Kang, Yizhou Sun</dc:creator>
    </item>
    <item>
      <title>Robustness of graph embedding methods for community detection</title>
      <link>https://arxiv.org/abs/2405.00636</link>
      <description>arXiv:2405.00636v2 Announce Type: replace-cross 
Abstract: This study investigates the robustness of graph embedding methods for community detection in the face of network perturbations, specifically edge deletions. Graph embedding techniques, which represent nodes as low-dimensional vectors, are widely used for various graph machine learning tasks due to their ability to capture structural properties of networks effectively. However, the impact of perturbations on the performance of these methods remains relatively understudied. The research considers state-of-the-art graph embedding methods from two families: matrix factorization (e.g., LE, LLE, HOPE, M-NMF) and random walk-based (e.g., DeepWalk, LINE, node2vec). Through experiments conducted on both synthetic and real-world networks, the study reveals varying degrees of robustness within each family of graph embedding methods. The robustness is found to be influenced by factors such as network size, initial community partition strength, and the type of perturbation. Notably, node2vec and LLE consistently demonstrate higher robustness for community detection across different scenarios, including networks with degree and community size heterogeneity. These findings highlight the importance of selecting an appropriate graph embedding method based on the specific characteristics of the network and the task at hand, particularly in scenarios where robustness to perturbations is crucial.</description>
      <guid isPermaLink="false">oai:arXiv.org:2405.00636v2</guid>
      <category>physics.soc-ph</category>
      <category>cs.LG</category>
      <category>cs.SI</category>
      <category>physics.data-an</category>
      <pubDate>Mon, 04 Nov 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Zhi-Feng Wei, Pablo Moriano, Ramakrishnan Kannan</dc:creator>
    </item>
    <item>
      <title>IntraMix: Intra-Class Mixup Generation for Accurate Labels and Neighbors</title>
      <link>https://arxiv.org/abs/2405.00957</link>
      <description>arXiv:2405.00957v2 Announce Type: replace-cross 
Abstract: Graph Neural Networks (GNNs) have shown great performance in various tasks, with the core idea of learning from data labels and aggregating messages within the neighborhood of nodes. However, the common challenges in graphs are twofold: insufficient accurate (high-quality) labels and limited neighbors for nodes, resulting in weak GNNs. Existing graph augmentation methods typically address only one of these challenges, often adding training costs or relying on oversimplified or knowledge-intensive strategies, limiting their generalization. To simultaneously address both challenges faced by graphs in a generalized way, we propose an elegant method called IntraMix. Considering the incompatibility of vanilla Mixup with the complex topology of graphs, IntraMix innovatively employs Mixup among inaccurate labeled data of the same class, generating high-quality labeled data at minimal cost. Additionally, it finds data with high confidence of being clustered into the same group as the generated data to serve as their neighbors, thereby enriching the neighborhoods of graphs. IntraMix efficiently tackles both issues faced by graphs and challenges the prior notion of the limited effectiveness of Mixup in node classification. IntraMix is a theoretically grounded plug-in-play method that can be readily applied to all GNNs. Extensive experiments demonstrate the effectiveness of IntraMix across various GNNs and datasets. Our code is available at: https://github.com/Zhengsh123/IntraMix.</description>
      <guid isPermaLink="false">oai:arXiv.org:2405.00957v2</guid>
      <category>cs.LG</category>
      <category>cs.AI</category>
      <category>cs.SI</category>
      <pubDate>Mon, 04 Nov 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Shenghe Zheng, Hongzhi Wang, Xianglong Liu</dc:creator>
    </item>
    <item>
      <title>Modularity maximization and community detection in complex networks through recursive and hierarchical annealing in the D-Wave Advantage quantum processing units</title>
      <link>https://arxiv.org/abs/2410.07744</link>
      <description>arXiv:2410.07744v2 Announce Type: replace-cross 
Abstract: Quantum adiabatic optimization has long been expected to outperform classical methods in solving NP-type problems. While this has been proven in certain experiments, its main applications still reside in academic problems where the size of the system to be solved would not represent an obstacle to any modern desktop computer. Here we develop a systematic procedure to find the global optima of the modularity function to discover community structure in complex networks solely relying on pure annealers rather than hybrid solutions. We bypass the one-hot encoding constraints by hierarchically and recursively encoding binary instances of the problem that can be solved without the need to guess the exact penalties for the Lagrange multipliers. We study the variability, and robustness of the annealing process as a function of network size, directness of connections, topology, and the resolution of the communities. We show how our approach produces meaningful and at least equally optimal solutions to state-of-the-art community detection algorithms while maintaining tractable computing times. Lastly, due to its recursive nature, the annealing process returns intermediate subdivisions thus offering interpretable rather than black-box solutions. These \textit{dendrograms} can be used to unveil normal and pathological hidden hierarchies in brain networks hence opening the door to clinical workflows. Overall, this represents a first step towards an applicable practice-oriented usage of pure quantum annealing potentially bridging two segregated communities in modern science and engineering; that of network science and quantum computing.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.07744v2</guid>
      <category>physics.soc-ph</category>
      <category>cs.SI</category>
      <category>math.CO</category>
      <pubDate>Mon, 04 Nov 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Joan Falc\'o-Roget, Kacper Jurek, Barbara Wojtarowicz, Karol Capa{\l}a, Katarzyna Rycerz</dc:creator>
    </item>
  </channel>
</rss>
