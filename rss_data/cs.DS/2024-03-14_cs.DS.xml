<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>cs.DS updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/cs.DS</link>
    <description>cs.DS updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/cs.DS" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Thu, 14 Mar 2024 04:00:08 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Thu, 14 Mar 2024 00:00:00 -0400</pubDate>
    <skipDays>
      <day>Saturday</day>
      <day>Sunday</day>
    </skipDays>
    <item>
      <title>Highway Preferential Attachment Models for Geographic Routing</title>
      <link>https://arxiv.org/abs/2403.08105</link>
      <description>arXiv:2403.08105v1 Announce Type: new 
Abstract: In the 1960s, the world-renowned social psychologist Stanley Milgram conducted experiments that showed that not only do there exist ``short chains'' of acquaintances between any two arbitrary people, but that these arbitrary strangers are able to find these short chains. This phenomenon, known as the \emph{small-world phenomenon}, is explained in part by any model that has a low diameter, such as the Barab\'asi and Albert's \emph{preferential attachment} model, but these models do not display the same efficient routing that Milgram's experiments showed. In the year 2000, Kleinberg proposed a model with an efficient $\mathcal{O}(\log^2{n})$ greedy routing algorithm. In 2004, Martel and Nguyen showed that Kleinberg's analysis was tight, while also showing that Kleinberg's model had an expected diameter of only $\Theta(\log{n})$ -- a much smaller value than the greedy routing algorithm's path lengths. In 2022, Goodrich and Ozel proposed the \emph{neighborhood preferential attachment} model (NPA), combining elements from Barab\'asi and Albert's model with Kleinberg's model, and experimentally showed that the resulting model outperformed Kleinberg's greedy routing performance on U.S. road networks. While they displayed impressive empirical results, they did not provide any theoretical analysis of their model. In this paper, we first provide a theoretical analysis of a generalization of Kleinberg's original model and show that it can achieve expected $\mathcal{O}(\log{n})$ routing, a much better result than Kleinberg's model. We then propose a new model, \emph{windowed NPA}, that is similar to the neighborhood preferential attachment model but has provable theoretical guarantees w.h.p. We show that this model is able to achieve $\mathcal{O}(\log^{1 + \epsilon}{n})$ greedy routing for any $\epsilon &gt; 0$.</description>
      <guid isPermaLink="false">oai:arXiv.org:2403.08105v1</guid>
      <category>cs.DS</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Ofek Gila (University of California, Irvine), Evrim Ozel (University of California, Irvine), Michael T. Goodrich (University of California, Irvine)</dc:creator>
    </item>
    <item>
      <title>Height-bounded Lempel-Ziv encodings</title>
      <link>https://arxiv.org/abs/2403.08209</link>
      <description>arXiv:2403.08209v1 Announce Type: new 
Abstract: We introduce height-bounded LZ encodings (LZHB), a new family of compressed representations that is a variant of Lempel-Ziv parsings with a focus on allowing fast access to arbitrary positions of the text directly via the compressed representation. Any LZHB encoding whose referencing height is bounded by $h$ allows access to an arbitrary position of the underlying text using $O(h)$ predecessor queries. We show that there exists a constant $c$ such that the size $\hat{z}_{\mathit{HB}(c\log n)}$ of the optimal (smallest) LZHB encoding whose height is bounded by $c\log n$ for any string of length $n$ is $O(\hat{g}_{\mathrm{rl}})$, where $\hat{g}_{\mathrm{rl}}$ is the size of the smallest run-length grammar. Furthermore, we show that there exists a family of strings such that $\hat{z}_{\mathit{HB}(c\log n)} = o(\hat{g}_{\mathrm{rl}})$, thus making $\hat{z}_{\mathit{HB}(c\log n)}$ one of the smallest known repetitiveness measures for which $O(\mathit{polylog} n)$ time access is possible using $O(\hat{z}_{\mathit{HB}(c\log n)})$ space. While computing the optimal LZHB representation for any given height seems difficult, we propose linear and near linear time greedy algorithms which we show experimentally can efficiently find small LZHB representations in practice.</description>
      <guid isPermaLink="false">oai:arXiv.org:2403.08209v1</guid>
      <category>cs.DS</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Hideo Bannai, Mitsuru Funakoshi, Diptarama Hendrian, Myuji Matsuda, Simon J. Puglisi</dc:creator>
    </item>
    <item>
      <title>Worst-Case to Expander-Case Reductions: Derandomized and Generalized</title>
      <link>https://arxiv.org/abs/2403.08394</link>
      <description>arXiv:2403.08394v1 Announce Type: new 
Abstract: A recent paper by Abboud and Wallheimer [ITCS 2023] presents self-reductions for various fundamental graph problems, that transform worst-case instances to expanders, thus proving that the complexity remains unchanged if the input is assumed to be an expander. An interesting corollary of their self-reductions is that, if some problem admit such reduction, then the popular algorithmic paradigm based on expander-decompositions is useless against it. In this paper, we improve their core gadget, which augments a graph to make it an expander while retaining its important structure. Our new core construction has the benefit of being simple to analyze and generalize, while obtaining the following results:
  1. A derandomization of the self-reductions, showing that the equivalence between worst-case and expander-case holds even for deterministic algorithms, and ruling out the use of expander-decompositions as a derandomization tool.
  2. An extension of the results to other models of computation, such as the Fully Dynamic model and the Congested Clique model. In the former, we either improve or provide an alternative approach to some recent hardness results for dynamic expander graphs, by Henzinger, Paz, and Sricharan [ESA 2022].
  In addition, we continue this line of research by designing new self-reductions for more problems, such as Max-Cut and dynamic Densest Subgraph, and demonstrating that the core gadget can be utilized to lift lower bounds based on the OMv Conjecture to expanders.</description>
      <guid isPermaLink="false">oai:arXiv.org:2403.08394v1</guid>
      <category>cs.DS</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Amir Abboud, Nathan Wallheimer</dc:creator>
    </item>
    <item>
      <title>Improved Randomized Approximation of Hard Universality and Emptiness Problems</title>
      <link>https://arxiv.org/abs/2403.08707</link>
      <description>arXiv:2403.08707v1 Announce Type: new 
Abstract: We build on recent research on polynomial randomized approximation (PRAX) algorithms for the hard problems of NFA universality and NFA equivalence. Loosely speaking, PRAX algorithms use sampling of infinite domains within any desired accuracy $\delta$. In the spirit of experimental mathematics, we extend the concept of PRAX algorithms to be applicable to the emptiness and universality problems in any domain whose instances admit a tractable distribution as defined in this paper. A technical result here is that a linear (w.r.t. $1/\delta$) number of samples is sufficient, as opposed to the quadratic number of samples in previous papers. We show how the improved and generalized PRAX algorithms apply to universality and emptiness problems in various domains: ordinary automata, tautology testing of propositions, 2D automata, and to solution sets of certain Diophantine equations.</description>
      <guid isPermaLink="false">oai:arXiv.org:2403.08707v1</guid>
      <category>cs.DS</category>
      <category>cs.FL</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Pantelis Andreou, Stavros Konstantinidis, Taylor J. Smith</dc:creator>
    </item>
    <item>
      <title>The Runtime of Random Local Search on the Generalized Needle Problem</title>
      <link>https://arxiv.org/abs/2403.08153</link>
      <description>arXiv:2403.08153v1 Announce Type: cross 
Abstract: In their recent work, C. Doerr and Krejca (Transactions on Evolutionary Computation, 2023) proved upper bounds on the expected runtime of the randomized local search heuristic on generalized Needle functions. Based on these upper bounds, they deduce in a not fully rigorous manner a drastic influence of the needle radius $k$ on the runtime.
  In this short article, we add the missing lower bound necessary to determine the influence of parameter $k$ on the runtime. To this aim, we derive an exact description of the expected runtime, which also significantly improves the upper bound given by C. Doerr and Krejca. We also describe asymptotic estimates of the expected runtime.</description>
      <guid isPermaLink="false">oai:arXiv.org:2403.08153v1</guid>
      <category>cs.NE</category>
      <category>cs.AI</category>
      <category>cs.DS</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Benjamin Doerr, Andrew James Kelley</dc:creator>
    </item>
    <item>
      <title>A bargain for mergesorts (functional pearl) -- How to prove your mergesort correct and stable, almost for free</title>
      <link>https://arxiv.org/abs/2403.08173</link>
      <description>arXiv:2403.08173v1 Announce Type: cross 
Abstract: We present a novel characterization of stable mergesort functions using relational parametricity, and show that it implies the correctness of mergesort. As a result, one can prove the correctness of several variations of mergesort (e.g., top-down, bottom-up, tail-recursive, non-tail-recursive, smooth, and non-smooth mergesorts) by proving the characterization property for each variation. To further motivate this work, we show a performance trade-off between tail-recursive and non-tail-recursive mergesorts that (1) the former in call-by-value evaluation avoids using up stack space and is efficient and (2) the latter in call-by-need evaluation is an optimal incremental sort, meaning that it performs only $\mathcal{O}(n + k \log k)$ comparisons to compute the least (or greatest) $k$ items of a list of length $n$. Thanks to our characterization and the parametricity translation, we deduced the correctness results, including stability, of various implementations of mergesort for lists, including highly optimized ones, in the Coq proof assistant.</description>
      <guid isPermaLink="false">oai:arXiv.org:2403.08173v1</guid>
      <category>cs.LO</category>
      <category>cs.DS</category>
      <category>cs.PL</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Cyril Cohen, Kazuhiko Sakaguchi</dc:creator>
    </item>
    <item>
      <title>Terminal Embeddings in Sublinear Time</title>
      <link>https://arxiv.org/abs/2110.08691</link>
      <description>arXiv:2110.08691v3 Announce Type: replace 
Abstract: Recently (Elkin, Filtser, Neiman 2017) introduced the concept of a {\it terminal embedding} from one metric space $(X,d_X)$ to another $(Y,d_Y)$ with a set of designated terminals $T\subset X$. Such an embedding $f$ is said to have distortion $\rho\ge 1$ if $\rho$ is the smallest value such that there exists a constant $C&gt;0$ satisfying
  \begin{equation*}
  \forall x\in T\ \forall q\in X,\ C d_X(x, q) \le d_Y(f(x), f(q)) \le C \rho d_X(x, q) .
  \end{equation*}
  When $X,Y$ are both Euclidean metrics with $Y$ being $m$-dimensional, recently (Narayanan, Nelson 2019), following work of (Mahabadi, Makarychev, Makarychev, Razenshteyn 2018), showed that distortion $1+\epsilon$ is achievable via such a terminal embedding with $m = O(\epsilon^{-2}\log n)$ for $n := |T|$. This generalizes the Johnson-Lindenstrauss lemma, which only preserves distances within $T$ and not to $T$ from the rest of space. The downside of prior work is that evaluating their embedding on some $q\in \mathbb{R}^d$ required solving a semidefinite program with $\Theta(n)$ constraints in~$m$ variables and thus required some superlinear $\mathrm{poly}(n)$ runtime. Our main contribution in this work is to give a new data structure for computing terminal embeddings. We show how to pre-process $T$ to obtain an almost linear-space data structure that supports computing the terminal embedding image of any $q\in\mathbb{R}^d$ in sublinear time $O^* (n^{1-\Theta(\epsilon^2)} + d)$. To accomplish this, we leverage tools developed in the context of approximate nearest neighbor search.</description>
      <guid isPermaLink="false">oai:arXiv.org:2110.08691v3</guid>
      <category>cs.DS</category>
      <category>cs.CG</category>
      <category>cs.LG</category>
      <category>stat.ML</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <arxiv:DOI>10.46298/theoretics.24.6</arxiv:DOI>
      <arxiv:journal_reference>TheoretiCS, Volume 3 (2024), Article 6, 1-52</arxiv:journal_reference>
      <dc:creator>Yeshwanth Cherapanamjeri, Jelani Nelson</dc:creator>
    </item>
    <item>
      <title>Lower Bounds on the Complexity of Mixed-Integer Programs for Stable Set and Knapsack</title>
      <link>https://arxiv.org/abs/2308.16711</link>
      <description>arXiv:2308.16711v2 Announce Type: replace-cross 
Abstract: Standard mixed-integer programming formulations for the stable set problem on $n$-node graphs require $n$ integer variables. We prove that this is almost optimal: We give a family of $n$-node graphs for which every polynomial-size MIP formulation requires $\Omega(n/\log^2 n)$ integer variables. By a polyhedral reduction we obtain an analogous result for $n$-item knapsack problems. In both cases, this improves the previously known bounds of $\Omega(\sqrt{n}/\log n)$ by Cevallos, Weltge &amp; Zenklusen (SODA 2018).
  To this end, we show that there exists a family of $n$-node graphs whose stable set polytopes satisfy the following: any $(1+\varepsilon/n)$-approximate extended formulation for these polytopes, for some constant $\varepsilon &gt; 0$, has size $2^{\Omega(n/\log n)}$. Our proof extends and simplifies the information-theoretic methods due to G\"o\"os, Jain &amp; Watson (FOCS 2016, SIAM J. Comput. 2018) who showed the same result for the case of exact extended formulations (i.e. $\varepsilon = 0$).</description>
      <guid isPermaLink="false">oai:arXiv.org:2308.16711v2</guid>
      <category>cs.DM</category>
      <category>cs.DS</category>
      <category>math.OC</category>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Jamico Schade, Makrand Sinha, Stefan Weltge</dc:creator>
    </item>
  </channel>
</rss>
