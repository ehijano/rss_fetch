<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>cs.CE updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/cs.CE</link>
    <description>cs.CE updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/cs.CE" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Thu, 09 Oct 2025 01:43:56 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Wed, 08 Oct 2025 00:00:00 -0400</pubDate>
    <skipDays>
      <day>Saturday</day>
      <day>Sunday</day>
    </skipDays>
    <item>
      <title>Gaussian Ensemble Topology (GET): A New Explicit and Inherently Smooth Framework for Manufacture-Ready Topology Optimization</title>
      <link>https://arxiv.org/abs/2510.05572</link>
      <description>arXiv:2510.05572v1 Announce Type: new 
Abstract: We introduce the Gaussian Ensemble Topology (GET) method, a new explicit and manufacture-ready framework for topology optimization in which design geometries are represented as superpositions of anisotropic Gaussian functions. By combining explicit Gaussian descriptions with a level-set-like Heaviside projection, GET inherently generates smooth, curvature-continuous designs without requiring post-processing steps such as mesh or corner smoothing and feature extraction. The method is validated on standard compliance-minimization and compliant mechanism benchmarks in two and three dimensions. The optimized designs achieve objective values comparable to those obtained with classical Moving Morphable Component (MMC) approaches, but with geometrically consistent, refined boundaries. Numerical examples demonstrate additional advantages of the GET framework, including mesh independence inherent to explicit parameterizations, strong geometric expressiveness, and effective control over smoothness, discreteness, and structural complexity through parameter tuning. As a robust and manufacture-ready approach to explicit topology optimization, GET opens avenues for tackling advanced and complex design problems.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.05572v1</guid>
      <category>cs.CE</category>
      <pubDate>Wed, 08 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Xinyu Ma, Chengxin Wang, Meng Wang, Xu Guo, Liu Yang, Huajian Gao</dc:creator>
    </item>
    <item>
      <title>Physicochemically Informed Dual-Conditioned Generative Model of T-Cell Receptor Variable Regions for Cellular Therapy</title>
      <link>https://arxiv.org/abs/2510.05747</link>
      <description>arXiv:2510.05747v1 Announce Type: new 
Abstract: Physicochemically informed biological sequence generation has the potential to accelerate computer-aided cellular therapy, yet current models fail to \emph{jointly} ensure novelty, diversity, and biophysical plausibility when designing variable regions of T-cell receptors (TCRs). We present \textbf{PhysicoGPTCR}, a large generative protein Transformer that is \emph{dual-conditioned} on peptide and HLA context and trained to autoregressively synthesise TCR sequences while embedding residue-level physicochemical descriptors. The model is optimised on curated TCR--peptide--HLA triples with a maximum-likelihood objective and compared against ANN, GPTCR, LSTM, and VAE baselines. Across multiple neoantigen benchmarks, PhysicoGPTCR substantially improves edit-distance, similarity, and longest-common-subsequence scores, while populating a broader region of sequence space. Blind in-silico docking and structural modelling further reveal a higher proportion of binding-competent clones than the strongest baseline, validating the benefit of explicit context conditioning and physicochemical awareness. Experimental results demonstrate that dual-conditioned, physics-grounded generative modelling enables end-to-end design of functional TCR candidates, reducing the discovery timeline from months to minutes without sacrificing wet-lab verifiability.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.05747v1</guid>
      <category>cs.CE</category>
      <category>q-bio.BM</category>
      <pubDate>Wed, 08 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Jiahao Ma, Hongzong Li, Ye-Fan Hu, Jian-Dong Huang</dc:creator>
    </item>
    <item>
      <title>Code Smell Detection via Pearson Correlation and ML Hyperparameter Optimization</title>
      <link>https://arxiv.org/abs/2510.05835</link>
      <description>arXiv:2510.05835v1 Announce Type: new 
Abstract: This study addresses the challenge of detecting code smells in large-scale software systems using machine learning (ML). Traditional detection methods often suffer from low accuracy and poor generalization across different datasets. To overcome these issues, we propose a machine learning-based model that automatically and accurately identifies code smells, offering a scalable solution for software quality analysis. The novelty of our approach lies in the use of eight diverse ML algorithms, including XGBoost, AdaBoost, and other classifiers, alongside key techniques such as the Synthetic Minority Over-sampling Technique (SMOTE) for class imbalance and Pearson correlation for efficient feature selection. These methods collectively improve model accuracy and generalization. Our methodology involves several steps: first, we preprocess the data and apply SMOTE to balance the dataset; next, Pearson correlation is used for feature selection to reduce redundancy; followed by training eight ML algorithms and tuning hyperparameters through Grid Search, Random Search, and Bayesian Optimization. Finally, we evaluate the models using accuracy, F-measure, and confusion matrices. The results show that AdaBoost, Random Forest, and XGBoost perform best, achieving accuracies of 100%, 99%, and 99%, respectively. This study provides a robust framework for detecting code smells, enhancing software quality assurance, and demonstrating the effectiveness of a comprehensive, optimized ML approach.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.05835v1</guid>
      <category>cs.CE</category>
      <pubDate>Wed, 08 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Moinuddin Muhammad Imtiaz Bhuiyan, Kazi Ekramul Hoque, Rakibul Islam, Md. Mahbubur Rahman Tusher, Najmul Hassan, Yoichi Tomioka, Satoshi Nishimura, Jungpil Shin, Abu Saleh Musa Miah</dc:creator>
    </item>
    <item>
      <title>A comprehensive comparison of neural operators for 3D industry-scale engineering designs</title>
      <link>https://arxiv.org/abs/2510.05995</link>
      <description>arXiv:2510.05995v1 Announce Type: new 
Abstract: Neural operators have emerged as powerful tools for learning nonlinear mappings between function spaces, enabling real-time prediction of complex dynamics in diverse scientific and engineering applications. With their growing adoption in engineering design evaluation, a wide range of neural operator architectures have been proposed for various problem settings. However, model selection remains challenging due to the absence of fair and comprehensive comparisons. To address this, we propose and standardize six representative 3D industry-scale engineering design datasets spanning thermal analysis, linear elasticity, elasto-plasticity, time-dependent plastic problems, and computational fluid dynamics. All datasets include fully preprocessed inputs and outputs for model training, making them directly usable across diverse neural operator architectures. Using these datasets, we conduct a systematic comparison of four types of neural operator variants, including Branch-Trunk-based Neural Operators inspired by DeepONet, Graph-based Neural Operators inspired by Graph Neural Networks, Grid-based Neural Operators inspired by Fourier Neural Operators, and Point-based Neural Operators inspired by PointNet. We further introduce practical enhancements to adapt these models to different engineering settings, improving the fairness of the comparison. Our benchmarking study evaluates each model strengths and limitations in terms of predictive performance, computational efficiency, memory usage, and deployment complexity. The findings provide actionable insights to guide future neural operator development.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.05995v1</guid>
      <category>cs.CE</category>
      <pubDate>Wed, 08 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <dc:creator>Weiheng Zhong, Qibang Liu, Diab Abueidda, Seid Koric, Hadi Meidani</dc:creator>
    </item>
    <item>
      <title>Towards Structured Knowledge: Advancing Triple Extraction from Regional Trade Agreements using Large Language Models</title>
      <link>https://arxiv.org/abs/2510.05121</link>
      <description>arXiv:2510.05121v1 Announce Type: cross 
Abstract: This study investigates the effectiveness of Large Language Models (LLMs) for the extraction of structured knowledge in the form of Subject-Predicate-Object triples. We apply the setup for the domain of Economics application. The findings can be applied to a wide range of scenarios, including the creation of economic trade knowledge graphs from natural language legal trade agreement texts. As a use case, we apply the model to regional trade agreement texts to extract trade-related information triples. In particular, we explore the zero-shot, one-shot and few-shot prompting techniques, incorporating positive and negative examples, and evaluate their performance based on quantitative and qualitative metrics. Specifically, we used Llama 3.1 model to process the unstructured regional trade agreement texts and extract triples. We discuss key insights, challenges, and potential future directions, emphasizing the significance of language models in economic applications.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.05121v1</guid>
      <category>cs.CL</category>
      <category>cs.CE</category>
      <category>cs.IR</category>
      <category>cs.LG</category>
      <pubDate>Wed, 08 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Durgesh Nandini, Rebekka Koch, Mirco Schoenfeld</dc:creator>
    </item>
    <item>
      <title>Auditing Algorithmic Bias in Transformer-Based Trading</title>
      <link>https://arxiv.org/abs/2510.05140</link>
      <description>arXiv:2510.05140v1 Announce Type: cross 
Abstract: Transformer models have become increasingly popular in financial applications, yet their potential risk making and biases remain under-explored. The purpose of this work is to audit the reliance of the model on volatile data for decision-making, and quantify how the frequency of price movements affects the model's prediction confidence. We employ a transformer model for prediction, and introduce a metric based on Partial Information Decomposition (PID) to measure the influence of each asset on the model's decision making. Our analysis reveals two key observations: first, the model disregards data volatility entirely, and second, it is biased toward data with lower-frequency price movements.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.05140v1</guid>
      <category>cs.LG</category>
      <category>cs.CE</category>
      <pubDate>Wed, 08 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Armin Gerami, Ramani Duraiswami</dc:creator>
    </item>
    <item>
      <title>Lang-PINN: From Language to Physics-Informed Neural Networks via a Multi-Agent Framework</title>
      <link>https://arxiv.org/abs/2510.05158</link>
      <description>arXiv:2510.05158v1 Announce Type: cross 
Abstract: Physics-informed neural networks (PINNs) provide a powerful approach for solving partial differential equations (PDEs), but constructing a usable PINN remains labor-intensive and error-prone. Scientists must interpret problems as PDE formulations, design architectures and loss functions, and implement stable training pipelines. Existing large language model (LLM) based approaches address isolated steps such as code generation or architecture suggestion, but typically assume a formal PDE is already specified and therefore lack an end-to-end perspective. We present Lang-PINN, an LLM-driven multi-agent system that builds trainable PINNs directly from natural language task descriptions. Lang-PINN coordinates four complementary agents: a PDE Agent that parses task descriptions into symbolic PDEs, a PINN Agent that selects architectures, a Code Agent that generates modular implementations, and a Feedback Agent that executes and diagnoses errors for iterative refinement. This design transforms informal task statements into executable and verifiable PINN code. Experiments show that Lang-PINN achieves substantially lower errors and greater robustness than competitive baselines: mean squared error (MSE) is reduced by up to 3--5 orders of magnitude, end-to-end execution success improves by more than 50\%, and reduces time overhead by up to 74\%.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.05158v1</guid>
      <category>cs.AI</category>
      <category>cs.CE</category>
      <category>cs.LG</category>
      <category>cs.MA</category>
      <pubDate>Wed, 08 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Xin He, Liangliang You, Hongduan Tian, Bo Han, Ivor Tsang, Yew-Soon Ong</dc:creator>
    </item>
    <item>
      <title>AgentZero++: Modeling Fear-Based Behavior</title>
      <link>https://arxiv.org/abs/2510.05185</link>
      <description>arXiv:2510.05185v1 Announce Type: cross 
Abstract: We present AgentZero++, an agent-based model that integrates cognitive, emotional, and social mechanisms to simulate decentralized collective violence in spatially distributed systems. Building on Epstein's Agent\_Zero framework, we extend the original model with eight behavioral enhancements: age-based impulse control; memory-based risk estimation; affect-cognition coupling; endogenous destructive radius; fight-or-flight dynamics; affective homophily; retaliatory damage; and multi-agent coordination. These additions allow agents to adapt based on internal states, previous experiences, and social feedback, producing emergent dynamics such as protest asymmetries, escalation cycles, and localized retaliation. Implemented in Python using the Mesa ABM framework, AgentZero++ enables modular experimentation and visualization of how micro-level cognitive heterogeneity shapes macro-level conflict patterns. Our results highlight how small variations in memory, reactivity, and affective alignment can amplify or dampen unrest through feedback loops. By explicitly modeling emotional thresholds, identity-driven behavior, and adaptive networks, this work contributes a flexible and extensible platform for analyzing affective contagion and psychologically grounded collective action.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.05185v1</guid>
      <category>cs.MA</category>
      <category>cs.CE</category>
      <category>cs.CY</category>
      <category>cs.NE</category>
      <category>cs.SI</category>
      <pubDate>Wed, 08 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Vrinda Malhotra, Jiaman Li, Nandini Pisupati</dc:creator>
    </item>
    <item>
      <title>Intertemporal Pricing of Time-Bound Stablecoins: Measuring and Controlling the Liquidity-of-Time Premium</title>
      <link>https://arxiv.org/abs/2510.05711</link>
      <description>arXiv:2510.05711v1 Announce Type: cross 
Abstract: Time-bound stablecoins are DeFi assets that temporarily tokenize traditional securities during market off-hours, enabling continuous cross-market liquidity. We introduce the Liquidity-of-Time Premium (TLP): the extra return or cost of providing liquidity when the primary market is closed. We build a no-arbitrage pricing model that yields a band for fair values over different expiries, and a dynamic risk-control mechanism that adjusts loan-to-value (LTV) ratios in real time to keep TLP within a target range. Our analysis blends financial engineering (no-arbitrage conditions, option-style pricing) with empirical finance (event studies on cross-listed stocks and futures) to measure TLP under time-zone frictions. We define TLP formally, derive closed-form expressions for its term structure under idealized assumptions, and simulate scenarios that vary volatility and collateralization. We then propose an LTV policy that raises or lowers collateral to expand or curtail time-bound stablecoin supply, analogous to a central bank adjusting rates to defend a peg. We outline empirical proxies for TLP, including ADR premiums, overseas index futures versus cash index divergence, and pre-market versus official close gaps. Results show that TLP grows with closure length and volatility, yet can be contained by adaptive LTV. We provide backtests and figures (term-structure curves, capital-efficiency versus tail-risk trade-offs, time-liquidity heatmaps) and discuss protocol design (vault structure, closing-price oracles, on-chain auction liquidations). The findings position time-bound stablecoins as a tool to reduce temporal market inefficiencies and inform future research and deployment.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.05711v1</guid>
      <category>cs.DC</category>
      <category>cs.CE</category>
      <pubDate>Wed, 08 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <dc:creator>Ailiya Borjigin, Cong He</dc:creator>
    </item>
    <item>
      <title>Distributional Semantics Tracing: A Framework for Explaining Hallucinations in Large Language Models</title>
      <link>https://arxiv.org/abs/2510.06107</link>
      <description>arXiv:2510.06107v1 Announce Type: cross 
Abstract: Large Language Models (LLMs) are prone to hallucination, the generation of plausible yet factually incorrect statements. This work investigates the intrinsic, architectural origins of this failure mode through three primary contributions.First, to enable the reliable tracing of internal semantic failures, we propose \textbf{Distributional Semantics Tracing (DST)}, a unified framework that integrates established interpretability techniques to produce a causal map of a model's reasoning, treating meaning as a function of context (distributional semantics). Second, we pinpoint the model's layer at which a hallucination becomes inevitable, identifying a specific \textbf{commitment layer} where a model's internal representations irreversibly diverge from factuality. Third, we identify the underlying mechanism for these failures. We observe a conflict between distinct computational pathways, which we interpret using the lens of dual-process theory: a fast, heuristic \textbf{associative pathway} (akin to System 1) and a slow, deliberate \textbf{contextual pathway} (akin to System 2), leading to predictable failure modes such as \textit{Reasoning Shortcut Hijacks}. Our framework's ability to quantify the coherence of the contextual pathway reveals a strong negative correlation ($\rho = -0.863$) with hallucination rates, implying that these failures are predictable consequences of internal semantic weakness. The result is a mechanistic account of how, when, and why hallucinations occur within the Transformer architecture.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.06107v1</guid>
      <category>cs.CL</category>
      <category>cs.AI</category>
      <category>cs.CE</category>
      <pubDate>Wed, 08 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-sa/4.0/</dc:rights>
      <dc:creator>Gagan Bhatia, Somayajulu G Sripada, Kevin Allan, Jacobo Azcona</dc:creator>
    </item>
    <item>
      <title>A Generative Approach to Credit Prediction with Learnable Prompts for Multi-scale Temporal Representation Learning</title>
      <link>https://arxiv.org/abs/2404.13004</link>
      <description>arXiv:2404.13004v5 Announce Type: replace 
Abstract: Recent industrial credit scoring models remain heavily reliant on manually tuned statistical learning methods. Despite their potential, deep learning architectures have struggled to consistently outperform traditional statistical models in industrial credit scoring, largely due to the complexity of heterogeneous financial data and the challenge of modeling evolving creditworthiness. To bridge this gap, we introduce FinLangNet, a novel framework that reformulates credit scoring as a multi-scale sequential learning problem. FinLangNet processes heterogeneous financial data through a dual-module architecture that combines tabular feature extraction with temporal sequence modeling, generating probability distributions of users' future financial behaviors across multiple time horizons. A key innovation is our dual-prompt mechanism within the sequential module, which introduces learnable prompts operating at both feature-level granularity for capturing fine-grained temporal patterns and user-level granularity for aggregating holistic risk profiles. In extensive evaluations, FinLangNet significantly outperforms a production XGBoost system, achieving a 7.2% improvement in the KS metric and a 9.9% relative reduction in bad debt rate. Its effectiveness as a general-purpose sequential learning framework is further validated through state-of-the-art performance on the public UEA time series classification benchmark. The system has been successfully deployed on DiDi's international finance platform, serving leading financial credit companies in Latin America.</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.13004v5</guid>
      <category>cs.CE</category>
      <category>cs.AI</category>
      <pubDate>Wed, 08 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Yu Lei, Zixuan Wang, Yiqing Feng, Junru Zhang, Yahui Li, Chu Liu, Tongyao Wang</dc:creator>
    </item>
    <item>
      <title>Report of the 2025 Workshop on Next-Generation Ecosystems for Scientific Computing: Harnessing Community, Software, and AI for Cross-Disciplinary Team Science</title>
      <link>https://arxiv.org/abs/2510.03413</link>
      <description>arXiv:2510.03413v2 Announce Type: replace 
Abstract: This report summarizes insights from the 2025 Workshop on Next-Generation Ecosystems for Scientific Computing: Harnessing Community, Software, and AI for Cross-Disciplinary Team Science, which convened more than 40 experts from national laboratories, academia, industry, and community organizations to chart a path toward more powerful, sustainable, and collaborative scientific software ecosystems. To address urgent challenges at the intersection of high-performance computing (HPC), AI, and scientific software, participants envisioned agile, robust ecosystems built through socio-technical co-design--the intentional integration of social and technical components as interdependent parts of a unified strategy. This approach combines advances in AI, HPC, and software with new models for cross-disciplinary collaboration, training, and workforce development. Key recommendations include building modular, trustworthy AI-enabled scientific software systems; enabling scientific teams to integrate AI systems into their workflows while preserving human creativity, trust, and scientific rigor; and creating innovative training pipelines that keep pace with rapid technological change. Pilot projects were identified as near-term catalysts, with initial priorities focused on hybrid AI/HPC infrastructure, cross-disciplinary collaboration and pedagogy, responsible AI guidelines, and prototyping of public-private partnerships. This report presents a vision of next-generation ecosystems for scientific computing where AI, software, hardware, and human expertise are interwoven to drive discovery, expand access, strengthen the workforce, and accelerate scientific progress.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.03413v2</guid>
      <category>cs.CE</category>
      <category>cs.AI</category>
      <pubDate>Wed, 08 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Lois Curfman McInnes, Dorian Arnold, Prasanna Balaprakash, Mike Bernhardt, Beth Cerny, Anshu Dubey, Roscoe Giles, Denice Ward Hood, Mary Ann Leung, Vanessa Lopez-Marrero, Paul Messina, Olivia B. Newton, Chris Oehmen, Stefan M. Wild, Jim Willenbring, Lou Woodley, Tony Baylis, David E. Bernholdt, Chris Camano, Johannah Cohoon, Charles Ferenbaugh, Stephen M. Fiore, Sandra Gesing, Diego Gomez-Zara, James Howison, Tanzima Islam, David Kepczynski, Charles Lively, Harshitha Menon, Bronson Messer, Marieme Ngom, Umesh Paliath, Michael E. Papka, Irene Qualters, Elaine M. Raybourn, Katherine Riley, Paulina Rodriguez, Damian Rouson, Michelle Schwalbe, Sudip K. Seal, Ozge Surer, Valerie Taylor, Lingfei Wu</dc:creator>
    </item>
  </channel>
</rss>
