<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>cs.ET updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/cs.ET</link>
    <description>cs.ET updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/cs.ET" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Wed, 23 Oct 2024 04:00:12 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Wed, 23 Oct 2024 00:00:00 -0400</pubDate>
    <skipDays>
      <day>Sunday</day>
      <day>Saturday</day>
    </skipDays>
    <item>
      <title>Towards a Reliable Offline Personal AI Assistant for Long Duration Spaceflight</title>
      <link>https://arxiv.org/abs/2410.16397</link>
      <description>arXiv:2410.16397v1 Announce Type: cross 
Abstract: As humanity prepares for new missions to the Moon and Mars, astronauts will need to operate with greater autonomy, given the communication delays that make real-time support from Earth difficult. For instance, messages between Mars and Earth can take up to 24 minutes, making quick responses impossible. This limitation poses a challenge for astronauts who must rely on in-situ tools to access the large volume of data from spacecraft sensors, rovers, and satellites, data that is often fragmented and difficult to use. To bridge this gap, systems like the Mars Exploration Telemetry-Driven Information System (METIS) are being developed. METIS is an AI assistant designed to handle routine tasks, monitor spacecraft systems, and detect anomalies, all while reducing the reliance on mission control. Current Generative Pretrained Transformer (GPT) Models, while powerful, struggle in safety-critical environments. They can generate plausible but incorrect responses, a phenomenon known as "hallucination," which could endanger astronauts. To overcome these limitations, this paper proposes enhancing systems like METIS by integrating GPTs, Retrieval-Augmented Generation (RAG), Knowledge Graphs (KGs), and Augmented Reality (AR). The idea is to allow astronauts to interact with their data more intuitively, using natural language queries and visualizing real-time information through AR. KGs will be used to easily access live telemetry and multimodal data, ensuring that astronauts have the right information at the right time. By combining AI, KGs, and AR, this new system will empower astronauts to work more autonomously, safely, and efficiently during future space missions.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.16397v1</guid>
      <category>cs.AI</category>
      <category>cs.ET</category>
      <pubDate>Wed, 23 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Oliver Bensch, Leonie Bensch, Tommy Nilsson, Florian Saling, Wafa M. Sadri, Carsten Hartmann, Tobias Hecking, J. Nathan Kutz</dc:creator>
    </item>
    <item>
      <title>Resolvability of classical-quantum channels</title>
      <link>https://arxiv.org/abs/2410.16704</link>
      <description>arXiv:2410.16704v1 Announce Type: cross 
Abstract: Channel resolvability concerns the minimum resolution for approximating the channel output. We study the resolvability of classical-quantum channels in two settings, for the channel output generated from the worst input, and form the fixed independent and identically distributed (i.i.d.) input. The direct part of the worst-input setting is derived from sequential hypothesis testing as it involves of non-i.i.d.~inputs. The strong converse of the worst-input setting is obtained via the connection to identification codes. For the fixed-input setting, while the direct part follows from the known quantum soft covering result, we exploit the recent alternative quantum Sanov theorem to solve the strong converse.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.16704v1</guid>
      <category>quant-ph</category>
      <category>cs.ET</category>
      <category>cs.IT</category>
      <category>math.IT</category>
      <pubDate>Wed, 23 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Masahito Hayashi, Hao-Chung Cheng, Li Gao</dc:creator>
    </item>
    <item>
      <title>Lunar Subterra: a Self-Integrative Unit with an Automated Drilling System</title>
      <link>https://arxiv.org/abs/2410.17114</link>
      <description>arXiv:2410.17114v1 Announce Type: cross 
Abstract: As humans venture deeper into space, the need for a lunar settlement, housing the first group of settlers, grows steadily. By means of new technologies such as in situ resource utilisation (ISRU) as well as computational design, this goal can be implemented in present years. Providing the first arrivals with an immediate underground habitat safe from radiation and other environmental constraints is of crucial importance to initialise a prolonged mission on the Moon. The project's proposal revolves around the idea of establishing a base which provides an immediately habitable space with the possibility for future expansion. Advanced construction methods and sustainable practices lay the groundwork for a permanent human presence, predominantly based on ISRU. This paper outlines a two-phase initiative aimed at the foundation of the Lunar Subterra, followed by an extension of the habitat above ground. Following our collaboration with the PoliSpace Sparc Student Association group, a Virtual Reality (VR) reproduction of the proposed habitat enabled quick iterative testing of the habitable space with the use of a Meta Quest 2 headset. This not only allowed an evaluation of the environment and its impact on human residents but also eradicated the need for tangible models to conceptualise the idea, enabling rapid user-centred design and implementation in the future of space exploration.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.17114v1</guid>
      <category>cs.HC</category>
      <category>cs.ET</category>
      <pubDate>Wed, 23 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Anthony Sfeir, Asya Petkova, Sabine Chaaya, Karina Chichova, Marta Rossi, Anna Vock, Alessandro Mosut, Akshayanivasini Ramasamy Saravanaraj, Valentina Sumini, Tommy Nilsson</dc:creator>
    </item>
    <item>
      <title>Tactile Displays Driven by Projected Light</title>
      <link>https://arxiv.org/abs/2410.05494</link>
      <description>arXiv:2410.05494v2 Announce Type: replace 
Abstract: Tactile displays that lend tangible form to digital content could transform computing interactions. However, achieving the resolution, speed, and dynamic range needed for perceptual fidelity remains challenging. We present a tactile display that directly converts projected light into visible tactile patterns via a photomechanical surface populated with millimeter-scale optotactile pixels. The pixels transduce incident light into mechanical displacements through photostimulated thermal gas expansion, yielding millimeter scale displacements with response times of 2 to 100 milliseconds. Employing projected light for power transmission and addressing renders these displays highly scalable. We demonstrate devices with up to 1511 addressable pixels. Perceptual studies confirm that they can reproduce diverse spatiotemporal tactile patterns with high fidelity. This research establishes a foundation for practical, versatile high-resolution tactile displays driven by light.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.05494v2</guid>
      <category>cs.ET</category>
      <category>cs.HC</category>
      <category>cs.RO</category>
      <category>physics.optics</category>
      <pubDate>Wed, 23 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Max Linnander, Dustin Goetz, Gregory Reardon, Elliot Hawkes, Yon Visell</dc:creator>
    </item>
    <item>
      <title>Adversarial Challenges in Network Intrusion Detection Systems: Research Insights and Future Prospects</title>
      <link>https://arxiv.org/abs/2409.18736</link>
      <description>arXiv:2409.18736v3 Announce Type: replace-cross 
Abstract: Machine learning has brought significant advances in cybersecurity, particularly in the development of Intrusion Detection Systems (IDS). These improvements are mainly attributed to the ability of machine learning algorithms to identify complex relationships between features and effectively generalize to unseen data. Deep neural networks, in particular, contributed to this progress by enabling the analysis of large amounts of training data, significantly enhancing detection performance. However, machine learning models remain vulnerable to adversarial attacks, where carefully crafted input data can mislead the model into making incorrect predictions. While adversarial threats in unstructured data, such as images and text, have been extensively studied, their impact on structured data like network traffic is less explored. This survey aims to address this gap by providing a comprehensive review of machine learning-based Network Intrusion Detection Systems (NIDS) and thoroughly analyzing their susceptibility to adversarial attacks. We critically examine existing research in NIDS, highlighting key trends, strengths, and limitations, while identifying areas that require further exploration. Additionally, we discuss emerging challenges in the field and offer insights for the development of more robust and resilient NIDS. In summary, this paper enhances the understanding of adversarial attacks and defenses in NIDS and guide future research in improving the robustness of machine learning models in cybersecurity applications.</description>
      <guid isPermaLink="false">oai:arXiv.org:2409.18736v3</guid>
      <category>cs.CR</category>
      <category>cs.ET</category>
      <category>cs.NI</category>
      <pubDate>Wed, 23 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Sabrine Ennaji, Fabio De Gaspari, Dorjan Hitaj, Alicia Kbidi, Luigi V. Mancini</dc:creator>
    </item>
  </channel>
</rss>
