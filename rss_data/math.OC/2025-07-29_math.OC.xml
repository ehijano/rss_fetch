<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>math.OC updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/math.OC</link>
    <description>math.OC updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/math.OC" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Tue, 29 Jul 2025 04:01:34 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Tue, 29 Jul 2025 00:00:00 -0400</pubDate>
    <skipDays>
      <day>Sunday</day>
      <day>Saturday</day>
    </skipDays>
    <item>
      <title>Linearizations and optimization problems in diffeological spaces</title>
      <link>https://arxiv.org/abs/2507.19508</link>
      <description>arXiv:2507.19508v1 Announce Type: new 
Abstract: By generalizing the notion of linearization, a concept originally arising from microlocal analysis and symbolic calculus, to diffeological spaces, we make a first proposal setting for optimization problems in this category.
  We show how linearizations allow the construction of smooth paths and variational flows without requiring canonical charts or gradients. With these constructions, we introduce a general optimization algorithm adapted to diffeological spaces under weakened assumptions. The method applies to spaces of mappings with low regularity.
  Our results show that weak convergence toward minima or critical values can still be achieved under diffeological conditions. The approach extends classical variational methods into a flexible, non-linear infinite-dimensional framework. Preliminary steps to the search for fixed points of diffeological mappings are discussed.</description>
      <guid isPermaLink="false">oai:arXiv.org:2507.19508v1</guid>
      <category>math.OC</category>
      <category>math.DG</category>
      <pubDate>Tue, 29 Jul 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Jean-Pierre Magnot</dc:creator>
    </item>
    <item>
      <title>On Bauschke-Bendit-Moursi modulus of averagedness and classifications of averaged nonexpansive operators</title>
      <link>https://arxiv.org/abs/2507.19533</link>
      <description>arXiv:2507.19533v1 Announce Type: new 
Abstract: Averaged operators are important in Convex Analysis and Optimization Algorithms. In this paper, we propose classifications of averaged operators, firmly nonexpansive operators, and proximal operators using the Bauschke-Bendit-Moursi modulus of averagedness. We show that if an operator is averaged with a constant less than 1/2, then it is a bi-Lipschitz homeomorphism. Amazingly the proximal operator of a convex function has its modulus of averagedness less than 1/2 if and only if the function is Lipschitz smooth. Some results on the averagedness of operator compositions are obtained. Explicit formulae for calculating the modulus of averagedness of resolvents and proximal operators in terms of various values associated with the maximally monotone operator or subdifferential are also given. Examples are provided to illustrate our results.</description>
      <guid isPermaLink="false">oai:arXiv.org:2507.19533v1</guid>
      <category>math.OC</category>
      <category>math.FA</category>
      <pubDate>Tue, 29 Jul 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Shuang Song, Xianfu Wang</dc:creator>
    </item>
    <item>
      <title>Rural School Bus Routing and Scheduling</title>
      <link>https://arxiv.org/abs/2507.19538</link>
      <description>arXiv:2507.19538v1 Announce Type: new 
Abstract: Long school bus rides adversely affect student performance and well-being. Rural school bus rides are particularly long, incentivizing parents to drive their children to school rather than to opt for the school bus. This in turn exacerbates the traffic congestion around schools, further compounding the problem of long bus rides, creating a vicious cycle. It also results in underutilized school buses and higher bus operating costs per rider. To address these challenges, this paper focuses on the design of rural school bus routes and schedules, a particularly challenging problem due to its unique operational complexities, including mixed loading and irregular road networks. We formalize a rural school bus routing and scheduling model that tackles these complexities while minimizing the total bus ride time of students. We develop an original road network-aware cluster-then-route heuristic that leverages our problem formulation to produce high-quality solutions. For real-world case studies, our approach outperforms status quo solutions by reducing the bus ride times of students by 37-39 %. Our solutions also make the school bus more attractive, helping address both the underutilization of school buses and the prevalence of private commutes. Our routing and scheduling approach can improve school bus use by 17-19 % and reduce car trips that induce congestion near schools by 12-17 %. Many rural school districts share the operational characteristics modeled in this study, including long bus rides, high operational expenditures, mixed loading, and a high proportion of car-based school commutes, suggesting the broad applicability of our approach. Ultimately, by reducing student travel times, increasing school bus utilization, and alleviating congestion near schools, our approach enables rural school district planners to address transportation-related barriers to student performance and well-being.</description>
      <guid isPermaLink="false">oai:arXiv.org:2507.19538v1</guid>
      <category>math.OC</category>
      <category>cs.CY</category>
      <pubDate>Tue, 29 Jul 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Prabhat Hegde, Vikrant Vaze</dc:creator>
    </item>
    <item>
      <title>A Global-Local Optimization Approach for Asynchronous SAR ADC Design</title>
      <link>https://arxiv.org/abs/2507.19541</link>
      <description>arXiv:2507.19541v1 Announce Type: new 
Abstract: This paper presents a system-level optimization framework for automated asynchronous SAR ADC design, addressing the limitations of block-level methods in terms of suboptimal performance and manual effort. The proposed approach integrates a fast global optimizer with a multi-fidelity local optimizer to efficiently handle high-dimensionality and expensive simulation cost. Experimental results from 12 design cases, covering 7- and 12-bit resolutions and a frequency range of 100 kHz to 250 MHz, demonstrate highly competitive performance compared with prior works.</description>
      <guid isPermaLink="false">oai:arXiv.org:2507.19541v1</guid>
      <category>math.OC</category>
      <pubDate>Tue, 29 Jul 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Yijia Hao, Ken Li, Miguel Gandara, Shaolan Li, Bo Liu</dc:creator>
    </item>
    <item>
      <title>Time-optimal synchronisation to self-sustained oscillations under bounded control</title>
      <link>https://arxiv.org/abs/2507.19560</link>
      <description>arXiv:2507.19560v1 Announce Type: new 
Abstract: Incorporating force bounds is crucial for realistic control implementations in physical systems. In this Letter, we investigate the fastest possible synchronisation of a Li\'enard system to its limit cycle using a bounded external force. To tackle this challenging non-linear optimal control problem, our approach involves applying Pontryagin's Maximum Principle with a combination of analytical and numerical tools. We show that the optimal control develops a remarkably complex structure in phase space as the force bound is lowered. Trajectories rewound from the limit cycle's extreme points turn out to play a key role in determining the maximum number of control bangs for optimal connection. We illustrate these intricate features using the paradigmatic van der Pol oscillator model.</description>
      <guid isPermaLink="false">oai:arXiv.org:2507.19560v1</guid>
      <category>math.OC</category>
      <pubDate>Tue, 29 Jul 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>C. R\'ios-Monje, C. A. Plata, D. Gu\'ery-Odelin, A. Prados</dc:creator>
    </item>
    <item>
      <title>Long-Duration Station-Keeping Strategy for Cislunar Spacecraft Formations</title>
      <link>https://arxiv.org/abs/2507.19620</link>
      <description>arXiv:2507.19620v1 Announce Type: new 
Abstract: This paper demonstrates a novel guidance and control strategy for cislunar near-rectilinear halo orbit formation-keeping applied to high-fidelity dynamics. Bounded relative motion is constructed about long-duration ephemeris trajectories with osculating invariant circles to form quasi-periodic relative orbits. State-of-the-art absolute control strategies are paired with a simple and effective relative control feedback law. Finally, a control barrier function is implemented to ensure recursively passively-safe bounded relative motion under feedback in the presence of possible missed maneuver events for the duration of the formation flight. The strategy is verified in high-fidelity simulation environments through Monte Carlo trials.</description>
      <guid isPermaLink="false">oai:arXiv.org:2507.19620v1</guid>
      <category>math.OC</category>
      <category>cs.SY</category>
      <category>eess.SY</category>
      <category>math.DS</category>
      <pubDate>Tue, 29 Jul 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Ethan Foss, Yuji Takubo, Simone D'Amico</dc:creator>
    </item>
    <item>
      <title>Hierarchical clustering and dimensional reduction for optimal control of large-scale agent-based models</title>
      <link>https://arxiv.org/abs/2507.19644</link>
      <description>arXiv:2507.19644v1 Announce Type: new 
Abstract: Agent-based models (ABMs) provide a powerful framework to describe complex systems composed of interacting entities, capable of producing emergent collective behaviours such as consensus formation or clustering. However, the increasing dimensionality of these models -- in terms of both the number of agents and the size of their state space -- poses significant computational challenges, particularly in the context of optimal control. In this work, we propose a scalable control frame work for large-scale ABMs based on a twofold model order reduction strategy: agent clustering and projection-based reduction via Proper Orthogonal Decomposition (POD). These techniques are integrated into a feedback loop that enables the design and application of optimal control laws over a reduced-order representation of the system. To illustrate the effectiveness of the approach, we consider the opinion dynamics model, a prototyp ical first-order ABM where agents interact through state-dependent influence functions. We show that our method significantly improves control efficiency, even in scenarios where direct control fails due to model complexity. Beyond its methodological contributions, this work also highlights the rel evance of opinion dynamics models in environmental contexts -- for example, modeling the diffusion of pro-environmental attitudes or decision-making processes in sustainable policy adoption -- where controlling consensus formation plays a crucial role.</description>
      <guid isPermaLink="false">oai:arXiv.org:2507.19644v1</guid>
      <category>math.OC</category>
      <category>cs.NA</category>
      <category>math.NA</category>
      <pubDate>Tue, 29 Jul 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Angela Monti, Fasma Diele, Dante Kalise</dc:creator>
    </item>
    <item>
      <title>Ultracoarse Equilibria and Ordinal-Folding Dynamics in Operator-Algebraic Models of Infinite Multi-Agent Games</title>
      <link>https://arxiv.org/abs/2507.19694</link>
      <description>arXiv:2507.19694v1 Announce Type: new 
Abstract: We develop an operator algebraic framework for infinite games with a continuum of agents and prove that regret based learning dynamics governed by a noncommutative continuity equation converge to a unique quantal response equilibrium under mild regularity assumptions. The framework unifies functional analysis, coarse geometry and game theory by assigning to every game a von Neumann algebra that represents collective strategy evolution. A reflective regret operator within this algebra drives the flow of strategy distributions and its fixed point characterises equilibrium. We introduce the ordinal folding index, a computable ordinal valued metric that measures the self referential depth of the dynamics, and show that it bounds the transfinite time needed for convergence, collapsing to zero on coarsely amenable networks. The theory yields new invariant subalgebra rigidity results, establishes existence and uniqueness of envy free and maximin share allocations in continuum economies, and links analytic properties of regret flows with empirical stability phenomena in large language models. These contributions supply a rigorous mathematical foundation for large scale multi agent systems and demonstrate the utility of ordinal metrics for equilibrium selection.</description>
      <guid isPermaLink="false">oai:arXiv.org:2507.19694v1</guid>
      <category>math.OC</category>
      <category>cs.AI</category>
      <category>cs.GT</category>
      <category>cs.MA</category>
      <pubDate>Tue, 29 Jul 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Faruk Alpay, Hamdi Alakkad, Bugra Kilictas, Taylan Alpay</dc:creator>
    </item>
    <item>
      <title>Stackelberg stopping games</title>
      <link>https://arxiv.org/abs/2507.19746</link>
      <description>arXiv:2507.19746v1 Announce Type: new 
Abstract: We study a Stackelberg variant of the classical Dynkin game in discrete time, where the two players are no longer on equal footing. Player 1 (the leader) announces her stopping strategy first, and Player 2 (the follower) responds optimally. This Stackelberg stopping game can be viewed as an optimal control problem for the leader. Our primary focus is on the time-inconsistency that arises from the leader-follower game structure. We begin by using a finite-horizon example to clarify key concepts, including precommitment and equilibrium strategies in the Stackelberg setting, as well as the Nash equilibrium in the standard Dynkin game. We then turn to the infinite-horizon case and study randomized precommitment and equilibrium strategies. We provide a characterization for the leader's value induced by precommitment strategies and show that it may fail to attain the supremum. Moreover, we construct a counterexample to demonstrate that a randomized equilibrium strategy may not exist. Then we introduce an entropy-regularized Stackelberg stopping game, in which the follower's optimization is regularized with an entropy term. This modification yields a continuous best response and ensures the existence of a regular randomized equilibrium strategy, which can be viewed as an approximation of the exact equilibrium.</description>
      <guid isPermaLink="false">oai:arXiv.org:2507.19746v1</guid>
      <category>math.OC</category>
      <pubDate>Tue, 29 Jul 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Jingjie Zhang, Zhou Zhou</dc:creator>
    </item>
    <item>
      <title>Computing optimal policies for managing inventories with noisy observations</title>
      <link>https://arxiv.org/abs/2507.19765</link>
      <description>arXiv:2507.19765v1 Announce Type: new 
Abstract: This paper implements the Deep Deterministic Policy Gradient (DDPG) algorithm for computing optimal policies for partially observable single-product periodic review inventory control problems with setup costs and backorders. The decision maker does not know the exact inventory level, but can obtain noise-corrupted observations of them. The goal is to maximize the expected total discounted costs incurred over a finite planning horizon. We also investigate the Gaussian version of this problem with normally distributed initial inventories, demands, and observation noise. We show that expected posterior observations of inventory levels, also called mean beliefs, provide sufficient statistics for the Gaussian problem. Moreover, they can be represented in the form of a Markov Decision Processes for an inventory control system with time-dependent holding costs and demands. Thus, for a Gaussian problem, the there exist (s_t,S_t)-optimal policies based on mean beliefs, and this fact explains the structure of the approximately optimal policies computed by DDPG. For the Gaussian case, we also numerically compare the performance of policies derived from DDPG to optimal policies for discretized versions of the original continuous problem.</description>
      <guid isPermaLink="false">oai:arXiv.org:2507.19765v1</guid>
      <category>math.OC</category>
      <pubDate>Tue, 29 Jul 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Eugene Feinberg, Jefferson Huang, Pavlo Kasyanov, Thomas O'Neill</dc:creator>
    </item>
    <item>
      <title>\(H_2/H_\infty\) Control for Continuous-Time Mean-Field Stochastic Systems with Affine Terms</title>
      <link>https://arxiv.org/abs/2507.19809</link>
      <description>arXiv:2507.19809v1 Announce Type: new 
Abstract: This paper discusses the \( H_2/H_{\infty} \) control problem for continuous-time mean-field linear stochastic systems with affine terms over a finite horizon. We employ the Mean-Field Stochastic Bounded Real Lemma (MF-SBRL), which provides the necessary and sufficient conditions to ensure that the \( H_{\infty} \) norm of system perturbations remains below a certain level. By utilizing the Mean-Field Forward-Backward Stochastic Differential Equations (MF-FBSDE), we establish the equivalence conditions for open-loop \( H_2/H_{\infty} \) control strategies. Furthermore, the paper demonstrates that the control problem is solvable under closed-loop conditions if solutions exist for four coupled Difference Riccati Equations (CDREs), two sets of backward stochastic differential equations (BSDEs) and ordinary equations (ODEs). The state-feedback gains for the control strategy can be derived from these solutions, thereby linking the feasibility of open-loop and closed-loop solutions.</description>
      <guid isPermaLink="false">oai:arXiv.org:2507.19809v1</guid>
      <category>math.OC</category>
      <pubDate>Tue, 29 Jul 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-sa/4.0/</dc:rights>
      <dc:creator>Xuling Fang, Jun Moon, Maoning Tang, Qingxin Meng</dc:creator>
    </item>
    <item>
      <title>Nonconvex Optimization Framework for Group-Sparse Feedback Linear-Quadratic Optimal Control. II: Non-Penalty Approach</title>
      <link>https://arxiv.org/abs/2507.19895</link>
      <description>arXiv:2507.19895v1 Announce Type: new 
Abstract: This work is a companion paper of [8], where the distributed linear-quadratic problem with fixed communication topology (DFT-LQ) and the sparse feedback LQ problem (SF-LQ) are formulated into a nonsmooth and nonconvex optimization problem with affine constraints. Moreover, a penalty approach is considered in \cite{feng-part1}, and the PALM (proximal alternating linearized minimization) algorithm is studied with convergence and complexity analysis. In this paper, we aim to address the inherent drawbacks of the penalty approach, such as the challenge of tuning the penalty parameter and the risk of introducing spurious stationary points. Specifically, we first reformulate the SF-LQ problem and the DFT-LQ problem from an epi-composition function perspective, aiming to solve the constrained problem directly. Then, from a theoretical viewpoint, we revisit the alternating direction method of multipliers (ADMM) and establish its convergence to the set of cluster points under certain assumptions. When these assumptions do not hold, we can effectively utilize alternative approaches combining subgradient descent with Difference-of-Convex relaxation methods. In summary, our results enable the direct design of group-sparse feedback gains with theoretical guarantees, without resorting to convex surrogates, restrictive structural assumptions, or penalty formulations that incorporate constraints into the cost function.</description>
      <guid isPermaLink="false">oai:arXiv.org:2507.19895v1</guid>
      <category>math.OC</category>
      <category>cs.LG</category>
      <pubDate>Tue, 29 Jul 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Lechen Feng, Xun Li, Yuan-Hua Ni</dc:creator>
    </item>
    <item>
      <title>Self-protection and self-insurance for general risk models via a BSDE approach</title>
      <link>https://arxiv.org/abs/2507.19959</link>
      <description>arXiv:2507.19959v1 Announce Type: new 
Abstract: We investigate an optimal prevention and insurance problem in a general risk setting, where a representative agent is exposed to potential losses. The agent adopts a strategy that combines self-protection, aimed at reducing the frequency of claims, and self-insurance, aimed at mitigating their severity. The problem, which consists in maximizing the expected exponential utility of terminal wealth, is formulated as a stochastic control problem and solved by means of backward stochastic differential equations (BSDEs). Our approach, essentially based on a general Bellman Optimality Principle (see [13] among others), does not require specification of the underlying filtration structure, making it applicable to a broad class of risk models, including Markov-modulated, stochastic factor, Cox-shot noise and self-excited models. We extend recent results by [3, 5], which focused on self-protection in specific models, by allowing for both self-protection and self-insurance within a unified and general framework.</description>
      <guid isPermaLink="false">oai:arXiv.org:2507.19959v1</guid>
      <category>math.OC</category>
      <pubDate>Tue, 29 Jul 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Claudia Ceci, Alessandra Cretarola</dc:creator>
    </item>
    <item>
      <title>A Convex Optimization Approach to Model-Free Inverse Optimal Control with Provable Convergence</title>
      <link>https://arxiv.org/abs/2507.19965</link>
      <description>arXiv:2507.19965v1 Announce Type: new 
Abstract: Inverse Optimal Control (IOC) aims to infer the underlying cost functional of an agent from observations of its expert behavior. This paper focuses on the IOC problem within the continuous-time linear quadratic regulator framework, specifically addressing the challenging scenario where both the system dynamics and the cost functional weighting matrices are unknown. A significant limitation of existing methods for this joint estimation problem is the lack of rigorous theoretical guarantees on the convergence and convergence rate of their optimization algorithms, which restricts their application in safety-critical systems. To bridge this theoretical gap, we propose an analytical framework for IOC that provides such guarantees. The core contribution lies in the equivalent reformulation of this non-convex problem of jointly estimating system and cost parameters into a convex second-order cone programming problem. Building on this transformation, we design an efficient iterative solver based on the block successive upper-bound minimization algorithm. We rigorously prove that the proposed algorithm achieves a sublinear convergence rate of $\mathcal{O}(1/k)$. To the best of our knowledge, this is the first solution for the model-free IOC problem that comes with an explicit convergence rate guarantee. Finally, comparative simulation experiments against a state-of-the-art benchmark algorithm validate the superiority of our proposed method. The results demonstrate that our algorithm achieves an order-of-magnitude improvement in convergence speed while also exhibiting significant advantages in reconstruction accuracy and robustness.</description>
      <guid isPermaLink="false">oai:arXiv.org:2507.19965v1</guid>
      <category>math.OC</category>
      <pubDate>Tue, 29 Jul 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Meiling Yu, Lechen Feng, Lei Jiang, Yuan-Hua Ni</dc:creator>
    </item>
    <item>
      <title>A general perspective on CBO methods with stochastic rate of information</title>
      <link>https://arxiv.org/abs/2507.20029</link>
      <description>arXiv:2507.20029v1 Announce Type: new 
Abstract: This paper studies a class of Consensus-Based Optimization (CBO) models featuring an additional stochastic rate of information, modeling the agents' knowledge of the environment and energy landscape. The well-posedness of the stochastic system is proved, together with its finite-particle approximation and the mean-field convergence to a kinetic PDE. Particles are shown to concentrate around the consensus point under mild assumptions on the initial spatial distribution and initial level of knowledge. In particular, the analysis unveils that a positive, however small, initial level of knowledge is enough for convergence to consensus to happen. The framework presented is general enough to include the first instances of CBO proposed in the literature.</description>
      <guid isPermaLink="false">oai:arXiv.org:2507.20029v1</guid>
      <category>math.OC</category>
      <category>math.AP</category>
      <pubDate>Tue, 29 Jul 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Stefano Almi, Alessandro Baldi, Marco Morandotti, Francesco Solombrino</dc:creator>
    </item>
    <item>
      <title>Fully Coupled Nonlinear FBS$\Delta$Es: Maximum principle and LQ Control Insights</title>
      <link>https://arxiv.org/abs/2507.20075</link>
      <description>arXiv:2507.20075v1 Announce Type: new 
Abstract: This paper investigates the optimal control problem for a class of nonlinear fully coupled forward-backward stochastic difference equations (FBS$\Delta$Es). Under the convexity assumption of the control domain, we establish a variational formula for the cost functional involving the Hamiltonian and adjoint system. Both necessary and sufficient conditions for optimal control are derived using the Pontryagin maximum principle. As an application, we present a linear quadratic optimal control problem to illustrate our theoretical results.</description>
      <guid isPermaLink="false">oai:arXiv.org:2507.20075v1</guid>
      <category>math.OC</category>
      <pubDate>Tue, 29 Jul 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-sa/4.0/</dc:rights>
      <dc:creator>Zhipeng Niu, Jun Moon, Qingxin Meng</dc:creator>
    </item>
    <item>
      <title>A direct approach of the existence of the solution to a Riccati equation</title>
      <link>https://arxiv.org/abs/2507.20171</link>
      <description>arXiv:2507.20171v1 Announce Type: new 
Abstract: Finding the state feedback control in an $% H^{\infty }$-optimal control problem involves a challenging approach of the associated algebraic Riccati equation of the generic form $A^{\ast }P+PA+P\Gamma P=F$. In view of this objective, we explore first in this paper the existence of the solution to this algebraic Riccati equation by a direct operatorial approach in the space of Hilbert-Schmidt operators. The proofs are provided, under certain assumptions on the operators $\Gamma $ and $F,$ for the cases with $A$ coercive and $A\geq 0,$ respectively. Next, relying on the existence of the solution to the Riccati equation, we provide a result concerning the associated $H^{\infty }$-optimal control problem. An example regarding the application of the existence proof for the solution to the Riccati equation is given for a parabolic equation with a singular potential of Hardy type.</description>
      <guid isPermaLink="false">oai:arXiv.org:2507.20171v1</guid>
      <category>math.OC</category>
      <category>math.AP</category>
      <pubDate>Tue, 29 Jul 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Gabriela Marinoschi</dc:creator>
    </item>
    <item>
      <title>Multiobjective Accelerated Gradient-like Flow with Asymptotic Vanishing Normalized Gradient</title>
      <link>https://arxiv.org/abs/2507.20183</link>
      <description>arXiv:2507.20183v1 Announce Type: new 
Abstract: In this paper, we extend the gradient system with unit-norm gradient term modification proposed by Wang et al.\cite{wang2021search} to multiobjective optimization, studying the following system: $$ \ddot x(t)+\frac{\alpha }{t}\dot x(t)+\frac{\alpha -\beta }{t^p}\frac{\|\dot x(t)\|}{\|\proj_{C(x(t))}(0)\|}\proj_{C(x(t))}(0)+\proj_{C(x(t))}(-\ddot x(t))=0 $$ where $C(x(t))=\textbf{conv}\{\nabla f_i(x(t)):i=1,\cdots,m\}$, $f_i(x(t)):\R^n\to \R$ are continuously differentiable convex functions, and $\alpha \ge \beta \ge 3$. Under certain assumptions, we establish the existence of trajectory solutions for this system. Using a merit function, we characterize the convergence of trajectory solutions: For $p&gt;1$, $\alpha &gt;\beta \ge 3$, we obtain a convergence rate of $O(1/t^2)$. When $\beta &gt;3$, the trajectory solutions converge to a weak Pareto solution of the multiobjective optimization problem $\min _{x}(f_1(x),\cdots,f_m(x))^\top$. For $p=1$, $\alpha &gt;\beta \ge 3$, we derive a convergence rate of $O(\ln^2 t/t^2)$. We further generalize Wang et al.'s FISC-nes algorithm to multiobjective optimization, achieving a convergence rate of $O(\ln^2k/k^2)$. The numerical experiments demonstrate that our system and algorithm exhibit competitive performance.</description>
      <guid isPermaLink="false">oai:arXiv.org:2507.20183v1</guid>
      <category>math.OC</category>
      <pubDate>Tue, 29 Jul 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Yingdong Yin</dc:creator>
    </item>
    <item>
      <title>On the Finiteness Property of the Polynomial Complementarity Problem</title>
      <link>https://arxiv.org/abs/2507.20339</link>
      <description>arXiv:2507.20339v1 Announce Type: new 
Abstract: This paper explores the finiteness of the solution set of the polynomial complementarity problem (PCP). To achieve this goal, we introduce two new classes of structured tensor tuples, namely the nondegenerate tensor tuple and the strong nondegenerate tensor tuple, as a generalization of nondegenerate tensors, and discuss their properties and interconnections. We investigate the finiteness of the solution set of the PCP in the context of these structured tensor tuples and establish a sufficient condition that guarantees a finite solution set. As a consequence, we establish a result related to the finiteness of the solution set of tensor complementarity problems.</description>
      <guid isPermaLink="false">oai:arXiv.org:2507.20339v1</guid>
      <category>math.OC</category>
      <pubDate>Tue, 29 Jul 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Sonali Sharma, V. Vetrivel</dc:creator>
    </item>
    <item>
      <title>The Augmented Mixing Method: Computing High-Accuracy Primal-Dual Solutions to Large-Scale SDPs via Column Updates</title>
      <link>https://arxiv.org/abs/2507.20386</link>
      <description>arXiv:2507.20386v1 Announce Type: new 
Abstract: The Burer-Monteiro factorization has become a powerful tool for solving large-scale semidefinite programs (SDPs), enabling recently developed low-rank solvers to tackle problems previously beyond reach. However, existing methods are typically designed to prioritize scalability over solution accuracy. We introduce the Augmented Mixing Method, a new algorithm that combines the Burer-Monteiro factorization with an inexact augmented Lagrangian framework and a block coordinate descent scheme. Our method emphasizes solving the resulting subproblems efficiently and to high precision. Inequality constraints are handled directly, without reformulation or introducing slack variables. A novel dynamic update strategy for the penalty parameter ensures that primal and dual feasibility progress remain balanced. This approach enables our method to compute highly accurate primal-dual solutions, even for large-scale SDPs with more than ten million inequality constraints. Despite lacking theoretical convergence guarantees, the Augmented Mixing Method shows strong practical performance with default parameters, across a wide range of SDP instances. It often produces more accurate primal-dual solutions than state-of-the-art interior-point methods and scales significantly better. Our open-source Julia implementation is memory-efficient, customizable, and supports arbitrary-precision arithmetic.</description>
      <guid isPermaLink="false">oai:arXiv.org:2507.20386v1</guid>
      <category>math.OC</category>
      <pubDate>Tue, 29 Jul 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Daniel Brosch, Jan Schwiddessen, Angelika Wiegele</dc:creator>
    </item>
    <item>
      <title>Beyond Value Functions: Single-Loop Bilevel Optimization under Flatness Conditions</title>
      <link>https://arxiv.org/abs/2507.20400</link>
      <description>arXiv:2507.20400v1 Announce Type: new 
Abstract: Bilevel optimization, a hierarchical optimization paradigm, has gained significant attention in a wide range of practical applications, notably in the fine-tuning of generative models. However, due to the nested problem structure, most existing algorithms require either the Hessian vector calculation or the nested loop updates, which are computationally inefficient in large language model (LLM) fine-tuning. In this paper, building upon the fully first-order penalty-based approach, we propose an efficient value function-free (PBGD-Free) algorithm that eliminates the loop of solving the lower-level problem and admits fully single-loop updates. Inspired by the landscape analysis of representation learning-based LLM fine-tuning problem, we propose a relaxed flatness condition for the upper-level function and prove the convergence of the proposed value-function-free algorithm. We test the performance of the proposed algorithm in various applications and demonstrate its superior computational efficiency over the state-of-the-art bilevel methods.</description>
      <guid isPermaLink="false">oai:arXiv.org:2507.20400v1</guid>
      <category>math.OC</category>
      <pubDate>Tue, 29 Jul 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Liuyuan Jiang, Quan Xiao, Lisha Chen, Tianyi Chen</dc:creator>
    </item>
    <item>
      <title>Relax-and-Cut for Temporal SCUC Decomposition</title>
      <link>https://arxiv.org/abs/2507.20465</link>
      <description>arXiv:2507.20465v1 Announce Type: new 
Abstract: The Security-Constrained Unit Commitment (SCUC) problem presents formidable computational challenges due to its combinatorial complexity, large-scale network dimensions, and numerous security constraints. While conventional temporal decomposition methods achieve computational tractability through fixed short-term time windows, this limited look-ahead capability often results in suboptimal, myopic solutions. We propose an innovative relax-and-cut framework that alleviates these limitations through two key innovations. First, our enhanced temporal decomposition strategy maintains integer variables for immediate unit commitment decisions while relaxing integrality constraints for future time periods, thereby extending the optimization horizon without compromising tractability. Second, we develop a dynamic cutting-plane mechanism that selectively incorporates N-1 contingency constraints during the branch-and-cut process, avoiding the computational burden of complete upfront enumeration. The framework optionally employs a Relaxation-Induced Neighborhood Search procedure for additional solution refinement when computational resources permit. Comprehensive numerical experiments demonstrate the effectiveness of our approach on large-scale systems up to 13,000 buses. The proposed method can achieve optimality gaps below 1% while requiring only 20% of the computation time of monolithic Gurobi solutions. Compared to existing decomposition approaches, our framework provides superior performance, simultaneously reducing primal gaps by 60% and doubling solution speed. These significant improvements make our method particularly well-suited for practical SCUC implementations where both solution quality and computational efficiency are crucial.</description>
      <guid isPermaLink="false">oai:arXiv.org:2507.20465v1</guid>
      <category>math.OC</category>
      <pubDate>Tue, 29 Jul 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Jinxin Xiong, Linxin Yang, Yingxiao Wang, Yanting Huang, Jianghua Wu, Shunbo Lei, Akang Wang</dc:creator>
    </item>
    <item>
      <title>Post-estimation Adjustments in Data-driven Decision-making with Applications in Pricing</title>
      <link>https://arxiv.org/abs/2507.20501</link>
      <description>arXiv:2507.20501v1 Announce Type: new 
Abstract: The predict-then-optimize (PTO) framework is a standard approach in data-driven decision-making, where a decision-maker first estimates an unknown parameter from historical data and then uses this estimate to solve an optimization problem. While widely used for its simplicity and modularity, PTO can lead to suboptimal decisions because the estimation step does not account for the structure of the downstream optimization problem. We study a class of problems where the objective function, evaluated at the PTO decision, is asymmetric with respect to estimation errors. This asymmetry causes the expected outcome to be systematically degraded by noise in the parameter estimate, as the penalty for underestimation differs from that of overestimation. To address this, we develop a data-driven post-estimation adjustment that improves decision quality while preserving the practicality and modularity of PTO. We show that when the objective function satisfies a particular curvature condition, based on the ratio of its third and second derivatives, the adjustment simplifies to a closed-form expression. This condition holds for a broad range of pricing problems, including those with linear, log-linear, and power-law demand models. Under this condition, we establish theoretical guarantees that our adjustment uniformly and asymptotically outperforms standard PTO, and we precisely characterize the resulting improvement. Additionally, we extend our framework to multi-parameter optimization and settings with biased estimators. Numerical experiments demonstrate that our method consistently improves revenue, particularly in small-sample regimes where estimation uncertainty is most pronounced. This makes our approach especially well-suited for pricing new products or in settings with limited historical price variation.</description>
      <guid isPermaLink="false">oai:arXiv.org:2507.20501v1</guid>
      <category>math.OC</category>
      <category>stat.AP</category>
      <pubDate>Tue, 29 Jul 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Michael Albert, Max Biggs, Ningyuan Chen, Guan Wang</dc:creator>
    </item>
    <item>
      <title>An Image Noise Level Estimation Based on Tensor T-Product</title>
      <link>https://arxiv.org/abs/2507.20515</link>
      <description>arXiv:2507.20515v1 Announce Type: new 
Abstract: Currently, the noise level of color images is estimated by many algorithms through separate selection of each page of the third-order tensor using sliding blocks of size ${M_1} \times {M_1}$. The data structure of the tensor is disrupted by this method, leading to errors in the estimation results. In order not to disrupt the data structure of the tensor, we directly select the tensor using a sliding block of size ${M_1} \times {M_1} \times 3$ and then re-arrange it. The newly obtained tensor is decomposed into a block diagonal matrix form through T-product. It is demonstrated that the eigenvalues of this matrix are related to the noise level of the color image. Then train the relationship coefficients through learning methods, thereby obtaining the estimated noise level. The effectiveness of the algorithm was verified through numerical experiments, and it also achieved high estimation accuracy.</description>
      <guid isPermaLink="false">oai:arXiv.org:2507.20515v1</guid>
      <category>math.OC</category>
      <pubDate>Tue, 29 Jul 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Hanxin Liu, Yisheng Song</dc:creator>
    </item>
    <item>
      <title>Computing an optimal single machine schedule with sequence dependent setup times using shortest path computations</title>
      <link>https://arxiv.org/abs/2507.20611</link>
      <description>arXiv:2507.20611v1 Announce Type: new 
Abstract: We study a single-machine scheduling problem with sequence dependent setup times, motivated by applications in manufacturing and service industries - in particular, the calendering stage in rubber flooring production. In this phase, setup times are primarily driven by temperature and color transitions between consecutive jobs, with significant impact on throughput and energy efficiency. We present a novel solution framework that transforms the scheduling problem into a path-finding problem on a specially constructed layered graph. By encoding sequence-dependent effects directly into the graph's structure, we enable the use of classical shortest-path algorithms to compute optimal job sequences. The resulting method is polynomial-time solvable for the two-color case and reveals key structural properties of optimal schedules. Our approach thus provides both a theoretically grounded and practically applicable optimization technique.</description>
      <guid isPermaLink="false">oai:arXiv.org:2507.20611v1</guid>
      <category>math.OC</category>
      <pubDate>Tue, 29 Jul 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Dominik Leib, Till Heller, Raphael K\"uhn</dc:creator>
    </item>
    <item>
      <title>Subspace decomposition in regularized least-squares: solution properties, restricted coercivity and beyond</title>
      <link>https://arxiv.org/abs/2507.20686</link>
      <description>arXiv:2507.20686v1 Announce Type: new 
Abstract: We study the solution properties of regularized lease-squares problem. By the
  subspace decomposition technique, we develop expressions of the solution set in terms of conjugate
  function, from which various properties, including existence, compactness and uniqueness, can then
  be easily analyzed. An important difference of our approach from the existing works is that the
  existence and compactness are discussed separately. Many existing results under the notions of
  recession cone and sublevel set are unified, and further connected to our results by associating
  recession function with the recession cone of subdifferential of conjugate function. In particular, the
  concept of restricted coercivity is developed and discussed in various aspects. The associated linearly
  constrained counterpart is discussed in a similar manner. Its connections to regularized least-squares
  are further established via the exactness of infimal postcomposition. Our results are supported by
  many examples, where the simple geometry of lasso solution deserves further investigations in near
  future.</description>
      <guid isPermaLink="false">oai:arXiv.org:2507.20686v1</guid>
      <category>math.OC</category>
      <pubDate>Tue, 29 Jul 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Feng Xue, Hui Zhang</dc:creator>
    </item>
    <item>
      <title>The Ellipsoidal Separation Machine</title>
      <link>https://arxiv.org/abs/2507.20698</link>
      <description>arXiv:2507.20698v1 Announce Type: new 
Abstract: We propose the -- to the best of our knowledge -- first fully functional implementation of the ``Separation by a Convex Body'' (SCB) approach first outlined in Grzybowski et al. [1] for classification, separating two data sets using an ellipsoid. A training problem is defined that is structurally similar to the Support Vector Machine (SVM) one, thus leading to call our method the Ellipsoidal Separation Machine (ESM). Like SVM, the training problem is convex, and can in particular be formulated as a Semidefinite Program (SDP); however, solving it by means of standard SDP approaches does not scale to the size required by practical classification task. As an alternative, a nonconvex formulation is proposed that is amenable to a Block-Gauss-Seidel approach alternating between a much smaller SDP and a simple separable Second-Order Cone Program (SOCP). For the purpose of the classification approach the reduced SDP can even be solved approximately by relaxing it in a Lagrangian way and updating the multipliers by fast subgradient-type approaches. A characteristic of ESM is that it necessarily defines ``indeterminate points'', i.e., those that cannot be reliably classified as belonging to one of the two sets. This makes it particularly suitable for Classification with Rejection (CwR) tasks, whereby the system explicitly indicates that classification of some points as belonging to one of the two sets is too doubtful to be reliable. We show that, in many datasets, ESM is competitive with SVM -- with the kernel chosen among the three standard ones and endowed with CwR capabilities using the margin of the classifier -- and in general behaves differently; thus, ESM provides another arrow in the quiver when designing CwR approaches.</description>
      <guid isPermaLink="false">oai:arXiv.org:2507.20698v1</guid>
      <category>math.OC</category>
      <pubDate>Tue, 29 Jul 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Antonio Frangioni, Enrico Gorgone, Benedetto Manca</dc:creator>
    </item>
    <item>
      <title>Electrolyzers Bidding in Electricity Markets under Green Hydrogen Regulations and Uncertainty</title>
      <link>https://arxiv.org/abs/2507.20702</link>
      <description>arXiv:2507.20702v1 Announce Type: new 
Abstract: Hydrogen produced through electrolysis offers a pathway to decarbonize hard-to-abate sectors by replacing gray hydrogen derived from natural gas reforming when produced using renewable power. However, grid-connected electrolyzers may inadvertently increase power-system emissions, resulting in hydrogen whose life-cycle intensity is similar to or higher than that of gray hydrogen. To address the high cost barrier of electrolytic hydrogen, both the E.U. and U.S. have introduced subsidy schemes conditional on low associated emissions. One key requirement is temporal matching, under which a subsidy applies only to the hydrogen volume that, ex-post, can be shown to match renewable generation over each one-hour interval. This requirement exposes the electrolyzer to uncertainty in the subsidy-eligible volume and thus the value of the produced hydrogen. This paper develops an uncertainty-aware day-ahead bid curve for a grid-connected electrolyzer. We formulate a linear program that maximizes expected profit across scenarios of renewable production and derive the bid curve from its Karush-Kuhn-Tucker conditions. A case study demonstrates that incorporating renewable uncertainty into the bid curve increases electrolyzer profit by approximately 4%, although it does not improve ex-post temporal matching. This finding highlights a potential distortion in the incentive effects of temporal-matching regulations when uncertainty is taken into account.</description>
      <guid isPermaLink="false">oai:arXiv.org:2507.20702v1</guid>
      <category>math.OC</category>
      <pubDate>Tue, 29 Jul 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Andrea Gloppen Johnsen, Lesia Mitridati, Jalal Kazempour, Line Roald</dc:creator>
    </item>
    <item>
      <title>Fundamental diagram constrained dynamic optimal transport via proximal splitting methods</title>
      <link>https://arxiv.org/abs/2507.20717</link>
      <description>arXiv:2507.20717v1 Announce Type: new 
Abstract: Optimal transport has recently been brought forward as a tool for modeling and efficiently solving a variety of flow problems, such as origin-destination problems and multi-commodity flow problems. Although the framework has shown to be effective for many large scale flow problems, the formulations typically lack dynamic properties used in common traffic models, such as the Lighthill-Whitham-Richards model. In this work, we propose an optimal transport framework that includes dynamic constraints specified by the fundamental diagram for modeling macroscopic traffic flow. The problem is cast as a convex variant of dynamic optimal transport, with additional nonlinear temporal-spatial inequality constraints of momentum, modeled after the fundamental diagram from traffic theory. This constraint imposes a density-dependent upper bound on the admissible flux, capturing flow saturation and congestion effects, and thus leaves space for kinetic optimization. The formulation follows the Benamou-Brenier transportation rationale, whereby kinetic energy over density and momentum fields is optimized subject to the mass conservation law. We develop proximal splitting methods, namely the Douglas-Rachford and Chambolle-Pock algorithms, which exploit the separable structure of the constraint set and require only simple proximal operations, and can accommodate additional (time-varying) spatial restrictions or obstacles. Numerical experiments illustrate the impact of the constraint on transport behavior, including congestion-aware spreading, rerouting, and convergence. The framework establishes a connection between optimal transport and macroscopic traffic flow theory and provides a scalable, variational tool for modeling congestion-constricted (or saturation-aware) Wasserstein gradient flow.</description>
      <guid isPermaLink="false">oai:arXiv.org:2507.20717v1</guid>
      <category>math.OC</category>
      <category>cs.SY</category>
      <category>eess.SY</category>
      <pubDate>Tue, 29 Jul 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Anqi Dong, Karl Henrik Johansson, Johan Karlsson</dc:creator>
    </item>
    <item>
      <title>Accelerating Deterministic Global Optimization via GPU-parallel Interval Arithmetic</title>
      <link>https://arxiv.org/abs/2507.20769</link>
      <description>arXiv:2507.20769v1 Announce Type: new 
Abstract: Spatial Branch and Bound (B&amp;B) algorithms are widely used for solving nonconvex problems to global optimality, yet they remain computationally expensive. Though some works have been carried out to speed up B&amp;B via CPU parallelization, GPU parallelization is much less explored. In this work, we investigate the design of a spatial B&amp;B algorithm that involves an interval-based GPU-parallel lower bounding solver: The domain of each B&amp;B node is temporarily partitioned into numerous subdomains, then massive GPU parallelism is leveraged to compute interval bounds of the objective function and constraints on each subdomain, using the Mean Value Form. The resulting bounds are tighter than those achieved via regular interval arithmetic without partitioning, but they remain fast to compute. We implement the method into our open-source solver MAiNGO via CUDA in two manners: wrapping all GPU tasks within one kernel function, or distributing the GPU tasks onto a CUDA graph. Numerical experiments show that using more subdomains leads to significantly tighter lower bounds and thus less B&amp;B iterations. Regarding wall clock time, the proposed spatial B&amp;B framework achieves a speedup of three orders of magnitude compared to applying interval arithmetic on the CPU without domain partitioning. Among the two implementations, the one developed with CUDA graph enables higher efficiency. Moreover, in some case studies, the proposed method delivers competitive or better performance compared to MAiNGO's default solver which is based on McCormick relaxations. These results highlight the potential of GPU-accelerated bounding techniques to accelerate B&amp;B algorithms.</description>
      <guid isPermaLink="false">oai:arXiv.org:2507.20769v1</guid>
      <category>math.OC</category>
      <category>cs.DC</category>
      <pubDate>Tue, 29 Jul 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Hongzhen Zhang (Department of Chemical Engineering, KU Leuven, Leuven, Belgium), Tim Kerkenhoff (Institute of Climate and Energy Systems - Energy Systems Engineering), Neil Kichler (Software and Tools for Computational Engineering), Manuel Dahmen (Institute of Climate and Energy Systems - Energy Systems Engineering), Alexander Mitsos (JARA-CSD, Aachen, Germany, Process Systems Enginering, Institute of Climate and Energy Systems - Energy Systems Engineering), Uwe Naumann (Software and Tools for Computational Engineering), Dominik Bongartz (Department of Chemical Engineering, KU Leuven, Leuven, Belgium)</dc:creator>
    </item>
    <item>
      <title>Numerical Design of Optimized First-Order Algorithms</title>
      <link>https://arxiv.org/abs/2507.20773</link>
      <description>arXiv:2507.20773v1 Announce Type: new 
Abstract: We derive several numerical methods for designing optimized first-order algorithms in unconstrained convex optimization settings. Our methods are based on the Performance Estimation Problem (PEP) framework, which casts the worst-case analysis of optimization algorithms as an optimization problem itself. We benchmark our methods against existing approaches in the literature on the task of optimizing the step sizes of memoryless gradient descent (which uses only the current gradient for updates) over the class of smooth convex functions. We then apply our methods to numerically tune the step sizes of several memoryless and full (i.e., using all past gradient information for updates) fixed-step first-order algorithms, namely coordinate descent, inexact gradient descent, and cyclic gradient descent, in the context of linear convergence. In all cases, we report accelerated convergence rates compared to those of classical algorithms.</description>
      <guid isPermaLink="false">oai:arXiv.org:2507.20773v1</guid>
      <category>math.OC</category>
      <pubDate>Tue, 29 Jul 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Yassine Kamri, Julien M. Hendrickx, Fran\c{c}ois Glineur</dc:creator>
    </item>
    <item>
      <title>Route Optimization Over Scheduled Services For Large-Scale Package Delivery Networks</title>
      <link>https://arxiv.org/abs/2507.20844</link>
      <description>arXiv:2507.20844v1 Announce Type: new 
Abstract: This paper introduces the Trailer Path Optimization with Schedule Services Problem (TPOSSP) and proposes a column-generation heuristic (CG-heuristic) to find high-quality solutions to large-scale instances. The TPOSSP aims at determining trailer routes over a time-dependent network using existing scheduled services, while considering tractor capacity constraints and time windows for trailer pickups and deliveries. The objective is to minimize both the number of schedules used and the total miles traveled. To address the large scale of industrial instances, the paper proposes a network reduction technique that identifies the set of feasible schedule-legs for each requests. Moreover, to address the resulting MIP models, that still contains hundred of millions variables, the paper proposes a stabilized column-generation, whose pricing problem is a time-dependent shortest path. The approach is evaluated on industrial instances both for tactical planning where requests for the entire network are re-optimized and for real-time operations where new requests are inserted. In the tactical planning setting, the column-generation heuristic returns solutions with a 3.7%-5.7% optimality gap (based on a MIP relaxation) in under 1.7-10.3 hours, and improves the current practice by 2.3-3.2%, with translates into savings of tens of millions of dollars a year. In the real-time setting, the column-generation heuristic returns solution within 3% of optimality in under 1 minute, which makes it adequate for real-time deployment. The results also show that the network reduction decreases run times by 85% for the column-generation heuristic.</description>
      <guid isPermaLink="false">oai:arXiv.org:2507.20844v1</guid>
      <category>math.OC</category>
      <pubDate>Tue, 29 Jul 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <dc:creator>Mohammed Faisal Ahmed, Pascal Van Hentenryck, Ahmed El Nashar</dc:creator>
    </item>
    <item>
      <title>Iterative Schemes for Markov Perfect Equilibria</title>
      <link>https://arxiv.org/abs/2507.20898</link>
      <description>arXiv:2507.20898v1 Announce Type: new 
Abstract: We study Markov perfect equilibria in continuous-time dynamic games with finitely many symmetric players. The corresponding Nash system reduces to the Nash-Lasry-Lions equation for the common value function, also known as the master equation in the mean-field setting. In the finite-state space problems we consider, this equation becomes a nonlinear ordinary differential equation admitting a unique classical solution. Leveraging this uniqueness, we prove the convergence of both Picard and weighted Picard iterations, yielding efficient computational methods. Numerical experiments confirm the effectiveness of algorithms based on this approach.</description>
      <guid isPermaLink="false">oai:arXiv.org:2507.20898v1</guid>
      <category>math.OC</category>
      <pubDate>Tue, 29 Jul 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Felix H\"ofer, Mathieu Lauri\`ere, H. Mete Soner, Qinxin Yan</dc:creator>
    </item>
    <item>
      <title>Mean-Field Langevin Diffusions with Density-dependent Temperature</title>
      <link>https://arxiv.org/abs/2507.20958</link>
      <description>arXiv:2507.20958v1 Announce Type: new 
Abstract: In the context of non-convex optimization, we let the temperature of a Langevin diffusion to depend on the diffusion's own density function. The rationale is that the induced density reveals to some extent the landscape imposed by the non-convex function to be minimized, such that a density-dependent temperature can provide location-wise random perturbation that may better react to, for instance, the location and depth of local minimizers. As the Langevin dynamics is now self-regulated by its own density, it forms a mean-field stochastic differential equation (SDE) of the Nemytskii type, distinct from the standard McKean-Vlasov equations. Relying on Wasserstein subdifferential calculus, we first show that the corresponding (nonlinear) Fokker-Planck equation has a unique solution. Next, a weak solution to the SDE is constructed from the solution to the Fokker-Planck equation, by Trevisan's superposition principle. As time goes to infinity, we further show that the density induced by the SDE converges to an invariant distribution, which admits an explicit formula in terms of the Lambert $W$ function.</description>
      <guid isPermaLink="false">oai:arXiv.org:2507.20958v1</guid>
      <category>math.OC</category>
      <category>cs.LG</category>
      <category>math.PR</category>
      <pubDate>Tue, 29 Jul 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Yu-Jui Huang, Zachariah Malik</dc:creator>
    </item>
    <item>
      <title>Benamou-Brenier and Kantorovich are equivalent on sub-Riemannian manifolds with no abnormal geodesics</title>
      <link>https://arxiv.org/abs/2507.20959</link>
      <description>arXiv:2507.20959v1 Announce Type: new 
Abstract: We prove that the Benamou-Brenier formulation of the Optimal Transport problem and the Kantorovich formulation are equivalent on a sub-Riemannian connected and complete manifold $M$ without boundary and with no abnormal geodesics, when the problems are considered between two measures of compact supports. Furthermore, we prove the existence of a minimizer for the Benamou-Brenier formulation and link it to the optimal transport plan.</description>
      <guid isPermaLink="false">oai:arXiv.org:2507.20959v1</guid>
      <category>math.OC</category>
      <pubDate>Tue, 29 Jul 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Giovanna Citti, Mattia Galeotti, Andrea Pinamonti</dc:creator>
    </item>
    <item>
      <title>Stochastic gradient with least-squares control variates</title>
      <link>https://arxiv.org/abs/2507.20981</link>
      <description>arXiv:2507.20981v1 Announce Type: new 
Abstract: The stochastic gradient descent (SGD) method is a widely used approach for solving stochastic optimization problems, but its convergence is typically slow. Existing variance reduction techniques, such as SAGA, improve convergence by leveraging stored gradient information; however, they are restricted to settings where the objective functional is a finite sum, and their performance degrades when the number of terms in the sum is large. In this work, we propose a novel approach which is well suited when the objective is given by an expectation over random variables with a continuous probability distribution. Our method constructs a control variate by fitting a linear model to past gradient evaluations using weighted discrete least-squares, effectively reducing variance while preserving computational efficiency. We establish theoretical sublinear convergence guarantees for strongly convex objectives and demonstrate the method's effectiveness through numerical experiments on random PDE-constrained optimization problems.</description>
      <guid isPermaLink="false">oai:arXiv.org:2507.20981v1</guid>
      <category>math.OC</category>
      <category>cs.NA</category>
      <category>math.NA</category>
      <pubDate>Tue, 29 Jul 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Fabio Nobile, Matteo Raviola, Nathan Schaeffer</dc:creator>
    </item>
    <item>
      <title>Whale Optimization Algorithms based fractional order fuzzy PID controller for Depth of Anesthesia</title>
      <link>https://arxiv.org/abs/2507.19532</link>
      <description>arXiv:2507.19532v1 Announce Type: cross 
Abstract: One of the most important surgical factors is Depth of Anesthesia (DOA) control in patients. The main problem is to overcome the uncertainty and nonlinearity of the system, due to different physiological parameters of the patient's body and maintain DOA of patients in desired range during surgery. This study demonstrates a fractional order fuzzy PID controller (FOFPID) and fractional order PID controller (FOPID) to the problem. The Whale Optimization Algorithms (WOA) is used to optimized the parameters of proposed controllers. The orders of derivative and integral fractional controller is achieved by WOA. The results indicate that FOFPID has a better performance than FOPID. To check the performance of the controllers in presence of uncertainty, physiological logical model of 8 patients has been investigated. The modeling is based on Pharmacodynamic and Pharmacokinetic model. The results show the performance of the proposed method.</description>
      <guid isPermaLink="false">oai:arXiv.org:2507.19532v1</guid>
      <category>eess.SY</category>
      <category>cs.SY</category>
      <category>math.OC</category>
      <pubDate>Tue, 29 Jul 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Amin Behboudifar, Chen Jing</dc:creator>
    </item>
    <item>
      <title>State evolution beyond first-order methods I: Rigorous predictions and finite-sample guarantees</title>
      <link>https://arxiv.org/abs/2507.19611</link>
      <description>arXiv:2507.19611v1 Announce Type: cross 
Abstract: We develop a toolbox for exact analysis of iterative algorithms on a class of high-dimensional nonconvex optimization problems with random data. While prior work has shown that low-dimensional statistics of (generalized) first-order methods can be predicted by a deterministic recursion known as state evolution, our focus is on developing such a prediction for a more general class of algorithms. We provide a state evolution for any method whose iterations are given by (possibly interleaved) first-order and saddle point updates, showing two main results. First, we establish a rigorous state evolution prediction that holds even when the updates are not coordinate-wise separable. Second, we establish finite-sample guarantees bounding the deviation of the empirical updates from the established state evolution. In the process, we develop a technical toolkit that may prove useful in related problems. One component of this toolkit is a general Hilbert space lifting technique to prove existence and uniqueness of a convenient parameterization of the state evolution. Another component of the toolkit combines a generic application of Bolthausen's conditioning method with a sequential variant of Gordon's Gaussian comparison inequality, and provides additional ingredients that enable a general finite-sample analysis.</description>
      <guid isPermaLink="false">oai:arXiv.org:2507.19611v1</guid>
      <category>math.ST</category>
      <category>cs.LG</category>
      <category>math.OC</category>
      <category>stat.ML</category>
      <category>stat.TH</category>
      <pubDate>Tue, 29 Jul 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Michael Celentano, Chen Cheng, Ashwin Pananjady, Kabir Aladin Verchand</dc:creator>
    </item>
    <item>
      <title>Federated Calculation of the Free-Support Transportation Barycenter by Single-Loop Dual Decomposition</title>
      <link>https://arxiv.org/abs/2507.19627</link>
      <description>arXiv:2507.19627v1 Announce Type: cross 
Abstract: We propose an efficient federated dual decomposition algorithm for calculating the Wasserstein barycenter of several distributions, including choosing the support of the solution. The algorithm does not access local data and uses only highly aggregated information. It also does not require repeated solutions to mass transportation problems. Because of the absence of any matrix-vector operations, the algorithm exhibits a very low complexity of each iteration and significant scalability. We illustrate its virtues and compare it to the state-of-the-art methods on several examples of mixture models.</description>
      <guid isPermaLink="false">oai:arXiv.org:2507.19627v1</guid>
      <category>cs.LG</category>
      <category>math.OC</category>
      <category>stat.ML</category>
      <pubDate>Tue, 29 Jul 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Zhengqi Lin, Andrzej Ruszczy\'nski</dc:creator>
    </item>
    <item>
      <title>Interpolation-Based Gradient-Error Bounds for Use in Derivative-Free Optimization of Noisy Functions</title>
      <link>https://arxiv.org/abs/2507.19661</link>
      <description>arXiv:2507.19661v1 Announce Type: cross 
Abstract: In this paper, we analyze the accuracy of gradient estimates obtained by linear interpolation when the underlying function is subject to bounded measurement noise. The total gradient error is decomposed into a deterministic component arising from the interpolation (finite-difference) approximation, and a stochastic component due to noise. Various upper bounds for both error components are derived and compared through several illustrative examples. Our comparative study reveals that strict deterministic bounds, including those commonly used in derivative-free optimization (DFO), tend to be overly conservative. To address this, we propose approximate gradient error bounds that aim to upper bound the gradient error norm more realistically, without the excessive conservatism of classical bounds. Finally, drawing inspiration from dual real-time optimization strategies, we present a DFO scheme based on sequential programming, where the approximate gradient error bounds are enforced as constraints within the optimization problem.</description>
      <guid isPermaLink="false">oai:arXiv.org:2507.19661v1</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <category>math.OC</category>
      <pubDate>Tue, 29 Jul 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Alejandro G. Marchetti, Dominique Bonvin</dc:creator>
    </item>
    <item>
      <title>Optimal mean-variance portfolio selection under regime-switching-induced stock price shocks</title>
      <link>https://arxiv.org/abs/2507.19824</link>
      <description>arXiv:2507.19824v1 Announce Type: cross 
Abstract: In this paper, we investigate mean-variance (MV) portfolio selection problems with jumps in a regime-switching financial model. The novelty of our approach lies in allowing not only the market parameters -- such as the interest rate, appreciation rate, volatility, and jump intensity -- to depend on the market regime, but also in permitting stock prices to experience jumps when the market regime switches, in addition to the usual micro-level jumps. This modeling choice is motivated by empirical observations that stock prices often exhibit sharp declines when the market shifts from a ``bullish'' to a ``bearish'' regime, and vice versa. By employing the completion-of-squares technique, we derive the optimal portfolio strategy and the efficient frontier, both of which are characterized by three systems of multi-dimensional ordinary differential equations (ODEs). Among these, two systems are linear, while the first one is an $\ell$-dimensional, fully coupled, and highly nonlinear Riccati equation. In the absence of regime-switching-induced stock price shocks, these systems reduce to simple linear ODEs. Thus, the introduction of regime-switching-induced stock price shocks adds significant complexity and challenges to our model. Additionally, we explore the MV problem under a no-shorting constraint. In this case, the corresponding Riccati equation becomes a $2\ell$-dimensional, fully coupled, nonlinear ODE, for which we establish solvability. The solution is then used to explicitly express the optimal portfolio and the efficient frontier.</description>
      <guid isPermaLink="false">oai:arXiv.org:2507.19824v1</guid>
      <category>q-fin.PM</category>
      <category>math.OC</category>
      <category>math.PR</category>
      <category>q-fin.MF</category>
      <pubDate>Tue, 29 Jul 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Xiaomin Shi, Zuo Quan Xu</dc:creator>
    </item>
    <item>
      <title>Structural Identifiability and Discrete Symmetries</title>
      <link>https://arxiv.org/abs/2507.19884</link>
      <description>arXiv:2507.19884v1 Announce Type: cross 
Abstract: We discuss the use of symmetries for analysing the structural identifiability and observability of control systems. Special emphasis is put on the role of discrete symmetries, in contrast to the more commonly studied continuous or Lie symmetries. We argue that discrete symmetries are the origin of parameters which are structurally locally identifiable, but not globally. We exploit this fact to present a methodology for structural identifiability analysis that detects such parameters and characterizes the symmetries in which they are involved. We demonstrate the use of our methodology by applying it to four case studies.</description>
      <guid isPermaLink="false">oai:arXiv.org:2507.19884v1</guid>
      <category>math.DS</category>
      <category>math.OC</category>
      <pubDate>Tue, 29 Jul 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <dc:creator>Xabier Rey Barreiro, Nick Baberuxki, Meskerem Abebaw Mebratie, Alejandro F. Villaverde, Werner M. Seiler</dc:creator>
    </item>
    <item>
      <title>Deep Uzawa for Kinetic Transport with Lagrange-Enforced Boundaries</title>
      <link>https://arxiv.org/abs/2507.19907</link>
      <description>arXiv:2507.19907v1 Announce Type: cross 
Abstract: We propose a neural network framework for solving stationary linear transport equations with inflow boundary conditions. The method represents the solution using a neural network and imposes the boundary condition via a Lagrange multiplier, based on a saddle-point formulation inspired by the classical Uzawa algorithm. The scheme is mesh-free, compatible with automatic differentiation and extends naturally to problems with scattering and heterogeneous media. We establish convergence of the continuum formulation and analyse the effects of quadrature error, neural approximation and inexact optimisation in the discrete implementation. Numerical experiments show that the method captures anisotropic transport, enforces boundary conditions and resolves scattering dynamics accurately.</description>
      <guid isPermaLink="false">oai:arXiv.org:2507.19907v1</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <category>math.OC</category>
      <category>physics.comp-ph</category>
      <pubDate>Tue, 29 Jul 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Charalambos Makridakis, Aaron Pim, Tristan Pryer, Nikolaos Rekatsinas</dc:creator>
    </item>
    <item>
      <title>The Phantom of Davis-Wielandt Shell: A Unified Framework for Graphical Stability Analysis of MIMO LTI Systems</title>
      <link>https://arxiv.org/abs/2507.19918</link>
      <description>arXiv:2507.19918v1 Announce Type: cross 
Abstract: This paper presents a unified framework based on Davis-Wielandt (DW) shell for graphical stability analysis of multi-input and multi-output linear time-invariant feedback systems. Connections between DW shells and various graphical descriptions, as well as gain and phase measures, are established through an intuitive geometric perspective. Within this framework, we examine the relationships and relative conservatism among various separation conditions. A rotated Scaled Relative Graph (SRG) concept is proposed as a mixed gain-phase representation, from which a closed-loop stability criterion is derived and shown to be the least conservative among the existing 2-D graphical conditions for bi-component feedback loops. We also propose a reliable algorithm for visualizing the rotated SRGs and include an example to demonstrate the non-conservatism of the proposed condition.</description>
      <guid isPermaLink="false">oai:arXiv.org:2507.19918v1</guid>
      <category>eess.SY</category>
      <category>cs.SY</category>
      <category>math.OC</category>
      <category>math.RA</category>
      <pubDate>Tue, 29 Jul 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Ding Zhang, Xiaokan Yang, Axel Ringh, Li Qiu</dc:creator>
    </item>
    <item>
      <title>Feed-anywhere ANN (I) Steady Discrete $\to$ Diffusing on Graph Hidden States</title>
      <link>https://arxiv.org/abs/2507.20088</link>
      <description>arXiv:2507.20088v1 Announce Type: cross 
Abstract: We propose a novel framework for learning hidden graph structures from data using geometric analysis and nonlinear dynamics. Our approach: (1) Defines discrete Sobolev spaces on graphs for scalar/vector fields, establishing key functional properties; (2) Introduces gauge-equivalent nonlinear Schr\"odinger and Landau--Lifshitz dynamics with provable stable stationary solutions smoothly dependent on input data and graph weights; (3) Develops a stochastic gradient algorithm over graph moduli spaces with sparsity regularization. Theoretically, we guarantee: topological correctness (homology recovery), metric convergence (Gromov--Hausdorff), and efficient search space utilization. Our dynamics-based model achieves stronger generalization bounds than standard neural networks, with complexity dependent on the data manifold's topology.</description>
      <guid isPermaLink="false">oai:arXiv.org:2507.20088v1</guid>
      <category>cs.LG</category>
      <category>math-ph</category>
      <category>math.MP</category>
      <category>math.OC</category>
      <category>stat.ML</category>
      <pubDate>Tue, 29 Jul 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Dmitry Pasechnyuk-Vilensky, Daniil Doroshenko</dc:creator>
    </item>
    <item>
      <title>Viscous-inertial waves on the surface of the Sun: modeling, forward and inverse problems</title>
      <link>https://arxiv.org/abs/2507.20488</link>
      <description>arXiv:2507.20488v1 Announce Type: cross 
Abstract: This paper develops a mathematical framework for studying the newly discovered solar inertial oscillations, offering promising new avenues for exploring the Sun's dynamics. Under the assumption of purely toroidal motions, the stream function of the flow satisfies a fourth-order scalar equation governing inertial waves on the rotating Sun. We prove well-posedness of wave solutions under explicit conditions on differential rotation. Moreover, we study the inverse problem of simultaneously reconstructing viscosity and differential rotation parameters from either complete or partial surface observations. To this end, we verify the tangential cone condition, ensuring the convergence of iterative regularization methods. Numerical experiments employing the Nesterov-Landweber iteration confirm robustness of the reconstruction across different observation schemes and noise levels.</description>
      <guid isPermaLink="false">oai:arXiv.org:2507.20488v1</guid>
      <category>math.AP</category>
      <category>math-ph</category>
      <category>math.MP</category>
      <category>math.OC</category>
      <pubDate>Tue, 29 Jul 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Tram Thi Ngoc Nguyen, Damien Fournier, Thorsten Hohage</dc:creator>
    </item>
    <item>
      <title>Sequential Operation of Residential Energy Hubs</title>
      <link>https://arxiv.org/abs/2507.20621</link>
      <description>arXiv:2507.20621v1 Announce Type: cross 
Abstract: The operation of residential energy hubs with multiple energy carriers (electricity, heat, mobility) poses a significant challenge due to different carrier dynamics, hybrid storage coordination and high-dimensional action-spaces. Energy management systems oversee their operation, deciding the set points of the primary control layer. This paper presents a novel 2-stage economic model predictive controller for electrified buildings including physics-based models of the battery degradation and thermal systems. The hierarchical control operates in the Dutch sequential energy markets. In particular common assumptions regarding intra-day markets (auction and continuous-time) are discussed as well as the coupling of the different storage systems. The best control policy is to co-optimize day-ahead and intra-day auctions in the first stage, to later follow intra-day auctions. If no intra-day prices are known at the time of the day-ahead auction, its best to follow continuous time intra-day in the summer and the intra-day auction in the winter. Additionally, this sequential operation increases battery degradation. Finally, under our controller the realized short-term flexibility of the thermal energy storage is marginal compared to the flexibility delivered by static battery pack and electric vehicles with bidirectional charging.</description>
      <guid isPermaLink="false">oai:arXiv.org:2507.20621v1</guid>
      <category>eess.SY</category>
      <category>cs.SY</category>
      <category>math.OC</category>
      <pubDate>Tue, 29 Jul 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Dar\'io Slaifstein (Delft University of Technology), Gautham Ram Chandra Mouli (Delft University of Technology), Laura Ramirez-Elizondo (Delft University of Technology), Pavol Bauer (Delft University of Technology)</dc:creator>
    </item>
    <item>
      <title>A fixed-time stable dynamical model for solving EVLCPs</title>
      <link>https://arxiv.org/abs/2507.20652</link>
      <description>arXiv:2507.20652v1 Announce Type: cross 
Abstract: A fixed-time stable dynamical system for solving the extended vertical linear complementarity problem (EVLCP) is developed. The system is based on the reformulation of EVLCP as a special case of a new kind of generalized absolute value equations. Some properties of the new kind of generalized absolute value equations are explored which are useful for developing a fixed-time stable dynamical system for solving it. Without using any smoothing technique, we develop a dynamical system for solving the new kind of generalized absolute value equations and prove its fixed-time stability. The model is applicable for solving EVLCP. As two by-products, a new condition which guarantees the unique solvability of EVLCP and a new error bound of EVLCP are given. Numerical results are given to demonstrate our claims.</description>
      <guid isPermaLink="false">oai:arXiv.org:2507.20652v1</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <category>math.OC</category>
      <pubDate>Tue, 29 Jul 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Yufei Wei, Shiping Lin, Cairong Chen, Dongmei Yu, Deren Han</dc:creator>
    </item>
    <item>
      <title>Exposing the Illusion of Fairness: Auditing Vulnerabilities to Distributional Manipulation Attacks</title>
      <link>https://arxiv.org/abs/2507.20708</link>
      <description>arXiv:2507.20708v1 Announce Type: cross 
Abstract: Proving the compliance of AI algorithms has become an important challenge with the growing deployment of such algorithms for real-life applications. Inspecting possible biased behaviors is mandatory to satisfy the constraints of the regulations of the EU Artificial Intelligence's Act. Regulation-driven audits increasingly rely on global fairness metrics, with Disparate Impact being the most widely used. Yet such global measures depend highly on the distribution of the sample on which the measures are computed. We investigate first how to manipulate data samples to artificially satisfy fairness criteria, creating minimally perturbed datasets that remain statistically indistinguishable from the original distribution while satisfying prescribed fairness constraints. Then we study how to detect such manipulation. Our analysis (i) introduces mathematically sound methods for modifying empirical distributions under fairness constraints using entropic or optimal transport projections, (ii) examines how an auditee could potentially circumvent fairness inspections, and (iii) offers recommendations to help auditors detect such data manipulations. These results are validated through experiments on classical tabular datasets in bias detection.</description>
      <guid isPermaLink="false">oai:arXiv.org:2507.20708v1</guid>
      <category>cs.LG</category>
      <category>math.OC</category>
      <category>stat.AP</category>
      <pubDate>Tue, 29 Jul 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Valentin Lafargue, Adriana Laurindo Monteiro, Emmanuelle Claeys, Laurent Risser, Jean-Michel Loubes</dc:creator>
    </item>
    <item>
      <title>Optimal and Self Selection of Service Type in a Queueing System where Long Service Postpones the Need for the Next Service</title>
      <link>https://arxiv.org/abs/2208.09348</link>
      <description>arXiv:2208.09348v3 Announce Type: replace 
Abstract: We study a make-to-order system with a finite set of customers. Production is stochastic with a nonlinear dependence between the ordered quantity and the production rate. Customers may have to queue until their turn arrives, and therefore their order decisions interact. Specifically, while being served, customers are aware of the queue length and choose one of two order quantities (or service types). The time to the next replenishment (their activity time) is stochastic and depends on the order quantities. A customer is inactive during service and while waiting in the queue. We refer to the type of service with a greater ratio of expected activity to service time as ``more efficient''. In the centralized case, the system is interested in maximizing the steady-state average number of active customers, which is referred to as the efficiency of the system. We show that choosing the more efficient service is not always optimal, but the optimal strategy can be approximated well by selecting one of three threshold strategies which depend on the number of inactive customers. In the decentralized case, each customer acts to maximize the fraction of time she is active. We observe that individuals and the manager have opposite incentives: When the queue is long, individuals tend to choose the long service, while the manager prefers the short service in this case. This makes the system difficult to regulate. However, we show that simply removing the less efficient service significantly increases efficiency.</description>
      <guid isPermaLink="false">oai:arXiv.org:2208.09348v3</guid>
      <category>math.OC</category>
      <category>math.PR</category>
      <pubDate>Tue, 29 Jul 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Refael Hassin, Jiesen Wang</dc:creator>
    </item>
    <item>
      <title>A Validation Approach to Over-parameterized Matrix and Image Recovery</title>
      <link>https://arxiv.org/abs/2209.10675</link>
      <description>arXiv:2209.10675v3 Announce Type: replace 
Abstract: This paper studies the problem of recovering a low-rank matrix from several noisy random linear measurements. We consider the setting where the rank of the ground-truth matrix is unknown a priori and use an objective function built from a rank-overspecified factored representation of the matrix variable, where the global optimal solutions overfit and do not correspond to the underlying ground truth. We then solve the associated nonconvex problem using gradient descent with small random initialization. We show that as long as the measurement operators satisfy the restricted isometry property (RIP) with its rank parameter scaling with the rank of the ground-truth matrix rather than scaling with the overspecified matrix rank, gradient descent iterations are on a particular trajectory towards the ground-truth matrix and achieve nearly information-theoretically optimal recovery when it is stopped appropriately. We then propose an efficient stopping strategy based on the common hold-out method and show that it detects a nearly optimal estimator provably. Moreover, experiments show that the proposed validation approach can also be efficiently used for image restoration with deep image prior, which over-parameterizes an image with a deep network.</description>
      <guid isPermaLink="false">oai:arXiv.org:2209.10675v3</guid>
      <category>math.OC</category>
      <category>cs.LG</category>
      <category>eess.IV</category>
      <category>stat.ML</category>
      <pubDate>Tue, 29 Jul 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Lijun Ding, Zhen Qin, Liwei Jiang, Jinxin Zhou, Zhihui Zhu</dc:creator>
    </item>
    <item>
      <title>Stochastic Approximation for Expectation Objective and Expectation Inequality-Constrained Nonconvex Optimization</title>
      <link>https://arxiv.org/abs/2307.02943</link>
      <description>arXiv:2307.02943v3 Announce Type: replace 
Abstract: Stochastic Approximation has been a prominent set of tools for solving problems with noise and uncertainty. Increasingly, it becomes important to solve optimization problems wherein there is noise in both a set of constraints that a practitioner requires the system to adhere to, as well as the objective, which typically involves some empirical loss. We present the first stochastic approximation approach for solving this class of problems using the Ghost framework of incorporating penalty functions for analysis of a sequential convex programming approach together with a Monte Carlo estimator of nonlinear maps. We provide almost sure convergence guarantees and demonstrate the performance of the procedure on some representative examples.</description>
      <guid isPermaLink="false">oai:arXiv.org:2307.02943v3</guid>
      <category>math.OC</category>
      <pubDate>Tue, 29 Jul 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Francisco Facchinei, Vyacheslav Kungurtsev</dc:creator>
    </item>
    <item>
      <title>A New Random Reshuffling Method for Nonsmooth Nonconvex Finite-sum Optimization</title>
      <link>https://arxiv.org/abs/2312.01047</link>
      <description>arXiv:2312.01047v3 Announce Type: replace 
Abstract: Random reshuffling techniques are prevalent in large-scale applications, such as training neural networks. While the convergence and acceleration effects of random reshuffling-type methods are fairly well understood in the smooth setting, much less studies seem available in the nonsmooth case. In this work, we design a new normal map-based proximal random reshuffling (norm-PRR) method for nonsmooth nonconvex finite-sum problems. We show that norm-PRR achieves the iteration complexity ${\cal O}(n^{-1/3}T^{-2/3})$ where $n$ denotes the number of component functions $f(\cdot,i)$ and $T$ counts the total number of iterations. This improves the currently known complexity bounds for this class of problems by a factor of $n^{-1/3}$ in terms of the number of gradient evaluations. Additionally, we prove that norm-PRR converges linearly under the (global) Polyak-{\L}ojasiewicz condition and in the interpolation setting. We further complement these non-asymptotic results and provide an in-depth analysis of the asymptotic properties of norm-PRR. Specifically, under the (local) Kurdyka-{\L}ojasiewicz inequality, the whole sequence of iterates generated by norm-PRR is shown to converge to a single stationary point. Moreover, we derive last-iterate convergence rates that can match those in the smooth, strongly convex setting. Finally, numerical experiments are performed on nonconvex classification tasks to illustrate the efficiency of the proposed approach.</description>
      <guid isPermaLink="false">oai:arXiv.org:2312.01047v3</guid>
      <category>math.OC</category>
      <category>cs.LG</category>
      <pubDate>Tue, 29 Jul 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Junwen Qiu, Xiao Li, Andre Milzarek</dc:creator>
    </item>
    <item>
      <title>On data-driven Wasserstein distributionally robust Nash equilibrium problems with heterogeneous uncertainty</title>
      <link>https://arxiv.org/abs/2312.03573</link>
      <description>arXiv:2312.03573v3 Announce Type: replace 
Abstract: We study stochastic Nash equilibrium problems subject to heterogeneous uncertainty on the expected valued cost functions of the individual agents, where we assume no prior knowledge of the underlying probability distributions of the uncertain variables. To account for this lack of knowledge, we consider an ambiguity set around the empirical probability distribution under the Wasserstein metric. We then show that, under mild assumptions, finite-sample guarantees on the probability that any resulting distributionally robust Nash equilibrium is also robust with respect to the true probability distributions with high confidence can be obtained. Furthermore, by recasting the game as a distributionally robust variational inequality, we establish asymptotic consistency of the set of data-driven distributionally robust equilibria to the solution set of the original game. Finally, we recast the distributionally robust Nash game as a finite-dimensional Nash equilibrium problem. We illustrate the proposed distributionally robust reformulation via numerical experiments of stochastic peer-to-peer electricity markets and Nash-Cournot games.</description>
      <guid isPermaLink="false">oai:arXiv.org:2312.03573v3</guid>
      <category>math.OC</category>
      <category>cs.SY</category>
      <category>eess.SY</category>
      <pubDate>Tue, 29 Jul 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Georgios Pantazis, Barbara Franci, Sergio Grammatico</dc:creator>
    </item>
    <item>
      <title>Extended mean-field control problems with Poissonian common noise: Stochastic maximum principle and Hamiltonian-Jacobi-Bellman equation</title>
      <link>https://arxiv.org/abs/2407.05356</link>
      <description>arXiv:2407.05356v3 Announce Type: replace 
Abstract: This paper studies mean-field control problems with state-control joint law dependence and Poissonian common noise. We develop the stochastic maximum principle (SMP) and establish its connection to the Hamiltonian-Jacobi-Bellman (HJB) equation on the Wasserstein space. The presence of the conditional joint law in the McKean-Vlasov dynamics and its discontinuity caused by the Poissonian common noise bring new technical challenges. To develop the SMP when the control domain is not necessarily convex, we first consider a strong relaxed control formulation that allows us to perform the first-order variation. We propose the technique of extension transformation to overcome the compatibility issues arising from the joint law in the relaxed control formulation. By further establishing the equivalence between the relaxed control and the strict control formulations, we obtain the SMP for the original problem with strict controls. In the part to investigate the HJB equation, we formulate an auxiliary control problem subjecting to a controlled measure-valued dynamics with Poisson jumps, which allows us to derive the HJB equation of the original problem under the open-loop strict control by some newly established equivalence formulations. We also establish the connection between the SMP and the HJB equation.</description>
      <guid isPermaLink="false">oai:arXiv.org:2407.05356v3</guid>
      <category>math.OC</category>
      <category>math.PR</category>
      <pubDate>Tue, 29 Jul 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Lijun Bo, Jingfei Wang, Xiaoli Wei, Xiang Yu</dc:creator>
    </item>
    <item>
      <title>Adaptive Sampling-Based Bi-Fidelity Stochastic Trust Region Method for Derivative-Free Stochastic Optimization</title>
      <link>https://arxiv.org/abs/2408.04625</link>
      <description>arXiv:2408.04625v3 Announce Type: replace 
Abstract: Bi-fidelity stochastic optimization has gained increasing attention as an efficient approach to reduce computational costs by leveraging a low-fidelity (LF) model to optimize an expensive high-fidelity (HF) objective. In this paper, we propose ASTRO-BFDF, an adaptive sampling trust region method specifically designed for unconstrained bi-fidelity stochastic derivative-free optimization problems. In ASTRO-BFDF, the LF function serves two purposes: (i) to identify better iterates for the HF function when the optimization process indicates a high correlation between them, and (ii) to reduce the variance of the HF function estimates using bi-fidelity Monte Carlo (BFMC). The algorithm dynamically determines sample sizes while adaptively choosing between crude Monte Carlo and BFMC to balance the trade-off between optimization and sampling errors. We prove that the iterates generated by ASTRO-BFDF converge to the first-order stationary point almost surely. Additionally, we demonstrate the effectiveness of the proposed algorithm through numerical experiments on synthetic problems and simulation optimization problems involving discrete event systems.</description>
      <guid isPermaLink="false">oai:arXiv.org:2408.04625v3</guid>
      <category>math.OC</category>
      <pubDate>Tue, 29 Jul 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Yunsoo Ha, Juliane Mueller</dc:creator>
    </item>
    <item>
      <title>On the local and global minimizers of the smooth stress function in Euclidean Distance Matrix problems</title>
      <link>https://arxiv.org/abs/2408.07256</link>
      <description>arXiv:2408.07256v2 Announce Type: replace 
Abstract: We consider the nonconvex minimization problem, with quartic objective function, that arises in the exact recovery of a configuration matrix $P\in \R^{nd}$ of $n$ points when a Euclidean distance matrix, \EDMp, is given with embedding dimension $d$. It is an open question in the literature whether there are conditions such that the minimization problem admits a local nonglobal minimizer, \lngmp. We prove that all second-order stationary points are global minimizers whenever $n \leq d + 1$. {And, for $d=1$ and $n\geq 7&gt;d+1$, we present an example where we can analytically exhibit a local nonglobal minimizer. For more general cases,} we numerically find a second-order stationary point and then prove that there indeed exists a nearby \lngm for the quartic nonconvex minimization problem. Thus, we answer the previously open question about their existence in the affirmative. Our approach to finding the \lngm is novel in that we first exploit the translation and rotation invariance to remove the singularities of the Hessian, and reduce the size of the problem from $nd$ variables in $P$ to $(n-1)d - d(d-1)/2$ variables. This allows for stabilizing Newton's method, and for finding examples that satisfy the strict second order sufficient optimality conditions.
  The motivation for being able to find global minima is to obtain \emph{exact recovery} of the configuration matrix, even in the cases where the data is noisy and/or incomplete, without resorting to approximating solutions from convex (semidefinite programming) relaxations. In the process of our work we present new insights into when \lngmp s of the smooth stress function do and do not exist.</description>
      <guid isPermaLink="false">oai:arXiv.org:2408.07256v2</guid>
      <category>math.OC</category>
      <pubDate>Tue, 29 Jul 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Mengmeng Song, Douglas Goncalves, Woosuk L. Jung, Carlile Lavor, Antonio Mucherino, Henry Wolkowicz</dc:creator>
    </item>
    <item>
      <title>Flexible block-iterative analysis for the Frank-Wolfe algorithm</title>
      <link>https://arxiv.org/abs/2409.06931</link>
      <description>arXiv:2409.06931v2 Announce Type: replace 
Abstract: We prove that the block-coordinate Frank-Wolfe (BCFW) algorithm converges with state-of-the-art rates in both convex and nonconvex settings under a very mild "block-iterative" assumption. This appears to be the first result on BCFW addressing the setting of nonconvex objective functions with Lipschitz-continuous gradients and no additional assumptions. This analysis newly allows for (I) progress without activating the most-expensive linear minimization oracle(s), LMO(s), at every iteration, (II) parallelized updates that do not require all LMOs, and therefore (III) deterministic parallel update strategies that take into account the numerical cost of the problem's LMOs. Our results apply for short-step BCFW as well as an adaptive method for convex functions. New relationships between updated coordinates and primal progress are proven, and a favorable speedup is demonstrated using FrankWolfe.jl.</description>
      <guid isPermaLink="false">oai:arXiv.org:2409.06931v2</guid>
      <category>math.OC</category>
      <pubDate>Tue, 29 Jul 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>G\'abor Braun, Sebastian Pokutta, Zev Woodstock</dc:creator>
    </item>
    <item>
      <title>Observability inequalities for heat equations with potentials</title>
      <link>https://arxiv.org/abs/2409.09476</link>
      <description>arXiv:2409.09476v2 Announce Type: replace 
Abstract: This paper is mainly concerned with the observability inequalities for heat equations with time-dependent Lipschtiz potentials. The observability inequality for heat equations asserts that the total energy of a solution is bounded above by the energy localized in a subdomain with an observability constant. For a bounded measurable potential $V = V(x,t)$, the factor in the observability constant arising from the Carleman estimate is best known to be $\exp(C\|V\|_{\infty}^{2/3})$ (even for time-independent potentials). In this paper, we show that, for Lipschtiz potentials, this factor can be replaced by $\exp(C(\|\nabla V\|_{\infty}^{1/2} +\|\partial_tV\|_{\infty}^{1/3} ))$, which improves the previous bound $\exp(C\|V\|_{\infty}^{2/3})$ in some typical scenarios. As a consequence, with such a Lipschitz potential, we obtain a quantitative regular control in a null controllability problem. In addition, for the one-dimensional heat equation with some time-independent bounded measurable potential $V = V(x)$, we obtain the optimal observability constant.</description>
      <guid isPermaLink="false">oai:arXiv.org:2409.09476v2</guid>
      <category>math.OC</category>
      <category>math.AP</category>
      <pubDate>Tue, 29 Jul 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Jiuyi Zhu, Jinping Zhuge</dc:creator>
    </item>
    <item>
      <title>A single-loop proximal-conditional-gradient penalty method</title>
      <link>https://arxiv.org/abs/2409.14957</link>
      <description>arXiv:2409.14957v2 Announce Type: replace 
Abstract: We consider the problem of minimizing a convex separable objective (as a separable sum of two proper closed convex functions $f$ and $g$) over a linear coupling constraint. We assume that $f$ can be decomposed as the sum of a smooth part having H\"older continuous gradient (with exponent $\mu\in(0,1]$) and a nonsmooth part that admits efficient proximal mapping computations, while $g$ can be decomposed as the sum of a smooth part having H\"older continuous gradient (with exponent $\nu\in(0,1]$) and a nonsmooth part that admits efficient linear oracles. Motivated by the recent works [1,49], we propose a single-loop variant of the standard penalty method, which we call a single-loop proximal-conditional-gradient penalty method (proxCG$^{\rm pen}_{1\ell}$), for this problem. In each iteration of proxCG$^{\rm pen}_{1\ell}$, we successively perform one proximal-gradient step involving $f$ and one conditional-gradient step involving $g$ on the quadratic penalty function, followed by an update of the penalty parameter. We present explicit rules for updating the penalty parameter and the stepsize in the conditional-gradient step in each iteration. Under a standard constraint qualification and domain boundedness assumption, we show that the objective value deviations (from the optimal value) along the sequence generated decay in the order of $t^{-\min\{\mu,\nu,1/2\}}$ with the associated feasibility violations decaying in the order of $t^{-1/2}$. Moreover, if the nonsmooth parts are indicator functions and the extended objective is a KL function with exponent $\alpha\in[0,1)$, then the distances to the optimal solution set along the sequence generated by proxCG$^{\rm pen}_{1\ell}$ decay asymptotically at a rate of $t^{-(1-\alpha)\min\{\mu,\nu,1/2\}}$. Finally, we illustrate numerically the behavior of proxCG$^{\rm pen}_{1\ell}$ on solving low rank Hankel matrix completion problems.</description>
      <guid isPermaLink="false">oai:arXiv.org:2409.14957v2</guid>
      <category>math.OC</category>
      <pubDate>Tue, 29 Jul 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Hao Zhang, Liaoyuan Zeng, Ting Kei Pong</dc:creator>
    </item>
    <item>
      <title>Fast and robust consensus-based optimization via optimal feedback control</title>
      <link>https://arxiv.org/abs/2411.03051</link>
      <description>arXiv:2411.03051v2 Announce Type: replace 
Abstract: We propose a variant of consensus-based optimization (CBO) algorithms, controlled-CBO, which introduces a feedback control term to improve convergence towards global minimizers of non-convex functions in multiple dimensions. The feedback law is a gradient of a numerical approximation to the Hamilton-Jacobi-Bellman (HJB) equation, which serves as a proxy of the original objective function. Thus, the associated control signal furnishes gradient-like information to facilitate the identification of the global minimum without requiring derivative computation from the objective function itself. The proposed method exhibits significantly improved performance over standard CBO methods in numerical experiments, particularly in scenarios involving a limited number of particles, or where the initial particle ensemble is not well positioned with respect to the global minimum. At the same time, the modification keeps the algorithm amenable to theoretical analysis in the mean-field sense. The superior convergence rates are assessed experimentally.</description>
      <guid isPermaLink="false">oai:arXiv.org:2411.03051v2</guid>
      <category>math.OC</category>
      <pubDate>Tue, 29 Jul 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Yuyang Huang, Michael Herty, Dante Kalise, Nikolas Kantas</dc:creator>
    </item>
    <item>
      <title>The Effective Countable Generalized Moment Problem</title>
      <link>https://arxiv.org/abs/2501.09385</link>
      <description>arXiv:2501.09385v3 Announce Type: replace 
Abstract: We establish new convergence rates for the Moment-Sum-of-Squares (Moment-SoS) relaxations for the Generalized Moment Problem (GMP) with countable moment constraints on vectors of measures, under dual optimum attainment, S-fullness and Archimedean conditions. These bounds, which adapt to the geometry of the underlying semi-algebraic set, apply to both the convergence of optima, and to the convergence in Hausdorff distance between the relaxation feasibility set and the GMP feasibility set. This research provides quantitative geometry-adaptive rates for GMPs cast as linear programs on measures. It complements earlier analyses of specific GMP instances (e.g., polynomial optimization) as well as recent methodological frameworks that have been applied to volume computation and optimal control. We apply the convergence rate analysis to symmetric tensor decomposition problems, providing new effective error bounds for the convergence of the Moment-SoS hierarchies for tensor decomposition.</description>
      <guid isPermaLink="false">oai:arXiv.org:2501.09385v3</guid>
      <category>math.OC</category>
      <pubDate>Tue, 29 Jul 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Lucas Gamertsfelder (AROMATH), Bernard Mourrain (AROMATH)</dc:creator>
    </item>
    <item>
      <title>SPLD polynomial optimization and bounded degree SOS hierarchies</title>
      <link>https://arxiv.org/abs/2502.11343</link>
      <description>arXiv:2502.11343v2 Announce Type: replace 
Abstract: In this paper, we introduce a new class of structured polynomials, called separable plus lower degree (SPLD) polynomials. The formal definition of an SPLD polynomial, which extends the concept of SPQ polynomials (Ahmadi et al. in Math Oper Res 48:1316--1343, 2023), is provided. A type of bounded degree SOS hierarchy, referred to as BSOS-SPLD, is proposed to efficiently solve optimization problems involving SPLD polynomials. Numerical experiments on several benchmark problems indicate that the proposed method yields better performance than the standard bounded degree SOS hierarchy (Lasserre et al. in EURO J Comput Optim 5:87--117, 2017). An exact SOS relaxation for a class of convex SPLD polynomial optimization problems is proposed. Finally, we present an application of SPLD polynomials to convex polynomial regression problems arising in statistics.</description>
      <guid isPermaLink="false">oai:arXiv.org:2502.11343v2</guid>
      <category>math.OC</category>
      <pubDate>Tue, 29 Jul 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Liguo Jiao, Jae Hyoung Lee, Nguyen Bui Nguyen Thao</dc:creator>
    </item>
    <item>
      <title>A strongly polynomial-time algorithm for the general linear programming problem</title>
      <link>https://arxiv.org/abs/2503.12041</link>
      <description>arXiv:2503.12041v4 Announce Type: replace 
Abstract: This article presents a strongly polynomial-time algorithm for the general linear programming problem. This algorithm is an implicit reduction procedure that works as follows. Primal and dual problems are combined into a special system of linear equations constrained by complementarity relations and non-negative variables. Each iteration of the algorithm consists of applying a pair of complementary Gauss-Jordan pivoting operations, guided by a necessary-condition lemma. The algorithm requires no more than k+n iterations, as there are only k+n complementary pairs of columns to compare one-pair-at-a-time, where k is the number of constraints and n is the number of variables of given general linear programming problem. Numerical illustration is given that includes an instance of a classical problem of Klee and Minty and a problem of Beale.</description>
      <guid isPermaLink="false">oai:arXiv.org:2503.12041v4</guid>
      <category>math.OC</category>
      <pubDate>Tue, 29 Jul 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Samuel Awoniyi</dc:creator>
    </item>
    <item>
      <title>Distributed Learning over Arbitrary Topology: Linear Speed-Up with Polynomial Transient Time</title>
      <link>https://arxiv.org/abs/2503.16123</link>
      <description>arXiv:2503.16123v2 Announce Type: replace 
Abstract: We study a distributed learning problem in which $n$ agents, each with potentially heterogeneous local data, collaboratively minimize the sum of their local cost functions via peer-to-peer communication. We propose a novel algorithm, \emph{Spanning Tree Push-Pull} (STPP), which employs two spanning trees extracted from a general communication graph to distribute both model parameters and stochastic gradients. Unlike prior approaches that rely heavily on spectral gap properties, STPP leverages a more flexible topological characterization, enabling robust information flow and efficient updates. Theoretically, we prove that STPP achieves linear speedup and polynomial transient iteration complexity -- up to $\mathcal{O}(n^7)$ for smooth nonconvex objectives and $\tilde{\mathcal{O}}(n^3)$ for smooth strongly convex objectives -- under arbitrary network topologies. Moreover, compared with existing methods, STPP achieves faster convergence rates on sparse and non-regular topologies (e.g., directed rings) and reduces communication overhead on dense networks (e.g., static exponential graphs). Numerical experiments further demonstrate the strong performance of STPP across various graph architectures.</description>
      <guid isPermaLink="false">oai:arXiv.org:2503.16123v2</guid>
      <category>math.OC</category>
      <category>cs.LG</category>
      <pubDate>Tue, 29 Jul 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <dc:creator>Runze You, Shi Pu</dc:creator>
    </item>
    <item>
      <title>Ordering and refining path-complete Lyapunov functions through composition lifts</title>
      <link>https://arxiv.org/abs/2503.18189</link>
      <description>arXiv:2503.18189v2 Announce Type: replace 
Abstract: A fruitful approach to study stability of switched systems is to look for multiple Lyapunov functions. However, in general, we do not yet understand the interplay between the desired stability certificate, the template of the Lyapunov functions and their mutual relationships to accommodate switching. In this work we elaborate on path-complete Lyapunov functions: a graphical framework that aims to elucidate this interplay. In particular, previously, several preorders were introduced to compare multiple Lyapunov functions. These preorders are initially algorithmically intractable due to the algebraic nature of Lyapunov inequalities, yet, lifting techniques were proposed to turn some preorders purely combinatorial and thereby eventually tractable. In this note we show that a conjecture in this area regarding the so-called composition lift, that was believed to be true, is false. This refutal, however, points us to a beneficial structural feature of the composition lift that we exploit to iteratively refine path-complete graphs, plus, it points us to a favourable adaptation of the composition lift.</description>
      <guid isPermaLink="false">oai:arXiv.org:2503.18189v2</guid>
      <category>math.OC</category>
      <category>cs.SY</category>
      <category>eess.SY</category>
      <pubDate>Tue, 29 Jul 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Wouter Jongeneel, Rapha\"el M. Jungers</dc:creator>
    </item>
    <item>
      <title>Coupled Adaptable Backward-Forward-Backward Resolvent Splitting Algorithm (CABRA): A Matrix-Parametrized Resolvent Splitting Method for the Sum of Maximal Monotone and Cocoercive Operators Composed with Linear Coupling Operators</title>
      <link>https://arxiv.org/abs/2505.13927</link>
      <description>arXiv:2505.13927v2 Announce Type: replace 
Abstract: We present a novel matrix-parametrized frugal splitting algorithm which finds the zero of a sum of maximal monotone and cocoercive operators composed with linear selection operators. We also develop a semidefinite programming framework for selecting matrix parameters and demonstrate its use for designing matrix parameters which provide beneficial diagonal scaling, allow parallelization, and adhere to a given communication structure. We show that taking advantage of the linear selection operators in this way accelerates convergence in numerical experiments, and show that even when the selection operators are the identity, we can accelerate convergence by using the matrix parameters to provide appropriately chosen diagonal scaling. We conclude by demonstrating the applicability of this algorithm to multi-stage stochastic programming, outlining a decentralized approach to the relaxed stochastic weapon target assignment problem which splits over the source nodes and has low data transfer and memory requirements.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.13927v2</guid>
      <category>math.OC</category>
      <pubDate>Tue, 29 Jul 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Peter Barkley, Robert L. Bassett</dc:creator>
    </item>
    <item>
      <title>Mean Field Control with Poissonian Common Noise: A Pathwise Compactification Approach</title>
      <link>https://arxiv.org/abs/2505.23441</link>
      <description>arXiv:2505.23441v2 Announce Type: replace 
Abstract: This paper contributes to the compactification approach to tackle mean-field control (MFC) problems with Poissonian common noise. To overcome the lack of compactness and continuity issues due to common noise, we exploit the point process representation of the Poisson random measure with finite intensity and propose a pathwise formulation by freezing a sample path of the common noise. We first study a pathwise relaxed control problem in an auxiliary setup without common noise but with finite deterministic jumping times over the finite horizon. By employing the compactification argument for the pathwise relaxed control problem with Skorokhod topology, we establish the existence of optimal controls in the pathwise formulation. To address the original problem, the main challenge is to close the gap between the problem in the original model with common noise and the pathwise formulation. With the help of concatenation techniques over the sequence of deterministic jumping times, we develop a new tool, also interpreted as the superposition principle in the pathwise formulation, to draw a relationship between the pathwise relaxed control problem and the pathwise measure-valued control problem associated to Fokker-Planck equation. As a result, we can bridge the desired equivalence among different problem formulations. We also extend the methodology to solve mean-field games with Poissonian common noise, confirming the existence of a strong mean field equilibrium.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.23441v2</guid>
      <category>math.OC</category>
      <category>math.PR</category>
      <pubDate>Tue, 29 Jul 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Lijun Bo, Jingfei Wang, Xiaoli Wei, Xiang Yu</dc:creator>
    </item>
    <item>
      <title>Convergence rates of regularized quasi-Newton methods without strong convexity</title>
      <link>https://arxiv.org/abs/2506.00521</link>
      <description>arXiv:2506.00521v4 Announce Type: replace 
Abstract: In this paper, we study convergence rates of the cubic regularized proximal quasi-Newton method (\csr) for solving non-smooth additive composite problems that satisfy the so-called Kurdyka-\L ojasiewicz (K\L ) property with respect to some desingularization function $\phi$ rather than strong convexity. After a number of iterations $k_0$, Cubic SR1 PQN exhibits non-asymptotic explicit super-linear convergence rates for any $k\geq k_0$. In particular, when $\phi(t)=ct^{1/2}$, Cubic SR1 PQN has a convergence rate of order $\left(\frac{C}{(k-k_0)^{1/2}}\right)^{(k-k_0)/2}$, where $k$ is the number of iterations and $C&gt;0$ is a constant. For the special case, i.e. functions which satisfy \L ojasiewicz inequality, the rate becomes global and non-asymptotic. This work presents, for the first time, non-asymptotic explicit convergence rates of regularized (proximal) SR1 quasi-Newton methods applied to non-convex non-smooth problems with K\L\ property. Actually, the rates are novel even in the smooth non-convex case. Notably, we achieve this without employing line search or trust region strategies, without assuming the Dennis-Mor\'e condition, without any assumptions on quasi-Newton metrics and without assuming strong convexity. Furthermore, for convex problems, we focus on a more tractable gradient regularized quasi-Newton method (Grad SR1 PQN) which can achieve results similar to those obtained with cubic regularization. We also demonstrate, for the first time, the non-asymptotic super-linear convergence rate of Grad SR1 PQN for solving convex problems with the help of the \L ojasiewicz inequality instead of strong convexity.</description>
      <guid isPermaLink="false">oai:arXiv.org:2506.00521v4</guid>
      <category>math.OC</category>
      <pubDate>Tue, 29 Jul 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Shida Wang, Jalal Fadili, Peter Ochs</dc:creator>
    </item>
    <item>
      <title>On a mean-field Pontryagin minimum principle for stochastic optimal control</title>
      <link>https://arxiv.org/abs/2506.10506</link>
      <description>arXiv:2506.10506v3 Announce Type: replace 
Abstract: This papers outlines a novel extension of the classical Pontryagin minimum (maximum) principle to stochastic optimal control problems. Contrary to the well-known stochastic Pontryagin minimum principle involving forward-backward stochastic differential equations, the proposed formulation is deterministic and of mean-field type. We denote it the McKean-Pontryagin minimum principle. The Hamiltonian structure of the proposed McKean-Pontryagin minimum principle is achieved via the introduction of an appropriate gauge variable. The gauge freedom can be used to decouple the forward and reverse time equations; hence simplifying the solution of the underlying boundary value problem. We also consider infinite horizon discounted cost optimal control problems. In this case, the mean-field formulation allows converting the computation of the desired optimal control law into solving a pair of forward mean-field ordinary differential equations. The McKean-Pontryagin minimum principle is tested numerically for a controlled inverted pendulum and a controlled Lorenz-63 system.</description>
      <guid isPermaLink="false">oai:arXiv.org:2506.10506v3</guid>
      <category>math.OC</category>
      <category>cs.NA</category>
      <category>math.NA</category>
      <pubDate>Tue, 29 Jul 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Manfred Opper, Sebastian Reich</dc:creator>
    </item>
    <item>
      <title>First-Order Sparse Convex Optimization: Better Rates with Sparse Updates</title>
      <link>https://arxiv.org/abs/2506.19075</link>
      <description>arXiv:2506.19075v2 Announce Type: replace 
Abstract: In was recently established that for convex optimization problems with a sparse optimal solution (may it be entry-wise sparsity or matrix rank-wise sparsity) it is possible to have linear convergence rates which depend on an improved mixed-norm condition number of the form $\frac{\beta_1{}s}{\alpha_2}$, where $\beta_1$ is the $\ell_1$-Lipchitz continuity constant of the gradient, $\alpha_2$ is the $\ell_2$-quadratic growth constant, and $s$ is the sparsity of the optimal solution. However, beyond the improved convergence rate, these methods are unable to leverage the sparsity of optimal solutions towards improving also the runtime of each iteration, which may still be prohibitively high for high-dimensional problems. In this work, we establish that linear convergence rates which depend on this improved condition number can be obtained using only sparse updates, which may result in overall significantly improved running times. Moreover, our methods are considerably easier to implement.</description>
      <guid isPermaLink="false">oai:arXiv.org:2506.19075v2</guid>
      <category>math.OC</category>
      <category>cs.LG</category>
      <pubDate>Tue, 29 Jul 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Dan Garber</dc:creator>
    </item>
    <item>
      <title>On the controllability of laminated beams with Venttsel-type boundary conditions</title>
      <link>https://arxiv.org/abs/2506.22887</link>
      <description>arXiv:2506.22887v2 Announce Type: replace 
Abstract: This paper examines the boundary controllability of a Timoshenko laminated beam system subject to Venttsel-type boundary conditions. The study focuses on a novel configuration in which three controls are applied solely at the boundary of the beam. Controllability is established by deriving an appropriate observability inequality for the corresponding adjoint system, which is then employed within the framework of the duality method in the setup of the classical Hilbert uniqueness method (HUM) to achieve the control problem. The main contribution lies in the analysis of a system comprising three beams governed by dynamic Venttsel-type boundary conditions, as introduced by Venttsel in [Theory Probab. Appl., 4 (1959)].</description>
      <guid isPermaLink="false">oai:arXiv.org:2506.22887v2</guid>
      <category>math.OC</category>
      <category>math.AP</category>
      <pubDate>Tue, 29 Jul 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/publicdomain/zero/1.0/</dc:rights>
      <dc:creator>George J. Bautista, Roberto de A. Capistrano-Filho, Juan L\'imaco</dc:creator>
    </item>
    <item>
      <title>Qualitative and Generalized Differentiation Properties of Optimal Value Functions with Applications to Duality</title>
      <link>https://arxiv.org/abs/2507.07377</link>
      <description>arXiv:2507.07377v2 Announce Type: replace 
Abstract: This paper investigates general and generalized differentiation properties of the optimal value function associated with perturbed optimization problems. Fundamental results on nearly convex sets and functions in infinite-dimensional spaces are then established. We proceed by analyzing general properties of the optimal value function, including its domain, epigraph, strict epigraph, near convexity, semicontinuity, and Lipschitz-type continuity in both convex and nonconvex settings. Subsequently, we derive calculus rules and representation formulas for the $\epsilon$-subdifferentials of the optimal value function and its Fenchel conjugate. We then develop a duality framework for constrained optimization problems with set-valued constraints using the Fenchel conjugate for set-valued mappings. This approach provides new perspectives on duality in generalized settings.</description>
      <guid isPermaLink="false">oai:arXiv.org:2507.07377v2</guid>
      <category>math.OC</category>
      <pubDate>Tue, 29 Jul 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>V. S. T. Long, B. S. Mordukhovich, N. M. Nam, L. White</dc:creator>
    </item>
    <item>
      <title>Geometric structure of shallow neural networks and constructive ${\mathcal L}^2$ cost minimization</title>
      <link>https://arxiv.org/abs/2309.10370</link>
      <description>arXiv:2309.10370v3 Announce Type: replace-cross 
Abstract: In this paper, we approach the problem of cost (loss) minimization in underparametrized shallow ReLU networks through the explicit construction of upper bounds which appeal to the structure of classification data, without use of gradient descent. A key focus is on elucidating the geometric structure of approximate and precise minimizers. We consider an $\mathcal{L}^2$ cost function, input space $\mathbb{R}^M$, output space ${\mathbb R}^Q$ with $Q\leq M$, and training input sample size that can be arbitrarily large. We prove an upper bound on the minimum of the cost function of order $O(\delta_P)$ where $\delta_P$ measures the signal-to-noise ratio of training data. In the special case $M=Q$, we explicitly determine an exact degenerate local minimum of the cost function, and show that the sharp value differs from the upper bound obtained for $Q\leq M$ by a relative error $O(\delta_P^2)$. The proof of the upper bound yields a constructively trained network; we show that it metrizes a particular $Q$-dimensional subspace in the input space ${\mathbb R}^M$. We comment on the characterization of the global minimum of the cost function in the given context.</description>
      <guid isPermaLink="false">oai:arXiv.org:2309.10370v3</guid>
      <category>cs.LG</category>
      <category>cs.AI</category>
      <category>math-ph</category>
      <category>math.MP</category>
      <category>math.OC</category>
      <category>stat.ML</category>
      <pubDate>Tue, 29 Jul 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Thomas Chen, Patr\'icia Mu\~noz Ewald</dc:creator>
    </item>
    <item>
      <title>Markov chain entropy games and the geometry of their Nash equilibria</title>
      <link>https://arxiv.org/abs/2310.04115</link>
      <description>arXiv:2310.04115v3 Announce Type: replace-cross 
Abstract: We introduce and study a two-player zero-sum game between a probabilist and Nature defined by a convex function $f$, a finite collection $\mathcal{B}$ of Markov generators (or its convex hull), and a target distribution $\pi$. The probabilist selects a mixed strategy $\mu \in \mathcal{P}(\mathcal{B})$, the set of probability measures on $\mathcal{B}$, while Nature adopts a pure strategy and selects a $\pi$-reversible Markov generator $M$. The probabilist receives a payoff equal to the $f$-divergence $D_f(M \| L)$, where $L$ is drawn according to $\mu$. We prove that this game always admits a mixed strategy Nash equilibrium and satisfies a minimax identity. In contrast, a pure strategy equilibrium may fail to exist. We develop a projected subgradient method to compute approximate mixed strategy equilibria with provable convergence guarantees. Connections to information centroids, Chebyshev centers, and Bayes risk are discussed. This paper extends earlier minimax results on $f$-divergences to the context of Markov generators.</description>
      <guid isPermaLink="false">oai:arXiv.org:2310.04115v3</guid>
      <category>math.PR</category>
      <category>cs.IT</category>
      <category>math.IT</category>
      <category>math.OC</category>
      <category>stat.CO</category>
      <pubDate>Tue, 29 Jul 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Michael C. H. Choi, Geoffrey Wolfer</dc:creator>
    </item>
    <item>
      <title>Simple matrix expressions for the curvatures of Grassmannian</title>
      <link>https://arxiv.org/abs/2406.11821</link>
      <description>arXiv:2406.11821v3 Announce Type: replace-cross 
Abstract: We show that modeling a Grassmannian as symmetric orthogonal matrices $\operatorname{Gr}(k,\mathbb{R}^n) \cong\{Q \in \mathbb{R}^{n \times n} : Q^{\scriptscriptstyle\mathsf{T}} Q = I, \; Q^{\scriptscriptstyle\mathsf{T}} = Q,\; \operatorname{tr}(Q)=2k - n\}$ yields exceedingly simple matrix formulas for various curvatures and curvature-related quantities, both intrinsic and extrinsic. These include Riemann, Ricci, Jacobi, sectional, scalar, mean, principal, and Gaussian curvatures; Schouten, Weyl, Cotton, Bach, Pleba\'nski, cocurvature, nonmetricity, and torsion tensors; first, second, and third fundamental forms; Gauss and Weingarten maps; and upper and lower delta invariants. We will derive explicit, simple expressions for the aforementioned quantities in terms of standard matrix operations that are stably computable with numerical linear algebra. Many of these aforementioned quantities have never before been presented for the Grassmannian.</description>
      <guid isPermaLink="false">oai:arXiv.org:2406.11821v3</guid>
      <category>math.DG</category>
      <category>cs.NA</category>
      <category>math.NA</category>
      <category>math.OC</category>
      <pubDate>Tue, 29 Jul 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Zehua Lai, Lek-Heng Lim, Ke Ye</dc:creator>
    </item>
    <item>
      <title>Non-convex matrix sensing: Breaking the quadratic rank barrier in the sample complexity</title>
      <link>https://arxiv.org/abs/2408.13276</link>
      <description>arXiv:2408.13276v4 Announce Type: replace-cross 
Abstract: For the problem of reconstructing a low-rank matrix from a few linear measurements, two classes of algorithms have been widely studied in the literature: convex approaches based on nuclear norm minimization, and non-convex approaches that use factorized gradient descent. Under certain statistical model assumptions, it is known that nuclear norm minimization recovers the ground truth as soon as the number of samples scales linearly with the number of degrees of freedom of the ground-truth. In contrast, while non-convex approaches are computationally less expensive, existing recovery guarantees assume that the number of samples scales at least quadratically with the rank $r$ of the ground-truth matrix. In this paper, we close this gap by showing that the non-convex approaches can be as efficient as nuclear norm minimization in terms of sample complexity. Namely, we consider the problem of reconstructing a positive semidefinite matrix from a few Gaussian measurements. We show that factorized gradient descent with spectral initialization converges to the ground truth at a linear rate as soon as the number of samples scales with $ \Omega (rd\kappa^2)$, where $d$ is the dimension, and $\kappa$ is the condition number of the ground truth matrix. This improves the previous rank-dependence in the sample complexity of non-convex matrix factorization from quadratic to linear. Furthermore, we extend our theory to the noisy setting, where we show that with noisy measurements, factorized gradient descent with spectral initialization converges to the minimax optimal error up to a factor linear in $\kappa$. Our proof relies on a probabilistic decoupling argument, where we show that the gradient descent iterates are only weakly dependent on the individual entries of the measurement matrices. We expect that our proof technique is of independent interest for other non-convex problems.</description>
      <guid isPermaLink="false">oai:arXiv.org:2408.13276v4</guid>
      <category>stat.ML</category>
      <category>cs.IT</category>
      <category>cs.LG</category>
      <category>math.IT</category>
      <category>math.OC</category>
      <category>math.PR</category>
      <category>math.ST</category>
      <category>stat.TH</category>
      <pubDate>Tue, 29 Jul 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Dominik St\"oger, Yizhe Zhu</dc:creator>
    </item>
    <item>
      <title>Reinforcement Leaning for Infinite-Dimensional Systems</title>
      <link>https://arxiv.org/abs/2409.15737</link>
      <description>arXiv:2409.15737v2 Announce Type: replace-cross 
Abstract: Interest in reinforcement learning (RL) for massive-scale systems consisting of large populations of intelligent agents interacting with heterogeneous environments has witnessed a significant surge in recent years across diverse scientific domains. However, the large-scale nature of these systems often results in high computational costs or compromised performance for most state-of-the-art RL techniques. To address these challenges, we propose a novel RL architecture along with the derivation of effective algorithms to learn optimal policies for arbitrarily large systems of agents. In our formulation, we model such a system as a parameterized control system defined on an infinite-dimensional function space. We then develop a moment kernel transform to map the parameterized system and the value function into a reproducing kernel Hilbert space. This transformation generates a sequence of finite-dimensional moment representations for the RL problem, which are organized into a filtrated structure. Leveraging this RL filtration, we develop a hierarchical algorithm for learning optimal policies for the infinite-dimensional parameterized system. We further enhance the efficiency of the algorithm by exploiting early stopping at each hierarchy, which demonstrates the fast convergence property of the algorithm through the construction of a convergent spectral sequence. The performance and efficiency of the proposed algorithm are validated using practical examples.</description>
      <guid isPermaLink="false">oai:arXiv.org:2409.15737v2</guid>
      <category>eess.SY</category>
      <category>cs.SY</category>
      <category>math.OC</category>
      <pubDate>Tue, 29 Jul 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Wei Zhang, Jr-Shin Li</dc:creator>
    </item>
    <item>
      <title>Sensitivity-preserving of Fisher Information Matrix through random data down-sampling for experimental design</title>
      <link>https://arxiv.org/abs/2409.15906</link>
      <description>arXiv:2409.15906v2 Announce Type: replace-cross 
Abstract: The quality of numerical reconstructions of unknown parameters in inverse problems heavily relies on the chosen data. It is crucial to select data that is sensitive to the parameters, which can be expressed through a sufficient conditioning of the Fisher Information Matrix. We propose a general framework that provides an efficient down-sampling strategy that can select experimental setups that preserves this conditioning, as opposed to the standard optimization approach in optimal experimental design. Matrix sketching techniques from randomized linear algebra is heavily leaned on to achieve this goal. The method requires drawing samples from a sensitivity-informed distribution, and gradient free sampling methods are integrated to execute the data selection. Numerical experiments demonstrate the effectiveness of this method in selecting sensor locations for Schr\"odinger potential reconstruction.</description>
      <guid isPermaLink="false">oai:arXiv.org:2409.15906v2</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <category>math.OC</category>
      <pubDate>Tue, 29 Jul 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-sa/4.0/</dc:rights>
      <dc:creator>Kathrin Hellmuth, Christian Klingenberg, Qin Li</dc:creator>
    </item>
    <item>
      <title>Reinforcement Learning for Finite Space Mean-Field Type Games</title>
      <link>https://arxiv.org/abs/2409.18152</link>
      <description>arXiv:2409.18152v3 Announce Type: replace-cross 
Abstract: Mean field type games (MFTGs) describe Nash equilibria between large coalitions: each coalition consists of a continuum of cooperative agents who maximize the average reward of their coalition while interacting non-cooperatively with a finite number of other coalitions. Although the theory has been extensively developed, we are still lacking efficient and scalable computational methods. Here, we develop reinforcement learning methods for such games in a finite space setting with general dynamics and reward functions. We start by proving that the MFTG solution yields approximate Nash equilibria in finite-size coalition games. We then propose two algorithms. The first is based on the quantization of mean-field spaces and Nash Q-learning. We provide convergence and stability analysis. We then propose a deep reinforcement learning algorithm, which can scale to larger spaces. Numerical experiments in 4 environments with mean-field distributions of dimension up to $200$ show the scalability and efficiency of the proposed method.</description>
      <guid isPermaLink="false">oai:arXiv.org:2409.18152v3</guid>
      <category>cs.GT</category>
      <category>cs.LG</category>
      <category>math.OC</category>
      <pubDate>Tue, 29 Jul 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Kai Shao, Jiacheng Shen, Mathieu Lauri\`ere</dc:creator>
    </item>
    <item>
      <title>The networked input-output economic problem</title>
      <link>https://arxiv.org/abs/2412.13564</link>
      <description>arXiv:2412.13564v2 Announce Type: replace-cross 
Abstract: In this chapter, an input-output economic model with multiple interactive economic systems is considered. The model captures the multi-dimensional nature of the economic sectors or industries in each economic system, the interdependencies among industries within an economic system and across different economic systems, and the influence of demand. To determine the equilibrium price structure of the model, a matrix-weighted updating algorithm is proposed. The equilibrium price structure is proved to be globally asymptotically achieved when certain joint conditions on the matrix-weighted graph and the input-output matrices are satisfied. The theoretical results are then supported by numerical simulations.</description>
      <guid isPermaLink="false">oai:arXiv.org:2412.13564v2</guid>
      <category>eess.SY</category>
      <category>cs.SY</category>
      <category>math.OC</category>
      <pubDate>Tue, 29 Jul 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Minh Hoang Trinh, Nhat-Minh Le-Phan, Hyo-Sung Ahn</dc:creator>
    </item>
    <item>
      <title>Matrix nearness problems and eigenvalue optimization</title>
      <link>https://arxiv.org/abs/2503.14750</link>
      <description>arXiv:2503.14750v2 Announce Type: replace-cross 
Abstract: This book is about solving matrix nearness problems that are related to eigenvalues or singular values or pseudospectra. These problems arise in great diversity in various fields, be they related to dynamics, as in questions of robust stability and robust control, or related to graphs, as in questions of clustering and ranking. Algorithms for such problems work with matrix perturbations that drive eigenvalues or singular values or Rayleigh quotients to desired locations.
  Remarkably, the optimal perturbation matrices are typically of rank one or are projections of rank-1 matrices onto a linear structure, e.g. a prescribed sparsity pattern. In the approach worked out here, these optimal rank-1 perturbations will be determined in a two-level iteration: In the inner iteration, an eigenvalue optimization problem for a fixed perturbation size is to be solved via gradient-based rank-1 matrix differential equations. This amounts to numerically driving a rank-1 matrix, which is represented by two vectors, into a stationary point, mostly starting nearby. The outer iteration determines the optimal perturbation size by solving a scalar nonlinear equation.
  A wide variety of matrix nearness problems, as outlined in the introductory Chapter I, will be tackled in Chapters II to VIII by such an approach and its nontrivial extensions.</description>
      <guid isPermaLink="false">oai:arXiv.org:2503.14750v2</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <category>math.DS</category>
      <category>math.OC</category>
      <pubDate>Tue, 29 Jul 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Nicola Guglielmi, Christian Lubich</dc:creator>
    </item>
    <item>
      <title>Fast Last-Iterate Convergence of SGD in the Smooth Interpolation Regime</title>
      <link>https://arxiv.org/abs/2507.11274</link>
      <description>arXiv:2507.11274v2 Announce Type: replace-cross 
Abstract: We study population convergence guarantees of stochastic gradient descent (SGD) for smooth convex objectives in the interpolation regime, where the noise at optimum is zero or near zero. The behavior of the last iterate of SGD in this setting -- particularly with large (constant) stepsizes -- has received growing attention in recent years due to implications for the training of over-parameterized models, as well as to analyzing forgetting in continual learning and to understanding the convergence of the randomized Kaczmarz method for solving linear systems. We establish that after $T$ steps of SGD on $\beta$-smooth convex loss functions with stepsize $0 &lt; \eta &lt; 2/\beta$, the last iterate exhibits expected excess risk $\widetilde{O}(\frac{1}{\eta (2-\beta \eta) T^{1-\beta\eta/2}} + \frac{\eta}{(2-\beta\eta)^2} T^{\beta\eta/2} \sigma_\star^2)$, where $\sigma_\star^2$ denotes the variance of the stochastic gradients at the optimum. In particular, for a well-tuned stepsize we obtain a near optimal $\widetilde{O}(1/T + \sigma_\star/\sqrt{T})$ rate for the last iterate, extending the results of Varre et al. (2021) beyond least squares regression; and when $\sigma_\star=0$ we obtain a rate of $\smash{O(1/\sqrt T)}$ with $\eta=1/\beta$, improving upon the best-known $\smash{O(T^{-1/4})}$ rate recently established by Evron et al. (2025) in the special case of realizable linear regression.</description>
      <guid isPermaLink="false">oai:arXiv.org:2507.11274v2</guid>
      <category>cs.LG</category>
      <category>math.OC</category>
      <category>stat.ML</category>
      <pubDate>Tue, 29 Jul 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Amit Attia, Matan Schliserman, Uri Sherman, Tomer Koren</dc:creator>
    </item>
  </channel>
</rss>
