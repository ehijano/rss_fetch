<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>q-bio.QM updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/q-bio.QM</link>
    <description>q-bio.QM updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/q-bio.QM" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Tue, 18 Feb 2025 04:16:08 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Mon, 17 Feb 2025 00:00:00 -0500</pubDate>
    <skipDays>
      <day>Sunday</day>
      <day>Saturday</day>
    </skipDays>
    <item>
      <title>Multi-Omics Fusion with Soft Labeling for Enhanced Prediction of Distant Metastasis in Nasopharyngeal Carcinoma Patients after Radiotherapy</title>
      <link>https://arxiv.org/abs/2502.09656</link>
      <description>arXiv:2502.09656v1 Announce Type: new 
Abstract: Omics fusion has emerged as a crucial preprocessing approach in the field of medical image processing, providing significant assistance to several studies. One of the challenges encountered in the integration of omics data is the presence of unpredictability arising from disparities in data sources and medical imaging equipment. In order to overcome this challenge and facilitate the integration of their joint application to specific medical objectives, this study aims to develop a fusion methodology that mitigates the disparities inherent in omics data. The utilization of the multi-kernel late-fusion method has gained significant popularity as an effective strategy for addressing this particular challenge. An efficient representation of the data may be achieved by utilizing a suitable single-kernel function to map the inherent features and afterward merging them in a space with a high number of dimensions. This approach effectively addresses the differences noted before. The inflexibility of label fitting poses a constraint on the use of multi-kernel late-fusion methods in complex nasopharyngeal carcinoma (NPC) datasets, hence affecting the efficacy of general classifiers in dealing with high-dimensional characteristics. This innovative methodology aims to increase the disparity between the two cohorts, hence providing a more flexible structure for the allocation of labels. The examination of the NPC-ContraParotid dataset demonstrates the model's robustness and efficacy, indicating its potential as a valuable tool for predicting distant metastases in patients with nasopharyngeal carcinoma (NPC).</description>
      <guid isPermaLink="false">oai:arXiv.org:2502.09656v1</guid>
      <category>q-bio.QM</category>
      <category>cs.CV</category>
      <category>eess.IV</category>
      <pubDate>Mon, 17 Feb 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <arxiv:DOI>10.1016/j.compbiomed.2023.107684</arxiv:DOI>
      <arxiv:journal_reference>Computers in Biology and Medicine, 168, 107684 (2024)</arxiv:journal_reference>
      <dc:creator>Jiabao Sheng, SaiKit Lam, Jiang Zhang, Yuanpeng Zhang, Jing Cai</dc:creator>
    </item>
    <item>
      <title>Generalizable Cervical Cancer Screening via Large-scale Pretraining and Test-Time Adaptation</title>
      <link>https://arxiv.org/abs/2502.09662</link>
      <description>arXiv:2502.09662v1 Announce Type: new 
Abstract: Cervical cancer is a leading malignancy in female reproductive system. While AI-assisted cytology offers a cost-effective and non-invasive screening solution, current systems struggle with generalizability in complex clinical scenarios. To address this issue, we introduced Smart-CCS, a generalizable Cervical Cancer Screening paradigm based on pretraining and adaptation to create robust and generalizable screening systems. To develop and validate Smart-CCS, we first curated a large-scale, multi-center dataset named CCS-127K, which comprises a total of 127,471 cervical cytology whole-slide images collected from 48 medical centers. By leveraging large-scale self-supervised pretraining, our CCS models are equipped with strong generalization capability, potentially generalizing across diverse scenarios. Then, we incorporated test-time adaptation to specifically optimize the trained CCS model for complex clinical settings, which adapts and refines predictions, improving real-world applicability. We conducted large-scale system evaluation among various cohorts. In retrospective cohorts, Smart-CCS achieved an overall area under the curve (AUC) value of 0.965 and sensitivity of 0.913 for cancer screening on 11 internal test datasets. In external testing, system performance maintained high at 0.950 AUC across 6 independent test datasets. In prospective cohorts, our Smart-CCS achieved AUCs of 0.947, 0.924, and 0.986 in three prospective centers, respectively. Moreover, the system demonstrated superior sensitivity in diagnosing cervical cancer, confirming the accuracy of our cancer screening results by using histology findings for validation. Interpretability analysis with cell and slide predictions further indicated that the system's decision-making aligns with clinical practice. Smart-CCS represents a significant advancement in cancer screening across diverse clinical contexts.</description>
      <guid isPermaLink="false">oai:arXiv.org:2502.09662v1</guid>
      <category>q-bio.QM</category>
      <category>cs.CV</category>
      <category>eess.IV</category>
      <pubDate>Mon, 17 Feb 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Hao Jiang, Cheng Jin, Huangjing Lin, Yanning Zhou, Xi Wang, Jiabo Ma, Li Ding, Jun Hou, Runsheng Liu, Zhizhong Chai, Luyang Luo, Huijuan Shi, Yinling Qian, Qiong Wang, Changzhong Li, Anjia Han, Ronald Cheong Kin Chan, Hao Chen</dc:creator>
    </item>
    <item>
      <title>CellFlow: Simulating Cellular Morphology Changes via Flow Matching</title>
      <link>https://arxiv.org/abs/2502.09775</link>
      <description>arXiv:2502.09775v1 Announce Type: new 
Abstract: Building a virtual cell capable of accurately simulating cellular behaviors in silico has long been a dream in computational biology. We introduce CellFlow, an image-generative model that simulates cellular morphology changes induced by chemical and genetic perturbations using flow matching. Unlike prior methods, CellFlow models distribution-wise transformations from unperturbed to perturbed cell states, effectively distinguishing actual perturbation effects from experimental artifacts such as batch effects -- a major challenge in biological data. Evaluated on chemical (BBBC021), genetic (RxRx1), and combined perturbation (JUMP) datasets, CellFlow generates biologically meaningful cell images that faithfully capture perturbation-specific morphological changes, achieving a 35% improvement in FID scores and a 12% increase in mode-of-action prediction accuracy over existing methods. Additionally, CellFlow enables continuous interpolation between cellular states, providing a potential tool for studying perturbation dynamics. These capabilities mark a significant step toward realizing virtual cell modeling for biomedical research.</description>
      <guid isPermaLink="false">oai:arXiv.org:2502.09775v1</guid>
      <category>q-bio.QM</category>
      <category>cs.CV</category>
      <category>cs.LG</category>
      <category>q-bio.BM</category>
      <category>q-bio.CB</category>
      <pubDate>Mon, 17 Feb 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Yuhui Zhang, Yuchang Su, Chenyu Wang, Tianhong Li, Zoe Wefers, Jeffrey Nirschl, James Burgess, Daisy Ding, Alejandro Lozano, Emma Lundberg, Serena Yeung-Levy</dc:creator>
    </item>
    <item>
      <title>OptimOTU: Taxonomically aware OTU clustering with optimized thresholds and a bioinformatics workflow for metabarcoding data</title>
      <link>https://arxiv.org/abs/2502.10350</link>
      <description>arXiv:2502.10350v1 Announce Type: new 
Abstract: To turn environmentally derived metabarcoding data into community matrices for ecological analysis, sequences must first be clustered into operational taxonomic units (OTUs). This task is particularly complex for data including large numbers of taxa with incomplete reference libraries. OptimOTU offers a taxonomically aware approach to OTU clustering. It uses a set of taxonomically identified reference sequences to choose optimal genetic distance thresholds for grouping each ancestor taxon into clusters which most closely match its descendant taxa. Then, query sequences are clustered according to preliminary taxonomic identifications and the optimized thresholds for their ancestor taxon. The process follows the taxonomic hierarchy, resulting in a full taxonomic classification of all the query sequences into named taxonomic groups as well as placeholder "pseudotaxa" which accommodate the sequences that could not be classified to a named taxon at the corresponding rank. The OptimOTU clustering algorithm is implemented as an R package, with computationally intensive steps implemented in C++ for speed, and incorporating open-source libraries for pairwise sequence alignment. Distances may also be calculated externally, and may be read from a UNIX pipe, allowing clustering of large datasets where the full distance matrix would be inconveniently large to store in memory. The OptimOTU bioinformatics pipeline includes a full workflow for paired-end Illumina sequencing data that incorporates quality filtering, denoising, artifact removal, taxonomic classification, and OTU clustering with OptimOTU. The OptimOTU pipeline is developed for use on high performance computing clusters, and scales to datasets with millions of reads per sample, and tens of thousands of samples.</description>
      <guid isPermaLink="false">oai:arXiv.org:2502.10350v1</guid>
      <category>q-bio.QM</category>
      <pubDate>Mon, 17 Feb 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Brendan Furneaux, Sten Anslan, Panu Somervuo, Jenni Hultman, Nerea Abrego, Tomas Roslin, Otso Ovaskainen</dc:creator>
    </item>
    <item>
      <title>Characterizing nonlinear dynamics by contrastive cartography</title>
      <link>https://arxiv.org/abs/2502.09628</link>
      <description>arXiv:2502.09628v1 Announce Type: cross 
Abstract: The qualitative study of dynamical systems using bifurcation theory is key to understanding systems from biological clocks and neurons to physical phase transitions. Data generated from such systems can feature complex transients, an unknown number of attractors, and stochasticity. Making an analogy to bifurcation analysis, which specifies that useful dynamical features are often invariant to coordinate transforms, we leverage contrastive learning to devise a generic tool to discover dynamical classes from stochastic trajectory data. By providing a model-free trajectory analysis tool, this method automatically recovers the dynamical phase diagram of known models and provides a "map" of dynamical behaviors for a large ensemble of dynamical systems. The method thus provides a way to characterize and compare dynamical trajectories without governing equations or prior knowledge of target behavior. This approach can be used as a standalone analysis tool, or as part of a broader data-driven analysis framework.</description>
      <guid isPermaLink="false">oai:arXiv.org:2502.09628v1</guid>
      <category>nlin.CD</category>
      <category>physics.data-an</category>
      <category>q-bio.QM</category>
      <pubDate>Mon, 17 Feb 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Nicolas Romeo, Chris Chi, Aaron R. Dinner, Elizabeth R. Jerison</dc:creator>
    </item>
    <item>
      <title>Automated Hypothesis Validation with Agentic Sequential Falsifications</title>
      <link>https://arxiv.org/abs/2502.09858</link>
      <description>arXiv:2502.09858v1 Announce Type: cross 
Abstract: Hypotheses are central to information acquisition, decision-making, and discovery. However, many real-world hypotheses are abstract, high-level statements that are difficult to validate directly. This challenge is further intensified by the rise of hypothesis generation from Large Language Models (LLMs), which are prone to hallucination and produce hypotheses in volumes that make manual validation impractical. Here we propose Popper, an agentic framework for rigorous automated validation of free-form hypotheses. Guided by Karl Popper's principle of falsification, Popper validates a hypothesis using LLM agents that design and execute falsification experiments targeting its measurable implications. A novel sequential testing framework ensures strict Type-I error control while actively gathering evidence from diverse observations, whether drawn from existing data or newly conducted procedures. We demonstrate Popper on six domains including biology, economics, and sociology. Popper delivers robust error control, high power, and scalability. Furthermore, compared to human scientists, Popper achieved comparable performance in validating complex biological hypotheses while reducing time by 10 folds, providing a scalable, rigorous solution for hypothesis validation.</description>
      <guid isPermaLink="false">oai:arXiv.org:2502.09858v1</guid>
      <category>cs.LG</category>
      <category>cs.AI</category>
      <category>cs.CL</category>
      <category>q-bio.QM</category>
      <pubDate>Mon, 17 Feb 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Kexin Huang, Ying Jin, Ryan Li, Michael Y. Li, Emmanuel Cand\`es, Jure Leskovec</dc:creator>
    </item>
    <item>
      <title>MassSpecGym: A benchmark for the discovery and identification of molecules</title>
      <link>https://arxiv.org/abs/2410.23326</link>
      <description>arXiv:2410.23326v3 Announce Type: replace 
Abstract: The discovery and identification of molecules in biological and environmental samples is crucial for advancing biomedical and chemical sciences. Tandem mass spectrometry (MS/MS) is the leading technique for high-throughput elucidation of molecular structures. However, decoding a molecular structure from its mass spectrum is exceptionally challenging, even when performed by human experts. As a result, the vast majority of acquired MS/MS spectra remain uninterpreted, thereby limiting our understanding of the underlying (bio)chemical processes. Despite decades of progress in machine learning applications for predicting molecular structures from MS/MS spectra, the development of new methods is severely hindered by the lack of standard datasets and evaluation protocols. To address this problem, we propose MassSpecGym -- the first comprehensive benchmark for the discovery and identification of molecules from MS/MS data. Our benchmark comprises the largest publicly available collection of high-quality labeled MS/MS spectra and defines three MS/MS annotation challenges: de novo molecular structure generation, molecule retrieval, and spectrum simulation. It includes new evaluation metrics and a generalization-demanding data split, therefore standardizing the MS/MS annotation tasks and rendering the problem accessible to the broad machine learning community. MassSpecGym is publicly available at https://github.com/pluskal-lab/MassSpecGym.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.23326v3</guid>
      <category>q-bio.QM</category>
      <category>cs.LG</category>
      <pubDate>Mon, 17 Feb 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Roman Bushuiev, Anton Bushuiev, Niek F. de Jonge, Adamo Young, Fleming Kretschmer, Raman Samusevich, Janne Heirman, Fei Wang, Luke Zhang, Kai D\"uhrkop, Marcus Ludwig, Nils A. Haupt, Apurva Kalia, Corinna Brungs, Robin Schmid, Russell Greiner, Bo Wang, David S. Wishart, Li-Ping Liu, Juho Rousu, Wout Bittremieux, Hannes Rost, Tytus D. Mak, Soha Hassoun, Florian Huber, Justin J. J. van der Hooft, Michael A. Stravs, Sebastian B\"ocker, Josef Sivic, Tom\'a\v{s} Pluskal</dc:creator>
    </item>
    <item>
      <title>Supervised contrastive learning for cell stage classification of animal embryos</title>
      <link>https://arxiv.org/abs/2502.07360</link>
      <description>arXiv:2502.07360v2 Announce Type: replace 
Abstract: Video microscopy, when combined with machine learning, offers a promising approach for studying the early development of in vitro produced (IVP) embryos. However, manually annotating developmental events, and more specifically cell divisions, is time-consuming for a biologist and cannot scale up for practical applications. We aim to automatically classify the cell stages of embryos from 2D time-lapse microscopy videos with a deep learning approach. We focus on the analysis of bovine embryonic development using video microscopy, as we are primarily interested in the application of cattle breeding, and we have created a Bovine Embryos Cell Stages (ECS) dataset. The challenges are three-fold: (1) low-quality images and bovine dark cells that make the identification of cell stages difficult, (2) class ambiguity at the boundaries of developmental stages, and (3) imbalanced data distribution. To address these challenges, we introduce CLEmbryo, a novel method that leverages supervised contrastive learning combined with focal loss for training, and the lightweight 3D neural network CSN-50 as an encoder. We also show that our method generalizes well. CLEmbryo outperforms state-of-the-art methods on both our Bovine ECS dataset and the publicly available NYU Mouse Embryos dataset.</description>
      <guid isPermaLink="false">oai:arXiv.org:2502.07360v2</guid>
      <category>q-bio.QM</category>
      <category>cs.CV</category>
      <pubDate>Mon, 17 Feb 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Yasmine Hachani (LACODAM), Patrick Bouthemy (SAIRPICO), Elisa Fromont (LACODAM), Sylvie Ruffini (UVSQ,INRAE), Ludivine Laffont (UVSQ,INRAE), Alline de Paula Reis (BREED,ENVA)</dc:creator>
    </item>
    <item>
      <title>A note on promotion time cure models with a new biological consideration</title>
      <link>https://arxiv.org/abs/2408.17188</link>
      <description>arXiv:2408.17188v2 Announce Type: replace-cross 
Abstract: We introduce a generalized promotion time cure model motivated by a new biological consideration. The new approach is flexible to model heterogeneous survival data, in particular for addressing intra-sample heterogeneity. We also indicate that the new approach is suited to model a series or parallel system consisting of multiple subsystems in reliability analysis.</description>
      <guid isPermaLink="false">oai:arXiv.org:2408.17188v2</guid>
      <category>stat.ME</category>
      <category>q-bio.GN</category>
      <category>q-bio.QM</category>
      <category>q-bio.SC</category>
      <pubDate>Mon, 17 Feb 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Zhi Zhao, Fatih K{\i}z{\i}laslan</dc:creator>
    </item>
    <item>
      <title>Learning Stochastic Dynamics from Snapshots through Regularized Unbalanced Optimal Transport</title>
      <link>https://arxiv.org/abs/2410.00844</link>
      <description>arXiv:2410.00844v2 Announce Type: replace-cross 
Abstract: Reconstructing dynamics using samples from sparsely time-resolved snapshots is an important problem in both natural sciences and machine learning. Here, we introduce a new deep learning approach for solving regularized unbalanced optimal transport (RUOT) and inferring continuous unbalanced stochastic dynamics from observed snapshots. Based on the RUOT form, our method models these dynamics without requiring prior knowledge of growth and death processes or additional information, allowing them to be learned directly from data. Theoretically, we explore the connections between the RUOT and Schr\"odinger bridge problem and discuss the key challenges and potential solutions. The effectiveness of our method is demonstrated with a synthetic gene regulatory network, high-dimensional Gaussian Mixture Model, and single-cell RNA-seq data from blood development. Compared with other methods, our approach accurately identifies growth and transition patterns, eliminates false transitions, and constructs the Waddington developmental landscape. Our code is available at: https://github.com/zhenyiizhang/DeepRUOT.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.00844v2</guid>
      <category>cs.LG</category>
      <category>math.OC</category>
      <category>physics.comp-ph</category>
      <category>q-bio.QM</category>
      <pubDate>Mon, 17 Feb 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <dc:creator>Zhenyi Zhang, Tiejun Li, Peijie Zhou</dc:creator>
    </item>
    <item>
      <title>New tools for comparing classical and neural ODE models for tumor growth</title>
      <link>https://arxiv.org/abs/2502.07964</link>
      <description>arXiv:2502.07964v2 Announce Type: replace-cross 
Abstract: A new computational tool TumorGrowth$.$jl for modeling tumor growth is introduced. The tool allows the comparison of standard textbook models, such as General Bertalanffy and Gompertz, with some newer models, including, for the first time, neural ODE models. As an application, we revisit a human meta-study of non-small cell lung cancer and bladder cancer lesions, in patients undergoing two different treatment options, to determine if previously reported performance differences are statistically significant, and if newer, more complex models perform any better. In a population of examples with at least four time-volume measurements available for calibration, and an average of about 6.3, our main conclusion is that the General Bertalanffy model has superior performance, on average. However, where more measurements are available, we argue that more complex models, capable of capturing rebound and relapse behavior, may be better choices.</description>
      <guid isPermaLink="false">oai:arXiv.org:2502.07964v2</guid>
      <category>cs.LG</category>
      <category>q-bio.QM</category>
      <pubDate>Mon, 17 Feb 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Anthony D. Blaom, Samuel Okon</dc:creator>
    </item>
  </channel>
</rss>
