<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>stat.ME updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/stat.ME</link>
    <description>stat.ME updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/stat.ME" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Mon, 26 May 2025 04:00:18 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Mon, 26 May 2025 00:00:00 -0400</pubDate>
    <skipDays>
      <day>Saturday</day>
      <day>Sunday</day>
    </skipDays>
    <item>
      <title>Transfer Faster, Price Smarter: Minimax Dynamic Pricing under Cross-Market Preference Shift</title>
      <link>https://arxiv.org/abs/2505.17203</link>
      <description>arXiv:2505.17203v1 Announce Type: new 
Abstract: We study contextual dynamic pricing when a target market can leverage K auxiliary markets -- offline logs or concurrent streams -- whose mean utilities differ by a structured preference shift. We propose Cross-Market Transfer Dynamic Pricing (CM-TDP), the first algorithm that provably handles such model-shift transfer and delivers minimax-optimal regret for both linear and non-parametric utility models.
  For linear utilities of dimension d, where the difference between source- and target-task coefficients is $s_{0}$-sparse, CM-TDP attains regret $\tilde{O}((d*K^{-1}+s_{0})\log T)$. For nonlinear demand residing in a reproducing kernel Hilbert space with effective dimension $\alpha$, complexity $\beta$ and task-similarity parameter $H$, the regret becomes $\tilde{O}\!(K^{-2\alpha\beta/(2\alpha\beta+1)}T^{1/(2\alpha\beta+1)} + H^{2/(2\alpha+1)}T^{1/(2\alpha+1)})$, matching information-theoretic lower bounds up to logarithmic factors. The RKHS bound is the first of its kind for transfer pricing and is of independent interest.
  Extensive simulations show up to 50% lower cumulative regret and 5 times faster learning relative to single-market pricing baselines. By bridging transfer learning, robust aggregation, and revenue optimization, CM-TDP moves toward pricing systems that transfer faster, price smarter.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.17203v1</guid>
      <category>stat.ME</category>
      <category>cs.LG</category>
      <category>stat.AP</category>
      <pubDate>Mon, 26 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Yi Zhang, Elynn Chen, Yujun Yan</dc:creator>
    </item>
    <item>
      <title>Reservoir Designs for Online Paired Experiments</title>
      <link>https://arxiv.org/abs/2505.17247</link>
      <description>arXiv:2505.17247v1 Announce Type: new 
Abstract: We study the question of how best to stratify units into matched pairs in online experiments, so that units within a pair receive opposite treatment. Past work by Bai, Romano, and Shaikh (2022) has demonstrated the asymptotic variance improvement that comes from pairing units with similar covariates in this way. However, their method requires knowing the covariates for all units a priori; this is not the case in many A/B testing problems, in which units arrive one at a time and must have treatment assigned immediately. Inspired by the terminology of Kapelner and Krieger (2014), we thus introduce the notion of a reservoir design, which maintains a reservoir of unpaired units that can potentially be paired with an incoming unit. We construct a particular reservoir design that uses a distance-based criterion to determine pairing and, via a packing argument, prove conditions under which it attains the asymptotic variance improvement of Bai, Romano, and Shaikh (2022). We illustrate our reservoir design on synthetic and semi-synthetic examples and find improved performance relative to both IID sampling and the design of Kapelner and Krieger (2014).</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.17247v1</guid>
      <category>stat.ME</category>
      <pubDate>Mon, 26 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Tim Morrison</dc:creator>
    </item>
    <item>
      <title>Efficient Adaptive Experimentation with Non-Compliance</title>
      <link>https://arxiv.org/abs/2505.17468</link>
      <description>arXiv:2505.17468v1 Announce Type: new 
Abstract: We study the problem of estimating the average treatment effect (ATE) in adaptive experiments where treatment can only be encouraged--rather than directly assigned--via a binary instrumental variable. Building on semiparametric efficiency theory, we derive the efficiency bound for ATE estimation under arbitrary, history-dependent instrument-assignment policies, and show it is minimized by a variance-aware allocation rule that balances outcome noise and compliance variability. Leveraging this insight, we introduce AMRIV--an \textbf{A}daptive, \textbf{M}ultiply-\textbf{R}obust estimator for \textbf{I}nstrumental-\textbf{V}ariable settings with variance-optimal assignment. AMRIV pairs (i) an online policy that adaptively approximates the optimal allocation with (ii) a sequential, influence-function-based estimator that attains the semiparametric efficiency bound while retaining multiply-robust consistency. We establish asymptotic normality, explicit convergence rates, and anytime-valid asymptotic confidence sequences that enable sequential inference. Finally, we demonstrate the practical effectiveness of our approach through empirical studies, showing that adaptive instrument assignment, when combined with the AMRIV estimator, yields improved efficiency and robustness compared to existing baselines.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.17468v1</guid>
      <category>stat.ME</category>
      <category>cs.LG</category>
      <category>stat.ML</category>
      <pubDate>Mon, 26 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Miruna Oprescu, Brian M Cho, Nathan Kallus</dc:creator>
    </item>
    <item>
      <title>Sampling from Conditional Distributions of Simplified Vines</title>
      <link>https://arxiv.org/abs/2505.17706</link>
      <description>arXiv:2505.17706v1 Announce Type: new 
Abstract: Simplified vine copulas are flexible tools over standard multivariate distributions for modeling and understanding different dependence properties in high-dimensional data. Their conditional distributions are of utmost importance, from statistical learning to graphical models. However, the conditional densities of vine copulas and, thus, vine distributions cannot be obtained in closed form without integration for all possible sets of conditioning variables. We propose a Markov Chain Monte Carlo based approach of using Hamiltonian Monte Carlo to sample from any conditional distribution of arbitrarily specified simplified vine copulas and thus vine distributions. We show its accuracy through simulation studies and analyze data of multiple maize traits such as flowering times, plant height, and vigor. Use cases from predicting traits to estimating conditional Kendall's tau are presented.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.17706v1</guid>
      <category>stat.ME</category>
      <category>stat.CO</category>
      <pubDate>Mon, 26 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Ariane Hanebeck, \"Ozge \c{S}ahin, Petra Havl\'i\v{c}kov\'a, Claudia Czado</dc:creator>
    </item>
    <item>
      <title>Anytime-valid simultaneous lower confidence bounds for the true discovery proportion</title>
      <link>https://arxiv.org/abs/2505.17803</link>
      <description>arXiv:2505.17803v1 Announce Type: new 
Abstract: We propose a method that combines the closed testing framework with the concept of safe anytime-valid inference (SAVI) to compute lower confidence bounds for the true discovery proportion in a multiple testing setting. The proposed procedure provides confidence bounds that are valid at every observation time point and that are simultaneous for all possible subsets of hypotheses. While the hypotheses are assumed to be fixed over time, the subsets of interest may vary. Anytime-valid simultaneous confidence bounds allow us to sequentially update the bounds over time and allow for optional stopping. This is a desirable property in practical applications such as neuroscience, where data acquisition is costly and time-consuming. We also present a computational shortcut which makes the application of the proposed procedure feasible when the number of hypotheses under consideration is large. We illustrate the performance of the proposed method in a simulation study and give some practical guidelines on the implementation of the proposed procedure.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.17803v1</guid>
      <category>stat.ME</category>
      <pubDate>Mon, 26 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Friederike Preusse</dc:creator>
    </item>
    <item>
      <title>Federated Causal Inference from Multi-Site Observational Data via Propensity Score Aggregation</title>
      <link>https://arxiv.org/abs/2505.17961</link>
      <description>arXiv:2505.17961v1 Announce Type: new 
Abstract: Causal inference typically assumes centralized access to individual-level data. Yet, in practice, data are often decentralized across multiple sites, making centralization infeasible due to privacy, logistical, or legal constraints. We address this by estimating the Average Treatment Effect (ATE) from decentralized observational data using federated learning, which enables inference through the exchange of aggregate statistics rather than individual-level data. We propose a novel method to estimate propensity scores in a (non-)parametric manner by computing a federated weighted average of local scores, using two theoretically grounded weighting schemes -- Membership Weights (MW) and Density Ratio Weights (DW) -- that balance communication efficiency and model flexibility. These federated scores are then used to construct two ATE estimators: the Federated Inverse Propensity Weighting estimator (Fed-IPW) and its augmented variant (Fed-AIPW). Unlike meta-analysis methods, which fail when any site violates positivity, our approach leverages heterogeneity in treatment assignment across sites to improve overlap. We show that Fed-IPW and Fed-AIPW perform well under site-level heterogeneity in sample sizes, treatment mechanisms, and covariate distributions, with theoretical analysis and experiments on simulated and real-world data highlighting their strengths and limitations relative to meta-analysis and related methods.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.17961v1</guid>
      <category>stat.ME</category>
      <category>cs.AI</category>
      <category>math.ST</category>
      <category>stat.AP</category>
      <category>stat.TH</category>
      <pubDate>Mon, 26 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Khellaf R\'emi, Bellet Aur\'elien, Josse Julie</dc:creator>
    </item>
    <item>
      <title>How does noise protection affect the accuracy of life expectancy and other demographic indicators?</title>
      <link>https://arxiv.org/abs/2505.17963</link>
      <description>arXiv:2505.17963v1 Announce Type: new 
Abstract: New and efficient methods based on noise addition to protect the confidentiality in population statistics have been developed, tested and applied in census production by various members of the European Statistical System over the past years. Basic demographic statistics - such as population stocks, live births and deaths by age, sex and region - may be protected in a similar way, but also form the raw input to calculate various demographic indicators. This paper analyses the impact on the accuracy of some selected indicators, namely fertility and mortality rates and life expectancies, under the assumption that the raw input counts are protected with a generic noise method with fixed variance parameter, by comparing the size of noise uncertainties with intrinsic statistical uncertainties using a Poisson model. As a by-product, we derive and validate numerically a closed analytical expression for the variance of life expectancies in a certain class of calculation models as a function of the variance of input mortality data. This expression also allows to calculate analytically the statistical uncertainty of life expectancies using the mentioned Poisson model for the input death counts.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.17963v1</guid>
      <category>stat.ME</category>
      <pubDate>Mon, 26 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Fabian Bach</dc:creator>
    </item>
    <item>
      <title>The bipartite structure of treatment-trial networks reveals the flow of information in network meta-analysis</title>
      <link>https://arxiv.org/abs/2505.18036</link>
      <description>arXiv:2505.18036v1 Announce Type: new 
Abstract: Network meta-analysis (NMA) combines evidence from multiple trials comparing treatment options for the same condition. The method derives its name from a graphical representation of the data where nodes are treatments, and edges represent comparisons between treatments in trials. However, edges in this graph are limited to pairwise comparisons and fail to represent trials that compare more than two treatments. In this paper, we describe NMA as a bipartite graph where trials define a second type of node. Edges then correspond to the arms of trials, connecting each trial node to the treatment nodes it compares. We consider an NMA model parameterized in terms of the observations in each arm. By linking the hat matrix of this model to the bipartite framework, we reveal how evidence flows through the arms of trials. We then define a random walk on the bipartite graph and propose two conjectures that relate the movement of this walker to evidence flow. We illustrate our methods on a network of treatments for plaque psoriasis and verify our conjectures in simulations on randomly generated graphs. The bipartite framework provides new insights into the evidence structure of NMA and the role of individual trials in producing NMA estimates.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.18036v1</guid>
      <category>stat.ME</category>
      <pubDate>Mon, 26 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Annabel L Davies</dc:creator>
    </item>
    <item>
      <title>Assessing the impact of variance heterogeneity and misspecification in mixed-effects location-scale models</title>
      <link>https://arxiv.org/abs/2505.18038</link>
      <description>arXiv:2505.18038v1 Announce Type: new 
Abstract: Linear Mixed Model (LMM) is a common statistical approach to model the relation between exposure and outcome while capturing individual variability through random effects. However, this model assumes the homogeneity of the error term's variance. Breaking this assumption, known as homoscedasticity, can bias estimates and, consequently, may change a study's conclusions. If this assumption is unmet, the mixed-effect location-scale model (MELSM) offers a solution to account for within-individual variability. Our work explores how LMMs and MELSMs behave when the homoscedasticity assumption is not met. Further, we study how misspecification affects inference for MELSM. To this aim, we propose a simulation study with longitudinal data and evaluate the estimates' bias and coverage. Our simulations show that neglecting heteroscedasticity in LMMs leads to loss of coverage for the estimated coefficients and biases the estimates of the standard deviations of the random effects. In MELSMs, scale misspecification does not bias the location model, but location misspecification alters the scale estimates. Our simulation study illustrates the importance of modelling heteroscedasticity, with potential implications beyond mixed effect models, for generalised linear mixed models for non-normal outcomes and joint models with survival data.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.18038v1</guid>
      <category>stat.ME</category>
      <category>stat.CO</category>
      <pubDate>Mon, 26 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Vincent Jeanselme, Marco Palma, Jessica K Barrett</dc:creator>
    </item>
    <item>
      <title>Loss Functions for Measuring the Accuracy of Nonnegative Cross-Sectional Predictions</title>
      <link>https://arxiv.org/abs/2505.18130</link>
      <description>arXiv:2505.18130v1 Announce Type: new 
Abstract: Measuring the accuracy of cross-sectional predictions is a subjective problem. Generally, this problem is avoided. In contrast, this paper confronts subjectivity up front by eliciting an impartial decision-maker's preferences. These preferences are embedded into an axiomatically-derived loss function, the simplest version of which is described. The parameters of the loss function can be estimated by linear regression. Specification tests for this function are described. This framework is extended to weighted averages of estimates to find the optimal weightings. Rescalings to account for changes in control data or base year data are considered. A special case occurs when the predictions represent resource allocations: the apportionment literature is used to construct the Webster-Saint Lague Rule, a particular parametrization of the loss function. These loss functions are compared to those existing in the literature. Finally, a bias measure is created that uses signed versions of these loss functions.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.18130v1</guid>
      <category>stat.ME</category>
      <category>math.ST</category>
      <category>stat.TH</category>
      <pubDate>Mon, 26 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/publicdomain/zero/1.0/</dc:rights>
      <dc:creator>Charles D. Coleman</dc:creator>
    </item>
    <item>
      <title>Statistical Inference for Online Algorithms</title>
      <link>https://arxiv.org/abs/2505.17300</link>
      <description>arXiv:2505.17300v1 Announce Type: cross 
Abstract: Construction of confidence intervals and hypothesis tests for functionals based on asymptotically normal estimators is a classical topic in statistical inference. The simplest and in many cases optimal inference procedure is the Wald interval or the likelihood ratio test, both of which require an estimator and an estimate of the asymptotic variance of the estimator. Estimators obtained from online/sequential algorithms forces one to consider the computational aspects of the inference problem, i.e., one cannot access all of the data as many times as needed. Several works on this topic explored the online estimation of asymptotic variance. In this article, we propose computationally efficient, rate-optimal, and asymptotically valid confidence regions based on the output of online algorithms {\em without} estimating the asymptotic variance. As a special case, this implies inference from any algorithm that yields an asymptotically normal estimator. We focus our efforts on stochastic gradient descent with Polyak averaging to understand the practical performance of the proposed method.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.17300v1</guid>
      <category>stat.ML</category>
      <category>cs.LG</category>
      <category>stat.CO</category>
      <category>stat.ME</category>
      <pubDate>Mon, 26 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Selina Carter, Arun K Kuchibhotla</dc:creator>
    </item>
    <item>
      <title>A Novel Bayesian Extrapolation Design for Assessing Equivalence in Exposure-Response Curves between Pediatric and Adult Populations</title>
      <link>https://arxiv.org/abs/2505.17397</link>
      <description>arXiv:2505.17397v1 Announce Type: cross 
Abstract: Development of effective treatments in pediatric population poses unique scientific and ethical challenges in addition to the small population. In this regard, both the U.S. and E.U. regulations suggest a complementary strategy, pediatric extrapolation, based on assessing the relevance of existing information in the adult population to the pediatric population. The pediatric extrapolation approach often relies on data extrapolation from adults, contingent upon evidence of similar disease progression, pharmacology and clinical response to treatment between adult and children. Similarity evaluation in pharmacology is usually characterized through the exposure-response relationship. Current methodologies for comparing exposure-response (E-R) curves between these groups are inadequate, typically focusing on isolated data points rather than the entire curve spectrum (Zhang et al., 2021). To overcome this limitation, we introduce an innovative Bayesian approach for a comprehensive evaluation of E-R curve similarities between adult and pediatric populations. This method encompasses the entire curve, employing logistic regression for binary endpoints. We have developed an algorithm to determine sample size and key design parameters, such as the Bayesian posterior probability threshold, and utilize the maximum curve distance as a measure of similarity. Integrating Bayesian and frequentist principles, our approach involves developing a method to simulate datasets under both null and alternative hypotheses, allowing for type I error and type II error control. Simulation studies and sensitivity analyses demonstrate that our method maintains a stable performance with type I error and type II error control.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.17397v1</guid>
      <category>stat.AP</category>
      <category>stat.ME</category>
      <pubDate>Mon, 26 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Zhongheng Cai, Lian Ma, Jingjing Ye, Haitao Pan</dc:creator>
    </item>
    <item>
      <title>A Position Paper on the Automatic Generation of Machine Learning Leaderboards</title>
      <link>https://arxiv.org/abs/2505.17465</link>
      <description>arXiv:2505.17465v1 Announce Type: cross 
Abstract: An important task in machine learning (ML) research is comparing prior work, which is often performed via ML leaderboards: a tabular overview of experiments with comparable conditions (e.g., same task, dataset, and metric). However, the growing volume of literature creates challenges in creating and maintaining these leaderboards. To ease this burden, researchers have developed methods to extract leaderboard entries from research papers for automated leaderboard curation. Yet, prior work varies in problem framing, complicating comparisons and limiting real-world applicability. In this position paper, we present the first overview of Automatic Leaderboard Generation (ALG) research, identifying fundamental differences in assumptions, scope, and output formats. We propose an ALG unified conceptual framework to standardise how the ALG task is defined. We offer ALG benchmarking guidelines, including recommendations for datasets and metrics that promote fair, reproducible evaluation. Lastly, we outline challenges and new directions for ALG, such as, advocating for broader coverage by including all reported results and richer metadata.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.17465v1</guid>
      <category>cs.CL</category>
      <category>stat.ME</category>
      <pubDate>Mon, 26 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Roelien C Timmer, Yufang Hou, Stephen Wan</dc:creator>
    </item>
    <item>
      <title>M-learner:A Flexible And Powerful Framework To Study Heterogeneous Treatment Effect In Mediation Model</title>
      <link>https://arxiv.org/abs/2505.17917</link>
      <description>arXiv:2505.17917v1 Announce Type: cross 
Abstract: We propose a novel method, termed the M-learner, for estimating heterogeneous indirect and total treatment effects and identifying relevant subgroups within a mediation framework. The procedure comprises four key steps. First, we compute individual-level conditional average indirect/total treatment effect Second, we construct a distance matrix based on pairwise differences. Third, we apply tSNE to project this matrix into a low-dimensional Euclidean space, followed by K-means clustering to identify subgroup structures. Finally, we calibrate and refine the clusters using a threshold-based procedure to determine the optimal configuration. To the best of our knowledge, this is the first approach specifically designed to capture treatment effect heterogeneity in the presence of mediation. Experimental results validate the robustness and effectiveness of the proposed framework. Application to the real-world Jobs II dataset highlights the broad adaptability and potential applicability of our method.Code is available at https: //anonymous.4open.science/r/M-learner-C4BB.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.17917v1</guid>
      <category>stat.ML</category>
      <category>cs.LG</category>
      <category>stat.ME</category>
      <pubDate>Mon, 26 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Xingyu Li, Qing Liu, Tony Jiang, Hong Amy Xia, Brian P. Hobbs, Peng Wei</dc:creator>
    </item>
    <item>
      <title>Rethinking Climate Econometrics: Data Cleaning, Flexible Trend Controls, and Predictive Validation</title>
      <link>https://arxiv.org/abs/2505.18033</link>
      <description>arXiv:2505.18033v1 Announce Type: cross 
Abstract: We assess empirical models in climate econometrics using modern statistical learning techniques. Existing approaches are prone to outliers, ignore sample dependencies, and lack principled model selection. To address these issues, we implement robust preprocessing, nonparametric time-trend controls, and out-of-sample validation across 700+ climate variables. Our analysis reveals that widely used models and predictors-such as mean temperature-have little predictive power. A previously overlooked humidity-related variable emerges as the most consistent predictor, though even its performance remains limited. These findings challenge the empirical foundations of climate econometrics and point toward a more robust, data-driven path forward.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.18033v1</guid>
      <category>stat.AP</category>
      <category>stat.ME</category>
      <pubDate>Mon, 26 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Christof Sch\"otz, Jan Hassel, Christian Otto</dc:creator>
    </item>
    <item>
      <title>How Can I Publish My LLM Benchmark Without Giving the True Answers Away?</title>
      <link>https://arxiv.org/abs/2505.18102</link>
      <description>arXiv:2505.18102v1 Announce Type: cross 
Abstract: Publishing a large language model (LLM) benchmark on the Internet risks contaminating future LLMs: the benchmark may be unintentionally (or intentionally) used to train or select a model. A common mitigation is to keep the benchmark private and let participants submit their models or predictions to the organizers. However, this strategy will require trust in a single organization and still permits test-set overfitting through repeated queries. To overcome this issue, we propose a way to publish benchmarks without completely disclosing the ground-truth answers to the questions, while still maintaining the ability to openly evaluate LLMs. Our main idea is to inject randomness to the answers by preparing several logically correct answers, and only include one of them as the solution in the benchmark. This reduces the best possible accuracy, i.e., Bayes accuracy, of the benchmark. Not only is this helpful to keep us from disclosing the ground truth, but this approach also offers a test for detecting data contamination. In principle, even fully capable models should not surpass the Bayes accuracy. If a model surpasses this ceiling despite this expectation, this is a strong signal of data contamination. We present experimental evidence that our method can detect data contamination accurately on a wide range of benchmarks, models, and training methodologies.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.18102v1</guid>
      <category>cs.LG</category>
      <category>cs.AI</category>
      <category>cs.CL</category>
      <category>stat.ME</category>
      <pubDate>Mon, 26 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Takashi Ishida, Thanawat Lodkaew, Ikko Yamane</dc:creator>
    </item>
    <item>
      <title>A new measure of dependence: Integrated $R^2$</title>
      <link>https://arxiv.org/abs/2505.18146</link>
      <description>arXiv:2505.18146v1 Announce Type: cross 
Abstract: We propose a new measure of dependence that quantifies the degree to which a random variable $Y$ depends on a random vector $X$. This measure is zero if and only if $Y$ and $X$ are independent, and equals one if and only if $Y$ is a measurable function of $X$. We introduce a simple and interpretable estimator that is comparable in ease of computation to classical correlation coefficients such as Pearson's, Spearman's, or Chatterjee's. Building on this coefficient, we develop a model-free variable selection algorithm, feature ordering by dependence (FORD), inspired by FOCI. FORD requires no tuning parameters and is provably consistent under suitable sparsity assumptions. We demonstrate its effectiveness and improvements over FOCI through experiments on both synthetic and real datasets.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.18146v1</guid>
      <category>math.ST</category>
      <category>cs.IT</category>
      <category>math.IT</category>
      <category>math.PR</category>
      <category>stat.ME</category>
      <category>stat.TH</category>
      <pubDate>Mon, 26 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Mona Azadkia, Pouya Roudaki</dc:creator>
    </item>
    <item>
      <title>Advances in Bayesian random partition models: A comprehensive review</title>
      <link>https://arxiv.org/abs/2303.17182</link>
      <description>arXiv:2303.17182v3 Announce Type: replace 
Abstract: Clustering is a crucial task in various domains of knowledge, including medicine, epidemiology, genomics, environmental science, economics, and visual sciences, among others. Methodologies for inferring the number of clusters have often been shown to be inconsistent, and incorporating a dependence structure among clusters introduces additional challenges in the estimation process. In a Bayesian framework, clustering is performed by treating the unknown partition as a random object and defining a prior distribution for it. This prior distribution can be induced by models assumed for the observations or directly defined on the partition itself. However, recent findings have revealed difficulties in consistently estimating the number of clusters and, consequently, the partition. Furthermore, summarizing the posterior distribution of the partition remains an open problem due to the high dimensionality of the partition space. This study aims to review Bayesian approaches for random partition models, highlighting the advantages and disadvantages of each method, and suggesting potential avenues for future research.</description>
      <guid isPermaLink="false">oai:arXiv.org:2303.17182v3</guid>
      <category>stat.ME</category>
      <pubDate>Mon, 26 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Clara Grazian</dc:creator>
    </item>
    <item>
      <title>Integrating Random Forests and Generalized Linear Models for Improved Accuracy and Interpretability</title>
      <link>https://arxiv.org/abs/2307.01932</link>
      <description>arXiv:2307.01932v2 Announce Type: replace 
Abstract: Random forests (RFs) are among the most popular supervised learning algorithms due to their nonlinear flexibility and ease-of-use. However, as black box models, they can only be interpreted via algorithmically-defined feature importance methods, such as Mean Decrease in Impurity (MDI), which have been observed to be highly unstable and have ambiguous scientific meaning. Furthermore, they can perform poorly in the presence of smooth or additive structure. To address this, we reinterpret decision trees and MDI as linear regression and $R^2$ values, respectively, with respect to engineered features associated with the tree's decision splits. This allows us to combine the respective strengths of RFs and generalized linear models in a framework called RF+, which also yields an improved feature importance method we call MDI+. Through extensive data-inspired simulations and real-world datasets, we show that RF+ improves prediction accuracy over RFs and that MDI+ outperforms popular feature importance measures in identifying signal features, often yielding more than a 10% improvement over its closest competitor. In case studies on drug response prediction and breast cancer subtyping, we further show that MDI+ extracts well-established genes with significantly greater stability compared to existing feature importance measures.</description>
      <guid isPermaLink="false">oai:arXiv.org:2307.01932v2</guid>
      <category>stat.ME</category>
      <category>cs.AI</category>
      <category>cs.LG</category>
      <category>stat.ML</category>
      <pubDate>Mon, 26 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Abhineet Agarwal, Ana M. Kenney, Yan Shuo Tan, Tiffany M. Tang, Bin Yu</dc:creator>
    </item>
    <item>
      <title>Power calculation for cross-sectional stepped wedge cluster randomized trials with a time-to-event endpoint</title>
      <link>https://arxiv.org/abs/2312.13097</link>
      <description>arXiv:2312.13097v3 Announce Type: replace 
Abstract: Stepped wedge cluster randomized trials (SW-CRTs) are a form of randomized trial whereby clusters are progressively transitioned from control to intervention, with the timing of transition randomized for each cluster. An important task at the design stage is to ensure that the planned trial has sufficient power. While methods for determining power have been well-developed for SW-CRTs with continuous and binary outcomes, limited methods for power calculation are available for SW-CRTs with censored time-to-event outcomes. In this article, we propose a stratified marginal Cox model to analyze cross-sectional SW-CRTs and then derive an explicit expression of the robust sandwich variance to facilitate power calculations without the need for computationally intensive simulations. Power formulas based on both the Wald and robust score tests are developed, assuming constant within-period and between-period correlation parameters, and are further validated via simulation under different finite-sample scenarios. Finally, we illustrate our methods in the context of a SW-CRT testing the effect of a new electronic reminder system on time to catheter removal in hospital settings. We also offer an R Shiny application to facilitate sample size and power calculations using our proposed methods.</description>
      <guid isPermaLink="false">oai:arXiv.org:2312.13097v3</guid>
      <category>stat.ME</category>
      <pubDate>Mon, 26 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Mary Ryan Baumann, Denise Esserman, Monica Taljaard, Fan Li</dc:creator>
    </item>
    <item>
      <title>ANPP: the Adapted Normalized Power Prior for Borrowing Information from Multiple Historical Datasets in Clinical Trials</title>
      <link>https://arxiv.org/abs/2404.02453</link>
      <description>arXiv:2404.02453v2 Announce Type: replace 
Abstract: The power prior is a popular class of informative priors for incorporating information from historical data. It involves raising the likelihood for the historical data to a power, which acts as a discounting parameter. When the discounting parameter is modeled as random, the normalized power prior (NPP) is recommended. When there are multiple historical datasets, there has been limited research on how to choose priors for the multiple discounting parameters of the NPP to induce desirable information borrowing behavior. In this work, we address this question by investigating the analytical relationship between the NPP and the Bayesian hierarchical model (BHM), which is a widely used method for synthesizing information from different sources. We develop the adapted normalized power prior (ANPP), which establishes dependence between the dataset-specific discounting parameters of the NPP, leading to inferences that are identical to the BHM. We establish a direct relationship between the prior for the dataset-specific discounting parameters of the ANPP and the prior for the variance parameter of the BHM. Establishing this relationship not only justifies the NPP from the perspective of hierarchical modeling, but also achieves easy prior elicitation for the NPP for the purpose of dynamic borrowing. We examine the borrowing properties of the ANPP through simulations, and apply it to a case study for a pediatric lupus trial.</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.02453v2</guid>
      <category>stat.ME</category>
      <category>math.ST</category>
      <category>stat.TH</category>
      <pubDate>Mon, 26 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Yueqi Shen, Matthew A. Psioda, Luiz M. Carvalho, Joseph G. Ibrahim</dc:creator>
    </item>
    <item>
      <title>Conformal Prediction for Ensembles: Improving Efficiency via Score-Based Aggregation</title>
      <link>https://arxiv.org/abs/2405.16246</link>
      <description>arXiv:2405.16246v3 Announce Type: replace 
Abstract: Distribution-free uncertainty estimation for ensemble methods is increasingly desirable due to the widening deployment of multi-modal black-box predictive models. Conformal prediction is one approach that avoids such distributional assumptions. Methods for conformal aggregation have in turn been proposed for ensembled prediction, where the prediction regions of individual models are merged as to retain coverage guarantees while minimizing conservatism. Merging the prediction regions directly, however, sacrifices structures present in the conformal scores that can further reduce conservatism. We, therefore, propose a novel framework that extends the standard scalar formulation of a score function to a multivariate score that produces more efficient prediction regions. We then demonstrate that such a framework can be efficiently leveraged in both classification and predict-then-optimize regression settings downstream and empirically show the advantage over alternate conformal aggregation methods.</description>
      <guid isPermaLink="false">oai:arXiv.org:2405.16246v3</guid>
      <category>stat.ME</category>
      <category>stat.ML</category>
      <pubDate>Mon, 26 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Eduardo Ochoa Rivera, Yash Patel, Ambuj Tewari</dc:creator>
    </item>
    <item>
      <title>Primed Priors for Simulation-Based Validation of Bayesian Models</title>
      <link>https://arxiv.org/abs/2408.06504</link>
      <description>arXiv:2408.06504v2 Announce Type: replace 
Abstract: Simulation-based calibration (SBC) is a method for validating inference algorithms and model implementations through repeated inference on data simulated from a generative model. For a model to be generative, one must specify proper priors. However, in all but the simplest of cases, choosing priors for every model parameter is a nontrivial task. In particular, priors that are too broad can produce numerical issues due to extreme parameter values while overly narrow ones can exclude precisely those regions of the parameter space where legitimate problems in the implementation would have manifested. When the data to be analyzed is already available, the issue can be sidestepped by checking calibration on the corresponding posterior, but that is not always a viable option. In this paper, we adapt the framework of catalytic priors, which have been recently proposed for construction of data-based prior distributions, and propose primed priors, which do not require real data and can therefore facilitate prior specification in SBC. We discuss relevant connections of primed priors to the theory of catalytic priors and show their use for SBC in three simulation studies.</description>
      <guid isPermaLink="false">oai:arXiv.org:2408.06504v2</guid>
      <category>stat.ME</category>
      <pubDate>Mon, 26 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Luna Fazio, Maximilian Scholz, Javier Enrique Aguilar, Paul-Christian B\"urkner</dc:creator>
    </item>
    <item>
      <title>A comparison of methods for estimating the average treatment effect on the treated for externally controlled trials</title>
      <link>https://arxiv.org/abs/2408.07193</link>
      <description>arXiv:2408.07193v2 Announce Type: replace 
Abstract: While randomized trials may be the gold standard for evaluating the effectiveness of the treatment intervention, in some special circumstances, single-arm clinical trials utilizing external control may be considered. The causal treatment effect of interest for single-arm trials is usually the average treatment effect on the treated (ATT) rather than the average treatment effect (ATE). Although methods have been developed to estimate the ATT, the selection and use of these methods require a thorough comparison and in-depth understanding of the advantages and disadvantages of these methods. In this study, we conducted simulations under different identifiability assumptions to compare the performance metrics (e.g., bias, standard deviation (SD), mean squared error (MSE), type I error rate) for a variety of methods, including the regression model, propensity score matching (PSM), Mahalanobis distance matching (MDM), coarsened exact matching, inverse probability weighting, augmented inverse probability weighting (AIPW), AIPW with SuperLearner, and targeted maximum likelihood estimator (TMLE) with SuperLearner.
  Our simulation results demonstrate that the doubly robust methods in general have smaller biases than other methods. In terms of SD, nonmatching methods in general have smaller SDs than matching-based methods. The performance of MSE is a trade-off between the bias and SD, and no method consistently performs better in term of MSE. The identifiability assumptions are critical to the models' performance: Violation of the positivity assumption can lead to a significant inflation of type I errors in some methods; violation of the unconfoundedness assumption can lead to a large bias for all methods... (Further details are available in the main body of the paper).</description>
      <guid isPermaLink="false">oai:arXiv.org:2408.07193v2</guid>
      <category>stat.ME</category>
      <pubDate>Mon, 26 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <arxiv:DOI>10.51387/25-NEJSDS77</arxiv:DOI>
      <arxiv:journal_reference>The New England Journal of Statistics in Data Science (2025):1-12</arxiv:journal_reference>
      <dc:creator>Huan Wang, Fei Wu, Yeh-Fong Chen</dc:creator>
    </item>
    <item>
      <title>A New Forward Discriminant Analysis Framework Based On Pillai's Trace and ULDA</title>
      <link>https://arxiv.org/abs/2409.03136</link>
      <description>arXiv:2409.03136v2 Announce Type: replace 
Abstract: Linear discriminant analysis (LDA), a traditional classification tool, suffers from limitations such as sensitivity to noise and computational challenges when dealing with non-invertible within-class scatter matrices. Traditional stepwise LDA frameworks, which iteratively select the most informative features, often exacerbate these issues by relying heavily on Wilks' $\Lambda$, potentially causing premature stopping of the selection process. This paper introduces a novel forward discriminant analysis framework that integrates Pillai's trace with Uncorrelated Linear Discriminant Analysis (ULDA) to address these challenges, and offers a unified and stand-alone classifier. Through simulations and real-world datasets, the new framework demonstrates effective control of Type I error rates and improved classification accuracy, particularly in cases involving perfect group separations. The results highlight the potential of this approach as a robust alternative to the traditional stepwise LDA framework.</description>
      <guid isPermaLink="false">oai:arXiv.org:2409.03136v2</guid>
      <category>stat.ME</category>
      <category>stat.CO</category>
      <category>stat.ML</category>
      <pubDate>Mon, 26 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Siyu Wang, Kehui Yao</dc:creator>
    </item>
    <item>
      <title>Detecting Spatial Dependence in Transcriptomics Data using Vectorised Persistence Diagrams</title>
      <link>https://arxiv.org/abs/2409.03575</link>
      <description>arXiv:2409.03575v2 Announce Type: replace 
Abstract: Evaluating spatial patterns in data is an integral task across various domains, including geostatistics, astronomy, and spatial tissue biology. The analysis of transcriptomics data in particular relies on methods for detecting spatially-dependent features that exhibit significant spatial patterns for both explanatory analysis and feature selection. However, given the complex and high-dimensional nature of these data, there is a need for robust, stable, and reliable descriptors of spatial dependence. We leverage the stability and multiscale properties of persistent homology to address this task. To this end, we introduce a novel framework using functional topological summaries, such as Betti curves and persistence landscapes, for identifying and describing non-random patterns in spatial data. In particular, we propose a non-parametric one-sample permutation test for spatial dependence and investigate its utility across both simulated and real spatial omics data. Our vectorised approach outperforms baseline methods at accurately detecting spatial dependence. Further, we find that our method is more robust to outliers than alternative tests using Moran's I.</description>
      <guid isPermaLink="false">oai:arXiv.org:2409.03575v2</guid>
      <category>stat.ME</category>
      <category>cs.CG</category>
      <pubDate>Mon, 26 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Katharina Limbeck, Bastian Rieck</dc:creator>
    </item>
    <item>
      <title>Beyond Arbitrary Replications: A Principled Approach to Simulation Design in Causal Inference</title>
      <link>https://arxiv.org/abs/2409.05161</link>
      <description>arXiv:2409.05161v3 Announce Type: replace 
Abstract: Evaluation of novel treatment effect estimators frequently relies on simulation studies lacking formal statistical comparisons and using arbitrary numbers of replications ($J$). This hinders reproducibility and efficiency. We propose the Test-Informed Simulation Count Algorithm (TISCA) to address these shortcomings. TISCA integrates Welch's t-tests with power analysis, iteratively running simulations until a pre-specified power (e.g., 0.8) is achieved for detecting a user-defined minimum detectable effect size (MDE) at a given significance level ($\alpha$). This yields a statistically justified simulation count ($J$) and rigorous model comparisons. Our bibliometric study confirms the heterogeneity of current practices regarding $J$. A case study revisiting McJames et al. (2024) demonstrates TISCA identifies sufficient simulations ($J=500$ vs. original $J=1000$), saving computational resources while providing statistically sound evidence. TISCA promotes rigorous, efficient, and sustainable simulation practices in causal inference and beyond.</description>
      <guid isPermaLink="false">oai:arXiv.org:2409.05161v3</guid>
      <category>stat.ME</category>
      <pubDate>Mon, 26 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <dc:creator>Hugo Gobato Souto, Francisco Louzada Neto</dc:creator>
    </item>
    <item>
      <title>Doubly Robust Conformalized Survival Analysis with Right-Censored Data</title>
      <link>https://arxiv.org/abs/2412.09729</link>
      <description>arXiv:2412.09729v2 Announce Type: replace 
Abstract: We present a conformal inference method for constructing lower prediction bounds for survival times from right-censored data, extending recent approaches designed for more restrictive type-I censoring scenarios. The proposed method imputes unobserved censoring times using a machine learning model, and then analyzes the imputed data using a survival model calibrated via weighted conformal inference. This approach is theoretically supported by an asymptotic double robustness property. Empirical studies on simulated and real data demonstrate that our method leads to relatively informative predictive inferences and is especially robust in challenging settings where the survival model may be inaccurate.</description>
      <guid isPermaLink="false">oai:arXiv.org:2412.09729v2</guid>
      <category>stat.ME</category>
      <category>cs.LG</category>
      <pubDate>Mon, 26 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Matteo Sesia, Vladimir Svetnik</dc:creator>
    </item>
    <item>
      <title>Statistical Analysis of Large-scale Item Response Data under Measurement Non-invariance: A Statistically Consistent Method and Its Application to PISA 2022</title>
      <link>https://arxiv.org/abs/2505.16608</link>
      <description>arXiv:2505.16608v2 Announce Type: replace 
Abstract: With the process of globalization, International Large-scale Assessments in education (ILSAs), such as the Programme for International Student Assessment (PISA), have become increasingly important in educational research and policy-making. They collect valuable data on education quality and performance development across many education systems worldwide, allowing countries to share techniques and policies that have proven efficient and successful. A key to analyzing ILSA data is an Item Response Theory (IRT) model, which is used to estimate the performance distributions of different groups (e.g., countries) and then produce a ranking. A major challenge in calibrating the IRT model is that some items suffer from Differential Item Functioning (DIF), i.e., different groups have different probabilities of correctly answering the items after controlling for individual proficiency levels. DIF is particularly common in ILSA due to the differences in test languages, cultural contexts, and curriculum designs across different groups. Ignoring or improperly accounting for DIF when calibrating the IRT model can lead to severe biases in the estimated performance distributions, which may further distort the ranking of the groups. Unfortunately, existing methods cannot guarantee the statistically consistent recovery of the group ranking without unrealistic assumptions for ILSA, such as the existence and knowledge of reference groups and anchor items. To fill this gap, this paper proposes a new approach to DIF analysis across multiple groups. This approach is computationally efficient and statistically consistent, without making strong assumptions about reference groups and anchor items. The proposed method is applied to PISA 2022 data from the mathematics, science, and reading domains, providing insights into their DIF structures and performance rankings of countries.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.16608v2</guid>
      <category>stat.ME</category>
      <pubDate>Mon, 26 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Jing Ouyang, Yunxiao Chen, Chengcheng Li, Gongjun Xu</dc:creator>
    </item>
    <item>
      <title>Conformal Robust Control of Linear Systems</title>
      <link>https://arxiv.org/abs/2405.16250</link>
      <description>arXiv:2405.16250v3 Announce Type: replace-cross 
Abstract: End-to-end engineering design pipelines, in which designs are evaluated using concurrently defined optimal controllers, are becoming increasingly common in practice. To discover designs that perform well even under the misspecification of system dynamics, such end-to-end pipelines have now begun evaluating designs with a robust control objective in place of the nominal optimal control setup. Current approaches of specifying such robust control subproblems, however, rely on hand specification of perturbations anticipated to be present upon deployment or margin methods that ignore problem structure, resulting in a lack of theoretical guarantees and overly conservative empirical performance. We, instead, propose a novel methodology for LQR systems that leverages conformal prediction to specify such uncertainty regions in a data-driven fashion. Such regions have distribution-free coverage guarantees on the true system dynamics, in turn allowing for a probabilistic characterization of the regret of the resulting robust controller. We then demonstrate that such a controller can be efficiently produced via a novel policy gradient method that has convergence guarantees. We finally demonstrate the superior empirical performance of our method over alternate robust control specifications, such as $H_{\infty}$ and LQR with multiplicative noise, across a collection of engineering control systems.</description>
      <guid isPermaLink="false">oai:arXiv.org:2405.16250v3</guid>
      <category>eess.SY</category>
      <category>cs.SY</category>
      <category>stat.ME</category>
      <pubDate>Mon, 26 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Yash Patel, Sahana Rayan, Ambuj Tewari</dc:creator>
    </item>
    <item>
      <title>Data-driven stochastic 3D modeling of the nanoporous binder-conductive additive phase in battery cathodes</title>
      <link>https://arxiv.org/abs/2409.11080</link>
      <description>arXiv:2409.11080v3 Announce Type: replace-cross 
Abstract: A stochastic 3D modeling approach for the nanoporous binder-conductive additive phase in hierarchically structured cathodes of lithium-ion batteries is presented. The binder-conductive additive phase of these electrodes consists of carbon black, polyvinylidene difluoride binder and graphite particles. For its stochastic 3D modeling, a three-step procedure based on methods from stochastic geometry is used. First, the graphite particles are described by a Boolean model with ellipsoidal grains. Second, the mixture of carbon black and binder is modeled by an excursion set of a Gaussian random field in the complement of the graphite particles. Third, large pore regions within the mixture of carbon black and binder are described by a Boolean model with spherical grains. The model parameters are calibrated to 3D image data of cathodes in lithium-ion batteries acquired by focused ion beam scanning electron microscopy. Subsequently, model validation is performed by comparing model realizations with measured image data in terms of various morphological descriptors that are not used for model fitting. Finally, we use the stochastic 3D model for predictive simulations, where we generate virtual, yet realistic, image data of nanoporous binder-conductive additives with varying amounts of graphite particles. Based on these virtual nanostructures, we can investigate structure-property relationships. In particular, we quantitatively study the influence of graphite particles on effective transport properties in the nanoporous binder-conductive additive phase, which have a crucial impact on electrochemical processes in the cathode and thus on the performance of battery cells.</description>
      <guid isPermaLink="false">oai:arXiv.org:2409.11080v3</guid>
      <category>cond-mat.mtrl-sci</category>
      <category>stat.AP</category>
      <category>stat.CO</category>
      <category>stat.ME</category>
      <pubDate>Mon, 26 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <arxiv:DOI>10.1186/s13362-025-00174-z</arxiv:DOI>
      <arxiv:journal_reference>J.Math.Industry 15, 9 (2025)</arxiv:journal_reference>
      <dc:creator>Phillip Gr\"afensteiner, Markus Osenberg, Andr\'e Hilger, Nicole Bohn, Joachim R. Binder, Ingo Manke, Volker Schmidt, Matthias Neumann</dc:creator>
    </item>
    <item>
      <title>FoLDTree: A ULDA-Based Decision Tree Framework for Efficient Oblique Splits and Feature Selection</title>
      <link>https://arxiv.org/abs/2410.23147</link>
      <description>arXiv:2410.23147v2 Announce Type: replace-cross 
Abstract: Traditional decision trees are limited by axis-orthogonal splits, which can perform poorly when true decision boundaries are oblique. While oblique decision tree methods address this limitation, they often face high computational costs, difficulties with multi-class classification, and a lack of effective feature selection. In this paper, we introduce LDATree and FoLDTree, two novel frameworks that integrate Uncorrelated Linear Discriminant Analysis (ULDA) and Forward ULDA into a decision tree structure. These methods enable efficient oblique splits, handle missing values, support feature selection, and provide both class labels and probabilities as model outputs. Through evaluations on simulated and real-world datasets, LDATree and FoLDTree consistently outperform axis-orthogonal and other oblique decision tree methods, achieving accuracy levels comparable to the random forest. The results highlight the potential of these frameworks as robust alternatives to traditional single-tree methods.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.23147v2</guid>
      <category>cs.LG</category>
      <category>stat.ME</category>
      <category>stat.ML</category>
      <pubDate>Mon, 26 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Siyu Wang, Kehui Yao</dc:creator>
    </item>
    <item>
      <title>Potato Potahto in the FAO-GAEZ Productivity Measures? Nonclassical Measurement Error with Multiple Proxies</title>
      <link>https://arxiv.org/abs/2502.12141</link>
      <description>arXiv:2502.12141v3 Announce Type: replace-cross 
Abstract: The FAO-GAEZ productivity data are widely used in Economics. However, the empirical literature rarely discusses measurement error. We use two proxies to derive novel bounds around the effect of agricultural productivity in a setting with nonclassical measurement error. These bounds rely on assumptions that are weaker than the ones imposed in empirical studies and exhaust the information contained in the first two moments of the data. We reevaluate three influential studies, documenting that measurement error matters and that the impact of agricultural productivity may be smaller than previously reported. Our methodology has broad applications in empirical research involving mismeasured variables.</description>
      <guid isPermaLink="false">oai:arXiv.org:2502.12141v3</guid>
      <category>econ.GN</category>
      <category>q-fin.EC</category>
      <category>stat.ME</category>
      <pubDate>Mon, 26 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <dc:creator>Rafael Araujo, Vitor Possebom</dc:creator>
    </item>
    <item>
      <title>Bayesian sample size calculations for external validation studies of risk prediction models</title>
      <link>https://arxiv.org/abs/2504.15923</link>
      <description>arXiv:2504.15923v2 Announce Type: replace-cross 
Abstract: Contemporary sample size calculations for external validation of risk prediction models require users to specify fixed values of assumed model performance metrics alongside target precision levels (e.g., 95% CI widths). However, due to the finite samples of previous studies, our knowledge of true model performance in the target population is uncertain, and so choosing fixed values represents an incomplete picture. As well, for net benefit (NB) as a measure of clinical utility, the relevance of conventional precision-based inference is doubtful. In this work, we propose a general Bayesian framework for multi-criteria sample size considerations for prediction models for binary outcomes. For statistical metrics of performance (e.g., discrimination and calibration), we propose sample size rules that target desired expected precision or desired assurance probability that the precision criteria will be satisfied. For NB, we propose rules based on Optimality Assurance (the probability that the planned study correctly identifies the optimal strategy) and Value of Information (VoI) analysis. We showcase these developments in a case study on the validation of a risk prediction model for deterioration of hospitalized COVID-19 patients. Compared to the conventional sample size calculation methods, a Bayesian approach requires explicit quantification of uncertainty around model performance, and thereby enables flexible sample size rules based on expected precision, assurance probabilities, and VoI. In our case study, calculations based on VoI for NB suggest considerably lower sample sizes are needed than when focusing on precision of calibration metrics.</description>
      <guid isPermaLink="false">oai:arXiv.org:2504.15923v2</guid>
      <category>stat.AP</category>
      <category>stat.CO</category>
      <category>stat.ME</category>
      <pubDate>Mon, 26 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Mohsen Sadatsafavi, Paul Gustafson, Solmaz Setayeshgar, Laure Wynants, Richard D Riley</dc:creator>
    </item>
    <item>
      <title>Model Selection for Gaussian-gated Gaussian Mixture of Experts Using Dendrograms of Mixing Measures</title>
      <link>https://arxiv.org/abs/2505.13052</link>
      <description>arXiv:2505.13052v2 Announce Type: replace-cross 
Abstract: Mixture of Experts (MoE) models constitute a widely utilized class of ensemble learning approaches in statistics and machine learning, known for their flexibility and computational efficiency. They have become integral components in numerous state-of-the-art deep neural network architectures, particularly for analyzing heterogeneous data across diverse domains. Despite their practical success, the theoretical understanding of model selection, especially concerning the optimal number of mixture components or experts, remains limited and poses significant challenges. These challenges primarily stem from the inclusion of covariates in both the Gaussian gating functions and expert networks, which introduces intrinsic interactions governed by partial differential equations with respect to their parameters. In this paper, we revisit the concept of dendrograms of mixing measures and introduce a novel extension to Gaussian-gated Gaussian MoE models that enables consistent estimation of the true number of mixture components and achieves the pointwise optimal convergence rate for parameter estimation in overfitted scenarios. Notably, this approach circumvents the need to train and compare a range of models with varying numbers of components, thereby alleviating the computational burden, particularly in high-dimensional or deep neural network settings. Experimental results on synthetic data demonstrate the effectiveness of the proposed method in accurately recovering the number of experts. It outperforms common criteria such as the Akaike information criterion, the Bayesian information criterion, and the integrated completed likelihood, while achieving optimal convergence rates for parameter estimation and accurately approximating the regression function.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.13052v2</guid>
      <category>stat.ML</category>
      <category>cs.LG</category>
      <category>math.ST</category>
      <category>stat.CO</category>
      <category>stat.ME</category>
      <category>stat.TH</category>
      <pubDate>Mon, 26 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Tuan Thai, TrungTin Nguyen, Dat Do, Nhat Ho, Christopher Drovandi</dc:creator>
    </item>
  </channel>
</rss>
