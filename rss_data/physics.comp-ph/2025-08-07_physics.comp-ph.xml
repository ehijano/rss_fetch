<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>physics.comp-ph updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/physics.comp-ph</link>
    <description>physics.comp-ph updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/physics.comp-ph" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Fri, 08 Aug 2025 04:00:16 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Fri, 08 Aug 2025 00:00:00 -0400</pubDate>
    <skipDays>
      <day>Sunday</day>
      <day>Saturday</day>
    </skipDays>
    <item>
      <title>Hyperbolic tiling neighborhoods in O(1) time</title>
      <link>https://arxiv.org/abs/2508.04765</link>
      <description>arXiv:2508.04765v1 Announce Type: new 
Abstract: Tilings of the hyperbolic plane are of significant interest among many branches of mathematics, physics and computer science. Yet, their construction remains a non-trivial task. Current approaches primarily use tree-based recursive algorithms, which are fundamentally limited: they do not readily yield the neighborhood graph representing cell adjacencies, which is however required for many applications. We introduce a novel approach that allows to build hyperbolic tilings and their associated graph structure simultaneously, using only combinatoric rules without requiring an explicit coordinate representation. This allows to generate arbitrarily large, exact hyperbolic graphs, with an algorithmic complexity that does not depend on the lattice size. We provide an easy-to-use implementation which substantially outperforms existing methods, hence rendering ultra large-scale numerical simulations on these geometric structures accessible for the scientific community.</description>
      <guid isPermaLink="false">oai:arXiv.org:2508.04765v1</guid>
      <category>physics.comp-ph</category>
      <category>cond-mat.other</category>
      <category>hep-lat</category>
      <pubDate>Fri, 08 Aug 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Yanick Thurn, Manuel Schrauth, Johanna Erdmenger</dc:creator>
    </item>
    <item>
      <title>Identifying Optimal Regression Models For DEM Simulation Datasets</title>
      <link>https://arxiv.org/abs/2508.05308</link>
      <description>arXiv:2508.05308v1 Announce Type: new 
Abstract: Developing fast regression models (surrogate/metamodels) from DEM data is key for practical industrial application to allow real-time evaluations. However, benchmarking different models is often overlooked in particle technology for regression tasks, as model selection is frequently not the primary research focus. This can lead to the use of suboptimal models, resulting in subpar predictive accuracy, slow evaluations, or poor generalisation, hindering effective real-time decision-making and process optimisation. In this work, we discuss applying k-fold cross-validation to assess regression models for tabular DEM datasets and propose a simple framework for readers to follow to find the optimal model for their data. An example demonstrates its application to a DEM dataset of packing fractions measured in a simple measuring beaker with varying inter-particle properties, namely, average particle diameter, coefficient of restitution, coefficient of sliding friction, coefficient of rolling resistance, and cohesive energy density. Out of 16 different models tested, a histogram-based gradient boosting model was found to be optimal, providing a good fit with acceptable training and inference times.</description>
      <guid isPermaLink="false">oai:arXiv.org:2508.05308v1</guid>
      <category>physics.comp-ph</category>
      <pubDate>Fri, 08 Aug 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>B. D. Jenkins, A. L. Nicusan, A. Neveu, G. Lumay, F. Francqui, J. P. K. Seville, C. R. K. Windows-Yule</dc:creator>
    </item>
    <item>
      <title>Optimization of Ab-Initio Based Tight-Binding Models</title>
      <link>https://arxiv.org/abs/2508.04861</link>
      <description>arXiv:2508.04861v1 Announce Type: cross 
Abstract: The electronic structure of solids can routinely be calculated by standard methods like density functional theory. However, in complicated situations like interfaces, grain boundaries or contact geometries one needs to resort to more simplified models of the electronic structure. Tight-binding models are using a reduced set of orbitals and aim to approximate the electronic structure by short range hopping processes. For example, maximally localized Wannier functions are often used for that purpose. However, their accuracy is limited by the need to disentangle the electronic bands. Here, we develop and investigate a different procedure to obtain tight-binding models inspired by machine-learning techniques. The model parameters are optimized in such a way as to reproduce ab-initio band structure data as accurately as possible using an as small as possible number of model parameters. The procedure is shown to result in models with smaller ranges and fewer orbitals than maximally localized Wannier functions but same or even better accuracy. We argue that such a procedure is more useful for automated construction of tight-binding models particularly for large-scale materials calculations.</description>
      <guid isPermaLink="false">oai:arXiv.org:2508.04861v1</guid>
      <category>cond-mat.mtrl-sci</category>
      <category>physics.comp-ph</category>
      <pubDate>Fri, 08 Aug 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Henrik Dick, Thomas Dahm</dc:creator>
    </item>
    <item>
      <title>Simulation of Non-Premixed, Supersonic Combustion using the Discontinuous Galerkin Method on Fully Unstructured Grids</title>
      <link>https://arxiv.org/abs/2508.04930</link>
      <description>arXiv:2508.04930v1 Announce Type: cross 
Abstract: In this study, three-dimensional simulations of a reacting hydrogen jet in supersonic crossflow using a structure-preserving discontinuous Galerkin (DG) formulation are examined. The hydrogen jet, with a momentum flux ratio of five, is injected into a high enthalpy crossflow. The sensitivities of the solution to the grid element size and polynomial order are investigated to determine an accurate and computationally efficient approach to simulating high-speed airbreathing propulsion vehicles. The results demonstrate that DG(p = 2) solutions, which are nominally third-order accurate in smooth regions of the flow, show reasonable agreement with existing experimental results. The separation shock formation behind the jet is found to be heavily grid dependent and necessary for accurate simulations of the reacting jet in supersonic crossflow. It is determined that the highest resolution cell and polynomial order is required to capture the upstream separation shock and consequently the flame stabilization point. The mixing and combustion mode is also determined using the flame index and demonstrates the flow is heavily skewed towards a non-premixed diffusion mode which is consistent with previously run simulations of this case using traditional finite volume schemes and sub grid scale modeling approaches. Beyond this analysis, the novelty of this work lies in demonstrating a high-speed, multicomponent, chemically reacting flow on a fully unstructured tetrahedral mesh: a first-of-its-kind calculation. This highlights the potential of these methods for simulating fluids in complex geometries with complex physics</description>
      <guid isPermaLink="false">oai:arXiv.org:2508.04930v1</guid>
      <category>physics.flu-dyn</category>
      <category>physics.comp-ph</category>
      <pubDate>Fri, 08 Aug 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/publicdomain/zero/1.0/</dc:rights>
      <dc:creator>Cal J. Rising, Eric J. Ching, Ryan F. Johnson</dc:creator>
    </item>
    <item>
      <title>Constitutive modeling of viscoelastic solids at large strains based on the theory of evolving natural configurations</title>
      <link>https://arxiv.org/abs/2508.05043</link>
      <description>arXiv:2508.05043v1 Announce Type: cross 
Abstract: The theory of evolving natural configurations is an effective technique to model dissipative processes. In this paper, we use this theory to revisit nonlinear constitutive models of viscoelastic solids. Particularly, a Maxwell and a Kelvin-Voigt model and their associated standard solids, viz., a Zener and a Poynting-Thompson solids respectively, have been modeled within a Lagrangian framework. We show that while a strain-space formulation of the evolving natural configurations is useful in modeling Maxwell-type materials, a stress-space formulation that incorporates a rate of dissipation function in terms of the relevant configurational forces is required for modeling the Kelvin-Voigt type materials. Furthermore, we also show that the basic Maxwell and Kelvin-Voigt models can be obtained as limiting cases from the derived standard solid models. Integration algorithms for the proposed models have been developed and numerical solutions for a relevant boundary value problem are obtained. The response of the developed models have been compared and benchmarked with experimental data. Specifically, the response of the novel Poynting-Thompson model is studied in details. This model shows a very good match with the existing experimental data obtained from a uniaxial stretching of polymers over a large extent of strain. The relaxation behavior and rate effects for the developed models have been studied.</description>
      <guid isPermaLink="false">oai:arXiv.org:2508.05043v1</guid>
      <category>cond-mat.soft</category>
      <category>physics.comp-ph</category>
      <pubDate>Fri, 08 Aug 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Tarun Singh, Sandipan Paul</dc:creator>
    </item>
    <item>
      <title>A Time-Domain Method of Auxiliary Sources for Efficient Analysis of Transient Electromagnetic Scattering by Moderately Conductive Cylinders</title>
      <link>https://arxiv.org/abs/2508.05217</link>
      <description>arXiv:2508.05217v1 Announce Type: cross 
Abstract: This paper presents a time-domain implementation of the Method of Auxiliary Sources (MAS) combined with the Standard Impedance Boundary Condition (SIBC) for electromagnetic scattering problems involving cylindrical scatterers with finite but moderate conductivity. The proposed approach focuses on solving the two-dimensional problem using a first-order SIBC, which is valid when the conductivity is sufficiently higher than the maximum spectral frequency times the dielectric permittivity of the scatterer. This regime includes moderately conductive materials--such as carbon-based composites, conductive polymers, and doped dielectrics--that are increasingly used in real-world radio-frequency applications, including wearable electronics, electromagnetic interference shielding, and biomedical sensors. Under the above validity conditions, the interaction between the incident wave and the scatterer is dominated by surface effects, allowing for an efficient and accurate modeling strategy without the need to compute internal fields. The theoretical formulation of the time-domain MAS-SIBC method is developed, followed by extensive numerical testing on various geometries whose cross section is a closed curve. Such geometries include circular, elliptical, super-circular, rounded-triangular, and inverted-elliptical scatterers. A planar geometry is also tested. All results are validated against analytical solutions and commercial frequency-domain solvers, demonstrating the accuracy and practical potential of the proposed method. The findings suggest that time-domain MAS-SIBC offers a promising and computationally efficient approach for modeling scattering from materials even with moderate conductivity.</description>
      <guid isPermaLink="false">oai:arXiv.org:2508.05217v1</guid>
      <category>physics.class-ph</category>
      <category>physics.comp-ph</category>
      <pubDate>Fri, 08 Aug 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Minas Kouroublakis, Nikolaos L. Tsitsas, Yehuda Leviatan</dc:creator>
    </item>
    <item>
      <title>Many-body perturbation theory vs. density functional theory: A systematic benchmark for band gaps of solids</title>
      <link>https://arxiv.org/abs/2508.05247</link>
      <description>arXiv:2508.05247v1 Announce Type: cross 
Abstract: We benchmark many-body perturbation theory against density functional theory (DFT) for the band gaps of solids. We systematically compare four $GW$ variants $-$ $G_{0}W_{0}$ using the Godby-Needs plasmon-pole approximation ($G_{0}W_{0}$-PPA), full-frequency quasiparticle $G_{0}W_{0}$ (QP$G_{0}W_{0}$), full-frequency quasiparticle self-consistent $GW$ (QS$GW$), and QS$GW$ augmented with vertex corrections in $W$ (QS$G\hat{W}$) $-$ against the currently best performing and popular density functionals mBJ and HSE06. Our results show that $G_{0}W_{0}$-PPA calculations offer only a marginal accuracy gain over the best DFT methods, however at a higher cost. Replacing the PPA with a full-frequency integration of the dielectric screening improves the predictions dramatically, almost matching the accuracy of the QS$G\hat{W}$. The QS$GW$ removes starting-point bias, but systematically overestimates experimental gaps by about $15\%$. Adding vertex corrections to the screened Coulomb interaction, i.e., performing a QS$G\hat{W}$ calculation, eliminates the overestimation, producing band gaps that are so accurate that they even reliably flag questionable experimental measurements.</description>
      <guid isPermaLink="false">oai:arXiv.org:2508.05247v1</guid>
      <category>cond-mat.mtrl-sci</category>
      <category>physics.comp-ph</category>
      <pubDate>Fri, 08 Aug 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Max Gro{\ss}mann, Marc Thieme, Malte Grunert, Erich Runge</dc:creator>
    </item>
    <item>
      <title>High Purcell enhancement in all-TMDC nanobeam resonator designs with optically active monolayers for nanolasers</title>
      <link>https://arxiv.org/abs/2508.05333</link>
      <description>arXiv:2508.05333v1 Announce Type: cross 
Abstract: We propose a nanobeam resonator incorporating an optically active monolayer, designed to achieve a high Purcell enhancement. The resonator is fully composed of transition metal dichalcogenide (TMDC) materials and intended to operate as a high-beta-factor nanolaser. A theoretical framework that models and optimizes the Purcell enhancement associated with the emission from atomically thin layers is developed. This framework is based on a resonance expansion, enabling spectral resolution of physical quantities governed by high-Q resonances. The numerical optimization of the resonator leads to the presence of a high-Q resonance supporting a strong electric field confinement in the monolayer to maximize the modal gain.</description>
      <guid isPermaLink="false">oai:arXiv.org:2508.05333v1</guid>
      <category>physics.optics</category>
      <category>cond-mat.mes-hall</category>
      <category>physics.comp-ph</category>
      <pubDate>Fri, 08 Aug 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Felix Binkowski, Aris Koulas-Simos, Fridtjof Betz, Matthias Plock, Ivan Sekulic, Phillip Manley, Martin Hammerschmidt, Philipp-Immanuel Schneider, Lin Zschiedrich, Battulga Munkhbat, Stephan Reitzenstein, Sven Burger</dc:creator>
    </item>
    <item>
      <title>Hole-doping reduces the coercive field in ferroelectric hafnia</title>
      <link>https://arxiv.org/abs/2508.05345</link>
      <description>arXiv:2508.05345v1 Announce Type: cross 
Abstract: Ferroelectric hafnia holds promise for next-generation memory and logic applications because of its CMOS compatibility. However, the high coercive field required for polarization switching in hafnia remains a critical challenge for efficient device operations. Using first-principles calculations and phenomenological modeling, we predict that hole doping can reduce the coercive field from 8 MV/cm in undoped hafnia to 6 MV/cm in hafnia doped with 0.2 holes per formula unit (f.u.). In the absence of doping, the reversal of polarization of the Pca21 phase is preferred through the non-polar, tetragonal P42/nmc phase. This switching pathway involves the coupling of three hard distortion modes that render undoped hafnia as an improper ferroelectric. The overall energy barrier through this pathway remains unchanged (80 meV/f.u.) upon hole doping. However, the introduction of holes hardens the polar distortion mode that connects the polar Pca21 phase to the non-polar, orthorhombic Pbcm phase, and reduces the energy barrier from 180 meV/f.u. in undoped hafnia to 80 meV/f.u. at 0.2 holes/f.u.. Overall, hole doping makes the latter switching pathway through the Pbcm phase competitive, and renders hafnia as a proper ferroelectric with a lower coercive field.</description>
      <guid isPermaLink="false">oai:arXiv.org:2508.05345v1</guid>
      <category>cond-mat.mtrl-sci</category>
      <category>physics.comp-ph</category>
      <pubDate>Fri, 08 Aug 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Pravan Omprakash, Gwan Yeong Jung, Guodong Ren, Rohan Mishra</dc:creator>
    </item>
    <item>
      <title>The use of open boundaries in stochastic hydrodynamic models of nucleation</title>
      <link>https://arxiv.org/abs/2508.05528</link>
      <description>arXiv:2508.05528v1 Announce Type: cross 
Abstract: Stochastic hydrodynamics is a central tool in the study of first order phase transitions at a fundamental level. Combined with sophisticated free energy models, e.g. as developed in classical Density Functional Theory, complex processes such as crystallization can be modeled and information such as free energy barriers, nucleation pathways and the unstable eigenvector and eigenvalues determined. The latter are particularly interesting as they play key roles in defining the natural (unbiased) order parameter and the nucleation rate respectively. As is often the case, computational realities restrict the size of system that can be modeled and this makes it difficult to achieve experimental conditions for which the volume is effectively infinite. In this paper, the use of open boundary conditions is discussed. By using an open system, the calculations become much closer to experimental conditions however, the introduction of open boundary conditions raises a number of questions concerning the stochastic model such as whether the fluctuation-dissipation relation is preserved and whether stationary points on the free energy surface remain stationary points of the dynamics.</description>
      <guid isPermaLink="false">oai:arXiv.org:2508.05528v1</guid>
      <category>cond-mat.stat-mech</category>
      <category>physics.chem-ph</category>
      <category>physics.comp-ph</category>
      <pubDate>Fri, 08 Aug 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>James F. Lutsko</dc:creator>
    </item>
    <item>
      <title>Model-based framework for automated quantification of error sources in quantum state tomography</title>
      <link>https://arxiv.org/abs/2508.05538</link>
      <description>arXiv:2508.05538v1 Announce Type: cross 
Abstract: High-quality quantum state generation is essential for advanced quantum information processing, including quantum communication, quantum sensing, and quantum computing. In practice, various error sources degrade the quality of quantum states, and quantum state tomography (QST) is a standard diagnostic tool. However, in QST, multiple error sources gather in a single density matrix, making it difficult to identify individual error sources. To address this problem, we propose an automated method for quantifying error sources by combining simulation and parameter optimization to reproduce the experimental density matrix. We focus on the experimental generation of time-bin entangled photon pairs, for which we model the relevant error sources and simulate the density matrix with adjustable model parameters, thereby optimizing the parameters and minimizing the trace distance to the experimental data. Optimization of the parameters reduced the trace distance from 0.177 to 0.024, indicating that our modeled error sources explain 86% of the errors. Reducing the predicted error sources improves the state quality, consistent with our predictions and thus validating the proposed method. In addition, the modular structure of this framework makes it applicable to other quantum platforms, such as superconducting qubits, atoms, and solid-state spins.</description>
      <guid isPermaLink="false">oai:arXiv.org:2508.05538v1</guid>
      <category>quant-ph</category>
      <category>physics.comp-ph</category>
      <category>physics.optics</category>
      <pubDate>Fri, 08 Aug 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Junpei Oba, Hsin-Pin Lo, Yasuhiro Yamada, Takayuki Matsui, Takuya Ikuta, Yuya Yonezu, Toshimori Honjo, Seiji Kajita, Hiroki Takesue</dc:creator>
    </item>
    <item>
      <title>The Missing Reward: Active Inference in the Era of Experience</title>
      <link>https://arxiv.org/abs/2508.05619</link>
      <description>arXiv:2508.05619v1 Announce Type: cross 
Abstract: This paper argues that Active Inference (AIF) provides a crucial foundation for developing autonomous AI agents capable of learning from experience without continuous human reward engineering. As AI systems begin to exhaust high-quality training data and rely on increasingly large human workforces for reward design, the current paradigm faces significant scalability challenges that could impede progress toward genuinely autonomous intelligence. The proposal for an ``Era of Experience,'' where agents learn from self-generated data, is a promising step forward. However, this vision still depends on extensive human engineering of reward functions, effectively shifting the bottleneck from data curation to reward curation. This highlights what we identify as the \textbf{grounded-agency gap}: the inability of contemporary AI systems to autonomously formulate, adapt, and pursue objectives in response to changing circumstances. We propose that AIF can bridge this gap by replacing external reward signals with an intrinsic drive to minimize free energy, allowing agents to naturally balance exploration and exploitation through a unified Bayesian objective. By integrating Large Language Models as generative world models with AIF's principled decision-making framework, we can create agents that learn efficiently from experience while remaining aligned with human values. This synthesis offers a compelling path toward AI systems that can develop autonomously while adhering to both computational and physical constraints.</description>
      <guid isPermaLink="false">oai:arXiv.org:2508.05619v1</guid>
      <category>cs.AI</category>
      <category>nlin.AO</category>
      <category>physics.bio-ph</category>
      <category>physics.comp-ph</category>
      <category>physics.hist-ph</category>
      <pubDate>Fri, 08 Aug 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <dc:creator>Bo Wen</dc:creator>
    </item>
    <item>
      <title>Adaptive Compressible Smoothed Particle Hydrodynamics</title>
      <link>https://arxiv.org/abs/2504.11350</link>
      <description>arXiv:2504.11350v2 Announce Type: replace-cross 
Abstract: Modulating the number of particles in a region is key to accurately capturing the nuances in compressible flows with Smoothed Particle Hydrodynamics (SPH). This paper presents a volume-based adaptive refinement and derefinement procedure, with state-of-the-art features such as automatic local adaptivity and solution adaptivity applied in the context of compressible flows. A shock-aware particle shifting procedure is introduced to regularize the particle distribution while preserving the integrity of shocks. To our knowledge, this is the first demonstration of shock-based solution adaptivity and shock-aware particle shifting in the literature. A wide variety of test problems, which involve flow in and around boundaries, are employed to highlight the utility of these adaptivity features in improving the results and in making simulations faster. For instance, the adaptive resolution procedure is shown to achieve an order of magnitude increase in computational speed. We also demonstrate the effectiveness of the adaptivity procedure in resolving issues such as errors arising from the interaction with differently spaced ghost particles at boundaries, formation of spot-like structures due to particle clumping, and poorly resolved low-density regions. In essence, the adaptivity technique presented in this paper is a powerful tool for simulating compressible flows with enhanced accuracy and efficiency.</description>
      <guid isPermaLink="false">oai:arXiv.org:2504.11350v2</guid>
      <category>physics.flu-dyn</category>
      <category>physics.comp-ph</category>
      <pubDate>Fri, 08 Aug 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <arxiv:DOI>10.1016/j.jcp.2025.114257</arxiv:DOI>
      <arxiv:journal_reference>Journal of Computational Physics 539 (2025) 114257</arxiv:journal_reference>
      <dc:creator>Navaneet Villodi, Prabhu Ramachandran</dc:creator>
    </item>
    <item>
      <title>Self-consistent GW via conservation of spectral moments</title>
      <link>https://arxiv.org/abs/2504.17439</link>
      <description>arXiv:2504.17439v2 Announce Type: replace-cross 
Abstract: We expand on a recently introduced alternate framework for $GW$ simulation of charged excitations [Scott et. al., J. Chem. Phys., 158, 124102 (2023)], based around the conservation of directly computed spectral moments of the GW self-energy. Featuring a number of desirable formal properties over other implementations, we also detail efficiency improvements and a parallelism strategy, resulting in an implementation with a demonstrable similar scaling to an established Hartree--Fock code, with only an order of magnitude increase in cost. We also detail the applicability of a range of self-consistent $GW$ variants within this framework, including a scheme for full self-consistency of all dynamical variables, whilst avoiding the Matsubara axis or analytic continuation, allowing formal convergence at zero temperature. By investigating a range of self-consistency protocols over the GW100 molecular test set, we find that a little-explored self-consistent variant based around a simpler coupled chemical potential and Fock matrix optimization to be the most accurate self-consistent $GW$ approach. Additionally, we validate recently observed evidence that Tamm--Dancoff based screening approximations within $GW$ lead to higher accuracy than traditional random phase approximation screening over these molecular test cases. Finally, we consider the Chlorophyll A molecule, finding agreement with experiment within the experimental uncertainty, and a description of the full-frequency spectrum of charged excitations.</description>
      <guid isPermaLink="false">oai:arXiv.org:2504.17439v2</guid>
      <category>physics.chem-ph</category>
      <category>cond-mat.str-el</category>
      <category>physics.comp-ph</category>
      <category>quant-ph</category>
      <pubDate>Fri, 08 Aug 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Oliver J. Backhouse, Marcus K. Allen, Charles C. J. Scott, George H. Booth</dc:creator>
    </item>
    <item>
      <title>Stochastic Gradient-Descent Calibration of Pyragas Delayed-Feedback Control for Chaos Suppression in the Sprott Circuit</title>
      <link>https://arxiv.org/abs/2506.06639</link>
      <description>arXiv:2506.06639v2 Announce Type: replace-cross 
Abstract: This paper explores chaos control in the Sprott circuit by leveraging Stochastic Gradient Descent (SGD) to calibrate Pyragas delayed feedback control. Using a third-order nonlinear differential equation, we model the circuit and aim to suppress chaos by optimizing control parameters (gain $K$, delay $T_{\text{con}}$) and the variable resistor $R_v$. Experimental voltage data, extracted from published figures via WebPlotDigitizer, serve as the calibration target. We compare two calibration techniques: sum of squared errors (SSE) minimization via grid search and stochastic gradient descent (SGD) with finite differences. Joint optimization of $K$, $T_{\text{con}}$, and $R_v$ using SGD achieves superior alignment with experimental data, capturing both phase and amplitude with high fidelity. Compared to grid search, SGD excels in phase synchronization, though minor amplitude discrepancies persist due to model simplifications. Phase space analysis confirms the model ability to replicate the chaotic attractor geometry, despite slight deviations. We analyze the trade-off between calibration accuracy and computational cost, highlighting scalability challenges. Overall, SGD-based calibration demonstrates significant potential for precise control of chaotic systems, advancing mathematical modeling and applications in electrical engineering.</description>
      <guid isPermaLink="false">oai:arXiv.org:2506.06639v2</guid>
      <category>nlin.CD</category>
      <category>math.OC</category>
      <category>physics.comp-ph</category>
      <pubDate>Fri, 08 Aug 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <dc:creator>Adib Kabir, Onil Morshed, Oishi Kabir, Juthi Hira, Caitlin Hult</dc:creator>
    </item>
    <item>
      <title>MOFClassifier: A Machine Learning Approach for Validating Computation-Ready Metal-Organic Frameworks</title>
      <link>https://arxiv.org/abs/2506.14845</link>
      <description>arXiv:2506.14845v2 Announce Type: replace-cross 
Abstract: The computational discovery and design of new crystalline materials, particularly metal-organic frameworks (MOFs), heavily relies on high-quality, computation-ready structural data. However, recent studies have revealed significant error rates within existing MOF databases, posing a critical data problem that hinders efficient high-throughput computational screening. While rule-based algorithms like MOSAEC, MOFChecker, and the Chen and Manz method (Chen-Manz) have been developed to address this, they often suffer from inherent limitations and misclassification of structures. To overcome this challenge, we developed MOFClassifier, a novel machine learning approach built upon a positive-unlabeled crystal graph convolutional neural network (PU-CGCNN) model. MOFClassifier learns intricate patterns from perfect crystal structures to predict a crystal-likeness score (CLscore), effectively classifying MOFs as computation-ready. Our model achieves a ROC value of 0.979 (previous best 0.912) and, importantly, can identify subtle structural and chemical errors that are undetectable by current rule-based methods. By accurately recovering previously misclassified false-negative structures, MOFClassifier reduces the risk of overlooking promising material candidates in large-scale computational screening campaigns. This user-friendly tool is freely available and has been integrated into the prepara-tion workflow for the updated CoRE MOF DB 2025 v1.0, contributing to accelerated computational discovery of MOF materials.</description>
      <guid isPermaLink="false">oai:arXiv.org:2506.14845v2</guid>
      <category>physics.chem-ph</category>
      <category>cond-mat.mtrl-sci</category>
      <category>physics.comp-ph</category>
      <pubDate>Fri, 08 Aug 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <dc:creator>Guobin Zhao, Pengyu Zhao, Yongchul G. Chung</dc:creator>
    </item>
  </channel>
</rss>
