<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>stat.CO updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/stat.CO</link>
    <description>stat.CO updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/stat.CO" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Tue, 12 Aug 2025 02:38:56 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Mon, 11 Aug 2025 00:00:00 -0400</pubDate>
    <skipDays>
      <day>Sunday</day>
      <day>Saturday</day>
    </skipDays>
    <item>
      <title>Identifiability of the minimum-trace directed acyclic graph and hill climbing algorithms without strict local optima under weakly increasing error variances</title>
      <link>https://arxiv.org/abs/2508.05706</link>
      <description>arXiv:2508.05706v1 Announce Type: new 
Abstract: We prove that the true underlying directed acyclic graph (DAG) in Gaussian linear structural equation models is identifiable as the minimum-trace DAG when the error variances are weakly increasing with respect to the true causal ordering. This result bridges two existing frameworks as it extends the identifiable cases within the minimum-trace DAG method and provides a principled interpretation of the algorithmic ordering search approach, revealing that its objective is actually to minimize the total residual sum of squares. On the computational side, we prove that the hill climbing algorithm with a random-to-random (R2R) neighborhood does not admit any strict local optima. Under standard settings, we confirm the result through extensive simulations, observing only a few weak local optima. Interestingly, algorithms using other neighborhoods of equal size exhibit suboptimal behavior, having strict local optima and a substantial number of weak local optima.</description>
      <guid isPermaLink="false">oai:arXiv.org:2508.05706v1</guid>
      <category>stat.CO</category>
      <category>math.ST</category>
      <category>stat.ML</category>
      <category>stat.TH</category>
      <pubDate>Mon, 11 Aug 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Hyunwoong Chang, Jaehoan Kim</dc:creator>
    </item>
    <item>
      <title>Reverse Diffusion Sequential Monte Carlo Samplers</title>
      <link>https://arxiv.org/abs/2508.05926</link>
      <description>arXiv:2508.05926v1 Announce Type: new 
Abstract: We propose a novel sequential Monte Carlo (SMC) method for sampling from unnormalized target distributions based on a reverse denoising diffusion process. While recent diffusion-based samplers simulate the reverse diffusion using approximate score functions, they can suffer from accumulating errors due to time discretization and imperfect score estimation. In this work, we introduce a principled SMC framework that formalizes diffusion-based samplers as proposals while systematically correcting for their biases. The core idea is to construct informative intermediate target distributions that progressively steer the sampling trajectory toward the final target distribution. Although ideal intermediate targets are intractable, we develop exact approximations using quantities from the score estimation-based proposal, without requiring additional model training or inference overhead. The resulting sampler, termed RDSMC, enables consistent sampling and unbiased estimation of the target's normalization constant under mild conditions. We demonstrate the effectiveness of our method on a range of synthetic targets and real-world Bayesian inference problems.</description>
      <guid isPermaLink="false">oai:arXiv.org:2508.05926v1</guid>
      <category>stat.CO</category>
      <pubDate>Mon, 11 Aug 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Luhuan Wu, Yi Han, Christian A. Naesseth, John P. Cunningham</dc:creator>
    </item>
    <item>
      <title>Introducing 'inrep': an R package that facilitates fully reproducible research workfows for survey-based assessments</title>
      <link>https://arxiv.org/abs/2507.15893</link>
      <description>arXiv:2507.15893v3 Announce Type: replace 
Abstract: Conducting research often involves managing multiple disconnected tools for survey design, data collection, response analysis, and report generation, leading to inefficiencies, increased error risks, and challenges in ensuring reproducibility. To address these issues, we introduce inrep, an open-source R package that integrates the entire assessment workflow within a unified, flexible framework in R. With inrep, researchers can create customized assessments, streamline data management, and generate personalized participant reports without switching software or manually transferring data. inrep includes built-in support for generating structured prompts to guide large language models, enabling tailored adaptation of assessment components to specific study needs. By consolidating all stages of the assessment process, inrep enhances research efficiency, improves reliability, and ensures full reproducibility, making sophisticated testing methodologies accessible to researchers, educators, and practitioners regardless of programming expertise.</description>
      <guid isPermaLink="false">oai:arXiv.org:2507.15893v3</guid>
      <category>stat.CO</category>
      <pubDate>Mon, 11 Aug 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Clievins Selva</dc:creator>
    </item>
    <item>
      <title>Non-asymptotic estimates for accelerated high order Langevin Monte Carlo algorithms</title>
      <link>https://arxiv.org/abs/2405.05679</link>
      <description>arXiv:2405.05679v2 Announce Type: replace-cross 
Abstract: In this paper, we propose two new algorithms, namely, aHOLA and aHOLLA, to sample from high-dimensional target distributions with possibly super-linearly growing potentials. We establish non-asymptotic convergence bounds for aHOLA in Wasserstein-1 and Wasserstein-2 distances with rates of convergence equal to $1+q/2$ and $1/2+q/4$, respectively, under a local H\"{o}lder condition with exponent $q\in(0,1]$ and a convexity at infinity condition on the potential of the target distribution. Similar results are obtained for aHOLLA under certain global continuity conditions and a dissipativity condition. Crucially, we achieve state-of-the-art rates of convergence of the proposed algorithms in the non-convex setting which are higher than those of the existing algorithms. Examples from high-dimensional sampling and logistic regression are presented, and numerical results support our main findings.</description>
      <guid isPermaLink="false">oai:arXiv.org:2405.05679v2</guid>
      <category>math.ST</category>
      <category>math.PR</category>
      <category>stat.CO</category>
      <category>stat.ML</category>
      <category>stat.TH</category>
      <pubDate>Mon, 11 Aug 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Ariel Neufeld, Ying Zhang</dc:creator>
    </item>
    <item>
      <title>L1-Regularized Functional Support Vector Machine</title>
      <link>https://arxiv.org/abs/2508.05567</link>
      <description>arXiv:2508.05567v2 Announce Type: replace-cross 
Abstract: In functional data analysis, binary classification with one functional covariate has been extensively studied. We aim to fill in the gap of considering multivariate functional covariates in classification. In particular, we propose an $L_1$-regularized functional support vector machine for binary classification. An accompanying algorithm is developed to fit the classifier. By imposing an $L_1$ penalty, the algorithm enables us to identify relevant functional covariates of the binary response. Numerical results from simulations and one real-world application demonstrate that the proposed classifier enjoys good performance in both prediction and feature selection.</description>
      <guid isPermaLink="false">oai:arXiv.org:2508.05567v2</guid>
      <category>stat.ML</category>
      <category>cs.LG</category>
      <category>stat.CO</category>
      <pubDate>Mon, 11 Aug 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <arxiv:DOI>10.4310/22-SII773</arxiv:DOI>
      <dc:creator>Bingfan Liu, Peijun Sang</dc:creator>
    </item>
  </channel>
</rss>
