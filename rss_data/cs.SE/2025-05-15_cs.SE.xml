<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>cs.SE updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/cs.SE</link>
    <description>cs.SE updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/cs.SE" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Fri, 16 May 2025 04:00:03 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Fri, 16 May 2025 00:00:00 -0400</pubDate>
    <skipDays>
      <day>Sunday</day>
      <day>Saturday</day>
    </skipDays>
    <item>
      <title>Automated Statistical Testing and Certification of a Reliable Model-Coupling Server for Scientific Computing</title>
      <link>https://arxiv.org/abs/2505.09769</link>
      <description>arXiv:2505.09769v1 Announce Type: new 
Abstract: Sequence-based specification and usage-driven statistical testing are designed for rigorous and cost-effective software development, offering a semi-formal approach to assessing the behavior of complex systems and interactions between various components. This approach is particularly valuable for scientific computing applications in which comprehensive tests are needed to prevent flawed results or conclusions. As scientific discovery becomes increasingly more complex, domain scientists couple multiple scientific computing models or simulations to solve intricate multiphysics and multiscale problems. These model-coupling applications use a hardwired coupling program or a flexible web service to link and combine different models. In this paper, we focus on the quality assurance of the more elastic web service via a combination of rigorous specification and testing methods. The application of statistical testing exposes problems ignored by pre-written unit tests and highlights areas in the code where failures might occur. We certify the model-coupling server controller with a derived reliability statistic, offering a quantitative measure to support a claim of its robustness.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.09769v1</guid>
      <category>cs.SE</category>
      <pubDate>Fri, 16 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-sa/4.0/</dc:rights>
      <dc:creator>Seth Wolfgang, Lan Lin, Fengguang Song</dc:creator>
    </item>
    <item>
      <title>What Makes a Fairness Tool Project Sustainable in Open Source?</title>
      <link>https://arxiv.org/abs/2505.09802</link>
      <description>arXiv:2505.09802v1 Announce Type: new 
Abstract: As society becomes increasingly reliant on artificial intelligence, the need to mitigate risk and harm is paramount. In response, researchers and practitioners have developed tools to detect and reduce undesired bias, commonly referred to as fairness tools. Many of these tools are publicly available for free use and adaptation. While the growing availability of such tools is promising, little is known about the broader landscape beyond well-known examples like AI Fairness 360 and Fairlearn. Because fairness is an ongoing concern, these tools must be built for long-term sustainability. Using an existing set of fairness tools as a reference, we systematically searched GitHub and identified 50 related projects. We then analyzed various aspects of their repositories to assess community engagement and the extent of ongoing maintenance. Our findings show diverse forms of engagement with these tools, suggesting strong support for open-source development. However, we also found significant variation in how well these tools are maintained. Notably, 53 percent of fairness projects become inactive within the first three years. By examining sustainability in fairness tooling, we aim to promote more stability and growth in this critical area.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.09802v1</guid>
      <category>cs.SE</category>
      <category>cs.HC</category>
      <pubDate>Fri, 16 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Sadia Afrin Mim, Fatemeh Vares, Andrew Meenly, Brittany Johnson</dc:creator>
    </item>
    <item>
      <title>Incidents During Microservice Decomposition: A Case Study</title>
      <link>https://arxiv.org/abs/2505.09813</link>
      <description>arXiv:2505.09813v1 Announce Type: new 
Abstract: Software errors and incidents are inevitable in web based applications. Scalability challenges, increasing demand, and ongoing code changes can contribute to such failures. As software architectures evolve rapidly, understanding how and why incidents occur is crucial for enhancing system reliability. In this study, we introduce Carbon Health's software stack, share our microservices journey, and analyze 107 incidents. Based on these incidents, we share insights and lessons learned on microservice decomposition. Finally, we suggest that starting with monolithic modularization as an initial step toward microservice decomposition may help reduce incidents and contribute to building more resilient software.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.09813v1</guid>
      <category>cs.SE</category>
      <pubDate>Fri, 16 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Do\u{g}a\c{c} Eldenk, H. Alperen \c{C}etin</dc:creator>
    </item>
    <item>
      <title>Evaluating Large Language Models for the Generation of Unit Tests with Equivalence Partitions and Boundary Values</title>
      <link>https://arxiv.org/abs/2505.09830</link>
      <description>arXiv:2505.09830v1 Announce Type: new 
Abstract: The design and implementation of unit tests is a complex task many programmers neglect. This research evaluates the potential of Large Language Models (LLMs) in automatically generating test cases, comparing them with manual tests. An optimized prompt was developed, that integrates code and requirements, covering critical cases such as equivalence partitions and boundary values. The strengths and weaknesses of LLMs versus trained programmers were compared through quantitative metrics and manual qualitative analysis. The results show that the effectiveness of LLMs depends on well-designed prompts, robust implementation, and precise requirements. Although flexible and promising, LLMs still require human supervision. This work highlights the importance of manual qualitative analysis as an essential complement to automation in unit test evaluation.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.09830v1</guid>
      <category>cs.SE</category>
      <category>cs.AI</category>
      <pubDate>Fri, 16 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Mart\'in Rodr\'iguez, Gustavo Rossi, Alejandro Fernandez</dc:creator>
    </item>
    <item>
      <title>Determining Absence of Unreasonable Risk: Approval Guidelines for an Automated Driving System Release</title>
      <link>https://arxiv.org/abs/2505.09880</link>
      <description>arXiv:2505.09880v1 Announce Type: new 
Abstract: This paper provides an overview of how the determination of absence of unreasonable risk can be operationalized. It complements previous theoretical work published by existing developers of Automated Driving Systems (ADS) on the overall engineering practices and methodologies for readiness determination. Readiness determination is, at its core, a risk assessment process. It is aimed at evaluating the residual risk associated with the deployment of a new software release candidate. The paper proposes methodological criteria to ground the readiness review process for an ADS release. While informed by Waymo's experience in this domain, the criteria presented are agnostic of any specific ADS technological solution and/or architectural choice, to support broad implementation by others in the industry. The paper continues with a discussion on governance and decision-making toward approval of a new software release candidate for the ADS. The implementation of the presented criteria requires the existence of appropriate safety management practices in addition to many other cultural, procedural, and operational considerations. As such, the paper is concluded by a statement of limitations for those wishing to replicate part or all of its content.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.09880v1</guid>
      <category>cs.SE</category>
      <category>cs.CY</category>
      <pubDate>Fri, 16 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Francesca Favaro, Scott Schnelle, Laura Fraade-Blanar, Trent Victor, Mauricio Pe\~na, Nick Webb, Holland Broce, Craig Paterson, Dan Smith</dc:creator>
    </item>
    <item>
      <title>Advancing Mobile UI Testing by Learning Screen Usage Semantics</title>
      <link>https://arxiv.org/abs/2505.09894</link>
      <description>arXiv:2505.09894v1 Announce Type: new 
Abstract: The demand for quality in mobile applications has increased greatly given users' high reliance on them for daily tasks. Developers work tirelessly to ensure that their applications are both functional and user-friendly. In pursuit of this, Automated Input Generation (AIG) tools have emerged as a promising solution for testing mobile applications by simulating user interactions and exploring app functionalities. However, these tools face significant challenges in navigating complex Graphical User Interfaces (GUIs), and developers often have trouble understanding their output. More specifically, AIG tools face difficulties in navigating out of certain screens, such as login pages and advertisements, due to a lack of contextual understanding which leads to suboptimal testing coverage. Furthermore, while AIG tools can provide interaction traces consisting of action and screen details, there is limited understanding of its coverage of higher level functionalities, such as logging in, setting alarms, or saving notes. Understanding these covered use cases are essential to ensure comprehensive test coverage of app functionalities. Difficulty in testing mobile UIs can lead to the design of complex interfaces, which can adversely affect users of advanced age who often face usability barriers due to small buttons, cluttered layouts, and unintuitive navigation. There exists many studies that highlight these issues, but automated solutions for improving UI accessibility needs more attention. This research seeks to enhance automated UI testing techniques by learning the screen usage semantics of mobile apps and helping them navigate more efficiently, offer more insights about tested functionalities and also improve the usability of a mobile app's interface by identifying and mitigating UI design issues.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.09894v1</guid>
      <category>cs.SE</category>
      <pubDate>Fri, 16 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-sa/4.0/</dc:rights>
      <dc:creator>Safwat Ali Khan</dc:creator>
    </item>
    <item>
      <title>UICopilot: Automating UI Synthesis via Hierarchical Code Generation from Webpage Designs</title>
      <link>https://arxiv.org/abs/2505.09904</link>
      <description>arXiv:2505.09904v1 Announce Type: new 
Abstract: Automating the synthesis of User Interfaces (UIs) plays a crucial role in enhancing productivity and accelerating the development lifecycle, reducing both development time and manual effort. Recently, the rapid development of Multimodal Large Language Models (MLLMs) has made it possible to generate front-end Hypertext Markup Language (HTML) code directly from webpage designs. However, real-world webpages encompass not only a diverse array of HTML tags but also complex stylesheets, resulting in significantly lengthy code. The lengthy code poses challenges for the performance and efficiency of MLLMs, especially in capturing the structural information of UI designs. To address these challenges, this paper proposes UICopilot, a novel approach to automating UI synthesis via hierarchical code generation from webpage designs. The core idea of UICopilot is to decompose the generation process into two stages: first, generating the coarse-grained HTML hierarchical structure, followed by the generation of fine-grained code. To validate the effectiveness of UICopilot, we conduct experiments on a real-world dataset, i.e., WebCode2M. Experimental results demonstrate that UICopilot significantly outperforms existing baselines in both automatic evaluation metrics and human evaluations. Specifically, statistical analysis reveals that the majority of human annotators prefer the webpages generated by UICopilot over those produced by GPT-4V.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.09904v1</guid>
      <category>cs.SE</category>
      <pubDate>Fri, 16 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <arxiv:DOI>10.1145/3696410.3714891</arxiv:DOI>
      <dc:creator>Yi Gui, Yao Wan, Zhen Li, Zhongyi Zhang, Dongping Chen, Hongyu Zhang, Yi Su, Bohua Chen, Xing Zhou, Wenbin Jiang, Xiangliang Zhang</dc:creator>
    </item>
    <item>
      <title>Probabilistic Bisimulation for Parameterized Anonymity and Uniformity Verification</title>
      <link>https://arxiv.org/abs/2505.09963</link>
      <description>arXiv:2505.09963v1 Announce Type: new 
Abstract: Bisimulation is crucial for verifying process equivalence in probabilistic systems. This paper presents a novel logical framework for analyzing bisimulation in probabilistic parameterized systems, namely, infinite families of finite-state probabilistic systems. Our framework is built upon the first-order theory of regular structures, which provides a decidable logic for reasoning about these systems. We show that essential properties like anonymity and uniformity can be encoded and verified within this framework in a manner aligning with the principles of deductive software verification, where systems, properties, and proofs are expressed in a unified decidable logic. By integrating language inference techniques, we achieve full automation in synthesizing candidate bisimulation proofs for anonymity and uniformity. We demonstrate the efficacy of our approach by addressing several challenging examples, including cryptographic protocols and randomized algorithms that were previously beyond the reach of fully automated methods.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.09963v1</guid>
      <category>cs.SE</category>
      <category>cs.FL</category>
      <pubDate>Fri, 16 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <arxiv:DOI>10.1109/TSE.2025.3567423</arxiv:DOI>
      <dc:creator>Chih-Duo Hong, Anthony W. Lin, Philipp R\"ummer, Rupak Majumdar</dc:creator>
    </item>
    <item>
      <title>SVA-ICL: Improving LLM-based Software Vulnerability Assessment via In-Context Learning and Information Fusion</title>
      <link>https://arxiv.org/abs/2505.10008</link>
      <description>arXiv:2505.10008v1 Announce Type: new 
Abstract: Context: Software vulnerability assessment (SVA) is critical for identifying, evaluating, and prioritizing security weaknesses in software applications. Objective: Despite the increasing application of large language models (LLMs) in various software engineering tasks, their effectiveness in SVA remains underexplored. Method: To address this gap, we introduce a novel approach SVA-ICL, which leverages in-context learning (ICL) to enhance LLM performance. Our approach involves the selection of high-quality demonstrations for ICL through information fusion, incorporating both source code and vulnerability descriptions. For source code, we consider semantic, lexical, and syntactic similarities, while for vulnerability descriptions, we focus on textual similarity. Based on the selected demonstrations, we construct context prompts and consider DeepSeek-V2 as the LLM for SVA-ICL. Results: We evaluate the effectiveness of SVA-ICL using a large-scale dataset comprising 12,071 C/C++ vulnerabilities. Experimental results demonstrate that SVA-ICL outperforms state-of-the-art SVA baselines in terms of Accuracy, F1-score, and MCC measures. Furthermore, ablation studies highlight the significance of component customization in SVA-ICL, such as the number of demonstrations, the demonstration ordering strategy, and the optimal fusion ratio of different modalities. Conclusion: Our findings suggest that leveraging ICL with information fusion can effectively improve the effectiveness of LLM-based SVA, warranting further research in this direction.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.10008v1</guid>
      <category>cs.SE</category>
      <pubDate>Fri, 16 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Chaoyang Gao, Xiang Chen, Guangbei Zhang</dc:creator>
    </item>
    <item>
      <title>GBM Returns the Best Prediction Performance among Regression Approaches: A Case Study of Stack Overflow Code Quality</title>
      <link>https://arxiv.org/abs/2505.10019</link>
      <description>arXiv:2505.10019v1 Announce Type: new 
Abstract: Practitioners are increasingly dependent on publicly available resources for supporting their knowledge needs during software development. This has thus caused a spotlight to be paced on these resources, where researchers have reported mixed outcomes around the quality of these resources. Stack Overflow, in particular, has been studied extensively, with evidence showing that code resources on this platform can be of poor quality at times. Limited research has explored the variables or factors that predict code quality on Stack Overflow, but instead has focused on ranking content, identifying defects and predicting future content. In many instances approaches used for prediction are not evaluated to identify the best techniques. Contextualizing the Stack Overflow code quality problem as regression-based, we examined the variables that predict Stack Overflow (Java) code quality, and the regression approach that provides the best predictive power. Six approaches were considered in our evaluation, where Gradient Boosting Machine (GBM) stood out. In addition, longer Stack Overflow code tended to have more code violations, questions that were scored higher also attracted more views and the more answers that are added to questions on Stack Overflow the more errors were typically observed in the code that was provided. Outcomes here point to the value of the GBM ensemble learning mechanism, and the need for the practitioner community to be prudent when contributing and reusing Stack Overflow Java coding resource.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.10019v1</guid>
      <category>cs.SE</category>
      <pubDate>Fri, 16 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Sherlock A. Licorish, Brendon Woodford, Lakmal Kiyaduwa Vithanage, Osayande Pascal Omondiagbe</dc:creator>
    </item>
    <item>
      <title>Cross-Functional AI Task Forces (X-FAITs) for AI Transformation of Software Organizations</title>
      <link>https://arxiv.org/abs/2505.10021</link>
      <description>arXiv:2505.10021v1 Announce Type: new 
Abstract: This experience report introduces the Cross-Functional AI Task Force (X-FAIT) framework to bridge the gap between strategic AI ambitions and operational execution within software-intensive organizations. Drawing from an Action Research case study at a global Swedish enterprise, we identify and address critical barriers such as departmental fragmentation, regulatory constraints, and organizational inertia that can impede successful AI transformation. X-FAIT employs force field analysis, executive sponsorship, cross-functional integration, and systematic risk assessment strategies to coordinate efforts across organizational boundaries, facilitating knowledge sharing and ensuring AI initiatives align with objectives. The framework provides both theoretical insights into AI-driven organizational transformation and practical guidance for software organizations aiming to effectively integrate AI into their daily workflows and, longer-term, products.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.10021v1</guid>
      <category>cs.SE</category>
      <pubDate>Fri, 16 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Lucas Gren, Robert Feldt</dc:creator>
    </item>
    <item>
      <title>Digital Natives, Digital Activists: Youth, Social Media and the Rise of Environmental Sustainability Movements</title>
      <link>https://arxiv.org/abs/2505.10158</link>
      <description>arXiv:2505.10158v1 Announce Type: new 
Abstract: The research examines the challenges revolving around young people's social movements, activism regarding sustainability, as well as the accompanying social media aspect, and how social media impacts environmental action. This study focuses on the environmental craze on social media platforms and its impact on young activists aged 16-25. With the advancement of social media, new avenues have opened for participation in sustainability issues, especially for the marginalized, as information moved through transnational networks at lightning speed. Along with specific Formative Visual Storytelling methods, the young leaders of the movement deploy hashtags and other online tools to capture the attention of their peers and decision makers. Challenges persist with "clicktivism" fatigue from the internet, and site limitations. This article contributes to insights on emerging forms of civic activism by explaining how digital natives adapt technology to reframe green activism. The research suggests that effective digital environmental movements integrate online and offline action, make it simple for individuals to get involved, and promote tolerance to algorithmic modifications and climate care among participants.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.10158v1</guid>
      <category>cs.SE</category>
      <category>cs.CY</category>
      <pubDate>Fri, 16 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Manya Pandit, Triveni Magadum, Harshit Mittal, Omkar Kushwaha</dc:creator>
    </item>
    <item>
      <title>Are Sparse Autoencoders Useful for Java Function Bug Detection?</title>
      <link>https://arxiv.org/abs/2505.10375</link>
      <description>arXiv:2505.10375v1 Announce Type: new 
Abstract: Software vulnerabilities such as buffer overflows and SQL injections are a major source of security breaches. Traditional methods for vulnerability detection remain essential but are limited by high false positive rates, scalability issues, and reliance on manual effort. These constraints have driven interest in AI-based approaches to automated vulnerability detection and secure code generation. While Large Language Models (LLMs) have opened new avenues for classification tasks, their complexity and opacity pose challenges for interpretability and deployment. Sparse Autoencoder offer a promising solution to this problem. We explore whether SAEs can serve as a lightweight, interpretable alternative for bug detection in Java functions. We evaluate the effectiveness of SAEs when applied to representations from GPT-2 Small and Gemma 2B, examining their capacity to highlight buggy behaviour without fine-tuning the underlying LLMs. We found that SAE-derived features enable bug detection with an F1 score of up to 89%, consistently outperforming fine-tuned transformer encoder baselines. Our work provides the first empirical evidence that SAEs can be used to detect software bugs directly from the internal representations of pretrained LLMs, without any fine-tuning or task-specific supervision.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.10375v1</guid>
      <category>cs.SE</category>
      <category>cs.AI</category>
      <category>cs.LG</category>
      <pubDate>Fri, 16 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Rui Melo, Claudia Mamede, Andre Catarino, Rui Abreu, Henrique Lopes Cardoso</dc:creator>
    </item>
    <item>
      <title>Are Large Language Models Robust in Understanding Code Against Semantics-Preserving Mutations?</title>
      <link>https://arxiv.org/abs/2505.10443</link>
      <description>arXiv:2505.10443v1 Announce Type: new 
Abstract: Understanding the reasoning and robustness of Large Language Models (LLMs) is critical for their reliable use in programming tasks. While recent studies have assessed LLMs' ability to predict program outputs, most focus solely on the accuracy of those predictions, without evaluating the reasoning behind them. Moreover, it has been observed on mathematical reasoning tasks that LLMs can arrive at correct answers through flawed logic, raising concerns about similar issues in code understanding.
  In this work, we evaluate whether state-of-the-art LLMs with up to 8B parameters can reason about Python programs or are simply guessing. We apply five semantics-preserving code mutations: renaming variables, mirroring comparison expressions, swapping if-else branches, converting for loops to while, and loop unrolling. These mutations maintain program semantics while altering its syntax. We evaluated six LLMs and performed a human expert analysis using LiveCodeBench to assess whether the correct predictions are based on sound reasoning. We also evaluated prediction stability across different code mutations on LiveCodeBench and CruxEval. Our findings show that some LLMs, such as Llama3.2, produce correct predictions based on flawed reasoning in up to 61% of cases. Furthermore, LLMs often change predictions in response to our code mutations, indicating limited robustness in their semantic understanding.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.10443v1</guid>
      <category>cs.SE</category>
      <category>cs.AI</category>
      <pubDate>Fri, 16 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <dc:creator>Pedro Orvalho, Marta Kwiatkowska</dc:creator>
    </item>
    <item>
      <title>Rethinking Repetition Problems of LLMs in Code Generation</title>
      <link>https://arxiv.org/abs/2505.10402</link>
      <description>arXiv:2505.10402v1 Announce Type: cross 
Abstract: With the advent of neural language models, the performance of code generation has been significantly boosted. However, the problem of repetitions during the generation process continues to linger. Previous work has primarily focused on content repetition, which is merely a fraction of the broader repetition problem in code generation. A more prevalent and challenging problem is structural repetition. In structural repetition, the repeated code appears in various patterns but possesses a fixed structure, which can be inherently reflected in grammar. In this paper, we formally define structural repetition and propose an efficient decoding approach called RPG, which stands for Repetition Penalization based on Grammar, to alleviate the repetition problems in code generation for LLMs. Specifically, RPG first leverages grammar rules to identify repetition problems during code generation, and then strategically decays the likelihood of critical tokens that contribute to repetitions, thereby mitigating them in code generation. To facilitate this study, we construct a new dataset CodeRepetEval to comprehensively evaluate approaches for mitigating the repetition problems in code generation. Extensive experimental results demonstrate that RPG substantially outperforms the best-performing baselines on CodeRepetEval dataset as well as HumanEval and MBPP benchmarks, effectively reducing repetitions and enhancing the quality of generated code.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.10402v1</guid>
      <category>cs.CL</category>
      <category>cs.AI</category>
      <category>cs.LG</category>
      <category>cs.SE</category>
      <pubDate>Fri, 16 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Yihong Dong, Yuchen Liu, Xue Jiang, Zhi Jin, Ge Li</dc:creator>
    </item>
    <item>
      <title>Biomedical Open Source Software: Crucial Packages and Hidden Heroes</title>
      <link>https://arxiv.org/abs/2404.06672</link>
      <description>arXiv:2404.06672v3 Announce Type: replace 
Abstract: Despite the importance of scientific software for research, it is often not formally recognized and rewarded. This is especially true for foundation libraries, which are used by the software packages visible to the users, being ``hidden'' themselves. The funders and other organizations need to understand the complex network of computer programs that the modern research relies upon.
  In this work we used CZ Software Mentions Dataset to map the dependencies of the software used in biomedical papers and find the packages critical to the software ecosystems. We propose the centrality metrics for the network of software dependencies, analyze three ecosystems (PyPi, CRAN, Bioconductor) and determine the packages with the highest centrality.</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.06672v3</guid>
      <category>cs.SE</category>
      <category>cs.CY</category>
      <pubDate>Fri, 16 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Andrew Nesbitt, Boris Veytsman, Daniel Mietchen, Eva Maxfield Brown, James Howison, Jo\~ao Felipe Pimentel, Laurent H\`ebert-Dufresne, Stephan Druskat</dc:creator>
    </item>
    <item>
      <title>MORepair: Teaching LLMs to Repair Code via Multi-Objective Fine-tuning</title>
      <link>https://arxiv.org/abs/2404.12636</link>
      <description>arXiv:2404.12636v3 Announce Type: replace 
Abstract: Within the realm of software engineering, specialized tasks on code, such as program repair, present unique challenges, necessitating fine-tuning Large language models~(LLMs) to unlock state-of-the-art performance. Fine-tuning approaches proposed in the literature for LLMs on program repair tasks generally overlook the need to reason about the logic behind code changes, beyond syntactic patterns in the data. High-performing fine-tuning experiments also usually come at very high computational costs. With MORepair, we propose a novel perspective on the learning focus of LLM fine-tuning for program repair: we not only adapt the LLM parameters to the syntactic nuances of the task of code transformation (objective 1), but we also specifically fine-tune the LLM with respect to the logical reason behind the code change in the training data (objective 2). Such a multi-objective fine-tuning will instruct LLMs to generate high-quality patches. We apply MORepair to fine-tune four open-source LLMs with different sizes and architectures. Experimental results on function-level and repository-level repair benchmarks show that the implemented fine-tuning effectively boosts LLM repair performance by 11.4% to 56.0%. We further show that our fine-tuning strategy yields superior performance compared to the state-of-the-art approaches, including standard fine-tuning, Fine-tune-CoT, and RepairLLaMA.</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.12636v3</guid>
      <category>cs.SE</category>
      <pubDate>Fri, 16 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Boyang Yang, Haoye Tian, Jiadong Ren, Hongyu Zhang, Jacques Klein, Tegawend\'e F. Bissyand\'e, Claire Le Goues, Shunfu Jin</dc:creator>
    </item>
    <item>
      <title>Using Cooperative Co-evolutionary Search to Generate Metamorphic Test Cases for Autonomous Driving Systems</title>
      <link>https://arxiv.org/abs/2412.03843</link>
      <description>arXiv:2412.03843v3 Announce Type: replace 
Abstract: Autonomous Driving Systems (ADSs) rely on Deep Neural Networks, allowing vehicles to navigate complex, open environments. However, the unpredictability of these scenarios highlights the need for rigorous system-level testing to ensure safety, a task usually performed with a simulator in the loop. Though one important goal of such testing is to detect safety violations, there are many undesirable system behaviors, that may not immediately lead to violations, that testing should also be focusing on, thus detecting more subtle problems and enabling a finer-grained analysis. This paper introduces Cooperative Co-evolutionary MEtamorphic test Generator for Autonomous systems (CoCoMEGA), a novel automated testing framework aimed at advancing system-level safety assessments of ADSs. CoCoMEGA combines Metamorphic Testing (MT) with a search-based approach utilizing Cooperative Co-Evolutionary Algorithms (CCEA) to efficiently generate a diverse set of test cases. CoCoMEGA emphasizes the identification of test scenarios that present undesirable system behavior, that may eventually lead to safety violations, captured by Metamorphic Relations (MRs). When evaluated within the CARLA simulation environment on the Interfuser ADS, CoCoMEGA consistently outperforms baseline methods, demonstrating enhanced effectiveness and efficiency in generating severe, diverse MR violations and achieving broader exploration of the test space. These results underscore CoCoMEGA as a promising, more scalable solution to the inherent challenges in ADS testing with a simulator in the loop. Future research directions may include extending the approach to additional simulation platforms, applying it to other complex systems, and exploring methods for further improving testing efficiency such as surrogate modeling.</description>
      <guid isPermaLink="false">oai:arXiv.org:2412.03843v3</guid>
      <category>cs.SE</category>
      <category>cs.NE</category>
      <pubDate>Fri, 16 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <arxiv:DOI>10.1109/TSE.2025.3570897</arxiv:DOI>
      <dc:creator>Hossein Yousefizadeh, Shenghui Gu, Lionel C. Briand, Ali Nasr</dc:creator>
    </item>
    <item>
      <title>User Modeling in Model-Driven Engineering: A Systematic Literature Review</title>
      <link>https://arxiv.org/abs/2412.15871</link>
      <description>arXiv:2412.15871v2 Announce Type: replace 
Abstract: In software applications, user models can be used to specify the profile of the typical users of the application, including personality traits, preferences, skills, etc. In theory, this would enable an adaptive application behavior that could lead to a better user experience. Nevertheless, user models do not seem to be part of standard modeling languages nor common in current model-driven engineering (MDE) approaches. In this paper, we conduct a systematic literature review to analyze existing proposals for user modeling in MDE and identify their limitations. The results showcase that there is a lack of a unified and complete user modeling perspective. Instead, we observe a lot of fragmented and partial proposals considering only simple user dimensions and with lack of proper tool support. This limits the implementation of richer user interfaces able to better support the user-specific needs. Therefore, we hope this analysis triggers a discussion on the importance of user models and their inclusion in MDE pipelines. Especially in a context where, thanks to the rise of AI techniques, personalization, based on a rich number of user dimensions, is becoming more and more of a possibility.</description>
      <guid isPermaLink="false">oai:arXiv.org:2412.15871v2</guid>
      <category>cs.SE</category>
      <pubDate>Fri, 16 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Aaron Conrardy, Alfredo Capozucca, Jordi Cabot</dc:creator>
    </item>
    <item>
      <title>Unified Modeling Language Code Generation from Diagram Images Using Multimodal Large Language Models</title>
      <link>https://arxiv.org/abs/2503.12293</link>
      <description>arXiv:2503.12293v2 Announce Type: replace 
Abstract: The Unified Modeling Language is a standardized visual language widely used for modeling and documenting the design of software systems. Although many tools generate UML diagrams from UML code, generating executable UML code from image-based UML diagrams remains challenging. This paper proposes a new approach to generate UML code using a large multimodal language model automatically. Synthetic UML activity and sequence diagram datasets were created to train and test the model. We compared standard fine-tuning with LoRA techniques to optimize base models. The experiments measured code generation accuracy across different model sizes and training strategies. These results demonstrated that domain-adapted MM-LLMs perform for UML code generation automation, whereby, at the best model, it achieved BLEU and SSIM scores of 0.779 and 0.942 on sequence diagrams. This will enable the modernization of legacy systems and decrease the manual effort in software development workflows.</description>
      <guid isPermaLink="false">oai:arXiv.org:2503.12293v2</guid>
      <category>cs.SE</category>
      <category>cs.LG</category>
      <pubDate>Fri, 16 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <arxiv:DOI>10.1016/j.mlwa.2025.100660</arxiv:DOI>
      <arxiv:journal_reference>Mach. Learn. Appl. 20 (2025) 100660</arxiv:journal_reference>
      <dc:creator>Averi Bates, Ryan Vavricka, Shane Carleton, Ruosi Shao, Chongle Pan</dc:creator>
    </item>
    <item>
      <title>Mitigating Configuration Differences Between Development and Production Environments: A Catalog of Strategies</title>
      <link>https://arxiv.org/abs/2505.09392</link>
      <description>arXiv:2505.09392v2 Announce Type: replace 
Abstract: Context: The Configuration Management of the development and production environments is an important aspect of IT operations. However, managing the configuration differences between these two environments can be challenging, leading to inconsistent behavior, unexpected errors, and increased downtime. Objective: In this study, we sought to investigate the strategies software companies employ to mitigate the configuration differences between the development and production environments. Our goal is to provide a comprehensive understanding of these strategies used to contribute to reducing the risk of configuration-related issues. Method: To achieve this goal, we interviewed 17 participants and leveraged the Thematic Analysis methodology to analyze the interview data. These participants shed some light on the current practices, processes, challenges, or issues they have encountered. Results: Based on the interviews, we systematically formulated and structured a catalog of eight strategies that explain how software producing companies mitigate these configuration differences. These strategies vary from 1) creating detailed configuration management plans, 2) using automation tools, and 3) developing processes to test and validate changes through containers and virtualization technologies. Conclusion: By implementing these strategies, companies can improve their ability to respond quickly and effectively to changes in the production environment. In addition, they can also ensure compliance with industry standards and regulations.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.09392v2</guid>
      <category>cs.SE</category>
      <pubDate>Fri, 16 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Marcos Nazario, Rodrigo Bonifacio, Gustavo Pinto</dc:creator>
    </item>
    <item>
      <title>CloudHeatMap: Heatmap-Based Monitoring for Large-Scale Cloud Systems</title>
      <link>https://arxiv.org/abs/2410.21092</link>
      <description>arXiv:2410.21092v2 Announce Type: replace-cross 
Abstract: Cloud computing is essential for modern enterprises, requiring robust tools to monitor and manage Large-Scale Cloud Systems (LCS). Traditional monitoring tools often miss critical insights due to the complexity and volume of LCS telemetry data. This paper presents CloudHeatMap, a novel heatmap-based visualization tool for near-real-time monitoring of LCS health. It offers intuitive visualizations of key metrics, such as call volumes and response times, enabling operators to quickly identify performance issues. A case study on the IBM Cloud Console demonstrates the tool's effectiveness in enhancing operational monitoring and decision-making.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.21092v2</guid>
      <category>cs.DC</category>
      <category>cs.SE</category>
      <pubDate>Fri, 16 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Sarah Sohana, William Pourmajidi, John Steinbacher, Andriy Miranskyy</dc:creator>
    </item>
    <item>
      <title>SceneGenAgent: Precise Industrial Scene Generation with Coding Agent</title>
      <link>https://arxiv.org/abs/2410.21909</link>
      <description>arXiv:2410.21909v2 Announce Type: replace-cross 
Abstract: The modeling of industrial scenes is essential for simulations in industrial manufacturing. While large language models (LLMs) have shown significant progress in generating general 3D scenes from textual descriptions, generating industrial scenes with LLMs poses a unique challenge due to their demand for precise measurements and positioning, requiring complex planning over spatial arrangement. To address this challenge, we introduce SceneGenAgent, an LLM-based agent for generating industrial scenes through C# code. SceneGenAgent ensures precise layout planning through a structured and calculable format, layout verification, and iterative refinement to meet the quantitative requirements of industrial scenarios. Experiment results demonstrate that LLMs powered by SceneGenAgent exceed their original performance, reaching up to 81.0% success rate in real-world industrial scene generation tasks and effectively meeting most scene generation requirements. To further enhance accessibility, we construct SceneInstruct, a dataset designed for fine-tuning open-source LLMs to integrate into SceneGenAgent. Experiments show that fine-tuning open-source LLMs on SceneInstruct yields significant performance improvements, with Llama3.1-70B approaching the capabilities of GPT-4o. Our code and data are available at https://github.com/THUDM/SceneGenAgent .</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.21909v2</guid>
      <category>cs.CL</category>
      <category>cs.LG</category>
      <category>cs.SE</category>
      <pubDate>Fri, 16 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Xiao Xia, Dan Zhang, Zibo Liao, Zhenyu Hou, Tianrui Sun, Jing Li, Ling Fu, Yuxiao Dong</dc:creator>
    </item>
    <item>
      <title>SmartShift: A Secure and Efficient Approach to Smart Contract Migration</title>
      <link>https://arxiv.org/abs/2504.09315</link>
      <description>arXiv:2504.09315v2 Announce Type: replace-cross 
Abstract: Blockchain and smart contracts have emerged as revolutionary technologies transforming distributed computing. While platform evolution and smart contracts' inherent immutability necessitate migrations both across and within chains, migrating the vast amounts of critical data in these contracts while maintaining data integrity and minimizing operational disruption presents a significant challenge. To address these challenges, we present SmartShift, a framework that enables secure and efficient smart contract migrations through intelligent state partitioning and progressive function activation, preserving operational continuity during transitions. Our comprehensive evaluation demonstrates that SmartShift significantly reduces migration downtime while ensuring robust security, establishing a foundation for efficient and secure smart contract migration systems.</description>
      <guid isPermaLink="false">oai:arXiv.org:2504.09315v2</guid>
      <category>cs.CR</category>
      <category>cs.SE</category>
      <pubDate>Fri, 16 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <arxiv:DOI>10.1145/3696630.3728517</arxiv:DOI>
      <dc:creator>Tahrim Hossain, Faisal Haque Bappy, Tarannum Shaila Zaman, Raiful Hasan, Tariqul Islam</dc:creator>
    </item>
  </channel>
</rss>
