<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>cs.DS updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/cs.DS</link>
    <description>cs.DS updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/cs.DS" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Fri, 09 May 2025 04:00:05 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Fri, 09 May 2025 00:00:00 -0400</pubDate>
    <skipDays>
      <day>Saturday</day>
      <day>Sunday</day>
    </skipDays>
    <item>
      <title>PSSketch: Finding Persistent and Sparse Flow with High Accuracy and Efficiency</title>
      <link>https://arxiv.org/abs/2505.04892</link>
      <description>arXiv:2505.04892v1 Announce Type: new 
Abstract: Finding persistent sparse (PS) flow is critical to early warning of many threats. Previous works have predominantly focused on either heavy or persistent flows, with limited attention given to PS flows. Although some recent studies pay attention to PS flows, they struggle to establish an objective criterion due to insufficient data-driven observations, resulting in reduced accuracy. In this paper, we define a new criterion "anomaly boundary" to distinguish PS flows from regular flows. Specifically, a flow whose persistence exceeds a threshold will be protected, while a protected flow with a density lower than a threshold is reported as a PS flow. We then introduce PSSketch, a high-precision layered sketch to find PS flows. PSSketch employs variable-length bitwise counters, where the first layer tracks the frequency and persistence of all flows, and the second layer protects potential PS flows and records overflow counts from the first layer. Some optimizations have also been implemented to reduce memory consumption further and improve accuracy. The experiments show that PSSketch reduces memory consumption by an order of magnitude compared to the strawman solution combined with existing work. Compared with SOTA solutions for finding PS flows, it outperforms up to 2.94x in F1 score and reduces ARE by 1-2 orders of magnitude. Meanwhile, PSSketch achieves a higher throughput than these solutions.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.04892v1</guid>
      <category>cs.DS</category>
      <pubDate>Fri, 09 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Jiayao Wang, Qilong Shi, Xiyan Liang, Han Wang, Wenjun Li, Ziling Wei, Weizhe Zhang, Shuhui Chen</dc:creator>
    </item>
    <item>
      <title>With a Little Help From My Friends: Exploiting Probability Distribution Advice in Algorithm Design</title>
      <link>https://arxiv.org/abs/2505.04949</link>
      <description>arXiv:2505.04949v1 Announce Type: new 
Abstract: We study online algorithms with predictions using distributional advice, a type of prediction that arises when leveraging expert knowledge or historical data. To demonstrate the usefulness and versatility of this framework, we focus on two fundamental problems: first, the prophet inequality problem, for which we provide an algorithm achieving $\max\{\frac{1}{2}-\eta-o(1),\frac{1}{e}\}$-competitive ratio, where $\eta$ quantifies the quality of the prediction. Second, we turn to the online metric matching problem under random arrivals, for which our main positive result is an algorithm achieving the optimal cost under perfect advice, while smoothly defaulting to competitive ratios comparable to advice-free algorithms as the prediction's quality degrades.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.04949v1</guid>
      <category>cs.DS</category>
      <pubDate>Fri, 09 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <dc:creator>Cl\'ement L. Canonne, Kenny Chen, Juli\'an Mestre</dc:creator>
    </item>
    <item>
      <title>Zip-Tries: Simple Dynamic Data Structures for Strings</title>
      <link>https://arxiv.org/abs/2505.04953</link>
      <description>arXiv:2505.04953v1 Announce Type: new 
Abstract: In this paper, we introduce zip-tries, which are simple, dynamic, memory-efficient data structures for strings. Zip-tries support search and update operations for $k$-length strings in $\mathcal{O}(k+\log n)$ time in the standard RAM model or in $\mathcal{O}(k/\alpha+\log n)$ time in the word RAM model, where $\alpha$ is the length of the longest string that can fit in a memory word, and $n$ is the number of strings in the trie. Importantly, we show how zip-tries can achieve this while only requiring $\mathcal{O}(\log{\log{n}} + \log{\log{\frac{k}{\alpha}}})$ bits of metadata per node w.h.p., which is an exponential improvement over previous results for long strings. Despite being considerably simpler and more memory efficient, we show how zip-tries perform competitively with state-of-the-art data structures on large datasets of long strings.
  Furthermore, we provide a simple, general framework for parallelizing string comparison operations in linked data structures, which we apply to zip-tries to obtain parallel zip-tries. Parallel zip-tries are able to achieve good search and update performance in parallel, performing such operations in $\mathcal{O}(\log{n})$ span. We also apply our techniques to an existing external-memory string data structure, the string B-tree, obtaining a parallel string B-tree which performs search operations using $\mathcal{O}(\log_B{n})$ I/O span and $\mathcal{O}(\frac{k}{\alpha B} + \log_B{n})$ I/O work in the parallel external memory (PEM) model. The parallel string B-tree can perform prefix searches using only $\mathcal{O}(\frac{\log{n}}{\log{\log{n}}})$ span under the practical PRAM model.
  For the case of long strings that share short common prefixes, we provide LCP-aware variants of all our algorithms that should be quite efficient in practice, which we justify empirically.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.04953v1</guid>
      <category>cs.DS</category>
      <pubDate>Fri, 09 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>David Eppstein (University of California, Irvine), Ofek Gila (University of California, Irvine), Michael T. Goodrich (University of California, Irvine), Ryuto Kitagawa (University of California, Irvine)</dc:creator>
    </item>
    <item>
      <title>Learning Partitions with Optimal Query and Round Complexities</title>
      <link>https://arxiv.org/abs/2505.05009</link>
      <description>arXiv:2505.05009v1 Announce Type: new 
Abstract: We consider the basic problem of learning an unknown partition of $n$ elements into at most $k$ sets using simple queries that reveal information about a small subset of elements. Our starting point is the well-studied pairwise same-set queries which ask if a pair of elements belong to the same class. It is known that non-adaptive algorithms require $\Theta(n^2)$ queries, while adaptive algorithms require $\Theta(nk)$ queries, and the best known algorithm uses $k-1$ rounds. This problem has been studied extensively over the last two decades in multiple communities due to its fundamental nature and relevance to clustering, active learning, and crowd sourcing. In many applications, it is of high interest to reduce adaptivity while minimizing query complexity. We give a complete characterization of the deterministic query complexity of this problem as a function of the number of rounds, $r$, interpolating between the non-adaptive and adaptive settings: for any constant $r$, the query complexity is $\Theta(n^{1+\frac{1}{2^r-1}}k^{1-\frac{1}{2^r-1}})$. Our algorithm only needs $O(\log \log n)$ rounds to attain the optimal $O(nk)$ query complexity.
  Next, we consider two generalizations of pairwise queries to subsets $S$ of size at most $s$: (1) weak subset queries which return the number of classes intersected by $S$, and (2) strong subset queries which return the entire partition restricted on $S$. Once again in crowd sourcing applications, queries on large sets may be prohibitive. For non-adaptive algorithms, we show $\Omega(n^2/s^2)$ strong queries are needed. Perhaps surprisingly, we show that there is a non-adaptive algorithm using weak queries that matches this bound up to log-factors for all $s \leq \sqrt{n}$. More generally, we obtain nearly matching upper and lower bounds for algorithms using subset queries in terms of both the number of rounds, $r$, and the query size bound, $s$.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.05009v1</guid>
      <category>cs.DS</category>
      <pubDate>Fri, 09 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Hadley Black, Arya Mazumdar, Barna Saha</dc:creator>
    </item>
    <item>
      <title>Efficient Parallel Ising Samplers via Localization Schemes</title>
      <link>https://arxiv.org/abs/2505.05185</link>
      <description>arXiv:2505.05185v1 Announce Type: new 
Abstract: We introduce efficient parallel algorithms for sampling from the Gibbs distribution and estimating the partition function of Ising models. These algorithms achieve parallel efficiency, with polylogarithmic depth and polynomial total work, and are applicable to Ising models in the following regimes: (1) Ferromagnetic Ising models with external fields; (2) Ising models with interaction matrix $J$ of operator norm $\|J\|_2&lt;1$.
  Our parallel Gibbs sampling approaches are based on localization schemes, which have proven highly effective in establishing rapid mixing of Gibbs sampling. In this work, we employ two such localization schemes to obtain efficient parallel Ising samplers: the \emph{field dynamics} induced by \emph{negative-field localization}, and \emph{restricted Gaussian dynamics} induced by \emph{stochastic localization}. This shows that localization schemes are powerful tools, not only for achieving rapid mixing but also for the efficient parallelization of Gibbs sampling.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.05185v1</guid>
      <category>cs.DS</category>
      <pubDate>Fri, 09 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Xiaoyu Chen, Hongyang Liu, Yitong Yin, Xinyuan Zhang</dc:creator>
    </item>
    <item>
      <title>Overlapping Biclustering</title>
      <link>https://arxiv.org/abs/2505.05213</link>
      <description>arXiv:2505.05213v1 Announce Type: new 
Abstract: In this paper, we introduce Bicluster Editing with Vertex Splitting, a variant of the Bicluster Editing problem, which aims to transform a given graph into a bicluster graph using a minimum number of operations. In Bicluster Editing, the allowed operations are the insertion and deletion of edges. In Bicluster Editing with Vertex Splitting we additionally allow overlapping clusters, which we model by allowing vertex splits. We prove that Bicluster Editing with Vertex Splitting is NP-complete. On the positive side, we show that it admits a polynomial kernel with respect to the number k of allowed edit operations and present an algorithm running in O(k^{11k} + n + m) time, where n and m denote the number of vertices and edges in the input graph, respectively.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.05213v1</guid>
      <category>cs.DS</category>
      <pubDate>Fri, 09 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Matthias Bentert, P{\aa}l Gr{\o}n{\aa}s Drange, Erlend Haugen</dc:creator>
    </item>
    <item>
      <title>InfTDA: A Simple TopDown Mechanism for Hierarchical Differentially Private Counting Queries</title>
      <link>https://arxiv.org/abs/2505.05347</link>
      <description>arXiv:2505.05347v1 Announce Type: new 
Abstract: This paper extends $\texttt{InfTDA}$, a mechanism proposed in (Boninsegna, Silvestri, PETS 2025) for mobility datasets with origin and destination trips, in a general setting. The algorithm presented in this paper works for any dataset of $d$ categorical features and produces a differentially private synthetic dataset that answers all hierarchical queries, a special case of marginals, each with bounded maximum absolute error. The algorithm builds upon the TopDown mechanism developed for the 2020 US Census.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.05347v1</guid>
      <category>cs.DS</category>
      <pubDate>Fri, 09 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Fabrizio Boninsegna</dc:creator>
    </item>
    <item>
      <title>CART-ELC: Oblique Decision Tree Induction via Exhaustive Search</title>
      <link>https://arxiv.org/abs/2505.05402</link>
      <description>arXiv:2505.05402v1 Announce Type: cross 
Abstract: Oblique decision trees have attracted attention due to their potential for improved classification performance over traditional axis-aligned decision trees. However, methods that rely on exhaustive search to find oblique splits face computational challenges. As a result, they have not been widely explored. We introduce a novel algorithm, Classification and Regression Tree - Exhaustive Linear Combinations (CART-ELC), for inducing oblique decision trees that performs an exhaustive search on a restricted set of hyperplanes. We then investigate the algorithm's computational complexity and its predictive capabilities. Our results demonstrate that CART-ELC consistently achieves competitive performance on small datasets, often yielding statistically significant improvements in classification accuracy relative to existing decision tree induction algorithms, while frequently producing shallower, simpler, and thus more interpretable trees.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.05402v1</guid>
      <category>cs.LG</category>
      <category>cs.AI</category>
      <category>cs.DS</category>
      <pubDate>Fri, 09 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-sa/4.0/</dc:rights>
      <dc:creator>Andrew D. Laack</dc:creator>
    </item>
    <item>
      <title>Online Matching on $3$-Uniform Hypergraphs</title>
      <link>https://arxiv.org/abs/2402.13227</link>
      <description>arXiv:2402.13227v2 Announce Type: replace 
Abstract: The online matching problem was introduced by Karp, Vazirani and Vazirani (STOC 1990) on bipartite graphs with vertex arrivals. It is well-known that the optimal competitive ratio is $1-1/e$ for both integral and fractional versions of the problem. Since then, there has been considerable effort to find optimal competitive ratios for other related settings. In this work, we go beyond the graph case and study the online matching problem on $k$-uniform hypergraphs. For $k=3$, we provide an optimal primal-dual fractional algorithm, which achieves a competitive ratio of $(e-1)/(e+1)\approx 0.4621$. As our main technical contribution, we present a carefully constructed adversarial instance, which shows that this ratio is in fact optimal. It combines ideas from known hard instances for bipartite graphs under the edge-arrival and vertex-arrival models. For $k\geq 3$, we give a simple integral algorithm which performs better than greedy when the online nodes have bounded degree. As a corollary, it achieves the optimal competitive ratio of 1/2 on 3-uniform hypergraphs when every online node has degree at most 2. This is because the special case where every online node has degree 1 is equivalent to the edge-arrival model on graphs, for which an upper bound of 1/2 is known.</description>
      <guid isPermaLink="false">oai:arXiv.org:2402.13227v2</guid>
      <category>cs.DS</category>
      <category>math.OC</category>
      <pubDate>Fri, 09 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Sander Borst, Danish Kashaev, Zhuan Khye Koh</dc:creator>
    </item>
    <item>
      <title>A Fast Algorithm for Computing Prefix Probabilities</title>
      <link>https://arxiv.org/abs/2306.02303</link>
      <description>arXiv:2306.02303v5 Announce Type: replace-cross 
Abstract: Multiple algorithms are known for efficiently calculating the prefix probability of a string under a probabilistic context-free grammar (PCFG). Good algorithms for the problem have a runtime cubic in the length of the input string. However, some proposed algorithms are suboptimal with respect to the size of the grammar. This paper proposes a novel speed-up of Jelinek and Lafferty's (1991) algorithm, whose original runtime is $O(n^3 |N|^3 + |N|^4)$, where $n$ is the input length and $|N|$ is the number of non-terminals in the grammar. In contrast, our speed-up runs in $O(n^2 |N|^3+n^3|N|^2)$.</description>
      <guid isPermaLink="false">oai:arXiv.org:2306.02303v5</guid>
      <category>cs.FL</category>
      <category>cs.DS</category>
      <pubDate>Fri, 09 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <arxiv:DOI>10.18653/v1/2023.acl-short.6</arxiv:DOI>
      <arxiv:journal_reference>Proceedings of the 61st Annual Meeting of the Association for Computational Linguistics, Volume 2: Short Papers, pages 57-67, 2003</arxiv:journal_reference>
      <dc:creator>Franz Nowak, Ryan Cotterell</dc:creator>
    </item>
    <item>
      <title>Unravelling Expressive Delegations: Complexity and Normative Analysis</title>
      <link>https://arxiv.org/abs/2312.11932</link>
      <description>arXiv:2312.11932v2 Announce Type: replace-cross 
Abstract: We consider binary group decision-making under a rich model of liquid democracy recently proposed by Colley, Grandi, and Novaro (2022): agents submit ranked delegation options, where each option may be a function of multiple agents' votes; e.g., "I vote yes if a majority of my friends vote yes." Such ballots are unravelled into a profile of direct votes by selecting one entry from each ballot so as not to introduce cyclic dependencies. We study delegation via monotonic Boolean functions, and two unravelling procedures: MinSum, which minimises the sum of the ranks of the chosen entries, and its egalitarian counterpart, MinMax. We provide complete computational dichotomies: MinSum is hard to compute (and approximate) as soon as any non-trivial functions are permitted, and polynomial otherwise; for MinMax the easiness results extend to arbitrary-arity logical ORs and ANDs taken in isolation, but not beyond. For the classic model of delegating to individual agents, we give asymptotically near-tight algorithms for carrying out the two procedures and efficient algorithms for finding optimal unravellings with the highest vote count for a given alternative. These algorithms inspire novel tie-breaking rules for the setup of voting to change a status quo. We then introduce a new axiom, which can be viewed as a variant of the participation axiom, and use algorithmic techniques developed earlier in the paper to show that it is satisfied by MinSum and a lexicographic refinement of MinMax (but not MinMax itself).</description>
      <guid isPermaLink="false">oai:arXiv.org:2312.11932v2</guid>
      <category>cs.GT</category>
      <category>cs.CC</category>
      <category>cs.DS</category>
      <pubDate>Fri, 09 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Giannis Tyrovolas, Andrei Constantinescu, Edith Elkind</dc:creator>
    </item>
    <item>
      <title>$k$-local Graphs</title>
      <link>https://arxiv.org/abs/2410.00601</link>
      <description>arXiv:2410.00601v2 Announce Type: replace-cross 
Abstract: In 2017 Day et al. introduced the notion of locality as a structural complexity-measure for patterns in the field of pattern matching established by Angluin in 1980. In 2019 Casel et al. showed that determining the locality of an arbitrary pattern is NP-complete. Inspired by hierarchical clustering, we extend the notion to coloured graphs, i.e., given a coloured graph determine an enumeration of the colours such that colouring the graph stepwise according to the enumeration leads to as few clusters as possible. Next to first theoretical results on graph classes, we propose a priority search algorithm to compute the $k$-locality of a graph. The algorithm is optimal in the number of marking prefix expansions, and is faster by orders of magnitude than an exhaustive search. Finally, we perform a case study on a DBLP subgraph to demonstrate the potential of $k$-locality for knowledge discovery.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.00601v2</guid>
      <category>math.CO</category>
      <category>cs.DS</category>
      <category>cs.SI</category>
      <pubDate>Fri, 09 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Christian Beth, Pamela Fleischmann, Annika Huch, Daniyal Kazempour, Peer Kr\"oger, Andrea Kulow, Matthias Renz</dc:creator>
    </item>
    <item>
      <title>Regularized Robustly Reliable Learners and Instance Targeted Attacks</title>
      <link>https://arxiv.org/abs/2410.10572</link>
      <description>arXiv:2410.10572v4 Announce Type: replace-cross 
Abstract: Instance-targeted data poisoning attacks, where an adversary corrupts a training set to induce errors on specific test points, have raised significant concerns. Balcan et al (2022) proposed an approach to addressing this challenge by defining a notion of robustly-reliable learners that provide per-instance guarantees of correctness under well-defined assumptions, even in the presence of data poisoning attacks. They then give a generic optimal (but computationally inefficient) robustly reliable learner as well as a computationally efficient algorithm for the case of linear separators over log-concave distributions.
  In this work, we address two challenges left open by Balcan et al (2022). The first is that the definition of robustly-reliable learners in Balcan et al (2022) becomes vacuous for highly-flexible hypothesis classes: if there are two classifiers h_0, h_1 \in H both with zero error on the training set such that h_0(x) \neq h_1(x), then a robustly-reliable learner must abstain on x. We address this problem by defining a modified notion of regularized robustly-reliable learners that allows for nontrivial statements in this case. The second is that the generic algorithm of Balcan et al (2022) requires re-running an ERM oracle (essentially, retraining the classifier) on each test point x, which is generally impractical even if ERM can be implemented efficiently. To tackle this problem, we show that at least in certain interesting cases we can design algorithms that can produce their outputs in time sublinear in training time, by using techniques from dynamic algorithm design.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.10572v4</guid>
      <category>cs.LG</category>
      <category>cs.CR</category>
      <category>cs.DS</category>
      <category>stat.ML</category>
      <pubDate>Fri, 09 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Avrim Blum, Donya Saless</dc:creator>
    </item>
    <item>
      <title>Guaranteed Recovery of Unambiguous Clusters</title>
      <link>https://arxiv.org/abs/2501.13093</link>
      <description>arXiv:2501.13093v3 Announce Type: replace-cross 
Abstract: Clustering is often a challenging problem because of the inherent ambiguity in what the "correct" clustering should be. Even when the number of clusters $K$ is known, this ambiguity often still exists, particularly when there is variation in density among different clusters, and clusters have multiple relatively separated regions of high density. In this paper we propose an information-theoretic characterization of when a $K$-clustering is ambiguous, and design an algorithm that recovers the clustering whenever it is unambiguous. This characterization formalizes the situation when two high density regions within a cluster are separable enough that they look more like two distinct clusters than two truly distinct clusters in the $K$-clustering. The algorithm first identifies $K$ partial clusters (or "seeds") using a density-based approach, and then adds unclustered points to the initial $K$ partial clusters in a greedy manner to form a complete clustering. We implement and test a version of the algorithm that is modified to effectively handle overlapping clusters, and observe that it requires little parameter selection and displays improved performance on many datasets compared to widely used algorithms for non-convex cluster recovery.</description>
      <guid isPermaLink="false">oai:arXiv.org:2501.13093v3</guid>
      <category>cs.IT</category>
      <category>cs.AI</category>
      <category>cs.DS</category>
      <category>cs.LG</category>
      <category>math.IT</category>
      <category>math.ST</category>
      <category>stat.TH</category>
      <pubDate>Fri, 09 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Kayvon Mazooji, Ilan Shomorony</dc:creator>
    </item>
    <item>
      <title>The Marco Polo Problem: A Combinatorial Approach to Geometric Localization</title>
      <link>https://arxiv.org/abs/2504.17955</link>
      <description>arXiv:2504.17955v2 Announce Type: replace-cross 
Abstract: We introduce and study the Marco Polo problem, which is a combinatorial approach to geometric localization. In this problem, we are told there are one or more points of interest (POIs) within distance $n$ of the origin that we wish to localize. Given a mobile search point, $\Delta$, that is initially at the origin, a localization algorithm is a strategy to move $\Delta$ to be within a distance of $1$ of a POI. In the combinatorial localization problem we study, the only tool we can use is reminiscent of the children's game, "Marco Polo," in that $\Delta$ can issue a probe signal out a specified distance, $d$, and the search algorithm learns whether or not there is a POI within distance $d$ of $\Delta$. For example, we could imagine that POIs are one or more hikers lost in a forest and we need to design a search-and-rescue (SAR) strategy to find them using radio signal probes to a response device that hikers carry. Unlike other known localization algorithms, probe responses do not inform our search algorithm of the direction or distance to a POI. The optimization problem is to minimize the number of probes and/or POI responses, as well as possibly minimizing the distance traveled by $\Delta$. We describe a number of efficient combinatorial Marco Polo localization strategies and we analyze each one in terms of the size, $n$, of the search domain. Moreover, we derive strong bounds for the constant factors for the search costs for our algorithms, which in some cases involve computer-assisted proofs. We also show how to extend these strategies to find all POIs using a simple, memoryless search algorithm, traveling a distance that is $\mathcal{O}(\log{k})$-competitive with the optimal traveling salesperson (TSP) tour for $k$ POIs.</description>
      <guid isPermaLink="false">oai:arXiv.org:2504.17955v2</guid>
      <category>cs.CG</category>
      <category>cs.DS</category>
      <pubDate>Fri, 09 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Ofek Gila (University of California, Irvine), Michael T. Goodrich (University of California, Irvine), Zahra Hadizadeh (University of Rochester), Daniel S. Hirschberg (University of California, Irvine), Shayan Taherijam (University of California, Irvine)</dc:creator>
    </item>
    <item>
      <title>Approximate Lifted Model Construction</title>
      <link>https://arxiv.org/abs/2504.20784</link>
      <description>arXiv:2504.20784v2 Announce Type: replace-cross 
Abstract: Probabilistic relational models such as parametric factor graphs enable efficient (lifted) inference by exploiting the indistinguishability of objects. In lifted inference, a representative of indistinguishable objects is used for computations. To obtain a relational (i.e., lifted) representation, the Advanced Colour Passing (ACP) algorithm is the state of the art. The ACP algorithm, however, requires underlying distributions, encoded as potential-based factorisations, to exactly match to identify and exploit indistinguishabilities. Hence, ACP is unsuitable for practical applications where potentials learned from data inevitably deviate even if associated objects are indistinguishable. To mitigate this problem, we introduce the $\varepsilon$-Advanced Colour Passing ($\varepsilon$-ACP) algorithm, which allows for a deviation of potentials depending on a hyperparameter $\varepsilon$. $\varepsilon$-ACP efficiently uncovers and exploits indistinguishabilities that are not exact. We prove that the approximation error induced by $\varepsilon$-ACP is strictly bounded and our experiments show that the approximation error is close to zero in practice.</description>
      <guid isPermaLink="false">oai:arXiv.org:2504.20784v2</guid>
      <category>cs.AI</category>
      <category>cs.DS</category>
      <category>cs.LG</category>
      <pubDate>Fri, 09 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <dc:creator>Malte Luttermann, Jan Speller, Marcel Gehrke, Tanya Braun, Ralf M\"oller, Mattis Hartwig</dc:creator>
    </item>
  </channel>
</rss>
