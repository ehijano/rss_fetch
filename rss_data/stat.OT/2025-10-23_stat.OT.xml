<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>stat.OT updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/stat.OT</link>
    <description>stat.OT updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/stat.OT" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Fri, 24 Oct 2025 04:01:01 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Fri, 24 Oct 2025 00:00:00 -0400</pubDate>
    <skipDays>
      <day>Saturday</day>
      <day>Sunday</day>
    </skipDays>
    <item>
      <title>Change, dependence, and discovery: Celebrating the work of T.L. Lai</title>
      <link>https://arxiv.org/abs/2510.20023</link>
      <description>arXiv:2510.20023v1 Announce Type: new 
Abstract: Tze Leung Lai made seminal contributions to sequential analysis, particularly in sequential hypothesis testing, changepoint detection and nonlinear renewal theory. His work established fundamental optimality results for the sequential probability ratio test and its extensions, and provided a general framework for testing composite hypotheses. In changepoint detection, he introduced new optimality criteria and computationally efficient procedures that remain influential. He applied these and related tools to problems in biostatistics. In this article, we review these key results in the broader context of sequential analysis.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.20023v1</guid>
      <category>stat.OT</category>
      <category>math.ST</category>
      <category>stat.TH</category>
      <pubDate>Fri, 24 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Alexander G. Tartakovskya, Jay Bartroff, Cheng-Der Fuh, Haipeng Xing</dc:creator>
    </item>
    <item>
      <title>Factors Associated with Unit-Specific Failure in a University-Level Statistics Course</title>
      <link>https://arxiv.org/abs/2510.20100</link>
      <description>arXiv:2510.20100v1 Announce Type: new 
Abstract: This study investigates the factors associated with failure in each of the four thematic units of a General Statistics course offered at a private university in Colombia. Unlike traditional analyses that treat performance as a single outcome, this research disaggregates results by unit: Exploratory Data Analysis, Probability and Random Variables, Statistical Inference, and Linear Regression -- highlighting distinct challenges across content areas. Based on a sample of 186 undergraduate students from Engineering, Geology, and Interactive Design programs, the study combines exam performance data with self-perceived preparedness surveys to develop unit-specific logistic regression models. The findings reveal consistent structural disadvantages for students from non-engineering programs, especially in concept-heavy units such as Inference and Regression. Academic stage and perception of competence also emerged as important predictors, though their effects varied across units. The results align with prior research on statistical thinking and self-efficacy, and support the need for targeted pedagogical interventions and curricular alignment. This disaggregated approach offers a more nuanced understanding of academic vulnerability in statistics education and contributes to the design of evidence-based, context-sensitive strategies to reduce failure and improve learning outcomes.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.20100v1</guid>
      <category>stat.OT</category>
      <pubDate>Fri, 24 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Biviana Marcela Suarez Sierra</dc:creator>
    </item>
    <item>
      <title>Unifying Boxplots: A Multiple Testing Perspective</title>
      <link>https://arxiv.org/abs/2510.20259</link>
      <description>arXiv:2510.20259v1 Announce Type: cross 
Abstract: Tukey's boxplot is a foundational tool for exploratory data analysis, but its classic outlier-flagging rule does not account for the sample size, and subsequent modifications have often been presented as separate, heuristic adjustments. In this paper, we propose a unifying framework that recasts the boxplot and its variants as graphical implementations of multiple testing procedures. We demonstrate that Tukey's original method is equivalent to an unadjusted procedure, while existing sample-size-aware modifications correspond to controlling the Family-Wise Error Rate (FWER) or the Per-Family Error Rate (PFER). This perspective not only systematizes existing methods but also naturally leads to new, more adaptive constructions. We introduce a boxplot motivated by the False Discovery Rate (FDR), and show how our framework provides a flexible pipeline for integrating state-of-the-art robust estimation techniques directly into the boxplot's graphical format. By connecting a classic graphical tool to the principles of multiple testing, our work provides a principled language for comparing, critiquing, and extending outlier detection rules for modern exploratory analysis.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.20259v1</guid>
      <category>stat.ME</category>
      <category>stat.OT</category>
      <pubDate>Fri, 24 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <dc:creator>Bowen Gang, Hongmei Lin, Tiejun Tong</dc:creator>
    </item>
    <item>
      <title>Optimizing Feature Ordering in Radar Charts for Multi-Profile Comparison</title>
      <link>https://arxiv.org/abs/2510.20738</link>
      <description>arXiv:2510.20738v1 Announce Type: cross 
Abstract: Radar charts are widely used to visualize multivariate data and compare multiple profiles across features. However, the visual clarity of radar charts can be severely compromised when feature values alternate drastically in magnitude around the circle, causing areas to collapse, which misrepresents relative differences. In the present work we introduce a permutation optimization strategy that reorders features to minimize polygon ``spikiness'' across multiple profiles simultaneously. The method is combinatorial (exhaustive search) for moderate numbers of features and uses a lexicographic minimax criterion that first considers overall smoothness (mean jump) and then the largest single jump as a tie-breaker. This preserves more global information and produces visually balanced arrangements. We discuss complexity, practical bounds, and relations to existing approaches that either change the visualization (e.g., OrigamiPlot) or learn orderings (e.g., Versatile Ordering Network). An example with two profiles and $p=6$ features (before/after ordering) illustrates the qualitative improvement.
  Keywords: data visualization, radar charts, combinatorial optimization, minimax optimization, feature ordering</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.20738v1</guid>
      <category>cs.HC</category>
      <category>cs.DS</category>
      <category>cs.GR</category>
      <category>math.OC</category>
      <category>stat.OT</category>
      <pubDate>Fri, 24 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <dc:creator>Albert Dorador</dc:creator>
    </item>
    <item>
      <title>Revisiting Functional Derivatives in Multi-object Tracking</title>
      <link>https://arxiv.org/abs/2508.12982</link>
      <description>arXiv:2508.12982v3 Announce Type: replace-cross 
Abstract: Probability generating functionals (PGFLs) are efficient and powerful tools for tracking independent objects in clutter. It was shown that PGFLs could be used for the elegant derivation of practical multi-object tracking algorithms, e.g., the probability hypothesis density (PHD) filter. However, derivations using PGFLs use the so-called functional derivatives whose definitions usually appear too complicated or heuristic, involving Dirac delta ``functions''. This paper begins by comparing different definitions of functional derivatives and exploring their relationships and implications for practical applications. It then proposes a rigorous definition of the functional derivative, utilizing straightforward yet precise mathematics for clarity. Key properties of the functional derivative are revealed and discussed.</description>
      <guid isPermaLink="false">oai:arXiv.org:2508.12982v3</guid>
      <category>eess.SY</category>
      <category>cs.SY</category>
      <category>stat.OT</category>
      <pubDate>Fri, 24 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Jan Krej\v{c}\'i, Ond\v{r}ej Straka, Petr Girg, Ji\v{r}\'i Benedikt</dc:creator>
    </item>
  </channel>
</rss>
