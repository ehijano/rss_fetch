<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>math.OC updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/math.OC</link>
    <description>math.OC updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/math.OC" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Mon, 07 Oct 2024 04:00:30 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Mon, 07 Oct 2024 00:00:00 -0400</pubDate>
    <skipDays>
      <day>Saturday</day>
      <day>Sunday</day>
    </skipDays>
    <item>
      <title>Long Range Games</title>
      <link>https://arxiv.org/abs/2410.02822</link>
      <description>arXiv:2410.02822v1 Announce Type: new 
Abstract: We consider $N$-player games, in continuous time, finite state space and finite time horizon, on a geometrical structure possessing a macroscopic limit in a suitable sense. This geometrical structure breaks the permutation invariance property that gives rise to mean field games. The corresponding limit game is a variant of mean field games that we call {\em long range game}. We prove that this asymptotic scheme satisfies the following key properties: a) the long range game admits al least one equilibrium; b) this equilibrium is unique under a suitable monotonicity condition; c) the feedback corresponding to any equilibrium of the long range game is a quasi-Nash equilibrium for the $N$-player games. We finally show that this scheme includes several examples of interaction mechanisms, in particular Kac-type interactions and interactions on generalized Erd\"{o}s-Renyi graphs.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.02822v1</guid>
      <category>math.OC</category>
      <category>math.PR</category>
      <pubDate>Mon, 07 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Francesca Albertini, Paolo Dai Pra</dc:creator>
    </item>
    <item>
      <title>Model-free, Learning-based Control of LGKS Quantum System</title>
      <link>https://arxiv.org/abs/2410.02882</link>
      <description>arXiv:2410.02882v1 Announce Type: new 
Abstract: This paper presents a model-free, learning-based adaptive controller for the density tracking problem in a two-level Lindblad-Gorini-Kossakowski-Sudarshan (LGKS) quantum system. The adaptive controller is based on the continuous-time retrospective cost adaptive control. To preserve the geometric properties of the quantum system, an adaptive PID controller driven and optimized by Ulhmann's fidelity is used. The proposed controller is validated in simulation for a low and a high-entropy density-tracking problem.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.02882v1</guid>
      <category>math.OC</category>
      <pubDate>Mon, 07 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <dc:creator>Jhon Manuel Portella Delgado, Ankit Goel</dc:creator>
    </item>
    <item>
      <title>Approximation Schemes for POMPDs with Continuous Spaces and Their Near Optimality</title>
      <link>https://arxiv.org/abs/2410.02895</link>
      <description>arXiv:2410.02895v1 Announce Type: new 
Abstract: We study an approximation method for partially observed Markov decision processes (POMDPs) with continuous spaces. Belief MDP reduction, which has been the standard approach to study POMDPs requires rigorous approximation methods for practical applications, due to the state space being lifted to the space of probability measures. Generalizing recent work, in this paper we present rigorous approximation methods via discretizing the observation space and constructing a fully observed finite MDP model using a finite length history of the discrete observations and control actions. We show that the resulting policy is near-optimal under some regularity assumptions on the channel, and under certain controlled filter stability requirements for the hidden state process. Furthermore, by quantizing the measurements, we are able to utilize refined filter stability conditions. We also provide a Q learning algorithm that uses a finite memory of discretized information variables, and prove its convergence to the optimality equation of the finite fully observed MDP constructed using the approximation method.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.02895v1</guid>
      <category>math.OC</category>
      <category>cs.SY</category>
      <category>eess.SY</category>
      <pubDate>Mon, 07 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Ali Devran Kara, Erhan Bayraktar, Serdar Yuksel</dc:creator>
    </item>
    <item>
      <title>Convergence Guarantees for Neural Network-Based Hamilton-Jacobi Reachability</title>
      <link>https://arxiv.org/abs/2410.02904</link>
      <description>arXiv:2410.02904v1 Announce Type: new 
Abstract: We provide a novel uniform convergence guarantee for DeepReach, a deep learning-based method for solving Hamilton-Jacobi-Isaacs (HJI) equations associated with reachability analysis. Specifically, we show that the DeepReach algorithm, as introduced by Bansal et al. in their eponymous paper from 2020, is stable in the sense that if the loss functional for the algorithm converges to zero, then the resulting neural network approximation converges uniformly to the classical solution of the HJI equation, assuming that a classical solution exists. We also provide numerical tests of the algorithm, replicating the experiments provided in the original DeepReach paper and empirically examining the impact that training with a supremum norm loss metric has on approximation error.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.02904v1</guid>
      <category>math.OC</category>
      <category>cs.NA</category>
      <category>math.NA</category>
      <category>stat.ML</category>
      <pubDate>Mon, 07 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-sa/4.0/</dc:rights>
      <dc:creator>William Hofgard</dc:creator>
    </item>
    <item>
      <title>Optimization for Evaluating the Practical Capacity of a Transshipment Yard</title>
      <link>https://arxiv.org/abs/2410.02968</link>
      <description>arXiv:2410.02968v1 Announce Type: new 
Abstract: In order to increase rail freight transportation in Italy, Rete Ferroviaria Italiana (RFI) the Italian railway infrastructure manager, is carrying out several investment plans to enhance the Transshipment Yards, that act as an interface between the rail and road networks. The need is to increase their practical capacity, i.e. the maximum number of train services that can be inserted without altering the current timetable while respecting all relevant constraints. Several factors influence the practical capacity of a transshipment yard: physical resources (such as tracks and vehicles for loading/unloading); constraints on the possible time slots of individual operations; constraints on the length of time a train must stay in the yard, that follow from both timetable requirements that are settled by the (prevalent) main line and from administrative and organisational issues in the yard. In this paper, we propose a MILP-based optimization model that is based on the solution of a suitable saturation problem, that deals with all these constraints and that can be used for evaluating the practical capacity of a transshipment yard both in its current configuration and in any plausible future configuration. The model provides operational details, such as routes and schedules, for each train service, and allows to impose periodic timetables and schedules that keep the daily management of the yard easier. Both the model and its solutions are validated on a real Italian transshipment yard, located at Marzaglia, on different scenarios corresponding to different investment plans of RFI. The results show that proper investments allow to get a feasible timetable with a period of 24 hours with doubles the number of current train services.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.02968v1</guid>
      <category>math.OC</category>
      <pubDate>Mon, 07 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Anna Russo Russo, Roberto Mancini, Gianpaolo Oriolo, Veronica Piccialli, Davide Ussai</dc:creator>
    </item>
    <item>
      <title>$\gamma$-Competitiveness: An Approach to Multi-Objective Optimization with High Computation Costs in Lipschitz Functions</title>
      <link>https://arxiv.org/abs/2410.03023</link>
      <description>arXiv:2410.03023v1 Announce Type: new 
Abstract: In practical engineering and optimization, solving multi-objective optimization (MOO) problems typically involves scalarization methods that convert a multi-objective problem into a single-objective one. While effective, these methods often incur significant computational costs due to iterative calculations and are further complicated by the need for hyperparameter tuning. In this paper, we introduce an extension of the concept of competitive solutions and propose the Scalarization With Competitiveness Method (SWCM) for multi-criteria problems. This method is highly interpretable and eliminates the need for hyperparameter tuning. Additionally, we offer a solution for cases where the objective functions are Lipschitz continuous and can only be computed once, termed Competitiveness Approximation on Lipschitz Functions (CAoLF). This approach is particularly useful when computational resources are limited or re-computation is not feasible. Through computational experiments on the minimum-cost concurrent flow problem, we demonstrate the efficiency and scalability of the proposed method, underscoring its potential for addressing computational challenges in MOO across various applications.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.03023v1</guid>
      <category>math.OC</category>
      <pubDate>Mon, 07 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Ilgam Latypov, Yuriy Dorn</dc:creator>
    </item>
    <item>
      <title>Enhancing sharp augmented Lagrangian methods with smoothing techniques for nonlinear programming</title>
      <link>https://arxiv.org/abs/2410.03050</link>
      <description>arXiv:2410.03050v1 Announce Type: new 
Abstract: This paper proposes a novel approach to solving nonlinear programming problems using a sharp augmented Lagrangian method with a smoothing technique. Traditional sharp augmented Lagrangian methods are known for their effectiveness but are often hindered by the need for global minimization of nonconvex, nondifferentiable functions at each iteration. To address this challenge, we introduce a smoothing function that approximates the sharp augmented Lagrangian, enabling the use of primal minimization strategies similar to those in Powell--Hestenes--Rockafellar (PHR) methods. Our approach retains the theoretical rigor of classical duality schemes while allowing for the use of stationary points in the primal optimization process. We present two algorithms based on this method--one utilizing standard descent and the other employing coordinate descent. Numerical experiments demonstrate that our smoothing--based method compares favorably with the PHR augmented Lagrangian approach, offering both robustness and practical efficiency. The proposed method is particularly advantageous in scenarios where exact minimization is computationally infeasible, providing a balance between theoretical precision and computational tractability.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.03050v1</guid>
      <category>math.OC</category>
      <pubDate>Mon, 07 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Jos\'e Luis Romero, Dami\'an Fernandez, Germ\'an Ariel Torres</dc:creator>
    </item>
    <item>
      <title>A Policy Iteration Algorithm for N-player General-Sum Linear Quadratic Dynamic Games</title>
      <link>https://arxiv.org/abs/2410.03106</link>
      <description>arXiv:2410.03106v1 Announce Type: new 
Abstract: We present a policy iteration algorithm for the infinite-horizon N-player general-sum deterministic linear quadratic dynamic games and compare it to policy gradient methods. We demonstrate that the proposed policy iteration algorithm is distinct from the Gauss-Newton policy gradient method in the N-player game setting, in contrast to the single-player setting where under suitable choice of step size they are equivalent. We illustrate in numerical experiments that the convergence rate of the proposed policy iteration algorithm significantly surpasses that of the Gauss-Newton policy gradient method and other policy gradient variations. Furthermore, our numerical results indicate that, compared to policy gradient methods, the convergence performance of the proposed policy iteration algorithm is less sensitive to the initial policy and changes in the number of players.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.03106v1</guid>
      <category>math.OC</category>
      <category>cs.SY</category>
      <category>eess.SY</category>
      <pubDate>Mon, 07 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Yuxiang Guan, Giulio Salizzoni, Maryam Kamgarpour, Tyler H. Summers</dc:creator>
    </item>
    <item>
      <title>Learning to Select Cutting Planes in Mixed Integer Linear Programming Solving</title>
      <link>https://arxiv.org/abs/2410.03112</link>
      <description>arXiv:2410.03112v1 Announce Type: new 
Abstract: Cutting planes (cuts) are crucial for solving Mixed Integer Linear Programming (MILP) problems. Advanced MILP solvers typically rely on manually designed heuristic algorithms for cut selection, which require much expert experience and cannot be generalized for different scales of MILP problems. Therefore, learning-based methods for cut selection are considered a promising direction. State-of-the-art learning-based methods formulate cut selection as a sequence-to-sequence problem, easily handled by sequence models. However, the existing sequence models need help with the following issues: (1) the model only captures cut information while neglecting the Linear Programming (LP) relaxation; (2) the sequence model utilizes positional information of the input sequence, which may influence cut selection. To address these challenges, we design a novel learning model HGTSM for better select cuts. We encode MILP problem state as a heterogeneous tripartite graph, utilizing heterogeneous graph networks to fully capture the underlying structure of MILP problems. Simultaneously, we propose a novel sequence model whose architecture is tailored to handle inputs in different orders. Experimental results demonstrate that our model outperforms heuristic methods and learning-based baselines on multiple challenging MILP datasets. Additionally, the model exhibits stability and the ability to generalize to different types of problems.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.03112v1</guid>
      <category>math.OC</category>
      <pubDate>Mon, 07 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Xuefeng Zhang, Liangyu Chen, Zhenbing Zeng</dc:creator>
    </item>
    <item>
      <title>Prevailing against Adversarial Noncentral Disturbances: Exact Recovery of Linear Systems with the $l_1$-norm Estimator</title>
      <link>https://arxiv.org/abs/2410.03218</link>
      <description>arXiv:2410.03218v1 Announce Type: new 
Abstract: This paper studies the linear system identification problem in the general case where the disturbance is sub-Gaussian, correlated, and possibly adversarial. First, we consider the case with noncentral (nonzero-mean) disturbances for which the ordinary least-squares (OLS) method fails to correctly identify the system. We prove that the $l_1$-norm estimator accurately identifies the system under the condition that each disturbance has equal probabilities of being positive or negative. This condition restricts the sign of each disturbance but allows its magnitude to be arbitrary. Second, we consider the case where each disturbance is adversarial with the model that the attack times happen occasionally but the distributions of the attack values are completely arbitrary. We show that when the probability of having an attack at a given time is less than 0.5, the $l_1$-norm estimator prevails against any adversarial noncentral disturbances and the exact recovery is achieved within a finite time. These results pave the way to effectively defend against arbitrarily large noncentral attacks in safety-critical systems.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.03218v1</guid>
      <category>math.OC</category>
      <pubDate>Mon, 07 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Jihun Kim, Javad Lavaei</dc:creator>
    </item>
    <item>
      <title>Generalized Ordered Weighted Aggregation Robustness to Solve Uncertain Single Objective Optimization Problems</title>
      <link>https://arxiv.org/abs/2410.03222</link>
      <description>arXiv:2410.03222v1 Announce Type: new 
Abstract: Robust optimization aims to find optimum points from the collection of points that are feasible for every possible scenario of a given uncertain set. An optimum solution to a robust optimization problem is commonly found by the min-max robust counterpart or by the best out of the worst-cases analysis. In this article, we introduce a new counterpart with the help of the generalized ordered weighted aggregation (GOWA) operator to solve uncertain single objective optimization problems. After introducing GOWA robustness, we analyze a few elementary properties of the GOWA robust objective function, like continuity, monotonicity, coerciveness, local Lipschitz property, and subdifferential regularity. An approach to computing the Clarke subdifferential of the GOWA robust objective function is also provided. We discuss the relationship between the concept of GOWA robustness with other existing robustness -- flimsily, highly, min-max, light, and min-min robustness. We show that in a particular case, GOWA robustness reduces to the commonly used min-max robustness. The entire paper is supported by several geometrical and numerical illustrations.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.03222v1</guid>
      <category>math.OC</category>
      <pubDate>Mon, 07 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Nand Kishor, Debdas Ghosh, Xiaopeng Zhao</dc:creator>
    </item>
    <item>
      <title>Sparsity of Quadratically Regularized Optimal Transport: Scalar Case</title>
      <link>https://arxiv.org/abs/2410.03353</link>
      <description>arXiv:2410.03353v1 Announce Type: new 
Abstract: The quadratically regularized optimal transport problem is empirically known to have sparse solutions: its optimal coupling $\pi_{\varepsilon}$ has sparse support for small regularization parameter $\varepsilon$, in contrast to entropic regularization whose solutions have full support for any $\varepsilon&gt;0$. Focusing on continuous and scalar marginals, we provide the first precise description of this sparsity. Namely, we show that the support of $\pi_{\varepsilon}$ shrinks to the Monge graph at the sharp rate $\varepsilon^{1/3}$. This result is based on a detailed analysis of the dual potential $f_{\varepsilon}$ for small $\varepsilon$. In particular, we prove that $f_{\varepsilon}$ is twice differentiable a.s. and bound the second derivative uniformly in $\varepsilon$, showing that $f_{\varepsilon}$ is uniformly strongly convex. Convergence rates for $f_{\varepsilon}$ and its derivative are also obtained.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.03353v1</guid>
      <category>math.OC</category>
      <pubDate>Mon, 07 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Alberto Gonz\'alez-Sanz, Marcel Nutz</dc:creator>
    </item>
    <item>
      <title>Sparsity of Quadratically Regularized Optimal Transport: Bounds on concentration and bias</title>
      <link>https://arxiv.org/abs/2410.03425</link>
      <description>arXiv:2410.03425v1 Announce Type: new 
Abstract: We study the quadratically regularized optimal transport (QOT) problem for quadratic cost and compactly supported marginals $\mu$ and $\nu$. It has been empirically observed that the optimal coupling $\pi_\epsilon$ for the QOT problem has sparse support for small regularization parameter $\epsilon&gt;0.$ In this article we provide the first quantitative description of this phenomenon in general dimension: we derive bounds on the size and on the location of the support of $\pi_\epsilon$ compared to the Monge coupling. Our analysis is based on pointwise bounds on the density of $\pi_\epsilon$ together with Minty's trick, which provides a quadratic detachment from the optimal transport duality gap. In the self-transport setting $\mu=\nu$ we obtain optimal rates of order $\epsilon^{\frac{1}{2+d}}.$</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.03425v1</guid>
      <category>math.OC</category>
      <category>math.PR</category>
      <pubDate>Mon, 07 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Johannes Wiesel, Xingyu Xu</dc:creator>
    </item>
    <item>
      <title>Characterizations, Dynamical Systems and Gradient Methods for Strongly Quasiconvex Functions</title>
      <link>https://arxiv.org/abs/2410.03534</link>
      <description>arXiv:2410.03534v1 Announce Type: new 
Abstract: We study differentiable strongly quasiconvex functions for providing new properties for algorithmic and monotonicity purposes. Furthemore, we provide insights into the decreasing behaviour of strongly quasiconvex functions, applying this for establishing exponential convergence for first- and second-order gradient systems without relying on the usual Lipschitz continuity assumption on the gradient of the function. The explicit discretization of the first-order dynamical system leads to the gradient descent method while discretization of the second-order dynamical system with viscous damping recovers the heavy ball method. We establish the linear convergence of both methods under suitable conditions on the parameters as well as comparisons with other classes of nonconvex functions used in the gradient descent literature.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.03534v1</guid>
      <category>math.OC</category>
      <pubDate>Mon, 07 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/publicdomain/zero/1.0/</dc:rights>
      <dc:creator>Felipe Lara, Ra\'ul T. Marcavillaca, Phan T. Vuong</dc:creator>
    </item>
    <item>
      <title>A universal example for quantitative semi-uniform stability</title>
      <link>https://arxiv.org/abs/2410.02357</link>
      <description>arXiv:2410.02357v1 Announce Type: cross 
Abstract: We characterise quantitative semi-uniform stability for $C_0$-semigroups arising from port-Hamiltonian systems, complementing recent works on exponential and strong stability. With the result, we present a simple universal example class of port-Hamiltonian $C_0$-semigroups exhibiting arbitrary decay rates slower than $t^{-1/2}$. The latter is based on results from the theory of Diophantine approximation as the decay rates will be strongly related to approximation properties of irrational numbers by rationals given through cut-offs of continued fraction expansions.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.02357v1</guid>
      <category>math.AP</category>
      <category>math.FA</category>
      <category>math.NT</category>
      <category>math.OC</category>
      <pubDate>Mon, 07 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Sahiba Arora, Felix Schwenninger, Ingrid Vukusic, Marcus Waurick</dc:creator>
    </item>
    <item>
      <title>Forecasting and decisions in the birth-death-suppression Markov model for wildfires</title>
      <link>https://arxiv.org/abs/2410.02765</link>
      <description>arXiv:2410.02765v1 Announce Type: cross 
Abstract: As changing climates transform the landscape of wildfire management and suppression, agencies are faced with difficult resource allocation decisions. We analyze trade-offs in temporal resource allocation using a simple but robust Markov model of a wildfire under suppression: the birth-death-suppression process. Though the model is not spatial, its stochastic nature and rich temporal structure make it broadly applicable in describing the dynamic evolution of a fire including ignition, the effect of adverse conditions, and the effect of external suppression. With strong analytical and numerical control of the probabilities of outcomes, we construct classes of processes which analogize common wildfire suppression scenarios and determine aspects of optimal suppression allocations. We model problems which include resource management in changing conditions, the effect of resource mobilization delay, and allocation under uncertainty about future events. Our results are consistent with modern resource management and suppression practices in wildland fire.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.02765v1</guid>
      <category>physics.soc-ph</category>
      <category>math.OC</category>
      <category>stat.AP</category>
      <pubDate>Mon, 07 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>George Hulsey, David L. Alderson, Jean Carlson</dc:creator>
    </item>
    <item>
      <title>Estimating the Unobservable Components of Electricity Demand Response with Inverse Optimization</title>
      <link>https://arxiv.org/abs/2410.02774</link>
      <description>arXiv:2410.02774v1 Announce Type: cross 
Abstract: Understanding and predicting the electricity demand responses to prices are critical activities for system operators, retailers, and regulators. While conventional machine learning and time series analyses have been adequate for the routine demand patterns that have adapted only slowly over many years, the emergence of active consumers with flexible assets such as solar-plus-storage systems, and electric vehicles, introduces new challenges. These active consumers exhibit more complex consumption patterns, the drivers of which are often unobservable to the retailers and system operators. In practice, system operators and retailers can only monitor the net demand (metered at grid connection points), which reflects the overall energy consumption or production exchanged with the grid. As a result, all "behind-the-meter" activities-such as the use of flexibility-remain hidden from these entities. Such behind-the-meter behavior may be controlled by third party agents or incentivized by tariffs; in either case, the retailer's revenue and the system loads would be impacted by these activities behind the meter, but their details can only be inferred. We define the main components of net demand, as baseload, flexible, and self-generation, each having nonlinear responses to market price signals. As flexible demand response and self generation are increasing, this raises a pressing question of whether existing methods still perform well and, if not, whether there is an alternative way to understand and project the unobserved components of behavior. In response to this practical challenge, we evaluate the potential of a data-driven inverse optimization (IO) methodology. This approach characterizes decomposed consumption patterns without requiring direct observation of behind-the-meter behavior or device-level metering [...]</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.02774v1</guid>
      <category>eess.SP</category>
      <category>cs.CE</category>
      <category>cs.LG</category>
      <category>math.OC</category>
      <category>stat.AP</category>
      <category>stat.ME</category>
      <pubDate>Mon, 07 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Adrian Esteban-Perez, Derek Bunn, Yashar Ghiassi-Farrokhfal</dc:creator>
    </item>
    <item>
      <title>Learning Optimal Control and Dynamical Structure of Global Trajectory Search Problems with Diffusion Models</title>
      <link>https://arxiv.org/abs/2410.02976</link>
      <description>arXiv:2410.02976v1 Announce Type: cross 
Abstract: Spacecraft trajectory design is a global search problem, where previous work has revealed specific solution structures that can be captured with data-driven methods. This paper explores two global search problems in the circular restricted three-body problem: hybrid cost function of minimum fuel/time-of-flight and transfers to energy-dependent invariant manifolds. These problems display a fundamental structure either in the optimal control profile or the use of dynamical structures. We build on our prior generative machine learning framework to apply diffusion models to learn the conditional probability distribution of the search problem and analyze the model's capability to capture these structures.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.02976v1</guid>
      <category>cs.LG</category>
      <category>cs.SY</category>
      <category>eess.SY</category>
      <category>math.OC</category>
      <pubDate>Mon, 07 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Jannik Graebner, Anjian Li, Amlan Sinha, Ryne Beeson</dc:creator>
    </item>
    <item>
      <title>Individual vaccination as Nash equilibrium in a SIR model with application to the 2009-10 Influenza A(H1N1) epidemic in France</title>
      <link>https://arxiv.org/abs/2410.03567</link>
      <description>arXiv:2410.03567v1 Announce Type: cross 
Abstract: The vaccination against ongoing epidemics is seldom compulsory but remains one of the most classical means to fight epidemic propagation. However recent debates concerning the innocuity of vaccines and their risk with respect to the risk of the epidemic itself lead to severe vaccination campaign failures and new mass behaviors appeared driven by individual self-interest. Prompted by this context we analyze, in a Susceptible-Infected-Recovered (SIR) model, whether egocentric individuals can reach an equilibrium with the rest of the society. Using techniques from the "Mean Field Games" theory, we extend previous results and show that an equilibrium exists and characterizes completely the individual best vaccination strategy (with or without discounting). We also compare with a strategy based only on overall societal optimization and exhibit a situation with non-negative price of anarchy. Finally, we apply the theory to the 2009-2010 Influenza A (H1N1) vaccination campaign in France and hint that a group of individuals stopped vaccinating at levels that indicated a pessimistic perception of the risk of the vaccine.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.03567v1</guid>
      <category>q-bio.PE</category>
      <category>math.OC</category>
      <pubDate>Mon, 07 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <arxiv:DOI>10.1007/s11538-015-0111-7</arxiv:DOI>
      <arxiv:journal_reference>Bull Math Biol 77, 1955-1984 (2015)</arxiv:journal_reference>
      <dc:creator>Laetitia Laguzet, Gabriel Turinici</dc:creator>
    </item>
    <item>
      <title>Accelerated Gradient Tracking over Time-varying Graphs for Decentralized Optimization</title>
      <link>https://arxiv.org/abs/2104.02596</link>
      <description>arXiv:2104.02596v4 Announce Type: replace 
Abstract: Decentralized optimization over time-varying graphs has been increasingly common in modern machine learning with massive data stored on millions of mobile devices, such as in federated learning. This paper revisits the widely used accelerated gradient tracking and extends it to time-varying graphs. We prove that the practical single loop accelerated gradient tracking needs $O((\frac{\gamma}{1-\sigma_{\gamma}})^2\sqrt{\frac{L}{\epsilon}})$ and $O((\frac{\gamma}{1-\sigma_{\gamma}})^{1.5}\sqrt{\frac{L}{\mu}}\log\frac{1}{\epsilon})$ iterations to reach an $\epsilon$-optimal solution over time-varying graphs when the problems are nonstrongly convex and strongly convex, respectively, where $\gamma$ and $\sigma_{\gamma}$ are two common constants charactering the network connectivity, $L$ and $\mu$ are the smoothness and strong convexity constants, respectively, and one iteration corresponds to one gradient oracle call and one communication round. Our convergence rates improve significantly over the ones of $O(\frac{1}{\epsilon^{5/7}})$ and $O((\frac{L}{\mu})^{5/7}\frac{1}{(1-\sigma)^{1.5}}\log\frac{1}{\epsilon})$, respectively, which were proved in the original literature of accelerated gradient tracking only for static graphs, where $\frac{\gamma}{1-\sigma_{\gamma}}$ equals $\frac{1}{1-\sigma}$ when the network is time-invariant. When combining with a multiple consensus subroutine, the dependence on the network connectivity constants can be further improved to $O(1)$ and $O(\frac{\gamma}{1-\sigma_{\gamma}})$ for the gradient oracle and communication round complexities, respectively. When the network is static, by employing the Chebyshev acceleration, our complexities exactly match the lower bounds without hiding any poly-logarithmic factor for both nonstrongly convex and strongly convex problems.</description>
      <guid isPermaLink="false">oai:arXiv.org:2104.02596v4</guid>
      <category>math.OC</category>
      <category>cs.LG</category>
      <pubDate>Mon, 07 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <arxiv:journal_reference>Journal of Machine Learning Research (JMLR) 2024</arxiv:journal_reference>
      <dc:creator>Huan Li, Zhouchen Lin</dc:creator>
    </item>
    <item>
      <title>Global and Preference-based Optimization with Mixed Variables using Piecewise Affine Surrogates</title>
      <link>https://arxiv.org/abs/2302.04686</link>
      <description>arXiv:2302.04686v3 Announce Type: replace 
Abstract: Optimization problems involving mixed variables, i.e., variables of numerical and categorical nature, can be challenging to solve, especially in the presence of mixed-variable constraints. Moreover, when the objective function is the result of a complicated simulation or experiment, it may be expensive-to-evaluate. This paper proposes a novel surrogate-based global optimization algorithm to solve linearly constrained mixed-variable problems up to medium size (around 100 variables after encoding) based on constructing a piecewise affine surrogate of the objective function over feasible samples. We assume the objective function is black-box and expensive-to-evaluate, while the linear constraints are quantifiable unrelaxable a priori known and are cheap to evaluate. We introduce two types of exploration functions to efficiently search the feasible domain via mixed-integer linear programming solvers. We also provide a preference-based version of the algorithm, which can be used when only pairwise comparisons between samples can be acquired while the underlying objective function to minimize remains unquantified. The two algorithms are tested on mixed-variable benchmark problems with and without constraints. The results show that, within a small number of acquisitions, the proposed algorithms can often achieve better or comparable results than other existing methods.</description>
      <guid isPermaLink="false">oai:arXiv.org:2302.04686v3</guid>
      <category>math.OC</category>
      <category>cs.LG</category>
      <pubDate>Mon, 07 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Mengjia Zhu, Alberto Bemporad</dc:creator>
    </item>
    <item>
      <title>A Sequential Quadratic Programming Method for Optimization with Stochastic Objective Functions, Deterministic Inequality Constraints and Robust Subproblems</title>
      <link>https://arxiv.org/abs/2302.07947</link>
      <description>arXiv:2302.07947v2 Announce Type: replace 
Abstract: In this paper, a robust sequential quadratic programming method for constrained optimization is generalized to problem with an {expectation} objective function {and} deterministic equality and inequality constraints. A stochastic line search scheme is employed to globalize the steps. {We show theoretically that sequences generated by the algorithm converge almost surely to a Karush-Kuhn-Tucker point under the assumption of the extended Mangasarian-Fromovitz constraint qualification}. Encouraging numerical results are reported.</description>
      <guid isPermaLink="false">oai:arXiv.org:2302.07947v2</guid>
      <category>math.OC</category>
      <pubDate>Mon, 07 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Songqiang Qiu, Vyacheslav Kungurtsev</dc:creator>
    </item>
    <item>
      <title>Bregman Proximal Method for Efficient Communications under Similarity</title>
      <link>https://arxiv.org/abs/2311.06953</link>
      <description>arXiv:2311.06953v3 Announce Type: replace 
Abstract: We propose a novel stochastic distributed method for both monotone and strongly monotone variational inequalities with Lipschitz operator and proper convex regularizers arising in various applications from game theory to adversarial training. By exploiting similarity, our algorithm overcomes the communication bottleneck that is a major issue in distributed optimization. The proposed method enjoys optimal communication complexity. All the existing distributed algorithms achieving the lower bounds under similarity condition essentially utilize the Euclidean setup. In contrast to them, our method is built upon the Bregman proximal maps and it is compatible with an arbitrary problem geometry. Thereby the proposed method fills an existing gap in this area of research. Our theoretical results are confirmed by numerical experiments on a stochastic matrix game.</description>
      <guid isPermaLink="false">oai:arXiv.org:2311.06953v3</guid>
      <category>math.OC</category>
      <pubDate>Mon, 07 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Aleksandr Beznosikov, Darina Dvinskikh, Dmitry Bylinkin, Andrei Semenov, Alexander Gasnikov</dc:creator>
    </item>
    <item>
      <title>A Vertex-Skipping property for almost-minimizers of the relative perimeter in convex sets</title>
      <link>https://arxiv.org/abs/2401.14725</link>
      <description>arXiv:2401.14725v2 Announce Type: replace 
Abstract: Given a convex domain $\Omega\subset \mathbb{R}^{3}$ and an almost-minimizer $E$ of the relative perimeter in $\Omega$, we prove that the closure of $\partial E \cap \Omega$ does not contain vertices of $\Omega$.</description>
      <guid isPermaLink="false">oai:arXiv.org:2401.14725v2</guid>
      <category>math.OC</category>
      <pubDate>Mon, 07 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Gian Paolo Leonardi, Giacomo Vianello</dc:creator>
    </item>
    <item>
      <title>Data-Enabled Policy Optimization for Direct Adaptive Learning of the LQR</title>
      <link>https://arxiv.org/abs/2401.14871</link>
      <description>arXiv:2401.14871v4 Announce Type: replace 
Abstract: Direct data-driven design methods for the linear quadratic regulator (LQR) mainly use offline or episodic data batches, and their online adaptation has been acknowledged as an open problem. In this paper, we propose a direct adaptive method to learn the LQR from online closed-loop data. First, we propose a new policy parameterization based on the sample covariance to formulate a direct data-driven LQR problem, which is shown to be equivalent to the certainty-equivalence LQR with optimal non-asymptotic guarantees. Second, we design a novel data-enabled policy optimization (DeePO) method to directly update the policy, where the gradient is explicitly computed using only a batch of persistently exciting (PE) data. Third, we establish its global convergence via a projected gradient dominance property. Importantly, we efficiently use DeePO to adaptively learn the LQR by performing only one-step projected gradient descent per sample of the closed-loop system, which also leads to an explicit recursive update of the policy. Under PE inputs and for bounded noise, we show that the average regret of the LQR cost is upper-bounded by two terms signifying a sublinear decrease in time $\mathcal{O}(1/\sqrt{T})$ plus a bias scaling inversely with signal-to-noise ratio (SNR), which are independent of the noise statistics. Finally, we perform simulations to validate the theoretical results and demonstrate the computational and sample efficiency of our method.</description>
      <guid isPermaLink="false">oai:arXiv.org:2401.14871v4</guid>
      <category>math.OC</category>
      <category>cs.SY</category>
      <category>eess.SY</category>
      <pubDate>Mon, 07 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Feiran Zhao, Florian D\"orfler, Alessandro Chiuso, Keyou You</dc:creator>
    </item>
    <item>
      <title>DualBi: A dual bisection algorithm for non-convex problems with a scalar complicating constraint</title>
      <link>https://arxiv.org/abs/2402.03013</link>
      <description>arXiv:2402.03013v2 Announce Type: replace 
Abstract: This paper addresses non-convex constrained optimization problems that are characterized by a scalar complicating constraint. We propose an iterative bisection method for the dual problem (DualBi Algorithm) that recovers a feasible primal solution, with a performance that is progressively improving throughout iterations. Application to multi-agent problems with a scalar coupling constraint results in a decentralized resolution scheme where a central unit is in charge of the update of the (scalar) dual variable while agents compute their local primal variables. In the case of multi-agent MILPs, simulations showcase the performance of the proposed method compared with state-of-the-art duality-based approaches.</description>
      <guid isPermaLink="false">oai:arXiv.org:2402.03013v2</guid>
      <category>math.OC</category>
      <pubDate>Mon, 07 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Lucrezia Manieri, Alessandro Falsone, Maria Prandini</dc:creator>
    </item>
    <item>
      <title>Distributed Optimization of Linear Multi-Agent Systems via Feedback-DGD</title>
      <link>https://arxiv.org/abs/2403.18386</link>
      <description>arXiv:2403.18386v2 Announce Type: replace 
Abstract: Feedback optimization is an increasingly popular control paradigm to optimize dynamical systems, accounting for control objectives that concern the system's operation at the steady-state. Existing feedback optimization techniques heavily rely on centralized system and controller architectures, and thus suffer from scalability and privacy issues when systems become large-scale. In this paper, we propose a distributed architecture for feedback optimization inspired by distributed gradient descent, whereby each agent updates its local control variable by combining the average of its neighbors with a local negative gradient step. Under convexity and smoothness assumptions for the cost, we establish convergence of the control method to a critical optimization point. By reinforcing the assumptions to restricted strong convexity, we show that our algorithm converges linearly to a neighborhood of the optimal point, where the size of the neighborhood depends on the choice of the stepsize. Simulations corroborate the theoretical results.</description>
      <guid isPermaLink="false">oai:arXiv.org:2403.18386v2</guid>
      <category>math.OC</category>
      <pubDate>Mon, 07 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-sa/4.0/</dc:rights>
      <dc:creator>Amir Mehrnoosh, Gianluca Bianchin</dc:creator>
    </item>
    <item>
      <title>Understanding the Impact of Coalitions between EV Charging Stations</title>
      <link>https://arxiv.org/abs/2404.03919</link>
      <description>arXiv:2404.03919v2 Announce Type: replace 
Abstract: The rapid growth of electric vehicles (EVs) is driving the expansion of charging infrastructure globally. As charging stations become ubiquitous, their substantial electricity consumption can influence grid operation and electricity pricing. Naturally, \textit{some} groups of charging stations, which could be jointly operated by a company, may coordinate to decide their charging profile. While coordination among all charging stations is ideal, it is unclear if coordination of some charging stations is better than no coordination. In this paper, we analyze this intermediate regime between no and full coordination of charging stations. We model EV charging as a non-cooperative aggregative game, where each station's cost is determined by both monetary payments tied to reactive electricity prices on the grid and its sensitivity to deviations from a desired charging profile. We consider a solution concept that we call $\mathcal{C}$-Nash equilibrium, which is tied to a coalition $\mathcal{C}$ of charging stations coordinating to reduce their costs. We provide sufficient conditions, in terms of the demand and sensitivity of charging stations, to determine when independent (aka uncoordinated) operation of charging stations could result in lower overall costs to charging stations, coalition and charging stations outside the coalition. Somewhat counter to common intuition, we show numerical instances where allowing charging stations to operate independently is better than coordinating a subset of stations as a coalition. Jointly, these results provide operators of charging stations insights into how to coordinate their charging behavior, and open several research directions.</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.03919v2</guid>
      <category>math.OC</category>
      <category>cs.GT</category>
      <category>cs.MA</category>
      <category>cs.SY</category>
      <category>eess.SY</category>
      <pubDate>Mon, 07 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Sukanya Kudva, Kshitij Kulkarni, Chinmay Maheshwari, Anil Aswani, Shankar Sastry</dc:creator>
    </item>
    <item>
      <title>Approximations of Rockafellians, Lagrangians, and Dual Functions</title>
      <link>https://arxiv.org/abs/2404.18097</link>
      <description>arXiv:2404.18097v2 Announce Type: replace 
Abstract: Solutions of an optimization problem are sensitive to changes caused by approximations or parametric perturbations, especially in the nonconvex setting. This paper investigates the ability of substitute problems, constructed from Rockafellian functions, to provide robustness against such approximations. Unlike classical stability analysis focused on local changes around (local) minimizers, we employ epi-convergence to examine whether the approximating problems suitably approach the actual one globally. We show that under natural assumptions the substitute problems can be well-behaved in the sense of epi-convergence even though the actual one is not. We further quantify the rates of convergence that often lead to Lipschitz-kind stability properties for the substitute problems.</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.18097v2</guid>
      <category>math.OC</category>
      <pubDate>Mon, 07 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Julio Deride, Johannes O. Royset</dc:creator>
    </item>
    <item>
      <title>Subsampled Ensemble Can Improve Generalization Tail Exponentially</title>
      <link>https://arxiv.org/abs/2405.14741</link>
      <description>arXiv:2405.14741v3 Announce Type: replace 
Abstract: Ensemble learning is a popular technique to improve the accuracy of machine learning models. It hinges on the rationale that aggregating multiple weak models can lead to better models with lower variance and hence higher stability, especially for discontinuous base learners. In this paper, we provide a new perspective on ensembling. By selecting the best model trained on subsamples via majority voting, we can attain exponentially decaying tails for the excess risk, even if the base learner suffers from slow (i.e., polynomial) decay rates. This tail enhancement power of ensembling is agnostic to the underlying base learner and is stronger than variance reduction in the sense of exhibiting rate improvement. We demonstrate how our ensemble methods can substantially improve out-of-sample performances in a range of examples involving heavy-tailed data or intrinsically slow rates. Code for the proposed methods is available at https://github.com/mickeyhqian/VoteEnsemble.</description>
      <guid isPermaLink="false">oai:arXiv.org:2405.14741v3</guid>
      <category>math.OC</category>
      <category>cs.LG</category>
      <category>stat.ML</category>
      <pubDate>Mon, 07 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/publicdomain/zero/1.0/</dc:rights>
      <dc:creator>Huajie Qian, Donghao Ying, Henry Lam, Wotao Yin</dc:creator>
    </item>
    <item>
      <title>Universal methods for variational inequalities: deterministic and stochastic cases</title>
      <link>https://arxiv.org/abs/2407.17519</link>
      <description>arXiv:2407.17519v2 Announce Type: replace 
Abstract: In this paper, we propose universal proximal mirror methods to solve the variational inequality problem with Holder continuous operators in both deterministic and stochastic settings. The proposed methods automatically adapt not only to the oracle's noise (in the stochastic setting of the problem) but also to the Holder continuity of the operator without having prior knowledge of either the problem class or the nature of the operator information. We analyzed the proposed algorithms in both deterministic and stochastic settings and obtained estimates for the required number of iterations to achieve a given quality of a solution to the variational inequality. We showed that, without knowing the Holder exponent and Holder constant of the operators, the proposed algorithms have the least possible in the worst case sense complexity for the considered class of variational inequalities. We also compared the resulting stochastic algorithm with other popular optimizers for the task of image classification.</description>
      <guid isPermaLink="false">oai:arXiv.org:2407.17519v2</guid>
      <category>math.OC</category>
      <pubDate>Mon, 07 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Anton Klimza, Alexander Gasnikov, Fedor Stonyakin, Mohammad Alkousa</dc:creator>
    </item>
    <item>
      <title>Discrete approximations and optimality conditions for integro-differential inclusions</title>
      <link>https://arxiv.org/abs/2408.02856</link>
      <description>arXiv:2408.02856v2 Announce Type: replace 
Abstract: This paper addresses a new class of generalized Bolza problems governed by nonconvex integro-differential inclusions with endpoint constraints on trajectories, where the integral terms are given in the general (with time-dependent integrands in the dynamics) Volterra form. We pursue here a threefold goal. First we construct well-posed approximations of continuous-time integro-differential systems by their discrete-time counterparts with showing that any feasible solution to the original system can be strongly approximated in the $W^{1,2}$-norm topology by piecewise-linear extensions of feasible discrete trajectories. This allows us to verify in turn the strong convergence of discrete optimal solutions to a prescribed local minimizer for the original problem. Facing intrinsic nonsmoothness of original integro-differential problem and its discrete approximations, we employ appropriate tools of generalized differentiation in variational analysis to derive necessary optimality conditions for discrete-time problems (which is our second goal) and finally accomplish our third goal to obtain necessary conditions for the original continuous-time problems by passing to the limit from discrete approximations. In this way we establish, in particular, a novel necessary optimality condition of the Volterra type, which is the crucial result for dynamic optimization of integro-differential inclusions.</description>
      <guid isPermaLink="false">oai:arXiv.org:2408.02856v2</guid>
      <category>math.OC</category>
      <pubDate>Mon, 07 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Abderrahim Bouach, Tahar Haddad, Boris S. Mordukhovich</dc:creator>
    </item>
    <item>
      <title>Singularity-free Backstepping-based Adaptive Control of a Bicopter with Unknown Mass and Inertia</title>
      <link>https://arxiv.org/abs/2409.13081</link>
      <description>arXiv:2409.13081v2 Announce Type: replace 
Abstract: The paper develops a singularity-free backstepping-based adaptive control for stabilizing and tracking the trajectory of a bicopter system. In the bicopter system, the inertial parameters parameterize the input map. Since the classical adaptive backstepping technique requires the inversion of the input map, which contains the estimate of parameter estimates, the stability of the closed-loop system cannot be guaranteed due to the inversion of parameter estimates. This paper proposes a novel technique to circumvent the inversion of parameter estimates in the control law. The resulting controller requires only the sign of the unknown parameters. The proposed controller is validated in simulation for a smooth and nonsmooth trajectory-tracking problem.</description>
      <guid isPermaLink="false">oai:arXiv.org:2409.13081v2</guid>
      <category>math.OC</category>
      <pubDate>Mon, 07 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <dc:creator>Jhon Manuel Portella Delgado, Ankit Goel</dc:creator>
    </item>
    <item>
      <title>A geometric approach to apriori estimates for optimal transport maps</title>
      <link>https://arxiv.org/abs/2311.10208</link>
      <description>arXiv:2311.10208v2 Announce Type: replace-cross 
Abstract: A key inequality which underpins the regularity theory of optimal transport for costs satisfying the Ma--Trudinger--Wang condition is the Pogorelov second derivative bound. This translates to an apriori interior $C^1$ estimate for smooth optimal maps. Here we give a new derivation of this estimate which relies in part on Kim, McCann and Warren's observation that the graph of an optimal map becomes a volume maximizing spacelike submanifold when the product of the source and target domains is endowed with a suitable pseudo-Riemannian geometry that combines both the marginal densities and the cost.</description>
      <guid isPermaLink="false">oai:arXiv.org:2311.10208v2</guid>
      <category>math.DG</category>
      <category>math.AP</category>
      <category>math.OC</category>
      <pubDate>Mon, 07 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Simon Brendle, Flavien L\'eger, Robert J. McCann, Cale Rankin</dc:creator>
    </item>
    <item>
      <title>MetaOptimize: A Framework for Optimizing Step Sizes and Other Meta-parameters</title>
      <link>https://arxiv.org/abs/2402.02342</link>
      <description>arXiv:2402.02342v5 Announce Type: replace-cross 
Abstract: This paper addresses the challenge of optimizing meta-parameters (i.e., hyperparameters) in machine learning algorithms, a critical factor influencing training efficiency and model performance. Moving away from the computationally expensive traditional meta-parameter search methods, we introduce MetaOptimize framework that dynamically adjusts meta-parameters, particularly step sizes (also known as learning rates), during training. More specifically, MetaOptimize can wrap around any first-order optimization algorithm, tuning step sizes on the fly to minimize a specific form of regret that accounts for long-term effect of step sizes on training, through a discounted sum of future losses. We also introduce low complexity variants of MetaOptimize that, in conjunction with its adaptability to multiple optimization algorithms, demonstrate performance competitive to those of best hand-crafted learning rate schedules across various machine learning applications.</description>
      <guid isPermaLink="false">oai:arXiv.org:2402.02342v5</guid>
      <category>cs.LG</category>
      <category>cs.AI</category>
      <category>math.OC</category>
      <pubDate>Mon, 07 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Arsalan Sharifnassab, Saber Salehkaleybar, Richard Sutton</dc:creator>
    </item>
    <item>
      <title>Jacobian Descent for Multi-Objective Optimization</title>
      <link>https://arxiv.org/abs/2406.16232</link>
      <description>arXiv:2406.16232v2 Announce Type: replace-cross 
Abstract: Many optimization problems require balancing multiple conflicting objectives. As gradient descent is limited to single-objective optimization, we introduce its direct generalization: Jacobian descent (JD). This algorithm iteratively updates parameters using the Jacobian matrix of a vector-valued objective function, in which each row is the gradient of an individual objective. While several methods to combine gradients already exist in the literature, they are generally hindered when the objectives conflict. In contrast, we propose projecting gradients to fully resolve conflict while ensuring that they preserve an influence proportional to their norm. We prove significantly stronger convergence guarantees with this approach, supported by our empirical results. Our method also enables instance-wise risk minimization (IWRM), a novel learning paradigm in which the loss of each training example is considered a separate objective. Applied to simple image classification tasks, IWRM exhibits promising results compared to the direct minimization of the average loss. Additionally, we outline an efficient implementation of JD using the Gramian of the Jacobian matrix to reduce time and memory requirements.</description>
      <guid isPermaLink="false">oai:arXiv.org:2406.16232v2</guid>
      <category>cs.LG</category>
      <category>cs.AI</category>
      <category>math.OC</category>
      <pubDate>Mon, 07 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Pierre Quinton, Val\'erian Rey</dc:creator>
    </item>
    <item>
      <title>Equilibrium control theory for Kihlstrom-Mirman preferences in continuous time</title>
      <link>https://arxiv.org/abs/2407.16525</link>
      <description>arXiv:2407.16525v2 Announce Type: replace-cross 
Abstract: In intertemporal settings, the multiattribute utility theory of Kihlstrom and Mirman suggests the application of a concave transform of the lifetime utility index. This construction, while allowing time and risk attitudes to be separated, leads to dynamically inconsistent preferences. We address this issue in a game-theoretic sense by formalizing an equilibrium control theory for continuous-time Markov processes. In these terms, we describe the equilibrium strategy and value function as the solution of an extended Hamilton-Jacobi-Bellman system of partial differential equations. We verify that (the solution of) this system is a sufficient condition for an equilibrium and examine some of its novel features. A consumption-investment problem for an agent with CRRA-CES utility showcases our approach.</description>
      <guid isPermaLink="false">oai:arXiv.org:2407.16525v2</guid>
      <category>q-fin.MF</category>
      <category>math.OC</category>
      <pubDate>Mon, 07 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Luca De Gennaro Aquino, Sascha Desmettre, Yevhen Havrylenko, Mogens Steffensen</dc:creator>
    </item>
    <item>
      <title>Active Learning of Deep Neural Networks via Gradient-Free Cutting Planes</title>
      <link>https://arxiv.org/abs/2410.02145</link>
      <description>arXiv:2410.02145v2 Announce Type: replace-cross 
Abstract: Active learning methods aim to improve sample complexity in machine learning. In this work, we investigate an active learning scheme via a novel gradient-free cutting-plane training method for ReLU networks of arbitrary depth. We demonstrate, for the first time, that cutting-plane algorithms, traditionally used in linear models, can be extended to deep neural networks despite their nonconvexity and nonlinear decision boundaries. Our results demonstrate that these methods provide a promising alternative to the commonly employed gradient-based optimization techniques in large-scale neural networks. Moreover, this training method induces the first deep active learning scheme known to achieve convergence guarantees. We exemplify the effectiveness of our proposed active learning method against popular deep active learning baselines via both synthetic data experiments and sentimental classification task on real datasets.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.02145v2</guid>
      <category>cs.LG</category>
      <category>math.OC</category>
      <pubDate>Mon, 07 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Erica Zhang, Fangzhao Zhang, Mert Pilanci</dc:creator>
    </item>
  </channel>
</rss>
