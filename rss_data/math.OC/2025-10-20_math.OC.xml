<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>math.OC updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/math.OC</link>
    <description>math.OC updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/math.OC" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Tue, 21 Oct 2025 04:01:00 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Tue, 21 Oct 2025 00:00:00 -0400</pubDate>
    <skipDays>
      <day>Sunday</day>
      <day>Saturday</day>
    </skipDays>
    <item>
      <title>Fitting an Escalier to a Curve</title>
      <link>https://arxiv.org/abs/2510.16148</link>
      <description>arXiv:2510.16148v1 Announce Type: new 
Abstract: We analyze the problem of fitting a fonction en escalier or multi-step function to a curve in L^2 Hilbert space. We propose a two-stage optimization approach whereby the step positions are initially fixed, corresponding to a classic linear least-squares problem with closed-form solution, and then are allowed to vary, leading to first-order conditions that can be solved recursively. We find that, subject to regularity conditions, the speed of convergence is linear as the number of steps $n$ goes to infinity, and we develop a simple algorithm to recover the global optimum fit. Our numerical results based on a sweep search implementation show promising performance in terms of speed and accuracy.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.16148v1</guid>
      <category>math.OC</category>
      <category>math.FA</category>
      <pubDate>Tue, 21 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <dc:creator>Sebastien Bossu, Andrew Papanicolaou, Nour El Hatto</dc:creator>
    </item>
    <item>
      <title>Agent-Based Optimal Control for Image Processing</title>
      <link>https://arxiv.org/abs/2510.16154</link>
      <description>arXiv:2510.16154v1 Announce Type: new 
Abstract: We investigate the use of multi-agent systems to solve classical image processing tasks, such as colour quantization and segmentation. We frame the task as an optimal control problem, where the objective is to steer the multi-agent dynamics to obtain colour clusters that segment the image. To do so, we balance the total variation of the colour field and fidelity to the original image. The solution is obtained resorting to primal-dual splitting and the method of multipliers. Numerical experiments, implemented in parallel with CUDA, demonstrate the efficacy of the approach and its potential for high-dimensional data.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.16154v1</guid>
      <category>math.OC</category>
      <category>cs.NA</category>
      <category>math.NA</category>
      <pubDate>Tue, 21 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Alessio Oliviero, Simone Cacace, Giuseppe Visconti</dc:creator>
    </item>
    <item>
      <title>Conformal Prediction in The Loop: A Feedback-Based Uncertainty Model for Trajectory Optimization</title>
      <link>https://arxiv.org/abs/2510.16376</link>
      <description>arXiv:2510.16376v1 Announce Type: new 
Abstract: Conformal Prediction (CP) is a powerful statistical machine learning tool to construct uncertainty sets with coverage guarantees, which has fueled its extensive adoption in generating prediction regions for decision-making tasks, e.g., Trajectory Optimization (TO) in uncertain environments. However, existing methods predominantly employ a sequential scheme, where decisions rely unidirectionally on the prediction regions, and consequently the information from decision-making fails to be fed back to instruct CP. In this paper, we propose a novel Feedback-Based CP (Fb-CP) framework for shrinking-horizon TO with a joint risk constraint over the entire mission time. Specifically, a CP-based posterior risk calculation method is developed by fully leveraging the realized trajectories to adjust the posterior allowable risk, which is then allocated to future times to update prediction regions. In this way, the information in the realized trajectories is continuously fed back to the CP, enabling attractive feedback-based adjustments of the prediction regions and a provable online improvement in trajectory performance. Furthermore, we theoretically prove that such adjustments consistently maintain the coverage guarantees of the prediction regions, thereby ensuring provable safety. Additionally, we develop a decision-focused iterative risk allocation algorithm with theoretical convergence analysis for allocating the posterior allowable risk which closely aligns with Fb-CP. Furthermore, we extend the proposed method to handle distribution shift. The effectiveness and superiority of the proposed method are demonstrated through benchmark experiments.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.16376v1</guid>
      <category>math.OC</category>
      <category>cs.AI</category>
      <category>cs.RO</category>
      <category>cs.SY</category>
      <category>eess.SY</category>
      <category>math.ST</category>
      <category>stat.TH</category>
      <pubDate>Tue, 21 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Han Wang, Chao Ning</dc:creator>
    </item>
    <item>
      <title>A Simple First-Order Algorithm for Full-Rank Equality Constrained Optimization</title>
      <link>https://arxiv.org/abs/2510.16390</link>
      <description>arXiv:2510.16390v1 Announce Type: new 
Abstract: A very simple first-order algorithm is proposed for solving nonlinear optimization problems with deterministic nonlinear equality constraints. This algorithm adaptively selects steps in the plane tangent to the constraints or steps that reduce infeasibility, without using a merit function or filter. The tangent steps are based on the AdaGrad method for unconstrained minimization. The objective function is never evaluated by the algorithm, making it suitable for noisy problems. Its worst-case evaluation complexity is analyzed, yielding a global convergence rate in O(1/sqrt{k}), which matches the best known rate of first-order methods for unconstrained problems. Numerical experiments are presented suggesting that the performance of the algorithm is comparable to that of first-order methods for unconstrained problems, and that its reliability is remarkably stable in the presence of noise on the gradient.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.16390v1</guid>
      <category>math.OC</category>
      <pubDate>Tue, 21 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Serge Gratton, Philippe L. Toint</dc:creator>
    </item>
    <item>
      <title>Charnes--Cooper transformation and fractional optimization with SOS-convex polynomials</title>
      <link>https://arxiv.org/abs/2510.16400</link>
      <description>arXiv:2510.16400v1 Announce Type: new 
Abstract: This paper proposes a parameter-free scheme that is based on the Charnes--Cooper transformation for solving a class of fractional programs with SOS-convex polynomials. Under certain conditions, we establish theorems of solution existence,strong duality and solution extraction. An illustrative example is designed to show the obtained results.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.16400v1</guid>
      <category>math.OC</category>
      <pubDate>Tue, 21 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Chengmiao Yang, Liguo Jiao, Jae Hyoung Lee</dc:creator>
    </item>
    <item>
      <title>Frank-Wolfe Algorithms for (L0, L1)-smooth functions</title>
      <link>https://arxiv.org/abs/2510.16468</link>
      <description>arXiv:2510.16468v1 Announce Type: new 
Abstract: We propose a new version of the Frank-Wolfe method, called the (L0, L1)-Frank-Wolfe algorithm, developed for optimization problems with (L0, L1)-smooth objectives. We establish that this algorithm achieves superior theoretical convergence rates compared to the classical Frank-Wolfe method. In addition, we introduce a novel adaptive procedure, termed the Adaptive (L0, L1)-Frank-Wolfe algorithm, which dynamically adjusts the smoothness parameters to further improve performance and stability. Comprehensive numerical experiments confirm the theoretical results and demonstrate the clear practical advantages of both proposed algorithms over existing Frank-Wolfe variants.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.16468v1</guid>
      <category>math.OC</category>
      <pubDate>Tue, 21 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>A. A. Vyguzov, F. S. Stonyakin</dc:creator>
    </item>
    <item>
      <title>On the convergence rate of the boosted Difference-of-Convex Algorithm (DCA)</title>
      <link>https://arxiv.org/abs/2510.16569</link>
      <description>arXiv:2510.16569v1 Announce Type: new 
Abstract: The difference-of-convex algorithm (DCA) is a well-established nonlinear programming technique that solves successive convex optimization problems. These sub-problems are obtained from the difference-of-convex~(DC) decompositions of the objective and constraint functions. We investigate the worst-case performance of the unconstrained DCA, with and without boosting, where boosting simply performs an additional step in the direction generated by the usual DCA method. We show that, for certain classes of DC decompositions, the boosted DCA is provably better in the worst-case than the usual DCA. While several numerical studies have reported that boosted DCA outperforms classical DCA, a theoretical explanation for this behavior has, to the best of our knowledge, not been given until now. Our proof technique relies on semidefinite programming (SDP) performance estimation.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.16569v1</guid>
      <category>math.OC</category>
      <pubDate>Tue, 21 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Hadi Abbaszadehpeivasti, Etienne de Klerk, Adrien Taylor</dc:creator>
    </item>
    <item>
      <title>Convexification of a Separable Function over a Polyhedral Ground Set</title>
      <link>https://arxiv.org/abs/2510.16595</link>
      <description>arXiv:2510.16595v1 Announce Type: new 
Abstract: In this paper, we study the set $\mathcal{S}^\kappa = \{ (x,y)\in\mathcal{G}\times\mathbb{R}^n : y_j = x_j^\kappa , j=1,\dots,n\}$, where $\kappa &gt; 1$ and the ground set $\mathcal{G}$ is a nonempty polytope contained in $[0,1]^n$. This nonconvex set is closely related to separable standard quadratic programming and appears as a substructure in potential-based network flow problems from gas and water networks. Our aim is to obtain the convex hull of $\mathcal{S}^\kappa$ or its tight outer-approximation for the special case when the ground set $\mathcal{G}$ is the standard simplex. We propose power cone, second-order cone and semidefinite programming relaxations for this purpose, which are further strengthened by the Reformulation-Linearization Technique and the Reformulation-Perspectification Technique. For $\kappa=2$, we obtain the convex hull of $\mathcal{S}^\kappa$ in the low-dimensional setting. For general $\kappa$, we give approximation guarantees for the power cone representable relaxation, the weakest relaxation we consider. We prove that this weakest relaxation is tight with probability one as $n\to\infty$ when a uniformly generated linear objective is optimized over it. Finally, we provide the results of our extensive computational experiments comparing the empirical strength of several conic programming relaxations that we propose.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.16595v1</guid>
      <category>math.OC</category>
      <pubDate>Tue, 21 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Santanu S. Dey, Burak Kocuk</dc:creator>
    </item>
    <item>
      <title>A class of singular control problems with tipping points</title>
      <link>https://arxiv.org/abs/2510.16599</link>
      <description>arXiv:2510.16599v1 Announce Type: new 
Abstract: Tipping points define situations where a system experiences sudden and irreversible changes and are generally associated with a random level of the system below which the changes materialize. In this paper, we study a singular stochastic control problem in which the performance criterion depends on the hitting time of a random level that is not a stopping time for the reference filtration. We establish a connection between the value of the problem and the value of a singular control problem involving a diffusion and its running minimum. We prove a verification theorem and apply our results to explicitly solve a resource extraction problem where the random evolution of the resource changes when it crosses a tipping point.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.16599v1</guid>
      <category>math.OC</category>
      <pubDate>Tue, 21 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Jean-Paul D\'ecamps, Fabien Gensbittel, Thomas Mariotti, St\'ephane Villeneuve</dc:creator>
    </item>
    <item>
      <title>Adversarial Reinforcement Learning for Robust Control of Fixed-Wing Aircraft under Model Uncertainty</title>
      <link>https://arxiv.org/abs/2510.16650</link>
      <description>arXiv:2510.16650v1 Announce Type: new 
Abstract: This paper presents a reinforcement learning-based path-following controller for a fixed-wing small uncrewed aircraft system (sUAS) that is robust to uncertainties in the aerodynamic model of the sUAS. The controller is trained using the Robust Adversarial Reinforcement Learning framework, where an adversary perturbs the environment (aerodynamic model) to expose the agent (sUAS) to demanding scenarios. In our formulation, the adversary introduces rate-bounded perturbations to the aerodynamic model coefficients. We demonstrate that adversarial training improves robustness compared to controllers trained using stochastic model uncertainty. The learned controller is also benchmarked against a switched uncertain initial condition controller. The effectiveness of the approach is validated through high-fidelity simulations using a realistic six-degree-of-freedom fixed-wing aircraft model, showing accurate and robust path-following performance under a variety of uncertain aerodynamic conditions.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.16650v1</guid>
      <category>math.OC</category>
      <category>cs.SY</category>
      <category>eess.SY</category>
      <pubDate>Tue, 21 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Dennis J. Marquis, Blake Wilhelm, Devaprakash Muniraj, Mazen Farhood</dc:creator>
    </item>
    <item>
      <title>Bregman Stochastic Proximal Point Algorithm with Variance Reduction</title>
      <link>https://arxiv.org/abs/2510.16655</link>
      <description>arXiv:2510.16655v1 Announce Type: new 
Abstract: Stochastic algorithms, especially stochastic gradient descent (SGD), have proven to be the go-to methods in data science and machine learning. In recent years, the stochastic proximal point algorithm (SPPA) emerged, and it was shown to be more robust than SGD with respect to stepsize settings. However, SPPA still suffers from a decreased convergence rate due to the need for vanishing stepsizes, which is resolved by using variance reduction methods. In the deterministic setting, there are many problems that can be solved more efficiently when viewing them in a non-Euclidean geometry using Bregman distances. This paper combines these two worlds and proposes variance reduction techniques for the Bregman stochastic proximal point algorithm (BSPPA). As special cases, we obtain SAGA- and SVRG-like variance reduction techniques for BSPPA. Our theoretical and numerical results demonstrate improved stability and convergence rates compared to the vanilla BSPPA with constant and vanishing stepsizes, respectively. Our analysis, also, allow to recover the same variance reduction techniques for Bregman SGD in a unified way.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.16655v1</guid>
      <category>math.OC</category>
      <pubDate>Tue, 21 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Cheik Traor\'e, Peter Ochs</dc:creator>
    </item>
    <item>
      <title>HNAG++: A Super-Fast Accelerated Gradient Method for Strongly Convex Optimization</title>
      <link>https://arxiv.org/abs/2510.16680</link>
      <description>arXiv:2510.16680v1 Announce Type: new 
Abstract: We introduce and analyze two methods, HNAG+ and HNAG++, for minimizing strongly convex functions with large condition number kappa. For HNAG+, we prove a global linear convergence rate of 1 - 2/sqrt(kappa), achieving the information-theoretic optimal rate. For HNAG++, we establish a global asymptotic linear rate of 1 - 2*sqrt(2/kappa) for functions with H\"older continuous Hessians, representing the fastest known rate among globally convergent first-order methods. Extensive numerical experiments on linear and nonlinear problems show that HNAG++ consistently outperforms existing accelerated gradient methods.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.16680v1</guid>
      <category>math.OC</category>
      <pubDate>Tue, 21 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Long Chen, Zeyi Xu</dc:creator>
    </item>
    <item>
      <title>Geometric Control Theory Over Networks: Minimal Node Cardinality Disturbance Decoupling Problems</title>
      <link>https://arxiv.org/abs/2510.16689</link>
      <description>arXiv:2510.16689v1 Announce Type: new 
Abstract: In this paper we show how to formulate and solve disturbance decoupling problems over networks while choosing a minimal number of input and output nodes. Feedback laws that isolate and eliminate the impact of disturbance nodes on specific target nodes to be protected are provided using state, output, and dynamical feedback. For that, we leverage the fact that when reformulated in terms of sets of nodes rather than subspaces, the controlled and conditional invariance properties admit a simple graphical interpretation. For state and dynamical feedback, the minimal input and output cardinality solutions can be computed exactly in polynomial time, via min-cut/max-flow algorithms.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.16689v1</guid>
      <category>math.OC</category>
      <category>cs.SY</category>
      <category>eess.SY</category>
      <pubDate>Tue, 21 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Luca Claude Gino Lebon, Claudio Altafini</dc:creator>
    </item>
    <item>
      <title>Local integral input-to-state stability for non-autonomous infinite-dimensional systems</title>
      <link>https://arxiv.org/abs/2510.16725</link>
      <description>arXiv:2510.16725v1 Announce Type: new 
Abstract: In this paper, we prove comparison principles for nonlinear differential equations with time-varying coefficients and develop Lyapunov analytical tools for the integral input-to-state stability (iISS) analysis of nonlinear non-autonomous infinite-dimensional systems, which involve nonlinearities satisfying a superlinear growth, {bringing} difficulties to the iISS {analysis.} Specifically, our approach starts by establishing several forms of comparison principles for a wide range of ordinary differential equations having time-varying coefficients and superlinear terms, paving the way to conduct iISS assessment for general nonlinear non-autonomous infinite-dimensional systems within the Lyapunov stability framework. Then, by using the comparison principles, we prove a local {iISS} {(LiISS)} Lyapunov theorem for the nonlinear non-autonomous infinite-dimensional systems in the framework of Banach spaces. {Furthermore,} we provide sufficient conditions of the existence of a local iISS Lyapunonv functional (LiISS-LF) and construct LiISS-LFs for the systems in the framework of Hilbert spaces. Finally, we preset two examples to illustrate the proposed {Lyapunov} method for the LiISS analysis: one is to show how to obtain the LiISS of a nonlinear finite-dimensional system with time-varying coefficients and superlinear terms under linear state feedback control law while another one is to show how to employ the interpolation inequalities to handle superliner terms and establish the LiISS-LF for a class of multi-dimensional parabolic equations with space-time-varying coefficients. To demonstrate the validity of the results, numerical experiments are also conducted to verify the LiISS of these two classes of systems.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.16725v1</guid>
      <category>math.OC</category>
      <category>cs.SY</category>
      <category>eess.SY</category>
      <pubDate>Tue, 21 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Yongchun Bi, Panyu Deng, Jun Zheng, Guchuan Zhu</dc:creator>
    </item>
    <item>
      <title>Equivalence of additive and parametric pinning control protocols for systems of weakly coupled oscillators</title>
      <link>https://arxiv.org/abs/2510.16766</link>
      <description>arXiv:2510.16766v1 Announce Type: new 
Abstract: Controlling the behavior of nonlinear systems on networks is a paramount task in control theory, in particular the control of synchronization, given its vast applicability. In this work, we focus on pinning control and we examine two different approaches: the first, more common in engineering applications, where the control is implemented through an external input (additive pinning); the other, where the parameters of the pinned nodes are varied (parametric pinning). By means of the phase reduction technique, we show that the two pinning approaches are equivalent for weakly coupled systems exhibiting periodic oscillatory behaviors. Through numerical simulations, we validate the claim for a system of coupled Stuart--Landau oscillators. Our results pave the way for further applications of pinning control in real-world systems.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.16766v1</guid>
      <category>math.OC</category>
      <category>nlin.AO</category>
      <category>nlin.PS</category>
      <category>physics.comp-ph</category>
      <pubDate>Tue, 21 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Riccardo Muolo, Yuzuru Kato</dc:creator>
    </item>
    <item>
      <title>Method of Monotone Structural Evolution for control and state constrained optimal and control problems</title>
      <link>https://arxiv.org/abs/2510.16768</link>
      <description>arXiv:2510.16768v1 Announce Type: new 
Abstract: A method of optimal control computation is proposed for problems with control and state constraints. It uses a sequence of control structure adjustments in the form of generations and reductions of nodes and arcs, which do not change the current control but redefine the decision space. Several examples are given.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.16768v1</guid>
      <category>math.OC</category>
      <pubDate>Tue, 21 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Maciej Szymkat, Adam Korytowski</dc:creator>
    </item>
    <item>
      <title>A Surrogate Value Function Formulation for Bilevel Optimization</title>
      <link>https://arxiv.org/abs/2510.16818</link>
      <description>arXiv:2510.16818v1 Announce Type: new 
Abstract: The value function formulation captures the hierarchical nature of bilevel optimization through the optimal value function of the lower level problem, yet its implicit and nonsmooth characteristics pose significant analytical and computational difficulties. We introduce a surrogate value function formulation that replaces the intractable value function with an explicit surrogate derived from lower level stationarity conditions. This surrogate formulation preserves the essential idea of the classical value function model but fundamentally departs from Karush Kuhn Tucker (KKT) formulations, which embed lower level stationary points into the upper level feasible region and obscure the hierarchical dependence. Instead, it enforces the hierarchy through a dominance constraint that remains valid even when lower level constraint qualifications fail at the solution. We establish equivalence with the original bilevel problem, reveal the failure of standard constraint qualifications, and show that its strong stationarity implies that of KKT models. To handle the complementarity constraints in the surrogate formulation, we apply a smoothing barrier augmented Lagrangian method and prove its convergence to solutions and Clarke stationary points. Extensive experiments demonstrate the robustness and high numerical precision of this formulation, especially in nonconvex settings, including the classical Mirrlees problem where KKT models fail.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.16818v1</guid>
      <category>math.OC</category>
      <pubDate>Tue, 21 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Mengwei Xu, Yu-Hong Dai, Xin-Wei Liu, Meiqi Ma</dc:creator>
    </item>
    <item>
      <title>The Augmented Lagrangian Methods: Overview and Recent Advances</title>
      <link>https://arxiv.org/abs/2510.16827</link>
      <description>arXiv:2510.16827v1 Announce Type: new 
Abstract: Large-scale constrained optimization is pivotal in modern scientific, engineering, and industrial computation, often involving complex systems with numerous variables and constraints. This paper provides a unified and comprehensive perspective on constructing augmented Lagrangian functions (based on Hestenes-Powell-Rockafellar augmented Lagrangian) for various optimization problems, including nonlinear programming and convex and nonconvex composite programming. We present the augmented Lagrangian method (ALM), covering its theoretical foundations in both convex and nonconvex cases, and discuss several successful examples and applications. Recent advancements have extended ALM's capabilities to handle nonconvex constraints and ensure global convergence to first and second-order stationary points. For nonsmooth convex problems, ALM utilizes proximal operations, preserving desirable properties such as locally linear convergence rates. Furthermore, recent progress has refined the complexity analysis for ALM and tackled challenging integer programming instances. This review aims to offer a thorough understanding of ALM's benefits and limitations, exploring different ALM variants designed to enhance convergence and computational performance. We also illustrate effective algorithms for ALM subproblems across different types of optimization problems and highlight practical implementations in several fields.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.16827v1</guid>
      <category>math.OC</category>
      <pubDate>Tue, 21 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Kangkang Deng, Rui Wang, Zhenyuan Zhu, Junyu Zhang, Zaiwen Wen</dc:creator>
    </item>
    <item>
      <title>Solving nonconvex optimization problems via a second order dynamical system with unbounded damping</title>
      <link>https://arxiv.org/abs/2510.16864</link>
      <description>arXiv:2510.16864v1 Announce Type: new 
Abstract: In this paper we study a second order dynamical system with variable coefficients in connection to the minimization problem of a smooth nonconvex function. The convergence of the trajectories generated by the dynamical system to a critical point of the objective function is assured, provided a regularization of the objective function satisfies the Kurdyka-{\L}ojasiewicz property. We also provide convergence rates for the trajectories generated by the dynamical system, formulated in terms of the {\L}ojasiewicz exponent, and we show that the unbounded damping considered in our dynamical system significantly improves the convergence rates known so far in the literature, that is, instead of linear rates we obtain superlinear rates.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.16864v1</guid>
      <category>math.OC</category>
      <pubDate>Tue, 21 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Szil\'ard Csaba L\'aszl\'o</dc:creator>
    </item>
    <item>
      <title>Distributionally Robust Nash Equilibria via Variational Inequalities</title>
      <link>https://arxiv.org/abs/2510.17024</link>
      <description>arXiv:2510.17024v1 Announce Type: new 
Abstract: Nash Equilibrium and its robust counterpart, Distributionally Robust Nash Equilibrium (DRNE), are fundamental problems in game theory with applications in economics, engineering, and machine learning. This paper addresses the problem of DRNE, where multiple players engage in a noncooperative game under uncertainty. Each player aims to minimize their objective against the worst-case distribution within an ambiguity set, resulting in a minimax structure. We reformulate the DRNE problem as a Variational Inequality (VI) problem, providing a unified framework for analysis and algorithm development. We propose a gradient descent-ascent type algorithm with convergence guarantee that effectively addresses the computational challenges of high-dimensional and nonsmooth objectives.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.17024v1</guid>
      <category>math.OC</category>
      <pubDate>Tue, 21 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Zeinab Alizadeh, Azadeh Farsi, Afrooz Jalilzadeh</dc:creator>
    </item>
    <item>
      <title>Optimal Trajectories for Optimal Transport in Nonuniform Environments</title>
      <link>https://arxiv.org/abs/2510.17170</link>
      <description>arXiv:2510.17170v1 Announce Type: new 
Abstract: In this work, we solve a discrete optimal transport problem in a nonuniform environment. The key challenge is to form the cost matrix, which requires finding the optimal path between two points, and for this task we formulate and solve the associated Euler-Lagrange equations. A main theoretical result of ours is to provide verifiable sufficient conditions of optimality of the solution of the Euler-Lagrange equation. We propose new algorithms to solve the problem, and illustrate our results and performance of the algorithms on several numerical examples.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.17170v1</guid>
      <category>math.OC</category>
      <category>cs.NA</category>
      <category>math.NA</category>
      <pubDate>Tue, 21 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Luca Dieci, Daniyar Omarov</dc:creator>
    </item>
    <item>
      <title>Periodic limit for non-autonomous Lagrangian systems and applications to a Kuramoto type model</title>
      <link>https://arxiv.org/abs/2510.17242</link>
      <description>arXiv:2510.17242v1 Announce Type: new 
Abstract: This paper explores the asymptotic properties of non-autonomous Lagrangian systems, assuming that the associated Tonelli Lagrangian converges to a time-periodic function. Specifically, given a continuous initial condition, we provide a suitable construction of a Lax-Oleinik semigroup such that it converges toward a periodic solution of the equation. Moreover, the graph of its gradient converges as time tends to infinity to the graph of the gradient of the periodic limit function with respect to the Hausdorff distance. Finally, we apply this result to a Kuramoto-type model, proving the existence of an invariant torus given by the graph of the gradient of the limiting periodic solution of the Hamilton-Jacobi equation.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.17242v1</guid>
      <category>math.OC</category>
      <category>math-ph</category>
      <category>math.AP</category>
      <category>math.MP</category>
      <pubDate>Tue, 21 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/publicdomain/zero/1.0/</dc:rights>
      <dc:creator>Veronica Danesi, Cristian Mendico, Xuan Tao, Kaizhi Wang</dc:creator>
    </item>
    <item>
      <title>A polynomial-based QCQP solver for encrypted optimization</title>
      <link>https://arxiv.org/abs/2510.17294</link>
      <description>arXiv:2510.17294v1 Announce Type: new 
Abstract: In this paper, we present a novel method for solving a class of quadratically constrained quadratic optimization problems using only additions and multiplications. This approach enables solving constrained optimization problems on private data since the operations involved are compatible with the capabilities of homomorphic encryption schemes. To solve the constrained optimization problem, a sequence of polynomial penalty functions of increasing degree is introduced, which are sufficiently steep at the boundary of the feasible set. Adding the penalty function to the original cost function creates a sequence of unconstrained optimization problems whose minimizer always lies in the admissible set and converges to the minimizer of the constrained problem. A gradient descent method is used to generate a sequence of iterates associated with these problems. For the algorithm, it is shown that the iterate converges to a minimizer of the original problem, and the feasible set is positively invariant under the iteration. Finally, the method is demonstrated on an illustrative cryptographic problem, finding the smaller value of two numbers, and the encrypted implementability is discussed.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.17294v1</guid>
      <category>math.OC</category>
      <category>cs.CR</category>
      <category>cs.SY</category>
      <category>eess.SY</category>
      <pubDate>Tue, 21 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Sebastian Schlor, Andrea Iannelli, Junsoo Kim, Hyungbo Shim, Frank Allg\"ower</dc:creator>
    </item>
    <item>
      <title>Assessing the Quality of a Set of Basis Functions for Inverse Optimal Control via Projection onto Global Minimizers</title>
      <link>https://arxiv.org/abs/2510.17339</link>
      <description>arXiv:2510.17339v1 Announce Type: new 
Abstract: Inverse optimization (Inverse optimal control) is the task of imputing a cost function such that given test points (trajectories) are (nearly) optimal with respect to the discovered cost. Prior methods in inverse optimization assume that the true cost is a convex combination of a set of convex basis functions and that this basis is consistent with the test points. However, the consistency assumption is not always justified, as in many applications the principles by which the data is generated are not well understood. This work proposes using the distance between a test point and the set of global optima generated by the convex combinations of the convex basis functions as a measurement for the expressive quality of the basis with respect to the test point. A large minimal distance invalidates the set of basis functions. The concept of a set of global optima is introduced and its properties are explored in unconstrained and constrained settings. Upper and lower bounds for the minimum distance in the convex quadratic setting are implemented by bi-level gradient descent and an enriched linear matrix inequality respectively. Extensions to this framework include max-representable basis functions, nonconvex basis functions (local minima), and applying polynomial optimization techniques.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.17339v1</guid>
      <category>math.OC</category>
      <category>cs.SY</category>
      <category>eess.SY</category>
      <pubDate>Tue, 21 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <arxiv:DOI>10.1109/CDC51059.2022.9993342</arxiv:DOI>
      <arxiv:journal_reference>2022 IEEE 61st Conference on Decision and Control (CDC), Cancun, Mexico, 2022, pp. 7598-7605</arxiv:journal_reference>
      <dc:creator>Filip Be\v{c}anovi\'c, Jared Miller, Vincent Bonnet, Kosta Jovanovi\'c, Samer Mohammed</dc:creator>
    </item>
    <item>
      <title>A Finite-Difference Trust-Region Method for Convexly Constrained Smooth Optimization</title>
      <link>https://arxiv.org/abs/2510.17366</link>
      <description>arXiv:2510.17366v1 Announce Type: new 
Abstract: We propose a derivative-free trust-region method based on finite-difference gradient approximations for smooth optimization problems with convex constraints. The proposed method does not require computing an approximate stationarity measure. For nonconvex problems, we establish a worst-case complexity bound of $\mathcal{O}\!\left(n\left(\tfrac{L}{\sigma}\epsilon\right)^{-2}\right)$ function evaluations for the method to reach an $\left(\tfrac{L}{\sigma}\epsilon\right)$-approximate stationary point, where $n$ is the number of variables, $L$ is the Lipschitz constant of the gradient, and $\sigma$ is a user-defined estimate of $L$. If the objective function is convex, the complexity to reduce the functional residual below $(L/\sigma)\epsilon$ is shown to be of $\mathcal{O}\!\left(n\left(\tfrac{L}{\sigma}\epsilon\right)^{-1}\right)$ function evaluations, while for Polyak-Lojasiewicz functions on unconstrained domains, the bound further improves to $\mathcal{O}\left(n\log\left(\left(\frac{L}{\sigma}\epsilon\right)^{-1}\right)\right)$. Numerical experiments on benchmark problems and a model-fitting application demonstrate the method's efficiency relative to state-of-the-art derivative-free solvers for both unconstrained and bound-constrained problems.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.17366v1</guid>
      <category>math.OC</category>
      <pubDate>Tue, 21 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>D\^an\^a Davar, Geovani Nunes Grapiglia</dc:creator>
    </item>
    <item>
      <title>A condensing approach for linear-quadratic optimization with geometric constraints</title>
      <link>https://arxiv.org/abs/2510.17465</link>
      <description>arXiv:2510.17465v1 Announce Type: new 
Abstract: Optimization problems with convex quadratic cost and polyhedral constraints are ubiquitous in signal processing, automatic control and decision-making. We consider here an enlarged problem class that allows to encode logical conditions and cardinality constraints, among others. In particular, we cover also situations where parts of the constraints are nonconvex and possibly complicated, but it is practical to compute projections onto this nonconvex set. Our approach combines the augmented Lagrangian framework with a solver-agnostic structure-exploiting subproblem reformulation. While convergence guarantees follow from the former, the proposed condensing technique leads to significant improvements in computational performance.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.17465v1</guid>
      <category>math.OC</category>
      <category>cs.SY</category>
      <category>eess.SY</category>
      <pubDate>Tue, 21 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Alberto De Marchi</dc:creator>
    </item>
    <item>
      <title>Towards Optimal Control and Algorithmic Structure of Decompression Schedules</title>
      <link>https://arxiv.org/abs/2510.17551</link>
      <description>arXiv:2510.17551v1 Announce Type: new 
Abstract: We formalise decompression planning as an optimal control problem with gas feasibility windows (ppO$_2$, END), affine ceilings, and convex penalties in normalised oversaturation. We prove existence, a monotone no re-descent structure and bang-bang ascents under a mild monotonicity assumption on inert fraction, and establish dwell time KKT conditions. We give pseudo-polynomial DP and label-setting algorithms with a priori error bounds, derive Lipschitz regularity of the online value function, and discuss multi-species extensions. The efficient frontier is continuous and generally nonconvex. We provide the first formal existence and bang-bang structure proof under mixed gas feasibility windows.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.17551v1</guid>
      <category>math.OC</category>
      <pubDate>Tue, 21 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Benjamin Marsh</dc:creator>
    </item>
    <item>
      <title>An Inexact General Descent Method with Applications in Differential Equation-Constrained Optimization</title>
      <link>https://arxiv.org/abs/2510.17581</link>
      <description>arXiv:2510.17581v1 Announce Type: new 
Abstract: In many applications, gradient evaluations are inherently approximate, motivating the development of optimization methods that remain reliable under inexact first-order information. A common strategy in this context is adaptive evaluation, whereby coarse gradients are used in early iterations and refined near a minimizer. This is particularly relevant in differential equation-constrained optimization (DECO), where discrete adjoint gradients depend on iterative solvers. Motivated by DECO applications, we propose an inexact general descent framework and establish its global convergence theory under two step-size regimes. For bounded step sizes, the analysis assumes that the error tolerance in the computed gradient is proportional to its norm, whereas for diminishing step sizes, the tolerance sequence is required to be summable. The framework is implemented through inexact gradient descent and an inexact BFGS-like method, whose performance is demonstrated on a second-order ODE inverse problem and a two-dimensional Laplace inverse problem using discrete adjoint gradients with adaptive accuracy. Across these examples, adaptive inexact gradients consistently reduced optimization time relative to fixed tight tolerances, while incorporating curvature information further improved overall efficiency.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.17581v1</guid>
      <category>math.OC</category>
      <category>cs.NA</category>
      <category>math.NA</category>
      <pubDate>Tue, 21 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Humberto Gimenes Macedo, Lu\'is Felipe Bueno</dc:creator>
    </item>
    <item>
      <title>A brief note on approximate optimization of submodular functions</title>
      <link>https://arxiv.org/abs/2510.17610</link>
      <description>arXiv:2510.17610v1 Announce Type: new 
Abstract: We briefly discuss the greedy method and a couple of its more efficient variants for approximately maximizing monotone submodular functions.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.17610v1</guid>
      <category>math.OC</category>
      <pubDate>Tue, 21 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Alen Alexanderian</dc:creator>
    </item>
    <item>
      <title>Counterfactual Explanations for Integer Optimization Problems</title>
      <link>https://arxiv.org/abs/2510.17624</link>
      <description>arXiv:2510.17624v1 Announce Type: new 
Abstract: Counterfactual explanations (CEs) offer a human-understandable way to explain decisions by identifying specific changes to the input parameters of a base or present model that would lead to a desired change in the outcome. For optimization models, CEs have primarily been studied in limited contexts and little research has been done on CEs for general integer optimization problems. In this work, we address this gap. We first show that the general problem of constructing a CE is $\Sigma_2^p$-complete even for binary integer programs with just a single mutable constraint. Second, we propose solution algorithms for several of the most tractable special cases: (i) mutable objective parameters, (ii) a single mutable constraint, (iii) mutable right-hand-side, and (iv) all input parameters can be modified. We evaluate our approach using classical knapsack problem instances, focusing on cases with mutable constraint parameters. Our results show that our methods are capable of finding optimal CEs for small instances involving up to 40 items within a few hours.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.17624v1</guid>
      <category>math.OC</category>
      <category>cs.CC</category>
      <pubDate>Tue, 21 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Felix Engelhardt, Jannis Kurtz, \c{S}. \.Ilker Birbil, Ted Ralphs</dc:creator>
    </item>
    <item>
      <title>Is Zadeh's Least-Entered Pivot Rule Exponential?</title>
      <link>https://arxiv.org/abs/2510.16055</link>
      <description>arXiv:2510.16055v1 Announce Type: cross 
Abstract: In 2011, Friedmann [F 7] claimed to have proved that pathological linear programs existed for which the Simplex method using Zadeh's least-entered rule [Z 14] would take an exponential number of pivots. In 2019, Disser and Hopp [DH 5] argued that there were errors in Friedmann's 2011 construction. In 2020, Disser, Friedmann, and Hopp [DFH 3,4] again contended that the least-entered rule was exponential. We show that their arguments contain multiple flaws. In other words, the worst-case behavior of the least-entered rule has not been established. Neither [F 7] nor [DFH 3,4] provides pathological linear programs that can be tested. Instead, the authors contend that their pathological linear programs are of the form (P) as shown on page 12 of [DFH 3]. The authors contend that the constraints of (P) ensure that the probability of entering a vertex u is equal to the probability of exiting u. In fact, we note that the authors' constraints (P) are flawed in at least three ways: a) they require the probability of exiting u to exceed the probability of entering u, b) they require the probability of exiting some nodes to exceed 1, and c) they overlook flows from decision nodes to decision nodes. At my request, in August of 2025, Disser, Friedmann, and Hopp provided me with their first ten purportedly pathological LPs and the graph of their first purportedly pathological Markov Decision Process (MDP1). It is shown that: a) their first two pathological LPs are infeasible if the variables are supposed to be probabilities, as the authors contend, and b) their first purportedly pathological LP does not match up with their first purportedly pathological MDP. In other words, the authors have not come close to providing counterexamples to the least-entered rule.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.16055v1</guid>
      <category>cs.DS</category>
      <category>math.OC</category>
      <pubDate>Tue, 21 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Norman Zadeh</dc:creator>
    </item>
    <item>
      <title>A Minimal-Assumption Analysis of Q-Learning with Time-Varying Policies</title>
      <link>https://arxiv.org/abs/2510.16132</link>
      <description>arXiv:2510.16132v1 Announce Type: cross 
Abstract: In this work, we present the first finite-time analysis of the Q-learning algorithm under time-varying learning policies (i.e., on-policy sampling) with minimal assumptions -- specifically, assuming only the existence of a policy that induces an irreducible Markov chain over the state space. We establish a last-iterate convergence rate for $\mathbb{E}[\|Q_k - Q^*\|_\infty^2]$, implying a sample complexity of order $O(1/\epsilon^2)$ for achieving $\mathbb{E}[\|Q_k - Q^*\|_\infty] \le \epsilon$, matching that of off-policy Q-learning but with a worse dependence on exploration-related parameters. We also derive an explicit rate for $\mathbb{E}[\|Q^{\pi_k} - Q^*\|_\infty^2]$, where $\pi_k$ is the learning policy at iteration $k$. These results reveal that on-policy Q-learning exhibits weaker exploration than its off-policy counterpart but enjoys an exploitation advantage, as its policy converges to an optimal one rather than remaining fixed. Numerical simulations corroborate our theory.
  Technically, the combination of time-varying learning policies (which induce rapidly time-inhomogeneous Markovian noise) and the minimal assumption on exploration presents significant analytical challenges. To address these challenges, we employ a refined approach that leverages the Poisson equation to decompose the Markovian noise corresponding to the lazy transition matrix into a martingale-difference term and residual terms. To control the residual terms under time inhomogeneity, we perform a sensitivity analysis of the Poisson equation solution with respect to both the Q-function estimate and the learning policy. These tools may further facilitate the analysis of general reinforcement learning algorithms with rapidly time-varying learning policies -- such as single-timescale actor--critic methods and learning-in-games algorithms -- and are of independent interest.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.16132v1</guid>
      <category>cs.LG</category>
      <category>math.OC</category>
      <category>stat.ML</category>
      <pubDate>Tue, 21 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Phalguni Nanda, Zaiwei Chen</dc:creator>
    </item>
    <item>
      <title>Explore-then-Commit for Nonstationary Linear Bandits with Latent Dynamics</title>
      <link>https://arxiv.org/abs/2510.16208</link>
      <description>arXiv:2510.16208v1 Announce Type: cross 
Abstract: We study a nonstationary bandit problem where rewards depend on both actions and latent states, the latter governed by unknown linear dynamics. Crucially, the state dynamics also depend on the actions, resulting in tension between short-term and long-term rewards. We propose an explore-then-commit algorithm for a finite horizon $T$. During the exploration phase, random Rademacher actions enable estimation of the Markov parameters of the linear dynamics, which characterize the action-reward relationship. In the commit phase, the algorithm uses the estimated parameters to design an optimized action sequence for long-term reward. Our proposed algorithm achieves $\tilde{\mathcal{O}}(T^{2/3})$ regret. Our analysis handles two key challenges: learning from temporally correlated rewards, and designing action sequences with optimal long-term reward. We address the first challenge by providing near-optimal sample complexity and error bounds for system identification using bilinear rewards. We address the second challenge by proving an equivalence with indefinite quadratic optimization over a hypercube, a known NP-hard problem. We provide a sub-optimality guarantee for this problem, enabling our regret upper bound. Lastly, we propose a semidefinite relaxation with Goemans-Williamson rounding as a practical approach.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.16208v1</guid>
      <category>cs.LG</category>
      <category>cs.SY</category>
      <category>eess.SY</category>
      <category>math.OC</category>
      <category>stat.ML</category>
      <pubDate>Tue, 21 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Sunmook Choi, Yahya Sattar, Yassir Jedra, Maryam Fazel, Sarah Dean</dc:creator>
    </item>
    <item>
      <title>Sparse Transformer Architectures via Regularized Wasserstein Proximal Operator with $L_1$ Prior</title>
      <link>https://arxiv.org/abs/2510.16356</link>
      <description>arXiv:2510.16356v1 Announce Type: cross 
Abstract: In this work, we propose a sparse transformer architecture that incorporates prior information about the underlying data distribution directly into the transformer structure of the neural network. The design of the model is motivated by a special optimal transport problem, namely the regularized Wasserstein proximal operator, which admits a closed-form solution and turns out to be a special representation of transformer architectures. Compared with classical flow-based models, the proposed approach improves the convexity properties of the optimization problem and promotes sparsity in the generated samples. Through both theoretical analysis and numerical experiments, including applications in generative modeling and Bayesian inverse problems, we demonstrate that the sparse transformer achieves higher accuracy and faster convergence to the target distribution than classical neural ODE-based methods.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.16356v1</guid>
      <category>cs.LG</category>
      <category>math.OC</category>
      <category>stat.ML</category>
      <pubDate>Tue, 21 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Fuqun Han, Stanley Osher, Wuchen Li</dc:creator>
    </item>
    <item>
      <title>Iterative solvers for partial differential equations with dissipative structure: Operator preconditioning and optimal control</title>
      <link>https://arxiv.org/abs/2510.16399</link>
      <description>arXiv:2510.16399v1 Announce Type: cross 
Abstract: This work considers the iterative solution of large-scale problems subject to non-symmetric matrices or operators arising in discretizations of (port-)Hamiltonian partial differential equations. We consider problems governed by an operator $\mathcal{A}=\mathcal{H}+\mathcal{S}$ with symmetric part $\mathcal{H}$ that is positive (semi-)definite and skew-symmetric part $\mathcal{S}$. Prior work has shown that the structure and sparsity of the associated linear system enables Krylov subspace solvers such as the generalized minimal residual method (GMRES) or short recurrence variants such as Widlund's or Rapoport's method using the symmetric part $\mathcal{H}$, or an approximation of it, as preconditioner. In this work, we analyze the resulting condition numbers, which are crucial for fast convergence of these methods, for various partial differential equations (PDEs) arising in diffusion phenomena, fluid dynamics, and elasticity. We show that preconditioning with the symmetric part leads to a condition number uniform in the mesh size in case of elliptic and parabolic PDEs where $\mathcal{H}^{-1}\mathcal{S}$ is a bounded operator. Further, we employ the tailored Krylov subspace methods in optimal control by means of a condensing approach and a constraint preconditioner for the optimality system. We illustrate the results by various large-scale numerical examples and discuss efficient evaluations of the preconditioner, such as incomplete Cholesky factorization or the algebraic multigrid method.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.16399v1</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <category>cs.SY</category>
      <category>eess.SY</category>
      <category>math.OC</category>
      <pubDate>Tue, 21 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Volker Mehrmann, Manuel Schaller, Martin Stoll</dc:creator>
    </item>
    <item>
      <title>Sharp comparisons between sliced and standard $1$-Wasserstein distances</title>
      <link>https://arxiv.org/abs/2510.16465</link>
      <description>arXiv:2510.16465v1 Announce Type: cross 
Abstract: Sliced Wasserstein distances are widely used in practice as a computationally efficient alternative to Wasserstein distances in high dimensions. In this paper, motivated by theoretical foundations of this alternative, we prove quantitative estimates between the sliced $1$-Wasserstein distance and the $1$-Wasserstein distance. We construct a concrete example to demonstrate the exponents in the estimate is sharp. We also provide a general analysis for the case where slicing involves projections onto $k$-planes and not just lines.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.16465v1</guid>
      <category>math.ST</category>
      <category>math.MG</category>
      <category>math.OC</category>
      <category>stat.TH</category>
      <pubDate>Tue, 21 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Guillaume Carlier, Alessio Figalli, Quentin M\'erigot, Yi Wang</dc:creator>
    </item>
    <item>
      <title>Free energy Wasserstein gradient flow and their particle counterparts: toy model, (degenerate) PL inequalities and exit times</title>
      <link>https://arxiv.org/abs/2510.16506</link>
      <description>arXiv:2510.16506v1 Announce Type: cross 
Abstract: In finite dimension, the long-time and metastable behavior of a gradient flow perturbated by a small Brownian noise is well understood. A similar situation arises when a Wasserstein gradient flow over a space of probability measure is approximated by a system of mean-field interacting particles, but classical results do not apply in these infinite-dimensional settings. This work is concerned with the situation where the objective function of the optimization problem contains an entropic penalization, so that the particle system is a Langevin diffusion process. We consider a very simple class of models, for which the infinite-dimensional behavior is fully characterized by a finite-dimensional process. The goal is to have a flexible class of benchmarks to fix some objectives, conjectures and (counter-)examples for the general situation. Inspired by the systematic study of these toy models, one application is presented on the continuous Curie-Weiss model in a symmetric double-well potential. We show that, at the critical temperature, although the $N$-particle Gibbs measure does not satisfy a uniform-in-$N$ standard log-Sobolev inequality (the optimal constant growing like $\sqrt{N}$), it does satisfy a more general Lojasiewicz inequality uniformly in $N$, inducing uniform polynomial long-time convergence rates, propagation of chaos at stationarity and uniformly in time, and creation of chaos.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.16506v1</guid>
      <category>math.PR</category>
      <category>math.AP</category>
      <category>math.OC</category>
      <pubDate>Tue, 21 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Pierre Monmarch\'e</dc:creator>
    </item>
    <item>
      <title>LSTM-Based Forecasting and Analysis of EV Charging Demand in a Dense Urban Campus</title>
      <link>https://arxiv.org/abs/2510.16719</link>
      <description>arXiv:2510.16719v1 Announce Type: cross 
Abstract: This paper presents a framework for processing EV charging load data in order to forecast future load predictions using a Recurrent Neural Network, specifically an LSTM. The framework processes a large set of raw data from multiple locations and transforms it with normalization and feature extraction to train the LSTM. The pre-processing stage corrects for missing or incomplete values by interpolating and normalizing the measurements. This information is then fed into a Long Short-Term Memory Model designed to capture the short-term fluctuations while also interpreting the long-term trends in the charging data. Experimental results demonstrate the model's ability to accurately predict charging demand across multiple time scales (daily, weekly, and monthly), providing valuable insights for infrastructure planning, energy management, and grid integration of EV charging facilities. The system's modular design allows for adaptation to different charging locations with varying usage patterns, making it applicable across diverse deployment scenarios.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.16719v1</guid>
      <category>cs.LG</category>
      <category>math.OC</category>
      <pubDate>Tue, 21 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Zak Ressler, Marcus Grijalva, Angelica Marie Ignacio, Melanie Torres, Abelardo Cuadra Rojas, Rohollah Moghadam, Mohammad Rasoul narimani</dc:creator>
    </item>
    <item>
      <title>Minimisation of Laplacian eigenvalue with indefinite weight under inhomogeneous Robin boundary condition</title>
      <link>https://arxiv.org/abs/2510.16866</link>
      <description>arXiv:2510.16866v1 Announce Type: cross 
Abstract: This paper explores a certain Laplacian eigenvalue optimisation problem with indefinite weight under inhomogeneous Robin boundary condition. The minimum principal eigenvalue is fully determined in one dimension by formulating the problem as a shape optimisation one. The result is verified numerically using a shooting method.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.16866v1</guid>
      <category>math.SP</category>
      <category>math.OC</category>
      <pubDate>Tue, 21 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Baruch Schneider, Diana Schneiderov\'a, Yifan Zhang</dc:creator>
    </item>
    <item>
      <title>MuonBP: Faster Muon via Block-Periodic Orthogonalization</title>
      <link>https://arxiv.org/abs/2510.16981</link>
      <description>arXiv:2510.16981v1 Announce Type: cross 
Abstract: Gradient orthogonalization is a simple strategy that shows great utility in speeding up gradient descent. The Muon optimizer (Jordan, Jin, et al., 2024) combines gradient orthogonalization with first-order momentum and achieves significant improvement in data efficiency over Adam/AdamW (Loshchilov and Hutter, 2019) for language model training. However, when using model parallelism, gradient orthogonalization introduces additional overhead compared to coordinate-wise optimizers (such as AdamW) due to additional gather and scatter operations on gradient matrix shards from different devices. This additional communication can amount to a throughput hit of 5%-10% compared to Adam/AdamW. To remedy this, we propose Muon with Block-Periodic Orthogonalization (MuonBP), which applies orthogonalization independently to matrix shards on each device and periodically performs full orthogonalization to maintain training stability at scale. We show how to adjust the learning rate from the baseline to MuonBP and give convergence guarantees for this algorithm. Crucially, our theory dictates that we use two stepsizes: one for the blockwise orthogonalization steps, and one for the full orthogonalization steps. Our method is simple, requires minimal hyperparameter adjustments, and achieves competitive iteration complexity compared with baseline Muon while providing per-iteration throughput comparable to coordinate-wise methods such as AdamW. When training an 8B model with eight-way tensor parallelism and ZeRO optimizer state sharding, MuonBP achieves 8% throughput increase compared to Muon with no degradation in performance.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.16981v1</guid>
      <category>cs.LG</category>
      <category>math.OC</category>
      <pubDate>Tue, 21 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Ahmed Khaled, Kaan Ozkara, Tao Yu, Mingyi Hong, Youngsuk Park</dc:creator>
    </item>
    <item>
      <title>Convergence of Regret Matching in Potential Games and Constrained Optimization</title>
      <link>https://arxiv.org/abs/2510.17067</link>
      <description>arXiv:2510.17067v1 Announce Type: cross 
Abstract: Regret matching (RM} -- and its modern variants -- is a foundational online algorithm that has been at the heart of many AI breakthrough results in solving benchmark zero-sum games, such as poker. Yet, surprisingly little is known so far in theory about its convergence beyond two-player zero-sum games. For example, whether regret matching converges to Nash equilibria in potential games has been an open problem for two decades. Even beyond games, one could try to use RM variants for general constrained optimization problems. Recent empirical evidence suggests that they -- particularly regret matching$^+$ (RM$^+$) -- attain strong performance on benchmark constrained optimization problems, outperforming traditional gradient descent-type algorithms.
  We show that alternating RM$^+$ converges to an $\epsilon$-KKT point after $O_\epsilon(1/\epsilon^4)$ iterations, establishing for the first time that it is a sound and fast first-order optimizer. Our argument relates the KKT gap to the accumulated regret, two quantities that are entirely disparate in general but interact in an intriguing way in our setting, so much so that when regrets are bounded, our complexity bound improves all the way to $O_\epsilon(1/\epsilon^2)$. From a technical standpoint, while RM$^+$ does not have the usual one-step improvement property in general, we show that it does in a certain region that the algorithm will quickly reach and remain in thereafter. In sharp contrast, our second main result establishes a lower bound: RM, with or without alternation, can take an exponential number of iterations to reach a crude approximate solution even in two-player potential games. This represents the first worst-case separation between RM and RM$^+$. Our lower bound shows that convergence to coarse correlated equilibria in potential games is exponentially faster than convergence to Nash equilibria.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.17067v1</guid>
      <category>cs.GT</category>
      <category>cs.LG</category>
      <category>math.OC</category>
      <pubDate>Tue, 21 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Ioannis Anagnostides, Emanuel Tewolde, Brian Hu Zhang, Ioannis Panageas, Vincent Conitzer, Tuomas Sandholm</dc:creator>
    </item>
    <item>
      <title>Differentiating Through Power Flow Solutions for Admittance and Topology Control</title>
      <link>https://arxiv.org/abs/2510.17071</link>
      <description>arXiv:2510.17071v1 Announce Type: cross 
Abstract: The power flow equations relate bus voltage phasors to power injections via the network admittance matrix. These equations are central to the key operational and protection functions of power systems (e.g., optimal power flow scheduling and control, state estimation, protection, and fault location, among others). As control, optimization, and estimation of network admittance parameters are central to multiple avenues of research in electric power systems, we propose a linearization of power flow solutions obtained by implicitly differentiating them with respect to the network admittance parameters. This is achieved by utilizing the implicit function theorem, in which we show that such a differentiation is guaranteed to exist under mild conditions and is applicable to generic power systems (radial or meshed). The proposed theory is applied to derive sensitivities of complex voltages, line currents, and power flows. The developed theory of linearizing the power flow equations around changes in the complex network admittance parameters has numerous applications. We demonstrate several of these applications, such as predicting the nodal voltages when the network topology changes without solving the power flow equations. We showcase the application for continuous admittance control, which is used to increase the hosting capacity of a given distribution network.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.17071v1</guid>
      <category>eess.SY</category>
      <category>cs.SY</category>
      <category>math.OC</category>
      <pubDate>Tue, 21 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Samuel Talkington, Daniel Turizo, Sergio A. Dorado-Rojas, Rahul K. Gupta, Daniel K. Molzahn</dc:creator>
    </item>
    <item>
      <title>Continuous Q-Score Matching: Diffusion Guided Reinforcement Learning for Continuous-Time Control</title>
      <link>https://arxiv.org/abs/2510.17122</link>
      <description>arXiv:2510.17122v1 Announce Type: cross 
Abstract: Reinforcement learning (RL) has achieved significant success across a wide range of domains, however, most existing methods are formulated in discrete time. In this work, we introduce a novel RL method for continuous-time control, where stochastic differential equations govern state-action dynamics. Departing from traditional value function-based approaches, our key contribution is the characterization of continuous-time Q-functions via a martingale condition and the linking of diffusion policy scores to the action gradient of a learned continuous Q-function by the dynamic programming principle. This insight motivates Continuous Q-Score Matching (CQSM), a score-based policy improvement algorithm. Notably, our method addresses a long-standing challenge in continuous-time RL: preserving the action-evaluation capability of Q-functions without relying on time discretization. We further provide theoretical closed-form solutions for linear-quadratic (LQ) control problems within our framework. Numerical results in simulated environments demonstrate the effectiveness of our proposed method and compare it to popular baselines.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.17122v1</guid>
      <category>cs.LG</category>
      <category>math.OC</category>
      <pubDate>Tue, 21 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Chengxiu Hua, Jiawen Gu, Yushun Tang</dc:creator>
    </item>
    <item>
      <title>Numerical boundary control of multi-dimensional discrete-velocity kinetic models</title>
      <link>https://arxiv.org/abs/2510.17246</link>
      <description>arXiv:2510.17246v1 Announce Type: cross 
Abstract: This paper extends our recent results on multi-dimensional discrete-velocity models to the numerical level. By adopting an operator splitting scheme and introducing a suitable discrete Lyapunov function, we derive numerical control laws that ensure the corresponding numerical solutions decay exponentially in time. To handle the stiff source term, we also use an implicit scheme for the collision part and prove the stability of the resulting schemes. The theoretical results are validated through three numerical simulations for the two-dimensional coplanar model.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.17246v1</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <category>math.OC</category>
      <pubDate>Tue, 21 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Haitian Yang, Wen-An Yong</dc:creator>
    </item>
    <item>
      <title>Comparison and performance analysis of dynamic encrypted control approaches</title>
      <link>https://arxiv.org/abs/2510.17333</link>
      <description>arXiv:2510.17333v1 Announce Type: cross 
Abstract: Encrypted controllers using homomorphic encryption have proven to guarantee the privacy of measurement and control signals, as well as system and controller parameters, while regulating the system as intended. However, encrypting dynamic controllers has remained a challenge due to growing noise and overflow issues in the encoding. In this paper, we review recent approaches to dynamic encrypted control, such as bootstrapping, periodic resets of the controller state, integer reformulations, and FIR controllers, and equip them with a stability and performance analysis to evaluate their suitability. We complement the analysis with a numerical performance comparison on a benchmark system.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.17333v1</guid>
      <category>eess.SY</category>
      <category>cs.CR</category>
      <category>cs.SY</category>
      <category>math.OC</category>
      <pubDate>Tue, 21 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Sebastian Schlor, Frank Allg\"ower</dc:creator>
    </item>
    <item>
      <title>Accelerating Adaptive Systems via Normalized Parameter Estimation Laws</title>
      <link>https://arxiv.org/abs/2510.17371</link>
      <description>arXiv:2510.17371v1 Announce Type: cross 
Abstract: In this paper, we propose a new class of parameter estimation laws for adaptive systems, called \emph{normalized parameter estimation laws}. A key feature of these estimation laws is that they accelerate the convergence of the system state, $\mathit{x(t)}$, to the origin. We quantify this improvement by showing that our estimation laws guarantee finite integrability of the $\mathit{r}$-th root of the squared norm of the system state, i.e., \( \mathit{\|x(t)\|}_2^{2/\mathit{r}} \in \mathcal{L}_1, \) where $\mathit{r} \geq 1$ is a pre-specified parameter that, for a broad class of systems, can be chosen arbitrarily large. In contrast, standard Lyapunov-based estimation laws only guarantee integrability of $\mathit{\|x(t)\|}_2^2$ (i.e., $\mathit{r} = 1$). We motivate our method by showing that, for large values of $r$, this guarantee serves as a sparsity-promoting mechanism in the time domain, meaning that it penalizes prolonged signal duration and slow decay, thereby promoting faster convergence of $\mathit{x(t)}$. The proposed estimation laws do not rely on time-varying or high adaptation gains and do not require persistent excitation. Moreover, they can be applied to systems with matched and unmatched uncertainties, regardless of their dynamic structure, as long as a control Lyapunov function (CLF) exists. Finally, they are compatible with any CLF-based certainty equivalence controllers. We further develop higher-order extensions of our estimation laws by incorporating momentum into the estimation dynamics. We illustrate the performance improvements achieved with the proposed scheme through various numerical experiments.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.17371v1</guid>
      <category>eess.SY</category>
      <category>cs.SY</category>
      <category>math.OC</category>
      <pubDate>Tue, 21 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Mohammad Boveiri, Mohammad Khosravi, Peyman Mohajerin Esfahan</dc:creator>
    </item>
    <item>
      <title>Inverse Optimal Control of Muscle Force Sharing During Pathological Gait</title>
      <link>https://arxiv.org/abs/2510.17456</link>
      <description>arXiv:2510.17456v1 Announce Type: cross 
Abstract: Muscle force sharing is typically resolved by minimizing a specific objective function to approximate neural control strategies. An inverse optimal control approach was applied to identify the "best" objective function, among a positive linear combination of basis objective functions, associated with the gait of two post-stroke males, one high-functioning (subject S1) and one low-functioning (subject S2). It was found that the "best" objective function is subject- and leg-specific. No single function works universally well, yet the best options are usually differently weighted combinations of muscle activation- and power-minimization. Subject-specific inverse optimal control models performed best on their respective limbs (\textbf{RMSE 178/213 N, CC 0.71/0.61} for non-paretic and paretic legs of S1; \textbf{RMSE 205/165 N, CC 0.88/0.85} for respective legs of S2), but cross-subject generalization was poor, particularly for paretic legs. Moreover, minimizing the root mean square of muscle power emerged as important for paretic limbs, while minimizing activation-based functions dominated for non-paretic limbs. This may suggest different neural control strategies between affected and unaffected sides, possibly altered by the presence of spasticity. Among the 15 considered objective functions commonly used in inverse dynamics-based computations, the root mean square of muscle power was the only one explicitly incorporating muscle velocity, leading to a possible model for spasticity in the paretic limbs. Although this objective function has been rarely used, it may be relevant for modeling pathological gait, such as post-stroke gait.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.17456v1</guid>
      <category>physics.med-ph</category>
      <category>cs.RO</category>
      <category>cs.SY</category>
      <category>eess.SY</category>
      <category>math.OC</category>
      <pubDate>Tue, 21 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Filip Be\v{c}anovi\'c, Vincent Bonnet, Kosta Jovanovi\'c, Samer Mohammed, Rapha\"el Dumas</dc:creator>
    </item>
    <item>
      <title>Stochastic Difference-of-Convex Optimization with Momentum</title>
      <link>https://arxiv.org/abs/2510.17503</link>
      <description>arXiv:2510.17503v1 Announce Type: cross 
Abstract: Stochastic difference-of-convex (DC) optimization is prevalent in numerous machine learning applications, yet its convergence properties under small batch sizes remain poorly understood. Existing methods typically require large batches or strong noise assumptions, which limit their practical use. In this work, we show that momentum enables convergence under standard smoothness and bounded variance assumptions (of the concave part) for any batch size. We prove that without momentum, convergence may fail regardless of stepsize, highlighting its necessity. Our momentum-based algorithm achieves provable convergence and demonstrates strong empirical performance.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.17503v1</guid>
      <category>cs.LG</category>
      <category>math.OC</category>
      <category>stat.ML</category>
      <pubDate>Tue, 21 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>El Mahdi Chayti, Martin Jaggi</dc:creator>
    </item>
    <item>
      <title>Convergence Rates for Gradient Descent on the Edge of Stability in Overparametrised Least Squares</title>
      <link>https://arxiv.org/abs/2510.17506</link>
      <description>arXiv:2510.17506v1 Announce Type: cross 
Abstract: Classical optimisation theory guarantees monotonic objective decrease for gradient descent (GD) when employed in a small step size, or ``stable", regime. In contrast, gradient descent on neural networks is frequently performed in a large step size regime called the ``edge of stability", in which the objective decreases non-monotonically with an observed implicit bias towards flat minima. In this paper, we take a step toward quantifying this phenomenon by providing convergence rates for gradient descent with large learning rates in an overparametrised least squares setting. The key insight behind our analysis is that, as a consequence of overparametrisation, the set of global minimisers forms a Riemannian manifold $M$, which enables the decomposition of the GD dynamics into components parallel and orthogonal to $M$. The parallel component corresponds to Riemannian gradient descent on the objective sharpness, while the orthogonal component is a bifurcating dynamical system. This insight allows us to derive convergence rates in three regimes characterised by the learning rate size: (a) the subcritical regime, in which transient instability is overcome in finite time before linear convergence to a suboptimally flat global minimum; (b) the critical regime, in which instability persists for all time with a power-law convergence toward the optimally flat global minimum; and (c) the supercritical regime, in which instability persists for all time with linear convergence to an orbit of period two centred on the optimally flat global minimum.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.17506v1</guid>
      <category>cs.LG</category>
      <category>math.OC</category>
      <pubDate>Tue, 21 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Lachlan Ewen MacDonald, Hancheng Min, Leandro Palma, Salma Tarmoun, Ziqing Xu, Ren\'e Vidal</dc:creator>
    </item>
    <item>
      <title>The complex Ginzburg-Landau equation on a finite interval and chaos suppression via a finite-dimensional boundary feedback stabilizer</title>
      <link>https://arxiv.org/abs/2510.17635</link>
      <description>arXiv:2510.17635v1 Announce Type: cross 
Abstract: In this paper, we study the well-posedness and boundary stabilization of the initial-boundary value problem for the complex Ginzburg-Landau (CGL) equation on a finite interval. First, we establish a local well-posedness theory for the open loop model in $L^2$-based fractional Sobolev spaces in the case of Dirichlet-Neumann type inhomogeneous mixed boundary conditions. This local well-posedness result is based on linear estimates derived by using the weak solution formula obtained via the unified transform (also known as the Fokas method). Next, we study the global well-posedness properties of the open loop model in presence of inhomogeneous boundary conditions. Then, we turn our attention to the rapid boundary feedback stabilization problem and design a nonlocal controller which uses a finite number of Fourier modes of the state of solution. This design relies on the fact that solutions of the CGL equation can be separated into a slow, finite-dimensional component and a rapidly decaying tail, with the former primarily governing long-term behavior. We determine the necessary number of modes required to stabilize the system at a specified rate. Additionally, we identify the minimum number of modes that ensure stabilization at an unspecified decay rate. These theoretical results are validated by numerical simulations. The spatiotemporal estimates established in the first part of the paper are also employed to obtain local solutions of the controlled system. The existence of global energy solutions follows from stabilization estimates, while uniqueness follows from the uniqueness of an associated initial-boundary value problem with homogeneous boundary conditions whose solutions are in correspondence with the solutions of the original system through a bounded invertible Volterra-type integral transform on Sobolev spaces.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.17635v1</guid>
      <category>math.AP</category>
      <category>math.OC</category>
      <pubDate>Tue, 21 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Dionyssios Mantzavinos, T\"urker \"Ozsar{\i}, Kemal Cem Y{\i}lmaz</dc:creator>
    </item>
    <item>
      <title>Nonlinear Rayleigh quotient optimization</title>
      <link>https://arxiv.org/abs/2510.17760</link>
      <description>arXiv:2510.17760v1 Announce Type: cross 
Abstract: Rayleigh quotient minimization deals with optimizing a quadratic homogeneous function over a sphere. Its critical points correspond to the normalized eigenvectors of the symmetric matrix associated with the quadratic form. In this paper, we consider a homogeneous polynomial objective function $f$ over a sphere, a projective algebraic variety $X$, and we study the $X$-eigenpoints of $f$, which are classes of critical points of $f$ constrained to the sphere and the affine cone over $X$. The number of $X$-eigenpoints of a generic polynomial $f$ is the Rayleigh-Ritz degree of $X$. This invariant is a version of the Euclidean distance degree of a Veronese embedding of $X$. We provide concrete formulas in various scenarios, including those involving varieties of rank-one tensors.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.17760v1</guid>
      <category>math.AG</category>
      <category>math.OC</category>
      <pubDate>Tue, 21 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Flavio Salizzoni, Luca Sodomaco, Julian Weigert</dc:creator>
    </item>
    <item>
      <title>Unbiased Gradient Low-Rank Projection</title>
      <link>https://arxiv.org/abs/2510.17802</link>
      <description>arXiv:2510.17802v1 Announce Type: cross 
Abstract: Memory-efficient optimization is critical for training increasingly large language models (LLMs). A popular strategy involves gradient low-rank projection, storing only the projected optimizer states, with GaLore being a representative example. However, a significant drawback of many such methods is their lack of convergence guarantees, as various low-rank projection approaches introduce inherent biases relative to the original optimization algorithms, which contribute to performance gaps compared to full-parameter training. Aiming to tackle this problem, this paper investigates the layerwise sampling technique for debiasing low-rank projection mechanisms. In particular, an instantiation of the paradigm gives rise to a novel and unbiased low-rank optimization method built upon GaLore's mechanism and the Muon algorithm, named GaLore Unbiased with Muon (GUM). We theoretically prove our method matches the convergence guarantees of the base Muon algorithm while preserving the memory efficiency of low-rank techniques. Empirical experiments on LLM fine-tuning and pretraining also demonstrate non-trivial improvements over GaLore and even better performance than full-parameter training. Further investigation shows that the improvement of this technique comes from a more uniform distribution of knowledge inside layers, leading to more efficient utilization of the model parameter space and better memorization.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.17802v1</guid>
      <category>cs.LG</category>
      <category>cs.AI</category>
      <category>math.OC</category>
      <pubDate>Tue, 21 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Rui Pan, Yang Luo, Yuxing Liu, Yang You, Tong Zhang</dc:creator>
    </item>
    <item>
      <title>The Complexity of Recognizing Facets for the Knapsack Polytope</title>
      <link>https://arxiv.org/abs/2211.03311</link>
      <description>arXiv:2211.03311v3 Announce Type: replace 
Abstract: The complexity class DP is the class of all languages that are the intersection of a language in NP and a language in coNP. It was conjectured that recognizing a facet for the knapsack polytope is DP-complete. We provide a positive answer to this conjecture. Moreover, despite the \DP-hardness of the recognition problem, we give a polynomial time algorithm for deciding if an inequality with a fixed number of distinct coefficients defines a facet of a knapsack polytope.</description>
      <guid isPermaLink="false">oai:arXiv.org:2211.03311v3</guid>
      <category>math.OC</category>
      <category>cs.CC</category>
      <pubDate>Tue, 21 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Rui Chen, Haoran Zhu</dc:creator>
    </item>
    <item>
      <title>Zeroth-order Gradient and Quasi-Newton Methods for Nonsmooth Nonconvex Stochastic Optimization</title>
      <link>https://arxiv.org/abs/2401.08665</link>
      <description>arXiv:2401.08665v3 Announce Type: replace 
Abstract: We consider the minimization of a Lipschitz continuous and expectation-valued function, denoted by $f$ and defined as $f(\mathbf{x}) \triangleq \mathbb{E}[\tilde{f}(\mathbf{x}, \mathbf{\xi})]$, over a closed and convex set $\mathcal{X}$. We obtain asymptotics as well as rate and complexity guarantees for computing approximate Clarke-stationary points via zeroth-order schemes. We adopt an approach reliant on minimizing $f_{\eta}$ where $f_{\eta}(\mathbf{x}) \triangleq \mathbb{E}_{\mathbf{u}}\left[\mathbf{x}, f(\mathbf{x}+\eta \mathbf{u})\, \right]$, $\mathbf{u}$ is a random variable defined on a unit sphere, and $\eta &gt; 0$. In fact, it is known that a stationary point of the $\eta$-smoothed problem is an $\eta$-stationary point for the original problem in the Clarke sense. In such a setting, we develop two schemes with promising empirical behavior. (I) We develop a variance-reduced zeroth-order gradient framework (VRG-ZO) for minimizing $f_{\eta}$ over $\mathcal{X}$. In this setting, we make two sets of contributions for the sequence generated by the proposed zeroth-order gradient scheme. (a) The residual function of the smoothed problem tends to zero almost surely along the generated sequence, guaranteeing $\eta$-Clarke stationary solutions of the original problem; (b) To compute an $\mathbf{x}$ such that the expected norm of the residual of the $\eta$-smoothed problem is within $\epsilon$ requires no greater than $\mathcal{O}({n^{1/2}}{(L_0\eta^{-1} +L_0^2)} \epsilon^{-2})$ projection steps and $\mathcal{O}({n^{3/2}(L_0^3\eta^{-2}+L_0^5)} \epsilon^{-4})$ function evaluations. (II) Our second scheme is a zeroth-order stochastic quasi-Newton scheme (VRSQN-ZO) reliant on randomized and Moreau smoothing; the iteration and sample complexities are $\mathcal{O}({L_0^{4}}{n^{2}}{\eta^{-4}}\epsilon^{-2})$ and $\mathcal{O}(L_0^{9} n^{5}\eta^{-5}\epsilon^{-5})$, respectively.</description>
      <guid isPermaLink="false">oai:arXiv.org:2401.08665v3</guid>
      <category>math.OC</category>
      <pubDate>Tue, 21 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Luke Marrinan, Uday V. Shanbhag, Farzad Yousefian</dc:creator>
    </item>
    <item>
      <title>Chebyshev centers and radii for sets induced by quadratic matrix inequalities</title>
      <link>https://arxiv.org/abs/2403.05315</link>
      <description>arXiv:2403.05315v4 Announce Type: replace 
Abstract: This paper studies sets of matrices induced by quadratic inequalities. In particular, the center and radius of a smallest ball containing the set, called a Chebyshev center and the Chebyshev radius, are studied. In addition, this work studies the diameter of the set, which is the farthest distance between any two elements of the set. Closed-form solutions are provided for a Chebyshev center, the Chebyshev radius, and the diameter of sets induced by quadratic matrix inequalities (QMIs) with respect to arbitrary unitarily invariant norms. Examples of these norms include the Frobenius norm, spectral norm, nuclear norm, Schatten p-norms, and Ky Fan k-norms. In addition, closed-form solutions are presented for the radius of the largest ball within a QMI-induced set. Finally, the paper discusses applications of the presented results in data-driven modeling and control.</description>
      <guid isPermaLink="false">oai:arXiv.org:2403.05315v4</guid>
      <category>math.OC</category>
      <pubDate>Tue, 21 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <arxiv:DOI>10.1007/s00498-025-00424-w</arxiv:DOI>
      <dc:creator>Amir Shakouri, Henk J. van Waarde, M. Kanat Camlibel</dc:creator>
    </item>
    <item>
      <title>Cut-based Conflict Analysis in Mixed Integer Programming</title>
      <link>https://arxiv.org/abs/2410.15110</link>
      <description>arXiv:2410.15110v2 Announce Type: replace 
Abstract: For almost two decades, mixed integer programming (MIP) solvers have used graph-based conflict analysis to learn from local infeasibilities during branch-and-bound search. In this paper, we improve MIP conflict analysis by instead using reasoning based on cuts, inspired by the development of conflict-driven solvers for pseudo-Boolean optimization. Phrased in MIP terminology, this type of conflict analysis can be understood as a sequence of linear combinations, integer roundings, and cut generation. We leverage this MIP perspective to design a new conflict analysis algorithm based on mixed integer rounding cuts, which theoretically dominates the state-of-the-art method in pseudo-Boolean optimization using Chv\'atal-Gomory cuts. Furthermore, we extend this cut-based conflict analysis from pure binary programs to mixed binary programs and-in limited form-to general MIP with also integer-valued variables. We perform an empirical evaluation of cut-based conflict analysis as implemented in the open-source MIP solver SCIP, testing it on a large and diverse set of MIP instances from MIPLIB 2017. Our experimental results indicate that the new algorithm improves the default performance of SCIP in terms of running time, number of nodes in the search tree, and the number of instances solved.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.15110v2</guid>
      <category>math.OC</category>
      <pubDate>Tue, 21 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Gioni Mexi, Felipe Serrano, Timo Berthold, Ambros Gleixner, Jakob Nordstr\"om</dc:creator>
    </item>
    <item>
      <title>Robust Stochastic Optimal Control via variance penalization: Application to Energy Management Systems</title>
      <link>https://arxiv.org/abs/2411.02015</link>
      <description>arXiv:2411.02015v4 Announce Type: replace 
Abstract: This paper addresses a class of robust stochastic optimal control problems. Its main contribution lies in the introduction of a general optimization model with variance penalization and an associated solution algorithm that improves out-of-sample robustness while preserving numerical complexity. The proposed variance-penalized model is inspired by a well-established machine learning practice that aims to limit overfitting and extends this idea to stochastic optimal control. Using the Douglas--Rachford splitting method, the authors develop a Variance-Penalized Progressive Hedging Algorithm (VPPHA) that retains the computational complexity of the standard PHA while achieving superior out-of-sample performance. In addition, the authors propose a three-step control framework comprising (i) a random scenario generation method, (ii) a scenario reduction algorithm, and (iii) a scenario-based optimal control computation using the VPPHA. Finally, the proposed method is validated through simulations of a stationary battery Energy Management System (EMS) using ground-truth electricity consumption and production measurements from a predominantly commercial building in Solaize, France. The results demonstrate that the proposed approach outperforms a classical Model Predictive Control (MPC) strategy, which itself performs better than the standard PHA.</description>
      <guid isPermaLink="false">oai:arXiv.org:2411.02015v4</guid>
      <category>math.OC</category>
      <pubDate>Tue, 21 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Paul Malisani (IFPEN), Adrien Spagnol (IFPEN), Vivien Smis-Michel (IFPEN)</dc:creator>
    </item>
    <item>
      <title>Scaled Relative Graphs for Nonmonotone Operators with Applications in Circuit Theory</title>
      <link>https://arxiv.org/abs/2411.17419</link>
      <description>arXiv:2411.17419v2 Announce Type: replace 
Abstract: The scaled relative graph (SRG) is a powerful graphical tool for analyzing the properties of operators, by mapping their graph onto the complex plane. In this work, we study the SRG of two classes of nonmonotone operators, namely the general class of semimonotone operators and a class of angle-bounded operators. In particular, we provide an analytical description of the SRG of these classes and show that membership of an operator to these classes can be verified through geometric containment of its SRG. To illustrate the importance of these results, we provide several examples in the context of electrical circuits. Most notably, we show that the Ebers-Moll transistor belongs to the class of angle-bounded operators and use this result to compute the response of a common-emitter amplifier using Chambolle-Pock, despite the underlying nonsmoothness and multi-valuedness, leveraging recent convergence results for this algorithm in the nonmonotone setting.</description>
      <guid isPermaLink="false">oai:arXiv.org:2411.17419v2</guid>
      <category>math.OC</category>
      <pubDate>Tue, 21 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <arxiv:DOI>10.1016/j.ejcon.2025.101335</arxiv:DOI>
      <dc:creator>Jan Quan, Brecht Evens, Rodolphe Sepulchre, Panagiotis Patrinos</dc:creator>
    </item>
    <item>
      <title>Optimizing Image Retrieval with an Extended b-Metric Space</title>
      <link>https://arxiv.org/abs/2411.18800</link>
      <description>arXiv:2411.18800v2 Announce Type: replace 
Abstract: This article provides a new approach on how to enhance data storage and retrieval in the Query By Image Content Systems (QBIC) by introducing the ${\rm NEM}_{\sigma}$ distance measure, satisfying the relaxed triangle inequality. By leveraging the concept of extended $b$-metric spaces, we address complex distance relationships, thereby improving the accuracy and efficiency of image database management. The use of ${\rm NEM}_{\sigma}$ facilitates better scalability and accuracy in large-scale image retrieval systems, optimizing both the storage and retrieval processes. The proposed method represents a significant advancement over traditional distance measures, offering enhanced flexibility and precision in the context of image content-based querying. Additionally, we take inspiration from ice flow models using ${\rm NEM}_{\sigma}$ and ${\rm NEM}_r$, adding dynamic and location-based factors to better capture details in images.</description>
      <guid isPermaLink="false">oai:arXiv.org:2411.18800v2</guid>
      <category>math.OC</category>
      <category>math.MG</category>
      <pubDate>Tue, 21 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Abdelkader Belhenniche, Roman Chertovskih</dc:creator>
    </item>
    <item>
      <title>Improved Approximation Algorithms for Low-Rank Problems Using Semidefinite Optimization</title>
      <link>https://arxiv.org/abs/2501.02942</link>
      <description>arXiv:2501.02942v2 Announce Type: replace 
Abstract: Inspired by the impact of the Goemans-Williamson algorithm on combinatorial optimization, we construct an analogous relax-then-round strategy for low-rank optimization problems. First, for orthogonally constrained quadratic optimization problems, we derive a semidefinite relaxation and a randomized rounding scheme that obtains provably near-optimal solutions, building on the blueprint from Goemans and Williamson for the Max-Cut problem. For a given $n \times m$ semi-orthogonal matrix, we derive a purely multiplicative approximation ratio for our algorithm, and show that it is never worse than $\max(2/(\pi m), 1/(\pi(\log (2m)+1)))$. We also show how to compute a tighter constant for a finite $(n,m)$ by solving a univariate optimization problem. We then extend our approach to generic low-rank optimization problems by developing new semidefinite relaxations that are both tighter and more broadly applicable than those in prior works. Although our original proposal introduces large semidefinite matrices as decision variables, we show that most of the blocks in these matrices can be safely omitted without altering the optimal value, hence improving the scalability of our approach. Using several examples (including matrix completion, basis pursuit, and reduced-rank regression), we show how to reduce the size of our relaxation even further. Finally, we numerically illustrate the effectiveness and scalability of our relaxation and sampling scheme on orthogonally constrained quadratic optimization and matrix completion problems.</description>
      <guid isPermaLink="false">oai:arXiv.org:2501.02942v2</guid>
      <category>math.OC</category>
      <category>cs.LG</category>
      <category>math.PR</category>
      <pubDate>Tue, 21 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Ryan Cory-Wright, Jean Pauphilet</dc:creator>
    </item>
    <item>
      <title>A new separable property of the joint numerical range of quadratic functions and its applications to the Smallest Enclosing Ball Problem</title>
      <link>https://arxiv.org/abs/2501.15399</link>
      <description>arXiv:2501.15399v2 Announce Type: replace 
Abstract: We explore separable property of the joint numerical range $G(\Bbb R^n)$ of a special class of quadratic functions and apply it to solving the smallest enclosing ball (SEB) problem which asks to find a ball $B(a,r)$ in $\Bbb R^n$ with smallest radius $r$ such that $B(a,r)$ contains the intersection $\cap_{i=1}^mB(a_i,r_i)$ of $m$ given balls $B(a_i,r_i).$ We show that $G(\Bbb R^n)$ is convex if and only if ${\rm rank}\{a_1-a, a_2-a, \ldots, a_m-a\}\le n-1.$ Otherwise, ${\rm rank}\{a_1-a, a_2-a, \ldots, a_m-a\}=n$ and $G(\Bbb R^n)$ is not convex. In this case we propose a new set $G(\Bbb R^n)^\bullet$ which allows to show that if $m=n$ then $G(\Bbb R^n)^\bullet$ is convex even $G(\Bbb R^n)$ is not. Importantly, the separable property of $G(\Bbb R^n)^\bullet$ then implies the separable property for $G(\Bbb R^n).$ As a result, a new progress on solving the SEB problem is obtained.</description>
      <guid isPermaLink="false">oai:arXiv.org:2501.15399v2</guid>
      <category>math.OC</category>
      <pubDate>Tue, 21 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Van-Bong Nguyen, Huu-Quang Nguyen</dc:creator>
    </item>
    <item>
      <title>Triangle Steepest Descent: A Geometry-Based Gradient Algorithm with Guaranteed R-Linear Convergence</title>
      <link>https://arxiv.org/abs/2501.16731</link>
      <description>arXiv:2501.16731v2 Announce Type: replace 
Abstract: Gradient methods are among the simplest yet most widely used algorithms for unconstrained optimization. Motivated by a geometric property of the steepest descent (SD) method that can alleviate the zigzag behavior in quadratic problems, we develop a new gradient variant called the Triangle Steepest Descent (TSD) method. The TSD method introduces a cycle parameter $j$ that governs the periodic combination of past search directions, providing a geometry-driven mechanism to enhance convergence. To the best of our knowledge, TSD is the first formally established geometry-based gradient scheme since Akaike (1959). We prove that TSD is at least R-linearly convergent for strongly convex quadratic problems and demonstrate through extensive numerical experiments that it exhibits superlinear behavior, outperforming the Barzilai-Borwein (BB) method and monotone Dai-Yuan gradient method (DY) in quadratic cases. These results suggest that incorporating geometric information into gradient directions offers a promising avenue for developing efficient optimization algorithms.</description>
      <guid isPermaLink="false">oai:arXiv.org:2501.16731v2</guid>
      <category>math.OC</category>
      <pubDate>Tue, 21 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Ya Shen, Qing-Na Li, Yu-Hong Dai</dc:creator>
    </item>
    <item>
      <title>Bilevel gradient methods and the Morse parametric qualification condition</title>
      <link>https://arxiv.org/abs/2502.09074</link>
      <description>arXiv:2502.09074v2 Announce Type: replace 
Abstract: We introduce the Morse parametric qualification condition for bilevel programming. Generic semi-algebraic functions are Morse parametric in a piecewise sense. Thus, bilevel programs with a Morse parametric lower level constitute a relevant intermediate class between strongly convex and fully generic lower levels. In this framework, we study bilevel gradient algorithms with two strategies: the single-step multi-step strategy, which involves a sequence of steps on the lower-level problems followed by one step on the upper-level problem, and a differentiable programming strategy that optimizes a smooth approximation of the bilevel problem. While the first is shown to be a biased gradient method on the problem with rich properties, the second, inspired by meta-learning applications, is less stable but offers simplicity and ease of implementation.</description>
      <guid isPermaLink="false">oai:arXiv.org:2502.09074v2</guid>
      <category>math.OC</category>
      <pubDate>Tue, 21 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>J\'er\^ome Bolte (TSE-R), Quoc-Tung Le (TSE-R, ANITI), Edouard Pauwels (CNRS, IRIT-ADRIA), Samuel Vaiter (CNRS, LJAD)</dc:creator>
    </item>
    <item>
      <title>Subgradient Method for System Identification with Non-Smooth Objectives</title>
      <link>https://arxiv.org/abs/2503.16673</link>
      <description>arXiv:2503.16673v2 Announce Type: replace 
Abstract: This paper investigates a subgradient-based algorithm to solve the system identification problem for linear time-invariant systems with non-smooth objectives. This is essential for robust system identification in safety-critical applications. While existing work provides theoretical exact recovery guarantees using optimization solvers, the design of fast learning algorithms with convergence guarantees for practical use remains unexplored. We analyze the subgradient method in this setting, where the optimization problems to be solved evolve over time as new measurements are collected, and we establish linear convergence to the ground-truth system for both the best and Polyak step sizes after a burn-in period. We further characterize sublinear convergence of the iterates under constant and diminishing step sizes, which require only minimal information and thus offer broad applicability. Finally, we compare the time complexity of standard solvers with the subgradient algorithm and support our findings with experimental results. This is the first work to analyze subgradient algorithms for system identification with non-smooth objectives.</description>
      <guid isPermaLink="false">oai:arXiv.org:2503.16673v2</guid>
      <category>math.OC</category>
      <category>cs.CC</category>
      <category>cs.LG</category>
      <category>cs.SY</category>
      <category>eess.SY</category>
      <pubDate>Tue, 21 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Baturalp Yalcin, Jihun Kim, Javad Lavaei</dc:creator>
    </item>
    <item>
      <title>Forward-backward splitting in bilaterally bounded Alexandrov spaces</title>
      <link>https://arxiv.org/abs/2503.24126</link>
      <description>arXiv:2503.24126v2 Announce Type: replace 
Abstract: With the goal of solving optimisation problems on non-Riemannian manifolds, such as geometrical surfaces with sharp edges, we develop and prove the convergence of a forward-backward method in Alexandrov spaces with curvature bounded both from above and from below. This bilateral boundedness is crucial for the availability of both the gradient and proximal steps, instead of just one or the other. We numerically demonstrate the behaviour of the proposed method on simple geometrical surfaces in $\mathbb{R}^3$.</description>
      <guid isPermaLink="false">oai:arXiv.org:2503.24126v2</guid>
      <category>math.OC</category>
      <category>math.DG</category>
      <pubDate>Tue, 21 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Heikki von Koch, Tuomo Valkonen</dc:creator>
    </item>
    <item>
      <title>Distributed Solving of Linear Quadratic Optimal Controller with Terminal State Constraint</title>
      <link>https://arxiv.org/abs/2504.05631</link>
      <description>arXiv:2504.05631v4 Announce Type: replace 
Abstract: This paper is concerned with the linear quadratic (LQ) optimal control of continuous-time system with terminal state constraint. In particular, multiple agents exist in the system which can only access partial information of the matrix parameters. This makes the classical solving method based on Riccati equation with global information suffering. The main contribution is to present a distributed algorithm to derive the optimal controller which is consisting of the distributed iterations for the Riccati equation, a backward differential equation driven by the optimal Lagrange multiplier and the optimal state. Furthermore, the proposed distributed iteration method is extended to solve the consensus control problem for heterogeneous multi-agent systems, achieving the globally optimal performance of the system. The effectiveness of the proposed algorithm is verified by two numerical examples, where the performance index under the proposed distributed controller is smaller than that under the commonly used consensus control.</description>
      <guid isPermaLink="false">oai:arXiv.org:2504.05631v4</guid>
      <category>math.OC</category>
      <pubDate>Tue, 21 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Wenjing Yang, Zhaorong Zhang, Juanjuan Xu</dc:creator>
    </item>
    <item>
      <title>Warehouse storage and retrieval optimization via clustering, dynamical systems modeling, and GPU-accelerated routing</title>
      <link>https://arxiv.org/abs/2504.20655</link>
      <description>arXiv:2504.20655v2 Announce Type: replace 
Abstract: This paper introduces a warehouse optimization procedure aimed at enhancing the efficiency of product storage and retrieval. By representing product locations and order flows within a time-evolving graph structure, we employ unsupervised clustering to define and refine compact order regions, effectively reducing picking distances. We describe the procedure using a dynamic mathematical model formulated using tools from random dynamical systems theory, enabling a principled analysis of the system's behavior over time even under random operational variations. For routing within this framework, we implement a parallelized Bellman-Ford algorithm, utilizing GPU acceleration to evaluate path segments efficiently. To address scalability challenges inherent in large routing graphs, we introduce a segmentation strategy that preserves performance while maintaining tractable memory requirements. Our results demonstrate significant improvements in both operational efficiency and computational feasibility for large-scale warehouse environments.</description>
      <guid isPermaLink="false">oai:arXiv.org:2504.20655v2</guid>
      <category>math.OC</category>
      <category>cs.DS</category>
      <category>math.DS</category>
      <pubDate>Tue, 21 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Magnus Bengtsson, Jens Wittsten, Jonas Waidringer</dc:creator>
    </item>
    <item>
      <title>Agency Problems and Adversarial Bilevel Optimization under Uncertainty and Cyber Threats</title>
      <link>https://arxiv.org/abs/2505.08989</link>
      <description>arXiv:2505.08989v4 Announce Type: replace 
Abstract: We study an agency problem between a holding company and its subsidiary, exposed to cyber threats that affect the overall value of the subsidiary. The holding company seeks to design an optimal incentive scheme to mitigate these losses. In response, the subsidiary selects an optimal cybersecurity investment strategy, modeled through a stochastic epidemiological SIR (Susceptible-Infected-Recovered) framework. The cyber threat landscape is captured through an L-hop risk framework with two primary sources of risk: (i) internal risk propagation via the contagion parameters in the SIR model, and (ii) external cyberattacks from a malicious external hacker. The uncertainty and adversarial nature of the hacking lead to consider a robust stochastic control approach that allows for increased volatility and ambiguity induced by cyber incidents. The agency problem is formulated as a max-min bilevel stochastic control problem with accidents. First, we derive the incentive compatibility condition by reducing the subsidiary's optimal response to the solution of a second-order backward stochastic differential equation with jumps. Next, we demonstrate that the principal's problem can be equivalently reformulated as an integro-partial Hamilton-Jacobi-Bellman-Isaacs (HJBI) equation. By extending the stochastic Perron's method to our setting, we show that the value function of the problem is the unique viscosity solution to the resulting integro-partial HJBI equation.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.08989v4</guid>
      <category>math.OC</category>
      <category>math.PR</category>
      <pubDate>Tue, 21 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Thibaut Mastrolia, Haoze Yan</dc:creator>
    </item>
    <item>
      <title>A line search framework with restarting for noisy optimization problems</title>
      <link>https://arxiv.org/abs/2506.03358</link>
      <description>arXiv:2506.03358v2 Announce Type: replace 
Abstract: Nonlinear optimization methods are typically iterative and make use of gradient information to determine a direction of improvement and function information to effectively check for progress. When this information is corrupted by noise, designing a convergent and practical algorithmic process becomes challenging, as care must be taken to avoid taking bad steps due to erroneous information. For this reason, simple gradient-based schemes have been quite popular, despite being outperformed by more advanced techniques in the noiseless setting. In this paper, we propose a general algorithmic framework based on line search that is endowed with iteration and evaluation complexity guarantees even in a noisy setting. These guarantees are obtained as a result of a restarting condition, that monitors desirable properties for the steps taken at each iteration and can be checked even in the presence of noise. Experiments using a nonlinear conjugate gradient variant and a quasi-Newton variant illustrate that restarting can be performed without compromising practical efficiency and robustness.</description>
      <guid isPermaLink="false">oai:arXiv.org:2506.03358v2</guid>
      <category>math.OC</category>
      <pubDate>Tue, 21 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <dc:creator>Albert S. Berahas, Michael J. O'Neill, Cl\'ement W. Royer</dc:creator>
    </item>
    <item>
      <title>Exact penalty functions in optimization with unbounded constraint sets</title>
      <link>https://arxiv.org/abs/2507.03424</link>
      <description>arXiv:2507.03424v2 Announce Type: replace 
Abstract: This paper identifies necessary and sufficient conditions for the exactness of penalty functions in optimization problems whose constraint sets are not necessarily bounded. The case where the data of problems is locally Lipschitz, semi-algebraic or non-degenerate polynomials is studied in detail. The conditions are given in terms of properties of the objective and residual functions of the problems in question. The obtained results generalize and improve some known results in the literature on exact penalty functions.</description>
      <guid isPermaLink="false">oai:arXiv.org:2507.03424v2</guid>
      <category>math.OC</category>
      <pubDate>Tue, 21 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Liguo Jiao, Tien-Son Pham, Nguyen Van Tuyen</dc:creator>
    </item>
    <item>
      <title>A fast algorithm for solving the lasso problem exactly without homotopy using differential inclusions</title>
      <link>https://arxiv.org/abs/2507.05562</link>
      <description>arXiv:2507.05562v2 Announce Type: replace 
Abstract: We prove in this work that the well-known lasso problem can be solved exactly without homotopy using novel differential inclusions techniques. Specifically, we show that a selection principle from the theory of differential inclusions transforms the dual lasso problem into the problem of calculating the trajectory of a projected dynamical system that we prove is integrable. Our analysis yields an exact algorithm for the lasso problem, numerically up to machine precision, that is amenable to computing regularization paths and is very fast. Moreover, we show the continuation of solutions to the integrable projected dynamical system in terms of the hyperparameter naturally yields a rigorous homotopy algorithm. Numerical experiments confirm that our algorithm outperforms the state-of-the-art algorithms in both efficiency and accuracy. Beyond this work, we expect our results and analysis can be adapted to compute exact or approximate solutions to a broader class of polyhedral-constrained optimization problems.</description>
      <guid isPermaLink="false">oai:arXiv.org:2507.05562v2</guid>
      <category>math.OC</category>
      <category>cs.LG</category>
      <category>math.FA</category>
      <pubDate>Tue, 21 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Gabriel P. Langlois, J\'er\^ome Darbon</dc:creator>
    </item>
    <item>
      <title>Popov Mirror-Prox Method for Variational Inequalities</title>
      <link>https://arxiv.org/abs/2507.23395</link>
      <description>arXiv:2507.23395v2 Announce Type: replace 
Abstract: This paper establishes the convergence properties of the Popov mirror-prox algorithm for solving stochastic and deterministic variational inequalities (VIs) under a polynomial growth condition on the mapping variation. Unlike existing methods that require prior knowledge of problem-specific parameters, we propose step-size schemes that are entirely parameter-free in both constant and diminishing forms. For stochastic and deterministic monotone VIs, we establish optimal convergence rates in terms of the dual gap function over a bounded constraint set. Additionally, for deterministic VIs with H\"older continuous mapping, we prove convergence in terms of the residual function without requiring a bounded set or a monotone mapping, provided a Minty solution exists. This allows our method to address certain classes of non-monotone VIs. However, knowledge of the H\"older exponent is necessary to achieve the best convergence rates in this case. By extending mirror-prox techniques to mappings with arbitrary polynomial growth, our work bridges an existing gap in the literature. We validate our theoretical findings with empirical results on matrix games, piecewise quadratic functions, and image classification tasks using ResNet-18.</description>
      <guid isPermaLink="false">oai:arXiv.org:2507.23395v2</guid>
      <category>math.OC</category>
      <pubDate>Tue, 21 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Abhishek Chakraborty, Angelia Nedi\'c</dc:creator>
    </item>
    <item>
      <title>A Frank-Wolfe-based primal heuristic for quadratic mixed-integer optimization</title>
      <link>https://arxiv.org/abs/2508.01299</link>
      <description>arXiv:2508.01299v2 Announce Type: replace 
Abstract: We propose a primal heuristic for quadratic mixed-integer problems. Our method extends the Boscia framework -- originally a mixed-integer convex solver leveraging a Frank-Wolfe-based branch-and-bound approach -- to address nonconvex quadratic objective and constraints. We reformulate nonlinear constraints, introduce preprocessing steps, and a suite of heuristics including rounding strategies, gradient-guided selection, and large neighborhood search techniques that exploit integer-feasible vertices generated during the Frank-Wolfe iterations. Computational results demonstrate the effectiveness of our method in solving challenging MIQCQPs, achieving improvements on QPLIB instances within minutes and winning first place in the Land-Doig MIP Computational Competition 2025.</description>
      <guid isPermaLink="false">oai:arXiv.org:2508.01299v2</guid>
      <category>math.OC</category>
      <pubDate>Tue, 21 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Gioni Mexi, Deborah Hendrych, S\'ebastien Designolle, Mathieu Besan\c{c}on, Sebastian Pokutta</dc:creator>
    </item>
    <item>
      <title>Digital Twins: McKean-Pontryagin Control for Partially Observed Physical Twins</title>
      <link>https://arxiv.org/abs/2510.00937</link>
      <description>arXiv:2510.00937v2 Announce Type: replace 
Abstract: Optimal control for fully observed diffusion processes is well established and has led to numerous numerical implementations based on, for example, Bellman's principle, model free reinforcement learning, Pontryagin's maximum principle, and model predictive control. On the contrary, much fewer algorithms are available for optimal control of partially observed processes. However, this scenario is central to the digital twin paradigm where a physical twin is partially observed and control laws are derived based on a digital twin. In this paper, we contribute to this challenge by combining data assimilation in the form of the ensemble Kalman filter with the recently proposed McKean-Pontryagin approach to stochastic optimal control. We derive forward evolving mean-field evolution equations for states and co-states which simultaneously allow for an online assimilation of data as well as an online computation of control laws. The proposed methodology is therefore perfectly suited for real time applications of digital twins. We present numerical results for a controlled Lorenz-63 system and an inverted pendulum.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.00937v2</guid>
      <category>math.OC</category>
      <category>cs.NA</category>
      <category>math.NA</category>
      <pubDate>Tue, 21 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Manfred Opper, Sebastian Reich</dc:creator>
    </item>
    <item>
      <title>A unified optimal control framework: time-optimal control and stochastic optimal control</title>
      <link>https://arxiv.org/abs/2510.07765</link>
      <description>arXiv:2510.07765v2 Announce Type: replace 
Abstract: In this paper, we propose a unified stochastic optimal control framework that integrates time-optimal control problems with classical stochastic optimal control formulations. Unlike conventional deterministic time-optimal control models, our approach incorporates a generalized stochastic control structure subject to minimum-time constraints. In this setting, the minimum-time condition is defined as the earliest achievable moment-in expectation-for reaching a target state, making the terminal time an endogenous and control-dependent variable. The main contributions of this work are twofold: first, we derive an extended stochastic maximum principle for the proposed model; second, we establish a bang-bang type optimal control for the linear time-optimal control problem. This unified stochastic optimal control framework facilitates the design of optimal strategies across diverse fields-such as finance, autonomous systems, and supply chain management-by enabling simultaneous minimization of operational costs and achievement of statistically-defined targets at the earliest feasible time. As an application, we solve a financial portfolio optimization problem within the proposed framework.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.07765v2</guid>
      <category>math.OC</category>
      <pubDate>Tue, 21 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Shuzhen Yang</dc:creator>
    </item>
    <item>
      <title>Identification and Adaptive Control of Markov Jump Systems: Sample Complexity and Regret Bounds</title>
      <link>https://arxiv.org/abs/2111.07018</link>
      <description>arXiv:2111.07018v2 Announce Type: replace-cross 
Abstract: Learning how to effectively control unknown dynamical systems is crucial for intelligent autonomous systems. This task becomes a significant challenge when the underlying dynamics are changing with time. Motivated by this challenge, this paper considers the problem of controlling an unknown Markov jump linear system (MJS) to optimize a quadratic objective. By taking a model-based perspective, we consider identification-based adaptive control of MJSs. We first provide a system identification algorithm for MJS to learn the dynamics in each mode as well as the Markov transition matrix, underlying the evolution of the mode switches, from a single trajectory of the system states, inputs, and modes. Through martingale-based arguments, sample complexity of this algorithm is shown to be $\mathcal{O}(1/\sqrt{T})$. We then propose an adaptive control scheme that performs system identification together with certainty equivalent control to adapt the controllers in an episodic fashion. Combining our sample complexity results with recent perturbation results for certainty equivalent control, we prove that when the episode lengths are appropriately chosen, the proposed adaptive control scheme achieves $\mathcal{O}(\sqrt{T})$ regret, which can be improved to $\mathcal{O}(polylog(T))$ with partial knowledge of the system. Our proof strategy introduces innovations to handle Markovian jumps and a weaker notion of stability common in MJSs. Our analysis provides insights into system theoretic quantities that affect learning accuracy and control performance. Numerical simulations are presented to further reinforce these insights.</description>
      <guid isPermaLink="false">oai:arXiv.org:2111.07018v2</guid>
      <category>cs.LG</category>
      <category>cs.SY</category>
      <category>eess.SY</category>
      <category>math.OC</category>
      <category>stat.ML</category>
      <pubDate>Tue, 21 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Yahya Sattar, Zhe Du, Davoud Ataee Tarzanagh, Laura Balzano, Necmiye Ozay, Samet Oymak</dc:creator>
    </item>
    <item>
      <title>Graph Neural Networks for the Offline Nanosatellite Task Scheduling Problem</title>
      <link>https://arxiv.org/abs/2303.13773</link>
      <description>arXiv:2303.13773v4 Announce Type: replace-cross 
Abstract: This study investigates how to schedule nanosatellite tasks more efficiently using Graph Neural Networks (GNNs). In the Offline Nanosatellite Task Scheduling (ONTS) problem, the goal is to find the optimal schedule for tasks to be carried out in orbit while taking into account Quality-of-Service (QoS) considerations such as priority, minimum and maximum activation events, execution time-frames, periods, and execution windows, as well as constraints on the satellite's power resources and the complexity of energy harvesting and management. The ONTS problem has been approached using conventional mathematical formulations and exact methods, but their applicability to challenging cases of the problem is limited. This study examines the use of GNNs in this context, which has been effectively applied to optimization problems such as the traveling salesman, scheduling, and facility placement problems. More specifically, we investigate whether GNNs can learn the complex structure of the ONTS problem with respect to feasibility and optimality of candidate solutions. Furthermore, we evaluate using GNN-based heuristic solutions to provide better solutions (w.r.t. the objective value) to the ONTS problem and reduce the optimization cost. Our experiments show that GNNs are not only able to learn feasibility and optimality for instances of the ONTS problem, but they can generalize to harder instances than those seen during training. Furthermore, the GNN-based heuristics improved the expected objective value of the best solution found under the time limit in 45%, and reduced the expected time to find a feasible solution in 35%, when compared to the SCIP (Solving Constraint Integer Programs) solver in its off-the-shelf configuration</description>
      <guid isPermaLink="false">oai:arXiv.org:2303.13773v4</guid>
      <category>cs.LG</category>
      <category>cs.AI</category>
      <category>math.OC</category>
      <pubDate>Tue, 21 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Bruno Machado Pacheco, Laio Oriel Seman, Cezar Antonio Rigo, Eduardo Camponogara, Eduardo Augusto Bezerra, Leandro dos Santos Coelho</dc:creator>
    </item>
    <item>
      <title>Local controllability around a regular solution and null-controllability of scattering solutions for semilinear wave equations</title>
      <link>https://arxiv.org/abs/2312.06373</link>
      <description>arXiv:2312.06373v2 Announce Type: replace-cross 
Abstract: On a Riemannian manifold with or without boundary, and whether bounded or unbounded, we consider a semilinear wave (or Klein-Gordon) equation with a subcritical nonlinearity (either defocusing or focusing). We establish local controllability around a partially analytic solution, under the Geometric Control Condition. Specifically, some blow-up solutions can be controlled. In the case of a Klein-Gordon equation on a non-trapping exterior domain of small dimension, we prove the null-controllability of scattering solutions. The proof is based on local energy decay and global-in-time Strichartz estimates. Several consequences are presented, including the null-controllability of a solution initiated near the ground state in some focusing cases, and exact controllability in some defocusing cases.</description>
      <guid isPermaLink="false">oai:arXiv.org:2312.06373v2</guid>
      <category>math.AP</category>
      <category>math.OC</category>
      <pubDate>Tue, 21 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Thomas Perrin</dc:creator>
    </item>
    <item>
      <title>Semi-definite optimization of the measured relative entropies of quantum states and channels</title>
      <link>https://arxiv.org/abs/2406.19060</link>
      <description>arXiv:2406.19060v3 Announce Type: replace-cross 
Abstract: The measured relative entropies of quantum states and channels find operational significance in quantum information theory as achievable error rates in hypothesis testing tasks. They are of interest in the near term, as they correspond to hybrid quantum--classical strategies with technological requirements far less challenging to implement than required by the most general strategies allowed by quantum mechanics. In this paper, we prove that these measured relative entropies can be calculated efficiently by means of semi-definite programming, by making use of variational formulas for the measured relative entropies of states and semi-definite representations of the weighted geometric mean and the operator connection of the logarithm. Not only do the semi-definite programs output the optimal values of the measured relative entropies of states and channels, but they also provide numerical characterizations of optimal strategies for achieving them, which is of significant practical interest for designing hypothesis testing protocols.</description>
      <guid isPermaLink="false">oai:arXiv.org:2406.19060v3</guid>
      <category>quant-ph</category>
      <category>cs.IT</category>
      <category>math-ph</category>
      <category>math.IT</category>
      <category>math.MP</category>
      <category>math.OC</category>
      <pubDate>Tue, 21 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Zixin Huang, Mark M. Wilde</dc:creator>
    </item>
    <item>
      <title>Riemannian Federated Learning via Averaging Gradient Streams</title>
      <link>https://arxiv.org/abs/2409.07223</link>
      <description>arXiv:2409.07223v2 Announce Type: replace-cross 
Abstract: Federated learning (FL) as a distributed learning paradigm has a significant advantage in addressing large-scale machine learning tasks. In the Euclidean setting, FL algorithms have been extensively studied with both theoretical and empirical success. However, there exist few works that investigate federated learning algorithms in the Riemannian setting. In particular, critical challenges such as partial participation and data heterogeneity among agents are not explored in the Riemannian federated setting. This paper presents and analyzes a Riemannian FL algorithm, called RFedAGS, based on a new efficient server aggregation -- averaging gradient streams, which can simultaneously handle partial participation and data heterogeneity. We theoretically show that the proposed RFedAGS has global convergence and sublinear convergence rate under decaying step sizes cases; and converges sublinearly/linearly to a neighborhood of a stationary point/solution under fixed step sizes cases. These analyses are based on a vital and non-trivial assumption induced by partial participation, which is shown to hold with high probability. Extensive experiments conducted on synthetic and real-world data demonstrate the good performance of RFedAGS.</description>
      <guid isPermaLink="false">oai:arXiv.org:2409.07223v2</guid>
      <category>cs.LG</category>
      <category>math.OC</category>
      <pubDate>Tue, 21 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Zhenwei Huang, Wen Huang, Pratik Jawanpuria, Bamdev Mishra</dc:creator>
    </item>
    <item>
      <title>Optimal control of stochastic reaction networks with entropic control cost and emergence of mode-switching strategies</title>
      <link>https://arxiv.org/abs/2409.17488</link>
      <description>arXiv:2409.17488v2 Announce Type: replace-cross 
Abstract: Controlling the stochastic dynamics of biological populations is a challenge that arises across various biological contexts. However, these dynamics are inherently nonlinear and involve a discrete state space, i.e., the number of molecules, cells, or organisms. Additionally, the possibility of extinction has a significant impact on both dynamics and control strategies, particularly when the population size is small. These factors hamper the direct application of conventional control theories to biological systems. To address these challenges, we formulate the optimal control problem for stochastic population dynamics by utilizing control cost functions based on the f-divergence, which naturally accounts for population-specific factors. If Kullback-Leibler (KL) divergence is adopted for the cost function, the complex nonlinear Hamilton-Jacobi-Bellman equation is simplified into a linear form, facilitating efficient computation of optimal solutions. We demonstrate the effectiveness of our approach by applying it to the control of interacting random walkers, Moran processes, and SIR models, and observe the mode-switching phenomena in the control strategies. Our approach provides new opportunities for applying control theory to a wide range of biological problems.</description>
      <guid isPermaLink="false">oai:arXiv.org:2409.17488v2</guid>
      <category>q-bio.PE</category>
      <category>cs.SY</category>
      <category>eess.SY</category>
      <category>math.OC</category>
      <category>physics.bio-ph</category>
      <category>q-bio.MN</category>
      <pubDate>Tue, 21 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <arxiv:DOI>10.1103/zttn-tpzq</arxiv:DOI>
      <arxiv:journal_reference>PRX Life 3, 033027 (2025)</arxiv:journal_reference>
      <dc:creator>Shuhei A. Horiguchi, Tetsuya J. Kobayashi</dc:creator>
    </item>
    <item>
      <title>Numerical computation of generalized Wasserstein distances with applications to traffic model analysis</title>
      <link>https://arxiv.org/abs/2410.11441</link>
      <description>arXiv:2410.11441v3 Announce Type: replace-cross 
Abstract: Generalized Wasserstein distances allow to quantitatively compare two continuous or atomic mass distributions with equal or different total mass. In this paper, we propose four numerical methods for the approximation of three different generalized Wasserstein distances introduced in the last years, giving some insights about their physical meaning. After that, we explore their usage in the context of the sensitivity analysis of differential models for traffic flow. The quantification of models sensitivity is obtained by computing the generalized Wasserstein distances between two (numerical) solutions corresponding to different inputs, including different boundary conditions.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.11441v3</guid>
      <category>math.AP</category>
      <category>cs.NA</category>
      <category>math.NA</category>
      <category>math.OC</category>
      <pubDate>Tue, 21 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Maya Briani, Emiliano Cristiani, Giovanni Franzina, Francesca L. Ignoto</dc:creator>
    </item>
    <item>
      <title>A parameterized linear formulation of the integer hull</title>
      <link>https://arxiv.org/abs/2501.02347</link>
      <description>arXiv:2501.02347v3 Announce Type: replace-cross 
Abstract: Let $A \in \mathbb{Z}^{m \times n}$ be an integer matrix with components bounded by $\Delta$ in absolute value. Cook et al.~(1986) have shown that there exists a universal matrix $B \in \mathbb{Z}^{m' \times n}$ with the following property: For each $b \in \mathbb{Z}^m$, there exists $t \in \mathbb{Z}^{m'}$ such that the integer hull of the polyhedron $P = \{ x \in \mathbb{R}^n \colon Ax \leq b\}$ is described by $P_I = \{ x \in \mathbb{R}^n \colon Bx \leq t\}$. Our \emph{main result} is that $t$ is an \emph{affine} function of $b$ as long as $b$ is from a fixed equivalence class of the lattice $D \cdot \mathbb{Z}^m$. Here $D \in \mathbb{N}$ is a number that depends on $n$ and $\Delta$ only. Furthermore, $D$ as well as the matrix $B$ can be computed in time depending on $\Delta$ and $n$ only. An application of this result is the solution of an open problem posed by Cslovjecsek et al.~(SODA 2024) concerning the complexity of \emph{2-stage-stochastic integer programming} problems. The main tool of our proof is the classical theory of \emph{Chv\'atal-Gomory cutting planes} and the \emph{elementary closure} of rational polyhedra.</description>
      <guid isPermaLink="false">oai:arXiv.org:2501.02347v3</guid>
      <category>cs.CC</category>
      <category>math.OC</category>
      <pubDate>Tue, 21 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Friedrich Eisenbrand, Thomas Rothvoss</dc:creator>
    </item>
    <item>
      <title>An ANN-Enhanced Approach for Flatness-Based Constrained Control of Nonlinear Systems</title>
      <link>https://arxiv.org/abs/2503.24031</link>
      <description>arXiv:2503.24031v2 Announce Type: replace-cross 
Abstract: Neural networks have proven practical for a synergistic combination of advanced control techniques. This work analyzes the implementation of rectified linear unit neural networks to achieve constrained control in differentially flat systems. Specifically, the class of flat systems enjoys the benefit of feedback linearizability, i.e., the systems can be linearized by means of a proper variable transformation. However, the price for linearizing the dynamics is that the constraint descriptions are distorted geometrically. Our results show that, by using neural networks, these constraints can be represented as a union of polytopes, enabling the use of mixed-integer programming tools to guarantee constraint satisfaction. We further analyze the integration of the characterization into efficient settings such as control Lyapunov function-based and model predictive control (MPC). Interestingly, this description also allows us to explicitly compute the solution of the MPC problem for the nonlinear system. Several examples are provided to illustrate the effectiveness of our framework.</description>
      <guid isPermaLink="false">oai:arXiv.org:2503.24031v2</guid>
      <category>eess.SY</category>
      <category>cs.SY</category>
      <category>math.OC</category>
      <pubDate>Tue, 21 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Huu-Thinh Do, Ionela Prodan, Florin Stoican</dc:creator>
    </item>
    <item>
      <title>Convergent Complex Quasi-Newton Proximal Methods for Gradient-Driven Denoisers in Compressed Sensing MRI Reconstruction</title>
      <link>https://arxiv.org/abs/2505.04820</link>
      <description>arXiv:2505.04820v2 Announce Type: replace-cross 
Abstract: In compressed sensing (CS) MRI, model-based methods are pivotal to achieving accurate reconstruction. One of the main challenges in model-based methods is finding an effective prior to describe the statistical distribution of the target image. Plug-and-Play (PnP) and REgularization by Denoising (RED) are two general frameworks that use denoisers as the prior. While PnP/RED methods with convolutional neural networks (CNNs) based denoisers outperform classical hand-crafted priors in CS MRI, their convergence theory relies on assumptions that do not hold for practical CNNs. The recently developed gradient-driven denoisers offer a framework that bridges the gap between practical performance and theoretical guarantees. However, the numerical solvers for the associated minimization problem remain slow for CS MRI reconstruction. This paper proposes a complex quasi-Newton proximal method that achieves faster convergence than existing approaches. To address the complex domain in CS MRI, we propose a modified Hessian estimation method that guarantees Hermitian positive definiteness. Furthermore, we provide a rigorous convergence analysis of the proposed method for nonconvex settings. Numerical experiments on both Cartesian and non-Cartesian sampling trajectories demonstrate the effectiveness and efficiency of our approach.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.04820v2</guid>
      <category>eess.IV</category>
      <category>cs.NA</category>
      <category>math.NA</category>
      <category>math.OC</category>
      <pubDate>Tue, 21 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Tao Hong, Zhaoyi Xu, Se Young Chun, Luis Hernandez-Garcia, Jeffrey A. Fessler</dc:creator>
    </item>
    <item>
      <title>Learning Cocoercive Conservative Denoisers via Helmholtz Decomposition for Poisson Inverse Problems</title>
      <link>https://arxiv.org/abs/2505.08909</link>
      <description>arXiv:2505.08909v2 Announce Type: replace-cross 
Abstract: Plug-and-play (PnP) methods with deep denoisers have shown impressive results in imaging problems. They typically require strong convexity or smoothness of the fidelity term and a (residual) non-expansive denoiser for convergence. These assumptions, however, are violated in Poisson inverse problems, and non-expansiveness can hinder denoising performance. To address these challenges, we propose a cocoercive conservative (CoCo) denoiser, which may be (residual) expansive, leading to improved denoising. By leveraging the generalized Helmholtz decomposition, we introduce a novel training strategy that combines Hamiltonian regularization to promote conservativeness and spectral regularization to ensure cocoerciveness. We prove that CoCo denoiser is a proximal operator of a weakly convex function, enabling a restoration model with an implicit weakly convex prior. The global convergence of PnP methods to a stationary point of this restoration model is established. Extensive experimental results demonstrate that our approach outperforms closely related methods in both visual quality and quantitative metrics.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.08909v2</guid>
      <category>cs.CV</category>
      <category>cs.LG</category>
      <category>math.FA</category>
      <category>math.OC</category>
      <pubDate>Tue, 21 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Deliang Wei, Peng Chen, Haobo Xu, Jiale Yao, Fang Li, Tieyong Zeng</dc:creator>
    </item>
    <item>
      <title>Primal-dual splitting methods for phase-field surfactant model with moving contact lines</title>
      <link>https://arxiv.org/abs/2505.09469</link>
      <description>arXiv:2505.09469v2 Announce Type: replace-cross 
Abstract: Surfactants have important effects on the dynamics of droplets on solid surfaces, which has inspired many industrial applications. Phase-field surfactant model with moving contact lines (PFS-MCL) has been employed to investigate the complex droplet dynamics with surfactants, while its numerical simulation remains challenging due to the coupling of gradient flows with respect to transport distances involving nonlinear and degenerate mobilities. We propose a novel structure-preserving variational scheme for PFS-MCL model with the dynamic boundary condition based on the minimizing movement scheme and optimal transport theory for Wasserstein gradient flows. The proposed scheme consists of a series of convex minimization problems and can be efficiently solved by our proposed primal-dual splitting method and its accelerated versions. By respecting the underlying PDE's variational structure with respect to the transport distance, the proposed scheme is proved to inherits the desirable properties including original energy dissipation, bound-preserving, and mass conservation. Through a suite of numerical simulations, we validate the performance of the proposed scheme and investigate the effects of surfactants on the droplet dynamics.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.09469v2</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <category>math.OC</category>
      <category>physics.comp-ph</category>
      <pubDate>Tue, 21 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Wei Wu, Zhen Zhang, Chaozhen Wei</dc:creator>
    </item>
    <item>
      <title>When majority rules, minority loses: bias amplification of gradient descent</title>
      <link>https://arxiv.org/abs/2505.13122</link>
      <description>arXiv:2505.13122v2 Announce Type: replace-cross 
Abstract: Despite growing empirical evidence of bias amplification in machine learning, its theoretical foundations remain poorly understood. We develop a formal framework for majority-minority learning tasks, showing how standard training can favor majority groups and produce stereotypical predictors that neglect minority-specific features. Assuming population and variance imbalance, our analysis reveals three key findings: (i) the close proximity between ``full-data'' and stereotypical predictors, (ii) the dominance of a region where training the entire model tends to merely learn the majority traits, and (iii) a lower bound on the additional training required. Our results are illustrated through experiments in deep learning for tabular and image classification tasks.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.13122v2</guid>
      <category>cs.LG</category>
      <category>cs.AI</category>
      <category>math.OC</category>
      <pubDate>Tue, 21 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Fran\c{c}ois Bachoc (LPP), J\'er\^ome Bolte (TSE-R), Ryan Boustany (TSE-R), Jean-Michel Loubes (IMT)</dc:creator>
    </item>
    <item>
      <title>On Triangular Forms for x-Flat Control-Affine Systems With Two Inputs</title>
      <link>https://arxiv.org/abs/2505.15562</link>
      <description>arXiv:2505.15562v3 Announce Type: replace-cross 
Abstract: This paper examines a broadly applicable triangular normal form for x-flat control-affine systems with two inputs. First, we show that this triangular form encompasses a wide range of established normal forms. Next, we prove that any x-flat system can be transformed into this triangular structure after a finite number of prolongations of each input. Finally, we introduce a refined algorithm for identifying candidates for x-flat outputs. Through illustrative examples, we demonstrate the usefulness of our results. In particular, we show that the refined algorithm exceeds the capabilities of existing methods for computing flat outputs based on triangular forms.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.15562v3</guid>
      <category>math.DS</category>
      <category>math.OC</category>
      <pubDate>Tue, 21 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Georg Hartl, Conrad Gst\"ottner, Markus Sch\"oberl</dc:creator>
    </item>
    <item>
      <title>Quantum Computing in the Computational Landscape of Power Electronics: Vision and Reality</title>
      <link>https://arxiv.org/abs/2507.02577</link>
      <description>arXiv:2507.02577v2 Announce Type: replace-cross 
Abstract: Quantum computing is rapidly emerging as a promising technology for solving complex optimization problems that arise in various engineering fields. Therefore, it holds significant promise to transform the computational foundations of power electronics. Motivated by this potential, this paper adopts a visionary perspective to examine how quantum computing could influence the evolution of power electronics in areas such as converter design, control, modulation, simulation workflows, and beyond. Within this framework, the current status, limitations, and anticipated progress of quantum algorithms and hardware are discussed, together with their potential to enable efficient solutions to large-scale, multiobjective, mixed-integer optimization problems. To place these developments in context, the paper begins with a concise tutorial on fundamental concepts in quantum computing, serving as both an introduction to the field and a bridge to its potential applications in power electronics. As a first step in this direction, the use of quantum computing for solving offline mixed-integer optimization problems commonly encountered in power electronics is examined. To this end, a simplified power electronics design problem is reformulated as a quadratic unconstrained binary optimization (QUBO) problem and executed on quantum hardware, despite current limitations such as low qubit counts and hardware noise. This demonstration marks a pioneering step towards leveraging quantum computing in power electronics and motivates the value of early adoption and exploration. Building on these insights, the paper outlines a forward-looking vision in which quantum computing becomes an integral part of the computational landscape of power electronics, guiding its transition from classical to quantum-enabled design and operation.</description>
      <guid isPermaLink="false">oai:arXiv.org:2507.02577v2</guid>
      <category>quant-ph</category>
      <category>math.OC</category>
      <pubDate>Tue, 21 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Nikolaos G. Paterakis, Petros Karamanakos, Corey O'Meara, Georgios Papafotiou</dc:creator>
    </item>
    <item>
      <title>Greedy Low-Rank Gradient Compression for Distributed Learning with Convergence Guarantees</title>
      <link>https://arxiv.org/abs/2507.08784</link>
      <description>arXiv:2507.08784v4 Announce Type: replace-cross 
Abstract: Distributed optimization is pivotal for large-scale signal processing and machine learning, yet communication overhead remains a major bottleneck. Low-rank gradient compression, in which the transmitted gradients are approximated by low-rank matrices to reduce communication, offers a promising remedy. Existing methods typically adopt either randomized or greedy compression strategies: randomized approaches project gradients onto randomly chosen subspaces, introducing high variance and degrading empirical performance; greedy methods select the most informative subspaces, achieving strong empirical results but lacking convergence guarantees. To address this gap, we propose GreedyLore--the first Greedy Low-Rank gradient compression algorithm for distributed learning with rigorous convergence guarantees. GreedyLore incorporates error feedback to correct the bias introduced by greedy compression and introduces a semi-lazy subspace update that ensures the compression operator remains contractive throughout all iterations. With these techniques, we prove that GreedyLore achieves a convergence rate of $\mathcal{O}(\sigma/\sqrt{NT} + 1/T)$ under standard optimizers such as MSGD and Adam--marking the first linear speedup convergence rate for low-rank gradient compression. Extensive experiments are conducted to validate our theoretical findings.</description>
      <guid isPermaLink="false">oai:arXiv.org:2507.08784v4</guid>
      <category>cs.LG</category>
      <category>math.OC</category>
      <pubDate>Tue, 21 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Chuyan Chen, Yutong He, Pengrui Li, Weichen Jia, Kun Yuan</dc:creator>
    </item>
    <item>
      <title>Direct data-driven interpolation and approximation of linear parameter-varying system trajectories</title>
      <link>https://arxiv.org/abs/2508.11332</link>
      <description>arXiv:2508.11332v2 Announce Type: replace-cross 
Abstract: We consider the problem of estimating missing values in trajectories of linear parameter-varying (LPV) systems. We solve this interpolation problem for the class of shifted-affine LPV systems. Conditions for the existence and uniqueness of solutions are given and a direct data-driven algorithm for its computation is presented, i.e., the data-generating system is not given by a parametric model but is implicitly specified by data. We illustrate the applicability of the proposed solution on illustrative examples of a mass-spring-damper system with exogenous and endogenous parameter variation.</description>
      <guid isPermaLink="false">oai:arXiv.org:2508.11332v2</guid>
      <category>eess.SY</category>
      <category>cs.SY</category>
      <category>eess.SP</category>
      <category>math.OC</category>
      <pubDate>Tue, 21 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <dc:creator>Chris Verhoek, Ivan Markovsky, Roland T\'oth</dc:creator>
    </item>
    <item>
      <title>The Nondecreasing Rank</title>
      <link>https://arxiv.org/abs/2509.00265</link>
      <description>arXiv:2509.00265v2 Announce Type: replace-cross 
Abstract: In this article the notion of the nondecreasing (ND) rank of a matrix or tensor is introduced. A tensor has an ND rank of r if it can be represented as a sum of r outer products of vectors, with each vector satisfying a monotonicity constraint. It is shown that for certain poset orderings finding an ND factorization of rank $r$ is equivalent to finding a nonnegative rank-r factorization of a transformed tensor. However, not every tensor that is monotonic has a finite ND rank. Theory is developed describing the properties of the ND rank, including typical, maximum, and border ND ranks. Highlighted also are the special settings where a matrix or tensor has an ND rank of one or two. As a means of finding low ND rank approximations to a data tensor we introduce a variant of the hierarchical alternating least squares algorithm. Low ND rank factorizations are found and interpreted for two datasets concerning the weight of pigs and a mental health survey during the COVID-19 pandemic.</description>
      <guid isPermaLink="false">oai:arXiv.org:2509.00265v2</guid>
      <category>stat.ML</category>
      <category>cs.LG</category>
      <category>cs.NA</category>
      <category>math.NA</category>
      <category>math.OC</category>
      <pubDate>Tue, 21 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Andrew McCormack</dc:creator>
    </item>
    <item>
      <title>Quantum Fisher information matrix via its classical counterpart from random measurements</title>
      <link>https://arxiv.org/abs/2509.08196</link>
      <description>arXiv:2509.08196v2 Announce Type: replace-cross 
Abstract: Preconditioning with the quantum Fisher information matrix (QFIM) is a popular approach in quantum variational algorithms. Yet the QFIM is costly to obtain directly, usually requiring more state preparation than its classical counterpart: the classical Fisher information matrix (CFIM). By revealing its relation to covariant measurement in quantum metrology, we show that averaging the classical Fisher information matrix over Haar-random measurement bases yields $\mathbb{E}_{U\sim\mu_H}[F^U(\boldsymbol{\theta})] = \frac{1}{2}Q(\boldsymbol{\theta})$ for pure states in $\mathbb{C}^N$. Furthermore, we obtain the variance of CFIM ($O(N^{-1})$) and establish non-asymptotic concentration bounds ($\exp(-\Theta(N)t^2)$), demonstrating that using few random measurement bases is sufficient to approximate the QFIM accurately, especially in high-dimensional settings. This work establishes a solid theoretical foundation for efficient quantum natural gradient methods via randomized measurements.</description>
      <guid isPermaLink="false">oai:arXiv.org:2509.08196v2</guid>
      <category>quant-ph</category>
      <category>math-ph</category>
      <category>math.MP</category>
      <category>math.OC</category>
      <pubDate>Tue, 21 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Jianfeng Lu, Kecen Sha</dc:creator>
    </item>
    <item>
      <title>A Human-Vector Susceptible-Infected-Susceptible Model for Analyzing and Controlling the Spread of Vector-Borne Diseases</title>
      <link>https://arxiv.org/abs/2510.14787</link>
      <description>arXiv:2510.14787v2 Announce Type: replace-cross 
Abstract: We propose an epidemic model for the spread of vector-borne diseases. The model, which is built extending the classical susceptible-infected-susceptible model, accounts for two populations -- humans and vectors -- and for cross-contagion between the two species, whereby humans become infected upon interaction with carrier vectors, and vectors become carriers after interaction with infected humans. We formulate the model as a system of ordinary differential equations and leverage monotone systems theory to rigorously characterize the epidemic dynamics. Specifically, we characterize the global asymptotic behavior of the disease, determining conditions for quick eradication of the disease (i.e., for which all trajectories converge to a disease-free equilibrium), or convergence to a (unique) endemic equilibrium. Then, we incorporate two control actions: namely, vector control and incentives to adopt protection measures. Using the derived mathematical tools, we assess the impact of these two control actions and determine the optimal control policy.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.14787v2</guid>
      <category>eess.SY</category>
      <category>cs.SY</category>
      <category>math.OC</category>
      <category>q-bio.PE</category>
      <pubDate>Tue, 21 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <arxiv:DOI>10.23919/ECC65951.2025.11186881</arxiv:DOI>
      <arxiv:journal_reference>Proceedings 2025 European Control Conference, pp. 1219-1224, 2025</arxiv:journal_reference>
      <dc:creator>Lorenzo Zino, Alessandro Casu, Alessandro Rizzo</dc:creator>
    </item>
  </channel>
</rss>
