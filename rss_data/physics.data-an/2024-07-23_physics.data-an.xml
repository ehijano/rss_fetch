<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>physics.data-an updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/physics.data-an</link>
    <description>physics.data-an updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/physics.data-an" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Wed, 24 Jul 2024 01:40:43 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Tue, 23 Jul 2024 00:00:00 -0400</pubDate>
    <skipDays>
      <day>Sunday</day>
      <day>Saturday</day>
    </skipDays>
    <item>
      <title>Error correction for encoded quantum annealing revisited</title>
      <link>https://arxiv.org/abs/2407.15480</link>
      <description>arXiv:2407.15480v2 Announce Type: cross 
Abstract: F. Pastawski and J. Preskill discussed error correction of quantum annealing (QA) based on a parity-encoded spin system, known as the Sourlas-Lechner-Hauke-Zoller (SLHZ) system. They pointed out that the SLHZ system is closely related to a classical low-density parity-check (LDPC) code and demonstrated its error-correcting capability through a belief propagation (BP) algorithm assuming independent random spin-flip errors. In contrast, Ablash et al. suggested that the SLHZ system does not receive the benefits of post-readout decoding. The reason is that independent random spin-flips are not the most relevant error arising from sampling excited states during the annealing process, whether in closed or open system cases. In this work, we revisit this issue: we propose a very simple decoding algorithm to eliminate errors in the readout of SLHZ systems and show experimental evidence suggesting that SLHZ system exhibits error-correcting capability in decoding annealing readouts. Our new algorithm can be thought of as a bit-flipping algorithm for LDPC codes. Assuming an independent and identical noise model, we found that the performance of our algorithm is comparable to that of the BP algorithm. The error correcting-capability for the sampled readouts was investigated using Monte Carlo calculations that simulate the final time distribution of QA. The results show that the algorithm successfully eliminates errors in the sampled readouts under conditions where error-free state or even code state is not sampled at all. Our simulation suggests that decoding of annealing readouts will be successful if the correctable states can be sampled by annealing, and annealing can be considered to play a role as a pre-process of the classical decoding process. This knowledge will be useful for designing and developing practical QA based on the SLHZ system in the near future.</description>
      <guid isPermaLink="false">oai:arXiv.org:2407.15480v2</guid>
      <category>quant-ph</category>
      <category>physics.app-ph</category>
      <category>physics.data-an</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Yoshihiro Nambu</dc:creator>
    </item>
    <item>
      <title>Can foreign exchange rates violate Bell inequalities?</title>
      <link>https://arxiv.org/abs/2407.15747</link>
      <description>arXiv:2407.15747v1 Announce Type: cross 
Abstract: The analysis of empirical data through model-free inequalities leads to the conclusion that violations of Bell-type inequalities by empirical data cannot have any significance unless one believes that the universe operates according to the rules of a mathematical model.</description>
      <guid isPermaLink="false">oai:arXiv.org:2407.15747v1</guid>
      <category>quant-ph</category>
      <category>physics.data-an</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <arxiv:DOI>10.1016/j.aop.2024.169742</arxiv:DOI>
      <arxiv:journal_reference>Annals of Physics 469 (2024) 169742</arxiv:journal_reference>
      <dc:creator>Hans De Raedt, Mikhail I. Katsnelson, Manpreet S. Jattana, Vrinda Mehta, Madita Willsch, Dennis Willsch, Kristel Michielsen, Fengping Jin</dc:creator>
    </item>
    <item>
      <title>Information cascade on networks and phase transitions</title>
      <link>https://arxiv.org/abs/2302.12295</link>
      <description>arXiv:2302.12295v2 Announce Type: replace-cross 
Abstract: Herein, we consider a voting model for information cascades on several types of networks -- a random graph, the Barab\'{a}si-Albert(BA) model, and lattice networks -- by using one parameter $\omega$; $\omega=1,0, -1$ respectively correspond to these networks. $\omega$ is related to the size of hubs. We discuss the differences between the phases in which the networks depend. In $\omega\ne -1$, without, the following two types of phase transitions can be observed: information cascade transition and super-normal transition. The first is the transition between a state where most voters make correct choices and a state where most of them are wrong. This is an absorption transition that belongs to the non-equilibrium transition. In the symmetric case, the phase transition is continuous and the universality class is the same as nonlinear P\'{o}lya model. In contrast, in the asymmetric case, there is a discontinuous phase transition, where the gap depends on the network. The super-normal transition is the transition of the convergence speed, and the critical point of the convergence speed transition depends on $\omega$. At $\omega=1$, in the BA model, this transition disappears. Both phase transitions disappear at $\omega=-1$ in the lattice case. In conclusion, as the performance near the lattice case, $\omega\sim-1$ exhibits the best performance of the voting in all networks. As the hub size decreases, the performance improves.</description>
      <guid isPermaLink="false">oai:arXiv.org:2302.12295v2</guid>
      <category>physics.soc-ph</category>
      <category>physics.data-an</category>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Masato Hisakado, Kazuaki Nakayama, Shintaro Mori</dc:creator>
    </item>
    <item>
      <title>Einstein-Podolsky-Rosen-Bohm experiments: a discrete data driven approach</title>
      <link>https://arxiv.org/abs/2304.03962</link>
      <description>arXiv:2304.03962v4 Announce Type: replace-cross 
Abstract: We take the point of view that building a one-way bridge from experimental data to mathematical models instead of the other way around avoids running into controversies resulting from attaching meaning to the symbols used in the latter. In particular, we show that adopting this view offers new perspectives for constructing mathematical models for and interpreting the results of Einstein-Podolsky-Rosen-Bohm experiments. We first prove new Bell-type inequalities constraining the values of the four correlations obtained by performing Einstein-Podolsky-Rosen-Bohm experiments under four different conditions. The proof is ``model-free'' in the sense that it does not refer to any mathematical model that one imagines to have produced the data. The constraints only depend on the number of quadruples obtained by reshuffling the data in the four data sets without changing the values of the correlations. These new inequalities reduce to model-free versions of the well-known Bell-type inequalities if the maximum fraction of quadruples is equal to one. Being model-free, a violation of the latter by experimental data implies that not all the data in the four data sets can be reshuffled to form quadruples. Furthermore, being model-free inequalities, a violation of the latter by experimental data only implies that any mathematical model assumed to produce this data does not apply. Starting from the data obtained by performing Einstein-Podolsky-Rosen-Bohm experiments, we construct instead of postulate mathematical models that describe the main features of these data. The mathematical framework of plausible reasoning is applied to reproducible and robust data, yielding without using any concept of quantum theory, the expression of the correlation for a system of two spin-1/2 objects in the singlet state. (truncated here)</description>
      <guid isPermaLink="false">oai:arXiv.org:2304.03962v4</guid>
      <category>quant-ph</category>
      <category>physics.data-an</category>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <arxiv:DOI>10.1016/j.aop.2023.169314</arxiv:DOI>
      <arxiv:journal_reference>Annals of Physics, Volume 453, 169314, 2023</arxiv:journal_reference>
      <dc:creator>Hans De Raedt, Mikhail I. Katsnelson, Manpreet S. Jattana, Vrinda Mehta, Madita Willsch, Dennis Willsch, Kristel Michielsen, Fengping Jin</dc:creator>
    </item>
    <item>
      <title>Bayesian identification of nonseparable Hamiltonians with multiplicative noise using deep learning and reduced-order modeling</title>
      <link>https://arxiv.org/abs/2401.12476</link>
      <description>arXiv:2401.12476v3 Announce Type: replace-cross 
Abstract: This paper presents a structure-preserving Bayesian approach for learning nonseparable Hamiltonian systems using stochastic dynamic models allowing for statistically-dependent, vector-valued additive and multiplicative measurement noise. The approach is comprised of three main facets. First, we derive a Gaussian filter for a statistically-dependent, vector-valued, additive and multiplicative noise model that is needed to evaluate the likelihood within the Bayesian posterior. Second, we develop a novel algorithm for cost-effective application of Bayesian system identification to high-dimensional systems. Third, we demonstrate how structure-preserving methods can be incorporated into the proposed framework, using nonseparable Hamiltonians as an illustrative system class. We assess the method's performance based on the forecasting accuracy of a model estimated from single-trajectory data. We compare the Bayesian method to a state-of-the-art machine learning method on a canonical nonseparable Hamiltonian model and a chaotic double pendulum model with small, noisy training datasets. The results show that using the Bayesian posterior as a training objective can yield upwards of 724 times improvement in Hamiltonian mean squared error using training data with up to 10% multiplicative noise compared to a standard training objective. Lastly, we demonstrate the utility of the novel algorithm for parameter estimation of a 64-dimensional model of the spatially-discretized nonlinear Schr\"odinger equation with data corrupted by up to 20% multiplicative noise.</description>
      <guid isPermaLink="false">oai:arXiv.org:2401.12476v3</guid>
      <category>stat.ML</category>
      <category>cs.LG</category>
      <category>math.DS</category>
      <category>physics.data-an</category>
      <category>stat.CO</category>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Nicholas Galioto, Harsh Sharma, Boris Kramer, Alex Arkady Gorodetsky</dc:creator>
    </item>
    <item>
      <title>Resolution of Simpson's paradox via the common cause principle</title>
      <link>https://arxiv.org/abs/2403.00957</link>
      <description>arXiv:2403.00957v2 Announce Type: replace-cross 
Abstract: Simpson's paradox is an obstacle to establishing a probabilistic association between two events $a_1$ and $a_2$, given the third (lurking) random variable $B$. We focus on scenarios when the random variables $A$ (which combines $a_1$, $a_2$, and their complements) and $B$ have a common cause $C$ that need not be observed. Alternatively, we can assume that $C$ screens out $A$ from $B$. For such cases, the correct association between $a_1$ and $a_2$ is to be defined via conditioning over $C$. This setup generalizes the original Simpson's paradox: now its two contradicting options refer to two particular and different causes $C$. We show that if $B$ and $C$ are binary and $A$ is quaternary (the minimal and the most widespread situation for the Simpson's paradox), the conditioning over any binary common cause $C$ establishes the same direction of association between $a_1$ and $a_2$ as the conditioning over $B$ in the original formulation of the paradox. Thus, for the minimal common cause, one should choose the option of Simpson's paradox that assumes conditioning over $B$ and not its marginalization. The same conclusion is reached when Simpson's paradox is formulated via 3 continuous Gaussian variables: within the minimal formulation of the paradox (3 scalar continuous variables $A_1$, $A_2$, and $B$), one should choose the option with the conditioning over $B$.</description>
      <guid isPermaLink="false">oai:arXiv.org:2403.00957v2</guid>
      <category>stat.ME</category>
      <category>cs.AI</category>
      <category>math.PR</category>
      <category>physics.data-an</category>
      <category>stat.AP</category>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>A. Hovhannisyan, A. E. Allahverdyan</dc:creator>
    </item>
  </channel>
</rss>
