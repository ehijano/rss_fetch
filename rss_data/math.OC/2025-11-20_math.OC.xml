<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>math.OC updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/math.OC</link>
    <description>math.OC updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/math.OC" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Fri, 21 Nov 2025 02:32:25 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Thu, 20 Nov 2025 00:00:00 -0500</pubDate>
    <skipDays>
      <day>Saturday</day>
      <day>Sunday</day>
    </skipDays>
    <item>
      <title>H-invariance theory: A complete characterization of minimax optimal fixed-point algorithms</title>
      <link>https://arxiv.org/abs/2511.14915</link>
      <description>arXiv:2511.14915v1 Announce Type: new 
Abstract: For nonexpansive fixed-point problems, Halpern's method with optimal parameters, its so-called H-dual algorithm, and in fact, an infinite family of algorithms containing them, all exhibit the exactly minimax optimal convergence rates. In this work, we provide a characterization of the complete, exhaustive family of distinct algorithms using predetermined step-sizes, represented as lower triangular H-matrices, which attain the same optimal convergence rate. The characterization is based on polynomials in the entries of the H-matrix that we call H-invariants, whose values stay constant over all optimal H-matrices, together with H-certificates, of which nonnegativity precisely specifies the region of optimality within the common level set of H-invariants. The H-invariance theory we present offers a novel view of optimal acceleration in first-order optimization as a mathematical study of carefully selected invariants, certificates, and structures induced by them.</description>
      <guid isPermaLink="false">oai:arXiv.org:2511.14915v1</guid>
      <category>math.OC</category>
      <pubDate>Thu, 20 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>TaeHo Yoon, Ernest K. Ryu, Benjamin Grimmer</dc:creator>
    </item>
    <item>
      <title>Finite-Horizon LQR for General Markov Jump Linear Systems: Deterministic Reformulation and Reduced-Order Solution</title>
      <link>https://arxiv.org/abs/2511.14926</link>
      <description>arXiv:2511.14926v1 Announce Type: new 
Abstract: This paper studies the Linear Quadratic Regulator (LQR) problem for continuous-time Markov Jump Linear Systems (MJLS) governed by general finite-state Markov chains that may include transient, absorbing, or non-communicating states. The problem, posed over a finite time horizon, is reformulated deterministically by expressing the cost functional in terms of a collection of second-moment matrices of the system state. A projection operator is introduced to restrict the analysis to the subspace of visited states, namely those with positive probability of being reached within the time horizon. The solution of the resulting deterministic problem is obtained from a reduced-order system of coupled matrix Riccati differential equations involving only the visited states, which define a quadratic value function satisfying a Hamilton-Jacobi-Bellman type equation. The structure of this equation is formally justified in the matrix setting via the Riesz-Frechet representation theorem, establishing a rigorous foundation for the deterministic reformulation and resolving an open aspect in previous literature. Several numerical examples, including cases with non-communicating states, validate the theoretical results and illustrate the practical relevance of the proposed generalization.</description>
      <guid isPermaLink="false">oai:arXiv.org:2511.14926v1</guid>
      <category>math.OC</category>
      <pubDate>Thu, 20 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Alfredo R. R. Narv\'aez, Jeinny Peralta, M. A. C. Candezano</dc:creator>
    </item>
    <item>
      <title>Computation of structured stability radii for Dissipative-Hamiltonian systems</title>
      <link>https://arxiv.org/abs/2511.14935</link>
      <description>arXiv:2511.14935v1 Announce Type: new 
Abstract: We study linear time-invariant Dissipative Hamiltonian (DH) systems arising in energy-based modeling of dynamical systems. An advantage of DH systems is that they are always stable due to the structure of their coefficient matrices, and, under further weak conditions, even asymptotically stable. In this paper, we discuss the computation of the stability radii for a given asymptotically stable DH system; i.e., the smallest structured perturbation that puts a DH system on the boundary of the region of asymptotic stability, so that it has purely imaginary eigenvalues. We obtain explicit computable formulas for various structured stability radii. For this, the problem of computing stability radii is reformulated in terms of minimizing the Rayleigh quotient of a Hermitian matrix or the sum of two generalized Rayleigh quotients of Hermitian semidefinite matrices. This reformulation results in the problem of minimizing the largest eigenvalue of an eigenvector-dependent Hermitian matrix or minimizing the smallest eigenvalue of a Hermitian matrix which depends on the eigenvector. It is also demonstrated (via numerical experiments) that, under structure-preserving perturbations, the asymptotic stability of a DH system is much more robust than under general perturbations, since the distance to instability is typically much larger when structure-preserving perturbations are considered. Finally, similar results are obtained for optimally robust representations of stable systems.</description>
      <guid isPermaLink="false">oai:arXiv.org:2511.14935v1</guid>
      <category>math.OC</category>
      <pubDate>Thu, 20 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/publicdomain/zero/1.0/</dc:rights>
      <dc:creator>Peter Benner, Volker Mehrmann, Anshul Prajapati, Punit Sharma</dc:creator>
    </item>
    <item>
      <title>Adversarial Physics-Informed Machine Learning for Robust Optimal Safe Predefined-Time Stabilization: A Game-Theoretic Approach</title>
      <link>https://arxiv.org/abs/2511.15018</link>
      <description>arXiv:2511.15018v1 Announce Type: new 
Abstract: We develop a game-theoretic framework for adversarially robust optimal safe predefined-time stabilization of parameter-dependent nonlinear dynamical systems with nonquadratic cost functionals. Our approach ensures that all system trajectories remain within a specified admissible set and converge to equilibrium in a predefined time despite adversarial disturbances. The control problem is formulated as a two-player zero-sum differential game, where the controller is a minimizing player and the adversary a maximizing player. We derive sufficient conditions for the existence of a saddle-point solution and safe predefined-time stability using a barrier Lyapunov function that satisfies a differential inequality and the steady-state Hamilton-Jacobi-Isaacs (HJI) equation. To address the analytical intractability of solving the HJI equation, we introduce a physics-informed learning algorithm that robustly learns the Nash safely predefined-time stabilizing control strategy. Simulation results demonstrate the efficacy and resilience of the proposed method in ensuring robust optimal safe predefined-time stabilization under adversarial disturbances.</description>
      <guid isPermaLink="false">oai:arXiv.org:2511.15018v1</guid>
      <category>math.OC</category>
      <pubDate>Thu, 20 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Nick-Marios T. Kokolakis, Shanqing Liu, Jerome Darbon, Rahul Mangharam, George Em Karniadakis</dc:creator>
    </item>
    <item>
      <title>Non-Convex Self-Concordant Functions: Practical Algorithms and Complexity Analysis</title>
      <link>https://arxiv.org/abs/2511.15019</link>
      <description>arXiv:2511.15019v1 Announce Type: new 
Abstract: We extend the standard notion of self-concordance to non-convex optimization and develop a family of second-order algorithms with global convergence guarantees. In particular, two function classes -- \textit{weakly self-concordant} functions and \textit{$F$-based self-concordant} functions -- generalize the self-concordant framework beyond convexity, without assuming the Lipschitz continuity of the gradient or Hessian. For these function classes, we propose a regularized Newton method and an adaptive regularization method that achieve an $\epsilon$-approximate first-order stationary point in $O(\epsilon^{-2})$ iterations. Equipped with an oracle capable of detecting negative curvature, the adaptive algorithm can further attain convergence to an approximate second-order stationary point. Our experimental results demonstrate that the proposed methods offer superior robustness and computational efficiency compared to cubic regularization and trust-region approaches, underscoring the broad potential of self-concordant regularization for large-scale and neural network optimization problems.</description>
      <guid isPermaLink="false">oai:arXiv.org:2511.15019v1</guid>
      <category>math.OC</category>
      <pubDate>Thu, 20 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Donald Goldfarb, Lexiao Lai, Tianyi Lin, Jiayu Zhang</dc:creator>
    </item>
    <item>
      <title>Adaptive Inverse Reinforcement Learning with Online Off-Policy Data Collection</title>
      <link>https://arxiv.org/abs/2511.15171</link>
      <description>arXiv:2511.15171v1 Announce Type: new 
Abstract: In this paper, the inverse reinforcement learning (IRL) problem is addressed to reconstruct the unknown cost function underlying an observed optimal policy in a model-free manner, whose online adaptation with completely off-policy system data still remains unclear in the literature. Without prior knowledge of the system model parameters, an adaptive and direct learning rule for the cost parameter is proposed using online off-policy system data, which only needs to satisfy the mild persistently exciting condition in the general data-driven paradigm. The adaptive and online IRL algorithm is achieved by designing full Nesterov-Todd (NT)-step primal-dual interior-point iterations. Despite solving a nonlinear and time-varying semi-definite program (SDP), the influence of system noise is rigorously analyzed, and the proposed online algorithm is shown to achieve a sublinear convergence. The proposed method is further generalized to nonlinear IRL based on differential dynamic programming. The gradient of the loss function is directly obtained via a backward pass, which eliminates the need to repeatedly solve forward RL problems as in conventional bi-level IRL frameworks. Finally, the efficiency and effectiveness of the proposed algorithms are demonstrated by numerical examples.</description>
      <guid isPermaLink="false">oai:arXiv.org:2511.15171v1</guid>
      <category>math.OC</category>
      <pubDate>Thu, 20 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Yibei Li, Yuexin Cao, Zhixin Liu, Lihua Xie</dc:creator>
    </item>
    <item>
      <title>Mean-Field Game of Relative Performance Portfolio for Two Populations with Poisson Common Noise</title>
      <link>https://arxiv.org/abs/2511.15176</link>
      <description>arXiv:2511.15176v1 Announce Type: new 
Abstract: This paper studies the mean field game (MFG) and N-player game on relative performance portfolio management with two heterogeneous populations. In addition to the Brownian idiosyncratic and common noise, the first population invests in assets driven by idiosyncratic Poisson jump risk, while the second population invests in assets subject to Poisson common noise. We establish the characterization of the mean-field equilibrium (MFE) in MFG with two populations as well as the Nash equilibrium in the $N_1+N_2$-player game. Furthermore, we prove the convergence of the Nash equilibrium in the $N_1+N_2$-player game to the MFE as the number of players in two populations tends to infinity. We also discuss some impacts on MFE by the Poisson idiosyncratic risk and Poisson common noise in the context of relative performance, compensated by some numerical examples and financial implications.</description>
      <guid isPermaLink="false">oai:arXiv.org:2511.15176v1</guid>
      <category>math.OC</category>
      <pubDate>Thu, 20 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Yuchen Li, Zongxia Liang, Xiang Yu</dc:creator>
    </item>
    <item>
      <title>Optimal sets for the quantitative isoperimetric inequality in the plane with the barycentric distance</title>
      <link>https://arxiv.org/abs/2511.15232</link>
      <description>arXiv:2511.15232v1 Announce Type: new 
Abstract: In a recent paper, C. Gambicchia and A. Pratelli proved a quantitative isoperimetric inequality involving the isoperimetric deficit $\delta(K)$ and the barycentric distance $\lambda_0(K)$ for sets $K\subset \mathbb{R}^N$ with given diameter $D$ and measure. In this work we are interested in the optimal sets for this inequality in the plane, i.e. sets that minimize the ratio $\delta(K)/\lambda_0(K)^2$. We prove existence of optimal sets (at least when $D$ is large enough), regularity and express the optimality conditions. Moreover, we prove that the optimal sets have exactly two connected components and their boundary does not contain any arc of circle.</description>
      <guid isPermaLink="false">oai:arXiv.org:2511.15232v1</guid>
      <category>math.OC</category>
      <category>math.MG</category>
      <pubDate>Thu, 20 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Gisella Croce, Antoine Henrot</dc:creator>
    </item>
    <item>
      <title>Mini-Extragradient Methods</title>
      <link>https://arxiv.org/abs/2511.15254</link>
      <description>arXiv:2511.15254v1 Announce Type: new 
Abstract: The Extragradient (EG) method stands as a cornerstone algorithm for solving monotone nonlinear equations but faces two important unresolved challenges: (i) how to select stepsizes without relying on the global Lipschitz constant or expensive line-search procedures, and (ii) how to reduce the two full evaluations of the mapping required per iteration to effectively one, without compromising convergence guarantees or computational efficiency. To address the first challenge, we propose the Greedy Mini-Extragradient (Mini-EG) method, which updates only the coordinate associated with the dominant component of the mapping at each extragradient step. This design capitalizes on componentwise Lipschitz constants that are far easier to estimate than the classical global Lipschitz constant. To further lower computational cost, we introduce a Random Mini-EG variant that replaces full mapping evaluations by sampling only a single coordinate per extragradient step. Although this resolves the second challenge from a theoretical standpoint, its practical efficiency remains limited. To bridge this gap, we develop the Watchdog-Max strategy, motivated by the slow decay of dominant component magnitudes. Instead of evaluating the full mapping, Watchdog-Max identifies and tracks only two coordinates at each extragradient step, dramatically reducing per-iteration cost while retaining strong practical performance. We establish convergence guarantees and rate analyses for all proposed methods. In particular, Greedy Mini-EG achieves enhanced convergence rates that surpass the classical guarantees of the vanilla EG method in several standard application settings. Numerical experiments on regularized decentralized logistic regression and compressed sensing show speedups exceeding $13\times$ compared with the classical EG method on both synthetic and real datasets.</description>
      <guid isPermaLink="false">oai:arXiv.org:2511.15254v1</guid>
      <category>math.OC</category>
      <pubDate>Thu, 20 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Xiaozhi Liu, Yong Xia</dc:creator>
    </item>
    <item>
      <title>RLS Framework with Segmentation of the Forgetting Profile and Low Rank Updates</title>
      <link>https://arxiv.org/abs/2511.15273</link>
      <description>arXiv:2511.15273v1 Announce Type: new 
Abstract: This report describes a new regularization approach based on segmentation of the forgetting profile in sliding window least squares estimation. Each segment is designed to enforce specific desirable properties of the estimator such as rapidity, desired condition number of the information matrix, accuracy, numerical stability, etc. The forgetting profile is divided in three segments, where the speed of estimation is ensured by the first segment, which employs rapid exponential forgetting of recent data.The second segment features a decline in the profile and marks the transition to the third segment, characterized by slow exponential forgetting to reduce the condition number of the information matrix using more distant data. Condition number reduction mitigates error propagation, thereby enhancing accuracy and stability. This approach facilitates the incorporation of a priori information regarding signal characteristics (i.e., the expected behavior of the signal) into the estimator. Recursive and computationally efficient algorithm with low rank updates based on new matrix inversion lemma for moving window associated with this regularization approach is developed. New algorithms significantly improve the approximation accuracy of low resolution daily temperature measurements obtained at the Stockholm Old Astronomical Observatory, thereby enhancing the reliability of temperature predictions.</description>
      <guid isPermaLink="false">oai:arXiv.org:2511.15273v1</guid>
      <category>math.OC</category>
      <category>cs.IT</category>
      <category>cs.NA</category>
      <category>math.DS</category>
      <category>math.IT</category>
      <category>math.NA</category>
      <pubDate>Thu, 20 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <arxiv:DOI>10.5120/ijca2025925940</arxiv:DOI>
      <dc:creator>Alexander Stotsky</dc:creator>
    </item>
    <item>
      <title>Complexity guarantees and polling strategies for Riemannian direct-search methods</title>
      <link>https://arxiv.org/abs/2511.15360</link>
      <description>arXiv:2511.15360v1 Announce Type: new 
Abstract: Direct-search algorithms are derivative-free optimization techniques that operate by polling the variable space along specific directions forming positive spanning sets (PSSs). When the problem variables are constrained to lie on a Riemannian manifold, polling must be performed along tangent directions. Although Riemannian variants of direct search have already been proposed and endowed with asymptotic guarantees, a proper generalization of PSSs on manifolds remains to be investigated. In particular, a measure of quality for those PSSs is required to obtain complexity bounds for direct search.
  In this paper, we derive complexity guarantees for a class of Riemannian direct-search techniques, and study two ways of generating positive spanning sets in tangent spaces. We pay particular attention the unit hypersphere case, for which we establish that generating directions directly within the tangent space leads to better complexity properties than projecting PSSs from the ambient space onto the tangent space. Our numerical experiments highlight the impact of dimension and codimension in more general settings.</description>
      <guid isPermaLink="false">oai:arXiv.org:2511.15360v1</guid>
      <category>math.OC</category>
      <pubDate>Thu, 20 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <dc:creator>Bastien Cavarretta, Florentin Goyens, Cl\'ement W. Royer, Florian Yger</dc:creator>
    </item>
    <item>
      <title>Optimal Neumann boundary and distributed control of the Westervelt equation with time-fractional attenuation</title>
      <link>https://arxiv.org/abs/2511.15382</link>
      <description>arXiv:2511.15382v1 Announce Type: new 
Abstract: Optimal control of nonlinear acoustic waves is relevant in many medical ultrasound technologies, ranging from cancer therapy to targeted drug delivery, where it can help guide the precise deposition of acoustic energy. In this work, we study Neumann boundary and distributed control problems for tracking a prescribed pressure field governed by the Westervelt equation with time-fractional dissipation. This model captures nonlinear ultrasonic wave propagation in biological media and accounts for the experimentally observed power-law attenuation. We begin by extending the existing well-posedness theory for time-fractional equations to include inhomogeneous Neumann boundary data used as control inputs, which requires constructing an appropriate data extension and regularization. Using these analytical results for the forward problem, we prove the existence of globally optimal controls and analyze the stability of the optimization problem with respect to perturbations in the target pressure field and to vanishing regularization parameters. Finally, we investigate the associated adjoint equation, which has state-dependent coefficients, and use it to derive first-order necessary optimality conditions.</description>
      <guid isPermaLink="false">oai:arXiv.org:2511.15382v1</guid>
      <category>math.OC</category>
      <category>math.AP</category>
      <pubDate>Thu, 20 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Vanja Nikoli\'c, Belkacem Said-Houari</dc:creator>
    </item>
    <item>
      <title>Generalized differentiation in Wasserstein space and application to multiagent control problem</title>
      <link>https://arxiv.org/abs/2511.15455</link>
      <description>arXiv:2511.15455v1 Announce Type: new 
Abstract: Several concepts of generalized differentiation in Wasserstein space have been proposed in order to deal with the intrinsic nonsmoothness arising in the context of optimization problems in Wasserstein spaces. In this paper we introduce a concept of admissible variation encompassing some of the most popular definitions as special cases, and using it to derive a comparison principle for viscosity solutions of an Hamilton Jacobi Bellman equation following from an optimal control of a multiagent systems.</description>
      <guid isPermaLink="false">oai:arXiv.org:2511.15455v1</guid>
      <category>math.OC</category>
      <category>math.AP</category>
      <pubDate>Thu, 20 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Rossana Capuani, Antonio Marigonda, Marc Quincampoix</dc:creator>
    </item>
    <item>
      <title>Existence and Uniqueness Theorem of Continuous and Monotone Bayesian Nash Equilibrium and Stability Analysis</title>
      <link>https://arxiv.org/abs/2511.15457</link>
      <description>arXiv:2511.15457v1 Announce Type: new 
Abstract: Since the seminal work by Meirowitz, there has been growing attention on the existence and uniqueness of continuous Bayesian Nash equilibria. In the existing literature, existence is typically established using Schauder's fixed-point theorem, relying on the equicontinuity of players' best response functions. Uniqueness, on the other hand, is usually derived under additional monotonicity conditions. In this paper, we revisit the issues of existence and uniqueness, and advance the literature by establishing both simultaneously using the Banach fixed-point theorem under a set of moderate conditions. Furthermore, we analyze the stability of such equilibria with respect to perturbations in the joint probability distribution of type parameters, offering theoretical support for the application of Bayesian Nash equilibrium models in data-driven contexts.</description>
      <guid isPermaLink="false">oai:arXiv.org:2511.15457v1</guid>
      <category>math.OC</category>
      <pubDate>Thu, 20 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Ziheng Su, Huifu Xu</dc:creator>
    </item>
    <item>
      <title>Real-Time Optimal Control via Transformer Networks and Bernstein Polynomials</title>
      <link>https://arxiv.org/abs/2511.15588</link>
      <description>arXiv:2511.15588v1 Announce Type: new 
Abstract: In this paper, we propose a Transformer-based framework for approximating solutions to infinite-dimensional optimization problems: calculus of variations problems and optimal control problems. Our approach leverages offline training on data generated by solving a sample of infinite- dimensional optimization problems using composite Bernstein collocation. Once trained, the Transformer efficiently generates near-optimal, feasible trajectories, making it well-suited for real-time applications. In motion planning for autonomous vehicles, for instance, these trajectories can serve to warm- start optimal motion planners or undergo rigorous evaluation to ensure safety. We demonstrate the effectiveness of this method through numerical results on a classical control problem and an online obstacle avoidance task. This data-driven approach offers a promising solution for real-time optimal control of nonlinear, nonconvex systems.</description>
      <guid isPermaLink="false">oai:arXiv.org:2511.15588v1</guid>
      <category>math.OC</category>
      <pubDate>Thu, 20 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Gage MacLin, Venanzio Cichella, Andrew Patterson, Irene Gregory</dc:creator>
    </item>
    <item>
      <title>GPU-Accelerated Dynamic Programming for Multistage Stochastic Energy Storage Arbitrage</title>
      <link>https://arxiv.org/abs/2511.15629</link>
      <description>arXiv:2511.15629v1 Announce Type: new 
Abstract: We develop a GPU-accelerated dynamic programming (DP) method for valuing, operating, and bidding energy storage under multistage stochastic electricity prices. Motivated by computational limitations in existing models, we formulate DP backward induction entirely in tensor-based algebraic operations that map naturally onto massively parallel GPU hardware. Our method accommodates general, potentially non-concave payoff structures, by combining a discretized DP formulation with a convexification procedure that produces market-feasible, monotonic price-quantity bid curves. Numerical experiments using ISO-NE real-time prices demonstrate up to a 100x speedup by the proposed GPU-based DP method relative to CPU computation, and an 8,000x speedup compared to a commercial MILP solver, while retaining sub-0.3% optimality gaps compared to exact benchmarks.</description>
      <guid isPermaLink="false">oai:arXiv.org:2511.15629v1</guid>
      <category>math.OC</category>
      <category>cs.SY</category>
      <category>eess.SY</category>
      <pubDate>Thu, 20 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Thomas Lee, Andy Sun</dc:creator>
    </item>
    <item>
      <title>Assessing Power Flow Controllability via Variable Line Reactance</title>
      <link>https://arxiv.org/abs/2511.15685</link>
      <description>arXiv:2511.15685v1 Announce Type: new 
Abstract: The rapid growth of large data center loads and inverter-based generation is increasing the stress on transmission networks, while expanding grid capacity at the required pace remains challenging. Power flow controllers (PFCs) that adjust effective line reactances to redistribute flows are often viewed as an interim solution to improve transmission network utilization. Traditional flexibility metrics and analysis approaches for PFCs focus on a limited number of operating points and contingencies. Towards gaining system-wide insights, this paper introduces a framework to quantify network flow controllability- the extent to which line flows can be reshaped through reactance adjustments. We derive analytical results demonstrating that installing PFCs on all lines enables complete controllability of feasible flow patterns. Building on these, we conduct empirical studies on the IEEE 39-bus system to examine how controllability varies with the number of PFCs and their reactance adjustment range. These analyses employ a mixed-integer linear program to optimize the siting and sizing of PFCs. Finally, we validate findings under AC power flow physics using an optimization routine that steers flows toward desired setpoints.</description>
      <guid isPermaLink="false">oai:arXiv.org:2511.15685v1</guid>
      <category>math.OC</category>
      <category>cs.SY</category>
      <category>eess.SY</category>
      <pubDate>Thu, 20 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Eric Haag, Yuhao Chen, Giri Venkataramanan, Manish K. Singh</dc:creator>
    </item>
    <item>
      <title>Optimal graph joining with applications to isomorphism detection and identification</title>
      <link>https://arxiv.org/abs/2511.14862</link>
      <description>arXiv:2511.14862v1 Announce Type: cross 
Abstract: We introduce an optimal transport based approach for comparing undirected graphs with non-negative edge weights and general vertex labels, and we study connections between the resulting linear program and the graph isomorphism problem. Our approach is based on the notion of a joining of two graphs $G$ and $H$, which is a product graph that preserves their marginal structure. Given $G$ and $H$ and a vertex-based cost function $c$, the optimal graph joining (OGJ) problem finds a joining of $G$ and $H$ minimizing degree weighted cost. The OGJ problem can be written as a linear program with a convex polyhedral solution set. We establish several basic properties of the OGJ problem, and present theoretical results connecting the OGJ problem to the graph isomorphism problem. In particular, we examine a variety of conditions on graph families that are sufficient to ensure that for every pair of graphs $G$ and $H$ in the family (i) $G$ and $H$ are isomorphic if and only if their optimal joining cost is zero, and (ii) if $G$ and $H$ are isomorphic, the the extreme points of the solution set of the OGJ problem are deterministic joinings corresponding to the isomorphisms from $G$ to $H$.</description>
      <guid isPermaLink="false">oai:arXiv.org:2511.14862v1</guid>
      <category>math.CO</category>
      <category>math.OC</category>
      <category>math.PR</category>
      <pubDate>Thu, 20 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Phuong N. Ho\`ang, Kevin McGoff, Andrew B. Nobel, Yang Xiang, Bongsoo Yi</dc:creator>
    </item>
    <item>
      <title>Va\u{i}nberg--Br\`{e}gman geometry and quasinonexpansive operators</title>
      <link>https://arxiv.org/abs/2511.14873</link>
      <description>arXiv:2511.14873v1 Announce Type: cross 
Abstract: We obtain an array of new results in the theory of Va\u{i}nberg--Br\`{e}gman relative entropies and quasinonexpansive operators on reflexive Banach spaces, and we also develop an extension of this theory to nonreflexive Banach spaces, providing a joint generalisation of the reflexive approach with the finite-dimensional information geometric approach. In the reflexive case, we study generalised pythagorean inequality, as well as norm-to-norm, uniform, and Lipschitz--H\"{o}lder continuity of entropic projections, proximal maps, and resolvents. We also provide a detailed account of the family of Va\u{i}nberg--Br\`{e}gman geometries that are naturally encoding the geometric properties of the underlying Banach space norm. The extended theory belongs to the intersection of convex theoretic and homeomorphic approaches to nonlinear analysis. Its models are constructed using integration theory on order unit spaces. Our main focus is on geometry of, and nonlinear quasinonexpansive operators on, normal state spaces of JBW- and W*-algebras, modelled via nonlinear embeddings into reflexive rearrangement invariant spaces. For example, we analyse the extended Va\u{i}nberg--Br\`{e}gman geometries induced by norm geometry of noncommutative and nonassociative L$_p$ spaces via Mazur embeddings, providing sufficient conditions for monoidal composability of extended quasinonexpansive operators, and computing the exponent parameters of Lipschitz--H\"{o}lder continuity of the corresponding extended entropic projections and resolvents. Other models feature the (commutative and noncommutative) Lozanovski\u{i} factorisation map, generalised spin factors, finite dimensional base normed spaces, and convex spectral functions on unitarily invariant ideals of compact operators. We also discuss several categories of entropic projections and quasinonexpansive operators naturally appearing in this framework.</description>
      <guid isPermaLink="false">oai:arXiv.org:2511.14873v1</guid>
      <category>math.FA</category>
      <category>math-ph</category>
      <category>math.MP</category>
      <category>math.OC</category>
      <pubDate>Thu, 20 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Ryshard-Pavel Kostecki</dc:creator>
    </item>
    <item>
      <title>A Graph-Based, Distributed Memory, Modeling Abstraction for Optimization</title>
      <link>https://arxiv.org/abs/2511.14966</link>
      <description>arXiv:2511.14966v1 Announce Type: cross 
Abstract: We present a general, flexible modeling abstraction for building and working with distributed optimization problems called a RemoteOptiGraph. This abstraction extends the OptiGraph model in Plasmo$.$jl, where optimization problems are represented as hypergraphs with nodes that define modular subproblems (variables, constraints, and objectives) and edges that encode algebraic linking constraints between nodes. The RemoteOptiGraph allows OptiGraphs to be utilized in distributed memory environments through InterWorkerEdges, which manage linking constraints that span workers. This abstraction offers a unified approach for modeling optimization problems on distributed memory systems (avoiding bespoke modeling approaches), and provides a basis for developing general-purpose meta-algorithms that can exploit distributed memory structure such as Benders or Lagrangian decompositions. We implement this abstraction in the open-source package, Plasmo$.$jl and we illustrate how it can be used by solving a mixed integer capacity expansion model for the western United States containing over 12 million variables and constraints. The RemoteOptiGraph abstraction together with Benders decomposition performs 7.5 times faster than solving the same problem without decomposition.</description>
      <guid isPermaLink="false">oai:arXiv.org:2511.14966v1</guid>
      <category>cs.DC</category>
      <category>cs.MS</category>
      <category>math.OC</category>
      <pubDate>Thu, 20 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>David L. Cole, Jordan Jalving, Jonah Langlieb, Jesse D. Jenkins</dc:creator>
    </item>
    <item>
      <title>Image Denoising Using Transformed L1 (TL1) Regularization via ADMM</title>
      <link>https://arxiv.org/abs/2511.15060</link>
      <description>arXiv:2511.15060v1 Announce Type: cross 
Abstract: Total variation (TV) regularization is a classical tool for image denoising, but its convex $\ell_1$ formulation often leads to staircase artifacts and loss of contrast. To address these issues, we introduce the Transformed $\ell_1$ (TL1) regularizer applied to image gradients. In particular, we develop a TL1-regularized denoising model and solve it using the Alternating Direction Method of Multipliers (ADMM), featuring a closed-form TL1 proximal operator and an FFT-based image update under periodic boundary conditions. Experimental results demonstrate that our approach achieves superior denoising performance, effectively suppressing noise while preserving edges and enhancing image contrast.</description>
      <guid isPermaLink="false">oai:arXiv.org:2511.15060v1</guid>
      <category>eess.IV</category>
      <category>cs.CV</category>
      <category>math.OC</category>
      <pubDate>Thu, 20 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Nabiha Choudhury, Jianqing Jia, Yifei Lou</dc:creator>
    </item>
    <item>
      <title>Nonholonomic Robot Parking by Feedback -- Part I: Modular Strict CLF Designs</title>
      <link>https://arxiv.org/abs/2511.15119</link>
      <description>arXiv:2511.15119v1 Announce Type: cross 
Abstract: It has been known in the robotics literature since about 1995 that, in polar coordinates, the nonholonomic unicycle is asymptotically stabilizable by smooth feedback, even globally. We introduce a modular design framework that selects the forward velocity to decouple the radial coordinate, allowing the steering subsystem to be stabilized independently. Within this structure, we develop families of feedback laws using passivity, backstepping, and integrator forwarding. Each law is accompanied by a strict control Lyapunov function, including barrier variants that enforce angular constraints. These strict CLFs provide constructive class KL convergence estimates and enable eigenvalue assignment at the target equilibrium. The framework generalizes and extends prior modular and nonmodular approaches, while preparing the ground for inverse optimal and adaptive redesigns in the sequel paper.</description>
      <guid isPermaLink="false">oai:arXiv.org:2511.15119v1</guid>
      <category>eess.SY</category>
      <category>cs.RO</category>
      <category>cs.SY</category>
      <category>math.DS</category>
      <category>math.OC</category>
      <pubDate>Thu, 20 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Velimir Todorovski, Kwang Hak Kim, Alessandro Astolfi, Miroslav Krstic</dc:creator>
    </item>
    <item>
      <title>Nonholonomic Robot Parking by Feedback -- Part II: Nonmodular, Inverse Optimal, Adaptive, Prescribed/Fixed-Time and Safe Designs</title>
      <link>https://arxiv.org/abs/2511.15219</link>
      <description>arXiv:2511.15219v1 Announce Type: cross 
Abstract: For the unicycle system, we provide constructive methods for the design of feedback laws that have one or more of the following properties: being nonmodular and globally exponentially stabilizing, inverse optimal, robust to arbitrary decrease or increase of input coefficients, adaptive, prescribed/fixed-time stabilizing, and safe (ensuring the satisfaction of state constraints). Our nonmodular backstepping feedbacks are implementable with either unidirectional or bidirectional velocity actuation. Thanks to constructing families of strict CLFs for the unicycle, we introduce a general design framework and families of feedback laws for the unicycle, which are inverse optimal with respect to meaningful costs. These inverse optimal feedback laws are endowed with robustness to actuator uncertainty and arbitrarily low input saturation due to the unicycle's driftlessness. Besides ensuring robustness to unknown input coefficients, we also develop adaptive laws for these unknown coefficients, enabling the achievement of good transient performance with lower initial control effort. Additionally, we develop controllers that achieve stabilization within a user-specified time horizon using two systematic methods: time-dilated prescribed-time design with smooth-in-time convergence to zero of both the states and the inputs and homogeneity-based fixed-time control that provides an explicit bound on the settling time. Finally, with a nonovershooting design we guarantee strictly forward motion without curb violation. This article, along with its Part I, lays a broad constructive design foundation for stabilization of the nonholonomic unicycle.</description>
      <guid isPermaLink="false">oai:arXiv.org:2511.15219v1</guid>
      <category>eess.SY</category>
      <category>cs.SY</category>
      <category>math.OC</category>
      <pubDate>Thu, 20 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Kwang Hak Kim, Velimir Todorovski, Miroslav Krsti\'c</dc:creator>
    </item>
    <item>
      <title>Optimizing Resource Distribution in a One-Dimensional Logistic Diffusion Model</title>
      <link>https://arxiv.org/abs/2511.15428</link>
      <description>arXiv:2511.15428v2 Announce Type: cross 
Abstract: In this article, we study the optimization of resource distributions in a one-dimensional logistic diffusive model. The goal is to determine a distribution on a bounded one-dimensional domain that maximizes the total population at equilibrium. Previous works have shown that optimal resources are bang-bang, and in one dimension, a sufficiently large dispersal rate forces the optimal resource to be concentrated. For general dispersal rates, however, the analysis becomes more difficult because the equilibrium population may behave irregularly, and the optimal resource may be fragmented. To address this, we introduce a block decomposition that reduces fragmented resources to a collection of concentrated blocks. We then define an advantage function, which measures the gain in the equilibrium population obtained by allocating resources on a fixed interval and is used to analyze the contribution of each block to the total population. This function also allows us to reformulate the optimization problem as a convexity analysis of the advantage function. We prove the superlinearity of this function when the total resource is small enough, and this property leads to an explicit characterization of the optimal control with sufficiently small total resource.</description>
      <guid isPermaLink="false">oai:arXiv.org:2511.15428v2</guid>
      <category>math.AP</category>
      <category>math.OC</category>
      <pubDate>Thu, 20 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Junyoung Heo, Yubin Lee</dc:creator>
    </item>
    <item>
      <title>Infinite Anticipation Backward Stochastic Differential Equations</title>
      <link>https://arxiv.org/abs/2511.15548</link>
      <description>arXiv:2511.15548v1 Announce Type: cross 
Abstract: In this paper, we introduce a new type of backward stochastic differential equations (BSDEs) with infinite anticipation, where the generator depends on the entire future values of the solution in infinite horizon. We show that the new BSDEs has a unique solution and admits a comparison result. In the end, we solve a stochastic control problem via a duality between BSDEs with infinite anticipation and stochastic differential equations (SDEs) with infinite delay.</description>
      <guid isPermaLink="false">oai:arXiv.org:2511.15548v1</guid>
      <category>math.PR</category>
      <category>math.OC</category>
      <pubDate>Thu, 20 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Guanwei Cheng, Shuzhen Yang</dc:creator>
    </item>
    <item>
      <title>Constraint-preserving quantum algorithm for the multi-frequency antenna placement problem</title>
      <link>https://arxiv.org/abs/2511.15566</link>
      <description>arXiv:2511.15566v1 Announce Type: cross 
Abstract: Quantum algorithms for combinatorial optimization typically encode constraints as soft penalties within the objective function, which can reduce efficiency and scalability compared to state-of-the-art classical methods that instead exploit constraints to guide the search toward high-quality solutions. Although solving this issue for an arbitrary problem is inherently a hard task, we address this challenge for a specific problem in the field of telecommunications, the multi-frequency antenna placement problem, by introducing a constraint-preserving quantum adiabatic algorithm (QAA). To this aim, we construct a quantum circuit that prepares an initial state comprising an equal superposition of all feasible solutions, and define a custom mixer that preserves both the one-hot encoding constraint for vertex coloring and the cardinality constraint on the number of antennas. This scheme can be extended to a broader range of applications characterized by similar constraints. We first benchmark the performance of this quantum algorithm against a basic version of QAA, demonstrating superior performance in terms of feasibility and success probability. We then apply this algorithm to large problem sizes with hundreds of variables using a constraint-aware decomposition method based on the SPLIT framework. Our results indicate competitive performance against other large-scale classical approaches, such as branch-and-bound and simulated annealing. This work supports previous claims that constraint-aware algorithms are crucial for the practical and efficient application of quantum methods in industrial settings.</description>
      <guid isPermaLink="false">oai:arXiv.org:2511.15566v1</guid>
      <category>quant-ph</category>
      <category>math.OC</category>
      <pubDate>Thu, 20 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Matteo Vandelli, Francesco Ferrari, Daniele Dragoni</dc:creator>
    </item>
    <item>
      <title>A Scenario Approach to the Robustness of Nonconvex-Nonconcave Minimax Problems</title>
      <link>https://arxiv.org/abs/2511.15606</link>
      <description>arXiv:2511.15606v1 Announce Type: cross 
Abstract: This paper investigates probabilistic robustness of nonconvex-nonconcave minimax problems via the scenario approach. Inspired by recent advances in scenario optimization (Garatti and Campi, 2025), we obtain robustness results for key equilibria with nonconvex-nonconcave payoffs, overcoming the dependence on the non-degeneracy assumption. Specifically, under convex strategy sets for all players, we first establish a probabilistic robustness guarantee for an epsilon-stationary point by proving the monotonicity of the stationary residual in the number of scenarios. Moreover, under nonconvex strategy sets for all players, we derive a probabilistic robustness guarantee for a global minimax point by invoking the extreme value theorem and Berge's maximum theorem. A numerical experiment on a unit commitment problem corroborates our theoretical findings.</description>
      <guid isPermaLink="false">oai:arXiv.org:2511.15606v1</guid>
      <category>cs.GT</category>
      <category>math.OC</category>
      <pubDate>Thu, 20 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Huan Peng, Guanpu Chen, Karl Henrik Johansson</dc:creator>
    </item>
    <item>
      <title>Economic Linear Quadratic MPC With Non-Unique Optimal Solutions</title>
      <link>https://arxiv.org/abs/2511.15630</link>
      <description>arXiv:2511.15630v1 Announce Type: cross 
Abstract: Asymptotic stability in economic receding horizon control can be obtained under a strict dissipativity assumption, related to positive-definiteness of a so-called rotated cost, and through the use of suitable terminal cost and constraints. In the linear-quadratic case, a common assumption is that the rotated cost is positive definite. The positive semi-definite case has received surprisingly little attention, and the connection to the standard dissipativity assumption has not been investigated. In this paper, we fill this gap by connecting existing results in economic model predictive control with the stability results for the semi-definite case, the properties of the constrained generalized discrete algebraic Riccati equation, and of two optimal control problems. Moreover, we extend recent results relating exponential stability to the choice of terminal cost in the absence of terminal constraints.</description>
      <guid isPermaLink="false">oai:arXiv.org:2511.15630v1</guid>
      <category>eess.SY</category>
      <category>cs.SY</category>
      <category>math.OC</category>
      <pubDate>Thu, 20 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <dc:creator>Mario Zanon</dc:creator>
    </item>
    <item>
      <title>Damped Proximal Augmented Lagrangian Method for weakly-Convex Problems with Convex Constraints</title>
      <link>https://arxiv.org/abs/2311.09065</link>
      <description>arXiv:2311.09065v3 Announce Type: replace 
Abstract: We give a damped proximal augmented Lagrangian method (DPALM) for solving problems with a weakly-convex objective and convex linear/nonlinear constraints. Instead of taking a full stepsize, DPALM adopts a damped dual stepsize to ensure the boundedness of dual iterates. We show that DPALM can produce a (near) $\vareps$-KKT point within $O(\vareps^{-2})$ outer iterations if each DPALM subproblem is solved to a proper accuracy. In addition, we establish overall iteration complexity of DPALM when the objective is either a regularized smooth function or in a regularized compositional form. For the former case, DPALM achieves the complexity of $\widetilde{\mathcal{O}}\left(\varepsilon^{-2.5} \right)$ to produce an $\varepsilon$-KKT point by applying an accelerated proximal gradient (APG) method to each DPALM subproblem. For the latter case, the complexity of DPALM is $\widetilde{\mathcal{O}}\left(\varepsilon^{-3} \right)$ to produce a near $\varepsilon$-KKT point by using an APG to solve a Moreau-envelope smoothed version of each subproblem. Our outer iteration complexity and the overall complexity either generalize existing best ones from unconstrained or linear-constrained problems to convex-constrained ones, or improve over the best-known results on solving the same-structured problems. Furthermore, numerical experiments on linearly/quadratically constrained non-convex quadratic programs and linear-constrained robust nonlinear least squares are conducted to demonstrate the empirical efficiency of the proposed DPALM over several state-of-the art methods.</description>
      <guid isPermaLink="false">oai:arXiv.org:2311.09065v3</guid>
      <category>math.OC</category>
      <category>cs.LG</category>
      <pubDate>Thu, 20 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Hari Dahal, Wei Liu, Yangyang Xu</dc:creator>
    </item>
    <item>
      <title>Globally-Constrained Decentralized Optimization with Variable Coupling</title>
      <link>https://arxiv.org/abs/2407.10770</link>
      <description>arXiv:2407.10770v4 Announce Type: replace 
Abstract: Many realistic decision-making problems in networked scenarios, such as formation control and collaborative task offloading, often involve complicatedly entangled local decisions, which, however, have not been sufficiently investigated yet. Motivated by this, we study a class of decentralized optimization problems with a variable coupling structure that is new to the literature. Specifically, we consider a network of nodes collaborating to minimize a global objective subject to a collection of global inequality and equality constraints, which are formed by the local objective and constraint functions of the nodes. On top of that, we allow such local functions of each node to depend on not only its own decision variable but the decisions of its neighbors as well. To address this problem, we propose a decentralized projected primal-dual algorithm. It first incorporates a virtual-queue technique with a primal-dual-primal scheme, and then linearizes the non-separable objective and constraint functions to enable decentralized implementation. Under mild conditions, we derive $O(1/k)$ convergence rates for both objective error and constraint violations. Finally, two numerical experiments corroborate our theoretical results and illustrate the competitive performance of the proposed algorithm.</description>
      <guid isPermaLink="false">oai:arXiv.org:2407.10770v4</guid>
      <category>math.OC</category>
      <pubDate>Thu, 20 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Dandan Wang, Xuyang Wu, Zichong Ou, Jie Lu</dc:creator>
    </item>
    <item>
      <title>Pathwise Optimal Control and Rough Fractional Hamilton-Jacobi-Bellman Equations for Rough-Fractional Dynamics</title>
      <link>https://arxiv.org/abs/2411.05488</link>
      <description>arXiv:2411.05488v3 Announce Type: replace 
Abstract: We use a rough path-based approach to investigate the degeneracy problem in the context of pathwise control. We extend the framework developed in arXiv:1902.05434 to treat admissible controls from a suitable class of H\"older continuous paths and simultaneously to handle a broader class of noise terms. Our approach uses fractional calculus to augment the original control equation, resulting in a system with added fractional dynamics. We adapt the existing analysis of fractional systems from the work of Gomoyunov arXiv:1908.01747, arXiv:2111.14400v1 , arXiv:2109.02451 to this new setting, providing a notion of a rough fractional viscosity solution for fractional systems that involve a noise term of arbitrarily low regularity. In this framework, following the method outlined in arXiv:1902.05434, we derive sufficient conditions to ensure that the control problem remains non-degenerate.</description>
      <guid isPermaLink="false">oai:arXiv.org:2411.05488v3</guid>
      <category>math.OC</category>
      <pubDate>Thu, 20 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Andrea Iannucci, Dan Crisan, Thomas Cass</dc:creator>
    </item>
    <item>
      <title>Stochastically Structured Reservoir Computers for Financial and Economic System Identification</title>
      <link>https://arxiv.org/abs/2507.17115</link>
      <description>arXiv:2507.17115v3 Announce Type: replace 
Abstract: This paper introduces a methodology for identifying and simulating financial and economic systems using stochastically structured reservoir computers (SSRCs). The framework combines structure-preserving embeddings with graph-informed coupling matrices to model inter-agent dynamics while enhancing interpretability. A constrained optimization scheme guarantees compliance with both stochastic and structural constraints. Two empirical case studies, a nonlinear stochastic dynamic model and regional inflation network dynamics, demonstrate the effectiveness of the approach in capturing complex nonlinear patterns and enabling interpretable predictive analysis under uncertainty.</description>
      <guid isPermaLink="false">oai:arXiv.org:2507.17115v3</guid>
      <category>math.OC</category>
      <category>cs.SY</category>
      <category>econ.TH</category>
      <category>eess.SY</category>
      <pubDate>Thu, 20 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Lendy Banegas, Fredy Vides</dc:creator>
    </item>
    <item>
      <title>Threshold dynamics in time-delay systems: polynomial $\beta$-control in a pressing process and connections to blow-up</title>
      <link>https://arxiv.org/abs/2508.07268</link>
      <description>arXiv:2508.07268v2 Announce Type: replace 
Abstract: This paper addresses a press control problem in straightening machines with small time delays due to system communication. To handle this, we propose a generalized $\beta$-control method, which replaces conventional linear velocity control with a polynomial of degree $\beta \ge 1$. The resulting model is a delay differential equation (DDE), for which we derive basic properties through nondimensionalization and analysis. Numerical experiments suggest the existence of a threshold initial velocity separating overshoot and non-overshoot dynamics, which we formulate as a conjecture. Based on this, we design a control algorithm under velocity constraints and confirm its effectiveness. We also highlight a connection between threshold behavior and finite-time blow-up in DDEs. This study provides a practical control strategy and contributes new insights into threshold dynamics and blow-up phenomena in delay systems.</description>
      <guid isPermaLink="false">oai:arXiv.org:2508.07268v2</guid>
      <category>math.OC</category>
      <category>cs.SY</category>
      <category>eess.SY</category>
      <category>math.DS</category>
      <pubDate>Thu, 20 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Masato Kimura, Hirotaka Kuma, Yikan Liu, Kazunori Matsui, Masahiro Yamamoto, Zhenxing Yang</dc:creator>
    </item>
    <item>
      <title>Solving Imaging Inverse Problems Using Plug-and-Play Denoisers: Regularization and Optimization Perspectives</title>
      <link>https://arxiv.org/abs/2509.03475</link>
      <description>arXiv:2509.03475v2 Announce Type: replace 
Abstract: Inverse problems lie at the heart of modern imaging science, with broad applications in areas such as medical imaging, remote sensing, and microscopy. Recent years have witnessed a paradigm shift in solving imaging inverse problems, where data-driven regularizers are used increasingly, leading to remarkably high-fidelity reconstruction. A particularly notable approach for data-driven regularization is to use learned image denoisers as implicit priors in iterative image reconstruction algorithms. This chapter presents a comprehensive overview of this powerful and emerging class of algorithms, commonly referred to as plug-and-play (PnP) methods. We begin by providing a brief background on image denoising and inverse problems, followed by a short review of traditional regularization strategies. We then explore how proximal splitting algorithms, such as the alternating direction method of multipliers (ADMM) and proximal gradient descent (PGD), can naturally accommodate learned denoisers in place of proximal operators, and under what conditions such replacements preserve convergence. The role of Tweedie's formula in connecting optimal Gaussian denoisers and score estimation is discussed, which lays the foundation for regularization-by-denoising (RED) and more recent diffusion-based posterior sampling methods. We discuss theoretical advances regarding the convergence of PnP algorithms, both within the RED and proximal settings, emphasizing the structural assumptions that the denoiser must satisfy for convergence, such as non-expansiveness, Lipschitz continuity, and local homogeneity. We also address practical considerations in algorithm design, including choices of denoiser architecture and acceleration strategies.</description>
      <guid isPermaLink="false">oai:arXiv.org:2509.03475v2</guid>
      <category>math.OC</category>
      <category>cs.LG</category>
      <category>eess.IV</category>
      <pubDate>Thu, 20 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Hong Ye Tan, Subhadip Mukherjee, Junqi Tang</dc:creator>
    </item>
    <item>
      <title>Uniform Sampling from the Reachable Set Using Optimal Transport</title>
      <link>https://arxiv.org/abs/2509.15571</link>
      <description>arXiv:2509.15571v2 Announce Type: replace 
Abstract: Estimating the reachable set of a dynamical system is a fundamental problem in control theory, particularly when control inputs are bounded. Direct simulation using randomly sampled admissible controls often leads to trajectories that cluster near attractors, resulting in poor coverage of the reachable set. To achieve a more uniform distribution of terminal states, we formulate the problem within an Optimal Transport (OT) framework. In this setting, the goal is to steer the system so that the final state distribution, determined by the chosen controls and initial conditions, matches a desired target distribution. Enforcing this condition exactly is not possible since the reachable set is not known. So we introduce an $L_2$-norm based regularization of the terminal distribution that relaxes the constraint while promoting uniform coverage. The resulting formulation can be approximated by a finite-dimensional, particle-based optimal control problem with kernel-coupled terminal cost. We show that this approach converges to the original formulation and demonstrate through numerical examples that it provides significantly more uniform reachable-set sampling than random control strategies.</description>
      <guid isPermaLink="false">oai:arXiv.org:2509.15571v2</guid>
      <category>math.OC</category>
      <category>cs.SY</category>
      <category>eess.SY</category>
      <pubDate>Thu, 20 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Karthik Elamvazhuthi, Sachin Shivakumar</dc:creator>
    </item>
    <item>
      <title>Overfitting in Adaptive Robust Optimization</title>
      <link>https://arxiv.org/abs/2509.16451</link>
      <description>arXiv:2509.16451v3 Announce Type: replace 
Abstract: Adaptive robust optimization (ARO) extends static robust optimization by allowing decisions to depend on the realized uncertainty - weakly dominating static solutions within the modeled uncertainty set. However, ARO makes previous constraints that were independent of uncertainty now dependent, making it vulnerable to additional infeasibilities when realizations fall outside the uncertainty set. This phenomenon of adaptive policies being brittle is analogous to overfitting in machine learning. To mitigate against this, we propose assigning constraint-specific uncertainty set sizes, with harder constraints given stronger probabilistic guarantees. Interpreted through the overfitting lens, this acts as regularization: tighter guarantees shrink adaptive coefficients to ensure stability, while looser ones preserve useful flexibility. This view motivates a principled approach to designing uncertainty sets that balances robustness and adaptivity.</description>
      <guid isPermaLink="false">oai:arXiv.org:2509.16451v3</guid>
      <category>math.OC</category>
      <category>cs.LG</category>
      <category>stat.ML</category>
      <pubDate>Thu, 20 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Karl Zhu, Dimitris Bertsimas</dc:creator>
    </item>
    <item>
      <title>ORACLE: A rigorous metric and method to explore all near-optimal designs for energy systems</title>
      <link>https://arxiv.org/abs/2509.26452</link>
      <description>arXiv:2509.26452v2 Announce Type: replace 
Abstract: Optimization models are fundamental tools for providing quantitative insights to decision-makers. However, models, objectives, and constraints do not capture all real-world factors accurately. Thus, instead of the single optimal solution, real-world stakeholders are often interested in the near-optimal space -- solutions that lie within a specified margin of the optimal objective value. Solutions in the near-optimal space can then be assessed regarding desirable non-modeled or qualitative aspects. The near-optimal space is usually explored by so-called Modelling to Generate Alternatives (MGA) methods. However, current MGA approaches mainly employ heuristics, which do not measure or guarantee convergence.
  We propose a method called ORACLE, which guarantees generation and exploration on the \emph{entire near-optimal} space by exploiting convexity. ORACLE iteratively approximates the near-optimal space by introducing a metric that both measures convergence and suggests exploration directions. Once the approximations are refined to a desired tolerance, any near-optimal designs can be generated with negligible computational effort.
  We compare our approach with existing methods on a sector-coupled energy system model of Switzerland. ORACLE is the only method able to guarantee convergence within a desired tolerance. Additionally, we show that heuristic MGA methods miss large areas of the near-optimal space, potentially skewing decision-making by leaving viable options for the energy transition off the table.</description>
      <guid isPermaLink="false">oai:arXiv.org:2509.26452v2</guid>
      <category>math.OC</category>
      <pubDate>Thu, 20 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>E. M. Turan, S. Moret, A. Bardow</dc:creator>
    </item>
    <item>
      <title>Flexibility aggregation via set projection for distribution grids with multiple interconnections</title>
      <link>https://arxiv.org/abs/2510.23352</link>
      <description>arXiv:2510.23352v2 Announce Type: replace 
Abstract: With the increasing number of flexible energy devices in distribution grids, coordination between Transmission System Operators (TSOs) and Distribution System Operators (DSOs) becomes critical for optimal system operation. One form of coordination is to solve the overall system operation problem in a hierarchical way, computing Feasible Operational Regions (FORs) for the interconnection between TSO/DSO. Most methods for computing FORs rely on the assumption of only one interconnection point between TSO and DSOs, which is often violated in practice. In this work, we propose a method for computing FORs in distribution grids with multiple interconnection points to the transmission grid. We test our method in a grid with two interconnecting points and analyze the properties of the resulting high-dimensional FOR from a power systems perspective.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.23352v2</guid>
      <category>math.OC</category>
      <category>cs.SY</category>
      <category>eess.SY</category>
      <pubDate>Thu, 20 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Ma\'isa Beraldo Bandeira, Alexander Engelmann, Timm Faulwasser</dc:creator>
    </item>
    <item>
      <title>Structured Symmetric Tensors</title>
      <link>https://arxiv.org/abs/2511.06966</link>
      <description>arXiv:2511.06966v2 Announce Type: replace 
Abstract: In this paper, we study structured symmetric tensors. We introduce several new classes of structured symmetric tensors: completely decomposable (CD) tensors, strictly sum of squares (SSOS) tensors and SOS$^*$ tensors. CD tensors have applications in data analysis and signal processing. Complete Hankel tensors are CD tensors. SSOS tensors are defined as SOS tensors with a positive definite Gram matrix, ensuring structural stability under perturbations. The SOS$^*$ cone is defined as the dual cone of the SOS tensor cone, with characterizations via moment matrices and polynomial nonnegativity. We study the relations among completely positive (CP) cones, CD cones, sum of squares (SOS) cones, positive semidefinite (PSD) cones and copositive (COP) cones. We identify the interiors of PSD, SOS, CP, COP and CD cones for even-order tensors. These characterizations are crucial for interior-point methods and stability analysis in polynomial and tensor optimization. We generalize the classical Schur product theorem to CD and CP tensors, including the case of strongly completely decomposable (SCD) and strongly completely positive (SCP) tensors. We identify equivalence between strictly CD (SCD) and positive definite (PD) for CD tensors. Furthermore, we give an example of a PSD but not SOS Hankel tensor. This answers an open question raised in the literature.</description>
      <guid isPermaLink="false">oai:arXiv.org:2511.06966v2</guid>
      <category>math.OC</category>
      <category>math.RA</category>
      <pubDate>Thu, 20 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Liqun Qi, Chunfeng Cui, Yi Xu</dc:creator>
    </item>
    <item>
      <title>Global Convergence of Four-Layer Matrix Factorization under Random Initialization</title>
      <link>https://arxiv.org/abs/2511.09925</link>
      <description>arXiv:2511.09925v2 Announce Type: replace 
Abstract: Gradient descent dynamics on the deep matrix factorization problem is extensively studied as a simplified theoretical model for deep neural networks. Although the convergence theory for two-layer matrix factorization is well-established, no global convergence guarantee for general deep matrix factorization under random initialization has been established to date. To address this gap, we provide a polynomial-time global convergence guarantee for randomly initialized gradient descent on four-layer matrix factorization, given certain conditions on the target matrix and a standard balanced regularization term. Our analysis employs new techniques to show saddle-avoidance properties of gradient decent dynamics, and extends previous theories to characterize the change in eigenvalues of layer weights.</description>
      <guid isPermaLink="false">oai:arXiv.org:2511.09925v2</guid>
      <category>math.OC</category>
      <category>cs.LG</category>
      <category>stat.ML</category>
      <pubDate>Thu, 20 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Minrui Luo, Weihang Xu, Xiang Gao, Maryam Fazel, Simon Shaolei Du</dc:creator>
    </item>
    <item>
      <title>Resource-Constrained Decentralized Federated Learning via Personalized Event-Triggering</title>
      <link>https://arxiv.org/abs/2211.12640</link>
      <description>arXiv:2211.12640v2 Announce Type: replace-cross 
Abstract: Federated learning (FL) is a popular technique for distributing machine learning (ML) across a set of edge devices. In this paper, we study fully decentralized FL, where in addition to devices conducting training locally, they carry out model aggregations via cooperative consensus formation over device-to-device (D2D) networks. We introduce asynchronous, event-triggered communications among the devices to handle settings where access to a central server is not feasible. To account for the inherent resource heterogeneity and statistical diversity challenges in FL, we define personalized communication triggering conditions at each device that weigh the change in local model parameters against the available local network resources. We theoretically recover the $O(\ln{k} / \sqrt{k})$ convergence rate to the globally optimal model of decentralized gradient descent (DGD) methods in the setup of our methodology. We provide our convergence guarantees for the last iterates of models, under relaxed graph connectivity and data heterogeneity assumptions compared with the existing literature. To do so, we demonstrate a $B$-connected information flow guarantee in the presence of sporadic communications over the time-varying D2D graph. Our subsequent numerical evaluations demonstrate that our methodology obtains substantial improvements in convergence speed and/or communication savings compared to existing decentralized FL baselines.</description>
      <guid isPermaLink="false">oai:arXiv.org:2211.12640v2</guid>
      <category>cs.LG</category>
      <category>cs.DC</category>
      <category>math.OC</category>
      <pubDate>Thu, 20 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Shahryar Zehtabi, Seyyedali Hosseinalipour, Christopher G. Brinton</dc:creator>
    </item>
    <item>
      <title>Distributed Event-Based Learning via ADMM</title>
      <link>https://arxiv.org/abs/2405.10618</link>
      <description>arXiv:2405.10618v3 Announce Type: replace-cross 
Abstract: We consider a distributed learning problem, where agents minimize a global objective function by exchanging information over a network. Our approach has two distinct features: (i) It substantially reduces communication by triggering communication only when necessary, and (ii) it is agnostic to the data-distribution among the different agents. We therefore guarantee convergence even if the local data-distributions of the agents are arbitrarily distinct. We analyze the convergence rate of the algorithm both in convex and nonconvex settings and derive accelerated convergence rates for the convex case. We also characterize the effect of communication failures and demonstrate that our algorithm is robust to these. The article concludes by presenting numerical results from distributed learning tasks on the MNIST and CIFAR-10 datasets. The experiments underline communication savings of 35% or more due to the event-based communication strategy, show resilience towards heterogeneous data-distributions, and highlight that our approach outperforms common baselines such as FedAvg, FedProx, SCAFFOLD and FedADMM.</description>
      <guid isPermaLink="false">oai:arXiv.org:2405.10618v3</guid>
      <category>cs.LG</category>
      <category>math.OC</category>
      <category>stat.ML</category>
      <pubDate>Thu, 20 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <arxiv:journal_reference>G. Dilsad Er, Sebastian Trimpe, and Michael Muehlebach, Distributed Event-Based Learning via ADMM, International Conference on Machine Learning 267 (2025), pp. 15384-15418</arxiv:journal_reference>
      <dc:creator>Guner Dilsad Er, Sebastian Trimpe, Michael Muehlebach</dc:creator>
    </item>
    <item>
      <title>Fast convergence of the Expectation Maximization algorithm under a logarithmic Sobolev inequality</title>
      <link>https://arxiv.org/abs/2407.17949</link>
      <description>arXiv:2407.17949v2 Announce Type: replace-cross 
Abstract: We present a new framework for analysing the Expectation Maximization (EM) algorithm. Drawing on recent advances in the theory of gradient flows over Euclidean-Wasserstein spaces, we extend techniques from alternating minimization in Euclidean spaces to the EM algorithm, via its representation as coordinate-wise minimization of the free energy. In so doing, we obtain finite sample error bounds and exponential convergence of the EM algorithm under a natural generalisation of the log-Sobolev inequality. We further show that this framework naturally extends to several variants of EM, offering a unified approach for studying such algorithms.</description>
      <guid isPermaLink="false">oai:arXiv.org:2407.17949v2</guid>
      <category>stat.ML</category>
      <category>cs.LG</category>
      <category>math.OC</category>
      <category>math.ST</category>
      <category>stat.CO</category>
      <category>stat.TH</category>
      <pubDate>Thu, 20 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <arxiv:DOI>10.1093/biomet/asaf061</arxiv:DOI>
      <arxiv:journal_reference>Biometrika, 112(4), 2025</arxiv:journal_reference>
      <dc:creator>Rocco Caprio, Adam M Johansen</dc:creator>
    </item>
    <item>
      <title>Revisiting Gradient Normalization and Clipping for Nonconvex SGD under Heavy-Tailed Noise: Necessity, Sufficiency, and Acceleration</title>
      <link>https://arxiv.org/abs/2410.16561</link>
      <description>arXiv:2410.16561v4 Announce Type: replace-cross 
Abstract: Gradient clipping has long been considered essential for ensuring the convergence of Stochastic Gradient Descent (SGD) in the presence of heavy-tailed gradient noise. In this paper, we revisit this belief and explore whether gradient normalization can serve as an effective alternative or complement. We prove that, under individual smoothness assumptions, gradient normalization alone is sufficient to guarantee convergence of the nonconvex SGD. Moreover, when combined with clipping, it yields far better rates of convergence under more challenging noise distributions. We provide a unifying theory describing normalization-only, clipping-only, and combined approaches. Moving forward, we investigate existing variance-reduced algorithms, establishing that, in such a setting, normalization alone is sufficient for convergence. Finally, we present an accelerated variant that under second-order smoothness improves convergence. Our results provide theoretical insights and practical guidance for using normalization and clipping in nonconvex optimization with heavy-tailed noise.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.16561v4</guid>
      <category>cs.LG</category>
      <category>math.OC</category>
      <category>stat.ML</category>
      <pubDate>Thu, 20 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/publicdomain/zero/1.0/</dc:rights>
      <dc:creator>Tao Sun, Xinwang Liu, Kun Yuan</dc:creator>
    </item>
    <item>
      <title>Global Convergence of Adjoint-Optimized Neural PDEs</title>
      <link>https://arxiv.org/abs/2506.13633</link>
      <description>arXiv:2506.13633v2 Announce Type: replace-cross 
Abstract: Many engineering and scientific fields have recently become interested in modeling terms in partial differential equations (PDEs) with neural networks, which requires solving the inverse problem of learning neural network terms from observed data in order to approximate missing or unresolved physics in the PDE model. The resulting neural-network PDE model, being a function of the neural network parameters, can be calibrated to the available ground truth data by optimizing over the PDE using gradient descent, where the gradient is evaluated in a computationally efficient manner by solving an adjoint PDE. These neural PDE models have emerged as an important research area in scientific machine learning. In this paper, we study the convergence of the adjoint gradient descent optimization method for training neural PDE models in the limit where both the number of hidden units and the training time tend to infinity. Specifically, for a general class of nonlinear parabolic PDEs with a neural network embedded in the source term, we prove convergence of the trained neural-network PDE solution to the target data (i.e., a global minimizer). The global convergence proof poses a unique mathematical challenge that is not encountered in finite-dimensional neural network convergence analyses due to (i) the neural network training dynamics involving a non-local neural network kernel operator in the infinite-width hidden layer limit where the kernel lacks a spectral gap for its eigenvalues and (ii) the nonlinearity of the limit PDE system, which leads to a non-convex optimization problem in the neural network function even in the infinite-width hidden layer limit (unlike in typical neural network training cases where the optimization problem becomes convex in the large neuron limit). The theoretical results are illustrated and empirically validated by numerical studies.</description>
      <guid isPermaLink="false">oai:arXiv.org:2506.13633v2</guid>
      <category>cs.LG</category>
      <category>cs.NA</category>
      <category>math.AP</category>
      <category>math.NA</category>
      <category>math.OC</category>
      <pubDate>Thu, 20 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Konstantin Riedl, Justin Sirignano, Konstantinos Spiliopoulos</dc:creator>
    </item>
    <item>
      <title>An inverse-free fixed-time stable dynamical system and its forward-Euler discretization for solving generalized absolute value equations</title>
      <link>https://arxiv.org/abs/2507.00531</link>
      <description>arXiv:2507.00531v2 Announce Type: replace-cross 
Abstract: An inverse-free dynamical system is proposed to solve the generalized absolute value equation (GAVE) with a fixed time convergence, where the time of convergence is finite and is uniformly bounded for all initial points. Moreover, an iterative method obtained by using the forward-Euler discretization of the proposed dynamic model is developed and sufficient conditions which guarantee that the discrete iteration globally converge to an arbitrarily small neighborhood of the unique solution of GAVE within a finite number of iterative steps are given. Numerical results illustrate the effectiveness of the proposed methods.</description>
      <guid isPermaLink="false">oai:arXiv.org:2507.00531v2</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <category>math.OC</category>
      <pubDate>Thu, 20 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Xuehua Li, Linjie Chen, Dongmei Yu, Cairong Chen, Deren Han</dc:creator>
    </item>
    <item>
      <title>MAP Estimation with Denoisers: Convergence Rates and Guarantees</title>
      <link>https://arxiv.org/abs/2507.15397</link>
      <description>arXiv:2507.15397v3 Announce Type: replace-cross 
Abstract: Denoiser models have become powerful tools for inverse problems, enabling the use of pretrained networks to approximate the score of a smoothed prior distribution. These models are often used in heuristic iterative schemes aimed at solving Maximum a Posteriori (MAP) optimisation problems, where the proximal operator of the negative log-prior plays a central role. In practice, this operator is intractable, and practitioners plug in a pretrained denoiser as a surrogate-despite the lack of general theoretical justification for this substitution. In this work, we show that a simple algorithm, closely related to several used in practice, provably converges to the proximal operator under a log-concavity assumption on the prior $p$. We show that this algorithm can be interpreted as a gradient descent on smoothed proximal objectives. Our analysis thus provides a theoretical foundation for a class of empirically successful but previously heuristic methods.</description>
      <guid isPermaLink="false">oai:arXiv.org:2507.15397v3</guid>
      <category>cs.LG</category>
      <category>math.OC</category>
      <category>stat.ML</category>
      <pubDate>Thu, 20 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Scott Pesme, Giacomo Meanti, Michael Arbel, Julien Mairal</dc:creator>
    </item>
    <item>
      <title>The Statistical Fairness-Accuracy Frontier</title>
      <link>https://arxiv.org/abs/2508.17622</link>
      <description>arXiv:2508.17622v2 Announce Type: replace-cross 
Abstract: Machine learning models must balance accuracy and fairness, but these goals often conflict, particularly when data come from multiple demographic groups. A useful tool for understanding this trade-off is the fairness-accuracy (FA) frontier, which characterizes the set of models that cannot be simultaneously improved in both fairness and accuracy. Prior analyses of the FA frontier provide a full characterization under the assumption of complete knowledge of population distributions -- an unrealistic ideal. We study the FA frontier in the finite-sample regime, showing how it deviates from its population counterpart and quantifying the worst-case gap between them. In particular, we derive minimax-optimal estimators that depend on the designer's knowledge of the covariate distribution. For each estimator, we characterize how finite-sample effects asymmetrically impact each group's risk, and identify optimal sample allocation strategies. Our results transform the FA frontier from a theoretical construct into a practical tool for policymakers and practitioners who must often design algorithms with limited data.</description>
      <guid isPermaLink="false">oai:arXiv.org:2508.17622v2</guid>
      <category>stat.ML</category>
      <category>cs.LG</category>
      <category>econ.TH</category>
      <category>math.OC</category>
      <pubDate>Thu, 20 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Alireza Fallah, Michael I. Jordan, Annie Ulichney</dc:creator>
    </item>
    <item>
      <title>Constrained bilinear optimal control of reactive evolution equations</title>
      <link>https://arxiv.org/abs/2510.15293</link>
      <description>arXiv:2510.15293v2 Announce Type: replace-cross 
Abstract: We consider constrained bilinear optimal control of second-order linear evolution partial differential equations (PDEs) with a reaction term on the half line, where control arises as a time-dependent reaction coefficient and constraints are imposed on the state and control variables. These PDEs represent a wide range of physical phenomena in fluid flow, heat, and mass transfer. Existing computational methods for this type of control problems only consider constraints on the control variable and lack global convergence guarantee. In this paper, we propose a novel optimize-then-discretize framework for computing constrained bilinear optimal control with both state and control constraints. Unlike existing methods that derive optimality conditions directly from the PDE constraint, this framework first replaces the PDE constraint with an equivalent integral representation of the PDE solution and then derives optimality conditions for the reformulated problem. The integral representation, derived from the unified transform method, does not involve differential operators, and thus explicit expressions for necessary conditions of optimality can be derived using the Karush-Kuhn-Tucker conditions for infinite-dimensional optimization. Discretizing the optimality conditions results in a system of finite-dimensional smooth nonlinear equations, which can be efficiently solved using existing algorithms with guaranteed global convergence at a quadratic rate. This is in contrast with discretize-then-optimize methods that discretize the PDE first and then solve the optimality conditions of the approximated finite-dimensional problem. Computational results for two applications, namely nuclear reactivity control and water quality treatment in a reactor, are presented to illustrate the effectiveness of the proposed framework.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.15293v2</guid>
      <category>physics.comp-ph</category>
      <category>math.OC</category>
      <pubDate>Thu, 20 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Zhexian Li, Felipe de Barros, Ketan Savla</dc:creator>
    </item>
  </channel>
</rss>
