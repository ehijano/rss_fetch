<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>cs.NI updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/cs.NI</link>
    <description>cs.NI updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/cs.NI" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Wed, 17 Dec 2025 02:40:32 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Tue, 16 Dec 2025 00:00:00 -0500</pubDate>
    <skipDays>
      <day>Saturday</day>
      <day>Sunday</day>
    </skipDays>
    <item>
      <title>Policy Gradient Algorithms for Age-of-Information Cost Minimization</title>
      <link>https://arxiv.org/abs/2512.11990</link>
      <description>arXiv:2512.11990v1 Announce Type: new 
Abstract: Recent developments in cyber-physical systems have increased the importance of maximizing the freshness of the information about the physical environment. However, optimizing the access policies of Internet of Things devices to maximize the data freshness, measured as a function of the Age-of-Information (AoI) metric, is a challenging task. This work introduces two algorithms to optimize the information update process in cyber-physical systems operating under the generate-at-will model, by finding an online policy without knowing the characteristics of the transmission delay or the age cost function. The optimization seeks to minimize the time-average cost, which integrates the AoI at the receiver and the data transmission cost, making the approach suitable for a broad range of scenarios. Both algorithms employ policy gradient methods within the framework of model-free reinforcement learning (RL) and are specifically designed to handle continuous state and action spaces. Each algorithm minimizes the cost using a distinct strategy for deciding when to send an information update. Moreover, we demonstrate that it is feasible to apply the two strategies simultaneously, leading to an additional reduction in cost. The results demonstrate that the proposed algorithms exhibit good convergence properties and achieve a time-average cost within 3% of the optimal value, when the latter is computable. A comparison with other state-of-the-art methods shows that the proposed algorithms outperform them in one or more of the following aspects: being applicable to a broader range of scenarios, achieving a lower time-average cost, and requiring a computational cost at least one order of magnitude lower.</description>
      <guid isPermaLink="false">oai:arXiv.org:2512.11990v1</guid>
      <category>cs.NI</category>
      <category>cs.IT</category>
      <category>cs.LG</category>
      <category>math.IT</category>
      <pubDate>Tue, 16 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <arxiv:DOI>10.1109/TCOMM.2025.3642695</arxiv:DOI>
      <dc:creator>Jos\'e-Ram\'on Vidal, Vicent Pla, Luis Guijarro, Israel Leyva-Mayorga</dc:creator>
    </item>
    <item>
      <title>A Leaner and Faster Web: How CBOR Can Improve Dynamic Content Encoding in JSON and DNS over HTTPS</title>
      <link>https://arxiv.org/abs/2512.12067</link>
      <description>arXiv:2512.12067v1 Announce Type: new 
Abstract: The Internet community has taken major efforts to decrease latency in the World Wide Web. Significant improvements have been achieved in accelerating content transport and in compressing static content. Less attention, however, has been dedicated to dynamic content compression. Such content is commonly provided by JSON and DNS over HTTPS. Aligned with the overall Web trend, dynamic content objects continue to grow in size, which increases latency and fosters the digital inequality. In this paper, we propose to counter this increase by utilizing components engineered for the constrained Internet of Things (IoT). We focus on the Concise Binary Object Representation (CBOR) and its use for dynamic content encoded in JSON or in DNS over HTTPS messages. CBOR was originally introduced to restrict packet sizes in constrained environments and enables small, effective encoding of data objects. We measure that simply switching the data representation from JSON to CBOR reduces data by up to 80.0% for a corpus of JSON objects collected via the HTTP Archive. This size reduction can decrease loading times by up to 13.8% when downloading large objects -- even in local setups. A new CBOR-based DNS message format designed for use with DNS over HTTPS (DoH) and DNS over CoAP (DoC) minimizes packets by up to 95.5% in its packed form and shows large potential for additionally compressing names and addresses. We contribute two name compression schemes that apply to the new CBOR format and save up to 226 bytes in a response. The decoder for our name compression scheme is lean and can fit into as little as 314 bytes of binary build size. One of those compression schemes and further optimization proposals directly influenced further improvements of the new CBOR format within Internet standardization.</description>
      <guid isPermaLink="false">oai:arXiv.org:2512.12067v1</guid>
      <category>cs.NI</category>
      <pubDate>Tue, 16 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Martine S. Lenders, Carsten Bormann, Thomas C. Schmidt, Matthias W\"ahlisch</dc:creator>
    </item>
    <item>
      <title>Dynamic SLA-aware Network Slice Monitoring</title>
      <link>https://arxiv.org/abs/2512.12123</link>
      <description>arXiv:2512.12123v1 Announce Type: new 
Abstract: Next-generation networks increasingly rely on network slices - logical networks tailored to specific application requirements, each with distinct Service-Level Agreements (SLAs). Ensuring compliance with these SLAs requires continuous, real-time monitoring of end-to-end performance metrics for each slice, within a limited telemetry budget. However, we find that existing solutions face two fundamental limitations: they either lack end-to-end visibility (e.g., sketches, probabilistic sampling) or provide visibility but lack the control mechanisms to dynamically allocate monitoring resources according to slice SLAs. We address this through a formal framework that reframes slice monitoring as a closed-loop control problem, and defines the minimal data plane requirements for SLA-aware slice monitoring via a telemetry primitive contract. We then present SliceScope, a realization of this framework that combines: (1) a control strategy that dynamically allocates the monitoring resources across diverse slices according to their SLA criticality, and (2) a data-plane based on change-triggered INT that provides per-packet end-to-end visibility with tunable accuracy-overhead trade-offs, satisfying the telemetry contract. Our evaluation results on programmable switches and in large-scale simulations with a mixture of different slice types, demonstrate that SliceScope tracks critical slices up to 4x more accurately compared to static baselines, while showing that change-triggered INT outperforms alternative primitives for realizing the telemetry primitive contract.</description>
      <guid isPermaLink="false">oai:arXiv.org:2512.12123v1</guid>
      <category>cs.NI</category>
      <pubDate>Tue, 16 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Niloy Saha, Mina Tahmasbi Arashloo, Nashid Shahriar, Raouf Boutaba</dc:creator>
    </item>
    <item>
      <title>Joint Power and Mobility Control</title>
      <link>https://arxiv.org/abs/2512.12137</link>
      <description>arXiv:2512.12137v1 Announce Type: new 
Abstract: This study addressed the challenge of improving network connectivity in autonomous V2X networks by jointly optimizing transmission power and vehicle mobility. We proposed a link reception model based on a sigmoid approximation of SINR and transformed it into a power-based formulation for simplicity in optimization. Building on this, we formulated a multi-node Network Utility Maximization (NUM) problem and demonstrated its concavity, enabling distributed trajectory and power adjustments. Both simulation and real-world experiments validated the theoretical findings, showing that symmetric positioning and balanced power allocation significantly enhance packet reception rates under interference-limited conditions. These results confirm that coordinated mobility and power control can effectively mitigate interference and improve connectivity in highly dynamic vehicular networks, paving the way for robust communication in future autonomous and UAV systems.</description>
      <guid isPermaLink="false">oai:arXiv.org:2512.12137v1</guid>
      <category>cs.NI</category>
      <pubDate>Tue, 16 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Yun Hou, Yening Zhang</dc:creator>
    </item>
    <item>
      <title>Agentic AI for 6G: A New Paradigm for Autonomous RAN Security Compliance</title>
      <link>https://arxiv.org/abs/2512.12400</link>
      <description>arXiv:2512.12400v1 Announce Type: new 
Abstract: Agentic AI systems are emerging as powerful tools for automating complex, multi-step tasks across various industries. One such industry is telecommunications, where the growing complexity of next-generation radio access networks (RANs) opens up numerous opportunities for applying these systems. Securing the RAN is a key area, particularly through automating the security compliance process, as traditional methods often struggle to keep pace with evolving specifications and real-time changes. In this article, we propose a framework that leverages LLM-based AI agents integrated with a retrieval-augmented generation (RAG) pipeline to enable intelligent and autonomous enforcement of security compliance. An initial case study demonstrates how an agent can assess configuration files for compliance with O-RAN Alliance and 3GPP standards, generate explainable justifications, and propose automated remediation if needed. We also highlight key challenges such as model hallucinations and vendor inconsistencies, along with considerations like agent security, transparency, and system trust. Finally, we outline future directions, emphasizing the need for telecom-specific LLMs and standardized evaluation frameworks.</description>
      <guid isPermaLink="false">oai:arXiv.org:2512.12400v1</guid>
      <category>cs.NI</category>
      <pubDate>Tue, 16 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Sotiris Chatzimiltis, Mahdi Boloursaz Mashhadi, Mohammad Shojafar, Merouane Debbah, Rahim Tafazolli</dc:creator>
    </item>
    <item>
      <title>Efficient Resource Allocation for Multi-User and Multi-Target MIMO-OFDM Underwater ISAC</title>
      <link>https://arxiv.org/abs/2512.12611</link>
      <description>arXiv:2512.12611v1 Announce Type: new 
Abstract: Integrated sensing and communication (ISAC) technology is crucial for next-generation underwater networks. However, covering multiple users and targets and balancing sensing and communication performance in complex underwater acoustic (UWA) environments remains challenging. This paper proposes an interleaved orthogonal frequency division multiplexing-based MIMO UWA-ISAC system, which employs a horizontal array to simultaneously transmit adaptive waveforms for downlink multi-user communication and omnidirectional target sensing. A multi-objective optimization framework is formulated to maximize the product of communication rate and range (PRR) while ensuring sensing performance and peak-to-average power ratio (PAPR) constraints. To solve this mixed-integer nonconvex problem, a two-dimensional grouped random search algorithm is developed, efficiently exploring subcarrier interleaved patterns and resource allocation schemes. Numerical simulations under real-world UWA channels demonstrate the designed system's superiority and effectiveness: our algorithm achieves 90% faster convergence than conventional exhaustive search with only a marginal 0.5 kbps km PRR degradation. Furthermore, the proposed resource allocation scheme maintains robustness beyond the baseline allocation schemes under stringent PRR and PAPR constraints.</description>
      <guid isPermaLink="false">oai:arXiv.org:2512.12611v1</guid>
      <category>cs.NI</category>
      <pubDate>Tue, 16 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Wei Men, Longfei Zhao, Yong Liang Guan, Xiangwang Hou, Yong Ren, Dusit Niyato</dc:creator>
    </item>
    <item>
      <title>Low-Complexity Monitoring and Compensation of Transceiver IQ Imbalance by Multi-dimensional Architecture for Dual-Polarization 16 Quadrature Amplitude Modulation</title>
      <link>https://arxiv.org/abs/2512.13266</link>
      <description>arXiv:2512.13266v1 Announce Type: new 
Abstract: In this paper, a low-complexity IQ imbalance compensation architecture is proposed, which reduces the effects of in-phase (I) and quadrature (Q) imbalance. The architecture consists of transceiver IQ skew estimation methods and a low-complexity MIMO equalizer structure. Before the IQ skew estimation, the chromatic dispersion(CD) is pre-compensated in the transmitter(TX) by chirp filtering. The receiver(RX) IQ skew is estimated by Gardner's phase detector, and the TX skew is estimated by finding the value that yields the lowest equalizer error. The low-complexity MIMO equalizer consists of a complex-valued MIMO(CV-MIMO) and a real-valued DD-LMS MIMO(RV-MIMO), which employ a butterfly and a non-butterfly structure, respectively. The CV-MIMO is used to perform polarization demultiplexing. The RV-MIMO equalizes each of the two polarisations and simultaneously compensates for the TX IQ imbalance. The architecture first compensates for the IQ skew at low-complexity, and the other imperfections are compensated by the low-complexity MIMO equalizer. Therefore, this architecture can equalize signals impaired by the transceiver IQ imbalance with low complexity. A 100 km transmission simulation and experiment with 36 Gbaud dual-polarization quadrature amplitude modulation(DP-QAM) signals and offline DSP showed that, with the RX IQ skew estimation, the number of real multiplications is reduced by more than 70% compared with conventional cases. With the low-complexity MIMO equalizer, the number of real multiplications is reduced by 51% compared with 4x4 MIMO</description>
      <guid isPermaLink="false">oai:arXiv.org:2512.13266v1</guid>
      <category>cs.NI</category>
      <category>cs.IT</category>
      <category>math.IT</category>
      <pubDate>Tue, 16 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Yukun Zhang, Xiaoxue Gong, Xu Zhang, Lei Guo</dc:creator>
    </item>
    <item>
      <title>Resource Orchestration and Optimization in 6G Extreme-edge Scenario</title>
      <link>https://arxiv.org/abs/2512.13306</link>
      <description>arXiv:2512.13306v1 Announce Type: new 
Abstract: 6G networks envision a pervasive service infrastructure spanning from centralized cloud to distributed edge and highly dynamic extreme-edge domains. This vision introduces significant challenges in orchestrating services over heterogeneous, volatile, and often mobile resources beyond traditional operator control. To address these challenges, this demo presents a 6G-ready orchestration architecture focused on resource prediction and service resilience at the extreme-edge. The proposed solution integrates (i) an AI/ML-based Infrastructure Status Prediction Module, (ii) a Monitoring System capable of handling large-scale, diverse telemetry, and (iii) a Decision Engine and Actuator that ensures proactive</description>
      <guid isPermaLink="false">oai:arXiv.org:2512.13306v1</guid>
      <category>cs.NI</category>
      <pubDate>Tue, 16 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <arxiv:DOI>10.1109/CSCN67557.2025.11230726</arxiv:DOI>
      <dc:creator>Manuel A. Jimenez, Sarang Kahvazadeh, Ignacio Labrador, Josep Mangues-Bafalluy</dc:creator>
    </item>
    <item>
      <title>Meta-Continual Mobility Forecasting for Proactive Handover Prediction</title>
      <link>https://arxiv.org/abs/2512.11841</link>
      <description>arXiv:2512.11841v1 Announce Type: cross 
Abstract: Short-term mobility forecasting is a core requirement for proactive handover (HO) in cellular networks. Real-world mobility is highly non-stationary: abrupt turns, rapid speed changes, and unpredictable user behavior cause conventional predictors to drift, leading to mistimed or failed handovers. We propose a lightweight meta-continual forecasting framework that integrates a GRU-based predictor, Reptile meta-initialization for fast few-shot adaptation, and an EWMA residual detector that triggers compact online updates only when drift occurs. Evaluated on a reproducible GeoLife and DeepMIMO pipeline, our method achieves 4.46 m ADE and 7.79 m FDE in zero-shot settings, improves few-shot ADE to 3.71 m at 10-shot, and enables recovery from abrupt drift about 2 to 3 times faster than an offline GRU. When applied to downstream HO prediction, the approach improves F1 to 0.83 and AUROC to 0.90, with substantial reductions in missed-HO and ping-pong events. The model is lightweight (128k parameters) and suitable for edge deployment in 5G and 6G systems.</description>
      <guid isPermaLink="false">oai:arXiv.org:2512.11841v1</guid>
      <category>cs.LG</category>
      <category>cs.NI</category>
      <pubDate>Tue, 16 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Sasi Vardhan Reddy Mandapati</dc:creator>
    </item>
    <item>
      <title>Should AI Become an Intergenerational Civil Right?</title>
      <link>https://arxiv.org/abs/2512.11892</link>
      <description>arXiv:2512.11892v1 Announce Type: cross 
Abstract: Artificial Intelligence (AI) is rapidly becoming a foundational layer of social, economic, and cognitive infrastructure. At the same time, the training and large-scale deployment of AI systems rely on finite and unevenly distributed energy, networking, and computational resources. This tension exposes a largely unexamined problem in current AI governance: while expanding access to AI is essential for social inclusion and equal opportunity, unconstrained growth in AI use risks unsustainable resource consumption, whereas restricting access threatens to entrench inequality and undermine basic rights.
  This paper argues that access to AI outputs largely derived from publicly produced knowledge should not be treated solely as a commercial service, but as a fundamental civil interest requiring explicit protection. We show that existing regulatory frameworks largely ignore the coupling between equitable access and resource constraints, leaving critical questions of fairness, sustainability, and long-term societal impact unresolved. To address this gap, we propose recognizing access to AI as an \emph{Intergenerational Civil Right}, establishing a legal and ethical framework that simultaneously safeguards present-day inclusion and the rights of future generations.
  Beyond normative analysis, we explore how this principle can be technically realized. Drawing on emerging paradigms in IoT--Edge--Cloud computing, decentralized inference, and energy-aware networking, we outline technological trajectories and a strawman architecture for AI Delivery Networks that support equitable access under strict resource constraints. By framing AI as a shared social infrastructure rather than a discretionary market commodity, this work connects governance principles with concrete system design choices, offering a pathway toward AI deployment that is both socially just and environmentally sustainable.</description>
      <guid isPermaLink="false">oai:arXiv.org:2512.11892v1</guid>
      <category>cs.CY</category>
      <category>cs.AI</category>
      <category>cs.NI</category>
      <pubDate>Tue, 16 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Jon Crowcroft, Rute C. Sofia, Dirk Trossen, Vassilis Tsaoussidis</dc:creator>
    </item>
    <item>
      <title>Strategic Server Deployment under Uncertainty in Mobile Edge Computing</title>
      <link>https://arxiv.org/abs/2512.12532</link>
      <description>arXiv:2512.12532v1 Announce Type: cross 
Abstract: Server deployment is a fundamental task in mobile edge computing: where to place the edge servers and what user cells to assign to them. To make this decision is context-specific, but common goals are 1) computing efficiency: maximize the amount of workload processed by the edge, and 2) communication efficiency: minimize the communication cost between the cells and their assigned servers. We focus on practical scenarios where the user workload in each cell is unknown and time-varying, and so are the effective capacities of the servers. Our research problem is to choose a subset of candidate servers and assign them to the user cells such that the above goals are sustainably achieved under the above uncertainties. We formulate this problem as a stochastic bilevel optimization, which is strongly NP-hard and unseen in the literature. By approximating the objective function with submodular functions, we can utilize state-of-the-art greedy algorithms for submodular maximization to effectively solve our problem. We evaluate the proposed algorithm using real-world data, showing its superiority to alternative methods; the improvement can be as high as 55%</description>
      <guid isPermaLink="false">oai:arXiv.org:2512.12532v1</guid>
      <category>cs.DC</category>
      <category>cs.NI</category>
      <pubDate>Tue, 16 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <arxiv:DOI>10.1080/17445760.2025.2605530</arxiv:DOI>
      <arxiv:journal_reference>International Journal of Parallel, Emergent and Distributed Systems 2025</arxiv:journal_reference>
      <dc:creator>Duc A. Tran, Dung Truong, Duy Le</dc:creator>
    </item>
    <item>
      <title>From Information Freshness to Semantics of Information and Goal-oriented Communications</title>
      <link>https://arxiv.org/abs/2512.12758</link>
      <description>arXiv:2512.12758v1 Announce Type: cross 
Abstract: Future wireless networks must support real-time, data-driven cyber-physical systems in which communication is tightly coupled with sensing, inference, control, and decision-making. Traditional communication paradigms centered on accuracy, throughput, and latency are increasingly inadequate for these systems, where the value of information depends on its semantic relevance to a specific task. This paper provides a unified exposition of the progression from classical distortion-based frameworks, through information freshness metrics such as the Age of Information (AoI) and its variants, to the emerging paradigm of goal-oriented semantics-aware communication. We organize and systematize existing semantics-aware metrics, including content- and version-aware measures, context-dependent distortion formulations, and history-dependent error persistence metrics that capture lasting impact and urgency. Within this framework, we highlight how these metrics address the limitations of purely accuracy- or freshness-centric designs, and how they collectively enable the selective generation and transmission of only task-relevant information. We further review analytical tools based on Markov decision process (MDP) and Lyapunov optimization methods that have been employed to characterize optimal or near-optimal timing and scheduling policies under semantic performance criteria and communication constraints. By synthesizing these developments into a coherent framework, the paper clarifies the design principles underlying goal-oriented, semantics-aware communication systems. It illustrates how they can significantly improve efficiency, reliability, and task performance. The presented perspective aims to serve as a bridge between information-theoretic, control-theoretic, and networking viewpoints, and to guide the design of semantic communication architectures for 6G and beyond.</description>
      <guid isPermaLink="false">oai:arXiv.org:2512.12758v1</guid>
      <category>cs.IT</category>
      <category>cs.NI</category>
      <category>cs.SY</category>
      <category>eess.SY</category>
      <category>math.IT</category>
      <pubDate>Tue, 16 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Jiping Luo, Erfan Delfani, Mehrdad Salimnejad, Nikolaos Pappas</dc:creator>
    </item>
    <item>
      <title>Optimal Resource Allocation for ML Model Training and Deployment under Concept Drift</title>
      <link>https://arxiv.org/abs/2512.12816</link>
      <description>arXiv:2512.12816v1 Announce Type: cross 
Abstract: We study how to allocate resources for training and deployment of machine learning (ML) models under concept drift and limited budgets. We consider a setting in which a model provider distributes trained models to multiple clients whose devices support local inference but lack the ability to retrain those models, placing the burden of performance maintenance on the provider. We introduce a model-agnostic framework that captures the interaction between resource allocation, concept drift dynamics, and deployment timing. We show that optimal training policies depend critically on the aging properties of concept durations. Under sudden concept changes, we derive optimal training policies subject to budget constraints when concept durations follow distributions with Decreasing Mean Residual Life (DMRL), and show that intuitive heuristics are provably suboptimal under Increasing Mean Residual Life (IMRL). We further study model deployment under communication constraints, prove that the associated optimization problem is quasi-convex under mild conditions, and propose a randomized scheduling strategy that achieves near-optimal client-side performance. These results offer theoretical and algorithmic foundations for cost-efficient ML model management under concept drift, with implications for continual learning, distributed inference, and adaptive ML systems.</description>
      <guid isPermaLink="false">oai:arXiv.org:2512.12816v1</guid>
      <category>cs.LG</category>
      <category>cs.NI</category>
      <pubDate>Tue, 16 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Hasan Burhan Beytur, Gustavo de Veciana, Haris Vikalo, Kevin S Chan</dc:creator>
    </item>
    <item>
      <title>Link-Aware Energy-Frugal Continual Learning for Fault Detection in IoT Networks</title>
      <link>https://arxiv.org/abs/2512.13340</link>
      <description>arXiv:2512.13340v1 Announce Type: cross 
Abstract: The use of lightweight machine learning (ML) models in internet of things (IoT) networks enables resource constrained IoT devices to perform on-device inference for several critical applications. However, the inference accuracy deteriorates due to the non-stationarity in the IoT environment and limited initial training data. To counteract this, the deployed models can be updated occasionally with new observed data samples. However, this approach consumes additional energy, which is undesirable for energy constrained IoT devices. This letter introduces an event-driven communication framework that strategically integrates continual learning (CL) in IoT networks for energy-efficient fault detection. Our framework enables the IoT device and the edge server (ES) to collaboratively update the lightweight ML model by adapting to the wireless link conditions for communication and the available energy budget. Evaluation on real-world datasets show that the proposed approach can outperform both periodic sampling and non-adaptive CL in terms of inference recall; our proposed approach achieves up to a 42.8% improvement, even under tight energy and bandwidth constraint.</description>
      <guid isPermaLink="false">oai:arXiv.org:2512.13340v1</guid>
      <category>cs.LG</category>
      <category>cs.NI</category>
      <pubDate>Tue, 16 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Henrik C. M. Frederiksen, Junya Shiraishi, Cedomir Stefanovic, Hei Victor Cheng, Shashi Raj Pandey</dc:creator>
    </item>
    <item>
      <title>Toward quantum-safe scalable networks: an open, standards-aware key management framework</title>
      <link>https://arxiv.org/abs/2509.09453</link>
      <description>arXiv:2509.09453v2 Announce Type: replace 
Abstract: With the advent of quantum computing, the increasing threats to security poses a great challenge to communication networks. Recent innovations in this field resulted in promising technologies such as Quantum Key Distribution (QKD), which enables the generation of unconditionally secure keys, establishing secure communications between remote nodes. Additionally, QKD networks enable the interconnection of multinode architectures, extending the point-to-point nature of QKD. However, due to the limitations of the current state of technology, the scalability of QKD networks remains a challenge toward feasible implementations. When it comes to long-distance implementations, trusted relay nodes partially solve the distance issue through the forwarding of the distributed keys, allowing applications that do not have a direct QKD link to securely share key material. Even though the relay procedure itself has been extensively studied, the establishment of the relaying node path still lacks a solution. This paper proposes an innovative network architecture that solves the challenges of Key Management System (KMS) identification, relay path discovery, and scalability of QKD networks by integrating Software-Defined Networking (SDN) principles, and establishing high-level virtual KMSs (vKMS) in each node and creating a new entity called the Quantum Security Controller (QuSeC). The vKMS serves the end-user key requests, managing the multiple KMSs within the node and abstracting the user from discovering the correct KMS. Additionally, based on the high-level view of the network topology and status, the QuSeC serves the path discovery requests from vKMSs, computing the end-to-end (E2E) relay path and applying security policies. The paper also provides a security analysis of the proposal, identifying the security levels of the architecture and analyzing the core networking security properties.</description>
      <guid isPermaLink="false">oai:arXiv.org:2509.09453v2</guid>
      <category>cs.NI</category>
      <pubDate>Tue, 16 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <arxiv:DOI>10.1109/MNET.2025.3636584</arxiv:DOI>
      <arxiv:journal_reference>IEEE Network, 2025</arxiv:journal_reference>
      <dc:creator>Ane Sanz, Asier Atutxa, David Franco, Jasone Astorga, Eduardo Jacob, Diego L\'opez</dc:creator>
    </item>
    <item>
      <title>BENNS: A Surrogate Model for Hybrid Online-Offline Evolution of SFC Embedding</title>
      <link>https://arxiv.org/abs/2509.16856</link>
      <description>arXiv:2509.16856v2 Announce Type: replace 
Abstract: Service Function Chains (SFCs) enable programmatic control of the functions and services in a computer network. By leveraging Software Defined Networking to control the links between virtualised network functions, SFCs provide a scalable approach to dealing with the increased pressures on network operation and management. However, embedding SFCs onto the underlying physical network and compute infrastructure is an NP-hard problem. Genetic Algorithms (GAs) have been used to address this issue, but they require significant time to evaluate solution quality (fitness) online, with most existing approaches instead adopting offline simulations or analytical evaluations.
  To enable online use of GAs in solving the SFC embedding problem, we introduce a hybrid online-offline approach to efficiently evaluate the fitness of generated solutions. At the core of this is BENNS: a surrogate model that approximates fitness and is agnostic to topology, traffic, and SFC-embedding. We evaluate our approach in a static environment across five experiments, varying available resources and traffic loads, and in a dynamic network environment. Our results demonstrate that our approach is capable of exploring thousands of potential configurations and generating deployable solutions in 19.1 minutes on average, compared to online-only approaches, which take 17.8 hours on average to explore ten solutions in our experiments and do not converge on an optimal solution.</description>
      <guid isPermaLink="false">oai:arXiv.org:2509.16856v2</guid>
      <category>cs.NI</category>
      <category>cs.NE</category>
      <pubDate>Tue, 16 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Theviyanthan Krishnamohan, Lauritz Thamsen, Paul Harvey</dc:creator>
    </item>
    <item>
      <title>RC-Gossip: Information Freshness in Clustered Networks with Rate-Changing Gossip</title>
      <link>https://arxiv.org/abs/2508.02657</link>
      <description>arXiv:2508.02657v2 Announce Type: replace-cross 
Abstract: A clustered gossip network is considered in which a source updates its information over time, and end-nodes, organized in clusters through clusterheads, are keeping track of it. The goal for the nodes is to remain as fresh as possible, i.e., have the same information as the source, which we assess by the long-term average binary freshness metric. We introduce a smart mechanism of information dissemination which we coin rate-changing gossip (RC-Gossip). Its main idea is that gossiping is directed towards nodes that need it the most, and hence the rate of gossiping changes based on the number of fresh nodes in the network at a given time. While Stochastic Hybrid System (SHS) analysis has been the norm in studying freshness of gossip networks, we present an equivalent way to analyze freshness using a renewal-reward-based approach. Using that, we show that RC-gossip significantly increases freshness of nodes in different clustered networks, with optimal cluster sizes, compared to traditional gossiping techniques.</description>
      <guid isPermaLink="false">oai:arXiv.org:2508.02657v2</guid>
      <category>cs.IT</category>
      <category>cs.NI</category>
      <category>eess.SP</category>
      <category>math.IT</category>
      <pubDate>Tue, 16 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Irtiza Hasan, Ahmed Arafa</dc:creator>
    </item>
    <item>
      <title>Decoding and Engineering the Phytobiome Communication for Smart Agriculture</title>
      <link>https://arxiv.org/abs/2508.03584</link>
      <description>arXiv:2508.03584v2 Announce Type: replace-cross 
Abstract: Smart agriculture applications, integrating technologies like the Internet of Things and machine learning/artificial intelligence (ML/AI) into agriculture, hold promise to address modern challenges of rising food demand, environmental pollution, and water scarcity. Alongside the concept of the phytobiome, which defines the area including the plant, its environment, and associated organisms, and the recent emergence of molecular communication (MC), there exists an important opportunity to advance agricultural science and practice using communication theory. In this article, we motivate to use the communication engineering perspective for developing a holistic understanding of the phytobiome communication and bridge the gap between the phytobiome communication and smart agriculture. Firstly, an overview of phytobiome communication via molecular and electrophysiological signals is presented and a multi-scale framework modeling the phytobiome as a communication network is conceptualized. Then, how this framework is used to model electrophysiological signals is demonstrated with plant experiments. Furthermore, possible smart agriculture applications, such as smart irrigation and targeted delivery of agrochemicals, through engineering the phytobiome communication are proposed. These applications merge ML/AI methods with the Internet of Bio-Nano-Things enabled by MC and pave the way towards more efficient, sustainable, and eco-friendly agricultural production. Finally, the implementation challenges, open research issues, and industrial outlook for these applications are discussed.</description>
      <guid isPermaLink="false">oai:arXiv.org:2508.03584v2</guid>
      <category>eess.SP</category>
      <category>cs.AI</category>
      <category>cs.ET</category>
      <category>cs.NI</category>
      <category>q-bio.MN</category>
      <pubDate>Tue, 16 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Fatih Gulec, Hamdan Awan, Nigel Wallbridge, Andrew W. Eckford</dc:creator>
    </item>
    <item>
      <title>SoK: Preconfirmations</title>
      <link>https://arxiv.org/abs/2510.02947</link>
      <description>arXiv:2510.02947v2 Announce Type: replace-cross 
Abstract: In recent years, significant research efforts have focused on improving blockchain throughput and confirmation speeds without compromising security. While decreasing the time it takes for a transaction to be included in the blockchain ledger enhances user experience, a fundamental delay still remains between when a transaction is issued by a user and when its inclusion is confirmed in the blockchain ledger. This delay limits user experience gains through the confirmation uncertainty it brings for users. This inherent delay in conventional blockchain protocols has led to the emergence of preconfirmation protocols -- protocols that provide users with early guarantees of eventual transaction confirmation.
  This article presents a Systematization of Knowledge (SoK) on preconfirmations. We present the core terms and definitions needed to understand preconfirmations, outline a general framework for preconfirmation protocols, and explore the economics and risks of preconfirmations. Finally, we survey and apply our framework to several implementations of real-world preconfirmation protocols, bridging the gap between theory and practice.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.02947v2</guid>
      <category>cs.CR</category>
      <category>cs.NI</category>
      <pubDate>Tue, 16 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Aikaterini-Panagiota Stouka, Conor McMenamin, Demetris Kyriacou, Lin Oshitani, Quentin Botha</dc:creator>
    </item>
    <item>
      <title>cMPI: Using CXL Memory Sharing for MPI One-Sided and Two-Sided Inter-Node Communications</title>
      <link>https://arxiv.org/abs/2510.05476</link>
      <description>arXiv:2510.05476v2 Announce Type: replace-cross 
Abstract: Message Passing Interface (MPI) is a foundational programming model for high-performance computing. MPI libraries traditionally employ network interconnects (e.g., Ethernet and InfiniBand) and network protocols (e.g., TCP and RoCE) with complex software stacks for cross-node communication. We present cMPI, the first work to optimize MPI point-to-point communication (both one-sided and two-sided) using CXL memory sharing on a real CXL platform, transforming cross-node communication into memory transactions and data copies within CXL memory, bypassing traditional network protocols. We analyze performance across various interconnects and find that CXL memory sharing achieves 7.2x-8.1x lower latency than TCP-based interconnects deployed in small- and medium-scale clusters. We address challenges of CXL memory sharing for MPI communication, including data object management over the dax representation [50], cache coherence, and atomic operations. Overall, cMPI outperforms TCP over standard Ethernet NIC and high-end SmartNIC by up to 49x and 72x in latency and bandwidth, respectively, for small messages.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.05476v2</guid>
      <category>cs.DC</category>
      <category>cs.AR</category>
      <category>cs.NI</category>
      <pubDate>Tue, 16 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <arxiv:DOI>10.1145/3712285.3759816</arxiv:DOI>
      <dc:creator>Xi Wang, Bin Ma, Jongryool Kim, Byungil Koh, Hoshik Kim, Dong Li</dc:creator>
    </item>
  </channel>
</rss>
