<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>cs.ET updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/cs.ET</link>
    <description>cs.ET updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/cs.ET" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Tue, 06 Jan 2026 03:17:50 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Mon, 05 Jan 2026 00:00:00 -0500</pubDate>
    <skipDays>
      <day>Sunday</day>
      <day>Saturday</day>
    </skipDays>
    <item>
      <title>On the Error Floor Evaluation of NOMA-Irregular Repetition Slotted ALOHA</title>
      <link>https://arxiv.org/abs/2601.00317</link>
      <description>arXiv:2601.00317v1 Announce Type: new 
Abstract: In this work, we provide a simple yet tight analytical approximation of the packet loss rate in the error floor region for a non-orthogonal multiple access (NOMA)-based irregular repetition slotted ALOHA (IRSA) scheme. Considering an Internet of Things (IoT) scenario, users randomly select both the number of replicas based on a designed degree distribution and the transmission power from predetermined levels, while successive interference cancellation (SIC) is performed at the receiver. Our derived packet loss rate expression in the finite length regime is promptly evaluated. Its accuracy is validated through Monte-Carlo simulations, demonstrating a strong match across channel loads, including those beyond the low load regime</description>
      <guid isPermaLink="false">oai:arXiv.org:2601.00317v1</guid>
      <category>cs.ET</category>
      <category>cs.NI</category>
      <pubDate>Mon, 05 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <arxiv:DOI>10.1109/TVT.2025.3593418</arxiv:DOI>
      <arxiv:journal_reference>IEEE Transactions on Vehicular Technology 2025</arxiv:journal_reference>
      <dc:creator>Estefan\'ia Recayte</dc:creator>
    </item>
    <item>
      <title>Two-Step Interference Cancellation for Energy Saving in Irregular Repetition Slotted ALOHA</title>
      <link>https://arxiv.org/abs/2601.00343</link>
      <description>arXiv:2601.00343v1 Announce Type: new 
Abstract: We evaluate a modification of irregular repetition slotted ALOHA (IRSA) involving intermediate decoding and early transmission termination by some nodes, upon their decoding success. This is meant to avoid unnecessary transmissions, thereby reducing energy consumption. We expect this to be particularly useful at low loads, where most transmissions can be avoided as they do not often result in a collision and are therefore redundant. To validate this proposal, we observe that most of the literature related to IRSA considers an asymptotic heavily loaded regime; thus, we also present a model of energy consumption and success probability for frames of limited length and low offered loads. Thanks to our analysis, also confirmed by simulation, we are able to show that the proposed technique is able to reduce IRSA energy consumption by minimizing transmissions, while preserving performance gains over standard ALOHA. For example, we are able to get a 33% energy saving at offered loads around 10% without affecting throughput.</description>
      <guid isPermaLink="false">oai:arXiv.org:2601.00343v1</guid>
      <category>cs.ET</category>
      <category>cs.NI</category>
      <pubDate>Mon, 05 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <arxiv:DOI>10.1109/GLOBECOM52923.2024.10901350</arxiv:DOI>
      <arxiv:journal_reference>GLOBECOM 2024 - 2024 IEEE Global Communications Conference</arxiv:journal_reference>
      <dc:creator>Estefan\'ia Recayte, Leonardo Badia, Andrea Munari</dc:creator>
    </item>
    <item>
      <title>Automated electrostatic characterization of quantum dot devices in single- and bilayer heterostructures</title>
      <link>https://arxiv.org/abs/2601.00067</link>
      <description>arXiv:2601.00067v1 Announce Type: cross 
Abstract: As quantum dot (QD)-based spin qubits advance toward larger, more complex device architectures, rapid, automated device characterization and data analysis tools become critical. The orientation and spacing of transition lines in a charge stability diagram (CSD) contain a fingerprint of a QD device's capacitive environment, making these measurements useful tools for device characterization. However, manually interpreting these features is time-consuming, error-prone, and impractical at scale. Here, we present an automated protocol for extracting underlying capacitive properties from CSDs. Our method integrates machine learning, image processing, and object detection to identify and track charge transitions across large datasets without manual labeling. We demonstrate this method using experimentally measured data from a strained-germanium single-quantum-well (planar) and a strained-germanium double-quantum-well (bilayer) QD device. Unlike for planar QD devices, CSDs in bilayer germanium heterostructure exhibit a larger set of transitions, including interlayer tunneling and distinct loading lines for the vertically stacked QDs, making them a powerful testbed for automation methods. By analyzing the properties of many CSDs, we can statistically estimate physically relevant quantities, like relative lever arms and capacitive couplings. Thus, our protocol enables rapid extraction of useful, nontrivial information about QD devices.</description>
      <guid isPermaLink="false">oai:arXiv.org:2601.00067v1</guid>
      <category>cond-mat.mes-hall</category>
      <category>cs.CV</category>
      <category>cs.ET</category>
      <category>cs.LG</category>
      <category>quant-ph</category>
      <pubDate>Mon, 05 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Merritt P. R. Losert, Dario Denora, Barnaby van Straaten, Michael Chan, Stefan D. Oosterhout, Lucas Stehouwer, Giordano Scappucci, Menno Veldhorst, Justyna P. Zwolak</dc:creator>
    </item>
    <item>
      <title>Toward Large-Scale Photonics-Empowered AI Systems: From Physical Design Automation to System-Algorithm Co-Exploration</title>
      <link>https://arxiv.org/abs/2601.00129</link>
      <description>arXiv:2601.00129v1 Announce Type: cross 
Abstract: In this work, we identify three considerations that are essential for realizing practical photonic AI systems at scale: (1) dynamic tensor operation support for modern models rather than only weight-static kernels, especially for attention/Transformer-style workloads; (2) systematic management of conversion, control, and data-movement overheads, where multiplexing and dataflow must amortize electronic costs instead of letting ADC/DAC and I/O dominate; and (3) robustness under hardware non-idealities that become more severe as integration density grows. To study these coupled tradeoffs quantitatively, and to ensure they remain meaningful under real implementation constraints, we build a cross-layer toolchain that supports photonic AI design from early exploration to physical realization. SimPhony provides implementation-aware modeling and rapid cross-layer evaluation, translating physical costs into system-level metrics so architectural decisions are grounded in realistic assumptions. ADEPT and ADEPT-Z enable end-to-end circuit and topology exploration, connecting system objectives to feasible photonic fabrics under practical device and circuit constraints. Finally, Apollo and LiDAR provide scalable photonic physical design automation, turning candidate circuits into manufacturable layouts while accounting for routing, thermal, and crosstalk constraints.</description>
      <guid isPermaLink="false">oai:arXiv.org:2601.00129v1</guid>
      <category>physics.optics</category>
      <category>cs.AI</category>
      <category>cs.AR</category>
      <category>cs.ET</category>
      <pubDate>Mon, 05 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Ziang Yin, Hongjian Zhou, Nicholas Gangi, Meng Zhang, Jeff Zhang, Zhaoran Rena Huang, Jiaqi Gu</dc:creator>
    </item>
    <item>
      <title>Democratizing Electronic-Photonic AI Systems: An Open-Source AI-Infused Cross-Layer Co-Design and Design Automation Toolflow</title>
      <link>https://arxiv.org/abs/2601.00130</link>
      <description>arXiv:2601.00130v1 Announce Type: cross 
Abstract: Photonics is becoming a cornerstone technology for high-performance AI systems and scientific computing, offering unparalleled speed, parallelism, and energy efficiency. Despite this promise, the design and deployment of electronic-photonic AI systems remain highly challenging due to a steep learning curve across multiple layers, spanning device physics, circuit design, system architecture, and AI algorithms. The absence of a mature electronic-photonic design automation (EPDA) toolchain leads to long, inefficient design cycles and limits cross-disciplinary innovation and co-evolution. In this work, we present a cross-layer co-design and automation framework aimed at democratizing photonic AI system development. We begin by introducing our architecture designs for scalable photonic edge AI and Transformer inference, followed by SimPhony, an open-source modeling tool for rapid EPIC AI system evaluation and design-space exploration. We then highlight advances in AI-enabled photonic design automation, including physical AI-based Maxwell solvers, a fabrication-aware inverse design framework, and a scalable inverse training algorithm for meta-optical neural networks, enabling a scalable EPDA stack for next-generation electronic-photonic AI systems.</description>
      <guid isPermaLink="false">oai:arXiv.org:2601.00130v1</guid>
      <category>physics.optics</category>
      <category>cs.AI</category>
      <category>cs.AR</category>
      <category>cs.ET</category>
      <pubDate>Mon, 05 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Hongjian Zhou, Ziang Yin, Jiaqi Gu</dc:creator>
    </item>
    <item>
      <title>Bio-inspired Agentic Self-healing Framework for Resilient Distributed Computing Continuum Systems</title>
      <link>https://arxiv.org/abs/2601.00339</link>
      <description>arXiv:2601.00339v1 Announce Type: cross 
Abstract: Human biological systems sustain life through extraordinary resilience, continually detecting damage, orchestrating targeted responses, and restoring function through self-healing. Inspired by these capabilities, this paper introduces ReCiSt, a bio-inspired agentic self-healing framework designed to achieve resilience in Distributed Computing Continuum Systems (DCCS). Modern DCCS integrate heterogeneous computing resources, ranging from resource-constrained IoT devices to high-performance cloud infrastructures, and their inherent complexity, mobility, and dynamic operating conditions expose them to frequent faults that disrupt service continuity. These challenges underscore the need for scalable, adaptive, and self-regulated resilience strategies. ReCiSt reconstructs the biological phases of Hemostasis, Inflammation, Proliferation, and Remodeling into the computational layers Containment, Diagnosis, Meta-Cognitive, and Knowledge for DCCS. These four layers perform autonomous fault isolation, causal diagnosis, adaptive recovery, and long-term knowledge consolidation through Language Model (LM)-powered agents. These agents interpret heterogeneous logs, infer root causes, refine reasoning pathways, and reconfigure resources with minimal human intervention. The proposed ReCiSt framework is evaluated on public fault datasets using multiple LMs, and no baseline comparison is included due to the scarcity of similar approaches. Nevertheless, our results, evaluated under different LMs, confirm ReCiSt's self-healing capabilities within tens of seconds with minimum of 10% of agent CPU usage. Our results also demonstrated depth of analysis to over come uncertainties and amount of micro-agents invoked to achieve resilience.</description>
      <guid isPermaLink="false">oai:arXiv.org:2601.00339v1</guid>
      <category>cs.AI</category>
      <category>cs.DC</category>
      <category>cs.ET</category>
      <category>cs.MA</category>
      <category>cs.NE</category>
      <pubDate>Mon, 05 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Alaa Saleh, Praveen Kumar Donta, Roberto Morabito, Sasu Tarkoma, Anders Lindgren, Qiyang Zhang, Schahram Dustdar, Susanna Pirttikangas, Lauri Lov\'en</dc:creator>
    </item>
    <item>
      <title>Multi-Satellite NOMA-Irregular Repetition Slotted ALOHA for IoT Networks</title>
      <link>https://arxiv.org/abs/2601.00341</link>
      <description>arXiv:2601.00341v1 Announce Type: cross 
Abstract: As the transition from 5G to 6G unfolds, a substantial increase in Internet of Things (IoT) devices is expected, enabling seamless and pervasive connectivity across various applications. Accommodating this surge and meeting the high capacity demands will necessitate the integration of NonTerrestrial Networks (NTNs). However, the extensive coverage area of satellites, relative to terrestrial receivers, will lead to a high density of users attempting to access the channel at the same time, increasing the collision probability. In turn, the deployment of mega constellations make it possible for ground users to be in visibility of more than one satellite at the same time, enabling receiver diversity. Therefore, in this paper, we evaluate the impact of multi-receivers in scenarios where IoT nodes share the channel following a non-orthogonal multiple access (NOMA)irregular repetition slotted ALOHA (IRSA) protocol. Considering the impairments of satellite channels, we derive a lower bound of system performance, serving as a fast tool for initial evaluation of network behavior. Additionally, we identify the trade-offs inherent to the network design parameters, with a focus on packet loss rate and energy efficiency. Notably, in the visibility of only one extra satellite as receiver yields significant gains in overall system performance.</description>
      <guid isPermaLink="false">oai:arXiv.org:2601.00341v1</guid>
      <category>cs.NI</category>
      <category>cs.ET</category>
      <pubDate>Mon, 05 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <arxiv:DOI>10.1109/ICC52391.2025.11160766</arxiv:DOI>
      <arxiv:journal_reference>ICC 2025 - IEEE International Conference on Communications</arxiv:journal_reference>
      <dc:creator>Estefan\'ia Recayte, Carla Amatetti</dc:creator>
    </item>
    <item>
      <title>RMAAT: Astrocyte-Inspired Memory Compression and Replay for Efficient Long-Context Transformers</title>
      <link>https://arxiv.org/abs/2601.00426</link>
      <description>arXiv:2601.00426v1 Announce Type: cross 
Abstract: The quadratic complexity of self-attention mechanism presents a significant impediment to applying Transformer models to long sequences. This work explores computational principles derived from astrocytes-glial cells critical for biological memory and synaptic modulation-as a complementary approach to conventional architectural modifications for efficient self-attention. We introduce the Recurrent Memory Augmented Astromorphic Transformer (RMAAT), an architecture integrating abstracted astrocyte functionalities. RMAAT employs a recurrent, segment-based processing strategy where persistent memory tokens propagate contextual information. An adaptive compression mechanism, governed by a novel retention factor derived from simulated astrocyte long-term plasticity (LTP), modulates these tokens. Attention within segments utilizes an efficient, linear-complexity mechanism inspired by astrocyte short-term plasticity (STP). Training is performed using Astrocytic Memory Replay Backpropagation (AMRB), a novel algorithm designed for memory efficiency in recurrent networks. Evaluations on the Long Range Arena (LRA) benchmark demonstrate RMAAT's competitive accuracy and substantial improvements in computational and memory efficiency, indicating the potential of incorporating astrocyte-inspired dynamics into scalable sequence models.</description>
      <guid isPermaLink="false">oai:arXiv.org:2601.00426v1</guid>
      <category>cs.NE</category>
      <category>cs.AI</category>
      <category>cs.ET</category>
      <category>cs.LG</category>
      <pubDate>Mon, 05 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Md Zesun Ahmed Mia, Malyaban Bal, Abhronil Sengupta</dc:creator>
    </item>
    <item>
      <title>Quantum Simulation of Protein Fragment Electronic Structure Using Moment-based Adaptive Variational Quantum Algorithms</title>
      <link>https://arxiv.org/abs/2601.00656</link>
      <description>arXiv:2601.00656v1 Announce Type: cross 
Abstract: Background: Understanding electronic interactions in protein active sites is fundamental to drug discovery and enzyme engineering, but remains computationally challenging due to exponential scaling of quantum mechanical calculations.
  Results: We present a quantum-classical hybrid framework for simulating protein fragment electronic structure using variational quantum algorithms. We construct fermionic Hamiltonians from experimentally determined protein structures, map them to qubits via Jordan-Wigner transformation, and optimize ground state energies using the Variational Quantum Eigensolver implemented in pure Python. For a 4-orbital serine protease fragment, we achieve chemical accuracy (&lt; 1.6 mHartree) with 95.3% correlation energy recovery. Systematic analysis reveals three-phase convergence behaviour with exponential decay ({\alpha} = 0.95), power law optimization ({\gamma} = 1.21), and asymptotic approach. Application to SARS-CoV-2 protease inhibition demonstrates predictive accuracy (MAE=0.25 kcal/mol), while cytochrome P450 metabolism predictions achieve 85% site accuracy.
  Conclusions: This work establishes a pathway for quantum-enhanced biomolecular simulations on near-term quantum hardware, bridging quantum algorithm development with practical biological applications.</description>
      <guid isPermaLink="false">oai:arXiv.org:2601.00656v1</guid>
      <category>q-bio.QM</category>
      <category>cs.ET</category>
      <pubDate>Mon, 05 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Biraja Ghoshal</dc:creator>
    </item>
    <item>
      <title>Assessing Quantum Annealing to Solve the Minimum Vertex Multicut</title>
      <link>https://arxiv.org/abs/2601.00711</link>
      <description>arXiv:2601.00711v1 Announce Type: cross 
Abstract: Cybersecurity in telecommunication networks often leads to hard combinatorial optimization problems that are challenging to solve with classical methods. This work investigates the practical feasibility of using quantum annealing to address the Restricted Vertex Minimum Multicut Problem. The problem is formulated as a Quadratic Unconstrained Binary Optimization model and implemented on D-Wave s quantum annealer. Rather than focusing on solution quality alone, we analyze key aspects of the quantum workflow including minor embedding techniques, chain length, topology constraints, chain strength selection, unembedding procedures, and postprocessing. Our results show that quantum annealing faces substantial hardware-level constraints limitations in embedding and scalability, especially for large instances, while hybrid quantum-classical solvers provide improved feasibility. This study offers a realistic assessment of the D-Wave system s current capabilities and identifies crucial parameters that govern the success of quantum optimization in cybersecurity-related network problems.</description>
      <guid isPermaLink="false">oai:arXiv.org:2601.00711v1</guid>
      <category>quant-ph</category>
      <category>cs.ET</category>
      <pubDate>Mon, 05 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Ali Abbassi, Yann Dujardin, Eric Gourdin, Philippe Lacomme, Caroline Prodhon</dc:creator>
    </item>
    <item>
      <title>Parameter Training Efficiency Aware Resource Allocation for AIGC in Space-Air-Ground Integrated Networks</title>
      <link>https://arxiv.org/abs/2406.13602</link>
      <description>arXiv:2406.13602v3 Announce Type: replace 
Abstract: With the evolution of artificial intelligence-generated content (AIGC) techniques and the development of space-air-ground integrated networks (SAGIN), there will be a growing opportunity to enhance more users' mobile experience with customized AIGC applications. This is made possible through the use of parameter-efficient fine-tuning (PEFT) training alongside mobile edge computing. In this paper, we formulate the optimization problem of maximizing the parameter training efficiency of the SAGIN system over wireless networks under limited resource constraints. We propose the Parameter training efficiency Aware Resource Allocation (PARA) technique to jointly optimize user association, data offloading, and communication and computational resource allocation. Solid proofs are presented to solve this difficult sum of ratios problem based on quadratically constrained quadratic programming (QCQP), semidefinite programming (SDP), graph theory, and fractional programming (FP) techniques. Our proposed PARA technique is effective in finding a stationary point of this non-convex problem. The simulation results demonstrate that the proposed PARA method outperforms other baselines.</description>
      <guid isPermaLink="false">oai:arXiv.org:2406.13602v3</guid>
      <category>cs.ET</category>
      <category>eess.SP</category>
      <pubDate>Mon, 05 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Liangxin Qian, Peiyuan Si, Jun Zhao, Kwok-Yan Lam</dc:creator>
    </item>
    <item>
      <title>Classical and Quantum Heuristics for the Binary Paint Shop Problem</title>
      <link>https://arxiv.org/abs/2509.15294</link>
      <description>arXiv:2509.15294v2 Announce Type: replace-cross 
Abstract: The Binary Paint Shop Problem (BPSP) is an $\mathsf{APX}$-hard optimisation problem in automotive manufacturing: given a sequence of $2n$ cars, comprising $n$ distinct models each appearing twice, the task is to decide which of two colours to paint each car so that the two occurrences of each model are painted differently, while minimising consecutive colour swaps. The key performance metric is the paint swap ratio, the average number of colour changes per car, which directly impacts production efficiency and cost. Prior work showed that the Quantum Approximate Optimisation Algorithm (QAOA) at depth $p=7$ achieves a paint swap ratio of $0.393$, outperforming the classical Recursive Greedy (RG) heuristic with an expected ratio of $0.4$ [Phys. Rev. A 104, 012403 (2021)]. More recently, the classical Recursive Star Greedy (RSG) heuristic was conjectured to achieve an expected ratio of $0.361$. In this study, we develop the theoretical foundations for applying QAOA to BPSP through a reduction of BPSP to weighted MaxCut, and use this framework to benchmark two state-of-the-art low-depth QAOA variants, eXpressive QAOA (XQAOA) and Recursive QAOA (RQAOA), at $p=1$ (denoted XQAOA$_1$ and RQAOA$_1$), against the strongest classical heuristics known to date. Across instances ranging from $2^7$ to $2^{12}$ cars, XQAOA$_1$ achieves an average ratio of $0.357$, surpassing RQAOA$_1$ and all classical heuristics, including the conjectured performance of RSG. Surprisingly, RQAOA$_1$ shows diminishing performance as size increases: despite using provably optimal QAOA$_1$ parameters at each recursion, it is outperformed by RSG on most $2^{11}$-car instances and all $2^{12}$-car instances. To our knowledge, this is the first study to report RQAOA$_1$'s performance degradation at scale. In contrast, XQAOA$_1$ remains robust, indicating strong potential to asymptotically surpass all known heuristics.</description>
      <guid isPermaLink="false">oai:arXiv.org:2509.15294v2</guid>
      <category>quant-ph</category>
      <category>cs.DS</category>
      <category>cs.ET</category>
      <category>math.OC</category>
      <pubDate>Mon, 05 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>V Vijendran, Dax Enshan Koh, Ping Koy Lam, Syed M Assad</dc:creator>
    </item>
  </channel>
</rss>
