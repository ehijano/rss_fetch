<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>cs.DS updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/cs.DS</link>
    <description>cs.DS updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/cs.DS" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Thu, 08 Jan 2026 05:00:01 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Thu, 08 Jan 2026 00:00:00 -0500</pubDate>
    <skipDays>
      <day>Saturday</day>
      <day>Sunday</day>
    </skipDays>
    <item>
      <title>Optimizing Exact String Matching via Statistical Anchoring</title>
      <link>https://arxiv.org/abs/2601.03271</link>
      <description>arXiv:2601.03271v1 Announce Type: new 
Abstract: In this work, we propose an enhancement to the Boyer-Moore-Horspool algorithm tailored for natural language text. The approach involves preprocessing the search pattern to identify its statistically least frequent character, referred to as the "anchor." During the search, verification is first performed at this high-entropy position, allowing the algorithm to quickly discard non-matching windows. This fail-fast strategy reduces unnecessary comparisons, improving overall efficiency. Our implementation shows that incorporating basic linguistic statistics into classical pattern-matching techniques can boost performance without increasing complexity to the shift heuristics.</description>
      <guid isPermaLink="false">oai:arXiv.org:2601.03271v1</guid>
      <category>cs.DS</category>
      <pubDate>Thu, 08 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Omar Garraoui</dc:creator>
    </item>
    <item>
      <title>Counting hypertriangles through hypergraph orientations</title>
      <link>https://arxiv.org/abs/2601.03573</link>
      <description>arXiv:2601.03573v1 Announce Type: new 
Abstract: Counting the number of small patterns is a central task in network analysis. While this problem is well studied for graphs, many real-world datasets are naturally modeled as hypergraphs, motivating the need for efficient hypergraph motif counting algorithms. In particular, we study the problem of counting hypertriangles - collections of three pairwise-intersecting hyperedges. These hypergraph patterns have a rich structure with multiple distinct intersection patterns unlike graph triangles.
  Inspired by classical graph algorithms based on orientations and degeneracy, we develop a theoretical framework that generalizes these concepts to hypergraphs and yields provable algorithms for hypertriangle counting. We implement these ideas in DITCH (Degeneracy Inspired Triangle Counter for Hypergraphs) and show experimentally that it is 10-100x faster and more memory efficient than existing state-of-the-art methods.</description>
      <guid isPermaLink="false">oai:arXiv.org:2601.03573v1</guid>
      <category>cs.DS</category>
      <category>cs.DB</category>
      <category>cs.SI</category>
      <pubDate>Thu, 08 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Daniel Paul-Pena, Vaishali Surianarayanan, Deeparnab Chakrabarty, C. Seshadhri</dc:creator>
    </item>
    <item>
      <title>On $k$-connectivity oracles in $k$-connected graphs</title>
      <link>https://arxiv.org/abs/2601.03643</link>
      <description>arXiv:2601.03643v1 Announce Type: new 
Abstract: A $k$-connectivity oracle for a graph $G=(V,E)$ is a data structure that given $s,t \in V$ determines whether there are at least $k+1$ internally disjoint $st$-paths in $G$. For undirected graphs, Pettie, Saranurak &amp; Yin [STOC 2022, pp. 151-161] proved that any $k$-connectivity oracle requires $\Omega(kn)$ bits of space. They asked whether $\Omega(kn)$ bits are still necessary if $G$ is $k$-connected. We will show by a very simple proof that this is so even if $G$ is $k$-connected, answering this open question.</description>
      <guid isPermaLink="false">oai:arXiv.org:2601.03643v1</guid>
      <category>cs.DS</category>
      <pubDate>Thu, 08 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Zeev Nutov</dc:creator>
    </item>
    <item>
      <title>Complexity of Perfect and Ideal Resilience Verification in Fast Re-Route Networks</title>
      <link>https://arxiv.org/abs/2601.03934</link>
      <description>arXiv:2601.03934v1 Announce Type: new 
Abstract: To achieve fast recovery from link failures, most modern communication networks feature fully decentralized fast re-routing mechanisms. These re-routing mechanisms rely on pre-installed static re-routing rules at the nodes (the routers), which depend only on local failure information, namely on the failed links incident to the node. Ideally, a network is perfectly resilient: the re-routing rules ensure that packets are always successfully routed to their destinations as long as the source and the destination are still physically connected in the underlying network after the failures. Unfortunately, there are examples where achieving perfect resilience is not possible. Surprisingly, only very little is known about the algorithmic aspect of when and how perfect resilience can be achieved.
  We investigate the computational complexity of analyzing such local fast re-routing mechanisms. Our main result is a negative one: we show that even checking whether a given set of static re-routing rules ensures perfect resilience is coNP-complete. We also show coNP-completeness of the so-called ideal resilience, a weaker notion of resilience often considered in the literature. Additionally, we investigate other fundamental variations of the problem. In particular, we show that our coNP-completeness proof also applies to scenarios where the re-routing rules have specific patterns (known as skipping in the literature).
  On the positive side, for scenarios where nodes do not have information about the link from which a packet arrived (the so-called in-port), we present linear-time algorithms for both the verification and synthesis problem for perfect resilience.</description>
      <guid isPermaLink="false">oai:arXiv.org:2601.03934v1</guid>
      <category>cs.DS</category>
      <pubDate>Thu, 08 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Matthias Bentert, Esra Ceylan-Kettler, Valentin H\"ubner, Stefan Schmid, Ji\v{r}\'i Srba</dc:creator>
    </item>
    <item>
      <title>A Polynomial Kernel for Face Cover on Non-Embedded Planar Graphs</title>
      <link>https://arxiv.org/abs/2601.04169</link>
      <description>arXiv:2601.04169v1 Announce Type: new 
Abstract: Given a planar graph, a subset of its vertices called terminals, and $k \in \mathbb{N}$, the Face Cover Number problem asks whether the terminals lie on the boundaries of at most $k$ faces of some embedding of the input graph. When a plane graph is given in the input, the problem is known to have a polynomial kernel~\cite{GarneroST17}. In this paper, we present the first polynomial kernel for Face Cover Number when the input is a planar graph (without a fixed embedding). Our approach overcomes the challenge of not having a predefined set of face boundaries by building a kernel bottom-up on an SPR-tree while preserving the essential properties of the face cover along the way.</description>
      <guid isPermaLink="false">oai:arXiv.org:2601.04169v1</guid>
      <category>cs.DS</category>
      <category>cs.CC</category>
      <category>cs.DM</category>
      <pubDate>Thu, 08 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Thekla Hamm, Sukanya Pandey, Krisztina Szil\'agyi</dc:creator>
    </item>
    <item>
      <title>Variance Computation for Weighted Model Counting with Knowledge Compilation Approach</title>
      <link>https://arxiv.org/abs/2601.03523</link>
      <description>arXiv:2601.03523v1 Announce Type: cross 
Abstract: One of the most important queries in knowledge compilation is weighted model counting (WMC), which has been applied to probabilistic inference on various models, such as Bayesian networks. In practical situations on inference tasks, the model's parameters have uncertainty because they are often learned from data, and thus we want to compute the degree of uncertainty in the inference outcome. One possible approach is to regard the inference outcome as a random variable by introducing distributions for the parameters and evaluate the variance of the outcome. Unfortunately, the tractability of computing such a variance is hardly known. Motivated by this, we consider the problem of computing the variance of WMC and investigate this problem's tractability. First, we derive a polynomial time algorithm to evaluate the WMC variance when the input is given as a structured d-DNNF. Second, we prove the hardness of this problem for structured DNNFs, d-DNNFs, and FBDDs, which is intriguing because the latter two allow polynomial time WMC algorithms. Finally, we show an application that measures the uncertainty in the inference of Bayesian networks. We empirically show that our algorithm can evaluate the variance of the marginal probability on real-world Bayesian networks and analyze the impact of the variances of parameters on the variance of the marginal.</description>
      <guid isPermaLink="false">oai:arXiv.org:2601.03523v1</guid>
      <category>cs.AI</category>
      <category>cs.DS</category>
      <pubDate>Thu, 08 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Kengo Nakamura, Masaaki Nishino, Norihito Yasuda</dc:creator>
    </item>
    <item>
      <title>Online Learning with Limited Information in the Sliding Window Model</title>
      <link>https://arxiv.org/abs/2601.03533</link>
      <description>arXiv:2601.03533v1 Announce Type: cross 
Abstract: Motivated by recent work on the experts problem in the streaming model, we consider the experts problem in the sliding window model. The sliding window model is a well-studied model that captures applications such as traffic monitoring, epidemic tracking, and automated trading, where recent information is more valuable than older data. Formally, we have $n$ experts, $T$ days, the ability to query the predictions of $q$ experts on each day, a limited amount of memory, and should achieve the (near-)optimal regret $\sqrt{nW}\text{polylog}(nT)$ regret over any window of the last $W$ days. While it is impossible to achieve such regret with $1$ query, we show that with $2$ queries we can achieve such regret and with only $\text{polylog}(nT)$ bits of memory. Not only are our algorithms optimal for sliding windows, but we also show for every interval $\mathcal{I}$ of days that we achieve $\sqrt{n|\mathcal{I}|}\text{polylog}(nT)$ regret with $2$ queries and only $\text{polylog}(nT)$ bits of memory, providing an exponential improvement on the memory of previous interval regret algorithms. Building upon these techniques, we address the bandit problem in data streams, where $q=1$, achieving $n T^{2/3}\text{polylog}(T)$ regret with $\text{polylog}(nT)$ memory, which is the first sublinear regret in the streaming model in the bandit setting with polylogarithmic memory; this can be further improved to the optimal $\mathcal{O}(\sqrt{nT})$ regret if the best expert's losses are in a random order.</description>
      <guid isPermaLink="false">oai:arXiv.org:2601.03533v1</guid>
      <category>stat.ML</category>
      <category>cs.DS</category>
      <category>cs.LG</category>
      <pubDate>Thu, 08 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Vladimir Braverman, Sumegha Garg, Chen Wang, David P. Woodruff, Samson Zhou</dc:creator>
    </item>
    <item>
      <title>Implementing Binary Search Trees in GP 2 (Extended Abstract)</title>
      <link>https://arxiv.org/abs/2601.03897</link>
      <description>arXiv:2601.03897v1 Announce Type: cross 
Abstract: We present an approach to implement binary search trees in the rule-based graph programming language GP 2. Our implementation uses GP 2's rooted graph transformation rules to be fast and supports insertion, deletion and query operations. We argue that the worst-case runtime for each of the operations is O(n) for a tree with n nodes. In addition, we expect that, on average, the operations run in time O(log(n)). Hence the implementation would match the time complexity of binary search trees implementations in imperative languages.</description>
      <guid isPermaLink="false">oai:arXiv.org:2601.03897v1</guid>
      <category>cs.PL</category>
      <category>cs.DS</category>
      <pubDate>Thu, 08 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <arxiv:DOI>10.4204/EPTCS.440.2</arxiv:DOI>
      <arxiv:journal_reference>EPTCS 440, 2026, pp. 6-12</arxiv:journal_reference>
      <dc:creator>Ziad Ismaili Alaoui (Department of Computer Science, University of Liverpool, Liverpool, United Kingdom), Detlef Plump (Department of Computer Science, University of York, York, United Kingdom)</dc:creator>
    </item>
    <item>
      <title>Worst-case optimal adaptive alphabetic prefix-free coding</title>
      <link>https://arxiv.org/abs/2109.02997</link>
      <description>arXiv:2109.02997v5 Announce Type: replace 
Abstract: We give the first algorithm for adaptive alphabetic prefix-free coding that is worst-case optimal in terms of time and compression when $\sigma \in o \left( \frac{n^{1 / 2}}{\log n} \right)$, where $\sigma$ is the size of the alphabet and $n$ is the length of the input.</description>
      <guid isPermaLink="false">oai:arXiv.org:2109.02997v5</guid>
      <category>cs.DS</category>
      <category>cs.IT</category>
      <category>math.IT</category>
      <pubDate>Thu, 08 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Travis Gagie</dc:creator>
    </item>
    <item>
      <title>Rapid Mixing at the Uniqueness Threshold</title>
      <link>https://arxiv.org/abs/2411.03413</link>
      <description>arXiv:2411.03413v3 Announce Type: replace 
Abstract: Over the past decades, a fascinating computational phase transition has been identified in sampling from Gibbs distributions. Though, the computational complexity at the critical point remains poorly understood, as previous algorithmic and hardness results all required a constant slack from this threshold.
  In this paper, we resolve this open question at the critical phase transition threshold, thus completing the picture of the computational phase transition. We show that for the hardcore model on graphs with maximum degree $\Delta\ge 3$ at the uniqueness threshold $\lambda = \lambda_c(\Delta)$, the mixing time of Glauber dynamics is upper bounded by a polynomial in $n$, but is not nearly linear in the worst case.
  For the Ising model (either antiferromagnetic or ferromagnetic), we establish similar results. For the Ising model on graphs with maximum degree $\Delta\ge 3$ at the critical temperature $\beta$ where $|\beta| = \beta_c(\Delta)$, with the tree-uniqueness threshold $\beta_c(\Delta)$, we show that the mixing time of Glauber dynamics is upper bounded by $\tilde{O}\left(n^{3 + O(1/\Delta)}\right)$ and lower bounded by $\Omega\left(n^{3/2}\right)$ in the worst case. For the Ising model specified by a critical interaction matrix $J$ with $\left \lVert J \right \rVert_2=1$, we obtain an upper bound $\tilde{O}(n^{3/2})$ for the mixing time, matching the lower bound $\Omega\left(n^{3/2}\right)$ on the complete graph up to a logarithmic factor.
  Our mixing time upper bounds are derived from a new interpretation and analysis of the localization scheme method introduced by Chen and Eldan (2022), applied to the field dynamics for the hardcore model and the proximal sampler for the Ising model. As key steps in both our upper and lower bounds, we establish sub-linear upper and lower bounds for spectral independence at the critical point for worst-case instances.</description>
      <guid isPermaLink="false">oai:arXiv.org:2411.03413v3</guid>
      <category>cs.DS</category>
      <category>math.PR</category>
      <pubDate>Thu, 08 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Xiaoyu Chen, Zongchen Chen, Yitong Yin, Xinyuan Zhang</dc:creator>
    </item>
    <item>
      <title>Improved Mixing of Critical Hardcore Model</title>
      <link>https://arxiv.org/abs/2505.07515</link>
      <description>arXiv:2505.07515v2 Announce Type: replace 
Abstract: The hardcore model is one of the most classic and widely studied examples of undirected graphical models. Given a graph $G$, the hardcore model describes a Gibbs distribution of $\lambda$-weighted independent sets of $G$. In the last two decades, a beautiful computational phase transition has been established at a precise threshold $\lambda_c(\Delta)$ where $\Delta$ denotes the maximum degree, where the task of sampling independent sets transitions from polynomial-time solvable to computationally intractable. We study the critical hardcore model where $\lambda = \lambda_c(\Delta)$ and show that the Glauber dynamics, a simple yet popular Markov chain algorithm, mixes in $\tilde{O}(n^{4+O(1/\Delta)})$ time on any $n$-vertex graph of maximum degree $\Delta\geq3$, significantly improving the previous upper bound $\tilde{O}(n^{12.88+O(1/\Delta)})$ by the recent work arXiv:2411.03413. Our improvement comes from an optimal bound on the $\ell_\infty$-spectral independence for the hardcore model at all subcritical fugacity $\lambda &lt; \lambda_c(\Delta)$.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.07515v2</guid>
      <category>cs.DS</category>
      <category>math.PR</category>
      <pubDate>Thu, 08 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Zongchen Chen, Tianhui Jiang</dc:creator>
    </item>
    <item>
      <title>Strong Sparsification for 1-in-3-SAT via Polynomial Freiman-Ruzsa</title>
      <link>https://arxiv.org/abs/2507.17878</link>
      <description>arXiv:2507.17878v3 Announce Type: replace 
Abstract: We introduce a new notion of sparsification, called \emph{strong sparsification}, in which constraints are not removed but variables can be merged. As our main result, we present a strong sparsification algorithm for 1-in-3-SAT. The correctness of the algorithm relies on establishing a sub-quadratic bound on the size of certain sets of vectors in $\mathbb{F}_2^d$. This result, obtained using the recent \emph{Polynomial Freiman-Ruzsa Theorem} (Gowers, Green, Manners and Tao, Ann. Math. 2025), could be of independent interest. As an application, we improve the state-of-the-art algorithm for approximating linearly-ordered colourings of 3-uniform hypergraphs (H{\aa}stad, Martinsson, Nakajima and{\v{Z}}ivn{\'{y}}, APPROX 2024).</description>
      <guid isPermaLink="false">oai:arXiv.org:2507.17878v3</guid>
      <category>cs.DS</category>
      <category>cs.CC</category>
      <category>cs.DM</category>
      <category>math.CO</category>
      <pubDate>Thu, 08 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Benjamin Bedert, Tamio-Vesa Nakajima, Karolina Okrasa, Stanislav \v{Z}ivn\'y</dc:creator>
    </item>
    <item>
      <title>Text Indexing and Pattern Matching with Ephemeral Edits</title>
      <link>https://arxiv.org/abs/2508.05124</link>
      <description>arXiv:2508.05124v2 Announce Type: replace 
Abstract: A sequence $e_0,e_1,\ldots$ of edit operations in a string $T$ is called ephemeral if operation $e_i$ constructing string $T^i$, for all $i=2k$ with $k\in\mathbb{N}$, is reverted by operation $e_{i+1}$ that reconstructs $T$. Such a sequence arises when processing a stream of independent edits or testing hypothetical edits.
  We introduce text indexing with ephemeral substring edits, a new version of text indexing. Our goal is to design a data structure over a given text that supports subsequent pattern matching queries with ephemeral substring insertions, deletions, or substitutions in the text; we require insertions and substitutions to be of constant length. In particular, we preprocess a text $T=T[0\mathinner{.\,.} n)$ over an integer alphabet $\Sigma=[0,\sigma)$ with $\sigma=n^{\mathcal{O}(1)}$ in $\mathcal{O}(n)$ time. Then, we can preprocess any arbitrary pattern $P=P[0\mathinner{.\,.} m)$ given online in $\mathcal{O}(m\log\log m)$ time and $\mathcal{O}(m)$ space and allow any ephemeral sequence of edit operations in $T$. Before reverting the $i$th operation, we report all Occ occurrences of $P$ in $T^i$ in $\mathcal{O}(\log\log n + \text{Occ})$ time.
  We also introduce pattern matching with ephemeral edits. In particular, we preprocess two strings $T$ and $P$, each of length at most $n$, over an integer alphabet $\Sigma=[0,\sigma)$ with $\sigma=n^{\mathcal{O}(1)}$ in $\mathcal{O}(n)$ time. Then, we allow any ephemeral sequence of edit operations in $T$. Before reverting the $i$th operation, we report all Occ occurrences of $P$ in $T^i$ in the optimal $\mathcal{O}(\text{Occ})$ time. Along our way to this result, we also give an optimal solution for pattern matching with ephemeral block deletions.</description>
      <guid isPermaLink="false">oai:arXiv.org:2508.05124v2</guid>
      <category>cs.DS</category>
      <pubDate>Thu, 08 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Solon P. Pissis</dc:creator>
    </item>
    <item>
      <title>Sparse Neighborhood Graph-Based Approximate Nearest Neighbor Search Revisited: Theoretical Analysis and Optimization</title>
      <link>https://arxiv.org/abs/2509.15531</link>
      <description>arXiv:2509.15531v3 Announce Type: replace 
Abstract: Graph-based approaches to approximate nearest neighbor search (ANNS) enable fast, high-recall retrieval on billion-scale vector datasets. Among them, the Sparse Neighborhood Graph (SNG) is widely used due to its strong search performance. However, the lack of theoretical understanding of SNG leads to expensive tuning of the truncation parameter that controls graph sparsification. In this work, we present OPT-SNG, a principled framework for analyzing and optimizing SNG construction. We introduce a martingale-based model of the pruning process that characterizes the stochastic evolution of candidate sets during graph construction. Using this framework, we prove that SNG has a maximum out-degree of \(O(n^{2/3+\epsilon})\), where \(\epsilon&gt;0\) is an arbitrarily small constant, and an expected search path length of \(O(\log n)\). Building on these insights, we derive a closed-form rule for selecting the optimal truncation parameter \(R\), thereby eliminating the need for costly parameter sweeping. Extensive experiments on real-world datasets demonstrate that OPT-SNG achieves an average \(5.9\times\) speedup in index construction time, with peak improvements reaching \(15.4\times\), while consistently maintaining or improving search performance.</description>
      <guid isPermaLink="false">oai:arXiv.org:2509.15531v3</guid>
      <category>cs.DS</category>
      <pubDate>Thu, 08 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Xinran Ma, Zhaoqi Zhou, Chuan Zhou, Zaijiu Shang, Guoliang Li, Zhiming Ma</dc:creator>
    </item>
    <item>
      <title>Learning Confidence Ellipsoids and Applications to Robust Subspace Recovery</title>
      <link>https://arxiv.org/abs/2512.16875</link>
      <description>arXiv:2512.16875v3 Announce Type: replace 
Abstract: We study the problem of finding confidence ellipsoids for an arbitrary distribution in high dimensions. Given samples from a distribution $\mathcal{D}$ and a confidence parameter $\alpha$, the goal is to find the smallest volume ellipsoid $E$ which has probability mass $\Pr_{\mathcal{D}}[E] \ge 1-\alpha$. Ellipsoids are a highly expressive class of confidence sets as they can capture correlations in the distribution, and can approximate any convex set. This problem has been studied in many different communities. In statistics, this is the classic minimum volume estimator introduced by Rousseeuw as a robust non-parametric estimator of location and scatter. However in high dimensions, it becomes NP-hard to obtain any non-trivial approximation factor in volume when the condition number $\beta$ of the ellipsoid (ratio of the largest to the smallest axis length) goes to $\infty$. This motivates the focus of our paper: can we efficiently find confidence ellipsoids with volume approximation guarantees when compared to ellipsoids of bounded condition number $\beta$?
  Our main result is a polynomial time algorithm that finds an ellipsoid $E$ whose volume is within a $O(\beta)^{\gamma d}$ multiplicative factor of the volume of best $\beta$-conditioned ellipsoid while covering at least $1-O(\alpha/\gamma)$ probability mass for any $\gamma \in (0,1)$. We complement this with a computational hardness result that shows that such a dependence seems necessary up to constants in the exponent. The algorithm and analysis uses the rich primal-dual structure of the minimum volume enclosing ellipsoid and the geometric Brascamp-Lieb inequality. As a consequence, we obtain the first polynomial time algorithm with approximation guarantees on worst-case instances of the robust subspace recovery problem.</description>
      <guid isPermaLink="false">oai:arXiv.org:2512.16875v3</guid>
      <category>cs.DS</category>
      <category>cs.LG</category>
      <category>math.ST</category>
      <category>stat.ML</category>
      <category>stat.TH</category>
      <pubDate>Thu, 08 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Chao Gao, Liren Shan, Vaidehi Srinivas, Aravindan Vijayaraghavan</dc:creator>
    </item>
    <item>
      <title>Solving Matrix Games with Near-Optimal Matvec Complexity</title>
      <link>https://arxiv.org/abs/2601.02347</link>
      <description>arXiv:2601.02347v2 Announce Type: replace-cross 
Abstract: We study the problem of computing an $\epsilon$-approximate Nash equilibrium of a two-player, bilinear game with a bounded payoff matrix $A \in \mathbb{R}^{m \times n}$, when the players' strategies are constrained to lie in simple sets. We provide algorithms which solve this problem in $\tilde{O}(\epsilon^{-2/3})$ matrix-vector multiplies (matvecs) in two well-studied cases: $\ell_1$-$\ell_1$ (or zero-sum) games, where the players' strategies are both in the probability simplex, and $\ell_2$-$\ell_1$ games (encompassing hard-margin SVMs), where the players' strategies are in the unit Euclidean ball and probability simplex respectively. These results improve upon the previous state-of-the-art complexities of $\tilde{O}(\epsilon^{-8/9})$ for $\ell_1$-$\ell_1$ and $\tilde{O}(\epsilon^{-7/9})$ for $\ell_2$-$\ell_1$ due to [KOS '25]. In both settings our results are nearly-optimal as they match lower bounds of [KS '25] up to polylogarithmic factors.</description>
      <guid isPermaLink="false">oai:arXiv.org:2601.02347v2</guid>
      <category>math.OC</category>
      <category>cs.DS</category>
      <category>cs.GT</category>
      <pubDate>Thu, 08 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Ishani Karmarkar, Liam O'Carroll, Aaron Sidford</dc:creator>
    </item>
  </channel>
</rss>
