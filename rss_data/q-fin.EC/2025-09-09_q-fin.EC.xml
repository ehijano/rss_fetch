<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>q-fin.EC updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/q-fin.EC</link>
    <description>q-fin.EC updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/q-fin.EC" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Tue, 09 Sep 2025 04:01:09 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Tue, 09 Sep 2025 00:00:00 -0400</pubDate>
    <skipDays>
      <day>Saturday</day>
      <day>Sunday</day>
    </skipDays>
    <item>
      <title>Critical Iridium Demands arising from future Expansion of Proton Exchange Membrane Electrolysis</title>
      <link>https://arxiv.org/abs/2509.05357</link>
      <description>arXiv:2509.05357v1 Announce Type: new 
Abstract: Proton exchange membrane electrolysis (PEMEL) is a key technology for producing green hydrogen, but its scalability is limited by the use of scarce materials, particularly iridium. Iridium oxide, the preferred anode catalyst in PEMEL, offers exceptional stability but is produced only as a by-product of platinum mining, with annual output around 7.5 tons. This study estimates future iridium demand for PEMEL under various deployment scenarios and technological advances. Results show that meeting net zero targets will require both significant improvements in catalyst efficiency and access to roughly 30\% of global iridium production annually. Supply shortages could arise as early as 2030, earlier than previously anticipated. The analysis also reveals that long-term iridium needs beyond 2040 are significantly underestimated. These findings underscore the urgent need for innovation in material efficiency and recycling, and the importance of integrating resource constraints into energy policy and technology planning to ensure a sustainable hydrogen transition.</description>
      <guid isPermaLink="false">oai:arXiv.org:2509.05357v1</guid>
      <category>econ.GN</category>
      <category>cond-mat.mtrl-sci</category>
      <category>q-fin.EC</category>
      <pubDate>Tue, 09 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <dc:creator>Bernhard Wortmann, Detlef Stolten, Heidi Heinrichs</dc:creator>
    </item>
    <item>
      <title>From Digital Distrust to Codified Honesty: Experimental Evidence on Generative AI in Credence Goods Markets</title>
      <link>https://arxiv.org/abs/2509.06069</link>
      <description>arXiv:2509.06069v1 Announce Type: new 
Abstract: Generative AI is transforming the provision of expert services. This article uses a series of one-shot experiments to quantify the behavioral, welfare and distribution consequences of large language models (LLMs) on AI-AI, Human-Human, Human-AI and Human-AI-Human expert markets. Using a credence goods framework where experts have private information about the optimal service for consumers, we find that Human-Human markets generally achieve higher levels of efficiency than AI-AI and Human-AI markets through pro-social expert preferences and higher consumer trust. Notably, LLM experts still earn substantially higher surplus than human experts -- at the expense of consumer surplus - suggesting adverse incentives that may spur the harmful deployment of LLMs. Concurrently, a majority of human experts chooses to rely on LLM agents when given the opportunity in Human-AI-Human markets, especially if they have agency over the LLM's (social) objective function. Here, a large share of experts prioritizes efficiency-loving preferences over pure self-interest. Disclosing these preferences to consumers induces strong efficiency gains by marginalizing self-interested LLM experts and human experts. Consequently, Human-AI-Human markets outperform Human-Human markets under transparency rules. With obfuscation, however, efficiency gains disappear, and adverse expert incentives remain. Our results shed light on the potential opportunities and risks of disseminating LLMs in the context of expert services and raise several regulatory challenges. On the one hand, LLMs can negatively affect human trust in the presence of information asymmetries and partially crowd-out experts' other-regarding preferences through automation. On the other hand, LLMs allow experts to codify and communicate their objective function, which reduces information asymmetries and increases efficiency.</description>
      <guid isPermaLink="false">oai:arXiv.org:2509.06069v1</guid>
      <category>econ.GN</category>
      <category>cs.HC</category>
      <category>q-fin.EC</category>
      <pubDate>Tue, 09 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Alexander Erlei</dc:creator>
    </item>
    <item>
      <title>DETERring more than Deforestation: Environmental Enforcement Reduces Violence in the Amazon</title>
      <link>https://arxiv.org/abs/2509.06076</link>
      <description>arXiv:2509.06076v1 Announce Type: new 
Abstract: We estimate the impact of environmental law enforcement on violence in the Brazilian Amazon. The introduction of the Real-Time Deforestation Detection System (DETER), which enabled the government to monitor deforestation in real time and issue fines for illegal clearing, significantly reduced homicides in the region. To identify causal effects, we exploit exogenous variation in satellite monitoring generated by cloud cover as an instrument for enforcement intensity. Our estimates imply that the expansion of state presence through DETER prevented approximately 1,477 homicides per year, a 15% reduction in homicides. These results show that curbing deforestation produces important social co-benefits, strengthening state presence and reducing violence in regions marked by institutional fragility and resource conflict.</description>
      <guid isPermaLink="false">oai:arXiv.org:2509.06076v1</guid>
      <category>econ.GN</category>
      <category>q-fin.EC</category>
      <category>stat.AP</category>
      <pubDate>Tue, 09 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <dc:creator>Rafael Araujo, Vitor Possebom, Gabriela Setti</dc:creator>
    </item>
    <item>
      <title>The Probability of Food Security: A new longitudinal data set using the Panel Study of Income Dynamics</title>
      <link>https://arxiv.org/abs/2509.06144</link>
      <description>arXiv:2509.06144v1 Announce Type: new 
Abstract: The study of food security dynamics in the U.S. has long been impeded by the lack of extended longitudinal observations of the same households or individuals. This paper applies a newly-introduced household-level food security measure, the probability of food security (PFS), to 26 waves of Panel Study of Income Dynamics (PSID) data, spanning 1979-2019, to generate a data product we describe and make newly available to the research community. We detail the construction of this unprecedentedly long food security panel data series in PSID data. Finally, we estimate key subpopulation- and national-level food security dynamics identifiable over the 40-year (1979-2019) period spanning multiple recessions and federal nutrition assistance policy changes, including disaggregated dynamics based on geography, race, sex, and educational attainment.</description>
      <guid isPermaLink="false">oai:arXiv.org:2509.06144v1</guid>
      <category>econ.GN</category>
      <category>q-fin.EC</category>
      <pubDate>Tue, 09 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Seungmin Lee, John Hoddinott, Christopher B. Barrett, Matthew P. Rabbitt</dc:creator>
    </item>
    <item>
      <title>Are international happiness rankings reliable?</title>
      <link>https://arxiv.org/abs/2509.06867</link>
      <description>arXiv:2509.06867v1 Announce Type: new 
Abstract: Global comparisons of wellbeing increasingly rely on survey questions that ask respondents to evaluate their lives, most commonly in the form of "life satisfaction" and "Cantril ladder" items. These measures underpin international rankings such as the World Happiness Report and inform policy initiatives worldwide, yet their comparability has not been established with contemporary global data. Using the Gallup World Poll, Global Flourishing Study, and World Values Survey, I show that the two question formats yield divergent distributions, rankings, and response patterns that vary across countries and surveys, defying simple explanations. To explore differences in respondents' cognitive interpretations, I compare regression coefficients from the Global Flourishing Study, analyzing how each question wording relates to life circumstances. While international rankings of wellbeing are unstable, the scientific study of the determinants of life evaluations appears more robust. Together, the findings underscore the need for a renewed research agenda on critical limitations to cross-country comparability of wellbeing.</description>
      <guid isPermaLink="false">oai:arXiv.org:2509.06867v1</guid>
      <category>econ.GN</category>
      <category>q-fin.EC</category>
      <pubDate>Tue, 09 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Christopher P Barrington-Leigh</dc:creator>
    </item>
    <item>
      <title>Characterizing Optimality in Dynamic Settings: A Monotonicity-based Approach</title>
      <link>https://arxiv.org/abs/2509.05354</link>
      <description>arXiv:2509.05354v1 Announce Type: cross 
Abstract: We develop a novel analytical method for studying optimal paths in dynamic optimization problems under general monotonicity conditions. The method centers on a locator function -- a simple object constructed directly from the model's primitives -- whose roots identify interior steady states and whose slope determines their local stability. Under strict concavity of the payoff function, the locator function also characterizes basins of attraction, yielding a complete description of qualitative dynamics. Without concavity, it can still deliver sharp results: if the function is single crossing from above, its root identifies a globally stable steady state; if the locator function is inverted-U-shaped with two interior roots (a typical case), only the higher root can be a locally stable interior steady state. The locator function further enables comparative statics of steady states with respect to parameters through direct analysis of its derivatives. These results are obtained without solving the full dynamic program. We illustrate the approach using a generalized neoclassical growth model, a rational (un)fitness model, and a learning-by-doing economy.</description>
      <guid isPermaLink="false">oai:arXiv.org:2509.05354v1</guid>
      <category>econ.TH</category>
      <category>econ.GN</category>
      <category>math.OC</category>
      <category>q-fin.EC</category>
      <pubDate>Tue, 09 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Zhuokai Huang, Demian Pouzo, Andr\'es Rodr\'iguez-Clare</dc:creator>
    </item>
    <item>
      <title>A note on the mechanism of substitution of labour with capital in the production processes</title>
      <link>https://arxiv.org/abs/2509.05386</link>
      <description>arXiv:2509.05386v1 Announce Type: cross 
Abstract: Considering the production processes, it was noted that the use of various equipment leads to an increase in output -- the phenomenon that is usually described as the substitution of labor with capital. The proposed theory of substitution is based on the assumption that not the quantity of capital (production equipment) does substitute labor, but rather its ability to operate similar to the workers. This is the true content of the substitution of labor by capital. To formulate a correct mechanism of substitution requires considering three factors of production: the amount of production equipment (capital $K$), human activity (labor $L$), and the substitutive capacity of equipment (substitutive work $P$). The technological properties of production equipment are characterized by the technological coefficients $\overline \lambda$ and $\overline \varepsilon$, indicating the amount of labor and energy required to engaged with a unit of equipment. The production function can assume various forms, none of which coincide with the popular Cobb-Douglas expression, which seems to be erroneous in its core.</description>
      <guid isPermaLink="false">oai:arXiv.org:2509.05386v1</guid>
      <category>physics.soc-ph</category>
      <category>econ.GN</category>
      <category>q-fin.EC</category>
      <pubDate>Tue, 09 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Vladimir Pokrovskii</dc:creator>
    </item>
    <item>
      <title>Unveiling Plant-Product Productivity via First-Order Conditions: Robust Replication of Orr (2022)</title>
      <link>https://arxiv.org/abs/2501.19354</link>
      <description>arXiv:2501.19354v2 Announce Type: replace 
Abstract: We assess the replicability of Orr (2022)'s method for estimating within-plant productivity across product lines, which combines demand estimation with cost minimization. The original study uses input price shocks in other output markets as instrumental variables, with exclusion restrictions based on downstream purchase shares. Using the original dataset of Indian machinery producers from 2000-2007, we successfully reproduce the main productivity patterns and demonstrate their robustness to variations in the exclusion threshold. However, extending the analysis to 2010-2019 and 2000-2019 periods yields inadmissible demand systems. Nevertheless, the main results remain robust when calibrating demand parameters to Orr (2022)'s original estimates.</description>
      <guid isPermaLink="false">oai:arXiv.org:2501.19354v2</guid>
      <category>econ.GN</category>
      <category>q-fin.EC</category>
      <pubDate>Tue, 09 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Joonkyo Hong, Davide Luparello</dc:creator>
    </item>
    <item>
      <title>Automation, AI, and the Intergenerational Transmission of Knowledge</title>
      <link>https://arxiv.org/abs/2507.16078</link>
      <description>arXiv:2507.16078v4 Announce Type: replace 
Abstract: Recent advances in Artificial Intelligence (AI) have sparked expectations of unprecedented economic growth. Yet, by enabling senior workers to accomplish more tasks independently, AI may inadvertently reduce entry-level opportunities, raising concerns about how future generations will acquire essential expertise. This paper develops a model to examine how advanced automation affects the intergenerational transmission of tacit knowledge -- practical insights that resist codification and are critical for workplace success. The analysis shows that the competitive equilibrium features socially excessive automation of early-career tasks and reveals a critical trade-off: while such automation delivers immediate productivity gains, it can undermine long-term growth by hindering younger workers' acquisition of tacit skills. Back-of-the-envelope calculations suggest AI-driven entry-level automation could lower the long-run annual growth rate of U.S. per capita output by 0.05 to 0.35 percentage points, depending on its scale. The analysis further shows that AI co-pilots -- systems providing access to tacit-like expertise once obtained only through direct experience -- can partially offset these losses by assisting individuals who fail to develop adequate skills early in their careers. However, co-pilots are not always beneficial, as they may also weaken junior workers' incentives to engage in hands-on learning. These findings challenge the view that AI will automatically lead to higher economic growth, highlighting the need to safeguard -- or deliberately create -- entry-level opportunities to fully realize AI's potential.</description>
      <guid isPermaLink="false">oai:arXiv.org:2507.16078v4</guid>
      <category>econ.GN</category>
      <category>q-fin.EC</category>
      <pubDate>Tue, 09 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Enrique Ide</dc:creator>
    </item>
    <item>
      <title>Game Theory and Multi-Agent Reinforcement Learning for Zonal Ancillary Markets</title>
      <link>https://arxiv.org/abs/2505.03288</link>
      <description>arXiv:2505.03288v3 Announce Type: replace-cross 
Abstract: We characterize zonal ancillary market coupling relying on noncooperative game theory. To that purpose, we formulate the ancillary market as a multi-leader single follower bilevel problem, that we subsequently cast as a generalized Nash game with side constraints and nonconvex feasibility sets. We determine conditions for equilibrium existence and show that the game has a generalized potential game structure. To compute market equilibrium, we rely on two exact approaches: an integrated optimization approach and Gauss-Seidel best-response, that we compare against multi-agent deep reinforcement learning. On real data from Germany and Austria, simulations indicate that multi-agent deep reinforcement learning achieves the smallest convergence rate but requires pretraining, while best-response is the slowest. On the economics side, multi-agent deep reinforcement learning results in smaller market costs compared to the exact methods, but at the cost of higher variability in the profit allocation among stakeholders. Further, stronger coupling between zones tends to reduce costs for larger zones.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.03288v3</guid>
      <category>cs.MA</category>
      <category>cs.GT</category>
      <category>econ.GN</category>
      <category>q-fin.EC</category>
      <pubDate>Tue, 09 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Francesco Morri, H\'el\`ene Le Cadre, Pierre Gruet, Luce Brotcorne</dc:creator>
    </item>
    <item>
      <title>Quantifying the Social Costs of Power Outages and Restoration Disparities Across Four U.S. Hurricanes</title>
      <link>https://arxiv.org/abs/2509.02653</link>
      <description>arXiv:2509.02653v2 Announce Type: replace-cross 
Abstract: The multifaceted nature of disaster impact shows that densely populated areas contribute more to aggregate burden, while sparsely populated but heavily affected regions suffer disproportionately at the individual level. This study introduces a framework for quantifying the societal impacts of power outages by translating customer weighted outage exposure into deprivation measures, integrating welfare metrics with three recovery indicators, average outage days per customer, restoration duration, and relative restoration rate, computed from sequential EAGLE I observations and linked to Zip Code Tabulation Area demographics. Applied to four United States hurricanes, Beryl 2024 Texas, Helene 2024 Florida, Milton 2024 Florida, and Ida 2021 Louisiana, this standardized pipeline provides the first cross event, fine scale evaluation of outage impacts and their drivers. Results demonstrate regressive patterns with greater burdens in lower income areas, mechanistic analysis shows deprivation increases with longer restoration durations and decreases with faster restoration rates, explainable modeling identifies restoration duration as the dominant driver, and clustering reveals distinct recovery typologies not captured by conventional reliability metrics. This framework delivers a transferable method for assessing outage impacts and equity, comparative cross event evidence linking restoration dynamics to social outcomes, and actionable spatial analyses that support equity informed restoration planning and resilience investment.</description>
      <guid isPermaLink="false">oai:arXiv.org:2509.02653v2</guid>
      <category>physics.soc-ph</category>
      <category>cs.LG</category>
      <category>econ.GN</category>
      <category>q-fin.EC</category>
      <pubDate>Tue, 09 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <dc:creator>Xiangpeng Li, Junwei Ma, Bo Li, Ali Mostafavi</dc:creator>
    </item>
  </channel>
</rss>
