<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>econ.EM updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/econ.EM</link>
    <description>econ.EM updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/econ.EM" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Fri, 14 Mar 2025 04:01:57 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Fri, 14 Mar 2025 00:00:00 -0400</pubDate>
    <skipDays>
      <day>Sunday</day>
      <day>Saturday</day>
    </skipDays>
    <item>
      <title>PLRD: Partially Linear Regression Discontinuity Inference</title>
      <link>https://arxiv.org/abs/2503.09907</link>
      <description>arXiv:2503.09907v1 Announce Type: new 
Abstract: Regression discontinuity designs have become one of the most popular research designs in empirical economics. We argue, however, that widely used approaches to building confidence intervals in regression discontinuity designs exhibit suboptimal behavior in practice: In a simulation study calibrated to high-profile applications of regression discontinuity designs, existing methods either have systematic under-coverage or have wider-than-necessary intervals. We propose a new approach, partially linear regression discontinuity inference (PLRD), and find it to address shortcomings of existing methods: Throughout our experiments, confidence intervals built using PLRD are both valid and short. We also provide large-sample guarantees for PLRD under smoothness assumptions.</description>
      <guid isPermaLink="false">oai:arXiv.org:2503.09907v1</guid>
      <category>econ.EM</category>
      <category>stat.ME</category>
      <pubDate>Fri, 14 Mar 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Aditya Ghosh, Guido Imbens, Stefan Wager</dc:creator>
    </item>
    <item>
      <title>Designing Graph Convolutional Neural Networks for Discrete Choice with Network Effects</title>
      <link>https://arxiv.org/abs/2503.09786</link>
      <description>arXiv:2503.09786v1 Announce Type: cross 
Abstract: We introduce a novel model architecture that incorporates network effects into discrete choice problems, achieving higher predictive performance than standard discrete choice models while offering greater interpretability than general-purpose flexible model classes. Econometric discrete choice models aid in studying individual decision-making, where agents select the option with the highest reward from a discrete set of alternatives. Intuitively, the utility an individual derives from a particular choice depends on their personal preferences and characteristics, the attributes of the alternative, and the value their peers assign to that alternative or their previous choices. However, most applications ignore peer influence, and models that do consider peer or network effects often lack the flexibility and predictive performance of recently developed approaches to discrete choice, such as deep learning. We propose a novel graph convolutional neural network architecture to model network effects in discrete choices, achieving higher predictive performance than standard discrete choice models while retaining the interpretability necessary for inference--a quality often lacking in general-purpose deep learning architectures. We evaluate our architecture using revealed commuting choice data, extended with travel times and trip costs for each travel mode for work-related trips in New York City, as well as 2016 U.S. election data aggregated by county, to test its performance on datasets with highly imbalanced classes. Given the interpretability of our models, we can estimate relevant economic metrics, such as the value of travel time savings in New York City. Finally, we compare the predictive performance and behavioral insights from our architecture to those derived from traditional discrete choice and general-purpose deep learning models.</description>
      <guid isPermaLink="false">oai:arXiv.org:2503.09786v1</guid>
      <category>cs.LG</category>
      <category>econ.EM</category>
      <category>stat.ML</category>
      <pubDate>Fri, 14 Mar 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Daniel F. Villarraga, Ricardo A. Daziano</dc:creator>
    </item>
    <item>
      <title>The Local Projection Residual Bootstrap for AR(1) Models</title>
      <link>https://arxiv.org/abs/2309.01889</link>
      <description>arXiv:2309.01889v4 Announce Type: replace 
Abstract: This paper proposes a local projection residual bootstrap method to construct confidence intervals for impulse response coefficients of AR(1) models. Our bootstrap method is based on the local projection (LP) approach and involves a residual bootstrap procedure applied to AR(1) models. We present theoretical results for our bootstrap method and proposed confidence intervals. First, we prove the uniform consistency of the LP-residual bootstrap over a large class of AR(1) models that allow for a unit root, conditional heteroskedasticity of unknown form, and serially dependent shocks. Then, we prove the asymptotic validity of our confidence intervals over the same class of AR(1) models. Finally, we show that the LP-residual bootstrap provides asymptotic refinements for confidence intervals on a restricted class of AR(1) models relative to those required for the uniform consistency of our bootstrap.</description>
      <guid isPermaLink="false">oai:arXiv.org:2309.01889v4</guid>
      <category>econ.EM</category>
      <pubDate>Fri, 14 Mar 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Amilcar Velez</dc:creator>
    </item>
    <item>
      <title>Revisiting Randomization with the Cube Method</title>
      <link>https://arxiv.org/abs/2407.13613</link>
      <description>arXiv:2407.13613v2 Announce Type: replace 
Abstract: We propose a novel randomization approach for randomized controlled trials (RCTs), based on the cube method developed by Deville and Till\'e (2004). The cube method allows for the selection of balanced samples across various covariate types, ensuring consistent adherence to balance tests and, whence, substantial precision gains when estimating treatment effects. We establish several statistical properties for the population and sample average treatment effects under randomization using the cube method. We formally derive and compare bounds on imbalances depending on the number of units $n$ and the number of covariates $p$ considered for the balancing. We show that our randomization approach outperforms methods proposed in the literature when $p$ is large and $p/n$ tends to 0. We run simulation studies to illustrate the substantial gains from the cube method for a large set of covariates.</description>
      <guid isPermaLink="false">oai:arXiv.org:2407.13613v2</guid>
      <category>econ.EM</category>
      <pubDate>Fri, 14 Mar 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Laurent Davezies, Guillaume Hollard, Pedro Vergara Merino</dc:creator>
    </item>
    <item>
      <title>A primer on optimal transport for causal inference with observational data</title>
      <link>https://arxiv.org/abs/2503.07811</link>
      <description>arXiv:2503.07811v2 Announce Type: replace-cross 
Abstract: The theory of optimal transportation has developed into a powerful and elegant framework for comparing probability distributions, with wide-ranging applications in all areas of science. The fundamental idea of analyzing probabilities by comparing their underlying state space naturally aligns with the core idea of causal inference, where understanding and quantifying counterfactual states is paramount. Despite this intuitive connection, explicit research at the intersection of optimal transport and causal inference is only beginning to develop. Yet, many foundational models in causal inference have implicitly relied on optimal transport principles for decades, without recognizing the underlying connection. Therefore, the goal of this review is to offer an introduction to the surprisingly deep existing connections between optimal transport and the identification of causal effects with observational data -- where optimal transport is not just a set of potential tools, but actually builds the foundation of model assumptions. As a result, this review is intended to unify the language and notation between different areas of statistics, mathematics, and econometrics, by pointing out these existing connections, and to explore novel problems and directions for future work in both areas derived from this realization.</description>
      <guid isPermaLink="false">oai:arXiv.org:2503.07811v2</guid>
      <category>stat.ME</category>
      <category>cs.AI</category>
      <category>econ.EM</category>
      <pubDate>Fri, 14 Mar 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Florian F Gunsilius</dc:creator>
    </item>
  </channel>
</rss>
