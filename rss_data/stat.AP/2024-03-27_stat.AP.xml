<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>stat.AP updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/stat.AP</link>
    <description>stat.AP updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/stat.AP" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Wed, 27 Mar 2024 04:00:31 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Wed, 27 Mar 2024 00:00:00 -0400</pubDate>
    <skipDays>
      <day>Sunday</day>
      <day>Saturday</day>
    </skipDays>
    <item>
      <title>Are Made and Missed Different? An analysis of Field Goal Attempts of Professional Basketball Players via Depth Based Testing Procedure</title>
      <link>https://arxiv.org/abs/2403.17221</link>
      <description>arXiv:2403.17221v1 Announce Type: new 
Abstract: In this paper, we develop a novel depth-based testing procedure on spatial point processes to examine the difference in made and missed field goal attempts for NBA players. Specifically, our testing procedure can statistically detect the differences between made and missed field goal attempts for NBA players. We first obtain the depths of two processes under the polar coordinate system. A two-dimensional Kolmogorov-Smirnov test is then performed to test the difference between the depths of the two processes. Throughout extensive simulation studies, we show our testing procedure with good frequentist properties under both null hypothesis and alternative hypothesis. A comparison against the competing methods shows that our proposed procedure has better testing reliability and testing power. Application to the shot chart data of 191 NBA players in the 2017-2018 regular season offers interesting insights about these players' made and missed shot patterns.</description>
      <guid isPermaLink="false">oai:arXiv.org:2403.17221v1</guid>
      <category>stat.AP</category>
      <category>stat.ME</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-sa/4.0/</dc:rights>
      <dc:creator>Kai Qi, Guanyu Hu, Wei Wu</dc:creator>
    </item>
    <item>
      <title>Methodological Problems in Every Black-Box Study of Forensic Firearm Comparisons</title>
      <link>https://arxiv.org/abs/2403.17248</link>
      <description>arXiv:2403.17248v1 Announce Type: new 
Abstract: Reviews conducted by the National Academy of Sciences (2009) and the President's Council of Advisors on Science and Technology (2016) concluded that the field of forensic firearm comparisons has not been demonstrated to be scientifically valid. Scientific validity requires adequately designed studies of firearm examiner performance in terms of accuracy, repeatability, and reproducibility. Researchers have performed ``black-box'' studies with the goal of estimating these performance measures. As statisticians with expertise in experimental design, we conducted a literature search of such studies to date and then evaluated the design and statistical analysis methods used in each study. Our conclusion is that all studies in our literature search have methodological flaws that are so grave that they render the studies invalid, that is, incapable of establishing scientific validity of the field of firearms examination. Notably, error rates among firearms examiners, both collectively and individually, remain unknown. Therefore, statements about the common origin of bullets or cartridge cases that are based on examination of ``individual" characteristics do not have a scientific basis. We provide some recommendations for the design and analysis of future studies.</description>
      <guid isPermaLink="false">oai:arXiv.org:2403.17248v1</guid>
      <category>stat.AP</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Maria Cuellar, Susan Vanderplas, Amanda Luby, Michael Rosenblum</dc:creator>
    </item>
    <item>
      <title>Measurement Uncertainty Impact on Koopman Operator Estimation of Power System Dynamics</title>
      <link>https://arxiv.org/abs/2403.17339</link>
      <description>arXiv:2403.17339v1 Announce Type: new 
Abstract: Sensor measurements are mission-critical for monitoring and controlling power systems because they provide real-time insight into the grid operating condition; however, confidence in these insights depends greatly on the quality of the sensor data. Uncertainty in sensor measurements is an intrinsic aspect of the measurement process. In this paper, we develop an analytical method to quantify the impact of measurement uncertainties in numerical methods that employ the Koopman operator to identify nonlinear dynamics based on recorded data. In particular, we quantify the confidence interval of each element in the push-forward matrix from which a subset of the Koopman operator's discrete spectrum is estimated. We provide a detailed numerical analysis of the developed method applied to numerical simulations and field data collected from experiments conducted in a megawatt-scale facility at the National Renewable Energy Laboratory.</description>
      <guid isPermaLink="false">oai:arXiv.org:2403.17339v1</guid>
      <category>stat.AP</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>P. Algikar, P. Sharma, M. Netto, L. Mili</dc:creator>
    </item>
    <item>
      <title>Handling multivariable missing data in causal mediation analysis</title>
      <link>https://arxiv.org/abs/2403.17396</link>
      <description>arXiv:2403.17396v1 Announce Type: new 
Abstract: Mediation analysis is commonly used in epidemiological research, but guidance is lacking on how multivariable missing data should be dealt with in these analyses. Multiple imputation (MI) is a widely used approach, but questions remain regarding impact of missingness mechanism, how to ensure imputation model compatibility and approaches to variance estimation. To address these gaps, we conducted a simulation study based on the Victorian Adolescent Health Cohort Study. We considered six missingness mechanisms, involving varying assumptions regarding the influence of outcome and/or mediator on missingness in key variables. We compared the performance of complete-case analysis, seven MI approaches, differing in how the imputation model was tailored, and a "substantive model compatible" MI approach. We evaluated both the MI-Boot (MI, then bootstrap) and Boot-MI (bootstrap, then MI) approaches to variance estimation. Results showed that when the mediator and/or outcome influenced their own missingness, there was large bias in effect estimates, while for other mechanisms appropriate MI approaches yielded approximately unbiased estimates. Beyond incorporating all analysis variables in the imputation model, how MI was tailored for compatibility with mediation analysis did not greatly impact point estimation bias. BootMI returned variance estimates with smaller bias than MIBoot, especially in the presence of incompatibility.</description>
      <guid isPermaLink="false">oai:arXiv.org:2403.17396v1</guid>
      <category>stat.AP</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-sa/4.0/</dc:rights>
      <dc:creator>S. Ghazaleh Dashti, Katherine J. Lee, Julie A. Simpson, John B. Carlin, Margarita Moreno-Betancur</dc:creator>
    </item>
    <item>
      <title>Towards Multilevel Modelling of Train Passing Events on the Staffordshire Bridge</title>
      <link>https://arxiv.org/abs/2403.17820</link>
      <description>arXiv:2403.17820v1 Announce Type: new 
Abstract: We suggest a multilevel model, to represent aggregate train-passing events from the Staffordshire bridge monitoring system. We formulate a combined model from simple units, representing strain envelopes (of each train passing) for two types of commuter train. The measurements are treated as a longitudinal dataset and represented with a (low-rank approximation) hierarchical Gaussian process. For each unit in the combined model, we encode domain expertise as boundary condition constraints and work towards a general representation of the strain response. Looking forward, this should allow for the simulation of train types that were previously unobserved in the training data. For example, trains with more passengers or freights with a heavier payload. The strain event simulations are valuable since they can inform further experiments (including FEM calibration, fatigue analysis, or design) to test the bridge in hypothesised scenarios.</description>
      <guid isPermaLink="false">oai:arXiv.org:2403.17820v1</guid>
      <category>stat.AP</category>
      <category>stat.ML</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <arxiv:DOI>10.12783/shm2023/37066</arxiv:DOI>
      <dc:creator>Lawrence A. Bull, Chiho Jeon, Mark Girolami, Andrew Duncan, Jennifer Schooling, Miguel Bravo Haro</dc:creator>
    </item>
    <item>
      <title>A Personalized Predictive Model that Jointly Optimizes Discrimination and Calibration</title>
      <link>https://arxiv.org/abs/2403.17132</link>
      <description>arXiv:2403.17132v1 Announce Type: cross 
Abstract: Precision medicine is accelerating rapidly in the field of health research. This includes fitting predictive models for individual patients based on patient similarity in an attempt to improve model performance. We propose an algorithm which fits a personalized predictive model (PPM) using an optimal size of a similar subpopulation that jointly optimizes model discrimination and calibration, as it is criticized that calibration is not assessed nearly as often as discrimination despite poorly calibrated models being potentially misleading. We define a mixture loss function that considers model discrimination and calibration, and allows for flexibility in emphasizing one performance measure over another. We empirically show that the relationship between the size of subpopulation and calibration is quadratic, which motivates the development of our jointly optimized model. We also investigate the effect of within-population patient weighting on performance and conclude that the size of subpopulation has a larger effect on the predictive performance of the PPM compared to the choice of weight function.</description>
      <guid isPermaLink="false">oai:arXiv.org:2403.17132v1</guid>
      <category>stat.ME</category>
      <category>stat.AP</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Tatiana Krikella, Joel A. Dubin</dc:creator>
    </item>
    <item>
      <title>Deep functional multiple index models with an application to SER</title>
      <link>https://arxiv.org/abs/2403.17562</link>
      <description>arXiv:2403.17562v1 Announce Type: cross 
Abstract: Speech Emotion Recognition (SER) plays a crucial role in advancing human-computer interaction and speech processing capabilities. We introduce a novel deep-learning architecture designed specifically for the functional data model known as the multiple-index functional model. Our key innovation lies in integrating adaptive basis layers and an automated data transformation search within the deep learning framework. Simulations for this new model show good performances. This allows us to extract features tailored for chunk-level SER, based on Mel Frequency Cepstral Coefficients (MFCCs). We demonstrate the effectiveness of our approach on the benchmark IEMOCAP database, achieving good performance compared to existing methods.</description>
      <guid isPermaLink="false">oai:arXiv.org:2403.17562v1</guid>
      <category>cs.SD</category>
      <category>eess.AS</category>
      <category>stat.AP</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Matthieu Saumard, Abir El Haj, Thibault Napoleon</dc:creator>
    </item>
    <item>
      <title>Hierarchical Bayesian Modeling for Time-Dependent Inverse Uncertainty Quantification</title>
      <link>https://arxiv.org/abs/2401.00641</link>
      <description>arXiv:2401.00641v3 Announce Type: replace 
Abstract: This paper introduces a novel hierarchical Bayesian model specifically designed to address challenges in Inverse Uncertainty Quantification (IUQ) for time-dependent problems in nuclear Thermal Hydraulics (TH) systems. The unique characteristics of time-dependent data, such as high dimensionality and correlation in model outputs requires special attention in the IUQ process. By integrating Gaussian Processes (GP) with Principal Component Analysis (PCA), we efficiently construct surrogate models that effectively handle the complexity of dynamic TH systems. Additionally, we incorporate Neural Network (NN) models for time series regression, enhancing the computational accuracy and facilitating derivative calculations for efficient posterior sampling using the Hamiltonian Monte Carlo Method - No U-Turn Sampler (NUTS).
  We demonstrate the effectiveness of this hierarchical Bayesian approach using the transient experiments in the PSBT benchmark. Our results show improved estimates of Physical Model Parameters' posterior distributions and a reduced tendency for over-fitting, compared to conventional single-level Bayesian models. This approach offers a promising framework for extending IUQ to more complex, time-dependent problems.</description>
      <guid isPermaLink="false">oai:arXiv.org:2401.00641v3</guid>
      <category>stat.AP</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Chen Wang</dc:creator>
    </item>
    <item>
      <title>A Practical Introduction to Regression Discontinuity Designs: Extensions</title>
      <link>https://arxiv.org/abs/2301.08958</link>
      <description>arXiv:2301.08958v2 Announce Type: replace-cross 
Abstract: This monograph, together with its accompanying first part Cattaneo, Idrobo and Titiunik (2020), collects and expands the instructional materials we prepared for more than $50$ short courses and workshops on Regression Discontinuity (RD) methodology that we taught between 2014 and 2023. In this second monograph, we discuss several topics in RD methodology that build on and extend the analysis of RD designs introduced in Cattaneo, Idrobo and Titiunik (2020). Our first goal is to present an alternative RD conceptual framework based on local randomization ideas. This methodological approach can be useful in RD designs with discretely-valued scores, and can also be used more broadly as a complement to the continuity-based approach in other settings. Then, employing both continuity-based and local randomization approaches, we extend the canonical Sharp RD design in multiple directions: fuzzy RD designs, RD designs with discrete scores, and multi-dimensional RD designs. The goal of our two-part monograph is purposely practical and hence we focus on the empirical analysis of RD designs.</description>
      <guid isPermaLink="false">oai:arXiv.org:2301.08958v2</guid>
      <category>stat.ME</category>
      <category>econ.EM</category>
      <category>stat.AP</category>
      <category>stat.CO</category>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <arxiv:DOI>10.1017/9781009441896</arxiv:DOI>
      <dc:creator>Matias D. Cattaneo, Nicolas Idrobo, Rocio Titiunik</dc:creator>
    </item>
    <item>
      <title>Recursive Neyman Algorithm for Optimum Sample Allocation under Box Constraints on Sample Sizes in Strata</title>
      <link>https://arxiv.org/abs/2304.07034</link>
      <description>arXiv:2304.07034v4 Announce Type: replace-cross 
Abstract: The optimum sample allocation in stratified sampling is one of the basic issues of survey methodology. It is a procedure of dividing the overall sample size into strata sample sizes in such a way that for given sampling designs in strata the variance of the stratified $\pi$ estimator of the population total (or mean) for a given study variable assumes its minimum. In this work, we consider the optimum allocation of a sample, under lower and upper bounds imposed jointly on sample sizes in strata. We are concerned with the variance function of some generic form that, in particular, covers the case of the simple random sampling without replacement in strata. The goal of this paper is twofold. First, we establish (using the Karush-Kuhn-Tucker conditions) a generic form of the optimal solution, the so-called optimality conditions. Second, based on the established optimality conditions, we derive an efficient recursive algorithm, named RNABOX, which solves the allocation problem under study. The RNABOX can be viewed as a generalization of the classical recursive Neyman allocation algorithm, a popular tool for optimum allocation when only upper bounds are imposed on sample strata-sizes. We implement RNABOX in R as a part of our package stratallo which is available from the Comprehensive R Archive Network (CRAN) repository.</description>
      <guid isPermaLink="false">oai:arXiv.org:2304.07034v4</guid>
      <category>stat.ME</category>
      <category>math.ST</category>
      <category>stat.AP</category>
      <category>stat.TH</category>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Jacek Weso{\l}owski, Robert Wieczorkowski, Wojciech W\'ojciak</dc:creator>
    </item>
    <item>
      <title>Electron-Tunnelling-Noise Programmable Random Variate Accelerator for Monte Carlo Sampling</title>
      <link>https://arxiv.org/abs/2403.16421</link>
      <description>arXiv:2403.16421v2 Announce Type: replace-cross 
Abstract: This article presents an electron tunneling noise programmable random variate accelerator for accelerating the sampling stage of Monte Carlo simulations. We used the LiteX framework to generate a FemtoRV imfc RISC-V instruction set soft processor and deploy it on a Digilent Arty-100T FPGA development board. The RISC-V soft processor augmented with our programmable random variate accelerator achieves an average speedup of 8.70 times and a median speedup of 8.68 times for a suite of twelve different benchmark applications when compared to GNU Scientific Library software random number generation. These speedups are achievable because the benchmarks spend an average of 90.0 % of their execution time generating random samples. The results of the Monte Carlo benchmark programs run over the programmable random variate accelerator have an average Wasserstein distance of 1.48 times and a median Wasserstein distance of 1.41 times$that of the results produced by the GNU Scientific Library random number generators. The soft processor samples the electron tunneling noise source using the hardened XADC block in the FPGA. The flexibility of the LiteX framework allows for the deployment of any LiteX-supported soft processor with an electron tunneling noise programmable random variate accelerator on any LiteX-supported development board that contains an FPGA with an XADC.</description>
      <guid isPermaLink="false">oai:arXiv.org:2403.16421v2</guid>
      <category>cs.AR</category>
      <category>cs.ET</category>
      <category>physics.comp-ph</category>
      <category>stat.AP</category>
      <category>stat.CO</category>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>James T. Meech, Vasileios Tsoutsouras, Phillip Stanley-Marbell</dc:creator>
    </item>
  </channel>
</rss>
