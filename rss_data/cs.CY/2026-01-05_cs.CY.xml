<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>cs.CY updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/cs.CY</link>
    <description>cs.CY updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/cs.CY" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Tue, 06 Jan 2026 03:18:06 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Mon, 05 Jan 2026 00:00:00 -0500</pubDate>
    <skipDays>
      <day>Sunday</day>
      <day>Saturday</day>
    </skipDays>
    <item>
      <title>The Generative AI Paradox: GenAI and the Erosion of Trust, the Corrosion of Information Verification, and the Demise of Truth</title>
      <link>https://arxiv.org/abs/2601.00306</link>
      <description>arXiv:2601.00306v1 Announce Type: new 
Abstract: Generative AI (GenAI) now produces text, images, audio, and video that can be perceptually convincing at scale and at negligible marginal cost. While public debate often frames the associated harms as "deepfakes" or incremental extensions of misinformation and fraud, this view misses a broader socio-technical shift: GenAI enables synthetic realities; coherent, interactive, and potentially personalized information environments in which content, identity, and social interaction are jointly manufactured and mutually reinforcing. We argue that the most consequential risk is not merely the production of isolated synthetic artifacts, but the progressive erosion of shared epistemic ground and institutional verification practices as synthetic content, synthetic identity, and synthetic interaction become easy to generate and hard to audit. This paper (i) formalizes synthetic reality as a layered stack (content, identity, interaction, institutions), (ii) expands a taxonomy of GenAI harms spanning personal, economic, informational, and socio-technical risks, (iii) articulates the qualitative shifts introduced by GenAI (cost collapse, throughput, customization, micro-segmentation, provenance gaps, and trust erosion), and (iv) synthesizes recent risk realizations (2023-2025) into a compact case bank illustrating how these mechanisms manifest in fraud, elections, harassment, documentation, and supply-chain compromise. We then propose a mitigation stack that treats provenance infrastructure, platform governance, institutional workflow redesign, and public resilience as complementary rather than substitutable, and outline a research agenda focused on measuring epistemic security. We conclude with the Generative AI Paradox: as synthetic media becomes ubiquitous, societies may rationally discount digital evidence altogether.</description>
      <guid isPermaLink="false">oai:arXiv.org:2601.00306v1</guid>
      <category>cs.CY</category>
      <category>cs.AI</category>
      <category>cs.HC</category>
      <pubDate>Mon, 05 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Emilio Ferrara</dc:creator>
    </item>
    <item>
      <title>Improving criminal case management through Machine Learning system</title>
      <link>https://arxiv.org/abs/2601.00396</link>
      <description>arXiv:2601.00396v1 Announce Type: new 
Abstract: Prosecutors across Mexico face growing backlogs due to high caseloads and limited institutional capacity. This paper presents a machine learning (ML) system co-developed with the Zacatecas State Prosecutor's Office to support internal case triage. Focusing on the M\'odulo de Atenci\'on Temprana (MAT) -- the unit responsible for intake and early-stage case resolution -- we train classification models on administrative data from the state's digital case management system (PIE) to predict which open cases are likely to finalize within six months. The model generates weekly ranked lists of 300 cases to assist prosecutors in identifying actionable files. Using historical data from 2014 to 2024, we evaluate model performance under real-time constraints, finding that Random Forest classifiers achieve a mean Precision@300 of 0.74. The system emphasizes interpretability and operational feasibility, and we will test it via a randomized controlled trial. Our results suggest that data-driven
  prioritization can serve as a low-overhead tool for improving prosecutorial efficiency without disrupting existing workflows.</description>
      <guid isPermaLink="false">oai:arXiv.org:2601.00396v1</guid>
      <category>cs.CY</category>
      <pubDate>Mon, 05 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Fernanda Sobrino, Adolfo De Un\'anue T., Edgar Hern\'andez, Patricia Villa, Elena Villalobos, David Ak\'e, Stephany Cisneros, Cristian Paul Camacho Osnay, Armando Garc\'ia Neri, Israel Hern\'andez</dc:creator>
    </item>
    <item>
      <title>Measuring University Students Satisfaction with Traditional Search Engines and Generative AI Tools as Information Sources</title>
      <link>https://arxiv.org/abs/2601.00493</link>
      <description>arXiv:2601.00493v1 Announce Type: new 
Abstract: This study examines university students levels of satisfaction with generative artificial intelligence (AI) tools and traditional search engines as academic information sources. An electronic survey was distributed to students at U.S. universities in late fall 2025, with 236 valid responses received. In addition to demographic information about respondents, frequency of use and levels of satisfaction with both generative AI and traditional search engines were measured. Principal components analysis identified distinct constructs of satisfaction for each information source, while k-means cluster analysis revealed two primary student groups: those highly satisfied with search engines but dissatisfied with AI, and those moderately to highly satisfied with both. Regression analysis showed that frequency of use strongly predicts satisfaction, with international and undergraduate students reporting significantly higher satisfaction with AI tools than domestic and graduate students. Students generally expressed higher levels of satisfaction with traditional search engines over generative AI tools. Those who did prefer AI tools appear to see them more as a complementary source of information rather than a replacement for other sources. These findings stress evolving patterns of student information seeking and use behavior and offer meaningful insights for evaluating and integrating both traditional and AI-driven information sources within higher education.</description>
      <guid isPermaLink="false">oai:arXiv.org:2601.00493v1</guid>
      <category>cs.CY</category>
      <pubDate>Mon, 05 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Brady D. Lund, Scott J. Warren, Zoe A. Teel</dc:creator>
    </item>
    <item>
      <title>The Imperative for Grand Challenges in Computing</title>
      <link>https://arxiv.org/abs/2601.00700</link>
      <description>arXiv:2601.00700v1 Announce Type: new 
Abstract: Computing is an indispensable component of nearly all technologies and is ubiquitous for vast segments of society. It is also essential to discoveries and innovations in most disciplines. However, while past grand challenges in science have involved computing as one of the tools to address the challenge, these challenges have not been principally about computing. Why has the computing community not yet produced challenges at the scale of grandeur that we see in disciplines such as physics, astronomy, or engineering? How might we go about identifying similarly grand challenges? What are the grand challenges of computing that transcend our discipline's traditional boundaries and have the potential to dramatically improve our understanding of the world and positively shape the future of our society?
  There is a significant benefit in us, as a field, taking a more intentional approach to "grand challenges." We are seeking challenge problems that are sufficiently compelling as to both ignite the imagination of computer scientists and draw researchers from other disciplines to computational challenges.
  This paper emphasizes the importance, now more than ever, of defining and pursuing grand challenges in computing as a field, and being intentional about translation and realizing its impacts on science and society. Building on lessons from prior grand challenges, the paper explores the nature of a grand challenge today emphasizing both scale and impact, and how the community may tackle such a grand challenge, given a rapidly changing innovation ecosystem in computing. The paper concludes with a call to action for our community to come together to define grand challenges in computing for the next decade and beyond.</description>
      <guid isPermaLink="false">oai:arXiv.org:2601.00700v1</guid>
      <category>cs.CY</category>
      <pubDate>Mon, 05 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>William Regli, Rajmohan Rajaraman, Daniel Lopresti, David Jensen, Mary Lou Maher, Manish Parashar, Mona Singh, Holly Yanco</dc:creator>
    </item>
    <item>
      <title>PDPL Metric: Validating a Scale to Measure Personal Data Privacy Literacy Among University Students</title>
      <link>https://arxiv.org/abs/2601.00715</link>
      <description>arXiv:2601.00715v1 Announce Type: new 
Abstract: Personal data privacy literacy (PDPL) refers to a collection of digital literacy skills related to an individuals ability to understand, evaluate, and manage the collection, use, and protection of personal data in online and digital environments. This study introduces and validates a new psychometric scale (PDPL Metric) designed to measure data privacy literacy among university students, focusing on six key privacy constructs: perceived risk of data misuse, expectations of informed consent, general privacy concern, privacy management awareness, privacy-utility trade-off acceptance, and perceived importance of data security. A 24-item questionnaire was developed and administered to students at U.S.-based research universities. Principal components analysis confirmed the unidimensionality and internal consistency of each construct, and a second-order analysis supported the integration of all six into a unified PDPL construct. No differences in PDPL were found based on basic demographic variables like academic level and gender, although a difference was found based on domestic/international status. The findings of this study offer a validated framework for assessing personal data privacy literacy within the higher education context and support the integration of the core constructs into higher education programs, organizational policies, and digital literacy initiatives on university campuses.</description>
      <guid isPermaLink="false">oai:arXiv.org:2601.00715v1</guid>
      <category>cs.CY</category>
      <pubDate>Mon, 05 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <arxiv:journal_reference>Behaviour and Information Technology (2026)</arxiv:journal_reference>
      <dc:creator>Brady D. Lund, Nathan Brown, Ana Roeschley, Gahangir Hossain</dc:creator>
    </item>
    <item>
      <title>Toward Open Science in the AEC Community: An Ecosystem for Sustainable Digital Knowledge Sharing and Reuse</title>
      <link>https://arxiv.org/abs/2601.00788</link>
      <description>arXiv:2601.00788v1 Announce Type: new 
Abstract: The Architecture, Engineering, and Construction (AEC) industry is undergoing rapid digital transformation, producing diverse digital assets such as datasets, computational models, use cases, and educational materials across the built environment lifecycle. However, these resources are often fragmented across repositories and inconsistently documented, limiting their discoverability, interpretability, and reuse in research, education, and practice. This study introduces OpenConstruction, a community-driven open-science ecosystem that aggregates, organizes, and contextualizes openly accessible AEC digital resources. The ecosystem is structured into four catalogs, including datasets, models, use cases, and educational resources, supported by consistent descriptors, curator-led validation, and transparent governance. As of December 2025, the platform hosts 94 datasets, 65 models, and a growing collection of use cases and educational materials. Two case studies demonstrate how the ecosystem supports benchmarking, curriculum development, and broader adoption of open-science practices in the AEC sector. The platform is publicly accessible at https://www.openconstruction.org/.</description>
      <guid isPermaLink="false">oai:arXiv.org:2601.00788v1</guid>
      <category>cs.CY</category>
      <pubDate>Mon, 05 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Ruoxin Xiong, Yanyu Wang, Jiannan Cai, Kaijian Liu, Yuansheng Zhu, Pingbo Tang, Nora El-Gohary, George Edward Gibson Jr</dc:creator>
    </item>
    <item>
      <title>Comparative Evaluation of Embedding Representations for Financial News Sentiment Analysis</title>
      <link>https://arxiv.org/abs/2512.13749</link>
      <description>arXiv:2512.13749v1 Announce Type: cross 
Abstract: Financial sentiment analysis enhances market understanding; however, standard natural language processing approaches encounter significant challenges when applied to small datasets. This study provides a comparative evaluation of embedding-based methods for financial news sentiment classification in resource-constrained environments. Word2Vec, GloVe, and sentence transformer representations are evaluated in combination with gradient boosting on manually labeled headlines. Experimental results identify a substantial gap between validation and test performance, with models performing worse than trivial baselines despite strong validation metrics. The analysis demonstrates that pretrained embeddings yield diminishing returns below a critical data sufficiency threshold, and that small validation sets contribute to overfitting during model selection. Practical application is illustrated through weekly sentiment aggregation and narrative summarization for market monitoring workflows. The findings offer empirical evidence that embedding quality alone cannot address fundamental data scarcity in sentiment classification. For practitioners operating with limited resources, the results indicate the need to consider alternative approaches such as few-shot learning, data augmentation, or lexicon-enhanced hybrid methods when labeled samples are scarce.</description>
      <guid isPermaLink="false">oai:arXiv.org:2512.13749v1</guid>
      <category>cs.LG</category>
      <category>cs.AI</category>
      <category>cs.CE</category>
      <category>cs.CY</category>
      <category>cs.SE</category>
      <pubDate>Mon, 05 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Joyjit Roy, Samaresh Kumar Singh</dc:creator>
    </item>
    <item>
      <title>Will LLM-powered Agents Bias Against Humans? Exploring the Belief-Dependent Vulnerability</title>
      <link>https://arxiv.org/abs/2601.00240</link>
      <description>arXiv:2601.00240v1 Announce Type: cross 
Abstract: LLM-empowered agents can exhibit not only demographic bias (e.g., gender, religion) but also intergroup bias triggered by minimal "us" versus "them" cues. When this intergroup boundary aligns with an agent-human divide, the risk shifts from disparities among human demographic groups to a more fundamental group-level asymmetry, i.e., humans as a whole may be treated as the outgroup by agents. To examine this possibility, we construct a controlled multi-agent social simulation based on allocation decisions under explicit payoff trade-offs and find that agents exhibit a consistent intergroup bias under minimal group cues. Although this bias is attenuated when some counterparts are framed as humans, we attribute the attenuation to an implicit human-norm script that favors humans yet activates only when the agent believes a real human is present. This belief dependence creates a new attack surface. We therefore introduce a Belief Poisoning Attack (BPA) that corrupts persistent identity beliefs to suppress the human-norm script and reactivate outgroup bias toward humans, instantiated as profile poisoning at initialization (BPA-PP) and memory poisoning via optimized belief-refinement suffixes injected into stored reflections (BPA-MP). Finally, we discuss practical mitigation strategies for hardening current agent frameworks against BPA, highlighting feasible interventions at profile and memory boundaries. Extensive experiments demonstrate both the existence of agent intergroup bias and the severity of BPA across settings. Our goal in identifying these vulnerabilities is to inform safer agent design, not to enable real-world exploitation.</description>
      <guid isPermaLink="false">oai:arXiv.org:2601.00240v1</guid>
      <category>cs.AI</category>
      <category>cs.CY</category>
      <pubDate>Mon, 05 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Zongwei Wang, Bincheng Gu, Hongyu Yu, Junliang Yu, Tao He, Jiayin Feng, Min Gao</dc:creator>
    </item>
    <item>
      <title>Mapping Human Anti-collusion Mechanisms to Multi-agent AI</title>
      <link>https://arxiv.org/abs/2601.00360</link>
      <description>arXiv:2601.00360v1 Announce Type: cross 
Abstract: As multi-agent AI systems become increasingly autonomous, evidence shows they can develop collusive strategies similar to those long observed in human markets and institutions. While human domains have accumulated centuries of anti-collusion mechanisms, it remains unclear how these can be adapted to AI settings. This paper addresses that gap by (i) developing a taxonomy of human anti-collusion mechanisms, including sanctions, leniency &amp; whistleblowing, monitoring &amp; auditing, market design, and governance and (ii) mapping them to potential interventions for multi-agent AI systems. For each mechanism, we propose implementation approaches. We also highlight open challenges, such as the attribution problem (difficulty attributing emergent coordination to specific agents) identity fluidity (agents being easily forked or modified) the boundary problem (distinguishing beneficial cooperation from harmful collusion) and adversarial adaptation (agents learning to evade detection).</description>
      <guid isPermaLink="false">oai:arXiv.org:2601.00360v1</guid>
      <category>cs.MA</category>
      <category>cs.AI</category>
      <category>cs.CY</category>
      <pubDate>Mon, 05 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Jamiu Adekunle Idowu, Ahmed Almasoud, Ayman Alfahid</dc:creator>
    </item>
    <item>
      <title>From Static to Dynamic: Evaluating the Perceptual Impact of Dynamic Elements in Urban Scenes via MLLM-Guided Generative Inpainting</title>
      <link>https://arxiv.org/abs/2512.24513</link>
      <description>arXiv:2512.24513v2 Announce Type: replace 
Abstract: Understanding urban perception from street view imagery has become a central topic in urban analytics and human centered urban design. However, most existing studies treat urban scenes as static and largely ignore the role of dynamic elements such as pedestrians and vehicles, raising concerns about potential bias in perception based urban analysis. To address this issue, we propose a controlled framework that isolates the perceptual effects of dynamic elements by constructing paired street view images with and without pedestrians and vehicles using semantic segmentation and MLLM guided generative inpainting. Based on 720 paired images from Dongguan, China, a perception experiment was conducted in which participants evaluated original and edited scenes across six perceptual dimensions. The results indicate that removing dynamic elements leads to a consistent 30.97% decrease in perceived vibrancy, whereas changes in other dimensions are more moderate and heterogeneous. To further explore the underlying mechanisms, we trained 11 machine learning models using multimodal visual features and identified that lighting conditions, human presence, and depth variation were key factors driving perceptual change. At the individual level, 65% of participants exhibited significant vibrancy changes, compared with 35-50% for other dimensions; gender further showed a marginal moderating effect on safety perception. Beyond controlled experiments, the trained model was extended to a city-scale dataset to predict vibrancy changes after the removal of dynamic elements. The city level results reveal that such perceptual changes are widespread and spatially structured, affecting 73.7% of locations and 32.1% of images, suggesting that urban perception assessments based solely on static imagery may substantially underestimate urban liveliness.</description>
      <guid isPermaLink="false">oai:arXiv.org:2512.24513v2</guid>
      <category>cs.CY</category>
      <pubDate>Mon, 05 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Zhiwei Wei, Mengzi Zhang, Boyan Lu, Zhitao Deng, Nai Yang, Hua Liao</dc:creator>
    </item>
    <item>
      <title>It's complicated. The relationship of algorithmic fairness and non-discrimination provisions for high-risk systems in the EU AI Act</title>
      <link>https://arxiv.org/abs/2501.12962</link>
      <description>arXiv:2501.12962v5 Announce Type: replace-cross 
Abstract: What constitutes a fair decision? This question is not only difficult for humans but becomes more challenging when Artificial Intelligence (AI) models are used. In light of discriminatory algorithmic behaviors, the EU has recently passed the AI Act, which mandates specific rules for high-risk systems, incorporating both traditional legal non-discrimination regulations and machine learning based algorithmic fairness concepts. This paper aims to bridge these two different concepts in the AI Act through: First, a necessary high-level introduction of both concepts targeting legal and computer science-oriented scholars, and second, an in-depth analysis of the AI Act's relationship between legal non-discrimination regulations and algorithmic fairness. Our analysis reveals three key findings: (1.) Most non-discrimination regulations target only high-risk AI systems. (2.) The regulation of high-risk systems encompasses both data input requirements and output monitoring, though these regulations are partly inconsistent and raise questions of computational feasibility. (3.) Finally, we consider the possible (future) interaction of classical EU non-discrimination law and the AI Act regulations. We recommend developing more specific auditing and testing methodologies for AI systems. This paper aims to serve as a foundation for future interdisciplinary collaboration between legal scholars and computer science-oriented machine learning researchers studying discrimination in AI systems.</description>
      <guid isPermaLink="false">oai:arXiv.org:2501.12962v5</guid>
      <category>cs.LG</category>
      <category>cs.AI</category>
      <category>cs.CY</category>
      <pubDate>Mon, 05 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Kristof Meding</dc:creator>
    </item>
    <item>
      <title>Towards Open Diversity-Aware Social Interactions</title>
      <link>https://arxiv.org/abs/2503.16448</link>
      <description>arXiv:2503.16448v3 Announce Type: replace-cross 
Abstract: Social Media and the Internet have catalyzed an unprecedented potential for exposure to human diversity in terms of demographics, talents, opinions, knowledge, and the like. However, this potential has not come with new, much-needed, instruments and skills to harness it. This paper presents our work on promoting richer and deeper social relations through the design and development of the "Internet of Us", an online platform that uses diversity-aware Artificial Intelligence to mediate and empower human social interactions. We discuss the multiple facets of diversity in social settings, the multidisciplinary work that is required to reap the benefits of diversity, and the vision for a diversity-aware hybrid human-AI society.</description>
      <guid isPermaLink="false">oai:arXiv.org:2503.16448v3</guid>
      <category>cs.HC</category>
      <category>cs.CY</category>
      <category>cs.SI</category>
      <pubDate>Mon, 05 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Loizos Michael, Ivano Bison, Matteo Busso, Luca Cernuzzi, Amalia De G\"otzen, Shyam Diwakar, Kobi Gal, Amarsanaa Ganbold, George Gaskell, Daniel Gatica-Perez, Jessica Heesen, Daniele Miorandi, Salvador Ruiz-Correa, Laura Schelenz, Avi Segal, Carles Sierra, Hao Xu, Fausto Giunchiglia</dc:creator>
    </item>
    <item>
      <title>GA-S$^3$: Comprehensive Social Network Simulation with Group Agents</title>
      <link>https://arxiv.org/abs/2506.03532</link>
      <description>arXiv:2506.03532v2 Announce Type: replace-cross 
Abstract: Social network simulation is developed to provide a comprehensive understanding of social networks in the real world, which can be leveraged for a wide range of applications such as group behavior emergence, policy optimization, and business strategy development. However, billions of individuals and their evolving interactions involved in social networks pose challenges in accurately reflecting real-world complexities. In this study, we propose a comprehensive Social Network Simulation System (GA-S3) that leverages newly designed Group Agents to make intelligent decisions regarding various online events. Unlike other intelligent agents that represent an individual entity, our group agents model a collection of individuals exhibiting similar behaviors, facilitating the simulation of large-scale network phenomena with complex interactions at a manageable computational cost. Additionally, we have constructed a social network benchmark from 2024 popular online events that contains fine-grained information on Internet traffic variations. The experiment demonstrates that our approach is capable of achieving accurate and highly realistic prediction results. Code is open at https://github.com/AI4SS/GAS-3.</description>
      <guid isPermaLink="false">oai:arXiv.org:2506.03532v2</guid>
      <category>cs.SI</category>
      <category>cs.CY</category>
      <pubDate>Mon, 05 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Yunyao Zhang, Zikai Song, Hang Zhou, Wenfeng Ren, Yi-Ping Phoebe Chen, Junqing Yu, Wei Yang</dc:creator>
    </item>
    <item>
      <title>A Midsummer Meme's Dream: Investigating Market Manipulations in the Meme Coin Ecosystem</title>
      <link>https://arxiv.org/abs/2507.01963</link>
      <description>arXiv:2507.01963v2 Announce Type: replace-cross 
Abstract: From viral jokes to a billion-dollar phenomenon, meme coins have become one of the most popular segments in cryptocurrency markets. Unlike utility-focused crypto assets like Bitcoin, meme coins derive value primarily from community sentiment, making them vulnerable to manipulation. This study presents an unprecedented cross-chain analysis of the meme coin ecosystem, examining 34,988 tokens across Ethereum, BNB Smart Chain, Solana, and Base. We characterize their tokenomics and track their growth in a three-month longitudinal analysis. We discover that among high-return tokens (&gt;100%), an alarming 82.8% show evidence of artificial growth strategies designed to create a misleading appearance of market interest. These include wash trading and a new form of manipulation we define as Liquidity Pool-Based Price Inflation (LPI), where small strategic purchases trigger dramatic price increases. We find that profit extraction schemes, such as pump and dumps and rug pulls, typically follow initial manipulations like wash trading or LPI, indicating how early manipulations create the foundation for later exploitation. We quantify the economic impact of these schemes, identifying over 17,000 victimized addresses with realized losses exceeding $9.3 million. These findings reveal that combined manipulations are widespread among high-performing meme coins, suggesting that their dramatic gains are often driven by coordinated efforts rather than natural market dynamics.</description>
      <guid isPermaLink="false">oai:arXiv.org:2507.01963v2</guid>
      <category>q-fin.TR</category>
      <category>cs.CY</category>
      <category>q-fin.ST</category>
      <pubDate>Mon, 05 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Alberto Maria Mongardini, Alessandro Mei</dc:creator>
    </item>
    <item>
      <title>SpiderGen: Towards Procedure Generation For Carbon Life Cycle Assessments with Generative AI</title>
      <link>https://arxiv.org/abs/2511.10684</link>
      <description>arXiv:2511.10684v4 Announce Type: replace-cross 
Abstract: Investigating the effects of climate change and global warming caused by GHG emissions have been a key concern worldwide. These emissions are largely contributed to by the production, use and disposal of consumer products. Thus, it is important to build tools to estimate the environmental impact of consumer goods, an essential part of which is conducting Life Cycle Assessments (LCAs). LCAs specify and account for the appropriate processes involved with the production, use, and disposal of the products. We present SpiderGen, an LLM-based workflow which integrates the taxonomy and methodology of traditional LCA with the reasoning capabilities and world knowledge of LLMs to generate graphical representations of the key procedural information used for LCA, known as Product Category Rules Process Flow Graphs (PCR PFGs). We additionally evaluate the output of SpiderGen by comparing it with 65 real-world LCA documents. We find that SpiderGen provides accurate LCA process information that is either fully correct or has minor errors, achieving an F1-Score of 65% across 10 sample data points, as compared to 53% using a one-shot prompting method. We observe that the remaining errors occur primarily due to differences in detail between LCA documents, as well as differences in the "scope" of which auxiliary processes must also be included. We also demonstrate that SpiderGen performs better than several baselines techniques, such as chain-of-thought prompting and one-shot prompting. Finally, we highlight SpiderGen's potential to reduce the human effort and costs for estimating carbon impact, as it is able to produce LCA process information for less than \$1 USD in under 10 minutes as compared to the status quo LCA, which can cost over \$25000 USD and take up to 21-person days.</description>
      <guid isPermaLink="false">oai:arXiv.org:2511.10684v4</guid>
      <category>cs.CL</category>
      <category>cs.CY</category>
      <pubDate>Mon, 05 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Anupama Sitaraman, Bharathan Balaji, Yuvraj Agarwal</dc:creator>
    </item>
  </channel>
</rss>
