<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>cs.ET updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/cs.ET</link>
    <description>cs.ET updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/cs.ET" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Fri, 10 Oct 2025 04:01:01 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Fri, 10 Oct 2025 00:00:00 -0400</pubDate>
    <skipDays>
      <day>Sunday</day>
      <day>Saturday</day>
    </skipDays>
    <item>
      <title>SEPhIA: &lt;1 laser/neuron Spiking Electro-Photonic Integrated Multi-Tiled Architecture for Scalable Optical Neuromorphic Computing</title>
      <link>https://arxiv.org/abs/2510.07427</link>
      <description>arXiv:2510.07427v1 Announce Type: new 
Abstract: Research into optical spiking neural networks (SNNs) has primarily focused on spiking devices, networks of excitable lasers or numerical modelling of large architectures, often overlooking key constraints such as limited optical power, crosstalk and footprint. We introduce SEPhIA, a photonic-electronic, multi-tiled SNN architecture emphasizing implementation feasibility and realistic scaling. SEPhIA leverages microring resonator modulators (MRMs) and multi-wavelength sources to achieve effective sub-one-laser-per-spiking neuron efficiency. We validate SEPhIA at both device and architecture levels by time-domain co-simulating excitable CMOS-MRR coupled circuits and by devising a physics-aware, trainable optoelectronic SNN model, with both approaches utilizing experimentally derived device parameters. The multi-layer optoelectronic SNN achieves classification accuracies over 90% on a four-class spike-encoded dataset, closely comparable to software models. A design space study further quantifies how photonic device parameters impact SNN performance under constrained signal-to-noise conditions. SEPhIA offers a scalable, expressive, physically grounded solution for neuromorphic photonic computing, capable of addressing spike-encoded tasks.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.07427v1</guid>
      <category>cs.ET</category>
      <category>cs.NE</category>
      <category>physics.optics</category>
      <pubDate>Fri, 10 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-sa/4.0/</dc:rights>
      <dc:creator>Mat\v{e}j Hejda, Aishwarya Natarajan, Chaerin Hong, Mehmet Berkay On, S\'ebastien d'Herbais de Thun, Raymond G. Beausoleil, Thomas Van Vaerenbergh</dc:creator>
    </item>
    <item>
      <title>A Distributed Emulation Environment for In-Memory Computing Systems</title>
      <link>https://arxiv.org/abs/2510.08257</link>
      <description>arXiv:2510.08257v1 Announce Type: new 
Abstract: In-memory computing technology is used extensively in artificial intelligence devices due to lower power consumption and fast calculation of matrix-based functions. The development of such a device and its integration in a system takes a significant amount of time and requires the use of a real-time emulation environment, where various system aspects are analyzed, microcode is tested, and applications are deployed, even before the real chip is available. In this work, we present the architecture, the software development tools, and experimental results of a distributed and expandable emulation system for rapid prototyping of integrated circuits based on in-memory computing technologies. Presented experimental results demonstrate the usefulness of the proposed emulator.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.08257v1</guid>
      <category>cs.ET</category>
      <category>cs.AI</category>
      <pubDate>Fri, 10 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <arxiv:DOI>10.1109/I2MTC62753.2025.11078997</arxiv:DOI>
      <dc:creator>Eleni Bougioukou, Anastasios Petropoulos, Nikolaos Toulgaridis, Theodoros Chatzimichail, Theodore Antonakopoulos</dc:creator>
    </item>
    <item>
      <title>DRACO: Data Replication and Collection Framework for Enhanced Data Availability and Robustness in IoT Networks</title>
      <link>https://arxiv.org/abs/2510.07464</link>
      <description>arXiv:2510.07464v1 Announce Type: cross 
Abstract: The Internet of Things (IoT) bridges the gap between the physical and digital worlds, enabling seamless interaction with real-world objects via the Internet. However, IoT systems face significant challenges in ensuring efficient data generation, collection, and management, particularly due to the resource-constrained and unreliable nature of connected devices, which can lead to data loss. This paper presents DRACO (Data Replication and Collection), a framework that integrates a distributed hop-by-hop data replication approach with an overhead-free mobile sink-based data collection strategy. DRACO enhances data availability, optimizes replica placement, and ensures efficient data retrieval even under node failures and varying network densities. Extensive ns-3 simulations demonstrate that DRACO outperforms state-of-the-art techniques, improving data availability by up to 15% and 34%, and replica creation by up to 18% and 40%, compared to greedy and random replication techniques, respectively. DRACO also ensures efficient data dissemination through optimized replica distribution and achieves superior data collection efficiency under varying node densities and failure scenarios as compared to commonly used uncontrolled sink mobility approaches namely random walk and self-avoiding random walk. By addressing key IoT data management challenges, DRACO offers a scalable and resilient solution well-suited for emerging use cases.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.07464v1</guid>
      <category>cs.NI</category>
      <category>cs.ET</category>
      <pubDate>Fri, 10 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Waleed Bin Qaim, Oznur Ozkasap, Rabia Qadar, Moncef Gabbouj</dc:creator>
    </item>
    <item>
      <title>Sentiment Matters: An Analysis of 200 Human-SAV Interactions</title>
      <link>https://arxiv.org/abs/2510.08202</link>
      <description>arXiv:2510.08202v1 Announce Type: cross 
Abstract: Shared Autonomous Vehicles (SAVs) are likely to become an important part of the transportation system, making effective human-SAV interactions an important area of research. This paper introduces a dataset of 200 human-SAV interactions to further this area of study. We present an open-source human-SAV conversational dataset, comprising both textual data (e.g., 2,136 human-SAV exchanges) and empirical data (e.g., post-interaction survey results on a range of psychological factors). The dataset's utility is demonstrated through two benchmark case studies: First, using random forest modeling and chord diagrams, we identify key predictors of SAV acceptance and perceived service quality, highlighting the critical influence of response sentiment polarity (i.e., perceived positivity). Second, we benchmark the performance of an LLM-based sentiment analysis tool against the traditional lexicon-based TextBlob method. Results indicate that even simple zero-shot LLM prompts more closely align with user-reported sentiment, though limitations remain. This study provides novel insights for designing conversational SAV interfaces and establishes a foundation for further exploration into advanced sentiment modeling, adaptive user interactions, and multimodal conversational systems.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.08202v1</guid>
      <category>cs.HC</category>
      <category>cs.AI</category>
      <category>cs.CL</category>
      <category>cs.ET</category>
      <pubDate>Fri, 10 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Lirui Guo, Michael G. Burke, Wynita M. Griggs</dc:creator>
    </item>
    <item>
      <title>Quantum Multiplexer Simplification for State Preparation</title>
      <link>https://arxiv.org/abs/2409.05618</link>
      <description>arXiv:2409.05618v2 Announce Type: replace-cross 
Abstract: The initialization of quantum states or Quantum State Preparation (QSP) is a basic subroutine in quantum algorithms. In the worst case, general QSP algorithms are expensive due to the application of multi-controlled gates required to build the quantum state. Here, we propose an algorithm that detects whether a given quantum state can be factored into substates, increasing the efficiency of compiling the QSP circuit when we initialize states with some level of unentanglement. The simplification is done by eliminating controls of quantum multiplexers, significantly reducing circuit depth and the number of CNOT gates with a better execution and compilation time than the previous QSP algorithms. Considering efficiency in terms of depth and number of CNOT gates, our method is competitive with the methods in the literature. However, when it comes to run-time and compilation efficiency, our result is significantly better, and the experiments show that by increasing the number of qubits, the gap between the temporal efficiency of the methods increases.</description>
      <guid isPermaLink="false">oai:arXiv.org:2409.05618v2</guid>
      <category>quant-ph</category>
      <category>cs.ET</category>
      <pubDate>Fri, 10 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <arxiv:DOI>10.1145/3748260</arxiv:DOI>
      <arxiv:journal_reference>ACM Transactions on Quantum Computing 6, 4, Article 26 (December 2025)</arxiv:journal_reference>
      <dc:creator>Jos\'e A. de Carvalho, Carlos A. Batista, Tiago M. L. de Veras, Israel F. Araujo, Adenilton J. da Silva</dc:creator>
    </item>
    <item>
      <title>SmartUT: Receive Beamforming for Spectral Coexistence of NGSO Satellite Systems</title>
      <link>https://arxiv.org/abs/2505.07714</link>
      <description>arXiv:2505.07714v2 Announce Type: replace-cross 
Abstract: In this paper, we investigate downlink co-frequency interference (CFI) mitigation in non-geostationary satellites orbits (NGSOs) co-existing systems. Traditional mitigation techniques, such as Zero-forcing (ZF), produce a null towards the direction of arrivals (DOAs) of the interfering signals, but they suffer from high computational complexity due to matrix inversions and required knowledge of the channel state information (CSI). Furthermore, adaptive beamformers, such as sample matrix inversion (SMI)-based minimum variance, provide poor performance when the available snapshots are limited. We propose a Mamba-based beamformer (MambaBF) that leverages an unsupervised deep learning (DL) approach and can be deployed on the user terminal (UT) antenna array, for assisting downlink beamforming and CFI mitigation using only a limited number of available array snapshots as input, and without CSI knowledge. Simulation results demonstrate that MambaBF consistently outperforms conventional beamforming techniques in mitigating interference and maximizing the signal-to-interference-plus-noise ratio (SINR), particularly under challenging conditions characterized by low SINR, limited snapshots, and imperfect CSI.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.07714v2</guid>
      <category>eess.SP</category>
      <category>cs.ET</category>
      <category>cs.LG</category>
      <pubDate>Fri, 10 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <dc:creator>Almoatssimbillah Saifaldawla, Eva Lagunas, Flor Ortiz, Abuzar B. M. Adam, Symeon Chatzinotas</dc:creator>
    </item>
    <item>
      <title>Chisme: Fully Decentralized Differentiated Deep Learning for IoT Intelligence</title>
      <link>https://arxiv.org/abs/2505.09854</link>
      <description>arXiv:2505.09854v2 Announce Type: replace-cross 
Abstract: As end-user device capability increases and demand for intelligent services at the Internet's edge rise, distributed learning has emerged as a key enabling technology. Existing approaches like federated learning (FL) and decentralized FL (DFL) enable distributed learning among clients, while gossip learning (GL) approaches have emerged to address the potential challenges in resource-constrained, connectivity-challenged infrastructure-less environments. However, most distributed learning approaches assume largely homogeneous data distributions and may not consider or exploit the heterogeneity of clients and their underlying data distributions. This paper introduces Chisme, a novel fully decentralized distributed learning algorithm designed to address the challenges of implementing robust intelligence in network edge contexts characterized by heterogeneous data distributions, episodic connectivity, and sparse network infrastructure. Chisme leverages cosine similarity-based data affinity heuristics calculated from received model exchanges to inform how much influence received models have when merging into the local model. By doing so, it facilitates stronger merging influence between clients with more similar model learning progressions, enabling clients to strategically balance between broader collaboration to build more general knowledge and more selective collaboration to build specific knowledge. We evaluate Chisme against contemporary approaches using image recognition and time-series prediction scenarios while considering different network connectivity conditions, representative of real-world distributed intelligent systems. Our experiments demonstrate that Chisme outperforms state-of-the-art edge intelligence approaches in almost every case -- clients using Chisme exhibit faster training convergence, lower final loss after training, and lower performance disparity between clients.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.09854v2</guid>
      <category>cs.LG</category>
      <category>cs.ET</category>
      <category>cs.MA</category>
      <category>cs.SI</category>
      <pubDate>Fri, 10 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Harikrishna Kuttivelil, Katia Obraczka</dc:creator>
    </item>
    <item>
      <title>A Computational Perspective on NeuroAI and Synthetic Biological Intelligence</title>
      <link>https://arxiv.org/abs/2509.23896</link>
      <description>arXiv:2509.23896v2 Announce Type: replace-cross 
Abstract: NeuroAI is an emerging field at the intersection of neuroscience and artificial intelligence, where insights from brain function guide the design of intelligent systems. A central area within this field is synthetic biological intelligence (SBI), which combines the adaptive learning properties of biological neural networks with engineered hardware and software. SBI systems provide a platform for modeling neural computation, developing biohybrid architectures, and enabling new forms of embodied intelligence. In this review, we organize the NeuroAI landscape into three interacting domains: hardware, software, and wetware. We outline computational frameworks that integrate biological and non-biological systems and highlight recent advances in organoid intelligence, neuromorphic computing, and neuro-symbolic learning. These developments collectively point toward a new class of systems that compute through interactions between living neural tissue and digital algorithms.</description>
      <guid isPermaLink="false">oai:arXiv.org:2509.23896v2</guid>
      <category>q-bio.NC</category>
      <category>cs.ET</category>
      <category>cs.NE</category>
      <pubDate>Fri, 10 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Dhruvik Patel, Md Sayed Tanveer, Jesus Gonzalez-Ferrer, Alon Loeffler, Brett J. Kagan, Mohammed A. Mostajo-Radji, Ge Wang</dc:creator>
    </item>
  </channel>
</rss>
