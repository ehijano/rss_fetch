<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>stat.CO updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/stat.CO</link>
    <description>stat.CO updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/stat.CO" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Mon, 13 Jan 2025 05:00:06 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Mon, 13 Jan 2025 00:00:00 -0500</pubDate>
    <skipDays>
      <day>Saturday</day>
      <day>Sunday</day>
    </skipDays>
    <item>
      <title>Generative Modeling: A Review</title>
      <link>https://arxiv.org/abs/2501.05458</link>
      <description>arXiv:2501.05458v1 Announce Type: new 
Abstract: Generative methods (Gen-AI) are reviewed with a particular goal to solving tasks in Machine Learning and Bayesian inference. Generative models require one to simulate a large training dataset and to use deep neural networks to solve a supervised learning problem. To do this, we require high dimensional regression methods and tools for dimensionality reduction (a.k.a feature selection). The main advantage of Gen-AI methods is their ability to be model-free and to use deep neural networks to estimate conditional densities or posterior quantiles of interest. To illustrate generative methods, we analyze the well-known Ebola data-set. Finally, we conclude with directions for future research.</description>
      <guid isPermaLink="false">oai:arXiv.org:2501.05458v1</guid>
      <category>stat.CO</category>
      <category>cs.LG</category>
      <pubDate>Mon, 13 Jan 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/publicdomain/zero/1.0/</dc:rights>
      <dc:creator>Nick Polson, Vadim Sokolov</dc:creator>
    </item>
    <item>
      <title>MCMC for multi-modal distributions</title>
      <link>https://arxiv.org/abs/2501.05908</link>
      <description>arXiv:2501.05908v1 Announce Type: new 
Abstract: We explain the fundamental challenges of sampling from multimodal distributions, particularly for high-dimensional problems. We present the major types of MCMC algorithms that are designed for this purpose, including parallel tempering, mode jumping and Wang-Landau, as well as several state-of-the-art approaches that have recently been proposed. We demonstrate these methods using both synthetic and real-world examples of multimodal distributions with discrete or continuous state spaces.</description>
      <guid isPermaLink="false">oai:arXiv.org:2501.05908v1</guid>
      <category>stat.CO</category>
      <pubDate>Mon, 13 Jan 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Krzysztof {\L}atuszy\'nski, Matthew T. Moores, Timoth\'ee Stumpf-F\'etizon</dc:creator>
    </item>
    <item>
      <title>Bayesian Joint Additive Factor Models for Multiview Learning</title>
      <link>https://arxiv.org/abs/2406.00778</link>
      <description>arXiv:2406.00778v3 Announce Type: replace-cross 
Abstract: It is increasingly common in a wide variety of applied settings to collect data of multiple different types on the same set of samples. Our particular focus in this article is on studying relationships between such multiview features and responses. A motivating application arises in the context of precision medicine where multi-omics data are collected to correlate with clinical outcomes. It is of interest to infer dependence within and across views while combining multimodal information to improve the prediction of outcomes. The signal-to-noise ratio can vary substantially across views, motivating more nuanced statistical tools beyond standard late and early fusion. This challenge comes with the need to preserve interpretability, select features, and obtain accurate uncertainty quantification. We propose a joint additive factor regression model (JAFAR) with a structured additive design, accounting for shared and view-specific components. We ensure identifiability via a novel dependent cumulative shrinkage process (D-CUSP) prior. We provide an efficient implementation via a partially collapsed Gibbs sampler and extend our approach to allow flexible feature and outcome distributions. Prediction of time-to-labor onset from immunome, metabolome, and proteome data illustrates performance gains against state-of-the-art competitors. Our open-source software (R package) is available at https://github.com/niccoloanceschi/jafar.</description>
      <guid isPermaLink="false">oai:arXiv.org:2406.00778v3</guid>
      <category>stat.ML</category>
      <category>cs.AI</category>
      <category>cs.LG</category>
      <category>stat.CO</category>
      <category>stat.ME</category>
      <pubDate>Mon, 13 Jan 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Niccolo Anceschi, Federico Ferrari, David B. Dunson, Himel Mallick</dc:creator>
    </item>
    <item>
      <title>Bayesian inference for the Markov-modulated Poisson process with an outcome process</title>
      <link>https://arxiv.org/abs/2408.15314</link>
      <description>arXiv:2408.15314v2 Announce Type: replace-cross 
Abstract: In medical research, understanding changes in outcome measurements is crucial for inferring shifts in health conditions. However, traditional methods often struggle with large, irregularly longitudinal data and fail to account for the tendency of individuals in poorer health to interact more frequently with the healthcare system. Additionally, clinical data can lack information on terminating events like death. To address these challenges, we start from the continuous-time hidden Markov model which models observed data as outcomes influenced by latent health states. Our extension incorporates a point process to account for the impact of health states on observation timings and includes a "death" state to model unobserved terminating events through a Poisson process, where transition rates depend on the latent health state. This approach captures both the severity of the disease and the timing of healthcare interactions. We present an exact Gibbs sampler procedure that alternates between sampling the latent health state paths and the model parameters. By including the "death" state, we mitigate biases in parameter estimation that would arise from solely modelling "live" health states. Simulation studies demonstrate that the proposed Gibbs sampler performs effectively. We apply our method to Canadian healthcare data, offering valuable insights for healthcare management.</description>
      <guid isPermaLink="false">oai:arXiv.org:2408.15314v2</guid>
      <category>stat.AP</category>
      <category>stat.CO</category>
      <pubDate>Mon, 13 Jan 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Yu Luo, Chris Sherlock</dc:creator>
    </item>
    <item>
      <title>Bayesian Transfer Learning for Artificially Intelligent Geospatial Systems: A Predictive Stacking Approach</title>
      <link>https://arxiv.org/abs/2410.09504</link>
      <description>arXiv:2410.09504v2 Announce Type: replace-cross 
Abstract: Building artificially intelligent geospatial systems require rapid delivery of spatial data analysis at massive scales with minimal human intervention. Depending upon their intended use, data analysis may also entail model assessment and uncertainty quantification. This article devises transfer learning frameworks for deployment in artificially intelligent systems, where a massive data set is split into smaller data sets that stream into the analytical framework to propagate learning and assimilate inference for the entire data set. Specifically, we introduce Bayesian predictive stacking for multivariate spatial data and demonstrate its effectiveness in rapidly analyzing massive data sets. Furthermore, we make inference feasible in a reasonable amount of time, and without excessively demanding hardware settings. We illustrate the effectiveness of this approach in extensive simulation experiments and subsequently analyze massive data sets in climate science on sea surface temperatures and on vegetation index.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.09504v2</guid>
      <category>stat.ME</category>
      <category>stat.CO</category>
      <pubDate>Mon, 13 Jan 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Luca Presicce, Sudipto Banerjee</dc:creator>
    </item>
  </channel>
</rss>
