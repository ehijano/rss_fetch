<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>cs.DL updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/cs.DL</link>
    <description>cs.DL updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/cs.DL" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Wed, 05 Feb 2025 02:49:00 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Tue, 04 Feb 2025 00:00:00 -0500</pubDate>
    <skipDays>
      <day>Saturday</day>
      <day>Sunday</day>
    </skipDays>
    <item>
      <title>Paper Copilot: The Artificial Intelligence and Machine Learning Community Should Adopt a More Transparent and Regulated Peer Review Process</title>
      <link>https://arxiv.org/abs/2502.00874</link>
      <description>arXiv:2502.00874v1 Announce Type: new 
Abstract: The rapid growth of submissions to top-tier Artificial Intelligence (AI) and Machine Learning (ML) conferences has prompted many venues to transition from closed to open review platforms. Some have fully embraced open peer reviews, allowing public visibility throughout the process, while others adopt hybrid approaches, such as releasing reviews only after final decisions or keeping reviews private despite using open peer review systems. In this work, we analyze the strengths and limitations of these models, highlighting the growing community interest in transparent peer review. To support this discussion, we examine insights from Paper Copilot, a website launched two years ago to aggregate and analyze AI / ML conference data while engaging a global audience. The site has attracted over 200,000 early-career researchers, particularly those aged 18-34 from 177 countries, many of whom are actively engaged in the peer review process. Drawing on our findings, this position paper advocates for a more transparent, open, and well-regulated peer review aiming to foster greater community involvement and propel advancements in the field.</description>
      <guid isPermaLink="false">oai:arXiv.org:2502.00874v1</guid>
      <category>cs.DL</category>
      <category>cs.AI</category>
      <category>cs.CV</category>
      <category>cs.CY</category>
      <pubDate>Tue, 04 Feb 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Jing Yang</dc:creator>
    </item>
    <item>
      <title>Research Data in Scientific Publications: A Cross-Field Analysis</title>
      <link>https://arxiv.org/abs/2502.01407</link>
      <description>arXiv:2502.01407v1 Announce Type: new 
Abstract: Data sharing is fundamental to scientific progress, enhancing transparency, reproducibility, and innovation across disciplines. Despite its growing significance, the variability of data-sharing practices across research fields remains insufficiently understood, limiting the development of effective policies and infrastructure. This study investigates the evolving landscape of data-sharing practices, specifically focusing on the intentions behind data release, reuse, and referencing. Leveraging the PubMed open dataset, we developed a model to identify mentions of datasets in the full-text of publications. Our analysis reveals that data release is the most prevalent sharing mode, particularly in fields such as Commerce, Management, and the Creative Arts. In contrast, STEM fields, especially the Biological and Agricultural Sciences, show significantly higher rates of data reuse. However, the humanities and social sciences are slower to adopt these practices. Notably, dataset referencing remains low across most disciplines, suggesting that datasets are not yet fully recognized as research outputs. A temporal analysis highlights an acceleration in data releases after 2012, yet obstacles such as data discoverability and compatibility for reuse persist. Our findings can inform institutional and policy-level efforts to improve data-sharing practices, enhance dataset accessibility, and promote broader adoption of open science principles across research domains.</description>
      <guid isPermaLink="false">oai:arXiv.org:2502.01407v1</guid>
      <category>cs.DL</category>
      <pubDate>Tue, 04 Feb 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Puyu Yang, Giovanni Colavizza</dc:creator>
    </item>
    <item>
      <title>Originality in scientific titles and abstracts can predict citation count</title>
      <link>https://arxiv.org/abs/2502.01417</link>
      <description>arXiv:2502.01417v1 Announce Type: new 
Abstract: In this research-in-progress paper, we apply a computational measure correlating with originality from creativity science: Divergent Semantic Integration (DSI), to a selection of 99,557 scientific abstracts and titles selected from the Web of Science. We observe statistically significant differences in DSI between subject and field of research, and a slight rise in DSI over time. We model the base 10 logarithm of the citation count after 5 years with DSI and find a statistically significant positive correlation in all fields of research with an adjusted $R^2$ of 0.13.</description>
      <guid isPermaLink="false">oai:arXiv.org:2502.01417v1</guid>
      <category>cs.DL</category>
      <category>cs.CL</category>
      <pubDate>Tue, 04 Feb 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Jack H. Culbert, Yoed N. Kenett, Philipp Mayr</dc:creator>
    </item>
    <item>
      <title>Archiving and Replaying Current Web Advertisements: Challenges and Opportunities</title>
      <link>https://arxiv.org/abs/2502.01525</link>
      <description>arXiv:2502.01525v1 Announce Type: new 
Abstract: Although web advertisements represent an inimitable part of digital cultural heritage, serious archiving and replay challenges persist. To explore these challenges, we created a dataset of 279 archived ads. We encountered five problems in archiving and replaying them. For one, prior to August 2023, Internet Archive's Save Page Now service excluded not only well-known ad services' ads, but also URLs with ad related file and directory names. Although after August 2023, Save Page Now still blocked the archiving of ads loaded on a web page, it permitted the archiving of an ad's resources if the user directly archived the URL(s) associated with the ad. Second, Brozzler's incompatibility with Chrome prevented ads from being archived. Third, during crawling and replay sessions, Google's and Amazon's ad scripts generated URLs with different random values. This precluded archived ads' replay. Updating replay systems' fuzzy matching approach should enable the replay of these ads. Fourth, when loading Flashtalking web page ads outside of ad iframes, the ad script requested a non-existent URL. This, prevented the replay of ad resources. But as was the case with Google and Amazon ads, updating replay systems' fuzzy matching approach should enable Flashtalking ads' replay. Finally, successful replay of ads loaded in iframes with the src attribute of "about:blank" depended upon a given browser's service worker implementation. A Chromium bug stopped service workers from accessing resources inside of this type of iframe, which in turn prevented replay. Replacing the "about:blank" value for the iframe's src attribute with a blob URL before an ad was loaded solved this problem. Resolving these replay problems will improve the replay of ads and other dynamically loaded embedded web resources that use random values or "about:blank" iframes.</description>
      <guid isPermaLink="false">oai:arXiv.org:2502.01525v1</guid>
      <category>cs.DL</category>
      <pubDate>Tue, 04 Feb 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <dc:creator>Travis Reid, Alex H. Poole, Hyung Wook Choi, Christopher Rauch, Mat Kelly, Michael L. Nelson, Michele C. Weigle</dc:creator>
    </item>
    <item>
      <title>Digital twins in tourism: a systematic literature review</title>
      <link>https://arxiv.org/abs/2502.00002</link>
      <description>arXiv:2502.00002v1 Announce Type: cross 
Abstract: Purpose: This systematic literature review (SLR) characterizes the current state of the art on digital twinning (DT) technology in tourism-related applications. We aim to evaluate the types of DTs described in the literature, identifying their purposes, the areas of tourism where they have been proposed, their main components, and possible future directions based on current work.
  Design/methodology/approach: We conducted this SLR with bibliometric analysis based on an existing, validated methodology. Thirty-four peer-reviewed studies from three major scientific databases were selected for review. They were categorized using a taxonomy that included tourism type, purpose, spatial scale, data sources, data linkage, visualization, and application.
  Findings: The topic is at an early, evolving stage, as the oldest study found dates back to 2021. Most reviewed studies deal with cultural tourism, focusing on digitising cultural heritage. Destination management is the primary purpose of these DTs, with mainly site-level spatial scales. In many studies, the physical-digital data linkage is unilateral, lacking twin synchronization. In most DTs considered bilateral, the linkage is indirect. There are more applied than theoretical studies, suggesting progress in applying DTs in the field. Finally, there is an extensive research gap regarding DT technology in tourism, which is worth filling.
  Originality/Value: This paper presents a novel SLR with a bibliometric analysis of DTs' applied and theoretical application in tourism. Each reviewed publication is assessed and characterized, identifying the current state of the topic, possible research gaps, and future directions.</description>
      <guid isPermaLink="false">oai:arXiv.org:2502.00002v1</guid>
      <category>cs.CY</category>
      <category>cs.DL</category>
      <pubDate>Tue, 04 Feb 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Duarte Sampaio de Almeida, Fernando Brito e Abreu, In\^es Boavida-Portugal</dc:creator>
    </item>
    <item>
      <title>Dissecting Submission Limit in Desk-Rejections: A Mathematical Analysis of Fairness in AI Conference Policies</title>
      <link>https://arxiv.org/abs/2502.00690</link>
      <description>arXiv:2502.00690v1 Announce Type: cross 
Abstract: As AI research surges in both impact and volume, conferences have imposed submission limits to maintain paper quality and alleviate organizational pressure. In this work, we examine the fairness of desk-rejection systems under submission limits and reveal that existing practices can result in substantial inequities. Specifically, we formally define the paper submission limit problem and identify a critical dilemma: when the number of authors exceeds three, it becomes impossible to reject papers solely based on excessive submissions without negatively impacting innocent authors. Thus, this issue may unfairly affect early-career researchers, as their submissions may be penalized due to co-authors with significantly higher submission counts, while senior researchers with numerous papers face minimal consequences. To address this, we propose an optimization-based fairness-aware desk-rejection mechanism and formally define two fairness metrics: individual fairness and group fairness. We prove that optimizing individual fairness is NP-hard, whereas group fairness can be efficiently optimized via linear programming. Through case studies, we demonstrate that our proposed system ensures greater equity than existing methods, including those used in CVPR 2025, offering a more socially just approach to managing excessive submissions in AI conferences.</description>
      <guid isPermaLink="false">oai:arXiv.org:2502.00690v1</guid>
      <category>cs.LG</category>
      <category>cs.AI</category>
      <category>cs.CY</category>
      <category>cs.DL</category>
      <pubDate>Tue, 04 Feb 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Yuefan Cao, Xiaoyu Li, Yingyu Liang, Zhizhou Sha, Zhenmei Shi, Zhao Song, Jiahao Zhang</dc:creator>
    </item>
    <item>
      <title>Toward Living Narrative Reviews: An Empirical Study of the Processes and Challenges in Updating Survey Articles in Computing Research</title>
      <link>https://arxiv.org/abs/2502.00881</link>
      <description>arXiv:2502.00881v1 Announce Type: cross 
Abstract: Surveying prior literature to establish a foundation for new knowledge is essential for scholarly progress. However, survey articles are resource-intensive and challenging to create, and can quickly become outdated as new research is published, risking information staleness and inaccuracy. Keeping survey articles current with the latest evidence is therefore desirable, though there is a limited understanding of why, when, and how these surveys should be updated. Toward this end, through a series of in-depth retrospective interviews with 11 researchers, we present an empirical examination of the work practices in authoring and updating survey articles in computing research. We find that while computing researchers acknowledge the value in maintaining an updated survey, continuous updating remains unmanageable and misaligned with academic incentives. Our findings suggest key leverage points within current workflows that present opportunities for enabling technologies to facilitate more efficient and effective updates.</description>
      <guid isPermaLink="false">oai:arXiv.org:2502.00881v1</guid>
      <category>cs.HC</category>
      <category>cs.DL</category>
      <pubDate>Tue, 04 Feb 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Raymond Fok, Alexa Siu, Daniel S. Weld</dc:creator>
    </item>
    <item>
      <title>Meursault as a Data Point</title>
      <link>https://arxiv.org/abs/2502.01364</link>
      <description>arXiv:2502.01364v1 Announce Type: cross 
Abstract: In an era dominated by datafication, the reduction of human experiences to quantifiable metrics raises profound philosophical and ethical questions. This paper explores these issues through the lens of Meursault, the protagonist of Albert Camus' The Stranger, whose emotionally detached existence epitomizes the existential concept of absurdity. Using natural language processing (NLP) techniques including emotion detection (BERT), sentiment analysis (VADER), and named entity recognition (spaCy)-this study quantifies key events and behaviors in Meursault's life. Our analysis reveals the inherent limitations of applying algorithmic models to complex human experiences, particularly those rooted in existential alienation and moral ambiguity. By examining how modern AI tools misinterpret Meursault's actions and emotions, this research underscores the broader ethical dilemmas of reducing nuanced human narratives to data points, challenging the foundational assumptions of our data-driven society. The findings presented in this paper serve as a critique of the increasing reliance on data-driven narratives and advocate for incorporating humanistic values in artificial intelligence.</description>
      <guid isPermaLink="false">oai:arXiv.org:2502.01364v1</guid>
      <category>cs.CY</category>
      <category>cs.AI</category>
      <category>cs.CL</category>
      <category>cs.DL</category>
      <category>cs.LG</category>
      <pubDate>Tue, 04 Feb 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Abhinav Pratap, Amit Pathak</dc:creator>
    </item>
    <item>
      <title>Regional profile of questionable publishing</title>
      <link>https://arxiv.org/abs/2312.07844</link>
      <description>arXiv:2312.07844v2 Announce Type: replace 
Abstract: Countries and authors in the academic periphery occasionally have been criticized for contributing to the expansion of questionable publishing because they share a major fraction of papers in questionable journals. On the other side, topics preferred by mainstream journals sometimes necessitate large-scale investigation, which is impossible for developing countries. Thus, local journals, commonly low-impacted, are essential to sustain the regional academia for such countries. In this study, we perform an in-depth analysis of the distribution of questionable publications and journals with their interplay with countries quantifying the influence of questionable publications regarding academia's inequality. We find that low-impact journals play a vital role in the regional academic environment, whereas questionable journals with equivalent impact publish papers from all over the world, both geographically and academically. The business model of questionable journals differs from that of regional journals, and may thus be detrimental to the broader academic community.</description>
      <guid isPermaLink="false">oai:arXiv.org:2312.07844v2</guid>
      <category>cs.DL</category>
      <category>physics.soc-ph</category>
      <pubDate>Tue, 04 Feb 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Taekho You, Jinseo Park, June Young Lee, Jinhyuk Yun</dc:creator>
    </item>
    <item>
      <title>Transforming Role Classification in Scientific Teams Using LLMs and Advanced Predictive Analytics</title>
      <link>https://arxiv.org/abs/2501.07267</link>
      <description>arXiv:2501.07267v2 Announce Type: replace 
Abstract: Scientific team dynamics are critical in determining the nature and impact of research outputs. However, existing methods for classifying author roles based on self-reports and clustering lack comprehensive contextual analysis of contributions. Thus, we present a transformative approach to classifying author roles in scientific teams using advanced large language models (LLMs), which offers a more refined analysis compared to traditional clustering methods. Specifically, we seek to complement and enhance these traditional methods by utilizing open source and proprietary LLMs, such as GPT-4, Llama3 70B, Llama2 70B, and Mistral 7x8B, for role classification. Utilizing few-shot prompting, we categorize author roles and demonstrate that GPT-4 outperforms other models across multiple categories, surpassing traditional approaches such as XGBoost and BERT. Our methodology also includes building a predictive deep learning model using 10 features. By training this model on a dataset derived from the OpenAlex database, which provides detailed metadata on academic publications -- such as author-publication history, author affiliation, research topics, and citation counts -- we achieve an F1 score of 0.76, demonstrating robust classification of author roles.</description>
      <guid isPermaLink="false">oai:arXiv.org:2501.07267v2</guid>
      <category>cs.DL</category>
      <category>cs.SI</category>
      <pubDate>Tue, 04 Feb 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <dc:creator>Wonduk Seo, Yi Bu</dc:creator>
    </item>
    <item>
      <title>DeepScribe: Localization and Classification of Elamite Cuneiform Signs Via Deep Learning</title>
      <link>https://arxiv.org/abs/2306.01268</link>
      <description>arXiv:2306.01268v2 Announce Type: replace-cross 
Abstract: Twenty-five hundred years ago, the paperwork of the Achaemenid Empire was recorded on clay tablets. In 1933, archaeologists from the University of Chicago's Oriental Institute (OI) found tens of thousands of these tablets and fragments during the excavation of Persepolis. Many of these tablets have been painstakingly photographed and annotated by expert cuneiformists, and now provide a rich dataset consisting of over 5,000 annotated tablet images and 100,000 cuneiform sign bounding boxes. We leverage this dataset to develop DeepScribe, a modular computer vision pipeline capable of localizing cuneiform signs and providing suggestions for the identity of each sign. We investigate the difficulty of learning subtasks relevant to cuneiform tablet transcription on ground-truth data, finding that a RetinaNet object detector can achieve a localization mAP of 0.78 and a ResNet classifier can achieve a top-5 sign classification accuracy of 0.89. The end-to-end pipeline achieves a top-5 classification accuracy of 0.80. As part of the classification module, DeepScribe groups cuneiform signs into morphological clusters. We consider how this automatic clustering approach differs from the organization of standard, printed sign lists and what we may learn from it. These components, trained individually, are sufficient to produce a system that can analyze photos of cuneiform tablets from the Achaemenid period and provide useful transliteration suggestions to researchers. We evaluate the model's end-to-end performance on locating and classifying signs, providing a roadmap to a linguistically-aware transliteration system, then consider the model's potential utility when applied to other periods of cuneiform writing.</description>
      <guid isPermaLink="false">oai:arXiv.org:2306.01268v2</guid>
      <category>cs.CV</category>
      <category>cs.DL</category>
      <category>cs.IR</category>
      <pubDate>Tue, 04 Feb 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Edward C. Williams, Grace Su, Sandra R. Schloen, Miller C. Prosser, Susanne Paulus, Sanjay Krishnan</dc:creator>
    </item>
  </channel>
</rss>
