<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>q-bio.BM updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/q-bio.BM</link>
    <description>q-bio.BM updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/q-bio.BM" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Fri, 28 Jun 2024 04:01:33 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Fri, 28 Jun 2024 00:00:00 -0400</pubDate>
    <skipDays>
      <day>Saturday</day>
      <day>Sunday</day>
    </skipDays>
    <item>
      <title>DRAK: Unlocking Molecular Insights with Domain-Specific Retrieval-Augmented Knowledge in LLMs</title>
      <link>https://arxiv.org/abs/2406.18535</link>
      <description>arXiv:2406.18535v1 Announce Type: new 
Abstract: Large Language Models (LLMs) encounter challenges with the unique syntax of specific domains, such as biomolecules. Existing fine-tuning or modality alignment techniques struggle to bridge the domain knowledge gap and understand complex molecular data, limiting LLMs' progress in specialized fields. To overcome these limitations, we propose an expandable and adaptable non-parametric knowledge injection framework named Domain-specific Retrieval-Augmented Knowledge (DRAK), aimed at enhancing reasoning capabilities in specific domains. Utilizing knowledge-aware prompts and gold label-induced reasoning, DRAK has developed profound expertise in the molecular domain and the capability to handle a broad spectrum of analysis tasks. We evaluated two distinct forms of DRAK variants, proving that DRAK exceeds previous benchmarks on six molecular tasks within the Mol-Instructions dataset. Extensive experiments have underscored DRAK's formidable performance and its potential to unlock molecular insights, offering a unified paradigm for LLMs to tackle knowledge-intensive tasks in specific domains. Our code will be available soon.</description>
      <guid isPermaLink="false">oai:arXiv.org:2406.18535v1</guid>
      <category>q-bio.BM</category>
      <category>cs.AI</category>
      <category>cs.IR</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Jinzhe Liu, Xiangsheng Huang, Zhuo Chen, Yin Fang</dc:creator>
    </item>
    <item>
      <title>LICO: Large Language Models for In-Context Molecular Optimization</title>
      <link>https://arxiv.org/abs/2406.18851</link>
      <description>arXiv:2406.18851v1 Announce Type: cross 
Abstract: Optimizing black-box functions is a fundamental problem in science and engineering. To solve this problem, many approaches learn a surrogate function that estimates the underlying objective from limited historical evaluations. Large Language Models (LLMs), with their strong pattern-matching capabilities via pretraining on vast amounts of data, stand out as a potential candidate for surrogate modeling. However, directly prompting a pretrained language model to produce predictions is not feasible in many scientific domains due to the scarcity of domain-specific data in the pretraining corpora and the challenges of articulating complex problems in natural language. In this work, we introduce LICO, a general-purpose model that extends arbitrary base LLMs for black-box optimization, with a particular application to the molecular domain. To achieve this, we equip the language model with a separate embedding layer and prediction layer, and train the model to perform in-context predictions on a diverse set of functions defined over the domain. Once trained, LICO can generalize to unseen molecule properties simply via in-context prompting. LICO achieves state-of-the-art performance on PMO, a challenging molecular optimization benchmark comprising over 20 objective functions.</description>
      <guid isPermaLink="false">oai:arXiv.org:2406.18851v1</guid>
      <category>cs.LG</category>
      <category>cs.AI</category>
      <category>physics.chem-ph</category>
      <category>q-bio.BM</category>
      <category>q-bio.QM</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Tung Nguyen, Aditya Grover</dc:creator>
    </item>
    <item>
      <title>Flipping Out: Role of Arginine in Hydrophobic Interactions and Biological Formulation Design</title>
      <link>https://arxiv.org/abs/2403.11305</link>
      <description>arXiv:2403.11305v3 Announce Type: replace-cross 
Abstract: Arginine has been a mainstay in biological formulation development for decades. To date, the way arginine modulates protein stability has been widely studied and debated. Here, we employed a hydrophobic polymer to decouple hydrophobic effects from other interactions relevant to protein folding. While existing hypotheses for the effects of arginine can generally be categorized as either direct or indirect, our results indicate that direct and indirect mechanisms of arginine co-exist and oppose each other. At low concentrations, arginine was observed to stabilize hydrophobic polymer collapse via a sidechain-dominated direct mechanism, while at high concentrations, arginine stabilized polymer collapse via a backbone-dominated indirect mechanism. When adding partial charges to sites on the polymer, arginine destabilized polymer collapse. Further, we found arginine-induced destabilization of a model virus similar to direct-mechanism destabilization of the charged polymer, and concentration-dependent stabilization of a model protein similar to the indirect mechanism of hydrophobic polymer stabilization. These findings highlight the modular nature of the widely used additive arginine, with relevance in the design of stable biological formulations.</description>
      <guid isPermaLink="false">oai:arXiv.org:2403.11305v3</guid>
      <category>cond-mat.soft</category>
      <category>q-bio.BM</category>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Jonathan W. P. Zajac, Praveen Muralikrishnan, Idris Tohidian, Xianci Zeng, Caryn L. Heldt, Sarah L. Perry, Sapna Sarupria</dc:creator>
    </item>
  </channel>
</rss>
