<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>econ.EM updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/econ.EM</link>
    <description>econ.EM updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/econ.EM" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Tue, 04 Nov 2025 20:34:26 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Tue, 04 Nov 2025 00:00:00 -0500</pubDate>
    <skipDays>
      <day>Saturday</day>
      <day>Sunday</day>
    </skipDays>
    <item>
      <title>Residual Balancing for Non-Linear Outcome Models in High Dimensions</title>
      <link>https://arxiv.org/abs/2511.00324</link>
      <description>arXiv:2511.00324v1 Announce Type: new 
Abstract: We extend the approximate residual balancing (ARB) framework to nonlinear models, answering an open problem posed by Athey et al. (2018). Our approach addresses the challenge of estimating average treatment effects in high-dimensional settings where the outcome follows a generalized linear model. We derive a new bias decomposition for nonlinear models that reveals the need for a second-order correction to account for the curvature of the link function. Based on this insight, we construct balancing weights through an optimization problem that controls for both first and second-order sources of bias. We provide theoretical guarantees for our estimator, establishing its $\sqrt{n}$-consistency and asymptotic normality under standard high-dimensional assumptions.</description>
      <guid isPermaLink="false">oai:arXiv.org:2511.00324v1</guid>
      <category>econ.EM</category>
      <category>math.ST</category>
      <category>stat.TH</category>
      <pubDate>Tue, 04 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Isaac Meza</dc:creator>
    </item>
    <item>
      <title>Concentration Inequalities for Suprema of Empirical Processes with Dependent Data via Generic Chaining with Applications to Statistical Learning</title>
      <link>https://arxiv.org/abs/2511.00597</link>
      <description>arXiv:2511.00597v1 Announce Type: new 
Abstract: This paper develops a general concentration inequality for the suprema of empirical processes with dependent data. The concentration inequality is obtained by combining generic chaining with a coupling-based strategy. Our framework accommodates high-dimensional and heavy-tailed (sub-Weibull) data. We demonstrate the usefulness of our result by deriving non-asymptotic predictive performance guarantees for empirical risk minimization in regression problems with dependent data. In particular, we establish an oracle inequality for a broad class of nonlinear regression models and, as a special case, a single-layer neural network model. Our results show that empirical risk minimzaton with dependent data attains a prediction accuracy comparable to that in the i.i.d. setting for a wide range of nonlinear regression models.</description>
      <guid isPermaLink="false">oai:arXiv.org:2511.00597v1</guid>
      <category>econ.EM</category>
      <pubDate>Tue, 04 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Chiara Amorino, Christian Brownlees, Ankita Ghosh</dc:creator>
    </item>
    <item>
      <title>Improving control over unobservables with network data</title>
      <link>https://arxiv.org/abs/2511.00612</link>
      <description>arXiv:2511.00612v1 Announce Type: new 
Abstract: This paper develops a method to conduct causal inference in the presence of unobserved confounders by leveraging networks with homophily, a frequently observed tendency to form edges with similar nodes. I introduce a concept of asymptotic homophily, according to which individuals' selectivity scales with the size of the potential connection pool. It contributes to the network formation literature with a model that can accommodate common empirical features such as homophily, degree heterogeneity, sparsity, and clustering, and provides a framework to obtain consistent estimators of treatment effects that are robust to selection on unobservables. I also consider an alternative setting that accommodates dense networks and show how selecting linked individuals whose observed characteristics made such a connection less likely delivers an estimator with similar properties. In an application, I recover an estimate of the effect of parental involvement on students' test scores that is greater than that of OLS, arguably due to the estimator's ability to account for unobserved ability.</description>
      <guid isPermaLink="false">oai:arXiv.org:2511.00612v1</guid>
      <category>econ.EM</category>
      <pubDate>Tue, 04 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Vincent Starck</dc:creator>
    </item>
    <item>
      <title>Cross-Validated Causal Inference: a Modern Method to Combine Experimental and Observational Data</title>
      <link>https://arxiv.org/abs/2511.00727</link>
      <description>arXiv:2511.00727v1 Announce Type: new 
Abstract: We develop new methods to integrate experimental and observational data in causal inference. While randomized controlled trials offer strong internal validity, they are often costly and therefore limited in sample size. Observational data, though cheaper and often with larger sample sizes, are prone to biases due to unmeasured confounders. To harness their complementary strengths, we propose a systematic framework that formulates causal estimation as an empirical risk minimization (ERM) problem. A full model containing the causal parameter is obtained by minimizing a weighted combination of experimental and observational losses--capturing the causal parameter's validity and the full model's fit, respectively. The weight is chosen through cross-validation on the causal parameter across experimental folds. Our experiments on real and synthetic data show the efficacy and reliability of our method. We also provide theoretical non-asymptotic error bounds.</description>
      <guid isPermaLink="false">oai:arXiv.org:2511.00727v1</guid>
      <category>econ.EM</category>
      <category>stat.ME</category>
      <category>stat.ML</category>
      <pubDate>Tue, 04 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Xuelin Yang, Licong Lin, Susan Athey, Michael I. Jordan, Guido W. Imbens</dc:creator>
    </item>
    <item>
      <title>High-Dimensional Spatial Arbitrage Pricing Theory with Heterogeneous Interactions</title>
      <link>https://arxiv.org/abs/2511.01271</link>
      <description>arXiv:2511.01271v1 Announce Type: new 
Abstract: This paper investigates estimation and inference of a Spatial Arbitrage Pricing Theory (SAPT) model that integrates spatial interactions with multi-factor analysis, accommodating both observable and latent factors. Building on the classical mean-variance analysis, we introduce a class of Spatial Capital Asset Pricing Models (SCAPM) that account for spatial effects in high-dimensional assets, where we define {\it spatial rho} as a counterpart to market beta in CAPM. We then extend SCAPM to a general SAPT framework under a {\it complete} market setting by incorporating multiple factors. For SAPT with observable factors, we propose a generalized shrinkage Yule-Walker (SYW) estimation method that integrates ridge regression to estimate spatial and factor coefficients. When factors are latent, we first apply an autocovariance-based eigenanalysis to extract factors, then employ the SYW method using the estimated factors. We establish asymptotic properties for these estimators under high-dimensional settings where both the dimension and sample size diverge. Finally, we use simulated and real data examples to demonstrate the efficacy and usefulness of the proposed model and method.</description>
      <guid isPermaLink="false">oai:arXiv.org:2511.01271v1</guid>
      <category>econ.EM</category>
      <category>q-fin.PR</category>
      <category>q-fin.ST</category>
      <pubDate>Tue, 04 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Zhaoxing Gao, Sihan Tu, Ruey S. Tsay</dc:creator>
    </item>
    <item>
      <title>Making Interpretable Discoveries from Unstructured Data: A High-Dimensional Multiple Hypothesis Testing Approach</title>
      <link>https://arxiv.org/abs/2511.01680</link>
      <description>arXiv:2511.01680v1 Announce Type: new 
Abstract: Social scientists are increasingly turning to unstructured datasets to unlock new empirical insights, e.g., estimating causal effects on text outcomes, measuring beliefs from open-ended survey responses. In such settings, unsupervised analysis is often of interest, in that the researcher does not want to pre-specify the objects of measurement or otherwise artificially delimit the space of measurable concepts; they are interested in discovery. This paper proposes a general and flexible framework for pursuing discovery from unstructured data in a statistically principled way. The framework leverages recent methods from the literature on machine learning interpretability to map unstructured data points to high-dimensional, sparse, and interpretable dictionaries of concepts; computes (test) statistics of these dictionary entries; and then performs selective inference on them using newly developed statistical procedures for high-dimensional exceedance control of the $k$-FWER under arbitrary dependence. The proposed framework has few researcher degrees of freedom, is fully replicable, and is cheap to implement -- both in terms of financial cost and researcher time. Applications to recent descriptive and causal analyses of unstructured data in empirical economics are explored. An open source Jupyter notebook is provided for researchers to implement the framework in their own projects.</description>
      <guid isPermaLink="false">oai:arXiv.org:2511.01680v1</guid>
      <category>econ.EM</category>
      <category>cs.LG</category>
      <pubDate>Tue, 04 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Jacob Carlson</dc:creator>
    </item>
    <item>
      <title>On the estimation of leverage effect and volatility of volatility in the presence of jumps</title>
      <link>https://arxiv.org/abs/2511.00944</link>
      <description>arXiv:2511.00944v1 Announce Type: cross 
Abstract: We study the estimation of leverage effect and volatility of volatility by using high-frequency data with the presence of jumps. We first construct spot volatility estimator by using the empirical characteristic function of the high-frequency increments to deal with the effect of jumps, based on which the estimators of leverage effect and volatility of volatility are proposed. Compared with existing estimators, our method is valid under more general jumps, making it a better alternative for empirical applications. Under some mild conditions, the asymptotic normality of the estimators is established and consistent estimators of the limiting variances are proposed based on the estimation of volatility functionals. We conduct extensive simulation study to verify the theoretical results. The results demonstrate that our estimators have relative better performance than the existing ones, especially when the jump is of infinite variation. Besides, we apply our estimators to a real high-frequency dataset, which reveals nonzero leverage effect and volatility of volatility in the market.</description>
      <guid isPermaLink="false">oai:arXiv.org:2511.00944v1</guid>
      <category>stat.ME</category>
      <category>econ.EM</category>
      <pubDate>Tue, 04 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/publicdomain/zero/1.0/</dc:rights>
      <dc:creator>Qiang Liu, Zhi Liu, Wang Zhou</dc:creator>
    </item>
    <item>
      <title>A Distance Covariance-based Estimator</title>
      <link>https://arxiv.org/abs/2102.07008</link>
      <description>arXiv:2102.07008v4 Announce Type: replace 
Abstract: This paper proposes an estimator that relaxes the conventional relevance condition in instrumental variable (IV) analyses. The method allows endogenous covariates to be weakly correlated, uncorrelated, or even mean-independent -- though not independent -- of the instruments, enabling the use of the maximal set of relevant instruments in a given application. Identification is attainable without exclusion restrictions and without finite-moment assumptions on the disturbance term. Under either of two non-nested exogeneity conditions, combined with mild regularity conditions, the parameter of interest is identified. The estimator is shown to be consistent and asymptotically normal, and the relaxed relevance condition required for identification is testable.</description>
      <guid isPermaLink="false">oai:arXiv.org:2102.07008v4</guid>
      <category>econ.EM</category>
      <pubDate>Tue, 04 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Emmanuel Selorm Tsyawo, Abdul-Nasah Soale</dc:creator>
    </item>
    <item>
      <title>Policy Choice in Time Series by Empirical Welfare Maximization</title>
      <link>https://arxiv.org/abs/2205.03970</link>
      <description>arXiv:2205.03970v5 Announce Type: replace 
Abstract: This paper develops a novel method for policy choice in a dynamic setting where the available data is a multivariate time series. Overcoming challenges unique to time-series setting such as time-varying environments, history-dependent welfare, dynamic causal effects, and statistical dependence, we propose Time-series Empirical Welfare Maximization (T-EWM) methods. We characterize conditions for T-EWM to consistently learn optimal policies conditional or unconditinal on the time-series history, and derive nonasymptotic upper bounds for the welfare regrets. We illustrate a use of T-EWM for optimal restriction rules against Covid-19.</description>
      <guid isPermaLink="false">oai:arXiv.org:2205.03970v5</guid>
      <category>econ.EM</category>
      <pubDate>Tue, 04 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Toru Kitagawa, Weining Wang, Mengshan Xu</dc:creator>
    </item>
    <item>
      <title>GCov-Based Portmanteau Test</title>
      <link>https://arxiv.org/abs/2312.05373</link>
      <description>arXiv:2312.05373v3 Announce Type: replace 
Abstract: We study nonlinear serial dependence tests for non-Gaussian time series and residuals of dynamic models based on portmanteau statistics involving nonlinear autocovariances. A new test with an asymptotic $\chi^2$ distribution is introduced for testing nonlinear serial dependence (NLSD) in time series. This test is inspired by the Generalized Covariance (GCov) residual-based specification test, recently proposed as a diagnostic tool for semi-parametric dynamic models with i.i.d. non-Gaussian errors. It has a $\chi^2$ distribution when the model is correctly specified and estimated by the GCov estimator. We derive new asymptotic results under local alternatives for testing hypotheses on the parameters of a semi-parametric model. We extend it by introducing a GCov bootstrap test for residual diagnostics,\color{black} which is also available for models estimated by a different method, such as the maximum likelihood estimator under a parametric assumption on the error distribution. \color{black} A simulation study shows that the tests perform well in applications to mixed causal-noncausal autoregressive models. The GCov specification test is used to assess the fit of a mixed causal-noncausal model of aluminum prices with locally explosive patterns, i.e. bubbles and spikes between 2005 and 2024.</description>
      <guid isPermaLink="false">oai:arXiv.org:2312.05373v3</guid>
      <category>econ.EM</category>
      <pubDate>Tue, 04 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Joann Jasiak, Aryan Manafi Neyazi</dc:creator>
    </item>
    <item>
      <title>Type 2 Tobit Sample Selection Models with Bayesian Additive Regression Trees</title>
      <link>https://arxiv.org/abs/2502.03600</link>
      <description>arXiv:2502.03600v2 Announce Type: replace 
Abstract: This paper introduces Type 2 Tobit Bayesian Additive Regression Trees (TOBART-2). BART can produce accurate individual-specific treatment effect estimates. However, in practice estimates are often biased by sample selection. We extend the Type 2 Tobit sample selection model to account for nonlinearities and model uncertainty by including sums of trees in both the selection and outcome equations. A Dirichlet Process Mixture distribution for the error terms allows for departure from the assumption of bivariate normally distributed errors. Soft trees and a Dirichlet prior on splitting probabilities improve modeling of smooth and sparse data generating processes. We include a simulation study and an application to the RAND Health Insurance Experiment dataset.</description>
      <guid isPermaLink="false">oai:arXiv.org:2502.03600v2</guid>
      <category>econ.EM</category>
      <category>stat.ML</category>
      <pubDate>Tue, 04 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Eoghan O'Neill</dc:creator>
    </item>
  </channel>
</rss>
