<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>cs.MS updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/cs.MS</link>
    <description>cs.MS updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/cs.MS" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Tue, 25 Feb 2025 05:00:13 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Tue, 25 Feb 2025 00:00:00 -0500</pubDate>
    <skipDays>
      <day>Sunday</day>
      <day>Saturday</day>
    </skipDays>
    <item>
      <title>Annotation-guided AoS-to-SoA conversions and GPU offloading with data views in C++</title>
      <link>https://arxiv.org/abs/2502.16517</link>
      <description>arXiv:2502.16517v1 Announce Type: new 
Abstract: The C++ programming language provides classes and structs as fundamental modeling entities. Consequently, C++ code tends to favour array-of-structs (AoS) for encoding data sequences, even though structure-of-arrays (SoA) yields better performance for some calculations. We propose a C++ language extension based on attributes that allows developers to guide the compiler in selecting memory arrangements, i.e.~to select the optimal choice between AoS and SoA dynamically depending on both the execution context and algorithm step. The compiler can then automatically convert data into the preferred format prior to the calculations and convert results back afterward. The compiler handles all the complexity of determining which data to convert and how to manage data transformations. Our implementation realises the compiler-extension for the new annotations in Clang and demonstrates their effectiveness through a smoothed particle hydrodynamics (SPH) code, which we evaluate on an Intel CPU, an ARM CPU, and a Grace-Hopper GPU. While the separation of concerns between data structure and operators is elegant and provides performance improvements, the new annotations do not eliminate the need for performance engineering. Instead, they challenge conventional performance wisdom and necessitate rethinking approaches how to write efficient implementations.</description>
      <guid isPermaLink="false">oai:arXiv.org:2502.16517v1</guid>
      <category>cs.MS</category>
      <category>cs.PF</category>
      <category>cs.PL</category>
      <pubDate>Tue, 25 Feb 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Pawel K. Radtke, Tobias Weinzierl</dc:creator>
    </item>
    <item>
      <title>On the computation of the cumulative distribution function of the Normal Inverse Gaussian distribution</title>
      <link>https://arxiv.org/abs/2502.16015</link>
      <description>arXiv:2502.16015v1 Announce Type: cross 
Abstract: In this paper, we obtain various series and asymptotic expansions involving the modified Bessel function of the second kind for the normal inverse Gaussian cumulative distribution function. The new expansions accelerate computations, complementing the numerical integration methods implemented in statistical software packages. We also provide a detailed description of the algorithm and its corresponding implementation in C++. The performance and accuracy of the algorithm are extensively tested and benchmarked with open-source implementations, offering superior accuracy and speed-ups of a factor from 5 to 60.</description>
      <guid isPermaLink="false">oai:arXiv.org:2502.16015v1</guid>
      <category>math.NA</category>
      <category>cs.MS</category>
      <category>cs.NA</category>
      <category>stat.CO</category>
      <pubDate>Tue, 25 Feb 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Guillermo Navas-Palencia</dc:creator>
    </item>
    <item>
      <title>Giga-scale Kernel Matrix Vector Multiplication on GPU</title>
      <link>https://arxiv.org/abs/2202.01085</link>
      <description>arXiv:2202.01085v4 Announce Type: replace-cross 
Abstract: Kernel matrix-vector multiplication (KMVM) is a foundational operation in machine learning and scientific computing. However, as KMVM tends to scale quadratically in both memory and time, applications are often limited by these computational constraints. In this paper, we propose a novel approximation procedure coined \textit{Faster-Fast and Free Memory Method} ($\fthreem$) to address these scaling issues of KMVM for tall~($10^8\sim 10^9$) and skinny~($D\leq7$) data. Extensive experiments demonstrate that $\fthreem$ has empirical \emph{linear time and memory} complexity with a relative error of order $10^{-3}$ and can compute a full KMVM for a billion points \emph{in under a minute} on a high-end GPU, leading to a significant speed-up in comparison to existing CPU methods. We demonstrate the utility of our procedure by applying it as a drop-in for the state-of-the-art GPU-based linear solver FALKON, \emph{improving speed 1.5-5.5 times} at the cost of $&lt;1\%$ drop in accuracy. We further demonstrate competitive results on \emph{Gaussian Process regression} coupled with significant speedups on a variety of real-world datasets.</description>
      <guid isPermaLink="false">oai:arXiv.org:2202.01085v4</guid>
      <category>math.NA</category>
      <category>cs.LG</category>
      <category>cs.MS</category>
      <category>cs.NA</category>
      <category>stat.CO</category>
      <pubDate>Tue, 25 Feb 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Robert Hu, Siu Lun Chau, Dino Sejdinovic, Joan Alexis Glaun\`es</dc:creator>
    </item>
  </channel>
</rss>
