<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>math.NA updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/math.NA</link>
    <description>math.NA updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/math.NA" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Fri, 10 Jan 2025 02:33:22 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Thu, 09 Jan 2025 00:00:00 -0500</pubDate>
    <skipDays>
      <day>Saturday</day>
      <day>Sunday</day>
    </skipDays>
    <item>
      <title>Adaptive Algebraic Reuse of Reordering in Cholesky Factorization with Dynamic Sparsity Pattern</title>
      <link>https://arxiv.org/abs/2501.04011</link>
      <description>arXiv:2501.04011v1 Announce Type: new 
Abstract: Cholesky linear solvers are a critical bottleneck in challenging applications within computer graphics and scientific computing. These applications include but are not limited to elastodynamic barrier methods such as Incremental Potential Contact (IPC), and geometric operations such as remeshing and morphology. In these contexts, the sparsity patterns of the linear systems frequently change across successive calls to the Cholesky solver, necessitating repeated symbolic analyses that dominate the overall solver runtime.
  To address this bottleneck, we evaluate our method on over 150,000 linear systems generated from diverse nonlinear problems with dynamic sparsity changes in Incremental Potential Contact (IPC) and patch remeshing on a wide range of triangular meshes of various sizes. Our analysis using three leading sparse Cholesky libraries, Intel MKL Pardiso, SuiteSparse CHOLMOD, and Apple Accelerate, reveals that the primary performance constraint lies in the symbolic re-ordering phase of the solver. Recognizing this, we introduce Parth, an innovative re-ordering method designed to update ordering vectors only where local connectivity changes occur adaptively. Parth employs a novel hierarchical graph decomposition algorithm to break down the dual graph of the input matrix into fine-grained subgraphs, facilitating the selective reuse of fill-reducing orderings when sparsity patterns exhibit temporal coherence.
  Our extensive evaluation demonstrates that Parth achieves up to a 255x and 13x speedup in fill-reducing ordering for our IPC and remeshing benchmark and a 6.85x and 10.7x acceleration in symbolic analysis. These enhancements translate to up to 2.95x and 5.89x reduction in overall solver runtime. Additionally, Parth's integration requires only three lines of code, resulting in significant computational savings without the requirement of changes to the computational stack.</description>
      <guid isPermaLink="false">oai:arXiv.org:2501.04011v1</guid>
      <category>math.NA</category>
      <category>cs.GR</category>
      <category>cs.NA</category>
      <pubDate>Thu, 09 Jan 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <dc:creator>Behrooz Zarebavani, Danny M. Kaufman, David I. W. Levin, Maryam Mehri Dehnavi</dc:creator>
    </item>
    <item>
      <title>Convergence of Physics-Informed Neural Networks for Fully Nonlinear PDE's</title>
      <link>https://arxiv.org/abs/2501.04013</link>
      <description>arXiv:2501.04013v1 Announce Type: new 
Abstract: The present work is focused on exploring convergence of Physics-informed Neural Networks (PINNs) when applied to a specific class of second-order fully nonlinear Partial Differential Equations (PDEs). It is well-known that as the number of data grows, PINNs generate a sequence of minimizers which correspond to a sequence of neural networks. We show that such sequence converges to a unique viscosity solution of a certain class of second-order fully nonlinear PDE's, provided the latter satisfies the comparison principle in the viscosity sense.</description>
      <guid isPermaLink="false">oai:arXiv.org:2501.04013v1</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <category>math.AP</category>
      <pubDate>Thu, 09 Jan 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Avetik Arakelyan, Rafayel Barkhudaryan</dc:creator>
    </item>
    <item>
      <title>Computing Barycentres of Measures for Generic Transport Costs</title>
      <link>https://arxiv.org/abs/2501.04016</link>
      <description>arXiv:2501.04016v1 Announce Type: new 
Abstract: Wasserstein barycentres represent average distributions between multiple probability measures for the Wasserstein distance. The numerical computation of Wasserstein barycentres is notoriously challenging. A common approach is to use Sinkhorn iterations, where an entropic regularisation term is introduced to make the problem more manageable. Another approach involves using fixed-point methods, akin to those employed for computing Fr\'echet means on manifolds. The convergence of such methods for 2-Wasserstein barycentres, specifically with a quadratic cost function and absolutely continuous measures, was studied by Alvarez-Esteban et al. (2016). In this paper, we delve into the main ideas behind this fixed-point method and explore how it can be generalised to accommodate more diverse transport costs and generic probability measures, thereby extending its applicability to a broader range of problems. We show convergence results for this approach and illustrate its numerical behaviour on several barycentre problems.</description>
      <guid isPermaLink="false">oai:arXiv.org:2501.04016v1</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <category>math.PR</category>
      <pubDate>Thu, 09 Jan 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Eloi Tanguy, Julie Delon, Natha\"el Gozlan</dc:creator>
    </item>
    <item>
      <title>Virtual element methods based on boundary triangulation:fitted and unfitted meshes</title>
      <link>https://arxiv.org/abs/2501.04021</link>
      <description>arXiv:2501.04021v1 Announce Type: new 
Abstract: One remarkable feature of virtual element methods (VEMs) is their great flexibility and robustness when used on almost arbitrary polytopal meshes. This very feature makes it widely used in both fitted and unfitted mesh methods. Despite extensive numerical studies, a rigorous analysis of robust optimal convergence has remained open for highly anisotropic 3D polyhedral meshes. In this work, we consider the VEMs in \cite{2023CaoChenGuo,2017ChenWeiWen} that introduce a boundary triangulation satisfying the maximum angle condition. We close this theoretical gap regarding optimal convergence on polyhedral meshes in the lowest-order case for the following three types of meshes: (1) elements only contain non-shrinking inscribed balls but \textit{are not necessarily star convex} to those balls; (2) elements are cut arbitrarily from a background Cartesian mesh, which can extremely shrink; (3) elements contain different materials on which the virtual spaces involve discontinuous coefficients. The first two widely appear in generating fitted meshes for interface and fracture problems, while the third one is used for unfitted mesh on interface problems. In addition, the present work also generalizes the maximum angle condition from simplicial meshes to polyhedral meshes.</description>
      <guid isPermaLink="false">oai:arXiv.org:2501.04021v1</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <pubDate>Thu, 09 Jan 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Ruchi Guo</dc:creator>
    </item>
    <item>
      <title>Approximation Rates in Fr\'echet Metrics: Barron Spaces, Paley-Wiener Spaces, and Fourier Multipliers</title>
      <link>https://arxiv.org/abs/2501.04023</link>
      <description>arXiv:2501.04023v1 Announce Type: new 
Abstract: Operator learning is a recent development in the simulation of Partial Differential Equations (PDEs) by means of neural networks. The idea behind this approach is to learn the behavior of an operator, such that the resulting neural network is an (approximate) mapping in infinite-dimensional spaces that is capable of (approximately) simulating the solution operator governed by the PDE. In our work, we study some general approximation capabilities for linear differential operators by approximating the corresponding symbol in the Fourier domain. Analogous to the structure of the class of H\"ormander-Symbols, we consider the approximation with respect to a topology that is induced by a sequence of semi-norms. In that sense, we measure the approximation error in terms of a Fr\'echet metric, and our main result identifies sufficient conditions for achieving a predefined approximation error. Secondly, we then focus on a natural extension of our main theorem, in which we manage to reduce the assumptions on the sequence of semi-norms. Based on some existing approximation result for the exponential spectral Barron space, we then present a concrete example of symbols that can be approximated well, and we also show the analogy of this approximation to the design of digital filters in Signal Processing.</description>
      <guid isPermaLink="false">oai:arXiv.org:2501.04023v1</guid>
      <category>math.NA</category>
      <category>cs.IT</category>
      <category>cs.LG</category>
      <category>cs.NA</category>
      <category>math.IT</category>
      <category>stat.ML</category>
      <pubDate>Thu, 09 Jan 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Ahmed Abdeljawad, Thomas Dittrich</dc:creator>
    </item>
    <item>
      <title>Evaluation of data driven low-rank matrix factorization for accelerated solutions of the Vlasov equation</title>
      <link>https://arxiv.org/abs/2501.04024</link>
      <description>arXiv:2501.04024v1 Announce Type: new 
Abstract: Low-rank methods have shown success in accelerating simulations of a collisionless plasma described by the Vlasov equation, but still rely on computationally costly linear algebra every time step. We propose a data-driven factorization method using artificial neural networks, specifically with convolutional layer architecture, that trains on existing simulation data. At inference time, the model outputs a low-rank decomposition of the distribution field of the charged particles, and we demonstrate that this step is faster than the standard linear algebra technique. Numerical experiments show that the method effectively interpolates time-series data, generalizing to unseen test data in a manner beyond just memorizing training data; patterns in factorization also inherently followed the same numerical trend as those within algebraic methods (e.g., truncated singular-value decomposition). However, when training on the first 70% of a time-series data and testing on the remaining 30%, the method fails to meaningfully extrapolate. Despite this limiting result, the technique may have benefits for simulations in a statistical steady-state or otherwise showing temporal stability.</description>
      <guid isPermaLink="false">oai:arXiv.org:2501.04024v1</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <category>stat.ML</category>
      <pubDate>Thu, 09 Jan 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Bhavana Jonnalagadda, Stephen Becker</dc:creator>
    </item>
    <item>
      <title>A continuous scale space of diffeomorphisms</title>
      <link>https://arxiv.org/abs/2501.04031</link>
      <description>arXiv:2501.04031v1 Announce Type: new 
Abstract: In this paper, we define and study a nested family of reproducing kernel Hilbert spaces of vector fields that is indexed by a range of scales, from which we construct a reproducing kernel Hilbert space of scale-dependent vector fields. We provide a characterization of the reproducing kernel of that space, with numerical approximations ensuring quick evaluations when this kernel does not have a closed form. We then introduce a multiscale version of the large deformation diffeomorphic metric mapping (LDDMM) problem and prove the existence of solutions. Finally, we provide numerical experiments performing landmark matching using multiscale LDDMM.</description>
      <guid isPermaLink="false">oai:arXiv.org:2501.04031v1</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <pubDate>Thu, 09 Jan 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Yechen Liu, Laurent Younes</dc:creator>
    </item>
    <item>
      <title>Three-dimensional DtN-FEM scattering analysis of Lamb and SH guided waves by a symmetric cavity defect in an isotropic infinite plate</title>
      <link>https://arxiv.org/abs/2501.04039</link>
      <description>arXiv:2501.04039v1 Announce Type: new 
Abstract: In this paper, a three-dimensional Dirichlet-to-Neumann (DtN) finite element method (FEM) is developed to analyze the scattering of Lamb and SH guided waves due to a symmetric cavity defect in an isotropic infinite plate. During the finite element analysis, it is necessary to determine the far-field DtN conditions at virtual boundaries where both displacements and tractions are unknown. In this study, firstly, the scattered waves at the virtual boundaries are represented by a superposition of guided waves with unknown scattered coefficients. Secondly, utilizing the mode orthogonality, the unknown tractions at virtual boundaries are expressed in terms of the unknown scattered displacements at virtual boundaries via scattered coefficients. Thirdly, this relationship at virtual boundaries can be finally assembled into the global DtN-FEM matrix to solve the problem. This method is simple and elegant, which has advantages on dimension reduction and needs no absorption medium or perfectly matched layer to suppress the reflected waves compared to traditional FEM. Furthermore, the reflection and transmission coefficients of each guided mode can be directly obtained without post-processing. This proposed 3D DtN-FEM will be compared with boundary element method (BEM) and finally validated for several benchmark problems.</description>
      <guid isPermaLink="false">oai:arXiv.org:2501.04039v1</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <category>physics.comp-ph</category>
      <pubDate>Thu, 09 Jan 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Chen Yang, Junichi Nakaoka, Sohichi Hirose</dc:creator>
    </item>
    <item>
      <title>A stabilized finite element method for steady Darcy-Brinkman-Forchheimer flow model with different viscous and inertial resistances in porous media</title>
      <link>https://arxiv.org/abs/2501.04041</link>
      <description>arXiv:2501.04041v1 Announce Type: new 
Abstract: We implement a stabilized finite element method for steady Darcy-Brinkman-Forchheimer model within the continuous Galerkin framework. The nonlinear fluid model is first linearized using a standard \textit{Newton's method. The sequence of linear problems is then discretized utilizing a stable \textit{inf-sup} type continuous finite elements based on the \textit{Taylor-Hood} pair to approximate the primary variables: velocity and pressure}. Such a pair is known to be optimal for the approximation of the isotropic Navier-Stokes equation. To overcome the well-known numerical instability in the convection-dominated problems, the Grad-Div stabilization is employed with an efficient \textit{augmented Lagrangian-type} penalty method. We use the penalty term to develop the \textit{block Schur complement} preconditioner, which is later coupled with a Krylov-space-based iterative linear solver. In addition, the Kelly error estimator for the adaptive mesh refinement is employed to achieve better numerical results with less computational cost. Performance of the proposed algorithm is verified for a classical benchmark problem. Particularly for the Forchheimer parameter, we present some interesting flow patterns with the velocity components and their streamlines along the mid-lines in the computational domain. The role of the Forchheimer term is highlighted for different porous medium scenarios. This study can offer an attractive setting for discretizing many multi-physics problems along with the fluid flow having inertial effects in porous media.</description>
      <guid isPermaLink="false">oai:arXiv.org:2501.04041v1</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <pubDate>Thu, 09 Jan 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Hyun Chul Yoon, S. M. Mallikarjunaiah</dc:creator>
    </item>
    <item>
      <title>Linear Optimization for the Perfect Meal: A Data-Driven Approach to Optimising the Perfect Meal Using Gurobi</title>
      <link>https://arxiv.org/abs/2501.04143</link>
      <description>arXiv:2501.04143v1 Announce Type: new 
Abstract: This study aims to optimize meal planning for nutritional health and cost efficiency using linear programming. Linear optimization provides an effective framework for addressing the problem of an optimal diet, as the composition of food can be naturally modeled as a linearly additive system. Leveraging a comprehensive nutrition dataset, our model minimizes meal costs while meeting specific nutritional requirements. We explore additional complexities, such as fractional weights and nutrient ratio constraints, enhancing the robustness of the solution. Case studies address common nutritional challenges, providing tailored diet plans. The significance lies in aiding individuals to form balanced, cost-effective dietary schedules, considering fitness goals and caloric needs. This research contributes to efficient, sustainable, and time-sensitive meal planning, emphasizing the intersection of nutrition, optimization, and real-world applicability.</description>
      <guid isPermaLink="false">oai:arXiv.org:2501.04143v1</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <category>math.OC</category>
      <pubDate>Thu, 09 Jan 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/publicdomain/zero/1.0/</dc:rights>
      <dc:creator>Utkarsh Prajapati, Tanushree Jain, Abhishek Machiraju, Divyam Kaushik</dc:creator>
    </item>
    <item>
      <title>Automatic partitioning for the low-rank integration of stochastic Boolean reaction networks</title>
      <link>https://arxiv.org/abs/2501.04157</link>
      <description>arXiv:2501.04157v1 Announce Type: new 
Abstract: Boolean reaction networks are an important tool in biochemistry for studying mechanisms in the biological cell. However, the stochastic formulation of such networks requires the solution of a master equation which inherently suffers from the curse of dimensionality. In the past, the dynamical low-rank (DLR) approximation has been repeatedly used to solve high-dimensional reaction networks by separating the network into smaller partitions. However, the partitioning of these networks was so far only done by hand. In this paper, we present a heuristic, automatic partitioning scheme based on two ingredients: the Kernighan-Lin algorithm and information entropy. Our approach is computationally inexpensive and can be easily incorporated as a preprocessing step into the existing simulation workflow. We test our scheme by partitioning Boolean reaction networks on a single level and also in a hierarchical fashion with tree tensor networks. The resulting accuracy of the scheme is superior to both partitionings chosen by human experts and those found by simply minimizing the number of reaction pathways between partitions.</description>
      <guid isPermaLink="false">oai:arXiv.org:2501.04157v1</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <category>physics.bio-ph</category>
      <category>physics.comp-ph</category>
      <pubDate>Thu, 09 Jan 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Lukas Einkemmer, Julian Mangott, Martina Prugger</dc:creator>
    </item>
    <item>
      <title>Dual Numbers for Arbitrary Order Automatic Differentiation</title>
      <link>https://arxiv.org/abs/2501.04159</link>
      <description>arXiv:2501.04159v1 Announce Type: new 
Abstract: Dual numbers are a well-known tool for computing derivatives of functions. While the theoretical framework for calculating derivatives of arbitrary order is well established, practical implementations remain less developed. One notable implementation is available in the Julia programming language where dual numbers are designed to be nested, enabling the computation of derivatives to arbitrary order. However, this approach has a significant drawback as it struggles with scalability for high-order derivatives. The nested structure quickly consumes memory, making it challenging to compute derivatives of higher orders. In this study, we introduce DNAOAD, a Fortran-based implementation of automatic differentiation capable of handling derivatives of arbitrary order using dual numbers. This implementation employs a direct approach to represent dual numbers without relying on recursive or nested structures. As a result, DNAOAD facilitates the efficient computation of derivatives of very high orders while addressing the memory limitations of existing methods.</description>
      <guid isPermaLink="false">oai:arXiv.org:2501.04159v1</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <pubDate>Thu, 09 Jan 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>F. Pe\~nu\~nuri, K. B. Cant\'un-Avila, R. Pe\'on-Escalante</dc:creator>
    </item>
    <item>
      <title>Three-precision iterative refinement with parameter regularization and prediction for solving large sparse linear systems</title>
      <link>https://arxiv.org/abs/2501.04229</link>
      <description>arXiv:2501.04229v1 Announce Type: new 
Abstract: This study presents a novel mixed-precision iterative refinement algorithm, GADI-IR, within the general alternating-direction implicit (GADI) framework, designed for efficiently solving large-scale sparse linear systems. By employing low-precision arithmetic, particularly half-precision (FP16), for computationally intensive inner iterations, the method achieves substantial acceleration while maintaining high numerical accuracy. Key challenges such as overflow in FP16 and convergence issues for low precision are addressed through careful backward error analysis and the application of a regularization parameter $\alpha$. Furthermore, the integration of low-precision arithmetic into the parameter prediction process, using Gaussian process regression (GPR), significantly reduces computational time without degrading performance. The method is particularly effective for large-scale linear systems arising from discretized partial differential equations and other high-dimensional problems, where both accuracy and efficiency are critical. Numerical experiments demonstrate that the use of FP16 and mixed-precision strategies not only accelerates computation but also ensures robust convergence, making the approach advantageous for various applications. The results highlight the potential of leveraging lower-precision arithmetic to achieve superior computational efficiency in high-performance computing.</description>
      <guid isPermaLink="false">oai:arXiv.org:2501.04229v1</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <pubDate>Thu, 09 Jan 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Juan Zhang, Jifeng Ge, Jianzhou Liu</dc:creator>
    </item>
    <item>
      <title>Willmore regularized sharp-interface model for strongly anisotropic solid-state dewetting with axisymmetric geometry: modeling and simulation</title>
      <link>https://arxiv.org/abs/2501.04280</link>
      <description>arXiv:2501.04280v1 Announce Type: new 
Abstract: In this work, we consider the three-dimensional solid-state dewetting with strongly anisotropic surface energy, assuming an axisymmetric morphology of the thin film. However, when surface energy exhibits strong anisotropy, certain orientations may be missing from the equilibrium shapes, which will lead to an ill-posed governing equation. By incorporating the Willmore energy, we define a regularized total free energy and rigorously derive a sharp-interface model based on thermodynamic variations. We further develop a numerical scheme for the sharp-interface model that can preserve two important structural properties, including both the volume-conservation and energy-stability laws. We conclude by presenting a series of numerical simulations that illustrate the accuracy and structure-preserving properties. More importantly, extensive numerical simulations clearly demonstrate that our schemes can significantly enhance mesh quality, which is beneficial for long-term computations.</description>
      <guid isPermaLink="false">oai:arXiv.org:2501.04280v1</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <pubDate>Thu, 09 Jan 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Meng Li, Chunjie Zhou</dc:creator>
    </item>
    <item>
      <title>LU Decomposition and Generalized Autoone-Takagi Decomposition of Dual Matrices and their Applications</title>
      <link>https://arxiv.org/abs/2501.04324</link>
      <description>arXiv:2501.04324v1 Announce Type: new 
Abstract: This paper uses matrix transformations to provide the Autoone-Takagi decomposition of dual complex symmetric matrices and extends it to dual quaternion $\eta$-Hermitian matrices. The LU decomposition of dual matrices is given using the general solution of the Sylvester equation, and its equivalence to the existence of rank-k decomposition and dual Moore-Penrose generalized inverse (DMPGI) is proved. Similar methods are then used to provide the Cholesky decomposition of dual real symmetric positive definite matrices. Both of our decompositions are driven by applications in numerical linear algebra.</description>
      <guid isPermaLink="false">oai:arXiv.org:2501.04324v1</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <pubDate>Thu, 09 Jan 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Renjie Xu, Yimin Wei, Hong Yan</dc:creator>
    </item>
    <item>
      <title>Mathematical Modelling of Mechanotransduction via RhoA Signalling Pathways</title>
      <link>https://arxiv.org/abs/2501.04407</link>
      <description>arXiv:2501.04407v1 Announce Type: new 
Abstract: We derive and simulate a mathematical model for mechanotransduction related to the Rho GTPase signalling pathway. The model addresses the bidirectional coupling between signalling processes and cell mechanics. A numerical method based on bulk-surface finite elements is proposed for the approximation of the coupled system of nonlinear reaction-diffusion equations, defined inside the cell and on the cell membrane, and the equations of elasticity. Our simulation results illustrate novel emergent features such as the strong dependence of the dynamics on cell shape, a threshold-like response to changes in substrate stiffness, and the fact that coupling mechanics and signalling can lead to the robustness of cell deformation to larger changes in substrate stiffness, ensuring mechanical homeostasis in agreement with experiments.</description>
      <guid isPermaLink="false">oai:arXiv.org:2501.04407v1</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <category>physics.bio-ph</category>
      <category>q-bio.CB</category>
      <pubDate>Thu, 09 Jan 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Sofie Verhees, Chandrasekhar Venkataraman, Mariya Ptashnyk</dc:creator>
    </item>
    <item>
      <title>On the basins of attraction of a one-dimensional family of root finding algorithms: from Newton to Traub</title>
      <link>https://arxiv.org/abs/2501.04450</link>
      <description>arXiv:2501.04450v1 Announce Type: new 
Abstract: In this paper we study the dynamics of damped Traub's methods $T_\delta$ when applied to polynomials. The family of damped Traub's methods consists of root finding algorithms which contain both Newton's ($\delta=0$) and Traub's method ($\delta=1$). Our goal is to obtain several topological properties of the basins of attraction of the roots of a polynomial $p$ under $T_1$, which are used to determine a (universal) set of initial conditions for which convergence to all roots of $p$ can be guaranteed. We also numerically explore the global properties of the dynamical plane for $T_\delta$ to better understand the connection between Newton's method and Traub's method.</description>
      <guid isPermaLink="false">oai:arXiv.org:2501.04450v1</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <category>math.DS</category>
      <pubDate>Thu, 09 Jan 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <arxiv:DOI>10.1007/s00209-023-03215-8</arxiv:DOI>
      <arxiv:journal_reference>Mathematische Zeitschrift, 303 (2023), no.3, Paper No. 55, 22 pp</arxiv:journal_reference>
      <dc:creator>Jordi Canela, Vasiliki Evdoridou, Antonio Garijo, Xavier Jarque</dc:creator>
    </item>
    <item>
      <title>Bayesian buckling load optimisation for structures with geometric uncertainties</title>
      <link>https://arxiv.org/abs/2501.04553</link>
      <description>arXiv:2501.04553v1 Announce Type: new 
Abstract: Optimised lightweight structures, such as shallow domes and slender towers, are prone to sudden buckling failure because geometric uncertainties/imperfections can lead to a drastic reduction in their buckling loads. We introduce a framework for the robust optimisation of buckling loads, considering geometric nonlinearities and random geometric imperfections. The mean and standard deviation of buckling loads are estimated by Monte Carlo sampling of random imperfections and performing a nonlinear finite element computation for each sample. The extended system method is employed to compute the buckling load directly, avoiding costly path-following procedures. Furthermore, the quasi-Monte Carlo sampling using the Sobol sequence is implemented to generate more uniformly distributed samples, which significantly reduces the number of finite element computations. The objective function consisting of the weighted sum of the mean and standard deviation of the buckling load is optimised using Bayesian optimisation. The accuracy and efficiency of the proposed framework are demonstrated through robust sizing optimisation of several geometrically nonlinear truss examples.</description>
      <guid isPermaLink="false">oai:arXiv.org:2501.04553v1</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <pubDate>Thu, 09 Jan 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Tianyi Liu, Xiao Xiao, Fehmi Cirak</dc:creator>
    </item>
    <item>
      <title>High order positivity-preserving numerical methods for a non-local photochemical model</title>
      <link>https://arxiv.org/abs/2501.04573</link>
      <description>arXiv:2501.04573v1 Announce Type: new 
Abstract: In this paper we design high-order positivity-preserving approximation schemes for an integro-differential model describing photochemical reactions. Specifically, we introduce and analyze three classes of dynamically consistent methods, encompassing non-standard finite difference schemes, direct quadrature techniques and predictor-corrector approaches. The proposed discretizations guarantee the positivity, monotonicity and boundedness of the solution regardless of the temporal, spatial and frequency stepsizes. Comprehensive numerical experiments confirm the theoretical findings and demonstrate the efficacy of the proposed methods in simulating realistic photochemical phenomena.</description>
      <guid isPermaLink="false">oai:arXiv.org:2501.04573v1</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <pubDate>Thu, 09 Jan 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Mario Pezzella</dc:creator>
    </item>
    <item>
      <title>Sparse free deconvolution under unknown noise level via eigenmatrix</title>
      <link>https://arxiv.org/abs/2501.04599</link>
      <description>arXiv:2501.04599v1 Announce Type: new 
Abstract: This note considers the spectral estimation problems of sparse spectral measures under unknown noise levels. The main technical tool is the eigenmatrix method for solving unstructured sparse recovery problems. When the noise level is determined, the free deconvolution reduces the problem to an unstructured sparse recovery problem to which the eigenmatrix method can be applied. To determine the unknown noise level, we propose an optimization problem based on the singular values of an intermediate matrix of the eigenmatrix method. Numerical results are provided for both the additive and multiplicative free deconvolutions.</description>
      <guid isPermaLink="false">oai:arXiv.org:2501.04599v1</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <category>math.ST</category>
      <category>stat.TH</category>
      <pubDate>Thu, 09 Jan 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Lexing Ying</dc:creator>
    </item>
    <item>
      <title>Strong error estimates for a fully discrete SAV scheme for the stochastic Allen--Cahn equation with multiplicative noise</title>
      <link>https://arxiv.org/abs/2501.04618</link>
      <description>arXiv:2501.04618v1 Announce Type: new 
Abstract: We investigate the numerical approximation of the stochastic Allen--Cahn equation with multiplicative noise on a periodic domain. The considered scheme uses a recently proposed augmented variant of scalar auxiliary variable method for the discretization with respect to time. While scalar auxiliary variable methods in general allow for the construction of unconditionally stable, efficient linear schemes, the considered augmented version (cf. [S. Metzger, 2024, IMA J. Numer. Anal.]) additionally compensates for the typically poor temporal regularity of solutions to stochastic partial differential equations and hence extends the range of applicability of the scheme. In this work, we establish strong rates of convergence and show that the proposed linear scheme exhibits the same optimal rates of convergence that were established in [A. K. Majee &amp; A. Prohl, 2018, Comput. Methods Appl. Math.] for a nonlinear structure preserving scheme. Finally, we provide numerical simulations verifying our theoretical findings.</description>
      <guid isPermaLink="false">oai:arXiv.org:2501.04618v1</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <pubDate>Thu, 09 Jan 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Stefan Metzger</dc:creator>
    </item>
    <item>
      <title>Convergence of a second-order central scheme for conservation laws with discontinuous flux</title>
      <link>https://arxiv.org/abs/2501.04620</link>
      <description>arXiv:2501.04620v2 Announce Type: new 
Abstract: In this article, we propose a Nessyahu-Tadmor-type second-order central scheme for a class of scalar conservation laws with discontinuous flux and present its convergence analysis. Since solutions to problems with discontinuous flux typically do not belong to the space of bounded variation (BV), we employ the theory of compensated compactness as the main tool for the convergence of approximate solutions. A central component of the analysis involves establishing the maximum principle and the $\mathrm{W}^{-1,2}_{\mathrm{loc}}$ compactness of the approximate solutions, the latter achieved through the derivation of several essential estimates. Finally, by introducing a mesh-dependent correction term in the slope limiter, we show that the numerical solutions generated by the the proposed second-order scheme converge to the entropy solution.</description>
      <guid isPermaLink="false">oai:arXiv.org:2501.04620v2</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <pubDate>Thu, 09 Jan 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Nikhil Manoj, Sudarshan Kumar K</dc:creator>
    </item>
    <item>
      <title>Dynamics of Newton-like root finding methods</title>
      <link>https://arxiv.org/abs/2501.04645</link>
      <description>arXiv:2501.04645v1 Announce Type: new 
Abstract: When exploring the literature, it can be observed that the operator obtained when applying \textit{Newton-like} root finding algorithms to the quadratic polynomials $z^2-c$ has the same form regardless of which algorithm has been used. In this paper we justify why this expression is obtained. This is done by studying the symmetries of the operators obtained after applying Newton-like algorithms to a family of degree $d$ polynomials $p(z)=z^d-c$. Moreover, we provide an iterative procedure to obtain the expression of new Newton-like algoritms. We also carry out a dynamical study of the given generic operator and provide general conclusions of this type of methods.</description>
      <guid isPermaLink="false">oai:arXiv.org:2501.04645v1</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <pubDate>Thu, 09 Jan 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <arxiv:DOI>10.1007/s11075-022-01474-w</arxiv:DOI>
      <arxiv:journal_reference>Numerical Algorithms, 93 (2023), 1453-1480</arxiv:journal_reference>
      <dc:creator>Beatriz Campos, Jordi Canela, Pura Vindel</dc:creator>
    </item>
    <item>
      <title>A Novel Highly Parallelizable Machine-Learning Based Method for the Fast Solution of Integral Equations for Electromagnetic Scattering Problems</title>
      <link>https://arxiv.org/abs/2501.04684</link>
      <description>arXiv:2501.04684v1 Announce Type: new 
Abstract: We propose a novel method for the efficient and accurate iterative solution of frequency domain integral equations (IEs) that are used for large/multi-scale electromagnetic scattering problems. The proposed method uses a novel group-by-group interaction strategy to accurately evaluate far-zone interactions within the framework of the one-box-buffer scheme during the matrix-vector multiplication at each iteration. Briefly, subdomain basis functions that are used to model the scatterer at each box are represented by a fixed number of uniformly distributed and arbitrarily oriented Hertzian dipoles (referred to as uniform basis functions), and then the dipole-to-dipole interactions are predicted in a group-wise manner by employing machine learning algorithms, thereby showcasing efficiency, strong scalability for parallelization and accuracy without the low-frequency breakdown (LFB) problem. Since the dipole representation is independent of the underlying material properties of the scatterer, the proposed method is valid for all types of IEs (surface or volume). Moreover, because the training is performed offline, the resulting networks can be used for any scatterer under any IE, without extra training, as long as the size of, and the distances among the boxes are preserved. The efficiency and accuracy of the proposed method are assessed by comparing our results with those obtained from the conventional multilevel fast multipole algorithm for various scattering problems. The proposed method's parallelization performance is showcased through scalability tests, and its resilience to LFB is demonstrated.</description>
      <guid isPermaLink="false">oai:arXiv.org:2501.04684v1</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <category>physics.comp-ph</category>
      <pubDate>Thu, 09 Jan 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Enes Ko\c{c}, Mert Kalfa, Secil E. Dogan, Vakur B. Ert\"urk</dc:creator>
    </item>
    <item>
      <title>SEIHRDV: a multi-age multi-group epidemiological model and its validation on the COVID-19 epidemics in Italy</title>
      <link>https://arxiv.org/abs/2501.04148</link>
      <description>arXiv:2501.04148v1 Announce Type: cross 
Abstract: We propose a novel epidemiological model, referred to as SEIHRDV, for the numerical simulation of the COVID-19 epidemic, which we validate using data from Italy starting in September 2020. SEIHRDV features the following compartments: Susceptible (S), Exposed (E), Infectious (I), Healing (H), Recovered (R), Deceased (D) and Vaccinated (V). The model is age-stratified, as it considers the population split into 15 age groups. Moreover, it takes into account 7 different contexts of exposition to the infection (family, home, school, work, transport, leisure, other contexts), which impact on the transmission mechanism. Thanks to these features, the model can address the analysis of the epidemics and the efficacy of non-pharmaceutical interventions, as well as possible vaccination strategies and the introduction of the Green Pass, a containment measure introduced in Italy in 2021. By leveraging on the SEIHRDV model, we successfully analyzed epidemic trends during the COVID-19 outbreak from September 2020 to July 2021. The model proved instrumental in conducting comprehensive what-if studies and scenario analyses tailored to Italy and its regions. Furthermore, SEIHRDV facilitated accurate forecasting of the future potential trajectory of the epidemic, providing critical information for informed decision making and public health strategies.</description>
      <guid isPermaLink="false">oai:arXiv.org:2501.04148v1</guid>
      <category>q-bio.PE</category>
      <category>cs.NA</category>
      <category>math.NA</category>
      <pubDate>Thu, 09 Jan 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Luca Dede', Nicola Parolini, Alfio Quarteroni, Giulia Villani, Giovanni Ziarelli</dc:creator>
    </item>
    <item>
      <title>Fixed Points of Deep Neural Networks: Emergence, Stability, and Applications</title>
      <link>https://arxiv.org/abs/2501.04182</link>
      <description>arXiv:2501.04182v1 Announce Type: cross 
Abstract: We present numerical and analytical results on the formation and stability of a family of fixed points of deep neural networks (DNNs). Such fixed points appear in a class of DNNs when dimensions of input and output vectors are the same. We demonstrate examples of applications of such networks in supervised, semi-supervised and unsupervised learning such as encoding/decoding of images, restoration of damaged images among others.
  We present several numerical and analytical results. First, we show that for untrained DNN's with weights and biases initialized by normally distributed random variables the only one fixed point exists. This result holds for DNN with any depth (number of layers) $L$, any layer width $N$, and sigmoid-type activation functions. Second, it has been shown that for a DNN whose parameters (weights and biases) are initialized by ``light-tailed'' distribution of weights (e.g. normal distribution), after training the distribution of these parameters become ``heavy-tailed''. This motivates our study of DNNs with ``heavy-tailed'' initialization. For such DNNs we show numerically %existence and stability that training leads to emergence of $Q(N,L)$ fixed points, where $Q(N,L)$ is a positive integer which depends on the number of layers $L$ and layer width $N$. We further observe numerically that for fixed $N = N_0$ the function $Q(N_0, L)$ is non-monotone, that is it initially grows as $L$ increases and then decreases to 1.
  This non-monotone behavior of $Q(N_0, L)$ is also obtained by analytical derivation of equation for Empirical Spectral Distribution (ESD) of input-output Jacobian followed by numerical solution of this equation.</description>
      <guid isPermaLink="false">oai:arXiv.org:2501.04182v1</guid>
      <category>cs.LG</category>
      <category>cs.AI</category>
      <category>cs.NA</category>
      <category>math.NA</category>
      <pubDate>Thu, 09 Jan 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>L. Berlyand, V. Slavin</dc:creator>
    </item>
    <item>
      <title>Stable Derivative Free Gaussian Mixture Variational Inference for Bayesian Inverse Problems</title>
      <link>https://arxiv.org/abs/2501.04259</link>
      <description>arXiv:2501.04259v1 Announce Type: cross 
Abstract: This paper is concerned with the approximation of probability distributions known up to normalization constants, with a focus on Bayesian inference for large-scale inverse problems in scientific computing. In this context, key challenges include costly repeated evaluations of forward models, multimodality, and inaccessible gradients for the forward model. To address them, we develop a variational inference framework that combines Fisher-Rao natural gradient with specialized quadrature rules to enable derivative free updates of Gaussian mixture variational families. The resulting method, termed Derivative Free Gaussian Mixture Variational Inference (DF-GMVI), guarantees covariance positivity and affine invariance, offering a stable and efficient framework for approximating complex posterior distributions. The effectiveness of DF-GMVI is demonstrated through numerical experiments on challenging scenarios, including distributions with multiple modes, infinitely many modes, and curved modes in spaces with up to hundreds of dimensions. The method's practicality is further demonstrated in a large-scale application, where it successfully recovers the initial conditions of the Navier-Stokes equations from solution data at positive times.</description>
      <guid isPermaLink="false">oai:arXiv.org:2501.04259v1</guid>
      <category>cs.LG</category>
      <category>cs.NA</category>
      <category>math.NA</category>
      <pubDate>Thu, 09 Jan 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Baojun Che, Yifan Chen, Zhenghao Huan, Daniel Zhengyu Huang, Weijie Wang</dc:creator>
    </item>
    <item>
      <title>An algorithm for a constrained P-spline</title>
      <link>https://arxiv.org/abs/2501.04335</link>
      <description>arXiv:2501.04335v1 Announce Type: cross 
Abstract: Regression splines are largely used to investigate and predict data behavior, attracting the interest of mathematicians for their beautiful numerical properties, and of statisticians for their versatility with respect to the applications. Several penalized spline regression models are available in the literature, and the most commonly used ones in real-world applications are P-splines, which enjoy the advantages of penalized models while being easy to generalize across different functional spaces and higher degree order, because of their discrete penalty term. To face the different requirements imposed by the nature of the problem or the physical meaning of the expected values, the P-spline definition is often modified by additional hypotheses, often translated into constraints on the solution or its derivatives. In this framework, our work is motivated by the aim of getting approximation models that fall within pre-established thresholds. Specifically, starting from a set of observed data, we consider a P-spline constrained between some prefixed bounds. In our paper, we just consider 0 as lower bound, although our approach applies to more general cases. We propose to get nonnegativity by imposing lower bounds on selected sample points. The spline can be computed through a sequence of linearly constrained problems. We suggest a strategy to dynamically select the sample points, to avoid extremely dense sampling, and therefore try to reduce as much as possible the computational burden. We show through some computational experiments the reliability of our approach and the accuracy of the results compared to some state-of-the-art models.</description>
      <guid isPermaLink="false">oai:arXiv.org:2501.04335v1</guid>
      <category>stat.ME</category>
      <category>cs.NA</category>
      <category>math.NA</category>
      <category>math.OC</category>
      <pubDate>Thu, 09 Jan 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Rosanna Campagna, Serena Crisci, Gabriele Santin, Gerardo Toraldo, Marco Viola</dc:creator>
    </item>
    <item>
      <title>On Domain Decomposition for Magnetostatic Problems in 3D</title>
      <link>https://arxiv.org/abs/2501.04340</link>
      <description>arXiv:2501.04340v1 Announce Type: cross 
Abstract: The simulation of three dimensional magnetostatic problems plays an important role, for example when simulating synchronous electric machines. Building on prior work that developed a domain decomposition algorithm using isogeometric analysis, this paper extends the method to support subdomains composed of multiple patches. This extension enables load-balancing across available CPUs, facilitated by graph partitioning tools such as METIS. The proposed approach enhances scalability and flexibility, making it suitable for large-scale simulations in diverse industrial contexts.</description>
      <guid isPermaLink="false">oai:arXiv.org:2501.04340v1</guid>
      <category>cs.CE</category>
      <category>cs.NA</category>
      <category>math.NA</category>
      <pubDate>Thu, 09 Jan 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Mario Mally, Melina Merkel</dc:creator>
    </item>
    <item>
      <title>Numerical approximation of the stochastic Cahn-Hilliard equation with space-time white noise near the sharp interface limit</title>
      <link>https://arxiv.org/abs/2401.12832</link>
      <description>arXiv:2401.12832v2 Announce Type: replace 
Abstract: We consider the stochastic Cahn-Hilliard equation with additive space-time white noise $\epsilon^{\gamma}\dot{W}$ in dimension $d=2,3$, where $\epsilon&gt;0$ is an interfacial width parameter. We study numerical approximation of the equation which combines a structure preserving implicit time-discretization scheme with a discrete approximation of the space-time white noise. We derive a strong error estimate for the considered numerical approximation which is robust with respect to the inverse of the interfacial width parameter $\epsilon$. Furthermore, by a splitting approach, we show that for sufficiently large scaling parameter $\gamma$, the numerical approximation of the stochastic Cahn-Hilliard equation converges uniformly to the deterministic Hele-Shaw/Mullins-Sekerka problem in the sharp interface limit $\epsilon\rightarrow 0$.</description>
      <guid isPermaLink="false">oai:arXiv.org:2401.12832v2</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <pubDate>Thu, 09 Jan 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>\v{L}ubom\'ir Ba\v{n}as, Jean Daniel Mukam</dc:creator>
    </item>
    <item>
      <title>Optimal convergence rates of an adaptive hybrid FEM-BEM method for full-space linear transmission problems</title>
      <link>https://arxiv.org/abs/2402.07040</link>
      <description>arXiv:2402.07040v2 Announce Type: replace 
Abstract: We consider a hybrid FEM-BEM method to compute approximations of full-space linear elliptic transmission problems. First, we derive a priori and a posteriori error estimates. Then, building on the latter, we present an adaptive algorithm and prove that it converges at optimal rates with respect to the number of mesh elements. Finally, we provide numerical experiments, demonstrating the practical performance of the adaptive algorithm.</description>
      <guid isPermaLink="false">oai:arXiv.org:2402.07040v2</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <pubDate>Thu, 09 Jan 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Gregor Gantner, Michele Ruggeri</dc:creator>
    </item>
    <item>
      <title>Generalized sparsity-promoting solvers for Bayesian inverse problems: Versatile sparsifying transforms and unknown noise variances</title>
      <link>https://arxiv.org/abs/2402.16623</link>
      <description>arXiv:2402.16623v2 Announce Type: replace 
Abstract: Bayesian hierarchical models can provide efficient algorithms for finding sparse solutions to ill-posed inverse problems. The models typically comprise a conditionally Gaussian prior model for the unknown which is augmented by a generalized gamma hyper-prior model for variance hyper-parameters. This investigation generalizes these models and their efficient maximum a posterior (MAP) estimation using the iterative alternating sequential (IAS) algorithm in two ways: (1) General sparsifying transforms: Diverging from conventional methods, our approach permits the use of sparsifying transformations with nontrivial kernels; (2) Unknown noise variances: We treat the noise variance as a random variable that is estimated during the inference procedure. This is important in applications where the noise estimate cannot be accurately estimated a priori. Remarkably, these augmentations neither significantly burden the computational expense of the algorithm nor compromise its efficacy. We include convexity and convergence analysis for the method and demonstrate its efficacy in several numerical experiments.</description>
      <guid isPermaLink="false">oai:arXiv.org:2402.16623v2</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <category>math.OC</category>
      <pubDate>Thu, 09 Jan 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <arxiv:DOI>10.1088/1361-6420/ada17f</arxiv:DOI>
      <dc:creator>Jonathan Lindbloom, Jan Glaubitz, Anne Gelb</dc:creator>
    </item>
    <item>
      <title>Off-the-grid regularisation for Poisson inverse problems</title>
      <link>https://arxiv.org/abs/2404.00810</link>
      <description>arXiv:2404.00810v2 Announce Type: replace 
Abstract: Off-the-grid regularisation has been extensively employed over the last decade in the context of ill-posed inverse problems formulated in the continuous setting of the space of Radon measures $\mathcal{M}(\mathcal{X})$. These approaches enjoy convexity and counteract the discretisation biases as well the numerical instabilities typical of their discrete counterparts. In the framework of sparse reconstruction of discrete point measures (sum of weighted Diracs), a Total Variation regularisation norm in $\mathcal{M}(\mathcal{X})$ is typically combined with an $L^2$ data term modelling additive Gaussian noise. To asses the framework of off-the-grid regularisation in the presence of signal-dependent Poisson noise, we consider in this work a variational model coupling the Total Variation regularisation with a Kullback-Leibler data term under a non-negativity constraint. Analytically, we study the optimality conditions of the composite functional and analyse its dual problem. Then, we consider an homotopy strategy to select an optimal regularisation parameter and use it within a Sliding Frank-Wolfe algorithm. Several numerical experiments on both 1D/2D simulated and real 3D fluorescent microscopy data are reported.</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.00810v2</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <category>math.OC</category>
      <pubDate>Thu, 09 Jan 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Marta Lazzaretti, Claudio Estatico, Alejandro Melero, Luca Calatroni</dc:creator>
    </item>
    <item>
      <title>Statistical Rounding Error Analysis for Random Matrix Computations</title>
      <link>https://arxiv.org/abs/2405.07537</link>
      <description>arXiv:2405.07537v3 Announce Type: replace 
Abstract: The conventional rounding error analysis provides worst-case bounds with an associated failure probability and ignores the statistical property of the rounding errors. In this paper, we develop a new statistical rounding error analysis for random matrix computations. Such computations occur, e.g., during the precoding or detection process for massive multiple-input multiple-output (MIMO) systems. By assuming the relative errors are independent random variables, we derive the approximate closed-form expressions for the expectation and variance of the rounding errors in various key computations for random matrices. Numerical experiments validate the accuracy of our derivations and demonstrate that our analytical expressions are generally at least two orders of magnitude tighter than alternative worst-case bounds, exemplified through the inner products.</description>
      <guid isPermaLink="false">oai:arXiv.org:2405.07537v3</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <pubDate>Thu, 09 Jan 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Yiming Fang, Li Chen</dc:creator>
    </item>
    <item>
      <title>PSCToolkit: solving sparse linear systems with a large number of GPUs</title>
      <link>https://arxiv.org/abs/2406.19754</link>
      <description>arXiv:2406.19754v2 Announce Type: replace 
Abstract: In this chapter, we describe the Parallel Sparse Computation Toolkit (PSCToolkit), a suite of libraries for solving large-scale linear algebra problems in an HPC environment. In particular, we focus on the tools provided for the solution of symmetric and positive-definite linear systems using up to 8192 GPUs on the EuroHPC-JU Leonardo supercomputer. PSCToolkit is an ongoing mathematical software project aimed at exploiting the extreme computational speed of current supercomputers for relevant problems in Computational and Data Science. The toolkit is designed for node-level efficiency, flexibility and usability, supporting integration with both Fortran and C/C++, enabling researchers and developers from diverse computational backgrounds to leverage its powerful capabilities.</description>
      <guid isPermaLink="false">oai:arXiv.org:2406.19754v2</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <pubDate>Thu, 09 Jan 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Pasqua D'Ambra, Fabio Durastante, Salvatore Filippone</dc:creator>
    </item>
    <item>
      <title>A three-stage method for reconstructing multiple coefficients in coupled photoacoustic and diffuse optical imaging</title>
      <link>https://arxiv.org/abs/2408.03496</link>
      <description>arXiv:2408.03496v2 Announce Type: replace 
Abstract: This paper studies inverse problems in quantitative photoacoustic tomography with additional optical current data supplemented from diffuse optical tomography. We propose a three-stage image reconstruction method for the simultaneous recovery of the absorption, diffusion, and Gr\"uneisen coefficients. We demonstrate, through numerical simulations, that: (i) when the Gr\"uneisen coefficient is known, the addition of the optical measurements allows a more accurate reconstruction of the scattering and absorption coefficients; and (ii) when the Gr\"uneisen coefficient is not known, the addition of optical current measurements allows us to reconstruct uniquely the Gr\"uneisen, the scattering and absorption coefficients. Numerical simulations based on synthetic data are presented to demonstrate the effectiveness of the proposed idea.</description>
      <guid isPermaLink="false">oai:arXiv.org:2408.03496v2</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <category>math.OC</category>
      <category>physics.comp-ph</category>
      <category>physics.med-ph</category>
      <pubDate>Thu, 09 Jan 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Yinxi Pan, Kui Ren, Shanyin Tong</dc:creator>
    </item>
    <item>
      <title>Multilevel Picard approximations and deep neural networks with ReLU, leaky ReLU, and softplus activation overcome the curse of dimensionality when approximating semilinear parabolic partial differential equations in $L^p$-sense</title>
      <link>https://arxiv.org/abs/2409.20431</link>
      <description>arXiv:2409.20431v2 Announce Type: replace 
Abstract: We prove that multilevel Picard approximations and deep neural networks with ReLU, leaky ReLU, and softplus activation are capable of approximating solutions of semilinear Kolmogorov PDEs in $L^\mathfrak{p}$-sense, $\mathfrak{p}\in [2,\infty)$, in the case of gradient-independent, Lipschitz-continuous nonlinearities, while the computational effort of the multilevel Picard approximations and the required number of parameters in the neural networks grow at most polynomially in both dimension $d\in \mathbb{N}$ and reciprocal of the prescribed accuracy $\epsilon$.</description>
      <guid isPermaLink="false">oai:arXiv.org:2409.20431v2</guid>
      <category>math.NA</category>
      <category>cs.LG</category>
      <category>cs.NA</category>
      <category>math.PR</category>
      <pubDate>Thu, 09 Jan 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Ariel Neufeld, Tuan Anh Nguyen</dc:creator>
    </item>
    <item>
      <title>Efficient Langevin sampling with position-dependent diffusion</title>
      <link>https://arxiv.org/abs/2501.02943</link>
      <description>arXiv:2501.02943v2 Announce Type: replace 
Abstract: We introduce a numerical method for Brownian dynamics with position dependent diffusion tensor which is second order accurate for sampling the invariant measure while requiring only one force evaluation per timestep. Analysis of the sampling bias is performed using the algebraic framework of exotic aromatic Butcher-series. Numerical experiments confirm the theoretical order of convergence and illustrate the efficiency of the new method.</description>
      <guid isPermaLink="false">oai:arXiv.org:2501.02943v2</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <pubDate>Thu, 09 Jan 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Eugen Bronasco, Benedict Leimkuhler, Dominic Phillips, Gilles Vilmart</dc:creator>
    </item>
    <item>
      <title>Manifold Filter-Combine Networks</title>
      <link>https://arxiv.org/abs/2307.04056</link>
      <description>arXiv:2307.04056v4 Announce Type: replace-cross 
Abstract: In order to better understand manifold neural networks (MNNs), we introduce Manifold Filter-Combine Networks (MFCNs). Our filter-combine framework parallels the popular aggregate-combine paradigm for graph neural networks (GNNs) and naturally suggests many interesting families of MNNs which can be interpreted as manifold analogues of various popular GNNs. We propose a method for implementing MFCNs on high-dimensional point clouds that relies on approximating an underlying manifold by a sparse graph. We then prove that our method is consistent in the sense that it converges to a continuum limit as the number of data points tends to infinity, and we numerically demonstrate its effectiveness on real-world and synthetic data sets.</description>
      <guid isPermaLink="false">oai:arXiv.org:2307.04056v4</guid>
      <category>stat.ML</category>
      <category>cs.LG</category>
      <category>cs.NA</category>
      <category>eess.SP</category>
      <category>math.NA</category>
      <pubDate>Thu, 09 Jan 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>David R. Johnson, Joyce A. Chew, Edward De Brouwer, Smita Krishnaswamy, Deanna Needell, Michael Perlmutter</dc:creator>
    </item>
    <item>
      <title>Stability of stationary states for mean field models with multichromatic interaction potentials</title>
      <link>https://arxiv.org/abs/2406.04884</link>
      <description>arXiv:2406.04884v2 Announce Type: replace-cross 
Abstract: We consider weakly interacting diffusions on the torus, for multichromatic interaction potentials. We consider interaction potentials that are not H-stable, leading to phase transitions in the mean field limit. We show that the mean field dynamics can exhibit multipeak stationary states, where the number of peaks is related to the number of nonzero Fourier modes of the interaction. We also consider the effect of a confining potential on the structure of non-uniform steady states. We approach the problem by means of analysis, perturbation theory and numerical simulations for the interacting particle systems and the PDEs.</description>
      <guid isPermaLink="false">oai:arXiv.org:2406.04884v2</guid>
      <category>math-ph</category>
      <category>cs.NA</category>
      <category>math.MP</category>
      <category>math.NA</category>
      <pubDate>Thu, 09 Jan 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Benedetta Bertoli, Benjamin D. Goddard, Grigorios A. Pavliotis</dc:creator>
    </item>
    <item>
      <title>Edge-Wise Graph-Instructed Neural Networks</title>
      <link>https://arxiv.org/abs/2409.08023</link>
      <description>arXiv:2409.08023v2 Announce Type: replace-cross 
Abstract: The problem of multi-task regression over graph nodes has been recently approached through Graph-Instructed Neural Network (GINN), which is a promising architecture belonging to the subset of message-passing graph neural networks. In this work, we discuss the limitations of the Graph-Instructed (GI) layer, and we formalize a novel edge-wise GI (EWGI) layer. We discuss the advantages of the EWGI layer and we provide numerical evidence that EWGINNs perform better than GINNs over some graph-structured input data, like the ones inferred from the Barabasi-Albert graph, and improve the training regularization on graphs with chaotic connectivity, like the ones inferred from the Erdos-Renyi graph.</description>
      <guid isPermaLink="false">oai:arXiv.org:2409.08023v2</guid>
      <category>cs.LG</category>
      <category>cs.AI</category>
      <category>cs.NA</category>
      <category>math.NA</category>
      <pubDate>Thu, 09 Jan 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <arxiv:DOI>10.1016/j.jocs.2024.102518</arxiv:DOI>
      <dc:creator>Francesco Della Santa, Antonio Mastropietro, Sandra Pieraccini, Francesco Vaccarino</dc:creator>
    </item>
    <item>
      <title>Refreshing idea on Fourier analysis</title>
      <link>https://arxiv.org/abs/2501.03514</link>
      <description>arXiv:2501.03514v2 Announce Type: replace-cross 
Abstract: The "theoretical limit of time-frequency resolution in Fourier analysis" is thought to originate in certain mathematical and/or physical limitations. This, however, is not true. The actual origin arises from the numerical (technical) method deployed to reduce computation time. In addition, there is a gap between the theoretical equation for Fourier analysis and its numerical implementation. Knowing the facts brings us practical benefits. In this case, these related to boundary conditions, and complex integrals. For example, replacing a Fourier integral with a complex integral brings a hybrid method for the Laplace and Fourier transforms, and reveals another perspective on time-frequency analysis. We present such a perspective here with a simple demonstrative analysis.</description>
      <guid isPermaLink="false">oai:arXiv.org:2501.03514v2</guid>
      <category>physics.soc-ph</category>
      <category>cs.NA</category>
      <category>math.NA</category>
      <pubDate>Thu, 09 Jan 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Fumihiko Ishiyama</dc:creator>
    </item>
  </channel>
</rss>
