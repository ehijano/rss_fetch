<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>math.OC updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/math.OC</link>
    <description>math.OC updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/math.OC" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Fri, 04 Apr 2025 04:00:08 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Fri, 04 Apr 2025 00:00:00 -0400</pubDate>
    <skipDays>
      <day>Sunday</day>
      <day>Saturday</day>
    </skipDays>
    <item>
      <title>Differentiable Optimization for Deep Learning-Enhanced DC Approximation of AC Optimal Power Flow</title>
      <link>https://arxiv.org/abs/2504.01970</link>
      <description>arXiv:2504.01970v1 Announce Type: new 
Abstract: The growing scale of power systems and the increasing uncertainty introduced by renewable energy sources necessitates novel optimization techniques that are significantly faster and more accurate than existing methods. The AC Optimal Power Flow (AC-OPF) problem, a core component of power grid optimization, is often approximated using linearized DC Optimal Power Flow (DC-OPF) models for computational tractability, albeit at the cost of suboptimal and inefficient decisions. To address these limitations, we propose a novel deep learning-based framework for network equivalency that enhances DC-OPF to more closely mimic the behavior of AC-OPF. The approach utilizes recent advances in differentiable optimization, incorporating a neural network trained to predict adjusted nodal shunt conductances and branch susceptances in order to account for nonlinear power flow behavior. The model can be trained end-to-end using modern deep learning frameworks by leveraging the implicit function theorem. Results demonstrate the framework's ability to significantly improve prediction accuracy, paving the way for more reliable and efficient power systems.</description>
      <guid isPermaLink="false">oai:arXiv.org:2504.01970v1</guid>
      <category>math.OC</category>
      <category>cs.AI</category>
      <category>cs.LG</category>
      <category>cs.SY</category>
      <category>eess.SY</category>
      <pubDate>Fri, 04 Apr 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Andrew Rosemberg, Michael Klamkin</dc:creator>
    </item>
    <item>
      <title>Distributed Multi-agent Coordination over Cellular Sheaves</title>
      <link>https://arxiv.org/abs/2504.02049</link>
      <description>arXiv:2504.02049v1 Announce Type: new 
Abstract: Techniques for coordination of multi-agent systems are vast and varied, often utilizing purpose-built solvers or controllers with tight coupling to the types of systems involved or the coordination goal. In this paper, we introduce a general unified framework for heterogeneous multi-agent coordination using the language of cellular sheaves and nonlinear sheaf Laplacians, which are generalizations of graphs and graph Laplacians. Specifically, we introduce the concept of a nonlinear homological program encompassing a choice of cellular sheaf on an undirected graph, nonlinear edge potential functions, and constrained convex node objectives. We use the alternating direction method of multipliers to derive a distributed optimization algorithm for solving these nonlinear homological programs. To demonstrate the wide applicability of this framework, we show how hybrid coordination goals including combinations of consensus, formation, and flocking can be formulated as nonlinear homological programs and provide numerical simulations showing the efficacy of our distributed solution algorithm.</description>
      <guid isPermaLink="false">oai:arXiv.org:2504.02049v1</guid>
      <category>math.OC</category>
      <category>cs.MA</category>
      <category>math.AT</category>
      <pubDate>Fri, 04 Apr 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Tyler Hanks, Hans Riess, Samuel Cohen, Trevor Gross, Matthew Hale, James Fairbanks</dc:creator>
    </item>
    <item>
      <title>Symmetry in linear physical systems</title>
      <link>https://arxiv.org/abs/2504.02062</link>
      <description>arXiv:2504.02062v1 Announce Type: new 
Abstract: Physical systems with symmetry arise abundantly in applications, and are endowed with interesting mathematical structures. The present paper focusses on linear reciprocal and input-output Hamiltonian systems. Their characterization is studied from an input-output as well as from a state point of view. Geometrically, it turns out that they both define Lagrangian subspaces with corresponding generating functionals. Furthermore, the relations with time reversibility are analyzed. The system classes under consideration are expected to admit scalable control laws, and to be important building blocks in design.</description>
      <guid isPermaLink="false">oai:arXiv.org:2504.02062v1</guid>
      <category>math.OC</category>
      <pubDate>Fri, 04 Apr 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Arjan van der Schaft, Rodolphe Sepulchre, Tom Chaffey</dc:creator>
    </item>
    <item>
      <title>On the threshold of excitable systems: An energy-based perspective</title>
      <link>https://arxiv.org/abs/2504.02171</link>
      <description>arXiv:2504.02171v1 Announce Type: new 
Abstract: A fundamental characteristic of excitable systems is their ability to exhibit distinct subthreshold and suprathreshold behaviors. Precisely quantifying this distinction requires a proper definition of the threshold, which has remained elusive in neurodynamics. In this paper, we introduce a novel, energy-based threshold definition for excitable circuits grounded in dissipativity theory, specifically using the classical concept of required supply. According to our definition, the threshold corresponds to a local maximum of the required supply, clearly separating subthreshold passive responses from suprathreshold regenerative spikes. We illustrate and validate the proposed definition through analytical and numerical studies of three canonical systems: a simple RC circuit, the FitzHugh--Nagumo model, and the biophysically detailed Hodgkin--Huxley model.</description>
      <guid isPermaLink="false">oai:arXiv.org:2504.02171v1</guid>
      <category>math.OC</category>
      <category>cs.SY</category>
      <category>eess.SY</category>
      <category>nlin.AO</category>
      <category>q-bio.NC</category>
      <pubDate>Fri, 04 Apr 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Rodolphe Sepulchre, Guanchun Tong</dc:creator>
    </item>
    <item>
      <title>Semidefinite Programming Duality in Infinite-Horizon Linear Quadratic Differential Games</title>
      <link>https://arxiv.org/abs/2504.02201</link>
      <description>arXiv:2504.02201v1 Announce Type: new 
Abstract: Semidefinite programs (SDPs) play a crucial role in control theory, traditionally as a computational tool. Beyond computation, the duality theory in convex optimization also provides valuable analytical insights and new proofs of classical results in control. In this work, we extend this analytical use of SDPs to study the infinite-horizon linear-quadratic (LQ) differential game in continuous time. Under standard assumptions, we introduce a new SDP-based primal-dual approach to establish the saddle point characterized by linear static policies in LQ games. For this, we leverage the Gramian representation technique, which elegantly transforms linear quadratic control problems into tractable convex programs. We also extend this duality-based proof to the $\mathcal{H}_\infty$ suboptimal control problem. To our knowledge, this work provides the first primal-dual analysis using Gramian representations for the LQ game and $\mathcal{H}_\infty$ control beyond LQ optimal control and $\mathcal{H}_\infty$ analysis.</description>
      <guid isPermaLink="false">oai:arXiv.org:2504.02201v1</guid>
      <category>math.OC</category>
      <pubDate>Fri, 04 Apr 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Yuto Watanabe, Chih-Fan Pai, Yang Zheng</dc:creator>
    </item>
    <item>
      <title>Traffic Flow Data Completion and Anomaly Diagnosis via Sparse and Low-Rank Tensor Optimization</title>
      <link>https://arxiv.org/abs/2504.02245</link>
      <description>arXiv:2504.02245v1 Announce Type: new 
Abstract: Spatiotemporal traffic time series, such as traffic speed data, collected from sensing systems are often incomplete, with considerable corruption and large amounts of missing values. A vast amount of data conceals implicit data structures, which poses significant challenges for data recovery issues, such as mining the potential spatio-temporal correlations of data and identifying abnormal data. In this paper, we propose a Tucker decomposition-based sparse low-rank high-order tensor optimization model (TSLTO) for data imputation and anomaly diagnosis. We decompose the traffic tensor data into low-rank and sparse tensors, and establish a sparse low-rank high-order tensor optimization model based on Tucker decomposition. By utilizing tools of non-smooth analysis for tensor functions, we explore the optimality conditions of the proposed tensor optimization model and design an ADMM optimization algorithm for solving the model. Finally, numerical experiments are conducted on both synthetic data and a real-world dataset: the urban traffic speed dataset of Guangzhou. Numerical comparisons with several representative existing algorithms demonstrate that our proposed approach achieves higher accuracy and efficiency in traffic flow data recovery and anomaly diagnosis tasks.</description>
      <guid isPermaLink="false">oai:arXiv.org:2504.02245v1</guid>
      <category>math.OC</category>
      <category>cs.NA</category>
      <category>math.NA</category>
      <pubDate>Fri, 04 Apr 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Junxi Man, Yumin Lin, Xiaoyu Li</dc:creator>
    </item>
    <item>
      <title>Riemannian Optimization for Sparse Tensor CCA</title>
      <link>https://arxiv.org/abs/2504.02339</link>
      <description>arXiv:2504.02339v1 Announce Type: new 
Abstract: Tensor canonical correlation analysis (TCCA) has received significant attention due to its ability to effectively preserve the geometric structure of high-order data. However, existing methods generally rely on tensor decomposition techniques with high computational complexity, which severely limits their application in large-scale datasets. In this paper, a modified method, TCCA-L, is proposed, which integrates sparse regularization and Laplacian regularization. An alternating manifold proximal gradient algorithm is designed based on Riemannian manifold theory. The algorithm avoids the traditional tensor decomposition and combines with the semi-smooth Newton algorithm to solve the subproblem, thus significantly improving the computational efficiency. Furthermore, the global convergence of the sequence generated by the algorithm is established, providing a solid theoretical foundation for its convergence. Numerical experiments demonstrate that TCCA-L outperforms traditional methods in both classification accuracy and running time.</description>
      <guid isPermaLink="false">oai:arXiv.org:2504.02339v1</guid>
      <category>math.OC</category>
      <pubDate>Fri, 04 Apr 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Yanjiao Zhu, Xianchao Xiu, Qilin Li</dc:creator>
    </item>
    <item>
      <title>A Comparative Study of MINLP and MPVC Formulations for Solving Complex Nonlinear Decision-Making Problems in Aerospace Applications</title>
      <link>https://arxiv.org/abs/2504.02375</link>
      <description>arXiv:2504.02375v1 Announce Type: new 
Abstract: High-level decision-making for dynamical systems often involves performance and safety specifications that are activated or deactivated depending on conditions related to the system state and commands. Such decision-making problems can be naturally formulated as optimization problems where these conditional activations are regulated by discrete variables. However, solving these problems can be challenging numerically, even on powerful computing platforms, especially when the dynamics are nonlinear. In this work, we consider decision-making for nonlinear systems where certain constraints, as well as possible terms in the cost function, are activated or deactivated depending on the system state and commands. We show that these problems can be formulated either as mixed-integer nonlinear programs (MINLPs) or as mathematical programs with vanishing constraints (MPVCs), where the former formulation involves discrete decision variables, whereas the latter relies on continuous variables subject to structured nonconvex constraints. We discuss the different solution methods available for both formulations and demonstrate them on optimal trajectory planning problems in various aerospace applications. Finally, we compare the strengths and weaknesses of the MINLP and MPVC approaches through a focused case study on powered descent guidance with divert-feasible regions.</description>
      <guid isPermaLink="false">oai:arXiv.org:2504.02375v1</guid>
      <category>math.OC</category>
      <category>cs.SY</category>
      <category>eess.SY</category>
      <pubDate>Fri, 04 Apr 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Andrea Ghezzi, Armin Nurkanovi\'c, Avishai Weiss, Moritz Diehl, Stefano Di Cairano</dc:creator>
    </item>
    <item>
      <title>Spectrum Assignment of Stochastic Systems with Multiplicative Noise</title>
      <link>https://arxiv.org/abs/2504.02562</link>
      <description>arXiv:2504.02562v1 Announce Type: new 
Abstract: This paper studies the spectrum assignment of a class of stochastic systems with multiplicative noise. A novel $\alpha$-spectrum assignment is proposed for discrete-time and continuous-time stochastic systems with multiplicative noise. In particular, $0$-spectrum assignment is equivalent to the pole assignment for the deterministic systems. The main contribution is two-fold: On the one hand, we present the conditions for $\alpha$-spectrum assignment and the design of feedback controllers based on the system parameters. On the other hand, when the system parameters are unknown, we present a stochastic approximation algorithm to learn the feedback gains which guarantee the spectrum of the stochastic systems to achieve the predetermined value. Numerical examples are provided to demonstrate the effectiveness of the proposed algorithms.</description>
      <guid isPermaLink="false">oai:arXiv.org:2504.02562v1</guid>
      <category>math.OC</category>
      <pubDate>Fri, 04 Apr 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Xiaomin Xue, Juanjuan Xu, Huanshui Zhang</dc:creator>
    </item>
    <item>
      <title>A Numerically Efficient Method to Enhance Model Predictive Control Performance with a Reinforcement Learning Policy</title>
      <link>https://arxiv.org/abs/2504.02710</link>
      <description>arXiv:2504.02710v1 Announce Type: new 
Abstract: We propose a novel approach for combining model predictive control (MPC) with reinforcement learning (RL) to reduce online computation while achieving high closed-loop tracking performance and constraint satisfaction. This method, called Policy-Enhanced Partial Tightening (PEPT), approximates the optimal value function through a Riccati recursion around a state-control trajectory obtained by evaluating the RL policy. The result is a convex quadratic terminal cost that can be seamlessly integrated into the MPC formulation. The proposed controller is tested in simulations on a trajectory tracking problem for a quadcopter with nonlinear dynamics and bounded state and control. The results highlight PEPT's effectiveness, outperforming both pure RL policies and several MPC variations. Compared to pure RL, PEPT achieves 1000 times lower constraint violation cost with only twice the feedback time. Against the best MPC-based policy, PEPT reduces constraint violations by 2 to 5 times and runs nearly 3 times faster while maintaining similar tracking performance. The code is open-source at www.github.com/aghezz1/pept.</description>
      <guid isPermaLink="false">oai:arXiv.org:2504.02710v1</guid>
      <category>math.OC</category>
      <pubDate>Fri, 04 Apr 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Andrea Ghezzi, Rudolf Reiter, Katrin Baumg\"artner, Alberto Bemporad, Moritz Diehl</dc:creator>
    </item>
    <item>
      <title>A Geometric Framework for Stochastic Iterations</title>
      <link>https://arxiv.org/abs/2504.02761</link>
      <description>arXiv:2504.02761v1 Announce Type: new 
Abstract: This paper concerns models and convergence principles for dealing with stochasticity in a wide range of algorithms arising in nonlinear analysis and optimization in Hilbert spaces. It proposes a flexible geometric framework within which existing solution methods can be recast and improved, and new ones can be designed. Almost sure weak, strong, and linear convergence results are established in particular for fixed point and feasibility problems. In these areas, the proposed algorithms exceed the features of the state of the art in several respects. Numerical applications to signal and image recovery are provided.</description>
      <guid isPermaLink="false">oai:arXiv.org:2504.02761v1</guid>
      <category>math.OC</category>
      <category>math.PR</category>
      <pubDate>Fri, 04 Apr 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Patrick L. Combettes, Javier I. Madariaga</dc:creator>
    </item>
    <item>
      <title>A Truncated Newton Method for Optimal Transport</title>
      <link>https://arxiv.org/abs/2504.02067</link>
      <description>arXiv:2504.02067v1 Announce Type: cross 
Abstract: Developing a contemporary optimal transport (OT) solver requires navigating trade-offs among several critical requirements: GPU parallelization, scalability to high-dimensional problems, theoretical convergence guarantees, empirical performance in terms of precision versus runtime, and numerical stability in practice. With these challenges in mind, we introduce a specialized truncated Newton algorithm for entropic-regularized OT. In addition to proving that locally quadratic convergence is possible without assuming a Lipschitz Hessian, we provide strategies to maximally exploit the high rate of local convergence in practice. Our GPU-parallel algorithm exhibits exceptionally favorable runtime performance, achieving high precision orders of magnitude faster than many existing alternatives. This is evidenced by wall-clock time experiments on 24 problem sets (12 datasets $\times$ 2 cost functions). The scalability of the algorithm is showcased on an extremely large OT problem with $n \approx 10^6$, solved approximately under weak entopric regularization.</description>
      <guid isPermaLink="false">oai:arXiv.org:2504.02067v1</guid>
      <category>cs.LG</category>
      <category>cs.MS</category>
      <category>math.OC</category>
      <pubDate>Fri, 04 Apr 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Mete Kemertas, Amir-massoud Farahmand, Allan D. Jepson</dc:creator>
    </item>
    <item>
      <title>Extending quantum annealing to continuous domains: a hybrid method for quadratic programming</title>
      <link>https://arxiv.org/abs/2504.02073</link>
      <description>arXiv:2504.02073v1 Announce Type: cross 
Abstract: We propose Quantum Enhanced Simulated Annealing (QESA), a novel hybrid optimization framework that integrates quantum annealing (QA) into simulated annealing (SA) to tackle continuous optimization problems. While QA has shown promise in solving binary problems such as those expressed in Ising or QUBO form, its direct applicability to real-valued domains remains limited. QESA bridges this gap by using QA to select discrete search directions that guide SA through the continuous solution space, enabling the use of quantum resources without requiring full problem discretization. We demonstrate QESA's effectiveness on box-constrained quadratic programming (QP) problems, a class of non-convex optimization tasks that frequently arise in practice. Experimental results show that QESA consistently outperforms classical baselines in solution quality, particularly on larger and more ill-conditioned problems, while maintaining competitive runtime. As quantum annealing hardware matures, QESA offers a scalable and flexible strategy for leveraging quantum capabilities in continuous optimization.</description>
      <guid isPermaLink="false">oai:arXiv.org:2504.02073v1</guid>
      <category>quant-ph</category>
      <category>cs.ET</category>
      <category>math.OC</category>
      <pubDate>Fri, 04 Apr 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Hristo N. Djidjev</dc:creator>
    </item>
    <item>
      <title>On Model Protection in Federated Learning against Eavesdropping Attacks</title>
      <link>https://arxiv.org/abs/2504.02114</link>
      <description>arXiv:2504.02114v1 Announce Type: cross 
Abstract: In this study, we investigate the protection offered by federated learning algorithms against eavesdropping adversaries. In our model, the adversary is capable of intercepting model updates transmitted from clients to the server, enabling it to create its own estimate of the model. Unlike previous research, which predominantly focuses on safeguarding client data, our work shifts attention protecting the client model itself. Through a theoretical analysis, we examine how various factors, such as the probability of client selection, the structure of local objective functions, global aggregation at the server, and the eavesdropper's capabilities, impact the overall level of protection. We further validate our findings through numerical experiments, assessing the protection by evaluating the model accuracy achieved by the adversary. Finally, we compare our results with methods based on differential privacy, underscoring their limitations in this specific context.</description>
      <guid isPermaLink="false">oai:arXiv.org:2504.02114v1</guid>
      <category>cs.CR</category>
      <category>cs.AI</category>
      <category>cs.LG</category>
      <category>cs.SY</category>
      <category>eess.SY</category>
      <category>math.OC</category>
      <category>stat.ML</category>
      <pubDate>Fri, 04 Apr 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Dipankar Maity, Kushal Chakrabarti</dc:creator>
    </item>
    <item>
      <title>Towards Enabling Learning for Time-Varying finite horizon Sequential Decision-Making Problems*</title>
      <link>https://arxiv.org/abs/2504.02129</link>
      <description>arXiv:2504.02129v1 Announce Type: cross 
Abstract: Parameterized Sequential Decision Making (Para-SDM) framework models a wide array of network design applications spanning supply-chain, transportation, and sensor networks. These problems entail sequential multi-stage optimization characterized by states, control actions, and cost functions dependent on designable parameters. The challenge is to determine both the sequential decision policy and parameters simultaneously to minimize cumulative stagewise costs. Many Para-SDM problems are NP-hard and often necessitate time-varying policies. Existing algorithms tackling finite-horizon time-varying Para-SDM problems struggle with scalability when faced with a large number of states. Conversely, the sole algorithm addressing infinite-horizon Para-SDM assumes time (stage)-invariance, yielding stationary policies. However, this approach proves scalable for time-invariant problems by leveraging deep neural networks to learn optimal stage-invariant state-action value functions, enabling handling of large-scale scenarios. This article proposes a novel approach that reinterprets finite-horizon, time-varying Para-SDM problems as equivalent time-invariant problems through topography lifting. Our method achieves nearly identical results to the time-varying solution while exhibiting improved performance times in various simulations, notably in the small cell network problem. This fresh perspective on Para-SDM problems expands the scope of addressable issues and holds promise for future scalability through the integration of learning methods.</description>
      <guid isPermaLink="false">oai:arXiv.org:2504.02129v1</guid>
      <category>eess.SY</category>
      <category>cs.SY</category>
      <category>math.CO</category>
      <category>math.OC</category>
      <pubDate>Fri, 04 Apr 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Dhananjay Tiwari, Salar Basiri, Srinivasa Salapaka</dc:creator>
    </item>
    <item>
      <title>Error Analysis of Sampling Algorithms for Approximating Stochastic Optimal Control</title>
      <link>https://arxiv.org/abs/2504.02198</link>
      <description>arXiv:2504.02198v1 Announce Type: cross 
Abstract: This paper is concerned with the error analysis of two types of sampling algorithms, namely model predictive path integral (MPPI) and an interacting particle system (\IPS) algorithm, that have been proposed in the literature for numerical approximation of the stochastic optimal control. The analysis is presented through the lens of Gibbs variational principle. For an illustrative example of a single-stage stochastic optimal control problem, analytical expressions for approximation error and scaling laws, with respect to the state dimension and sample size, are derived. The analytical results are illustrated with numerical simulations.</description>
      <guid isPermaLink="false">oai:arXiv.org:2504.02198v1</guid>
      <category>eess.SY</category>
      <category>cs.NA</category>
      <category>cs.SY</category>
      <category>math.NA</category>
      <category>math.OC</category>
      <pubDate>Fri, 04 Apr 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Anant A. Joshi, Amirhossein Taghvaei, Prashant G. Mehta</dc:creator>
    </item>
    <item>
      <title>The Spear and the Ring: Emergent Structures in Magnetic Colloidal Suspensions</title>
      <link>https://arxiv.org/abs/2504.02379</link>
      <description>arXiv:2504.02379v1 Announce Type: cross 
Abstract: We study from a mathematical point of view the nanoparticle model of a magnetic colloid, presented by G. Klughertz. Our objective is to obtain properties of stable stationary structures that arise in the long-time limit for the magnetic nanoparticles dynamics following this model. In this article, we present a detailed study of two specific structures using techniques from the calculus of variations. The first, called the spear, consists of a chain of aligned particles interacting via a Lennard-Jones potential. We establish existence and uniqueness results, derive bounds on the distances between neighboring particles, and provide a sharp asymptotic description as the number of particles tends to infinity. The second structure, the ring, features particles uniformly distributed along a circle. We prove its existence and uniqueness and derive an explicit formula for its radius.</description>
      <guid isPermaLink="false">oai:arXiv.org:2504.02379v1</guid>
      <category>math-ph</category>
      <category>math.MP</category>
      <category>math.OC</category>
      <pubDate>Fri, 04 Apr 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Rapha\"el C\^ote (IRMA, UNISTRA, USIAS), Cl\'ementine Court\`es (IRMA, UNISTRA), Guillaume Ferri\`ere (UL FST, Paradyse), Ludovic Godard-Cadillac (UB, IMB, Bordeaux INP), Yannick Privat (ENSMN, IECL, IUF)</dc:creator>
    </item>
    <item>
      <title>Solving the Paint Shop Problem with Flexible Management of Multi-Lane Buffers Using Reinforcement Learning and Action Masking</title>
      <link>https://arxiv.org/abs/2504.02644</link>
      <description>arXiv:2504.02644v1 Announce Type: cross 
Abstract: In the paint shop problem, an unordered incoming sequence of cars assigned to different colors has to be reshuffled with the objective of minimizing the number of color changes. To reshuffle the incoming sequence, manufacturers can employ a first-in-first-out multi-lane buffer system allowing store and retrieve operations. So far, prior studies primarily focused on simple decision heuristics like greedy or simplified problem variants that do not allow full flexibility when performing store and retrieve operations. In this study, we propose a reinforcement learning approach to minimize color changes for the flexible problem variant, where store and retrieve operations can be performed in an arbitrary order. After proving that greedy retrieval is optimal, we incorporate this finding into the model using action masking. Our evaluation, based on 170 problem instances with 2-8 buffer lanes and 5-15 colors, shows that our approach reduces color changes compared to existing methods by considerable margins depending on the problem size. Furthermore, we demonstrate the robustness of our approach towards different buffer sizes and imbalanced color distributions.</description>
      <guid isPermaLink="false">oai:arXiv.org:2504.02644v1</guid>
      <category>cs.LG</category>
      <category>math.OC</category>
      <pubDate>Fri, 04 Apr 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Mirko Stappert, Bernhard Lutz, Janis Brammer, Dirk Neumann</dc:creator>
    </item>
    <item>
      <title>Optimizing Resource Allocation to Mitigate the Risk of Disruptive Events in Homeland Security and Emergency Management</title>
      <link>https://arxiv.org/abs/2504.02652</link>
      <description>arXiv:2504.02652v1 Announce Type: cross 
Abstract: Homeland security in the United States faces a daunting task due to the multiple threats and hazards that can occur. Natural disasters, human-caused incidents such as terrorist attacks, and technological failures can result in significant damage, fatalities, injuries, and economic losses. The increasing frequency and severity of disruptive events in the United States highlight the urgent need for effectively allocating resources in homeland security and emergency preparedness. This article presents an optimization-based decision support model to help homeland security policymakers identify and select projects that best mitigate the risk of threats and hazards while satisfying a budget constraint. The model incorporates multiple hazards, probabilistic risk assessments, and multidimensional consequences and integrates historical data and publicly available sources to evaluate and select the most effective risk mitigation projects and optimize resource allocation across various disaster scenarios. We apply this model to the state of Iowa, considering 16 hazards, six types of consequences, and 52 mitigation projects. Our results demonstrate how different budget levels influence project selection, emphasizing cost-effective solutions that maximize risk reduction. Sensitivity analysis examines the robustness of project selection under varying effectiveness assumptions and consequence estimations. The findings offer critical insights for policymakers in homeland security and emergency management and provide a basis for more efficient resource allocation and improved disaster resilience.</description>
      <guid isPermaLink="false">oai:arXiv.org:2504.02652v1</guid>
      <category>cs.CY</category>
      <category>math.OC</category>
      <pubDate>Fri, 04 Apr 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Parastoo Akbari, Cameron A. MacKenzie</dc:creator>
    </item>
    <item>
      <title>Integrating Human Knowledge Through Action Masking in Reinforcement Learning for Operations Research</title>
      <link>https://arxiv.org/abs/2504.02662</link>
      <description>arXiv:2504.02662v1 Announce Type: cross 
Abstract: Reinforcement learning (RL) provides a powerful method to address problems in operations research. However, its real-world application often fails due to a lack of user acceptance and trust. A possible remedy is to provide managers with the possibility of altering the RL policy by incorporating human expert knowledge. In this study, we analyze the benefits and caveats of including human knowledge via action masking. While action masking has so far been used to exclude invalid actions, its ability to integrate human expertise remains underexplored. Human knowledge is often encapsulated in heuristics, which suggest reasonable, near-optimal actions in certain situations. Enforcing such actions should hence increase trust among the human workforce to rely on the model's decisions. Yet, a strict enforcement of heuristic actions may also restrict the policy from exploring superior actions, thereby leading to overall lower performance. We analyze the effects of action masking based on three problems with different characteristics, namely, paint shop scheduling, peak load management, and inventory management. Our findings demonstrate that incorporating human knowledge through action masking can achieve substantial improvements over policies trained without action masking. In addition, we find that action masking is crucial for learning effective policies in constrained action spaces, where certain actions can only be performed a limited number of times. Finally, we highlight the potential for suboptimal outcomes when action masks are overly restrictive.</description>
      <guid isPermaLink="false">oai:arXiv.org:2504.02662v1</guid>
      <category>cs.LG</category>
      <category>math.OC</category>
      <pubDate>Fri, 04 Apr 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Mirko Stappert, Bernhard Lutz, Niklas Goby, Dirk Neumann</dc:creator>
    </item>
    <item>
      <title>Centroidal Voronoi Tessellations as Electrostatic Equilibria: A Generalized Thomson Problem in Convex Domains</title>
      <link>https://arxiv.org/abs/2504.02700</link>
      <description>arXiv:2504.02700v1 Announce Type: cross 
Abstract: We present a variational framework in which Centroidal Voronoi Tessellations (CVTs) arise as local minimizers of a generalized electrostatic energy functional. By modeling interior point distributions in a convex domain as repelling charges balanced against a continuous boundary charge, we show that the resulting equilibrium configurations converge to CVT structures. We prove this by showing that CVTs minimize both the classical centroidal energy and the electrostatic potential, establishing a connection between geometric quantization and potential theory. Finally, we introduce a thermodynamic annealing scheme for global CVT optimization, rooted in Boltzmann statistics and random walk dynamics. By introducing a scheme for varying time steps (faster or slower cooling) we show that the set of minima of the centroid energy functional (and therefore the electrostatic potential) can be recovered. By recovering a set of generator locations corresponding to each minimum we can create a lattice continuation that allows for a customizable framework for individual minimum seeking.</description>
      <guid isPermaLink="false">oai:arXiv.org:2504.02700v1</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <category>math-ph</category>
      <category>math.MG</category>
      <category>math.MP</category>
      <category>math.OC</category>
      <pubDate>Fri, 04 Apr 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Zachary Mullaghy</dc:creator>
    </item>
    <item>
      <title>Sequential Binary Hypothesis Testing with Competing Agents under Information Asymmetry</title>
      <link>https://arxiv.org/abs/2504.02743</link>
      <description>arXiv:2504.02743v1 Announce Type: cross 
Abstract: This paper concerns sequential hypothesis testing in competitive multi-agent systems where agents exchange potentially manipulated information. Specifically, a two-agent scenario is studied where each agent aims to correctly infer the true state of nature while optimizing decision speed and accuracy. At each iteration, agents collect private observations, update their beliefs, and share (possibly corrupted) belief signals with their counterparts before deciding whether to stop and declare a state, or continue gathering more information. The analysis yields three main results: (1)~when agents share information strategically, the optimal signaling policy involves equal-probability randomization between truthful and inverted beliefs; (2)~agents maximize performance by relying solely on their own observations for belief updating while using received information only to anticipate their counterpart's stopping decision; and (3)~the agent reaching their confidence threshold first cause the other agent to achieve a higher conditional probability of error. Numerical simulations further demonstrate that agents with higher KL divergence in their conditional distributions gain competitive advantage. Furthermore, our results establish that information sharing -- despite strategic manipulation -- reduces overall system stopping time compared to non-interactive scenarios, which highlights the inherent value of communication even in this competitive setup.</description>
      <guid isPermaLink="false">oai:arXiv.org:2504.02743v1</guid>
      <category>eess.SY</category>
      <category>cs.MA</category>
      <category>cs.SY</category>
      <category>math.OC</category>
      <pubDate>Fri, 04 Apr 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Aneesh Raghavan, M. Umar B. Niazi, Karl H. Johansson</dc:creator>
    </item>
    <item>
      <title>On Composable and Parametric Uncertainty in Systems Co-Design</title>
      <link>https://arxiv.org/abs/2504.02766</link>
      <description>arXiv:2504.02766v1 Announce Type: cross 
Abstract: Optimizing the design of complex systems requires navigating interdependent decisions, heterogeneous components, and multiple objectives. Our monotone theory of co-design offers a compositional framework for addressing this challenge, modeling systems as Design Problems (DPs), representing trade-offs between functionalities and resources within partially ordered sets. While current approaches model uncertainty using intervals, capturing worst- and best-case bounds, they fail to express probabilistic notions such as risk and confidence. These limitations hinder the applicability of co-design in domains where uncertainty plays a critical role. In this paper, we introduce a unified framework for composable uncertainty in co-design, capturing intervals, distributions, and parametrized models. This extension enables reasoning about risk-performance trade-offs and supports advanced queries such as experiment design, learning, and multi-stage decision making. We demonstrate the expressiveness and utility of the framework via a numerical case study on the uncertainty-aware co-design of task-driven Unmanned Aerial Vehicle (UAV).</description>
      <guid isPermaLink="false">oai:arXiv.org:2504.02766v1</guid>
      <category>eess.SY</category>
      <category>cs.SY</category>
      <category>math.OC</category>
      <pubDate>Fri, 04 Apr 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Yujun Huang, Marius Furter, Gioele Zardini</dc:creator>
    </item>
    <item>
      <title>On Some Geometric Behavior of Value Iteration on the Orthant: Switching System Perspective</title>
      <link>https://arxiv.org/abs/2304.05597</link>
      <description>arXiv:2304.05597v4 Announce Type: replace 
Abstract: In this paper, the primary goal is to offer additional insights into the value iteration through the lens of switching system models in the control community. These models establish a connection between value iteration and switching system theory and reveal additional geometric behaviors of value iteration in solving discounted Markov decision problems. Specifically, the main contributions of this paper are twofold: 1) We provide a switching system model of value iteration and, based on it, offer a different proof for the contraction property of the value iteration. 2) Furthermore, from the additional insights, new geometric behaviors of value iteration are proven when the initial iterate lies in a special region. We anticipate that the proposed perspectives might have the potential to be a useful tool, applicable in various settings. Therefore, further development of these methods could be a valuable avenue for future research.</description>
      <guid isPermaLink="false">oai:arXiv.org:2304.05597v4</guid>
      <category>math.OC</category>
      <category>cs.SY</category>
      <category>eess.SY</category>
      <pubDate>Fri, 04 Apr 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Donghwan Lee</dc:creator>
    </item>
    <item>
      <title>Convex optimization over a probability simplex</title>
      <link>https://arxiv.org/abs/2305.09046</link>
      <description>arXiv:2305.09046v2 Announce Type: replace 
Abstract: We propose a new iteration scheme, the Cauchy-Simplex, to optimize convex problems over the probability simplex $\{w\in\mathbb{R}^n\ |\ \sum_i w_i=1\ \textrm{and}\ w_i\geq0\}$. Specifically, we map the simplex to the positive quadrant of a unit sphere, envisage gradient descent in latent variables, and map the result back in a way that only depends on the simplex variable. Moreover, proving rigorous convergence results in this formulation leads inherently to tools from information theory (e.g., cross-entropy and KL divergence). Each iteration of the Cauchy-Simplex consists of simple operations, making it well-suited for high-dimensional problems. In continuous time, we prove that $f(x_T)-f(x^*) = {O}(1/T)$ for differentiable real-valued convex functions, where $T$ is the number of time steps and $w^*$ is the optimal solution. Numerical experiments of projection onto convex hulls show faster convergence than similar algorithms. Finally, we apply our algorithm to online learning problems and prove the convergence of the average regret for (1) Prediction with expert advice and (2) Universal Portfolios.</description>
      <guid isPermaLink="false">oai:arXiv.org:2305.09046v2</guid>
      <category>math.OC</category>
      <category>cs.LG</category>
      <category>cs.NA</category>
      <category>math.NA</category>
      <category>q-fin.PM</category>
      <category>stat.ML</category>
      <pubDate>Fri, 04 Apr 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>James Chok, Geoffrey M. Vasil</dc:creator>
    </item>
    <item>
      <title>A discrete Consensus-Based Global Optimization Method with Noisy Objective Function</title>
      <link>https://arxiv.org/abs/2408.10078</link>
      <description>arXiv:2408.10078v2 Announce Type: replace 
Abstract: Consensus based optimization is a derivative-free particles-based method for the solution of global optimization problems. Several versions of the method have been proposed in the literature, and different convergence results have been proved. However, all existing results assume the objective function to be evaluated exactly at each iteration of the method. In this work, we extend the convergence analysis of a discrete-time CBO method to the case where only a noisy stochastic estimator of the objective function can be computed at a given point. In particular we prove that under suitable assumptions on the oracle's noise, the expected value of the mean squared distance of the particles from the solution can be made arbitrarily small in a finite number of iterations. Numerical experiments showing the impact of noise are also given.</description>
      <guid isPermaLink="false">oai:arXiv.org:2408.10078v2</guid>
      <category>math.OC</category>
      <pubDate>Fri, 04 Apr 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Stefania Bellavia, Greta Malaspina</dc:creator>
    </item>
    <item>
      <title>Analyzing the numerical correctness of branch-and-bound decisions for mixed-integer programming</title>
      <link>https://arxiv.org/abs/2412.14710</link>
      <description>arXiv:2412.14710v3 Announce Type: replace 
Abstract: Most state-of-the-art branch-and-bound solvers for mixed-integer linear programming rely on limited-precision floating-point arithmetic and use numerical tolerances when reasoning about feasibility and optimality during their search. While the practical success of floating-point MIP solvers bears witness to their overall numerical robustness, it is well-known that numerically challenging input can lead them to produce incorrect results. Even when their final answer is correct, one critical question remains: Were the individual decisions taken during branch-and-bound justified, i.e., can they be verified in exact arithmetic? In this paper, we attempt a first such a posteriori analysis of a pure LP-based branch-and-bound solver by checking all intermediate decisions critical to the correctness of the result: accepting solutions as integer feasible, declaring the LP relaxation infeasible, and pruning subtrees as subopti mal. Our computational study in the academic MIP solver SCIP confirms the expectation that in the overwhelming majority of cases, all decisions are correct. When errors do occur on numerically challenging instances, they typically affect only a small, typically single-digit, amount of leaf nodes that would require further processing.</description>
      <guid isPermaLink="false">oai:arXiv.org:2412.14710v3</guid>
      <category>math.OC</category>
      <pubDate>Fri, 04 Apr 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Alexander Hoen, Ambros Gleixner</dc:creator>
    </item>
    <item>
      <title>Solving Large Multicommodity Network Flow Problems on GPUs</title>
      <link>https://arxiv.org/abs/2501.17996</link>
      <description>arXiv:2501.17996v2 Announce Type: replace 
Abstract: We consider the all-pairs multicommodity network flow problem on a network with capacitated edges. The usual treatment keeps track of a separate flow for each source-destination pair on each edge; we rely on a more efficient formulation in which flows with the same destination are aggregated, reducing the number of variables by a factor equal to the size of the network. Problems with hundreds of nodes, with a total number of variables on the order of a million, can be solved using standard generic interior-point methods on CPUs; we focus on GPU-compatible algorithms that can solve such problems much faster, and in addition scale to much larger problems, with up to a billion variables. Our method relies on the primal-dual hybrid gradient algorithm, and exploits several specific features of the problem for efficient GPU computation. Numerical experiments show that our primal-dual multicommodity network flow method accelerates state of the art generic commercial solvers by $100\times$ to $1000\times$, and scales to problems that are much larger. We provide an open source implementation of our method.</description>
      <guid isPermaLink="false">oai:arXiv.org:2501.17996v2</guid>
      <category>math.OC</category>
      <pubDate>Fri, 04 Apr 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Fangzhao Zhang, Stephen Boyd</dc:creator>
    </item>
    <item>
      <title>Diffusion at Absolute Zero: Langevin Sampling Using Successive Moreau Envelopes [conference paper]</title>
      <link>https://arxiv.org/abs/2502.01358</link>
      <description>arXiv:2502.01358v2 Announce Type: replace 
Abstract: In this article we propose a novel method for sampling from Gibbs distributions of the form $\pi(x)\propto\exp(-U(x))$ with a potential $U(x)$. In particular, inspired by diffusion models we propose to consider a sequence $(\pi^{t_k})_k$ of approximations of the target density, for which $\pi^{t_k}\approx \pi$ for $k$ small and, on the other hand, $\pi^{t_k}$ exhibits favorable properties for sampling for $k$ large. This sequence is obtained by replacing parts of the potential $U$ by its Moreau envelopes. Sampling is performed in an Annealed Langevin type procedure, that is, sequentially sampling from $\pi^{t_k}$ for decreasing $k$, effectively guiding the samples from a simple starting density to the more complex target. In addition to a theoretical analysis we show experimental results supporting the efficacy of the method in terms of increased convergence speed and applicability to multi-modal densities $\pi$.</description>
      <guid isPermaLink="false">oai:arXiv.org:2502.01358v2</guid>
      <category>math.OC</category>
      <category>cs.CV</category>
      <category>cs.NA</category>
      <category>math.NA</category>
      <pubDate>Fri, 04 Apr 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Andreas Habring, Alexander Falk, Thomas Pock</dc:creator>
    </item>
    <item>
      <title>Characterizations of Tilt-Stable Local Minimizers of a Class of Matrix Optimization Problems</title>
      <link>https://arxiv.org/abs/2503.03217</link>
      <description>arXiv:2503.03217v2 Announce Type: replace 
Abstract: Tilt stability plays a pivotal role in understanding how local solutions of an optimization problem respond to small, targeted perturbations of the objective. Although quadratic bundles are a powerful tool for capturing second-order variational behavior, their characterization remains incomplete beyond well-known polyhedral and certain specialized nonpolyhedral settings. To help bridge this gap, we propose a new point-based criterion for tilt stability in prox-regular, subdifferentially continuous functions by exploiting the notion of minimal quadratic bundles. Furthermore, we derive an explicit formula for the minimal quadratic bundle associated with a broad class of general spectral functions, thus providing a practical and unifying framework that significantly extends existing results and offers broader applicability in matrix optimization problems.</description>
      <guid isPermaLink="false">oai:arXiv.org:2503.03217v2</guid>
      <category>math.OC</category>
      <pubDate>Fri, 04 Apr 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Chao Ding, Ebrahim Sarabi, Shiwei Wang</dc:creator>
    </item>
    <item>
      <title>A strongly polynomial-time algorithm for the general linear programming problem</title>
      <link>https://arxiv.org/abs/2503.12041</link>
      <description>arXiv:2503.12041v2 Announce Type: replace 
Abstract: This article presents a strongly polynomial-time algorithm for the general linear programming problem. This algorithm is an implicit reduction procedure that works as follows. Primal and dual problems are combined into a special system of linear equations constrained by complementarity relations and non-negative variables. Each iteration of the algorithm consists of applying a pair of complementary Gauss-Jordan pivoting operations, guided by a necessary-condition lemma. The algorithm requires no more than k+n iterations, as there are only k+n complementary pairs of columns to compare one-pair-at-a-time, where k is the number of constraints and n is the number of variables of given general linear programming problem. Numerical illustration is given that includes an instance of a classical problem of Klee and Minty and a problem of Beale.</description>
      <guid isPermaLink="false">oai:arXiv.org:2503.12041v2</guid>
      <category>math.OC</category>
      <pubDate>Fri, 04 Apr 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Samuel Awoniyi</dc:creator>
    </item>
    <item>
      <title>Extremum Seeking with High-Order Lie Bracket Approximations: Achieving Exponential Decay Rate</title>
      <link>https://arxiv.org/abs/2504.01136</link>
      <description>arXiv:2504.01136v2 Announce Type: replace 
Abstract: This paper focuses on the further development of the Lie bracket approximation approach for extremum seeking systems. Classical results in this area provide extremum seeking algorithms with exponential convergence rates for quadratic-like cost functions, and polynomial decay rates for cost functions of higher degrees. This paper proposes a novel control design approach that ensures the motion of the extremum seeking system along directions associated with higher-order Lie brackets, thereby ensuring exponential convergence for cost functions that are polynomial-like but with degree greater than two.</description>
      <guid isPermaLink="false">oai:arXiv.org:2504.01136v2</guid>
      <category>math.OC</category>
      <category>math.DS</category>
      <pubDate>Fri, 04 Apr 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Victoria Grushkovskaya, Sameh A. Eisa</dc:creator>
    </item>
    <item>
      <title>On Distributed Larger-Than-Memory Subset Selection With Pairwise Submodular Functions</title>
      <link>https://arxiv.org/abs/2402.16442</link>
      <description>arXiv:2402.16442v3 Announce Type: replace-cross 
Abstract: Modern datasets span billions of samples, making training on all available data infeasible. Selecting a high quality subset helps in reducing training costs and enhancing model quality. Submodularity, a discrete analogue of convexity, is commonly used for solving such subset selection problems. However, existing algorithms for optimizing submodular functions are sequential, and the prior distributed methods require at least one central machine to fit the target subset in DRAM. At billion datapoint scale, even the subset may not fit a single machine, and the sequential algorithms are prohibitively slow. In this paper, we relax the requirement of having a central machine for the target subset by proposing a novel distributed bounding algorithm with provable approximation guarantees. The algorithm iteratively bounds the minimum and maximum utility values to select high quality points and discard the unimportant ones. When bounding does not find the complete subset, we use a multi-round, partition-based distributed greedy algorithm to identify the remaining subset. We discuss how to implement these algorithms in a distributed data processing framework and empirically analyze different configurations. We find high quality subsets on CIFAR-100 and ImageNet with marginal or no loss in quality compared to centralized methods, and scale to a dataset with 13 billion points.</description>
      <guid isPermaLink="false">oai:arXiv.org:2402.16442v3</guid>
      <category>cs.LG</category>
      <category>cs.AI</category>
      <category>cs.CV</category>
      <category>cs.DC</category>
      <category>math.OC</category>
      <pubDate>Fri, 04 Apr 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Maximilian B\"other, Abraham Sebastian, Pranjal Awasthi, Ana Klimovic, Srikumar Ramalingam</dc:creator>
    </item>
    <item>
      <title>Generalised rank-constrained approximations of Hilbert-Schmidt operators on separable Hilbert spaces and applications</title>
      <link>https://arxiv.org/abs/2408.05104</link>
      <description>arXiv:2408.05104v3 Announce Type: replace-cross 
Abstract: In this work we solve, for given bounded operators $B,C$ and Hilbert-Schmidt operator $M$ acting on potentially infinite-dimensional separable Hilbert spaces, the reduced rank approximation problem, $\min\{\lVert M-BXC\rVert_{L_2}:\ \text{dim ran}\ X\leq r\}.$ This extends the result of Sondermann (Statistische Hefte, 1986) and Friedland and Torokhti (SIAM J. Matrix Analysis and Applications, 2007), which studies this problem in the case of matrices $M$, $B$, $C$, $X$, and the analysis involves the Moore-Penrose inverse. In classical approximation problems that can be solved by the singular value decomposition or Moore-Penrose inverse, the solution satisfies a minimal norm property. Friedland and Torokhti state such a minimal norm property of the solution. We show that this minimal norm property does not hold in general and give a modified minimality property that does hold. We show that the solution may be discontinuous in infinite-dimensional settings. We give conditions for continuity of the solutions and construct continuous approximations when such conditions are not met. Finally, we study problems from signal processing, reduced rank regression and linear operator learning under a rank constraint. Our theoretical results enable us to explicitly find solutions to these problems and to characterise their existence, uniqueness and minimality property.</description>
      <guid isPermaLink="false">oai:arXiv.org:2408.05104v3</guid>
      <category>math.FA</category>
      <category>math.OC</category>
      <pubDate>Fri, 04 Apr 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Giuseppe Carere, Han Cheng Lie</dc:creator>
    </item>
    <item>
      <title>Parallel Tempering-Inspired Distributed Binary Optimization with In-Memory Computing</title>
      <link>https://arxiv.org/abs/2409.09152</link>
      <description>arXiv:2409.09152v4 Announce Type: replace-cross 
Abstract: In-memory computing (IMC) has been shown to be a promising approach for solving binary optimization problems while significantly reducing energy and latency. Building on the advantages of parallel computation, we propose an IMC-compatible parallelism framework based on the physics-inspired parallel tempering (PT) algorithm, enabling cross-replica communication to improve the performance of IMC solvers. This framework enables an IMC solver not only to improve performance beyond what can be achieved through parallelization, but also affords greater flexibility for the search process with low hardware overhead. We justify that the framework can be applied to almost any IMC solver. We demonstrate the effectiveness of the framework for the Boolean satisfiability (SAT) problem, using the WalkSAT heuristic as a proxy for existing IMC solvers. The resulting PT-inspired cooperative WalkSAT (PTIC-WalkSAT) algorithm outperforms the standard WalkSAT heuristic in terms of the iterations-to-solution in 84.0% of the tested problem instances and its na\"ive parallel variant (PA-WalkSAT) does so in 64.9% of the instances, and with a higher success rate in the majority of instances. An estimate of the energy overhead of the PTIC framework for two hardware accelerator architectures indicates that in both cases the overhead of running the PTIC framework would be less than 1% of the total energy required to run each accelerator.</description>
      <guid isPermaLink="false">oai:arXiv.org:2409.09152v4</guid>
      <category>cs.ET</category>
      <category>cs.AR</category>
      <category>math.OC</category>
      <pubDate>Fri, 04 Apr 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Xiangyi Zhang, Fabian B\"ohm, Elisabetta Valiante, Moslem Noori, Thomas Van Vaerenbergh, Chan-Woo Yang, Giacomo Pedretti, Masoud Mohseni, Raymond Beausoleil, Ignacio Rozada</dc:creator>
    </item>
    <item>
      <title>Optimization of partially isolated quantum harmonic oscillator memory systems by mean square decoherence time criteria</title>
      <link>https://arxiv.org/abs/2409.15720</link>
      <description>arXiv:2409.15720v2 Announce Type: replace-cross 
Abstract: This paper is concerned with open quantum harmonic oscillators with position-momentum system variables, whose internal dynamics and interaction with the environment are governed by linear quantum stochastic differential equations. A recently proposed approach to such systems as Heisenberg picture quantum memories exploits their ability to approximately retain initial conditions over a decoherence horizon. Using the quantum memory decoherence time defined previously in terms of a fidelity threshold on a weighted mean-square deviation of the system variables from their initial values, we apply this approach to a partially isolated subsystem of the oscillator, which is not directly affected by the external fields. The partial isolation leads to an appropriate system decomposition and a qualitatively different short-horizon asymptotic behaviour of the deviation, which yields a longer decoherence time in the high-fidelity limit. The resulting approximate decoherence time maximization over the energy parameters for improving the quantum memory performance is discussed for a coherent feedback interconnection of such systems.</description>
      <guid isPermaLink="false">oai:arXiv.org:2409.15720v2</guid>
      <category>quant-ph</category>
      <category>cs.SY</category>
      <category>eess.SY</category>
      <category>math.OC</category>
      <pubDate>Fri, 04 Apr 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Igor G. Vladimirov, Ian R. Petersen</dc:creator>
    </item>
    <item>
      <title>L4acados: Learning-based models for acados, applied to Gaussian process-based predictive control</title>
      <link>https://arxiv.org/abs/2411.19258</link>
      <description>arXiv:2411.19258v2 Announce Type: replace-cross 
Abstract: Incorporating learning-based models, such as artificial neural networks or Gaussian processes, into model predictive control (MPC) strategies can significantly improve control performance and online adaptation capabilities for real-world applications. Still, enabling state-of-the-art implementations of learning-based models for MPC is complicated by the challenge of interfacing machine learning frameworks with real-time optimal control software. This work aims at filling this gap by incorporating external sensitivities in sequential quadratic programming solvers for nonlinear optimal control. To this end, we provide L4acados, a general framework for incorporating Python-based residual models in the real-time optimal control software acados. By computing external sensitivities via a user-defined Python module, L4acados enables the implementation of MPC controllers with learning-based residual models in acados, while supporting parallelization of sensitivity computations when preparing the quadratic subproblems. We demonstrate significant speed-ups and superior scaling properties of L4acados compared to available software using a neural-network-based control example. Last, we provide an efficient and modular real-time implementation of Gaussian process-based MPC using L4acados, which is applied to two hardware examples: autonomous miniature racing, as well as motion control of a full-scale autonomous vehicle for an ISO lane change maneuver.</description>
      <guid isPermaLink="false">oai:arXiv.org:2411.19258v2</guid>
      <category>eess.SY</category>
      <category>cs.SY</category>
      <category>math.OC</category>
      <pubDate>Fri, 04 Apr 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Amon Lahr, Joshua N\"af, Kim P. Wabersich, Jonathan Frey, Pascal Siehl, Andrea Carron, Moritz Diehl, Melanie N. Zeilinger</dc:creator>
    </item>
    <item>
      <title>Representation and Regression Problems in Neural Networks: Relaxation, Generalization, and Numerics</title>
      <link>https://arxiv.org/abs/2412.01619</link>
      <description>arXiv:2412.01619v2 Announce Type: replace-cross 
Abstract: In this work, we address three non-convex optimization problems associated with the training of shallow neural networks (NNs) for exact and approximate representation, as well as for regression tasks. Through a mean-field approach, we convexify these problems and, applying a representer theorem, prove the absence of relaxation gaps. We establish generalization bounds for the resulting NN solutions, assessing their predictive performance on test datasets and, analyzing the impact of key hyperparameters on these bounds, propose optimal choices.
  On the computational side, we examine the discretization of the convexified problems and derive convergence rates. For low-dimensional datasets, these discretized problems are efficiently solvable using the simplex method. For high-dimensional datasets, we propose a sparsification algorithm that, combined with gradient descent for over-parameterized shallow NNs, yields effective solutions to the primal problems.</description>
      <guid isPermaLink="false">oai:arXiv.org:2412.01619v2</guid>
      <category>cs.LG</category>
      <category>math.OC</category>
      <pubDate>Fri, 04 Apr 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Kang Liu, Enrique Zuazua</dc:creator>
    </item>
    <item>
      <title>Processes on Wasserstein spaces and energy-minimizing particle representations in fractional Sobolev spaces</title>
      <link>https://arxiv.org/abs/2503.10859</link>
      <description>arXiv:2503.10859v2 Announce Type: replace-cross 
Abstract: Given a probability-measure-valued process $(\mu_t)$, we aim to find, among all path-continuous stochastic processes whose one-dimensional time marginals coincide almost surely with $(\mu_t)$ (if there is any), a process that minimizes a given energy in expectation. Building on our recent study (arXiv:2502.12068), where the minimization of fractional Sobolev energy was investigated for deterministic paths on Wasserstein spaces, we now extend the results to the stochastic setting to address some applications that originally motivated our study. Two applications are given. We construct minimizing particle representations for processes on Wasserstein spaces on $\mathbb{R}$ with H\"{o}lder regularity, using optimal transportation. We prove the existence of minimizing particle representations for solutions to stochastic Fokker--Planck--Kolmogorov equations on $\mathbb{R}^\mathrm{d}$ satisfying an integrability condition, using the stochastic superposition principle of Lacker--Shkolnikov--Zhang (J. Eur. Math. Soc. 25, 3229--3288 (2023)).</description>
      <guid isPermaLink="false">oai:arXiv.org:2503.10859v2</guid>
      <category>math.PR</category>
      <category>math.OC</category>
      <pubDate>Fri, 04 Apr 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Ehsan Abedi</dc:creator>
    </item>
  </channel>
</rss>
