<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>eess.SP updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/eess.SP</link>
    <description>eess.SP updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/eess.SP" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Tue, 26 Nov 2024 04:05:38 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Mon, 25 Nov 2024 00:00:00 -0500</pubDate>
    <skipDays>
      <day>Saturday</day>
      <day>Sunday</day>
    </skipDays>
    <item>
      <title>Industrial Machines Health Prognosis using a Transformer-based Framework</title>
      <link>https://arxiv.org/abs/2411.14443</link>
      <description>arXiv:2411.14443v1 Announce Type: new 
Abstract: This article introduces Transformer Quantile Regression Neural Networks (TQRNNs), a novel data-driven solution for real-time machine failure prediction in manufacturing contexts. Our objective is to develop an advanced predictive maintenance model capable of accurately identifying machine system breakdowns. To do so, TQRNNs employ a two-step approach: (i) a modified quantile regression neural network to segment anomaly outliers while maintaining low time complexity, and (ii) a concatenated transformer network aimed at facilitating accurate classification even within a large timeframe of up to one hour. We have implemented our proposed pipeline in a real-world beverage manufacturing industry setting. Our findings demonstrate the model's effectiveness, achieving an accuracy rate of 70.84% with a 1-hour lead time for predicting machine breakdowns. Additionally, our analysis shows that using TQRNNs can increase high-quality production, improving product yield from 78.38% to 89.62%. We believe that predictive maintenance assumes a pivotal role in modern manufacturing, minimizing unplanned downtime, reducing repair costs, optimizing production efficiency, and ensuring operational stability. Its potential to generate substantial cost savings while enhancing sustainability and competitiveness underscores its importance in contemporary manufacturing practices.</description>
      <guid isPermaLink="false">oai:arXiv.org:2411.14443v1</guid>
      <category>eess.SP</category>
      <category>cs.LG</category>
      <pubDate>Mon, 25 Nov 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>David J Poland, Lemuel Puglisi, Daniele Ravi</dc:creator>
    </item>
    <item>
      <title>Past, Present, and Future of Sensor-based Human Activity Recognition using Wearables: A Surveying Tutorial on a Still Challenging Task</title>
      <link>https://arxiv.org/abs/2411.14452</link>
      <description>arXiv:2411.14452v1 Announce Type: new 
Abstract: In the many years since the inception of wearable sensor-based Human Activity Recognition (HAR), a wide variety of methods have been introduced and evaluated for their ability to recognize activities. Substantial gains have been made since the days of hand-crafting heuristics as features, yet, progress has seemingly stalled on many popular benchmarks, with performance falling short of what may be considered 'sufficient'-- despite the increase in computational power and scale of sensor data, as well as rising complexity in techniques being employed. The HAR community approaches a new paradigm shift, this time incorporating world knowledge from foundational models. In this paper, we take stock of sensor-based HAR -- surveying it from its beginnings to the current state of the field, and charting its future. This is accompanied by a hands-on tutorial, through which we guide practitioners in developing HAR systems for real-world application scenarios. We provide a compendium for novices and experts alike, of methods that aim at finally solving the activity recognition problem.</description>
      <guid isPermaLink="false">oai:arXiv.org:2411.14452v1</guid>
      <category>eess.SP</category>
      <category>cs.LG</category>
      <pubDate>Mon, 25 Nov 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Harish Haresamudram, Chi Ian Tang, Sungho Suh, Paul Lukowicz, Thomas Ploetz</dc:creator>
    </item>
    <item>
      <title>mmWave Radar for Sit-to-Stand Analysis: A Comparative Study with Wearables and Kinect</title>
      <link>https://arxiv.org/abs/2411.14656</link>
      <description>arXiv:2411.14656v1 Announce Type: new 
Abstract: This study explores a novel approach for analyzing Sit-to-Stand (STS) movements using millimeter-wave (mmWave) radar technology. The goal is to develop a non-contact sensing, privacy-preserving, and all-day operational method for healthcare applications, including fall risk assessment. We used a 60GHz mmWave radar system to collect radar point cloud data, capturing STS motions from 45 participants. By employing a deep learning pose estimation model, we learned the human skeleton from Kinect built-in body tracking and applied Inverse Kinematics (IK) to calculate joint angles, segment STS motions, and extract commonly used features in fall risk assessment. Radar extracted features were then compared with those obtained from Kinect and wearable sensors. The results demonstrated the effectiveness of mmWave radar in capturing general motion patterns and large joint movements (e.g., trunk). Additionally, the study highlights the advantages and disadvantages of individual sensors and suggests the potential of integrated sensor technologies to improve the accuracy and reliability of motion analysis in clinical and biomedical research settings.</description>
      <guid isPermaLink="false">oai:arXiv.org:2411.14656v1</guid>
      <category>eess.SP</category>
      <category>cs.ET</category>
      <category>stat.AP</category>
      <pubDate>Mon, 25 Nov 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Shuting Hu, Peggy Ackun, Xiang Zhang, Siyang Cao, Jennifer Barton, Melvin G. Hector, Mindy J. Fain, Nima Toosizadeh</dc:creator>
    </item>
    <item>
      <title>Fast High-Quality Enhanced Imaging Algorithm for Layered Dielectric Targets Based on MMW MIMO-SAR System</title>
      <link>https://arxiv.org/abs/2411.14837</link>
      <description>arXiv:2411.14837v1 Announce Type: new 
Abstract: Millimeter-wave (MMW) multiple-input multiple-output synthetic aperture radar (MIMO-SAR) system is a technology that can achieve high resolution, high frame rate, and all-weather imaging and has received extensive attention in the non-destructive testing and internal imaging applications of layered dielectric targets. However, the non-ideal scattering effect caused by dielectric materials can significantly deteriorate the imaging quality when using the existing MIMO-SAR fast algorithms. This paper proposes a rapid, high-quality dielectric target-enhanced imaging algorithm for a new universal non-uniform MIMO-SAR system. The algorithm builds on the existing non-uniform MIMO-SAR dielectric target frequency-domain algorithm (DT-FDA) by constructing a forward sensing operator and incorporating it into the alternating direction method of multipliers (ADMM) framework. This approach avoids large matrix operations while maintaining computational efficiency. By integrating an optimal regularization parameter search, the algorithm enhances the image reconstruction quality of dielectric internal structures or defects. Experimental results show the proposed algorithm outperforms IBP and DT-FDA, achieving better focusing, sidelobe suppression, and 3D imaging accuracy. It yields the lowest image entropy (8.864) and significantly improves efficiency (imaging time: 15.29 s vs. 23295.3 s for IBP).</description>
      <guid isPermaLink="false">oai:arXiv.org:2411.14837v1</guid>
      <category>eess.SP</category>
      <pubDate>Mon, 25 Nov 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Xu Chen, Guangsheng Yu, Zhian Yuan, Hao Wu, Yilin Jiang, Ying Wang, Bin Deng, Limin Guo</dc:creator>
    </item>
    <item>
      <title>CardioLab: Laboratory Values Estimation and Monitoring from Electrocardiogram Signals -- A Multimodal Deep Learning Approach</title>
      <link>https://arxiv.org/abs/2411.14886</link>
      <description>arXiv:2411.14886v1 Announce Type: new 
Abstract: Background: Laboratory values are fundamental to medical diagnosis and management, but acquiring these values can be costly, invasive, and time-consuming. While electrocardiogram (ECG) patterns have been linked to certain laboratory abnormalities, the comprehensive modeling of these relationships remains underexplored.
  Methods: We utilize MIMIC-IV dataset to develop multimodal deep-learning models to demonstrate the feasibility of estimating (real-time) and monitoring (predict at future intervals) laboratory value abnormalities from ECG waveforms, demographics, biometrics, and vital signs.
  Results: The models exhibit a strong predictive performance with AUROC scores above 0.70 in a statistically significant manner for 23 laboratory values in the estimation setting and up to 26 values in the monitoring setting. Most notably, the accurately predictable values encompassing abnormalities across diverse physiological categories such as cardiac, renal, hematological, metabolic, immunological and coagulation. To name examples, for estimation NTproBNP (&gt;353 pg/mL) with 0.882, whereas for monitoring at 30 minutes Urea nitrogen (&lt;6 mg/dL) with 0.851, at 60 minutes creatinine (&lt;0.5 mg/dL) with 0.85, and at 120 minutes hemoglobin (&gt;17.5 g/dL) with 0.821.
  Conclusions: This study provides first evidence for the feasibility of using ECG data alongside clinical routine data for the real-time estimation and monitoring of laboratory value abnormalities, which could provide a non-invasive, cost-effective supplement to traditional laboratory testing, with strong implications for enhanced patient monitoring and early intervention. Further validation could facilitate their integration into routine clinical practice.</description>
      <guid isPermaLink="false">oai:arXiv.org:2411.14886v1</guid>
      <category>eess.SP</category>
      <category>cs.LG</category>
      <pubDate>Mon, 25 Nov 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Juan Miguel Lopez Alcaraz, Nils Strodthoff</dc:creator>
    </item>
    <item>
      <title>Resolution-Adaptive Micro-Doppler Spectrogram for Human Activity Recognition</title>
      <link>https://arxiv.org/abs/2411.15057</link>
      <description>arXiv:2411.15057v1 Announce Type: new 
Abstract: The rising demand for remote-sensing systems for detecting hazardous situations has led to increased interest in radar-based human activity recognition (HAR). Conventional radar-based HAR methods predominantly rely on micro-Doppler spectrograms for recognition tasks. However, spectrograms frequently fail to effectively capture micro-Doppler signatures because of their limited linear resolution. To address this limitation, we propose a time--frequency domain representation method that adaptively adjusts the resolution based on activity characteristics. This approach nonlinearly transforms the resolution to focus on the most relevant frequency range for micro-Doppler signatures. We validate the proposed method by training deep-learning-based HAR models on datasets generated using the adaptive representation method. Experimental results demonstrate that the models trained using the proposed method achieve superior recognition accuracy compared with those trained using conventional methods.</description>
      <guid isPermaLink="false">oai:arXiv.org:2411.15057v1</guid>
      <category>eess.SP</category>
      <pubDate>Mon, 25 Nov 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Do-Hyun Park, Min-Wook Jeon, Hyoung-Nam Kim</dc:creator>
    </item>
    <item>
      <title>Efficient Radar Modulation Recognition via a Noise-Aware Ensemble Neural Network</title>
      <link>https://arxiv.org/abs/2411.15104</link>
      <description>arXiv:2411.15104v1 Announce Type: new 
Abstract: Electronic warfare support (ES) systems intercept adversary radar signals and estimate various types of signal information, including modulation schemes. The accurate and rapid identification of modulation schemes under conditions of very low signal power remains a significant challenge for ES systems. This paper proposes a recognition model based on a noise-aware ensemble learning (NAEL) framework to efficiently recognize radar modulation schemes in noisy environments. The NAEL framework evaluates the influence of noise on recognition and adaptively selects an appropriate neural network structure, offering significant advantages in terms of computational efficiency and recognition performance. Furthermore, we employ feature extraction blocks to enhance the efficiency of the proposed recognition model. We present the analysis results of the recognition performance of the proposed model based on experimental data. Our recognition model demonstrates superior recognition accuracy with low computational complexity compared to conventional classification models.</description>
      <guid isPermaLink="false">oai:arXiv.org:2411.15104v1</guid>
      <category>eess.SP</category>
      <pubDate>Mon, 25 Nov 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Do-Hyun Park, Min-Wook Jeon, Jinwoo Jeong, Isaac Sim, Sangbom Yun, Junghyun Seo, Hyoung-Nam Kim</dc:creator>
    </item>
    <item>
      <title>Performance Analysis of Traditional and Network Coded Transmission in Infrastructure-less Multi-hop Wireless Networks</title>
      <link>https://arxiv.org/abs/2411.14539</link>
      <description>arXiv:2411.14539v1 Announce Type: cross 
Abstract: Infrastructure-less Multi-hop Wireless Networks are the backbone for mission critical communications such as in disaster and battlefield scenarios. However, interference signals in the wireless channel cause losses to transmission in wireless networks resulting in a reduced network throughput and making efficient transmission very challenging. Therefore, techniques to overcome interference and increase transmission efficiency have been a hot area of research for decades. In this paper two methods for transmitting data through infrastructure-less multi hop wireless networks, Traditional (TR) and Network Coded (NC) transmission are thoroughly examined for scenarios having one or two communication streams in a network. The study has developed network models in MATLAB for each transmission technique and scenario. The simulation results showed that the NC transmission method yielded a better throughput under the same network settings and physical interference. Furthermore, the impact of increasing numbers of hops between source and destination on the network capacity and the communications latency was also observed and conclusions were drawn.</description>
      <guid isPermaLink="false">oai:arXiv.org:2411.14539v1</guid>
      <category>cs.NI</category>
      <category>eess.SP</category>
      <pubDate>Mon, 25 Nov 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Muhammad Ali, Alister Burr</dc:creator>
    </item>
    <item>
      <title>DNN based Two-stage Compensation Algorithm for THz Hybrid Beamforming with imperfect Hardware</title>
      <link>https://arxiv.org/abs/2411.14699</link>
      <description>arXiv:2411.14699v1 Announce Type: cross 
Abstract: Terahertz (THz) communication is envisioned as a key technology for 6G and beyond wireless systems owing to its multi-GHz bandwidth. To maintain the same aperture area and the same link budget as the lower frequencies, ultra-massive multi-input and multi-output (UM-MIMO) with hybrid beamforming is promising. Nevertheless, the hardware imperfections particularly at THz frequencies, can degrade spectral efficiency and lead to a high symbol error rate (SER), which is often overlooked yet imperative to address in practical THz communication systems. In this paper, the hybrid beamforming is investigated for THz UM-MIMO systems accounting for comprehensive hardware imperfections, including DAC and ADC quantization errors, in-phase and quadrature imbalance (IQ imbalance), phase noise, amplitude and phase error of imperfect phase shifters and power amplifier (PA) nonlinearity. Then, a two-stage hardware imperfection compensation algorithm is proposed. A deep neural network (DNN) is developed in the first stage to represent the combined hardware imperfections, while in the second stage, the digital precoder in the transmitter (Tx) or the combiner in the receiver (Rx) is designed using NN to effectively compensate for these imperfections. Furthermore, to balance the performance and network complexity, three slimming methods including pruning, parameter sharing, and removing parts of the network are proposed and combined to slim the DNN in the first stage. Numerical results show that the Tx compensation can perform better than the Rx compensation. Additionally, using the combined slimming methods can reduce parameters by 97.2% and running time by 39.2% while maintaining nearly the same performance in both uncoded and coded systems.</description>
      <guid isPermaLink="false">oai:arXiv.org:2411.14699v1</guid>
      <category>cs.IT</category>
      <category>eess.SP</category>
      <category>math.IT</category>
      <pubDate>Mon, 25 Nov 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Wenqi Zhao, Chong Han, Ho-Jin Song, Emil Bj\"ornson</dc:creator>
    </item>
    <item>
      <title>Scalable Wavelength Arbitration for Microring-based DWDM Transceivers</title>
      <link>https://arxiv.org/abs/2411.14810</link>
      <description>arXiv:2411.14810v1 Announce Type: cross 
Abstract: This paper introduces the concept of autonomous microring arbitration, or \textit{wavelength arbitration}, to address the challenge of multi-microring initialization in microring-based Dense-Wavelength-Division-Multiplexed (DWDM) transceivers. This arbitration is inherently policy-driven, defining critical system characteristics such as the spectral ordering of microrings. Furthermore, to facilitate large-scale deployment, the arbitration algorithms must operate independently of specific wavelength information and be resilient to system variability. Addressing these complexities requires a holistic approach that encompasses the entire system, from device-level variabilities to the transceiver interface - this system-wide perspective is the focus of this paper. To support efficient analysis, we develop a hierarchical framework incorporating an ideal, wavelength-aware arbitration model to examine arbitration failures at both the policy and algorithmic levels. The effectiveness of this approach is demonstrated in two ways: by analyzing the robustness of each policy in relation to device variabilities, and by developing an algorithm that achieves near-perfect alignment with the ideal model, offering superior robustness compared to the traditional sequential tuning method. The simulator code used in this paper is available at \url{https://github.com/wdmsim/wdm-simulator}.</description>
      <guid isPermaLink="false">oai:arXiv.org:2411.14810v1</guid>
      <category>cs.AR</category>
      <category>eess.SP</category>
      <pubDate>Mon, 25 Nov 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Sunjin Choi, Vladimir Stojanovi\'c</dc:creator>
    </item>
    <item>
      <title>Random Permutation Codes: Lossless Source Coding of Non-Sequential Data</title>
      <link>https://arxiv.org/abs/2411.14879</link>
      <description>arXiv:2411.14879v1 Announce Type: cross 
Abstract: This thesis deals with the problem of communicating and storing non-sequential data. We investigate this problem through the lens of lossless source coding, also sometimes referred to as lossless compression, from both an algorithmic and information-theoretic perspective.
  Lossless compression algorithms typically preserve the ordering in which data points are compressed. However, there are data types where order is not meaningful, such as collections of files, rows in a database, nodes in a graph, and, notably, datasets in machine learning applications.
  Compressing with traditional algorithms is possible if we pick an order for the elements and communicate the corresponding ordered sequence. However, unless the order information is somehow removed during the encoding process, this procedure will be sub-optimal, because the order contains information and therefore more bits are used to represent the source than are truly necessary.
  In this work we give a formal definition for non-sequential objects as random sets of equivalent sequences, which we refer to as Combinatorial Random Variables (CRVs). The definition of equivalence, formalized as an equivalence relation, establishes the non-sequential data type represented by the CRV. The achievable rates of CRVs is fully characterized as a function of the equivalence relation as well as the data distribution.
  The optimal rates of CRVs are achieved within the family of Random Permutation Codes (RPCs) developed in later chapters. RPCs randomly select one-of-many possible sequences that can represent the instance of the CRV. Specialized RPCs are given for the case of multisets, graphs, and partitions/clusterings, providing new algorithms for compression of databases, social networks, and web data in the JSON file format.</description>
      <guid isPermaLink="false">oai:arXiv.org:2411.14879v1</guid>
      <category>cs.IT</category>
      <category>eess.SP</category>
      <category>math.IT</category>
      <pubDate>Mon, 25 Nov 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Daniel Severo</dc:creator>
    </item>
    <item>
      <title>Optimal Beamforming for Multi-User Continuous Aperture Array (CAPA) Systems</title>
      <link>https://arxiv.org/abs/2411.14919</link>
      <description>arXiv:2411.14919v1 Announce Type: cross 
Abstract: The optimal beamforming design for multi-user continuous aperture array (CAPA) systems is proposed. In contrast to conventional spatially discrete array (SPDA), the beamformer for CAPA is a continuous function rather than a discrete vector or matrix, rendering beamforming optimization a non-convex integral-based functional programming. To address this challenging issue, we first derive the closed-form optimal structure of the CAPA beamformer for maximizing generic system utility functions, by using the Lagrangian duality and the calculus of variations. The derived optimal structure is a linear combination of the continuous channel responses for CAPA, with the linear weights determined by the channel correlations. As a further advance, a monotonic optimization method is proposed for obtaining globally optimal CAPA beamforming based on the derived optimal structure. More particularly, a closed-form fixed-point iteration is proposed to obtain the globally optimal solution to the power minimization problem for CAPA beamforming. Furthermore, based on the optimal structure, the low-complexity maximum ratio transmission (MRT), zero-forcing (ZF), and minimum mean-squared error (MMSE) designs for CAPA beamforming are derived. It is theoretically proved that: 1) the MRT and ZF designs are asymptotically optimal in low and high signal-to-noise ratio (SNR) regimes, respectively, and 2) the MMSE design is optimal for signal-to-leakage-plus-noise ratio (SLNR) maximization. Our numerical results validate the effectiveness of the proposed designs and reveal that: i) CAPA achieves significant communication performance gain over SPDA, and ii) the MMSE design achieves nearly optimal performance in most cases, while the MRT and ZF designs achieve nearly optimal performance in specific cases.</description>
      <guid isPermaLink="false">oai:arXiv.org:2411.14919v1</guid>
      <category>cs.IT</category>
      <category>eess.SP</category>
      <category>math.IT</category>
      <pubDate>Mon, 25 Nov 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Zhaolin Wang, Chongjun Ouyang, Yuanwei Liu</dc:creator>
    </item>
    <item>
      <title>Multipath Mitigation Technology-integrated GNSS Direct Position Estimation Plug-in Module</title>
      <link>https://arxiv.org/abs/2411.13339</link>
      <description>arXiv:2411.13339v2 Announce Type: replace 
Abstract: Direct position estimation (DPE) is an effective solution to the MP issue at the signal processing level. Unlike two-step positioning (2SP) receivers, DPE directly solves for the receiver position, velocity, and time (PVT) in the navigation domain, without the estimation of intermediate measurements, thus allowing it to provide more robust and accurate PVT estimates in the presence of multipath (MP) and weak signals. But GNSS positioning with DPE is mostly left unapplied commercially, and continuing research into DPE has remained relatively stagnant over the past few years. To encourage further research on DPE by the GNSS community, we propose a DPE plug-in module that can be integrated into the conventional 2SP software-defined receivers (SDRs). Programmed in MATLAB, the proposed DPE plug-in module is aimed for better understanding and familiarity of a practical implementation of DPE. Its plug-in module architecture allows it to be incorporated with 2SP MATLAB SDRs, both vector tracking and scalar tracking with minimum changes, making it easy to use, and provides greater flexibility for researchers using various 2SP SDRs. Since the proposed DPE implementation makes use of tracking observables from 2SP to propagate the channel, we propose to further improve the performance of DPE against MP through using MP-compensated observables generated from Multipath Mitigation Technology (MMT)-aided tracking. Referred to as Multipath Mitigation Technology (MMT)-integrated DPE, it is proposed as a variant of DPE that is better suit for urban environment applications. Results show that while in MP-only conditions, an MMT-integrated 2SP has similar performance with MMT-integrated DPE, the proposed MMT-integrated DPE manages to show great superiority against non-line-of-sight (NLOS), making it the preferable option for applications in urban environments.</description>
      <guid isPermaLink="false">oai:arXiv.org:2411.13339v2</guid>
      <category>eess.SP</category>
      <pubDate>Mon, 25 Nov 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Sergio Vicenzo, Bing Xu</dc:creator>
    </item>
    <item>
      <title>A Deep-Generative Hybrid Model to Integrate Multimodal and Dynamic Connectivity for Predicting Spectrum-Level Deficits in Autism</title>
      <link>https://arxiv.org/abs/2007.01931</link>
      <description>arXiv:2007.01931v2 Announce Type: replace-cross 
Abstract: We propose an integrated deep-generative framework, that jointly models complementary information from resting-state functional MRI (rs-fMRI) connectivity and diffusion tensor imaging (DTI) tractography to extract predictive biomarkers of a disease. The generative part of our framework is a structurally-regularized Dynamic Dictionary Learning (sr-DDL) model that decomposes the dynamic rs-fMRI correlation matrices into a collection of shared basis networks and time varying patient-specific loadings. This matrix factorization is guided by the DTI tractography matrices to learn anatomically informed connectivity profiles. The deep part of our framework is an LSTM-ANN block, which models the temporal evolution of the patient sr-DDL loadings to predict multidimensional clinical severity. Our coupled optimization procedure collectively estimates the basis networks, the patient-specific dynamic loadings, and the neural network weights. We validate our framework on a multi-score prediction task in 57 patients diagnosed with Autism Spectrum Disorder (ASD). Our hybrid model outperforms state-of-the-art baselines in a five-fold cross validated setting and extracts interpretable multimodal neural signatures of brain dysfunction in ASD.</description>
      <guid isPermaLink="false">oai:arXiv.org:2007.01931v2</guid>
      <category>cs.LG</category>
      <category>eess.SP</category>
      <category>stat.ML</category>
      <pubDate>Mon, 25 Nov 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Niharika Shimona D'Souza, Mary Beth Nebel, Deana Crocetti, Nicholas Wymbs, Joshua Robinson, Stewart Mostofsky, Archana Venkataraman</dc:creator>
    </item>
    <item>
      <title>A Joint Network Optimization Framework to Predict Clinical Severity from Resting State Functional MRI Data</title>
      <link>https://arxiv.org/abs/2009.03238</link>
      <description>arXiv:2009.03238v2 Announce Type: replace-cross 
Abstract: We propose a novel optimization framework to predict clinical severity from resting state fMRI (rs-fMRI) data. Our model consists of two coupled terms. The first term decomposes the correlation matrices into a sparse set of representative subnetworks that define a network manifold. These subnetworks are modeled as rank-one outer-products which correspond to the elemental patterns of co-activation across the brain; the subnetworks are combined via patient-specific non-negative coefficients. The second term is a linear regression model that uses the patient-specific coefficients to predict a measure of clinical severity. We validate our framework on two separate datasets in a ten fold cross validation setting. The first is a cohort of fifty-eight patients diagnosed with Autism Spectrum Disorder (ASD). The second dataset consists of sixty three patients from a publicly available ASD database. Our method outperforms standard semi-supervised frameworks, which employ conventional graph theoretic and statistical representation learning techniques to relate the rs-fMRI correlations to behavior. In contrast, our joint network optimization framework exploits the structure of the rs-fMRI correlation matrices to simultaneously capture group level effects and patient heterogeneity. Finally, we demonstrate that our proposed framework robustly identifies clinically relevant networks characteristic of ASD.</description>
      <guid isPermaLink="false">oai:arXiv.org:2009.03238v2</guid>
      <category>q-bio.NC</category>
      <category>cs.LG</category>
      <category>eess.SP</category>
      <category>stat.ML</category>
      <pubDate>Mon, 25 Nov 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Niharika Shimona D'Souza, Mary Beth Nebel, Nicholas Wymbs, Stewart H. Mostofsky, Archana Venkataraman</dc:creator>
    </item>
    <item>
      <title>Scalable-Complexity Steered Response Power Mapping based on Low-Rank and Sparse Interpolation</title>
      <link>https://arxiv.org/abs/2306.08514</link>
      <description>arXiv:2306.08514v2 Announce Type: replace-cross 
Abstract: The steered response power (SRP) is a popular approach to compute a map of the acoustic scene, typically used for acoustic source localization. The SRP map is obtained as the frequency-weighted output power of a beamformer steered towards a grid of candidate locations. Due to the exhaustive search over a fine grid at all frequency bins, conventional frequency domain-based SRP (conv. FD-SRP) results in a high computational complexity. Time domain-based SRP (conv. TD-SRP) implementations reduce computational complexity at the cost of accuracy using the inverse fast Fourier transform (iFFT). In this paper, to enable a more favourable complexity-performance trade-off as compared to conv. FD-SRP and conv. TD-SRP, we consider the problem of constructing a fine SRP map over the entire search space at scalable computational cost. We propose two approaches to this problem. Expressing the conv. FD-SRP map as a matrix transform of frequency-domain GCCs, we decompose the SRP matrix into a sampling matrix and an interpolation matrix. While sampling can be implemented by the iFFT, we propose to use optimal low-rank or sparse approximations of the interpolation matrix for complexity reduction. The proposed approaches, refered to as sampling + low-rank interpolation-based SRP (SLRI-SRP) and sampling + sparse interpolation-based SRP (SSPI-SRP), are evaluated in various localization scenarios with speech as source signals and compared to the state-of-the-art. The results indicate that SSPI-SRP performs better if large array apertures are used, while SLRI-SRP performs better at small array apertures or a large number of microphones. In comparison to conv. FD-SRP, two to three orders of magnitude of complexity reduction can achieved, often times enabling a more favourable complexity-performance trade-off as compared to conv. TD-SRP. A MATLAB implementation is available online.</description>
      <guid isPermaLink="false">oai:arXiv.org:2306.08514v2</guid>
      <category>eess.AS</category>
      <category>eess.SP</category>
      <pubDate>Mon, 25 Nov 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <arxiv:DOI>10.1109/TASLP.2024.3496317</arxiv:DOI>
      <arxiv:journal_reference>IEEE/ACM Trans. Audio, Speech, Lang. Process., 2024</arxiv:journal_reference>
      <dc:creator>Thomas Dietzen, Enzo De Sena, Toon van Waterschoot</dc:creator>
    </item>
    <item>
      <title>EchoScan: Scanning Complex Room Geometries via Acoustic Echoes</title>
      <link>https://arxiv.org/abs/2310.11728</link>
      <description>arXiv:2310.11728v4 Announce Type: replace-cross 
Abstract: Accurate estimation of indoor space geometries is vital for constructing precise digital twins, whose broad industrial applications include navigation in unfamiliar environments and efficient evacuation planning, particularly in low-light conditions. This study introduces EchoScan, a deep neural network model that utilizes acoustic echoes to perform room geometry inference. Conventional sound-based techniques rely on estimating geometry-related room parameters such as wall position and room size, thereby limiting the diversity of inferable room geometries. Contrarily, EchoScan overcomes this limitation by directly inferring room floorplan maps and height maps, thereby enabling it to handle rooms with complex shapes, including curved walls. The segmentation task for predicting floorplan and height maps enables the model to leverage both low- and high-order reflections. The use of high-order reflections further allows EchoScan to infer complex room shapes when some walls of the room are unobservable from the position of an audio device. Herein, EchoScan was trained and evaluated using RIRs synthesized from complex environments, including the Manhattan and Atlanta layouts, employing a practical audio device configuration compatible with commercial, off-the-shelf devices.</description>
      <guid isPermaLink="false">oai:arXiv.org:2310.11728v4</guid>
      <category>cs.SD</category>
      <category>eess.AS</category>
      <category>eess.SP</category>
      <pubDate>Mon, 25 Nov 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <arxiv:DOI>10.1109/TASLP.2024.3485516</arxiv:DOI>
      <arxiv:journal_reference>in IEEE/ACM Transactions on Audio, Speech, and Language Processing, vol. 32, pp. 4768-4782, 2024</arxiv:journal_reference>
      <dc:creator>Inmo Yeon, Iljoo Jeong, Seungchul Lee, Jung-Woo Choi</dc:creator>
    </item>
    <item>
      <title>Understanding Generalizability of Diffusion Models Requires Rethinking the Hidden Gaussian Structure</title>
      <link>https://arxiv.org/abs/2410.24060</link>
      <description>arXiv:2410.24060v4 Announce Type: replace-cross 
Abstract: In this work, we study the generalizability of diffusion models by looking into the hidden properties of the learned score functions, which are essentially a series of deep denoisers trained on various noise levels. We observe that as diffusion models transition from memorization to generalization, their corresponding nonlinear diffusion denoisers exhibit increasing linearity. This discovery leads us to investigate the linear counterparts of the nonlinear diffusion models, which are a series of linear models trained to match the function mappings of the nonlinear diffusion denoisers. Surprisingly, these linear denoisers are approximately the optimal denoisers for a multivariate Gaussian distribution characterized by the empirical mean and covariance of the training dataset. This finding implies that diffusion models have the inductive bias towards capturing and utilizing the Gaussian structure (covariance information) of the training dataset for data generation. We empirically demonstrate that this inductive bias is a unique property of diffusion models in the generalization regime, which becomes increasingly evident when the model's capacity is relatively small compared to the training dataset size. In the case that the model is highly overparameterized, this inductive bias emerges during the initial training phases before the model fully memorizes its training data. Our study provides crucial insights into understanding the notable strong generalization phenomenon recently observed in real-world diffusion models.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.24060v4</guid>
      <category>cs.LG</category>
      <category>cs.CV</category>
      <category>eess.IV</category>
      <category>eess.SP</category>
      <pubDate>Mon, 25 Nov 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <dc:creator>Xiang Li, Yixiang Dai, Qing Qu</dc:creator>
    </item>
  </channel>
</rss>
