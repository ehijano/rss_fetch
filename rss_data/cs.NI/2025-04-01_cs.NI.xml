<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>cs.NI updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/cs.NI</link>
    <description>cs.NI updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/cs.NI" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Tue, 01 Apr 2025 04:00:11 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Tue, 01 Apr 2025 00:00:00 -0400</pubDate>
    <skipDays>
      <day>Saturday</day>
      <day>Sunday</day>
    </skipDays>
    <item>
      <title>Globus Service Enhancements for Exascale Applications and Facilities</title>
      <link>https://arxiv.org/abs/2503.22981</link>
      <description>arXiv:2503.22981v1 Announce Type: new 
Abstract: Many extreme-scale applications require the movement of large quantities of data to, from, and among leadership computing facilities, as well as other scientific facilities and the home institutions of facility users. These applications, particularly when leadership computing facilities are involved, can touch upon edge cases (e.g., terabyte files) that had not been a focus of previous Globus optimization work, which had emphasized rather the movement of many smaller (megabyte to gigabyte) files. We report here on how automated client-driven chunking can be used to accelerate both the movement of large files and the integrity checking operations that have proven to be essential for large data transfers. We present detailed performance studies that provide insights into the benefits of these modifications in a range of file transfer scenarios.</description>
      <guid isPermaLink="false">oai:arXiv.org:2503.22981v1</guid>
      <category>cs.NI</category>
      <pubDate>Tue, 01 Apr 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <arxiv:DOI>10.1177/10943420241281744</arxiv:DOI>
      <dc:creator>Weijian Zheng, Jack Kordas, Tyler J. Skluzacek, Raj Kettimuthu, Ian Foster</dc:creator>
    </item>
    <item>
      <title>PartialLoading: User Scheduling and Bandwidth Allocation for Parameter-sharing Edge Inference</title>
      <link>https://arxiv.org/abs/2503.22982</link>
      <description>arXiv:2503.22982v1 Announce Type: new 
Abstract: By provisioning inference offloading services, edge inference drives the rapid growth of AI applications at the network edge. However, achieving high task throughput with stringent latency requirements remains a significant challenge. To address this issue, we develop a parameter-sharing AI model loading (PartialLoading) framework for multi-user edge inference, which exploits two key insights: 1) the majority of latency arises from loading AI models into server GPU memory, and 2) different AI models can share a significant number of parameters, for which redundant loading should be avoided. Towards this end, we formulate a joint multi-user scheduling and spectrum bandwidth allocation problem to maximize task throughput by exploiting shared parameter blocks across models. The intuition is to judiciously schedule user requests to reuse the shared parameter blocks between consecutively loaded models, thereby reducing model loading time substantially. To facilitate solution finding, we decouple the problem into two sub-problems, i.e., user scheduling and bandwidth allocation, showing that solving them sequentially is equivalent to solving the original problem. Due to the NP-hardness of the problem, we first study an important special case called the "bottom-layer-sharing" case, where AI models share some bottom layers within clusters, and design a dynamic programming-based algorithm to obtain the optimal solution in polynomial time. For the general case, where shared parameter blocks appear at arbitrary positions within AI models, we propose a greedy heuristic to obtain the sub-optimal solution efficiently. Simulation results demonstrate that the proposed framework significantly improves task throughput under deadline constraints compared with user scheduling without exploiting parameter sharing.</description>
      <guid isPermaLink="false">oai:arXiv.org:2503.22982v1</guid>
      <category>cs.NI</category>
      <category>cs.AI</category>
      <pubDate>Tue, 01 Apr 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Guanqiao Qu, Qian Chen, Xianhao Chen, Kaibin Huang, Yuguang Fang</dc:creator>
    </item>
    <item>
      <title>Novel Closed Loop Control Mechanism for Zero Touch Networks using BiLSTM and Q-Learning</title>
      <link>https://arxiv.org/abs/2503.23000</link>
      <description>arXiv:2503.23000v1 Announce Type: new 
Abstract: As networks advance toward the Sixth Generation (6G), management of high-speed and ubiquitous connectivity poses major challenges in meeting diverse Service Level Agreements (SLAs). The Zero Touch Network (ZTN) framework has been proposed to automate and optimize network management tasks. It ensures SLAs are met effectively even during dynamic network conditions. Though, ZTN literature proposes closed-loop control, methods for implementing such a mechanism remain largely unexplored. This paper proposes a novel two-stage closedloop control for ZTN to optimize the network continuously. First, an XGBoosted Bidirectional Long Short Term Memory (BiLSTM) model is trained to predict the network state (in terms of bandwidth). In the second stage, the Q-learning algorithm selects actions based on the predicted network state to optimize Quality of Service (QoS) parameters. By selecting appropriate actions, it serves the applications perpetually within the available resource limits in a closed loop. Considering the scenario of network congestion, with available bandwidth as state and traffic shaping options as an action for mitigation, results show that the proposed closed-loop mechanism can adjust to changing network conditions. Simulation results show that the proposed mechanism achieves 95% accuracy in matching the actual network state by selecting the appropriate action based on the predicted state.</description>
      <guid isPermaLink="false">oai:arXiv.org:2503.23000v1</guid>
      <category>cs.NI</category>
      <pubDate>Tue, 01 Apr 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Tamizhelakkiya K, Dibakar Das, Jyotsna Bapat, Debabrata Das, Komal Sharma</dc:creator>
    </item>
    <item>
      <title>LAURA: LLM-Assisted UAV Routing for AoI Minimization</title>
      <link>https://arxiv.org/abs/2503.23132</link>
      <description>arXiv:2503.23132v1 Announce Type: new 
Abstract: With the rapid growth of the low-altitude economy, there is increasing demand for real-time data collection using UAV-assisted wireless sensor networks. This paper investigates the problem of minimizing the age of information (AoI) in UAV-assisted wireless sensor networks by optimizing the UAV flight routing. We formulate the AoI minimization task and propose a large language model (LLM)-assisted UAV routing algorithm (LAURA). LAURA employs an LLM as intelligent crossover operators within an evolutionary optimization framework to efficiently explore the solution space. Simulation results show that LAURA outperforms benchmark methods in reducing the maximum AoI, especially in scenarios with a large number of sensor nodes.</description>
      <guid isPermaLink="false">oai:arXiv.org:2503.23132v1</guid>
      <category>cs.NI</category>
      <category>cs.IT</category>
      <category>math.IT</category>
      <pubDate>Tue, 01 Apr 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Bisheng Wei, Ruichen Zhang, Ruihong Jiang, Mugen Peng, Dusit Niyato</dc:creator>
    </item>
    <item>
      <title>Efficient Twin Migration in Vehicular Metaverses: Multi-Agent Split Deep Reinforcement Learning with Spatio-Temporal Trajectory Generation</title>
      <link>https://arxiv.org/abs/2503.23290</link>
      <description>arXiv:2503.23290v1 Announce Type: new 
Abstract: Vehicle Twins (VTs) as digital representations of vehicles can provide users with immersive experiences in vehicular metaverse applications, e.g., Augmented Reality (AR) navigation and embodied intelligence. VT migration is an effective way that migrates the VT when the locations of physical entities keep changing to maintain seamless immersive VT services. However, an efficient VT migration is challenging due to the rapid movement of vehicles, dynamic workloads of Roadside Units (RSUs), and heterogeneous resources of the RSUs. To achieve efficient migration decisions and a minimum latency for the VT migration, we propose a multi-agent split Deep Reinforcement Learning (DRL) framework combined with spatio-temporal trajectory generation. In this framework, multiple split DRL agents utilize split architecture to efficiently determine VT migration decisions. Furthermore, we propose a spatio-temporal trajectory generation algorithm based on trajectory datasets and road network data to simulate vehicle trajectories, enhancing the generalization of the proposed scheme for managing VT migration in dynamic network environments. Finally, experimental results demonstrate that the proposed scheme not only enhances the Quality of Experience (QoE) by 29% but also reduces the computational parameter count by approximately 25% while maintaining similar performances, enhancing users' immersive experiences in vehicular metaverses.</description>
      <guid isPermaLink="false">oai:arXiv.org:2503.23290v1</guid>
      <category>cs.NI</category>
      <pubDate>Tue, 01 Apr 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Junlong Chen, Jiawen Kang, Minrui Xu, Fan Wu, Hongliang Zhang, Huawei Huang, Dusit Niyato, Shiwen Mao</dc:creator>
    </item>
    <item>
      <title>Convexity and Optimization in Deficit Round Robin Scheduling for Delay-Constrained Systems</title>
      <link>https://arxiv.org/abs/2503.23366</link>
      <description>arXiv:2503.23366v1 Announce Type: new 
Abstract: The Deficit Round Robin (DRR) scheduler is widely used in network systems for its simplicity and fairness. However, configuring its integer-valued parameters, known as quanta, to meet stringent delay constraints remains a significant challenge. This paper addresses this issue by demonstrating the convexity of the feasible parameter set for a two-flow DRR system under delay constraints. The analysis is then extended to n-flow systems, uncovering key structural properties that guide parameter selection. Additionally, we propose an optimization method to maximize the number of packets served in a round while satisfying delay constraints. The effectiveness of this approach is validated through numerical simulations, providing a practical framework for enhancing DRR scheduling. These findings offer valuable insights into resource allocation strategies for maintaining Quality of Service (QoS) standards in network slicing environments.</description>
      <guid isPermaLink="false">oai:arXiv.org:2503.23366v1</guid>
      <category>cs.NI</category>
      <pubDate>Tue, 01 Apr 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Aniket Mukherjee, Joy Kuri, Chandramani Singh</dc:creator>
    </item>
    <item>
      <title>Semantic Communication for the Internet of Space: New Architecture, Challenges, and Future Vision</title>
      <link>https://arxiv.org/abs/2503.23446</link>
      <description>arXiv:2503.23446v1 Announce Type: new 
Abstract: The expansion of sixth-generation (6G) wireless networks into space introduces technical challenges that conventional bit-oriented communication approaches cannot efficiently address, including intermittent connectivity, severe latency, limited bandwidth, and constrained onboard resources. To overcome these limitations, semantic communication has emerged as a transformative paradigm, shifting the communication focus from transmitting raw data to delivering context-aware, missionrelevant information. In this article, we propose a semantic communication architecture explicitly tailored for the 6G Internet of Space (IoS), integrating multi-modal semantic processing, AIdriven semantic encoding and decoding, and adaptive transmission mechanisms optimized for space environments. The effectiveness of our proposed framework is demonstrated through a representative deep-space scenario involving semantic-based monitoring of Mars dust storms. Finally, we outline open research challenges and discuss future directions toward realizing practical semantic-enabled IoS systems.</description>
      <guid isPermaLink="false">oai:arXiv.org:2503.23446v1</guid>
      <category>cs.NI</category>
      <category>cs.IT</category>
      <category>eess.SP</category>
      <category>math.IT</category>
      <pubDate>Tue, 01 Apr 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Hanlin Cai, Houtianfu Wang, Haofan Dong, Ozgur B. Akan</dc:creator>
    </item>
    <item>
      <title>Multi-Agent Deep Reinforcement Learning for Optimized Multi-UAV Coverage and Power-Efficient UE Connectivity</title>
      <link>https://arxiv.org/abs/2503.23669</link>
      <description>arXiv:2503.23669v1 Announce Type: new 
Abstract: In critical situations such as natural disasters, network outages, battlefield communication, or large-scale public events, Unmanned Aerial Vehicles (UAVs) offer a promising approach to maximize wireless coverage for affected users in the shortest possible time. In this paper, we propose a novel framework where multiple UAVs are deployed with the objective to maximize the number of served user equipment (UEs) while ensuring a predefined data rate threshold. UEs are initially clustered using a K-means algorithm, and UAVs are optimally positioned based on the UEs' spatial distribution. To optimize power allocation and mitigate inter-cluster interference, we employ the Multi-Agent Deep Deterministic Policy Gradient (MADDPG) algorithm, considering both LOS and NLOS fading. Simulation results demonstrate that our method significantly enhances UEs coverage and outperforms Deep Q-Network (DQN) and equal power distribution methods, improving their UE coverage by up to 2.07 times and 8.84 times, respectively.</description>
      <guid isPermaLink="false">oai:arXiv.org:2503.23669v1</guid>
      <category>cs.NI</category>
      <pubDate>Tue, 01 Apr 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Xuli Cai, Poonam Lohan, Burak Kantarci</dc:creator>
    </item>
    <item>
      <title>Blockchain for Federated Learning in the Internet of Things: Trustworthy Adaptation, Standards, and the Road Ahead</title>
      <link>https://arxiv.org/abs/2503.23823</link>
      <description>arXiv:2503.23823v1 Announce Type: new 
Abstract: As edge computing gains prominence in Internet of Things (IoTs), smart cities, and autonomous systems, the demand for real-time machine intelligence with low latency and model reliability continues to grow. Federated Learning (FL) addresses these needs by enabling distributed model training without centralizing user data, yet it remains reliant on centralized servers and lacks built-in mechanisms for transparency and trust. Blockchain and Distributed Ledger Technologies (DLTs) can fill this gap by introducing immutability, decentralized coordination, and verifiability into FL workflows. This article presents current standardization efforts from 3GPP, ETSI, ITU-T, IEEE, and O-RAN that steer the integration of FL and blockchain in IoT ecosystems. We then propose a blockchain-based FL framework that replaces the centralized aggregator, incorporates reputation monitoring of IoT devices, and minimizes overhead via selective on-chain storage of model updates. We validate our approach with IOTA Tangle, demonstrating stable throughput and block confirmations, even under increasing FL workloads. Finally, we discuss architectural considerations and future directions for embedding trustworthy and resource-efficient FL in emerging 6G networks and vertical IoT applications. Our results underscore the potential of DLT-enhanced FL to meet stringent trust and energy requirements of next-generation IoT deployments.</description>
      <guid isPermaLink="false">oai:arXiv.org:2503.23823v1</guid>
      <category>cs.NI</category>
      <pubDate>Tue, 01 Apr 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Farhana Javed, Engin Zeydan, Josep Mangues-Bafalluy, Kapal Dev, Luis Blanco</dc:creator>
    </item>
    <item>
      <title>Robust Predictive Routing for Internet of Vehicles Leveraging Both V2I and V2V Links</title>
      <link>https://arxiv.org/abs/2503.23889</link>
      <description>arXiv:2503.23889v1 Announce Type: new 
Abstract: With the developments of the Internet of Vehicles (IoV) from 4G to 5G, vehicle-to-infrastructure (V2I) communications are becoming attractive for vehicle users (VUEs) to obtain diverse cloud service through base stations (BSs). To tackle V2I link deterioration caused by blockage and out-of-coverage cases, multi-hop V2X routing with both vehicle-to-vehicle (V2V) and V2I links needs to be investigated. However, traditional routing reacts to statistical or real-time information, which may suffer link degradation during path switchover in fast-changing vehicular networks. Predictive routing protocols take timely actions by forecasting link connectivity, but they fail to satisfy specific QoS requirements. Low robustness to link failures is also incurred without considering imperfect prediction. To build continual paths between VUEs and BSs for QoS provision of cloud service, a robust predictive routing framework (ROPE) is proposed with three major components: 1) an early warning scheme detects V2I link deterioration in advance via predicting vehicle mobility and link signal strength to facilitate seamless path switchover; 2) a virtual routing mechanism finds top3 paths that have the highest path strength and satisfy the connectivity and hop count constraints based on the prediction results to fulfill QoS requirements of cloud service; 3) a path verification protocol checks availability and quality of the top3 paths shortly before switchover and activates one qualified path for switchover to ensure routing robustness. We implement ROPE in a simulation framework incorporating real-world urban maps, microscopic traffic generation, geometry-based channel modeling, and offline data analysis as well as online inference. Extensive simulations demonstrate the superiority of ROPE over direct V2I communications and a connectivity-based predictive routing protocol under various scenarios.</description>
      <guid isPermaLink="false">oai:arXiv.org:2503.23889v1</guid>
      <category>cs.NI</category>
      <pubDate>Tue, 01 Apr 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Yawen Chang, Xudong Wang</dc:creator>
    </item>
    <item>
      <title>Cell-Free Massive MIMO Under Mobility: A Fairness-Differentiated Handover Scheme</title>
      <link>https://arxiv.org/abs/2503.24081</link>
      <description>arXiv:2503.24081v1 Announce Type: new 
Abstract: While cell-free massive MIMO (CF-mMIMO) offers both uniform and high network-wide throughput in static networks, its performance in a mobile network is not yet fully addressed. In this paper, we evaluate the performance of a mobile CF-mMIMO network under a comprehensive throughput model and show that it suffers from large performance degradation due to the combined effect of channel aging and handover delay. To improve the performance of CF-mMIMO under mobility, we propose a fairness-differentiated handover scheme. Our scheme differentiates the handover policy for different users by their channel conditions compared to a threshold based on Jain's fairness index, in order to prioritize handovers for the poorly served users. We present an extensive evaluation of the mobile throughput performance of our handover scheme with realistic urban network distributions and UE mobility patterns. Our results show that our scheme significantly outperforms the existing literature benchmarks when considering both channel aging and handover delay cost. Importantly, the advantage of UE-centric over network-centric CF-mMIMO, of uniformly good performance over the network, is uniquely preserved under mobility by our handover scheme. We thus show that CF-mMIMO can be a feasible architecture for practical mobile networks.</description>
      <guid isPermaLink="false">oai:arXiv.org:2503.24081v1</guid>
      <category>cs.NI</category>
      <pubDate>Tue, 01 Apr 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Yunlu Xiao, Marina Petrova, Ljiljana Simi\'c</dc:creator>
    </item>
    <item>
      <title>Trident: Interference Avoidance in Multi-reader Backscatter Network via Frequency-space Division</title>
      <link>https://arxiv.org/abs/2503.24148</link>
      <description>arXiv:2503.24148v1 Announce Type: new 
Abstract: Backscatter is a key technology for battery-free sensing in industrial IoT applications. To fully cover numerous tags in the deployment area, one often needs to deploy multiple readers, each of which communicates with tags within its communication range. However, the actual backscattered signals from a tag are likely to reach a reader outside its communication range and cause interference. Conventional TDMA or CSMA based approaches for interference avoidance separate readers' media access in time, leading to limited network throughput. In this paper, we propose TRIDENT, a novel backscatter design that enables interference avoidance via frequency-space division. By incorporating a tunable bandpass filter and multiple terminal loads, a TRIDENT tag can detect its channel condition and adaptively adjust the frequency and the power of its backscattered signals. We further propose a frequency assignment algorithm for the readers. With these designs, all the readers in the network can operate concurrently without being interfered. We implement TRIDENT and evaluate its performance under various settings. The results demonstrate that TRIDENT enhances the network throughput by 3.18x, compared to the TDMA-based scheme.</description>
      <guid isPermaLink="false">oai:arXiv.org:2503.24148v1</guid>
      <category>cs.NI</category>
      <pubDate>Tue, 01 Apr 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <arxiv:DOI>10.1109/TNET.2024.3495660</arxiv:DOI>
      <dc:creator>Yang Zou, Xin Na, Yimiao Sun, Yuan He</dc:creator>
    </item>
    <item>
      <title>Traffic Engineering in Large-scale Networks with Generalizable Graph Neural Networks</title>
      <link>https://arxiv.org/abs/2503.24203</link>
      <description>arXiv:2503.24203v1 Announce Type: new 
Abstract: Traffic engineering (TE) in large-scale computer networks has become a fundamental yet challenging problem, owing to the swift growth of global-scale cloud wide-area networks or backbone low-Earth-orbit satellite constellations. To address the scalability issue of traditional TE algorithms, learning-based approaches have been proposed, showing potential of significant efficiency improvement over state-of-the-art methods. Nevertheless, the intrinsic limitations of existing learning-based methods hinder their practical application: they are not generalizable across diverse topologies and network conditions, incur excessive training overhead, and do not respect link capacities by default.
  This paper proposes TELGEN, a novel TE algorithm that learns to solve TE problems efficiently in large-scale networks, while achieving superior generalizability across diverse network conditions. TELGEN is based on the novel idea of transforming the problem of "predicting the optimal TE solution" into "predicting the optimal TE algorithm", which enables TELGEN to learn and efficiently approximate the end-to-end solving process of classical optimal TE algorithms. The learned algorithm is agnostic to the exact network topology or traffic patterns, and can efficiently solve TE problems given arbitrary inputs and generalize well to unseen topologies and demands.
  We trained and evaluated TELGEN on random and real-world networks with up to 5000 nodes and 106 links. TELGEN achieved less than 3% optimality gap while ensuring feasibility in all cases, even when the test network had up to 20x more nodes than the largest in training. It also saved up to 84% solving time than classical optimal solver, and could reduce training time per epoch and solving time by 2-4 orders of magnitude than latest learning algorithms on the largest networks.</description>
      <guid isPermaLink="false">oai:arXiv.org:2503.24203v1</guid>
      <category>cs.NI</category>
      <category>cs.LG</category>
      <pubDate>Tue, 01 Apr 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Fangtong Zhou, Xiaorui Liu, Ruozhou Yu, Guoliang Xue</dc:creator>
    </item>
    <item>
      <title>Moving Edge for On-Demand Edge Computing: An Uncertainty-aware Approach</title>
      <link>https://arxiv.org/abs/2503.24214</link>
      <description>arXiv:2503.24214v1 Announce Type: new 
Abstract: We study an edge demand response problem where, based on historical edge workload demands, an edge provider needs to dispatch moving computing units, e.g. truck-carried modular data centers, in response to emerging hotspots within service area. The goal of edge provider is to maximize the expected revenue brought by serving congested users with satisfactory performance, while minimizing the costs of moving units and the potential service-level agreement violation penalty for interrupted services. The challenge is to make robust predictions for future demands, as well as optimized moving unit dispatching decisions. We propose a learning-based, uncertain-aware moving unit scheduling framework, URANUS, to address this problem. Our framework novelly combines Bayesian deep learning and distributionally robust approximation to make predictions that are robust to data, model and distributional uncertainties in deep learning-based prediction models. Based on the robust prediction outputs, we further propose an efficient planning algorithm to optimize moving unit scheduling in an online manner. Simulation experiments show that URANUS can significantly improve robustness in decision making, and achieve superior performance compared to state-of-the-art reinforcement learning, uncertainty-agnostic learning-based methods, and other baselines.</description>
      <guid isPermaLink="false">oai:arXiv.org:2503.24214v1</guid>
      <category>cs.NI</category>
      <pubDate>Tue, 01 Apr 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Fangtong Zhou, Ruozhou Yu</dc:creator>
    </item>
    <item>
      <title>Fair Dynamic Spectrum Access via Fully Decentralized Multi-Agent Reinforcement Learning</title>
      <link>https://arxiv.org/abs/2503.24296</link>
      <description>arXiv:2503.24296v1 Announce Type: new 
Abstract: We consider a decentralized wireless network with several source-destination pairs sharing a limited number of orthogonal frequency bands. Sources learn to adapt their transmissions (specifically, their band selection strategy) over time, in a decentralized manner, without sharing information with each other. Sources can only observe the outcome of their own transmissions (i.e., success or collision), having no prior knowledge of the network size or of the transmission strategy of other sources. The goal of each source is to maximize their own throughput while striving for network-wide fairness. We propose a novel fully decentralized Reinforcement Learning (RL)-based solution that achieves fairness without coordination. The proposed Fair Share RL (FSRL) solution combines: (i) state augmentation with a semi-adaptive time reference; (ii) an architecture that leverages risk control and time difference likelihood; and (iii) a fairness-driven reward structure. We evaluate FSRL in more than 50 network settings with different number of agents, different amounts of available spectrum, in the presence of jammers, and in an ad-hoc setting. Simulation results suggest that, when we compare FSRL with a common baseline RL algorithm from the literature, FSRL can be up to 89.0% fairer (as measured by Jain's fairness index) in stringent settings with several sources and a single frequency band, and 48.1% fairer on average.</description>
      <guid isPermaLink="false">oai:arXiv.org:2503.24296v1</guid>
      <category>cs.NI</category>
      <category>cs.LG</category>
      <pubDate>Tue, 01 Apr 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Yubo Zhang, Pedro Botelho, Trevor Gordon, Gil Zussman, Igor Kadota</dc:creator>
    </item>
    <item>
      <title>Optimizing Age of Information in Networks with Large and Small Updates</title>
      <link>https://arxiv.org/abs/2503.23658</link>
      <description>arXiv:2503.23658v1 Announce Type: cross 
Abstract: Modern sensing and monitoring applications typically consist of sources transmitting updates of different sizes, ranging from a few bytes (position, temperature, etc.) to multiple megabytes (images, video frames, LIDAR point scans, etc.). Existing approaches to wireless scheduling for information freshness typically ignore this mix of large and small updates, leading to suboptimal performance. In this paper, we consider a single-hop wireless broadcast network with sources transmitting updates of different sizes to a base station over unreliable links. Some sources send large updates spanning many time slots while others send small updates spanning only a few time slots. Due to medium access constraints, only one source can transmit to the base station at any given time, thus requiring careful design of scheduling policies that takes the sizes of updates into account. First, we derive a lower bound on the achievable Age of Information (AoI) by any transmission scheduling policy. Second, we develop optimal randomized policies that consider both switching and no-switching during the transmission of large updates. Third, we introduce a novel Lyapunov function and associated analysis to propose an AoI-based Max-Weight policy that has provable constant factor optimality guarantees. Finally, we evaluate and compare the performance of our proposed scheduling policies through simulations, which show that our Max-Weight policy achieves near-optimal AoI performance.</description>
      <guid isPermaLink="false">oai:arXiv.org:2503.23658v1</guid>
      <category>eess.SY</category>
      <category>cs.NI</category>
      <category>cs.SY</category>
      <pubDate>Tue, 01 Apr 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Zhuoyi Zhao, Vishrant Tripathi, Igor Kadota</dc:creator>
    </item>
    <item>
      <title>Libertas: Privacy-Preserving Collective Computation for Decentralised Personal Data Stores</title>
      <link>https://arxiv.org/abs/2309.16365</link>
      <description>arXiv:2309.16365v2 Announce Type: replace 
Abstract: Data and data processing have become an indispensable aspect for our society. Insights drawn from collective data make invaluable contribution to scientific and societal research and business. But there are increasing worries about privacy issues and data misuse. This has prompted the emergence of decentralised personal data stores (PDS) like Solid that provide individuals more control over their personal data. However, existing PDS frameworks face challenges in ensuring data privacy when performing collective computations with data from multiple users. While Secure Multi-Party Computation (MPC) offers input secrecy protection during the computation without relying on any single party, issues emerge when directly applying MPC in the context of PDS, particularly due to key factors like autonomy and decentralisation. In this work, we discuss the essence of this issue, identify a potential solution, and introduce a modular architecture, Libertas, to integrate MPC with PDS like Solid, without requiring protocol-level changes. We introduce a paradigm shift from an `omniscient' view to individual-based, user-centric view of trust and security, and discuss the threat model of Libertas. Two realistic use cases for collaborative data processing are used for evaluation, both for technical feasibility and empirical benchmark, highlighting its effectiveness in empowering gig workers and generating differentially private synthetic data. The results of our experiments underscore Libertas' linear scalability and provide valuable insights into compute optimisations, thereby advancing the state-of-the-art in privacy-preserving data processing practices. By offering practical solutions for maintaining both individual autonomy and privacy in collaborative data processing environments, Libertas contributes significantly to the ongoing discourse on privacy protection in data-driven decision-making contexts.</description>
      <guid isPermaLink="false">oai:arXiv.org:2309.16365v2</guid>
      <category>cs.NI</category>
      <category>cs.CR</category>
      <category>cs.DC</category>
      <pubDate>Tue, 01 Apr 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Rui Zhao, Naman Goel, Nitin Agrawal, Jun Zhao, Jake Stein, Wael Albayaydh, Ruben Verborgh, Reuben Binns, Tim Berners-Lee, Nigel Shadbolt</dc:creator>
    </item>
    <item>
      <title>Toward One-Second Latency: Evolution of Live Media Streaming</title>
      <link>https://arxiv.org/abs/2310.03256</link>
      <description>arXiv:2310.03256v2 Announce Type: replace 
Abstract: This survey presents the evolution of live media streaming and the technological developments behind today's IP-based low-latency live streaming systems. Live streaming primarily involves capturing, encoding, packaging and delivering real-time events such as live sports, live news, personal broadcasts and surveillance videos. Live streaming also involves concurrent streaming of linear TV programming off the satellite, cable, over-the-air or IPTV broadcast, where the programming is not necessarily a real-time event.
  The survey starts with a discussion on the latency and latency continuum in streaming applications. Then, it lays out the existing live streaming workflows and protocols, followed by an in-depth analysis of the latency sources in these workflows and protocols. The survey continues with the technology enablers, low-latency extensions for the popular HTTP adaptive streaming methods and enhancements for robust low-latency playback. An entire section is dedicated to the detailed summary and findings of Twitch's grand challenge on low-latency live streaming. The survey concludes with a discussion of ongoing research problems in this space. We expect this survey to be the one-stop reference for those who would like to learn how low-latency live streaming has evolved and works today, and what further developments could happen in the future.</description>
      <guid isPermaLink="false">oai:arXiv.org:2310.03256v2</guid>
      <category>cs.NI</category>
      <category>cs.MM</category>
      <pubDate>Tue, 01 Apr 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <arxiv:DOI>10.1109/COMST.2025.3555514</arxiv:DOI>
      <dc:creator>Abdelhak Bentaleb, May Lim, Mehmet N. Akcay, Ali C. Begen, Sarra Hammoudi, Roger Zimmermann</dc:creator>
    </item>
    <item>
      <title>Cascade Reinforcement Learning with State Space Factorization for O-RAN-based Traffic Steering</title>
      <link>https://arxiv.org/abs/2312.01970</link>
      <description>arXiv:2312.01970v3 Announce Type: replace 
Abstract: The Open Radio Access Network (O-RAN) architecture empowers intelligent and automated optimization of the RAN through applications deployed on the RAN Intelligent Controller (RIC) platform, enabling capabilities beyond what is achievable with traditional RAN solutions. Within this paradigm, Traffic Steering (TS) emerges as a pivotal RIC application that focuses on optimizing cell-level mobility settings in near-real-time, aiming to significantly improve network spectral efficiency. In this paper, we design a novel TS algorithm based on a Cascade Reinforcement Learning (CaRL) framework. We propose state space factorization and policy decomposition to reduce the need for large models and well-labeled datasets. For each sub-state space, an RL sub-policy will be trained to learn an optimized mapping onto the action space. To apply CaRL on new network regions, we propose a knowledge transfer approach to initialize a new sub-policy based on knowledge learned by the trained policies. To evaluate CaRL, we build a data-driven and scalable RIC digital twin (DT) that is modeled using important real-world data, including network configuration, user geo-distribution, and traffic demand, among others, from a tier-1 mobile operator in the US. We evaluate CaRL on two DT scenarios representing two network clusters in two different cities and compare its performance with the business-as-usual (BAU) policy and other competing optimization approaches using heuristic and Q-table algorithms. Benchmarking results show that CaRL performs the best and improves the average cluster-aggregated downlink throughput over the BAU policy by 24% and 18% in these two scenarios, respectively.</description>
      <guid isPermaLink="false">oai:arXiv.org:2312.01970v3</guid>
      <category>cs.NI</category>
      <category>cs.SY</category>
      <category>eess.SY</category>
      <pubDate>Tue, 01 Apr 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Chuanneng Sun, Gueyoung Jung, Tuyen Xuan Tran, Dario Pompili</dc:creator>
    </item>
    <item>
      <title>A$^3$L-FEC: Age-Aware Application Layer Forward Error Correction Flow Control</title>
      <link>https://arxiv.org/abs/2410.05852</link>
      <description>arXiv:2410.05852v2 Announce Type: replace 
Abstract: Age of Information (AoI) is a metric and KPI that has been developed for measuring and controlling data freshness. Optimization of AoI in a real-life network requires adapting the rate and timing of transmissions to varying network conditions. The vast majority of previous research on the control of AoI has been theoretical, using idealized models that ignored certain implementation aspects. As such, there is still a gap between the research on AoI and real-world protocols. In this paper we present an effort toward closing this gap by introducing an age-aware flow control algorithm. The algorithm, Age-Aware Application Layer Forward Error Correction (A$^3$L-FEC), is a packet generation mechanism operating on top of the User Datagram Protocol (UDP). The purpose is to control the peak Age of the end-to-end packet flow, specifically to reduce the rate of so-called "Age Violations," i.e., events where the peak age exceeds a given threshold. Evaluations in Mininet-WiFi and MATLAB indicate that A$3$L-FEC reduces age violations compared to two related protocols in the literature, namely TCP-BBR and ACP+.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.05852v2</guid>
      <category>cs.NI</category>
      <pubDate>Tue, 01 Apr 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Sajjad Baghaee, Elif Uysal</dc:creator>
    </item>
    <item>
      <title>IEEE 802.11bn Multi-AP Coordinated Spatial Reuse with Hierarchical Multi-Armed Bandits</title>
      <link>https://arxiv.org/abs/2501.03680</link>
      <description>arXiv:2501.03680v2 Announce Type: replace 
Abstract: Coordination among multiple access points (APs) is integral to IEEE 802.11bn (Wi-Fi 8) for managing contention in dense networks. This letter explores the benefits of Coordinated Spatial Reuse (C-SR) and proposes the use of reinforcement learning to optimize C-SR group selection. We develop a hierarchical multi-armed bandit (MAB) framework that efficiently selects APs for simultaneous transmissions across various network topologies, demonstrating reinforcement learning's promise in Wi-Fi settings. Among several MAB algorithms studied, we identify the upper confidence bound (UCB) as particularly effective, offering rapid convergence, adaptability to changes, and sustained performance.</description>
      <guid isPermaLink="false">oai:arXiv.org:2501.03680v2</guid>
      <category>cs.NI</category>
      <pubDate>Tue, 01 Apr 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <arxiv:DOI>10.1109/LCOMM.2024.3521079</arxiv:DOI>
      <arxiv:journal_reference>IEEE Communications Letters (2025), vol. 29, no. 3, pp. 428-432</arxiv:journal_reference>
      <dc:creator>Maksymilian Wojnar, Wojciech Ciezobka, Katarzyna Kosek-Szott, Krzysztof Rusek, Szymon Szott, David Nunez, Boris Bellalta</dc:creator>
    </item>
    <item>
      <title>The Forest Behind the Tree: Revealing Hidden Smart Home Communication Patterns</title>
      <link>https://arxiv.org/abs/2502.08535</link>
      <description>arXiv:2502.08535v2 Announce Type: replace 
Abstract: The widespread use of Smart Home devices has attracted significant research interest in understanding their behavior within home networks. Unlike general-purpose computers, these devices exhibit relatively simple and predictable network activity patterns. However, previous studies have primarily focused on normal network conditions, overlooking potential hidden patterns that emerge under challenging conditions. Discovering these hidden flows is crucial for assessing device robustness. This paper addresses this gap by presenting a framework that systematically and automatically reveals these hidden communication patterns. By actively disturbing communication and blocking observed traffic, the framework generates comprehensive profiles structured as behavior trees, uncovering flows that are missed by more shallow methods. This approach was applied to ten real-world devices, identifying 254 unique flows, with over 27% only discovered through this new method. These insights enhance our understanding of device robustness and can be leveraged to improve the accuracy of network security measures.</description>
      <guid isPermaLink="false">oai:arXiv.org:2502.08535v2</guid>
      <category>cs.NI</category>
      <category>cs.CR</category>
      <pubDate>Tue, 01 Apr 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Fran\c{c}ois De Keersmaeker, R\'emi Van Boxem, Cristel Pelsser, Ramin Sadre</dc:creator>
    </item>
    <item>
      <title>Uncrewed Vehicles in 6G Networks: A Unifying Treatment of Problems, Formulations, and Tools</title>
      <link>https://arxiv.org/abs/2404.14738</link>
      <description>arXiv:2404.14738v4 Announce Type: replace-cross 
Abstract: Uncrewed Vehicles (UVs) functioning as autonomous agents are anticipated to play a crucial role in the 6th Generation of wireless networks. Their seamless integration, cost-effectiveness, and the additional controllability through motion planning make them an attractive deployment option for a wide range of applications, both as assets in the network (e.g., mobile base stations) and as consumers of network services (e.g., autonomous delivery systems). However, despite their potential, the convergence of UVs and wireless systems brings forth numerous challenges that require attention from both academia and industry. This paper then aims to offer a comprehensive overview encompassing the transformative possibilities as well as the significant challenges associated with UV-assisted next-generation wireless communications. Considering the diverse landscape of possible application scenarios, problem formulations, and mathematical tools related to UV-assisted wireless systems, the underlying core theme of this paper is the unification of the problem space, providing a structured framework to understand the use cases, problem formulations, and necessary mathematical tools. Overall, the paper sets forth a clear understanding of how uncrewed vehicles can be integrated in the 6G ecosystem, paving the way towards harnessing the full potential at this intersection.</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.14738v4</guid>
      <category>eess.SY</category>
      <category>cs.NI</category>
      <category>cs.SY</category>
      <pubDate>Tue, 01 Apr 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/publicdomain/zero/1.0/</dc:rights>
      <arxiv:DOI>10.1109/JPROC.2025.3541949</arxiv:DOI>
      <dc:creator>Winston Hurst, Spilios Evmorfos, Athina Petropulu, Yasamin Mostofi</dc:creator>
    </item>
    <item>
      <title>Teola: Towards End-to-End Optimization of LLM-based Applications</title>
      <link>https://arxiv.org/abs/2407.00326</link>
      <description>arXiv:2407.00326v3 Announce Type: replace-cross 
Abstract: Large language model (LLM)-based applications consist of both LLM and non-LLM components, each contributing to the end-to-end latency. Despite great efforts to optimize LLM inference, end-to-end workflow optimization has been overlooked. Existing frameworks employ coarse-grained orchestration with task modules, which confines optimizations to within each module and yields suboptimal scheduling decisions. We propose fine-grained end-to-end orchestration, which utilizes task primitives as the basic units and represents each query's workflow as a primitive-level dataflow graph. This explicitly exposes a much larger design space, enables optimizations in parallelization and pipelining across primitives of different modules, and enhances scheduling to improve application-level performance. We build Teola, a novel orchestration framework for LLM-based applications that implements this scheme. Comprehensive experiments show that Teola can achieve up to 2.09x speedup over existing systems across various popular LLM applications. The code is available at https://github.com/NetX-lab/Ayo.</description>
      <guid isPermaLink="false">oai:arXiv.org:2407.00326v3</guid>
      <category>cs.DC</category>
      <category>cs.AI</category>
      <category>cs.NI</category>
      <pubDate>Tue, 01 Apr 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Xin Tan, Yimin Jiang, Yitao Yang, Hong Xu</dc:creator>
    </item>
    <item>
      <title>Privacy-Preserving Secure Neighbor Discovery for Wireless Networks</title>
      <link>https://arxiv.org/abs/2503.22232</link>
      <description>arXiv:2503.22232v2 Announce Type: replace-cross 
Abstract: Traditional Neighbor Discovery (ND) and Secure Neighbor Discovery (SND) are key elements for network functionality. SND is a hard problem, satisfying not only typical security properties (authentication, integrity) but also verification of direct communication, which involves distance estimation based on time measurements and device coordinates. Defeating relay attacks, also known as "wormholes", leading to stealthy Byzantine links and significant degradation of communication and adversarial control, is key in many wireless networked systems. However, SND is not concerned with privacy; it necessitates revealing the identity and location of the device(s) participating in the protocol execution. This can be a deterrent for deployment, especially involving user-held devices in the emerging Internet of Things (IoT) enabled smart environments. To address this challenge, we present a novel Privacy-Preserving Secure Neighbor Discovery (PP-SND) protocol, enabling devices to perform SND without revealing their actual identities and locations, effectively decoupling discovery from the exposure of sensitive information. We use Homomorphic Encryption (HE) for computing device distances without revealing their actual coordinates, as well as employing a pseudonymous device authentication to hide identities while preserving communication integrity. PP-SND provides SND [1] along with pseudonymity, confidentiality, and unlinkability. Our presentation here is not specific to one wireless technology, and we assess the performance of the protocols (cryptographic overhead) on a Raspberry Pi 4 and provide a security and privacy analysis.</description>
      <guid isPermaLink="false">oai:arXiv.org:2503.22232v2</guid>
      <category>cs.CR</category>
      <category>cs.NI</category>
      <pubDate>Tue, 01 Apr 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Ahmed Mohamed Hussain, Panos Papadimitratos</dc:creator>
    </item>
  </channel>
</rss>
