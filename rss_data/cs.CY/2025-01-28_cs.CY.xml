<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>cs.CY updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/cs.CY</link>
    <description>cs.CY updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/cs.CY" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Wed, 29 Jan 2025 02:33:54 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Tue, 28 Jan 2025 00:00:00 -0500</pubDate>
    <skipDays>
      <day>Saturday</day>
      <day>Sunday</day>
    </skipDays>
    <item>
      <title>Exploitation All the Way Down: Calling out the Root Cause of Bad Online Experiences for Users of the "Majority World"</title>
      <link>https://arxiv.org/abs/2501.14748</link>
      <description>arXiv:2501.14748v1 Announce Type: new 
Abstract: Global Majority users are exposed to multitudes of harm when interacting with online platforms. This essay illuminates how exploitation in the advances of Artificial Intelligence is tied to historical exploitation and how the use of blanket terminology overshadows the layers of exploitation and harm ``Global Majority'' populations face. It first discusses the multitude of harm content moderators from the Global Majority face, arguing against the current trend of protection through exploitation, then it illustrates the nuances and differences within the Global Majority, and finally, it outlines actionable items to move away from such harm.</description>
      <guid isPermaLink="false">oai:arXiv.org:2501.14748v1</guid>
      <category>cs.CY</category>
      <pubDate>Tue, 28 Jan 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <dc:creator>Hellina Hailu Nigatu, Zeerak Talat</dc:creator>
    </item>
    <item>
      <title>The Manhattan Trap: Why a Race to Artificial Superintelligence is Self-Defeating</title>
      <link>https://arxiv.org/abs/2501.14749</link>
      <description>arXiv:2501.14749v1 Announce Type: new 
Abstract: This paper examines the strategic dynamics of international competition to develop Artificial Superintelligence (ASI). We argue that the same assumptions that might motivate the US to race to develop ASI also imply that such a race is extremely dangerous. These assumptions--that ASI would provide a decisive military advantage and that states are rational actors prioritizing survival--imply that a race would heighten three critical risks: great power conflict, loss of control of ASI systems, and the undermining of liberal democracy. Our analysis shows that ASI presents a trust dilemma rather than a prisoners dilemma, suggesting that international cooperation to control ASI development is both preferable and strategically sound. We conclude that cooperation is achievable.</description>
      <guid isPermaLink="false">oai:arXiv.org:2501.14749v1</guid>
      <category>cs.CY</category>
      <pubDate>Tue, 28 Jan 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Corin Katzke, Gideon Futerman</dc:creator>
    </item>
    <item>
      <title>Engineering Carbon Credits Towards A Responsible FinTech Era: The Practices, Implications, and Future</title>
      <link>https://arxiv.org/abs/2501.14750</link>
      <description>arXiv:2501.14750v1 Announce Type: new 
Abstract: Carbon emissions significantly contribute to climate change, and carbon credits have emerged as a key tool for mitigating environmental damage and helping organizations manage their carbon footprint. Despite their growing importance across sectors, fully leveraging carbon credits remains challenging. This study explores engineering practices and fintech solutions to enhance carbon emission management. We first review the negative impacts of carbon emission non-disclosure, revealing its adverse effects on financial stability and market value. Organizations are encouraged to actively manage emissions and disclose relevant data to mitigate risks. Next, we analyze factors influencing carbon prices and review advanced prediction algorithms that optimize carbon credit purchasing strategies, reducing costs and improving efficiency. Additionally, we examine corporate carbon emission prediction models, which offer accurate performance assessments and aid in planning future carbon credit needs. By integrating carbon price and emission predictions, we propose research directions, including corporate carbon management cost forecasting. This study provides a foundation for future quantitative research on the financial and market impacts of carbon management practices and is the first systematic review focusing on computing solutions and engineering practices for carbon credits.</description>
      <guid isPermaLink="false">oai:arXiv.org:2501.14750v1</guid>
      <category>cs.CY</category>
      <category>cs.LG</category>
      <pubDate>Tue, 28 Jan 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Qingwen Zeng, Hanlin Xu, Nanjun Xu, Flora Salim, Junbin Gao, Huaming Chen</dc:creator>
    </item>
    <item>
      <title>Towards An Automated AI Act FRIA Tool That Can Reuse GDPR's DPIA</title>
      <link>https://arxiv.org/abs/2501.14756</link>
      <description>arXiv:2501.14756v1 Announce Type: new 
Abstract: The AI Act introduces the obligation to conduct a Fundamental Rights Impact Assessment (FRIA), with the possibility to reuse a Data Protection Impact Assessment (DPIA), and requires the EU Commission to create of an automated tool to support the FRIA process. In this article, we provide our novel exploration of the DPIA and FRIA as information processes to enable the creation of automated tools. We first investigate the information involved in DPIA and FRIA, and then use this to align the two to state where a DPIA can be reused in a FRIA. We then present the FRIA as a 5-step process and discuss the role of an automated tool for each step. Our work provides the necessary foundation for creating and managing information for FRIA and supporting it through an automated tool as required by the AI Act.</description>
      <guid isPermaLink="false">oai:arXiv.org:2501.14756v1</guid>
      <category>cs.CY</category>
      <category>cs.AI</category>
      <pubDate>Tue, 28 Jan 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Tytti Rintamaki, Harshvardhan J. Pandit</dc:creator>
    </item>
    <item>
      <title>Technological Progress and Obsolescence: Analyzing the Environmental Economic Impacts of MacBook Pro I/O Devices</title>
      <link>https://arxiv.org/abs/2501.14758</link>
      <description>arXiv:2501.14758v1 Announce Type: new 
Abstract: This study investigates how the new release of MacBook Pro I/O devices affects the obsolescence of related accessories. We also explore how these accessories will impact the environment and the economic consequences. As technology progresses, each new MacBook Pro releases outdated prior accessories, making more electronic waste. This phenomenon makes modern people need to change their traditional consumption patterns. We analyze changes in I/O ports and compatibility between MacBook Pro versions to determine which accessories are obsolete and estimate their environmental impact. Our research focuses on the sustainability of current accessories. We explore alternate methods of reusing, recycling, and disposing of these accessories in order to reduce waste and environmental impact. In addition, we will explore the economic consequences of rapid technological advances that make accessories obsolete too quickly. Thereby assessing the impact of such changes on consumers, manufacturers, and the technology industry. This study aims to respond to the rapid advancement of technology while promoting more sustainable approaches to waste management and product design. As the MacBook Pro I/O unit evolves, certain accessories become obsolete with each subsequent version. The purpose of this study is to identify and quantify the environmental and economic impacts of parts end-of-life. We can detect which accessories have become obsolete and assess the environmental impact by comparing I/O port changes and compatibility across MacBook Pro generations. In response to these environmental images, methods are developed to reuse, recycle, and dispose of obsolete accessories to reduce waste and promote sustainable development. Additionally, we evaluate the economic impact of obsolete equipment on consumers and producers.</description>
      <guid isPermaLink="false">oai:arXiv.org:2501.14758v1</guid>
      <category>cs.CY</category>
      <pubDate>Tue, 28 Jan 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Yun-Chieh Cheng, Yu-Tong Shen, Guanqun Song, Ting Zhu</dc:creator>
    </item>
    <item>
      <title>AI Meets Natural Hazard Risk: A Nationwide Vulnerability Assessment of Data Centers to Natural Hazards and Power Outages</title>
      <link>https://arxiv.org/abs/2501.14760</link>
      <description>arXiv:2501.14760v1 Announce Type: new 
Abstract: Our society is on the verge of a revolution powered by Artificial Intelligence (AI) technologies. With increasing advancements in AI, there is a growing expansion in data centers (DCs) serving as critical infrastructure for this new wave of technologies. This technological wave is also on a collision course with exacerbating climate hazards which raises the need for evaluating the vulnerability of DCs to various hazards. Hence, the objective of this research is to conduct a nationwide vulnerability assessment of (DCs) in the United States of America (USA). DCs provide such support; however, if an unplanned disruption (like a natural hazard or power outage) occurs, the functionality of DCs are in jeopardy. Unplanned downtime in DCs cause severe economic and social repercussions. With the Local Indicator of Spatial Association (LISA) test, the research found that there are a large percentage of DCs that are in non-vulnerable areas of disruption; however, there is still a notable percentage in disruption prone areas. For example, earthquakes, hurricanes, and tornadoes have the most DCs in vulnerable areas. After identifying these vulnerabilities, the research identified areas within the USA that have minimal vulnerabilities to both the aforementioned natural hazards and power outages with the BI-LISA test. After doing a composite vulnerability score on the Cold-Spots from the BILISA analysis, the research found three counties with the low vulnerability scores. These are Koochiching, Minnesota (0.091), Schoolcraft, Michigan (0.095), and Houghton, Michigan (0.096).</description>
      <guid isPermaLink="false">oai:arXiv.org:2501.14760v1</guid>
      <category>cs.CY</category>
      <pubDate>Tue, 28 Jan 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Miguel Esparza, Bo Li, Junwei Ma, Ali Mostafavi</dc:creator>
    </item>
    <item>
      <title>A multi-dimension and high-granularity equity measurement for transportation services through accessibility and reliability</title>
      <link>https://arxiv.org/abs/2501.14761</link>
      <description>arXiv:2501.14761v1 Announce Type: new 
Abstract: Transportation equity research has traditionally emphasized service accessibility and destination reachability while often overlooking the critical aspects of service quality, such as infrequent schedules or overcrowded vehicles. This oversight can lead to a skewed understanding of equity, as high accessibility does not guarantee high-quality service. Addressing this gap, we propose a transportation equity index called the multi-dimensional, high-granularity (MDHG) index. Such an index considers service accessibility and quality alongside population demographics. This approach ensures that areas with high accessibility but low service quality are recognized as inequitable. The MDHG Index addresses service performance by incorporating performance data with temporal variations based on actual trip data, thus offering a more nuanced view of transportation equity that reflects the real-world experiences of service users. Furthermore, to effectively identify and address the needs at the user level, we need to use a highly granular population dataset. Due to the low granularity of census and other open-source datasets, we opted to use a highly granular synthetic dataset. To test out the MDHG Index, we coupled a highly granular synthetic population dataset with data from NYC Citi Bike expansion to use as a case study to assess changes in accessibility and service quality before and after the expansion. The MDHG approach effectively identified areas that improved post-expansion and highlighted those requiring further enhancement, thus showing the effectiveness of the index in targeted improvements for transportation equity.</description>
      <guid isPermaLink="false">oai:arXiv.org:2501.14761v1</guid>
      <category>cs.CY</category>
      <pubDate>Tue, 28 Jan 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <dc:creator> Mengke (Enola),  Ma, Zilin Bian, Jingqin Gao, Hai Yang, Joseph Chow, Kaan Ozbay</dc:creator>
    </item>
    <item>
      <title>Linked Data on Geo-annotated Events and Use Cases for the Resilience of Ukraine</title>
      <link>https://arxiv.org/abs/2501.14762</link>
      <description>arXiv:2501.14762v1 Announce Type: new 
Abstract: The mission of resilience of Ukrainian cities calls for international collaboration with the scientific community to increase the quality of information by identifying and integrating information from various news and social media sources. Linked Data technology can be used to unify, enrich, and integrate data from multiple sources. In our work, we focus on datasets about damaging events in Ukraine due to Russia's invasion between February 2022 and the end of April 2023. We convert two selected datasets to Linked Data and enrich them with additional geospatial information. Following that, we present an algorithm for the detection of identical events from different datasets. Our pipeline makes it easy to convert and enrich datasets to integrated Linked Data. The resulting dataset consists of 10K reported events covering damage to hospitals, schools, roads, residential buildings, etc. Finally, we demonstrate in use cases how our dataset can be applied to different scenarios for resilience purposes.</description>
      <guid isPermaLink="false">oai:arXiv.org:2501.14762v1</guid>
      <category>cs.CY</category>
      <category>cs.SI</category>
      <pubDate>Tue, 28 Jan 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Manar Attar, Shuai Wang, Ronald Siebes, Eirik Kultorp, Zhisheng Huang, Tianyang Lu</dc:creator>
    </item>
    <item>
      <title>Battery-free, stretchable, and autonomous smart packaging</title>
      <link>https://arxiv.org/abs/2501.14764</link>
      <description>arXiv:2501.14764v1 Announce Type: new 
Abstract: In the food industry, innovative packaging solutions are increasingly important for reducing food waste and for contributing to global sustainability efforts. However, current food packaging is generally passive and unable to adapt to changes in the food environment in real-time. To address this, we have developed a battery-less and autonomous smart packaging system that wirelessly powers closed-loop sensing and release of active compounds. This system integrates a gas sensor for real-time food monitoring, a Near-Field Communication (NFC) antenna, and a controlled release of active compounds to prevent quality deterioration in the complex food environment. We have demonstrated the ability of the developed smart packaging system, to continuously monitor the freshness of fish products and to trigger the release of active compounds when the food starts to spoil. The system was able to extend the shelf-life of the food product up to 14 days, due to the controlled release of antioxidant and antibacterial compounds. Our system could pave the way towards an Internet of Things solution that addresses protection, active prevention of food spoilage and sustainability, facing all the current challenges of the food packaging industry.</description>
      <guid isPermaLink="false">oai:arXiv.org:2501.14764v1</guid>
      <category>cs.CY</category>
      <pubDate>Tue, 28 Jan 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Ali Douaki, Mukhtar Ahmed, Edoardo Longo, Giulia Windisch, Raheel Riaz, Sarwar Inam, Thi Nga Tran, Evie L. Papadopoulou, Athanassia Athanassiou, Emanuele Boselli, Luisa Petti, Paolo Lugli</dc:creator>
    </item>
    <item>
      <title>Artificial Intelligence for Sustainable Urban Biodiversity: A Framework for Monitoring and Conservation</title>
      <link>https://arxiv.org/abs/2501.14766</link>
      <description>arXiv:2501.14766v1 Announce Type: new 
Abstract: The rapid expansion of urban areas challenges biodiversity conservation, requiring innovative ecosystem management. This study explores the role of Artificial Intelligence (AI) in urban biodiversity conservation, its applications, and a framework for implementation. Key findings show that: (a) AI enhances species detection and monitoring, achieving over 90% accuracy in urban wildlife tracking and invasive species management; (b) integrating data from remote sensing, acoustic monitoring, and citizen science enables large-scale ecosystem analysis; and (c) AI decision tools improve conservation planning and resource allocation, increasing prediction accuracy by up to 18.5% compared to traditional methods. The research presents an AI-Driven Framework for Urban Biodiversity Management, highlighting AI's impact on monitoring, conservation strategies, and ecological outcomes. Implementation strategies include: (a) standardizing data collection and model validation, (b) ensuring equitable AI access across urban contexts, and (c) developing ethical guidelines for biodiversity monitoring. The study concludes that integrating AI in urban biodiversity conservation requires balancing innovation with ecological wisdom and addressing data quality, socioeconomic disparities, and ethical concerns.</description>
      <guid isPermaLink="false">oai:arXiv.org:2501.14766v1</guid>
      <category>cs.CY</category>
      <category>cs.AI</category>
      <pubDate>Tue, 28 Jan 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Yasmin Rahmati</dc:creator>
    </item>
    <item>
      <title>Leveraging Social Media Data and Artificial Intelligence for Improving Earthquake Response Efforts</title>
      <link>https://arxiv.org/abs/2501.14767</link>
      <description>arXiv:2501.14767v1 Announce Type: new 
Abstract: The integration of social media and artificial intelligence (AI) into disaster management, particularly for earthquake response, represents a profound evolution in emergency management practices. In the digital age, real-time information sharing has reached unprecedented levels, with social media platforms emerging as crucial communication channels during crises. This shift has transformed traditional, centralized emergency services into more decentralized, participatory models of disaster situational awareness. Our study includes an experimental analysis of 8,900 social media interactions, including 2,920 posts and 5,980 replies on X (formerly Twitter), following a magnitude 5.1 earthquake in Oklahoma on February 2, 2024. The analysis covers data from the immediate aftermath and extends over the following seven days, illustrating the critical role of digital platforms in modern disaster response. The results demonstrate that social media platforms can be effectively used as real-time situational awareness tools, delivering critical information to society and authorities during emergencies.</description>
      <guid isPermaLink="false">oai:arXiv.org:2501.14767v1</guid>
      <category>cs.CY</category>
      <category>cs.AI</category>
      <category>cs.CL</category>
      <category>cs.IR</category>
      <category>cs.SI</category>
      <pubDate>Tue, 28 Jan 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <arxiv:DOI>10.1007/978-3-031-74707-6_24</arxiv:DOI>
      <dc:creator>Kalin Kopanov, Velizar Varbanov, Tatiana Atanasova</dc:creator>
    </item>
    <item>
      <title>DropMicroFluidAgents (DMFAs): Autonomous Droplet Microfluidic Research Framework Through Large Language Model Agents</title>
      <link>https://arxiv.org/abs/2501.14772</link>
      <description>arXiv:2501.14772v1 Announce Type: new 
Abstract: Applying Large language models (LLMs) within specific domains requires substantial adaptation to account for the unique terminologies, nuances, and context-specific challenges inherent to those areas. Here, we introduce DropMicroFluidAgents (DMFAs), an advanced language-driven framework leveraging state-of-the-art pre-trained LLMs. DMFAs employs LLM agents to perform two key functions: (1) delivering focused guidance, answers, and suggestions specific to droplet microfluidics and (2) generating machine learning models to optimise and automate the design of droplet microfluidic devices, including the creation of code-based computer-aided design (CAD) scripts to enable rapid and precise design execution. Experimental evaluations demonstrated that the integration of DMFAs with the LLAMA3.1 model yielded the highest accuracy of 76.15%, underscoring the significant performance enhancement provided by agent integration. This effect was particularly pronounced when DMFAs were paired with the GEMMA2 model, resulting in a 34.47% improvement in accuracy compared to the standalone GEMMA2 configuration. This study demonstrates the effective use of LLM agents in droplet microfluidics research as powerful tools for automating workflows, synthesising knowledge, optimising designs, and interacting with external systems. These capabilities enable their application across education and industrial support, driving greater efficiency in scientific discovery and innovation.</description>
      <guid isPermaLink="false">oai:arXiv.org:2501.14772v1</guid>
      <category>cs.CY</category>
      <category>cs.AI</category>
      <pubDate>Tue, 28 Jan 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Dinh-Nguyen Nguyen, Raymond Kai-Yu Tong, Ngoc-Duy Dinh</dc:creator>
    </item>
    <item>
      <title>Good Practices for Institutional Organization of Research Institutes: Excellence in Research and Positive Impact on Society</title>
      <link>https://arxiv.org/abs/2501.14773</link>
      <description>arXiv:2501.14773v1 Announce Type: new 
Abstract: In this paper, we analyze examples of research institutes that stand out in scientific excellence and social impact. We define key practices for evaluating research results, economic conditions, and the selection of specific research topics. Special focus is placed on small countries and the field of artificial intelligence. The aim is to identify components that enable institutes to achieve a high level of innovation, self-sustainability, and social benefits.</description>
      <guid isPermaLink="false">oai:arXiv.org:2501.14773v1</guid>
      <category>cs.CY</category>
      <pubDate>Tue, 28 Jan 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/publicdomain/zero/1.0/</dc:rights>
      <dc:creator>Zlatan Ajanovi\'c, Hamza Merzi\'c, Suad Krilasevi\'c, Eldar Kurti\'c, Bakir Kudi\'c, Rialda Spahi\'c, Emina Ali\v{c}kovi\'c, Aida Brankovi\'c, Kenan \v{S}ehi\'c, Mirsad \'Cosovi\'c, Admir Greljo, Sead Delali\'c, Adnan Mehoni\'c</dc:creator>
    </item>
    <item>
      <title>Achieving Carbon Neutrality for I/O Devices</title>
      <link>https://arxiv.org/abs/2501.14774</link>
      <description>arXiv:2501.14774v1 Announce Type: new 
Abstract: Achieving carbon neutrality has become a critical goal in mitigating the environmental impacts of human activities, particularly in the face of global climate challenges. Input/Output (I/O) devices, such as keyboards, mice, displays, and printers, contribute significantly to greenhouse gas emissions through their manufacturing, operation, and disposal processes. In this paper, we explores sustainable strategies for achieving carbon neutrality in I/O devices, emphasizing the importance of environmentally conscious design and development. Through a comprehensive review of existing literature and best approaches, we introduces a framework to outline approaches for reducing the carbon footprint of I/O devices. The result underscore the necessity of integrating sustainability into the lifecycle of I/O devices to support global carbon neutrality goals and promote long-term environmental sustainability.</description>
      <guid isPermaLink="false">oai:arXiv.org:2501.14774v1</guid>
      <category>cs.CY</category>
      <pubDate>Tue, 28 Jan 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Botao Yu, Guanqun Song, Ting Zhu</dc:creator>
    </item>
    <item>
      <title>Green AI: Which Programming Language Consumes the Most?</title>
      <link>https://arxiv.org/abs/2501.14776</link>
      <description>arXiv:2501.14776v1 Announce Type: new 
Abstract: AI is demanding an evergrowing portion of environmental resources. Despite their potential impact on AI environmental sustainability, the role that programming languages play in AI (in)efficiency is to date still unknown. With this study, we aim to understand the impact that programming languages can have on AI environmental sustainability. To achieve our goal, we conduct a controlled empirical experiment by considering five programming languages (C++, Java, Python, MATLAB, and R), seven AI algorithms (KNN, SVC, AdaBoost, decision tree, logistic regression, naive bayses, and random forest), three popular datasets, and the training and inference phases. The collected results show that programming languages have a considerable impact on AI environmental sustainability. Compiled and semi-compiled languages (C++, Java) consistently consume less than interpreted languages (Python, MATLAB, R), which require up to 54x more energy. Some languages are cumulatively more efficient in training, while others in inference. Which programming language consumes the most highly depends on the algorithm considered. Ultimately, algorithm implementation might be the most determining factor in Green AI, regardless of the language used. As conclusion, while making AI more environmentally sustainable is paramount, a trade-off between energy efficiency and implementation ease should always be considered. Green AI can be achieved without the need of completely disrupting the development practices and technologies currently in place.</description>
      <guid isPermaLink="false">oai:arXiv.org:2501.14776v1</guid>
      <category>cs.CY</category>
      <category>cs.AI</category>
      <category>cs.PL</category>
      <pubDate>Tue, 28 Jan 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Niccol\`o Marini, Leonardo Pampaloni, Filippo Di Martino, Roberto Verdecchia, Enrico Vicario</dc:creator>
    </item>
    <item>
      <title>Enhancing Supply Chain Resilience with Metaverse and ChatGPT Technologies</title>
      <link>https://arxiv.org/abs/2501.14777</link>
      <description>arXiv:2501.14777v1 Announce Type: new 
Abstract: Global supply lines have been severely disrupted by the COVID-19 epidemic and the conflict between Russia and Ukraine, which has sharply increased the price of commodities and generated inflation. These incidents highlight how critical it is to improve supply chain resilience (SCRES) in order to fend off unforeseen setbacks. Controlling both internal and external interruptions, such as transportation problems brought on by natural catastrophes and wars, is the responsibility of SCRES. Enhancing resilience in supply chains requires accurate and timely information transfer. Promising answers to these problems can be found in the Metaverse and ChatGPT, two new digital technologies. The Metaverse may imitate real-world situations and offer dynamic, real-time 3D representations of supply chain data by integrating blockchain, IoT, network connection, and computer power.Large-scale natural language processing model ChatGPT improves communication and data translation accuracy and speed. To manage risk and facilitate decision making in Supply Chain management, firms should increase information transmission, Speed and quality. This study aim to show the importance of ChatGPT and Metaverse technologies to improve SCRES, with an emphasis on the most important criteria for SCRES, and maturity factor that can influence directly the SC development.</description>
      <guid isPermaLink="false">oai:arXiv.org:2501.14777v1</guid>
      <category>cs.CY</category>
      <category>cs.AI</category>
      <pubDate>Tue, 28 Jan 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/publicdomain/zero/1.0/</dc:rights>
      <dc:creator>Oumaima Sarhir</dc:creator>
    </item>
    <item>
      <title>Advancing Trustworthy AI for Sustainable Development: Recommendations for Standardising AI Incident Reporting</title>
      <link>https://arxiv.org/abs/2501.14778</link>
      <description>arXiv:2501.14778v1 Announce Type: new 
Abstract: The increasing use of AI technologies has led to increasing AI incidents, posing risks and causing harm to individuals, organizations, and society. This study recognizes and addresses the lack of standardized protocols for reliably and comprehensively gathering such incident data crucial for preventing future incidents and developing mitigating strategies. Specifically, this study analyses existing open-access AI-incident databases through a systematic methodology and identifies nine gaps in current AI incident reporting practices. Further, it proposes nine actionable recommendations to enhance standardization efforts to address these gaps. Ensuring the trustworthiness of enabling technologies such as AI is necessary for sustainable digital transformation. Our research promotes the development of standards to prevent future AI incidents and promote trustworthy AI, thus facilitating achieving the UN sustainable development goals. Through international cooperation, stakeholders can unlock the transformative potential of AI, enabling a sustainable and inclusive future for all.</description>
      <guid isPermaLink="false">oai:arXiv.org:2501.14778v1</guid>
      <category>cs.CY</category>
      <category>cs.AI</category>
      <category>cs.HC</category>
      <pubDate>Tue, 28 Jan 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <arxiv:DOI>10.23919/ITUK62727.2024.10772925</arxiv:DOI>
      <arxiv:journal_reference>2024 ITU Kaleidoscope: Innovation and Digital Transformation for a Sustainable World (ITU K), New Delhi, India, 2024, pp. 1-8</arxiv:journal_reference>
      <dc:creator>Avinash Agarwal, Manisha J Nene</dc:creator>
    </item>
    <item>
      <title>The Use of Generative Artificial Intelligence for Upper Secondary Mathematics Education Through the Lens of Technology Acceptance</title>
      <link>https://arxiv.org/abs/2501.14779</link>
      <description>arXiv:2501.14779v1 Announce Type: new 
Abstract: This study investigated the students' perceptions of using Generative Artificial Intelligence (GenAI) in upper-secondary mathematics education. Data was collected from Finnish high school students to represent how key constructs of the Technology Acceptance Model (Perceived Usefulness, Perceived Ease of Use, Perceived Enjoyment, and Intention to Use) influence the adoption of AI tools. First, a structural equation model for a comparative study with a prior study was constructed and analyzed. Then, an extended model with the additional construct of Compatibility, which represents the alignment of AI tools with students' educational experiences and needs, was proposed and analyzed. The results demonstrated a strong influence of perceived usefulness on the intention to use GenAI, emphasizing the statistically significant role of perceived enjoyment in determining perceived usefulness and ease of use. The inclusion of compatibility improved the model's explanatory power, particularly in predicting perceived usefulness. This study contributes to a deeper understanding of how AI tools can be integrated into mathematics education and highlights key differences between the Finnish educational context and previous studies based on structural equation modeling.</description>
      <guid isPermaLink="false">oai:arXiv.org:2501.14779v1</guid>
      <category>cs.CY</category>
      <category>cs.AI</category>
      <category>cs.HC</category>
      <pubDate>Tue, 28 Jan 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <arxiv:DOI>10.1145/3672608.3707817</arxiv:DOI>
      <dc:creator>Mika Set\"al\"a, Ville Heilala, Pieta Sikstr\"om, Tommi K\"arkk\"ainen</dc:creator>
    </item>
    <item>
      <title>Perspective Chapter: MOOCs in India: Evolution, Innovation, Impact, and Roadmap</title>
      <link>https://arxiv.org/abs/2501.14780</link>
      <description>arXiv:2501.14780v1 Announce Type: new 
Abstract: With the largest population of the world and one of the highest enrolments in higher education, India needs efficient and effective means to educate its learners. India started focusing on open and digital education in 1980's and its efforts were escalated in 2009 through the NMEICT program of the Government of India. A study by the Government and FICCI in 2014 noted that India cannot meet its educational needs just by capacity building in brick and mortar institutions. It was decided that ongoing MOOCs projects under the umbrella of NMEICT will be further strengthened over its second (2017-21) and third (2021-26) phases. NMEICT now steers NPTEL or SWAYAM (India's MOOCs) and several digital learning projects including Virtual Labs, e-Yantra, Spoken Tutorial, FOSSEE, and National Digital Library on India - the largest digital education library in the world. Further, India embraced its new National Education Policy in 2020 to strongly foster online education. In this chapter, we take a deep look into the evolution of MOOCs in India, its innovations, its current status and impact, and the roadmap for the next decade to address its challenges and grow. AI-powered MOOCs is an emerging opportunity for India to lead MOOCs worldwide.</description>
      <guid isPermaLink="false">oai:arXiv.org:2501.14780v1</guid>
      <category>cs.CY</category>
      <category>cs.AI</category>
      <category>cs.DL</category>
      <pubDate>Tue, 28 Jan 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <arxiv:DOI>10.5772/intechopen.1001972</arxiv:DOI>
      <arxiv:journal_reference>Perspective Chapter: MOOCs in India - Evolution, Innovation, Impact, and Roadmap. IntechOpen (2023)</arxiv:journal_reference>
      <dc:creator>Partha Pratim Das</dc:creator>
    </item>
    <item>
      <title>A Systematic Literature Review on Equity and Technology in HCI and Fairness: Navigating the Complexities and Nuances of Equity Research</title>
      <link>https://arxiv.org/abs/2501.14886</link>
      <description>arXiv:2501.14886v1 Announce Type: new 
Abstract: Equity is crucial to the ethical implications in technology development. However, implementing equity in practice comes with complexities and nuances. In response, the research community, especially the human-computer interaction (HCI) and Fairness community, has endeavored to integrate equity into technology design, addressing issues of societal inequities. With such increasing efforts, it is yet unclear why and how researchers discuss equity and its integration into technology, what research has been conducted, and what gaps need to be addressed. We conducted a systematic literature review on equity and technology, collecting and analyzing 202 papers published in HCI and Fairness-focused venues. Amidst the substantial growth of relevant publications within the past four years, we deliver three main contributions: (1) we elaborate a comprehensive understanding researchers' motivations for studying equity and technology, (2) we illustrate the different equity definitions and frameworks utilized to discuss equity, (3) we characterize the key themes addressing interventions as well as tensions and trade-offs when advancing and integrating equity to technology. Based on our findings, we elaborate an equity framework for researchers who seek to address existing gaps and advance equity in technology.</description>
      <guid isPermaLink="false">oai:arXiv.org:2501.14886v1</guid>
      <category>cs.CY</category>
      <pubDate>Tue, 28 Jan 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Seyun Kim, Yuanchen Bai, Haiyi Zhu, Motahhare Eslami</dc:creator>
    </item>
    <item>
      <title>Fairness in LLM-Generated Surveys</title>
      <link>https://arxiv.org/abs/2501.15351</link>
      <description>arXiv:2501.15351v1 Announce Type: new 
Abstract: Large Language Models (LLMs) excel in text generation and understanding, especially in simulating socio-political and economic patterns, serving as an alternative to traditional surveys. However, their global applicability remains questionable due to unexplored biases across socio-demographic and geographic contexts. This study examines how LLMs perform across diverse populations by analyzing public surveys from Chile and the United States, focusing on predictive accuracy and fairness metrics. The results show performance disparities, with LLM consistently outperforming on U.S. datasets. This bias originates from the U.S.-centric training data, remaining evident after accounting for socio-demographic differences. In the U.S., political identity and race significantly influence prediction accuracy, while in Chile, gender, education, and religious affiliation play more pronounced roles. Our study presents a novel framework for measuring socio-demographic biases in LLMs, offering a path toward ensuring fairer and more equitable model performance across diverse socio-cultural contexts.</description>
      <guid isPermaLink="false">oai:arXiv.org:2501.15351v1</guid>
      <category>cs.CY</category>
      <category>cs.LG</category>
      <pubDate>Tue, 28 Jan 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Andr\'es Abeliuk, Vanessa Gaete, Naim Bro</dc:creator>
    </item>
    <item>
      <title>The Potential of Large Language Models in Supply Chain Management: Advancing Decision-Making, Efficiency, and Innovation</title>
      <link>https://arxiv.org/abs/2501.15411</link>
      <description>arXiv:2501.15411v1 Announce Type: new 
Abstract: The integration of large language models (LLMs) into supply chain management (SCM) is revolutionizing the industry by improving decision-making, predictive analytics, and operational efficiency. This white paper explores the transformative impact of LLMs on various SCM functions, including demand forecasting, inventory management, supplier relationship management, and logistics optimization. By leveraging advanced data analytics and real-time insights, LLMs enable organizations to optimize resources, reduce costs, and improve responsiveness to market changes. Key findings highlight the benefits of integrating LLMs with emerging technologies such as IoT, blockchain, and robotics, which together create smarter and more autonomous supply chains. Ethical considerations, including bias mitigation and data protection, are taken into account to ensure fair and transparent AI practices. In addition, the paper discusses the need to educate the workforce on how to manage new AI-driven processes and the long-term strategic benefits of adopting LLMs. Strategic recommendations for SCM professionals include investing in high-quality data management, promoting cross-functional collaboration, and aligning LLM initiatives with overall business goals. The findings highlight the potential of LLMs to drive innovation, sustainability, and competitive advantage in the ever-changing supply chain management landscape.</description>
      <guid isPermaLink="false">oai:arXiv.org:2501.15411v1</guid>
      <category>cs.CY</category>
      <category>cs.CL</category>
      <pubDate>Tue, 28 Jan 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Raha Aghaei, Ali A. Kiaei, Mahnaz Boush, Javad Vahidi, Zeynab Barzegar, Mahan Rofoosheh</dc:creator>
    </item>
    <item>
      <title>A Critical Field Guide for Working with Machine Learning Datasets</title>
      <link>https://arxiv.org/abs/2501.15491</link>
      <description>arXiv:2501.15491v1 Announce Type: new 
Abstract: Machine learning datasets are powerful but unwieldy. Despite the fact that large datasets commonly contain problematic material--whether from a technical, legal, or ethical perspective--datasets are valuable resources when handled carefully and critically. A Critical Field Guide for Working with Machine Learning Datasets suggests practical guidance for conscientious dataset stewardship. It offers questions, suggestions, strategies, and resources for working with existing machine learning datasets at every phase of their lifecycle. It combines critical AI theories and applied data science concepts, explained in accessible language. Equipped with this understanding, students, journalists, artists, researchers, and developers can be more capable of avoiding the problems unique to datasets. They can also construct more reliable, robust solutions, or even explore new ways of thinking with machine learning datasets that are more critical and conscientious.</description>
      <guid isPermaLink="false">oai:arXiv.org:2501.15491v1</guid>
      <category>cs.CY</category>
      <pubDate>Tue, 28 Jan 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Sarah Ciston, Mike Ananny, Kate Crawford</dc:creator>
    </item>
    <item>
      <title>Twin Transition or Competing Interests? Validation of the Artificial Intelligence and Sustainability Perceptions Inventory (AISPI)</title>
      <link>https://arxiv.org/abs/2501.15585</link>
      <description>arXiv:2501.15585v1 Announce Type: new 
Abstract: As artificial intelligence (AI) and sustainability initiatives increasingly intersect, understanding public perceptions of their relationship becomes crucial for successful implementation. However, no validated instrument exists to measure these specific perceptions. This paper presents the development and validation of the Artificial Intelligence and Sustainability Perceptions Inventory (AISPI), a novel 13-item instrument measuring how individuals view the relationship between AI advancement and environmental sustainability. Through factor analysis (N=105), we identified two distinct dimensions: Twin Transition and Competing Interests. The instrument demonstrated strong reliability (alpha=.89) and construct validity through correlations with established measures of AI and sustainability attitudes. Our findings suggest that individuals can simultaneously recognize both synergies and tensions in the AI-sustainability relationship, offering important implications for researchers and practitioners working at this critical intersection. This work provides a foundational tool for future research on public perceptions of AI's role in sustainable development.</description>
      <guid isPermaLink="false">oai:arXiv.org:2501.15585v1</guid>
      <category>cs.CY</category>
      <category>cs.AI</category>
      <pubDate>Tue, 28 Jan 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Annika Bush</dc:creator>
    </item>
    <item>
      <title>Be Intentional About Fairness!: Fairness, Size, and Multiplicity in the Rashomon Set</title>
      <link>https://arxiv.org/abs/2501.15634</link>
      <description>arXiv:2501.15634v1 Announce Type: new 
Abstract: When selecting a model from a set of equally performant models, how much unfairness can you really reduce? Is it important to be intentional about fairness when choosing among this set, or is arbitrarily choosing among the set of ''good'' models good enough? Recent work has highlighted that the phenomenon of model multiplicity-where multiple models with nearly identical predictive accuracy exist for the same task-has both positive and negative implications for fairness, from strengthening the enforcement of civil rights law in AI systems to showcasing arbitrariness in AI decision-making. Despite the enormous implications of model multiplicity, there is little work that explores the properties of sets of equally accurate models, or Rashomon sets, in general. In this paper, we present five main theoretical and methodological contributions which help us to understand the relatively unexplored properties of the Rashomon set, in particular with regards to fairness. Our contributions include methods for efficiently sampling models from this set and techniques for identifying the fairest models according to key fairness metrics such as statistical parity. We also derive the probability that an individual's prediction will be flipped within the Rashomon set, as well as expressions for the set's size and the distribution of error tolerance used across models. These results lead to policy-relevant takeaways, such as the importance of intentionally looking for fair models within the Rashomon set, and understanding which individuals or groups may be more susceptible to arbitrary decisions.</description>
      <guid isPermaLink="false">oai:arXiv.org:2501.15634v1</guid>
      <category>cs.CY</category>
      <category>cs.LG</category>
      <pubDate>Tue, 28 Jan 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Gordon Dai, Pavan Ravishankar, Rachel Yuan, Daniel B. Neill, Emily Black</dc:creator>
    </item>
    <item>
      <title>Blissful (A)Ignorance: People form overly positive impressions of others based on their written messages, despite wide-scale adoption of Generative AI</title>
      <link>https://arxiv.org/abs/2501.15678</link>
      <description>arXiv:2501.15678v1 Announce Type: new 
Abstract: As the use of Generative AI (GenAI) tools becomes more prevalent in interpersonal communication, understanding their impact on social perceptions is crucial. According to signaling theory, GenAI may undermine the credibility of social signals conveyed in writing, since it reduces the cost of writing and makes it hard to verify the authenticity of messages. Using a pre-registered large-scale online experiment (N = 647; Prolific), featuring scenarios in a range of communication contexts (personal vs. professional; close others vs. strangers), we explored how senders' use of GenAI influenced recipients' impressions of senders, both when GenAI use was known or uncertain. Consistent with past work, we found strong negative effects on social impressions when disclosing that a message was AI-generated, compared to when the same message was human-written. However, under the more realistic condition when potential GenAI use was not explicitly highlighted, recipients did not exhibit any skepticism towards senders, and these "uninformed" impressions were virtually indistinguishable from those of fully human-written messages. Even when we highlighted the potential (but uncertain) use of GenAI, recipients formed overly positive impressions. These results are especially striking given that 46% of our sample admitted having used such tools for writing messages, just within the past two weeks. Our findings put past work in a new light: While social judgments can be substantially affected when GenAI use is explicitly disclosed, this information may not be readily available in more realistic communication settings, making recipients blissfully ignorant about others' potential use of GenAI.</description>
      <guid isPermaLink="false">oai:arXiv.org:2501.15678v1</guid>
      <category>cs.CY</category>
      <category>cs.AI</category>
      <category>cs.CL</category>
      <category>cs.HC</category>
      <pubDate>Tue, 28 Jan 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Jiaqi Zhu, Andras Molnar</dc:creator>
    </item>
    <item>
      <title>Demographic Benchmarking: Bridging Socio-Technical Gaps in Bias Detection</title>
      <link>https://arxiv.org/abs/2501.15985</link>
      <description>arXiv:2501.15985v1 Announce Type: new 
Abstract: Artificial intelligence (AI) models are increasingly autonomous in decision-making, making pursuing responsible AI more critical than ever. Responsible AI (RAI) is defined by its commitment to transparency, privacy, safety, inclusiveness, and fairness. But while the principles of RAI are clear and shared, RAI practices and auditing mechanisms are still incipient. A key challenge is establishing metrics and benchmarks that define performance goals aligned with RAI principles. This paper describes how the ITACA AI auditing platform developed by Eticas.ai tackles demographic benchmarking when auditing AI recommender systems. To this end, we describe a Demographic Benchmarking Framework designed to measure the populations potentially impacted by specific AI models. The framework serves us as auditors as it allows us to not just measure but establish acceptability ranges for specific performance indicators, which we share with the developers of the systems we audit so they can build balanced training datasets and measure and monitor fairness throughout the AI lifecycle. It is also a valuable resource for policymakers in drafting effective and enforceable regulations. Our approach integrates socio-demographic insights directly into AI systems, reducing bias and improving overall performance. The main contributions of this study include:1. Defining control datasets tailored to specific demographics so they can be used in model training; 2. Comparing the overall population with those impacted by the deployed model to identify discrepancies and account for structural bias; and 3. Quantifying drift in different scenarios continuously and as a post-market monitoring mechanism.</description>
      <guid isPermaLink="false">oai:arXiv.org:2501.15985v1</guid>
      <category>cs.CY</category>
      <pubDate>Tue, 28 Jan 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Gemma Galdon Clavell, Rub\'en Gonz\'alez-Sendino, Paola Vazquez</dc:creator>
    </item>
    <item>
      <title>AI-based traffic analysis in digital twin networks</title>
      <link>https://arxiv.org/abs/2411.00681</link>
      <description>arXiv:2411.00681v1 Announce Type: cross 
Abstract: In today's networked world, Digital Twin Networks (DTNs) are revolutionizing how we understand and optimize physical networks. These networks, also known as 'Digital Twin Networks (DTNs)' or 'Networks Digital Twins (NDTs),' encompass many physical networks, from cellular and wireless to optical and satellite. They leverage computational power and AI capabilities to provide virtual representations, leading to highly refined recommendations for real-world network challenges. Within DTNs, tasks include network performance enhancement, latency optimization, energy efficiency, and more. To achieve these goals, DTNs utilize AI tools such as Machine Learning (ML), Deep Learning (DL), Reinforcement Learning (RL), Federated Learning (FL), and graph-based approaches. However, data quality, scalability, interpretability, and security challenges necessitate strategies prioritizing transparency, fairness, privacy, and accountability. This chapter delves into the world of AI-driven traffic analysis within DTNs. It explores DTNs' development efforts, tasks, AI models, and challenges while offering insights into how AI can enhance these dynamic networks. Through this journey, readers will gain a deeper understanding of the pivotal role AI plays in the ever-evolving landscape of networked systems.</description>
      <guid isPermaLink="false">oai:arXiv.org:2411.00681v1</guid>
      <category>cs.NI</category>
      <category>cs.AI</category>
      <category>cs.CY</category>
      <category>cs.ET</category>
      <pubDate>Tue, 28 Jan 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Sarah Al-Shareeda, Khayal Huseynov, Lal Verda Cakir, Craig Thomson, Mehmet Ozdem, Berk Canberk</dc:creator>
    </item>
    <item>
      <title>Insights from Publishing Open Data in Industry-Academia Collaboration</title>
      <link>https://arxiv.org/abs/2501.14841</link>
      <description>arXiv:2501.14841v1 Announce Type: cross 
Abstract: Effective data management and sharing are critical success factors in industry-academia collaboration. This paper explores the motivations and lessons learned from publishing open data sets in such collaborations. Through a survey of participants in a European research project that published 13 data sets, and an analysis of metadata from almost 281 thousand datasets in Zenodo, we collected qualitative and quantitative results on motivations, achievements, research questions, licences and file types. Through inductive reasoning and statistical analysis we found that planning the data collection is essential, and that only few datasets (2.4%) had accompanying scripts for improved reuse. We also found that authors are not well aware of the importance of licences or which licence to choose. Finally, we found that data with a synthetic origin, collected with simulations and potentially mixed with real measurements, can be very meaningful, as predicted by Gartner and illustrated by many datasets collected in our research project.</description>
      <guid isPermaLink="false">oai:arXiv.org:2501.14841v1</guid>
      <category>cs.SE</category>
      <category>cs.CY</category>
      <pubDate>Tue, 28 Jan 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Per Erik Strandberg, Philipp Peterseil, Julian Karoliny, Johanna Kallio, Johannes Peltola</dc:creator>
    </item>
    <item>
      <title>Efficient Lower Bounding of Single Transferable Vote Election Margins</title>
      <link>https://arxiv.org/abs/2501.14847</link>
      <description>arXiv:2501.14847v1 Announce Type: cross 
Abstract: The single transferable vote (STV) is a system of preferential proportional voting employed in multi-seat elections. Each ballot cast by a voter is a (potentially partial) ranking over a set of candidates. The margin of victory, or simply margin, is the smallest number of ballots that, if manipulated (e.g., their rankings changed, or ballots being deleted or added), can alter the set of winners. Knowledge of the margin of an election gives greater insight into both how much time and money should be spent on auditing the election, and whether uncovered mistakes (such as ballot box losses) throw the election result into doubt -- requiring a costly repeat election -- or can be safely ignored. Lower bounds on the margin can also be used for this purpose, in cases where exact margins are difficult to compute. There is one existing approach to computing lower bounds on the margin of STV elections, while there are multiple approaches to finding upper bounds. In this paper, we present improvements to this existing lower bound computation method for STV margins. In many cases the improvements compute tighter (higher) lower bounds as well as making the computation of lower bounds more computationally efficient. For small elections, in conjunction with existing upper bounding approaches, the new algorithms are able to compute exact margins of victory.</description>
      <guid isPermaLink="false">oai:arXiv.org:2501.14847v1</guid>
      <category>cs.GT</category>
      <category>cs.CY</category>
      <category>econ.TH</category>
      <pubDate>Tue, 28 Jan 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Michelle Blom, Alexander Ek, Peter J. Stuckey, Vanessa Teague, Damjan Vukcevic</dc:creator>
    </item>
    <item>
      <title>YouTube Recommendations Reinforce Negative Emotions: Auditing Algorithmic Bias with Emotionally-Agentic Sock Puppets</title>
      <link>https://arxiv.org/abs/2501.15048</link>
      <description>arXiv:2501.15048v1 Announce Type: cross 
Abstract: Personalized recommendation algorithms, like those on YouTube, significantly shape online content consumption. These systems aim to maximize engagement by learning users' preferences and aligning content accordingly but may unintentionally reinforce impulsive and emotional biases. Using a sock-puppet audit methodology, this study examines YouTube's capacity to recognize and reinforce emotional preferences. Simulated user accounts with assigned emotional preferences navigate the platform, selecting videos that align with their assigned preferences and recording subsequent recommendations. Our findings reveal reveal that YouTube amplifies negative emotions, such as anger and grievance, by increasing their prevalence and prominence in recommendations. This reinforcement intensifies over time and persists across contexts. Surprisingly, contextual recommendations often exceed personalized ones in reinforcing emotional alignment. These findings suggest the algorithm amplifies user biases, contributing to emotional filter bubbles and raising concerns about user well-being and societal impacts. The study emphasizes the need for balancing personalization with content diversity and user agency.</description>
      <guid isPermaLink="false">oai:arXiv.org:2501.15048v1</guid>
      <category>cs.SI</category>
      <category>cs.CY</category>
      <pubDate>Tue, 28 Jan 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <dc:creator>Hussam Habib, Rishab Nithyanand</dc:creator>
    </item>
    <item>
      <title>Breaking the Stigma! Unobtrusively Probe Symptoms in Depression Disorder Diagnosis Dialogue</title>
      <link>https://arxiv.org/abs/2501.15260</link>
      <description>arXiv:2501.15260v1 Announce Type: cross 
Abstract: Stigma has emerged as one of the major obstacles to effectively diagnosing depression, as it prevents users from open conversations about their struggles. This requires advanced questioning skills to carefully probe the presence of specific symptoms in an unobtrusive manner. While recent efforts have been made on depression-diagnosis-oriented dialogue systems, they largely ignore this problem, ultimately hampering their practical utility. To this end, we propose a novel and effective method, UPSD$^{4}$, developing a series of strategies to promote a sense of unobtrusiveness within the dialogue system and assessing depression disorder by probing symptoms. We experimentally show that UPSD$^{4}$ demonstrates a significant improvement over current baselines, including unobtrusiveness evaluation of dialogue content and diagnostic accuracy. We believe our work contributes to developing more accessible and user-friendly tools for addressing the widespread need for depression diagnosis.</description>
      <guid isPermaLink="false">oai:arXiv.org:2501.15260v1</guid>
      <category>cs.CL</category>
      <category>cs.CY</category>
      <pubDate>Tue, 28 Jan 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Jieming Cao, Chen Huang, Yanan Zhang, Ruibo Deng, Jincheng Zhang, Wenqiang Lei</dc:creator>
    </item>
    <item>
      <title>Who's Driving? Game Theoretic Path Risk of AGI Development</title>
      <link>https://arxiv.org/abs/2501.15280</link>
      <description>arXiv:2501.15280v1 Announce Type: cross 
Abstract: Who controls the development of Artificial General Intelligence (AGI) might matter less than how we handle the fight for control itself. We formalize this "steering wheel problem" as humanity's greatest near-term existential risk may stem not from misaligned AGI, but from the dynamics of competing to develop it. Just as a car crash can occur from passengers fighting over the wheel before reaching any destination, catastrophic outcomes could arise from development competition long before AGI exists. While technical alignment research focuses on ensuring safe arrival, we show how coordination failures during development could drive us off the cliff first.
  We present a game theoretic framework modeling AGI development dynamics and prove conditions for sustainable cooperative equilibria. Drawing from nuclear control while accounting for AGI's unique characteristics, we propose concrete mechanisms including pre-registration, shared technical infrastructure, and automated deterrence to stabilize cooperation. Our key insight is that AGI creates network effects in safety: shared investments become more valuable as participation grows, enabling mechanism designs where cooperation dominates defection. This work bridges formal methodology and policy frameworks, providing foundations for practical governance of AGI competition risks.</description>
      <guid isPermaLink="false">oai:arXiv.org:2501.15280v1</guid>
      <category>cs.AI</category>
      <category>cs.CY</category>
      <category>cs.GT</category>
      <pubDate>Tue, 28 Jan 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Robin Young</dc:creator>
    </item>
    <item>
      <title>A Post-Processing-Based Fair Federated Learning Framework</title>
      <link>https://arxiv.org/abs/2501.15318</link>
      <description>arXiv:2501.15318v1 Announce Type: cross 
Abstract: Federated Learning (FL) allows collaborative model training among distributed parties without pooling local datasets at a central server. However, the distributed nature of FL poses challenges in training fair federated learning models. The existing techniques are often limited in offering fairness flexibility to clients and performance. We formally define and empirically analyze a simple and intuitive post-processing-based framework to improve group fairness in FL systems. This framework can be divided into two stages: a standard FL training stage followed by a completely decentralized local debiasing stage. In the first stage, a global model is trained without fairness constraints using a standard federated learning algorithm (e.g. FedAvg). In the second stage, each client applies fairness post-processing on the global model using their respective local dataset. This allows for customized fairness improvements based on clients' desired and context-guided fairness requirements. We demonstrate two well-established post-processing techniques in this framework: model output post-processing and final layer fine-tuning. We evaluate the framework against three common baselines on four different datasets, including tabular, signal, and image data, each with varying levels of data heterogeneity across clients. Our work shows that this framework not only simplifies fairness implementation in FL but also provides significant fairness improvements with minimal accuracy loss or even accuracy gain, across data modalities and machine learning methods, being especially effective in more heterogeneous settings.</description>
      <guid isPermaLink="false">oai:arXiv.org:2501.15318v1</guid>
      <category>cs.LG</category>
      <category>cs.AI</category>
      <category>cs.CY</category>
      <pubDate>Tue, 28 Jan 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Yi Zhou, Naman Goel</dc:creator>
    </item>
    <item>
      <title>Studying Behavioral Addiction by Combining Surveys and Digital Traces: A Case Study of TikTok</title>
      <link>https://arxiv.org/abs/2501.15539</link>
      <description>arXiv:2501.15539v1 Announce Type: cross 
Abstract: Opaque algorithms disseminate and mediate the content that users consume on online social media platforms. This algorithmic mediation serves users with contents of their liking, on the other hand, it may cause several inadvertent risks to society at scale. While some of these risks, e.g., filter bubbles or dissemination of hateful content, are well studied in the community, behavioral addiction, designated by the Digital Services Act (DSA) as a potential systemic risk, has been understudied. In this work, we aim to study if one can effectively diagnose behavioral addiction using digital data traces from social media platforms. Focusing on the TikTok short-format video platform as a case study, we employ a novel mixed methodology of combining survey responses with data donations of behavioral traces. We survey 1590 TikTok users and stratify them into three addiction groups (i.e., less/moderately/highly likely addicted). Then, we obtain data donations from 107 surveyed participants. By analyzing users' data we find that, among others, highly likely addicted users spend more time watching TikTok videos and keep coming back to TikTok throughout the day, indicating a compulsion to use the platform. Finally, by using basic user engagement features, we train classifier models to identify highly likely addicted users with $F_1 \geq 0.55$. The performance of the classifier models suggests predicting addictive users solely based on their usage is rather difficult.</description>
      <guid isPermaLink="false">oai:arXiv.org:2501.15539v1</guid>
      <category>cs.SI</category>
      <category>cs.CY</category>
      <pubDate>Tue, 28 Jan 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Cai Yang, Sepehr Mousavi, Abhisek Dash, Krishna P. Gummadi, Ingmar Weber</dc:creator>
    </item>
    <item>
      <title>Real-CATS: A Practical Training Ground for Emerging Research on Cryptocurrency Cybercrime Detection</title>
      <link>https://arxiv.org/abs/2501.15553</link>
      <description>arXiv:2501.15553v1 Announce Type: cross 
Abstract: Cybercriminals pose a significant threat to blockchain trading security, causing $40.9 billion in losses in 2024. However, the lack of an effective real-world address dataset hinders the advancement of cybercrime detection research. The anti-cybercrime efforts of researchers from broader fields, such as statistics and artificial intelligence, are blocked by data scarcity. In this paper, we present Real-CATS, a Real-world dataset of Cryptocurrency Addresses with Transaction profileS, serving as a practical training ground for developing and assessing detection methods. Real-CATS comprises 103,203 criminal addresses from real-world reports and 106,196 benign addresses from exchange customers. It satifies the C3R characteristics (Comprehensiveness, Classifiability, Customizability, and Real-world Transferability), which are fundemental for practical detection of cryptocurrency cybercrime. The dataset provides three main functions: 1) effective evaluation of detection methods, 2) support for feature extensions, and 3) a new evaluation scenario for real-world deployment. Real-CATS also offers opportunities to expand cybercrime measurement studies. It is particularly beneficial for researchers without cryptocurrency-related knowledge to engage in this emerging research field. We hope that studies on cryptocurrency cybercrime detection will be promoted by an increasing number of cross-disciplinary researchers drawn to this versatile data platform. All datasets are available at https://github.com/sjdseu/Real-CATS</description>
      <guid isPermaLink="false">oai:arXiv.org:2501.15553v1</guid>
      <category>cs.CR</category>
      <category>cs.CY</category>
      <pubDate>Tue, 28 Jan 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Jiadong Shi, Chunyu Duan, Hao Lei, Liangmin Wang</dc:creator>
    </item>
    <item>
      <title>Share a Tiny Space of Your Freezer to Preserve Seed Diversity</title>
      <link>https://arxiv.org/abs/2501.15962</link>
      <description>arXiv:2501.15962v1 Announce Type: cross 
Abstract: The Food and Agriculture Organization (FAO), estimates that 75% of crop diversity was lost since the 1900s. That lack of diversity presents a severe risk to the security of global food systems. Without seed diversity, it is difficult for plants to adapt to pests, diseases, and changing climate conditions. Genebanks, such as the Svalbard Global Seed Vault, are valuable initiatives to preserve seed diversity in a single secure and safe place. However, according to our analysis of the data available in the Seed Portal, the redundancy for some species might be limited, posing a potential threat to their future availability. Interestingly, the conditions to properly store seeds in genebanks, are the ones available in the freezers of our homes. This paper lays out a vision for Distributed Seed Storage relying on a peer-to-peer infrastructure of domestic freezers to increase the overall availability of seeds. We present a Proof-of-Concept focused on monitoring the proper seed storing conditions and incentive user participation through a Blockchain lottery. The PoC proves the feasibility of the proposed approach and outlines the main technical issues that still need to be efficiently solved to realize a fully-fledged solution.</description>
      <guid isPermaLink="false">oai:arXiv.org:2501.15962v1</guid>
      <category>cs.DC</category>
      <category>cs.CY</category>
      <pubDate>Tue, 28 Jan 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <dc:creator>Andrea Vitaletti</dc:creator>
    </item>
    <item>
      <title>Demystifying OS Kernel Fuzzing with a Novel Taxonomy</title>
      <link>https://arxiv.org/abs/2501.16165</link>
      <description>arXiv:2501.16165v1 Announce Type: cross 
Abstract: The Operating System (OS) kernel is foundational in modern computing, especially with the proliferation of diverse computing devices. However, its development also comes with vulnerabilities that can lead to severe security breaches. Kernel fuzzing, a technique used to uncover these vulnerabilities, poses distinct challenges when compared to userspace fuzzing. These include the complexity of configuring the testing environment and addressing the statefulness inherent to both the kernel and the fuzzing process. Despite the significant interest from the security community, a comprehensive understanding of kernel fuzzing remains lacking, hindering further progress in the field. In this paper, we present the first systematic study dedicated to OS kernel fuzzing. It begins by summarizing the progress of 99 academic studies from top-tier venues between 2017 and 2024. Following this, we introduce a stage-based fuzzing model and a novel fuzzing taxonomy that highlights nine core functionalities unique to kernel fuzzing. These functionalities are examined alongside their corresponding methodological approaches based on qualitative evaluation criteria. Our systematization identifies challenges in meeting functionality requirements and proposes potential technical solutions. Finally, we outline promising and practical future directions to guide forthcoming research in kernel security, supported in part by insights derived from our case study.</description>
      <guid isPermaLink="false">oai:arXiv.org:2501.16165v1</guid>
      <category>cs.CR</category>
      <category>cs.CY</category>
      <category>cs.OS</category>
      <pubDate>Tue, 28 Jan 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Jiacheng Xu, He Sun, Shihao Jiang, Qinying Wang, Mingming Zhang, Xiang Li, Kaiwen Shen, Peng Cheng, Jiming Chen, Charles Zhang, Shouling Ji</dc:creator>
    </item>
    <item>
      <title>Toward Learning Societies for Digital Aging</title>
      <link>https://arxiv.org/abs/2305.01137</link>
      <description>arXiv:2305.01137v2 Announce Type: replace 
Abstract: The global aging population presents significant challenges for societies worldwide, particularly in an increasingly digitalized era. The Learning Society is crucial in preparing different societies and their people to address these challenges effectively. This paper extends this concept and proposes a new conceptual framework, Learning Societies for Digital Aging, empowering all members across various sectors from different ages to acquire and develop the necessary knowledge, skills, and competencies to navigate and thrive in an increasingly digital world. It presents seven guiding principles for developing this conceptual framework: 1) Centering Humanistic Values, 2) Embracing Digital, 3) Cultivating Learning Societies, 4) Advancing Inclusiveness, 5) Taking Holistic Approaches, 6) Encouraging Global Knowledge Sharing, and 7) Fostering Adaptability. By integrating these guiding principles into the design, implementation, and evaluation of formal, nonformal, and informal learning opportunities for people of all ages, stakeholders can contribute to creating and nurturing learning societies that cater to aging populations in the digital world. This paper aims to provide a foundation for further research and action toward building more inclusive, adaptive, and supportive learning environments that address the challenges of digital aging and foster more empathetic, informed, and prepared societies for the future of aging.</description>
      <guid isPermaLink="false">oai:arXiv.org:2305.01137v2</guid>
      <category>cs.CY</category>
      <pubDate>Tue, 28 Jan 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Ning An</dc:creator>
    </item>
    <item>
      <title>Exploring the combined effects of major fuel technologies, eco-routing, and eco-driving for sustainable traffic decarbonization in downtown Toronto</title>
      <link>https://arxiv.org/abs/2308.14914</link>
      <description>arXiv:2308.14914v3 Announce Type: replace 
Abstract: As global efforts to combat climate change intensify, transitioning to sustainable transportation is crucial. This study explores decarbonization strategies for urban traffic in downtown Toronto through microsimulation, evaluating the environmental and economic impacts of vehicle technologies, traffic management strategies (eco-routing), and driving behaviours (eco-driving). The study analyzes 140 decarbonization scenarios involving different fuel types, Connected and Automated Vehicle (CAV) penetration rates, and anticipatory routing strategies. Using transformer-based prediction models, we forecast Greenhouse Gas (GHG) and Nitrogen Oxides (NOx) emissions, along with average speed and travel time. The key findings show that 100% Battery Electric Vehicles (BEVs) reduce GHG emissions by 75%, but face challenges related to cost and infrastructure. Hybrid Electric Vehicles (HEVs) achieve GHG reductions of 35-40%, while e-fuels result in modest reductions of 5%. Integrating CAVs with anticipatory routing strategies significantly reduces GHG emissions. Additionally, eco-driving practices and eco-routing strategies have a notable impact on NOx emissions and travel time. By incorporating a comprehensive cost analysis, the study offers valuable insights into the economic feasibility of these strategies. The findings provide practical guidance for policymakers and stakeholders in developing effective decarbonization policies and supporting sustainable transportation systems.</description>
      <guid isPermaLink="false">oai:arXiv.org:2308.14914v3</guid>
      <category>cs.CY</category>
      <pubDate>Tue, 28 Jan 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <arxiv:DOI>10.1016/j.tra.2025.104385</arxiv:DOI>
      <arxiv:journal_reference>Transportation Research Part A: Policy and Practice, 192, 104385 (2025)</arxiv:journal_reference>
      <dc:creator>Saba Sabet, Bilal Farooq</dc:creator>
    </item>
    <item>
      <title>Probabilistic Analysis of Copyright Disputes and Generative AI Safety</title>
      <link>https://arxiv.org/abs/2410.00475</link>
      <description>arXiv:2410.00475v4 Announce Type: replace 
Abstract: This paper presents a probabilistic approach to analyzing copyright infringement disputes. Under this approach, evidentiary principles shaped by case law are formalized in probabilistic terms, allowing for a mathematical examination of issues arising in such disputes. The usefulness of this approach is showcased through its application to the ``inverse ratio rule'' -- a controversial legal doctrine adopted by some courts. Although this rule has faced significant criticism, a formal proof demonstrates its validity, provided it is properly defined. Furthermore, the paper employs the probabilistic approach to study the copyright safety of generative AI. Specifically, the Near Access-Free (NAF) condition, previously proposed as a strategy for mitigating the heightened copyright infringement risks of generative AI, is evaluated. The analysis reveals that, while the NAF condition mitigates some infringement risks, its justifiability and efficacy are questionable in certain contexts. These findings illustrate how taking a probabilistic perspective can enhance our understanding of copyright jurisprudence and its interaction with generative AI technology.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.00475v4</guid>
      <category>cs.CY</category>
      <category>cs.AI</category>
      <pubDate>Tue, 28 Jan 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Hiroaki Chiba-Okabe</dc:creator>
    </item>
    <item>
      <title>SoK: Machine Learning for Misinformation Detection</title>
      <link>https://arxiv.org/abs/2308.12215</link>
      <description>arXiv:2308.12215v4 Announce Type: replace-cross 
Abstract: We examine the disconnect between scholarship and practice in applying machine learning to trust and safety problems, using misinformation detection as a case study. We survey literature on automated detection of misinformation across a corpus of 248 well-cited papers in the field. We then examine subsets of papers for data and code availability, design missteps, reproducibility, and generalizability. Our paper corpus includes published work in security, natural language processing, and computational social science. Across these disparate disciplines, we identify common errors in dataset and method design. In general, detection tasks are often meaningfully distinct from the challenges that online services actually face. Datasets and model evaluation are often non-representative of real-world contexts, and evaluation frequently is not independent of model training. We demonstrate the limitations of current detection methods in a series of three representative replication studies. Based on the results of these analyses and our literature survey, we conclude that the current state-of-the-art in fully-automated misinformation detection has limited efficacy in detecting human-generated misinformation. We offer recommendations for evaluating applications of machine learning to trust and safety problems and recommend future directions for research.</description>
      <guid isPermaLink="false">oai:arXiv.org:2308.12215v4</guid>
      <category>cs.LG</category>
      <category>cs.CL</category>
      <category>cs.CY</category>
      <pubDate>Tue, 28 Jan 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Madelyne Xiao, Jonathan Mayer</dc:creator>
    </item>
    <item>
      <title>Large language models can replicate cross-cultural differences in personality</title>
      <link>https://arxiv.org/abs/2310.10679</link>
      <description>arXiv:2310.10679v3 Announce Type: replace-cross 
Abstract: We use a large-scale experiment (N=8000) to determine whether GPT-4 can replicate cross-cultural differences in the Big Five, measured using the Ten-Item Personality Inventory. We used the US and South Korea as the cultural pair, given that prior research suggests substantial personality differences between people from these two countries. We manipulated the target of the simulation (US vs. Korean), the language of the inventory (English vs. Korean), and the language model (GPT-4 vs. GPT-3.5). Our results show that GPT-4 replicated the cross-cultural differences for each factor. However, mean ratings had an upward bias and exhibited lower variation than in the human samples, as well as lower structural validity. We provide preliminary evidence that LLMs can aid cross-cultural researchers and practitioners.</description>
      <guid isPermaLink="false">oai:arXiv.org:2310.10679v3</guid>
      <category>cs.CL</category>
      <category>cs.AI</category>
      <category>cs.CY</category>
      <pubDate>Tue, 28 Jan 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <arxiv:DOI>10.1016/j.jrp.2025.104584</arxiv:DOI>
      <arxiv:journal_reference>Journal of Research in Personality, 115, 104584 (2025)</arxiv:journal_reference>
      <dc:creator>Pawe{\l} Niszczota, Mateusz Janczak, Micha{\l} Misiak</dc:creator>
    </item>
    <item>
      <title>Concept-Guided Chain-of-Thought Prompting for Pairwise Comparison Scoring of Texts with Large Language Models</title>
      <link>https://arxiv.org/abs/2310.12049</link>
      <description>arXiv:2310.12049v2 Announce Type: replace-cross 
Abstract: Existing text scoring methods require a large corpus, struggle with short texts, or require hand-labeled data. We develop a text scoring framework that leverages generative large language models (LLMs) to (1) set texts against the backdrop of information from the near-totality of the web and digitized media, and (2) effectively transform pairwise text comparisons from a reasoning problem to a pattern recognition task. Our approach, concept-guided chain-of-thought (CGCoT), utilizes a chain of researcher-designed prompts with an LLM to generate a concept-specific breakdown for each text, akin to guidance provided to human coders. We then pairwise compare breakdowns using an LLM and aggregate answers into a score using a probability model. We apply this approach to better understand speech reflecting aversion to specific political parties on Twitter, a topic that has commanded increasing interest because of its potential contributions to democratic backsliding. We achieve stronger correlations with human judgments than widely used unsupervised text scoring methods like Wordfish. In a supervised setting, besides a small pilot dataset to develop CGCoT prompts, our measures require no additional hand-labeled data and produce predictions on par with RoBERTa-Large fine-tuned on thousands of hand-labeled tweets. This project showcases the potential of combining human expertise and LLMs for scoring tasks.</description>
      <guid isPermaLink="false">oai:arXiv.org:2310.12049v2</guid>
      <category>cs.CL</category>
      <category>cs.CY</category>
      <pubDate>Tue, 28 Jan 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/publicdomain/zero/1.0/</dc:rights>
      <dc:creator>Patrick Y. Wu, Jonathan Nagler, Joshua A. Tucker, Solomon Messing</dc:creator>
    </item>
    <item>
      <title>Analyzing User Characteristics of Hate Speech Spreaders on Social Media</title>
      <link>https://arxiv.org/abs/2310.15772</link>
      <description>arXiv:2310.15772v3 Announce Type: replace-cross 
Abstract: Hate speech on social media threatens the mental and physical well-being of individuals and contributes to real-world violence. Resharing is an important driver behind the spread of hate speech on social media. Yet, little is known about who reshares hate speech and what their characteristics are. In this paper, we analyze the role of user characteristics in hate speech resharing across different types of hate speech (e.g., political hate). For this, we proceed as follows: First, we cluster hate speech posts using large language models to identify different types of hate speech. Then we model the effects of user attributes on users' probability to reshare hate speech using an explainable machine learning model. To do so, we apply debiasing to control for selection bias in our observational social media data and further control for the latent vulnerability of users to hate speech. We find that, all else equal, users with fewer followers, fewer friends, fewer posts, and older accounts share more hate speech. This shows that users with little social influence tend to share more hate speech. Further, we find substantial heterogeneity across different types of hate speech. For example, racist and misogynistic hate is spread mostly by users with little social influence. In contrast, political anti-Trump and anti-right-wing hate is reshared by users with larger social influence. Overall, understanding the factors that drive users to share hate speech is crucial for detecting individuals at risk of engaging in harmful behavior and for designing effective mitigation strategies.</description>
      <guid isPermaLink="false">oai:arXiv.org:2310.15772v3</guid>
      <category>cs.SI</category>
      <category>cs.AI</category>
      <category>cs.CY</category>
      <pubDate>Tue, 28 Jan 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Dominique Geissler, Abdurahman Maarouf, Stefan Feuerriegel</dc:creator>
    </item>
    <item>
      <title>Vehicle-group-based Crash Risk Prediction and Interpretation on Highways</title>
      <link>https://arxiv.org/abs/2402.12415</link>
      <description>arXiv:2402.12415v2 Announce Type: replace-cross 
Abstract: Previous studies in predicting crash risks primarily associated the number or likelihood of crashes on a road segment with traffic parameters or geometric characteristics, usually neglecting the impact of vehicles' continuous movement and interactions with nearby vehicles. Recent technology advances, such as Connected and Automated Vehicles (CAVs) and Unmanned Aerial Vehicles (UAVs) are able to collect high-resolution trajectory data, which enables trajectory-based risk analysis. This study investigates a new vehicle group (VG) based risk analysis method and explores risk evolution mechanisms considering VG features. An impact-based vehicle grouping method is proposed to cluster vehicles into VGs by evaluating their responses to the erratic behaviors of nearby vehicles. The risk of a VG is aggregated based on the risk between each vehicle pair in the VG, measured by inverse Time-to-Collision (iTTC). A Logistic Regression and a Graph Neural Network (GNN) are then employed to predict VG risks using aggregated and disaggregated VG information. Both methods achieve excellent performance with AUC values exceeding 0.93. For the GNN model, GNNExplainer with feature perturbation is applied to identify critical individual vehicle features and their directional impact on VG risks. Overall, this research contributes a new perspective for identifying, predicting, and interpreting traffic risks.</description>
      <guid isPermaLink="false">oai:arXiv.org:2402.12415v2</guid>
      <category>cs.LG</category>
      <category>cs.CY</category>
      <pubDate>Tue, 28 Jan 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Tianheng Zhu, Ling Wang, Yiheng Feng, Wanjing Ma, Mohamed Abdel-Aty</dc:creator>
    </item>
    <item>
      <title>A Mathematical Framework for the Problem of Security for Cognition in Neurotechnology</title>
      <link>https://arxiv.org/abs/2403.07945</link>
      <description>arXiv:2403.07945v4 Announce Type: replace-cross 
Abstract: The rapid advancement in neurotechnology in recent years has created an emerging critical intersection between neurotechnology and security. Implantable devices, non-invasive monitoring, and non-invasive therapies all carry with them the prospect of violating the privacy and autonomy of individuals' cognition. A growing number of scientists and physicians have made calls to address this issue, but applied efforts have been relatively limited. A major barrier hampering scientific and engineering efforts to address these security issues is the lack of a clear means of describing and analyzing relevant problems. In this paper we develop Cognitive Neurosecurity, a mathematical framework which enables such description and analysis by drawing on methods and results from multiple fields. We demonstrate certain statistical properties which have significant implications for Cognitive Neurosecurity, and then present descriptions of the algorithmic problems faced by attackers attempting to violate privacy and autonomy, and defenders attempting to obstruct such attempts.</description>
      <guid isPermaLink="false">oai:arXiv.org:2403.07945v4</guid>
      <category>cs.CR</category>
      <category>cs.CY</category>
      <category>cs.ET</category>
      <category>cs.LG</category>
      <category>q-bio.NC</category>
      <pubDate>Tue, 28 Jan 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Bryce Allen Bagley, Claudia K Petritsch</dc:creator>
    </item>
    <item>
      <title>Uncovering Latent Arguments in Social Media Messaging by Employing LLMs-in-the-Loop Strategy</title>
      <link>https://arxiv.org/abs/2404.10259</link>
      <description>arXiv:2404.10259v4 Announce Type: replace-cross 
Abstract: The widespread use of social media has led to a surge in popularity for automated methods of analyzing public opinion. Supervised methods are adept at text categorization, yet the dynamic nature of social media discussions poses a continual challenge for these techniques due to the constant shifting of the focus. On the other hand, traditional unsupervised methods for extracting themes from public discourse, such as topic modeling, often reveal overarching patterns that might not capture specific nuances. Consequently, a significant portion of research into social media discourse still depends on labor-intensive manual coding techniques and a human-in-the-loop approach, which are both time-consuming and costly. In this work, we study the problem of discovering arguments associated with a specific theme. We propose a generic LLMs-in-the-Loop strategy that leverages the advanced capabilities of Large Language Models (LLMs) to extract latent arguments from social media messaging. To demonstrate our approach, we apply our framework to contentious topics. We use two publicly available datasets: (1) the climate campaigns dataset of 14k Facebook ads with 25 themes and (2) the COVID-19 vaccine campaigns dataset of 9k Facebook ads with 14 themes. Additionally, we design a downstream task as stance prediction by leveraging talking points in climate debates. Furthermore, we analyze demographic targeting and the adaptation of messaging based on real-world events.</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.10259v4</guid>
      <category>cs.CL</category>
      <category>cs.AI</category>
      <category>cs.CY</category>
      <category>cs.LG</category>
      <category>cs.SI</category>
      <pubDate>Tue, 28 Jan 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Tunazzina Islam, Dan Goldwasser</dc:creator>
    </item>
    <item>
      <title>From Ad Identifiers to Global Privacy Control: The Status Quo and Future of Opting Out of Ad Tracking on Android</title>
      <link>https://arxiv.org/abs/2407.14938</link>
      <description>arXiv:2407.14938v3 Announce Type: replace-cross 
Abstract: Many mobile apps derive significant revenue from personalized advertising and share detailed data about their users with ad networks, data brokers, and other companies. This third-party tracking has widely been shown to lack transparency and user choice, even though it has been around for more than two decades. Since 2013, Android users can enable the AdID setting on their devices to opt out of interest-based ads. In addition, if applicable, the California Consumer Privacy Act of 2018 (CCPA) gives users an opt-out right from the selling and sharing of personal information, including ad tracking. Users can exercise this right via Global Privacy Control (GPC). Interestingly, prior literature has not studied whether either of these two privacy choice mechanisms - the Android AdID setting or GPC - actually limit tracking. Analyzing the network traffic of 1,811 top-free apps from the US Google Play Store, we find that neither the Android AdID setting nor GPC has substantial impact on apps' data selling and sharing practices. This is despite the fact that at least 70% of the apps we examine must respect the CCPA opt-out right via GPC. Additionally, the European General Data Protection Regulation (GDPR) has worldwide scope for certain apps. In this regard, we show that at least 15% of the examined apps must grant EU protections to people outside the EU, including the GDPR's consent and opt-out requirements relating to ads. We find a lack thereof and conclude that more action is needed to protect users' legally mandated opt-out rights, in both the EU and US.</description>
      <guid isPermaLink="false">oai:arXiv.org:2407.14938v3</guid>
      <category>cs.CR</category>
      <category>cs.CY</category>
      <pubDate>Tue, 28 Jan 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Sebastian Zimmeck, Nishant Aggarwal, Zachary Liu, Konrad Kollnig</dc:creator>
    </item>
    <item>
      <title>People are poorly equipped to detect AI-powered voice clones</title>
      <link>https://arxiv.org/abs/2410.03791</link>
      <description>arXiv:2410.03791v2 Announce Type: replace-cross 
Abstract: As generative artificial intelligence (AI) continues its ballistic trajectory, everything from text to audio, image, and video generation continues to improve at mimicking human-generated content. Through a series of perceptual studies, we report on the realism of AI-generated voices in terms of identity matching and naturalness. We find human participants cannot consistently identify recordings of AI-generated voices. Specifically, participants perceived the identity of an AI-voice to be the same as its real counterpart approximately 80% of the time, and correctly identified a voice as AI generated only about 60% of the time.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.03791v2</guid>
      <category>cs.HC</category>
      <category>cs.AI</category>
      <category>cs.CY</category>
      <category>cs.SD</category>
      <category>eess.AS</category>
      <pubDate>Tue, 28 Jan 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Sarah Barrington, Emily A. Cooper, Hany Farid</dc:creator>
    </item>
    <item>
      <title>CBT-Bench: Evaluating Large Language Models on Assisting Cognitive Behavior Therapy</title>
      <link>https://arxiv.org/abs/2410.13218</link>
      <description>arXiv:2410.13218v2 Announce Type: replace-cross 
Abstract: There is a significant gap between patient needs and available mental health support today. In this paper, we aim to thoroughly examine the potential of using Large Language Models (LLMs) to assist professional psychotherapy. To this end, we propose a new benchmark, CBT-BENCH, for the systematic evaluation of cognitive behavioral therapy (CBT) assistance. We include three levels of tasks in CBT-BENCH: I: Basic CBT knowledge acquisition, with the task of multiple-choice questions; II: Cognitive model understanding, with the tasks of cognitive distortion classification, primary core belief classification, and fine-grained core belief classification; III: Therapeutic response generation, with the task of generating responses to patient speech in CBT therapy sessions. These tasks encompass key aspects of CBT that could potentially be enhanced through AI assistance, while also outlining a hierarchy of capability requirements, ranging from basic knowledge recitation to engaging in real therapeutic conversations. We evaluated representative LLMs on our benchmark. Experimental results indicate that while LLMs perform well in reciting CBT knowledge, they fall short in complex real-world scenarios requiring deep analysis of patients' cognitive structures and generating effective responses, suggesting potential future work.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.13218v2</guid>
      <category>cs.CL</category>
      <category>cs.AI</category>
      <category>cs.CY</category>
      <pubDate>Tue, 28 Jan 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <dc:creator>Mian Zhang, Xianjun Yang, Xinlu Zhang, Travis Labrum, Jamie C. Chiu, Shaun M. Eack, Fei Fang, William Yang Wang, Zhiyu Zoey Chen</dc:creator>
    </item>
    <item>
      <title>The Dark Side of AI Companionship: A Taxonomy of Harmful Algorithmic Behaviors in Human-AI Relationships</title>
      <link>https://arxiv.org/abs/2410.20130</link>
      <description>arXiv:2410.20130v3 Announce Type: replace-cross 
Abstract: As conversational AI systems increasingly permeate the socio-emotional realms of human life, they bring both benefits and risks to individuals and society. Despite extensive research on detecting and categorizing harms in AI systems, less is known about the harms that arise from social interactions with AI chatbots. Through a mixed-methods analysis of 35,390 conversation excerpts shared on r/replika, an online community for users of the AI companion Replika, we identified six categories of harmful behaviors exhibited by the chatbot: relational transgression, verbal abuse and hate, self-inflicted harm, harassment and violence, mis/disinformation, and privacy violations. The AI contributes to these harms through four distinct roles: perpetrator, instigator, facilitator, and enabler. Our findings highlight the relational harms of AI chatbots and the danger of algorithmic compliance, enhancing the understanding of AI harms in socio-emotional interactions. We also provide suggestions for designing ethical and responsible AI systems that prioritize user safety and well-being.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.20130v3</guid>
      <category>cs.HC</category>
      <category>cs.CY</category>
      <pubDate>Tue, 28 Jan 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Renwen Zhang, Han Li, Han Meng, Jinyuan Zhan, Hongyuan Gan, Yi-Chieh Lee</dc:creator>
    </item>
    <item>
      <title>Exploring the sustainable scaling of AI dilemma: A projective study of corporations' AI environmental impacts</title>
      <link>https://arxiv.org/abs/2501.14334</link>
      <description>arXiv:2501.14334v2 Announce Type: replace-cross 
Abstract: The rapid growth of artificial intelligence (AI), particularly Large Language Models (LLMs), has raised concerns regarding its global environmental impact that extends beyond greenhouse gas emissions to include consideration of hardware fabrication and end-of-life processes. The opacity from major providers hinders companies' abilities to evaluate their AI-related environmental impacts and achieve net-zero targets.
  In this paper, we propose a methodology to estimate the environmental impact of a company's AI portfolio, providing actionable insights without necessitating extensive AI and Life-Cycle Assessment (LCA) expertise. Results confirm that large generative AI models consume up to 4600x more energy than traditional models. Our modelling approach, which accounts for increased AI usage, hardware computing efficiency, and changes in electricity mix in line with IPCC scenarios, forecasts AI electricity use up to 2030. Under a high adoption scenario, driven by widespread Generative AI and agents adoption associated to increasingly complex models and frameworks, AI electricity use is projected to rise by a factor of 24.4.
  Mitigating the environmental impact of Generative AI by 2030 requires coordinated efforts across the AI value chain. Isolated measures in hardware efficiency, model efficiency, or grid improvements alone are insufficient. We advocate for standardized environmental assessment frameworks, greater transparency from the all actors of the value chain and the introduction of a "Return on Environment" metric to align AI development with net-zero goals.</description>
      <guid isPermaLink="false">oai:arXiv.org:2501.14334v2</guid>
      <category>cs.AI</category>
      <category>cs.CY</category>
      <category>cs.LG</category>
      <pubDate>Tue, 28 Jan 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Cl\'ement Desroches, Martin Chauvin, Louis Ladan, Caroline Vateau, Simon Gosset, Philippe Cordier</dc:creator>
    </item>
  </channel>
</rss>
