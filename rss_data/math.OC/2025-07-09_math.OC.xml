<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>math.OC updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/math.OC</link>
    <description>math.OC updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/math.OC" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Thu, 10 Jul 2025 01:25:46 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Wed, 09 Jul 2025 00:00:00 -0400</pubDate>
    <skipDays>
      <day>Sunday</day>
      <day>Saturday</day>
    </skipDays>
    <item>
      <title>An inexact inertial projective splitting algorithm with strong convergence</title>
      <link>https://arxiv.org/abs/2507.05382</link>
      <description>arXiv:2507.05382v1 Announce Type: new 
Abstract: We propose and study a strongly convergent inexact inertial projective splitting (PS) algorithm for finding zeros of composite monotone inclusion problems involving the sum of finitely many maximal monotone operators. Strong convergence of the iterates is ensured by projections onto the intersection of appropriately defined half-spaces, even in the absence of inertial effects. We also establish iteration-complexity results for the proposed PS method, which likewise hold without requiring inertial terms. The algorithm includes two inertial sequences, controlled by parameters satisfying mild conditions, while preserving strong convergence and enabling iteration-complexity analysis. Furthermore, for more structured monotone inclusion problems, we derive two variants of the main algorithm that employ forward-backward and forward-backward-forward steps.</description>
      <guid isPermaLink="false">oai:arXiv.org:2507.05382v1</guid>
      <category>math.OC</category>
      <pubDate>Wed, 09 Jul 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>M. Marques Alves, J. E. Navarro Caballero, R. T. Marcavillaca</dc:creator>
    </item>
    <item>
      <title>Computer-aided analyses of stochastic first-order methods, via interpolation conditions for stochastic optimization</title>
      <link>https://arxiv.org/abs/2507.05466</link>
      <description>arXiv:2507.05466v2 Announce Type: new 
Abstract: This work proposes a framework, embedded within the Performance Estimation framework (PEP), for obtaining worst-case performance guarantees on stochastic first-order methods. Given a first-order method, a function class, and a noise model with prescribed expectation and variance properties, we present a range of semidefinite programs (SDPs) of increasingly large size, whose solutions yield increasingly strong convergence guarantees on the problem. Eventually, we propose SDPs whose size depends on $2^N$, with $N$ the number of iterations analyzed, that yield tight guarantees, attained by specific functions and noise distributions within these classes. On the other side of the spectrum, we propose SDPs whose size depends linearly on $N$, and numerically show that, on many problems, they already provide tight guarantees.
  The framework accommodates a wide range of stochastic settings, with finite or infinite support, including the unstructured noise model with bounded variance, finite-sum optimization, and block-coordinate methods, in a unified manner, as guarantees apply to any setting consistent with the noise model, i.e., its expectation and variance. It covers both non-variance-reduced and variance-reduced methods. Using the framework, we analyze the stochastic gradient method under several noise models, and illustrate how the resulting numerical and analytical convergence rates connect with existing results. In particular, we provide improved convergence rates on the unstructured noise model with bounded variance and in the block-coordinate setting.</description>
      <guid isPermaLink="false">oai:arXiv.org:2507.05466v2</guid>
      <category>math.OC</category>
      <pubDate>Wed, 09 Jul 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Anne Rubbens, S\'ebastien Colla, Julien M. Hendrickx</dc:creator>
    </item>
    <item>
      <title>MultiObjectiveAlgorithms.jl: a Julia package for solving multi-objective optimization problems</title>
      <link>https://arxiv.org/abs/2507.05501</link>
      <description>arXiv:2507.05501v1 Announce Type: new 
Abstract: We present MultiObjectiveAlgorithms.jl, an open-source Julia library for solving multi-objective optimization problems written in JuMP. MultiObjectiveAlgorithms.jl implements a number of different solution algorithms, which all rely on an iterative scalarization of the problem from a multi-objective optimization problem to a sequence of single-objective subproblems. As part of this work, we extended JuMP to support vector-valued objective functions. Because it is based on JuMP, MultiObjectiveAlgorithms.jl can use a wide variety of commercial and open-source solvers to solve the single-objective subproblems, and it supports problem classes ranging from linear, to conic, semi-definite, and general nonlinear. MultiObjectiveAlgorithms.jl is available at https://github.com/jump-dev/MultiObjectiveAlgorithms.jl under a MPL-2 license.</description>
      <guid isPermaLink="false">oai:arXiv.org:2507.05501v1</guid>
      <category>math.OC</category>
      <pubDate>Wed, 09 Jul 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Oscar Dowson, Xavier Gandibleux, G\"okhan Kof</dc:creator>
    </item>
    <item>
      <title>Exact and efficient basis pursuit denoising via differential inclusions and a selection principle</title>
      <link>https://arxiv.org/abs/2507.05562</link>
      <description>arXiv:2507.05562v1 Announce Type: new 
Abstract: Basis pursuit denoising (BPDN) is a cornerstone of compressive sensing, statistics and machine learning. While various algorithms for BPDN have been proposed, they invariably suffer from drawbacks and must either favor efficiency at the expense of accuracy or vice versa. As such, state-of-the-art algorithms remain ineffective for high-dimensional applications that require accurate solutions within a reasonable amount of computational time. In this work, we address this issue and propose an exact and efficient algorithm for BPDN using differential inclusions. Specifically, we prove that a selection principle from the theory of differential inclusions turns the dual problem of BPDN into calculating the trajectory of an \emph{integrable} projected dynamical system, that is, whose trajectory and asymptotic limit can be computed exactly. Our analysis naturally yields an exact algorithm, numerically up to machine precision, that is amenable to computing regularization paths and very fast. Numerical experiments confirm that our algorithm outperforms the state-of-the-art algorithms in both accuracy and efficiency. Moreover, we show that the global continuation of solutions (in terms of the hyperparameter and data) of the projected dynamical system yields a rigorous homotopy algorithm for BPDN, as well as a novel greedy algorithm for computing feasible solutions to basis pursuit in strongly polynomial time. Beyond this work, we expect that our results and analysis can be adapted to compute exact or approximate solutions to a broader class of polyhedral-constrained optimization problems.</description>
      <guid isPermaLink="false">oai:arXiv.org:2507.05562v1</guid>
      <category>math.OC</category>
      <category>cs.LG</category>
      <category>math.FA</category>
      <pubDate>Wed, 09 Jul 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Gabriel P. Langlois, J\'er\^ome Darbon</dc:creator>
    </item>
    <item>
      <title>On the Inherent Privacy of Zeroth Order Projected Gradient Descent</title>
      <link>https://arxiv.org/abs/2507.05610</link>
      <description>arXiv:2507.05610v2 Announce Type: new 
Abstract: Differentially private zeroth-order optimization methods have recently gained popularity in private fine tuning of machine learning models due to their reduced memory requirements. Current approaches for privatizing zeroth-order methods rely on adding Gaussian noise to the estimated zeroth-order gradients. However, since the search direction in the zeroth-order methods is inherently random, researchers including Tang et al. (2024) and Zhang et al. (2024a) have raised an important question: is the inherent noise in zeroth-order estimators sufficient to ensure the overall differential privacy of the algorithm? This work settles this question for a class of oracle-based optimization algorithms where the oracle returns zeroth-order gradient estimates. In particular, we show that for a fixed initialization, there exist strongly convex objective functions such that running (Projected) Zeroth-Order Gradient Descent (ZO-GD) is not differentially private. Furthermore, we show that even with random initialization and without revealing (initial and) intermediate iterates, the privacy loss in ZO-GD can grow superlinearly with the number of iterations when minimizing convex objective functions.</description>
      <guid isPermaLink="false">oai:arXiv.org:2507.05610v2</guid>
      <category>math.OC</category>
      <category>cs.LG</category>
      <category>stat.ML</category>
      <pubDate>Wed, 09 Jul 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Devansh Gupta, Meisam Razaviyayn, Vatsal Sharan</dc:creator>
    </item>
    <item>
      <title>A derivative-free regularization algorithm for equality constrained nonlinear least squares problems</title>
      <link>https://arxiv.org/abs/2507.05623</link>
      <description>arXiv:2507.05623v1 Announce Type: new 
Abstract: In this paper, we study the equality constrained nonlinear least squares problem, where the Jacobian matrices of the objective function and constraints are unavailable or expensive to compute. We approximate the Jacobian matrices via orthogonal spherical smoothing and propose a derivative-free regularization algorithm for solving the problem. At each iteration, a regularized augmented Lagrangian subproblem is solved to obtain a Newton-like step. If a sufficient decrease in the merit function of the approximate KKT system is achieved, the step is accepted, otherwise a derivative-free LM algorithm is applied to get another step to satisfy the sufficient decrease condition. It is shown that the algorithm either finds an approximate KKT point with arbitrary high probability or converges to a stationary point of constraints violation almost surely.</description>
      <guid isPermaLink="false">oai:arXiv.org:2507.05623v1</guid>
      <category>math.OC</category>
      <pubDate>Wed, 09 Jul 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Xi Chen, Jinyan Fan</dc:creator>
    </item>
    <item>
      <title>A Fully Adaptive Frank-Wolfe Algorithm for Relatively Smooth Problems and Its Application to Centralized Distributed Optimization</title>
      <link>https://arxiv.org/abs/2507.05669</link>
      <description>arXiv:2507.05669v1 Announce Type: new 
Abstract: We study the Frank-Wolfe algorithm for constrained optimization problems with relatively smooth and relatively strongly convex objectives. Building upon our previous work, we propose a fully adaptive variant of the Frank-Wolfe method that dynamically adjusts the step size based on both the relative smoothness constant and the Triangle Scaling Exponent (TSE) of the Bregman divergence. Our method does not require prior knowledge of the function parameters and guarantees convergence using only local information. We establish a linear convergence rate under relative strong convexity and provide a detailed theoretical analysis of the proposed adaptive step-size rule.
  Furthermore, we demonstrate how relative smoothness and strong convexity naturally arise in the setting of centralized distributed optimization. Under a variance-type assumption on the gradients, we show that the global objective becomes relatively strongly convex with respect to the Bregman divergence generated by a local function. This structure allows us to apply our adaptive Frank-Wolfe algorithm, leading to provable acceleration due to an improved relative condition number. We support our theoretical findings with numerical experiments, showing that the proposed method outperforms both non-adaptive and partially adaptive variants, especially in distributed settings.</description>
      <guid isPermaLink="false">oai:arXiv.org:2507.05669v1</guid>
      <category>math.OC</category>
      <pubDate>Wed, 09 Jul 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>A. A. Vyguzov, F. S. Stonyakin</dc:creator>
    </item>
    <item>
      <title>Nonstationary Distribution Estimation via Wasserstein Probability Flows</title>
      <link>https://arxiv.org/abs/2507.05893</link>
      <description>arXiv:2507.05893v1 Announce Type: new 
Abstract: We study the problem of estimating a sequence of evolving probability distributions from historical data, where the underlying distribution changes over time in a nonstationary and nonparametric manner. To capture gradual changes, we introduce a model that penalises large deviations between consecutive distributions using the Wasserstein distance. This leads to a method in which we estimate the underlying series of distributions by maximizing the log-likelihood of the observations with a penalty applied to the sum of the Wasserstein distances between consecutive distributions. We show how this can be reduced to a simple network-flow problem enabling efficient computation. We call this the Wasserstein Probability Flow method. We derive some properties of the optimal solutions and carry out numerical tests in different settings. Our results suggest that the Wasserstein Probability Flow method is a promising tool for applications such as nonstationary stochastic optimization.</description>
      <guid isPermaLink="false">oai:arXiv.org:2507.05893v1</guid>
      <category>math.OC</category>
      <pubDate>Wed, 09 Jul 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Edward J. Anderson, Dominic S. T. Keehan</dc:creator>
    </item>
    <item>
      <title>Heuristic approaches for a new variant of the Team Orienteering Problem</title>
      <link>https://arxiv.org/abs/2507.06012</link>
      <description>arXiv:2507.06012v1 Announce Type: new 
Abstract: In this paper we tackle the Team Orienteering Problem with Service Times, Mandatory Nodes and Incompatibilities, introduced in~\cite{Guastalla2024} and arising from two real-world healthcare applications. We propose two heuristic algorithms in the form of a Variable Descent Neighbourhood algorithm and a matheuristic based on a Cuts Separation approach. For the former, we also provide a multi-thread version exploiting its intrinsic capability to be parallelised. Both algorithms include a specific heuristic routine to provide a starting feasible solution, since finding a feasible solution has been proved to be NP-complete. The results of our heuristic algorithms are compared with an exact cutting plane approach and have complementary strengths and weaknesses. They are also evaluated on existing TOP benchmarks against TOP state-of-the-art algorithms, demonstrating their competitiveness on general grounds.</description>
      <guid isPermaLink="false">oai:arXiv.org:2507.06012v1</guid>
      <category>math.OC</category>
      <pubDate>Wed, 09 Jul 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Alberto Guastalla, Roberto Aringhieri, Pierre Hosteins</dc:creator>
    </item>
    <item>
      <title>New Lagrangian framework for optimality conditions in optimal control of second order systems</title>
      <link>https://arxiv.org/abs/2507.06024</link>
      <description>arXiv:2507.06024v1 Announce Type: new 
Abstract: It has been shown recently that optimal control problems with the dynamical constraint given by a second order system admit a regular Lagrangian formulation. This implies that the optimality conditions can be obtained in a new form based on the variational approach. In this paper we extend the first order necessary optimality conditions obtained previously to second order optimality conditions and discuss the role of the new Lagrangian.</description>
      <guid isPermaLink="false">oai:arXiv.org:2507.06024v1</guid>
      <category>math.OC</category>
      <pubDate>Wed, 09 Jul 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <dc:creator>Michael Konopik, Sigrid Leyendecker, Sofya Maslovskaya, Sina Ober-Bl\"obaum, Rodrigo T. Sato Mart\'in de Almagro</dc:creator>
    </item>
    <item>
      <title>Relationship between maximum principle and dynamic programming principle for recursive optimal control problem of stochastic evolution equations</title>
      <link>https://arxiv.org/abs/2507.06118</link>
      <description>arXiv:2507.06118v1 Announce Type: new 
Abstract: This paper aims to study the relationship between the maximum principle and the dynamic programming principle for recursive optimal control problem of stochastic evolution equations, where the control domain is not necessarily convex and the value function may be nonsmooth. By making use of the notion of conditionally expected operator-valued backward stochastic integral equations, we establish a connection between the first and second-order adjoint processes in MP and the general derivatives of the value function. Under certain additional assumptions, the value function is shown to be $C^{1,1}$-regular. Furthermore, we discuss the smooth case and present several applications of our results.</description>
      <guid isPermaLink="false">oai:arXiv.org:2507.06118v1</guid>
      <category>math.OC</category>
      <pubDate>Wed, 09 Jul 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Ying Hu, Guomin Liu, Shanjian Tang</dc:creator>
    </item>
    <item>
      <title>A Generalized $\ell_1$-Merit Function SQP Method Using Function Approximations with Tunable Accuracy</title>
      <link>https://arxiv.org/abs/2507.06199</link>
      <description>arXiv:2507.06199v1 Announce Type: new 
Abstract: This paper develops a generalization of the line-search sequential quadratic programming (SQP) algorithm with $\ell_1$-merit function that uses objective and constraint function approximations with tunable accuracy to solve smooth equality-constrained optimization problems. The evaluation of objective and constraint functions and their gradients is potentially computationally expensive, but it is assumed that one can construct effective, computationally inexpensive models of these functions. This paper specifies how these models can be used to generate new iterates. At each iteration, the models have to satisfy function error and relative gradient error tolerances determined by the algorithm based on its progress. Moreover, bounds for the model errors are used to explore regions where the combined objective function and constraint models are sufficiently accurate. The algorithm has the same first-order global convergence properties as a line-search SQP algorithm with $\ell_1$-merit function, but only uses objective and constraint function models and the model error bounds. The algorithm is applied to a discretized boundary control problem in which the evaluation of the objective and constraint functions requires the solution of the Boussinesq partial differential equation (PDE). The models are constructed from projection-based reduced-order models of the Boussinesq PDE.</description>
      <guid isPermaLink="false">oai:arXiv.org:2507.06199v1</guid>
      <category>math.OC</category>
      <category>cs.NA</category>
      <category>math.NA</category>
      <pubDate>Wed, 09 Jul 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Dane S. Grundvig, Matthias Heinkenschloss</dc:creator>
    </item>
    <item>
      <title>Fairness-Aware Static and Dynamic Assortment Optimization: Optimal Selection with Balanced Market Share</title>
      <link>https://arxiv.org/abs/2507.05606</link>
      <description>arXiv:2507.05606v1 Announce Type: cross 
Abstract: Assortment optimization is a critical tool for online retailers aiming to maximize revenue. However, optimizing purely for revenue can lead to imbalanced sales across products, potentially causing supplier disengagement and reduced product diversity. To address these fairness concerns, we introduce a market share balancing constraint that limits the disparity in expected sales between any two offered products to a factor of a given parameter $\alpha$. We study both static and dynamic assortment optimization under the multinomial logit (MNL) model with this fairness constraint. In the static setting, the seller selects a distribution over assortments that satisfies the market share balancing constraint while maximizing expected revenue. We show that this problem can be solved in polynomial time, and we characterize the structure of the optimal solution: a product is included if and only if its revenue and preference weight exceed certain thresholds. We further extend our analysis to settings with additional feasibility constraints on the assortment and demonstrate that, given a $\beta$-approximation oracle for the constrained problem, we can construct a $\beta$-approximation algorithm under the fairness constraint. In the dynamic setting, each product has a finite initial inventory, and the seller implements a dynamic policy to maximize total expected revenue while respecting both inventory limits and the market share balancing constraint in expectation. We design a policy that is asymptotically optimal, with its approximation ratio converging to one as inventories grow large.</description>
      <guid isPermaLink="false">oai:arXiv.org:2507.05606v1</guid>
      <category>cs.GT</category>
      <category>math.OC</category>
      <pubDate>Wed, 09 Jul 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Omar El Housni, Qing Feng, Huseyin Topaloglu</dc:creator>
    </item>
    <item>
      <title>Assessing Linear Control Strategies for Zero-Speed Fin Roll Damping</title>
      <link>https://arxiv.org/abs/2507.05867</link>
      <description>arXiv:2507.05867v1 Announce Type: cross 
Abstract: Roll stabilization is a critical aspect of ship motion control, particularly for vessels operating in low-speed or zero-speed conditions, where traditional hydrodynamic fins lose their effectiveness. In this paper, we consider a roll damping system, developed by Navis JSC, based on two actively controlled zero-speed fins. Unlike conventional fin stabilizers, zero-speed fins employ a drag-based mechanism and active oscillations to generate stabilizing forces even when the vessel is stationary. We propose a simple linear control architecture that, however, accounts for nonlinear drag forces and actuator limitations. Simulation results on a high-fidelity vessel model used for HIL testing demonstrate the effectiveness of the proposed approach.</description>
      <guid isPermaLink="false">oai:arXiv.org:2507.05867v1</guid>
      <category>eess.SY</category>
      <category>cs.RO</category>
      <category>cs.SY</category>
      <category>math.OC</category>
      <pubDate>Wed, 09 Jul 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Nikita Savin, Elena Ambrosovskaya, Dmitry Romaev, Anton Proskurnikov</dc:creator>
    </item>
    <item>
      <title>Stable Acoustic Relay Assignment with High Throughput via Lase Chaos-based Reinforcement Learning</title>
      <link>https://arxiv.org/abs/2507.05900</link>
      <description>arXiv:2507.05900v1 Announce Type: cross 
Abstract: This study addresses the problem of stable acoustic relay assignment in an underwater acoustic network. Unlike the objectives of most existing literature, two distinct objectives, namely classical stable arrangement and ambiguous stable arrangement, are considered. To achieve these stable arrangements, a laser chaos-based multi-processing learning (LC-ML) method is introduced to efficiently obtain high throughput and rapidly attain stability. In order to sufficiently explore the relay's decision-making, this method uses random numbers generated by laser chaos to learn the assignment of relays to multiple source nodes. This study finds that the laser chaos-based random number and multi-processing in the exchange process have a positive effect on higher throughput and strong adaptability with environmental changing over time. Meanwhile, ambiguous cognitions result in the stable configuration with less volatility compared to accurate ones. This provides a practical and useful method and can be the basis for relay selection in complex underwater environments.</description>
      <guid isPermaLink="false">oai:arXiv.org:2507.05900v1</guid>
      <category>cs.SD</category>
      <category>cs.LG</category>
      <category>eess.AS</category>
      <category>math.OC</category>
      <pubDate>Wed, 09 Jul 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Zengjing Chen, Lu Wang, Chengzhi Xing</dc:creator>
    </item>
    <item>
      <title>Optimal Placement of Smart Hybrid Transformers in Distribution Networks</title>
      <link>https://arxiv.org/abs/2507.05967</link>
      <description>arXiv:2507.05967v1 Announce Type: cross 
Abstract: Hybrid transformers are a relatively new technology that combine conventional power transformers with power electronics to provide voltage and reactive power control capabilities in distribution networks. This paper proposes a novel method of determining the optimal location and utilisation of hybrid transformers in 3-phase distribution networks to maximise the net present value of hybrid transformers based on their ability to increase the export of power produced by distributed generators over their operational lifespan. This has been accomplished through sequential linear programming, a key feature of which is the consideration of nonlinear characteristics and constraints relating to hybrid transformer power electronics and control capabilities. Test cases were carried out in a modified version of the Cigre European Low Voltage Distribution Network Benchmark, which has been extended by connecting it with two additional low voltage distribution test networks. All test case results demonstrate that the installation and utilisation of hybrid transformers can improve the income earned from exporting excess active power, justifying their installation cost (with the highest net present value being {\pounds}6.56 million, resulting from a 45.53 percent increase in estimated annual profits due to coordinated HT compensation).</description>
      <guid isPermaLink="false">oai:arXiv.org:2507.05967v1</guid>
      <category>eess.SY</category>
      <category>cs.SY</category>
      <category>math.OC</category>
      <pubDate>Wed, 09 Jul 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Samuel Hayward, Martin Doff-Sotta, Michael Merlin, Matthew Williams, Thomas Morstyn</dc:creator>
    </item>
    <item>
      <title>Convex Submodular Minimization with Indicator Variables</title>
      <link>https://arxiv.org/abs/2209.13161</link>
      <description>arXiv:2209.13161v2 Announce Type: replace 
Abstract: We study a general class of convex submodular optimization problems with indicator variables. Many applications such as the problem of inferring Markov random fields (MRFs) with a sparsity or robustness prior can be naturally modeled in this form. We show that these problems can be reduced to binary submodular minimization problems, possibly after a suitable reformulation, and thus are strongly polynomially solvable. Furthermore, we develop a parametric approach for computing the associated extreme bases under certain smoothness conditions. This leads to a fast solution method, whose efficiency is demonstrated through numerical experiments.</description>
      <guid isPermaLink="false">oai:arXiv.org:2209.13161v2</guid>
      <category>math.OC</category>
      <pubDate>Wed, 09 Jul 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <dc:creator>Shaoning Han, Andr\'es G\'omez</dc:creator>
    </item>
    <item>
      <title>Good and Fast Row-Sparse ah-Symmetric Reflexive Generalized Inverses</title>
      <link>https://arxiv.org/abs/2401.17540</link>
      <description>arXiv:2401.17540v3 Announce Type: replace 
Abstract: We present several algorithms aimed at constructing sparse and structured sparse (row-sparse) generalized inverses, with application to the efficient computation of least-squares solutions, for inconsistent systems of linear equations, in the setting of multiple right-hand sides and a rank-deficient constraint matrix. Leveraging our earlier formulations to minimize the 1- and 2,1- norms of generalized inverses that satisfy important properties of the Moore-Penrose pseudoinverse, we develop efficient and scalable ADMM algorithms to address these norm-minimization problems and to limit the number of nonzero rows in the solution. We establish a 2,1-norm approximation result for a local-search procedure that was originally designed for 1-norm minimization, and we compare the ADMM algorithms with the local-search procedure and with general-purpose optimization solvers.</description>
      <guid isPermaLink="false">oai:arXiv.org:2401.17540v3</guid>
      <category>math.OC</category>
      <pubDate>Wed, 09 Jul 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Gabriel Ponte, Marcia Fampa, Jon Lee, Luze Xu</dc:creator>
    </item>
    <item>
      <title>Quantitative Indicators for Strength of Inequalities with Respect to a Polyhedron, Part I: Theory</title>
      <link>https://arxiv.org/abs/2403.14522</link>
      <description>arXiv:2403.14522v2 Announce Type: replace 
Abstract: We study strength of inequalities used in mixed-integer programming, and in branch-and-cut algorithms that solve such problems. Strength is an ethereal property lacking good formal definition, but crucial for computational speed. We review several quantitative indicators proposed in the literature we claim provide a measure of the relative strength of inequalities with respect to a given polyhedron. We evaluate two of these indicators (extreme point ratio (EPR) and centroid distance (CD)) on various facet classes for both the traveling salesman polytope TSP, and spanning tree in hypergraph polytope STHGP, obtaining closed-forms for EPR and CD on each facet class. Within each facet class, the two indicators yield strikingly similar strength rankings, with excellent agreement on which facets are strongest and which are weakest. Both indicators corroborate all known computational experience with both polytopes. The indicators also reveal previously unknown properties of STHGP subtours. We also evaluate EPR and CD for the subtour inequalities of the spanning tree in graphs polytope STGP, obtaining surprising and unexpected results that (at least for STGP and STHGP subtours) lead us to believe EPR to be a more accurate estimate of strength than CD. Applications include: comparing the relative strength of different classes of inequalities; design of rapidly-converging separation algorithms; design or justification for constraint strengthening procedures.
  The companion paper exploits one of the newly revealed properties of STHGP subtours in GeoSteiner, with detailed computational results. Across all distance metrics and instances studied, these results are remarkable -- culminating with an optimal solution of a 1,000,000 terminal random Euclidean instance. This confirms these indicators to be highly predictive and strongly correlated with actual computational strength.</description>
      <guid isPermaLink="false">oai:arXiv.org:2403.14522v2</guid>
      <category>math.OC</category>
      <pubDate>Wed, 09 Jul 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>David M. Warme</dc:creator>
    </item>
    <item>
      <title>Quantitative Indicators for Strength of Inequalities with Respect to a Polyhedron, Part II: Applications and Computational Evidence</title>
      <link>https://arxiv.org/abs/2403.14540</link>
      <description>arXiv:2403.14540v2 Announce Type: replace 
Abstract: "Strength" is an important property of inequalities used in mixed-integer optimization, both in theory and practice. Unfortunately, no good formal characterization for strength exists, nor is it well-understood. The first paper explored two strength indicators (extreme point ratio (EPR) and centroid distance (CD)), applying them to the subtour inequalities of the spanning tree in hypergraph polytope STHGP. Although it was known that subtour inequalities of small cardinality were strong, EPR and CD agree that subtour inequalities of large cardinality are significantly stronger. In this second paper, we exploit this previously unknown property algorithmically, presenting strong computational evidence that the EPR and CD indicators are highly predictive of actual computational strength. Previous branch-and-cut implementations for optimizing over STHGP find violated subtour inequalities of only relatively small cardinality, strengthening only by reducing the cardinality of violated subtours. We present new methods that strengthen violated subtour inequalities by augmentation (instead of reduction). Combining strengthening via reduction and augmentation yields violated subtour inequalities of both small and large cardinality, covering both classes deemed "strong" by EPR and CD. Across all instance classes studied, the computational results are remarkable -- culminating with an optimal solution of a 1,000,000 terminal random Euclidean Steiner tree instance. The conclusion is that the EPR and CD strength indicators presented in the first paper have strong predictive power regarding actual computational strength (at least regarding STHGP subtours). The ability to accurately measure the strength of inequalities has numerous applications of great importance, both in theory and practice.</description>
      <guid isPermaLink="false">oai:arXiv.org:2403.14540v2</guid>
      <category>math.OC</category>
      <pubDate>Wed, 09 Jul 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>David M. Warme</dc:creator>
    </item>
    <item>
      <title>Stability for Nash Equilibrium Problems</title>
      <link>https://arxiv.org/abs/2405.11266</link>
      <description>arXiv:2405.11266v2 Announce Type: replace 
Abstract: This paper is devoted to studying the stability properties of the Karush-Kuhn-Tucker (KKT) solution mapping $S_{\rm KKT}$ for Nash equilibrium problems (NEPs) with canonical perturbations. Firstly, we obtain an exact characterization of the strong regularity of $S_{\rm KKT}$ and a sufficient condition that is easy to verify. Secondly, we propose equivalent conditions for the continuously differentiable single-valued localization of $S_{\rm KKT}$. Thirdly, the isolated calmness of $S_{\rm KKT}$ is studied based on two conditions: Property A and Property B, and Property B proves to be sufficient for the robustness of both $E(p)$ and $S_{\rm KKT}$ under the convex assumptions, where $E(p)$ denotes the Nash equilibria at perturbation $p$. Furthermore, we establish that studying the stability properties of the NEP with canonical perturbations is equivalent to studying those of the NEP with only tilt perturbations based on the prior discussions. Finally, we provide detailed characterizations of stability for NEPs whose each individual player solves a quadratic programming (QP) problem.</description>
      <guid isPermaLink="false">oai:arXiv.org:2405.11266v2</guid>
      <category>math.OC</category>
      <pubDate>Wed, 09 Jul 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <arxiv:DOI>10.1287/moor.2024.0609</arxiv:DOI>
      <dc:creator>Ruoyu Diao, Yu-Hong Dai, Liwei Zhang</dc:creator>
    </item>
    <item>
      <title>Convergence Analysis of EXTRA in Non-convex Distributed Optimization</title>
      <link>https://arxiv.org/abs/2503.11104</link>
      <description>arXiv:2503.11104v2 Announce Type: replace 
Abstract: Optimization problems involving the minimization of a finite sum of smooth, possibly non-convex functions arise in numerous applications. To achieve a consensus solution over a network, distributed optimization algorithms, such as \textbf{EXTRA} (decentralized exact first-order algorithm), have been proposed to address these challenges. In this paper, we analyze the convergence properties of \textbf{EXTRA} in the context of smooth, non-convex optimization. By interpreting its updates as a nonlinear dynamical system, we show novel insights into its convergence properties. Specifically, i) \textbf{EXTRA} converges to a consensual first-order stationary point of the global objective with a sublinear rate; and ii) \textbf{EXTRA} avoids convergence to consensual strict saddle points, offering second-order guarantees that ensure robustness. These findings provide a deeper understanding of \textbf{EXTRA} in a non-convex context.</description>
      <guid isPermaLink="false">oai:arXiv.org:2503.11104v2</guid>
      <category>math.OC</category>
      <pubDate>Wed, 09 Jul 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Lei Qin, Ye Pu</dc:creator>
    </item>
    <item>
      <title>A compact implementation of a recently proposed strongly polynomial-time algorithm for the general LP problem</title>
      <link>https://arxiv.org/abs/2505.01426</link>
      <description>arXiv:2505.01426v2 Announce Type: replace 
Abstract: This article presents a compact implementation of a recently proposed strongly polynomial-time algorithm for the general linear programming problem. Each iteration of the algorithm consists of applying a pair of complementary Gauss-Jordan (GJ) pivoting operations. In this compact implementation of the algorithm, the GJ pivoting operations are done inside a matrix that has half the size of the original matrix. A numerical illustration is given.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.01426v2</guid>
      <category>math.OC</category>
      <pubDate>Wed, 09 Jul 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Samuel Awoniyi</dc:creator>
    </item>
    <item>
      <title>Bounds for the number of basic feasible solutions generated by the simplex method with the largest distance rule</title>
      <link>https://arxiv.org/abs/2507.04672</link>
      <description>arXiv:2507.04672v2 Announce Type: replace 
Abstract: In this paper, we show bounds for the number of different basic solutions generated by the simplex method with the maximum distance rule. The pivoting rule was recently proposed, and in some cases, it was reported to be more efficient than the renowned steepest edge rule. If the problem is nondegenerate, these results provide bounds on the number of iterations. As far as we know, they are the first theoretical bounds for the maximum distance rule.</description>
      <guid isPermaLink="false">oai:arXiv.org:2507.04672v2</guid>
      <category>math.OC</category>
      <pubDate>Wed, 09 Jul 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Tomonari Kitahara</dc:creator>
    </item>
    <item>
      <title>Convex relaxation for the generalized maximum-entropy sampling problem</title>
      <link>https://arxiv.org/abs/2404.01390</link>
      <description>arXiv:2404.01390v3 Announce Type: replace-cross 
Abstract: The generalized maximum-entropy sampling problem (GMESP) is to select an order-$s$ principal submatrix from an order-$n$ covariance matrix, to maximize the product of its $t$ greatest eigenvalues, $0&lt;t\leq s &lt;n$. Introduced more than 25 years ago, GMESP is a natural generalization of two fundamental problems in statistical design theory: (i) maximum-entropy sampling problem (MESP); (ii) binary D-optimality (D-Opt). In the general case, it can be motivated by a selection problem in the context of principal component analysis (PCA).
  We introduce the first convex-optimization based relaxation for GMESP, study its behavior, compare it to an earlier spectral bound, and demonstrate its use in a branch-and-bound scheme. We find that such an approach is practical when $s-t$ is very small.</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.01390v3</guid>
      <category>math.ST</category>
      <category>math.OC</category>
      <category>stat.TH</category>
      <pubDate>Wed, 09 Jul 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Gabriel Ponte, Marcia Fampa, Jon Lee</dc:creator>
    </item>
    <item>
      <title>Lorentzian problems on the Heisenberg group</title>
      <link>https://arxiv.org/abs/2407.07379</link>
      <description>arXiv:2407.07379v2 Announce Type: replace-cross 
Abstract: Three left-invariant Lorentzian problems on the Heisenberg group are considered. The Pontryagin maximum principle was applied to both problems and a parameterization of abnormal and normal extremal trajectories was obtained. Reachability sets and the existence of optimal trajectories are investigated.</description>
      <guid isPermaLink="false">oai:arXiv.org:2407.07379v2</guid>
      <category>math.DG</category>
      <category>math.MG</category>
      <category>math.OC</category>
      <pubDate>Wed, 09 Jul 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>I. A. Galyaev, Yu. L. Sachkov</dc:creator>
    </item>
    <item>
      <title>Quantum algorithms for optimizers</title>
      <link>https://arxiv.org/abs/2408.07086</link>
      <description>arXiv:2408.07086v5 Announce Type: replace-cross 
Abstract: This is a set of lecture notes for a graduate-level course on quantum algorithms, with an emphasis on quantum optimization algorithms. It is developed for applied mathematicians and engineers, and requires no previous background in quantum mechanics. The main topics of this course, in addition to a rigorous introduction to the computational model, are: input/output models, quantum search, the quantum gradient algorithm, matrix manipulation algorithms, the mirror descent framework for semidefinite optimization (including the matrix multiplicative weights update algorithm), adiabatic optimization.
  This is a preprint for personal use only. Please refer to the printed version of the material.</description>
      <guid isPermaLink="false">oai:arXiv.org:2408.07086v5</guid>
      <category>quant-ph</category>
      <category>cs.DM</category>
      <category>math.OC</category>
      <pubDate>Wed, 09 Jul 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Giacomo Nannicini</dc:creator>
    </item>
    <item>
      <title>Efficient Risk-sensitive Planning via Entropic Risk Measures</title>
      <link>https://arxiv.org/abs/2502.20423</link>
      <description>arXiv:2502.20423v2 Announce Type: replace-cross 
Abstract: Risk-sensitive planning aims to identify policies maximizing some tail-focused metrics in Markov Decision Processes (MDPs). Such an optimization task can be very costly for the most widely used and interpretable metrics such as threshold probabilities or (Conditional) Values at Risk. Indeed, previous work showed that only Entropic Risk Measures (EntRM) can be efficiently optimized through dynamic programming, leaving a hard-to-interpret parameter to choose. We show that the computation of the full set of optimal policies for EntRM across parameter values leads to tight approximations for the metrics of interest. We prove that this optimality front can be computed effectively thanks to a novel structural analysis and smoothness properties of entropic risks. Empirical results demonstrate that our approach achieves strong performance in a variety of decision-making scenarios.</description>
      <guid isPermaLink="false">oai:arXiv.org:2502.20423v2</guid>
      <category>stat.ML</category>
      <category>cs.AI</category>
      <category>cs.LG</category>
      <category>math.OC</category>
      <category>math.PR</category>
      <pubDate>Wed, 09 Jul 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Alexandre Marthe (ENS de Lyon, UMPA-ENSL), Samuel Bounan (UMPA-ENSL, MC2), Aur\'elien Garivier (UMPA-ENSL, MC2), Claire Vernade</dc:creator>
    </item>
    <item>
      <title>On data usage and predictive behavior of data-driven predictive control with 1-norm regularization</title>
      <link>https://arxiv.org/abs/2505.22307</link>
      <description>arXiv:2505.22307v2 Announce Type: replace-cross 
Abstract: We investigate the data usage and predictive behavior of data-driven predictive control (DPC) with 1-norm regularization. Our analysis enables the offline removal of unused data and facilitates a comparison between the identified symmetric structure and data usage against prior knowledge of the true system. This comparison helps assess the suitability of the DPC scheme for effective control.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.22307v2</guid>
      <category>eess.SY</category>
      <category>cs.SY</category>
      <category>math.OC</category>
      <pubDate>Wed, 09 Jul 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <arxiv:DOI>10.1109/LCSYS.2025.3575436</arxiv:DOI>
      <dc:creator>Manuel Kl\"adtke, Moritz Schulze Darup</dc:creator>
    </item>
    <item>
      <title>Making Non-Negative Polynomials into Sums of Squares</title>
      <link>https://arxiv.org/abs/2506.16321</link>
      <description>arXiv:2506.16321v2 Announce Type: replace-cross 
Abstract: We investigate linear operators $A:\mathbb{R}[x_1,\dots,x_n]\to\mathbb{R}[x_1,\dots,x_n]$. We give explicit operators $A$ such that, for fixed $d\in\mathbb{N}_0$ and closed $K\subseteq\mathbb{R}^n$, $e^A\mathrm{Pos}(K)_{\leq 2d}\subseteq\sum\mathbb{R}[x_1,\dots,x_n]_{\leq d}^2$. We give an explicit operator $A$ such that $e^A\mathrm{Pos}(\mathbb{R}^n)\subseteq\sum\mathbb{R}[x_1,\dots,x_n]^2$. For $K\subseteq\mathbb{R}^n$, we give a condition such that $A$ exists with $e^A\mathrm{Pos}(K)\subseteq\sum\mathbb{R}[x_1,\dots,x_n]^2$. We show that, for compact $K\subseteq\mathbb{R}^n$, there is no bijective linear operator $T:\mathbb{R}[x_1,\dots,x_n]\to\mathbb{R}[x_1,\dots,x_n]$ with $T\mathrm{Pos}(K)\subseteq\sum\mathbb{R}[x_1,\dots,x_n]^2$. In the framework of regular Fr\'echet Lie groups and Lie algebras we investigate the linear operators $A$ such that $e^{tA}:\mathbb{R}[x_1,\dots,x_n]\to\mathbb{R}[x_1,\dots,x_n]$ is well-defined for all $t\in\mathbb{R}$. We give a three-line-proof of Stochel's Theorem.</description>
      <guid isPermaLink="false">oai:arXiv.org:2506.16321v2</guid>
      <category>math.AG</category>
      <category>math.FA</category>
      <category>math.GR</category>
      <category>math.OA</category>
      <category>math.OC</category>
      <pubDate>Wed, 09 Jul 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Philipp J. di Dio</dc:creator>
    </item>
    <item>
      <title>Adaptive Two-sided Assortment Optimization: Revenue Maximization</title>
      <link>https://arxiv.org/abs/2507.04156</link>
      <description>arXiv:2507.04156v2 Announce Type: replace-cross 
Abstract: We study adaptive two-sided assortment optimization for revenue maximization in choice-based matching platforms. The platform has two sides of agents, an initiating side, and a responding side. The decision-maker sequentially selects agents from the initiating side, shows each an assortment of agents from the responding side, and observes their choices. After processing all initiating agents, the responding agents are shown assortments and make their selections. A match occurs when two agents mutually select each other, generating pair-dependent revenue. Choices follow Multinomial Logit (MNL) models. This setting generalizes prior work focused on maximizing the number of matches under submodular demand assumptions, which do not hold in our revenue-maximization context. Our main contribution is the design of polynomial-time approximation algorithms with constant-factor guarantees. In particular, for general pairwise revenues, we develop a randomized algorithm that achieves a $(\frac{1}{2} - \epsilon)$-approximation in expectation for any $\epsilon &gt; 0$. The algorithm is static and provides guarantees under various agent arrival settings, including fixed order, simultaneous processing, and adaptive selection. When revenues are uniform across all pairs involving any given responding-side agent, the guarantee improves to $(1 - \frac{1}{e} - \epsilon)$. In structural settings where responding-side agents share a common revenue-based ranking, we design a simpler adaptive deterministic algorithm achieving a $\frac{1}{2}$-approximation. Our approach leverages novel linear programming relaxations, correlation gap arguments, and structural properties of the revenue functions.</description>
      <guid isPermaLink="false">oai:arXiv.org:2507.04156v2</guid>
      <category>cs.GT</category>
      <category>math.OC</category>
      <pubDate>Wed, 09 Jul 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Mohammadreza Ahmadnejadsaein, Omar El Housni</dc:creator>
    </item>
  </channel>
</rss>
