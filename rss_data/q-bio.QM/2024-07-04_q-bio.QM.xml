<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>q-bio.QM updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/q-bio.QM</link>
    <description>q-bio.QM updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/q-bio.QM" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Thu, 04 Jul 2024 04:00:27 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Thu, 04 Jul 2024 00:00:00 -0400</pubDate>
    <skipDays>
      <day>Saturday</day>
      <day>Sunday</day>
    </skipDays>
    <item>
      <title>Development of Machine Learning Classifiers for Blood-based Diagnosis and Prognosis of Suspected Acute Infections and Sepsis</title>
      <link>https://arxiv.org/abs/2407.02737</link>
      <description>arXiv:2407.02737v1 Announce Type: new 
Abstract: We applied machine learning to the unmet medical need of rapid and accurate diagnosis and prognosis of acute infections and sepsis in emergency departments. Our solution consists of a Myrna (TM) Instrument and embedded TriVerity (TM) classifiers. The instrument measures abundances of 29 messenger RNAs in patient's blood, subsequently used as features for machine learning. The classifiers convert the input features to an intuitive test report comprising the separate likelihoods of (1) a bacterial infection (2) a viral infection, and (3) severity (need for Intensive Care Unit-level care). In internal validation, the system achieved AUROC = 0.83 on the three-class disease diagnosis (bacterial, viral, or non-infected) and AUROC = 0.77 on binary prognosis of disease severity. The Myrna, TriVerity system was granted breakthrough device designation by the United States Food and Drug Administration (FDA). This engineering manuscript teaches the standard and novel machine learning methods used to translate an academic research concept to a clinical product aimed at improving patient care, and discusses lessons learned.</description>
      <guid isPermaLink="false">oai:arXiv.org:2407.02737v1</guid>
      <category>q-bio.QM</category>
      <category>cs.LG</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Ljubomir Buturovic, Michael Mayhew, Roland Luethy, Kirindi Choi, Uros Midic, Nandita Damaraju, Yehudit Hasin-Brumshtein, Amitesh Pratap, Rhys M. Adams, Joao Fonseca, Ambika Srinath, Paul Fleming, Claudia Pereira, Oliver Liesenfeld, Purvesh Khatri, Timothy Sweeney</dc:creator>
    </item>
    <item>
      <title>Examining the impact of forcing function inputs on structural identifiability</title>
      <link>https://arxiv.org/abs/2407.02771</link>
      <description>arXiv:2407.02771v1 Announce Type: new 
Abstract: For mathematical and experimental ease, models with time varying parameters are often simplified to assume constant parameters. However, this simplification can potentially lead to identifiability issues (lack of uniqueness of parameter estimates). Methods have been developed to algebraically and numerically determine the identifiability of a model, as well as resolve identifiability issues. This specific type of simplification presents an alternate opportunity to instead use this information to resolve the unidentifiability. Given that re-parameterizing, collecting more data, and adding inputs can be potentially costly or impractical, this could present new alternatives.
  We present a method for resolving unidentifiability in a system by introducing a new data stream correlated with a parameter of interest. First, we demonstrate how and when non-constant input data can be introduced into any rational function ODE system without worsening the model identifiability. Then, we prove when these input functions improve structural and potentially also practical identifiability for a given model and relevant data.
  By utilizing pre-existing data streams, these methods can potentially reduce experimental costs, while still answering key questions. By connecting mathematical proofs to application, our framework removes guesswork from when, where, and how researchers can best introduce new data to improve model outcomes.</description>
      <guid isPermaLink="false">oai:arXiv.org:2407.02771v1</guid>
      <category>q-bio.QM</category>
      <category>math.DS</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Jessica R Conrad, Marisa C Eisenberg</dc:creator>
    </item>
    <item>
      <title>Solving the inverse problem of microscopy deconvolution with a residual Beylkin-Coifman-Rokhlin neural network</title>
      <link>https://arxiv.org/abs/2407.03239</link>
      <description>arXiv:2407.03239v1 Announce Type: new 
Abstract: Optic deconvolution in light microscopy (LM) refers to recovering the object details from images, revealing the ground truth of samples. Traditional explicit methods in LM rely on the point spread function (PSF) during image acquisition. Yet, these approaches often fall short due to inaccurate PSF models and noise artifacts, hampering the overall restoration quality. In this paper, we approached the optic deconvolution as an inverse problem. Motivated by the nonstandard-form compression scheme introduced by Beylkin, Coifman, and Rokhlin (BCR), we proposed an innovative physics-informed neural network Multi-Stage Residual-BCR Net (m-rBCR) to approximate the optic deconvolution. We validated the m-rBCR model on four microscopy datasets - two simulated microscopy datasets from ImageNet and BioSR, real dSTORM microscopy images, and real widefield microscopy images. In contrast to the explicit deconvolution methods (e.g. Richardson-Lucy) and other state-of-the-art NN models (U-Net, DDPM, CARE, DnCNN, ESRGAN, RCAN, Noise2Noise, MPRNet, and MIMO-U-Net), the m-rBCR model demonstrates superior performance to other candidates by PSNR and SSIM in two real microscopy datasets and the simulated BioSR dataset. In the simulated ImageNet dataset, m-rBCR ranks the second-best place (right after MIMO-U-Net). With the backbone from the optical physics, m-rBCR exploits the trainable parameters with better performances (from ~30 times fewer than the benchmark MIMO-U-Net to ~210 times than ESRGAN). This enables m-rBCR to achieve a shorter runtime (from ~3 times faster than MIMO-U-Net to ~300 times faster than DDPM). To summarize, by leveraging physics constraints our model reduced potentially redundant parameters significantly in expertise-oriented NN candidates and achieved high efficiency with superior performance.</description>
      <guid isPermaLink="false">oai:arXiv.org:2407.03239v1</guid>
      <category>q-bio.QM</category>
      <category>cs.CV</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Rui Li, Mikhail Kudryashev, Artur Yakimovich</dc:creator>
    </item>
    <item>
      <title>Reproducible image-based profiling with Pycytominer</title>
      <link>https://arxiv.org/abs/2311.13417</link>
      <description>arXiv:2311.13417v2 Announce Type: replace 
Abstract: Advances in high-throughput microscopy have enabled the rapid acquisition of large numbers of high-content microscopy images. Whether by deep learning or classical algorithms, image analysis pipelines then produce single-cell features. To process these single-cells for downstream applications, we present Pycytominer, a user-friendly, open-source python package that implements the bioinformatics steps, known as image-based profiling. We demonstrate Pycytominers usefulness in a machine learning project to predict nuisance compounds that cause undesirable cell injuries.</description>
      <guid isPermaLink="false">oai:arXiv.org:2311.13417v2</guid>
      <category>q-bio.QM</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Erik Serrano, Srinivas Niranj Chandrasekaran, Dave Bunten, Kenneth I. Brewer, Jenna Tomkinson, Roshan Kern, Michael Bornholdt, Stephen Fleming, Ruifan Pei, John Arevalo, Hillary Tsang, Vincent Rubinetti, Callum Tromans-Coia, Tim Becker, Erin Weisbart, Charlotte Bunne, Alexandr A. Kalinin, Rebecca Senft, Stephen J. Taylor, Nasim Jamali, Adeniyi Adeboye, Hamdah Shafqat Abbasi, Allen Goodman, Juan C. Caicedo, Anne E. Carpenter, Beth A. Cimini, Shantanu Singh, Gregory P. Way</dc:creator>
    </item>
    <item>
      <title>DiffFit: Visually-Guided Differentiable Fitting of Molecule Structures to a Cryo-EM Map</title>
      <link>https://arxiv.org/abs/2404.02465</link>
      <description>arXiv:2404.02465v3 Announce Type: replace 
Abstract: We introduce DiffFit, a differentiable algorithm for fitting protein atomistic structures into experimental reconstructed Cryo-Electron Microscopy (cryo-EM) volume map. This process is essential in structural biology to semi-automatically reconstruct large meso-scale models of complex protein assemblies and complete cellular structures that are based on measured cryo-EM data. Current approaches require manual fitting in 3D that already results in approximately aligned structures followed by an automated fine-tuning of the alignment. With our DiffFit approach, we enable domain scientists to automatically fit new structures and visualize the fitting results for inspection and interactive revision. Our fitting begins with differentiable 3D rigid transformations of the protein atom coordinates, followed by sampling the density values at its atom coordinates from the target cryo-EM volume. To ensure a meaningful correlation between the sampled densities and the protein structure, we propose a novel loss function based on a multi-resolution volume-array approach and the exploitation of the negative space. Such loss function serves as a critical metric for assessing the fitting quality, ensuring both fitting accuracy and improved visualization of the results. We assessed the placement quality of DiffFit with several large, realistic datasets and found its quality to be superior to that of previous methods. We further evaluated our method in two use cases. First, we demonstrate its use in the process of automating the integration of known composite structures into larger protein complexes. Second, we show that it facilitates the fitting of predicted protein domains into volume densities to aid researchers in the identification of unknown proteins. We open-sourced (github.com/nanovis/DiffFitViewer) DiffFit as a plugin in ChimeraX. All supplemental materials are available at osf.io/5tx4q.</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.02465v3</guid>
      <category>q-bio.QM</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Deng Luo, Zainab Alsuwaykit, Dawar Khan, Ond\v{r}ej Strnad, Tobias Isenberg, Ivan Viola</dc:creator>
    </item>
  </channel>
</rss>
