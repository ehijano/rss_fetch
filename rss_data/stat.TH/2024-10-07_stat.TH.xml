<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>stat.TH updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/stat.TH</link>
    <description>stat.TH updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/stat.TH" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Tue, 08 Oct 2024 04:01:58 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Tue, 08 Oct 2024 00:00:00 -0400</pubDate>
    <skipDays>
      <day>Saturday</day>
      <day>Sunday</day>
    </skipDays>
    <item>
      <title>Matrix generalized elliptical binomial series under real normed division algebras and the central matrix variate beta distribution</title>
      <link>https://arxiv.org/abs/2410.04023</link>
      <description>arXiv:2410.04023v1 Announce Type: new 
Abstract: In this paper we provide a matrix extension of the scalar binomial series under elliptical contoured models and real normed division algebras. The classical hypergeometric series ${}_{1}F_{0}^{\beta}(a;\mathbf{Z})={}_{1}^{k}P_{0}^{\beta,1}(1:a;\mathbf{Z})=|\mathbf{I}-\mathbf{Z}|^{-a}$ of Jack polynomials are now seen as an invariant generalized determinant with a series representation indexed by any elliptical generator function. In particular, a corollary emerges for a simple derivation of the central matrix variate beta type II distribution under elliptically contoured models in the unified real, complex, quaternions and octonions.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.04023v1</guid>
      <category>math.ST</category>
      <category>stat.TH</category>
      <pubDate>Tue, 08 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Francisco J. Caro-Lopera, Jos\'e A. D\'iaz-Garc\'ia</dc:creator>
    </item>
    <item>
      <title>Break recovery in graphical networks with D-trace loss</title>
      <link>https://arxiv.org/abs/2410.04057</link>
      <description>arXiv:2410.04057v1 Announce Type: new 
Abstract: We consider the problem of estimating a time-varying sparse precision matrix, which is assumed to evolve in a piece-wise constant manner. Building upon the Group Fused LASSO and LASSO penalty functions, we estimate both the network structure and the change-points. We propose an alternative estimator to the commonly employed Gaussian likelihood loss, namely the D-trace loss. We provide the conditions for the consistency of the estimated change-points and of the sparse estimators in each block. We show that the solutions to the corresponding estimation problem exist when some conditions relating to the tuning parameters of the penalty functions are satisfied. Unfortunately, these conditions are not verifiable in general, posing challenges for tuning the parameters in practice. To address this issue, we introduce a modified regularizer and develop a revised problem that always admits solutions: these solutions can be used for detecting possible unsolvability of the original problem or obtaining a solution of the original problem otherwise. An alternating direction method of multipliers (ADMM) is then proposed to solve the revised problem. The relevance of the method is illustrated through simulations and real data experiments.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.04057v1</guid>
      <category>math.ST</category>
      <category>stat.TH</category>
      <pubDate>Tue, 08 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Ying Lin, Benjamin Poignard, Ting Kei Pong, Akiko Takeda</dc:creator>
    </item>
    <item>
      <title>Transition of $\alpha$-mixing in Random Iterations with Applications in Queuing Theory</title>
      <link>https://arxiv.org/abs/2410.05056</link>
      <description>arXiv:2410.05056v1 Announce Type: new 
Abstract: Nonlinear time series models incorporating exogenous regressors provide the foundation for numerous significant models across econometrics, queuing theory, machine learning, and various other disciplines. Despite their importance, the framework for the statistical analysis of such models is still incomplete. In contrast, multiple versions of the law of large numbers and the (functional) central limit theorem have been established for weakly dependent variables. We prove the transition of mixing properties of the exogenous regressor to the response through a coupling argument, leveraging these established results. Furthermore, we study Markov chains in random environments under a suitable form of drift and minorization condition when the environment process is non-stationary, merely having favorable mixing properties. Following a novel statistical estimation theory approach and using the Cram\'er-Rao lower bound, we also establish the functional central limit theorem. Additionally, we apply our framework to single-server queuing models. Overall, these results open the door to the statistical analysis of a large class of random iterative models.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.05056v1</guid>
      <category>math.ST</category>
      <category>cs.AI</category>
      <category>math.PR</category>
      <category>stat.TH</category>
      <pubDate>Tue, 08 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Attila Lovas</dc:creator>
    </item>
    <item>
      <title>Quantile regression under dependent censoring with unknown association</title>
      <link>https://arxiv.org/abs/2410.05069</link>
      <description>arXiv:2410.05069v1 Announce Type: new 
Abstract: The study of survival data often requires taking proper care of the censoring mechanism that prohibits complete observation of the data. Under right censoring, only the first occurring event is observed: either the event of interest, or a competing event like withdrawal of a subject from the study. The corresponding identifiability difficulties led many authors to imposing (conditional) independence or a fully known dependence between survival and censoring times, both of which are not always realistic. However, recent results in survival literature showed that parametric copula models allow identification of all model parameters, including the association parameter, under appropriately chosen marginal distributions. The present paper is the first one to apply such models in a quantile regression context, hence benefiting from its well-known advantages in terms of e.g. robustness and richer inference results. The parametric copula is supplemented with a likewise parametric, yet flexible, enriched asymmetric Laplace distribution for the survival times conditional on the covariates. Its asymmetric Laplace basis provides its close connection to quantiles, while the extension with Laguerre orthogonal polynomials ensures sufficient flexibility for increasing polynomial degrees. The distributional flavour of the quantile regression presented, comes with advantages of both theoretical and computational nature. All model parameters are proven to be identifiable, consistent, and asymptotically normal. Finally, performance of the model and of the proposed estimation procedure is assessed through extensive simulation studies as well as an application on liver transplant data.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.05069v1</guid>
      <category>math.ST</category>
      <category>stat.TH</category>
      <pubDate>Tue, 08 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Myrthe D'Haen, Ingrid Van Keilegom, Anneleen Verhasselt</dc:creator>
    </item>
    <item>
      <title>New divergence measures between persistence diagrams and stability of vectorizations</title>
      <link>https://arxiv.org/abs/2410.03910</link>
      <description>arXiv:2410.03910v1 Announce Type: cross 
Abstract: Given a filtration of simplicial complexes, one usually applies persistent homology and summarizes the results in barcodes. Then, in order to extract statistical information from these barcodes, one needs to compute statistical indicators over the bars of the barcode. An issue with this approach is that usually infinite bars must be deleted or cut to finite ones; however, so far there is no consensus on how to perform this procedure. In this work we propose for the first time a systematic way to analyze barcodes through the use of statistical indicators. Our approach is based on the minimization of a divergence measure that generalizes the standard Wasserstein or bottleneck distance to a new asymmetric distance-like function that we introduce and which is interesting on its own. In particular, we analyze the topology induced by this divergence and the stability of known vectorizations with respect to this topology.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.03910v1</guid>
      <category>math.AT</category>
      <category>math.ST</category>
      <category>stat.TH</category>
      <pubDate>Tue, 08 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Alessandro Bravetti, Mart\'in Mijangos, Pablo Padilla</dc:creator>
    </item>
    <item>
      <title>Jackknife empirical likelihood ratio test for log symmetric distribution using probability weighted moments</title>
      <link>https://arxiv.org/abs/2410.04082</link>
      <description>arXiv:2410.04082v1 Announce Type: cross 
Abstract: Log symmetric distributions are useful in modeling data which show high skewness and have found applications in various fields. Using a recent characterization for log symmetric distributions, we propose a goodness of fit test for testing log symmetry. The asymptotic distributions of the test statistics under both null and alternate distributions are obtained. As the normal-based test is difficult to implement, we also propose a jackknife empirical likelihood (JEL) ratio test for testing log symmetry. We conduct a Monte Carlo Simulation to evaluate the performance of the JEL ratio test. Finally, we illustrated our methodology using different data sets.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.04082v1</guid>
      <category>stat.ME</category>
      <category>math.ST</category>
      <category>stat.TH</category>
      <pubDate>Tue, 08 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Anjana S, Sudheesh Kattumannil</dc:creator>
    </item>
    <item>
      <title>Subspace decompositions for association structure learning in multivariate categorical response regression</title>
      <link>https://arxiv.org/abs/2410.04356</link>
      <description>arXiv:2410.04356v1 Announce Type: cross 
Abstract: Modeling the complex relationships between multiple categorical response variables as a function of predictors is a fundamental task in the analysis of categorical data. However, existing methods can be difficult to interpret and may lack flexibility. To address these challenges, we introduce a penalized likelihood method for multivariate categorical response regression that relies on a novel subspace decomposition to parameterize interpretable association structures. Our approach models the relationships between categorical responses by identifying mutual, joint, and conditionally independent associations, which yields a linear problem within a tensor product space. We establish theoretical guarantees for our estimator, including error bounds in high-dimensional settings, and demonstrate the method's interpretability and prediction accuracy through comprehensive simulation studies.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.04356v1</guid>
      <category>stat.ME</category>
      <category>math.ST</category>
      <category>stat.TH</category>
      <pubDate>Tue, 08 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Hongru Zhao, Aaron J. Molstad, Adam J. Rothman</dc:creator>
    </item>
    <item>
      <title>A Reflection on the Impact of Misspecifying Unidentifiable Causal Inference Models in Surrogate Endpoint Evaluation</title>
      <link>https://arxiv.org/abs/2410.04438</link>
      <description>arXiv:2410.04438v1 Announce Type: cross 
Abstract: Surrogate endpoints are often used in place of expensive, delayed, or rare true endpoints in clinical trials. However, regulatory authorities require thorough evaluation to accept these surrogate endpoints as reliable substitutes. One evaluation approach is the information-theoretic causal inference framework, which quantifies surrogacy using the individual causal association (ICA). Like most causal inference methods, this approach relies on models that are only partially identifiable. For continuous outcomes, a normal model is often used. Based on theoretical elements and a Monte Carlo procedure we studied the impact of model misspecification across two scenarios: 1) the true model is based on a multivariate t-distribution, and 2) the true model is based on a multivariate log-normal distribution. In the first scenario, the misspecification has a negligible impact on the results, while in the second, it has a significant impact when the misspecification is detectable using the observed data. Finally, we analyzed two data sets using the normal model and several D-vine copula models that were indistinguishable from the normal model based on the data at hand. We observed that the results may vary when different models are used.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.04438v1</guid>
      <category>stat.ME</category>
      <category>math.ST</category>
      <category>stat.AP</category>
      <category>stat.TH</category>
      <pubDate>Tue, 08 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Gokce Deliorman, Florian Stijven, Wim Van der Elst, Maria del Carmen Pardo, Ariel Alonso</dc:creator>
    </item>
    <item>
      <title>Identification des param\`etres d'un mod\`ele logistique en dynamique des populations avec sortie affine</title>
      <link>https://arxiv.org/abs/2410.04443</link>
      <description>arXiv:2410.04443v1 Announce Type: cross 
Abstract: We study the parameters identification of a dynamic model of a population living in a given host environment governed by a logistic law. We use a statistic Kullback-Leibler type method to derive the algorithm for estimating the parameters of the model in two levels. The first level AIG is an offline algorithm and global it is obtained using the critical points of the reestimation transformation between two parameters. It estimates the parameters in a global iterative manner starting from a block of data. The second level ARE is adaptive recursive and is used online. It constitutes a refinement of the AIG algorithm. The convergence of the AIG algorithm is an open problem. The convergence of the ARE algorithm is demonstrated by constructing a new model, a new space and a new probability law.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.04443v1</guid>
      <category>math.DS</category>
      <category>math.ST</category>
      <category>stat.TH</category>
      <pubDate>Tue, 08 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Messaoud Souilah, Imene Sabira Soualah</dc:creator>
    </item>
    <item>
      <title>Function Gradient Approximation with Random Shallow ReLU Networks with Control Applications</title>
      <link>https://arxiv.org/abs/2410.05071</link>
      <description>arXiv:2410.05071v1 Announce Type: cross 
Abstract: Neural networks are widely used to approximate unknown functions in control. A common neural network architecture uses a single hidden layer (i.e. a shallow network), in which the input parameters are fixed in advance and only the output parameters are trained. The typical formal analysis asserts that if output parameters exist to approximate the unknown function with sufficient accuracy, then desired control performance can be achieved. A long-standing theoretical gap was that no conditions existed to guarantee that, for the fixed input parameters, required accuracy could be obtained by training the output parameters. Our recent work has partially closed this gap by demonstrating that if input parameters are chosen randomly, then for any sufficiently smooth function, with high-probability there are output parameters resulting in $O((1/m)^{1/2})$ approximation errors, where $m$ is the number of neurons. However, some applications, notably continuous-time value function approximation, require that the network approximates the both the unknown function and its gradient with sufficient accuracy. In this paper, we show that randomly generated input parameters and trained output parameters result in gradient errors of $O((\log(m)/m)^{1/2})$, and additionally, improve the constants from our prior work. We show how to apply the result to policy evaluation problems.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.05071v1</guid>
      <category>cs.LG</category>
      <category>cs.SY</category>
      <category>eess.SY</category>
      <category>math.OC</category>
      <category>math.ST</category>
      <category>stat.TH</category>
      <pubDate>Tue, 08 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Andrew Lamperski, Siddharth Salapaka</dc:creator>
    </item>
    <item>
      <title>Assouad, Fano, and Le Cam with Interaction: A Unifying Lower Bound Framework and Characterization for Bandit Learnability</title>
      <link>https://arxiv.org/abs/2410.05117</link>
      <description>arXiv:2410.05117v1 Announce Type: cross 
Abstract: In this paper, we develop a unified framework for lower bound methods in statistical estimation and interactive decision making. Classical lower bound techniques -- such as Fano's inequality, Le Cam's method, and Assouad's lemma -- have been central to the study of minimax risk in statistical estimation, yet they are insufficient for the analysis of methods that collect data in an interactive manner. The recent minimax lower bounds for interactive decision making via the Decision-Estimation Coefficient (DEC) appear to be genuinely different from the classical methods. We propose a unified view of these distinct methodologies through a general algorithmic lower bound method. We further introduce a novel complexity measure, decision dimension, which facilitates the derivation of new lower bounds for interactive decision making. In particular, decision dimension provides a characterization of bandit learnability for any structured bandit model class. Further, we characterize the sample complexity of learning convex model class up to a polynomial gap with the decision dimension, addressing the remaining gap between upper and lower bounds in Foster et al. (2021, 2023).</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.05117v1</guid>
      <category>cs.LG</category>
      <category>cs.IT</category>
      <category>math.IT</category>
      <category>math.ST</category>
      <category>stat.ML</category>
      <category>stat.TH</category>
      <pubDate>Tue, 08 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Fan Chen, Dylan J. Foster, Yanjun Han, Jian Qian, Alexander Rakhlin, Yunbei Xu</dc:creator>
    </item>
    <item>
      <title>Regression Conformal Prediction under Bias</title>
      <link>https://arxiv.org/abs/2410.05263</link>
      <description>arXiv:2410.05263v1 Announce Type: cross 
Abstract: Uncertainty quantification is crucial to account for the imperfect predictions of machine learning algorithms for high-impact applications. Conformal prediction (CP) is a powerful framework for uncertainty quantification that generates calibrated prediction intervals with valid coverage. In this work, we study how CP intervals are affected by bias - the systematic deviation of a prediction from ground truth values - a phenomenon prevalent in many real-world applications. We investigate the influence of bias on interval lengths of two different types of adjustments -- symmetric adjustments, the conventional method where both sides of the interval are adjusted equally, and asymmetric adjustments, a more flexible method where the interval can be adjusted unequally in positive or negative directions. We present theoretical and empirical analyses characterizing how symmetric and asymmetric adjustments impact the "tightness" of CP intervals for regression tasks. Specifically for absolute residual and quantile-based non-conformity scores, we prove: 1) the upper bound of symmetrically adjusted interval lengths increases by $2|b|$ where $b$ is a globally applied scalar value representing bias, 2) asymmetrically adjusted interval lengths are not affected by bias, and 3) conditions when asymmetrically adjusted interval lengths are guaranteed to be smaller than symmetric ones. Our analyses suggest that even if predictions exhibit significant drift from ground truth values, asymmetrically adjusted intervals are still able to maintain the same tightness and validity of intervals as if the drift had never happened, while symmetric ones significantly inflate the lengths. We demonstrate our theoretical results with two real-world prediction tasks: sparse-view computed tomography (CT) reconstruction and time-series weather forecasting. Our work paves the way for more bias-robust machine learning systems.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.05263v1</guid>
      <category>stat.ML</category>
      <category>cs.AI</category>
      <category>cs.LG</category>
      <category>math.ST</category>
      <category>stat.ME</category>
      <category>stat.TH</category>
      <pubDate>Tue, 08 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Matt Y. Cheung, Tucker J. Netherton, Laurence E. Court, Ashok Veeraraghavan, Guha Balakrishnan</dc:creator>
    </item>
    <item>
      <title>Multiply Robust Causal Mediation Analysis with Continuous Treatments</title>
      <link>https://arxiv.org/abs/2105.09254</link>
      <description>arXiv:2105.09254v3 Announce Type: replace 
Abstract: In many applications, researchers are interested in the direct and indirect causal effects of a treatment or exposure on an outcome of interest. Mediation analysis offers a rigorous framework for identifying and estimating these causal effects. For binary treatments, efficient estimators for the direct and indirect effects are presented by Tchetgen Tchetgen and Shpitser (2012) based on the influence function of the parameter of interest. These estimators possess desirable properties such as multiple-robustness and asymptotic normality while allowing for slower than root-n rates of convergence for the nuisance parameters. However, in settings involving continuous treatments, these influence function-based estimators are not readily applicable without making strong parametric assumptions. In this work, utilizing a kernel-smoothing approach, we propose an estimator suitable for settings with continuous treatments inspired by the influence function-based estimator of Tchetgen Tchetgen and Shpitser (2012). Our proposed approach employs cross-fitting, relaxing the smoothness requirements on the nuisance functions and allowing them to be estimated at slower rates than the target parameter. Additionally, similar to influence function-based estimators, our proposed estimator is multiply robust and asymptotically normal, allowing for inference in settings where parametric assumptions may not be justified.</description>
      <guid isPermaLink="false">oai:arXiv.org:2105.09254v3</guid>
      <category>math.ST</category>
      <category>cs.LG</category>
      <category>econ.EM</category>
      <category>stat.ML</category>
      <category>stat.TH</category>
      <pubDate>Tue, 08 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Yizhen Xu, Numair Sani, AmirEmad Ghassami, Ilya Shpitser</dc:creator>
    </item>
    <item>
      <title>Nonparametric Jackknife Instrumental Variable Estimation and Confounding Robust Surrogate Indices</title>
      <link>https://arxiv.org/abs/2406.14140</link>
      <description>arXiv:2406.14140v2 Announce Type: replace 
Abstract: Jackknife instrumental variable estimation (JIVE) is a classic method to leverage many weak instrumental variables (IVs) to estimate linear structural models, overcoming the bias of standard methods like two-stage least squares. In this paper, we extend the jackknife approach to nonparametric IV (NPIV) models with many weak IVs. Since NPIV characterizes the structural regression as having residuals projected onto the IV being zero, existing approaches minimize an estimate of the average squared projected residuals, but their estimates are biased under many weak IVs. We introduce an IV splitting device inspired by JIVE to remove this bias, and by carefully studying this split-IV empirical process we establish learning rates that depend on generic complexity measures of the nonparametric hypothesis class. We then turn to leveraging this for semiparametric inference on average treatment effects (ATEs) on unobserved long-term outcomes predicted from short-term surrogates, using historical experiments as IVs to learn this nonparametric predictive relationship even in the presence of confounding between short- and long-term observations. Using split-IV estimates of a debiasing nuisance, we develop asymptotically normal estimates for predicted ATEs, enabling inference.</description>
      <guid isPermaLink="false">oai:arXiv.org:2406.14140v2</guid>
      <category>math.ST</category>
      <category>stat.TH</category>
      <pubDate>Tue, 08 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Aur\'elien Bibaut, Nathan Kallus, Apoorva Lal</dc:creator>
    </item>
    <item>
      <title>On some recent quasi-copula problems and some new methods</title>
      <link>https://arxiv.org/abs/2407.15393</link>
      <description>arXiv:2407.15393v2 Announce Type: replace 
Abstract: The aim of this paper is to present three construction methods for quasi-copulas based on recent developments: a representation of multivariate quasi-copulas by means of infima and suprema of copulas, an extension of a classical result on shuffles of min to the setting of quasi-copulas, and a construction method for quasi-copulas obeying a given signed mass pattern on a patch.</description>
      <guid isPermaLink="false">oai:arXiv.org:2407.15393v2</guid>
      <category>math.ST</category>
      <category>stat.TH</category>
      <pubDate>Tue, 08 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Matja\v{z} Omladi\v{c}, Nik Stopar</dc:creator>
    </item>
    <item>
      <title>Measuring Evidence with a Continuous Test</title>
      <link>https://arxiv.org/abs/2409.05654</link>
      <description>arXiv:2409.05654v4 Announce Type: replace 
Abstract: Testing has developed into the fundamental statistical framework for falsifying hypotheses. Unfortunately, tests are binary in nature: a test either rejects a hypothesis or not. Such binary decisions do not reflect the reality of many scientific studies, which often aim to present the evidence against a hypothesis and do not necessarily intend to establish a definitive conclusion. To solve this, we propose the continuous generalization of a test, which we use to measure the evidence against a hypothesis. Such a continuous test can be viewed as a continuous and non-randomized interpretation of the classical 'randomized test'. This offers the benefits of a randomized test, without the downsides of external randomization. Another interpretation is as a literal measure, which measures the amount of binary tests that reject the hypothesis. Our work completes the bridge between classical tests and the recently proposed $e$-values: $e$-values bounded to $[0, 1/\alpha]$ are continuously interpreted size $\alpha$ randomized tests. Taking $\alpha$ to 0 yields the regular $e$-value: a 'level 0' continuous test. Moreover, we generalize the traditional notion of power by using generalized means. This produces a unified framework that contains both classical Neyman-Pearson optimal testing and log-optimal $e$-values, as well as a continuum of other options. The traditional $p$-value appears as the reciprocal of generally invalid continuous test. In an illustration in a Gaussian location model, we find that optimal continuous tests are of a beautifully simple form.</description>
      <guid isPermaLink="false">oai:arXiv.org:2409.05654v4</guid>
      <category>math.ST</category>
      <category>stat.TH</category>
      <pubDate>Tue, 08 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Nick W. Koning</dc:creator>
    </item>
    <item>
      <title>Just Wing It: Near-Optimal Estimation of Missing Mass in a Markovian Sequence</title>
      <link>https://arxiv.org/abs/2404.05819</link>
      <description>arXiv:2404.05819v2 Announce Type: replace-cross 
Abstract: We study the problem of estimating the stationary mass -- also called the unigram mass -- that is missing from a single trajectory of a discrete-time, ergodic Markov chain. This problem has several applications -- for example, estimating the stationary missing mass is critical for accurately smoothing probability estimates in sequence models. While the classical Good--Turing estimator from the 1950s has appealing properties for i.i.d. data, it is known to be biased in the Markovian setting, and other heuristic estimators do not come equipped with guarantees. Operating in the general setting in which the size of the state space may be much larger than the length $n$ of the trajectory, we develop a linear-runtime estimator called Windowed Good--Turing (WingIt) and show that its risk decays as $\widetilde{O}(\mathsf{T_{mix}}/n)$, where $\mathsf{T_{mix}}$ denotes the mixing time of the chain in total variation distance. Notably, this rate is independent of the size of the state space and minimax-optimal up to a logarithmic factor in $n / \mathsf{T_{mix}}$. We also present an upper bound on the variance of the missing mass random variable, which may be of independent interest. We extend our estimator to approximate the stationary mass placed on elements occurring with small frequency in the trajectory. Finally, we demonstrate the efficacy of our estimators both in simulations on canonical chains and on sequences constructed from natural language text.</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.05819v2</guid>
      <category>stat.ML</category>
      <category>cs.IT</category>
      <category>cs.LG</category>
      <category>math.IT</category>
      <category>math.PR</category>
      <category>math.ST</category>
      <category>stat.TH</category>
      <pubDate>Tue, 08 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Ashwin Pananjady, Vidya Muthukumar, Andrew Thangaraj</dc:creator>
    </item>
    <item>
      <title>Optimal Aggregation of Prediction Intervals under Unsupervised Domain Shift</title>
      <link>https://arxiv.org/abs/2405.10302</link>
      <description>arXiv:2405.10302v2 Announce Type: replace-cross 
Abstract: As machine learning models are increasingly deployed in dynamic environments, it becomes paramount to assess and quantify uncertainties associated with distribution shifts. A distribution shift occurs when the underlying data-generating process changes, leading to a deviation in the model's performance. The prediction interval, which captures the range of likely outcomes for a given prediction, serves as a crucial tool for characterizing uncertainties induced by their underlying distribution. In this paper, we propose methodologies for aggregating prediction intervals to obtain one with minimal width and adequate coverage on the target domain under unsupervised domain shift, under which we have labeled samples from a related source domain and unlabeled covariates from the target domain. Our analysis encompasses scenarios where the source and the target domain are related via i) a bounded density ratio, and ii) a measure-preserving transformation. Our proposed methodologies are computationally efficient and easy to implement. Beyond illustrating the performance of our method through real-world datasets, we also delve into the theoretical details. This includes establishing rigorous theoretical guarantees, coupled with finite sample bounds, regarding the coverage and width of our prediction intervals. Our approach excels in practical applications and is underpinned by a solid theoretical framework, ensuring its reliability and effectiveness across diverse contexts.</description>
      <guid isPermaLink="false">oai:arXiv.org:2405.10302v2</guid>
      <category>stat.ME</category>
      <category>cs.LG</category>
      <category>math.ST</category>
      <category>stat.ML</category>
      <category>stat.TH</category>
      <pubDate>Tue, 08 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Jiawei Ge, Debarghya Mukherjee, Jianqing Fan</dc:creator>
    </item>
  </channel>
</rss>
