<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>cs.NA updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/cs.NA</link>
    <description>cs.NA updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/cs.NA" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Fri, 06 Jun 2025 04:03:14 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Fri, 06 Jun 2025 00:00:00 -0400</pubDate>
    <skipDays>
      <day>Sunday</day>
      <day>Saturday</day>
    </skipDays>
    <item>
      <title>Solving engineering eigenvalue problems with neural networks using the Rayleigh quotient</title>
      <link>https://arxiv.org/abs/2506.04375</link>
      <description>arXiv:2506.04375v1 Announce Type: new 
Abstract: From characterizing the speed of a thermal system's response to computing natural modes of vibration, eigenvalue analysis is ubiquitous in engineering. In spite of this, eigenvalue problems have received relatively little treatment compared to standard forward and inverse problems in the physics-informed machine learning literature. In particular, neural network discretizations of solutions to eigenvalue problems have seen only a handful of studies. Owing to their nonlinearity, neural network discretizations prevent the conversion of the continuous eigenvalue differential equation into a standard discrete eigenvalue problem. In this setting, eigenvalue analysis requires more specialized techniques. Using a neural network discretization of the eigenfunction, we show that a variational form of the eigenvalue problem called the "Rayleigh quotient" in tandem with a Gram-Schmidt orthogonalization procedure is a particularly simple and robust approach to find the eigenvalues and their corresponding eigenfunctions. This method is shown to be useful for finding sets of harmonic functions on irregular domains, parametric and nonlinear eigenproblems, and high-dimensional eigenanalysis. We also discuss the utility of harmonic functions as a spectral basis for approximating solutions to partial differential equations. Through various examples from engineering mechanics, the combination of the Rayleigh quotient objective, Gram-Schmidt procedure, and the neural network discretization of the eigenfunction is shown to offer unique advantages for handling continuous eigenvalue problems.</description>
      <guid isPermaLink="false">oai:arXiv.org:2506.04375v1</guid>
      <category>math.NA</category>
      <category>cs.LG</category>
      <category>cs.NA</category>
      <pubDate>Fri, 06 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Conor Rowan, John Evans, Kurt Maute, Alireza Doostan</dc:creator>
    </item>
    <item>
      <title>Exponential Time Differencing Runge-Kutta Discontinuous Galerkin (ETD-RKDG) Methods for Nonlinear Degenerate Parabolic Equations</title>
      <link>https://arxiv.org/abs/2506.04416</link>
      <description>arXiv:2506.04416v1 Announce Type: new 
Abstract: In this paper, we study high-order exponential time differencing Runge-Kutta (ETD-RK) discontinuous Galerkin (DG) methods for nonlinear degenerate parabolic equations. This class of equations exhibits hyperbolic behavior in degenerate regions and parabolic behavior in non-degenerate regions, resulting in sharp wave fronts in the solution profiles and a parabolic-type time-step restriction, $\tau \sim O(h^2)$, for explicit time integration. To address these challenges and solve such equations in complex domains, we employ DG methods with appropriate stabilizing limiters on unstructured meshes to capture the wave fronts and use ETD-RK methods for time integration to resolve the stiffness of parabolic terms. We extract the system's stiffness using the Jacobian matrix of the DG discretization for diffusion terms and adopt a nodal formulation to facilitate its computation. The algorithm is described in detail for two-dimensional triangular meshes. We also conduct a linear stability analysis in one spatial dimension and present computational results on three-dimensional simplex meshes, demonstrating significant improvements in stability and large time-step sizes.</description>
      <guid isPermaLink="false">oai:arXiv.org:2506.04416v1</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <pubDate>Fri, 06 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Ziyao Xu, Yong-Tao Zhang</dc:creator>
    </item>
    <item>
      <title>An Augmented Lagrangian Preconditioner for Navier--Stokes Equations with Runge--Kutta in Time</title>
      <link>https://arxiv.org/abs/2506.04451</link>
      <description>arXiv:2506.04451v1 Announce Type: new 
Abstract: We consider a Runge--Kutta method for the numerical time integration of the nonstationary incompressible Navier--Stokes equations. This yields a sequence of nonlinear problems to be solved for the stages of the Runge--Kutta method. The resulting nonlinear system of differential equations is discretized using a finite element method. To compute a numerical approximation of the stages at each time step, we employ Newton's method, which requires the solution of a large and sparse generalized saddle-point problem at each nonlinear iteration. We devise an augmented Lagrangian preconditioner within the flexible GMRES method for solving the Newton systems at each time step. The preconditioner can be applied inexactly with the help of a multigrid routine. We present numerical evidence of the robustness and efficiency of the proposed strategy for different values of the viscosity, mesh size, time step, and number of stages of the Runge--Kutta method.</description>
      <guid isPermaLink="false">oai:arXiv.org:2506.04451v1</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <pubDate>Fri, 06 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Santolo Leveque, Yunhui He, Maxim Olshanskii</dc:creator>
    </item>
    <item>
      <title>An Array Decomposition Method for Finite Arrays with Electrically Connected Elements for fast Toeplitz Solvers</title>
      <link>https://arxiv.org/abs/2506.04710</link>
      <description>arXiv:2506.04710v1 Announce Type: new 
Abstract: A large part of the geometry of array antennas is often partially defined by finite translational symmetries. Applying the method of moments (MoM) with the RWG-like element on an appropriately structured mesh to these arrays results in an impedance matrix where the main part exhibits a multilevel block Toeplitz structure. This article introduces a memory-efficient construction method that effectively represents and reuses impedance calculations. The proposed method, applicable to electrically connected elements, also accounts for all non-symmetric parts of the array. The core idea involves nine distinct electrically connectable components from which the array can be assembled. The derived multilevel block Toeplitz matrix is further utilized by an in-house inverse solver to achieve faster and more memory-efficient MoM current vector calculations. We demonstrate the method by computing the far-field of a 32x32 array and the scattering parameters of two tightly coupled 9x9 arrays. This approach reduces the memory allocation from $\mathcal{O}(N_x^2 N_y^2)$ to $\mathcal{O}(N_x N_y)$, for an $N_x \times N_y$ array.</description>
      <guid isPermaLink="false">oai:arXiv.org:2506.04710v1</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <category>eess.SP</category>
      <pubDate>Fri, 06 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Lucas {\AA}kerstedt, Harald Hultin, B. L. G. Jonsson</dc:creator>
    </item>
    <item>
      <title>A Fast, Accurate and Oscillation-free Spectral Collocation Solver for High-dimensional Transport Problems</title>
      <link>https://arxiv.org/abs/2506.04732</link>
      <description>arXiv:2506.04732v1 Announce Type: new 
Abstract: Transport phenomena-describing the movement of particles, energy, or other physical quantities-are fundamental in various scientific disciplines, including nuclear physics, plasma physics, astrophysics, engineering, and the natural sciences.
  However, solving the associated seven-dimensional transport equations poses a significant computational challenge due to the curse of dimensionality.
  We introduce the Tensor Train Superconsistent Spectral (T${^2}$S${^2}$) solver to address this challenge, integrating Spectral Collocation for exponential convergence, Superconsistency for stabilization in transport-dominated regimes, and Tensor Train format for substantial data compression. T${^2}$S${^2}$ enforces a dimension-wise superconsistent condition compatible with tensor structures, achieving extremely low compression ratios, in the order of $(10^{-12})$, while preserving spectral accuracy. Numerical experiments on linear problems demonstrate that T${^2}$S${^2}$ can solve high-dimensional transport problems in minutes on standard hardware, making previously intractable problems computationally feasible. This advancement opens new avenues for efficiently and accurately modeling complex transport phenomena.</description>
      <guid isPermaLink="false">oai:arXiv.org:2506.04732v1</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <pubDate>Fri, 06 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Nicola Cavallini, Gianmarco Manzini, Daniele Funaro, Andrea Favalli</dc:creator>
    </item>
    <item>
      <title>Tensor-based multivariate function approximation: methods benchmarking and comparison</title>
      <link>https://arxiv.org/abs/2506.04791</link>
      <description>arXiv:2506.04791v1 Announce Type: new 
Abstract: In this note, we evaluate the performances, the features and the user-experience of some methods (and their implementations) designed for tensor- (or data-) based multivariate function construction and approximation. To this aim, a collection of multivariate functions extracted from contributive works coming from different communities, is suggested. First, these functions with varying complexity (e.g. number and degree of the variables) and nature (e.g. rational, irrational, differentiable or not, symmetric, etc.) are used to construct tensors, each of different dimension and size on the disk. Second, grounded on this tensor, we inspect performances of each considered method (e.g. the accuracy, the computational time, the parameters tuning impact, etc.). Finally, considering the "best" parameter tuning set, we compare each method using multiple evaluation criteria. The purpose of this note is not to rank the methods but rather to evaluate as fairly as possible the different available strategies, with the idea in mind to guide users to understand the process, the possibilities, the advantages and the limits brought by each tools. The contribution claimed is to suggest a complete benchmark collection of some available tools for tensor approximation by surrogate models (e.g. rational functions, networks, etc.). In addition, as contributors of the multivariate Loewner Framework (mLF) approach (and its side implementation in MDSPACK), attention and details of the latter are more explicitly given, in order to provide readers a digest of this contributive work and some details with simple examples.</description>
      <guid isPermaLink="false">oai:arXiv.org:2506.04791v1</guid>
      <category>math.NA</category>
      <category>cs.CE</category>
      <category>cs.NA</category>
      <category>cs.SE</category>
      <pubDate>Fri, 06 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Athanasios C. Antoulas, Ion Victor Gosea, Charles Poussot-Vassal, Pierre Vuillemin</dc:creator>
    </item>
    <item>
      <title>Numerical solution of the wave equation outside a sphere</title>
      <link>https://arxiv.org/abs/2506.04809</link>
      <description>arXiv:2506.04809v1 Announce Type: new 
Abstract: A method is presented for the fast evaluation of the transient acoustic field generated outside a spherical surface by sources inside the surface. The method employs Lebedev quadratures, which are the optimal method for spatial integration, and Lagrange interpolation and differentiation in an advanced time algorithm for the evaluation of the transient field. Numerical testing demonstrates that the approach gives near machine-precision accuracy and a speed-up in evaluation time which depends on the order of quadrature rule employed but breaks even with direct evaluation at a number of field points about 1.15 times the number of surface quadrature nodes.</description>
      <guid isPermaLink="false">oai:arXiv.org:2506.04809v1</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <category>math.AP</category>
      <category>physics.class-ph</category>
      <category>physics.comp-ph</category>
      <pubDate>Fri, 06 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Michael J. Carley</dc:creator>
    </item>
    <item>
      <title>Efficient randomized algorithms for the fixed Tucker-rank problem of Tucker decomposition with adaptive shifts</title>
      <link>https://arxiv.org/abs/2506.04840</link>
      <description>arXiv:2506.04840v1 Announce Type: new 
Abstract: Randomized numerical linear algebra is proved to bridge theoretical advancements to offer scalable solutions for approximating tensor decomposition. This paper introduces fast randomized algorithms for solving the fixed Tucker-rank problem of Tucker decomposition, through the integration of adaptive shifted power iterations. The proposed algorithms enhance randomized variants of truncated high-order singular value decomposition (T-HOSVD) and sequentially T-HOSVD (ST-HOSVD) by incorporating dynamic shift strategies, which accelerate convergence by refining the singular value gap and reduce the number of required power iterations while maintaining accuracy. Theoretical analyses provide probabilistic error bounds, demonstrating that the proposed methods achieve comparable or superior accuracy compared to deterministic approaches. Numerical experiments on synthetic and real-world datasets validate the efficiency and robustness of the proposed algorithms, showing a significant decline in runtime and approximation error over state-of-the-art techniques.</description>
      <guid isPermaLink="false">oai:arXiv.org:2506.04840v1</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <pubDate>Fri, 06 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Maolin Che, Yimin Wei, Chong Wu, Hong Yan</dc:creator>
    </item>
    <item>
      <title>Active flux for ideal magnetohydrodynamics: A positivity-preserving scheme with the Godunov-Powell source term</title>
      <link>https://arxiv.org/abs/2506.04857</link>
      <description>arXiv:2506.04857v1 Announce Type: new 
Abstract: The Active Flux (AF) is a compact, high-order finite volume scheme that allows more flexibility by introducing additional point value degrees of freedom at cell interfaces. This paper proposes a positivity-preserving (PP) AF scheme for solving the ideal magnetohydrodynamics, where the Godunov-Powell source term is employed to deal with the divergence-free constraint. For the evolution of the cell average, apart from the standard conservative finite volume method for the flux derivative, the nonconservative source term is built on the quadratic reconstruction in each cell, which maintains the compact stencil in the AF scheme. For the point value update, the local Lax-Friedrichs (LLF) flux vector splitting is adopted for the flux derivative, originally proposed in [Duan, Barsukow, and Klingenberg, SIAM Journal on Scientific Computing, 47(2), A811--A837, 2025], and a central difference is used to discretize the divergence in the source term. A parametrized flux limiter and a scaling limiter are presented to preserve the density and pressure positivity by blending the AF scheme with the first-order PP LLF scheme with the source term. To suppress oscillations, a new shock sensor considering the divergence error is proposed, which is used to compute the blending coefficients for the cell average. Several numerical tests are conducted to verify the third-order accuracy, PP property, and shock-capturing ability of the scheme. The key role of the Godunov-Powell source term and its suitable discretization in controlling divergence error is also validated.</description>
      <guid isPermaLink="false">oai:arXiv.org:2506.04857v1</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <pubDate>Fri, 06 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Junming Duan, Praveen Chandrashekar, Christian Klingenberg</dc:creator>
    </item>
    <item>
      <title>Numerical analysis for constrained and unconstrained Q-tensor energies for liquid crystals</title>
      <link>https://arxiv.org/abs/2506.04880</link>
      <description>arXiv:2506.04880v1 Announce Type: new 
Abstract: This paper introduces a comprehensive finite element approximation framework for three-dimensional Landau-de Gennes $Q$-tensor energies for nematic liquid crystals, with a particular focus on the anisotropy of the elastic energy and the Ball-Majumdar singular potential. This potential imposes essential physical constraints on the eigenvalues of the $Q$-tensor, ensuring realistic modeling. We address the approximation of regular solutions to nonlinear elliptic partial differential equations with non-homogeneous boundary conditions associated with Landau-de Gennes energies. The well-posedness of the discrete linearized problem is rigorously demonstrated. The existence and local uniqueness of the discrete solution is derived using the Newton-Kantorovich theorem. Furthermore, we demonstrate an optimal order convergence rate in the energy norm and discuss the impact of eigenvalue constraints on the a priori error analysis.</description>
      <guid isPermaLink="false">oai:arXiv.org:2506.04880v1</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <pubDate>Fri, 06 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Heiko Gimperlein, Ruma R. Maity</dc:creator>
    </item>
    <item>
      <title>Probability of Collision with Tethered Spacecraft</title>
      <link>https://arxiv.org/abs/2506.04969</link>
      <description>arXiv:2506.04969v1 Announce Type: new 
Abstract: This Engineering Note addresses the challenge of estimating the probability of collision for tethered spacecraft during close encounters with other space objects. Standard probability of collision methods, based on spherical hard-body assumptions, tend to be overly conservative when applied to long tether systems. We introduce a method that accounts for the tether's spatial extent and configuration uncertainty by maximizing the probability of collision over all physically admissible tether shapes. Applied to real-world conjunction events involving a kilometer-scale flexible inextensible tether, the method yields more realistic risk estimates. This approach improves the ability to distinguish hazardous from benign encounters, thereby supporting more informed collision avoidance decisions.</description>
      <guid isPermaLink="false">oai:arXiv.org:2506.04969v1</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <pubDate>Fri, 06 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Yema Paul, Emmanuel Delande, Francois Vinet, Francois Laporte, Manuel Sanjurjo-Rivo, Aldo Tonnini, Joan-Pau Sanchez</dc:creator>
    </item>
    <item>
      <title>Norming Sets for Tensor and Polynomial Sketching</title>
      <link>https://arxiv.org/abs/2506.05174</link>
      <description>arXiv:2506.05174v1 Announce Type: new 
Abstract: This paper develops the sketching (i.e., randomized dimension reduction) theory for real algebraic varieties and images of polynomial maps, including, e.g., the set of low rank tensors and tensor networks. Through the lens of norming sets, we provide a framework for controlling the sketching dimension for \textit{any} sketch operator used to embed said sets, including sub-Gaussian, fast Johnson-Lindenstrauss, and tensor structured sketch operators. Leveraging norming set theory, we propose a new sketching method called the median sketch. It embeds such a set $V$ using only $\widetilde{\mathcal{O}}(\dim V)$ tensor structured or sparse linear measurements.</description>
      <guid isPermaLink="false">oai:arXiv.org:2506.05174v1</guid>
      <category>math.NA</category>
      <category>cs.IT</category>
      <category>cs.NA</category>
      <category>math.AG</category>
      <category>math.IT</category>
      <pubDate>Fri, 06 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Yifan Zhang, Joe Kileel</dc:creator>
    </item>
    <item>
      <title>Nombre Effectif de Partis Politiques en Afrique: Une Nouvelle M\'ethode pour un Calcul Objectif et Institutionnellement Neutre</title>
      <link>https://arxiv.org/abs/2506.04279</link>
      <description>arXiv:2506.04279v1 Announce Type: cross 
Abstract: Political fragmentation in Africa poses to a significant challenge to effective governance and stability. Traditional measures of party system fragmentation, such as the Effective Number of Parties (ENP) index, often fail to capture the nuanced realities of African political landscapes, particularly the influence of dominant parties, fluid party affiliations, and the impact of ethnic and regional cleavages. To address these limitations, this paper introduces two novel "apolitical" or "institutionally neutral" measures for calculating the effective number of parties, focusing on geographical and demographic dimensions, notably population size and territorial area. By incorporating these local realities and ensuring a minimum threshold of two parties, the proposed models offer a simpler and more contextually relevant framework for understanding political dynamics in Africa, especially in data-scarce environments. This approach provides a valuable tool for analyzing and streamlining political systems, with potential for broader application beyond the African context.</description>
      <guid isPermaLink="false">oai:arXiv.org:2506.04279v1</guid>
      <category>physics.soc-ph</category>
      <category>cs.NA</category>
      <category>math.NA</category>
      <pubDate>Fri, 06 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Adama Nouboukpo, Kodzo Michel Aladji, Muktar Bappa</dc:creator>
    </item>
    <item>
      <title>Spectrally accurate and efficient convolution with the 3D free-space Laplace Green's function via the super-potential</title>
      <link>https://arxiv.org/abs/2506.04489</link>
      <description>arXiv:2506.04489v1 Announce Type: cross 
Abstract: We present a high-accuracy spectral method for solving the unbounded three-dimensional Poisson equation with smooth, compactly supported sources. The approach is based on a super-potential formulation, where the solution is obtained by applying the Laplacian to a convolution with the biharmonic Green's function. A separable Gaussian-sum (GS) approximation enables efficient FFT-based computation with quasi-linear complexity. Owing to the improved regularity of the biharmonic kernel, the GS cutoff error is of order four, eliminating the need for correction terms or Taylor expansions required in standard GS or Ewald-type methods. Numerical benchmarks demonstrate that the method achieves machine-precision accuracy and outperforms existing GS-based schemes in both error and runtime, making it a robust and efficient tool for free-space Poisson problems on uniform grids.</description>
      <guid isPermaLink="false">oai:arXiv.org:2506.04489v1</guid>
      <category>physics.comp-ph</category>
      <category>cs.NA</category>
      <category>math.NA</category>
      <pubDate>Fri, 06 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Lukas Exl, Sebastian Schaffer</dc:creator>
    </item>
    <item>
      <title>Inverse elastic obstacle scattering problems by monotonicity method</title>
      <link>https://arxiv.org/abs/2506.04655</link>
      <description>arXiv:2506.04655v1 Announce Type: cross 
Abstract: We consider the elastic wave scattering problem involving rigid obstacles. This work addresses the inverse problem of reconstructing the position and shape of such obstacles using far-field measurements. A novel monotonicity-based approach is developed for this purpose. By factorizing the far-field operator and utilizing the existence of localized wave functions, we derive a shape characterization criterion for the obstacle boundary. The proposed method employs monotonicity tests to determine the geometric relationship between any given test domain and the actual scatterer. As a result, the shape and location of rigid elastic obstacles can be uniquely identified without requiring any initial guesses or prior knowledge of the physical parameters of the homogeneous background medium.</description>
      <guid isPermaLink="false">oai:arXiv.org:2506.04655v1</guid>
      <category>math.AP</category>
      <category>cs.NA</category>
      <category>math.NA</category>
      <pubDate>Fri, 06 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Mengjiao Bai, Huaian Diao, Weisheng Zhou</dc:creator>
    </item>
    <item>
      <title>Asymptotically Compatible Error Bound of Finite Element Method for Nonlocal Diffusion Model with An Efficient Implementation</title>
      <link>https://arxiv.org/abs/2408.16243</link>
      <description>arXiv:2408.16243v3 Announce Type: replace 
Abstract: This paper presents an asymptotically compatible error bound for the finite element method (FEM) applied to a nonlocal diffusion model. The analysis covers two scenarios: meshes with and without shape regularity. For shape-regular meshes, the error is bounded by \(O(h^k + \delta)\), where \(h\) is the mesh size, \(\delta\) is the nonlocal horizon, and \(k\) is the order of the FEM basis. Without shape regularity, the bound becomes \(O(h^{k+1}/\delta + \delta)\). In addition, we present an efficient implementation of the finite element method of nonlocal model. The direct implementation of the finite element method of nonlocal model requires computation of $2n$-dimensional integrals which are very expensive. For the nonlocal model with Gaussian kernel function, we can decouple the $2n$-dimensional integral to 2-dimensional integrals which reduce the computational cost tremendously. Numerical experiments verify the theoretical results and demonstrate the outstanding performance of the proposed numerical approach.</description>
      <guid isPermaLink="false">oai:arXiv.org:2408.16243v3</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <pubDate>Fri, 06 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Yanzun Meng, Zuoqiang Shi</dc:creator>
    </item>
    <item>
      <title>On the backward stability of s-step GMRES</title>
      <link>https://arxiv.org/abs/2409.03079</link>
      <description>arXiv:2409.03079v2 Announce Type: replace 
Abstract: Communication, i.e., data movement, is a critical bottleneck for the performance of classical Krylov subspace method solvers on modern computer architectures. Variants of these methods which avoid communication have been introduced, which, while equivalent in exact arithmetic, can be unstable in finite precision. In this work, we address the backward stability of $s$-step GMRES, also known as communication-avoiding GMRES. Compared to the ``modular framework'' proposed in [A.~Buttari, N.~J.~Higham, T.~Mary, \&amp; B.~Vieubl\'e. Preprint in 2024.], we present an improved framework for simplifying the analysis of $s$-step GMRES, which includes standard GMRES ($s=1$) as a special case, by isolating the effects of rounding errors in the QR factorization and the solution of the least squares problem. The key advantage of this new framework is that it is evident how the orthogonalization method affects the backward error, and it is not necessary to re-evaluate anything other than the orthogonalization itself when modifying the orthogonalization used in GMRES. Using this framework, we analyze $s$-step GMRES with popular block orthogonalization methods: block modified Gram--Schmidt and reorthogonalized block classical Gram--Schmidt algorithms.
  An example illustrates the resulting instability of $s$-step GMRES when paired with the classical $s$-step Arnoldi process and shows the limitations of popular strategies for resolving this instability. To address this issue, we propose a modified $s$-step Arnoldi process that allows for much larger block size $s$ while maintaining satisfactory accuracy, as confirmed by our numerical experiments.</description>
      <guid isPermaLink="false">oai:arXiv.org:2409.03079v2</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <pubDate>Fri, 06 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Erin Carson, Yuxin Ma</dc:creator>
    </item>
    <item>
      <title>Numerical spectral analysis of Cauchy-type inverse problems: A probabilistic approach</title>
      <link>https://arxiv.org/abs/2409.03686</link>
      <description>arXiv:2409.03686v2 Announce Type: replace 
Abstract: We investigate the inverse Cauchy and data completion problems for elliptic partial differential equations in a bounded domain $D \subset \mathbb{R}^d$, $d \ge 2$, with a special emphasis on the steady-state heat conduction in anisotropic media. More precisely, boundary conditions are prescribed on an accessible part of the boundary $\varnothing \neq \Gamma_0 \subsetneqq \partial{D}$ and/or internal conditions are available inside the domain $D$ and the aim is to reconstruct the solution to these inverse problems in the domain and on the inaccessible remaining boundary $\Gamma_1 := \partial{D} \setminus \Gamma_0$. Although such severely ill-posed problems have been studied intensively in the past decades, deriving efficient methods for approximating their solution still remains challenging in the general setting, e.g., in high dimensions, for solutions and/or domains with singularities, in complex geometries, etc. Herein, we derive a fundamental probabilistic framework for the stable reconstruction of the solution to the Cauchy and data completion problems in steady-state anisotropic heat conduction, as well as enhancing the knowledge on the impact of the geometry of the domain $D$ and the structure of the conductivity tensor $\mathbf{K}$ on the stability of these inverse problems. This is achieved in three steps: ({\it i}) the spectrum of the direct problem is simulated using stochastic estimators; ({\it ii}) the singular value decomposition of the corresponding direct operator is performed; and ({\it iii}) for the prescribed measurements, a natural subspace of approximate solutions is constructed. This approach is based on elliptic measures, in conjunction with probabilistic representations and parallel Monte Carlo simulations. Thorough numerical simulations performed on GPU, for various two- and three-dimensional geometries, are also provided.</description>
      <guid isPermaLink="false">oai:arXiv.org:2409.03686v2</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <category>math.AP</category>
      <pubDate>Fri, 06 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Iulian C\^impean, Andreea Grecu, Liviu Marin</dc:creator>
    </item>
    <item>
      <title>A stable one-synchronization variant of reorthogonalized block classical Gram--Schmidt</title>
      <link>https://arxiv.org/abs/2411.07077</link>
      <description>arXiv:2411.07077v2 Announce Type: replace 
Abstract: The block classical Gram--Schmidt (BCGS) algorithm and its reorthogonalized variant are widely-used methods for computing the economic QR factorization of block columns $X$ due to their lower communication cost compared to other approaches such as modified Gram--Schmidt and Householder QR. To further reduce communication, i.e., synchronization, there has been a long ongoing search for a variant of reorthogonalized BCGS variant that achieves $O(u)$ loss of orthogonality while requiring only \emph{one} synchronization point per block column, where $u$ represents the unit roundoff. Utilizing Pythagorean inner products and delayed normalization techniques, we propose the first provably stable one-synchronization reorthogonalized BCGS variant, demonstrating that it has $O(u)$ loss of orthogonality under the condition $O(u) \kappa^2(X) \leq 1/2$, where $\kappa(\cdot)$ represents the condition number.
  By incorporating one additional synchronization point, we develop a two-synchronization reorthogonalized BCGS variant which maintains $O(u)$ loss of orthogonality under the improved condition $O(u) \kappa(X) \leq 1/2$. An adaptive strategy is then proposed to combine these two variants, ensuring $O(u)$ loss of orthogonality while using as few synchronization points as possible under the less restrictive condition $O(u) \kappa(X) \leq 1/2$. As an example of where this adaptive approach is beneficial, we show that using the adaptive orthogonalization variant, $s$-step GMRES achieves a backward error comparable to $s$-step GMRES with BCGSI+, also known as BCGS2, both theoretically and numerically, but requires fewer synchronization points.</description>
      <guid isPermaLink="false">oai:arXiv.org:2411.07077v2</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <pubDate>Fri, 06 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Erin Carson, Yuxin Ma</dc:creator>
    </item>
    <item>
      <title>Lattice Rules Meet Kernel Cubature</title>
      <link>https://arxiv.org/abs/2501.09500</link>
      <description>arXiv:2501.09500v2 Announce Type: replace 
Abstract: Rank-1 lattice rules are a class of equally weighted quasi-Monte Carlo methods that achieve essentially linear convergence rates for functions in a reproducing kernel Hilbert space (RKHS) characterized by square-integrable first-order mixed partial derivatives. In this work, we explore the impact of replacing the equal weights in lattice rules with optimized cubature weights derived using the reproducing kernel. We establish a theoretical result demonstrating a doubled convergence rate in the one-dimensional case and provide numerical investigations of convergence rates in higher dimensions. We also present numerical results for an uncertainty quantification problem involving an elliptic partial differential equation with a random coefficient.</description>
      <guid isPermaLink="false">oai:arXiv.org:2501.09500v2</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <category>math.ST</category>
      <category>stat.TH</category>
      <pubDate>Fri, 06 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Vesa Kaarnioja, Ilja Klebanov, Claudia Schillings, Yuya Suzuki</dc:creator>
    </item>
    <item>
      <title>Function recovery and optimal sampling in the presence of nonuniform evaluation costs</title>
      <link>https://arxiv.org/abs/2502.10613</link>
      <description>arXiv:2502.10613v2 Announce Type: replace 
Abstract: We consider recovering a function $f : D \rightarrow \mathbb{C}$ in an $n$-dimensional linear subspace $\mathcal{P}$ from i.i.d. pointwise samples via (weighted) least-squares estimators. Different from most works, we assume the cost of evaluating $f$ is potentially nonuniform, and governed by a cost function $c : D \rightarrow (0,\infty)$ which may blow up at certain points. We therefore strive to choose the sampling measure in a way that minimizes the expected total cost. We provide a recovery guarantee which asserts accurate and stable recovery with an expected cost depending on the Christoffel function and Remez constant of the space $\mathcal{P}$. This leads to a general recipe for finding a good sampling measure for general $c$. As an example, we consider one-dimensional polynomial spaces. Here, we provide two strategies for choosing the sampling measure, which we prove are optimal (up to constants and log factors) in the case of algebraically-growing cost functions.</description>
      <guid isPermaLink="false">oai:arXiv.org:2502.10613v2</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <pubDate>Fri, 06 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Ben Adcock</dc:creator>
    </item>
    <item>
      <title>Fast LDL factorization for dense and sparse symmetric matrices over an arbitrary field</title>
      <link>https://arxiv.org/abs/2504.20305</link>
      <description>arXiv:2504.20305v3 Announce Type: replace 
Abstract: While existing algorithms may be used to solve a linear system over a general field in matrix-multiplication time, the complexity of constructing a symmetric triangular factorization (LDL) has received relatively little formal study. The LDL factorization is a common tool for factorization of symmetric matrices, and, unlike orthogonal counterparts, generalizes to an arbitrary field. We provide algorithms for dense and sparse LDL nd LU factorization that aim to minimize complexity for factorization over a general field. For LDL of an $n\times n$ matrix, we give an algorithm with complexity $O(n^\omega)$, where the complexity of $n\times n$ matrix multiplication is assumed to be $O(n^\omega)$ with $\omega&gt;2$. For sparse matrices corresponding to graphs with treewidth $\tau$, we give an algorithm with complexity $O(n\tau^{\omega-1})$, to compute an LDL an implicit form, or the explicit LDL if the matrix is near full rank. Our sparse LDL algorithm is based on an adaptation of the null-space method for solving saddle point systems of equations, which may be of independent interest. The sparse LDL factorization algorithm also extends to computing a sparse LU factorization.</description>
      <guid isPermaLink="false">oai:arXiv.org:2504.20305v3</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <pubDate>Fri, 06 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Edgar Solomonik</dc:creator>
    </item>
    <item>
      <title>Weak Physics Informed Neural Networks for Geometry Compatible Hyperbolic Conservation Laws on Manifolds</title>
      <link>https://arxiv.org/abs/2505.19036</link>
      <description>arXiv:2505.19036v2 Announce Type: replace 
Abstract: Physics-informed neural networks (PINNs), owing to their mesh-free nature, offer a powerful approach for solving high-dimensional partial differential equations (PDEs) in complex geometries, including irregular domains. This capability effectively circumvents the challenges of mesh generation that traditional numerical methods face in high-dimensional or geometrically intricate settings. While recent studies have extended PINNs to manifolds, the theoretical foundations remain scarce. Existing theoretical analyses of PINNs in Euclidean space often rely on smoothness assumptions for the solutions. However, recent empirical evidence indicates that PINNs may struggle to approximate solutions with low regularity, such as those arising from nonlinear hyperbolic equations. In this paper, we develop a framework for PINNs tailored to the efficient approximation of weak solutions, particularly nonlinear hyperbolic equations defined on manifolds. We introduce a novel weak PINN (wPINN) formulation on manifolds that leverages the well-posedness theory to approximate entropy solutions of geometry-compatible hyperbolic conservation laws on manifolds. Employing tools from approximation theory, we establish a convergence analysis of the algorithm, including an analysis of approximation errors for time-dependent entropy solutions. This analysis provides insight into the accumulation of approximation errors over long time horizons. Notably, the network complexity depends only on the intrinsic dimension, independent of the ambient space dimension. Our results match the minimax rate in the d-dimensional Euclidean space, demonstrating that PINNs can alleviate the curse of dimensionality in the context of low-dimensional manifolds. Finally, we validate the performance of the proposed wPINN framework through numerical experiments, confirming its ability to efficiently approximate entropy solutions on manifolds.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.19036v2</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <category>stat.ML</category>
      <pubDate>Fri, 06 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Hanfei Zhou, Lei Shi</dc:creator>
    </item>
    <item>
      <title>Nonlinear Optimal Recovery in Hilbert Spaces</title>
      <link>https://arxiv.org/abs/2506.00704</link>
      <description>arXiv:2506.00704v2 Announce Type: replace 
Abstract: This paper investigates solution strategies for nonlinear problems in Hilbert spaces, such as nonlinear partial differential equations (PDEs) in Sobolev spaces, when only finite measurements are available. We formulate this as a nonlinear optimal recovery problem, establishing its well-posedness and proving its convergence to the true solution as the number of measurements increases. However, the resulting formulation might not have a finite-dimensional solution in general. We thus present a sufficient condition for the finite dimensionality of the solution, applicable to problems with well-defined point evaluation measurements. To address the broader setting, we introduce a relaxed nonlinear optimal recovery and provide a detailed convergence analysis. An illustrative example is given to demonstrate that our formulations and theoretical findings offer a comprehensive framework for solving nonlinear problems in infinite-dimensional spaces with limited data.</description>
      <guid isPermaLink="false">oai:arXiv.org:2506.00704v2</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <pubDate>Fri, 06 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Daozhe Lin, Qiang Du</dc:creator>
    </item>
    <item>
      <title>Learning collective variables that preserve transition rates</title>
      <link>https://arxiv.org/abs/2506.01222</link>
      <description>arXiv:2506.01222v2 Announce Type: replace 
Abstract: Collective variables (CVs) play a crucial role in capturing rare events in high-dimensional systems, motivating the continual search for principled approaches to their design. In this work, we revisit the framework of quantitative coarse graining and identify the orthogonality condition from Legoll and Lelievre (2010) as a key criterion for constructing CVs that accurately preserve the statistical properties of the original process. We establish that satisfaction of the orthogonality condition enables error estimates for both relative entropy and pathwise distance to scale proportionally with the degree of scale separation. Building on this foundation, we introduce a general numerical method for designing neural network-based CVs that integrates tools from manifold learning with group-invariant featurization. To demonstrate the efficacy of our approach, we construct CVs for butane and achieve a CV that reproduces the anti-gauche transition rate with less than ten percent relative error. Additionally, we provide empirical evidence challenging the necessity of uniform positive definiteness in diffusion tensors for transition rate reproduction and highlight the critical role of light atoms in CV design for molecular dynamics.</description>
      <guid isPermaLink="false">oai:arXiv.org:2506.01222v2</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <category>physics.chem-ph</category>
      <category>stat.ML</category>
      <pubDate>Fri, 06 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Shashank Sule, Arnav Mehta, Maria K. Cameron</dc:creator>
    </item>
    <item>
      <title>Block Alpha-Circulant Preconditioners for All-at-Once Diffusion-Based Covariance Operators</title>
      <link>https://arxiv.org/abs/2506.03947</link>
      <description>arXiv:2506.03947v2 Announce Type: replace 
Abstract: Covariance matrices are central to data assimilation and inverse methods derived from statistical estimation theory. Previous work has considered the application of an all-at-once diffusion-based representation of a covariance matrix operator in order to exploit inherent parallellism in the underlying problem. In this paper, we provide practical methods to apply block $\alpha$-circulant preconditioners to the all-at-once system for the case where the main diffusion operation matrix cannot be readily diagonalized using a discrete Fourier transform. Our new framework applies the block $\alpha$-circulant preconditioner approximately by solving an inner block diagonal problem via a choice of inner iterative approaches. Our first method applies Chebyshev semi-iteration to a symmetric positive definite matrix, shifted by a complex scaling of the identity. We extend theoretical results for Chebyshev semi-iteration in the symmetric positive definite setting, to obtain computable bounds on the asymptotic convergence factor for each of the complex sub-problems. The second approach transforms the complex sub-problem into a (generalized) saddle point system with real coefficients. Numerical experiments reveal that in the case of unlimited computational resources, both methods can match the iteration counts of the `best-case' block $\alpha$-circulant preconditioner. We also provide a practical adaptation to the nested Chebyshev approach, which improves performance in the case of a limited computational budget. Using an appropriate choice of $\alpha$ our new approaches are robust and efficient in terms of outer iterations and matrix--vector products.</description>
      <guid isPermaLink="false">oai:arXiv.org:2506.03947v2</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <pubDate>Fri, 06 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Jemima M. Tabeart, Selime G\"urol, John W. Pearson, Anthony T. Weaver</dc:creator>
    </item>
    <item>
      <title>Second Order Ensemble Langevin Method for Sampling and Inverse Problems</title>
      <link>https://arxiv.org/abs/2208.04506</link>
      <description>arXiv:2208.04506v3 Announce Type: replace-cross 
Abstract: We propose a sampling method based on an ensemble approximation of second order Langevin dynamics. The log target density is appended with a quadratic term in an auxiliary momentum variable and damped-driven Hamiltonian dynamics introduced; the resulting stochastic differential equation is invariant to the Gibbs measure, with marginal on the position coordinates given by the target. A preconditioner based on covariance under the law of the dynamics does not change this invariance property, and is introduced to accelerate convergence to the Gibbs measure. The resulting mean-field dynamics may be approximated by an ensemble method; this results in a gradient-free and affine-invariant stochastic dynamical system. Numerical results demonstrate its potential as the basis for a numerical sampler in Bayesian inverse problems.</description>
      <guid isPermaLink="false">oai:arXiv.org:2208.04506v3</guid>
      <category>math.DS</category>
      <category>cs.LG</category>
      <category>cs.NA</category>
      <category>math.NA</category>
      <category>stat.ME</category>
      <pubDate>Fri, 06 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <arxiv:journal_reference>Communications in Mathematical Sciences, Volume 23 (2025) Number 5</arxiv:journal_reference>
      <dc:creator>Ziming Liu, Andrew M. Stuart, Yixuan Wang</dc:creator>
    </item>
    <item>
      <title>Multiplicative Dynamic Mode Decomposition</title>
      <link>https://arxiv.org/abs/2405.05334</link>
      <description>arXiv:2405.05334v2 Announce Type: replace-cross 
Abstract: Koopman operators are infinite-dimensional operators that linearize nonlinear dynamical systems, facilitating the study of their spectral properties and enabling the prediction of the time evolution of observable quantities. Recent methods have aimed to approximate Koopman operators while preserving key structures. However, approximating Koopman operators typically requires a dictionary of observables to capture the system's behavior in a finite-dimensional subspace. The selection of these functions is often heuristic, may result in the loss of spectral information, and can severely complicate structure preservation. This paper introduces Multiplicative Dynamic Mode Decomposition (MultDMD), which enforces the multiplicative structure inherent in the Koopman operator within its finite-dimensional approximation. Leveraging this multiplicative property, we guide the selection of observables and define a constrained optimization problem for the matrix approximation, which can be efficiently solved. MultDMD presents a structured approach to finite-dimensional approximations and can more accurately reflect the spectral properties of the Koopman operator. We elaborate on the theoretical framework of MultDMD, detailing its formulation, optimization strategy, and convergence properties. The efficacy of MultDMD is demonstrated through several examples, including the nonlinear pendulum, the Lorenz system, and fluid dynamics data, where we demonstrate its remarkable robustness to noise.</description>
      <guid isPermaLink="false">oai:arXiv.org:2405.05334v2</guid>
      <category>math.DS</category>
      <category>cs.LG</category>
      <category>cs.NA</category>
      <category>math.NA</category>
      <category>math.OC</category>
      <category>math.SP</category>
      <pubDate>Fri, 06 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Nicolas Boull\'e, Matthew J. Colbrook</dc:creator>
    </item>
    <item>
      <title>Weak Generative Sampler to Efficiently Sample Invariant Distribution of Stochastic Differential Equation</title>
      <link>https://arxiv.org/abs/2405.19256</link>
      <description>arXiv:2405.19256v2 Announce Type: replace-cross 
Abstract: Sampling invariant distributions from an It\^o diffusion process presents a significant challenge in stochastic simulation. Traditional numerical solvers for stochastic differential equations require both a fine step size and a lengthy simulation period, resulting in biased and correlated samples. The current deep learning-based method solves the stationary Fokker--Planck equation to determine the invariant probability density function in the form of deep neural networks, but they generally do not directly address the problem of sampling from the computed density function. In this work, we introduce a framework that employs a weak generative sampler (WGS) to directly generate independent and identically distributed (iid) samples induced by a transformation map derived from the stationary Fokker--Planck equation. Our proposed loss function is based on the weak form of the Fokker--Planck equation, integrating normalizing flows to characterize the invariant distribution and facilitate sample generation from a base distribution. Our randomized test function circumvents the need for min-max optimization in the traditional weak formulation. Our method necessitates neither the computationally intensive calculation of the Jacobian determinant nor the invertibility of the transformation map. A crucial component of our framework is the adaptively chosen family of test functions in the form of Gaussian kernel functions with centers related to the generated data samples. Experimental results on several benchmark examples demonstrate the effectiveness and scalability of our method, which offers both low computational costs and excellent capability in exploring multiple metastable states.</description>
      <guid isPermaLink="false">oai:arXiv.org:2405.19256v2</guid>
      <category>cs.LG</category>
      <category>cs.NA</category>
      <category>math-ph</category>
      <category>math.DS</category>
      <category>math.MP</category>
      <category>math.NA</category>
      <category>math.PR</category>
      <pubDate>Fri, 06 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Zhiqiang Cai, Yu Cao, Yuanfei Huang, Xiang Zhou</dc:creator>
    </item>
    <item>
      <title>Solving Inverse Problems via Diffusion-Based Priors: An Approximation-Free Ensemble Sampling Approach</title>
      <link>https://arxiv.org/abs/2506.03979</link>
      <description>arXiv:2506.03979v2 Announce Type: replace-cross 
Abstract: Diffusion models (DMs) have proven to be effective in modeling high-dimensional distributions, leading to their widespread adoption for representing complex priors in Bayesian inverse problems (BIPs). However, current DM-based posterior sampling methods proposed for solving common BIPs rely on heuristic approximations to the generative process. To exploit the generative capability of DMs and avoid the usage of such approximations, we propose an ensemble-based algorithm that performs posterior sampling without the use of heuristic approximations. Our algorithm is motivated by existing works that combine DM-based methods with the sequential Monte Carlo (SMC) method. By examining how the prior evolves through the diffusion process encoded by the pre-trained score function, we derive a modified partial differential equation (PDE) governing the evolution of the corresponding posterior distribution. This PDE includes a modified diffusion term and a reweighting term, which can be simulated via stochastic weighted particle methods. Theoretically, we prove that the error between the true posterior distribution can be bounded in terms of the training error of the pre-trained score function and the number of particles in the ensemble. Empirically, we validate our algorithm on several inverse problems in imaging to show that our method gives more accurate reconstructions compared to existing DM-based methods.</description>
      <guid isPermaLink="false">oai:arXiv.org:2506.03979v2</guid>
      <category>cs.LG</category>
      <category>cs.CV</category>
      <category>cs.NA</category>
      <category>eess.IV</category>
      <category>math.NA</category>
      <category>stat.ML</category>
      <pubDate>Fri, 06 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Haoxuan Chen, Yinuo Ren, Martin Renqiang Min, Lexing Ying, Zachary Izzo</dc:creator>
    </item>
  </channel>
</rss>
