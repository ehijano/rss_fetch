<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>cs.DS updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/cs.DS</link>
    <description>cs.DS updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/cs.DS" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Wed, 08 Oct 2025 04:01:01 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Wed, 08 Oct 2025 00:00:00 -0400</pubDate>
    <skipDays>
      <day>Sunday</day>
      <day>Saturday</day>
    </skipDays>
    <item>
      <title>Approximating Multiple-Depot Capacitated Vehicle Routing via LP Rounding</title>
      <link>https://arxiv.org/abs/2510.05321</link>
      <description>arXiv:2510.05321v1 Announce Type: new 
Abstract: In Capacitated Vehicle Routing with Multiple Depots (CVRP-MD) we are given a set of client locations $C$ and a set of depots $R$ located in a metric space with costs $c(i,j)$ between $u,v \in C \cup R$. Additionally, we are given a capacity bound $k$. The goal is to find a collection of tours of minimum total cost such that each tour starts and ends at some depot $r \in R$ and includes at most $k$ clients and such that each client lies on at least one tour. Our main result is a $3.9365$-approximation based on rounding a new LP relaxation for CVRP-MD.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.05321v1</guid>
      <category>cs.DS</category>
      <pubDate>Wed, 08 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Zachary Friggstad, Tobias M\"omke</dc:creator>
    </item>
    <item>
      <title>Time To Replace Your Filter: How Maplets Simplify System Design</title>
      <link>https://arxiv.org/abs/2510.05518</link>
      <description>arXiv:2510.05518v1 Announce Type: new 
Abstract: Filters such as Bloom, quotient, and cuckoo filters are fundamental building blocks providing space-efficient approximate set membership testing. However, many applications need to associate small values with keys-functionality that filters do not provide. This mismatch forces complex workarounds that degrade performance. We argue that maplets-space-efficient data structures for approximate key-value mappings-are the right abstraction. A maplet provides the same space benefits as filters while natively supporting key-value associations with one-sided error guarantees. Through detailed case studies of SplinterDB (LSM-based key-value store), Squeakr (k-mer counter), and Mantis (genomic sequence search), we identify the common patterns and demonstrate how a unified maplet abstraction can lead to simpler designs and better performance. We conclude that applications benefit from defaulting to maplets rather than filters across domains including databases, computational biology, and networking.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.05518v1</guid>
      <category>cs.DS</category>
      <pubDate>Wed, 08 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Michael A. Bender, Alex Conway, Mart\'in Farach-Colton, Rob Johnson, Prashant Pandey</dc:creator>
    </item>
    <item>
      <title>Parameterized Complexity of Temporal Connected Components: Treewidth and k-Path Graphs</title>
      <link>https://arxiv.org/abs/2510.05806</link>
      <description>arXiv:2510.05806v1 Announce Type: new 
Abstract: We study the parameterized complexity of maximum temporal connected components (tccs) in temporal graphs, i.e., graphs that deterministically change over time. In a tcc, any pair of vertices must be able to reach each other via a time-respecting path. We consider both problems of maximum open tccs (openTCC), which allow temporal paths through vertices outside the component, and closed tccs (closedTCC) which require at least one temporal path entirely within the component for every pair. We focus on the structural parameter of treewidth, tw, and the recently introduced temporal parameter of temporal path number, tpn, which is the minimum number of paths needed to fully describe a temporal graph. We prove that these parameters on their own are not sufficient for fixed parameter tractability: both openTCC and closedTCC are NP-hard even when tw=9, and closedTCC is NP-hard when tpn=6. In contrast, we prove that openTCC is in XP when parameterized by tpn. On the positive side, we show that both problem become fixed parameter tractable under various combinations of structural and temporal parameters that include, tw plus tpn, tw plus the lifetime of the graph, and tw plus the maximum temporal degree.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.05806v1</guid>
      <category>cs.DS</category>
      <category>cs.DM</category>
      <category>math.CO</category>
      <pubDate>Wed, 08 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Argyrios Deligkas, Michelle D\"oring, Eduard Eiben, Tiger-Lily Goldsmith, George Skretas, Georg Tennigkeit</dc:creator>
    </item>
    <item>
      <title>Improved Streaming Algorithm for Fair $k$-Center Clustering</title>
      <link>https://arxiv.org/abs/2510.05937</link>
      <description>arXiv:2510.05937v1 Announce Type: new 
Abstract: Many real-world applications pose challenges in incorporating fairness constraints into the $k$-center clustering problem, where the dataset consists of $m$ demographic groups, each with a specified upper bound on the number of centers to ensure fairness. Focusing on big data scenarios, this paper addresses the problem in a streaming setting, where data points arrive one by one sequentially in a continuous stream. Leveraging a structure called the $\lambda$-independent center set, we propose a one-pass streaming algorithm that first computes a reserved set of points during the streaming process. Then, for the post-streaming process, we propose an approach for selecting centers from the reserved point set by analyzing all three possible cases, transforming the most complicated one into a specially constrained vertex cover problem in an auxiliary graph. Our algorithm achieves a tight approximation ratio of 5 while consuming $O(k\log n)$ memory. It can also be readily adapted to solve the offline fair $k$-center problem, achieving a 3-approximation ratio that matches the current state of the art. Furthermore, we extend our approach to a semi-structured data stream, where data points from each group arrive in batches. In this setting, we present a 3-approximation algorithm for $m = 2$ and a 4-approximation algorithm for general $m$. Lastly, we conduct extensive experiments to evaluate the performance of our approaches, demonstrating that they outperform existing baselines in both clustering cost and runtime efficiency.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.05937v1</guid>
      <category>cs.DS</category>
      <category>cs.DM</category>
      <pubDate>Wed, 08 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Longkun Guo, Zeyu Lin, Chaoqi Jia, Chao Chen</dc:creator>
    </item>
    <item>
      <title>Efficient Heuristics and Exact Methods for Pairwise Interaction Sampling</title>
      <link>https://arxiv.org/abs/2510.05955</link>
      <description>arXiv:2510.05955v1 Announce Type: new 
Abstract: We consider a class of optimization problems that are fundamental to testing in modern configurable software systems, e.g., in automotive industries. In pairwise interaction sampling, we are given a (potentially very large) configuration space, in which each dimension corresponds to a possible Boolean feature of a software system; valid configurations are the satisfying assignments of a given propositional formula $\varphi$. The objective is to find a minimum-sized family of configurations, such that each pair of features is jointly tested at least once. Due to its relevance in Software Engineering, this problem has been studied extensively for over 20 years. In addition to new theoretical insights (we prove BH-hardness), we provide a broad spectrum of key contributions on the practical side that allow substantial progress for the practical performance. Remarkably, we are able to solve the largest instances we found in published benchmark sets (with about 500000000 feasible interactions) to provable optimality. Previous approaches were not even able to compute feasible solutions.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.05955v1</guid>
      <category>cs.DS</category>
      <category>cs.CC</category>
      <category>cs.SE</category>
      <pubDate>Wed, 08 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>S\'andor P. Fekete, Phillip Keldenich, Dominik Krupke, Michael Perk</dc:creator>
    </item>
    <item>
      <title>Fast-Convergent Proximity Graphs for Approximate Nearest Neighbor Search</title>
      <link>https://arxiv.org/abs/2510.05975</link>
      <description>arXiv:2510.05975v1 Announce Type: new 
Abstract: Approximate nearest neighbor (ANN) search in high-dimensional metric spaces is a fundamental problem with many applications. Over the past decade, proximity graph (PG)-based indexes have demonstrated superior empirical performance over alternatives. However, these methods often lack theoretical guarantees regarding the quality of query results, especially in the worst-case scenarios. In this paper, we introduce the {\alpha}-convergent graph ({\alpha}-CG), a new PG structure that employs a carefully designed edge pruning rule. This rule eliminates candidate neighbors for each data point p by applying the shifted-scaled triangle inequalities among p, its existing out-neighbors, and new candidates. If the distance between the query point q and its exact nearest neighbor v* is at most {\tau} for some constant {\tau} &gt; 0, our {\alpha}-CG finds the exact nearest neighbor in poly-logarithmic time, assuming bounded intrinsic dimensionality for the dataset; otherwise, it can find an ANN in the same time. To enhance scalability, we develop the {\alpha}-convergent neighborhood graph ({\alpha}-CNG), a practical variant that applies the pruning rule locally within each point's neighbors. We also introduce optimizations to reduce the index construction time. Experimental results show that our {\alpha}-CNG outperforms existing PGs on real-world datasets. For most datasets, {\alpha}-CNG can reduce the number of distance computations and search steps by over 15% and 45%, respectively, when compared with the best-performing baseline.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.05975v1</guid>
      <category>cs.DS</category>
      <pubDate>Wed, 08 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Binhong Li, Xiao Yan, Shangqi Lu</dc:creator>
    </item>
    <item>
      <title>A Finer View of the Parameterized Landscape of Labeled Graph Contractions</title>
      <link>https://arxiv.org/abs/2510.06102</link>
      <description>arXiv:2510.06102v1 Announce Type: new 
Abstract: We study the \textsc{Labeled Contractibility} problem, where the input consists of two vertex-labeled graphs $G$ and $H$, and the goal is to determine whether $H$ can be obtained from $G$ via a sequence of edge contractions.
  Lafond and Marchand~[WADS 2025] initiated the parameterized complexity study of this problem, showing it to be \(\W[1]\)-hard when parameterized by the number \(k\) of allowed contractions. They also proved that the problem is fixed-parameter tractable when parameterized by the tree-width \(\tw\) of \(G\), via an application of Courcelle's theorem resulting in a non-constructive algorithm.
  In this work, we present a constructive fixed-parameter algorithm for \textsc{Labeled Contractibility} with running time \(2^{\mathcal{O}(\tw^2)} \cdot |V(G)|^{\mathcal{O}(1)}\). We also prove that unless the Exponential Time Hypothesis (\ETH) fails, it does not admit an algorithm running in time \(2^{o(\tw^2)} \cdot |V(G)|^{\mathcal{O}(1)}\). This result adds \textsc{Labeled Contractibility} to a small list of problems that admit such a lower bound and matching algorithm.
  We further strengthen existing hardness results by showing that the problem remains \NP-complete even when both input graphs have bounded maximum degree. We also investigate parameterizations by \((k + \delta(G))\) where \(\delta(G)\) denotes the degeneracy of \(G\), and rule out the existence of subexponential-time algorithms. This answers question raised in Lafond and Marchand~[WADS 2025]. We additionally provide an improved \FPT\ algorithm with better dependence on \((k + \delta(G))\) than previously known. Finally, we analyze a brute-force algorithm for \textsc{Labeled Contractibility} with running time \(|V(H)|^{\mathcal{O}(|V(G)|)}\), and show that this running time is optimal under \ETH.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.06102v1</guid>
      <category>cs.DS</category>
      <category>cs.DM</category>
      <pubDate>Wed, 08 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Yashaswini Mathur, Prafullkumar Tale</dc:creator>
    </item>
    <item>
      <title>Local Search-based Individually Fair Clustering with Outliers</title>
      <link>https://arxiv.org/abs/2510.06130</link>
      <description>arXiv:2510.06130v1 Announce Type: new 
Abstract: In this paper, we present a local search-based algorithm for individually fair clustering in the presence of outliers. We consider the individual fairness definition proposed in Jung et al., which requires that each of the $n$ points in the dataset must have one of the $k$ centers within its $n/k$ nearest neighbors. However, if the dataset is known to contain outliers, the set of fair centers obtained under this definition might be suboptimal for non-outlier points. In order to address this issue, we propose a method that discards a set of points marked as outliers and computes the set of fair centers for the remaining non-outlier points. Our method utilizes a randomized variant of local search, which makes it scalable to large datasets. We also provide an approximation guarantee of our method as well as a bound on the number of outliers discarded. Additionally, we demonstrate our claims experimentally on a set of real-world datasets.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.06130v1</guid>
      <category>cs.DS</category>
      <pubDate>Wed, 08 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Binita Maity, Shrutimoy Das, Anirban Dasgupta</dc:creator>
    </item>
    <item>
      <title>Exact Causal Attention with 10% Fewer Operations</title>
      <link>https://arxiv.org/abs/2510.05175</link>
      <description>arXiv:2510.05175v1 Announce Type: cross 
Abstract: We present Fast Causal Attention (FCA), an algorithm that computes exact Causal Attention using 10\% fewer operations. FCA accelerates a special class of matrix multiplications where either one operand or the output matrix is upper- or lower-triangular. This includes all operations in forward and backward pass of Causal Attention, such as masked product $\mathrm{Mask}(QK^{T})$. For these matrix multiplications on GPU, FCA reaches noticeable accelerations over the default PyTorch implementations and Triton compiled kernels. FCA is built upon algebraic identities discovered via machine learning and combinatorial search.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.05175v1</guid>
      <category>cs.LG</category>
      <category>cs.DM</category>
      <category>cs.DS</category>
      <pubDate>Wed, 08 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Dmitry Rybin, Yushun Zhang, Ding Tian, Zhihang Lin, Ruoyu Sun, Zhi-Quan Luo</dc:creator>
    </item>
    <item>
      <title>Fair Rent Division: New Budget and Rent Constraints</title>
      <link>https://arxiv.org/abs/2510.05434</link>
      <description>arXiv:2510.05434v1 Announce Type: cross 
Abstract: We study the classical rent division problem, where $n$ agents must allocate $n$ indivisible rooms and split a fixed total rent $R$. The goal is to compute an envy-free (EF) allocation, where no agent prefers another agent's room and rent to their own. This problem has been extensively studied under standard assumptions, where efficient algorithms for computing EF allocations are known.
  We extend this framework by introducing two practically motivated constraints: (i) lower and upper bounds on room rents, and (ii) room-specific budget for agents. We develop efficient combinatorial algorithms that either compute a feasible EF allocation or certify infeasibility.
  We further design algorithms to optimize over EF allocations using natural fairness objectives such as maximin utility, leximin utility, and minimum utility spread. Our approach unifies both constraint types within a single algorithmic framework, advancing the applicability of fair division methods in real-world platforms such as Spliddit.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.05434v1</guid>
      <category>cs.GT</category>
      <category>cs.DS</category>
      <pubDate>Wed, 08 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Rohith Reddy Gangam, Shayan Taherijam, Vijay V. Vazirani</dc:creator>
    </item>
    <item>
      <title>Efficient learning of bosonic Gaussian unitaries</title>
      <link>https://arxiv.org/abs/2510.05531</link>
      <description>arXiv:2510.05531v1 Announce Type: cross 
Abstract: Bosonic Gaussian unitaries are fundamental building blocks of central continuous-variable quantum technologies such as quantum-optic interferometry and bosonic error-correction schemes. In this work, we present the first time-efficient algorithm for learning bosonic Gaussian unitaries with a rigorous analysis. Our algorithm produces an estimate of the unknown unitary that is accurate to small worst-case error, measured by the physically motivated energy-constrained diamond distance. Its runtime and query complexity scale polynomially with the number of modes, the inverse target accuracy, and natural energy parameters quantifying the allowed input energy and the unitary's output-energy growth.
  The protocol uses only experimentally friendly photonic resources: coherent and squeezed probes, passive linear optics, and heterodyne/homodyne detection. We then employ an efficient classical post-processing routine that leverages a symplectic regularization step to project matrix estimates onto the symplectic group. In the limit of unbounded input energy, our procedure attains arbitrarily high precision using only $2m+2$ queries, where $m$ is the number of modes. To our knowledge, this is the first provably efficient learning algorithm for a multiparameter family of continuous-variable unitaries.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.05531v1</guid>
      <category>quant-ph</category>
      <category>cs.DS</category>
      <category>cs.LG</category>
      <pubDate>Wed, 08 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Marco Fanizza, Vishnu Iyer, Junseo Lee, Antonio A. Mele, Francesco A. Mele</dc:creator>
    </item>
    <item>
      <title>A New Quantum Linear System Algorithm Beyond the Condition Number and Its Application to Solving Multivariate Polynomial Systems</title>
      <link>https://arxiv.org/abs/2510.05588</link>
      <description>arXiv:2510.05588v1 Announce Type: cross 
Abstract: Given a matrix $A$ of dimension $M \times N$ and a vector $\vec{b}$, the quantum linear system (QLS) problem asks for the preparation of a quantum state $|\vec{y}\rangle$ proportional to the solution of $A\vec{y} = \vec{b}$. Existing QLS algorithms have runtimes that scale linearly with the condition number $\kappa(A)$, the sparsity of $A$, and logarithmically with inverse precision, but often overlook structural properties of $\vec{b}$, whose alignment with $A$'s eigenspaces can greatly affect performance.
  In this work, we present a new QLS algorithm that explicitly leverages the structure of the right-hand side vector $\vec{b}$. The runtime of our algorithm depends polynomially on the sparsity of the augmented matrix $H = [A, -\vec{b}]$, the inverse precision, the $\ell_2$ norm of the solution $\vec{y} = A^+ \vec{b}$, and a new instance-dependent parameter \[ ET= \sum_{i=1}^M p_i^2 \cdot d_i, \] where $\vec{p} = (AA^{\top})^+ \vec{b}$, and $d_i$ denotes the squared $\ell_2$ norm of the $i$-th row of $H$. We also introduce a structure-aware rescaling technique tailored to the solution $\vec{y} = A^+ \vec{b}$. Unlike left preconditioning methods, which transform the linear system to $DA\vec{y} = D\vec{b}$, our approach applies a right rescaling matrix, reformulating the linear system as $AD\vec{z} = \vec{b}$.
  As an application of our instance-aware QLS algorithm and new rescaling scheme, we develop a quantum algorithm for solving multivariate polynomial systems in regimes where prior QLS-based methods fail. This yields an end-to-end framework applicable to a broad class of problems. In particular, we apply it to the maximum independent set (MIS) problem, formulated as a special case of a polynomial system, and show through detailed analysis that, under certain conditions, our quantum algorithm for MIS runs in polynomial time.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.05588v1</guid>
      <category>quant-ph</category>
      <category>cs.DS</category>
      <pubDate>Wed, 08 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Jianqiang Li</dc:creator>
    </item>
    <item>
      <title>Computational Complexity in Property Testing</title>
      <link>https://arxiv.org/abs/2510.05927</link>
      <description>arXiv:2510.05927v1 Announce Type: cross 
Abstract: We initiate a systematic study of the computational complexity of property testing, focusing on the relationship between query and time complexity. While traditional work in property testing has emphasized query complexity, relatively little is known about the computational hardness of property testers. Our goal is to chart the landscape of time-query interplay and develop tools for proving time complexity lower bounds. Our first contribution is a pair of time-query hierarchy theorems for property testing. For all suitable nondecreasing functions $q(n)$ and $t(n)$ with $t(n)\geq q(n)$, we construct properties with query complexity $\tilde{\Theta}(q(n))$ and time complexity $\tilde\Omega(t(n))$. Our weak hierarchy holds unconditionally, whereas the strong version-assuming the Strong Exponential Time Hypothesis-provides better control over the time complexity of the constructed properties.
  We then turn to halfspaces in $\mathbb{R}^d$, a fundamental class in property testing and learning theory. We study the problem of approximating the distance from the input function to the nearest halfspace within additive error $\epsilon$. For the distribution-free distance approximation problem, known algorithms achieve query complexity $O(d/\epsilon^2)$, but take time $\tilde{\Theta}(1/\epsilon^d)$. We provide a fine-grained justification for this gap: assuming the $k$-SUM conjecture, any algorithm must have running time ${\Omega}(1/\epsilon^{d/2})$. This fine-grained lower bound yields a provable separation between query and time complexity for a natural and well-studied (tolerant) testing problem. We also prove that any Statistical Query (SQ) algorithm under the standard Gaussian distribution requires $(1/\epsilon)^{\Omega(d)}$ queries if the queries are answered with additive error up to $\epsilon^{\Omega(d)}$, revealing a fundamental barrier even in the distribution-specific setting.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.05927v1</guid>
      <category>cs.CC</category>
      <category>cs.DS</category>
      <pubDate>Wed, 08 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Renato Ferreira Pinto Jr., Diptaksho Palit, Sofya Raskhodnikova</dc:creator>
    </item>
    <item>
      <title>Non-iid hypothesis testing: from classical to quantum</title>
      <link>https://arxiv.org/abs/2510.06147</link>
      <description>arXiv:2510.06147v1 Announce Type: cross 
Abstract: We study hypothesis testing (aka state certification) in the non-identically distributed setting. A recent work (Garg et al. 2023) considered the classical case, in which one is given (independent) samples from $T$ unknown probability distributions $p_1, \dots, p_T$ on $[d] = \{1, 2, \dots, d\}$, and one wishes to accept/reject the hypothesis that their average $p_{\mathrm{avg}}$ equals a known hypothesis distribution $q$. Garg et al. showed that if one has just $c = 2$ samples from each $p_i$, and provided $T \gg \frac{\sqrt{d}}{\epsilon^2} + \frac{1}{\epsilon^4}$, one can (whp) distinguish $p_{\mathrm{avg}} = q$ from $d_{\mathrm{TV}}(p_{\mathrm{avg}},q) &gt; \epsilon$. This nearly matches the optimal result for the classical iid setting (namely, $T \gg \frac{\sqrt{d}}{\epsilon^2}$). Besides optimally improving this result (and generalizing to tolerant testing with more stringent distance measures), we study the analogous problem of hypothesis testing for non-identical quantum states. Here we uncover an unexpected phenomenon: for any $d$-dimensional hypothesis state $\sigma$, and given just a single copy ($c = 1$) of each state $\rho_1, \dots, \rho_T$, one can distinguish $\rho_{\mathrm{avg}} = \sigma$ from $D_{\mathrm{tr}}(\rho_{\mathrm{avg}},\sigma) &gt; \epsilon$ provided $T \gg d/\epsilon^2$. (Again, we generalize to tolerant testing with more stringent distance measures.) This matches the optimal result for the iid case, which is surprising because doing this with $c = 1$ is provably impossible in the classical case. We also show that the analogous phenomenon happens for the non-iid extension of identity testing between unknown states. A technical tool we introduce may be of independent interest: an Efron-Stein inequality, and more generally an Efron-Stein decomposition, in the quantum setting.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.06147v1</guid>
      <category>quant-ph</category>
      <category>cs.DS</category>
      <category>cs.LG</category>
      <pubDate>Wed, 08 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Giacomo De Palma, Marco Fanizza, Connor Mowry, Ryan O'Donnell</dc:creator>
    </item>
    <item>
      <title>Composable Coresets for Constrained Determinant Maximization and Beyond</title>
      <link>https://arxiv.org/abs/2211.00289</link>
      <description>arXiv:2211.00289v2 Announce Type: replace 
Abstract: We study algorithms for construction of composable coresets for the task of Determinant Maximization under partition constraint. Given a point set $V\subset \mathbb{R}^d$ that is partitioned into $s$ groups $V_1,\cdots, V_s$, and integers $k_1,...,k_s$, where $k=\sum_i k_i$, the goal is to pick $k_i$ points from group $V_i$ such that the overall determinant of the picked $k$ points is maximized. Determinant Maximization and its constrained variants have gained a lot of interest for modeling diversity, and have found applications in the context of data summarization.
  When the cardinality $k$ of the selected set is greater than the dimension $d$, we show a peeling algorithm that gives us a composable coreset of size $kd$ with a provably optimal approximation factor of $d^{O(d)}.$ When $k\leq d$, we show a simple coreset construction with optimal size and approximation factor. As a further application of our technique, we get a composable coreset for determinant maximization under the more general laminar matroid constraints, and a composable coreset for unconstrained determinant maximization in a previously unresolved regime.
  Our results generalize to all strongly Rayleigh distributions and to several other experimental design problems. As an application, we improve the runtime of the practical local-search based algorithm of [Anari-Vuong--COLT'22] for determinantal maximization under partition constraint from $O(n^{2^s}k^{2^s})$ to $O(n k^{2^s})$, making it only linear on the number of points $n$.</description>
      <guid isPermaLink="false">oai:arXiv.org:2211.00289v2</guid>
      <category>cs.DS</category>
      <category>cs.CG</category>
      <category>cs.DC</category>
      <pubDate>Wed, 08 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Sepideh Mahabadi, Thuy-Duong Vuong</dc:creator>
    </item>
    <item>
      <title>On classes of bounded tree rank, their interpretations, and efficient sparsification</title>
      <link>https://arxiv.org/abs/2404.18904</link>
      <description>arXiv:2404.18904v2 Announce Type: replace-cross 
Abstract: Graph classes of bounded tree rank were introduced recently in the context of the model checking problem for first-order logic of graphs. These graph classes are a common generalization of graph classes of bounded degree and bounded treedepth, and they are a special case of graph classes of bounded expansion. We introduce a notion of decomposition for these classes and show that these decompositions can be efficiently computed. Also, a natural extension of our decomposition leads to a new characterization and decomposition for graph classes of bounded expansion (and an efficient algorithm computing this decomposition).
  We then focus on interpretations of graph classes of bounded tree rank. We give a characterization of graph classes interpretable in graph classes of tree rank $2$. Importantly, our characterization leads to an efficient sparsification procedure: For any graph class $C$ interpretable in a efficiently bounded graph class of tree rank at most $2$, there is a polynomial time algorithm that to any $G \in C$ computes a (sparse) graph $H$ from a fixed graph class of tree rank at most $2$ such that $G = I(H)$ for a fixed interpretation $I$. To the best of our knowledge, this is the first efficient "interpretation reversal" result that generalizes the result of Gajarsk\'y et al. [LICS 2016], who showed an analogous result for graph classes interpretable in classes of graphs of bounded degree.</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.18904v2</guid>
      <category>cs.DM</category>
      <category>cs.DS</category>
      <category>cs.LO</category>
      <pubDate>Wed, 08 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Jakub Gajarsk\'y, Rose McCarty</dc:creator>
    </item>
    <item>
      <title>An Optimal Algorithm for Shortest Paths in Unweighted Disk Graphs</title>
      <link>https://arxiv.org/abs/2507.05569</link>
      <description>arXiv:2507.05569v2 Announce Type: replace-cross 
Abstract: Given in the plane a set $S$ of $n$ points and a set of disks centered at these points, the disk graph $G(S)$ induced by these disks has vertex set $S$ and an edge between two vertices if their disks intersect. Note that the disks may have different radii. We consider the problem of computing shortest paths from a source point $s\in S$ to all vertices in $G(S)$ where the length of a path in $G(S)$ is defined as the number of edges in the path. The previously best algorithm solves the problem in $O(n\log^2 n)$ time. A lower bound of $\Omega(n\log n)$ is also known for this problem under the algebraic decision tree model. In this paper, we present an $O(n\log n)$ time algorithm, which matches the lower bound and thus is optimal. Another virtue of our algorithm is that it is quite simple.</description>
      <guid isPermaLink="false">oai:arXiv.org:2507.05569v2</guid>
      <category>cs.CG</category>
      <category>cs.DS</category>
      <pubDate>Wed, 08 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Bruce W. Brewer, Haitao Wang</dc:creator>
    </item>
  </channel>
</rss>
