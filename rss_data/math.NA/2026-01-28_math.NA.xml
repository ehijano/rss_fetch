<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>math.NA updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/math.NA</link>
    <description>math.NA updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/math.NA" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Wed, 28 Jan 2026 05:00:31 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Wed, 28 Jan 2026 00:00:00 -0500</pubDate>
    <skipDays>
      <day>Saturday</day>
      <day>Sunday</day>
    </skipDays>
    <item>
      <title>A Hybrid Discretize-then-Project Reduced Order Model for Turbulent Flows on Collocated Grids with Data-Driven Closure</title>
      <link>https://arxiv.org/abs/2601.18817</link>
      <description>arXiv:2601.18817v1 Announce Type: new 
Abstract: This study presents a hybrid reduced-order modeling (ROM) framework for turbulent incompressible flows on collocated finite volume grids. The methodology employs the "discretize-then-project" consistent flux strategy, which ensures mass conservation and pressure-velocity coupling without requiring auxiliary stabilization like boundary control or pressure stabilization techniques. However, because standard Galerkin projection fails to yield physically consistent results for the turbulent viscosity field, a hybrid strategy is adopted: velocity and pressure are resolved via intrusive projection, while the turbulent viscosity is reconstructed using a non-intrusive data-driven closure. We evaluate three neural network architectures, Multilayer Perceptron (MLP), Transformers, and Long Short-Term Memory (LSTM), to model the temporal evolution of the viscosity coefficients. Validated against a 3D Large Eddy Simulation of a lid-driven cavity, the LSTM-based closure demonstrates superior performance in capturing transient dynamics, achieving relative errors of 0.7\% for velocity and 4\% for turbulent viscosity. The resulting framework effectively combines the mathematical rigor of the consistent flux formulation with the adaptability of deep learning for turbulence modeling.</description>
      <guid isPermaLink="false">oai:arXiv.org:2601.18817v1</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <category>physics.flu-dyn</category>
      <pubDate>Wed, 28 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Nadim Rooholamin, Kabir Bakhshaei, Giovanni Stabile</dc:creator>
    </item>
    <item>
      <title>Kroneckerised Particle Mesh Ewald</title>
      <link>https://arxiv.org/abs/2601.18838</link>
      <description>arXiv:2601.18838v1 Announce Type: new 
Abstract: Particle Mesh Ewald (PME) methods accelerated through Fast Fourier Transforms (FFTs) for their reciprocal part are widely used to solve N -body problems over periodic structures with Laplace-like kernels. The FFT dependence of classical PME may mitigate its performance on parallel distributed-memory architectures. We here introduce a new variant of the reciprocal part based on Sum of Kronecker Products (SKP) instead of FFT. Moreover, our implementation of this new method is not linearithmic (as opposed to classical PME) but has an important parallel potential. We present the different approximation levels exploited in our new scheme and demonstrate to what extent it could be used on parallel distributed-memory architectures. Numerical examples supplement presented assertions.</description>
      <guid isPermaLink="false">oai:arXiv.org:2601.18838v1</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <pubDate>Wed, 28 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Igor Chollet (LAGA)</dc:creator>
    </item>
    <item>
      <title>On the Strong Stability Preserving Property of Runge-Kutta Methods for Hyperbolic Problems</title>
      <link>https://arxiv.org/abs/2601.18947</link>
      <description>arXiv:2601.18947v1 Announce Type: new 
Abstract: Strong Stability Preserving (SSP) time integration schemes maintain stability of the forward Euler method for any initial value problem. However, only a small subset of Runge-Kutta (RK) methods are SSP, and many efficient high-order time integration schemes do not formally belong to this class. In this work, we introduce a mathematical strategy to analyze the nonlinear stability of RK schemes that may not necessarily belong to the SSP class. With this approach, we mathematically demonstrate that there are time integration schemes outside the class of SSP schemes that can maintain entropy stability and positivity of density and pressure for the Lax-Friedrichs discretization, and Total Variation Diminishing stability for the first-order upwind and the second-order MUSCL schemes. As a result, for these problems, a broader range of RK methods, including the classical fourth-order, four-stage RK scheme, can be used while the numerical integration remains stable. Numerical experiments confirm these theoretical findings, and additional experiments demonstrate similar observations for a wider class of space discretizatins.</description>
      <guid isPermaLink="false">oai:arXiv.org:2601.18947v1</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <pubDate>Wed, 28 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Mohammad R. Najafian, Brian C. Vermeire</dc:creator>
    </item>
    <item>
      <title>AAA least squares solution of Helmholtz problems</title>
      <link>https://arxiv.org/abs/2601.19020</link>
      <description>arXiv:2601.19020v1 Announce Type: new 
Abstract: This paper presents an adaptive numerical framework for solving exterior "sound-soft" scattering problems governed by the Helmholtz equation. By interpreting the Method of Fundamental Solutions through the lens of rational approximation, we introduce an automated strategy for singularity placement based on the analytic continuation of boundary data. The proposed AAALS-Helmholtz algorithm leverages a "continuum" variant of the AAA algorithm to identify the singularities limiting analytic extension, and to ensure an optimal source distribution even for complex, non star-shaped geometries. Furthermore, we establish a formal connection between the Helmholtz and Laplace problems, providing a theoretical justification for the "double poles" technique. The approach offers a robust, meshless alternative to heuristic source placement.</description>
      <guid isPermaLink="false">oai:arXiv.org:2601.19020v1</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <pubDate>Wed, 28 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Stefano Costa</dc:creator>
    </item>
    <item>
      <title>A sixth-order compact time-splitting Fourier pseudospectral method</title>
      <link>https://arxiv.org/abs/2601.19172</link>
      <description>arXiv:2601.19172v1 Announce Type: new 
Abstract: In this paper, we propose a novel sixth-order compact time-splitting scheme, denoted as $ S_{6\text{c}}$, for solving the Dirac equation in the absence of external magnetic potentials. This method is easy to implement, and it provides a substantial reduction in computational complexity compared to the existing sixth-order splitting schemes. By incorporating a time-ordering technique, we also extend $S_{6\text{c}}$ to address problems with time-dependent potentials. Comprehensive comparisons with various time-splitting methods show that $S_{6\text{c}}$ exhibits significant advantages in terms of both precision and efficiency. Moreover, numerical results indicate that $S_{6\text{c}}$ maintains the super-resolution property for the Dirac equation in the nonrelativistic regime in the absence of external magnetic potentials.</description>
      <guid isPermaLink="false">oai:arXiv.org:2601.19172v1</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <pubDate>Wed, 28 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Weiguo Gao, Zhansi He, Jia Yin</dc:creator>
    </item>
    <item>
      <title>On a Class of Multi-Dimensional Non-linear Time-Fractional Fokker-Planck Equations Capturing Brownian Motion</title>
      <link>https://arxiv.org/abs/2601.19211</link>
      <description>arXiv:2601.19211v1 Announce Type: new 
Abstract: The time-fractional Fokker-Planck equation is a key model for characterizing anomalous diffusion, stochastic transport, and non-equilibrium statistical mechanics with applications in finance, chaotic dynamics, optical physics, and biological systems. In this work, we develop a semi-analytical solution for the multi-dimensional time-fractional Fokker-Planck equation employing the Laplace residual power series method. This method blends the Laplace transform and the traditional residual power series method, guaranteeing efficient solutions incorporating the memory and nonlocal effects. To validate the accuracy and effectiveness of the approach, we address several examples, including non-linear problems in multi-dimensions, and analyze the evolution of errors. The numerical simulations are compared with existing methods to confirm the adopted method's strength. The smooth and stable error evolution promises that the suggested method is a powerful tool for analyzing time-fractional Fokker-Planck equations.</description>
      <guid isPermaLink="false">oai:arXiv.org:2601.19211v1</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <category>math.AP</category>
      <pubDate>Wed, 28 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Neetu Garg, Varsha R</dc:creator>
    </item>
    <item>
      <title>Precision-induced Adaptive Randomized Low-Rank Approximation for SVD and Matrix Inversion</title>
      <link>https://arxiv.org/abs/2601.19250</link>
      <description>arXiv:2601.19250v1 Announce Type: new 
Abstract: Singular value decomposition (SVD) and matrix inversion are ubiquitous in scientific computing. Both tasks are computationally demanding for large scale matrices. Existing algorithms can approximatively solve these problems with a given rank, which however is unknown in practice and requires considerable cost for tuning. In this paper, we tackle the SVD and matrix inversion problems from a new angle, where the optimal rank for the approximate solution is explicitly guided by the distribution of the singular values. Under the framework, we propose a precision-induced random re-normalization procedure for the considered problems without the need of guessing a good rank. The new algorithms built upon the procedure simultaneously calculate the optimal rank for the task at a desired precision level and lead to the corresponding approximate solution with a substantially reduced computational cost. The promising performance of the new algorithms is supported by both theory and numerical examples.</description>
      <guid isPermaLink="false">oai:arXiv.org:2601.19250v1</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <pubDate>Wed, 28 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Weiwei Xu, Weijie Shen, Zhengjian Bai, Chen Xu</dc:creator>
    </item>
    <item>
      <title>Seepage analysis using a polygonal cell-based smoothed finite element method</title>
      <link>https://arxiv.org/abs/2601.19357</link>
      <description>arXiv:2601.19357v1 Announce Type: new 
Abstract: This work develops a polygonal cell-based smoothed finite element method for steady-state, transient, and free-surface seepage in saturated porous media. Wachspress interpolation on convex polygonal elements is combined with cell-based gradient smoothing, so that element matrices are assembled using boundary integrals without in-element derivatives. Polygonal, quadtree, and hybrid quadtree--polygonal meshes are employed to accommodate local refinement and hanging nodes, and a solution-driven adaptive strategy further concentrates resolution near steep gradients and wet--dry transitions. Free-surface seepage is solved using a fixed-mesh iterative scheme that updates the wetted region, permeability field, and boundary conditions. Benchmark tests demonstrate accurate hydraulic-head and free-surface predictions, and show that adaptivity attains similar accuracy with substantially fewer degrees of freedom and CPU time.</description>
      <guid isPermaLink="false">oai:arXiv.org:2601.19357v1</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <pubDate>Wed, 28 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Yang Yang, Mingjiao Yan, Zongliang Zhang, Yinpeng Yin, Qiang Liu, You-liang Li</dc:creator>
    </item>
    <item>
      <title>Unified Regularization of 2D Singular Integrals for Axisymmetric Galerkin BEM in Eddy-Current Evaluation</title>
      <link>https://arxiv.org/abs/2601.19542</link>
      <description>arXiv:2601.19542v1 Announce Type: new 
Abstract: This paper presents an axisymmetric Galerkin boundary element method (BEM) for modeling eddy-current interactions between excitation coils and conductive objects. The formulation derives boundary integral equations from the Stratton-Chu representation for the azimuthal component of the vector potential in both air and conductive regions. The central contribution is a unified regularization framework for the two-dimensional (2D) singular integrals arising in Galerkin BEM. This framework handles both logarithmic and Cauchy singularities through a common set of integral transformations, eliminating the need for case-by-case analytical singularity extraction and enabling straightforward numerical quadrature. The regularization and quadrature stability are proved and verified numerically. The method is validated on several representative axisymmetric geometries, including cylindrical, conical, and spherical shells. Numerical experiments demonstrate consistently high accuracy and computational efficiency across broad frequency ranges and coil lift-off distances. The results confirm that the proposed axisymmetric Galerkin BEM, combined with the integral transformation technique, provides a robust and efficient framework for axisymmetric eddy-current nondestructive evaluation.</description>
      <guid isPermaLink="false">oai:arXiv.org:2601.19542v1</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <category>physics.comp-ph</category>
      <pubDate>Wed, 28 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Yao Luo</dc:creator>
    </item>
    <item>
      <title>A Green's Function-Based Enclosure Framework for Poisson's Equation and Generalized Sub- and Super-Solutions</title>
      <link>https://arxiv.org/abs/2601.19682</link>
      <description>arXiv:2601.19682v1 Announce Type: new 
Abstract: This paper presents a novel framework for enclosing solutions of Poisson's equation based on generalized sub- and super-solutions constructed using fundamental solutions. The conventional definition of sub- and super-solutions based on variational inequalities often fails for natural function classes such as piecewise linear functions and encounters theoretical difficulties in non-convex polygonal domains, where H^2 regularity is lost because of corner singularities. To overcome these limitations, we introduce the concept of ``Green-representable solutions'' utilizing test functions constructed from fundamental solutions. This framework enables a new formulation of sub- and super-solutions that permits rigorous pointwise evaluation. For one-dimensional problems, we derive explicit constructions of the test functions. For two-dimensional polygonal domains, we employ the Method of Fundamental Solutions to generate test functions. The approach is validated through numerical experiments in both settings, including non-convex polygons. The results demonstrate that the proposed method yields strict and accurate pointwise enclosures of the true solution, even for problems with discontinuous source terms or geometric singularities.</description>
      <guid isPermaLink="false">oai:arXiv.org:2601.19682v1</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <category>math.AP</category>
      <pubDate>Wed, 28 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Kazuaki Tanaka, Ryoga Iwanami, Kaname Matsue, Hiroyuki Ochiai</dc:creator>
    </item>
    <item>
      <title>Error estimates of a training-free diffusion model for high-dimensional sampling</title>
      <link>https://arxiv.org/abs/2601.19740</link>
      <description>arXiv:2601.19740v1 Announce Type: new 
Abstract: Score-based diffusion models are a powerful class of generative models, but their practical use often depends on training neural networks to approximate the score function. Training-free diffusion models provide an attractive alternative by exploiting analytically tractable score functions, and have recently enabled supervised learning of efficient end-to-end generative samplers. Despite their empirical success, the training-free diffusion models lack rigorous and numerically verifiable error estimates. In this work, we develop a comprehensive error analysis for a class of training-free diffusion models used to generate labeled data for supervised learning of generative samplers. By exploiting the availability of the exact score function for Gaussian mixture models, our analysis avoids propagating score-function approximation errors through the reverse-time diffusion process and recovers classical convergence rates for ODE discretization schemes, such as first-order convergence for the Euler method. Moreover, the resulting error bounds exhibit favorable dimension dependence, scaling as $O(d)$ in the $\ell_2$ norm and $O(\log d)$ in the $\ell_\infty$ norm. Importantly, the proposed error estimates are fully numerically verifiable with respect to both time-step size and dimensionality, thereby bridging the gap between theoretical analysis and observed numerical behavior.</description>
      <guid isPermaLink="false">oai:arXiv.org:2601.19740v1</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <pubDate>Wed, 28 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Pengjun Wang, Zezhong Zhang, Minglei Yang, Feng Bao, Yanzhao Cao, Guannan Zhang</dc:creator>
    </item>
    <item>
      <title>A refined nonlinear least-squares method for the rational approximation problem</title>
      <link>https://arxiv.org/abs/2601.19813</link>
      <description>arXiv:2601.19813v1 Announce Type: new 
Abstract: The adaptive Antoulas-Anderson (AAA) algorithm for rational approximation is a widely used method for the efficient construction of highly accurate rational approximations to given data. While AAA can often produce rational approximations accurate to any prescribed tolerance, these approximations may have degrees larger than what is actually required to meet the given tolerance. In this work, we consider the adaptive construction of interpolating rational approximations while aiming for the smallest feasible degree to satisfy a given error tolerance. To this end, we introduce refinement approaches to the linear least-squares step of the classical AAA algorithm that aim to minimize the true nonlinear least-squares error with respect to the given data. Furthermore, we theoretically analyze the derived approaches in terms of the corresponding gradients from the resulting minimization problems and use these insights to propose a new greedy framework that ensures monotonic error convergence. Numerical examples from function approximation and model order reduction verify the effectiveness of the proposed algorithm to construct accurate rational approximations of small degrees.</description>
      <guid isPermaLink="false">oai:arXiv.org:2601.19813v1</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <category>cs.SY</category>
      <category>eess.SY</category>
      <category>math.DS</category>
      <category>math.OC</category>
      <pubDate>Wed, 28 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Michael S. Ackermann, Linus Balicki, Serkan Gugercin, Steffen W. R. Werner</dc:creator>
    </item>
    <item>
      <title>Galerkin-type time discretizations for parabolic and hyperbolic problems: stability and a priori error analysis</title>
      <link>https://arxiv.org/abs/2601.19828</link>
      <description>arXiv:2601.19828v1 Announce Type: new 
Abstract: We present a unified framework for the analysis of space-time methods based on Galerkin-type time discretizations for parabolic and hyperbolic problems. Crucially, the stability analysis relies on a suitable choice of test functions to establish the continuous dependence of the discrete solution on the data in $L^{\infty}(0, T; X)$ norms, which is then used to derive a priori error estimates. This approach closes the gap in the analysis of some methods in this class caused by the limitation of standard energy arguments, and is characterized by the absence of Gr\"onwall estimates, applicability to arbitrary approximation degrees, reduced regularity assumptions, and robustness with respect to the model parameters.</description>
      <guid isPermaLink="false">oai:arXiv.org:2601.19828v1</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <pubDate>Wed, 28 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Sergio G\'omez</dc:creator>
    </item>
    <item>
      <title>Modified splitting methods for Gross-Pitaevskii systems modelling Bose-Einstein condensates: Time evolution and ground state computation</title>
      <link>https://arxiv.org/abs/2601.19838</link>
      <description>arXiv:2601.19838v1 Announce Type: new 
Abstract: The year 2025 marks the 100 and 30 years anniversaries of the discovery of Bose--Einstein condensation and its successful experimental realisation. Inspired by these important research achievements, a conceptually simple approach is proposed to facilitate reliable and efficient numerical simulations. The structure of the underlying systems of coupled Gross--Pitaevskii equations suggests the use of optimised high-order operator splitting methods for dynamical evolution and ground state computation. A second-order barrier, however, prevents the applicability of standard operator splitting methods for both, time evolution as well as imaginary time propagation. An innovative alternative approach accomplishes the design of novel modified operator splitting methods that remain stable under moderate smallness assumptions on the time increments. The core idea is to incorporate commutators of the defining differential and nonlinear multiplication operators, since this permits to fulfill the basic stability requirement of positive method coefficients. Further improvements with respect to convergence at the targeted precision arise from automatic adjustments of the time stepsizes by an inexpensive local error control. The presented numerical experiments confirm the favourable performance of a specific fourth-order modified operator splitting method. Amongst others, it is demonstrated that the excellent mass and energy conservation in long-term evolutions, intrinsic attributes of geometric numerical integrators for Hamiltonian systems, is maintained for a sensible variation of the time stepsizes. Moreover, the benefits of adaptive higher-order approximations in ground state computations are illustrated.</description>
      <guid isPermaLink="false">oai:arXiv.org:2601.19838v1</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <pubDate>Wed, 28 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Mechthild Thalhammer, Gregor Thalhammer-Thurner</dc:creator>
    </item>
    <item>
      <title>An Energy-Preserving Domain of Dependence Stabilization for the Linear Wave Equation on Cut-Cell Meshes</title>
      <link>https://arxiv.org/abs/2601.19877</link>
      <description>arXiv:2601.19877v1 Announce Type: new 
Abstract: We present an energy-preserving (either energy-conservative or energy-dissipative) domain of dependence stabilization method for the linear wave equation on cut-cell meshes. Our scheme is based on a standard discontinuous Galerkin discretization in space and an explicit (strong stability preserving) Runge Kutta method in time. Tailored stabilization terms allow for selecting the time step length based on the size of the background cells rather than the small cut cells by propagating information across small cut cells. The stabilization terms preserve the energy stability or energy conservation property of the underlying discontinuous Galerkin space discretization. Numerical results display the high accuracy and stability properties of our scheme.</description>
      <guid isPermaLink="false">oai:arXiv.org:2601.19877v1</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <pubDate>Wed, 28 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Gunnar Birke, Christian Engwer, Sandra May, Louis Petri, Hendrik Ranocha</dc:creator>
    </item>
    <item>
      <title>Tensorized Discontinuous Isogeometric Analysis Method for the 2-D Time-Independent Linearized Boltzmann Transport Equation</title>
      <link>https://arxiv.org/abs/2601.18925</link>
      <description>arXiv:2601.18925v1 Announce Type: cross 
Abstract: We present the novel Tensorized Discontinuous Isogeometric Analysis (TDIGA) method applied to the discontinuous Galerkin (DG) time-independent 2-D linearized Boltzmann transport equation (LBTE) with higher-order scattering, discretized with discrete ordinates in angle, multigroup in energy, and isogeometric analysis (IGA) in space. We formulate operator assembly in the tensor train (TT) format, producing seven-dimensional operators for both fixed-source and $k$-eigenvalue neutron transport problems solved using the restarted Generalized Minimum Residual Method (GMRES) and power iteration with an uncompressed solution vector. Our results on single-patch homogeneous and multi-patch heterogeneous problems, including a cruciform-shaped fuel array inspired by advanced reactor fuel designs, demonstrate the TT format's ability to compress interior operators from petabytes to megabytes, whereas the Compressed Sparse Row (CSR) matrix format requires gigabytes of storage. However, highly coupled boundary operators present a significant challenge for TT. Despite the storage savings, TT formatted operators increase time-to-solution relative to CSR as an uncompressed solution vector forces operator-vector product scaling of $O(dr^2N^d\log(N))$ for TT while CSR scales at $O(\text{nnz})$. We mitigate this discrepancy by using mixed formats with interior operators in TT, while high-rank boundary operators remain in CSR format. We compare all results to Monte Carlo (MC) and analytic reference solutions. While CSR remains $&lt;10\times$ faster than this mixed format, the TDIGA method enables high-fidelity transport for expensive high-order IGA meshes.</description>
      <guid isPermaLink="false">oai:arXiv.org:2601.18925v1</guid>
      <category>physics.comp-ph</category>
      <category>cs.NA</category>
      <category>math.NA</category>
      <pubDate>Wed, 28 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Patrick A. Myers, Joseph A. Bogdan, Majdi I. Radaideh, Brian C. Kiedrowski</dc:creator>
    </item>
    <item>
      <title>Mixture-Weighted Ensemble Kalman Filter with Quasi-Monte Carlo Transport</title>
      <link>https://arxiv.org/abs/2601.18992</link>
      <description>arXiv:2601.18992v1 Announce Type: cross 
Abstract: The Bootstrap Particle Filter (BPF) and the Ensemble Kalman Filter (EnKF) are two widely used methods for sequential Bayesian filtering: the BPF is asymptotically exact but can suffer from weight degeneracy, while the EnKF scales well in high dimension yet is exact only in the linear-Gaussian case. We combine these approaches by retaining the EnKF transport step and adding a principled importance-sampling correction. Our first contribution is a general importance-sampling theory for mixture targets and proposals, including variance comparisons between individual- and mixture-based estimators. We then interpret the stochastic EnKF analysis as sampling from explicit Gaussian-mixture proposals obtained by conditioning on the current or previous ensemble, which leads to six self-normalized IS-EnKF schemes. We embed these updates into a broader class of ensemble-based filters and prove consistency and error bounds, including weight-variance comparisons and sufficient conditions ensuring finite-variance importance weights. As a second contribution, we construct transported quasi-Monte Carlo (TQMC) point sets for the Gaussian-mixture laws arising in prediction and analysis, yielding TQMC-enhanced variants that can substantially reduce sampling error without changing the filtering pipeline. Numerical experiments on benchmark models compare the proposed mixture-weighted and TQMC-enhanced filters, showing improved filtering accuracy relative to BPF, EnKF, and the standard weighted EnKF, and that the weighted schemes eliminate the EnKF error plateau often caused by analysis-target mismatch.</description>
      <guid isPermaLink="false">oai:arXiv.org:2601.18992v1</guid>
      <category>stat.ME</category>
      <category>cs.NA</category>
      <category>math.NA</category>
      <pubDate>Wed, 28 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Ilja Klebanov, Claudia Schillings, Dana Wrischnig</dc:creator>
    </item>
    <item>
      <title>Approximation by linear sampling operators in Banach spaces</title>
      <link>https://arxiv.org/abs/2601.19012</link>
      <description>arXiv:2601.19012v1 Announce Type: cross 
Abstract: This paper studies approximation properties of linear sampling operators in general Banach lattices $X$. We obtain matching direct and inverse approximation estimates, convergence criteria, equivalence results involving special $K$-functionals and their realizations by sampling operators, as well as strong converse inequalities, which, to the best of our knowledge, have not been previously established for sampling operators even in the classical spaces $L_p$. The results extend several classical theorems previously known mainly in $L_p$ and apply to all functions $f\in X$ for which the corresponding sampling operator is well defined, thereby substantially enlarging the class of functions that can be considered in this framework.</description>
      <guid isPermaLink="false">oai:arXiv.org:2601.19012v1</guid>
      <category>math.FA</category>
      <category>cs.NA</category>
      <category>math.CA</category>
      <category>math.NA</category>
      <pubDate>Wed, 28 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Yurii Kolomoitsev</dc:creator>
    </item>
    <item>
      <title>Polyhedral design with blended $n$-sided interpolants</title>
      <link>https://arxiv.org/abs/2601.19322</link>
      <description>arXiv:2601.19322v1 Announce Type: cross 
Abstract: A new parametric surface representation is proposed that interpolates the vertices of a given closed mesh of arbitrary topology. Smoothly connecting quadrilateral patches are created by blending local, multi-sided quadratic interpolants. In the non-four-sided case, this requires a special parameterization technique involving rational curves. Appropriate handling of triangular subpatches and alternative subpatch representations are also discussed.</description>
      <guid isPermaLink="false">oai:arXiv.org:2601.19322v1</guid>
      <category>cs.CG</category>
      <category>cs.NA</category>
      <category>math.NA</category>
      <pubDate>Wed, 28 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <arxiv:journal_reference>Proceedings of the Eleventh Hungarian Conference on Computer Graphics and Geometry, pp. 46-51, 2024</arxiv:journal_reference>
      <dc:creator>P\'eter Salvi</dc:creator>
    </item>
    <item>
      <title>Jacobi-Pi\~neiro Multiple Orthogonal Polynomials on the simplex</title>
      <link>https://arxiv.org/abs/2601.19416</link>
      <description>arXiv:2601.19416v1 Announce Type: cross 
Abstract: It is known that Rodrigues formulas provide a very powerful tool to compute orthogonal polynomials with respect to classical weights. We provide an example of bivariate multiple polynomials on the simplex defined via a Rodrigues formula. This approach offers a natural generalization of Jacobi--Pi\~neiro polynomials to the multivariate setting. Moreover, we apply these polynomials to the study of the bivariate Hermite--Pad\'e problem on the triangle.</description>
      <guid isPermaLink="false">oai:arXiv.org:2601.19416v1</guid>
      <category>math.CA</category>
      <category>cs.NA</category>
      <category>math.NA</category>
      <pubDate>Wed, 28 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Lidia Fern\'andez, Ana Foulqui\'e-Moreno, Juan Antonio Villegas</dc:creator>
    </item>
    <item>
      <title>On some nonlocal, nonlinear diffusion problems</title>
      <link>https://arxiv.org/abs/2601.19478</link>
      <description>arXiv:2601.19478v1 Announce Type: cross 
Abstract: This note is devoted to some nonlocal, nonlinear elliptic problems with an emphasis on the computation of the solution of such problems, reducing it in particular to a fixed point argument in R. Errors estimates and numerical experiments are provided.</description>
      <guid isPermaLink="false">oai:arXiv.org:2601.19478v1</guid>
      <category>math.AP</category>
      <category>cs.NA</category>
      <category>math.NA</category>
      <pubDate>Wed, 28 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>M. M. Chipot, A. Luthra, S. A. Sauter</dc:creator>
    </item>
    <item>
      <title>Computing the density of the Kesten-Stigum limit in supercritical Galton-Watson processes</title>
      <link>https://arxiv.org/abs/2601.19633</link>
      <description>arXiv:2601.19633v1 Announce Type: cross 
Abstract: This paper proposes a novel numerical method for computing the density of the limit random variable associated with a supercritical Galton-Watson process. This random variable captures the effect of early demographic fluctuations and determines the random amplitude of long-term exponential population growth. While the existence of a non-trivial limit is ensured by the Kesten-Stigum theorem, computing its density in a stable and efficient manner for arbitrary offspring laws remains a significant challenge. The proposed approach leverages a functional equation that characterizes the Laplace-Stieltjes transform of the limit distribution and combines it with a moment-matching method to obtain accurate approximations within a class of linear combinations of Laguerre polynomials with exponential damping. The effectiveness of the approach is validated on several examples in which the offspring generating function is a polynomial of bounded degree.</description>
      <guid isPermaLink="false">oai:arXiv.org:2601.19633v1</guid>
      <category>math.PR</category>
      <category>cs.NA</category>
      <category>math.NA</category>
      <pubDate>Wed, 28 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Alice Cortinovis, Sophie Hautphenne, Stefano Massei</dc:creator>
    </item>
    <item>
      <title>Learn and Verify: A Framework for Rigorous Verification of Physics-Informed Neural Networks</title>
      <link>https://arxiv.org/abs/2601.19818</link>
      <description>arXiv:2601.19818v1 Announce Type: cross 
Abstract: The numerical solution of differential equations using neural networks has become a central topic in scientific computing, with Physics-Informed Neural Networks (PINNs) emerging as a powerful paradigm for both forward and inverse problems. However, unlike classical numerical methods that offer established convergence guarantees, neural network-based approximations typically lack rigorous error bounds. Furthermore, the non-deterministic nature of their optimization makes it difficult to mathematically certify their accuracy. To address these challenges, we propose a "Learn and Verify" framework that provides computable, mathematically rigorous error bounds for the solutions of differential equations. By combining a novel Doubly Smoothed Maximum (DSM) loss for training with interval arithmetic for verification, we compute rigorous a posteriori error bounds as machine-verifiable proofs. Numerical experiments on nonlinear Ordinary Differential Equations (ODEs), including problems with time-varying coefficients and finite-time blow-up, demonstrate that the proposed framework successfully constructs rigorous enclosures of the true solutions, establishing a foundation for trustworthy scientific machine learning.</description>
      <guid isPermaLink="false">oai:arXiv.org:2601.19818v1</guid>
      <category>cs.LG</category>
      <category>cs.NA</category>
      <category>math.NA</category>
      <pubDate>Wed, 28 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Kazuaki Tanaka, Kohei Yatabe</dc:creator>
    </item>
    <item>
      <title>Adaptive finite elements for obstacle problems</title>
      <link>https://arxiv.org/abs/2410.22991</link>
      <description>arXiv:2410.22991v2 Announce Type: replace 
Abstract: We summarise three applications of the obstacle problem to membrane contact, elastoplastic torsion and cavitation modelling, and show how the resulting models can be solved using mixed finite elements. It is challenging to construct fixed computational meshes for any inequality-constrained problem because the coincidence set has an unknown shape. Consequently, we demonstrate how $h$-adaptivity can be used to resolve the unknown coincidence set. We demonstrate some practical challenges that must be overcome in the application of the adaptive method.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.22991v2</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <pubDate>Wed, 28 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <arxiv:DOI>10.1016/bs.aams.2024.03.004</arxiv:DOI>
      <arxiv:journal_reference>Advances in Applied Mechanics, volume 58, chapter 5, 2024</arxiv:journal_reference>
      <dc:creator>Tom Gustafsson</dc:creator>
    </item>
    <item>
      <title>Numerical stability revisited: A family of benchmark problems for the analysis of explicit stochastic differential equation integrators</title>
      <link>https://arxiv.org/abs/2503.19203</link>
      <description>arXiv:2503.19203v2 Announce Type: replace 
Abstract: In this paper, we revisit the numerical stability of four well-established explicit stochastic integration schemes through a new generic benchmark stochastic differential equation (SDE) designed to assess asymptotic statistical accuracy and stability properties. This one-parameter benchmark equation is derived from a general one-dimensional first-order SDE using spatio-temporal nondimensionalization and is employed to evaluate the performance of (1) Euler-Maruyama (EM), (2) Milstein (Mil), (3) Stochastic Heun (SH), and (4) a three-stage Runge-Kutta scheme (RK3). Our findings reveal that lower-order schemes can outperform higher-order ones over a range of time step sizes, depending on the benchmark parameters and application context. The theoretical results are validated through a series of numerical experiments, and we discuss their implications for more general applications, including a nonlinear example of particle transport in porous media under various conditions. Our results suggest that the insights obtained from the linear benchmark problem provide reliable guidance for time-stepping strategies when simulating nonlinear SDEs.</description>
      <guid isPermaLink="false">oai:arXiv.org:2503.19203v2</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <pubDate>Wed, 28 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Thomas Hudson, Xingjie Helen Li, Sarah Murphy</dc:creator>
    </item>
    <item>
      <title>Analysis of a finite element method for PDEs in evolving domains with topological changes</title>
      <link>https://arxiv.org/abs/2504.14116</link>
      <description>arXiv:2504.14116v3 Announce Type: replace 
Abstract: The paper presents the first rigorous error analysis of an unfitted finite element method for a linear parabolic problem posed on an evolving domain $\Omega(t)$ that may undergo a topological change, such as, for example, a domain splitting. The domain evolution is assumed to be $C^2$-smooth away from a critical time $t_c$, at which the topology may change instantaneously. To accommodate such topological transitions in the error analysis, we introduce several structural assumptions on the evolution of $\Omega(t)$ in the vicinity of the critical time. These assumptions allow a specific stability estimate even across singularities. Based on this stability result we derive optimal-order discretization error bounds, provided the continuous solution is sufficiently smooth. We demonstrate the applicability of our assumptions with examples of level-set domains undergoing topological transitions and discuss cases where the analysis fails. The theoretical error estimate is confirmed by the results of a numerical experiment.</description>
      <guid isPermaLink="false">oai:arXiv.org:2504.14116v3</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <pubDate>Wed, 28 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Maxim A. Olshanskii, Arnold Reusken</dc:creator>
    </item>
    <item>
      <title>Minimal residual rational Krylov subspace method for sequences of shifted linear systems</title>
      <link>https://arxiv.org/abs/2507.00267</link>
      <description>arXiv:2507.00267v2 Announce Type: replace 
Abstract: The solution of sequences of shifted linear systems is a classic problem in numerical linear algebra, and a variety of efficient methods have been proposed over the years. Nevertheless, there still exist challenging scenarios witnessing a lack of performing solvers. For instance, state-of-the-art procedures struggle to handle nonsymmetric problems where the shifts are complex numbers that do not come as conjugate pairs. We design a novel projection strategy based on the rational Krylov subspace equipped with a minimal residual condition. We also devise a novel pole selection procedure, tailored to our problem, providing poles for the rational Krylov basis construction that yield faster convergence than those computed by available general-purpose schemes. A panel of diverse numerical experiments shows that our novel approach performs better than state-of-the-art techniques, especially on the very challenging problems mentioned above.</description>
      <guid isPermaLink="false">oai:arXiv.org:2507.00267v2</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <pubDate>Wed, 28 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Hussam Al Daas, Davide Palitta</dc:creator>
    </item>
    <item>
      <title>Numerical Study of Dissipative Weak Solutions for the Euler Equations of Gas Dynamics</title>
      <link>https://arxiv.org/abs/2601.17452</link>
      <description>arXiv:2601.17452v2 Announce Type: replace 
Abstract: We study dissipative weak (DW) solutions of the Euler equations of gas dynamics using the first-, second-, third-, fifth-, seventh-, and ninth-order local characteristic decomposition-based central-upwind (LCDCU), low-dissipation central-upwind (LDCU), and viscous finite volume (VFV) methods, whose higher-order extensions are obtained via the framework of the alternative weighted essentially non-oscillatory (A-WENO) schemes. These methods are applied to several benchmark problems, including several two-dimensional Riemann problems and a Kelvin-Helmholtz instability test. The numerical results demonstrate that for methods converging only weakly in space and time, the limiting solutions are generalized DW solutions, approximated in the sense of ${\cal K}$-convergence and dependent on the numerical scheme. For all of the studied methods, we compute the associated Young measures and compare the DW solutions using entropy production and energy defect criteria.</description>
      <guid isPermaLink="false">oai:arXiv.org:2601.17452v2</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <pubDate>Wed, 28 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Shaoshuai Chu, Michael Herty, Alexander Kurganov, Maria Lukacova-Medvidova, Changsheng Yu</dc:creator>
    </item>
    <item>
      <title>Extensions on Low-complexity DCT Approximations for Larger Blocklengths Based on Minimal Angle Similarity</title>
      <link>https://arxiv.org/abs/2410.15244</link>
      <description>arXiv:2410.15244v2 Announce Type: replace-cross 
Abstract: The discrete cosine transform (DCT) is a central tool for image and video coding because it can be related to the Karhunen-Lo\`eve transform (KLT), which is the optimal transform in terms of retained transform coefficients and data decorrelation. In this paper, we introduce 16-, 32-, and 64-point low-complexity DCT approximations by minimizing individually the angle between the rows of the exact DCT matrix and the matrix induced by the approximate transforms. According to some classical figures of merit, the proposed transforms outperformed the approximations for the DCT already known in the literature. Fast algorithms were also developed for the low-complexity transforms, asserting a good balance between the performance and its computational cost. Practical applications in image encoding showed the relevance of the transforms in this context. In fact, the experiments showed that the proposed transforms had better results than the known approximations in the literature for the cases of 16, 32, and 64 blocklength.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.15244v2</guid>
      <category>eess.IV</category>
      <category>cs.CV</category>
      <category>cs.NA</category>
      <category>eess.SP</category>
      <category>math.NA</category>
      <category>stat.ME</category>
      <pubDate>Wed, 28 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <arxiv:DOI>10.1007/s11265-023-01848-w</arxiv:DOI>
      <arxiv:journal_reference>J Sign Process Syst 95, 495-516 (2023)</arxiv:journal_reference>
      <dc:creator>A. P. Rad\"unz, L. Portella, R. S. Oliveira, F. M. Bayer, R. J. Cintra</dc:creator>
    </item>
    <item>
      <title>Deeply Learned Robust Matrix Completion for Large-scale Low-rank Data Recovery</title>
      <link>https://arxiv.org/abs/2501.00677</link>
      <description>arXiv:2501.00677v2 Announce Type: replace-cross 
Abstract: Robust matrix completion (RMC) is a widely used machine learning tool that simultaneously tackles two critical issues in low-rank data analysis: missing data entries and extreme outliers. This paper proposes a novel scalable and learnable non-convex approach, coined Learned Robust Matrix Completion (LRMC), for large-scale RMC problems. LRMC enjoys low computational complexity with linear convergence. Motivated by the proposed theorem, the free parameters of LRMC can be effectively learned via deep unfolding to achieve optimum performance. Furthermore, this paper proposes a flexible feedforward-recurrent-mixed neural network framework that extends deep unfolding from fix-number iterations to infinite iterations. The superior empirical performance of LRMC is verified with extensive experiments against state-of-the-art on synthetic datasets and real applications, including video background subtraction, ultrasound imaging, face modeling, and cloud removal from satellite imagery.</description>
      <guid isPermaLink="false">oai:arXiv.org:2501.00677v2</guid>
      <category>cs.LG</category>
      <category>cs.CV</category>
      <category>cs.IT</category>
      <category>cs.NA</category>
      <category>math.IT</category>
      <category>math.NA</category>
      <category>stat.ML</category>
      <pubDate>Wed, 28 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <arxiv:DOI>10.1109/TPAMI.2026.3659041</arxiv:DOI>
      <dc:creator>HanQin Cai, Chandra Kundu, Jialin Liu, Wotao Yin</dc:creator>
    </item>
  </channel>
</rss>
