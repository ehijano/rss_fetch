<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>math.OC updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/math.OC</link>
    <description>math.OC updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/math.OC" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Tue, 26 Aug 2025 13:17:08 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Tue, 26 Aug 2025 00:00:00 -0400</pubDate>
    <skipDays>
      <day>Sunday</day>
      <day>Saturday</day>
    </skipDays>
    <item>
      <title>VFOG: Variance-Reduced Fast Optimistic Gradient Methods for a Class of Nonmonotone Generalized Equations</title>
      <link>https://arxiv.org/abs/2508.16791</link>
      <description>arXiv:2508.16791v1 Announce Type: new 
Abstract: We develop a novel optimistic gradient-type algorithmic framework, combining both Nesterov's acceleration and variance-reduction techniques, to solve a class of generalized equations involving possibly nonmonotone operators in data-driven applications. Our framework covers a wide class of stochastic variance-reduced schemes, including mini-batching, and control variate unbiased and biased estimators. We establish that our method achieves $\mathcal{O}(1/k^2)$ convergence rates in expectation on the squared norm of residual under the Lipschitz continuity and a ``co-hypomonotonicity-type'' assumptions, improving upon non-accelerated counterparts by a factor of $1/k$. We also prove faster $o(1/k^2)$ convergence rates, both in expectation and almost surely. In addition, we show that the sequence of iterates of our method almost surely converges to a solution of the underlying problem. We demonstrate the applicability of our method using general error bound criteria, covering mini-batch stochastic estimators as well as three well-known control variate estimators: loopless SVRG, SAGA, and loopless SARAH, for which the last three variants attain significantly better oracle complexity compared to existing methods. We validate our framework and theoretical results through two numerical examples. The preliminary results illustrate promising performance of our accelerated method over its non-accelerated counterparts.</description>
      <guid isPermaLink="false">oai:arXiv.org:2508.16791v1</guid>
      <category>math.OC</category>
      <category>stat.ML</category>
      <pubDate>Tue, 26 Aug 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Quoc Tran-Dinh, Nghia Nguyen-Trung</dc:creator>
    </item>
    <item>
      <title>Stabilization of Parabolic Time-Varying PDEs using Certified Reduced-Order Receding Horizon Control</title>
      <link>https://arxiv.org/abs/2508.16801</link>
      <description>arXiv:2508.16801v1 Announce Type: new 
Abstract: We address the stabilization of linear, time-varying parabolic PDEs using finite-dimensional receding horizon controls (RHCs) derived from reduced-order models (ROMs). We first prove exponential stability and suboptimality of the continuous-time full-order model (FOM) RHC scheme in Hilbert spaces. A Galerkin model reduction is then introduced, along with a rigorous a posteriori error analysis for the associated finite-horizon optimal control problems. This results in a ROM-based RHC algorithm that adaptively constructs reduced-order controls, ensuring exponential stability of the FOM closed-loop state and providing computable performance bounds with respect to the infinite-horizon FOM control problem. Numerical experiments with a non-smooth cost functional involving the squared l1-norm confirm the methods effectiveness, even for exponentially unstable systems.</description>
      <guid isPermaLink="false">oai:arXiv.org:2508.16801v1</guid>
      <category>math.OC</category>
      <category>cs.NA</category>
      <category>math.NA</category>
      <pubDate>Tue, 26 Aug 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Behzad Azmi, Michael Kartmann, Stefan Volkwein</dc:creator>
    </item>
    <item>
      <title>Accelerating a Linear Programming Algorithm on AMD GPUs</title>
      <link>https://arxiv.org/abs/2508.16806</link>
      <description>arXiv:2508.16806v1 Announce Type: new 
Abstract: Linear Programming (LP) is a foundational optimization technique with widespread applications in finance, energy trading, and supply chain logistics. However, traditional Central Processing Unit (CPU)-based LP solvers often struggle to meet the latency and scalability demands of dynamic, high-dimensional industrial environments, creating a significant computational challenge. This project addresses these limitations by accelerating linear programming on AMD Graphics Processing Units (GPUs), leveraging the ROCm open-source platform and PyTorch. The core of this work is the development of a robust, high-performance, open-source implementation of the Primal-Dual Hybrid Gradient (PDHG) algorithm, engineered specifically for general LP problems on AMD hardware. Performance is evaluated against standard LP test sets and established CPU-based solvers, with a particular focus on challenging real- world instances including the Security-Constrained Economic Dispatch (SCED) to guide hyperparameter tuning. Our results show a significant improvement, with up to a 36x speedup on GPU over CPU for large-scale problems, highlighting the advantages of GPU acceleration in solving complex optimization tasks.</description>
      <guid isPermaLink="false">oai:arXiv.org:2508.16806v1</guid>
      <category>math.OC</category>
      <pubDate>Tue, 26 Aug 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Xiyan Hu, Titus Parker, Connor Phillips, Yifa Yu</dc:creator>
    </item>
    <item>
      <title>Predictability Enables Parallelization of Nonlinear State Space Models</title>
      <link>https://arxiv.org/abs/2508.16817</link>
      <description>arXiv:2508.16817v1 Announce Type: new 
Abstract: The rise of parallel computing hardware has made it increasingly important to understand which nonlinear state space models can be efficiently parallelized. Recent advances like DEER (arXiv:2309.12252) or DeepPCR (arXiv:2309.16318) have shown that evaluating a state space model can be recast as solving a parallelizable optimization problem, and sometimes this approach can yield dramatic speed-ups in evaluation time. However, the factors that govern the difficulty of these optimization problems remain unclear, limiting the larger adoption of the technique. In this work, we establish a precise relationship between the dynamics of a nonlinear system and the conditioning of its corresponding optimization formulation. We show that the predictability of a system, defined as the degree to which small perturbations in state influence future behavior, impacts the number of optimization steps required for evaluation. In predictable systems, the state trajectory can be computed in $O((\log T)^2)$ time, where $T$ is the sequence length, a major improvement over the conventional sequential approach. In contrast, chaotic or unpredictable systems exhibit poor conditioning, with the consequence that parallel evaluation converges too slowly to be useful. Importantly, our theoretical analysis demonstrates that for predictable systems, the optimization problem is always well-conditioned, whereas for unpredictable systems, the conditioning degrades exponentially as a function of the sequence length. We validate our claims through extensive experiments, providing practical guidance on when nonlinear dynamical systems can be efficiently parallelized, and highlighting predictability as a key design principle for parallelizable models.</description>
      <guid isPermaLink="false">oai:arXiv.org:2508.16817v1</guid>
      <category>math.OC</category>
      <category>cs.LG</category>
      <category>cs.SY</category>
      <category>eess.SY</category>
      <category>math.DS</category>
      <category>stat.ML</category>
      <pubDate>Tue, 26 Aug 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Xavier Gonzalez, Leo Kozachkov, David M. Zoltowski, Kenneth L. Clarkson, Scott W. Linderman</dc:creator>
    </item>
    <item>
      <title>On the Shape of the Symmetric Solution Set of a Linear Complementarity Problem with Interval Data</title>
      <link>https://arxiv.org/abs/2508.16824</link>
      <description>arXiv:2508.16824v1 Announce Type: new 
Abstract: In this paper we give some two-dimensional and some three-dimensional examples for the shape of the symmetric solution set of a linear complementarity problem where the given data are not explicitly known but can only be enclosed in intervals.</description>
      <guid isPermaLink="false">oai:arXiv.org:2508.16824v1</guid>
      <category>math.OC</category>
      <category>cs.NA</category>
      <category>math.NA</category>
      <pubDate>Tue, 26 Aug 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Uwe Sch\"afer</dc:creator>
    </item>
    <item>
      <title>Shape optimization problems with random coefficients via the penalty method</title>
      <link>https://arxiv.org/abs/2508.16961</link>
      <description>arXiv:2508.16961v1 Announce Type: new 
Abstract: For shape optimization problems, governed by elliptic equations with Dirichlet boundary condition and random coefficients, we utilize a penalization technique to get the approximate problem. We consider that uncertainties exists in the diffusion coefficients and minimize objective functions in mean value form. Finite element method, Monte Carlo method and accelerated version of the gradient descent method are applied to solve the corresponding discretized problem. The convergence analysis and numerical results are included.</description>
      <guid isPermaLink="false">oai:arXiv.org:2508.16961v1</guid>
      <category>math.OC</category>
      <pubDate>Tue, 26 Aug 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Xiaowei Pang</dc:creator>
    </item>
    <item>
      <title>HV Metric For Time-Domain Full Waveform Inversion</title>
      <link>https://arxiv.org/abs/2508.17122</link>
      <description>arXiv:2508.17122v1 Announce Type: new 
Abstract: Full-waveform inversion (FWI) is a powerful technique for reconstructing high-resolution material parameters from seismic or ultrasound data. The conventional least-squares (\(L^{2}\)) misfit suffers from pronounced non-convexity that leads to \emph{cycle skipping}. Optimal-transport misfits, such as the Wasserstein distance, alleviate this issue; however, their use requires artificially converting the wavefields into probability measures, a preprocessing step that can modify critical amplitude and phase information of time-dependent wave data. We propose the \emph{HV metric}, a transport-based distance that acts naturally on signed signals, as an alternative metric for the \(L^{2}\) and Wasserstein objectives in time-domain FWI. After reviewing the metric's definition and its relationship to optimal transport, we derive closed-form expressions for the Fr\'echet derivative and Hessian of the map \(f \mapsto d_{\text{HV}}^2(f,g)\), enabling efficient adjoint-state implementations. A spectral analysis of the Hessian shows that, by tuning the hyperparameters \((\kappa,\lambda,\epsilon)\), the HV misfit seamlessly interpolates between \(L^{2}\), \(H^{-1}\), and \(H^{-2}\) norms, offering a tunable trade-off between the local point-wise matching and the global transport-based matching. Synthetic experiments on the Marmousi and BP benchmark models demonstrate that the HV metric-based objective function yields faster convergence and superior tolerance to poor initial models compared to both \(L^{2}\) and Wasserstein misfits. These results demonstrate the HV metric as a robust, geometry-preserving alternative for large-scale waveform inversion.</description>
      <guid isPermaLink="false">oai:arXiv.org:2508.17122v1</guid>
      <category>math.OC</category>
      <category>cs.LG</category>
      <pubDate>Tue, 26 Aug 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Matej Neumann, Yunan Yang</dc:creator>
    </item>
    <item>
      <title>Optimal Feedback Control in Social Networks in a McKean-Vlasov-Friedkin-Johnsen System</title>
      <link>https://arxiv.org/abs/2508.17138</link>
      <description>arXiv:2508.17138v1 Announce Type: new 
Abstract: This paper presents a comprehensive analytical formulation for deriving a closed-form optimal strategy for agents operating within a social network, modeled through a McKean-Vlasov stochastic differential equation (SDE). Each agent aims to minimize a personal dynamic cost functional that accounts for deviations from the collective opinions of others, their own past beliefs, and is influenced by randomness and inherent opinion rigidity, often described as stubbornness. To tackle this, we develop a novel methodology rooted in a Feynman-type path integral framework, incorporating a specially designed integrating factor to obtain explicit feedback control laws. This approach provides a tractable and insightful solution to the control problem in a setting shaped by both memory and noise. As part of our analysis, we adopt a modified form of the Friedkin-Johnsen opinion dynamics model to more accurately capture the influence of prior beliefs and social interactions, enabling the explicit derivation of the optimal strategy. Comparative simulations further illustrate the effectiveness and adaptability of our method across different network structures, highlighting its potential relevance to understanding opinion evolution and influence strategies in complex social systems.</description>
      <guid isPermaLink="false">oai:arXiv.org:2508.17138v1</guid>
      <category>math.OC</category>
      <pubDate>Tue, 26 Aug 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Paramahansa Pramanik</dc:creator>
    </item>
    <item>
      <title>Collaborative-Online-Learning-Enabled Distributionally Robust Motion Control for Multi-Robot Systems</title>
      <link>https://arxiv.org/abs/2508.17173</link>
      <description>arXiv:2508.17173v1 Announce Type: new 
Abstract: This paper develops a novel COllaborative-Online-Learning (COOL)-enabled motion control framework for multi-robot systems to avoid collision amid randomly moving obstacles whose motion distributions are partially observable through decentralized data streams. To address the notable challenge of data acquisition due to occlusion, a COOL approach based on the Dirichlet process mixture model is proposed to efficiently extract motion distribution information by exchanging among robots selected learning structures. By leveraging the fine-grained local-moment information learned through COOL, a data-stream-driven ambiguity set for obstacle motion is constructed. We then introduce a novel ambiguity set propagation method, which theoretically admits the derivation of the ambiguity sets for obstacle positions over the entire prediction horizon by utilizing obstacle current positions and the ambiguity set for obstacle motion. Additionally, we develop a compression scheme with its safety guarantee to automatically adjust the complexity and granularity of the ambiguity set by aggregating basic ambiguity sets that are close in a measure space, thereby striking an attractive trade-off between control performance and computation time. Then the probabilistic collision-free trajectories are generated through distributionally robust optimization problems. The distributionally robust obstacle avoidance constraints based on the compressed ambiguity set are equivalently reformulated by deriving separating hyperplanes through tractable semi-definite programming. Finally, we establish the probabilistic collision avoidance guarantee and the long-term tracking performance guarantee for the proposed framework. The numerical simulations are used to demonstrate the efficacy and superiority of the proposed approach compared with state-of-the-art methods.</description>
      <guid isPermaLink="false">oai:arXiv.org:2508.17173v1</guid>
      <category>math.OC</category>
      <category>cs.RO</category>
      <category>cs.SY</category>
      <category>eess.SY</category>
      <pubDate>Tue, 26 Aug 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Chao Ning, Han Wang, Longyan Li, Yang Shi</dc:creator>
    </item>
    <item>
      <title>Linear Dynamics meets Linear MDPs: Closed-Form Optimal Policies via Reinforcement Learning</title>
      <link>https://arxiv.org/abs/2508.17185</link>
      <description>arXiv:2508.17185v1 Announce Type: new 
Abstract: Many applications -- including power systems, robotics, and economics -- involve a dynamical system interacting with a stochastic and hard-to-model environment. We adopt a reinforcement learning approach to control such systems. Specifically, we consider a deterministic, discrete-time, linear, time-invariant dynamical system coupled with a feature-based linear Markov process with an unknown transition kernel. The objective is to learn a control policy that optimizes a quadratic cost over the system state, the Markov process, and the control input. Leveraging both components of the system, we derive an explicit parametric form for the optimal state-action value function and the corresponding optimal policy. Our model is distinct in combining aspects of both classical Linear Quadratic Regulator (LQR) and linear Markov decision process (MDP) frameworks. This combination retains the implementation simplicity of LQR, while allowing for sophisticated stochastic modeling afforded by linear MDPs, without estimating the transition probabilities, thereby enabling direct policy improvement. We use tools from control theory to provide theoretical guarantees on the stability of the system under the learned policy and provide a sample complexity analysis for its convergence to the optimal policy. We illustrate our results via a numerical example that demonstrates the effectiveness of our approach in learning the optimal control policy under partially known stochastic dynamics.</description>
      <guid isPermaLink="false">oai:arXiv.org:2508.17185v1</guid>
      <category>math.OC</category>
      <category>cs.SY</category>
      <category>eess.SY</category>
      <pubDate>Tue, 26 Aug 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Abed AlRahman Al Makdah, Oliver Kosut, Lalitha Sankar, Shaofeng Zou</dc:creator>
    </item>
    <item>
      <title>Maximum principle for discrete-time robust stochastic optimal control problem</title>
      <link>https://arxiv.org/abs/2508.17249</link>
      <description>arXiv:2508.17249v1 Announce Type: new 
Abstract: This paper firstly presents the necessary and sufficient conditions for a kind of discrete-time robust stochastic optimal control problem with convex control domains. As it is an "inf sup problem", the classical variational method is invalid. We obtain the variational inequality with a common reference probability by systematically using weak convergence approach and the minimax theorem. Moreover, a discrete-time robust investment problem is also studied where the explicit optimal control is given.</description>
      <guid isPermaLink="false">oai:arXiv.org:2508.17249v1</guid>
      <category>math.OC</category>
      <category>math.PR</category>
      <pubDate>Tue, 26 Aug 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Wei He</dc:creator>
    </item>
    <item>
      <title>Policy Optimization in the Linear Quadratic Gaussian Problem: A Frequency Domain Perspective</title>
      <link>https://arxiv.org/abs/2508.17252</link>
      <description>arXiv:2508.17252v1 Announce Type: new 
Abstract: The Linear Quadratic Gaussian (LQG) problem is a classic and widely studied model in optimal control, providing a fundamental framework for designing controllers for linear systems subject to process and observation noises. In recent years, researchers have increasingly focused on directly parameterizing dynamic controllers and optimizing the LQG cost over the resulting parameterized set. However, this parameterization typically gives rise to a highly non-convex optimization landscape for the resulting parameterized LQG problem. To our knowledge, there is currently no general method for certifying the global optimality of candidate controller parameters in this setting. In this work, we address these gaps with the following contributions. First, we derive a necessary and sufficient condition for the global optimality of stationary points in a parameterized LQG problems. This condition reduces the verification of optimality to a test of the controllability and observability for a novel, specially constructed transfer function, yielding a precise and computationally tractable certificate. Furthermore, our condition provides a rigorous explanation for why traditional parameterizations can lead to suboptimal stationary points. Second, we elevate the controller parameter space from conventional finite-dimensional settings to the infinite-dimensional $\mathcal{RH}_\infty$ space and develop a gradient-based algorithm in this setting, for which we provide a theoretical analysis establishing global convergence. Finally, representative numerical experiments validate the theoretical findings and demonstrate the practical viability of the proposed approach. Additionally, the appendix section explores a data-driven extension to the model-free setting, where we outline a parameter estimation scheme and demonstrate its practical viability through numerical simulation.</description>
      <guid isPermaLink="false">oai:arXiv.org:2508.17252v1</guid>
      <category>math.OC</category>
      <pubDate>Tue, 26 Aug 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Haoran Li, Xun Li, Yuan-Hua Ni, Xuebo Zhang</dc:creator>
    </item>
    <item>
      <title>Polyak Stepsize: Estimating Optimal Functional Values Without Parameters or Prior Knowledge</title>
      <link>https://arxiv.org/abs/2508.17288</link>
      <description>arXiv:2508.17288v1 Announce Type: new 
Abstract: The Polyak stepsize for Gradient Descent is known for its fast convergence but requires prior knowledge of the optimal functional value, which is often unavailable in practice. In this paper, we propose a parameter-free approach that estimates this unknown value during the algorithm's execution, enabling a parameter-free stepsize schedule. Our method maintains two sequences of iterates: one with a higher functional value is updated using the Polyak stepsize, and the other one with a lower functional value is used as an estimate of the optimal functional value. We provide a theoretical analysis of the approach and validate its performance through numerical experiments. The results demonstrate that our method achieves competitive performance without relying on prior function-dependent information.</description>
      <guid isPermaLink="false">oai:arXiv.org:2508.17288v1</guid>
      <category>math.OC</category>
      <pubDate>Tue, 26 Aug 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Farshed Abdukhakimov, Cuong Anh Pham, Samuel Horv\'ath, Martin Tak\'a\v{c}, Slavom{\i}r Hanzely</dc:creator>
    </item>
    <item>
      <title>First and Second Order Optimal $\mathcal{H}_2$ Model Reduction for Linear Continuous-Time Systems</title>
      <link>https://arxiv.org/abs/2508.17503</link>
      <description>arXiv:2508.17503v1 Announce Type: new 
Abstract: In this paper, we investigate the optimal $\mathcal{H}_2$ model reduction problem for single-input single-output (SISO) continuous-time linear time-invariant (LTI) systems. A semi-definite relaxation (SDR) approach is proposed to determine globally optimal interpolation points, providing an effective way to compute the reduced-order models via Krylov projection-based methods. In contrast to iterative approaches, we use the controllability Gramian and the moment-matching conditions to recast the model reduction problem as a convex optimization by introducing an upper bound $\gamma$ to minimize the $\mathcal{H}_2$ norm of the model reduction error system. We also prove that the relaxation is exact for first order reduced models and demonstrate, through examples, that it is exact for second order reduced models. We compare the performance of our proposed method with other iterative approaches and shift-selection methods on examples. Importantly, our approach also provides a means to verify the global optimality of known locally convergent methods.</description>
      <guid isPermaLink="false">oai:arXiv.org:2508.17503v1</guid>
      <category>math.OC</category>
      <category>cs.SY</category>
      <category>eess.SY</category>
      <pubDate>Tue, 26 Aug 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Wenshan Zhu, Imad Jaimoukha</dc:creator>
    </item>
    <item>
      <title>An experimental approach: The graph of graphs</title>
      <link>https://arxiv.org/abs/2508.17520</link>
      <description>arXiv:2508.17520v1 Announce Type: new 
Abstract: One of the essential issues in decision problems and preference modeling is the number of comparisons and their pattern to ask from the decision maker. We focus on the optimal patterns of pairwise comparisons and the sequence including the most (close to) optimal cases based on the results of a color selection experiment. In the test, six colors (red, green, blue, magenta, turquoise, yellow) were evaluated with pairwise comparisons as well as in a direct manner, on color-calibrated tablets in ISO standardized sensory test booths of a sensory laboratory. All the possible patterns of comparisons resulting in a connected representing graph were evaluated against the complete data based on 301 individual's pairwise comparison matrices (PCMs) using the logarithmic least squares weight calculation technique. It is shown that the empirical results, i.e., the empirical distributions of the elements of PCMs, are quite similar to the former simulated outcomes from the literature. The obtained empirically optimal patterns of comparisons were the best or the second best in the former simulations as well, while the sequence of comparisons that contains the most (close to) optimal patterns is exactly the same. In order to enhance the applicability of the results, besides the presentation of graph of graphs, and the representing graphs of the patterns that describe the proposed sequence of comparisons themselves, the recommendations are also detailed in a table format as well as in a Java application.</description>
      <guid isPermaLink="false">oai:arXiv.org:2508.17520v1</guid>
      <category>math.OC</category>
      <category>cs.AI</category>
      <pubDate>Tue, 26 Aug 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Zsombor Sz\'adoczki, S\'andor Boz\'oki, L\'aszl\'o Sipos, Zs\'ofia Galambosi</dc:creator>
    </item>
    <item>
      <title>Differentiating Through a Quadratic Cone Program</title>
      <link>https://arxiv.org/abs/2508.17522</link>
      <description>arXiv:2508.17522v1 Announce Type: new 
Abstract: Quadratic cone programs are rapidly becoming the standard canonical form for convex optimization problems. In this paper we address the question of differentiating the solution map for such problems, generalizing previous work for linear cone programs. We follow a similar path, using the implicit function theorem applied to the optimality conditions for a homogenous primal-dual embedding. Along with our proof of differentiability, we present methods for efficiently evaluating the derivative operator and its adjoint at a vector. Additionally, we present an open-source implementation of these methods, named \texttt{diffqcp}, that can execute on CPUs and GPUs. GPU-compatibility is already of consequence as it enables convex optimization solvers to be integrated into neural networks with reduced data movement, but we go a step further demonstrating that \texttt{diffqcp}'s performance on GPUs surpasses the performance of its CPU-based counterpart for larger quadratic cone programs.</description>
      <guid isPermaLink="false">oai:arXiv.org:2508.17522v1</guid>
      <category>math.OC</category>
      <pubDate>Tue, 26 Aug 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Quill Healey, Parth Nobel, Stephen Boyd</dc:creator>
    </item>
    <item>
      <title>An efficient algorithm for entropic optimal transport under martingale-type constraints</title>
      <link>https://arxiv.org/abs/2508.17641</link>
      <description>arXiv:2508.17641v1 Announce Type: new 
Abstract: This work introduces novel computational methods for entropic optimal transport (OT) problems under martingale-type conditions. The considered problems include the discrete martingale optimal transport (MOT) problem. Moreover, as the (super-)martingale conditions are equivalent to row-wise (in-)equality constraints on the coupling matrix, our work applies to a prevalent class of OT problems with structural constraints. Inspired by the recent empirical success of Sinkhorn-type algorithms, we propose an entropic formulation for the MOT problem and introduce Sinkhorn-type algorithms with sparse Newton iterations that utilize the (approximate) sparsity of the Hessian matrix of the dual objective. As exact martingale conditions are typically infeasible, we adopt entropic regularization to find an approximate constraint-satisfied solution. We show that, in practice, the proposed algorithms enjoy both super-exponential convergence and robustness with controllable thresholds for total constraint violations.</description>
      <guid isPermaLink="false">oai:arXiv.org:2508.17641v1</guid>
      <category>math.OC</category>
      <category>cs.NA</category>
      <category>math.NA</category>
      <pubDate>Tue, 26 Aug 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Xun Tang, Michael Shavlovsky, Holakou Rahmanian, Tesi Xiao, Lexing Ying</dc:creator>
    </item>
    <item>
      <title>Optimization of centroidal Voronoi tessellations</title>
      <link>https://arxiv.org/abs/2508.17721</link>
      <description>arXiv:2508.17721v1 Announce Type: new 
Abstract: In this paper, we investigate the optimization of Centroidal Voronoi Tessellations (CVT) under geometric constraints. For this purpose, we minimize a linear combination of the standard CVT energy functional with terms involving geometric attributes such as area and perimeter. The derivative of the objective functional with respect to the position of the generators is computed using techniques of shape calculus and sensitivity analysis of minimization diagrams. Several numerical experiments are presented to explore the geometric constraints of cells with identical areas, cells without small edges, and density-based distributions of cells.</description>
      <guid isPermaLink="false">oai:arXiv.org:2508.17721v1</guid>
      <category>math.OC</category>
      <pubDate>Tue, 26 Aug 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Ernesto G. Birgin, Juan S. C. Franco, Antoine Laurain</dc:creator>
    </item>
    <item>
      <title>G-BSDEs with non-Lipschitz coefficients and the corresponding stochastic recursive optimal control problem</title>
      <link>https://arxiv.org/abs/2508.17731</link>
      <description>arXiv:2508.17731v1 Announce Type: new 
Abstract: In this paper, we study the existence and uniqueness of solutions to a class of non-Lipschitz G-BSDEs and the corresponding stochastic recursive optimal control problem. More precisely, we suppose that the generator of G-BSDE is uniformly continuous and monotonic with respect to the first unknown variable. Using the comparison theorem for G-BSDE and the stability of viscosity solutions, we establish the dynamic programming principle and the connection between the value function and the viscosity solution of the associated Hamilton-Jacobi-Bellman equation.We provide an example of continuous time Epstein-Zin utility to demonstrate the application of our study.</description>
      <guid isPermaLink="false">oai:arXiv.org:2508.17731v1</guid>
      <category>math.OC</category>
      <category>math.PR</category>
      <pubDate>Tue, 26 Aug 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Wei He, Qiangjun Tang</dc:creator>
    </item>
    <item>
      <title>Finite-Horizon Partially Observable Semi-Markov Games with Risk Probability Criteria</title>
      <link>https://arxiv.org/abs/2508.17791</link>
      <description>arXiv:2508.17791v1 Announce Type: new 
Abstract: This paper studies partially observable two-person zero-sum semi-Markov games under a probability criterion, in which the system state may not be completely observed. It focuses on the probability that the accumulated rewards of player 1 (i.e., the incurred costs of player 2) fall short of a specified target at the terminal stage, which represents the risk of player 1 and the capacity of player 2. We study the game model via the technology of augmenting state space with the joint conditional distribution of the current unobserved state and the remaining goal. Under a mild condition, we establish a comparison theorem and derive the Shapley equation for the probability criterion. As a consequence, we prove the existence and the uniqueness of the value function and the existence of a Nash equilibrium.</description>
      <guid isPermaLink="false">oai:arXiv.org:2508.17791v1</guid>
      <category>math.OC</category>
      <pubDate>Tue, 26 Aug 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Xin Wen, Li Xia, Zhihui Yu</dc:creator>
    </item>
    <item>
      <title>Forward-Backward Quantization of Scenario Processes in Multi-Stage Stochastic Optimization</title>
      <link>https://arxiv.org/abs/2508.18112</link>
      <description>arXiv:2508.18112v1 Announce Type: new 
Abstract: Multi-stage stochastic optimization lies at the core of decision-making under uncertainty. As the analytical solution is available only in exceptional cases, dynamic optimization aims to efficiently find approximations but often neglects non-Markovian time-interdependencies. Methods on scenario trees can represent such interdependencies but are subject to the curse of dimensionality. To ease this problem, researchers typically approximate the uncertainty by smaller but more accurate trees. In this article, we focus on multi-stage optimal tree quantization methods of time-interdependent stochastic processes, for which we develop novel bounds and demonstrate that the upper bound can be minimized via projected gradient descent incorporating the tree structure as linear constraints. Consequently, we propose an efficient quantization procedure, which improves forward-looking samples using a backward step on the tree.We apply the results to the multi-stage inventory control with time-interdependent demand. For the case with one product, we benchmark the approximation because the problem allows a solution in closed-form. For the multi-dimensional problem, our solution found by optimal discrete approximation demonstrates the importance of holding mitigation inventory in different phases of the product life cycle.</description>
      <guid isPermaLink="false">oai:arXiv.org:2508.18112v1</guid>
      <category>math.OC</category>
      <pubDate>Tue, 26 Aug 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Anna Timonina-Farkas</dc:creator>
    </item>
    <item>
      <title>Sparse Polynomial Regression under Anomalous Data</title>
      <link>https://arxiv.org/abs/2508.18199</link>
      <description>arXiv:2508.18199v1 Announce Type: new 
Abstract: This paper starts with the general form of the polynomial regression model. We reformulate the Sparse Polynomial Regression Model (SPRM) with anomalous data filtering as Mixed-Integer Linear Program (MILP). This MILP is then converted to a non-convex Quadratically Constrained Quadratic Program (QCQP). Through a proposed mapping, the derived QCQP is reformulated as a Fractional Program (FP). We theoretically show that the reformulated FP has better computational properties than the original QCQP. We then suggest a conic-relaxation-based algorithm to solve the proposed FP. A Two-Step Convex Relaxation and Recovery (TS-CRR) algorithm is proposed for sparse polynomial regression with anomalous data filtering. Through a series of comprehensive computational experiments (using two different datasets), we have compared the results of our proposed TS-CRR algorithm with the results from several regression and artificial intelligent models. The numerical results show the promising performance of our proposed TS-CRR algorithm as compared to those studied benchmark models.</description>
      <guid isPermaLink="false">oai:arXiv.org:2508.18199v1</guid>
      <category>math.OC</category>
      <pubDate>Tue, 26 Aug 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Roozbeh Abolpour, Mohammad Reza Hesamzadeh, Maryam Dehghani</dc:creator>
    </item>
    <item>
      <title>Dimension-Decomposed Learning for Quadrotor Geometric Attitude Control with Almost Global Exponential Convergence on SO(3)</title>
      <link>https://arxiv.org/abs/2508.14422</link>
      <description>arXiv:2508.14422v1 Announce Type: cross 
Abstract: This paper introduces a lightweight and interpretable online learning approach called Dimension-Decomposed Learning (DiD-L) for disturbance identification in quadrotor geometric attitude control. As a module instance of DiD-L, we propose the Sliced Adaptive-Neuro Mapping (SANM). Specifically, to address underlying underfitting problems, the high-dimensional mapping for online identification is axially ``sliced" into multiple low-dimensional submappings (slices). In this way, the complex high-dimensional problem is decomposed into a set of simple low-dimensional subtasks addressed by shallow neural networks and adaptive laws. These neural networks and adaptive laws are updated online via Lyapunov-based adaptation without the persistent excitation (PE) condition. To enhance the interpretability of the proposed approach, we prove that the state solution of the rotational error dynamics exponentially converges into an arbitrarily small ball within an almost global attraction domain, despite time-varying disturbances and inertia uncertainties. This result is novel as it demonstrates exponential convergence without requiring pre-training for unseen disturbances and specific knowledge of the model. To our knowledge in the quadrotor control field, DiD-L is the first online learning approach that is lightweight enough to run in real-time at 400 Hz on microcontroller units (MCUs) such as STM32, and has been validated through real-world experiments.</description>
      <guid isPermaLink="false">oai:arXiv.org:2508.14422v1</guid>
      <category>eess.SY</category>
      <category>cs.RO</category>
      <category>cs.SY</category>
      <category>math.OC</category>
      <pubDate>Tue, 26 Aug 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Tianhua Gao, Masashi Izumita, Kohji Tomita, Akiya Kamimura</dc:creator>
    </item>
    <item>
      <title>Quantum-Inspired DRL Approach with LSTM and OU Noise for Cut Order Planning Optimization</title>
      <link>https://arxiv.org/abs/2508.16611</link>
      <description>arXiv:2508.16611v1 Announce Type: cross 
Abstract: Cut order planning (COP) is a critical challenge in the textile industry, directly impacting fabric utilization and production costs. Conventional methods based on static heuristics and catalog-based estimations often struggle to adapt to dynamic production environments, resulting in suboptimal solutions and increased waste. In response, we propose a novel Quantum-Inspired Deep Reinforcement Learning (QI-DRL) framework that integrates Long Short-Term Memory (LSTM) networks with Ornstein-Uhlenbeck noise. This hybrid approach is designed to explicitly address key research questions regarding the benefits of quantum-inspired probabilistic representations, the role of LSTM-based memory in capturing sequential dependencies, and the effectiveness of OU noise in facilitating smooth exploration and faster convergence. Extensive training over 1000 episodes demonstrates robust performance, with an average reward of 0.81 (-+0.03) and a steady decrease in prediction loss to 0.15 (-+0.02). A comparative analysis reveals that the proposed approach achieves fabric cost savings of up to 13% compared to conventional methods. Furthermore, statistical evaluations indicate low variability and stable convergence. Despite the fact that the simulation model makes several simplifying assumptions, these promising results underscore the potential of the scalable and adaptive framework to enhance manufacturing efficiency and pave the way for future innovations in COP optimization.</description>
      <guid isPermaLink="false">oai:arXiv.org:2508.16611v1</guid>
      <category>cs.LG</category>
      <category>math.OC</category>
      <pubDate>Tue, 26 Aug 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Yulison Herry Chrisnanto, Julian Evan Chrisnanto</dc:creator>
    </item>
    <item>
      <title>A predictive modular approach to constraint satisfaction under uncertainty - with application to glycosylation in continuous monoclonal antibody biosimilar production</title>
      <link>https://arxiv.org/abs/2508.16803</link>
      <description>arXiv:2508.16803v1 Announce Type: cross 
Abstract: The paper proposes a modular-based approach to constraint handling in process optimization and control. This is partly motivated by the recent interest in learning-based methods, e.g., within bioproduction, for which constraint handling under uncertainty is a challenge. The proposed constraint handler, called predictive filter, is combined with an adaptive constraint margin and a constraint violation cost monitor to minimize the cost of violating soft constraints due to model uncertainty and disturbances. The module can be combined with any controller and is based on minimally modifying the controller output, in a least squares sense, such that constraints are satisfied within the considered horizon. The proposed method is computationally efficient and suitable for real-time applications. The effectiveness of the method is illustrated through a realistic simulation case study of glycosylation constraint satisfaction in continuous monoclonal antibody biosimilar production using Chinese hamster ovary cells, for which the metabolic network model consists of 23 extracellular metabolites and 126 reactions.</description>
      <guid isPermaLink="false">oai:arXiv.org:2508.16803v1</guid>
      <category>eess.SY</category>
      <category>cs.SY</category>
      <category>math.OC</category>
      <category>q-bio.QM</category>
      <pubDate>Tue, 26 Aug 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Yu Wang, Xiao Chen, Hubert Schwarz, V\'eronique Chotteau, Elling W. Jacobsen</dc:creator>
    </item>
    <item>
      <title>Enhanced shape recovery in advection--diffusion problems via a novel ADMM-based CCBM optimization</title>
      <link>https://arxiv.org/abs/2508.16898</link>
      <description>arXiv:2508.16898v1 Announce Type: cross 
Abstract: This work proposes a novel shape optimization framework for geometric inverse problems governed by the advection-diffusion equation, based on the coupled complex boundary method (CCBM). Building on recent developments [2, 45, 46, 47, 51], we aim to recover the shape of an unknown inclusion via shape optimization driven by a cost functional constructed from the imaginary part of the complex-valued state variable over the entire domain. We rigorously derive the associated shape derivative in variational form and provide explicit expressions for the gradient and second-order information. Optimization is carried out using a Sobolev gradient method within a finite element framework. To address difficulties in reconstructing obstacles with concave boundaries, particularly under measurement noise and the combined effects of advection and diffusion, we introduce a numerical scheme inspired by the Alternating Direction Method of Multipliers (ADMM). In addition to implementing this non-conventional approach, we demonstrate how the adjoint method can be efficiently applied and utilize partial gradients to develop a more efficient CCBM-ADMM scheme. The accuracy and robustness of the proposed computational approach are validated through various numerical experiments.</description>
      <guid isPermaLink="false">oai:arXiv.org:2508.16898v1</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <category>math.OC</category>
      <pubDate>Tue, 26 Aug 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Elmehdi Cherrat, Lekbir Afraites, Julius Fergy Tiongson Rabago</dc:creator>
    </item>
    <item>
      <title>Online Learning for Approximately-Convex Functions with Long-term Adversarial Constraints</title>
      <link>https://arxiv.org/abs/2508.16992</link>
      <description>arXiv:2508.16992v1 Announce Type: cross 
Abstract: We study an online learning problem with long-term budget constraints in the adversarial setting. In this problem, at each round $t$, the learner selects an action from a convex decision set, after which the adversary reveals a cost function $f_t$ and a resource consumption function $g_t$. The cost and consumption functions are assumed to be $\alpha$-approximately convex - a broad class that generalizes convexity and encompasses many common non-convex optimization problems, including DR-submodular maximization, Online Vertex Cover, and Regularized Phase Retrieval. The goal is to design an online algorithm that minimizes cumulative cost over a horizon of length $T$ while approximately satisfying a long-term budget constraint of $B_T$. We propose an efficient first-order online algorithm that guarantees $O(\sqrt{T})$ $\alpha$-regret against the optimal fixed feasible benchmark while consuming at most $O(B_T \log T)+ \tilde{O}(\sqrt{T})$ resources in both full-information and bandit feedback settings. In the bandit feedback setting, our approach yields an efficient solution for the $\texttt{Adversarial Bandits with Knapsacks}$ problem with improved guarantees. We also prove matching lower bounds, demonstrating the tightness of our results. Finally, we characterize the class of $\alpha$-approximately convex functions and show that our results apply to a broad family of problems.</description>
      <guid isPermaLink="false">oai:arXiv.org:2508.16992v1</guid>
      <category>cs.LG</category>
      <category>math.OC</category>
      <pubDate>Tue, 26 Aug 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Dhruv Sarkar, Samrat Mukhopadhyay, Abhishek Sinha</dc:creator>
    </item>
    <item>
      <title>Stochastic Gradient Descent with Strategic Querying</title>
      <link>https://arxiv.org/abs/2508.17144</link>
      <description>arXiv:2508.17144v1 Announce Type: cross 
Abstract: This paper considers a finite-sum optimization problem under first-order queries and investigates the benefits of strategic querying on stochastic gradient-based methods compared to uniform querying strategy. We first introduce Oracle Gradient Querying (OGQ), an idealized algorithm that selects one user's gradient yielding the largest possible expected improvement (EI) at each step. However, OGQ assumes oracle access to the gradients of all users to make such a selection, which is impractical in real-world scenarios. To address this limitation, we propose Strategic Gradient Querying (SGQ), a practical algorithm that has better transient-state performance than SGD while making only one query per iteration. For smooth objective functions satisfying the Polyak-Lojasiewicz condition, we show that under the assumption of EI heterogeneity, OGQ enhances transient-state performance and reduces steady-state variance, while SGQ improves transient-state performance over SGD. Our numerical experiments validate our theoretical findings.</description>
      <guid isPermaLink="false">oai:arXiv.org:2508.17144v1</guid>
      <category>cs.LG</category>
      <category>math.OC</category>
      <pubDate>Tue, 26 Aug 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Nanfei Jiang, Hoi-To Wai, Mahnoosh Alizadeh</dc:creator>
    </item>
    <item>
      <title>One Equation to Rule Them All -- Part I: Direct Data-Driven Cascade Stabilisation</title>
      <link>https://arxiv.org/abs/2508.17248</link>
      <description>arXiv:2508.17248v1 Announce Type: cross 
Abstract: In this article we present a framework for direct data-driven control for general problems involving interconnections of dynamical systems. We first develop a method to determine the solution of a Sylvester equation from data. Such solution is used to describe a subspace that plays a role in a large variety of problems. We then provide an error analysis of the impact that noise has on this solution. This is a crucial contribution because, thanks to the interconnection approach developed throughout the article, we are able to track how the noise propagates at each stage, and thereby provide bounds on the final designs. Among the many potential problems that can be solved with this framework, we focus on three representatives: cascade stabilisation, model order reduction, and output regulation. This manuscript studies the first problem, while the companion Part II addresses the other two. For each of these settings we show how the problems can be recast in our framework. In the context of cascade stabilisation, we consider the 2-cascade problem, the effect of noise through the cascade, as well as N-cascade case, and we demonstrate that our proposed method is data efficient. The proposed designs are illustrated by means of a numerical example.</description>
      <guid isPermaLink="false">oai:arXiv.org:2508.17248v1</guid>
      <category>eess.SY</category>
      <category>cs.SY</category>
      <category>math.OC</category>
      <pubDate>Tue, 26 Aug 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Junyu Mao, Emyr Williams, Thulasi Mylvaganam, Giordano Scarciotti</dc:creator>
    </item>
    <item>
      <title>One Equation to Rule Them All -- Part II: Direct Data-Driven Reduction and Regulation</title>
      <link>https://arxiv.org/abs/2508.17251</link>
      <description>arXiv:2508.17251v1 Announce Type: cross 
Abstract: The Sylvester equation underpins a wide spectrum of control synthesis and systems analysis tools associated with cascade interconnections. In the preceding Part I [1] of this article, it was shown that such an equation can be reformulated using data, enabling the production of a collection of data-driven stabilisation procedures. In this second part of the article, we continue to develop the framework established in Part I to solve two important control-theoretic problems: model order reduction and output regulation. For the model order reduction problem we provide a solution from input-state measurements, from input-output measurements, and we study the effect of the noise. For the output regulation problem, we provide data-driven solutions for the static and dynamic feedback problem. The proposed designs are illustrated by means of examples.</description>
      <guid isPermaLink="false">oai:arXiv.org:2508.17251v1</guid>
      <category>eess.SY</category>
      <category>cs.SY</category>
      <category>math.OC</category>
      <pubDate>Tue, 26 Aug 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Junyu Mao, Emyr Williams, Thulasi Mylvaganam, Giordano Scarciotti</dc:creator>
    </item>
    <item>
      <title>The Statistical Fairness-Accuracy Frontier</title>
      <link>https://arxiv.org/abs/2508.17622</link>
      <description>arXiv:2508.17622v1 Announce Type: cross 
Abstract: Machine learning models must balance accuracy and fairness, but these goals often conflict, particularly when data come from multiple demographic groups. A useful tool for understanding this trade-off is the fairness-accuracy (FA) frontier, which characterizes the set of models that cannot be simultaneously improved in both fairness and accuracy. Prior analyses of the FA frontier provide a full characterization under the assumption of complete knowledge of population distributions -- an unrealistic ideal. We study the FA frontier in the finite-sample regime, showing how it deviates from its population counterpart and quantifying the worst-case gap between them. In particular, we derive minimax-optimal estimators that depend on the designer's knowledge of the covariate distribution. For each estimator, we characterize how finite-sample effects asymmetrically impact each group's risk, and identify optimal sample allocation strategies. Our results transform the FA frontier from a theoretical construct into a practical tool for policymakers and practitioners who must often design algorithms with limited data.</description>
      <guid isPermaLink="false">oai:arXiv.org:2508.17622v1</guid>
      <category>stat.ML</category>
      <category>cs.LG</category>
      <category>econ.TH</category>
      <category>math.OC</category>
      <pubDate>Tue, 26 Aug 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Alireza Fallah, Michael I. Jordan, Annie Ulichney</dc:creator>
    </item>
    <item>
      <title>Teaching LLMs to Think Mathematically: A Critical Study of Decision-Making via Optimization</title>
      <link>https://arxiv.org/abs/2508.18091</link>
      <description>arXiv:2508.18091v1 Announce Type: cross 
Abstract: This paper investigates the capabilities of large language models (LLMs) in formulating and solving decision-making problems using mathematical programming. We first conduct a systematic review and meta-analysis of recent literature to assess how well LLMs understand, structure, and solve optimization problems across domains. The analysis is guided by critical review questions focusing on learning approaches, dataset designs, evaluation metrics, and prompting strategies. Our systematic evidence is complemented by targeted experiments designed to evaluate the performance of state-of-the-art LLMs in automatically generating optimization models for problems in computer networks. Using a newly constructed dataset, we apply three prompting strategies: Act-as-expert, chain-of-thought, and self-consistency, and evaluate the obtained outputs based on optimality gap, token-level F1 score, and compilation accuracy. Results show promising progress in LLMs' ability to parse natural language and represent symbolic formulations, but also reveal key limitations in accuracy, scalability, and interpretability. These empirical gaps motivate several future research directions, including structured datasets, domain-specific fine-tuning, hybrid neuro-symbolic approaches, modular multi-agent architectures, and dynamic retrieval via chain-of-RAGs. This paper contributes a structured roadmap for advancing LLM capabilities in mathematical programming.</description>
      <guid isPermaLink="false">oai:arXiv.org:2508.18091v1</guid>
      <category>cs.AI</category>
      <category>math.OC</category>
      <pubDate>Tue, 26 Aug 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Mohammad J. Abdel-Rahman, Yasmeen Alslman, Dania Refai, Amro Saleh, Malik A. Abu Loha, Mohammad Yahya Hamed</dc:creator>
    </item>
    <item>
      <title>Realizing Reduced and Sparse Biochemical Reaction Networks from Dynamics</title>
      <link>https://arxiv.org/abs/2508.18096</link>
      <description>arXiv:2508.18096v1 Announce Type: cross 
Abstract: We propose a direct optimization framework for learning reduced and sparse chemical reaction networks (CRNs) from time-series trajectory data. In contrast to widely used indirect methods-such as those based on sparse identification of nonlinear dynamics (SINDy)-which infer reaction dynamics by fitting numerically estimated derivatives, our approach fits entire trajectories by solving a dynamically constrained optimization problem. This formulation enables the construction of reduced CRNs that are both low-dimensional and sparse, while preserving key dynamical behaviors of the original system. We develop an accelerated proximal gradient algorithm to efficiently solve the resulting non-convex optimization problem. Through illustrative examples, including a Drosophila circadian oscillator and a glycolytic oscillator, we demonstrate the ability of our method to recover accurate and interpretable reduced-order CRNs. Notably, the direct approach avoids the derivative estimation step and mitigates error accumulation issues inherent in indirect methods, making it a robust alternative for data-driven CRN realizations.</description>
      <guid isPermaLink="false">oai:arXiv.org:2508.18096v1</guid>
      <category>q-bio.MN</category>
      <category>cs.SY</category>
      <category>eess.SY</category>
      <category>math.OC</category>
      <pubDate>Tue, 26 Aug 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Maurice Filo, Mustafa Khammash</dc:creator>
    </item>
    <item>
      <title>Arc Routing Problems with Multiple Trucks and Drones: A Hybrid Genetic Algorithm</title>
      <link>https://arxiv.org/abs/2508.18105</link>
      <description>arXiv:2508.18105v1 Announce Type: cross 
Abstract: Arc-routing problems underpin numerous critical field operations, including power-line inspection, urban police patrolling, and traffic monitoring. In this domain, the Rural Postman Problem (RPP) is a fundamental variant in which a prescribed subset of edges or arcs in a network must be traversed. This paper investigates a generalized form of the RPP, called RPP-mTD, which involves a fleet of multiple trucks, each carrying multiple drones. The trucks act as mobile depots traversing a road network, from which drones are launched to execute simultaneous service, with the objective of minimizing the overall makespan. Given the combinatorial complexity of RPP-mTD, we propose a Hybrid Genetic Algorithm (HGA) that combines population-based exploration with targeted neighborhood searches. Solutions are encoded using a two-layer chromosome that represents: (i) an ordered, directed sequence of required edges, and (ii) their assignment to vehicles. A tailored segment-preserving crossover operator is introduced, along with multiple local search techniques to intensify the optimization. We benchmark the proposed HGA against established single truck-and-drone instances, demonstrating competitive performance. Additionally, we conduct extensive evaluations on new, larger-scale instances to demonstrate scalability. Our findings highlight the operational benefits of closely integrated truck-drone fleets, affirming the HGA's practical effectiveness as a decision-support tool in advanced mixed-fleet logistics.</description>
      <guid isPermaLink="false">oai:arXiv.org:2508.18105v1</guid>
      <category>cs.NE</category>
      <category>math.OC</category>
      <pubDate>Tue, 26 Aug 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Abhay Sobhanan, Hadi Charkhgard, Changhyun Kwon</dc:creator>
    </item>
    <item>
      <title>Provable Mixed-Noise Learning with Flow-Matching</title>
      <link>https://arxiv.org/abs/2508.18122</link>
      <description>arXiv:2508.18122v1 Announce Type: cross 
Abstract: We study Bayesian inverse problems with mixed noise, modeled as a combination of additive and multiplicative Gaussian components. While traditional inference methods often assume fixed or known noise characteristics, real-world applications, particularly in physics and chemistry, frequently involve noise with unknown and heterogeneous structure. Motivated by recent advances in flow-based generative modeling, we propose a novel inference framework based on conditional flow matching embedded within an Expectation-Maximization (EM) algorithm to jointly estimate posterior samplers and noise parameters. To enable high-dimensional inference and improve scalability, we use simulation-free ODE-based flow matching as the generative model in the E-step of the EM algorithm. We prove that, under suitable assumptions, the EM updates converge to the true noise parameters in the population limit of infinite observations. Our numerical results illustrate the effectiveness of combining EM inference with flow matching for mixed-noise Bayesian inverse problems.</description>
      <guid isPermaLink="false">oai:arXiv.org:2508.18122v1</guid>
      <category>cs.LG</category>
      <category>math.OC</category>
      <pubDate>Tue, 26 Aug 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Paul Hagemann, Robert Gruhlke, Bernhard Stankewitz, Claudia Schillings, Gabriele Steidl</dc:creator>
    </item>
    <item>
      <title>AdLoCo: adaptive batching significantly improves communications efficiency and convergence for Large Language Models</title>
      <link>https://arxiv.org/abs/2508.18182</link>
      <description>arXiv:2508.18182v1 Announce Type: cross 
Abstract: Scaling distributed training of Large Language Models (LLMs) requires not only algorithmic advances but also efficient utilization of heterogeneous hardware resources. While existing methods such as DiLoCo have demonstrated promising results, they often fail to fully exploit computational clusters under dynamic workloads. To address this limitation, we propose a three-stage method that combines Multi-Instance Training (MIT), Adaptive Batched DiLoCo, and switch mode mechanism. MIT allows individual nodes to run multiple lightweight training streams with different model instances in parallel and merge them to combine knowledge, increasing throughput and reducing idle time. Adaptive Batched DiLoCo dynamically adjusts local batch sizes to balance computation and communication, substantially lowering synchronization delays. Switch mode further stabilizes training by seamlessly introducing gradient accumulation once adaptive batch sizes grow beyond hardware-friendly limits. Together, these innovations improve both convergence speed and system efficiency. We also provide a theoretical estimate of the number of communications required for the full convergence of a model trained using our method.</description>
      <guid isPermaLink="false">oai:arXiv.org:2508.18182v1</guid>
      <category>cs.LG</category>
      <category>cs.AI</category>
      <category>math.OC</category>
      <pubDate>Tue, 26 Aug 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Nikolay Kutuzov, Makar Baderko, Stepan Kulibaba, Artem Dzhalilov, Daniel Bobrov, Maxim Mashtaler, Alexander Gasnikov</dc:creator>
    </item>
    <item>
      <title>Tractable Stochastic Hybrid Model Predictive Control using Gaussian Processes for Repetitive Tasks in Unseen Environments</title>
      <link>https://arxiv.org/abs/2508.18203</link>
      <description>arXiv:2508.18203v1 Announce Type: cross 
Abstract: Improving the predictive accuracy of a dynamics model is crucial to obtaining good control performance and safety from Model Predictive Controllers (MPC). One approach involves learning unmodelled (residual) dynamics, in addition to nominal models derived from first principles. Varying residual models across an environment manifest as modes of a piecewise residual (PWR) model that requires a) identifying how modes are distributed across the environment and b) solving a computationally intensive Mixed Integer Nonlinear Program (MINLP) problem for control. We develop an iterative mapping algorithm capable of predicting time-varying mode distributions. We then develop and solve two tractable approximations of the MINLP to combine with the predictor in closed-loop to solve the overall control problem. In simulation, we first demonstrate how the approximations improve performance by 4-18% in comparison to the MINLP while achieving significantly lower computation times (upto 250x faster). We then demonstrate how the proposed mapping algorithm incrementally improves controller performance (upto 3x) over multiple iterations of a trajectory tracking control task even when the mode distributions change over time.</description>
      <guid isPermaLink="false">oai:arXiv.org:2508.18203v1</guid>
      <category>eess.SY</category>
      <category>cs.SY</category>
      <category>math.OC</category>
      <pubDate>Tue, 26 Aug 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Leroy D'Souza, Yash Vardhan Pant, Sebastian Fischmeister</dc:creator>
    </item>
    <item>
      <title>A Global Optimization Algorithm for K-Center Clustering of One Billion Samples</title>
      <link>https://arxiv.org/abs/2301.00061</link>
      <description>arXiv:2301.00061v2 Announce Type: replace 
Abstract: This paper presents a practical global optimization algorithm for the K-center clustering problem, which aims to select K samples as the cluster centers to minimize the maximum within-cluster distance. This algorithm is based on a reduced-space branch and bound scheme and guarantees convergence to the global optimum in a finite number of steps by only branching on the regions of centers. To improve efficiency, we have designed a two-stage decomposable lower bound, the solution of which can be derived in a closed form. In addition, we also propose several acceleration techniques to narrow down the region of centers, including bounds tightening, sample reduction, and parallelization. Extensive studies on synthetic and real-world datasets have demonstrated that our algorithm can solve the K-center problems to global optimal within 4 hours for ten million samples in the serial mode and one billion samples in the parallel mode. Moreover, compared with the state-of-the-art heuristic methods, the global optimum obtained by our algorithm can averagely reduce the objective function by 25.8% on all the synthetic and real-world datasets.</description>
      <guid isPermaLink="false">oai:arXiv.org:2301.00061v2</guid>
      <category>math.OC</category>
      <category>cs.LG</category>
      <pubDate>Tue, 26 Aug 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Jiayang Ren, Ningning You, Kaixun Hua, Chaojie Ji, Yankai Cao</dc:creator>
    </item>
    <item>
      <title>Strong Partitioning and a Machine Learning Approximation for Accelerating the Global Optimization of Nonconvex QCQPs</title>
      <link>https://arxiv.org/abs/2301.00306</link>
      <description>arXiv:2301.00306v4 Announce Type: replace 
Abstract: We learn optimal instance-specific heuristics for the global minimization of nonconvex quadratically-constrained quadratic programs (QCQPs). Specifically, we consider partitioning-based convex mixed-integer programming relaxations for nonconvex QCQPs and propose the novel problem of strong partitioning to optimally partition variable domains without sacrificing global optimality. Since solving this max-min strong partitioning problem exactly can be very challenging, we design a local optimization method that leverages generalized gradients of the value function of its inner-minimization problem. However, even solving the strong partitioning problem to local optimality can be time-consuming. To address this, we propose a simple and practical machine learning (ML) approximation for homogeneous families of QCQPs. Motivated by practical applications, we conduct a detailed computational study using the open-source global solver Alpine to evaluate the effectiveness of our ML approximation in accelerating the repeated solution of homogeneous QCQPs with fixed structure. Our study considers randomly generated QCQP families, including instances of the pooling problem, that are benchmarked using state-of-the-art global optimization software. Numerical experiments demonstrate that our ML approximation of strong partitioning reduces Alpine's solution time by a factor of 2 to 4.5 on average, with maximum reduction factors ranging from 10 to 200 across these QCQP families.</description>
      <guid isPermaLink="false">oai:arXiv.org:2301.00306v4</guid>
      <category>math.OC</category>
      <pubDate>Tue, 26 Aug 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Rohit Kannan, Harsha Nagarajan, Deepjyoti Deka</dc:creator>
    </item>
    <item>
      <title>Non-Euclidean Monotone Operator Theory and Applications</title>
      <link>https://arxiv.org/abs/2303.11273</link>
      <description>arXiv:2303.11273v3 Announce Type: replace 
Abstract: While monotone operator theory is often studied on Hilbert spaces, many interesting problems in machine learning and optimization arise naturally in finite-dimensional vector spaces endowed with non-Euclidean norms, such as diagonally-weighted $\ell_{1}$ or $\ell_{\infty}$ norms. This paper provides a natural generalization of monotone operator theory to finite-dimensional non-Euclidean spaces. The key tools are weak pairings and logarithmic norms. We show that the resolvent and reflected resolvent operators of non-Euclidean monotone mappings exhibit similar properties to their counterparts in Hilbert spaces. Furthermore, classical iterative methods and splitting methods for finding zeros of monotone operators are shown to converge in the non-Euclidean case. We apply our theory to equilibrium computation and Lipschitz constant estimation of recurrent neural networks, obtaining novel iterations and tighter upper bounds via forward-backward splitting.</description>
      <guid isPermaLink="false">oai:arXiv.org:2303.11273v3</guid>
      <category>math.OC</category>
      <pubDate>Tue, 26 Aug 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Alexander Davydov, Saber Jafarpour, Anton V. Proskurnikov, Francesco Bullo</dc:creator>
    </item>
    <item>
      <title>Exact continuous relaxations of l0-regularized criteria with non-quadratic data terms</title>
      <link>https://arxiv.org/abs/2402.06483</link>
      <description>arXiv:2402.06483v3 Announce Type: replace 
Abstract: We propose a new class of exact continuous relaxations of l0-regularized criteria involving non-quadratic data terms such as the Kullback-Leibler divergence and the logistic regression, possibly combined with an l2 regularization. We first prove the existence of global minimizers for such problems and characterize their local minimizers.Then, we propose the l0 Bregman Relaxation (B-rex), a continuous approximation of the l0 pseudo-norm defined in terms of suitable Bregman distances, which leads to an exact continuous relaxations of the original l0-regularized problem in the sense that it does not alter its set of global minimizers and reduces the non-convexity by eliminating certain local minimizers. Both features make the relaxed problem more amenable to be solved by standard non-convex optimization algorithms. In this spirit, we consider the proximal gradient algorithm and provide explicit computation of proximal points for the B-rex penalty in several cases. Finally, we report a set of numerical results illustrating the geometrical behavior of the proposed B-rex penalty for different choices of the underlying Bregman distance, its relation with convex envelopes, as well as its exact relaxation properties in 1D/2D and higher dimensions.</description>
      <guid isPermaLink="false">oai:arXiv.org:2402.06483v3</guid>
      <category>math.OC</category>
      <pubDate>Tue, 26 Aug 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>M'hamed Essafri, Luca Calatroni, Emmanuel Soubies</dc:creator>
    </item>
    <item>
      <title>Optimality of Symmetric Independent Policies under Decentralized Mean-Field Information Sharing for Stochastic Teams and Equivalence with McKean-Vlasov Control of a Representative Agent</title>
      <link>https://arxiv.org/abs/2404.04957</link>
      <description>arXiv:2404.04957v3 Announce Type: replace 
Abstract: We study a class of stochastic exchangeable teams with a finite number of decision makers (DMs) as well as their mean-field limits with infinitely many DMs. In the finite population regime, we study exchangeable teams under the centralized information structure. The paper makes the following main contributions: i) For finite population exchangeable teams, we establish the existence of an optimal policy that is exchangeable (permutation invariant) and Markovian; ii) As our main result in the paper, we show that a sequence of exchangeable optimal policies for finite population settings (which satisfies a measure valued MDP formulation due to B{\"a}uerle) converges to a decentralized symmetric (identical) and conditionally independent (given the mean-field) policy for the infinite population problem, which is then globally optimal under both the centralized information structure as well as the mean-field sharing information structure. (iii) This result establishes existence of a symmetric, independent, decentralized optimal randomized policy for the infinite population problem and proves the optimality of the limiting measure-valued MDP for the representative DM. Our paper thus establishes the relation between the controlled McKean-Vlasov dynamics and the optimal infinite population decentralized stochastic control problem (without an apriori restriction of symmetry in policies of individual agents), for the first time, to our knowledge (beyond several special cases). We also establish near optimality of a numerical method for solving this problem. iv) Finally, we show that symmetric, independent, decentralized optimal randomized policies are approximately optimal for the corresponding finite-population team with a large number of DMs under the centralized information structure.</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.04957v3</guid>
      <category>math.OC</category>
      <pubDate>Tue, 26 Aug 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Sina Sanjari, Naci Saldi, Serdar Y\"uksel</dc:creator>
    </item>
    <item>
      <title>An interacting particle consensus method for constrained global optimization</title>
      <link>https://arxiv.org/abs/2405.00891</link>
      <description>arXiv:2405.00891v5 Announce Type: replace 
Abstract: This paper presents a particle-based optimization method designed for addressing minimization problems with equality constraints, particularly in cases where the loss function exhibits non-differentiability or non-convexity. The proposed method combines components from consensus-based optimization algorithm with a newly introduced forcing term directed at the constraint set. A rigorous mean-field limit of the particle system is derived, and the convergence of the mean-field limit to the constrained minimizer is established. Additionally, we introduce a stable discretized algorithm and conduct various numerical experiments to demonstrate the performance of the proposed method.</description>
      <guid isPermaLink="false">oai:arXiv.org:2405.00891v5</guid>
      <category>math.OC</category>
      <category>cs.NA</category>
      <category>math.AP</category>
      <category>math.NA</category>
      <pubDate>Tue, 26 Aug 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Jos\'e A. Carrillo, Shi Jin, Haoyu Zhang, Yuhua Zhu</dc:creator>
    </item>
    <item>
      <title>Co-Optimization of EV Charging Control and Incentivization for Enhanced Power System Stability</title>
      <link>https://arxiv.org/abs/2405.00947</link>
      <description>arXiv:2405.00947v2 Announce Type: replace 
Abstract: We study how high charging rate demands from electric vehicles (EVs) in a power distribution grid may collectively cause poor dynamic performance, and propose a price incentivization strategy to steer customers to settle for lesser charging rate demands so that such performance degradation can be avoided. We pose the problem as a joint optimization and optimal control formulation. The optimization determines the optimal charging setpoints for EVs to minimize the $\mathcal{H}_2$-norm of the transfer function of the grid model, while the optimal control simultaneously develops a linear quadratic regulator (LQR) based state-feedback control signal for the battery currents of those EVs to jointly improve the small-signal dynamic performance of the system states. A subsequent algorithm is developed to determine how much customers may be willing to sacrifice their intended charging rate demands in return for financial incentives. Results are derived for both unidirectional and bidirectional charging, and validated using numerical simulations of multiple EV charging stations (EVCSs) in the IEEE 33-bus power distribution model.</description>
      <guid isPermaLink="false">oai:arXiv.org:2405.00947v2</guid>
      <category>math.OC</category>
      <category>cs.SY</category>
      <category>eess.SY</category>
      <pubDate>Tue, 26 Aug 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Amit Kumer Podder, Tomonori Sadamoto, Aranya Chakrabortty</dc:creator>
    </item>
    <item>
      <title>A Novel Privacy Enhancement Scheme with Dynamic Quantization for Federated Learning</title>
      <link>https://arxiv.org/abs/2405.16058</link>
      <description>arXiv:2405.16058v5 Announce Type: replace 
Abstract: Federated learning (FL) has been widely regarded as a promising paradigm for privacy preservation of raw data in machine learning. Although, the data privacy in FL is locally protected to some extent, it is still a desideratum to enhance privacy and alleviate communication overhead caused by repetitively transmitting model parameters. Typically, these challenges are addressed separately, or jointly via a unified scheme that consists of noise-injected privacy mechanism and communication compression, which may lead to model corruption due to the introduced composite noise. In this work, we propose a novel model-splitting privacy-preserving FL (MSP-FL) scheme to achieve private FL with precise accuracy guarantee. Based upon MSP-FL, we further propose a model-splitting privacy-preserving FL with dynamic quantization (MSPDQ-FL) to mitigate the communication overhead, which incorporates a shrinking quantization interval to reduce the quantization error. We provide privacy and convergence analysis for both MSP-FL and MSPDQ-FL under non-i.i.d. dataset, partial clients participation and finite quantization level. Numerical results are presented to validate the superiority of the proposed schemes.</description>
      <guid isPermaLink="false">oai:arXiv.org:2405.16058v5</guid>
      <category>math.OC</category>
      <pubDate>Tue, 26 Aug 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Yifan Wang, Xianghui Cao, Shi Jin, Mo-Yuen Chow</dc:creator>
    </item>
    <item>
      <title>Epi-Consistent Approximation of Stochastic Dynamic Programs</title>
      <link>https://arxiv.org/abs/2501.19028</link>
      <description>arXiv:2501.19028v2 Announce Type: replace 
Abstract: We study the consistency of stochastic dynamic programs under converging probability distributions and other approximations. Utilizing results on the epi-convergence of expectation functions with varying measures and integrands, and the Attouch--Wets distance, we show that appropriate equi-semicontinuity assumptions assure epi-consistency. A number of examples illustrate the approach. In particular, we permit both unbounded and simultaneously approximated stage-cost functions, and treat an example with approximated constraints.</description>
      <guid isPermaLink="false">oai:arXiv.org:2501.19028v2</guid>
      <category>math.OC</category>
      <pubDate>Tue, 26 Aug 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Dominic S. T. Keehan, Johannes O. Royset</dc:creator>
    </item>
    <item>
      <title>Separable Approximations of Optimal Value Functions and Their Representation by Neural Networks</title>
      <link>https://arxiv.org/abs/2502.08559</link>
      <description>arXiv:2502.08559v2 Announce Type: replace 
Abstract: The use of separable approximations is proposed to mitigate the curse of dimensionality related to the approximation of high-dimensional value functions in optimal control. The separable approximation exploits intrinsic decaying sensitivity properties of the system, where the influence of a state variable on another diminishes as their spatial, temporal, or graph-based distance grows. This property allows the efficient representation of global functions as a sum of localized contributions. A theoretical framework for constructing separable approximations in the context of optimal control is proposed by leveraging decaying sensitivity in both discrete and continuous time. Results extend prior work on decay properties of solutions to Lyapunov and Riccati equations, offering new insights into polynomial and exponential decay regimes. Connections to neural networks are explored, demonstrating how separable structures enable scalable representations of high-dimensional value functions while preserving computational efficiency.</description>
      <guid isPermaLink="false">oai:arXiv.org:2502.08559v2</guid>
      <category>math.OC</category>
      <pubDate>Tue, 26 Aug 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Mario Sperl, Luca Saluzzi, Dante Kalise, Lars Gr\"une</dc:creator>
    </item>
    <item>
      <title>Optimistic Online Learning in Symmetric Cone Games</title>
      <link>https://arxiv.org/abs/2504.03592</link>
      <description>arXiv:2504.03592v2 Announce Type: replace 
Abstract: We introduce symmetric cone games (SCGs), a broad class of multi-player games where each player's strategy lies in a generalized simplex (the trace-one slice of a symmetric cone). This framework unifies a wide spectrum of settings, including normal-form games (simplex strategies), quantum games (density matrices), and continuous games with ball-constrained strategies. It also captures several structured machine learning and optimization problems, such as distance metric learning and Fermat-Weber facility location, as two-player zero-sum SCGs. To compute approximate Nash equilibria in two-player zero-sum SCGs, we propose a single online learning algorithm: Optimistic Symmetric Cone Multiplicative Weights Updates (OSCMWU). Unlike prior methods tailored to specific geometries, OSCMWU provides closed-form, projection-free updates over any symmetric cone and achieves an optimal $\tilde{\mathcal{O}}(1/\epsilon)$ iteration complexity for computing $\epsilon$-saddle points. Our analysis builds on the Optimistic Follow-the-Regularized-Leader framework and hinges on a key technical contribution: We prove that the symmetric cone negative entropy is strongly convex with respect to the trace-one norm. This result extends known results for the simplex and spectraplex to all symmetric cones, and may be of independent interest.</description>
      <guid isPermaLink="false">oai:arXiv.org:2504.03592v2</guid>
      <category>math.OC</category>
      <category>cs.GT</category>
      <category>cs.LG</category>
      <pubDate>Tue, 26 Aug 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Anas Barakat, Wayne Lin, John Lazarsfeld, Antonios Varvitsiotis</dc:creator>
    </item>
    <item>
      <title>The Pontryagin Maximum Principle for Training Convolutional Neural Networks</title>
      <link>https://arxiv.org/abs/2504.11647</link>
      <description>arXiv:2504.11647v2 Announce Type: replace 
Abstract: A novel batch sequential quadratic Hamiltonian (bSQH) algorithm for training convolutional neural networks (CNNs) with $L^0$-based regularization is presented. This methodology is based on a discrete-time Pontryagin maximum principle (PMP). It uses forward and backward sweeps together with the layerwise approximate maximization of an augmented Hamiltonian function, where the augmentation parameter is chosen adaptively.
  A technique for determining this augmentation parameter is proposed, and the loss-reduction and convergence properties of the bSQH algorithm are analysed theoretically and validated numerically. Results of numerical experiments in the context of image classification with a sparsity enforcing $L^0$-based regularizer demonstrate the effectiveness of the proposed method in full-batch and mini-batch modes.</description>
      <guid isPermaLink="false">oai:arXiv.org:2504.11647v2</guid>
      <category>math.OC</category>
      <pubDate>Tue, 26 Aug 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Sebastian Hofmann, Alfio Borz\`i</dc:creator>
    </item>
    <item>
      <title>A general approach to distributed operator splitting</title>
      <link>https://arxiv.org/abs/2504.14987</link>
      <description>arXiv:2504.14987v2 Announce Type: replace 
Abstract: Splitting methods have emerged as powerful tools to address complex problems by decomposing them into smaller solvable components. In this work, we develop a general approach of forward-backward splitting methods for solving monotone inclusion problems involving both set-valued and single-valued operators, where the latter may lack cocoercivity. Our proposed approach, based on some coefficient matrices, not only encompasses several important existing algorithms but also extends to new ones, offering greater flexibility for different applications. Moreover, by appropriately selecting the coefficient matrices, the resulting algorithms can be implemented in a distributed and decentralized manner.</description>
      <guid isPermaLink="false">oai:arXiv.org:2504.14987v2</guid>
      <category>math.OC</category>
      <pubDate>Tue, 26 Aug 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Minh N. Dao, Matthew K. Tam, Thang D. Truong</dc:creator>
    </item>
    <item>
      <title>Towards time series aggregation with exact error quantification for optimization of energy systems</title>
      <link>https://arxiv.org/abs/2505.06083</link>
      <description>arXiv:2505.06083v2 Announce Type: replace 
Abstract: Energy system optimization models are becoming increasingly popular for analyzing energy markets, such as the impact of new policies or interactions between energy carriers. One key challenge of these models is the trade-off between modeling accuracy and computational tractability. A recently proposed mathematical framework addresses this challenge by achieving exact time series aggregations merging time periods sharing the same active constraint sets. This aggregation, however, is insufficient when the number of unique active constraints is large. We overcome this issue by aggregating data points from different active constraint sets. While this further reduces model size, it inevitably introduces an error compared to the full model. Yet, we show how this error can be exactly quantified without re-solving the optimization problem, enabling users to trade off computational efficiency and model accuracy proactively. This may be especially useful in energy markets to accommodate varying granularity across short- and long-term time horizons.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.06083v2</guid>
      <category>math.OC</category>
      <pubDate>Tue, 26 Aug 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <arxiv:DOI>10.1109/EEM64765.2025.11050224</arxiv:DOI>
      <dc:creator>Beltr\'an Castro G\'omez, Yannick Werner, Sonja Wogrin</dc:creator>
    </item>
    <item>
      <title>Fast convergence of dynamical systems with implicit Hessian damping and Tikhonov regularization</title>
      <link>https://arxiv.org/abs/2506.19545</link>
      <description>arXiv:2506.19545v3 Announce Type: replace 
Abstract: This paper proposes novel primal-dual dynamical systems for solving linear equality constrained convex optimization. First, we introduce a primal-dual dynamical system with implicit Hessian damping, which can neutralize the transversal oscillations without requiring computation of the Hessian matrix. We establish the fast convergence properties of the proposed dynamical system under suitable conditions. Furthermore, we incorporate a Tikhonov regularization term and prove that the resulting trajectories converge strongly to the minimum norm solution. Numerical experiments are conducted to validate the theoretical findings.</description>
      <guid isPermaLink="false">oai:arXiv.org:2506.19545v3</guid>
      <category>math.OC</category>
      <pubDate>Tue, 26 Aug 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Hong-lu Li, Xin He, Yi-bin Xiao</dc:creator>
    </item>
    <item>
      <title>On the Out-of-Sample Performance of Stochastic Dynamic Programming and Model Predictive Control</title>
      <link>https://arxiv.org/abs/2506.23097</link>
      <description>arXiv:2506.23097v2 Announce Type: replace 
Abstract: Sample average approximation--based stochastic dynamic programming (SDP) and model predictive control (MPC) are two different methods for approaching multistage stochastic optimization. In this paper we investigate the conditions under which SDP may be outperformed by MPC. We show that, depending on the presence of concavity or convexity, MPC can be interpreted as solving a mean-constrained distributionally ambiguous version of the problem that is solved by SDP. This furnishes performance guarantees when the true mean is known and provides intuition for why MPC performs better in some applications and worse in others. We then study a multistage stochastic optimization problem that is representative of the type for which MPC may be the better choice. We find that this can indeed be the case when the probability distribution of the underlying random variable is skewed or has enough weight in the right-hand tail.</description>
      <guid isPermaLink="false">oai:arXiv.org:2506.23097v2</guid>
      <category>math.OC</category>
      <pubDate>Tue, 26 Aug 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Dominic S. T. Keehan, Andrew B. Philpott, Edward J. Anderson</dc:creator>
    </item>
    <item>
      <title>On the controllability of the Kuramoto-Sivashinsky equation on multi-dimensional cylindrical domains</title>
      <link>https://arxiv.org/abs/2508.00812</link>
      <description>arXiv:2508.00812v2 Announce Type: replace 
Abstract: In this article, we investigate null controllability of the Kuramoto-Sivashinsky (KS) equation on a cylindrical domain $\Omega=\Omega_x\times \Omega_y$ in $\mathbb R^N$, where $\Omega_x=(0,a),$ $a&gt;0$ and $\Omega_y$ is a smooth domain in $\mathbb R^{N-1}$. We first study the controllability of this system by a control acting on $\{0\}\times \omega$, $\omega\subset \Omega_y$, through the boundary term associated with the Laplacian component. The null controllability of the linearized system is proved using a combination of two techniques: the method of moments and Lebeau-Robbiano strategy. We provide a necessary and sufficient condition for the null controllability of this system along with an explicit control cost estimate. Furthermore, we show that there exists minimal time $T_0(x_0)&gt;0$ such that the system is null controllable for all time $T &gt; T_0(x_0)$ by means of an interior control exerted on $\gamma = \{x_0\} \times \omega \subset \Omega$, where $x_0/a\in (0,1)\setminus \mathbb{Q}$ and it is not controllable if $T&lt;T_0(x_0).$
  If we assume $x_0/a$ is an algebraic real number of order $d &gt; 1$, then we prove the controllability for any time $T&gt;0.$
  Finally, for the case of $N=2 \text{ or } 3$, we show the local null controllability of the main nonlinear system by employing the source term method followed by the Banach fixed point theorem.</description>
      <guid isPermaLink="false">oai:arXiv.org:2508.00812v2</guid>
      <category>math.OC</category>
      <category>math.AP</category>
      <pubDate>Tue, 26 Aug 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>V\'ictor Hern\'andez-Santamar\'ia, Subrata Majumdar</dc:creator>
    </item>
    <item>
      <title>Multiobjective Balanced Gradient Flow: A Dynamical Perspective on a Class of Optimization Algorithms</title>
      <link>https://arxiv.org/abs/2508.01775</link>
      <description>arXiv:2508.01775v2 Announce Type: replace 
Abstract: This paper proposes a novel dynamical system called the Multiobjective Balanced Gradient Flow (MBGF), offering a dynamical perspective for normalized gradient methods in a class of multi-objective optimization problems. Under certain assumptions, we prove the existence of solutions for MBGF trajectories and establish their convergence to weak Pareto points in the case of convex objective functions. For both convex and non-convex scenarios, we provide convergence rates of $O(1/t)$ and $O(1/\sqrt{t})$, respectively.</description>
      <guid isPermaLink="false">oai:arXiv.org:2508.01775v2</guid>
      <category>math.OC</category>
      <pubDate>Tue, 26 Aug 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Yingdong Yin</dc:creator>
    </item>
    <item>
      <title>A distributed augmented Lagrangian decomposition algorithm for constrained optimization</title>
      <link>https://arxiv.org/abs/2508.04960</link>
      <description>arXiv:2508.04960v2 Announce Type: replace 
Abstract: Within the framework of the Augmented Lagrangian (AL), we introduce a novel distributed optimization method called Distributed Augmented Lagrangian Decomposition (DALD). We provide a rigorous convergence proof for the standard version of this method, which is designed to tackle general constrained optimization problems. To address the high iteration costs in early stages, we propose several accelerated variants of DALD that enhances efficiency without compromising theoretical guarantees, supported by a comprehensive convergence analysis. To facilitate the description of the distributed optimization process, the concept of hierarchical coordination networks is introduced, integrating hierarchical matrix concepts to aid in this explanation. We further explore and expand the applicability of the DALD method and demonstrate how it unifies existing distributed optimization theories within the AL framework. The effectiveness and applicability of the proposed distributed optimization method and its variants are further validated through numerical experiments.</description>
      <guid isPermaLink="false">oai:arXiv.org:2508.04960v2</guid>
      <category>math.OC</category>
      <pubDate>Tue, 26 Aug 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Wenyou Guo, Ting Qu, Hainan Huang, Yafeng Wei</dc:creator>
    </item>
    <item>
      <title>Zeroth-Order Non-smooth Non-convex Optimization via Gaussian Smoothing</title>
      <link>https://arxiv.org/abs/2508.11073</link>
      <description>arXiv:2508.11073v2 Announce Type: replace 
Abstract: This paper addresses stochastic optimization of Lipschitz-continuous, nonsmooth and nonconvex objectives over compact convex sets, where only noisy function evaluations are available. While gradient-free methods have been developed for smooth nonconvex problems, extending these techniques to the nonsmooth setting remains challenging. The primary difficulty arises from the absence of a Taylor series expansion for Clarke subdifferentials, which limits the ability to approximate and analyze the behavior of the objective function in a neighborhood of a point. We propose a two time-scale zeroth-order projected stochastic subgradient method leveraging Gaussian smoothing to approximate Clarke subdifferentials. First, we establish that the expectation of the Gaussian-smoothed subgradient lies within an explicitly bounded error of the Clarke subdifferential, a result that extends prior analyses beyond convex/smooth settings. Second, we design a novel algorithm with coupled updates: a fast timescale tracks the subgradient approximation, while a slow timescale drives convergence. Using continuous-time dynamical systems theory and robust perturbation analysis, we prove that iterates converge almost surely to a neighborhood of the set of Clarke stationary points, with neighborhood size controlled by the smoothing parameter. To our knowledge, this is the first zeroth-order method achieving almost sure convergence for constrained nonsmooth nonconvex optimization problems.</description>
      <guid isPermaLink="false">oai:arXiv.org:2508.11073v2</guid>
      <category>math.OC</category>
      <pubDate>Tue, 26 Aug 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Anik Kumar Paul, Shalabh Bhatnagar</dc:creator>
    </item>
    <item>
      <title>A generalized Hurwitz stability criterion via rectangular block Hankel matrices for nonmonic matrix polynomials</title>
      <link>https://arxiv.org/abs/2508.14376</link>
      <description>arXiv:2508.14376v2 Announce Type: replace 
Abstract: We develop a Hurwitz stability criterion for nonmonic matrix polynomials via column reduction, generalizing existing approaches constrained by the monic assumption, as well as Gantmacher's classical stability criterion via Markov parameters. Starting from redefining the associated Markov parameters through a column-wise adaptive splitting method, our framework constructs two structured matrices whose rectangular Hankel blocks are obtained via the extraction of these parameters. We establish an explicit interrelation between the inertias of column reduced matrix polynomials and the derived structured matrices. Furthermore, we demonstrate that the Hurwitz stability of column reduced matrix polynomials can be determined by the Hermitian positive definiteness of these rectangular block Hankel matrices.</description>
      <guid isPermaLink="false">oai:arXiv.org:2508.14376v2</guid>
      <category>math.OC</category>
      <category>cs.NA</category>
      <category>math.NA</category>
      <pubDate>Tue, 26 Aug 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Xuzhou Zhan, Zixiang Ni</dc:creator>
    </item>
    <item>
      <title>On the Foundation of Distributionally Robust Reinforcement Learning</title>
      <link>https://arxiv.org/abs/2311.09018</link>
      <description>arXiv:2311.09018v4 Announce Type: replace-cross 
Abstract: Motivated by the need for a robust policy in the face of environment shifts between training and deployment, we contribute to the theoretical foundation of distributionally robust reinforcement learning (DRRL). This is accomplished through a comprehensive modeling framework centered around robust Markov decision processes (RMDPs). This framework obliges the decision maker to choose an optimal policy under the worst-case distributional shift orchestrated by an adversary. By unifying and extending existing formulations, we rigorously construct RMDPs that embrace various modeling attributes for both the decision maker and the adversary. These attributes include the structure of information availability-covering history-dependent, Markov, and Markov time-homogeneous dynamics-as well as constraints on the shifts induced by the adversary, with a focus on SA- and S-rectangularity. Within this RMDP framework, we investigate conditions for the existence or absence of the dynamic programming principle (DPP). From an algorithmic standpoint, the existence of DPP holds significant implications, as the vast majority of existing data and computationally efficient DRRL algorithms are reliant on the DPP. To investigate its existence, we systematically analyze various combinations of controller and adversary attributes, presenting streamlined proofs based on a unified methodology. We then construct counterexamples for settings where a fully general DPP fails to hold and establish asymptotically optimal history-dependent policies for key scenarios where the DPP is absent.</description>
      <guid isPermaLink="false">oai:arXiv.org:2311.09018v4</guid>
      <category>cs.LG</category>
      <category>cs.SY</category>
      <category>eess.SY</category>
      <category>math.OC</category>
      <category>stat.ML</category>
      <pubDate>Tue, 26 Aug 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Shengbo Wang, Nian Si, Jose Blanchet, Zhengyuan Zhou</dc:creator>
    </item>
    <item>
      <title>Generalizations of data-driven balancing: What to sample for different balancing-based reduced models</title>
      <link>https://arxiv.org/abs/2312.12561</link>
      <description>arXiv:2312.12561v2 Announce Type: replace-cross 
Abstract: The quadrature-based balanced truncation (QuadBT) framework of arXiv:2104.01006 is a non-intrusive reformulation of balanced truncation (BT), a classical projection-based model-order reduction technique for linear systems. QuadBT is non-intrusive in the sense that it builds approximate balanced truncation reduced-order models entirely from system response data, e.g., transfer function measurements, without the need to reference an explicit state-space realization of the underlying full-order model. In this work, we generalize the QuadBT framework to other types of balanced truncation model reduction. Namely, we show what transfer function data are required to compute data-driven reduced models by balanced stochastic truncation, positive-real balanced truncation, and bounded-real balanced truncation. In each case, these data are evaluations of particular spectral factors associated with the system of interest. These results lay the theoretical foundation for data-driven reformulations of the aforementioned BT variants. Although it is not yet clear how to compute or obtain these spectral factor data in a practical real-world setting, examples using synthetic (numerically evaluated) transfer function data are included to validate the data-based reduced models.</description>
      <guid isPermaLink="false">oai:arXiv.org:2312.12561v2</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <category>cs.SY</category>
      <category>eess.SY</category>
      <category>math.OC</category>
      <pubDate>Tue, 26 Aug 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <arxiv:DOI>10.1016/j.automatica.2025.112518</arxiv:DOI>
      <arxiv:journal_reference>Automatica 182 (2025): 112518</arxiv:journal_reference>
      <dc:creator>Sean Reiter, Ion Victor Gosea, Serkan Gugercin</dc:creator>
    </item>
    <item>
      <title>On a class of interdiction problems with partition matroids: complexity and polynomial-time algorithms</title>
      <link>https://arxiv.org/abs/2401.12010</link>
      <description>arXiv:2401.12010v5 Announce Type: replace-cross 
Abstract: In this study, we consider a class of linear matroid interdiction problems, where the feasible sets for the upper-level decision-maker (referred to as a leader) and the lower-level decision-maker (referred to as a follower) are induced by two distinct partition matroids with a common weighted ground set. Unlike classical network interdiction models where the leader is subject to a single budget constraint, in our setting, both the leader and the follower are subject to several independent capacity constraints and engage in a zero-sum game. While the problem of finding a maximum weight independent set in a partition matroid is known to be polynomially solvable, we prove that the considered bilevel problem is $NP$-hard even when the weights of ground elements are all binary. On a positive note, it is revealed that, if the number of capacity constraints is fixed for either the leader or the follower, then the considered class of bilevel problems admits several polynomial-time solution schemes. Specifically, these schemes are based on a single-level dual reformulation, a dynamic programming-based approach, and a greedy algorithm for the leader.</description>
      <guid isPermaLink="false">oai:arXiv.org:2401.12010v5</guid>
      <category>cs.CC</category>
      <category>math.OC</category>
      <pubDate>Tue, 26 Aug 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <arxiv:DOI>10.1287/ijoc.2024.0599</arxiv:DOI>
      <dc:creator>Sergey S. Ketkov, Oleg A. Prokopyev</dc:creator>
    </item>
    <item>
      <title>SINDy-RL: Interpretable and Efficient Model-Based Reinforcement Learning</title>
      <link>https://arxiv.org/abs/2403.09110</link>
      <description>arXiv:2403.09110v2 Announce Type: replace-cross 
Abstract: Deep reinforcement learning (DRL) has shown significant promise for uncovering sophisticated control policies that interact in complex environments, such as stabilizing a tokamak fusion reactor or minimizing the drag force on an object in a fluid flow. However, DRL requires an abundance of training examples and may become prohibitively expensive for many applications. In addition, the reliance on deep neural networks often results in an uninterpretable, black-box policy that may be too computationally expensive to use with certain embedded systems. Recent advances in sparse dictionary learning, such as the sparse identification of nonlinear dynamics (SINDy), have shown promise for creating efficient and interpretable data-driven models in the low-data regime. In this work we introduce SINDy-RL, a unifying framework for combining SINDy and DRL to create efficient, interpretable, and trustworthy representations of the dynamics model, reward function, and control policy. We demonstrate the effectiveness of our approaches on benchmark control environments and flow control problems, including gust mitigation on a 3D NACA 0012 airfoil at $Re=1000$. SINDy-RL achieves comparable performance to modern DRL algorithms using significantly fewer interactions in the environment and results in an interpretable control policy orders of magnitude smaller than a DRL policy.</description>
      <guid isPermaLink="false">oai:arXiv.org:2403.09110v2</guid>
      <category>cs.LG</category>
      <category>cs.SY</category>
      <category>eess.SY</category>
      <category>math.DS</category>
      <category>math.OC</category>
      <pubDate>Tue, 26 Aug 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Nicholas Zolman, Christian Lagemann, Urban Fasel, J. Nathan Kutz, Steven L. Brunton</dc:creator>
    </item>
    <item>
      <title>Reinforcement Learning for Jump-Diffusions, with Financial Applications</title>
      <link>https://arxiv.org/abs/2405.16449</link>
      <description>arXiv:2405.16449v5 Announce Type: replace-cross 
Abstract: We study continuous-time reinforcement learning (RL) for stochastic control in which system dynamics are governed by jump-diffusion processes. We formulate an entropy-regularized exploratory control problem with stochastic policies to capture the exploration--exploitation balance essential for RL. Unlike the pure diffusion case initially studied by Wang et al. (2020), the derivation of the exploratory dynamics under jump-diffusions calls for a careful formulation of the jump part. Through a theoretical analysis, we find that one can simply use the same policy evaluation and $q$-learning algorithms in Jia and Zhou (2022a, 2023), originally developed for controlled diffusions, without needing to check a priori whether the underlying data come from a pure diffusion or a jump-diffusion. However, we show that the presence of jumps ought to affect parameterizations of actors and critics in general. We investigate as an application the mean--variance portfolio selection problem with stock price modelled as a jump-diffusion, and show that both RL algorithms and parameterizations are invariant with respect to jumps. Finally, we present a detailed study on applying the general theory to option hedging.</description>
      <guid isPermaLink="false">oai:arXiv.org:2405.16449v5</guid>
      <category>cs.LG</category>
      <category>math.OC</category>
      <category>q-fin.MF</category>
      <pubDate>Tue, 26 Aug 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Xuefeng Gao, Lingfei Li, Xun Yu Zhou</dc:creator>
    </item>
    <item>
      <title>A Tie-breaking based Local Search Algorithm for Stable Matching Problems</title>
      <link>https://arxiv.org/abs/2409.10575</link>
      <description>arXiv:2409.10575v2 Announce Type: replace-cross 
Abstract: The stable marriage problem with incomplete lists and ties (SMTI) and the hospitals/residents problem with ties (HRT) are important in matching theory with broad practical applications. In this paper, we introduce a tie-breaking based local search (TBLS) algorithm designed to achieve a weakly stable matching of maximum size for both the SMTI and HRT problems. TBLS begins by arbitrarily resolving all ties and iteratively refines the tie-breaking strategy by adjusting the relative order within ties based on preference ranks and the current stable matching. Additionally, we introduce TBLS-E, an equity-focused variant of TBLS, specifically designed for the SMTI problem. This variant maintains the objective of maximizing matching size, while enhancing equity through two simple modifications. In comparison with ten other approximation and local search algorithms, TBLS achieves the highest matching size, while TBLS-E exhibits the lowest sex equality cost. Significantly, TBLS-E preserves a matching size comparable to that of TBLS. Both our algorithms demonstrate faster computational speed than other local search algorithms in solving large-scale instances. Moreover, our scalability analysis shows that both algorithms maintain efficient performance as problem size increases.</description>
      <guid isPermaLink="false">oai:arXiv.org:2409.10575v2</guid>
      <category>cs.DS</category>
      <category>cs.AI</category>
      <category>cs.DM</category>
      <category>math.OC</category>
      <pubDate>Tue, 26 Aug 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Junyuan Qiu</dc:creator>
    </item>
    <item>
      <title>Rigidly breaking potential flows and a countable Alexandrov theorem for polytopes</title>
      <link>https://arxiv.org/abs/2411.05606</link>
      <description>arXiv:2411.05606v4 Announce Type: replace-cross 
Abstract: We study all the ways that a given convex body in $d$ dimensions can break into countably many pieces that move away from each other rigidly at constant velocity, with no rotation or shearing. The initial velocity field is locally constant, but may be continuous and/or fail to be integrable. For any choice of mass-velocity pairs for the pieces, such a motion can be generated by the gradient of a convex potential that is affine on each piece. We classify such potentials in terms of a countable version of a theorem of Alexandrov for convex polytopes, and prove a stability theorem. For bounded velocities, there is a bijection between the mass-velocity data and optimal transport flows (Wasserstein geodesics) that are locally incompressible.
  Given any rigidly breaking velocity field that is the gradient of a continuous potential, the convexity of the potential is established under any of several conditions, such as the velocity field being continuous, the potential being semi-convex, the mass measure generated by a convexified transport potential being absolutely continuous, or there being a finite number of pieces. Also we describe a number of curious and paradoxical examples having fractal structure.</description>
      <guid isPermaLink="false">oai:arXiv.org:2411.05606v4</guid>
      <category>math.AP</category>
      <category>math.OC</category>
      <pubDate>Tue, 26 Aug 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Jian-Guo Liu, Robert L. Pego</dc:creator>
    </item>
    <item>
      <title>A characterization of unimodular hypergraphs with disjoint hyperedges</title>
      <link>https://arxiv.org/abs/2411.10593</link>
      <description>arXiv:2411.10593v2 Announce Type: replace-cross 
Abstract: The incidence matrix of a graph is totally unimodular if and only if the graph is bipartite, i.e., it contains no odd cycles. We extend the characterization of total unimodularity to hypergraphs whose hyperedges of size at least four are pairwise disjoint, which we call disjoint hypergraphs. Disjoint hypergraphs have been used to model problems with fairness constraints that ensure balanced representation. We prove that total unimodularity for disjoint hypergraphs is equivalent to forbidding both odd cycles and structures that we call odd tree houses. Our result extends to disjoint mixed hypergraphs, whose incidence matrices have $\{0, \pm1\}$-entries. As a corollary, we resolve a special case of a conjecture on almost totally unimodular matrices, originally posed by Padberg and later modified by Cornu\'ejols and Zuluaga.</description>
      <guid isPermaLink="false">oai:arXiv.org:2411.10593v2</guid>
      <category>math.CO</category>
      <category>math.OC</category>
      <pubDate>Tue, 26 Aug 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Marco Caoduro, Meike Neuwohner, Joseph Paat</dc:creator>
    </item>
    <item>
      <title>Approximate predictive control barrier function for discrete-time systems</title>
      <link>https://arxiv.org/abs/2411.11610</link>
      <description>arXiv:2411.11610v2 Announce Type: replace-cross 
Abstract: We propose integrating an approximation of a predictive control barrier function (PCBF) in a safety filter framework, resulting in a prediction horizon independent formulation. The PCBF is defined through the value function of an optimal control problem and ensures invariance as well as stability of a safe set within a larger domain of attraction. We provide a theoretical analysis of the proposed algorithm, establishing input-to-state stability of the safe set with respect to approximation errors as well as exogenous disturbances. Furthermore, we propose a continuous extension of the PCBF within the safe set, reducing the impact of learning errors on filter interventions. We demonstrate the stability properties and computational advantages of the proposed algorithm on a linear system example and its application as a safety filter for miniature race cars in simulation.</description>
      <guid isPermaLink="false">oai:arXiv.org:2411.11610v2</guid>
      <category>eess.SY</category>
      <category>cs.SY</category>
      <category>math.OC</category>
      <pubDate>Tue, 26 Aug 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Alexandre Didier, Melanie N. Zeilinger</dc:creator>
    </item>
    <item>
      <title>Optimizing the Optimizer for Physics-Informed Neural Networks and Kolmogorov-Arnold Networks</title>
      <link>https://arxiv.org/abs/2501.16371</link>
      <description>arXiv:2501.16371v5 Announce Type: replace-cross 
Abstract: Physics-Informed Neural Networks (PINNs) have revolutionized the computation of PDE solutions by integrating partial differential equations (PDEs) into the neural network's training process as soft constraints, becoming an important component of the scientific machine learning (SciML) ecosystem. More recently, physics-informed Kolmogorv-Arnold networks (PIKANs) have also shown to be effective and comparable in accuracy with PINNs. In their current implementation, both PINNs and PIKANs are mainly optimized using first-order methods like Adam, as well as quasi-Newton methods such as BFGS and its low-memory variant, L-BFGS. However, these optimizers often struggle with highly non-linear and non-convex loss landscapes, leading to challenges such as slow convergence, local minima entrapment, and (non)degenerate saddle points. In this study, we investigate the performance of Self-Scaled BFGS (SSBFGS), Self-Scaled Broyden (SSBroyden) methods and other advanced quasi-Newton schemes, including BFGS and L-BFGS with different line search strategies. These methods dynamically rescale updates based on historical gradient information, thus enhancing training efficiency and accuracy. We systematically compare these optimizers using both PINNs and PIKANs on key challenging PDEs, including the Burgers, Allen-Cahn, Kuramoto-Sivashinsky, Ginzburg-Landau, and Stokes equations. Additionally, we evaluate the performance of SSBFGS and SSBroyden for Deep Operator Network (DeepONet) architectures, demonstrating their effectiveness for data-driven operator learning. Our findings provide state-of-the-art results with orders-of-magnitude accuracy improvements without the use of adaptive weights or any other enhancements typically employed in PINNs.</description>
      <guid isPermaLink="false">oai:arXiv.org:2501.16371v5</guid>
      <category>cs.LG</category>
      <category>cs.AI</category>
      <category>math.OC</category>
      <pubDate>Tue, 26 Aug 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <dc:creator>Elham Kiyani, Khemraj Shukla, Jorge F. Urb\'an, J\'er\^ome Darbon, George Em Karniadakis</dc:creator>
    </item>
    <item>
      <title>Learning an Optimal Assortment Policy under Observational Data</title>
      <link>https://arxiv.org/abs/2502.06777</link>
      <description>arXiv:2502.06777v4 Announce Type: replace-cross 
Abstract: We study the fundamental problem of offline assortment optimization under the Multinomial Logit (MNL) model, where sellers must determine the optimal subset of the products to offer based solely on historical customer choice data. While most existing approaches to learning-based assortment optimization focus on the online learning of the optimal assortment through repeated interactions with customers, such exploration can be costly or even impractical in many real-world settings. In this paper, we consider the offline learning paradigm and investigate the minimal data requirements for efficient offline assortment optimization. To this end, we introduce Pessimistic Rank-Breaking (PRB), an algorithm that combines rank-breaking with pessimistic estimation. We prove that PRB is nearly minimax optimal by establishing the tight suboptimality upper bound and a nearly matching lower bound. This further shows that "optimal item coverage" - where each item in the optimal assortment appears sufficiently often in the historical data - is both sufficient and necessary for efficient offline learning. This significantly relaxes the previous requirement of observing the complete optimal assortment in the data. Our results provide fundamental insights into the data requirements for offline assortment optimization under the MNL model.</description>
      <guid isPermaLink="false">oai:arXiv.org:2502.06777v4</guid>
      <category>stat.ML</category>
      <category>cs.LG</category>
      <category>math.OC</category>
      <category>math.ST</category>
      <category>stat.TH</category>
      <pubDate>Tue, 26 Aug 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Yuxuan Han, Han Zhong, Miao Lu, Jose Blanchet, Zhengyuan Zhou</dc:creator>
    </item>
    <item>
      <title>Achieving constant regret for dynamic matching via state-independent policies</title>
      <link>https://arxiv.org/abs/2503.09762</link>
      <description>arXiv:2503.09762v2 Announce Type: replace-cross 
Abstract: We study a centralized discrete-time dynamic two-way matching model with finitely many agent types. Agents arrive stochastically over time and join their type-dedicated queues waiting to be matched. We focus on state-independent greedy policies that achieve constant regret at all times by making matching decisions based solely on agent availability across types, rather than requiring complete queue-length information. Such policies are particularly appealing for life-saving applications such as kidney exchange, as they require less information and provide more transparency compared to state-dependent policies.
  First, for acyclic matching networks, we analyze a deterministic priority policy proposed by Kerimov et al. [2023] that follows a static priority order over matches. We derive the first explicit regret bound in terms of the general position gap (GPG) parameter $\epsilon$, which measures the distance of the fluid relaxation from degeneracy. Second, for general two-way matching networks, we design a randomized state-independent greedy policy that achieves constant regret with optimal scaling $O(\epsilon^{-1})$, matching the existing lower bound established by Kerimov et al. [2024].</description>
      <guid isPermaLink="false">oai:arXiv.org:2503.09762v2</guid>
      <category>cs.DS</category>
      <category>math.OC</category>
      <category>math.PR</category>
      <pubDate>Tue, 26 Aug 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>S\"uleyman Kerimov, Pengyu Qian, Mingwei Yang, Sophie H. Yu</dc:creator>
    </item>
    <item>
      <title>Output-feedback model predictive control under dynamic uncertainties using integral quadratic constraints</title>
      <link>https://arxiv.org/abs/2504.00196</link>
      <description>arXiv:2504.00196v2 Announce Type: replace-cross 
Abstract: In this work, we propose an output-feedback tube-based model predictive control (MPC) scheme for linear systems under dynamic uncertainties that are described via integral quadratic constraints (IQC). By leveraging IQCs, a large class of nonlinear and dynamic uncertainties can be addressed. We leverage recent IQC synthesis tools to design a dynamic controller and an estimator that are robust to these uncertainties and minimize the size of the resulting constraint tightening in the MPC. Thereby, we show that the robust estimation problem using IQCs with peak-to-peak performance can be convexified. We guarantee recursive feasibility, robust constraint satisfaction, and input-to-state stability of the resulting MPC scheme.</description>
      <guid isPermaLink="false">oai:arXiv.org:2504.00196v2</guid>
      <category>eess.SY</category>
      <category>cs.SY</category>
      <category>math.OC</category>
      <pubDate>Tue, 26 Aug 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Lukas Schwenkel, Johannes K\"ohler, Matthias A. M\"uller, Frank Allg\"ower</dc:creator>
    </item>
    <item>
      <title>Global Convergence of Iteratively Reweighted Least Squares for Robust Subspace Recovery</title>
      <link>https://arxiv.org/abs/2506.20533</link>
      <description>arXiv:2506.20533v3 Announce Type: replace-cross 
Abstract: Robust subspace estimation is fundamental to many machine learning and data analysis tasks. Iteratively Reweighted Least Squares (IRLS) is an elegant and empirically effective approach to this problem, yet its theoretical properties remain poorly understood. This paper establishes that, under deterministic conditions, a variant of IRLS with dynamic smoothing regularization converges linearly to the underlying subspace from any initialization. We extend these guarantees to affine subspace estimation, a setting that lacks prior recovery theory. Additionally, we illustrate the practical benefits of IRLS through an application to low-dimensional neural network training. Our results provide the first global convergence guarantees for IRLS in robust subspace recovery and, more broadly, for nonconvex IRLS on a Riemannian manifold.</description>
      <guid isPermaLink="false">oai:arXiv.org:2506.20533v3</guid>
      <category>stat.ML</category>
      <category>cs.LG</category>
      <category>math.OC</category>
      <pubDate>Tue, 26 Aug 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Gilad Lerman, Kang Li, Tyler Maunu, Teng Zhang</dc:creator>
    </item>
    <item>
      <title>On the Foundations of Dynamic Games and Probability: Decision Making in Stochastic Extensive Form</title>
      <link>https://arxiv.org/abs/2508.04752</link>
      <description>arXiv:2508.04752v2 Announce Type: replace-cross 
Abstract: In this work, an abstract and general language for the fundamental objects underlying dynamic games under probabilistic uncertainty is developed. Combining the theory of decision trees by Al\'os-Ferrer--Ritzberger (2005) and a Harsanyian notion of exogenous uncertainty, the concept of stochastic decision forests is introduced. Exogenous information is modelled via filtration-like objects providing dynamic updates on the "realised tree", and an abstract decision-theoretic model of adapted choice is formulated.
  Based on this, a consistent model of "rules" is introduced, leading to the notion of stochastic extensive forms, generalising the works of Al\'os-Ferrer--Ritzberger (2008, 2011). Well-posedness is completely characterised in terms of order-theoretic properties of the underlying forest. Moreover, the language of stochastic extensive forms addresses a vast class of dynamic decision problems formulated in terms of time-indexed paths of action -- a first step towards an approximation theory of continuous-time games based on stochastic processes. In this formulation, a well-posed theory obtains if and only if the time half-axis is essentially well-ordered.
  Therefore, a relaxed game-theoretic model of "extensive form characteristics" is introduced: the stochastic process form. Its action processes arise from well-posed action path stochastic extensive forms under tilting convergence, which is introduced in order to faithfully describe accumulating reaction behaviour. The problem of instantaneous reaction and information about it is tackled by introducing vertically extended continuous time, for which a suitable stochastic analysis is developed. Stochastic process forms admit a natural notion of information sets, subgames, and equilibrium. The theory applies to stochastic differential and timing games, e.g., addressing open issues in Fudenberg--Tirole (1985) and Riedel--Steg (2017).</description>
      <guid isPermaLink="false">oai:arXiv.org:2508.04752v2</guid>
      <category>econ.TH</category>
      <category>math.OC</category>
      <category>math.PR</category>
      <pubDate>Tue, 26 Aug 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>E. Emanuel Rapsch</dc:creator>
    </item>
    <item>
      <title>Decentralized Contextual Bandits with Network Adaptivity</title>
      <link>https://arxiv.org/abs/2508.13411</link>
      <description>arXiv:2508.13411v2 Announce Type: replace-cross 
Abstract: We consider contextual linear bandits over networks, a class of sequential decision-making problems where learning occurs simultaneously across multiple locations and the reward distributions share structural similarities while also exhibiting local differences. While classical contextual bandits assume either fully centralized data or entirely isolated learners, much remains unexplored in networked environments when information is partially shared. In this paper, we address this gap by developing two network-aware Upper Confidence Bound (UCB) algorithms, NetLinUCB and Net-SGD-UCB, which enable adaptive information sharing guided by dynamically updated network weights. Our approach decompose learning into global and local components and as a result allow agents to benefit from shared structure without full synchronization. Both algorithms incur lighter communication costs compared to a fully centralized setting as agents only share computed summaries regarding the homogeneous features. We establish regret bounds showing that our methods reduce the learning complexity associated with the shared structure from $O(N)$ to sublinear $O(\sqrt{N})$, where $N$ is the size of the network. The two algorithms reveal complementary strengths: NetLinUCB excels in low-noise regimes with fine-grained heterogeneity, while Net-SGD-UCB is robust to high-dimensional, high-variance contexts. We further demonstrate the effectiveness of our methods across simulated pricing environments compared to standard benchmarks.</description>
      <guid isPermaLink="false">oai:arXiv.org:2508.13411v2</guid>
      <category>cs.LG</category>
      <category>math.OC</category>
      <pubDate>Tue, 26 Aug 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Chuyun Deng, Huiwen Jia</dc:creator>
    </item>
    <item>
      <title>Multi-User Contextual Cascading Bandits for Personalized Recommendation</title>
      <link>https://arxiv.org/abs/2508.13981</link>
      <description>arXiv:2508.13981v2 Announce Type: replace-cross 
Abstract: We introduce a Multi-User Contextual Cascading Bandit model, a new combinatorial bandit framework that captures realistic online advertising scenarios where multiple users interact with sequentially displayed items simultaneously. Unlike classical contextual bandits, MCCB integrates three key structural elements: (i) cascading feedback based on sequential arm exposure, (ii) parallel context sessions enabling selective exploration, and (iii) heterogeneous arm-level rewards. We first propose Upper Confidence Bound with Backward Planning (UCBBP), a UCB-style algorithm tailored to this setting, and prove that it achieves a regret bound of $\widetilde{O}(\sqrt{THN})$ over $T$ episodes, $H$ session steps, and $N$ contexts per episode. Motivated by the fact that many users interact with the system simultaneously, we introduce a second algorithm, termed Active Upper Confidence Bound with Backward Planning (AUCBBP), which shows a strict efficiency improvement in context scaling, i.e., user scaling, with a regret bound of $\widetilde{O}(\sqrt{T+HN})$. We validate our theoretical findings via numerical experiments, demonstrating the empirical effectiveness of both algorithms under various settings.</description>
      <guid isPermaLink="false">oai:arXiv.org:2508.13981v2</guid>
      <category>cs.LG</category>
      <category>math.OC</category>
      <category>stat.ML</category>
      <pubDate>Tue, 26 Aug 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Jiho Park, Huiwen Jia</dc:creator>
    </item>
  </channel>
</rss>
