<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>cs.NI updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/cs.NI</link>
    <description>cs.NI updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/cs.NI" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Thu, 17 Jul 2025 04:00:08 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Thu, 17 Jul 2025 00:00:00 -0400</pubDate>
    <skipDays>
      <day>Sunday</day>
      <day>Saturday</day>
    </skipDays>
    <item>
      <title>Towards a Non-Binary View of IPv6 Adoption</title>
      <link>https://arxiv.org/abs/2507.11678</link>
      <description>arXiv:2507.11678v1 Announce Type: new 
Abstract: Twelve years have passed since World IPv6 Launch Day, but what is the current state of IPv6 deployment? Prior work has examined IPv6 status as a binary: can you use IPv6, or not? As deployment increases we must consider a more nuanced, non-binary perspective on IPv6: how much and often can a user or a service use IPv6? We consider this question as a client, server, and cloud provider. Considering the client's perspective, we observe user traffic. We see that the fraction of IPv6 traffic a user sends varies greatly, both across users and day-by-day, with a standard deviation of over 15%. We show this variation occurs for two main reasons. First, IPv6 traffic is primarily human-generated, thus showing diurnal patterns. Second, some services are IPv6-forward and others IPv6-laggards, so as users do different things their fraction of IPv6 varies. We look at server-side IPv6 adoption in two ways. First, we expand analysis of web services to examine how many are only partially IPv6 enabled due to their reliance on IPv4-only resources. Our findings reveal that only 12.5% of top 100k websites qualify as fully IPv6-ready. Finally, we examine cloud support for IPv6. Although all clouds and CDNs support IPv6, we find that tenant deployment rates vary significantly across providers. We find that ease of enabling IPv6 in the cloud is correlated with tenant IPv6 adoption rates, and recommend best practices for cloud providers to improve IPv6 adoption. Our results suggest IPv6 deployment is growing, but many services lag, presenting a potential for improvement.</description>
      <guid isPermaLink="false">oai:arXiv.org:2507.11678v1</guid>
      <category>cs.NI</category>
      <pubDate>Thu, 17 Jul 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Sulyab Thottungal Valapu, John Heidemann</dc:creator>
    </item>
    <item>
      <title>On QoE-Aware Traffic Management for Real-time, Interactive Video with Time-variant Spatial Complexity</title>
      <link>https://arxiv.org/abs/2507.11798</link>
      <description>arXiv:2507.11798v1 Announce Type: new 
Abstract: We analyzed spatial complexity, defined as the relationship between the required bitrate and a corresponding picture Quality of Experience (QoE) metric, for realistic, long, real-time, interactive video clips. Apart from variation across different content types, e.g., game genres, we discovered time-variability within a clip from second to second, and explored the ramifications for traffic management. We introduced utility as an elegant way to manage resource sharing preferences. Our analysis of resource sharing methods shows that frequent QoE-aware reallocation has significant performance advantages compared to static rate allocation, even in case the latter is based on rich information about long-term average spatial complexity. We have also shown that utility-based resource allocation has clear advantages over methods targeting equal QoE allocation, it increases the average QoE, while it still controls the worst case QoE.</description>
      <guid isPermaLink="false">oai:arXiv.org:2507.11798v1</guid>
      <category>cs.NI</category>
      <pubDate>Thu, 17 Jul 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Szilveszter N\'adas, Lars Ernstr\"om, David Lindero, Jonathan Lynam</dc:creator>
    </item>
    <item>
      <title>Native-AI Empowered Scalable Architectures and Solutions for Future Non-Terrestrial Networks: An Overview</title>
      <link>https://arxiv.org/abs/2507.11935</link>
      <description>arXiv:2507.11935v1 Announce Type: new 
Abstract: As the path toward 6G networks is being charted, the emerging applications have motivated evolutions of network architectures to realize the efficient, reliable, and flexible wireless networks. Among the potential architectures, the non-terrestrial network (NTN) and open radio access network (ORAN) have received increasing interest from both academia and industry. Although the deployment of NTNs ensures coverage, enhances spectral efficiency, and improves the resilience of wireless networks. The high altitude and mobility of NTN present new challenges in the development and operations (DevOps) lifecycle, hindering intelligent and scalable network management due to the lack of native artificial intelligence (AI) capability. With the advantages of ORAN in disaggregation, openness, virtualization, and intelligence, several works propose integrating ORAN principles into the NTN, focusing mainly on ORAN deployment options based on transparent and regenerative systems. However, a holistic view of how to effectively combine ORAN and NTN throughout the DevOps lifecycle is still missing, especially regarding how intelligent ORAN addresses the scalability challenges in NTN. Motivated by this, in this paper, we first provide the background knowledge about ORAN and NTN, outline the state-of-the-art research on ORAN for NTNs, and present the DevOps challenges that motivate the adoption of ORAN solutions. We then propose the ORAN-based NTN framework, discussing its features and architectures in detail. These include the discussion about flexible fronthaul split, RAN intelligent controllers (RICs) enhancement for distributed learning, scalable deployment architecture, and multi-domain service management. Finally, the future research directions, including combinations of the ORAN-based NTN framework and other enabling technologies and schemes, as well as the candidate use cases, are highlighted.</description>
      <guid isPermaLink="false">oai:arXiv.org:2507.11935v1</guid>
      <category>cs.NI</category>
      <category>cs.AI</category>
      <category>cs.SY</category>
      <category>eess.SY</category>
      <pubDate>Thu, 17 Jul 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Jikang Deng, Fizza Hassan, Hui Zhou, Saad Al-Ahmadi, Mohamed-Slim Alouini, Daniel B. Da Costa</dc:creator>
    </item>
    <item>
      <title>FastReChain: Highly Responsive and Low-Overhead Centralized Route Scheduling in Clos Datacenter Networks</title>
      <link>https://arxiv.org/abs/2507.12265</link>
      <description>arXiv:2507.12265v1 Announce Type: new 
Abstract: Ever since Clos topologies were used in datacenter networks (DCNs), a practical centralized scheduling algorithm that supports dynamic scheduling has been absent. The introduction of optical switches in DCNs as a future-proof solution exacerbates this problem due to several properties of optical switches, such as the fact that they are generally bufferless and therefore rely on centralized scheduling, and that they have long switching times and therefore require the number of rearrangements to be minimized.
  In this paper, we propose a centralized scheduling algorithm that achieves theoretical maximum throughput even in one-rate bidirectional Clos networks, while producing schemes with near-minimal numbers of rearrangements. It is the only algorithm that directly supports bidirectional Clos networks and has a time efficiency high enough to support dynamic scheduling to date. For static minimal rewiring, its running time ranges from a fraction to a few hundredths of other algorithms, and the number of rearrangements has also been steadily improved, allowing for more frequent adjustments and less impact on ongoing communications. In addition, the algorithm is very flexible and can support various functional requirements in real-world environments. We achieve this result through the replacement chain concept and bitset optimization.</description>
      <guid isPermaLink="false">oai:arXiv.org:2507.12265v1</guid>
      <category>cs.NI</category>
      <category>cs.DS</category>
      <pubDate>Thu, 17 Jul 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-sa/4.0/</dc:rights>
      <dc:creator>Zihan Zhu, Dongchao Wu, Zhanbang Zhang, Jian Yang</dc:creator>
    </item>
    <item>
      <title>LLM-Based Config Synthesis requires Disambiguation</title>
      <link>https://arxiv.org/abs/2507.12443</link>
      <description>arXiv:2507.12443v1 Announce Type: new 
Abstract: Beyond hallucinations, another problem in program synthesis using LLMs is ambiguity in user intent. We illustrate the ambiguity problem in a networking context for LLM-based incremental configuration synthesis of route-maps and ACLs. These structures frequently overlap in header space, making the relative priority of actions impossible for the LLM to infer without user interaction. Measurements in a large cloud identify complex ACLs with 100's of overlaps, showing ambiguity is a real problem. We propose a prototype system, Clarify, which uses an LLM augmented with a new module called a Disambiguator that helps elicit user intent. On a small synthetic workload, Clarify incrementally synthesizes routing policies after disambiguation and then verifies them. Our treatment of ambiguities is useful more generally when the intent of updates can be correctly synthesized by LLMs, but their integration is ambiguous and can lead to different global behaviors.</description>
      <guid isPermaLink="false">oai:arXiv.org:2507.12443v1</guid>
      <category>cs.NI</category>
      <category>cs.AI</category>
      <category>cs.HC</category>
      <category>cs.PL</category>
      <pubDate>Thu, 17 Jul 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Rajdeep Mondal, Nikolaj Bjorner, Todd Millstein, Alan Tang, George Varghese</dc:creator>
    </item>
    <item>
      <title>CRAFT: Latency and Cost-Aware Genetic-Based Framework for Node Placement in Edge-Fog Environments</title>
      <link>https://arxiv.org/abs/2507.12445</link>
      <description>arXiv:2507.12445v1 Announce Type: new 
Abstract: Reducing latency in the Internet of Things (IoT) is a critical concern. While cloud computing facilitates communication, it falls short of meeting real-time requirements reliably. Edge and fog computing have emerged as viable solutions by positioning computing nodes closer to end users, offering lower latency and increased processing power. An edge-fog framework comprises various components, including edge and fog nodes, whose strategic placement is crucial as it directly impacts latency and system cost. This paper presents an effective and tunable node placement strategy based on a genetic algorithm to address the optimization problem of deploying edge and fog nodes. The main objective is to minimize latency and cost through optimal node placement. Simulation results demonstrate that the proposed framework achieves up to 2.77% latency and 31.15% cost reduction.</description>
      <guid isPermaLink="false">oai:arXiv.org:2507.12445v1</guid>
      <category>cs.NI</category>
      <category>cs.AR</category>
      <category>cs.DC</category>
      <pubDate>Thu, 17 Jul 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Soheil Mahdizadeh, Amir Mahdi Rasouli, Mohammad Pourashory, Sadra Galavani, Mohsen Ansari</dc:creator>
    </item>
    <item>
      <title>ZKP-FedEval: Verifiable and Privacy-Preserving Federated Evaluation using Zero-Knowledge Proofs</title>
      <link>https://arxiv.org/abs/2507.11649</link>
      <description>arXiv:2507.11649v1 Announce Type: cross 
Abstract: Federated Learning (FL) enables collaborative model training on decentralized data without exposing raw data. However, the evaluation phase in FL may leak sensitive information through shared performance metrics. In this paper, we propose a novel protocol that incorporates Zero-Knowledge Proofs (ZKPs) to enable privacy-preserving and verifiable evaluation for FL. Instead of revealing raw loss values, clients generate a succinct proof asserting that their local loss is below a predefined threshold. Our approach is implemented without reliance on external APIs, using self-contained modules for federated learning simulation, ZKP circuit design, and experimental evaluation on both the MNIST and Human Activity Recognition (HAR) datasets. We focus on a threshold-based proof for a simple Convolutional Neural Network (CNN) model (for MNIST) and a multi-layer perceptron (MLP) model (for HAR), and evaluate the approach in terms of computational overhead, communication cost, and verifiability.</description>
      <guid isPermaLink="false">oai:arXiv.org:2507.11649v1</guid>
      <category>cs.LG</category>
      <category>cs.DC</category>
      <category>cs.NI</category>
      <pubDate>Thu, 17 Jul 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Daniel Commey, Benjamin Appiah, Griffith S. Klogo, Garth V. Crosby</dc:creator>
    </item>
    <item>
      <title>Extremal Testing for Network Software using LLMs</title>
      <link>https://arxiv.org/abs/2507.11898</link>
      <description>arXiv:2507.11898v1 Announce Type: cross 
Abstract: Physicists often manually consider extreme cases when testing a theory. In this paper, we show how to automate extremal testing of network software using LLMs in two steps: first, ask the LLM to generate input constraints (e.g., DNS name length limits); then ask the LLM to generate tests that violate the constraints. We demonstrate how easy this process is by generating extremal tests for HTTP, BGP and DNS implementations, each of which uncovered new bugs. We show how this methodology extends to centralized network software such as shortest path algorithms, and how LLMs can generate filtering code to reject extremal input. We propose using agentic AI to further automate extremal testing. LLM-generated extremal testing goes beyond an old technique in software testing called Boundary Value Analysis.</description>
      <guid isPermaLink="false">oai:arXiv.org:2507.11898v1</guid>
      <category>cs.SE</category>
      <category>cs.NI</category>
      <pubDate>Thu, 17 Jul 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Rathin Singha, Harry Qian, Srinath Saikrishnan, Tracy Zhao, Ryan Beckett, Siva Kesava Reddy Kakarla, George Varghese</dc:creator>
    </item>
    <item>
      <title>MOFCO: Mobility- and Migration-Aware Task Offloading in Three-Layer Fog Computing Environments</title>
      <link>https://arxiv.org/abs/2507.12028</link>
      <description>arXiv:2507.12028v1 Announce Type: cross 
Abstract: Task offloading in three-layer fog computing environments presents a critical challenge due to user equipment (UE) mobility, which frequently triggers costly service migrations and degrades overall system performance. This paper addresses this problem by proposing MOFCO, a novel Mobility- and Migration-aware Task Offloading algorithm for Fog Computing environments. The proposed method formulates task offloading and resource allocation as a Mixed-Integer Nonlinear Programming (MINLP) problem and employs a heuristic-aided evolutionary game theory approach to solve it efficiently. To evaluate MOFCO, we simulate mobile users using SUMO, providing realistic mobility patterns. Experimental results show that MOFCO reduces system cost, defined as a combination of latency and energy consumption, by an average of 19% and up to 43% in certain scenarios compared to state-of-the-art methods.</description>
      <guid isPermaLink="false">oai:arXiv.org:2507.12028v1</guid>
      <category>cs.AR</category>
      <category>cs.DC</category>
      <category>cs.NI</category>
      <pubDate>Thu, 17 Jul 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Soheil Mahdizadeh, Elyas Oustad, Mohsen Ansari</dc:creator>
    </item>
    <item>
      <title>Eywa: Automating Model Based Testing using LLMs</title>
      <link>https://arxiv.org/abs/2312.06875</link>
      <description>arXiv:2312.06875v2 Announce Type: replace 
Abstract: Model-based testing (MBT), whereby a model of the system under test is analyzed to generate high-coverage test cases, has been used to test protocol implementations. A key barrier to the use of MBT is the need for users to understand protocol RFCs in detail to create a compliant model. Our new approach to MBT uses LLMs to automatically build rich models of intended protocol behavior from knowledge embedded in RFCs, blogs, and other natural language sources. Our approach addresses key challenges with using LLMs, including hallucinations and their inability to monolithically generate complex protocol models. We realize our approach through a novel protocol testing framework Eywa,and demonstrate its effectiveness through extensive case studies of DNS and BGP and a smaller study of SMTP. Despite minimal user effort, applying Eywa enabled the discovery of 32 unique bugs across widely used DNS, BGP, and SMTP implementations, 15 of which were previously undiscovered despite extensive prior testing with manually crafted models.</description>
      <guid isPermaLink="false">oai:arXiv.org:2312.06875v2</guid>
      <category>cs.NI</category>
      <pubDate>Thu, 17 Jul 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Rajdeep Mondal, Rathin Singha, Todd Millstein, George Varghese, Ryan Beckett, Siva Kesava Reddy Kakarla</dc:creator>
    </item>
    <item>
      <title>An End-to-End Pipeline Perspective on Video Streaming in Best-Effort Networks: A Survey and Tutorial</title>
      <link>https://arxiv.org/abs/2403.05192</link>
      <description>arXiv:2403.05192v4 Announce Type: replace 
Abstract: Remaining a dominant force in Internet traffic, video streaming captivates end users, service providers, and researchers. This paper takes a pragmatic approach to reviewing recent advances in the field by focusing on the prevalent streaming paradigm that involves delivering long-form two-dimensional videos over the best-effort Internet with client-side adaptive bitrate (ABR) algorithms and assistance from content delivery networks (CDNs). To enhance accessibility, we supplement the survey with tutorial material. Unlike existing surveys that offer fragmented views, our work provides a holistic perspective on the entire end-to-end streaming pipeline, from video capture by a camera-equipped device to playback by the end user. Our novel perspective covers the ingestion, processing, and distribution stages of the pipeline and addresses key challenges such as video compression, upload, transcoding, ABR algorithms, CDN support, and quality of experience. We review over 200 papers and classify streaming designs by their problem-solving methodology, whether based on intuition (simple heuristics), theory (formal optimization), or machine learning (generalizable data patterns). The survey further refines these methodology-based categories and characterizes each design by additional traits such as compatible codecs and use of super resolution. We connect the reviewed research to real-world applications by discussing the practices of commercial streaming platforms. Finally, the survey highlights prominent current trends and outlines future directions in video streaming.</description>
      <guid isPermaLink="false">oai:arXiv.org:2403.05192v4</guid>
      <category>cs.NI</category>
      <category>cs.MM</category>
      <pubDate>Thu, 17 Jul 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <arxiv:DOI>10.1145/3742472</arxiv:DOI>
      <arxiv:journal_reference>ACM Comput. Surv. 57, 12, Article 322 (December 2025), 47 pages</arxiv:journal_reference>
      <dc:creator>Leonardo Peroni, Sergey Gorinsky</dc:creator>
    </item>
    <item>
      <title>Energy-Efficient and Intelligent ISAC in V2X Networks with Spiking Neural Networks-Driven DRL</title>
      <link>https://arxiv.org/abs/2501.01038</link>
      <description>arXiv:2501.01038v2 Announce Type: replace 
Abstract: Integrated sensing and communication (ISAC) is emerging as a key enabler for vehicle-to-everything (V2X) systems. However, designing efficient beamforming schemes for ISAC signals to achieve accurate sensing and enhance communication performance in the dynamic and uncertain environments of V2X networks presents significant challenges. While artificial intelligence technologies offer promising solutions, the energy-intensive nature of neural networks imposes substantial burdens on communication infrastructures. To address these challenges, this work proposes an energy-efficient and intelligent ISAC system for V2X networks. Specifically, we first leverage a Markov Decision Process framework to model the dynamic and uncertain nature of V2X networks. This framework allows the roadside unit to develop beamforming schemes relying solely on its current sensing information, eliminating the need for numerous pilot signals and extensive CSI acquisition. We then introduce an advanced deep reinforcement learning (DRL) algorithm, enabling the joint optimization of beamforming and power allocation to guarantee both communication rate and sensing accuracy in dynamic and uncertain V2X scenario. To alleviate the energy demands of neural networks, we integrate spiking neural networks (SNNs) into the DRL algorithm. The event-driven, sparse spike-based processing of SNNs significantly improves energy efficiency while maintaining strong performance. Extensive simulation results validate the effectiveness of the proposed scheme with lower energy consumption, superior communication performance, and improved sensing accuracy.</description>
      <guid isPermaLink="false">oai:arXiv.org:2501.01038v2</guid>
      <category>cs.NI</category>
      <category>eess.SP</category>
      <pubDate>Thu, 17 Jul 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Chen Shang, Jiadong Yu, Dinh Thai Hoang</dc:creator>
    </item>
    <item>
      <title>Generative Artificial Intelligence for Beamforming in Low-Altitude Economy</title>
      <link>https://arxiv.org/abs/2504.15079</link>
      <description>arXiv:2504.15079v2 Announce Type: replace 
Abstract: The growth of low-altitude economy (LAE) has driven a rising demand for efficient and secure communication. However, conventional beamforming optimization techniques struggle in the complex LAE environments. In this context, generative artificial intelligence (GenAI) methods provide a promising solution. In this article, we first introduce the core concepts of LAE and the roles of beamforming in advanced communication technologies for LAE. We then examine their interrelation, followed by an analysis of the limitations of conventional beamforming methods. Next, we provide an overview of how GenAI methods enhance the process of beamforming, with a focus on its applications in LAE. Furthermore, we present a case study using a generative diffusion model (GDM)-based algorithm to enhance the performance of aerial collaborative beamforming-enabled remote secure communications in LAE and simulation results verified the effectiveness of the proposed algorithms. Finally, promising research opportunities are identified.</description>
      <guid isPermaLink="false">oai:arXiv.org:2504.15079v2</guid>
      <category>cs.NI</category>
      <pubDate>Thu, 17 Jul 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Geng Sun, Jia Qi, Chuang Zhang, Xuejie Liu, Jiacheng Wang, Dusit Niyato, Yuanwei Liu, Dong In Kim</dc:creator>
    </item>
    <item>
      <title>Qualitative Assessment of Low Power Wide Area Network Protocols and their Security Aspect</title>
      <link>https://arxiv.org/abs/2507.08677</link>
      <description>arXiv:2507.08677v2 Announce Type: replace 
Abstract: There are currently many communication options in the Internet of Things, even in particular areas such as constrained and battery-powered devices, such as Low Power Wide Area Networks. Understanding the differences and characteristics of each option is a challenge, even for professionals and researchers in the field. To meet this need, this work analyses the qualitative characteristics of Low Power Wide Area Network protocols and the challenges and opportunities of using constrained devices for sparse networks based on long-life batteries. For this study, a bibliographic survey of the literature was carried out as an analysis of three protocols (LoRaWAN, NB-IoT, and Sigfox), and a detailing of the first one. As a result, there is a discussion about the chosen network protocol and its use in IoT solutions with sparse sensors.</description>
      <guid isPermaLink="false">oai:arXiv.org:2507.08677v2</guid>
      <category>cs.NI</category>
      <pubDate>Thu, 17 Jul 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <dc:creator>Wesley dos Reis Bezerra, Lais Machado Bezerra, Carlos Becker Westphall</dc:creator>
    </item>
  </channel>
</rss>
