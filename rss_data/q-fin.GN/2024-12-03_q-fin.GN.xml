<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>q-fin.GN updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/q-fin.GN</link>
    <description>q-fin.GN updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/q-fin.GN" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Wed, 04 Dec 2024 02:54:51 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Tue, 03 Dec 2024 00:00:00 -0500</pubDate>
    <skipDays>
      <day>Sunday</day>
      <day>Saturday</day>
    </skipDays>
    <item>
      <title>The Promise and Peril of Generative AI: Evidence from GPT-4 as Sell-Side Analysts</title>
      <link>https://arxiv.org/abs/2412.01069</link>
      <description>arXiv:2412.01069v1 Announce Type: new 
Abstract: We investigate how advanced large language models (LLMs), specifically GPT-4, process corporate disclosures to forecast earnings. Using earnings press releases issued around GPT-4's knowledge cutoff date, we address two questions: (1) Do GPT-generated earnings forecasts outperform analysts in accuracy? (2) How is GPT's performance related to its processing of textual and quantitative information? Our findings suggest that GPT forecasts are significantly less accurate than those of analysts. This underperformance can be traced to GPT's distinct textual and quantitative approaches: its textual processing follows a consistent, generalized pattern across firms, highlighting its strengths in language tasks. In contrast, its quantitative processing capabilities vary significantly across firms, revealing limitations tied to the uneven availability of domain-specific training data. Additionally, there is some evidence that GPT's forecast accuracy diminishes beyond its knowledge cutoff, underscoring the need to evaluate LLMs under hindsight-free conditions. Overall, this study provides a novel exploration of the "black box" of GPT-4's information processing, offering insights into LLMs' potential and challenges in financial applications.</description>
      <guid isPermaLink="false">oai:arXiv.org:2412.01069v1</guid>
      <category>q-fin.GN</category>
      <category>econ.GN</category>
      <category>q-fin.EC</category>
      <pubDate>Tue, 03 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Edward Li, Zhiyuan Tu, Dexin Zhou</dc:creator>
    </item>
    <item>
      <title>Geometric insights into robust portfolio construction</title>
      <link>https://arxiv.org/abs/2107.06194</link>
      <description>arXiv:2107.06194v5 Announce Type: replace-cross 
Abstract: We investigate and extend the result that an alpha-weight angle from unconstrained quadratic portfolio optimisations has an upper bound dependent on the condition number of the covariance matrix. This is known to imply that better conditioned covariance matrices produce weights from unconstrained mean-variance optimisations that are better aligned with each assets expected return. Here we relate the inequality between the alpha-weight angle and the condition number to extend the result to include portfolio optimisations with gearing constraints to provide an extended family of robust optimisations. We use this to argue that in general the equally weighted portfolio is not preferable to the mean-variance portfolio even with poor forecast ability and a badly conditioned covariance matrix. We confirm the distribution free theoretical arguments with a simple Gaussian simulation.</description>
      <guid isPermaLink="false">oai:arXiv.org:2107.06194v5</guid>
      <category>q-fin.PM</category>
      <category>math.OC</category>
      <category>q-fin.GN</category>
      <pubDate>Tue, 03 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <arxiv:DOI>10.1142/S0219024924500249</arxiv:DOI>
      <arxiv:journal_reference>International Journal of Theoretical and Applied Finance, 2024</arxiv:journal_reference>
      <dc:creator>Lara Dalmeyer, Tim Gebbie</dc:creator>
    </item>
  </channel>
</rss>
