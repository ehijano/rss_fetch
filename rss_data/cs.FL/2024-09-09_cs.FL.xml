<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>cs.FL updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/cs.FL</link>
    <description>cs.FL updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/cs.FL" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Tue, 10 Sep 2024 02:49:20 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Mon, 09 Sep 2024 00:00:00 -0400</pubDate>
    <skipDays>
      <day>Saturday</day>
      <day>Sunday</day>
    </skipDays>
    <item>
      <title>Introducing Divergence for Infinite Probabilistic Models</title>
      <link>https://arxiv.org/abs/2308.08842</link>
      <description>arXiv:2308.08842v5 Announce Type: replace 
Abstract: Computing the reachability probability in infinite state probabilistic models has been the topic of numerous works. Here we introduce a new property called divergence that when satisfied allows to compute reachability probabilities up to an arbitrary precision. One of the main interest of divergence is that this computation does not require the reachability problem to be decidable. Then we study the decidability of divergence for random walks and the probabilistic versions of Petri nets where the weights associated with transitions may also depend on the current state. This should be contrasted with most of the existing works that assume weights independent of the state. Such an extended framework is motivated by the modeling of real case studies. Moreover, we exhibit some subclasses of channel systems and pushdown automata that are divergent by construction, particularly suited for specifying open distributed systems and networks prone to performance collapsing where probabilities related to service requirements are needed. where probabilities related to service requirements are needed.</description>
      <guid isPermaLink="false">oai:arXiv.org:2308.08842v5</guid>
      <category>cs.FL</category>
      <pubDate>Mon, 09 Sep 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Alain Finkel, Serge Haddad, Lina Ye</dc:creator>
    </item>
    <item>
      <title>Relating Reversible Petri Nets and Reversible Event Structures, categorically</title>
      <link>https://arxiv.org/abs/2302.14195</link>
      <description>arXiv:2302.14195v3 Announce Type: replace-cross 
Abstract: Causal nets (CNs) are Petri nets where causal dependencies are modelled via inhibitor arcs. They play the role of occurrence nets when representing the behaviour of a concurrent and distributed system, even when reversibility is considered. In this paper we extend CNs to account also for asymmetric conflicts and study (i) how this kind of nets, and their reversible versions, can be turned into a category; and (ii) their relation with the categories of reversible asymmetric event structures.</description>
      <guid isPermaLink="false">oai:arXiv.org:2302.14195v3</guid>
      <category>cs.LO</category>
      <category>cs.FL</category>
      <pubDate>Mon, 09 Sep 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Hern\'an Melgratti, Claudio Antares Mezzina, G. Michele Pinna</dc:creator>
    </item>
    <item>
      <title>The Transformation Logics</title>
      <link>https://arxiv.org/abs/2304.09639</link>
      <description>arXiv:2304.09639v3 Announce Type: replace-cross 
Abstract: We introduce a new family of temporal logics designed to finely balance the trade-off between expressivity and complexity. Their key feature is the possibility of defining operators of a new kind that we call transformation operators. Some of them subsume existing temporal operators, while others are entirely novel. Of particular interest are transformation operators based on semigroups. They enable logics to harness the richness of semigroup theory, and we show them to yield logics capable of creating hierarchies of increasing expressivity and complexity which are non-trivial to characterise in existing logics. The result is a genuinely novel and yet unexplored landscape of temporal logics, each of them with the potential of matching the trade-off between expressivity and complexity required by specific applications.</description>
      <guid isPermaLink="false">oai:arXiv.org:2304.09639v3</guid>
      <category>cs.LO</category>
      <category>cs.AI</category>
      <category>cs.FL</category>
      <pubDate>Mon, 09 Sep 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Alessandro Ronca</dc:creator>
    </item>
    <item>
      <title>On The Expressivity of Recurrent Neural Cascades</title>
      <link>https://arxiv.org/abs/2312.09048</link>
      <description>arXiv:2312.09048v2 Announce Type: replace-cross 
Abstract: Recurrent Neural Cascades (RNCs) are the recurrent neural networks with no cyclic dependencies among recurrent neurons. This class of recurrent networks has received a lot of attention in practice. Besides training methods for a fixed architecture such as backpropagation, the cascade architecture naturally allows for constructive learning methods, where recurrent nodes are added incrementally one at a time, often yielding smaller networks. Furthermore, acyclicity amounts to a structural prior that even for the same number of neurons yields a more favourable sample complexity compared to a fully-connected architecture. A central question is whether the advantages of the cascade architecture come at the cost of a reduced expressivity. We provide new insights into this question. We show that the regular languages captured by RNCs with sign and tanh activation with positive recurrent weights are the star-free regular languages. In order to establish our results we developed a novel framework where capabilities of RNCs are accessed by analysing which semigroups and groups a single neuron is able to implement. A notable implication of our framework is that RNCs can achieve the expressivity of all regular languages by introducing neurons that can implement groups.</description>
      <guid isPermaLink="false">oai:arXiv.org:2312.09048v2</guid>
      <category>cs.LG</category>
      <category>cs.FL</category>
      <category>cs.NE</category>
      <pubDate>Mon, 09 Sep 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Nadezda Alexandrovna Knorozova, Alessandro Ronca</dc:creator>
    </item>
  </channel>
</rss>
