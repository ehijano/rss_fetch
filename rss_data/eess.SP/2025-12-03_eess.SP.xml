<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>eess.SP updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/eess.SP</link>
    <description>eess.SP updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/eess.SP" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Wed, 03 Dec 2025 05:00:06 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Wed, 03 Dec 2025 00:00:00 -0500</pubDate>
    <skipDays>
      <day>Sunday</day>
      <day>Saturday</day>
    </skipDays>
    <item>
      <title>DySTAN: Joint Modeling of Sedentary Activity and Social Context from Smartphone Sensors</title>
      <link>https://arxiv.org/abs/2512.02025</link>
      <description>arXiv:2512.02025v1 Announce Type: new 
Abstract: Accurately recognizing human context from smartphone sensor data remains a significant challenge, especially in sedentary settings where activities such as studying, attending lectures, relaxing, and eating exhibit highly similar inertial patterns. Furthermore, social context plays a critical role in understanding user behavior, yet is often overlooked in mobile sensing research. To address these gaps, we introduce LogMe, a mobile sensing application that passively collects smartphone sensor data (accelerometer, gyroscope, magnetometer, and rotation vector) and prompts users for hourly self-reports capturing both sedentary activity and social context. Using this dual-label dataset, we propose DySTAN (Dynamic Cross-Stitch with Task Attention Network), a multi-task learning framework that jointly classifies both context dimensions from shared sensor inputs. It integrates task-specific layers with cross-task attention to model subtle distinctions effectively. DySTAN improves sedentary activity macro F1 scores by 21.8% over a single-task CNN-BiLSTM-GRU (CBG) model and by 8.2% over the strongest multi-task baseline, Sluice Network (SN). These results demonstrate the importance of modeling multiple, co-occurring context dimensions to improve the accuracy and robustness of mobile context recognition.</description>
      <guid isPermaLink="false">oai:arXiv.org:2512.02025v1</guid>
      <category>eess.SP</category>
      <category>cs.AI</category>
      <category>cs.HC</category>
      <category>cs.LG</category>
      <pubDate>Wed, 03 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Aditya Sneh, Nilesh Kumar Sahu, Snehil Gupta, Haroon R. Lone</dc:creator>
    </item>
    <item>
      <title>Towards Sustainable Precision: Machine Learning for Laser Micromachining Optimization</title>
      <link>https://arxiv.org/abs/2512.02026</link>
      <description>arXiv:2512.02026v1 Announce Type: new 
Abstract: In the pursuit of sustainable manufacturing, ultra-short pulse laser micromachining stands out as a promising solution while also offering high-precision and qualitative laser processing. However, unlocking the full potential of ultra-short pulse lasers requires an optimized monitoring system capable of early detection of defective workpieces, regardless of the preprocessing technique employed. While advances in machine learning can help predict process quality features, the complexity of monitoring data necessitates reducing both model size and data dimensionality to enable real-time analysis. To address these challenges, this paper introduces a machine learning framework designed to enhance surface quality assessment across diverse preprocessing techniques. To facilitate real-time laser processing monitoring, our solution aims to optimize the computational requirements of the machine learning model. Experimental results show that the proposed model not only outperforms the generalizability achieved by previous works across diverse preprocessing techniques but also significantly reduces the computational requirements for training. Through these advancements, we aim to establish the baseline for a more sustainable manufacturing process.</description>
      <guid isPermaLink="false">oai:arXiv.org:2512.02026v1</guid>
      <category>eess.SP</category>
      <category>cs.AI</category>
      <pubDate>Wed, 03 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-sa/4.0/</dc:rights>
      <arxiv:DOI>10.1007/978-3-031-77731-8_4</arxiv:DOI>
      <arxiv:journal_reference>Intelligent Data Engineering and Automated Learning (IDEAL 2024), LNCS 15346, pp. 40-50, 2025</arxiv:journal_reference>
      <dc:creator>Luis Correas-Naranjo, Miguel Camacho-S\'anchez, La\"etitia Launet, Milena Zuric, Valery Naranjo</dc:creator>
    </item>
    <item>
      <title>Seizure-NGCLNet: Representation Learning of SEEG Spatial Pathological Patterns for Epileptic Seizure Detection via Node-Graph Dual Contrastive Learning</title>
      <link>https://arxiv.org/abs/2512.02028</link>
      <description>arXiv:2512.02028v1 Announce Type: new 
Abstract: Complex spatial connectivity patterns, such as interictal suppression and ictal propagation, complicate accurate drug-resistant epilepsy (DRE) seizure detection using stereotactic electroencephalography (SEEG) and traditional machine learning methods. Two critical challenges remain:(1)a low signal-to-noise ratio in functional connectivity estimates, making it difficult to learn seizure-related interactions; and (2)expert labels for spatial pathological connectivity patterns are difficult to obtain, meanwhile lacking the patterns' representation to improve seizure detection. To address these issues, we propose a novel node-graph dual contrastive learning framework, Seizure-NGCLNet, to learn SEEG interictal suppression and ictal propagation patterns for detecting DRE seizures with high precision. First, an adaptive graph augmentation strategy guided by centrality metrics is developed to generate seizure-related brain networks. Second, a dual-contrastive learning approach is integrated, combining global graph-level contrast with local node-graph contrast, to encode both spatial structural and semantic epileptogenic features. Third, the pretrained embeddings are fine-tuned via a top-k localized graph attention network to perform the final classification. Extensive experiments on a large-scale public SEEG dataset from 33 DRE patients demonstrate that Seizure-NGCLNet achieves state-of-the-art performance, with an average accuracy of 95.93%, sensitivity of 96.25%, and specificity of 94.12%. Visualizations confirm that the learned embeddings clearly separate ictal from interictal states, reflecting suppression and propagation patterns that correspond to the clinical mechanisms. These results highlight Seizure-NGCLNet's ability to learn interpretable spatial pathological patterns, enhancing both seizure detection and seizure onset zone localization.</description>
      <guid isPermaLink="false">oai:arXiv.org:2512.02028v1</guid>
      <category>eess.SP</category>
      <category>cs.LG</category>
      <category>q-bio.NC</category>
      <pubDate>Wed, 03 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Yiping Wang, Peiren Wang, Zhenye Li, Fang Liu, Jinguo Huang</dc:creator>
    </item>
    <item>
      <title>Hardware Distortion Aware Precoding for ISAC Systems</title>
      <link>https://arxiv.org/abs/2512.02153</link>
      <description>arXiv:2512.02153v1 Announce Type: new 
Abstract: The impact of hardware impairments on the spectral efficiency of communication systems is well studied, but their effect on sensing performance remains unexplored. In this paper, we analyze the influence of hardware impairments on integrated sensing and communication (ISAC) systems in cluttered environments. We derive the sensing signal-to-clutter-plus-noise ratio (SCNR) and show that hardware distortions significantly degrade sensing performance by enhancing clutter-induced noise, which masks target echoes. The isotropic nature of transmit distortion due to multiple stream transmission further complicates clutter suppression. To address this, we propose a distortion- and clutter-aware precoding strategy that minimizes the deviation from the communication-optimized precoder while improving sensing robustness. We also propose an alternative power allocation-based approach that reduces computational complexity. Numerical results confirm the effectiveness of the proposed approaches in overcoming hardware- and clutter-induced limitations, demonstrating significant performance gains over distortion-unaware designs.</description>
      <guid isPermaLink="false">oai:arXiv.org:2512.02153v1</guid>
      <category>eess.SP</category>
      <category>cs.IT</category>
      <category>math.IT</category>
      <pubDate>Wed, 03 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Murat Babek Salman, Emil Bj\"ornson, \"Ozlem Tugfe Demir</dc:creator>
    </item>
    <item>
      <title>Wavenumber-Division Multiplexing in Holographic MIMO with NLoS Channels</title>
      <link>https://arxiv.org/abs/2512.02245</link>
      <description>arXiv:2512.02245v1 Announce Type: new 
Abstract: Wavenumber-division multiplexing (WDM) was introduced as a counterpart of orthogonal frequency-division multiplexing in the spatial-frequency domain for line-of-sight holographic multiple-input multiple-output (MIMO) systems. In this paper, we extend WDM to holographic MIMO channels with non-line-of-sight (NLoS) propagation. We show that applying WDM to the NLoS channel yields the corresponding angular-domain representation, which we characterize through the power spectral factor and power spectral density. We further obtain a closed-form characterization for the case of isotropic scattering, recovering Jakes' isotropic model. The analysis is complemented by numerical results evaluating the degrees of freedom and ergodic capacity under both isotropic and non-isotropic scattering.</description>
      <guid isPermaLink="false">oai:arXiv.org:2512.02245v1</guid>
      <category>eess.SP</category>
      <pubDate>Wed, 03 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Ashutosh Prajapati, Prathapasinghe Dharmawansa, Marco Di Renzo, Italo Atzeni</dc:creator>
    </item>
    <item>
      <title>Bayesian Probability Fusion for Multi-AP Collaborative Sensing in Mobile Networks</title>
      <link>https://arxiv.org/abs/2512.02462</link>
      <description>arXiv:2512.02462v1 Announce Type: new 
Abstract: Integrated sensing and communication is widely acknowledged as a foundational technology for next-generation mobile networks. Compared with monostatic sensing, multi-access point (AP) collaborative sensing endows mobile networks with broader, more accurate, and resilient sensing capabilities, which are critical for diverse location-based sectors. This paper focuses on collaborative sensing in multi-AP networks and proposes a Bayesian probability fusion framework for target parameter estimation using orthogonal frequency-division multiplexing waveform. The framework models multi-AP received signals as probability distributions to capture stochastic observations from channel noise and scattering coefficients. Prior information is then incorporated into the joint probability density function to cast the problem as a constrained maximum a posteriori estimation. To address the high-dimensional optimization, we develop a prior-constrained gradient ascent (PCGA) algorithm that decouples correlated parameters and performs efficient gradient updates guided by the target prior. Theoretical analysis covers optimal fusion weights for global signal-to-noise ratio maximization, PCGA convergence, and the Cramer-Rao lower bound of the estimator, with insights applicable to broader fusion schemes. Extensive numerical simulations and real-world experiments with commercial devices show the framework reduces transmission overhead by 90% versus signal fusion and lowers estimation error by 41% relative to parameter fusion. Notably, field tests achieve submeter accuracy with 50% probability in typical coverage of mmWave APs. These improvements highlight a favorable balance between communication efficiency and estimation accuracy for practical multi-AP sensing deployment.
  The dataset is released for research purposes and is publicly available at: http://pmldatanet.com.cn/dataapp/multimodal</description>
      <guid isPermaLink="false">oai:arXiv.org:2512.02462v1</guid>
      <category>eess.SP</category>
      <pubDate>Wed, 03 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Shengheng Liu, Xingkang Li, Yongming Huang, Yuan Fang, Qingji Jiang, Dazhuan Xu, Ziguo Zhong, Dongming Wang, Xiaohu You</dc:creator>
    </item>
    <item>
      <title>Channel Knowledge Map Enabled Low-Altitude ISAC Networks: Joint Air Corridor Planning and Base Station Deployment</title>
      <link>https://arxiv.org/abs/2512.02464</link>
      <description>arXiv:2512.02464v1 Announce Type: new 
Abstract: This letter addresses the joint air corridor planning and base station (BS) deployment problem for low-altitude integrated sensing and communication (ISAC) networks. In the considered system, unmanned aerial vehicles (UAVs) operate within a structured air corridor composed of connected cubic segments, and multiple BSs need to be selectively deployed at a set of candidate locations to ensure both sensing and communication coverage throughout the corridor. In particular, we leverage the channel knowledge map (CKM) to characterize wireless channels for candidate BS sites prior to deployment, thereby facilitating the offline planning. Under this setup, we minimize the system cost in terms of the weighted sum of the air corridor length and the number of deployed BSs, subject to the constraints on both sensing and communication performance across the corridor. To solve the formulated large-scale nonconvex integer programming problem, we develop a hierarchical coarse-to-fine grid decomposition algorithm. Simulation results demonstrate the benefit of the proposed joint design in reducing the overall deployment cost while ensuring the coverage of the low-altitude ISAC networks.</description>
      <guid isPermaLink="false">oai:arXiv.org:2512.02464v1</guid>
      <category>eess.SP</category>
      <pubDate>Wed, 03 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Jiaxuan Li, Yilong Chen, Fan Liu, Jie Xu</dc:creator>
    </item>
    <item>
      <title>Cell-free versus Conventional Massive MIMO : An Analysis of Channel Capacity based on Channel Measurement in the FR3 Band</title>
      <link>https://arxiv.org/abs/2512.02501</link>
      <description>arXiv:2512.02501v1 Announce Type: new 
Abstract: Cell-free massive MIMO (CF-mMIMO) has emerged as a promising technology for next generation wireless systems, combining the benefits of distributed antenna systems (DAS) and traditional MIMO technology. In this work, we present the first extensive channel measurements for CF-mMIMO in the mid-band (FR3, 6-24 GHz), using a virtual widely distributed antenna array comprising 512 elements in the urban Macrocell (UMa) environment. Based on the measurement data, this paper compares the channel capacity of CF-mMIMO and Conventional mMIMO under both line-of-sight (LOS) and non-line-of-sight (NLOS) conditions across a range of signal-to-noise ratios (SNRs). We then analyze how channel capacity varies with Rx positions from the perspectives of the full array and of individual subarrays. Finally, we conclude that the 64-element array configuration yields the greatest advantage in channel capacity for CF-mMIMO in the measurement environment considered, with gains of 14.02\% under LOS and 24.61\% under NLOS conditions. This in-depth analysis of channel capacity in the FR3 band provides critical insights for optimizing CF-mMIMO systems in next generation wireless networks.</description>
      <guid isPermaLink="false">oai:arXiv.org:2512.02501v1</guid>
      <category>eess.SP</category>
      <pubDate>Wed, 03 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Qi Zhen, Pan Tang, Haiyang Miao, Enrui Liu, Ximan Liu, Zihang Ding, Jianhua Zhang</dc:creator>
    </item>
    <item>
      <title>Deep Learning-Based Joint Uplink-Downlink CSI Acquisition for Next-Generation Upper Mid-Band Systems</title>
      <link>https://arxiv.org/abs/2512.02557</link>
      <description>arXiv:2512.02557v1 Announce Type: new 
Abstract: In next-generation wireless communication systems, the newly designated upper mid-band has attracted considerable attention, also called frequency range 3 (FR3), highlighting the need for downlink (DL) transmission design, which fundamentally relies on accurate CSI. However, CSI acquisition in FR3 systems faces significant challenges: the increased number of antennas and wider transmission bandwidth introduces prohibitive training overhead with traditional estimation approaches, as each probing captures only incomplete spatial-frequency observation, while higher carrier frequencies lead to faster temporal channel variation. To address these challenges, we propose a novel CSI acquisition framework that integrates CSI feedback, uplink (UL) and DL channel estimation, as well as channel prediction in the FR3 TDD massive MIMO systems. Specifically, we first develop the Joint UL and DL Channel Estimation Network (JUDCEN) to fuse incomplete observations based on the SRSs and CSI-RSs. By exploiting the complementary characteristics of preliminary UL and DL estimation features, obtained through initial UL estimation and quantized-feedback-assisted DL estimation, it enables full CSI reconstruction in the spatial domain. To mitigate the performance degradation in the feedback process, we propose the Transformer-MLP CSI Feedback Network (TMCFN), employing an MLP-based module to jointly exploit angle- and delay-domain features. Building upon the reconstructed full CSI, we further develop the Mamba-based Channel Prediction Network (MCPN), which exploits selective state-space model (SSM) mechanism to capture long-range temporal dynamics in the angle-delay domain for future CSI prediction. Simulation results demonstrate that the proposed framework consistently outperforms benchmarks in both CSI acquisition accuracy and transmission spectral efficiency with lower computational complexity.</description>
      <guid isPermaLink="false">oai:arXiv.org:2512.02557v1</guid>
      <category>eess.SP</category>
      <pubDate>Wed, 03 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Xuan He, Hongwei Hou, Yafei Wang, Wenjin Wang, Shi Jin, Symeon Chatzinotas, Bj\"orn Ottersten</dc:creator>
    </item>
    <item>
      <title>Predictive Beamforming in Low-Altitude Wireless Networks: A Cross-Attention Approach</title>
      <link>https://arxiv.org/abs/2512.02563</link>
      <description>arXiv:2512.02563v1 Announce Type: new 
Abstract: Accurate beam prediction is essential for maintaining reliable links and high spectral efficiency in dynamic low-altitude wireless networks. However, existing approaches often fail to capture the deep correlations across heterogeneous sensing modalities, limiting their adaptability in complex three-dimensional environments. To overcome these challenges, we propose a multi-modal predictive beamforming method based on a cross-attention fusion mechanism that jointly leverages visual and structured sensor data. The proposed model utilizes a Convolutional Neural Network (CNN) to learn multi-scale spatial feature hierarchies from visual images and a Transformer encoder to capture cross-dimensional dependencies within sensor data. Then, a cross-attention fusion module is introduced to integrate complementary information between the two modalities, generating a unified and discriminative representation for accurate beam prediction. Through experimental evaluations conducted on a real-world dataset, our method reaches 79.7% Top-1 accuracy and 99.3% Top-3 accuracy, surpassing the 3D ResNet-Transformer baseline by 4.4%-23.2% across Top-1 to Top-5 metrics. These results verify that multi-modal cross-attention fusion is effective for intelligent beam selection in dynamic low-altitude wireless networks.</description>
      <guid isPermaLink="false">oai:arXiv.org:2512.02563v1</guid>
      <category>eess.SP</category>
      <pubDate>Wed, 03 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Xiaotong Zhao, Yuanhao Cui, Weijie Yuan, Ziye Jia, Heng Liu, Chengwen Xing</dc:creator>
    </item>
    <item>
      <title>Zero-Forcing MU-MIMO Precoding under Power Amplifier Non-Linearities</title>
      <link>https://arxiv.org/abs/2512.02573</link>
      <description>arXiv:2512.02573v1 Announce Type: new 
Abstract: In multi-user multiple-input multiple-output (MU-MIMO) systems, the non-linear behavior of the power amplifiers (PAs) may cause degradation of the linear precoding schemes dealing with interference between user equipments (UEs), e.g., the zero-forcing (ZF) precoder. One way to minimize this effect is to use digital-pre-distortion (DPD) modules to linearize the PAs. However, using perfect DPD modules is costly and it may incur significant power consumption. As an alternative, we consider the problem of characterizing non-linearity-aware ZF (NLA-ZF) precoding schemes, hereby defined as linear precoders that achieve perfect interference cancellation in the presence of PA non-linearity by exploiting knowledge of this non-linear response. We provide initial iterative solutions that allow achieving NLA-ZF (up to adjustable tolerance) in a two-UE downlink MU-MIMO scenario where the base station (BS) has an even number of antennas, and each antenna is connected to a PA exhibiting third-order memory-less non-linear behavior. The proposed approach allows for performance gains in scenarios with significant residual interference.</description>
      <guid isPermaLink="false">oai:arXiv.org:2512.02573v1</guid>
      <category>eess.SP</category>
      <category>cs.IT</category>
      <category>math.IT</category>
      <pubDate>Wed, 03 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Juan Vidal Alegr\'ia, Ashkan Sheikhi, Ove Edfors</dc:creator>
    </item>
    <item>
      <title>Joint Beamforming and Matching for Ultra-Dense Massive Antenna Arrays</title>
      <link>https://arxiv.org/abs/2512.02628</link>
      <description>arXiv:2512.02628v1 Announce Type: new 
Abstract: Massive multiple-input multiple-output (MIMO) offers substantial spectral-efficiency gains, but scaling to very large antenna arrays with conventional all-digital and hybrid beamforming architectures quickly results in excessively high costs and power consumption. Low-cost, switch-based architectures have recently emerged as a potential alternative. However, prior studies rely on simplified models that ignore (among others) antenna coupling, radiation patterns, and matching losses, resulting in inaccurate performance predictions. In this paper, we use a physically consistent electromagnetic modeling framework to analyze an ultra-dense patch-antenna array architecture that performs joint beamforming and matching using networks of inexpensive RF switches. Our results demonstrate that simple, switch-based beamforming architectures can approach the antenna-gain of all-digital solutions at significantly lower cost and complexity.</description>
      <guid isPermaLink="false">oai:arXiv.org:2512.02628v1</guid>
      <category>eess.SP</category>
      <category>cs.IT</category>
      <category>math.IT</category>
      <pubDate>Wed, 03 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Carolina Nolasco-Ferencikova, Georg Schwan, Raphael Rolny, Alexander Stutz-Tirri, Christoph Studer</dc:creator>
    </item>
    <item>
      <title>G-PIFNN: A Generalizable Physics-informed Fourier Neural Network Framework for Electrical Circuits</title>
      <link>https://arxiv.org/abs/2512.02712</link>
      <description>arXiv:2512.02712v1 Announce Type: new 
Abstract: Physics-Informed Neural Networks (PINNs) have advanced the data-driven solution of differential equations (DEs) in dynamic physical systems, yet challenges remain in explainability, scalability, and architectural complexity. This paper presents a Generalizable Physics-Informed Fourier Neural Network (G-PIFNN) framework that enhances PINN architectures for efficient and interpretable electrical circuit analysis. The proposed G-PIFNN introduces three key advancements: (1) improved performance and interpretability via a physics activation function (PAF) and a lightweight Physics-Informed Fourier Neural Network (PIFNN) architecture; (2) automated, bond graph (BG) based formulation of physics-informed loss functions for systematic differential equation generation; and (3) integration of intra-circuit and cross-circuit class transfer learning (TL) strategies, enabling unsupervised fine-tuning for rapid adaptation to varying circuit topologies. Numerical simulations demonstrate that G-PIFNN achieves significantly better predictive performance and generalization across diverse circuit classes, while significantly reducing the number of trainable parameters compared to standard PINNs.</description>
      <guid isPermaLink="false">oai:arXiv.org:2512.02712v1</guid>
      <category>eess.SP</category>
      <pubDate>Wed, 03 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Ibrahim Shahbaz, Mohammad J. Abdel-Rahman, Eman Hammad</dc:creator>
    </item>
    <item>
      <title>Channel Knowledge Map Construction via Physics-Inspired Diffusion Model Without Prior Observations</title>
      <link>https://arxiv.org/abs/2512.02757</link>
      <description>arXiv:2512.02757v1 Announce Type: new 
Abstract: The ability to construct Channel Knowledge Map (CKM) with high precision is essential for environment awareness in 6G wireless systems. However, most existing CKM construction methods formulate the task as an image super-resolution or generation problem, thereby employing models originally developed for computer vision. As a result, the generated CKMs often fail to capture the underlying physical characteristics of wireless propagation. In this paper, we focus on the construction of CKM for large-scale fading scenarios and design three physics-based constraint terms to characterize the spatial distribution patterns of large-scale fading. By integrating these physical constraints with a state-of-the-art diffusion model that possesses superior generative capability, a physics-inspired diffusion model for CKM construction is proposed. Following this motivation, we derive the loss function of the diffusion model augmented with physics-based constraint terms and further design the training and generation framework for the proposed physics-inspired CKM generation diffusion model. Extensive experiments show that our approach outperforms all existing methods in terms of construction accuracy. Moreover, the proposed model provides a unified and effective framework with strong potential for generating diverse, accurate, and physically consistent CKM.</description>
      <guid isPermaLink="false">oai:arXiv.org:2512.02757v1</guid>
      <category>eess.SP</category>
      <pubDate>Wed, 03 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Yunzhe Zhu, Xuewen Liao, Zhenzhen Gao, Yong Zeng</dc:creator>
    </item>
    <item>
      <title>Effects of disease duration and antipsychotics on brain age in schizophrenia</title>
      <link>https://arxiv.org/abs/2512.02765</link>
      <description>arXiv:2512.02765v1 Announce Type: new 
Abstract: Accelerated brain aging has been consistently reported in patients with schizophrenia. Over the past decade, these findings have been replicated using the Brain Age paradigm, which applies machine learning techniques to estimate brain age from neuroimaging data. This approach yields a single index, the Brain Age Gap, defined as the difference between predicted and chronological age. Nevertheless, both the progressive nature of this phenomenon and the potential role of antipsychotic medication remain unclear. To investigate its progression, we compared the Brain Age Gap between individuals experiencing a first episode of psychosis and healthy controls using ANCOVA, adjusting for age, sex, body mass index, and estimated total intracranial volume. To enhance the robustness of our findings, we employed two distinct models: a transformer-inspired model based on harmonized volumetric brain features extracted with FastSurfer, and a previously trained deep learning model. To assess the potential effect of medication, we further compared bipolar patients who received antipsychotic treatment with those who did not. Mann-Whitney U test consistently showed that medicated bipolar patients did not exhibit a significantly larger Brain Age Gap. Both models converge on the conclusion that accelerated brain aging is unlikely to be explained by antipsychotic medication alone. Longitudinal studies are therefore required to clarify the temporal dynamics of brain aging in schizophrenia.</description>
      <guid isPermaLink="false">oai:arXiv.org:2512.02765v1</guid>
      <category>eess.SP</category>
      <pubDate>Wed, 03 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <arxiv:DOI>10.1016/j.schres.2025.11.008</arxiv:DOI>
      <arxiv:journal_reference>Schizophrenia Research, Volume 287, January 2026, Pages 82-90</arxiv:journal_reference>
      <dc:creator>Alejandro Roig-Herrero, Luis M. San-Jos\'e-Revuelta, Rafael Navarro-Gonz\'alez, Rodrigo de Luis-Garc\'ia, Vicente Molina</dc:creator>
    </item>
    <item>
      <title>Diffusion-Prior Split Gibbs Sampling for Synthetic Aperture Radar Imaging under Incomplete Measurements</title>
      <link>https://arxiv.org/abs/2512.02768</link>
      <description>arXiv:2512.02768v1 Announce Type: new 
Abstract: Synthetic aperture radar (SAR) imaging plays a critical role in all-weather, day-and-night remote sensing, yet reconstruction is often challenged by noise, undersampling, and complex scattering scenarios. Conventional methods, including matched filtering and sparsity-based compressed sensing, are limited in capturing intricate scene structures and frequently suffer from artifacts, elevated sidelobes, and loss of fine details. Recent diffusion models have demonstrated superior capability in representing high-order priors; however, existing diffusion-based SAR methods still yield degraded reconstructions due to oversimplified likelihood approximations in guided sampling. In this work, we propose a diffusion-driven split Gibbs sampling framework for SAR reconstruction, rigorously integrating measurement fidelity with learned diffusion priors. By alternately performing likelihood- and prior-driven updates via proximal sampling, this method ensures progressive convergence toward the true posterior while fully leveraging the expressive power of diffusion priors. Extensive experiments on simulated and Sentinel-1A datasets demonstrate substantial performance improvements: over 7 dB average PSNR gain in simulations, along with significant sidelobe suppression (MPLSR +2.96 dB, MISLR +11.5 dB) with respect to the best baseline result. On real-world Sentinel-1A data, the method achieves an average PSNR gain of 1.6 dB while effectively reducing artifacts and preserving scene details, including ridges, edges, and fine textures. These results underscore the potential of the adapted framework as a robust and generalizable solution for high-fidelity SAR imaging across diverse sensing scenarios.</description>
      <guid isPermaLink="false">oai:arXiv.org:2512.02768v1</guid>
      <category>eess.SP</category>
      <pubDate>Wed, 03 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Hefei Gao, Tianyao Huang, Letian Guo, Jie He, Yonina C. Eldar</dc:creator>
    </item>
    <item>
      <title>Low-Power Double RIS-Assisted Mobile LEO Satellite Communications</title>
      <link>https://arxiv.org/abs/2512.02255</link>
      <description>arXiv:2512.02255v1 Announce Type: cross 
Abstract: We propose a low-power mobile low earth orbit (LEO) satellite communication architecture, employing double reconfigurable intelligent surfaces (RIS) to enhance energy efficiency and signal performance. With a distance between RISs that satisfies the far-field requirement, this architecture positions one small RIS each in the near-field of the satellite's antenna and the user on the ground. Moreover, we develop a path loss model for the double-RIS communication link, considering the near-field and far-field effects. Further, with the help of dual-stage beamforming, the proposed system maximizes the signal power and minimizes power consumption. Simulation results show that the proposed architecture can reduce the power consumption with 40 dB in the uplink, with a small $0.25^2$ $\text{m}^2$ RIS near the user, to communicate in energy-constrained LEO satellite communication circumstances.</description>
      <guid isPermaLink="false">oai:arXiv.org:2512.02255v1</guid>
      <category>cs.IT</category>
      <category>eess.SP</category>
      <category>math.IT</category>
      <pubDate>Wed, 03 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <arxiv:DOI>10.1109/WCNC61545.2025.10978773</arxiv:DOI>
      <arxiv:journal_reference>2025 IEEE Wireless Communications and Networking Conference (WCNC)</arxiv:journal_reference>
      <dc:creator>Kunnathully Sadanandan Sanila, Rickard Nilsson, Emad Ibrahim, Neelakandan Rajamohan</dc:creator>
    </item>
    <item>
      <title>Adapting Tensor Kernel Machines to Enable Efficient Transfer Learning for Seizure Detection</title>
      <link>https://arxiv.org/abs/2512.02626</link>
      <description>arXiv:2512.02626v1 Announce Type: cross 
Abstract: Transfer learning aims to optimize performance in a target task by learning from a related source problem. In this work, we propose an efficient transfer learning method using a tensor kernel machine. Our method takes inspiration from the adaptive SVM and hence transfers 'knowledge' from the source to the 'adapted' model via regularization. The main advantage of using tensor kernel machines is that they leverage low-rank tensor networks to learn a compact non-linear model in the primal domain. This allows for a more efficient adaptation without adding more parameters to the model. To demonstrate the effectiveness of our approach, we apply the adaptive tensor kernel machine (Adapt-TKM) to seizure detection on behind-the-ear EEG. By personalizing patient-independent models with a small amount of patient-specific data, the patient-adapted model (which utilizes the Adapt-TKM), achieves better performance compared to the patient-independent and fully patient-specific models. Notably, it is able to do so while requiring around 100 times fewer parameters than the adaptive SVM model, leading to a correspondingly faster inference speed. This makes the Adapt-TKM especially useful for resource-constrained wearable devices.</description>
      <guid isPermaLink="false">oai:arXiv.org:2512.02626v1</guid>
      <category>cs.LG</category>
      <category>eess.SP</category>
      <pubDate>Wed, 03 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Seline J. S. de Rooij, Borb\'ala Hunyadi</dc:creator>
    </item>
    <item>
      <title>GNSS Array-Based Multipath Detection Employing UKF on Manifolds</title>
      <link>https://arxiv.org/abs/2512.02994</link>
      <description>arXiv:2512.02994v1 Announce Type: cross 
Abstract: Global Navigation Satellite Systems (GNSS) applications are often hindered by various sources of error, with multipath interference being one of the most challenging, particularly in urban environments. In this work, we build on previous research by implementing a GNSS array-based multipath detection algorithm, incorporating real-time attitude estimation for dynamic scenarios. The method fuses GNSS and IMU data using an Unscented Kalman Filter (UKF) on a manifold, enabling continuous attitude tracking. The proposed approach utilizes attitude information from satellite combinations to identify and exclude multipath-affected satellites, improving the accuracy of both positioning and attitude determination. To address computational challenges associated with evaluating large numbers of satellite combinations, we propose the use of the Random Sample Consensus (RANSAC) algorithm, which reduces the number of combinations assessed while maintaining high detection performance. Performance evaluations are conducted using trajectories and IMU readings from the KITTI dataset. GNSS observations are simulated based on ground truth positions and satellite ephemeris. The results demonstrate the effectiveness of the proposed approach in detecting satellites affected by multipath interference. Significant improvements in positioning accuracy are observed, particularly in scenarios where a large portion of the visible satellites are contaminated by severe multipath.</description>
      <guid isPermaLink="false">oai:arXiv.org:2512.02994v1</guid>
      <category>eess.SY</category>
      <category>cs.SY</category>
      <category>eess.SP</category>
      <pubDate>Wed, 03 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <arxiv:DOI>10.1109/PLANS61210.2025.11028455</arxiv:DOI>
      <dc:creator>Abdelgabar Ahmed, Tarig Ballal, Xing Liu, Mohanad Ahmed, Tareq Y. Al-Naffouri</dc:creator>
    </item>
    <item>
      <title>Energy-Efficient Multi-UAV-Enabled MEC Systems over Space-Air-Ground Integrated Networks</title>
      <link>https://arxiv.org/abs/2409.14782</link>
      <description>arXiv:2409.14782v3 Announce Type: replace 
Abstract: With the development of artificial intelligence integrated next-generation communication networks, mobile users (MUs) are increasingly demanding the efficient processing of computation-intensive and latency-sensitive tasks. However, existing mobile computing networks struggle to support the rapidly growing computational needs of the MUs. Fortunately, space-air-ground integrated network (SAGIN) supported mobile edge computing (MEC) is regarded as an effective solution, offering the MUs multi-tier and efficient computing services. In this paper, we consider an SAGIN supported MEC system, where a low Earth orbit satellite and multiple unmanned aerial vehicles (UAVs) are dispatched to provide computing services for MUs. An energy efficiency maximization problem is formulated, with the joint optimization of the MU-UAV association, the UAV trajectory, the task offloading decision, the computing frequency, and the transmission power control. Since the problem is non-convex, we decompose it into four subproblems, and propose an alternating optimization based algorithm to solve it. Simulation results confirm that the proposed algorithm outperforms the benchmarks.</description>
      <guid isPermaLink="false">oai:arXiv.org:2409.14782v3</guid>
      <category>eess.SP</category>
      <pubDate>Wed, 03 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Wenchao Liu, Xuhui Zhang, Chunjie Wang, Jinke Ren, Zheng Xing, Bo Yang, Shuqiang Wang, Yanyan Shen</dc:creator>
    </item>
    <item>
      <title>An Uncertainty Quantification Framework for Deep Learning-Based Automatic Modulation Classification</title>
      <link>https://arxiv.org/abs/2503.04142</link>
      <description>arXiv:2503.04142v2 Announce Type: replace 
Abstract: Deep learning has been shown to be highly effective for automatic modulation classification (AMC), which is a pivotal technology for next-generation cognitive communications. Yet, existing deep learning methods for AMC often lack robust mechanisms for uncertainty quantification (UQ). This limitation restricts their ability to produce accurate and reliable predictions in real-world environments, where signals can be perturbed as a result of several factors such as interference and low signal-to-noise ratios (SNR). To address this problem, we propose a deep ensemble approach that leverages multiple convolutional neural networks (CNNs) to generate predictive distributions, as opposed to point estimates produced by standard deep learning models, which produce statistical characteristics that quantify the uncertainty associated with each prediction. We validate our approach using real-world AMC data, evaluating performance through multiple UQ metrics in a variety of signal environments. Our results show that our proposed ensemble-based framework captures uncertainty to a greater degree compared to previously proposed baselines in multiple settings, including in-distribution samples, out-of-distribution samples, and low SNR signals. These findings highlight the strong UQ capabilities of our ensemble-based AMC approach, paving the way for more robust deep learning-based AMC.</description>
      <guid isPermaLink="false">oai:arXiv.org:2503.04142v2</guid>
      <category>eess.SP</category>
      <pubDate>Wed, 03 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/publicdomain/zero/1.0/</dc:rights>
      <dc:creator>Huian Yang, Rajeev Sahay</dc:creator>
    </item>
    <item>
      <title>Coordinated Decentralized Resource Optimization for Cell-Free ISAC Systems</title>
      <link>https://arxiv.org/abs/2508.01044</link>
      <description>arXiv:2508.01044v2 Announce Type: replace 
Abstract: Integrated Sensing and Communication (ISAC) is emerging as a key enabler for 6G wireless networks, allowing the joint use of spectrum and infrastructure for both communication and sensing. While prior ISAC solutions have addressed resource optimization, including power allocation, beamforming, and waveform design, they often rely on centralized architectures with full network knowledge, limiting their scalability in distributed systems. In this paper, we propose two coordinated decentralized optimization algorithms for beamforming and power allocation tailored to cell-free ISAC networks. The first algorithm employs locally designed fixed beamformers at access points (APs), combined with a centralized power allocation scheme computed at a central server (CS). The second algorithm jointly optimizes beamforming and power control through a fully decentralized consensus ADMM framework. Both approaches rely on local information at APs and limited coordination with the CS. Simulation results obtained using our proposed Python-based simulation framework evaluate their fronthaul overhead and system-level performance, demonstrating their practicality for scalable ISAC deployment in decentralized, cell-free architectures.</description>
      <guid isPermaLink="false">oai:arXiv.org:2508.01044v2</guid>
      <category>eess.SP</category>
      <category>math.OC</category>
      <pubDate>Wed, 03 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Mehdi Zafari, Rang Liu, A. Lee Swindlehurst</dc:creator>
    </item>
    <item>
      <title>Ray-Tracing Based Narrow-Beam Channel Simulation, Characterization and Performance Evaluation for 5G-R Systems</title>
      <link>https://arxiv.org/abs/2510.19401</link>
      <description>arXiv:2510.19401v2 Announce Type: replace 
Abstract: This paper investigates narrow-beam channel characterization and performance evaluation for 5G for railway (5G-R) systems based on ray-tracing (RT) simulation. Three representative high-speed railway (HSR) scenarios including viaduct, cutting, and station are established, and RT-based dynamic narrow-beam channel simulations are conducted using a designed beam tracking scheme that ensures continuous alignment with the moving train. The channel characteristics are analyzed in terms of both large-scale and small-scale fading, as well as non-stationarity, providing statistical insights into path loss, shadow fading, fading severity, time-frequency-space dispersion, and stationarity interval. The influence of beamwidth on these channel properties is also examined. Furthermore, the performance of 5G-R systems operating in such narrow-beam channels is evaluated using the Vienna 5G simulator, with a focus on block error rate, throughput, and spectral efficiency. A hardware-in-the-loop simulation platform is developed to further assess synchronization signal reference signal received power, signal-to-interference-plus-noise ratio, and reference signal received quality. The results provide valuable guidance for the design and optimization of 5G-R systems in HSR environments.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.19401v2</guid>
      <category>eess.SP</category>
      <pubDate>Wed, 03 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Tao Zhou, Liying Geng, Kaifeng Bao, Tianyun Feng, Liu Liu, Bo Ai</dc:creator>
    </item>
    <item>
      <title>Data-Efficient Motor Condition Monitoring with Time Series Foundation Models</title>
      <link>https://arxiv.org/abs/2511.23177</link>
      <description>arXiv:2511.23177v2 Announce Type: replace 
Abstract: Motor condition monitoring is essential for ensuring system reliability and preventing catastrophic failures. However, data-driven diagnostic methods often suffer from sparse fault labels and severe class imbalance, which limit their effectiveness in real-world applications. This paper proposes a motor condition monitoring framework that leverages the general features learned during pre-training of two time series foundation models, MOMENT and Mantis, to address these challenges. By transferring broad temporal representations from large-scale pre-training, the proposed approach significantly reduces dependence on labeled data while maintaining high diagnostic accuracy. Experimental results show that MOMENT achieves nearly twice the performance of conventional deep learning models using only 1% of the training data, whereas Mantis surpasses state-of-the-art baselines by 22%, reaching 90% accuracy with the same data ratio. These results demonstrate the strong generalization and data efficiency of time series foundation models in fault diagnosis, providing new insights into scalable and adaptive frameworks for intelligent motor condition monitoring.</description>
      <guid isPermaLink="false">oai:arXiv.org:2511.23177v2</guid>
      <category>eess.SP</category>
      <category>cs.SY</category>
      <category>eess.SY</category>
      <pubDate>Wed, 03 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Deyu Li, Xinyuan Liao, Shaowei Chen, Shuai Zhao</dc:creator>
    </item>
    <item>
      <title>CSI-BERT2: A BERT-inspired Framework for Efficient CSI Prediction and Classification in Wireless Communication and Sensing</title>
      <link>https://arxiv.org/abs/2412.06861</link>
      <description>arXiv:2412.06861v4 Announce Type: replace-cross 
Abstract: Channel state information (CSI) is a fundamental component in both wireless communication and sensing systems, enabling critical functions such as radio resource optimization and environmental perception. In wireless sensing, data scarcity and packet loss hinder efficient model training, while in wireless communication, high-dimensional CSI matrices and short coherent times caused by high mobility present challenges in CSI estimation. To address these issues, we propose a unified framework named CSI-BERT2 for CSI prediction and classification tasks, built on CSI-BERT, which adapts BERT to capture the complex relationships among CSI sequences through a bidirectional self-attention mechanism. We introduce a two-stage training method that first uses a mask language model (MLM) to enable the model to learn general feature extraction from scarce datasets in an unsupervised manner, followed by fine-tuning for specific downstream tasks. Specifically, we extend MLM into a mask prediction model (MPM), which efficiently addresses the CSI prediction task. To further enhance the representation capacity of CSI data, we modify the structure of the original CSI-BERT. We introduce an adaptive re-weighting layer (ARL) to enhance subcarrier representation and a multi-layer perceptron (MLP)-based temporal embedding module to mitigate temporal information loss problem inherent in the original Transformer. Extensive experiments on both real-world collected and simulated datasets demonstrate that CSI-BERT2 achieves state-of-the-art performance across all tasks. Our results further show that CSI-BERT2 generalizes effectively across varying sampling rates and robustly handles discontinuous CSI sequences caused by packet loss-challenges that conventional methods fail to address. The dataset and code are publicly available at https://github.com/RS2002/CSI-BERT2 .</description>
      <guid isPermaLink="false">oai:arXiv.org:2412.06861v4</guid>
      <category>cs.LG</category>
      <category>cs.AI</category>
      <category>eess.SP</category>
      <pubDate>Wed, 03 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Zijian Zhao, Fanyi Meng, Zhonghao Lyu, Hang Li, Xiaoyang Li, Guangxu Zhu</dc:creator>
    </item>
    <item>
      <title>Beyond Connectivity: An Open Architecture for AI-RAN Convergence in 6G</title>
      <link>https://arxiv.org/abs/2507.06911</link>
      <description>arXiv:2507.06911v2 Announce Type: replace-cross 
Abstract: Data-intensive Artificial Intelligence (AI) applications at the network edge demand a fundamental shift in Radio Access Network (RAN) design, from merely consuming AI for network optimization, to actively enabling distributed AI workloads. This presents a significant opportunity for network operators to monetize AI while leveraging existing infrastructure. To realize this vision, this article presents a novel converged O-RAN and AI-RAN architecture for unified orchestration and management of telecommunications and AI workloads on shared infrastructure. The proposed architecture extends the Open RAN principles of modularity, disaggregation, and cloud-nativeness to support heterogeneous AI deployments. We introduce two key architectural innovations: (i) the AI-RAN Orchestrator, which extends the O-RAN Service Management and Orchestration (SMO) to enable integrated resource and allocation across RAN and AI workloads; and (ii) AI-RAN sites that provide distributed edge AI platforms with real-time processing capabilities. The proposed architecture enables flexible orchestration, meeting requirements for managing heterogeneous workloads at different time scales while maintaining open, standardized interfaces and multi-vendor interoperability.</description>
      <guid isPermaLink="false">oai:arXiv.org:2507.06911v2</guid>
      <category>cs.NI</category>
      <category>cs.AI</category>
      <category>eess.SP</category>
      <pubDate>Wed, 03 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Michele Polese, Niloofar Mohamadi, Salvatore D'Oro, Leonardo Bonati, Tommaso Melodia</dc:creator>
    </item>
    <item>
      <title>Remotely sensing stress evolution in elastic media: a passive approach to earthquake monitoring</title>
      <link>https://arxiv.org/abs/2509.00268</link>
      <description>arXiv:2509.00268v4 Announce Type: replace-cross 
Abstract: Stress evolution governs material failure across scales, from microscopic fractures to large earthquakes, yet direct observation of its dynamics in natural systems has remained elusive. Laboratory experiments using active ultrasonic measurements have shown that seismic velocity and attenuation are sensitive to stress, but such monitoring has not previously been achievable remotely or passively.
  Here we introduce a stress-sensitive frequency-domain transform that enables passive monitoring of stress evolution using ambient seismic or acoustic noise. The method quantifies relative energy shifts between adjacent frequency bands, capturing subtle changes in wave-propagation properties linked to evolving shear and normal stress. Applied across scales, from laboratory stick-slip and slow-slip experiments to natural fault systems including the 2018 Kilauea collapse, Cascadia slow-slip episodes, and major earthquakes such as the 2011 Tohoku, 2010 Maule, 2002 Denali, and 2023 Turkey-Syria events, the transform consistently reveals distinctive precursory trajectories and stress-cycle patterns.
  These results demonstrate that stress evolution in elastic Earth materials can be remotely and passively monitored, bridging laboratory rock physics and large-scale seismology and offering a new foundation for real-time tracking of fault mechanics and earthquake preparation.</description>
      <guid isPermaLink="false">oai:arXiv.org:2509.00268v4</guid>
      <category>physics.geo-ph</category>
      <category>cs.AI</category>
      <category>eess.SP</category>
      <pubDate>Wed, 03 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Nader Shakibay Senobari</dc:creator>
    </item>
    <item>
      <title>CPEP: Contrastive Pose-EMG Pre-training Enhances Gesture Generalization on EMG Signals</title>
      <link>https://arxiv.org/abs/2509.04699</link>
      <description>arXiv:2509.04699v3 Announce Type: replace-cross 
Abstract: Hand gesture classification using high-quality structured data such as videos, images, and hand skeletons is a well-explored problem in computer vision. Leveraging low-power, cost-effective biosignals, e.g. surface electromyography (sEMG), allows for continuous gesture prediction on wearables. In this paper, we demonstrate that learning representations from weak-modality data that are aligned with those from structured, high-quality data can improve representation quality and enables zero-shot classification. Specifically, we propose a Contrastive Pose-EMG Pre-training (CPEP) framework to align EMG and pose representations, where we learn an EMG encoder that produces high-quality and pose-informative representations. We assess the gesture classification performance of our model through linear probing and zero-shot setups. Our model outperforms emg2pose benchmark models by up to 21% on in-distribution gesture classification and 72% on unseen (out-of-distribution) gesture classification.</description>
      <guid isPermaLink="false">oai:arXiv.org:2509.04699v3</guid>
      <category>cs.LG</category>
      <category>eess.SP</category>
      <pubDate>Wed, 03 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Wenhui Cui, Christopher Sandino, Hadi Pouransari, Ran Liu, Juri Minxha, Ellen Zippi, Aman Verma, Anna Sedlackova, Erdrin Azemi, Behrooz Mahasseni</dc:creator>
    </item>
    <item>
      <title>Tiny but Mighty: A Software-Hardware Co-Design Approach for Efficient Multimodal Inference on Battery-Powered Small Devices</title>
      <link>https://arxiv.org/abs/2510.05109</link>
      <description>arXiv:2510.05109v3 Announce Type: replace-cross 
Abstract: Large Multimodal Models (LMMs) are inherently modular, consisting of vision and audio encoders, projectors, and large language models. Yet, they are almost always executed monolithically, which underutilizes the heterogeneous accelerators (NPUs, GPUs, DSPs) in modern SoCs and leads to high end-to-end latency. In this paper, we present NANOMIND, a hardware--software co-design inference framework for Large Multimodal Models (LMMs) that breaks large models into modular ``bricks'' (vision, language, audio, etc.) and maps each to its ideal accelerator. The key insight is that large models can be broken into modular components and scheduled to run on the most appropriate compute units. It performs module-level dynamic offloading across accelerators on unified-memory SoCs. By combining customized hardware design, system-level scheduling, and optimized low-bit computation kernels, we demonstrate our framework with a compact, battery-powered device capable of running LMMs entirely on device. This prototype functions as a self-contained intelligent assistant that requires no network connectivity, while achieving higher throughput and superior power efficiency under strict resource constraints. The design further bypasses CPU bottlenecks and reduces redundant memory usage through token-aware buffer management and module-level coordination. Our system outperforms existing implementations in resource efficiency, cutting energy consumption by 42.3\% and GPU memory usage by 11.2\%. This enables a battery-powered device to run LLaVA-OneVision with a camera for nearly 20.8 hours.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.05109v3</guid>
      <category>cs.DC</category>
      <category>cs.AI</category>
      <category>cs.CL</category>
      <category>eess.SP</category>
      <pubDate>Wed, 03 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <dc:creator>Yilong Li, Shuai Zhang, Yijing Zeng, Hao Zhang, Xinmiao Xiong, Jingyu Liu, Pan Hu, Suman Banerjee</dc:creator>
    </item>
    <item>
      <title>MRI Super-Resolution with Deep Learning: A Comprehensive Survey</title>
      <link>https://arxiv.org/abs/2511.16854</link>
      <description>arXiv:2511.16854v3 Announce Type: replace-cross 
Abstract: High-resolution (HR) magnetic resonance imaging (MRI) is crucial for many clinical and research applications. However, achieving it remains costly and constrained by technical trade-offs and experimental limitations. Super-resolution (SR) presents a promising computational approach to overcome these challenges by generating HR images from more affordable low-resolution (LR) scans, potentially improving diagnostic accuracy and efficiency without requiring additional hardware. This survey reviews recent advances in MRI SR techniques, with a focus on deep learning (DL) approaches. It examines DL-based MRI SR methods from the perspectives of computer vision, computational imaging, inverse problems, and MR physics, covering theoretical foundations, architectural designs, learning strategies, benchmark datasets, and performance metrics. We propose a systematic taxonomy to categorize these methods and present an in-depth study of both established and emerging SR techniques applicable to MRI, considering unique challenges in clinical and research contexts. We also highlight open challenges and directions that the community needs to address. Additionally, we provide a collection of essential open-access resources, tools, and tutorials, available on our GitHub: https://github.com/mkhateri/Awesome-MRI-Super-Resolution.
  IEEE keywords: MRI, Super-Resolution, Deep Learning, Computational Imaging, Inverse Problem, Survey.</description>
      <guid isPermaLink="false">oai:arXiv.org:2511.16854v3</guid>
      <category>eess.IV</category>
      <category>cs.AI</category>
      <category>cs.CV</category>
      <category>eess.SP</category>
      <pubDate>Wed, 03 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Mohammad Khateri, Serge Vasylechko, Morteza Ghahremani, Liam Timms, Deniz Kocanaogullari, Simon K. Warfield, Camilo Jaimes, Davood Karimi, Alejandra Sierra, Jussi Tohka, Sila Kurugol, Onur Afacan</dc:creator>
    </item>
  </channel>
</rss>
