<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>cs.DL updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/cs.DL</link>
    <description>cs.DL updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/cs.DL" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Tue, 30 Dec 2025 05:00:29 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Tue, 30 Dec 2025 00:00:00 -0500</pubDate>
    <skipDays>
      <day>Sunday</day>
      <day>Saturday</day>
    </skipDays>
    <item>
      <title>Expert-Grounded Automatic Prompt Engineering for Extracting Lattice Constants of High-Entropy Alloys from Scientific Publications using Large Language Models</title>
      <link>https://arxiv.org/abs/2512.22130</link>
      <description>arXiv:2512.22130v1 Announce Type: new 
Abstract: Large language models (LLMs) have shown promise for scientific data extraction from publications, but rely on manual prompt refinement. We present an expert-grounded automatic prompt optimization framework that enhances LLM entity extraction reliability. Using high-entropy alloy lattice constant extraction as a testbed, we optimized prompts for Claude 3.5 Sonnet through feedback cycles on seven expert-annotated publications. Despite a modest optimization budget, recall improved from 0.27 to &gt; 0.9, demonstrating that a small, expert-curated dataset can yield significant improvements. The approach was applied to extract lattice constants from 2,267 publications, yielding data for 1,861 compositions. The optimized prompt transferred effectively to newer models: Claude 4.5 Sonnet, GPT-5, and Gemini 2.5 Flash. Analysis revealed three categories of LLM mistakes: contextual hallucination, semantic misinterpretation, and unit conversion errors, emphasizing the need for validation protocols. These results establish feedback-guided prompt optimization as a low-cost, transferable methodology for reliable scientific data extraction, providing a scalable pathway for complex LLM-assisted research tasks.</description>
      <guid isPermaLink="false">oai:arXiv.org:2512.22130v1</guid>
      <category>cs.DL</category>
      <category>cond-mat.mtrl-sci</category>
      <pubDate>Tue, 30 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Shunshun Liu, Talon R. Booth, Yangfeng Ji, Wesley Reinhart, Prasanna V. Balachandran</dc:creator>
    </item>
    <item>
      <title>Men and Women Survivors in Science: A Comprehensive Analysis</title>
      <link>https://arxiv.org/abs/2512.22140</link>
      <description>arXiv:2512.22140v1 Announce Type: new 
Abstract: We followed scientists who started publishing in 2000 and who continued publishing until 2020-2023 (N = 41,424). These survivors in science authored 2 million articles (N = 2,089,097) with more than 70 million cited references (N = 73,118,395) and worked in 38 OECD countries. Using a raw Scopus dataset, we examined gender disparities in publishing intensity, international collaboration, journal selection, productivity, citations, team formation, and publishing breaks in 16 STEMM and social science disciplines. Several author-level metrics were computed. Our data show a gender productivity gap for both lifetime scholarly output and annual journal prestige-normalized productivity. Surprisingly, in the context of extant literature, the data do not show a gender international collaboration gap, a gender journal selection gap, a gender citation gap, or a gender team formation gap. Men were on average 23% more productive than women cumulatively in 2000-2023 and 19% more productive in the last 5 years studied (2019-2023). Men and women published in equally prestigious journals, received the same number of citations (field-normalized), and worked in equally sized teams. In all, 80% of scientists in STEMM disciplines and 70% in the social sciences had published every year. Our data indicate interesting disciplinary differences in gender disparities.</description>
      <guid isPermaLink="false">oai:arXiv.org:2512.22140v1</guid>
      <category>cs.DL</category>
      <pubDate>Tue, 30 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Marek Kwiek, Lukasz Szymula</dc:creator>
    </item>
    <item>
      <title>International Research Collaboration Among Top Performers: A Gender Gap Persists</title>
      <link>https://arxiv.org/abs/2512.22141</link>
      <description>arXiv:2512.22141v1 Announce Type: new 
Abstract: We studied gender differences among Polish top performers (the upper 10% of scientists in terms of research productivity) in international research collaborations in 15 STEMM disciplines and over time. We examined five 6-year periods from 1992 to 2021. We operationalized international research collaboration by using international publication co-authorships in Scopus and used a sample of 152,043 unique Polish authors and their 587,558 articles published in 1992-2021. Our data show that a gender gap in international collaboration by top performers (and among the whole population of scientists) steadily widened: the gap was smallest in the early 1990s and grew over the next 30 years. Among top performers, internationalization intensity in four of the disciplines (AGRI, BIO, ENVI, and MED) was higher for men than for women. To capture the multidimensional nature of international research collaboration, we estimated a fractional logistic regression model with fixed effects that confirmed a persisting moderate but statistically significant international collaboration gender gap among top performers. We found an approximately 11% higher probability of international collaboration by men top performers compared with women top performers. Reflections on bibliometric-driven studies are offered.</description>
      <guid isPermaLink="false">oai:arXiv.org:2512.22141v1</guid>
      <category>cs.DL</category>
      <pubDate>Tue, 30 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Marek Kwiek, Wojciech Roszka</dc:creator>
    </item>
    <item>
      <title>Pre-review to Peer review: Pitfalls of Automating Reviews using Large Language Models</title>
      <link>https://arxiv.org/abs/2512.22145</link>
      <description>arXiv:2512.22145v1 Announce Type: new 
Abstract: Large Language Models are versatile general-task solvers, and their capabilities can truly assist people with scholarly peer review as \textit{pre-review} agents, if not as fully autonomous \textit{peer-review} agents. While incredibly beneficial, automating academic peer-review, as a concept, raises concerns surrounding safety, research integrity, and the validity of the academic peer-review process. The majority of the studies performing a systematic evaluation of frontier LLMs generating reviews across science disciplines miss the mark on addressing the alignment/misalignment of reviews along with the utility of LLM generated reviews when compared against publication outcomes such as \textbf{Citations}, \textbf{Hit-papers}, \textbf{Novelty}, and \textbf{Disruption}. This paper presents an experimental study in which we gathered ground-truth reviewer ratings from OpenReview and used various frontier open-weight LLMs to generate reviews of papers to gauge the safety and reliability of incorporating LLMs into the scientific review pipeline. Our findings demonstrate the utility of frontier open-weight LLMs as pre-review screening agents despite highlighting fundamental misalignment risks when deployed as autonomous reviewers. Our results show that all models exhibit weak correlation with human peer reviewers (0.15), with systematic overestimation bias of 3-5 points and uniformly high confidence scores (8.0-9.0/10) despite prediction errors. However, we also observed that LLM reviews correlate more strongly with post-publication metrics than with human scores, suggesting potential utility as pre-review screening tools. Our findings highlight the potential and address the pitfalls of automating peer reviews with language models. We open-sourced our dataset $D_{LMRSD}$ to help the research community expand the safety framework of automating scientific reviews.</description>
      <guid isPermaLink="false">oai:arXiv.org:2512.22145v1</guid>
      <category>cs.DL</category>
      <category>cs.AI</category>
      <category>cs.CY</category>
      <pubDate>Tue, 30 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Akhil Pandey Akella, Harish Varma Siravuri, Shaurya Rohatgi</dc:creator>
    </item>
    <item>
      <title>Oignon: Citation Graph Tool</title>
      <link>https://arxiv.org/abs/2512.22159</link>
      <description>arXiv:2512.22159v1 Announce Type: new 
Abstract: Citation graph visualisation is a useful tool for contextual awareness in academic research. Unfortunately, existing solutions can suffer from several drawbacks, such as a poor scaling, shallow network traversal, freemium gating, and slow build times. Oignon is a free, open-source tool for systematically exploring academic research. It uses a dual-path ranking system with recency weighting to create graphs capturing both foundational works and recent breakthroughs related to a specific publication.</description>
      <guid isPermaLink="false">oai:arXiv.org:2512.22159v1</guid>
      <category>cs.DL</category>
      <pubDate>Tue, 30 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Harry Ballington</dc:creator>
    </item>
    <item>
      <title>Artificial Intelligence Applications in Lean Startup Methodology: A Bibliometric Analysis of Research Trends and Future Directions</title>
      <link>https://arxiv.org/abs/2512.22164</link>
      <description>arXiv:2512.22164v1 Announce Type: new 
Abstract: This study presents a comprehensive bibliometric analysis of the emerging intersection between artificial intelligence (AI) and lean startup methodology. Using the PRISMA 2020 framework, we systematically analyzed 12 peer-reviewed articles published between 2010 and June 2025, sourced from the Scopus database. The analysis employed VOS viewer software to conduct co-authorship, keyword co-occurrence, and citation network analyses. Results reveal three distinct research clusters: operational integration of AI within startup experimentation processes, AI-enhanced learning systems for entrepreneurial contexts, and strategic implications of AI for uncertainty management in startups. The findings indicate a developing research domain characterized by fragmented authorship networks, limited international collaboration, and geographic concentration in developed economies, particularly the United States and Germany. Key research themes include business model innovation, iterative methods, and machine learning applications, with artificial intelligence serving as a bridging concept across thematic clusters. The analysis identifies significant research gaps in ethical considerations, cross-cultural validation, and empirical testing of AI-enabled lean startup frameworks. While current research demonstrates growing interest in AI integration within entrepreneurial experimentation, the field requires enhanced theoretical consolidation, methodological rigor, and interdisciplinary collaboration to achieve practical relevance and academic maturity. This study contributes to the emerging discourse on digital entrepreneurship by providing a systematic overview of research trends and identifying priority areas for future investigation at the intersection of AI and lean startup methodologies.</description>
      <guid isPermaLink="false">oai:arXiv.org:2512.22164v1</guid>
      <category>cs.DL</category>
      <pubDate>Tue, 30 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Parisa Omidmand, Rasam Dorri, Alireza Mozaffari, Saeid Ataei</dc:creator>
    </item>
    <item>
      <title>IANEC: Digital Forensic Investigation of Contemporary Writers' Archives</title>
      <link>https://arxiv.org/abs/2512.22167</link>
      <description>arXiv:2512.22167v1 Announce Type: new 
Abstract: The IANEC project (Investigation of Digital Archives of Contemporary Writers), led by the GREYC Research Lab and funded by the French Ministry of Culture aims to develop dedicated digital forensic investigation tools to automate the analysis of archival corpora from the Institut M{\'e}moires de l'{\'E}dition Contemporaine (IMEC). The project is based on the observation that born-digital archival materials are increasingly prevalent in contemporary archival institutions, and that digital forensics technologies have become essential for the extraction, identification, processing, and description of natively digital archival corpora.*</description>
      <guid isPermaLink="false">oai:arXiv.org:2512.22167v1</guid>
      <category>cs.DL</category>
      <category>cs.CR</category>
      <category>cs.IR</category>
      <pubDate>Tue, 30 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Emmanuel Giguet (GREYC)</dc:creator>
    </item>
    <item>
      <title>Interpretable Link Prediction in AI-Driven Cancer Research: Uncovering Co-Authorship Patterns</title>
      <link>https://arxiv.org/abs/2512.22181</link>
      <description>arXiv:2512.22181v1 Announce Type: new 
Abstract: Artificial intelligence (AI) is transforming cancer diagnosis and treatment. The intricate nature of this disease necessitates the collaboration of diverse stakeholders with varied expertise to ensure the effectiveness of cancer research. Despite its importance, forming effective interdisciplinary research teams remains challenging. Understanding and predicting collaboration patterns can help researchers, organizations, and policymakers optimize resources and foster impactful research. We examined co-authorship networks as a proxy for collaboration within AI-driven cancer research. Using 7,738 publications (2000-2017) from Scopus, we constructed 36 overlapping co-authorship networks representing new, persistent, and discontinued collaborations. We engineered both attribute-based and structure-based features and built four machine learning classifiers. Model interpretability was performed using Shapley Additive Explanations (SHAP). Random forest achieved the highest recall for all three types of examined collaborations. The discipline similarity score emerged as a crucial factor, positively affecting new and persistent patterns while negatively impacting discontinued collaborations. Additionally, high productivity and seniority were positively associated with discontinued links. Our findings can guide the formation of effective research teams, enhance interdisciplinary cooperation, and inform strategic policy decisions.</description>
      <guid isPermaLink="false">oai:arXiv.org:2512.22181v1</guid>
      <category>cs.DL</category>
      <category>cs.AI</category>
      <pubDate>Tue, 30 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Shahab Mosallaie, Andrea Schiffauerova, Ashkan Ebadi</dc:creator>
    </item>
    <item>
      <title>AETAS: Analysis of Evolving Temporal Affect and Semantics for Legal History</title>
      <link>https://arxiv.org/abs/2512.22196</link>
      <description>arXiv:2512.22196v1 Announce Type: new 
Abstract: Digital-humanities work on semantic shift often alternates between handcrafted close readings and opaque embedding machinery. We present a reproducible expert-system style pipeline that quantifies and visualises lexical drift in the Old Bailey Corpus (1720--1913), coupling interpretable trajectories with legally meaningful axes. We bin proceedings by decade with dynamic merging for low-resource slices, train skip-gram embeddings, align spaces through orthogonal Procrustes, and measure both geometric displacement and neighborhood turnover. Three visual analytics outputs, which are drift magnitudes, semantic trajectories, and movement along a mercy-versus-retribution axis, expose how justice, crime, poverty, and insanity evolve with penal reforms, transportation debates, and Victorian moral politics. The pipeline is implemented as auditable scripts so results can be reproduced in other historical corpora.</description>
      <guid isPermaLink="false">oai:arXiv.org:2512.22196v1</guid>
      <category>cs.DL</category>
      <category>cs.CY</category>
      <category>cs.LG</category>
      <pubDate>Tue, 30 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Qizhi Wang</dc:creator>
    </item>
    <item>
      <title>Periodical embeddings uncover hidden interdisciplinary patterns in the subject classification scheme of science</title>
      <link>https://arxiv.org/abs/2512.22524</link>
      <description>arXiv:2512.22524v1 Announce Type: new 
Abstract: Subject classification schemes are foundational to the organization, evaluation, and navigation of scientific knowledge. While expert-curated systems like Scopus provide widely used taxonomies, they often suffer from coarse granularity, subjectivity, and limited adaptability to emerging interdisciplinary fields. Data-driven alternatives based on citation networks show promise but lack rigorous, external validation against the semantic content of scientific literature. Here, we propose a novel quantitative framework that leverages classification tasks to evaluate the effectiveness of journal classification schemes. Using over 23 million paper abstracts, we demonstrate that labels derived from k-means clustering on Periodical2Vec (P2V)--a periodical embedding learned from paper-level citations--yield significantly higher classification performance than both Scopus and other data-driven baselines (e.g., citation, co-citation, and Node2Vec variants). By comparing journal partitions across classification schemes, two structural patterns emerge on the map of science: (1) the reorganization of disciplinary boundaries--splitting overly broad categories (e.g., "Medicine" into "Oncology", "Cardiology", and other specialties) while merging artificially fragmented ones (e.g., "Chemistry" and "Chemical Engineering"); and (2) the identification of coherent interdisciplinary clusters--such as "Biomedical Engineering", "Medical Ethics", and "Information Management"--that are dispersed across multiple categories but unified in citation space. These findings underscore that citation-derived periodical embeddings not only outperform traditional taxonomies in predictive validity but also offer a dynamic, fine-grained map of science that better reflects both the specialization and interdisciplinarity inherent in contemporary research.</description>
      <guid isPermaLink="false">oai:arXiv.org:2512.22524v1</guid>
      <category>cs.DL</category>
      <category>cs.SI</category>
      <category>physics.soc-ph</category>
      <pubDate>Tue, 30 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Zhuoqi Lyu, Qing Ke</dc:creator>
    </item>
    <item>
      <title>An Automated Grey Literature Extraction Tool for Software Engineering</title>
      <link>https://arxiv.org/abs/2512.23066</link>
      <description>arXiv:2512.23066v1 Announce Type: cross 
Abstract: Grey literature is essential to software engineering research as it captures practices and decisions that rarely appear in academic venues. However, collecting and assessing it at scale remains difficult because of their heterogeneous sources, formats, and APIs that impede reproducible, large-scale synthesis. To address this issue, we present GLiSE, a prompt-driven tool that turns a research topic prompt into platform-specific queries, gathers results from common software-engineering web sources (GitHub, Stack Overflow) and Google Search, and uses embedding-based semantic classifiers to filter and rank results according to their relevance. GLiSE is designed for reproducibility with all settings being configuration-based, and every generated query being accessible. In this paper, (i) we present the GLiSE tool, (ii) provide a curated dataset of software engineering grey-literature search results classified by semantic relevance to their originating search intent, and (iii) conduct an empirical study on the usability of our tool.</description>
      <guid isPermaLink="false">oai:arXiv.org:2512.23066v1</guid>
      <category>cs.SE</category>
      <category>cs.DL</category>
      <pubDate>Tue, 30 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Houcine Abdelkader Cherief, Brahim Mahmoudi, Zacharie Chenail-Larcher, Naouel Moha, Quentin Sti'evenart, Florent Avellaneda</dc:creator>
    </item>
    <item>
      <title>The Effect of Gender Diversity on Scientific Team Impact: A Team Roles Perspective</title>
      <link>https://arxiv.org/abs/2512.23429</link>
      <description>arXiv:2512.23429v1 Announce Type: cross 
Abstract: The influence of gender diversity on the success of scientific teams is of great interest to academia. However, prior findings remain inconsistent, and most studies operationalize diversity in aggregate terms, overlooking internal role differentiation. This limitation obscures a more nuanced understanding of how gender diversity shapes team impact. In particular, the effect of gender diversity across different team roles remains poorly understood. To this end, we define a scientific team as all coauthors of a paper and measure team impact through five-year citation counts. Using author contribution statements, we classified members into leadership and support roles. Drawing on more than 130,000 papers from PLOS journals, most of which are in biomedical-related disciplines, we employed multivariable regression to examine the association between gender diversity in these roles and team impact. Furthermore, we apply a threshold regression model to investigate how team size moderates this relationship. The results show that (1) the relationship between gender diversity and team impact follows an inverted U-shape for both leadership and support groups; (2) teams with an all-female leadership group and an all-male support group achieve higher impact than other team types. Interestingly, (3) the effect of leadership-group gender diversity is significantly negative for small teams but becomes positive and statistically insignificant in large teams. In contrast, the estimates for support-group gender diversity remain significant and positive, regardless of team size.</description>
      <guid isPermaLink="false">oai:arXiv.org:2512.23429v1</guid>
      <category>cs.CL</category>
      <category>cs.CY</category>
      <category>cs.DL</category>
      <pubDate>Tue, 30 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <arxiv:DOI>10.1016/j.joi.2025.101766</arxiv:DOI>
      <arxiv:journal_reference>Journal of Informetrics, 2026</arxiv:journal_reference>
      <dc:creator>Yi Zhao, Yongjun Zhu, Donghun Kim, Yuzhuo Wang, Heng Zhang, Chao Lu, Chengzhi Zhang</dc:creator>
    </item>
  </channel>
</rss>
