<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>q-fin.PM updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/q-fin.PM</link>
    <description>q-fin.PM updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/q-fin.PM" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Fri, 26 Jul 2024 04:05:16 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Fri, 26 Jul 2024 00:00:00 -0400</pubDate>
    <skipDays>
      <day>Sunday</day>
      <day>Saturday</day>
    </skipDays>
    <item>
      <title>Hopfield Networks for Asset Allocation</title>
      <link>https://arxiv.org/abs/2407.17645</link>
      <description>arXiv:2407.17645v1 Announce Type: cross 
Abstract: We present the first application of modern Hopfield networks to the problem of portfolio optimization. We performed an extensive study based on combinatorial purged cross-validation over several datasets and compared our results to both traditional and deep-learning-based methods for portfolio selection. Compared to state-of-the-art deep-learning methods such as Long-Short Term Memory networks and Transformers, we find that the proposed approach performs on par or better, while providing faster training times and better stability. Our results show that Modern Hopfield Networks represent a promising approach to portfolio optimization, allowing for an efficient, scalable, and robust solution for asset allocation, risk management, and dynamic rebalancing.</description>
      <guid isPermaLink="false">oai:arXiv.org:2407.17645v1</guid>
      <category>cs.LG</category>
      <category>q-fin.CP</category>
      <category>q-fin.PM</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Carlo Nicolini, Monisha Gopalan, Jacopo Staiano, Bruno Lepri</dc:creator>
    </item>
    <item>
      <title>Financial Statement Analysis with Large Language Models</title>
      <link>https://arxiv.org/abs/2407.17866</link>
      <description>arXiv:2407.17866v1 Announce Type: cross 
Abstract: We investigate whether an LLM can successfully perform financial statement analysis in a way similar to a professional human analyst. We provide standardized and anonymous financial statements to GPT4 and instruct the model to analyze them to determine the direction of future earnings. Even without any narrative or industry-specific information, the LLM outperforms financial analysts in its ability to predict earnings changes. The LLM exhibits a relative advantage over human analysts in situations when the analysts tend to struggle. Furthermore, we find that the prediction accuracy of the LLM is on par with the performance of a narrowly trained state-of-the-art ML model. LLM prediction does not stem from its training memory. Instead, we find that the LLM generates useful narrative insights about a company's future performance. Lastly, our trading strategies based on GPT's predictions yield a higher Sharpe ratio and alphas than strategies based on other models. Taken together, our results suggest that LLMs may take a central role in decision-making.</description>
      <guid isPermaLink="false">oai:arXiv.org:2407.17866v1</guid>
      <category>q-fin.ST</category>
      <category>cs.AI</category>
      <category>cs.CL</category>
      <category>q-fin.GN</category>
      <category>q-fin.PM</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Alex Kim, Maximilian Muhn, Valeri Nikolaev</dc:creator>
    </item>
    <item>
      <title>Fine-Tuning Large Language Models for Stock Return Prediction Using Newsflow</title>
      <link>https://arxiv.org/abs/2407.18103</link>
      <description>arXiv:2407.18103v1 Announce Type: cross 
Abstract: Large language models (LLMs) and their fine-tuning techniques have demonstrated superior performance in various language understanding and generation tasks. This paper explores fine-tuning LLMs for stock return forecasting with financial newsflow. In quantitative investing, return forecasting is fundamental for subsequent tasks like stock picking, portfolio optimization, etc. We formulate the model to include text representation and forecasting modules. We propose to compare the encoder-only and decoder-only LLMs, considering they generate text representations in distinct ways. The impact of these different representations on forecasting performance remains an open question. Meanwhile, we compare two simple methods of integrating LLMs' token-level representations into the forecasting module. The experiments on real news and investment universes reveal that: (1) aggregated representations from LLMs' token-level embeddings generally produce return predictions that enhance the performance of long-only and long-short portfolios; (2) in the relatively large investment universe, the decoder LLMs-based prediction model leads to stronger portfolios, whereas in the small universes, there are no consistent winners. Among the three LLMs studied (DeBERTa, Mistral, Llama), Mistral performs more robustly across different universes; (3) return predictions derived from LLMs' text representations are a strong signal for portfolio construction, outperforming conventional sentiment scores.</description>
      <guid isPermaLink="false">oai:arXiv.org:2407.18103v1</guid>
      <category>q-fin.CP</category>
      <category>cs.LG</category>
      <category>q-fin.PM</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Tian Guo, Emmanuel Hauptmann</dc:creator>
    </item>
    <item>
      <title>A semi-parametric marginalized dynamic conditional correlation framework</title>
      <link>https://arxiv.org/abs/2207.04595</link>
      <description>arXiv:2207.04595v3 Announce Type: replace-cross 
Abstract: We develop a novel multivariate semi-parametric framework for joint portfolio Value-at-Risk and Expected Shortfall forecasting. Unlike existing univariate semi-parametric approaches, the proposed framework explicitly models the dependence structure among portfolio asset returns through a marginalized dynamic conditional correlation (DCC) parameterization. To estimate the model, a two-step procedure based on the minimization of a strictly consistent scoring function derived from the Asymmetric Laplace distribution is developed. This procedure allows to simultaneously estimate the marginalized DCC parameters and the portfolio risk factors. The performance of the proposed model in risk forecasting and portfolio allocation is evaluated by means of a forecasting study on the components of the Dow Jones index for an out-of-sample period from December 2016 to September 2021. The empirical results support effectiveness of the proposed framework compared to a variety of existing approaches.</description>
      <guid isPermaLink="false">oai:arXiv.org:2207.04595v3</guid>
      <category>q-fin.RM</category>
      <category>q-fin.PM</category>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Giuseppe Storti, Chao Wang</dc:creator>
    </item>
  </channel>
</rss>
