<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>eess.SP updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/eess.SP</link>
    <description>eess.SP updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/eess.SP" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Thu, 29 May 2025 01:55:01 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Wed, 28 May 2025 00:00:00 -0400</pubDate>
    <skipDays>
      <day>Saturday</day>
      <day>Sunday</day>
    </skipDays>
    <item>
      <title>Federated Learning-Distillation Alternation for Resource-Constrained IoT</title>
      <link>https://arxiv.org/abs/2505.20456</link>
      <description>arXiv:2505.20456v1 Announce Type: new 
Abstract: Federated learning (FL) faces significant challenges in Internet of Things (IoT) networks due to device limitations in energy and communication resources, especially when considering the large size of FL models. From an energy perspective, the challenge is aggravated if devices rely on energy harvesting (EH), as energy availability can vary significantly over time, influencing the average number of participating users in each iteration. Additionally, the transmission of large model updates is more susceptible to interference from uncorrelated background traffic in shared wireless environments. As an alternative, federated distillation (FD) reduces communication overhead and energy consumption by transmitting local model outputs, which are typically much smaller than the entire model used in FL. However, this comes at the cost of reduced model accuracy. Therefore, in this paper, we propose FL-distillation alternation (FLDA). In FLDA, devices alternate between FD and FL phases, balancing model information with lower communication overhead and energy consumption per iteration. We consider a multichannel slotted-ALOHA EH-IoT network subject to background traffic/interference. In such a scenario, FLDA demonstrates higher model accuracy than both FL and FD, and achieves faster convergence than FL. Moreover, FLDA achieves target accuracies saving up to 98% in energy consumption, while also being less sensitive to interference, both relative to FL.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.20456v1</guid>
      <category>eess.SP</category>
      <category>cs.LG</category>
      <pubDate>Wed, 28 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Rafael Valente da Silva, Onel L. Alcaraz L\'opez, Richard Demo Souza</dc:creator>
    </item>
    <item>
      <title>BrainStratify: Coarse-to-Fine Disentanglement of Intracranial Neural Dynamics</title>
      <link>https://arxiv.org/abs/2505.20480</link>
      <description>arXiv:2505.20480v1 Announce Type: new 
Abstract: Decoding speech directly from neural activity is a central goal in brain-computer interface (BCI) research. In recent years, exciting advances have been made through the growing use of intracranial field potential recordings, such as stereo-ElectroEncephaloGraphy (sEEG) and ElectroCorticoGraphy (ECoG). These neural signals capture rich population-level activity but present key challenges: (i) task-relevant neural signals are sparsely distributed across sEEG electrodes, and (ii) they are often entangled with task-irrelevant neural signals in both sEEG and ECoG. To address these challenges, we introduce a unified Coarse-to-Fine neural disentanglement framework, BrainStratify, which includes (i) identifying functional groups through spatial-context-guided temporal-spatial modeling, and (ii) disentangling distinct neural dynamics within the target functional group using Decoupled Product Quantization (DPQ). We evaluate BrainStratify on two open-source sEEG datasets and one (epidural) ECoG dataset, spanning tasks like vocal production and speech perception. Extensive experiments show that BrainStratify, as a unified framework for decoding speech from intracranial neural signals, significantly outperforms previous decoding methods. Overall, by combining data-driven stratification with neuroscience-inspired modularity, BrainStratify offers a robust and interpretable solution for speech decoding from intracranial recordings.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.20480v1</guid>
      <category>eess.SP</category>
      <category>cs.CL</category>
      <category>q-bio.NC</category>
      <pubDate>Wed, 28 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Hui Zheng, Hai-Teng Wang, Yi-Tao Jing, Pei-Yang Lin, Han-Qing Zhao, Wei Chen, Peng-Hu Wei, Yong-Zhi Shan, Guo-Guang Zhao, Yun-Zhe Liu</dc:creator>
    </item>
    <item>
      <title>CardioPatternFormer: Pattern-Guided Attention for Interpretable ECG Classification with Transformer Architecture</title>
      <link>https://arxiv.org/abs/2505.20481</link>
      <description>arXiv:2505.20481v1 Announce Type: new 
Abstract: Accurate ECG interpretation is vital, yet complex cardiac data and "black-box" AI models limit clinical utility. Inspired by Transformer architectures' success in NLP for understanding sequential data, we frame ECG as the heart's unique "language" of temporal patterns. We present CardioPatternFormer, a novel Transformer-based model for interpretable ECG classification. It employs a sophisticated attention mechanism to precisely identify and classify diverse cardiac patterns, excelling at discerning subtle anomalies and distinguishing multiple co-occurring conditions. This pattern-guided attention provides clear insights by highlighting influential signal regions, effectively allowing the "heart to talk" through transparent interpretations. CardioPatternFormer demonstrates robust performance on challenging ECGs, including complex multi-pathology cases. Its interpretability via attention maps enables clinicians to understand the model's rationale, fostering trust and aiding informed diagnostic decisions. This work offers a powerful, transparent solution for advanced ECG analysis, paving the way for more reliable and clinically actionable AI in cardiology.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.20481v1</guid>
      <category>eess.SP</category>
      <category>cs.AI</category>
      <category>cs.LG</category>
      <pubDate>Wed, 28 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Berat Kutay U\u{g}ra\c{s}, \"Omer Nezih Gerek, \.Ibrahim Talha Sayg{\i}</dc:creator>
    </item>
    <item>
      <title>OpenNIRScap: An Open-Source, Low-Cost Wearable Near-Infrared Spectroscopy-based Brain Interfacing Cap</title>
      <link>https://arxiv.org/abs/2505.20509</link>
      <description>arXiv:2505.20509v1 Announce Type: new 
Abstract: Functional Near-Infrared Spectroscopy (fNIRS) is a non-invasive, real-time method for monitoring brain activity by measuring hemodynamic responses in the cerebral cortex. However, existing systems are expensive, bulky, and limited to clinical or research environments. This paper introduces OpenNIRScap, an open-source, low-cost, and wearable fNIRS system designed to make real-time brain monitoring more accessible in everyday environments. The device features 24 custom-designed sensor boards with dual-wavelength light emitters and photodiode detectors, a central electrical control unit (ECU) with analog multiplexing, and a real-time data processing pipeline. Bench validation and pilot tests on volunteers have confirmed the ability of the system to capture cognitively evoked hemodynamic responses, supporting its potential as an affordable tool for cognitive monitoring and portable neurotechnology applications. The hardware, software, and graphical user interface have all been open-sourced and made publicly available at the following link: https://github.com/tonykim07/fNIRS.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.20509v1</guid>
      <category>eess.SP</category>
      <pubDate>Wed, 28 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Tony Kim, Haotian Liu, Chiung-Ting Huang, Ingrid Wu, Xilin Liu</dc:creator>
    </item>
    <item>
      <title>A Unified RCS Modeling of Typical Targets for 3GPP ISAC Channel Standardization and Experimental Analysis</title>
      <link>https://arxiv.org/abs/2505.20673</link>
      <description>arXiv:2505.20673v1 Announce Type: new 
Abstract: Accurate radar cross section (RCS) modeling is crucial for characterizing target scattering and improving the precision of Integrated Sensing and Communication (ISAC) channel modeling. Existing RCS models are typically designed for specific target types, leading to increased complexity and lack of generalization. This makes it difficult to standardize RCS models for 3GPP ISAC channels, which need to account for multiple typical target types simultaneously. Furthermore, 3GPP models must support both system-level and link-level simulations, requiring the integration of large-scale and small-scale scattering characteristics. To address these challenges, this paper proposes a unified RCS modeling framework that consolidates these two aspects. The model decomposes RCS into three components: (1) a large-scale power factor representing overall scattering strength, (2) a small-scale angular-dependent component describing directional scattering, and (3) a random component accounting for variations across target instances. We validate the model through mono-static RCS measurements for UAV, human, and vehicle targets across five frequency bands. The results demonstrate that the proposed model can effectively capture RCS variations for different target types. Finally, the model is incorporated into an ISAC channel simulation platform to assess the impact of target RCS characteristics on path loss, delay spread, and angular spread, providing valuable insights for future ISAC system design.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.20673v1</guid>
      <category>eess.SP</category>
      <pubDate>Wed, 28 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Yuxiang Zhang, Jianhua Zhang, Xidong Hu, Jiwei Zhang, Hongbo Xing, Huiwen Gong, Shilin Luo, Yifeng Xiong, Li Yu, Zhiqing Yuan, Guangyi Liu, Tao Jiang</dc:creator>
    </item>
    <item>
      <title>Dual-Polarization Stacked Intelligent Metasurfaces for Holographic MIMO</title>
      <link>https://arxiv.org/abs/2505.20805</link>
      <description>arXiv:2505.20805v1 Announce Type: new 
Abstract: To address the limited wave domain signal processing capabilities of traditional single-polarized stacked intelligent metasurfaces (SIMs) in holographic multiple-input multiple-output (HMIMO) systems, which stems from limited integration space, this paper proposes a dual-polarized SIM (DPSIM) architecture. By stacking dual-polarized reconfigurable intelligent surfaces (DPRIS), DPSIM can independently process signals of two orthogonal polarizations in the wave domain, thereby effectively suppressing polarization cross-interference (PCI) and inter-stream interference (ISI). We introduce a layer-by-layer gradient descent with water-filling (LGD-WF) algorithm to enhance end-to-end performance. Simulation results show that, under the same number of metasurface layers and unit size, the DPSIM-aided HMIMO system can support more simultaneous data streams for ISI-free parallel transmission compared to traditional SIM-aided systems. Furthermore, under different polarization imperfection conditions, both the spectral efficiency (SE) and energy efficiency (EE) of the DPSIM-aided HMIMO system are significantly improved, approaching the theoretical upper bound.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.20805v1</guid>
      <category>eess.SP</category>
      <pubDate>Wed, 28 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Yida Zhang, Qiuyan Liu, Hongtao Luo, Yuqi Xia, Qiang Wang</dc:creator>
    </item>
    <item>
      <title>Estimators and Performance Bounds for Short Periodic Pulses</title>
      <link>https://arxiv.org/abs/2505.20831</link>
      <description>arXiv:2505.20831v1 Announce Type: new 
Abstract: In many industrial applications, signals with short periodic pulses, caused by repeated steps in the manufacturing process, are present, and their fundamental frequency or period may be of interest. Fundamental frequency estimation is in many cases performed by describing the periodic signal as a multiharmonic signal and employing the corresponding maximum likelihood estimator. However, since signals with short periodic pulses contain a large number of noise-only samples, the multiharmonic signal model is not optimal to describe them. In this work, two models of short periodic pulses with known and unknown pulse shape are considered. For both models, the corresponding maximum likelihood estimators, Fisher information matrices, and approximate Cram\'er-Rao lower bounds are presented. Numerical results demonstrate that the proposed estimators outperform the maximum likelihood estimator based on the multiharmonic signal model for low signal-to-noise ratios.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.20831v1</guid>
      <category>eess.SP</category>
      <pubDate>Wed, 28 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Sebastian Schertler, Oliver Lang, Jonas Lindenberger, Stefan Schuster, Stefan Scheiblhofer, Alexander Haberl, Clemens Staudinger, Mario Huemer</dc:creator>
    </item>
    <item>
      <title>Continuous SpO2 Monitoring Using Reflectance Pulse Oximetry at the Wrist and Upper Arm During Overnight Sleep Apnea Recordings</title>
      <link>https://arxiv.org/abs/2505.20846</link>
      <description>arXiv:2505.20846v1 Announce Type: new 
Abstract: Sleep apnea (SA) is a chronic sleep-related disorder consisting of repetitive pauses or restrictions in airflow during sleep and is known to be a risk factor for cerebro- and cardiovascular disease. It is generally diagnosed using polysomnography (PSG) recorded overnight in an in-lab setting at the hospital. This includes the measurement of blood oxygen saturation (SpO2), which exhibits fluctuations caused by SA events. In this paper, we investigate the accuracy and utility of reflectance pulse oximetry from a wearable device as a means to continuously monitor SpO2 during sleep. To this end, we analyzed data from a cohort of 134 patients with suspected SA undergoing overnight PSG and wearing the watch-like device at two measurement locations (upper arm and wrist). Our data show that standard requirements for pulse oximetry measurements are met at both measurement locations, with an accuracy (root mean squared error) of 1.9% at the upper arm and 3.2% at the wrist. With a rejection rate of 3.1%, the upper arm yielded better results in terms of data quality when compared to the wrist location which had 30.4% of data rejected.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.20846v1</guid>
      <category>eess.SP</category>
      <pubDate>Wed, 28 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Karen Adam, Cl\'ementine Aguet, Patrick Theurillat, Florent Baty, Maximilian Boesch, Damien Ferrario, Mathieu Lemay, Martin Brutsche, Fabian Braun</dc:creator>
    </item>
    <item>
      <title>Dynamic Resource Allocation in Distributed MIMO-LEO Satellite Networks</title>
      <link>https://arxiv.org/abs/2505.20891</link>
      <description>arXiv:2505.20891v1 Announce Type: new 
Abstract: This paper characterizes the impacts of channel estimation errors and Rician factors on achievable data rate and investigates the user scheduling strategy, combining scheme, power control, and dynamic bandwidth allocation to maximize the sum data rate in the distributed multiple-input-multiple-output (MIMO)-enabled low earth orbit (LEO) satellite networks. However, due to the resource-assignment problem, it is challenging to find the optimal solution for maximizing the sum data rate. To transform this problem into a more tractable form, we first quantify the channel estimation errors based on the minimum mean square error (MMSE) estimator and rigorously derive a closed-form lower bound of the achievable data rate, offering an explicit formulation for resource allocation. Then, to solve the NP-hard problem, we decompose it into three sub-problems, namely, user scheduling strategy, joint combination and power control, and dynamic bandwidth allocation, by using alternative optimization (AO). Specifically, the user scheduling is formulated as a graph coloring problem by iteratively updating an undirected graph based on user requirements, which is then solved using the DSatur algorithm. For the combining weights and power control, the successive convex approximation (SCA) and geometrical programming (GP) are adopted to obtain the sub-optimal solution with lower complexity. Finally, the optimal bandwidth allocation can be achieved by solving the concave problem.
  Numerical results validate the analytical tightness of the derived bound, especially for large Rician factors, and demonstrate significant performance gains over other benchmarks.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.20891v1</guid>
      <category>eess.SP</category>
      <pubDate>Wed, 28 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Qihao Peng, Qu Luo, Yi Ma, Chuan Heng Foh, Pei Xiao, Maged Elkashlan, Rahim Tafazolli, George K. Karagiannidis</dc:creator>
    </item>
    <item>
      <title>Recognition of Physiological Patterns during Activities of Daily Living Using Wearable Biosignal Sensors</title>
      <link>https://arxiv.org/abs/2505.20917</link>
      <description>arXiv:2505.20917v1 Announce Type: new 
Abstract: A key aspect of developing fall prevention systems is the early prediction of a fall before it occurs. This paper presents a statistical overview of results obtained by analyzing 22 activities of daily living to recognize physiological patterns and estimate the risk of an imminent fall. The results demonstrate distinctive patterns between high-intensity and low-intensity activity using EMG, ECG, and respiration sensors, also indicating the presence of a proportional trend between movement velocity and muscle activity. These outcomes highlight the potential benefits of using these sensors in the future to direct the development of an activity recognition and risk prediction framework for physiological phenomena that can cause fall injuries.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.20917v1</guid>
      <category>eess.SP</category>
      <pubDate>Wed, 28 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <arxiv:journal_reference>22nd Triennial Congress of the International Ergonomics Association (IEA 2024)</arxiv:journal_reference>
      <dc:creator>Nicholas Cartocci, Antonios E. Gkikakis, Natalia Kurvina, Natnael Takele, Fabio Pera, Maria Teresa Settino, Darwin G. Caldwell, Jes\'us Ortiz</dc:creator>
    </item>
    <item>
      <title>Ergonomic Assessment of Work Activities for an Industrial-oriented Wrist Exoskeleton</title>
      <link>https://arxiv.org/abs/2505.20939</link>
      <description>arXiv:2505.20939v1 Announce Type: new 
Abstract: Musculoskeletal disorders (MSD) are the most common cause of work-related injuries and lost production involving approximately 1.7 billion people worldwide and mainly affect low back (more than 50%) and upper limbs (more than 40%). It has a profound effect on both the workers affected and the company. This paper provides an ergonomic assessment of different work activities in a horse saddle-making company, involving 5 workers. This aim guides the design of a wrist exoskeleton to reduce the risk of musculoskeletal diseases wherever it is impossible to automate the production process. This evaluation is done either through subjective and objective measurement, respectively using questionnaires and by measurement of muscle activation with sEMG sensors.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.20939v1</guid>
      <category>eess.SP</category>
      <pubDate>Wed, 28 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <arxiv:journal_reference>22nd Triennial Congress of the International Ergonomics Association (IEA 2024) 22nd Triennial Congress of the International Ergonomics Association (IEA 2024) 22nd Triennial Congress of the International Ergonomics Association (IEA 2024)</arxiv:journal_reference>
      <dc:creator>Roberto F. Pitzalis, Nicholas Cartocci, Christian Di Natali, Luigi Monica, Darwin G. Caldwell, Giovanni Berselli, Jes\'us Ortiz</dc:creator>
    </item>
    <item>
      <title>CNN-Based Channel Map Estimation for Movable Antenna Systems</title>
      <link>https://arxiv.org/abs/2505.21001</link>
      <description>arXiv:2505.21001v1 Announce Type: new 
Abstract: Movable antenna (MA) has attracted increasing attention in wireless communications due to its capability of wireless channel reconfiguration through local antenna movement within a confined region at the transmitter/receiver. However, to determine the optimal antenna positions, channel state information (CSI) within the entire region, termed small-scale channel map, is required, which poses a significant challenge due to the unaffordable overhead for exhaustive channel estimation at all positions. To tackle this challenge, in this paper, we propose a new convolutional neural network (CNN)-based estimation scheme to reconstruct the small-scale channel map within a three-dimensional (3D) movement region. Specifically, we first collect a set of CSI measurements corresponding to a subset of MA positions and different receiver locations offline to comprehensively capture the environmental features. Subsequently, we train a CNN using the collected data, which is then used to reconstruct the full channel map during real-time transmission only based on a finite number of channel measurements taken at several selected MA positions within the 3D movement region. Numerical results demonstrate that our proposed scheme can accurately reconstruct the small-scale channel map and outperforms other benchmark schemes.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.21001v1</guid>
      <category>eess.SP</category>
      <pubDate>Wed, 28 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Yitai Huang, Weidong Mei, Xin Wei, Zhi Chen, Boyu Ning</dc:creator>
    </item>
    <item>
      <title>Channel-Aware Holographic Decision Fusion</title>
      <link>https://arxiv.org/abs/2505.21035</link>
      <description>arXiv:2505.21035v1 Announce Type: new 
Abstract: This work investigates Distributed Detection (DD) in Wireless Sensor Networks (WSNs) utilizing channel-aware binary-decision fusion over a shared flat-fading channel. A reconfigurable metasurface, positioned in the near-field of a limited number of receive antennas, is integrated to enable a holographic Decision Fusion (DF) system. This approach minimizes the need for multiple RF chains while leveraging the benefits of a large array. The optimal fusion rule for a fixed metasurface configuration is derived, alongside two suboptimal joint fusion rule and metasurface design strategies. These suboptimal approaches strike a balance between reduced complexity and lower system knowledge requirements, making them practical alternatives. The design objective focuses on effectively conveying the information regarding the phenomenon of interest to the FC while promoting energy-efficient data analytics aligned with the Internet of Things (IoT) paradigm. Simulation results underscore the viability of holographic DF, demonstrating its advantages even with suboptimal designs and highlighting the significant energy-efficiency gains achieved by the proposed system.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.21035v1</guid>
      <category>eess.SP</category>
      <pubDate>Wed, 28 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Domenico Ciuonzo, Alessio Zappone, Marco Di Renzo</dc:creator>
    </item>
    <item>
      <title>CiUAV: A Multi-Task 3D Indoor Localization System for UAVs based on Channel State Information</title>
      <link>https://arxiv.org/abs/2505.21216</link>
      <description>arXiv:2505.21216v1 Announce Type: new 
Abstract: Accurate indoor positioning for unmanned aerial vehicles (UAVs) is critical for logistics, surveillance, and emergency response applications, particularly in GPS-denied environments. Existing indoor localization methods, including optical tracking, ultra-wideband, and Bluetooth-based systems, face cost, accuracy, and robustness trade-offs, limiting their practicality for UAV navigation. This paper proposes CiUAV, a novel 3D indoor localization system designed for UAVs, leveraging channel state information (CSI) obtained from low-cost ESP32 IoT-based sensors. The system incorporates a dynamic automatic gain control (AGC) compensation algorithm to mitigate noise and stabilize CSI signals, significantly enhancing the robustness of the measurement. Additionally, a multi-task 3D localization model, Sensor-in-Sample (SiS), is introduced to enhance system robustness by addressing challenges related to incomplete sensor data and limited training samples. SiS achieves this by joint training with varying sensor configurations and sample sizes, ensuring reliable performance even in resource-constrained scenarios. Experiment results demonstrate that CiUAV achieves a LMSE localization error of 0.2629 m in a 3D space, achieving good accuracy and robustness. The proposed system provides a cost-effective and scalable solution, demonstrating its usefulness for UAV applications in resource-constrained indoor environments.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.21216v1</guid>
      <category>eess.SP</category>
      <pubDate>Wed, 28 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Cunyi Yin, Chenwei Wang, Jing Chen, Hao Jiang, Xiren Miao, Shaocong Zheng Zhenghua Chen Senior, Hong Yan</dc:creator>
    </item>
    <item>
      <title>Graph Neural Network Aided Detection for the Multi-User Multi-Dimensional Index Modulated Uplink</title>
      <link>https://arxiv.org/abs/2505.21343</link>
      <description>arXiv:2505.21343v1 Announce Type: new 
Abstract: The concept of Compressed Sensing-aided Space-Frequency Index Modulation (CS-SFIM) is conceived for the Large-Scale Multi-User Multiple-Input Multiple-Output Uplink (LS-MU-MIMO-UL) of Next-Generation (NG) networks. Explicitly, in CS-SFIM, the information bits are mapped to both spatial- and frequency-domain indices, where we treat the activation patterns of the transmit antennas and of the subcarriers separately. Serving a large number of users in an MU-MIMO-UL system leads to substantial Multi-User Interference (MUI). Hence, we design the Space-Frequency (SF) domain matrix as a joint factor graph, where the Approximate Message Passing (AMP) and Expectation Propagation (EP) based MU detectors can be utilized. In the LS-MU-MIMO-UL scenario considered, the proposed system uses optimal Maximum Likelihood (ML) and Minimum Mean Square Error (MMSE) detectors as benchmarks for comparison with the proposed MP-based detectors. These MP-based detectors significantly reduce the detection complexity compared to ML detection, making the design eminently suitable for LS-MU scenarios. To further reduce the detection complexity and improve the detection performance, we propose a pair of Graph Neural Network (GNN) based detectors, which rely on the orthogonal AMP (OAMP) and on the EP algorithm, which we refer to as the GNN-AMP and GEPNet detectors, respectively. The GEPNet detector maximizes the detection performance, while the GNN-AMP detector strikes a performance versus complexity trade-off. The GNN is trained for a single system configuration and yet it can be used for any number of users in the system. The simulation results show that the GNN-based detector approaches the ML performance in various configurations.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.21343v1</guid>
      <category>eess.SP</category>
      <pubDate>Wed, 28 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Xinyu Feng, Mohammed EL-Hajjar, Chao Xu, Lajos Hanzo</dc:creator>
    </item>
    <item>
      <title>Label-free Super-Resolution Microvessel Color Flow Imaging with Ultrasound</title>
      <link>https://arxiv.org/abs/2505.21384</link>
      <description>arXiv:2505.21384v1 Announce Type: new 
Abstract: We present phase subtraction imaging (PSI), a new spatial-temporal beamforming method that enables micrometer level resolution imaging of microvessels in live animals without labels, which are microbubbles in ultrasound super-resolution imaging. Subtraction of relative phase differences between consecutive frames beamformed with mismatched apodizations is used in PSI to overcome the diffraction limit. We validated this method by imaging both the mouse brain and rabbit kidney using different ultrasound probes and scanning machines.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.21384v1</guid>
      <category>eess.SP</category>
      <pubDate>Wed, 28 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Zhengchang Kou, Junhang Zhang, Chen Gong, Jie Ji, Nathiya Vaithiyalingam Chandra Sekaran, Zikai Wang, Rita J. Miller, Yaoheng Yang, Daniel Adolfo Llano, Qifa Zhou, Michael L. Oelze</dc:creator>
    </item>
    <item>
      <title>Expectation-maximization for multi-reference alignment: Two pitfalls and one remedy</title>
      <link>https://arxiv.org/abs/2505.21435</link>
      <description>arXiv:2505.21435v1 Announce Type: new 
Abstract: We study the multi-reference alignment model, which involves recovering a signal from noisy observations that have been randomly transformed by an unknown group action, a fundamental challenge in statistical signal processing, computational imaging, and structural biology. While much of the theoretical literature has focused on the asymptotic sample complexity of this model, the practical performance of reconstruction algorithms, particularly of the omnipresent expectation maximization (EM) algorithm, remains poorly understood.
  In this work, we present a detailed investigation of EM in the challenging low signal-to-noise ratio (SNR) regime. We identify and characterize two failure modes that emerge in this setting. The first, called Einstein from Noise, reveals a strong sensitivity to initialization, with reconstructions resembling the input template regardless of the true underlying signal. The second phenomenon, referred to as the Ghost of Newton, involves EM initially converging towards the correct solution but later diverging, leading to a loss of reconstruction fidelity. We provide theoretical insights and support our findings through numerical experiments. Finally, we introduce a simple, yet effective modification to EM based on mini-batching, which mitigates the above artifacts. Supported by both theory and experiments, this mini-batching approach processes small data subsets per iteration, reducing initialization bias and computational cost, while maintaining accuracy comparable to full-batch EM.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.21435v1</guid>
      <category>eess.SP</category>
      <pubDate>Wed, 28 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Amnon Balanov, Wasim Huleihel, Tamir Bendory</dc:creator>
    </item>
    <item>
      <title>PromptEVC: Controllable Emotional Voice Conversion with Natural Language Prompts</title>
      <link>https://arxiv.org/abs/2505.20678</link>
      <description>arXiv:2505.20678v1 Announce Type: cross 
Abstract: Controllable emotional voice conversion (EVC) aims to manipulate emotional expressions to increase the diversity of synthesized speech. Existing methods typically rely on predefined labels, reference audios, or prespecified factor values, often overlooking individual differences in emotion perception and expression. In this paper, we introduce PromptEVC that utilizes natural language prompts for precise and flexible emotion control. To bridge text descriptions with emotional speech, we propose emotion descriptor and prompt mapper to generate fine-grained emotion embeddings, trained jointly with reference embeddings. To enhance naturalness, we present a prosody modeling and control pipeline that adjusts the rhythm based on linguistic content and emotional cues. Additionally, a speaker encoder is incorporated to preserve identity. Experimental results demonstrate that PromptEVC outperforms state-of-the-art controllable EVC methods in emotion conversion, intensity control, mixed emotion synthesis, and prosody manipulation. Speech samples are available at https://jeremychee4.github.io/PromptEVC/.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.20678v1</guid>
      <category>eess.AS</category>
      <category>cs.SD</category>
      <category>eess.SP</category>
      <pubDate>Wed, 28 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Tianhua Qi, Shiyan Wang, Cheng Lu, Tengfei Song, Hao Yang, Zhanglin Wu, Wenming Zheng</dc:creator>
    </item>
    <item>
      <title>Polarforming for Wireless Networks: Opportunities and Challenges</title>
      <link>https://arxiv.org/abs/2505.20760</link>
      <description>arXiv:2505.20760v1 Announce Type: cross 
Abstract: Polarforming emerges as a promising technique for manipulating the polarization of electromagnetic (EM) waves by shaping the polarization of an antenna into a desired state. By dynamically adjusting antenna polarization, polarforming enables real-time polarization matching or mismatching with received EM waves, thereby leveraging polarization degrees of freedom (DoFs) to enhance wireless communication performance. In this article, we first present an overview of the fundamental principles and design approaches underlying the polarforming technique. We then analyze the key advantages of polarforming, including hardware cost reduction, depolarization mitigation, channel adaptation, signal power enhancement, and interference suppression. Furthermore, we explore promising applications of polarforming for next-generation wireless networks. Numerical case studies demonstrate the substantial performance gains of polarforming over conventional fixed-polarization antenna (FPA) systems, along with a discussion of implementation challenges to motivate future research.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.20760v1</guid>
      <category>cs.IT</category>
      <category>eess.SP</category>
      <category>math.IT</category>
      <pubDate>Wed, 28 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Jingze Ding, Zijian Zhou, Bingli Jiao, Rui Zhang</dc:creator>
    </item>
    <item>
      <title>Non-invasive maturity assessment of iPSC-CMs based on optical maturity characteristics using interpretable AI</title>
      <link>https://arxiv.org/abs/2505.20775</link>
      <description>arXiv:2505.20775v1 Announce Type: cross 
Abstract: Human induced pluripotent stem cell-derived cardiomyocytes (iPSC-CMs) are an important resource for the identification of new therapeutic targets and cardioprotective drugs. After differentiation iPSC-CMs show an immature, fetal-like phenotype. Cultivation of iPSC-CMs in lipid-supplemented maturation medium (MM) strongly enhances their structural, metabolic and functional phenotype. Nevertheless, assessing iPSC-CM maturation state remains challenging as most methods are time consuming and go in line with cell damage or loss of the sample. To address this issue, we developed a non-invasive approach for automated classification of iPSC-CM maturity through interpretable artificial intelligence (AI)-based analysis of beat characteristics derived from video-based motion analysis. In a prospective study, we evaluated 230 video recordings of early-state, immature iPSC-CMs on day 21 after differentiation (d21) and more mature iPSC-CMs cultured in MM (d42, MM). For each recording, 10 features were extracted using Maia motion analysis software and entered into a support vector machine (SVM). The hyperparameters of the SVM were optimized in a grid search on 80 % of the data using 5-fold cross-validation. The optimized model achieved an accuracy of 99.5 $\pm$ 1.1 % on a hold-out test set. Shapley Additive Explanations (SHAP) identified displacement, relaxation-rise time and beating duration as the most relevant features for assessing maturity level. Our results suggest the use of non-invasive, optical motion analysis combined with AI-based methods as a tool to assess iPSC-CMs maturity and could be applied before performing functional readouts or drug testing. This may potentially reduce the variability and improve the reproducibility of experimental studies.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.20775v1</guid>
      <category>cs.LG</category>
      <category>eess.SP</category>
      <category>q-bio.CB</category>
      <pubDate>Wed, 28 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Fabian Scheurer, Alexander Hammer, Mario Schubert, Robert-Patrick Steiner, Oliver Gamm, Kaomei Guan, Frank Sonntag, Hagen Malberg, Martin Schmidt</dc:creator>
    </item>
    <item>
      <title>Dynamical ON-OFF Control with Trajectory Prediction for Multi-RIS Wireless Networks</title>
      <link>https://arxiv.org/abs/2505.20887</link>
      <description>arXiv:2505.20887v1 Announce Type: cross 
Abstract: Reconfigurable intelligent surfaces (RISs) have demonstrated an unparalleled ability to reconfigure wireless environments by dynamically controlling the phase, amplitude, and polarization of impinging waves. However, as nearly passive reflective metasurfaces, RISs may not distinguish between desired and interference signals, which can lead to severe spectrum pollution and even affect performance negatively. In particular, in large-scale networks, the signal-to-interference-plus-noise ratio (SINR) at the receiving node can be degraded due to excessive interference reflected from the RIS. To overcome this fundamental limitation, we propose in this paper a trajectory prediction-based dynamical control algorithm (TPC) for anticipating RIS ON-OFF states sequence, integrating a long-short-term-memory (LSTM) scheme to predict user trajectories. In particular, through a codebook-based algorithm, the RIS controller adaptively coordinates the configuration of the RIS elements to maximize the received SINR. Our simulation results demonstrate the superiority of the proposed TPC method over various system settings.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.20887v1</guid>
      <category>cs.NI</category>
      <category>eess.SP</category>
      <pubDate>Wed, 28 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Kaining Wang, Bo Yang, Yusheng Lei, Zhiwen Yu, Xuelin Cao, George C. Alexandropoulos, Marco Di Renzo, Chau Yuen</dc:creator>
    </item>
    <item>
      <title>Analysis of Joint Radar and Communication in Disaster Scenarios</title>
      <link>https://arxiv.org/abs/2505.20931</link>
      <description>arXiv:2505.20931v1 Announce Type: cross 
Abstract: With the increasing frequency and intensity of natural disasters, there is a necessity for advanced technologies that can provide reliable situational awareness and communication. Conventional systems are often inadequate due to unreliable infrastructure, power grid failures, high investment costs and scalability challenges. This paper explores the potential of ad-hoc mesh joint radar and communication (JRC) networks as a scalable, resilient, energy-efficient solution for disaster management that can operate independently of conventional infrastructure. The proposed JRC network enhances disaster response by integrating target detection (such as identifying vital signs, hazardous leaks, and fires) with communication capabilities to ensure efficient information dissemination under intense clutter conditions. Key performance metrics, including data rate, Signal-to-Clutter and Noise Ratio (SCNR), probability of detection, and false alarm rate, are used to assess performance. An optimization approach is proposed to provide an energy-efficient resource allocation scheme. The results show the performance of ad-hoc mesh JRC systems, underscoring their potential to enhance disaster management efforts by addressing unique operational challenges.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.20931v1</guid>
      <category>eess.SY</category>
      <category>cs.SY</category>
      <category>eess.SP</category>
      <pubDate>Wed, 28 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <arxiv:DOI>10.1109/WCNC61545.2025.10978675</arxiv:DOI>
      <arxiv:journal_reference>A. B. Ozyurt, S. Mohalik and J. S. Thompson, "Analysis of Joint Radar and Communication in Disaster Scenarios," 2025 IEEE Wireless Communications and Networking Conference (WCNC), Milan, Italy, 2025, pp. 1-6</arxiv:journal_reference>
      <dc:creator>Ahmet Burak Ozyurt, Shreesh Mohalik, John S. Thompson</dc:creator>
    </item>
    <item>
      <title>Scattering Networks on Noncommutative Finite Groups</title>
      <link>https://arxiv.org/abs/2505.20950</link>
      <description>arXiv:2505.20950v1 Announce Type: cross 
Abstract: Scattering Networks were initially designed to elucidate the behavior of early layers in Convolutional Neural Networks (CNNs) over Euclidean spaces and are grounded in wavelets. In this work, we introduce a scattering transform on an arbitrary finite group (not necessarily abelian) within the context of group-equivariant convolutional neural networks (G-CNNs). We present wavelets on finite groups and analyze their similarity to classical wavelets. We demonstrate that, under certain conditions in the wavelet coefficients, the scattering transform is non-expansive, stable under deformations, preserves energy, equivariant with respect to left and right group translations, and, as depth increases, the scattering coefficients are less sensitive to group translations of the signal, all desirable properties of convolutional neural networks. Furthermore, we provide examples illustrating the application of the scattering transform to classify data with domains involving abelian and nonabelian groups.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.20950v1</guid>
      <category>math.NA</category>
      <category>cs.IT</category>
      <category>cs.LG</category>
      <category>cs.NA</category>
      <category>eess.SP</category>
      <category>math.IT</category>
      <pubDate>Wed, 28 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Maria Teresa Arias, Davide Barbieri, Eugenio Hern\'andez</dc:creator>
    </item>
    <item>
      <title>Interference Detection in Spectrum-Blind Multi-User Optical Spectrum as a Service</title>
      <link>https://arxiv.org/abs/2505.21018</link>
      <description>arXiv:2505.21018v1 Announce Type: cross 
Abstract: With the growing demand for high-bandwidth, low-latency applications, Optical Spectrum as a Service (OSaaS) is of interest for flexible bandwidth allocation within Elastic Optical Networks (EONs) and Open Line Systems (OLS). While OSaaS facilitates transparent connectivity and resource sharing among users, it raises concerns over potential network vulnerabilities due to shared fiber access and inter-channel interference, such as fiber non-linearity and amplifier based crosstalk. These challenges are exacerbated in multi-user environments, complicating the identification and localization of service interferences. To reduce system disruptions and system repair costs, it is beneficial to detect and identify such interferences timely. Addressing these challenges, this paper introduces a Machine Learning (ML) based architecture for network operators to detect and attribute interferences to specific OSaaS users while blind to the users' internal spectrum details. Our methodology leverages available coarse power measurements and operator channel performance data, bypassing the need for internal user information of wide-band shared spectra. Experimental studies conducted on a 190 km optical line system in the Open Ireland testbed, with three OSaaS users demonstrate the model's capability to accurately classify the source of interferences, achieving a classification accuracy of 90.3%.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.21018v1</guid>
      <category>cs.NI</category>
      <category>eess.SP</category>
      <pubDate>Wed, 28 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <arxiv:DOI>10.1364/JOCN.551188</arxiv:DOI>
      <arxiv:journal_reference>Journal of Optical Communications and Networking, Vol. 17, Issue 8, pp. C117-C126 (2025)</arxiv:journal_reference>
      <dc:creator>Agastya Raj, Daniel C. Kilper, Marco Ruffini</dc:creator>
    </item>
    <item>
      <title>Model as Loss: A Self-Consistent Training Paradigm</title>
      <link>https://arxiv.org/abs/2505.21156</link>
      <description>arXiv:2505.21156v1 Announce Type: cross 
Abstract: Conventional methods for speech enhancement rely on handcrafted loss functions (e.g., time or frequency domain losses) or deep feature losses (e.g., using WavLM or wav2vec), which often fail to capture subtle signal properties essential for optimal performance. To address this, we propose Model as Loss, a novel training paradigm that utilizes the encoder from the same model as a loss function to guide the training.
  The Model as Loss paradigm leverages the encoder's task-specific feature space, optimizing the decoder to produce output consistent with perceptual and task-relevant characteristics of the clean signal. By using the encoder's learned features as a loss function, this framework enforces self-consistency between the clean reference speech and the enhanced model output. Our approach outperforms pre-trained deep feature losses on standard speech enhancement benchmarks, offering better perceptual quality and robust generalization to both in-domain and out-of-domain datasets.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.21156v1</guid>
      <category>cs.SD</category>
      <category>cs.AI</category>
      <category>cs.LG</category>
      <category>eess.AS</category>
      <category>eess.SP</category>
      <pubDate>Wed, 28 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Saisamarth Rajesh Phaye, Milos Cernak, Andrew Harper</dc:creator>
    </item>
    <item>
      <title>WiCAL: Accurate Wi-Fi-Based 3D Localization Enabled by Collaborative Antenna Arrays</title>
      <link>https://arxiv.org/abs/2505.21408</link>
      <description>arXiv:2505.21408v1 Announce Type: cross 
Abstract: Accurate 3D localization is essential for realizing advanced sensing functionalities in next-generation Wi-Fi communication systems. This study investigates the potential of multistatic localization in Wi-Fi networks through the deployment of multiple cooperative antenna arrays. The collaborative gain offered by these arrays is twofold: (i) intra-array coherent gain at the wavelength scale among antenna elements, and (ii) inter-array cooperative gain across arrays. To evaluate the feasibility and performance of this approach, we develop WiCAL (Wi-Fi Collaborative Antenna Localization), a system built upon commercial Wi-Fi infrastructure equipped with uniform rectangular arrays. These arrays are driven by multiplexing embedded radio frequency chains available in standard access points or user devices, thereby eliminating the need for sophisticated, costly, and power-hungry multi-transceiver modules typically required in multiple-input and multiple-output systems. To address phase offsets introduced by RF chain multiplexing, we propose a three-stage, fine-grained phase alignment scheme to synchronize signals across antenna elements within each array. A bidirectional spatial smoothing MUSIC algorithm is employed to estimate angles of arrival (AoAs) and mitigate performance degradation caused by correlated interference. To further exploit inter-array cooperative gain, we elaborate on the synchronization mechanism among distributed URAs, which enables direct position determination by bypassing intermediate angle estimation. Once synchronized, the distributed URAs effectively form a virtual large-scale array, significantly enhancing spatial resolution and localization accuracy.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.21408v1</guid>
      <category>eess.SY</category>
      <category>cs.SY</category>
      <category>eess.SP</category>
      <pubDate>Wed, 28 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Fuhai Wang, Zhe Li, Rujing Xiong, Tiebin Mi, Robert Caiming Qiu</dc:creator>
    </item>
    <item>
      <title>Distribution Bounds on the Conditional ROC in a Poisson Field of Interferers and Clutters</title>
      <link>https://arxiv.org/abs/2505.21456</link>
      <description>arXiv:2505.21456v1 Announce Type: cross 
Abstract: We present a novel analytical framework to characterize the distribution of the conditional receiver operating characteristic (ROC) in radar systems operating within a realization of a Poisson field of interferers and clutters. While conventional stochastic geometry based studies focus on the distribution of signal to interference and noise ratio (SINR), they fail to capture the statistical variations in detection and false-alarm performance across different network realizations. By leveraging higher-order versions of the Campbell-Mecke theorem and tools from stochastic geometry, we derive closed-form expressions for the mean and variance of the conditional false-alarm probability, and provide tight upper bounds using Cantelli's inequality. Additionally, we present a beta distribution approximation to capture the meta-distribution of the noise and interference power, enabling fine-grained performance evaluation. The results are extended to analyze the conditional detection probability, albeit with simpler bounds. Our approach reveals a new approach to radar design and robust ROC selection, including percentile-level guarantees, which are essential for emerging high-reliability applications. The insights derived here advocate for designing radar detection thresholds and signal processing algorithms based not merely on mean false-alarm or detection probabilities, but on tail behavior and percentile guarantees.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.21456v1</guid>
      <category>cs.IT</category>
      <category>eess.SP</category>
      <category>math.IT</category>
      <pubDate>Wed, 28 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Gourab Ghatak</dc:creator>
    </item>
    <item>
      <title>Beamforming Design for Intelligent Reffecting Surface Aided Near-Field THz Communications</title>
      <link>https://arxiv.org/abs/2410.08459</link>
      <description>arXiv:2410.08459v2 Announce Type: replace 
Abstract: Intelligent reflecting surface (IRS) operating in the terahertz (THz) band has recently gained considerable interest due to its high spectrum bandwidth. Due to the exploitation of large scale of IRS, there is a high probability that the transceivers will be situated within the near-field region of the IRS. Thus, the near-field beam split effect poses a major challenge for the design of wideband IRS beamforming, which causes the radiation beam to deviate from its intended location, leading to significant gain losses and limiting the efficient use of available bandwidths. While delay-based IRS has emerged as a potential solution, current beamforming schemes generally assume unbounded range time delays (TDs). In this letter, we first investigate the near-field beam split issue at the IRS. Then, we extend the piece-wise far-field model to the IRS, based on which, a double-layer delta-delay (DLDD) IRS beamforming scheme is proposed. Specifically, we employ an element-grouping strategy and the TD imposed on each sub-surface of IRS is achieved by a series of TD modules. This method significantly reduces the required range of TDs. Numerical results show that the proposed DLDD IRS beamforming scheme can effectively mitigate the near-field beam split and achieve near-optimal performance.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.08459v2</guid>
      <category>eess.SP</category>
      <category>cs.IT</category>
      <category>cs.NI</category>
      <category>math.IT</category>
      <pubDate>Wed, 28 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Chi Qiu, Qingqing Wu, Wen Chen, Meng Hua, Wanming Hao, Mengnan Jian, Fen Hou</dc:creator>
    </item>
    <item>
      <title>Radar Network for Gait Monitoring: Technology and Validation</title>
      <link>https://arxiv.org/abs/2502.12696</link>
      <description>arXiv:2502.12696v2 Announce Type: replace 
Abstract: In recent years, radar-based devices have emerged as an alternative approach for gait monitoring. However, the radar configuration and the algorithms used to extract the gait parameters often differ between contributions, lacking a systematic evaluation of the most appropriate setup. Additionally, radar-based studies often exclude motorically impaired subjects, leaving it unclear whether the existing algorithms are applicable to such populations. In this paper, a radar network is developed and validated by monitoring the gait of five healthy individuals and three patients with Parkinson's disease. Six configurations and four algorithms were compared using Vicon as ground-truth to determine the most appropriate solution for gait monitoring. The best results were obtained using only three nodes: two oriented towards the feet and one towards the torso. The most accurate stride velocity and distance in the state of the art were obtained with this configuration. Moreover, we show that analyzing the feet velocity increases the reliability of the temporal parameters, especially with aged or motorically impaired subjects. The contribution is significant for the implementation of radar networks in clinical and domestic environments, as it addresses critical aspects concerning the radar network configuration and algorithms.</description>
      <guid isPermaLink="false">oai:arXiv.org:2502.12696v2</guid>
      <category>eess.SP</category>
      <category>cs.SY</category>
      <category>eess.SY</category>
      <pubDate>Wed, 28 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Ignacio E. L\'opez-Delgado, V\'ictor Navarro-L\'opez, Francisco Grandas-P\'erez, Juan I. Godino-Llorente, Jes\'us Grajal</dc:creator>
    </item>
    <item>
      <title>Frequency-Aware Masked Autoencoders for Human Activity Recognition using Accelerometers</title>
      <link>https://arxiv.org/abs/2502.17477</link>
      <description>arXiv:2502.17477v2 Announce Type: replace 
Abstract: Wearable accelerometers are widely used for continuous monitoring of physical activity. Supervised machine learning and deep learning algorithms have long been used to extract meaningful activity information from raw accelerometry data, but progress has been hampered by the limited amount of labeled data that is publicly available. Exploiting large unlabeled datasets using self-supervised pretraining is a relatively new and underexplored approach in the field of human activity recognition (HAR). We used a time-series transformer masked autoencoder (MAE) approach to self-supervised pretraining and propose two novel spectrogram-based loss functions: the log-scale meanmagnitude (LMM) and log-scale magnitude variance (LMV) losses. We compared these losses with the mean squared error (MSE) loss for MAE training. We leveraged the large unlabeled UK Biobank accelerometry dataset (n = 109k) for pretraining and evaluated downstream HAR performance using a linear classifier in a smaller labelled dataset. We found that pretraining with the LMM loss improved performance compared to an MAE pretrained with the MSE loss, with 12.7% increase in subject-wise F1 score when using linear probing. Compared with a state-of-the-art ResNet-based HAR model, our LMM-pretrained transformer models performed better (+9.8% F1) with linear probing and comparably when fine-tuned using an LSTM classifier. The addition of the LMV to the LMM loss decreased performance compared to the LMM loss alone. These findings establish the LMM loss as a robust and effective method for pretraining MAE models on accelerometer data for HAR and show the potential of pretraining sequence-based models for free-living HAR.</description>
      <guid isPermaLink="false">oai:arXiv.org:2502.17477v2</guid>
      <category>eess.SP</category>
      <category>cs.LG</category>
      <pubDate>Wed, 28 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <dc:creator>Niels R. Lorenzen, Poul J. Jennum, Emmanuel Mignot, Andreas Brink-Kjaer</dc:creator>
    </item>
    <item>
      <title>Improving Generative Inverse Design of Rectangular Patch Antennas with Test Time Optimization</title>
      <link>https://arxiv.org/abs/2505.18188</link>
      <description>arXiv:2505.18188v2 Announce Type: replace 
Abstract: We propose a two-stage deep learning framework for the inverse design of rectangular patch antennas. Our approach leverages generative modeling to learn a latent representation of antenna frequency response curves and conditions a subsequent generative model on these responses to produce feasible antenna geometries. We further demonstrate that leveraging search and optimization techniques at test-time improves the accuracy of the generated designs and enables consideration of auxiliary objectives such as manufacturability. Our approach generalizes naturally to different design criteria, and can be easily adapted to more complex geometric design spaces.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.18188v2</guid>
      <category>eess.SP</category>
      <category>cs.AI</category>
      <category>cs.LG</category>
      <category>cs.SY</category>
      <category>eess.SY</category>
      <pubDate>Wed, 28 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Beck LaBash, Shahriar Khushrushahi, Fabian Ruehle</dc:creator>
    </item>
    <item>
      <title>PhySense: Sensor Placement Optimization for Accurate Physics Sensing</title>
      <link>https://arxiv.org/abs/2505.18190</link>
      <description>arXiv:2505.18190v2 Announce Type: replace 
Abstract: Physics sensing plays a central role in many scientific and engineering domains, which inherently involves two coupled tasks: reconstructing dense physical fields from sparse observations and optimizing scattered sensor placements to observe maximum information. While deep learning has made rapid advances in sparse-data reconstruction, existing methods generally omit optimization of sensor placements, leaving the mutual enhancement between reconstruction and placement on the shelf. To change this suboptimal practice, we propose PhySense, a synergistic two-stage framework that learns to jointly reconstruct physical fields and to optimize sensor placements, both aiming for accurate physics sensing. The first stage involves a flow-based generative model enhanced by cross-attention to adaptively fuse sparse observations. Leveraging the reconstruction feedback, the second stage performs sensor placement via projected gradient descent to satisfy spatial constraints. We further prove that the learning objectives of the two stages are consistent with classical variance-minimization principles, providing theoretical guarantees. Extensive experiments across three challenging benchmarks, especially a 3D geometry dataset, indicate PhySense achieves state-of-the-art physics sensing accuracy and discovers informative sensor placements previously unconsidered.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.18190v2</guid>
      <category>eess.SP</category>
      <category>cs.AI</category>
      <category>cs.LG</category>
      <pubDate>Wed, 28 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Yuezhou Ma, Haixu Wu, Hang Zhou, Huikun Weng, Jianmin Wang, Mingsheng Long</dc:creator>
    </item>
    <item>
      <title>DYMAG: Rethinking Message Passing Using Dynamical-systems-based Waveforms</title>
      <link>https://arxiv.org/abs/2309.09924</link>
      <description>arXiv:2309.09924v5 Announce Type: replace-cross 
Abstract: We present DYMAG, a graph neural network based on a novel form of message aggregation. Standard message-passing neural networks, which often aggregate local neighbors via mean-aggregation, can be regarded as convolving with a simple rectangular waveform which is non-zero only on 1-hop neighbors of every vertex. Here, we go beyond such local averaging. We will convolve the node features with more sophisticated waveforms generated using dynamics such as the heat equation, wave equation, and the Sprott model (an example of chaotic dynamics). Furthermore, we use snapshots of these dynamics at different time points to create waveforms at many effective scales. Theoretically, we show that these dynamic waveforms can capture salient information about the graph including connected components, connectivity, and cycle structures even with no features. Empirically, we test DYMAG on both real and synthetic benchmarks to establish that DYMAG outperforms baseline models on recovery of graph persistence, generating parameters of random graphs, as well as property prediction for proteins, molecules and materials. Our code is available at https://github.com/KrishnaswamyLab/DYMAG.</description>
      <guid isPermaLink="false">oai:arXiv.org:2309.09924v5</guid>
      <category>cs.LG</category>
      <category>eess.SP</category>
      <category>stat.ML</category>
      <pubDate>Wed, 28 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Dhananjay Bhaskar, Xingzhi Sun, Yanlei Zhang, Charles Xu, Arman Afrasiyabi, Siddharth Viswanath, Oluwadamilola Fasina, Maximilian Nickel, Guy Wolf, Michael Perlmutter, Smita Krishnaswamy</dc:creator>
    </item>
    <item>
      <title>Advanced Signal Analysis in Detecting Replay Attacks for Automatic Speaker Verification Systems</title>
      <link>https://arxiv.org/abs/2403.01130</link>
      <description>arXiv:2403.01130v3 Announce Type: replace-cross 
Abstract: This study proposes novel signal analysis methods for replay speech detection in automatic speaker verification (ASV) systems. The proposed methods -- arbitrary analysis (AA), mel scale analysis (MA), and constant Q analysis (CQA) -- are inspired by the calculation of the Fourier inversion formula. These methods introduce new perspectives in signal analysis for replay speech detection by employing alternative sinusoidal sequence groups. The efficacy of the proposed methods is examined on the ASVspoof 2019 \&amp; 2021 PA databases with experiments, and confirmed by the performance of systems that incorporated the proposed methods; the successful integration of the proposed methods and a speech feature that calculates temporal autocorrelation of speech (TAC) from complex spectra strongly confirms it. Moreover, the proposed CQA and MA methods show their superiority to the conventional methods on efficiency (approximately 2.36 times as fast compared to the conventional constant Q transform (CQT) method) and efficacy, respectively, in analyzing speech signals, making them promising to utilize in music and speech processing works.</description>
      <guid isPermaLink="false">oai:arXiv.org:2403.01130v3</guid>
      <category>eess.AS</category>
      <category>eess.SP</category>
      <pubDate>Wed, 28 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Lee Shih Kuang</dc:creator>
    </item>
    <item>
      <title>Symmetry constrained neural networks for detection and localization of damage in metal plates</title>
      <link>https://arxiv.org/abs/2409.06084</link>
      <description>arXiv:2409.06084v3 Announce Type: replace-cross 
Abstract: The present paper is concerned with deep learning techniques applied to detection and localization of damage in a thin aluminum plate. We used data collected on a tabletop apparatus by mounting to the plate four piezoelectric transducers, each of which took turn to generate a Lamb wave that then traversed the region of interest before being received by the remaining three sensors. On training a neural network to analyze time-series data of the material response, which displayed damage-reflective features whenever the plate guided waves interacted with a contact load, we achieved a model that detected with greater than $99\%$ accuracy in addition to a model that localized with $2.58 \pm 0.12$ mm mean distance error. For each task, the best-performing model was designed according to the inductive bias that our transducers were both similar and arranged in a square pattern on a nearly uniform plate.</description>
      <guid isPermaLink="false">oai:arXiv.org:2409.06084v3</guid>
      <category>cs.LG</category>
      <category>eess.SP</category>
      <pubDate>Wed, 28 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <arxiv:DOI>10.1063/5.0242345</arxiv:DOI>
      <arxiv:journal_reference>APL Mach. Learn. 1 June 2025; 3 (2): 026106</arxiv:journal_reference>
      <dc:creator>James Amarel, Christopher Rudolf, Athanasios Iliopoulos, John Michopoulos, Leslie N. Smith</dc:creator>
    </item>
    <item>
      <title>Rician Channel Modelling for Super Wideband MIMO Communications</title>
      <link>https://arxiv.org/abs/2411.01878</link>
      <description>arXiv:2411.01878v2 Announce Type: replace-cross 
Abstract: Recent developments in Multiple-Input-Multiple-Output (MIMO) technology include packing a large number of antenna elements in a compact array to access the bandwidth benefits provided by higher mutual coupling (MC). The resulting super-wideband (SW) systems require a circuit-theoretic framework to handle the MC and channel models which span extremely large bands. Hence, in this paper, we make two key contributions. First, we develop a physically-consistent Rician channel model for use with SW systems. Secondly, we express the circuit-theoretic models in terms of a standard MIMO model, so that insights into the effects of antenna layouts, MC, and bandwidth can be made using standard communication theory. For example, we show the bandwidth widening resulting from the new channel model. In addition, we show that MC distorts line-of-sight paths which has beamforming implications. We also highlight the interaction between spatial correlation and MC and show that tight coupling reduces spatial correlations at low frequencies.</description>
      <guid isPermaLink="false">oai:arXiv.org:2411.01878v2</guid>
      <category>cs.IT</category>
      <category>eess.SP</category>
      <category>math.IT</category>
      <pubDate>Wed, 28 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Sachitha C. Bandara, Peter J. Smith, Erfan Khordad, Robin Evans, Rajitha Senanayake</dc:creator>
    </item>
    <item>
      <title>Flexible Multi-Beam Synthesis and Directional Suppression Through Transmissive RIS</title>
      <link>https://arxiv.org/abs/2411.02008</link>
      <description>arXiv:2411.02008v2 Announce Type: replace-cross 
Abstract: Despite extensive research on reconfigurable intelligent surfaces (RISs) in recent years, existing beamforming methods still face significant challenges in achieving flexible and robust beam synthesis, which is an essential capability for a wide range of communication scenarios. This paper introduces a Max-min criterion with nonlinear constraints, leveraging optimization techniques to simultaneously enable flexible multi-beam synthesis and directional suppression using transmissive RIS. Firstly, a realistic model grounded in geometrical optics is introduced to characterize the input/output behaviors of transmissive RISs, effectively bridging the gap between explicit beamforming requirements and practical implementations. Subsequently, a highly efficient algorithm for constrained Max-min optimizations involving quadratic forms is developed. By introducing an auxiliary variable and applying the compensated convexity transform, we successfully reformulate the original non-convex problem and obtain the optimal solution iteratively. This approach is readily applicable to a wide range of constrained Max-min optimization problems. Finally, numerical simulations and prototype experiments are conducted to validate the effectiveness of the proposed framework. The results demonstrate that the proposed algorithm can effectively enhance or selectively suppress signal beams in designated spatial directions, outperforming existing methods in terms of beam control accuracy and robustness. This framework provides valuable insights and references for practical communications applications such as physical layer security and interference mitigation.</description>
      <guid isPermaLink="false">oai:arXiv.org:2411.02008v2</guid>
      <category>cs.IT</category>
      <category>eess.SP</category>
      <category>math.IT</category>
      <pubDate>Wed, 28 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Rujing Xiong, Ke Yin, Jialong Lu, Kai Wan, Tiebin Mi, Robert Caiming Qiu</dc:creator>
    </item>
    <item>
      <title>UAV-Enabled Secure ISAC Against Dual Eavesdropping Threats: Joint Beamforming and Trajectory Design</title>
      <link>https://arxiv.org/abs/2412.19748</link>
      <description>arXiv:2412.19748v2 Announce Type: replace-cross 
Abstract: In this work, we study an unmanned aerial vehicle (UAV)-enabled secure integrated sensing and communication (ISAC) system, where a UAV serves as an aerial base station (BS) to simultaneously perform communication with a user and detect a target on the ground, while a dual-functional eavesdropper attempts to intercept the signals for both sensing and communication. Facing the dual eavesdropping threats, we aim to enhance the average achievable secrecy rate for the communication user by jointly designing the UAV trajectory together with the transmit information and sensing beamforming, while satisfying the requirements on sensing performance and sensing security, as well as the UAV power and flight constraints. To address the non-convex nature of the optimization problem, we employ the alternating optimization (AO) strategy, jointly with the successive convex approximation (SCA) and semidefinite relaxation (SDR) methods. Numerical results validate the proposed approach, demonstrating its ability to achieve a high secrecy rate while meeting the required sensing and security constraints.</description>
      <guid isPermaLink="false">oai:arXiv.org:2412.19748v2</guid>
      <category>cs.IT</category>
      <category>eess.SP</category>
      <category>math.IT</category>
      <pubDate>Wed, 28 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Jianping Yao, Zeyu Yang, Zai Yang, Jie Xu, Tony Q. S. Quek</dc:creator>
    </item>
    <item>
      <title>Resampling Filter Design for Multirate Neural Audio Effect Processing</title>
      <link>https://arxiv.org/abs/2501.18470</link>
      <description>arXiv:2501.18470v2 Announce Type: replace-cross 
Abstract: Neural networks have become ubiquitous in audio effects modelling, especially for guitar amplifiers and distortion pedals. One limitation of such models is that the sample rate of the training data is implicitly encoded in the model weights and therefore not readily adjustable at inference. Recent work explored modifications to recurrent neural network architecture to approximate a sample rate independent system, enabling audio processing at a rate that differs from the original training rate. This method works well for integer oversampling and can reduce aliasing caused by nonlinear activation functions. For small fractional changes in sample rate, fractional delay filters can be used to approximate sample rate independence, but in some cases this method fails entirely. Here, we explore the use of real-time signal resampling at the input and output of the neural network as an alternative solution. We investigate several resampling filter designs and show that a two-stage design consisting of a half-band IIR filter cascaded with a Kaiser window FIR filter can give similar or better results to the previously proposed model adjustment method with many fewer filtering operations per sample and less than one millisecond of latency at typical audio rates. Furthermore, we investigate interpolation and decimation filters for the task of integer oversampling and show that cascaded half-band IIR and FIR designs can be used in conjunction with the model adjustment method to reduce aliasing in a range of distortion effect models.</description>
      <guid isPermaLink="false">oai:arXiv.org:2501.18470v2</guid>
      <category>eess.AS</category>
      <category>cs.LG</category>
      <category>cs.SD</category>
      <category>eess.SP</category>
      <pubDate>Wed, 28 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Alistair Carson, Vesa V\"alim\"aki, Alec Wright, Stefan Bilbao</dc:creator>
    </item>
    <item>
      <title>Benchmarking Spatiotemporal Reasoning in LLMs and Reasoning Models: Capabilities and Challenges</title>
      <link>https://arxiv.org/abs/2505.11618</link>
      <description>arXiv:2505.11618v2 Announce Type: replace-cross 
Abstract: Spatiotemporal reasoning plays a key role in Cyber-Physical Systems (CPS). Despite advances in Large Language Models (LLMs) and Large Reasoning Models (LRMs), their capacity to reason about complex spatiotemporal signals remains underexplored. This paper proposes a hierarchical SpatioTemporal reAsoning benchmaRK, STARK, to systematically evaluate LLMs across three levels of reasoning complexity: state estimation (e.g., predicting field variables, localizing and tracking events in space and time), spatiotemporal reasoning over states (e.g., inferring spatial-temporal relationships), and world-knowledge-aware reasoning that integrates contextual and domain knowledge (e.g., intent prediction, landmark-aware navigation). We curate 26 distinct spatiotemporal tasks with diverse sensor modalities, comprising 14,552 challenges where models answer directly or by Python Code Interpreter. Evaluating 3 LRMs and 8 LLMs, we find LLMs achieve limited success in tasks requiring geometric reasoning (e.g., multilateration or triangulation), particularly as complexity increases. Surprisingly, LRMs show robust performance across tasks with various levels of difficulty, often competing or surpassing traditional first-principle-based methods. Our results show that in reasoning tasks requiring world knowledge, the performance gap between LLMs and LRMs narrows, with some LLMs even surpassing LRMs. However, the LRM o3 model continues to achieve leading performance across all evaluated tasks, a result attributed primarily to the larger size of the reasoning models. STARK motivates future innovations in model architectures and reasoning paradigms for intelligent CPS by providing a structured framework to identify limitations in the spatiotemporal reasoning of LLMs and LRMs.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.11618v2</guid>
      <category>cs.AI</category>
      <category>cs.LG</category>
      <category>eess.SP</category>
      <pubDate>Wed, 28 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Pengrui Quan, Brian Wang, Kang Yang, Liying Han, Mani Srivastava</dc:creator>
    </item>
    <item>
      <title>U-SAM: An audio language Model for Unified Speech, Audio, and Music Understanding</title>
      <link>https://arxiv.org/abs/2505.13880</link>
      <description>arXiv:2505.13880v3 Announce Type: replace-cross 
Abstract: The text generation paradigm for audio tasks has opened new possibilities for unified audio understanding. However, existing models face significant challenges in achieving a comprehensive understanding across diverse audio types, such as speech, general audio events, and music. Furthermore, their exclusive reliance on cross-entropy loss for alignment often falls short, as it treats all tokens equally and fails to account for redundant audio features, leading to weaker cross-modal alignment. To deal with the above challenges, this paper introduces U-SAM, an advanced audio language model that integrates specialized encoders for speech, audio, and music with a pre-trained large language model (LLM). U-SAM employs a Mixture of Experts (MoE) projector for task-aware feature fusion, dynamically routing and integrating the domain-specific encoder outputs. Additionally, U-SAM incorporates a Semantic-Aware Contrastive Loss Module, which explicitly identifies redundant audio features under language supervision and rectifies their semantic and spectral representations to enhance cross-modal alignment. Extensive experiments demonstrate that U-SAM consistently outperforms both specialized models and existing audio language models across multiple benchmarks. Moreover, it exhibits emergent capabilities on unseen tasks, showcasing its generalization potential. Code is available (https://github.com/Honee-W/U-SAM/).</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.13880v3</guid>
      <category>eess.AS</category>
      <category>cs.SD</category>
      <category>eess.SP</category>
      <pubDate>Wed, 28 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Ziqian Wang, Xianjun Xia, Xinfa Zhu, Lei Xie</dc:creator>
    </item>
    <item>
      <title>Joint Magnetometer-IMU Calibration via Maximum A Posteriori Estimation</title>
      <link>https://arxiv.org/abs/2505.16662</link>
      <description>arXiv:2505.16662v2 Announce Type: replace-cross 
Abstract: This paper presents a new approach for jointly calibrating magnetometers and inertial measurement units, focusing on improving calibration accuracy and computational efficiency. The proposed method formulates the calibration problem as a maximum a posteriori estimation problem, treating both the calibration parameters and orientation trajectory of the sensors as unknowns. This formulation enables efficient optimization with closed-form derivatives. The method is compared against two state-of-the-art approaches in terms of computational complexity and estimation accuracy. Simulation results demonstrate that the proposed method achieves lower root mean square error in calibration parameters while maintaining competitive computational efficiency. Further validation through real-world experiments confirms the practical benefits of our approach: it effectively reduces position drift in a magnetic field-aided inertial navigation system by more than a factor of two on most datasets. Moreover, the proposed method calibrated 30 magnetometers in less than 2 minutes. The contributions include a new calibration method, an analysis of existing methods, and a comprehensive empirical evaluation. Datasets and algorithms are made publicly available to promote reproducible research.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.16662v2</guid>
      <category>cs.RO</category>
      <category>eess.SP</category>
      <pubDate>Wed, 28 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Chuan Huang, Gustaf Hendeby, Isaac Skog</dc:creator>
    </item>
    <item>
      <title>FlowSE: Efficient and High-Quality Speech Enhancement via Flow Matching</title>
      <link>https://arxiv.org/abs/2505.19476</link>
      <description>arXiv:2505.19476v2 Announce Type: replace-cross 
Abstract: Generative models have excelled in audio tasks using approaches such as language models, diffusion, and flow matching. However, existing generative approaches for speech enhancement (SE) face notable challenges: language model-based methods suffer from quantization loss, leading to compromised speaker similarity and intelligibility, while diffusion models require complex training and high inference latency. To address these challenges, we propose FlowSE, a flow-matching-based model for SE. Flow matching learns a continuous transformation between noisy and clean speech distributions in a single pass, significantly reducing inference latency while maintaining high-quality reconstruction. Specifically, FlowSE trains on noisy mel spectrograms and optional character sequences, optimizing a conditional flow matching loss with ground-truth mel spectrograms as supervision. It implicitly learns speech's temporal-spectral structure and text-speech alignment. During inference, FlowSE can operate with or without textual information, achieving impressive results in both scenarios, with further improvements when transcripts are available. Extensive experiments demonstrate that FlowSE significantly outperforms state-of-the-art generative methods, establishing a new paradigm for generative-based SE and demonstrating the potential of flow matching to advance the field. Our code, pre-trained checkpoints, and audio samples are available.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.19476v2</guid>
      <category>eess.AS</category>
      <category>eess.SP</category>
      <pubDate>Wed, 28 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Ziqian Wang, Zikai Liu, Xinfa Zhu, Yike Zhu, Mingshuai Liu, Jun Chen, Longshuai Xiao, Chao Weng, Lei Xie</dc:creator>
    </item>
  </channel>
</rss>
