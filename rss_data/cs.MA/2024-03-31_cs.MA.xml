<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>cs.MA updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/cs.MA</link>
    <description>cs.MA updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/cs.MA" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Mon, 01 Apr 2024 04:00:58 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Mon, 01 Apr 2024 00:00:00 -0400</pubDate>
    <skipDays>
      <day>Sunday</day>
      <day>Saturday</day>
    </skipDays>
    <item>
      <title>Improving Learnt Local MAPF Policies with Heuristic Search</title>
      <link>https://arxiv.org/abs/2403.20300</link>
      <description>arXiv:2403.20300v1 Announce Type: new 
Abstract: Multi-agent path finding (MAPF) is the problem of finding collision-free paths for a team of agents to reach their goal locations. State-of-the-art classical MAPF solvers typically employ heuristic search to find solutions for hundreds of agents but are typically centralized and can struggle to scale when run with short timeouts. Machine learning (ML) approaches that learn policies for each agent are appealing as these could enable decentralized systems and scale well while maintaining good solution quality. Current ML approaches to MAPF have proposed methods that have started to scratch the surface of this potential. However, state-of-the-art ML approaches produce "local" policies that only plan for a single timestep and have poor success rates and scalability. Our main idea is that we can improve a ML local policy by using heuristic search methods on the output probability distribution to resolve deadlocks and enable full horizon planning. We show several model-agnostic ways to use heuristic search with learnt policies that significantly improve the policies' success rates and scalability. To our best knowledge, we demonstrate the first time ML-based MAPF approaches have scaled to high congestion scenarios (e.g. 20% agent density).</description>
      <guid isPermaLink="false">oai:arXiv.org:2403.20300v1</guid>
      <category>cs.MA</category>
      <category>cs.AI</category>
      <category>cs.RO</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Rishi Veerapaneni, Qian Wang, Kevin Ren, Arthur Jakobsson, Jiaoyang Li, Maxim Likhachev</dc:creator>
    </item>
    <item>
      <title>Reinforcement Learning in Agent-Based Market Simulation: Unveiling Realistic Stylized Facts and Behavior</title>
      <link>https://arxiv.org/abs/2403.19781</link>
      <description>arXiv:2403.19781v1 Announce Type: cross 
Abstract: Investors and regulators can greatly benefit from a realistic market simulator that enables them to anticipate the consequences of their decisions in real markets. However, traditional rule-based market simulators often fall short in accurately capturing the dynamic behavior of market participants, particularly in response to external market impact events or changes in the behavior of other participants. In this study, we explore an agent-based simulation framework employing reinforcement learning (RL) agents. We present the implementation details of these RL agents and demonstrate that the simulated market exhibits realistic stylized facts observed in real-world markets. Furthermore, we investigate the behavior of RL agents when confronted with external market impacts, such as a flash crash. Our findings shed light on the effectiveness and adaptability of RL-based agents within the simulation, offering insights into their response to significant market events.</description>
      <guid isPermaLink="false">oai:arXiv.org:2403.19781v1</guid>
      <category>q-fin.TR</category>
      <category>cs.LG</category>
      <category>cs.MA</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <dc:creator>Zhiyuan Yao, Zheng Li, Matthew Thomas, Ionut Florescu</dc:creator>
    </item>
    <item>
      <title>Existence and Verification of Nash Equilibria in Non-Cooperative Contribution Games with Resource Contention</title>
      <link>https://arxiv.org/abs/2403.20161</link>
      <description>arXiv:2403.20161v1 Announce Type: cross 
Abstract: In resource contribution games, a class of non-cooperative games, the players want to obtain a bundle of resources and are endowed with bags of bundles of resources that they can make available into a common for all to enjoy. Available resources can then be used towards their private goals. A player is potentially satisfied with a profile of contributed resources when his bundle could be extracted from the contributed resources. Resource contention occurs when the players who are potentially satisfied, cannot actually all obtain their bundle. The player's preferences are always single-minded (they consider a profile good or they do not) and parsimonious (between two profiles that are equally good, they prefer the profile where they contribute less). What makes a profile of contributed resources good for a player depends on their attitude towards resource contention. We study the problem of deciding whether an outcome is a pure Nash equilibrium for three kinds of players' attitudes towards resource contention: public contention-aversity, private contention-aversity, and contention-tolerance. In particular, we demonstrate that in the general case when the players are contention-averse, then the problem is harder than when they are contention-tolerant. We then identify a natural class of games where, in presence of contention-averse preferences, it becomes tractable, and where there is always a Nash equilibrium.</description>
      <guid isPermaLink="false">oai:arXiv.org:2403.20161v1</guid>
      <category>cs.GT</category>
      <category>cs.MA</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <arxiv:DOI>10.1007/s10472-023-09905-7</arxiv:DOI>
      <dc:creator>Nicolas Troquard</dc:creator>
    </item>
    <item>
      <title>Collaborative Safe Formation Control for Coupled Multi-Agent Systems</title>
      <link>https://arxiv.org/abs/2311.11156</link>
      <description>arXiv:2311.11156v2 Announce Type: replace-cross 
Abstract: The safe control of multi-robot swarms is a challenging and active field of research, where common goals include maintaining group cohesion while simultaneously avoiding obstacles and inter-agent collision. Building off our previously developed theory for distributed collaborative safety-critical control for networked dynamic systems, we propose a distributed algorithm for the formation control of robot swarms given individual agent dynamics, induced formation dynamics, and local neighborhood position and velocity information within a defined sensing radius for each agent. Individual safety guarantees for each agent are obtained using rounds of communication between neighbors to restrict unsafe control actions among cooperating agents through safety conditions derived from high-order control barrier functions. We provide conditions under which a swarm is guaranteed to achieve collective safety with respect to multiple obstacles using a modified collaborative safety algorithm. We demonstrate the performance of our distributed algorithm via simulation in a simplified physics-based environment.</description>
      <guid isPermaLink="false">oai:arXiv.org:2311.11156v2</guid>
      <category>math.OC</category>
      <category>cs.MA</category>
      <category>cs.RO</category>
      <category>cs.SY</category>
      <category>eess.SY</category>
      <category>math.DS</category>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Brooks A. Butler, Chi Ho Leung, Philip E. Par\'e</dc:creator>
    </item>
    <item>
      <title>A low-cost Framework for Decentralized Autonomous Intersection Management</title>
      <link>https://arxiv.org/abs/2311.17681</link>
      <description>arXiv:2311.17681v2 Announce Type: replace-cross 
Abstract: This paper addresses the traffic management problem for autonomous vehicles at intersections without traffic signals. In the current system, a road junction has no traffic signals when the traffic volume is low to medium. Installing infrastructure at each unsignalled crossing to coordinate autonomous cars can be formidable. We propose a novel low-cost solution strategy where the vehicles use a harmony matrix to find the best possible combination of the cars to cross the intersection without any crashes. The harmony matrix defines the connection between different vehicle maneuvers and is queried online for intersection management. We maximize the throughput of the intersection by solving a maximal clique problem formulated based on the vehicles present at the intersection. The proposed algorithm relies on the intent perceived by the autonomous vehicles. We compare our work with a communication-based strategy that uses V2I communication protocols, and through extensive simulation, we showed that our algorithm is comparable when the traffic volume is less than 500 PCUs/hr/lane.</description>
      <guid isPermaLink="false">oai:arXiv.org:2311.17681v2</guid>
      <category>cs.RO</category>
      <category>cs.MA</category>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-sa/4.0/</dc:rights>
      <dc:creator>Rugved Katole, Arpita Sinha</dc:creator>
    </item>
    <item>
      <title>Multi-Agent Diagnostics for Robustness via Illuminated Diversity</title>
      <link>https://arxiv.org/abs/2401.13460</link>
      <description>arXiv:2401.13460v2 Announce Type: replace-cross 
Abstract: In the rapidly advancing field of multi-agent systems, ensuring robustness in unfamiliar and adversarial settings is crucial. Notwithstanding their outstanding performance in familiar environments, these systems often falter in new situations due to overfitting during the training phase. This is especially pronounced in settings where both cooperative and competitive behaviours are present, encapsulating a dual nature of overfitting and generalisation challenges. To address this issue, we present Multi-Agent Diagnostics for Robustness via Illuminated Diversity (MADRID), a novel approach for generating diverse adversarial scenarios that expose strategic vulnerabilities in pre-trained multi-agent policies. Leveraging the concepts from open-ended learning, MADRID navigates the vast space of adversarial settings, employing a target policy's regret to gauge the vulnerabilities of these settings. We evaluate the effectiveness of MADRID on the 11vs11 version of Google Research Football, one of the most complex environments for multi-agent reinforcement learning. Specifically, we employ MADRID for generating a diverse array of adversarial settings for TiZero, the state-of-the-art approach which "masters" the game through 45 days of training on a large-scale distributed infrastructure. We expose key shortcomings in TiZero's tactical decision-making, underlining the crucial importance of rigorous evaluation in multi-agent systems.</description>
      <guid isPermaLink="false">oai:arXiv.org:2401.13460v2</guid>
      <category>cs.LG</category>
      <category>cs.AI</category>
      <category>cs.MA</category>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Mikayel Samvelyan, Davide Paglieri, Minqi Jiang, Jack Parker-Holder, Tim Rockt\"aschel</dc:creator>
    </item>
    <item>
      <title>Prioritize Team Actions: Multi-Agent Temporal Logic Task Planning with Ordering Constraints</title>
      <link>https://arxiv.org/abs/2403.17704</link>
      <description>arXiv:2403.17704v2 Announce Type: replace-cross 
Abstract: In this paper, we investigate the problem of linear temporal logic (LTL) path planning for multi-agent systems, introducing the new concept of \emph{ordering constraints}. Specifically, we consider a generic objective function that is defined for the path of each individual agent. The primary objective is to find a global plan for the team of agents, ensuring they collectively meet the specified LTL requirements. Simultaneously, we aim to maintain a pre-determined order in the values of the objective function for each agent, which we refer to as the ordering constraints. This new requirement stems from scenarios like security-aware planning, where relative orders outweigh absolute values in importance. We present an efficient algorithm to solve this problem, supported by proofs of correctness that demonstrate the optimality of our solution. Additionally, we provide a case study in security-aware path planning to illustrate the practicality and effectiveness of our proposed approach.</description>
      <guid isPermaLink="false">oai:arXiv.org:2403.17704v2</guid>
      <category>eess.SY</category>
      <category>cs.MA</category>
      <category>cs.SY</category>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Bowen Ye, Jianing Zhao, Shaoyuan Li, Xiang Yin</dc:creator>
    </item>
  </channel>
</rss>
