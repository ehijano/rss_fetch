<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>econ.EM updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/econ.EM</link>
    <description>econ.EM updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/econ.EM" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Fri, 18 Jul 2025 04:00:47 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Fri, 18 Jul 2025 00:00:00 -0400</pubDate>
    <skipDays>
      <day>Sunday</day>
      <day>Saturday</day>
    </skipDays>
    <item>
      <title>Semiparametric Learning of Integral Functionals on Submanifolds</title>
      <link>https://arxiv.org/abs/2507.12673</link>
      <description>arXiv:2507.12673v1 Announce Type: new 
Abstract: This paper studies the semiparametric estimation and inference of integral functionals on submanifolds, which arise naturally in a variety of econometric settings. For linear integral functionals on a regular submanifold, we show that the semiparametric plug-in estimator attains the minimax-optimal convergence rate $n^{-\frac{s}{2s+d-m}}$, where $s$ is the H\"{o}lder smoothness order of the underlying nonparametric function, $d$ is the dimension of the first-stage nonparametric estimation, $m$ is the dimension of the submanifold over which the integral is taken. This rate coincides with the standard minimax-optimal rate for a $(d-m)$-dimensional nonparametric estimation problem, illustrating that integration over the $m$-dimensional manifold effectively reduces the problem's dimensionality. We then provide a general asymptotic normality theorem for linear/nonlinear submanifold integrals, along with a consistent variance estimator. We provide simulation evidence in support of our theoretical results.</description>
      <guid isPermaLink="false">oai:arXiv.org:2507.12673v1</guid>
      <category>econ.EM</category>
      <pubDate>Fri, 18 Jul 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Xiaohong Chen, Wayne Yuan Gao</dc:creator>
    </item>
    <item>
      <title>NA-DiD: Extending Difference-in-Differences with Capabilities</title>
      <link>https://arxiv.org/abs/2507.12690</link>
      <description>arXiv:2507.12690v1 Announce Type: new 
Abstract: This paper introduces the Non-Additive Difference-in-Differences (NA-DiD) framework, which extends classical DiD by incorporating non-additive measures the Choquet integral for effect aggregation. It serves as a novel econometric tool for impact evaluation, particularly in settings with non-additive treatment effects. First, we introduce the integral representation of the classial DiD model, and then extend it to non-additive measures, therefore deriving the formulae for NA-DiD estimation. Then, we give its theoretical properties. Applying NA-DiD to a simulated hospital hygiene intervention, we find that classical DiD can overestimate treatment effects, f.e. failing to account for compliance erosion. In contrast, NA-DiD provides a more accurate estimate by incorporating non-linear aggregation. The Julia implementation of the techniques used and introduced in this article is provided in the appendices.</description>
      <guid isPermaLink="false">oai:arXiv.org:2507.12690v1</guid>
      <category>econ.EM</category>
      <category>stat.ME</category>
      <pubDate>Fri, 18 Jul 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Stanis{\l}aw M. S. Halkiewicz</dc:creator>
    </item>
    <item>
      <title>Placebo Discontinuity Design</title>
      <link>https://arxiv.org/abs/2507.12693</link>
      <description>arXiv:2507.12693v1 Announce Type: new 
Abstract: Standard regression discontinuity design (RDD) models rely on the continuity of expected potential outcomes at the cutoff. The standard continuity assumption can be violated by strategic manipulation of the running variable, which is realistic when the cutoff is widely known and when the treatment of interest is a social program or government benefit. In this work, we identify the treatment effect despite such a violation, by leveraging a placebo treatment and a placebo outcome. We introduce a local instrumental variable estimator. Our estimator decomposes into two terms: the standard RDD estimator of the target outcome's discontinuity, and a new adjustment term based on the placebo outcome's discontinuity. We show that our estimator is consistent, and we justify a robust bias-corrected inference procedure. Our method expands the applicability of RDD to settings with strategic behavior around the cutoff, which commonly arise in social science.</description>
      <guid isPermaLink="false">oai:arXiv.org:2507.12693v1</guid>
      <category>econ.EM</category>
      <category>stat.ME</category>
      <pubDate>Fri, 18 Jul 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Rahul Singh, Moses Stewart</dc:creator>
    </item>
    <item>
      <title>Refining the Notion of No Anticipation in Difference-in-Differences Studies</title>
      <link>https://arxiv.org/abs/2507.12891</link>
      <description>arXiv:2507.12891v1 Announce Type: cross 
Abstract: We address an ambiguity in identification strategies using difference-in-differences, which are widely applied in empirical research, particularly in economics. The assumption commonly referred to as the "no-anticipation assumption" states that treatment has no effect on outcomes before its implementation. However, because standard causal models rely on a temporal structure in which causes precede effects, such an assumption seems to be inherently satisfied. This raises the question of whether the assumption is repeatedly stated out of redundancy or because the formal statements fail to capture the intended subject-matter interpretation. We argue that confusion surrounding the no-anticipation assumption arises from ambiguity in the intervention considered and that current formulations of the assumption are ambiguous. Therefore, new definitions and identification results are proposed.</description>
      <guid isPermaLink="false">oai:arXiv.org:2507.12891v1</guid>
      <category>stat.ME</category>
      <category>econ.EM</category>
      <pubDate>Fri, 18 Jul 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Marco Piccininni, Eric J. Tchetgen Tchetgen, Mats J. Stensrud</dc:creator>
    </item>
    <item>
      <title>Nonlinear Fore(Back)casting and Innovation Filtering for Causal-Noncausal VAR Models</title>
      <link>https://arxiv.org/abs/2205.09922</link>
      <description>arXiv:2205.09922v4 Announce Type: replace 
Abstract: We show that the mixed causal-noncausal Vector Autoregressive (VAR) processes satisfy the Markov property in both calendar and reverse time. Based on that property, we introduce closed-form formulas of forward and backward predictive densities for point and interval forecasting and backcasting out-of-sample. The backcasting formula is used for adjusting the forecast interval to obtain a desired coverage level when the tail quantiles are difficult to estimate. A confidence set for the prediction interval is introduced for assessing the uncertainty due to estimation. We also define new nonlinear past-dependent innovations of mixed causal-noncausal VAR models for impulse response function analysis. Our approach is illustrated by simulations and an application to oil prices and real GDP growth rates.</description>
      <guid isPermaLink="false">oai:arXiv.org:2205.09922v4</guid>
      <category>econ.EM</category>
      <pubDate>Fri, 18 Jul 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Christian Gourieroux, Joann Jasiak</dc:creator>
    </item>
    <item>
      <title>Evaluating Meta-Regression Techniques: A Simulation Study on Heterogeneity in Location and Time</title>
      <link>https://arxiv.org/abs/2504.16696</link>
      <description>arXiv:2504.16696v2 Announce Type: replace 
Abstract: In this paper, we conduct a simulation study with subject-level data to evaluate conventional meta-regression approaches (study-level random, fixed, and mixed effects) against seven methodology specifications new to meta-regressions that control joint heterogeneity in location and time (including a new one that we introduce). We systematically vary heterogeneity levels to assess statistical power, estimator bias and model robustness for each methodology specification. This assessment focuses on three aspects: performance under joint heterogeneity in location and time, the effectiveness of our proposed settings incorporating location fixed effects and study-level fixed effects with a time trend, as well as guidelines for model selection. The results show that jointly modeling heterogeneity when heterogeneity is in both dimensions improves performance compared to modeling only one type of heterogeneity.</description>
      <guid isPermaLink="false">oai:arXiv.org:2504.16696v2</guid>
      <category>econ.EM</category>
      <pubDate>Fri, 18 Jul 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Ali Habibnia, Jonathan Gendron</dc:creator>
    </item>
    <item>
      <title>Catching Bid-rigging Cartels with Graph Attention Neural Networks</title>
      <link>https://arxiv.org/abs/2507.12369</link>
      <description>arXiv:2507.12369v2 Announce Type: replace 
Abstract: We propose a novel application of graph attention networks (GATs), a type of graph neural network enhanced with attention mechanisms, to develop a deep learning algorithm for detecting collusive behavior, leveraging predictive features suggested in prior research. We test our approach on a large dataset covering 13 markets across seven countries. Our results show that predictive models based on GATs, trained on a subset of the markets, can be effectively transferred to other markets, achieving accuracy rates between 80% and 90%, depending on the hyperparameter settings. The best-performing configuration, applied to eight markets from Switzerland and the Japanese region of Okinawa, yields an average accuracy of 91% for cross-market prediction. When extended to 12 markets, the method maintains a strong performance with an average accuracy of 84%, surpassing traditional ensemble approaches in machine learning. These results suggest that GAT-based detection methods offer a promising tool for competition authorities to screen markets for potential cartel activity.</description>
      <guid isPermaLink="false">oai:arXiv.org:2507.12369v2</guid>
      <category>econ.EM</category>
      <pubDate>Fri, 18 Jul 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>David Imhof, Emanuel W Viklund, Martin Huber</dc:creator>
    </item>
    <item>
      <title>Formalising causal inference as prediction on a target population</title>
      <link>https://arxiv.org/abs/2407.17385</link>
      <description>arXiv:2407.17385v3 Announce Type: replace-cross 
Abstract: The standard approach to causal modelling especially in social and health sciences is the potential outcomes framework due to Neyman and Rubin. In this framework, observations are thought to be drawn from a distribution over variables of interest, and the goal is to identify parameters of this distribution. Even though the stated goal is often to inform decision making on some target population, there is no straightforward way to include these target populations in the framework. Instead of modelling the relationship between the observed sample and the target population, the inductive assumptions in this framework take the form of abstract sampling and independence assumptions. In this paper, we develop a version of this framework that construes causal inference as treatment-wise predictions for finite populations where all assumptions are testable in retrospect; this means that one can not only test predictions themselves (without any fundamental problem) but also investigate sources of error when they fail. Due to close connections to the original framework, established methods can still be be analysed under the new framework.</description>
      <guid isPermaLink="false">oai:arXiv.org:2407.17385v3</guid>
      <category>stat.ME</category>
      <category>cs.LG</category>
      <category>econ.EM</category>
      <pubDate>Fri, 18 Jul 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Benedikt H\"oltgen, Robert C. Williamson</dc:creator>
    </item>
  </channel>
</rss>
