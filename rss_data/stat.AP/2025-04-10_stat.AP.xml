<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>stat.AP updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/stat.AP</link>
    <description>stat.AP updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/stat.AP" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Fri, 11 Apr 2025 01:42:24 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Thu, 10 Apr 2025 00:00:00 -0400</pubDate>
    <skipDays>
      <day>Saturday</day>
      <day>Sunday</day>
    </skipDays>
    <item>
      <title>Bayesian estimation for conditional probabilities associated to directed acyclic graphs: study of hospitalization of severe influenza cases</title>
      <link>https://arxiv.org/abs/2504.06440</link>
      <description>arXiv:2504.06440v1 Announce Type: new 
Abstract: This paper presents a Bayesian inferential framework for estimating joint, conditional, and marginal probabilities in directed acyclic graphs (DAGs) applied to the study of the progression of hospitalized patients with severe influenza. Using data from the PIDIRAC retrospective cohort study in Catalonia, we model patient pathways from admission through different stages of care until discharge, death, or transfer to a long-term care facility. Direct transition probabilities are estimated through a Bayesian approach combining conjugate Dirichlet-multinomial inferential processes, while posterior distributions associated to absorbing state or inverse probabilities are assessed via simulation techniques. Bayesian methodology quantifies uncertainty through posterior distributions, providing insights into disease progression and improving hospital resource planning during seasonal influenza peaks. These results support more effective patient management and decision making in healthcare systems.
  Keywords: Confirmed influenza hospitalization; Directed acyclic graphs (DAGs); Dirichlet-multinomial Bayesian inferential process; Healthcare decision-making; Transition probabilities.</description>
      <guid isPermaLink="false">oai:arXiv.org:2504.06440v1</guid>
      <category>stat.AP</category>
      <pubDate>Thu, 10 Apr 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Lesly Acosta, Carmen Armero</dc:creator>
    </item>
    <item>
      <title>LassoRNet: Accurate dim-light melatonin onset time prediction from multiple blood tissue samples</title>
      <link>https://arxiv.org/abs/2504.06494</link>
      <description>arXiv:2504.06494v1 Announce Type: new 
Abstract: Research on chemotherapy, heart surgery, and vaccines has indicated that the risks and benefits of a treatment could vary depending on the time of day it is administered. A challenge with performing studies on timing treatment administration is that the optimal treatment time is different for each patient, as it would be based on a patient's internal clock time (ICT) rather than the 24-hour day-night cycle time. Prediction methods have been developed to determine a patient's ICT based on biomarker measurements, which can be leveraged to personalize treatment time. However, these methods face two limitations. First, these methods are designed to output predictions given biomarker measurements from a single tissue sample, when multiple tissue samples can be collected over time. Second, these methods are based on linear modelling frameworks, which would not capture the potentially complex relationships between biomarkers and a patient's ICT. To address these two limitations, this paper introduces a recurrent neural network framework, which we refer to as LassoRNet, for predicting the ICT at which a patient's biomarkers are measured as well as the underlying offset between a patient's ICT and the 24-hour day-night cycle time, or that patient's dim-light melatonin onset (DLMO) time. A novel feature of LassoRNet is a proposed variable selection scheme that minimizes the number of biomarkers needed to predict ICT. We evaluate LassoRNet on three longitudinal circadian transcriptome study data sets where DLMO time was determined for each study participant, and find that it consistently outperforms state-of-the art in both ICT and DLMO time prediction. Notably, LassoRNet obtains a median absolute error of approximately one hour in ICT prediction and 30 to 40 minutes in DLMO time prediction, where DLMO time prediction is performed using three samples collected at sequential time points.</description>
      <guid isPermaLink="false">oai:arXiv.org:2504.06494v1</guid>
      <category>stat.AP</category>
      <category>stat.CO</category>
      <pubDate>Thu, 10 Apr 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Michael T. Gorczyca, Tavish M. McDonald, Brandon Oppong-Antwi</dc:creator>
    </item>
    <item>
      <title>Evaluating amyloid-beta as a surrogate endpoint in trials of anti-amyloid drugs in Alzheimer's disease: a Bayesian meta-analysis</title>
      <link>https://arxiv.org/abs/2504.06807</link>
      <description>arXiv:2504.06807v1 Announce Type: new 
Abstract: The use of amyloid-beta (A$\beta$) clearance to support regulatory approvals of drugs in Alzheimer's disease (AD) remains controversial. We evaluate A$\beta$ as a potential trial-level surrogate endpoint for clinical function in AD using a meta-analysis. Randomised controlled trials (RCTs) reporting data on the effectiveness of anti- A$\beta$ monoclonal antibodies (MABs) on A$\beta$ and clinical outcomes were identified through a literature review. A Bayesian bivariate meta-analysis was used to evaluate surrogate relationships between the treatment effects on A$\beta$ and clinical function, with the intercept, slope and variance quantifying the trial level association. The analysis was performed using RCT data both collectively across all MABs and separately for each MAB through subgroup analysis. The latter analysis was extended by applying Bayesian hierarchical models to borrow information across treatments. We identified 23 RCTs with 39 treatment contrasts for seven MABs. The association between treatment effects on A$\beta$ and Clinical Dementia Rating - Sum of Boxes (CDR-SOB) across all MABs was strong: with intercept of -0.03 (95% credible intervals: -0.16, 0.11), slope of 1.41 (0.60, 2.21) and variance of 0.02 (0.00, 0.05). For individual treatments, the surrogate relationships were suboptimal, displaying large uncertainty. The use of hierarchical models considerably reduced the uncertainty around key parameters, narrowing the intervals for the slopes by an average of 71% (range: 51%-95%) and for the variances by 28% (7%-65%). Our results suggest that A$\beta$ is a potential surrogate endpoint for CDR-SOB when assuming a common surrogate relationship across all MABs. When allowing for information-sharing, the surrogate relationships improved, but only for lecanemab and aducanumab was the improvement sufficient to support a surrogate relationship.</description>
      <guid isPermaLink="false">oai:arXiv.org:2504.06807v1</guid>
      <category>stat.AP</category>
      <pubDate>Thu, 10 Apr 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Sa Ren, Janharpreet Singh, Sandro Gsteiger, Christopher Cogley, Ben Reed, Keith R Abrams, Dalia Dawoud, Rhiannon K Owen, Paul Tappenden, Terrence J Quinn, Sylwia Bujkiewicz</dc:creator>
    </item>
    <item>
      <title>Restoring the Forecasting Power of Google Trends with Statistical Preprocessing</title>
      <link>https://arxiv.org/abs/2504.07032</link>
      <description>arXiv:2504.07032v1 Announce Type: new 
Abstract: Google Trends reports how frequently specific queries are searched on Google over time. It is widely used in research and industry to gain early insights into public interest. However, its data generation mechanism introduces missing values, sampling variability, noise, and trends. These issues arise from privacy thresholds mapping low search volumes to zeros, daily sampling variations causing discrepancies across historical downloads, and algorithm updates altering volume magnitudes over time. Data quality has recently deteriorated, with more zeros and noise, even for previously stable queries. We propose a comprehensive statistical methodology to preprocess Google Trends search information using hierarchical clustering, smoothing splines, and detrending. We validate our approach by forecasting U.S. influenza hospitalizations with a univariate ARIMAX model. Compared to omitting exogenous variables, our results show that raw Google Trends data degrades modeling performance, while preprocessed signals enhance forecast accuracy by 58% nationally and 24% at the state level.</description>
      <guid isPermaLink="false">oai:arXiv.org:2504.07032v1</guid>
      <category>stat.AP</category>
      <pubDate>Thu, 10 Apr 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Candice Djorno, Mauricio Santillana, Shihao Yang</dc:creator>
    </item>
    <item>
      <title>Going beyond explainability in multi-modal stroke outcome prediction models</title>
      <link>https://arxiv.org/abs/2504.06299</link>
      <description>arXiv:2504.06299v1 Announce Type: cross 
Abstract: Aim: This study aims to enhance interpretability and explainability of multi-modal prediction models integrating imaging and tabular patient data.
  Methods: We adapt the xAI methods Grad-CAM and Occlusion to multi-modal, partly interpretable deep transformation models (dTMs). DTMs combine statistical and deep learning approaches to simultaneously achieve state-of-the-art prediction performance and interpretable parameter estimates, such as odds ratios for tabular features. Based on brain imaging and tabular data from 407 stroke patients, we trained dTMs to predict functional outcome three months after stroke. We evaluated the models using different discriminatory metrics. The adapted xAI methods were used to generated explanation maps for identification of relevant image features and error analysis.
  Results: The dTMs achieve state-of-the-art prediction performance, with area under the curve (AUC) values close to 0.8. The most important tabular predictors of functional outcome are functional independence before stroke and NIHSS on admission, a neurological score indicating stroke severity. Explanation maps calculated from brain imaging dTMs for functional outcome highlighted critical brain regions such as the frontal lobe, which is known to be linked to age which in turn increases the risk for unfavorable outcomes. Similarity plots of the explanation maps revealed distinct patterns which give insight into stroke pathophysiology, support developing novel predictors of stroke outcome and enable to identify false predictions.
  Conclusion: By adapting methods for explanation maps to dTMs, we enhanced the explainability of multi-modal and partly interpretable prediction models. The resulting explanation maps facilitate error analysis and support hypothesis generation regarding the significance of specific image regions in outcome prediction.</description>
      <guid isPermaLink="false">oai:arXiv.org:2504.06299v1</guid>
      <category>eess.IV</category>
      <category>cs.CV</category>
      <category>cs.LG</category>
      <category>stat.AP</category>
      <pubDate>Thu, 10 Apr 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Jonas Br\"andli, Maurice Schneeberger, Lisa Herzog, Loran Avci, Nordin Dari, Martin H\"aansel, Hakim Baazaoui, Pascal B\"uhler, Susanne Wegener, Beate Sick</dc:creator>
    </item>
    <item>
      <title>Language-Dependent Political Bias in AI: A Study of ChatGPT and Gemini</title>
      <link>https://arxiv.org/abs/2504.06436</link>
      <description>arXiv:2504.06436v1 Announce Type: cross 
Abstract: As leading examples of large language models, ChatGPT and Gemini claim to provide accurate and unbiased information, emphasizing their commitment to political neutrality and avoidance of personal bias. This research investigates the political tendency of large language models and the existence of differentiation according to the query language. For this purpose, ChatGPT and Gemini were subjected to a political axis test using 14 different languages. The findings of the study suggest that these large language models do exhibit political tendencies, with both models demonstrating liberal and leftist biases. A comparative analysis revealed that Gemini exhibited a more pronounced liberal and left-wing tendency compared to ChatGPT. The study also found that these political biases varied depending on the language used for inquiry. The study delves into the factors that constitute political tendencies and linguistic differentiation, exploring differences in the sources and scope of educational data, structural and grammatical features of languages, cultural and political contexts, and the model's response to linguistic features. From this standpoint, and an ethical perspective, it is proposed that artificial intelligence tools should refrain from asserting a lack of political tendencies and neutrality, instead striving for political neutrality and executing user queries by incorporating these tendencies.</description>
      <guid isPermaLink="false">oai:arXiv.org:2504.06436v1</guid>
      <category>cs.CL</category>
      <category>cs.AI</category>
      <category>cs.ET</category>
      <category>stat.AP</category>
      <pubDate>Thu, 10 Apr 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Dogus Yuksel, Mehmet Cem Catalbas, Bora Oc</dc:creator>
    </item>
    <item>
      <title>Using theory-driven Integrated Population Models to evaluate competitive outcomes in stage-structured systems</title>
      <link>https://arxiv.org/abs/2504.06725</link>
      <description>arXiv:2504.06725v1 Announce Type: cross 
Abstract: Predicting competitive outcomes typically requires fitting dynamical models to data, from which interaction strengths and coexistence indicators such as invasion criteria can be produced. Methods that allow to propagate parameter uncertainty are particularly indicated. These should ideally allow for competition between and within species at various life-stages, and make the best out of multiple data sources, each of which can be relatively scarce by statistical standards. Here, we embed a mathematical model of stage-structured competition between two species, producing analytical invasion criteria, into a two-species Integrated Population Model. The community-level IPM allows to combine counts, capture-recapture, and fecundity data into a single statistical framework, and the Bayesian formulation of the IPM fully propagates parameter uncertainty into invasion criteria. Model fitting demonstrates that we can correctly predict coexistence through reciprocal invasion when present, but that interaction strengths are not always estimable, depending on the prior chosen. Our competitive exclusion scenario is shown to be harder to identify, although our model allows to at least flag this scenario as uncertain rather than mistakenly present it as coexistence. Our results confirm the importance of accounting for uncertainty in the prediction of competitive outcomes.</description>
      <guid isPermaLink="false">oai:arXiv.org:2504.06725v1</guid>
      <category>q-bio.PE</category>
      <category>stat.AP</category>
      <category>stat.ME</category>
      <pubDate>Thu, 10 Apr 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Matthieu Paquet, Fr\'ed\'eric Barraquand</dc:creator>
    </item>
    <item>
      <title>Communicating complex statistical models to a public health audience: translating science into action with the FARSI approach</title>
      <link>https://arxiv.org/abs/2504.06787</link>
      <description>arXiv:2504.06787v1 Announce Type: cross 
Abstract: Background. Effectively communicating complex statistical model outputs is a major challenge in public health. This study introduces the FARSI approach (Fast, Accessible, Reliable, Secure, Informative) as a framework to enhance the translation of intricate statistical findings into actionable insights for policymakers and stakeholders. We apply this framework in a real-world case study on chronic disease monitoring in Italy.
  Methods. The FARSI framework outlines key principles for developing user-friendly tools that improve the translation of statistical results. We applied these principles to create an open-access web application using R Shiny, designed to communicate chronic disease prevalence estimates from a Bayesian spatio-temporal logistic model. The case study highlights the importance of an intuitive design for fast accessibility, validated data and expert feedback for reliability, aggregated data for security, and insights into prevalence population subgroups, which were previously unobservable, for informativeness.
  Results. The web application enables stakeholders to explore disease prevalence across populations and geographical area through dynamic visualizations. It facilitates public health monitoring by, for instance, identifying disparities at the local level and assessing risk factors such as smoking. Its user-friendly interface enhances accessibility, making statistical findings more actionable. Conclusions. The FARSI framework provides a structured approach to improving the communication of complex research findings. By making statistical models more accessible and interpretable, it supports evidence-based decision-making in public health and increases the societal impact of research.</description>
      <guid isPermaLink="false">oai:arXiv.org:2504.06787v1</guid>
      <category>stat.OT</category>
      <category>stat.AP</category>
      <category>stat.ME</category>
      <pubDate>Thu, 10 Apr 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Mattia Stival, Lorenzo Schiavon, Gaia Bertarelli, Stefano Campostrini</dc:creator>
    </item>
    <item>
      <title>Bayesian Component Separation for DESI LAE Automated Spectroscopic Redshifts and Photometric Targeting</title>
      <link>https://arxiv.org/abs/2504.06870</link>
      <description>arXiv:2504.06870v1 Announce Type: cross 
Abstract: Lyman Alpha Emitters (LAEs) are valuable high-redshift cosmological probes traditionally identified using specialized narrow-band photometric surveys. In ground-based spectroscopy, it can be difficult to distinguish the sharp LAE peak from residual sky emission lines using automated methods, leading to misclassified redshifts. We present a Bayesian spectral component separation technique to automatically determine spectroscopic redshifts for LAEs while marginalizing over sky residuals. We use visually inspected spectra of LAEs obtained using the Dark Energy Spectroscopic Instrument (DESI) to create a data-driven prior and can determine redshift by jointly inferring sky residual, LAE, and residual components for each individual spectrum. We demonstrate this method on 910 spectroscopically observed $z = 2-4$ DESI LAE candidate spectra and determine their redshifts with $&gt;$90% accuracy when validated against visually inspected redshifts. Using the $\Delta \chi^2$ value from our pipeline as a proxy for detection confidence, we then explore potential survey design choices and implications for targeting LAEs with medium-band photometry. This method allows for scalability and accuracy in determining redshifts from DESI spectra, and the results provide recommendations for LAE targeting in anticipation of future high-redshift spectroscopic surveys.</description>
      <guid isPermaLink="false">oai:arXiv.org:2504.06870v1</guid>
      <category>astro-ph.IM</category>
      <category>astro-ph.CO</category>
      <category>stat.AP</category>
      <pubDate>Thu, 10 Apr 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Ana Sof\'ia M. Uzsoy, Andrew K. Saydjari, Arjun Dey, Anand Raichoor, Douglas P. Finkbeiner, Eric Gawiser, Kyoung-Soo Lee, Steven Ahlen, Davide Bianchi, David Brooks, Todd Claybaugh, Andrei Cuceu, Axel de la Macorra, Peter Doel, Andreu Font-Ribera, Jaime E. Forero-Romero, Enrique Gazta\~naga, Satya Gontcho A Gontcho, Gaston Gutierrez, Mustapha Ishak, Robert Kehoe, David Kirkby, Anthony Kremin, Martin Landriau, Laurent Le Guillou, Aaron Meisner, Ramon Miquel, John Moustakas, Nathalie Palanque-Delabrouille, Francisco Prada, Ignasi P\'erez-R\`afols, Graziano Rossi, Eusebio Sanchez, David Schlegel, Michael Schubnell, Hee-Jong Seo, David Sprayberry, Gregory Tarl\'e, Benjamin Alan Weaver, Hu Zou</dc:creator>
    </item>
    <item>
      <title>Polyspectral Mean based Time Series Clustering of Indian Stock Market</title>
      <link>https://arxiv.org/abs/2504.07021</link>
      <description>arXiv:2504.07021v1 Announce Type: cross 
Abstract: In this study, we employ k-means clustering algorithm of polyspectral means to analyze 49 stocks in the Indian stock market. We have used spectral and bispectral information obtained from the data, by using spectral and bispectral means with different weight functions that will give us varying insights into the temporal patterns of the stocks. In particular, the higher order polyspectral means can provide significantly more information than what we can gather from power spectra, and can also unveil nonlinear trends in a time series. Through rigorous analysis, we identify five distinctive clusters, uncovering nuanced market structures. Notably, one cluster emerges as that of a conglomerate powerhouse, featuring ADANI, BIRLA, TATA, and unexpectedly, government-owned bank SBI. Another cluster spotlights the IT sector with WIPRO and TCS, while a third combines private banks, government entities, and RELIANCE. The final cluster comprises publicly traded companies with dispersed ownership. Such clustering of stocks sheds light on intricate financial relationships within the stock market, providing valuable insights for investors and analysts navigating the dynamic landscape of the Indian stock market.</description>
      <guid isPermaLink="false">oai:arXiv.org:2504.07021v1</guid>
      <category>q-fin.ST</category>
      <category>stat.AP</category>
      <pubDate>Thu, 10 Apr 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <arxiv:DOI>10.1007/s44248-025-00030-w</arxiv:DOI>
      <arxiv:journal_reference>Discov Data 3, 10 (2025)</arxiv:journal_reference>
      <dc:creator>Dhrubajyoti Ghosh</dc:creator>
    </item>
    <item>
      <title>Beyond the Hype: Embeddings vs. Prompting for Multiclass Classification Tasks</title>
      <link>https://arxiv.org/abs/2504.04277</link>
      <description>arXiv:2504.04277v2 Announce Type: replace-cross 
Abstract: Are traditional classification approaches irrelevant in this era of AI hype? We show that there are multiclass classification problems where predictive models holistically outperform LLM prompt-based frameworks. Given text and images from home-service project descriptions provided by Thumbtack customers, we build embeddings-based softmax models that predict the professional category (e.g., handyman, bathroom remodeling) associated with each problem description. We then compare against prompts that ask state-of-the-art LLM models to solve the same problem. We find that the embeddings approach outperforms the best LLM prompts in terms of accuracy, calibration, latency, and financial cost. In particular, the embeddings approach has 49.5% higher accuracy than the prompting approach, and its superiority is consistent across text-only, image-only, and text-image problem descriptions. Furthermore, it yields well-calibrated probabilities, which we later use as confidence signals to provide contextualized user experience during deployment. On the contrary, prompting scores are overly uninformative. Finally, the embeddings approach is 14 and 81 times faster than prompting in processing images and text respectively, while under realistic deployment assumptions, it can be up to 10 times cheaper. Based on these results, we deployed a variation of the embeddings approach, and through A/B testing we observed performance consistent with our offline analysis. Our study shows that for multiclass classification problems that can leverage proprietary datasets, an embeddings-based approach may yield unequivocally better results. Hence, scientists, practitioners, engineers, and business leaders can use our study to go beyond the hype and consider appropriate predictive models for their classification use cases.</description>
      <guid isPermaLink="false">oai:arXiv.org:2504.04277v2</guid>
      <category>cs.LG</category>
      <category>cs.AI</category>
      <category>cs.CL</category>
      <category>stat.AP</category>
      <pubDate>Thu, 10 Apr 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Marios Kokkodis, Richard Demsyn-Jones, Vijay Raghavan</dc:creator>
    </item>
  </channel>
</rss>
