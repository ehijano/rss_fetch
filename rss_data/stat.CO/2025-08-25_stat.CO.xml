<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>stat.CO updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/stat.CO</link>
    <description>stat.CO updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/stat.CO" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Mon, 25 Aug 2025 04:01:16 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Mon, 25 Aug 2025 00:00:00 -0400</pubDate>
    <skipDays>
      <day>Sunday</day>
      <day>Saturday</day>
    </skipDays>
    <item>
      <title>A nonstationary spatial model of PM2.5 with localized transfer learning from numerical model output</title>
      <link>https://arxiv.org/abs/2508.15978</link>
      <description>arXiv:2508.15978v1 Announce Type: cross 
Abstract: Ambient air pollution measurements from regulatory monitoring networks are routinely used to support epidemiologic studies and environmental policy decision making. However, regulatory monitors are spatially sparse and preferentially located in areas with large populations. Numerical air pollution model output can be leveraged into the inference and prediction of air pollution data combining with measurements from monitors. Nonstationary covariance functions allow the model to adapt to spatial surfaces whose variability changes with location like air pollution data. In the paper, we employ localized covariance parameters learned from the numerical output model to knit together into a global nonstationary covariance, to incorporate in a fully Bayesian model. We model the nonstationary structure in a computationally efficient way to make the Bayesian model scalable.</description>
      <guid isPermaLink="false">oai:arXiv.org:2508.15978v1</guid>
      <category>stat.AP</category>
      <category>stat.CO</category>
      <category>stat.ME</category>
      <pubDate>Mon, 25 Aug 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Wenlong Gong, Brian J. Reich, Joseph Guinness</dc:creator>
    </item>
    <item>
      <title>The Community Index: A More Comprehensive Approach to Assessing Scholarly Impact</title>
      <link>https://arxiv.org/abs/2508.16519</link>
      <description>arXiv:2508.16519v1 Announce Type: cross 
Abstract: The h index is a widely recognized metric for assessing the research impact of scholars, defined as the maximum value h such that the scholar has published h papers each cited at least h times. While it has proven useful measuring individual scholarly productivity and citation impact, the h index has limitations, such as an inability to account for interdisciplinary collaboration or demographic differences in citation patterns. Moreover, it is sometimes mistakenly treated as a measure of research quality, even though it only reflects how often work has been cited. While metric based evaluations of research have grown in importance in some areas of academia, such as medicine, these evaluations fail to consider other important aspects of intellectual work, such as representational and epistemic diversity in research. In this article, we propose a new metric called the c index, or the community index, which combines multiple dimensions of scholarly impact. This is important because a plurality of perspectives and lived experiences within author teams can promote epistemological reflection and humility as part of the creation and validation of scientific knowledge. The c index is a means of accounting for the often global, and increasingly interdisciplinary nature of contemporary research, in particular, the data that is collected, curated and analyzed in the process of scientific inquiry. While the c index provides a means of quantifying diversity within research teams, diversity is integral to the advancement of scientific excellence and should be actively fostered through formal recognition and valuation. We herein describe the mathematical foundation of the c index and demonstrate its potential to provide a more comprehensive representation and more multidimensional assessment of scientific contributions of research impact as compared to the h index.</description>
      <guid isPermaLink="false">oai:arXiv.org:2508.16519v1</guid>
      <category>cs.DL</category>
      <category>stat.CO</category>
      <pubDate>Mon, 25 Aug 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/publicdomain/zero/1.0/</dc:rights>
      <dc:creator>Arav Kumar, Cameron Sabet, Alessandro Hammond, Amelia Fiske, Bhav Jain, Deirdre Goode, Dharaa Suresha, Leo Anthony Celi, Lisa Soleymani Lehmann, Ned Mccague, Rawan Abulibdeh, Sameer Pradhan</dc:creator>
    </item>
    <item>
      <title>Spherical latent space models for social network analysis</title>
      <link>https://arxiv.org/abs/2508.16556</link>
      <description>arXiv:2508.16556v1 Announce Type: cross 
Abstract: This article introduces a spherical latent space model for social network analysis, embedding actors on a hypersphere rather than in Euclidean space as in standard latent space models. The spherical geometry facilitates the representation of transitive relationships and community structure, naturally captures cyclical patterns, and ensures bounded distances, thereby mitigating degeneracy issues common in traditional approaches. Bayesian inference is performed via Markov chain Monte Carlo methods to estimate both latent positions and other model parameters. The approach is demonstrated using two benchmark social network datasets, yielding improved model fit and interpretability relative to conventional latent space models.</description>
      <guid isPermaLink="false">oai:arXiv.org:2508.16556v1</guid>
      <category>stat.ME</category>
      <category>stat.CO</category>
      <pubDate>Mon, 25 Aug 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Juan Sosa, Carlos Nosa</dc:creator>
    </item>
    <item>
      <title>Geodesic slice sampling on Riemannian manifolds</title>
      <link>https://arxiv.org/abs/2312.00417</link>
      <description>arXiv:2312.00417v3 Announce Type: replace 
Abstract: We propose a theoretically justified and practically applicable slice sampling based Markov chain Monte Carlo (MCMC) method for approximate sampling from probability measures on Riemannian manifolds. The latter naturally arise as posterior distributions in Bayesian inference of matrix-valued parameters, for example belonging to either the Stiefel or the Grassmann manifold. Our method, called geodesic slice sampling, is reversible with respect to the distribution of interest, and generalizes Hit-and-run slice sampling on $\mathbb{R}^{d}$ to Riemannian manifolds by using geodesics instead of straight lines. We demonstrate the robustness of our sampler's performance compared to other MCMC methods dealing with manifold valued distributions through extensive numerical experiments, on both synthetic and real data. In particular, we illustrate its remarkable ability to cope with anisotropic target densities, without using gradient information and preconditioning.</description>
      <guid isPermaLink="false">oai:arXiv.org:2312.00417v3</guid>
      <category>stat.CO</category>
      <category>math.PR</category>
      <category>stat.AP</category>
      <pubDate>Mon, 25 Aug 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Alain Durmus, Samuel Gruffaz, Mareike Hasenpflug, Daniel Rudolf</dc:creator>
    </item>
    <item>
      <title>Weak Poincar\'e inequality comparisons for ideal and hybrid slice sampling</title>
      <link>https://arxiv.org/abs/2402.13678</link>
      <description>arXiv:2402.13678v2 Announce Type: replace 
Abstract: Using the framework of weak Poincar\'e inequalities, we provide a general comparison between Hybrid and Ideal Slice Sampling in terms of their corresponding Dirichlet forms. In particular, under suitable assumptions Hybrid Slice Sampling inherits fast convergence from Ideal Slice Sampling and conversely. We apply our results to analyse the convergence of the Independent Metropolis-Hastings, stepping-out and shrinkage, as well as Hit-and-Run within slice sampling algorithms.</description>
      <guid isPermaLink="false">oai:arXiv.org:2402.13678v2</guid>
      <category>stat.CO</category>
      <category>math.PR</category>
      <category>stat.ME</category>
      <pubDate>Mon, 25 Aug 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Sam Power, Daniel Rudolf, Bj\"orn Sprungk, Andi Q. Wang</dc:creator>
    </item>
    <item>
      <title>A correlated pseudo-marginal approach to doubly intractable problems</title>
      <link>https://arxiv.org/abs/2210.02734</link>
      <description>arXiv:2210.02734v2 Announce Type: replace-cross 
Abstract: Doubly intractable models are encountered in a number of fields, e.g. social networks, ecology and epidemiology. Inference for such models requires the evaluation of a likelihood function, whose normalising factor depends on the model parameters and is assumed to be computationally intractable. The normalising constant of the posterior distribution and the additional normalising factor of the likelihood function result in a so-called doubly intractable posterior, for which it is difficult to directly apply Markov chain Monte Carlo methods. We propose a signed pseudo-marginal Metropolis-Hastings algorithm with an unbiased block-Poisson estimator to sample from the posterior distribution of doubly intractable models. As the estimator can be negative, the algorithm targets the absolute value of the estimated posterior and uses an importance sampling estimator to ensure simulation-consistent estimates of the posterior mean of a function of the parameters. The importance sampling estimator can perform poorly when its denominator is close to zero. We derive a finite-sample concentration inequality that ensures, with high probability, that this pathological case does not occur. Our estimator for doubly intractable problems has three advantages over existing estimators. First, the estimator is well-suited for efficient parallelisation and vectorisation. Second, its structure is ideal for correlated pseudo-marginal methods, which are well known to dramatically increase sampling efficiency. Third, the estimator enables the derivation of heuristic guidelines for tuning its hyperparameters under simplifying assumptions. We demonstrate the superior performance of our method in the standard benchmark example that models correlated spatial data using the Ising model, as well as the Kent distribution model for spherical data.</description>
      <guid isPermaLink="false">oai:arXiv.org:2210.02734v2</guid>
      <category>stat.ME</category>
      <category>stat.CO</category>
      <pubDate>Mon, 25 Aug 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Yu Yang, Matias Quiroz, Robert Kohn, Scott A. Sisson</dc:creator>
    </item>
  </channel>
</rss>
