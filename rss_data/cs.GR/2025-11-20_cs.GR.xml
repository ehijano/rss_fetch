<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>cs.GR updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/cs.GR</link>
    <description>cs.GR updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/cs.GR" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Thu, 20 Nov 2025 05:00:09 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Thu, 20 Nov 2025 00:00:00 -0500</pubDate>
    <skipDays>
      <day>Saturday</day>
      <day>Sunday</day>
    </skipDays>
    <item>
      <title>Fluid Control with Localized Spacetime Windows</title>
      <link>https://arxiv.org/abs/2511.15189</link>
      <description>arXiv:2511.15189v1 Announce Type: new 
Abstract: We present a physics-based fluid control method utilizing localized spacetime windows, extending force-based spacetime control to simulation scales that were previously intractable. Building on the observation that optimal control force distributions are often localized, we show that operating only in a localized spacetime window around the edit of interest can improve performance. To determine the optimal spacetime window size, we employ the Covariance Matrix Adaptation Evolution Strategy (CMA-ES) method to search for the optimal temporal window size within a user-defined spatial region. Instead of using a Lagrangian representation, we optimize and apply control forces on a "floating" background grid, decoupling the control dimensionality from the simulation and enabling seamless integration with particle-based methods. Moreover, since the boundary conditions of the localized areas are encoded in the objective function, no extra effort is required to ensure consistency between the local control region and the global simulation domain. We demonstrate the effectiveness and efficiency of our method with various 2D and 3D particle-based free-surface simulation examples.</description>
      <guid isPermaLink="false">oai:arXiv.org:2511.15189v1</guid>
      <category>cs.GR</category>
      <category>physics.flu-dyn</category>
      <pubDate>Thu, 20 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Yixin Chen, David I. W. Levin, Timothy R. Langlois</dc:creator>
    </item>
    <item>
      <title>One algebra for all : Geometric Algebra methods for neurosymbolic XR scene authoring, animation and neural rendering</title>
      <link>https://arxiv.org/abs/2511.15398</link>
      <description>arXiv:2511.15398v1 Announce Type: new 
Abstract: This position paper delves into the transformative role of Geometric Algebra (GA) in advancing specific areas of Computer Graphics (CG) and Extended Reality (XR), particularly in character animation, rendering, rigging, neural rendering, and generative AI-driven scene editing. Common CG algorithms require handling rotations, translations, and dilations (uniform scalings) in operations such as object rendering, rigged model animation, soft-body deformation, and XR simulations. Traditional representation forms - such as matrices, quaternions, and vectors - often introduce limitations in precision and performance. Recent breakthroughs in the use of GA suggest it can significantly enhance these processes by encapsulating geometric forms and transformations into uniform algebraic expressions, which maintain critical geometric properties throughout multi-step transformations. Furthermore, we explore how GA can serve as a unifying mathematical substrate for neurosymbolic XR scene authoring, bridging learned neural representations and explicit geometric reasoning. This paper outlines how GA-based approaches can improve the fidelity of rigged character animations, enhance soft-body simulations, streamline real-time rendering, and optimize neural and generative AI scene editing. GA offers a coherent and efficient framework for these processes, resulting in superior visual outcomes and computational efficiency, particularly in XR environments.</description>
      <guid isPermaLink="false">oai:arXiv.org:2511.15398v1</guid>
      <category>cs.GR</category>
      <pubDate>Thu, 20 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Manos Kamarianakis, Antonis Protopsaltis, George Papagiannakis</dc:creator>
    </item>
    <item>
      <title>MHR: Momentum Human Rig</title>
      <link>https://arxiv.org/abs/2511.15586</link>
      <description>arXiv:2511.15586v1 Announce Type: new 
Abstract: We present MHR, a parametric human body model that combines the decoupled skeleton/shape paradigm of ATLAS with a flexible, modern rig and pose corrective system inspired by the Momentum library. Our model enables expressive, anatomically plausible human animation, supporting non-linear pose correctives, and is designed for robust integration in AR/VR and graphics pipelines.</description>
      <guid isPermaLink="false">oai:arXiv.org:2511.15586v1</guid>
      <category>cs.GR</category>
      <category>cs.CV</category>
      <pubDate>Thu, 20 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Aaron Ferguson, Ahmed A. A. Osman, Berta Bescos, Carsten Stoll, Chris Twigg, Christoph Lassner, David Otte, Eric Vignola, Federica Bogo, Igor Santesteban, Javier Romero, Jenna Zarate, Jeongseok Lee, Jinhyung Park, Jinlong Yang, John Doublestein, Kishore Venkateshan, Kris Kitani, Ladislav Kavan, Marco Dal Farra, Matthew Hu, Matthew Cioffi, Michael Fabris, Michael Ranieri, Mohammad Modarres, Petr Kadlecek, Rinat Abdrashitov, Romain Pr\'evost, Roman Rajbhandari, Ronald Mallet, Russel Pearsall, Sandy Kao, Sanjeev Kumar, Scott Parrish, Te-Li Wang, Tony Tung, Yuan Dong, Yuhua Chen, Yuanlu Xu, Yuting Ye, Zhongshi Jiang</dc:creator>
    </item>
    <item>
      <title>Complex-Valued 2D Gaussian Representation for Computer-Generated Holography</title>
      <link>https://arxiv.org/abs/2511.15022</link>
      <description>arXiv:2511.15022v1 Announce Type: cross 
Abstract: We propose a new hologram representation based on structured complex-valued 2D Gaussian primitives, which replaces per-pixel information storage and reduces the parameter search space by up to 10:1. To enable end-to-end training, we develop a differentiable rasterizer for our representation, integrated with a GPU-optimized light propagation kernel in free space. Our extensive experiments show that our method achieves up to 2.5x lower VRAM usage and 50% faster optimization while producing higher-fidelity reconstructions than existing methods. We further introduce a conversion procedure that adapts our representation to practical hologram formats, including smooth and random phase-only holograms. Our experiments show that this procedure can effectively suppress noise artifacts observed in previous methods. By reducing the hologram parameter search space, our representation enables a more scalable hologram estimation in the next-generation computer-generated holography systems.</description>
      <guid isPermaLink="false">oai:arXiv.org:2511.15022v1</guid>
      <category>cs.CV</category>
      <category>cs.GR</category>
      <category>cs.LG</category>
      <pubDate>Thu, 20 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Yicheng Zhan, Xiangjun Gao, Long Quan, Kaan Ak\c{s}it</dc:creator>
    </item>
    <item>
      <title>Capture Stage Matting: Challenges, Approaches, and Solutions for Offline and Real-Time Processing</title>
      <link>https://arxiv.org/abs/2507.07623</link>
      <description>arXiv:2507.07623v2 Announce Type: replace 
Abstract: Capture stages are high-end sources of state-of-the-art recordings for downstream applications in movies, games, and other media. One crucial step in almost all pipelines is matting, i.e., separating captured performances from the background. While common matting algorithms deliver remarkable performance in other applications like teleconferencing and mobile entertainment, we found that they struggle significantly with the peculiarities of capture stage content. The goal of our work is to share insights into those challenges as a curated list of these characteristics along with a constructive discussion for proactive intervention and present a guideline to practitioners for an improved workflow to mitigate unresolved challenges. To this end, we also demonstrate an efficient pipeline to adapt state-of-the-art approaches to such custom setups without the need for extensive annotations, both offline and real-time. For an objective evaluation, we introduce a validation methodology using a state-of-the-art diffusion model to demonstrate the benefits of our approach.</description>
      <guid isPermaLink="false">oai:arXiv.org:2507.07623v2</guid>
      <category>cs.GR</category>
      <category>cs.CV</category>
      <pubDate>Thu, 20 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Hannah Dr\"oge, Janelle Pfeifer, Saskia Rabich, Reinhard Klein, Matthias B. Hullin, Markus Plack</dc:creator>
    </item>
    <item>
      <title>MedBuild AI: An Agent-Based Hybrid Intelligence Framework for Reshaping Agency in Healthcare Infrastructure Planning through Generative Design for Medical Architecture</title>
      <link>https://arxiv.org/abs/2511.11587</link>
      <description>arXiv:2511.11587v3 Announce Type: replace-cross 
Abstract: Globally, disparities in healthcare infrastructure remain stark, leaving countless communities without access to even basic services. Traditional infrastructure planning is often slow and inaccessible, and although many architects are actively delivering humanitarian and aid-driven hospital projects worldwide, these vital efforts still fall far short of the sheer scale and urgency of demand. This paper introduces MedBuild AI, a hybrid-intelligence framework that integrates large language models (LLMs) with deterministic expert systems to rebalance the early design and conceptual planning stages. As a web-based platform, it enables any region with satellite internet access to obtain guidance on modular, low-tech, low-cost medical building designs. The system operates through three agents: the first gathers local health intelligence via conversational interaction; the second translates this input into an architectural functional program through rule-based computation; and the third generates layouts and 3D models. By embedding computational negotiation into the design process, MedBuild AI fosters a reciprocal, inclusive, and equitable approach to healthcare planning, empowering communities and redefining agency in global healthcare architecture.</description>
      <guid isPermaLink="false">oai:arXiv.org:2511.11587v3</guid>
      <category>cs.HC</category>
      <category>cs.AI</category>
      <category>cs.CE</category>
      <category>cs.GR</category>
      <category>cs.MA</category>
      <pubDate>Thu, 20 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Yiming Zhang, Yuejia Xu, Ziyao Wang, Xin Yan, Xiaosai Hao</dc:creator>
    </item>
    <item>
      <title>SymGS : Leveraging Local Symmetries for 3D Gaussian Splatting Compression</title>
      <link>https://arxiv.org/abs/2511.13264</link>
      <description>arXiv:2511.13264v2 Announce Type: replace-cross 
Abstract: 3D Gaussian Splatting has emerged as a transformative technique in novel view synthesis, primarily due to its high rendering speed and photorealistic fidelity. However, its memory footprint scales rapidly with scene complexity, often reaching several gigabytes. Existing methods address this issue by introducing compression strategies that exploit primitive-level redundancy through similarity detection and quantization. We aim to surpass the compression limits of such methods by incorporating symmetry-aware techniques, specifically targeting mirror symmetries to eliminate redundant primitives. We propose a novel compression framework, SymGS, introducing learnable mirrors into the scene, thereby eliminating local and global reflective redundancies for compression. Our framework functions as a plug-and-play enhancement to state-of-the-art compression methods, (e.g. HAC) to achieve further compression. Compared to HAC, we achieve $1.66 \times$ compression across benchmark datasets (upto $3\times$ on large-scale scenes). On an average, SymGS enables $\bf{108\times}$ compression of a 3DGS scene, while preserving rendering quality. The project page and supplementary can be found at symgs.github.io</description>
      <guid isPermaLink="false">oai:arXiv.org:2511.13264v2</guid>
      <category>cs.CV</category>
      <category>cs.GR</category>
      <pubDate>Thu, 20 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Keshav Gupta, Akshat Sanghvi, Shreyas Reddy Palley, Astitva Srivastava, Charu Sharma, Avinash Sharma</dc:creator>
    </item>
  </channel>
</rss>
