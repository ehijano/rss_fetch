<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>q-fin.RM updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/q-fin.RM</link>
    <description>q-fin.RM updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/q-fin.RM" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Fri, 07 Jun 2024 04:12:37 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Fri, 07 Jun 2024 00:00:00 -0400</pubDate>
    <skipDays>
      <day>Sunday</day>
      <day>Saturday</day>
    </skipDays>
    <item>
      <title>Impact of aleatoric, stochastic and epistemic uncertainties on project cost contingency reserves</title>
      <link>https://arxiv.org/abs/2406.03500</link>
      <description>arXiv:2406.03500v1 Announce Type: cross 
Abstract: In construction projects, contingency reserves have traditionally been estimated based on a percentage of the total project cost, which is arbitrary and, thus, unreliable in practical cases. Monte Carlo simulation provides a more reliable estimation. However, works on this topic have focused exclusively on the effects of aleatoric uncertainty, but ignored the impacts of other uncertainty types. In this paper, we present a method to quantitatively determine project cost contingency reserves based on Monte Carlo Simulation that considers the impact of not only aleatoric uncertainty, but also of the effects of other uncertainty kinds (stochastic, epistemic) on the total project cost. The proposed method has been validated with a real-case construction project in Spain. The obtained results demonstrate that the approach will be helpful for construction Project Managers because the obtained cost contingency reserves are consistent with the actual uncertainty type that affects the risks identified in their projects.</description>
      <guid isPermaLink="false">oai:arXiv.org:2406.03500v1</guid>
      <category>stat.AP</category>
      <category>q-fin.RM</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <arxiv:DOI>10.1016/j.ijpe.2022.108626</arxiv:DOI>
      <arxiv:journal_reference>International Journal of Production Economics 253, 108626 2022</arxiv:journal_reference>
      <dc:creator>David Curto, Fernando Acebes, Jose M Gonzalez-Varona, David Poza</dc:creator>
    </item>
    <item>
      <title>Advancing Anomaly Detection: Non-Semantic Financial Data Encoding with LLMs</title>
      <link>https://arxiv.org/abs/2406.03614</link>
      <description>arXiv:2406.03614v1 Announce Type: cross 
Abstract: Detecting anomalies in general ledger data is of utmost importance to ensure trustworthiness of financial records. Financial audits increasingly rely on machine learning (ML) algorithms to identify irregular or potentially fraudulent journal entries, each characterized by a varying number of transactions. In machine learning, heterogeneity in feature dimensions adds significant complexity to data analysis. In this paper, we introduce a novel approach to anomaly detection in financial data using Large Language Models (LLMs) embeddings. To encode non-semantic categorical data from real-world financial records, we tested 3 pre-trained general purpose sentence-transformer models. For the downstream classification task, we implemented and evaluated 5 optimized ML models including Logistic Regression, Random Forest, Gradient Boosting Machines, Support Vector Machines, and Neural Networks. Our experiments demonstrate that LLMs contribute valuable information to anomaly detection as our models outperform the baselines, in selected settings even by a large margin. The findings further underscore the effectiveness of LLMs in enhancing anomaly detection in financial journal entries, particularly by tackling feature sparsity. We discuss a promising perspective on using LLM embeddings for non-semantic data in the financial context and beyond.</description>
      <guid isPermaLink="false">oai:arXiv.org:2406.03614v1</guid>
      <category>cs.LG</category>
      <category>cs.CL</category>
      <category>q-fin.RM</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Alexander Bakumenko (Clemson University, USA), Kate\v{r}ina Hlav\'a\v{c}kov\'a-Schindler (University of Vienna, Austria), Claudia Plant (University of Vienna, Austria), Nina C. Hubig (Clemson University, USA)</dc:creator>
    </item>
    <item>
      <title>Efficient Wrong-Way Risk Modelling for Funding Valuation Adjustments</title>
      <link>https://arxiv.org/abs/2209.12222</link>
      <description>arXiv:2209.12222v4 Announce Type: replace-cross 
Abstract: Wrong-Way Risk (WWR) is an important component in Funding Valuation Adjustment (FVA) modelling. Yet, the standard assumption is independence between market risks and the counterparty defaults and funding costs. This typical industrial setting is our point of departure, where we aim to assess the impact of WWR without running a full Monte Carlo simulation with all credit and funding processes. We propose to split the exposure profile into two parts: an independent and a WWR-driven part. For the former, exposures can be re-used from the standard xVA calculation. We express the second part of the exposure profile in terms of the stochastic drivers and approximate these by a common Gaussian stochastic factor. Within the affine setting, the proposed approximation is generic, is an add-on to the existing xVA calculations and provides an efficient and robust way to include WWR in FVA modelling. Case studies for an interest rate swap and a representative multi-currency portfolio of swaps illustrate that the approximation method is applicable in a practical setting. We analyze the approximation error and use the approximation to compute WWR sensitivities, which are needed for risk management. The approach is equally applicable to other metrics such as Credit Valuation Adjustment.</description>
      <guid isPermaLink="false">oai:arXiv.org:2209.12222v4</guid>
      <category>q-fin.CP</category>
      <category>q-fin.MF</category>
      <category>q-fin.RM</category>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <arxiv:DOI>10.1142/S0219024924500109</arxiv:DOI>
      <dc:creator>T. van der Zwaard, L. A. Grzelak, C. W. Oosterlee</dc:creator>
    </item>
    <item>
      <title>On the use of artificial intelligence in financial regulations and the impact on financial stability</title>
      <link>https://arxiv.org/abs/2310.11293</link>
      <description>arXiv:2310.11293v5 Announce Type: replace-cross 
Abstract: Artificial intelligence (AI) can undermine financial stability because of malicious use, misinformation, misalignment, and the AI analytics market structure. The low frequency and uniqueness of financial crises, coupled with mutable and unclear objectives, frustrate machine learning. Even if the authorities prefer a conservative approach to AI adoption, it will likely become widely used by stealth, taking over increasingly high-level functions driven by significant cost efficiencies and superior performance. We propose six criteria for judging the suitability of AI.</description>
      <guid isPermaLink="false">oai:arXiv.org:2310.11293v5</guid>
      <category>econ.GN</category>
      <category>q-fin.EC</category>
      <category>q-fin.RM</category>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Jon Danielsson, Andreas Uthemann</dc:creator>
    </item>
  </channel>
</rss>
