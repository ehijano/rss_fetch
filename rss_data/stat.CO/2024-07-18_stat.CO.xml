<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>stat.CO updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/stat.CO</link>
    <description>stat.CO updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/stat.CO" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Fri, 19 Jul 2024 04:00:32 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Fri, 19 Jul 2024 00:00:00 -0400</pubDate>
    <skipDays>
      <day>Sunday</day>
      <day>Saturday</day>
    </skipDays>
    <item>
      <title>Convergence of SMACOF</title>
      <link>https://arxiv.org/abs/2407.12945</link>
      <description>arXiv:2407.12945v1 Announce Type: new 
Abstract: To study convergence of SMACOF we introduce a modification mSMACOF that rotates the configurations from each of the SMACOF iterations to principal components. This modification, called mSMACOF, has the same stress values as SMACOF in each iteration, but unlike SMACOF it produces a sequence of configurations that properly converges to a solution. We show that the modified algorithm can be implemented by iterating ordinary SMACOF to convergence, and then rotating the SMACOF solution to principal components. The speed of linear convergence of SMACOF and mSMACOF is the same, and is equal to the largest eigenvalue of the derivative of the Guttman transform, ignoring the trivial unit eigenvalues that result from rotational indeterminacy.</description>
      <guid isPermaLink="false">oai:arXiv.org:2407.12945v1</guid>
      <category>stat.CO</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/publicdomain/zero/1.0/</dc:rights>
      <dc:creator>Jan De Leeuw</dc:creator>
    </item>
    <item>
      <title>Incorporating additional evidence as prior information to resolve non-identifiability in Bayesian disease model calibration</title>
      <link>https://arxiv.org/abs/2407.13451</link>
      <description>arXiv:2407.13451v1 Announce Type: new 
Abstract: Background: Statisticians evaluating the impact of policy interventions such as screening or vaccination will need to make use of mathematical and computational models of disease progression and spread. Calibration is the process of identifying the parameters of these models, with a Bayesian framework providing a natural way in which to do this in a probabilistic fashion. Markov Chain Monte Carlo (MCMC) is one of a number of computational tools that is useful in carrying out this calibration. Objective: In the context of complex models in particular, a key problem that arises is one of non-identifiability. In this setting, one approach which can be used is to consider and ensure that appropriately informative priors are specified on the joint parameter space. We give examples of how this arises and may be addressed in practice. Methods: Using a basic SIS model the calibration process and the associated challenge of non-identifiability is discussed. How this problem arises in the context of a larger model for HPV and cervical cancer is also illustrated. Results: The conditions which allow the problem of non-identifiability to be resolved are demonstrated for the SIS model. For the larger HPV model, how this impacts on the calibration process is also discussed.</description>
      <guid isPermaLink="false">oai:arXiv.org:2407.13451v1</guid>
      <category>stat.CO</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Daria Semochkina, Cathal Walsh</dc:creator>
    </item>
    <item>
      <title>Examining inverse generative social science to study targets of interest</title>
      <link>https://arxiv.org/abs/2407.13474</link>
      <description>arXiv:2407.13474v1 Announce Type: new 
Abstract: We assess an emerging simulation research method -- Inverse Generative Social Science (IGSS) \citep{Epstein23a} -- that harnesses the power of evolution by natural selection to model and explain complex targets.
  Drawing on a review of recent papers that use IGSS, and by applying it in two different studies of conflict, we here assess its potential both as a modelling approach and as formal theory.
  We find that IGSS has potential for research in studies of organistions. IGSS offers two huge advantages over most other approaches to modelling. 1) IGSS has the potential to fit complex non-linear models to a target and 2) the models have the potential to be interpreted as social theory.
  The paper presents IGSS to a new audience, illustrates how it can contribute, and provides software that can be used as a basis of an IGSS study.</description>
      <guid isPermaLink="false">oai:arXiv.org:2407.13474v1</guid>
      <category>stat.CO</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Thomas Chesney, Asif Jaffer, Robert Pasley</dc:creator>
    </item>
    <item>
      <title>Studying the Performance of the Jellyfish Search Optimiser for the Application of Projection Pursuit</title>
      <link>https://arxiv.org/abs/2407.13663</link>
      <description>arXiv:2407.13663v1 Announce Type: new 
Abstract: The projection pursuit (PP) guided tour interactively optimises a criteria function known as the PP index, to explore high-dimensional data by revealing interesting projections. The optimisation in PP can be non-trivial, involving non-smooth functions and optima with a small squint angle, detectable only from close proximity. To address these challenges, this study investigates the performance of a recently introduced swarm-based algorithm, Jellyfish Search Optimiser (JSO), for optimising PP indexes. The performance of JSO for visualising data is evaluated across various hyper-parameter settings and compared with existing optimisers. Additionally, this work proposes novel methods to quantify two properties of the PP index, smoothness and squintability that capture the complexities inherent in PP optimisation problems. These two metrics are evaluated along with JSO hyper-parameters to determine their effects on JSO success rate. Our numerical results confirm the positive impact of these metrics on the JSO success rate, with squintability being the most significant. The JSO algorithm has been implemented in the tourr package and functions to calculate smoothness and squintability are available in the ferrn package.</description>
      <guid isPermaLink="false">oai:arXiv.org:2407.13663v1</guid>
      <category>stat.CO</category>
      <category>cs.NE</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>H. Sherry Zhang, Dianne Cook, Nicolas Langren\'e, Jessica Wai Yin Leung</dc:creator>
    </item>
    <item>
      <title>Evaluating the evolution and inter-individual variability of infant functional module development from 0 to 5 years old</title>
      <link>https://arxiv.org/abs/2407.13118</link>
      <description>arXiv:2407.13118v1 Announce Type: cross 
Abstract: The segregation and integration of infant brain networks undergo tremendous changes due to the rapid development of brain function and organization. Traditional methods for estimating brain modularity usually rely on group-averaged functional connectivity (FC), often overlooking individual variability. To address this, we introduce a novel approach utilizing Bayesian modeling to analyze the dynamic development of functional modules in infants over time. This method retains inter-individual variability and, in comparison to conventional group averaging techniques, more effectively detects modules, taking into account the stationarity of module evolution. Furthermore, we explore gender differences in module development under awake and sleep conditions by assessing modular similarities. Our results show that female infants demonstrate more distinct modular structures between these two conditions, possibly implying relative quiet and restful sleep compared with male infants.</description>
      <guid isPermaLink="false">oai:arXiv.org:2407.13118v1</guid>
      <category>q-bio.NC</category>
      <category>stat.CO</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Lingbin Bian, Nizhuan Wang, Yuanning Li, Adeel Razi, Qian Wang, Han Zhang, Dinggang Shen, the UNC/UMN Baby Connectome Project Consortium</dc:creator>
    </item>
    <item>
      <title>Sparse and geometry-aware generalisation of the mutual information for joint discriminative clustering and feature selection</title>
      <link>https://arxiv.org/abs/2302.03391</link>
      <description>arXiv:2302.03391v2 Announce Type: replace-cross 
Abstract: Feature selection in clustering is a hard task which involves simultaneously the discovery of relevant clusters as well as relevant variables with respect to these clusters. While feature selection algorithms are often model-based through optimised model selection or strong assumptions on the data distribution, we introduce a discriminative clustering model trying to maximise a geometry-aware generalisation of the mutual information called GEMINI with a simple l1 penalty: the Sparse GEMINI. This algorithm avoids the burden of combinatorial feature subset exploration and is easily scalable to high-dimensional data and large amounts of samples while only designing a discriminative clustering model. We demonstrate the performances of Sparse GEMINI on synthetic datasets and large-scale datasets. Our results show that Sparse GEMINI is a competitive algorithm and has the ability to select relevant subsets of variables with respect to the clustering without using relevance criteria or prior hypotheses.</description>
      <guid isPermaLink="false">oai:arXiv.org:2302.03391v2</guid>
      <category>stat.ML</category>
      <category>cs.AI</category>
      <category>cs.LG</category>
      <category>stat.CO</category>
      <category>stat.ME</category>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Louis Ohl, Pierre-Alexandre Mattei, Charles Bouveyron, Micka\"el Leclercq, Arnaud Droit, Fr\'ed\'eric Precioso</dc:creator>
    </item>
  </channel>
</rss>
