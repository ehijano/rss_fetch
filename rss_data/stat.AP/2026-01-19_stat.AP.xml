<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>stat.AP updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/stat.AP</link>
    <description>stat.AP updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/stat.AP" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Mon, 19 Jan 2026 05:01:16 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Mon, 19 Jan 2026 00:00:00 -0500</pubDate>
    <skipDays>
      <day>Sunday</day>
      <day>Saturday</day>
    </skipDays>
    <item>
      <title>A Note on Harmonic Underspecification in Log-Normal Trigonometric Regression</title>
      <link>https://arxiv.org/abs/2601.10919</link>
      <description>arXiv:2601.10919v1 Announce Type: new 
Abstract: Analysis of biological rhythm data often involves performing least squares trigonometric regression, which models the oscillations of a response over time as a sum of sinusoidal components. When the response is not normally distributed, an investigator will either transform the response before applying least squares trigonometric regression or extend trigonometric regression to a generalized linear model (GLM) framework. In this note, we compare these two approaches when the number of oscillation harmonics is underspecified. We assume data are sampled under an equispaced experimental design and that a log link function would be appropriate for a GLM. We show that when the response follows a generalized gamma distribution, least squares trigonometric regression with a log-transformed response, or log-normal trigonometric regression, produces unbiased parameter estimates for the oscillation harmonics, even when the number of oscillation harmonics is underspecified. In contrast, GLMs require correct specification to produce unbiased parameter estimates. We apply both methods to cortisol level data and find that only log-normal trigonometric regression produces parameter estimates that are invariant to the number of specified oscillation harmonics. Additionally, when a sufficiently large number of oscillation harmonics is specified, both methods produce identical parameter estimates for the oscillation harmonics.</description>
      <guid isPermaLink="false">oai:arXiv.org:2601.10919v1</guid>
      <category>stat.AP</category>
      <pubDate>Mon, 19 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Michael T. Gorczyca</dc:creator>
    </item>
    <item>
      <title>Analyzing Residential Speeding Using Connected Vehicle Data: A Case Study in Charlottesville, VA Area</title>
      <link>https://arxiv.org/abs/2601.10974</link>
      <description>arXiv:2601.10974v1 Announce Type: new 
Abstract: This study uses connected vehicle data to analyze speeding behavior on residential roads. A scalable pipeline processes trajectory data and supplements missing speed limits to generate summaries at OpenStreetMap's way ID level. The findings reveal a highly skewed distribution of both aggressive and reckless speeding. Based on a case study of Charlottesville, VA's connected vehicle data on residential roads, we found that 38% of segments had at least one instance of aggressive speeding, and 20% had at least one instance of reckless speeding. In addition, night time speeding is 27 times more prevalent than day time, and extreme violations on specific road segments highlight how severe the issue can be. Several segments rank among the top 10 for both aggressive and reckless speedings, indicating that there exist high-risk residential roads. These findings support the need for both spatial and behavioral interventions. The analysis provides a rich foundation for policy and planning, offering a valuable complement to traditional enforcement and planning tools. In conclusion, this framework sets the foundation for future applications in traffic safety analytics, demonstrating the growing potential of telematics data to inform safer, more livable communities.</description>
      <guid isPermaLink="false">oai:arXiv.org:2601.10974v1</guid>
      <category>stat.AP</category>
      <pubDate>Mon, 19 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Shi Feng, B. Brian Park, Andrew Mondschein</dc:creator>
    </item>
    <item>
      <title>Beyond Unidimensionality: General Factors and Residual Heterogeneity in Performance Evaluation</title>
      <link>https://arxiv.org/abs/2601.10862</link>
      <description>arXiv:2601.10862v1 Announce Type: cross 
Abstract: How do evaluation systems compress multidimensional performance information into summary ratings? Using expert assessments of 9,669 professional soccer players on 28 attributes, we characterize the dimensional structure of evaluation outputs. The first principal component explains 40.6% of attribute variance, indicating a strong general factor, but formal noise discrimination procedures retain four components and bootstrap resampling confirms that this structure is highly stable. Internal consistency is high without evidence of redundancy. In out of sample prediction of expert overall ratings, a comprehensive model using the full attribute set substantially outperforms a single-factor summary (cross-validated R squared = 0.814). Overall, performance evaluations exhibit moderate information compression; they combine shared variance with stable residual dimensions that are economically meaningful for evaluation outcomes, with direct implications for the design of measurement systems.</description>
      <guid isPermaLink="false">oai:arXiv.org:2601.10862v1</guid>
      <category>econ.GN</category>
      <category>q-fin.EC</category>
      <category>stat.AP</category>
      <pubDate>Mon, 19 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Krishna Sharma, Pritam Basnet</dc:creator>
    </item>
    <item>
      <title>Locally sparse varying coefficient mixed model with application to longitudinal microbiome differential abundance</title>
      <link>https://arxiv.org/abs/2601.10872</link>
      <description>arXiv:2601.10872v1 Announce Type: cross 
Abstract: Differential abundance (DA) analysis in microbiome studies has recently been used to uncover a plethora of associations between microbial composition and various health conditions. While current approaches to DA typically apply only to cross-sectional data, many studies feature a longitudinal design to better understand the underlying microbial dynamics. To study DA in longitudinal microbial studies, we introduce a novel varying coefficient mixed-effects model with local sparsity. The proposed method can identify time intervals of significant group differences while accounting for temporal dependence. Specifically, we exploit a penalized kernel smoothing approach for parameter estimation and include a random effect to account for serial correlation. In particular, our method operates effectively regardless of whether sampling times are shared across subjects, accommodating irregular sampling and missing observations. Simulation studies demonstrate the necessity of modeling dependence for precise estimation and support recovery. The application of our method to a longitudinal study of mice oral microbiome during cancer development revealed significant scientific insights that were otherwise not discernible through cross-sectional analyses. An R implementation is available at https://github.com/fontaine618/LSVCMM.</description>
      <guid isPermaLink="false">oai:arXiv.org:2601.10872v1</guid>
      <category>stat.ME</category>
      <category>stat.AP</category>
      <pubDate>Mon, 19 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Simon Fontaine, Nisha J. D'Silva, Marcell Costa de Medeiros, Grace Y. Chen, Ji Zhu, Gen Li</dc:creator>
    </item>
    <item>
      <title>Optimal and Unbiased Fluxes from Up-the-Ramp Detectors under Variable Illumination</title>
      <link>https://arxiv.org/abs/2601.10878</link>
      <description>arXiv:2601.10878v1 Announce Type: cross 
Abstract: Near-infrared (NIR) detectors -- which use non-destructive readouts to measure time-series counts-per-pixel -- play a crucial role in modern astrophysics. Standard NIR flux extraction techniques were developed for space-based observations and assume that source fluxes are constant over an observation. However, ground-based telescopes often see short-timescale atmospheric variations that can dramatically change the number of photons arriving at a pixel. This work presents a new statistical model that shares information between neighboring spectral pixels to characterize time-variable observations and extract unbiased fluxes with optimal uncertainties. We generate realistic synthetic data using a variety of flux and amplitude-of-time-variability conditions to confirm that our model recovers unbiased and optimal estimates of both the true flux and the time-variable signal. We find that the time-variable model should be favored over a constant-flux model when the observed count rates change by more than 3.5%. Ignoring time variability in the data can result in flux-dependent, unknown-sign biases that are as large as ~120% of the flux uncertainty. Using real APOGEE spectra, we find empirical evidence for approximately wavelength-independent, time-dependent variations in count rates with amplitudes much greater than the 3.5% threshold. Our model can robustly measure and remove the time-dependence in real data, improving the quality of data-model comparison. We show several examples where the observed time-dependence quantitatively agrees with independent measurements of observing conditions, such as variable cloud cover and seeing.</description>
      <guid isPermaLink="false">oai:arXiv.org:2601.10878v1</guid>
      <category>astro-ph.IM</category>
      <category>stat.AP</category>
      <pubDate>Mon, 19 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <dc:creator>Bowen Li, Kevin A. McKinnon, Andrew K. Saydjari, Conor Sayres, Gwendolyn M. Eadie, Andrew R. Casey, Jon A. Holtzman, Timothy D. Brandt, Jose G. Fernandez-Trincado</dc:creator>
    </item>
    <item>
      <title>Distributional Treatment Effects of Content Promotion: Evidence from an ABEMA Field Experiment</title>
      <link>https://arxiv.org/abs/2601.11185</link>
      <description>arXiv:2601.11185v1 Announce Type: cross 
Abstract: We examine the impact of top-of-screen promotions on viewing time at ABEMA, a leading video streaming platform in Japan. To this end, we conduct a large-scale randomized controlled trial. Given the non-standard distribution of user viewing times, we estimate distributional treatment effects. Our estimation results document that spotlighting content through these promotions effectively boosts user engagement across diverse content types. Notably, promoting short content proves most effective in that it not only retains users but also motivates them to watch subsequent episodes.</description>
      <guid isPermaLink="false">oai:arXiv.org:2601.11185v1</guid>
      <category>econ.GN</category>
      <category>q-fin.EC</category>
      <category>stat.AP</category>
      <pubDate>Mon, 19 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Shota Yasui, Tatsushi Oka, Undral Byambadalai, Yuki Oishi</dc:creator>
    </item>
    <item>
      <title>Study on Light Propagation through Space-Time Random Media via Stochastic Partial Differential Equations</title>
      <link>https://arxiv.org/abs/2601.11213</link>
      <description>arXiv:2601.11213v1 Announce Type: cross 
Abstract: In this letter, the theory of stochastic partial differential equations is applied to the propagation of light fields in space-time random media. By modeling the fluctuation of refractive index's square of the media as a random field, we demonstrate that the hyperbolic Anderson model is applicable to describing the propagation of light fields in such media. Additionally, several new quantitative characterizations of the stochastic properties that govern the light fields are derived. Furthermore, the validity of the theoretical framework and corresponding results is experimentally verified by analyzing the statistical properties of the propagated light fields after determining the spatial and temporal stochastic features of the random media. The results presented here provide a more accurate theoretical basis for better understanding random phenomena in emerging domains such as free-space optical communication, detection, and imaging in transparent random media. The study could also have practical guiding significance for experimental system design in these fields.</description>
      <guid isPermaLink="false">oai:arXiv.org:2601.11213v1</guid>
      <category>physics.optics</category>
      <category>math-ph</category>
      <category>math.MP</category>
      <category>stat.AP</category>
      <pubDate>Mon, 19 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Chaoran Wang, Jinquan Qi, Shuang Liu, Chenjin Deng, Shensheng Han</dc:creator>
    </item>
    <item>
      <title>Practical privacy metrics for synthetic data</title>
      <link>https://arxiv.org/abs/2406.16826</link>
      <description>arXiv:2406.16826v4 Announce Type: replace 
Abstract: This paper explains how the synthpop package for R has been extended to include functions to calculate measures of identity and attribute disclosure risk for synthetic data that measure risks for the records used to create the synthetic data. The basic function, disclosure, calculates identity disclosure for a set of quasi-identifiers (keys) and attribute disclosure for one variable specified as a target from the same set of keys. The second function, disclosure.summary, is a wrapper for the first and presents summary results for a set of targets. This short paper explains the measures of disclosure risk and documents how they are calculated. We recommend two measures: $RepU$ (replicated uniques) for identity disclosure and $DiSCO$ (Disclosive in Synthetic Correct Original) for attribute disclosure. Both are expressed a \% of the original records and each can be compared to similar measures calculated from the original data. Experience with using the functions on real data found that some apparent disclosures could be identified as coming from relationships in the data that would be expected to be known to anyone familiar with its features. We flag cases when this seems to have occurred and provide means of excluding them.</description>
      <guid isPermaLink="false">oai:arXiv.org:2406.16826v4</guid>
      <category>stat.AP</category>
      <pubDate>Mon, 19 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Gillian M Raab, Beata Nowok, Chris Dibben</dc:creator>
    </item>
    <item>
      <title>KRED: Korea Research Economic Database for Macroeconomic Research</title>
      <link>https://arxiv.org/abs/2509.16115</link>
      <description>arXiv:2509.16115v2 Announce Type: replace-cross 
Abstract: We introduce KRED (Korea Research Economic Database), a new FRED MD style macroeconomic dataset for South Korea. KRED is constructed by aggregating 88 key monthly time series from multiple official sources (e.g., Bank of Korea ECOS, Statistics Korea KOSIS) into a unified, publicly available database. The dataset is aligned with the FRED MD format, enabling standardized transformations and direct comparability; an Appendix maps each Korean series to its FRED MD counterpart. Using a balanced panel of 80 series from 2009 to 2024, we extract four principal components via PCA that explain approximately 40% of the total variance. These four factors have intuitive economic interpretations, capturing monetary conditions, labor market activity, real output, and housing demand, analogous to diffusion indexes summarizing broad economic movements. Notably, the factor based diffusion indexes derived from KRED clearly trace major macroeconomic fluctuations over the sample period such as the 2020 COVID 19 recession. Our results demonstrate that KRED's factor structure can effectively condense complex economic information into a few informative indexes, yielding new insights into South Korea's business cycles and co movements.</description>
      <guid isPermaLink="false">oai:arXiv.org:2509.16115v2</guid>
      <category>econ.EM</category>
      <category>stat.AP</category>
      <pubDate>Mon, 19 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Changryong Baek, Seunghyun Moon, Seunghyeon Lee</dc:creator>
    </item>
    <item>
      <title>Multi-task Neural Diffusion Processes</title>
      <link>https://arxiv.org/abs/2510.03419</link>
      <description>arXiv:2510.03419v2 Announce Type: replace-cross 
Abstract: Neural diffusion processes provide a scalable, non-Gaussian approach to modelling distributions over functions, but existing formulations are limited to single-task inference and do not capture dependencies across related tasks. In many multi-task regression settings, jointly modelling correlated functions and enabling task-aware conditioning is crucial for improving predictive performance and uncertainty calibration, particularly in low-data regimes. We propose multi-task neural diffusion processes, an extension that incorporates a task encoder to enable task-conditioned probabilistic regression and few-shot adaptation across related functions. The task encoder extracts a low-dimensional representation from context observations and conditions the diffusion model on this representation, allowing information sharing across tasks while preserving input-size agnosticity and the equivariance properties of neural diffusion processes. The resulting framework retains the expressiveness and scalability of neural diffusion processes while enabling efficient transfer to unseen tasks. Empirical results demonstrate improved point prediction accuracy and better-calibrated predictive uncertainty compared to single-task neural diffusion processes and Gaussian process baselines. We validate the approach on real wind farm data appropriate for wind power prediction. In this high-impact application, reliable uncertainty quantification directly supports operational decision-making in wind farm management, illustrating effective few-shot adaptation in a challenging real-world multi-task regression setting.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.03419v2</guid>
      <category>cs.LG</category>
      <category>cs.AI</category>
      <category>stat.AP</category>
      <category>stat.ML</category>
      <pubDate>Mon, 19 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Joseph Rawson, Domniki Ladopoulou, Petros Dellaportas</dc:creator>
    </item>
    <item>
      <title>Local Intrinsic Dimensionality of Ground Motion Data for Early Detection of Complex Catastrophic Slope Failure</title>
      <link>https://arxiv.org/abs/2601.03569</link>
      <description>arXiv:2601.03569v2 Announce Type: replace-cross 
Abstract: Local Intrinsic Dimensionality (LID) has shown strong potential for identifying anomalies and outliers in high-dimensional data across a wide range of real-world applications, including landslide failure detection in granular media. Early and accurate identification of failure zones in landslide-prone areas is crucial for effective geohazard mitigation. While existing approaches typically rely on surface displacement data analyzed through statistical or machine learning techniques, they often fall short in capturing both the spatial correlations and temporal dynamics that are inherent in such data. To address this gap, we focus on ground-monitored landslides and introduce a novel approach that jointly incorporates spatial and temporal information, enabling the detection of complex landslides and including multiple successive failures occurring in distinct areas of the same slope. To be specific, our method builds upon an existing LID-based technique, known as sLID. We extend its capabilities in three key ways. (1) Kinematic enhancement: we incorporate velocity into the sLID computation to better capture short-term temporal dependencies and deformation rate relationships. (2) Spatial fusion: we apply Bayesian estimation to aggregate sLID values across spatial neighborhoods, effectively embedding spatial correlations into the LID scores. (3) Temporal modeling: we introduce a temporal variant, tLID, that learns long-term dynamics from time series data, providing a robust temporal representation of displacement behavior. Finally, we integrate both components into a unified framework, referred to as spatiotemporal LID (stLID), to identify samples that are anomalous in either or both dimensions. Extensive experiments show that stLID consistently outperforms existing methods in failure detection precision and lead-time.</description>
      <guid isPermaLink="false">oai:arXiv.org:2601.03569v2</guid>
      <category>cs.LG</category>
      <category>stat.AP</category>
      <pubDate>Mon, 19 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Yuansan Liu, Antoinette Tordesillas, James Bailey</dc:creator>
    </item>
  </channel>
</rss>
