<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>q-bio.QM updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/q-bio.QM</link>
    <description>q-bio.QM updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/q-bio.QM" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Wed, 12 Jun 2024 01:55:29 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Tue, 11 Jun 2024 00:00:00 -0400</pubDate>
    <skipDays>
      <day>Saturday</day>
      <day>Sunday</day>
    </skipDays>
    <item>
      <title>A Fine-tuning Dataset and Benchmark for Large Language Models for Protein Understanding</title>
      <link>https://arxiv.org/abs/2406.05540</link>
      <description>arXiv:2406.05540v1 Announce Type: new 
Abstract: The parallels between protein sequences and natural language in their sequential structures have inspired the application of large language models (LLMs) to protein understanding. Despite the success of LLMs in NLP, their effectiveness in comprehending protein sequences remains an open question, largely due to the absence of datasets linking protein sequences to descriptive text. Researchers have then attempted to adapt LLMs for protein understanding by integrating a protein sequence encoder with a pre-trained LLM. However, this adaptation raises a fundamental question: "Can LLMs, originally designed for NLP, effectively comprehend protein sequences as a form of language?" Current datasets fall short in addressing this question due to the lack of a direct correlation between protein sequences and corresponding text descriptions, limiting the ability to train and evaluate LLMs for protein understanding effectively. To bridge this gap, we introduce ProteinLMDataset, a dataset specifically designed for further self-supervised pretraining and supervised fine-tuning (SFT) of LLMs to enhance their capability for protein sequence comprehension. Specifically, ProteinLMDataset includes 17.46 billion tokens for pretraining and 893,000 instructions for SFT. Additionally, we present ProteinLMBench, the first benchmark dataset consisting of 944 manually verified multiple-choice questions for assessing the protein understanding capabilities of LLMs. ProteinLMBench incorporates protein-related details and sequences in multiple languages, establishing a new standard for evaluating LLMs' abilities in protein comprehension. The large language model InternLM2-7B, pretrained and fine-tuned on the ProteinLMDataset, outperforms GPT-4 on ProteinLMBench, achieving the highest accuracy score. The dataset and the benchmark are available at https://huggingface.co/datasets/tsynbio/ProteinLMBench.</description>
      <guid isPermaLink="false">oai:arXiv.org:2406.05540v1</guid>
      <category>q-bio.QM</category>
      <category>cs.AI</category>
      <category>cs.CL</category>
      <category>cs.LG</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Yiqing Shen, Zan Chen, Michail Mamalakis, Luhan He, Haiyang Xia, Tianbin Li, Yanzhou Su, Junjun He, Yu Guang Wang</dc:creator>
    </item>
    <item>
      <title>Improving Antibody Design with Force-Guided Sampling in Diffusion Models</title>
      <link>https://arxiv.org/abs/2406.05832</link>
      <description>arXiv:2406.05832v1 Announce Type: new 
Abstract: Antibodies, crucial for immune defense, primarily rely on complementarity-determining regions (CDRs) to bind and neutralize antigens, such as viruses. The design of these CDRs determines the antibody's affinity and specificity towards its target. Generative models, particularly denoising diffusion probabilistic models (DDPMs), have shown potential to advance the structure-based design of CDR regions. However, only a limited dataset of bound antibody-antigen structures is available, and generalization to out-of-distribution interfaces remains a challenge. Physics based force-fields, which approximate atomic interactions, offer a coarse but universal source of information to better mold designs to target interfaces. Integrating this foundational information into diffusion models is, therefore, highly desirable. Here, we propose a novel approach to enhance the sampling process of diffusion models by integrating force field energy-based feedback. Our model, DiffForce, employs forces to guide the diffusion sampling process, effectively blending the two distributions. Through extensive experiments, we demonstrate that our method guides the model to sample CDRs with lower energy, enhancing both the structure and sequence of the generated antibodies.</description>
      <guid isPermaLink="false">oai:arXiv.org:2406.05832v1</guid>
      <category>q-bio.QM</category>
      <category>cs.LG</category>
      <category>q-bio.BM</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Paulina Kulyt\.e, Francisco Vargas, Simon Valentin Mathis, Yu Guang Wang, Jos\'e Miguel Hern\'andez-Lobato, Pietro Li\`o</dc:creator>
    </item>
    <item>
      <title>Cross-sectional shape analysis for risk assessment and prognosis of patients with true lumen narrowing after type-A aortic dissection surgery</title>
      <link>https://arxiv.org/abs/2406.05173</link>
      <description>arXiv:2406.05173v1 Announce Type: cross 
Abstract: Background: For acute type-A aortic dissection (ATAAD) surgery, early post-surgery assessment is crucially important for effective treatment plans, underscoring the need for a framework to identify the risk level of aortic dissection cases. We examined true-lumen narrowing during follow-up examinations, collected morphological data 14 days (early stages) after surgery, and assessed patient risk levels over 2.8 years.
  Purpose: To establish an implementable framework supported by mathematical techniques to predict the risk of aortic dissection patients experiencing true-lumen narrowing after ATAAD surgery.
  Materials and Methods: This retrospective study analyzed CT data from 21 ATAAD patients. Forty uniformly distributed cross-sectional shapes (CSSs) are derived from each lumen to account for gradual changes in shape. We introduced the form factor (FF) to assess CSS morphology. Linear discriminant analysis (LDA) is used for the risk classification of aortic dissection patients. Leave-one-patient-out cross-validation (LOPO-CV) is used for risk prediction.
  Results: For this investigation, we examined data of 21 ATAAD patients categorized into high-risk, medium-risk, and low-risk cases based on clinical observations of the range of true-lumen narrowing. Our risk classification machine-learning (ML) model preserving the model's generalizability. The model's predictions reliably identified low-risk patients, thereby potentially reducing hospital visits. It also demonstrated proficiency in accurately predicting the risk for all high-risk patients.
  Conclusion: The suggested method anticipates the risk linked to aortic enlargement in patients with a narrowing true lumen in the early stage following ATAAD surgery, thereby aiding follow-up doctors in enhancing patient care.</description>
      <guid isPermaLink="false">oai:arXiv.org:2406.05173v1</guid>
      <category>physics.med-ph</category>
      <category>math.GT</category>
      <category>q-bio.QM</category>
      <category>stat.AP</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>J V Ramana Reddy (Advanced Institute for Materials Research, Tohoku University, 2-1-1 Katahira, Sendai, Miyagi, Japan), Toshitaka Watanabe (Medical Corporation Shimada Clinic Clover Clinic, Osaka, Japan), Taro Hayashi (Department of Cardiovascular Surgery, Akashi Medical Center, Hyogo, Japan), Hiroshi Suito (Advanced Institute for Materials Research, Tohoku University, 2-1-1 Katahira, Sendai, Miyagi, Japan)</dc:creator>
    </item>
    <item>
      <title>Graph-Based Bidirectional Transformer Decision Threshold Adjustment Algorithm for Class-Imbalanced Molecular Data</title>
      <link>https://arxiv.org/abs/2406.06479</link>
      <description>arXiv:2406.06479v1 Announce Type: cross 
Abstract: Data sets with imbalanced class sizes, often where one class size is much smaller than that of others, occur extremely often in various applications, including those with biological foundations, such as drug discovery and disease diagnosis. Thus, it is extremely important to be able to identify data elements of classes of various sizes, as a failure to detect can result in heavy costs. However, many data classification algorithms do not perform well on imbalanced data sets as they often fail to detect elements belonging to underrepresented classes. In this paper, we propose the BTDT-MBO algorithm, incorporating Merriman-Bence-Osher (MBO) techniques and a bidirectional transformer, as well as distance correlation and decision threshold adjustments, for data classification problems on highly imbalanced molecular data sets, where the sizes of the classes vary greatly. The proposed method not only integrates adjustments in the classification threshold for the MBO algorithm in order to help deal with the class imbalance, but also uses a bidirectional transformer model based on an attention mechanism for self-supervised learning. Additionally, the method implements distance correlation as a weight function for the similarity graph-based framework on which the adjusted MBO algorithm operates. The proposed model is validated using six molecular data sets, and we also provide a thorough comparison to other competing algorithms. The computational experiments show that the proposed method performs better than competing techniques even when the class imbalance ratio is very high.</description>
      <guid isPermaLink="false">oai:arXiv.org:2406.06479v1</guid>
      <category>cs.LG</category>
      <category>q-bio.QM</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Nicole Hayes, Ekaterina Merkurjev, Guo-Wei Wei</dc:creator>
    </item>
    <item>
      <title>Improving Antibody Humanness Prediction using Patent Data</title>
      <link>https://arxiv.org/abs/2401.14442</link>
      <description>arXiv:2401.14442v3 Announce Type: replace 
Abstract: We investigate the potential of patent data for improving the antibody humanness prediction using a multi-stage, multi-loss training process. Humanness serves as a proxy for the immunogenic response to antibody therapeutics, one of the major causes of attrition in drug discovery and a challenging obstacle for their use in clinical settings. We pose the initial learning stage as a weakly-supervised contrastive-learning problem, where each antibody sequence is associated with possibly multiple identifiers of function and the objective is to learn an encoder that groups them according to their patented properties. We then freeze a part of the contrastive encoder and continue training it on the patent data using the cross-entropy loss to predict the humanness score of a given antibody sequence. We illustrate the utility of the patent data and our approach by performing inference on three different immunogenicity datasets, unseen during training. Our empirical results demonstrate that the learned model consistently outperforms the alternative baselines and establishes new state-of-the-art on five out of six inference tasks, irrespective of the used metric.</description>
      <guid isPermaLink="false">oai:arXiv.org:2401.14442v3</guid>
      <category>q-bio.QM</category>
      <category>cs.LG</category>
      <category>stat.ML</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Talip Ucar, Aubin Ramon, Dino Oglic, Rebecca Croasdale-Wood, Tom Diethe, Pietro Sormanni</dc:creator>
    </item>
  </channel>
</rss>
