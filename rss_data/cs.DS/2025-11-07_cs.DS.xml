<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>cs.DS updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/cs.DS</link>
    <description>cs.DS updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/cs.DS" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Fri, 07 Nov 2025 05:00:13 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Fri, 07 Nov 2025 00:00:00 -0500</pubDate>
    <skipDays>
      <day>Saturday</day>
      <day>Sunday</day>
    </skipDays>
    <item>
      <title>Attractors Is All You Need: Parity Games In Polynomial Time</title>
      <link>https://arxiv.org/abs/2511.03752</link>
      <description>arXiv:2511.03752v1 Announce Type: new 
Abstract: This paper provides a polynomial-time algorithm for solving parity games that runs in $\mathcal{O}(n^{2}\cdot(n + m))$ time-ending a search that has taken decades. Unlike previous attractor-based algorithms, the presented algorithm only removes regions with a determined winner. The paper introduces a new type of attractor that can guarantee finding the minimal dominion of a parity game. The attractor runs in polynomial time and can peel the graph empty.</description>
      <guid isPermaLink="false">oai:arXiv.org:2511.03752v1</guid>
      <category>cs.DS</category>
      <category>cs.CC</category>
      <category>cs.FL</category>
      <category>cs.GT</category>
      <category>cs.LO</category>
      <pubDate>Fri, 07 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Rick van der Heijden</dc:creator>
    </item>
    <item>
      <title>Multi-Pass Streaming Lower Bounds for Uniformity Testing</title>
      <link>https://arxiv.org/abs/2511.03960</link>
      <description>arXiv:2511.03960v1 Announce Type: new 
Abstract: We prove multi-pass streaming lower bounds for uniformity testing over a domain of size $2m$. The tester receives a stream of $n$ i.i.d. samples and must distinguish (i) the uniform distribution on $[2m]$ from (ii) a Paninski-style planted distribution in which, for each pair $(2i-1,2i)$, the probabilities are biased left or right by $\epsilon/2m$. We show that any $\ell$-pass streaming algorithm using space $s$ and achieving constant advantage must satisfy the tradeoff $sn\ell=\tilde{\Omega}(m/\epsilon^2)$. This extends the one-pass lower bound of Diakonikolas, Gouleakis, Kane, and Rao (2019) to multiple passes.
  Our proof has two components. First, we develop a hybrid argument, inspired by Dinur (2020), that reduces streaming to two-player communication problems. This reduction relies on a new perspective on hardness: we identify the source of hardness as uncertainty in the bias directions, rather than the collision locations. Second, we prove a strong lower bound for a basic two-player communication task, in which Alice and Bob must decide whether two random sign vectors $Y^a,Y^b\in\{\pm 1\}^m$ are independent or identical, yet they cannot observe the signs directly--only noisy local views of each coordinate. Our techniques may be of independent use for other streaming problems with stochastic inputs.</description>
      <guid isPermaLink="false">oai:arXiv.org:2511.03960v1</guid>
      <category>cs.DS</category>
      <category>cs.CC</category>
      <pubDate>Fri, 07 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Qian Li, Xin Lyu</dc:creator>
    </item>
    <item>
      <title>HART: A Hybrid Addressing Scheme for Self-Balancing Binary Search Trees in Phase Change Memory (PCM)</title>
      <link>https://arxiv.org/abs/2511.03994</link>
      <description>arXiv:2511.03994v1 Announce Type: new 
Abstract: As DRAM and other transistor-based memory technologies approach their scalability limits, alternative storage solutions like Phase-Change Memory (PCM) are gaining attention for their scalability, fast access times, and zero leakage power. However, current memory-intensive algorithms, especially those used in big data systems, often overlook PCM's endurance limitations (10^6 to 10^8 writes before degradation) and write asymmetry. Self-balancing binary search trees (BSTs), which are widely used for large-scale data management, were developed without considering PCM's unique properties, leading to potential performance degradation. This paper introduces HART, a novel hybrid addressing scheme for self-balancing BSTs, designed to optimize PCM's characteristics. By combining DFATGray code addressing for deeper nodes with linear addressing for shallower nodes, HART balances reduced bit flips during frequent rotations at deeper levels with computational simplicity at shallow levels. Experimental results on PCM-aware AVL trees demonstrate significant improvements in performance, with a reduction in bit flips leading to enhanced endurance, increased lifetime, and lower write energy and latency. Notably, these benefits are achieved without imposing substantial computational overhead, making HART an efficient solution for big data applications.</description>
      <guid isPermaLink="false">oai:arXiv.org:2511.03994v1</guid>
      <category>cs.DS</category>
      <pubDate>Fri, 07 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <arxiv:DOI>10.1109/ICMI65310.2025.11141175</arxiv:DOI>
      <arxiv:journal_reference>2025 IEEE 4th International Conference on Computing and Machine Intelligence (ICMI), MI, USA, 2025, pp. 1-6</arxiv:journal_reference>
      <dc:creator>Mahek Desai, Apoorva Rumale, Marjan Asadinia</dc:creator>
    </item>
    <item>
      <title>Depth-13 Sorting Networks for 28 Channels</title>
      <link>https://arxiv.org/abs/2511.04107</link>
      <description>arXiv:2511.04107v1 Announce Type: new 
Abstract: We establish new depth upper bounds for sorting networks on 27 and 28 channels, improving the previous best bound of 14 to 13. Our 28-channel network is constructed with reflectional symmetry by combining high-quality prefixes of 16- and 12-channel networks, extending them greedily one comparator at a time, and using a SAT solver to complete the remaining layers.</description>
      <guid isPermaLink="false">oai:arXiv.org:2511.04107v1</guid>
      <category>cs.DS</category>
      <category>cs.DM</category>
      <pubDate>Fri, 07 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Chengu Wang</dc:creator>
    </item>
    <item>
      <title>Counting Patterns in Degenerate Graphs in Constant Space</title>
      <link>https://arxiv.org/abs/2511.04258</link>
      <description>arXiv:2511.04258v1 Announce Type: new 
Abstract: For an arbitrary, fixed graph (pattern graph), we study the algorithmic complexity of counting homomorphisms, subgraph isomorphisms, and induced subgraph isomorphisms from the pattern graph to $n$-vertex, $d$-degenerate graphs as input. Recent work by Bressan (Algorithmica, 2021) has shown that this problem has efficient dynamic programming algorithms using a graph parameter called DAG treewidth. Bressan used DAG treewidth to design a fast algorithm for counting homomorphisms, subgraph isomorphisms, and induced subgraph isomorphisms that use polynomial space. Bera, Gishboliner, Levanzov, Seshadhri, and Shapira (SODA, 2021) provided a characterization of graphs with DAG treewidth one.
  In this paper, we introduce a new graph parameter called DAG treedepth and show that it yields efficient divide and conquer algorithms that use only constant space (in the unit-cost RAM model). Specifically, we show:
  An algorithm for counting subgraphs isomorphic to sparse pattern graphs using only constant space.
  We derive an induced minor-based characterization for graphs of DAG treedepth up to two.
  For pattern graphs upto nine vertices, the induced subgraphs can be counted in $O(n^3)$ time using constant space.
  An algorithm for counting induced subgraphs that matches the running time given by Bressan but only uses constant space.
  Apart from the DAG treedepth result, we also focus on DAG treewidth. For DAG treewidth, we show that we can count homomorphisms, subgraph isomorphisms, and induced subgraph isomorphisms faster than Bressan's algorithm (2021). We further show that for all pattern graphs up to 11 vertices, we can count induced subgraphs in quadratic time.</description>
      <guid isPermaLink="false">oai:arXiv.org:2511.04258v1</guid>
      <category>cs.DS</category>
      <pubDate>Fri, 07 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Balagopal Komarath, Anant Kumar, Akash Pareek</dc:creator>
    </item>
    <item>
      <title>Estimating Hitting Times Locally At Scale</title>
      <link>https://arxiv.org/abs/2511.04343</link>
      <description>arXiv:2511.04343v1 Announce Type: new 
Abstract: Hitting times provide a fundamental measure of distance in random processes, quantifying the expected number of steps for a random walk starting at node $u$ to reach node $v$. They have broad applications across domains such as network centrality analysis, ranking and recommendation systems, and epidemiology. In this work, we develop local algorithms for estimating hitting times between a pair of vertices $u,v$ without accessing the full graph, overcoming scalability issues of prior global methods. Our first algorithm uses the key insight that hitting time computations can be truncated at the meeting time of two independent random walks from $u$ and $v$. This leads to an efficient estimator analyzed via the Kronecker product graph and Markov Chain Chernoff bounds. We also present an algorithm extending the work of [Peng et al.; KDD 2021], that introduces a novel adaptation of the spectral cutoff technique to account for the asymmetry of hitting times. This adaptation captures the directionality of the underlying random walk and requires non-trivial modifications to ensure accuracy and efficiency. In addition to the algorithmic upper bounds, we also provide tight asymptotic lower bounds. We also reveal a connection between hitting time estimation and distribution testing, and validate our algorithms using experiments on both real and synthetic data.</description>
      <guid isPermaLink="false">oai:arXiv.org:2511.04343v1</guid>
      <category>cs.DS</category>
      <pubDate>Fri, 07 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Themistoklis Haris, Fabian Spaeh, Spyros Dragazis, Charalampos Tsourakakis</dc:creator>
    </item>
    <item>
      <title>A Polynomial-Time Algorithm for the Next-to-Shortest Path Problem on Positively Weighted Directed Graphs</title>
      <link>https://arxiv.org/abs/2511.04345</link>
      <description>arXiv:2511.04345v1 Announce Type: new 
Abstract: Given a graph and a pair of terminals $s$, $t$, the next-to-shortest path problem asks for an $s\!\to \!t$ (simple) path that is shortest among all not shortest $s\!\to \!t$ paths (if one exists). This problem was introduced in 1996, and soon after was shown to be NP-complete for directed graphs with non-negative edge weights, leaving open the case of positive edge weights. Subsequent work investigated this open question, and developed polynomial-time algorithms for the cases of undirected graphs and planar directed graphs. In this work, we resolve this nearly 30-year-old open problem by providing an algorithm for the next-to-shortest path problem on directed graphs with positive edge weights.</description>
      <guid isPermaLink="false">oai:arXiv.org:2511.04345v1</guid>
      <category>cs.DS</category>
      <pubDate>Fri, 07 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Kuowen Chen, Nicole Wein, Yiran Zhang</dc:creator>
    </item>
    <item>
      <title>Free-order secretary for two-sided independence systems</title>
      <link>https://arxiv.org/abs/2511.04390</link>
      <description>arXiv:2511.04390v1 Announce Type: new 
Abstract: The Matroid Secretary Problem is a central question in online optimization, modeling sequential decision-making under combinatorial constraints. We introduce a bipartite graph framework that unifies and extends several known formulations, including the bipartite matching, matroid intersection, and random-order matroid secretary problems. In this model, elements form a bipartite graph between agents and items, and the objective is to select a matching that satisfies feasibility constraints on both sides, given by two independence systems.
  We study the free-order setting, where the algorithm may adaptively choose the next element to reveal. For $k$-matroid intersection, we leverage a core lemma by (Feldman, Svensson and Zenklusen, 2022) to design an $\Omega(1/k^2)$-competitive algorithm, extending known results for single matroids. Building on this, we identify the structural property underlying our approach and introduce $k$-growth systems. We establish a generalized core lemma for $k$-growth systems, showing that a suitably defined set of critical elements retains a $\Omega(1/k^2)$ fraction of the optimal weight. Using this lemma, we extend our $\Omega(1/k^2)$-competitive algorithm to $k$-growth systems for the edge-arrival model.
  We then study the agent-arrival model, which presents unique challenges to our framework. We extend the core lemma to this model and then apply it to obtain an $\Omega(\beta/k^2)$-competitive algorithm for $k$-growth systems, where $\beta$ denotes the competitiveness of a special type of order-oblivious algorithm for the item-side constraint. Finally, we relax the matching assumption and extend our results to the case of multiple item selection, where agents have individual independence systems coupled by a global item-side constraint. We obtain constant-competitive algorithms for fundamental cases such as partition matroids and $k$-matching constraints.</description>
      <guid isPermaLink="false">oai:arXiv.org:2511.04390v1</guid>
      <category>cs.DS</category>
      <pubDate>Fri, 07 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Krist\'of B\'erczi, Vasilis Livanos, Jos\'e A. Soto, Victor Verdugo</dc:creator>
    </item>
    <item>
      <title>Online Algorithms for Repeated Optimal Stopping: Achieving Both Competitive Ratio and Regret Bounds</title>
      <link>https://arxiv.org/abs/2511.04484</link>
      <description>arXiv:2511.04484v1 Announce Type: new 
Abstract: We study the repeated optimal stopping problem, which generalizes the classical optimal stopping problem with an unknown distribution to a setting where the same problem is solved repeatedly over $T$ rounds. In this framework, we aim to design algorithms that guarantee a competitive ratio in each round while also achieving sublinear regret across all rounds.
  Our primary contribution is a general algorithmic framework that achieves these objectives simultaneously for a wide array of repeated optimal stopping problems. The core idea is to dynamically select an algorithm for each round, choosing between two candidates: (1) an empirically optimal algorithm derived from the history of observations, and (2) a sample-based algorithm with a proven competitive ratio guarantee. Based on this approach, we design an algorithm that performs no worse than the baseline sample-based algorithm in every round, while ensuring that the total regret is bounded by $\tilde{O}(\sqrt{T})$.
  We demonstrate the broad applicability of our framework to canonical problems, including the prophet inequality, the secretary problem, and their variants under adversarial, random, and i.i.d. input models. For example, for the repeated prophet inequality problem, our method achieves a $1/2$-competitive ratio from the second round on and an $\tilde{O}(\sqrt{T})$ regret. Furthermore, we establish a regret lower bound of $\Omega(\sqrt{T})$ even in the i.i.d. model, confirming that our algorithm's performance is almost optimal with respect to the number of rounds.</description>
      <guid isPermaLink="false">oai:arXiv.org:2511.04484v1</guid>
      <category>cs.DS</category>
      <category>cs.LG</category>
      <pubDate>Fri, 07 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Tsubasa Harada, Yasushi Kawase, Hanna Sumita</dc:creator>
    </item>
    <item>
      <title>A Characterization of List Language Identification in the Limit</title>
      <link>https://arxiv.org/abs/2511.04103</link>
      <description>arXiv:2511.04103v1 Announce Type: cross 
Abstract: We study the problem of language identification in the limit, where given a sequence of examples from a target language, the goal of the learner is to output a sequence of guesses for the target language such that all the guesses beyond some finite time are correct. Classical results of Gold showed that language identification in the limit is impossible for essentially any interesting collection of languages. Later, Angluin gave a precise characterization of language collections for which this task is possible. Motivated by recent positive results for the related problem of language generation, we revisit the classic language identification problem in the setting where the learner is given the additional power of producing a list of $k$ guesses at each time step. The goal is to ensure that beyond some finite time, one of the guesses is correct at each time step.
  We give an exact characterization of collections of languages that can be $k$-list identified in the limit, based on a recursive version of Angluin's characterization (for language identification with a list of size $1$). This further leads to a conceptually appealing characterization: A language collection can be $k$-list identified in the limit if and only if the collection can be decomposed into $k$ collections of languages, each of which can be identified in the limit (with a list of size $1$). We also use our characterization to establish rates for list identification in the statistical setting where the input is drawn as an i.i.d. stream from a distribution supported on some language in the collection. Our results show that if a collection is $k$-list identifiable in the limit, then the collection can be $k$-list identified at an exponential rate, and this is best possible. On the other hand, if a collection is not $k$-list identifiable in the limit, then it cannot be $k$-list identified at any rate that goes to zero.</description>
      <guid isPermaLink="false">oai:arXiv.org:2511.04103v1</guid>
      <category>cs.CL</category>
      <category>cs.AI</category>
      <category>cs.DS</category>
      <category>cs.LG</category>
      <pubDate>Fri, 07 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Moses Charikar, Chirag Pabbaraju, Ambuj Tewari</dc:creator>
    </item>
    <item>
      <title>GPU-Based Floating-point Adaptive Lossless Compression</title>
      <link>https://arxiv.org/abs/2511.04140</link>
      <description>arXiv:2511.04140v1 Announce Type: cross 
Abstract: Domains such as IoT (Internet of Things) and HPC (High Performance Computing) generate a torrential influx of floating-point time-series data. Compressing these data while preserving their absolute fidelity is critical, and leveraging the massive parallelism of modern GPUs offers a path to unprecedented throughput. Nevertheless, designing such a high-performance GPU-based lossless compressor faces three key challenges: 1) heterogeneous data movement bottlenecks, 2) precision-preserving conversion complexity, and 3) anomaly-induced sparsity degradation. To address these challenges, this paper proposes Falcon, a GPU-based Floating-point Adaptive Lossless COmpressioN framework. Specifically, Falcon first introduces a lightweight asynchronous pipeline, which hides the I/O latency during the data transmission between the CPU and GPU. Then, we propose an accurate and fast float-to-integer transformation method with theoretical guarantees, which eliminates the errors caused by floating-point arithmetic. Moreover, we devise an adaptive sparse bit-plane lossless encoding strategy, which reduces the sparsity caused by outliers. Extensive experiments on 12 diverse datasets show that our compression ratio improves by 9.1% over the most advanced CPU-based method, with compression throughput 2.43X higher and decompression throughput 2.4X higher than the fastest GPU-based competitors, respectively.</description>
      <guid isPermaLink="false">oai:arXiv.org:2511.04140v1</guid>
      <category>cs.DB</category>
      <category>cs.DS</category>
      <pubDate>Fri, 07 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Zheng Li (Chongqing University), Weiyan Wang (Chongqing University), Ruiyuan Li (Chongqing University), Chao Chen (Chongqing University), Xianlei Long (Chongqing University), Linjiang Zheng (Chongqing University), Quanqing Xu (OceanBase, Ant Group), Chuanhui Yang (OceanBase, Ant Group)</dc:creator>
    </item>
    <item>
      <title>Boolean function monotonicity testing requires (almost) $n^(1/2)$ queries</title>
      <link>https://arxiv.org/abs/2511.04558</link>
      <description>arXiv:2511.04558v1 Announce Type: cross 
Abstract: We show that for any constant $c&gt;0$, any (two-sided error) adaptive algorithm for testing monotonicity of Boolean functions must have query complexity $\Omega(n^{1/2-c})$. This improves the $\tilde\Omega(n^{1/3})$ lower bound of [CWX17] and almost matches the $\tilde{O}(\sqrt{n})$ upper bound of [KMS18].</description>
      <guid isPermaLink="false">oai:arXiv.org:2511.04558v1</guid>
      <category>cs.CC</category>
      <category>cs.DM</category>
      <category>cs.DS</category>
      <pubDate>Fri, 07 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Mark Chen, Xi Chen, Hao Cui, William Pires, Jonah Stockwell</dc:creator>
    </item>
    <item>
      <title>Approximations for Fault-Tolerant Total and Partial Positive Influence Domination</title>
      <link>https://arxiv.org/abs/2506.12828</link>
      <description>arXiv:2506.12828v2 Announce Type: replace 
Abstract: In $\textit{total domination}$, given a graph $G=(V,E)$, we seek a minimum-size set of nodes $S\subseteq V$, such that every node in $V$ has at least one neighbor in $S$. We define a $\textit{fault-tolerant}$ version of total domination, where we require any node in $V \setminus S$ to have at least $m$ neighbors in $S$. Let $\Delta$ denote the maximum degree in $G$. We prove a first $1 + \ln(\Delta + m - 1)$ approximation for fault-tolerant total domination. We also consider fault-tolerant variants of the weighted $\textit{partial positive influence dominating set}$ problem, where we seek a minimum-size set of nodes $S\subseteq V$, such that every node in $V$ is either a member of $S$ or the sum of weights of its incident edges leading to nodes in $S$ is at least half of the sum of weights over all its incident edges. We prove the first logarithmic approximations for the simple, total, and connected variants of this problem. To prove the result for the connected case, we extend the general approximation framework for non-submodular functions from integer-valued to fractional-valued functions, which we believe is of independent interest.</description>
      <guid isPermaLink="false">oai:arXiv.org:2506.12828v2</guid>
      <category>cs.DS</category>
      <pubDate>Fri, 07 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Ioannis Lamprou, Ioannis Sigalas, Ioannis Vaxevanakis, Vassilis Zissimopoulos</dc:creator>
    </item>
    <item>
      <title>On zeros and algorithms for disordered systems: mean-field spin glasses</title>
      <link>https://arxiv.org/abs/2507.15616</link>
      <description>arXiv:2507.15616v2 Announce Type: replace 
Abstract: Spin glasses are fundamental probability distributions at the core of statistical physics, the theory of average-case computational complexity, and modern high-dimensional statistical inference. In the mean-field setting, we design deterministic quasipolynomial-time algorithms for estimating the partition function to arbitrarily high accuracy for all inverse temperatures in the second moment regime. In particular, for the Sherrington--Kirkpatrick model, our algorithms succeed for the entire replica-symmetric phase. To achieve this, we study the locations of the zeros of the partition function. Notably, our methods are conceptually simple, and apply equally well to the spherical case and the case of Ising spins.</description>
      <guid isPermaLink="false">oai:arXiv.org:2507.15616v2</guid>
      <category>cs.DS</category>
      <category>cond-mat.dis-nn</category>
      <category>cs.DM</category>
      <category>math-ph</category>
      <category>math.MP</category>
      <category>math.PR</category>
      <pubDate>Fri, 07 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Ferenc Bencs, Brice Huang, Daniel Z. Lee, Kuikui Liu, Guus Regts</dc:creator>
    </item>
    <item>
      <title>A Levelset Algorithm for 3D-Tarski</title>
      <link>https://arxiv.org/abs/2510.14777</link>
      <description>arXiv:2510.14777v2 Announce Type: replace 
Abstract: We present a simple new algorithm for finding a Tarski fixed point of a monotone function $F : [N]^3 \rightarrow [N]^3$. Our algorithm runs in $O(\log^2 N)$ time and makes $O(\log^2 N)$ queries to $F$, matching the $\Omega(\log^2 N)$ query lower bound due to Etessami et al. as well as the existing state-of-the-art algorithm due to Fearnley et al.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.14777v2</guid>
      <category>cs.DS</category>
      <pubDate>Fri, 07 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Sebastian Haslebacher, Jonas Lill</dc:creator>
    </item>
    <item>
      <title>A Branch-and-Bound Approach for Maximum Low-Diameter Dense Subgraph Problems</title>
      <link>https://arxiv.org/abs/2511.03157</link>
      <description>arXiv:2511.03157v2 Announce Type: replace 
Abstract: A graph with $n$ vertices is an $f(\cdot)$-dense graph if it has at least $f(n)$ edges, $f(\cdot)$ being a well-defined function. The notion $f(\cdot)$-dense graph encompasses various clique models like $\gamma$-quasi cliques, $k$-defective cliques, and dense cliques, arising in cohesive subgraph extraction applications. However, the $f(\cdot)$-dense graph may be disconnected or weakly connected. To conquer this, we study the problem of finding the largest $f(\cdot)$-dense subgraph with a diameter of at most two in the paper. Specifically, we present a decomposition-based branch-and-bound algorithm to optimally solve this problem. The key feature of the algorithm is a decomposition framework that breaks the graph into $n$ smaller subgraphs, allowing independent searches in each subgraph. We also introduce decomposition strategies including degeneracy and two-hop degeneracy orderings, alongside a branch-and-bound algorithm with a novel sorting-based upper bound to solve each subproblem. Worst-case complexity for each component is provided. Empirical results on 139 real-world graphs under two $f(\cdot)$ functions show our algorithm outperforms the MIP solver and pure branch-and-bound, solving nearly twice as many instances optimally within one hour.</description>
      <guid isPermaLink="false">oai:arXiv.org:2511.03157v2</guid>
      <category>cs.DS</category>
      <pubDate>Fri, 07 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Yi Zhou, Chunyu Luo, Zhengren Wang, Zhang-Hua Fu</dc:creator>
    </item>
    <item>
      <title>Local Fragments, Global Gains: Subgraph Counting using Graph Neural Networks</title>
      <link>https://arxiv.org/abs/2305.19659</link>
      <description>arXiv:2305.19659v4 Announce Type: replace-cross 
Abstract: Subgraph counting is a fundamental task for analyzing structural patterns in graph-structured data, with important applications in domains such as computational biology and social network analysis, where recurring motifs reveal functional and organizational properties. In this paper, we propose localized versions of the Weisfeiler-Leman (WL) algorithms to improve both expressivity and computational efficiency for this task. We introduce Local $k$-WL, which we prove to be more expressive than $k$-WL and at most as expressive as $(k+1)$-WL, and provide a characterization of patterns whose subgraph and induced subgraph counts are invariant under Local $k$-WL equivalence. To enhance scalability, we present two variants -- Layer $k$-WL and Recursive $k$-WL -- that achieve greater time and space efficiency compared to applying $k$-WL on the entire graph. Additionally, we propose a novel fragmentation technique that decomposes complex subgraphs into simpler subpatterns, enabling the exact count of all induced subgraphs of size at most $4$ using only $1$-WL, with extensions possible for larger patterns when $k&gt;1$. Building on these ideas, we develop a three-stage differentiable learning framework that combines subpattern counts to compute counts of more complex motifs, bridging combinatorial algorithm design with machine learning approaches. We also compare the expressive power of Local $k$-WL with existing GNN hierarchies and demonstrate that, under bounded time complexity, our methods are more expressive than prior approaches.</description>
      <guid isPermaLink="false">oai:arXiv.org:2305.19659v4</guid>
      <category>cs.LG</category>
      <category>cs.DS</category>
      <pubDate>Fri, 07 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Shubhajit Roy, Shrutimoy Das, Binita Maity, Anant Kumar, Anirban Dasgupta</dc:creator>
    </item>
    <item>
      <title>QCircuitBench: A Large-Scale Dataset for Benchmarking Quantum Algorithm Design</title>
      <link>https://arxiv.org/abs/2410.07961</link>
      <description>arXiv:2410.07961v2 Announce Type: replace-cross 
Abstract: Quantum computing is an emerging field recognized for the significant speedup it offers over classical computing through quantum algorithms. However, designing and implementing quantum algorithms pose challenges due to the complex nature of quantum mechanics and the necessity for precise control over quantum states. Despite the significant advancements in AI, there has been a lack of datasets specifically tailored for this purpose. In this work, we introduce QCircuitBench, the first benchmark dataset designed to evaluate AI's capability in designing and implementing quantum algorithms using quantum programming languages. Unlike using AI for writing traditional codes, this task is fundamentally more complicated due to highly flexible design space. Our key contributions include: 1. A general framework which formulates the key features of quantum algorithm design for Large Language Models. 2. Implementations for quantum algorithms from basic primitives to advanced applications, spanning 3 task suites, 25 algorithms, and 120,290 data points. 3. Automatic validation and verification functions, allowing for iterative evaluation and interactive reasoning without human inspection. 4. Promising potential as a training dataset through preliminary fine-tuning results. We observed several interesting experimental phenomena: LLMs tend to exhibit consistent error patterns, and fine-tuning does not always outperform few-shot learning. In all, QCircuitBench is a comprehensive benchmark for LLM-driven quantum algorithm design, and it reveals limitations of LLMs in this domain.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.07961v2</guid>
      <category>quant-ph</category>
      <category>cs.DS</category>
      <category>cs.LG</category>
      <pubDate>Fri, 07 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Rui Yang, Ziruo Wang, Yuntian Gu, Tianyi Chen, Yitao Liang, Tongyang Li</dc:creator>
    </item>
  </channel>
</rss>
