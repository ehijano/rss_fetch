<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>cs.ET updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/cs.ET</link>
    <description>cs.ET updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/cs.ET" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Mon, 10 Feb 2025 05:00:45 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Mon, 10 Feb 2025 00:00:00 -0500</pubDate>
    <skipDays>
      <day>Saturday</day>
      <day>Sunday</day>
    </skipDays>
    <item>
      <title>All-in-One Analog AI Accelerator: On-Chip Training and Inference with Conductive-Metal-Oxide/HfOx ReRAM Devices</title>
      <link>https://arxiv.org/abs/2502.04524</link>
      <description>arXiv:2502.04524v1 Announce Type: new 
Abstract: Analog in-memory computing is an emerging paradigm designed to efficiently accelerate deep neural network workloads. Recent advancements have demonstrated significant improvements in throughput and efficiency, focusing independently on either inference or training acceleration. However, a unified analog in-memory technology platform-capable of performing on-chip training, retaining the weights, and sustaining long-term inference acceleration-has yet to be reported. In this work, an all-in-one analog AI accelerator is presented and benchmarked, combining these capabilities to enable autonomous, energy-efficient, and continuously adaptable AI systems. The platform leverages an array of filamentary conductive-metal-oxide (CMO)/HfOx redox-based resistive switching memory cells (ReRAM) in one-transistor one-ReRAM (1T1R) configuration, integrated into the back-end-of-line (BEOL) of a 130 nm technology node. The array characterization demonstrates reliable and optimized resistive switching with voltage amplitudes of less than 1.5 V, enabling compatibility with advanced technology nodes. The multi-bit capability of over 32 stable states (5 bits) and record-low programming noise down to 10 nS enable an almost ideal weight transfer process, more than an order of magnitude better than other memristive technologies. The array's inference performance is validated through realistic matrix-vector multiplication simulations on a 64x64 array, achieving a record-low root-mean-square error ranging from 0.06 at 1 second to 0.2 at 10 years after programming, compared to the ideal floating-point case. The array is then measured under the same conditions as those used for on-chip training. Training accuracy closely matching the software equivalent is achieved across different datasets, with high-fidelity modelling of the device response based on experimental-only data.</description>
      <guid isPermaLink="false">oai:arXiv.org:2502.04524v1</guid>
      <category>cs.ET</category>
      <category>cs.AR</category>
      <pubDate>Mon, 10 Feb 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Donato Francesco Falcone, Victoria Clerico, Wooseok Choi, Tommaso Stecconi, Folkert Horst, Laura Begon-Lours, Matteo Galetta, Antonio La Porta, Nikhil Garg, Fabien Alibart, Bert Jan Offrein, Valeria Bragaglia</dc:creator>
    </item>
    <item>
      <title>Microdroplet-Based Communications with Frequency Shift Keying Modulation</title>
      <link>https://arxiv.org/abs/2502.04527</link>
      <description>arXiv:2502.04527v1 Announce Type: new 
Abstract: Droplet-based communications has been investigated as a more robust alternative to diffusion-based molecular communications (MC), yet most existing demonstrations employ large "plug-like" droplets or simple T-junction designs for droplet generation, restricting modulation strategies and achievable data rates. Here, we report a microfluidic communication system that encodes information via the generation rate of sub-100 $\mu$m water-in-oil microdroplets using a microfabricated flow focusing architecture. By precisely tuning the flow rate of the dispersed-phase (water) via a pressure-regulated flow controller, we implement frequency shift keying modulation with four symbols (4-FSK). A high-speed optical detection and video processing setup serves as the receiver, tracking system response in the microfluidic channel across different symbol durations (20 s and 12 s) and quantifying error performance. Despite the miniaturized device and channel architecture, our experiments demonstrate programmable and reliable data transmission with minimal symbol errors. Beyond water-in-oil systems, the same encoding principles can be extended to other compartmentalized carriers (e.g., giant unilamellar vesicles, polymersomes) that can also be synthesized via flow focusing techniques, paving the way for biocompatible, robust, and high-capacity communication in intrabody networks and the emerging Internet of Bio-Nano Things.</description>
      <guid isPermaLink="false">oai:arXiv.org:2502.04527v1</guid>
      <category>cs.ET</category>
      <pubDate>Mon, 10 Feb 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Eren Akyol, Aysa Azmoudeh, Iman Mokari Bolhassan, Pelin Kubra Isgor, Murat Kuscu</dc:creator>
    </item>
    <item>
      <title>WaferLLM: A Wafer-Scale LLM Inference System</title>
      <link>https://arxiv.org/abs/2502.04563</link>
      <description>arXiv:2502.04563v1 Announce Type: cross 
Abstract: Emerging AI accelerators increasingly adopt wafer-scale manufacturing technologies, integrating hundreds of thousands of AI cores in a mesh-based architecture with large distributed on-chip memory (tens of GB in total) and ultra-high on-chip memory bandwidth (tens of PB/s). However, current LLM inference systems, optimized for shared memory architectures like GPUs, fail to fully exploit these accelerators. We introduce WaferLLM, the first wafer-scale LLM inference system. WaferLLM is guided by a novel PLMR device model that captures the unique hardware characteristics of wafer-scale architectures. Leveraging this model, WaferLLM pioneers wafer-scale LLM parallelism, optimizing the utilization of hundreds of thousands of on-chip cores. It also introduces MeshGEMM and MeshGEMV, the first GEMM and GEMV implementations designed to scale effectively on wafer-scale accelerators. Evaluations show that WaferLLM achieves 200$\times$ better wafer-scale accelerator utilization than state-of-the-art systems. On a commodity wafer-scale accelerator, WaferLLM delivers 606$\times$ faster and 22$\times$ more energy-efficient GEMV compared to an advanced GPU. For LLMs, WaferLLM enables 39$\times$ faster decoding with 1.7$\times$ better energy efficiency. We anticipate these numbers will grow significantly as wafer-scale AI models, software, and hardware continue to mature.</description>
      <guid isPermaLink="false">oai:arXiv.org:2502.04563v1</guid>
      <category>cs.LG</category>
      <category>cs.AI</category>
      <category>cs.AR</category>
      <category>cs.DC</category>
      <category>cs.ET</category>
      <pubDate>Mon, 10 Feb 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Congjie He, Yeqi Huang, Pei Mu, Ziming Miao, Jilong Xue, Lingxiao Ma, Fan Yang, Luo Mai</dc:creator>
    </item>
    <item>
      <title>Bridging the Gap in XAI-Why Reliable Metrics Matter for Explainability and Compliance</title>
      <link>https://arxiv.org/abs/2502.04695</link>
      <description>arXiv:2502.04695v1 Announce Type: cross 
Abstract: This position paper emphasizes the critical gap in the evaluation of Explainable AI (XAI) due to the lack of standardized and reliable metrics, which diminishes its practical value, trustworthiness, and ability to meet regulatory requirements. Current evaluation methods are often fragmented, subjective, and biased, making them prone to manipulation and complicating the assessment of complex models. A central issue is the absence of a ground truth for explanations, complicating comparisons across various XAI approaches. To address these challenges, we advocate for widespread research into developing robust, context-sensitive evaluation metrics. These metrics should be resistant to manipulation, relevant to each use case, and based on human judgment and real-world applicability. We also recommend creating domain-specific evaluation benchmarks that align with the user and regulatory needs of sectors such as healthcare and finance. By encouraging collaboration among academia, industry, and regulators, we can create standards that balance flexibility and consistency, ensuring XAI explanations are meaningful, trustworthy, and compliant with evolving regulations.</description>
      <guid isPermaLink="false">oai:arXiv.org:2502.04695v1</guid>
      <category>cs.AI</category>
      <category>cs.CE</category>
      <category>cs.ET</category>
      <category>cs.LG</category>
      <pubDate>Mon, 10 Feb 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Pratinav Seth, Vinay Kumar Sankarapu</dc:creator>
    </item>
    <item>
      <title>Differential Privacy of Quantum and Quantum-Inspired-Classical Recommendation Algorithms</title>
      <link>https://arxiv.org/abs/2502.04758</link>
      <description>arXiv:2502.04758v1 Announce Type: cross 
Abstract: We analyze the DP (differential privacy) properties of the quantum recommendation algorithm and the quantum-inspired-classical recommendation algorithm. We discover that the quantum recommendation algorithm is a privacy curating mechanism on its own, requiring no external noise, which is different from traditional differential privacy mechanisms. In our analysis, a novel perturbation method tailored for SVD (singular value decomposition) and low-rank matrix approximation problems is introduced. Using the perturbation method and random matrix theory, we are able to derive that both the quantum and quantum-inspired-classical algorithms are $\big(\tilde{\mathcal{O}}\big(\frac 1n\big),\,\, \tilde{\mathcal{O}}\big(\frac{1}{\min\{m,n\}}\big)\big)$-DP under some reasonable restrictions, where $m$ and $n$ are numbers of users and products in the input preference database respectively. Nevertheless, a comparison shows that the quantum algorithm has better privacy preserving potential than the classical one.</description>
      <guid isPermaLink="false">oai:arXiv.org:2502.04758v1</guid>
      <category>quant-ph</category>
      <category>cs.CR</category>
      <category>cs.ET</category>
      <category>cs.LG</category>
      <pubDate>Mon, 10 Feb 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <dc:creator>Chenjian Li, Mingsheng Ying</dc:creator>
    </item>
    <item>
      <title>Spin-NeuroMem: A Low-Power Neuromorphic Associative Memory Design Based on Spintronic Devices</title>
      <link>https://arxiv.org/abs/2404.02463</link>
      <description>arXiv:2404.02463v2 Announce Type: replace-cross 
Abstract: Biologically-inspired computing models have made significant progress in recent years, but the conventional von Neumann architecture is inefficient for the large-scale matrix operations and massive parallelism required by these models. This paper presents Spin-NeuroMem, a low-power circuit design of Hopfield network for the function of associative memory. Spin-NeuroMem is equipped with energy-efficient spintronic synapses which utilize magnetic tunnel junctions (MTJs) to store weight matrices of multiple associative memories. The proposed synapse design achieves as low as 17.4% power consumption compared to the state-of-the-art synapse designs. Spin-NeuroMem also encompasses a novel voltage converter with a 53.3% reduction in transistor usage for effective Hopfield network computation. In addition, we propose an associative memory simulator for the first time, which achieves a 5Mx speedup with a comparable associative memory effect. By harnessing the potential of spintronic devices, this work paves the way for the development of energy-efficient and scalable neuromorphic computing systems.</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.02463v2</guid>
      <category>cs.AR</category>
      <category>cs.ET</category>
      <category>physics.app-ph</category>
      <pubDate>Mon, 10 Feb 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Siqing Fu, Lizhou Wu, Tiejun Li, Chunyuan Zhang, Jianmin Zhang, Sheng Ma</dc:creator>
    </item>
    <item>
      <title>Tap into Reality: Understanding the Impact of Interactions on Presence and Reaction Time in Mixed Reality</title>
      <link>https://arxiv.org/abs/2411.05272</link>
      <description>arXiv:2411.05272v2 Announce Type: replace-cross 
Abstract: Enhancing presence in mixed reality (MR) relies on precise measurement and quantification. While presence has traditionally been measured through subjective questionnaires, recent research links presence with objective metrics like reaction time. Past studies examined this correlation with varying technical factors (object realism and behavior) and human conditioning, but the impact of interaction remains unclear. To answer this question, we conducted a within-subjects study (N=50) to explore the correlation between presence and reaction time across two interaction scenarios (direct and symbolic) with two tasks (selection and manipulation). We found that presence scores and reaction times are correlated (correlation coefficient of $-0.54$), suggesting that the impact of interaction on reaction time correlates with its effect on presence.</description>
      <guid isPermaLink="false">oai:arXiv.org:2411.05272v2</guid>
      <category>cs.HC</category>
      <category>cs.ET</category>
      <pubDate>Mon, 10 Feb 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Yasra Chandio, Victoria Interrante, Fatima Anwar</dc:creator>
    </item>
    <item>
      <title>Reaction Time as a Proxy for Presence in Mixed Reality with Distraction</title>
      <link>https://arxiv.org/abs/2411.05275</link>
      <description>arXiv:2411.05275v2 Announce Type: replace-cross 
Abstract: Distractions in mixed reality (MR) environments can significantly influence user experience, affecting key factors such as presence, reaction time, cognitive load, and Break in Presence (BIP). Presence measures immersion, reaction time captures user responsiveness, cognitive load reflects mental effort, and BIP represents moments when attention shifts from the virtual to the real world, breaking immersion. However, the effects of distractions on these elements remain insufficiently explored. To address this gap, we have presented a theoretical model to understand how congruent and incongruent distractions affect all these constructs. We conducted a within-subject study (N=54) where participants performed image-sorting tasks under different distraction conditions. Our findings show that incongruent distractions significantly increase cognitive load, slow reaction times, and elevate BIP frequency, with presence mediating these effects.</description>
      <guid isPermaLink="false">oai:arXiv.org:2411.05275v2</guid>
      <category>cs.HC</category>
      <category>cs.ET</category>
      <pubDate>Mon, 10 Feb 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Yasra Chandio, Victoria Interrante, Fatima M. Anwar</dc:creator>
    </item>
    <item>
      <title>Spatio-Temporal Foundation Models: Vision, Challenges, and Opportunities</title>
      <link>https://arxiv.org/abs/2501.09045</link>
      <description>arXiv:2501.09045v2 Announce Type: replace-cross 
Abstract: Foundation models have revolutionized artificial intelligence, setting new benchmarks in performance and enabling transformative capabilities across a wide range of vision and language tasks. However, despite the prevalence of spatio-temporal data in critical domains such as transportation, public health, and environmental monitoring, spatio-temporal foundation models (STFMs) have not yet achieved comparable success. In this paper, we articulate a vision for the future of STFMs, outlining their essential characteristics and the generalization capabilities necessary for broad applicability. We critically assess the current state of research, identifying gaps relative to these ideal traits, and highlight key challenges that impede their progress. Finally, we explore potential opportunities and directions to advance research towards the aim of effective and broadly applicable STFMs.</description>
      <guid isPermaLink="false">oai:arXiv.org:2501.09045v2</guid>
      <category>cs.CV</category>
      <category>cs.AI</category>
      <category>cs.ET</category>
      <pubDate>Mon, 10 Feb 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Adam Goodge, Wee Siong Ng, Bryan Hooi, See Kiong Ng</dc:creator>
    </item>
    <item>
      <title>Conversation Routines: A Prompt Engineering Framework for Task-Oriented Dialog Systems</title>
      <link>https://arxiv.org/abs/2501.11613</link>
      <description>arXiv:2501.11613v4 Announce Type: replace-cross 
Abstract: This study introduces Conversation Routines (CR), a structured prompt engineering framework for developing task-oriented dialog systems using Large Language Models (LLMs). While LLMs demonstrate remarkable natural language understanding capabilities, engineering them to reliably execute complex business workflows remains challenging. The proposed CR framework enables the development of Conversation Agentic Systems (CAS) through natural language specifications, embedding task-oriented logic within LLM prompts. This approach provides a systematic methodology for designing and implementing complex conversational workflows while maintaining behavioral consistency. We demonstrate the framework's effectiveness through two proof-of-concept implementations: a Train Ticket Booking System and an Interactive Troubleshooting Copilot. These case studies validate CR's capability to encode sophisticated behavioral patterns and decision logic while preserving natural conversational flexibility. Results show that CR enables domain experts to design conversational workflows in natural language while leveraging custom functions (tools) developed by software engineers, creating an efficient division of responsibilities where developers focus on core API implementation and domain experts handle conversation design. While the framework shows promise in accessibility and adaptability, we identify key challenges including computational overhead, non-deterministic behavior, and domain-specific logic optimization. Future research directions include CR evaluation methods based on prompt engineering frameworks driven by goal-oriented grading criteria, improving scalability for complex multi-agent interactions, and enhancing system robustness to address the identified limitations across diverse business applications.</description>
      <guid isPermaLink="false">oai:arXiv.org:2501.11613v4</guid>
      <category>cs.CL</category>
      <category>cs.AI</category>
      <category>cs.ET</category>
      <category>cs.HC</category>
      <category>cs.PL</category>
      <pubDate>Mon, 10 Feb 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Giorgio Robino</dc:creator>
    </item>
  </channel>
</rss>
