<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>cs.SI updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/cs.SI</link>
    <description>cs.SI updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/cs.SI" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Tue, 14 Oct 2025 04:01:00 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Tue, 14 Oct 2025 00:00:00 -0400</pubDate>
    <skipDays>
      <day>Sunday</day>
      <day>Saturday</day>
    </skipDays>
    <item>
      <title>On the Relationship between Space-Time Accessibility and Leisure Activity Participation</title>
      <link>https://arxiv.org/abs/2510.10307</link>
      <description>arXiv:2510.10307v1 Announce Type: new 
Abstract: Understanding how accessibility shapes participation in leisure activities is central to promoting inclusive and vibrant urban life. Conventional accessibility measures often focus on potential access from fixed home locations, overlooking the constraints and opportunities embedded in daily routines. In this study, we introduce a space-time accessibility (SPA) metric rooted in the capability approach, capturing feasible leisure opportunities between home and work given a certain time budget, individual transport modes, and urban infrastructure. Using high-resolution GPS data from 2,415 residents in the Paris region, we assess how SPA influences total travel time and leisure participation, measured as the diversity of leisure activity locations. Spatial patterns show that most individuals-especially active transport users-choose destinations aligned with their SPA-defined opportunity sets, underscoring the metric's validity in capturing capability sets. Structural equation modeling reveals that SPA directly fosters leisure diversity but also reduces travel time, which in turn is associated with lower diversity. These findings highlight the value of person-centered, capability-informed accessibility metrics for understanding inequalities in urban mobility and informing transport planning strategies that expand real freedoms to participate in social life across diverse population groups.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.10307v1</guid>
      <category>cs.SI</category>
      <category>cs.CE</category>
      <pubDate>Tue, 14 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-sa/4.0/</dc:rights>
      <dc:creator>Yuan Liao, Rafael H. M. Pereira, Jorge Gil, Silvia De Sojo Caso, Laura Alessandretti</dc:creator>
    </item>
    <item>
      <title>Preserving Core Structures of Social Networks via Information Guided Multi-Step Graph Pruning</title>
      <link>https://arxiv.org/abs/2510.10499</link>
      <description>arXiv:2510.10499v1 Announce Type: new 
Abstract: Social networks often contain dense and overlapping connections that obscure their essential interaction patterns, making analysis and interpretation challenging. Identifying the structural backbone of such networks is crucial for understanding community organization, information flow, and functional relationships. This study introduces a multi-step network pruning framework that leverages principles from information theory to balance structural complexity and task-relevant information. The framework iteratively evaluates and removes edges from the graph based on their contribution to task-relevant mutual information, producing a trajectory of network simplification that preserves most of the inherent semantics. Motivated by gradient boosting, we propose IGPrune, which enables efficient, differentiable optimization to progressively uncover semantically meaningful connections. Extensive experiments on social and biological networks show that IGPrune retains critical structural and functional patterns. Beyond quantitative performance, the pruned networks reveal interpretable backbones, highlighting the method's potential to support scientific discovery and actionable insights in real-world networks.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.10499v1</guid>
      <category>cs.SI</category>
      <category>cs.IT</category>
      <category>math.IT</category>
      <pubDate>Tue, 14 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Yutong Hu, Bingxin Zhou, Jing Wang, Weishu Zhao, Liang Hong</dc:creator>
    </item>
    <item>
      <title>SocioBench: Modeling Human Behavior in Sociological Surveys with Large Language Models</title>
      <link>https://arxiv.org/abs/2510.11131</link>
      <description>arXiv:2510.11131v1 Announce Type: new 
Abstract: Large language models (LLMs) show strong potential for simulating human social behaviors and interactions, yet lack large-scale, systematically constructed benchmarks for evaluating their alignment with real-world social attitudes. To bridge this gap, we introduce SocioBench-a comprehensive benchmark derived from the annually collected, standardized survey data of the International Social Survey Programme (ISSP). The benchmark aggregates over 480,000 real respondent records from more than 30 countries, spanning 10 sociological domains and over 40 demographic attributes. Our experiments indicate that LLMs achieve only 30-40% accuracy when simulating individuals in complex survey scenarios, with statistically significant differences across domains and demographic subgroups. These findings highlight several limitations of current LLMs in survey scenarios, including insufficient individual-level data coverage, inadequate scenario diversity, and missing group-level modeling.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.11131v1</guid>
      <category>cs.SI</category>
      <category>cs.CY</category>
      <pubDate>Tue, 14 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Jia Wang, Ziyu Zhao, Tingjuntao Ni, Zhongyu Wei</dc:creator>
    </item>
    <item>
      <title>Beyond the Crowd: LLM-Augmented Community Notes for Governing Health Misinformation</title>
      <link>https://arxiv.org/abs/2510.11423</link>
      <description>arXiv:2510.11423v1 Announce Type: new 
Abstract: Community Notes, the crowd-sourced misinformation governance system on X (formerly Twitter), enables users to flag misleading posts, attach contextual notes, and vote on their helpfulness. However, our analysis of 30.8K health-related notes reveals significant latency, with a median delay of 17.6 hours before the first note receives a helpfulness status. To improve responsiveness during real-world misinformation surges, we propose CrowdNotes+, a unified framework that leverages large language models (LLMs) to augment Community Notes for faster and more reliable health misinformation governance. CrowdNotes+ integrates two complementary modes: (1) evidence-grounded note augmentation and (2) utility-guided note automation, along with a hierarchical three-step evaluation that progressively assesses relevance, correctness, and helpfulness. We instantiate the framework through HealthNotes, a benchmark of 1.2K helpfulness-annotated health notes paired with a fine-tuned helpfulness judge. Experiments on fifteen LLMs reveal an overlooked loophole in current helpfulness evaluation, where stylistic fluency is mistaken for factual accuracy, and demonstrate that our hierarchical evaluation and LLM-augmented generation jointly enhance factual precision and evidence utility. These results point toward a hybrid human-AI governance model that improves both the rigor and timeliness of crowd-sourced fact-checking.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.11423v1</guid>
      <category>cs.SI</category>
      <category>cs.CL</category>
      <pubDate>Tue, 14 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Jiaying Wu, Zihang Fu, Haonan Wang, Fanxiao Li, Min-Yen Kan</dc:creator>
    </item>
    <item>
      <title>Networks Multiscale Entropy Analysis</title>
      <link>https://arxiv.org/abs/2510.11524</link>
      <description>arXiv:2510.11524v1 Announce Type: new 
Abstract: Understanding the structural complexity and predictability of complex networks is a central challenge in network science. Although recent studies have revealed a relationship between compression-based entropy and link prediction performance, existing methods focus on single-scale representations. This approach often overlooks the rich hierarchical patterns that can exist in real-world networks. In this study, we introduce a multiscale entropy framework that extends previous entropy-based approaches by applying spectral graph reduction. This allows us to quantify how structural entropy evolves as the network is gradually coarsened, capturing complexity across multiple scales. We apply our framework to real-world networks across biological, economic, social, technological, and transportation domains. The results uncover consistent entropy profiles across network families, revealing three structural regimes$\unicode{x2013}$stable, increasing, and hybrid$\unicode{x2013}$that align with domain-specific behaviors. Compared to single-scale models, multiscale entropy significantly improves our ability to determine network predictability. This shows that considering structural information across scales provides a more complete characterization of network complexity. Together, these results position multiscale entropy as a powerful and scalable tool for characterizing, classifying, and assessing the structure of complex networks.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.11524v1</guid>
      <category>cs.SI</category>
      <category>math-ph</category>
      <category>math.MP</category>
      <pubDate>Tue, 14 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Sebasti\'an Brzovic, Crist\'obal Rojas, Andr\'es Abeliuk</dc:creator>
    </item>
    <item>
      <title>Population synthesis with geographic coordinates</title>
      <link>https://arxiv.org/abs/2510.09669</link>
      <description>arXiv:2510.09669v1 Announce Type: cross 
Abstract: It is increasingly important to generate synthetic populations with explicit coordinates rather than coarse geographic areas, yet no established methods exist to achieve this. One reason is that latitude and longitude differ from other continuous variables, exhibiting large empty spaces and highly uneven densities. To address this, we propose a population synthesis algorithm that first maps spatial coordinates into a more regular latent space using Normalizing Flows (NF), and then combines them with other features in a Variational Autoencoder (VAE) to generate synthetic populations. This approach also learns the joint distribution between spatial and non-spatial features, exploiting spatial autocorrelations. We demonstrate the method by generating synthetic homes with the same statistical properties of real homes in 121 datasets, corresponding to diverse geographies. We further propose an evaluation framework that measures both spatial accuracy and practical utility, while ensuring privacy preservation. Our results show that the NF+VAE architecture outperforms popular benchmarks, including copula-based methods and uniform allocation within geographic areas. The ability to generate geolocated synthetic populations at fine spatial resolution opens the door to applications requiring detailed geography, from household responses to floods, to epidemic spread, evacuation planning, and transport modeling.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.09669v1</guid>
      <category>cs.LG</category>
      <category>cs.CY</category>
      <category>cs.SI</category>
      <category>physics.soc-ph</category>
      <category>stat.ML</category>
      <pubDate>Tue, 14 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Jacopo Lenti, Lorenzo Costantini, Ariadna Fosch, Anna Monticelli, David Scala, Marco Pangallo</dc:creator>
    </item>
    <item>
      <title>Combining Blotto Networks and Voter Models to Simulate Voter Behavior in Response to Competitive Election Spending</title>
      <link>https://arxiv.org/abs/2510.09697</link>
      <description>arXiv:2510.09697v1 Announce Type: cross 
Abstract: In the past, the Voter Model has been explicitly used to model the impact of propaganda on a dynamic, interconnected population, and certain factors have been identified that influence the behavior of voters when under outside influence. The Blotto Game has also been explicitly used to study information wars between two opposing parties, whether in regards to a political issue or advertising war. Both the graph theory behind the Voter Model and the game theory aspects of the Blotto Game are relevant to the behavior of voters or consumers when they are under the influence of competing propaganda campaigns, and for this reason both are useful to understand the most effective spending strategy. In this project, we seek to combine the two problems into a Voter-Blotto Game and examine what components of the graph most effect its value in the eyes of the competing players.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.09697v1</guid>
      <category>physics.soc-ph</category>
      <category>cs.SI</category>
      <pubDate>Tue, 14 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Renee Jerome</dc:creator>
    </item>
    <item>
      <title>Observer-Based Source Localization in Tree Infection Networks via Laplace Transforms</title>
      <link>https://arxiv.org/abs/2510.09828</link>
      <description>arXiv:2510.09828v1 Announce Type: cross 
Abstract: We address the problem of localizing the source of infection in an undirected, tree-structured network under a susceptible-infected outbreak model. The infection propagates with independent random time increments (i.e., edge-delays) between neighboring nodes, while only the infection times of a subset of nodes can be observed. We show that a reduced set of observers may be sufficient, in the statistical sense, to localize the source and characterize its identifiability via the joint Laplace transform of the observers' infection times. Using the explicit form of these transforms in terms of the edge-delay probability distributions, we propose scale-invariant least-squares estimators of the source. We evaluate their performance on synthetic trees and on a river network, demonstrating accurate localization under diverse edge-delay models. To conclude, we highlight overlooked technical challenges for observer-based source localization on networks with cycles, where standard spanning-tree reductions may be ill-posed.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.09828v1</guid>
      <category>stat.ME</category>
      <category>cs.SI</category>
      <category>math.PR</category>
      <category>q-bio.PE</category>
      <pubDate>Tue, 14 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Kesler O'Connor, Julia M. Jess, Devlin Costello, Manuel E. Lladser</dc:creator>
    </item>
    <item>
      <title>Preference-driven Knowledge Distillation for Few-shot Node Classification</title>
      <link>https://arxiv.org/abs/2510.10116</link>
      <description>arXiv:2510.10116v1 Announce Type: cross 
Abstract: Graph neural networks (GNNs) can efficiently process text-attributed graphs (TAGs) due to their message-passing mechanisms, but their training heavily relies on the human-annotated labels. Moreover, the complex and diverse local topologies of nodes of real-world TAGs make it challenging for a single mechanism to handle. Large language models (LLMs) perform well in zero-/few-shot learning on TAGs but suffer from a scalability challenge. Therefore, we propose a preference-driven knowledge distillation (PKD) framework to synergize the complementary strengths of LLMs and various GNNs for few-shot node classification. Specifically, we develop a GNN-preference-driven node selector that effectively promotes prediction distillation from LLMs to teacher GNNs. To further tackle nodes' intricate local topologies, we develop a node-preference-driven GNN selector that identifies the most suitable teacher GNN for each node, thereby facilitating tailored knowledge distillation from teacher GNNs to the student GNN. Extensive experiments validate the efficacy of our proposed framework in few-shot node classification on real-world TAGs.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.10116v1</guid>
      <category>cs.LG</category>
      <category>cs.SI</category>
      <pubDate>Tue, 14 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Xing Wei, Chunchun Chen, Rui Fan, Xiaofeng Cao, Sourav Medya, Wei Ye</dc:creator>
    </item>
    <item>
      <title>HeroFilter: Adaptive Spectral Graph Filter for Varying Heterophilic Relations</title>
      <link>https://arxiv.org/abs/2510.10864</link>
      <description>arXiv:2510.10864v1 Announce Type: cross 
Abstract: Graph heterophily, where connected nodes have different labels, has attracted significant interest recently. Most existing works adopt a simplified approach - using low-pass filters for homophilic graphs and high-pass filters for heterophilic graphs. However, we discover that the relationship between graph heterophily and spectral filters is more complex - the optimal filter response varies across frequency components and does not follow a strict monotonic correlation with heterophily degree. This finding challenges conventional fixed filter designs and suggests the need for adaptive filtering to preserve expressiveness in graph embeddings. Formally, natural questions arise: Given a heterophilic graph G, how and to what extent will the varying heterophily degree of G affect the performance of GNNs? How can we design adaptive filters to fit those varying heterophilic connections? Our theoretical analysis reveals that the average frequency response of GNNs and graph heterophily degree do not follow a strict monotonic correlation, necessitating adaptive graph filters to guarantee good generalization performance. Hence, we propose [METHOD NAME], a simple yet powerful GNN, which extracts information across the heterophily spectrum and combines salient representations through adaptive mixing. [METHOD NAME]'s superior performance achieves up to 9.2% accuracy improvement over leading baselines across homophilic and heterophilic graphs.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.10864v1</guid>
      <category>cs.LG</category>
      <category>cs.AI</category>
      <category>cs.SI</category>
      <pubDate>Tue, 14 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Shuaicheng Zhang, Haohui Wang, Junhong Lin, Xiaojie Guo, Yada Zhu, Si Zhang, Dongqi Fu, Dawei Zhou</dc:creator>
    </item>
    <item>
      <title>Sentiment and Social Signals in the Climate Crisis: A Survey on Analyzing Social Media Responses to Extreme Weather Events</title>
      <link>https://arxiv.org/abs/2504.18837</link>
      <description>arXiv:2504.18837v4 Announce Type: replace 
Abstract: Extreme weather events driven by climate change, such as wildfires, floods, and heatwaves, prompt significant public reactions on social media platforms. Analyzing the sentiment expressed in these online discussions can offer valuable insights into public perception, inform policy decisions, and enhance emergency responses. Although sentiment analysis has been widely studied in various fields, its specific application to climate-induced events, particularly in real-time, high-impact situations like the 2025 Los Angeles forest fires, remains underexplored. In this survey, we thoroughly examine the methods, datasets, challenges, and ethical considerations related to sentiment analysis of social media content concerning weather and climate change events. We present a detailed taxonomy of approaches, ranging from lexicon-based and machine learning models to the latest strategies driven by large language models (LLMs). Additionally, we discuss data collection and annotation techniques, including weak supervision and real-time event tracking. Finally, we highlight several open problems, such as misinformation detection, multimodal sentiment extraction, and model alignment with human values. Our goal is to guide researchers and practitioners in effectively understanding sentiment during the climate crisis era.</description>
      <guid isPermaLink="false">oai:arXiv.org:2504.18837v4</guid>
      <category>cs.SI</category>
      <pubDate>Tue, 14 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Pouya Shaeri, Yasaman Mohammadpour, Alimohammad Beigi, Ariane Middel</dc:creator>
    </item>
    <item>
      <title>MoodAngels: A Retrieval-augmented Multi-agent Framework for Psychiatry Diagnosis</title>
      <link>https://arxiv.org/abs/2506.03750</link>
      <description>arXiv:2506.03750v2 Announce Type: replace 
Abstract: The application of AI in psychiatric diagnosis faces significant challenges, including the subjective nature of mental health assessments, symptom overlap across disorders, and privacy constraints limiting data availability. To address these issues, we present MoodAngels, the first specialized multi-agent framework for mood disorder diagnosis. Our approach combines granular-scale analysis of clinical assessments with a structured verification process, enabling more accurate interpretation of complex psychiatric data. Complementing this framework, we introduce MoodSyn, an open-source dataset of 1,173 synthetic psychiatric cases that preserves clinical validity while ensuring patient privacy. Experimental results demonstrate that MoodAngels outperforms conventional methods, with our baseline agent achieving 12.3% higher accuracy than GPT-4o on real-world cases, and our full multi-agent system delivering further improvements. Evaluation in the MoodSyn dataset demonstrates exceptional fidelity, accurately reproducing both the core statistical patterns and complex relationships present in the original data while maintaining strong utility for machine learning applications. Together, these contributions provide both an advanced diagnostic tool and a critical research resource for computational psychiatry, bridging important gaps in AI-assisted mental health assessment.</description>
      <guid isPermaLink="false">oai:arXiv.org:2506.03750v2</guid>
      <category>cs.SI</category>
      <category>cs.AI</category>
      <pubDate>Tue, 14 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <arxiv:journal_reference>NeurIPS 2025</arxiv:journal_reference>
      <dc:creator>Mengxi Xiao, Ben Liu, He Li, Jimin Huang, Qianqian Xie, Xiaofen Zong, Mang Ye, Min Peng</dc:creator>
    </item>
    <item>
      <title>Maximum entropy temporal networks</title>
      <link>https://arxiv.org/abs/2509.02098</link>
      <description>arXiv:2509.02098v2 Announce Type: replace 
Abstract: Temporal networks consist of timestamped directed interactions that may appear continuously in time, yet few studies have directly tackled the continuous-time modeling of networks. Here, we introduce a maximum-entropy approach to temporal networks and with basic assumptions on constraints, the corresponding network ensembles admit a modular and interpretable representation: a set of global time processes and a static maximum-entropy edge, e.g. node pair, probability. This time-edge labels factorization yields closed-form log-likelihoods, degree, clustering and motif expectations, and yields a whole class of effective generative models. We provide maximum-entropy derivation of an inhomogeneous Poisson edge intensity for temporal networks via functional optimization over path entropy, connecting NHPP modeling to maximum-entropy network ensembles. NHPP consistently improve log-likelihood over generic Poisson processes, while the maximum-entropy edge labels recover strength constraints and reproduce expected unique-degree curves. We discuss the limitations of this framework and how it can be integrated with multivariate Hawkes calibration procedures, renewal theory, and neural kernel estimation in graph neural networks.</description>
      <guid isPermaLink="false">oai:arXiv.org:2509.02098v2</guid>
      <category>cs.SI</category>
      <category>physics.data-an</category>
      <pubDate>Tue, 14 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Paolo Barucca</dc:creator>
    </item>
    <item>
      <title>Fake News in Social Networks</title>
      <link>https://arxiv.org/abs/1708.06233</link>
      <description>arXiv:1708.06233v2 Announce Type: replace-cross 
Abstract: We propose multi-agent reinforcement learning as a new method for modeling fake news in social networks. This method allows us to model human behavior in social networks both in unaccustomed populations and in populations that have adapted to the presence of fake news. In particular the latter is challenging for existing methods. We find that a fake-news attack is more effective if it targets highly connected people and people with weaker private information. Attacks are more effective when the disinformation is spread across several agents than when the disinformation is concentrated with more intensity on fewer agents. Furthermore, fake news spread less well in balanced networks than in clustered networks. We test a part of our findings in a human-subject experiment. The experimental evidence provides support for the predictions from the model, suggesting that the model is suitable to analyze the spread of fake news in social networks.</description>
      <guid isPermaLink="false">oai:arXiv.org:1708.06233v2</guid>
      <category>cs.AI</category>
      <category>cs.MA</category>
      <category>cs.SI</category>
      <category>physics.soc-ph</category>
      <category>q-fin.EC</category>
      <pubDate>Tue, 14 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Christoph Aymanns, Jakob Foerster, Co-Pierre Georg, Matthias Weber</dc:creator>
    </item>
    <item>
      <title>Leveraging Twitter Data for Sentiment Analysis of Transit User Feedback: An NLP Framework</title>
      <link>https://arxiv.org/abs/2310.07086</link>
      <description>arXiv:2310.07086v2 Announce Type: replace-cross 
Abstract: Traditional methods of collecting user feedback through transit surveys are often time-consuming, resource intensive, and costly. In this paper, we propose a novel NLP-based framework that harnesses the vast, abundant, and inexpensive data available on social media platforms like Twitter to understand users' perceptions of various service issues. Twitter, being a microblogging platform, hosts a wealth of real-time user-generated content that often includes valuable feedback and opinions on various products, services, and experiences. The proposed framework streamlines the process of gathering and analyzing user feedback without the need for costly and time-consuming user feedback surveys using two techniques. First, it utilizes few-shot learning for tweet classification within predefined categories, allowing effective identification of the issues described in tweets. It then employs a lexicon-based sentiment analysis model to assess the intensity and polarity of the tweet sentiments, distinguishing between positive, negative, and neutral tweets. The effectiveness of the framework was validated on a subset of manually labeled Twitter data and was applied to the NYC subway system as a case study. The framework accurately classifies tweets into predefined categories related to safety, reliability, and maintenance of the subway system and effectively measured sentiment intensities within each category. The general findings were corroborated through a comparison with an agency-run customer survey conducted in the same year. The findings highlight the effectiveness of the proposed framework in gauging user feedback through inexpensive social media data to understand the pain points of the transit system and plan for targeted improvements.</description>
      <guid isPermaLink="false">oai:arXiv.org:2310.07086v2</guid>
      <category>cs.AI</category>
      <category>cs.SI</category>
      <pubDate>Tue, 14 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Adway Das, Abhishek Kumar Prajapati, Pengxiang Zhang, Mukund Srinath, Andisheh Ranjbari</dc:creator>
    </item>
    <item>
      <title>Codiscovering graphical structure and functional relationships within data: A Gaussian Process framework for connecting the dots</title>
      <link>https://arxiv.org/abs/2311.17007</link>
      <description>arXiv:2311.17007v2 Announce Type: replace-cross 
Abstract: Most problems within and beyond the scientific domain can be framed into one of the following three levels of complexity of function approximation. Type 1: Approximate an unknown function given input/output data. Type 2: Consider a collection of variables and functions, some of which are unknown, indexed by the nodes and hyperedges of a hypergraph (a generalized graph where edges can connect more than two vertices). Given partial observations of the variables of the hypergraph (satisfying the functional dependencies imposed by its structure), approximate all the unobserved variables and unknown functions. Type 3: Expanding on Type 2, if the hypergraph structure itself is unknown, use partial observations of the variables of the hypergraph to discover its structure and approximate its unknown functions. These hypergraphs offer a natural platform for organizing, communicating, and processing computational knowledge. While most scientific problems can be framed as the data-driven discovery of unknown functions in a computational hypergraph whose structure is known (Type 2), many require the data-driven discovery of the structure (connectivity) of the hypergraph itself (Type 3). We introduce an interpretable Gaussian Process (GP) framework for such (Type 3) problems that does not require randomization of the data, access to or control over its sampling, or sparsity of the unknown functions in a known or learned basis. Its polynomial complexity, which contrasts sharply with the super-exponential complexity of causal inference methods, is enabled by the nonlinear ANOVA capabilities of GPs used as a sensing mechanism.</description>
      <guid isPermaLink="false">oai:arXiv.org:2311.17007v2</guid>
      <category>cs.LG</category>
      <category>cs.AI</category>
      <category>cs.NA</category>
      <category>cs.SI</category>
      <category>math.NA</category>
      <category>stat.ML</category>
      <pubDate>Tue, 14 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <arxiv:DOI>10.1073/pnas.2403449121</arxiv:DOI>
      <dc:creator>Th\'eo Bourdais, Pau Batlle, Xianjin Yang, Ricardo Baptista, Nicolas Rouquette, Houman Owhadi</dc:creator>
    </item>
    <item>
      <title>Fractional stochastic model of citation dynamics with memory and volatility</title>
      <link>https://arxiv.org/abs/2503.03011</link>
      <description>arXiv:2503.03011v2 Announce Type: replace-cross 
Abstract: Understanding the statistical laws governing citation dynamics remains a fundamental challenge in network theory and the science of science. Citation networks typically exhibit in-degree distributions well approximated by log-normal distributions yet also display power-law behaviour in the high-citation regime -- an apparent contradiction lacking a unified explanation. Here we identify a previously unrecognised phenomenon: the variance of the logarithm of citation counts per unit time follows a power law with respect to time ($t$) since publication, scaling as $t^{H}$, with $H$ constant. This discovery introduces a new challenge while simultaneously offering a crucial clue to resolving this discrepancy. We develop a stochastic model in which latent attention to publications evolves through a memory-driven process with cumulative advantage, modelled as fractional Brownian motion with Hurst parameter $H$ and volatility. We show that antipersistent fluctuations in attention ($H &lt; 1/2$) yield log-normal citation distributions, whereas persistent attention dynamics ($H &gt; 1/2$) favour heavy-tailed power laws, thus resolving the log-normal--power-law contradiction. Numerical simulations confirm both the $t^{H}$ law and the transition between regimes. Empirical analysis of arXiv e-prints indicates that the latent attention process is intrinsically antipersistent ($H \approx 0.13$). By linking memory effects and stochastic fluctuations in attention to broader network dynamics, our findings provide a unifying framework for understanding the evolution of collective attention in science and other attention-driven processes.</description>
      <guid isPermaLink="false">oai:arXiv.org:2503.03011v2</guid>
      <category>physics.soc-ph</category>
      <category>cond-mat.stat-mech</category>
      <category>cs.DL</category>
      <category>cs.SI</category>
      <pubDate>Tue, 14 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <arxiv:DOI>10.1103/l2xd-43n9</arxiv:DOI>
      <arxiv:journal_reference>Phys. Rev. E 112 (2025) 044304</arxiv:journal_reference>
      <dc:creator>Keisuke Okamura</dc:creator>
    </item>
    <item>
      <title>Emerging Activity Temporal Hypergraph: a model for generating realistic time-varying hypergraphs</title>
      <link>https://arxiv.org/abs/2507.01124</link>
      <description>arXiv:2507.01124v2 Announce Type: replace-cross 
Abstract: Time-varying group interactions constitute the building blocks of many complex systems. The framework of temporal hypergraphs makes it possible to represent them by taking into account the higher-order and temporal nature of the interactions. However, the corresponding datasets are often incomplete and/or limited in size and duration, and surrogate time-varying hypergraphs able to reproduce their statistical features constitute interesting substitutions, especially to understand how dynamical processes unfold on group interactions. Here, we present a new temporal hypergraph model, the Emerging Activity Temporal Hypergraph (EATH), which can be fed by parameters measured in a dataset and create synthetic datasets with similar properties. In the model, each node has an independent underlying activity dynamic and the overall system activity emerges from the nodes dynamics, with temporal group interactions resulting from both the activity of the nodes and memory mechanisms. We first show that the EATH model can generate surrogate hypergraphs of several empirical datasets of face-to-face interactions, mimicking temporal and topological properties at the node and hyperedge level. We also showcase the possibility to use the resulting synthetic data in simulations of higher-order contagion dynamics, comparing the outcome of such process on original and surrogate datasets. Finally, we illustrate the flexibility of the model, which can generate synthetic hypergraphs with tunable properties: as an example, we generate "hybrid" temporal hypergraphs, which mix properties of different empirical datasets. Our work opens several perspectives, from the generation of synthetic realistic hypergraphs describing contexts where data collection is difficult to a deeper understanding of dynamical processes on temporal hypergraphs.</description>
      <guid isPermaLink="false">oai:arXiv.org:2507.01124v2</guid>
      <category>physics.soc-ph</category>
      <category>cs.SI</category>
      <category>physics.data-an</category>
      <pubDate>Tue, 14 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Marco Mancastroppa, Giulia Cencetti, Alain Barrat</dc:creator>
    </item>
    <item>
      <title>RedOne: Revealing Domain-specific LLM Post-Training in Social Networking Services</title>
      <link>https://arxiv.org/abs/2507.10605</link>
      <description>arXiv:2507.10605v2 Announce Type: replace-cross 
Abstract: As a primary medium for modern information dissemination, social networking services (SNS) have experienced rapid growth, which has proposed significant challenges for platform content management and interaction quality improvement. Recently, the development of large language models (LLMs) has offered potential solutions but existing studies focus on isolated tasks, which not only encounter diminishing benefit from the data scaling within individual scenarios but also fail to flexibly adapt to diverse real-world context. To address these challenges, we introduce RedOne, a domain-specific LLM designed to break the performance bottleneck of single-task baselines and establish a comprehensive foundation for the SNS. RedOne was developed through a three-stage training strategy consisting of continue pretraining, supervised fine-tuning, and preference optimization, using a large-scale real-world dataset. Through extensive experiments, RedOne maintains strong general capabilities, and achieves an average improvement up to 14.02% across 8 major SNS tasks and 7.56% in SNS bilingual evaluation benchmark, compared with base models. Furthermore, through online testing, RedOne reduced the exposure rate in harmful content detection by 11.23% and improved the click page rate in post-view search by 14.95% compared with single-tasks finetuned baseline models. These results establish RedOne as a robust domain-specific LLM for SNS, demonstrating excellent generalization across various tasks and promising applicability in real-world scenarios.</description>
      <guid isPermaLink="false">oai:arXiv.org:2507.10605v2</guid>
      <category>cs.LG</category>
      <category>cs.AI</category>
      <category>cs.SI</category>
      <pubDate>Tue, 14 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Fei Zhao, Chonggang Lu, Yue Wang, Zheyong Xie, Ziyan Liu, Haofu Qian, JianZhao Huang, Fangcheng Shi, Zijie Meng, Hongcheng Guo, Mingqian He, Xinze Lyu, Yiming Lu, Ziyang Xiang, Zheyu Ye, Chengqiang Lu, Zhe Xu, Yi Wu, Yao Hu, Yan Gao, Jun Fan, Xiaolong Jiang, Weiting Liu, Boyang Wang, Shaosheng Cao</dc:creator>
    </item>
    <item>
      <title>Updating the Complex Systems Keyword Diagram Using Collective Feedback and Latest Literature Data</title>
      <link>https://arxiv.org/abs/2509.11997</link>
      <description>arXiv:2509.11997v2 Announce Type: replace-cross 
Abstract: The complex systems keyword diagram generated by the author in 2010 has been used widely in a variety of educational and outreach purposes, but it definitely needs a major update and reorganization. This short paper reports our recent attempt to update the keyword diagram using information collected from the following multiple sources: (a) collective feedback posted on social media, (b) recent reference books on complex systems and network science, (c) online resources on complex systems, and (d) keyword search hits obtained using OpenAlex, an open-access bibliographic catalogue of scientific publications. The data (a), (b) and (c) were used to incorporate the research community's and other public communities' perceptions of the relevant topics, whereas the data (d) was used to obtain more objective measurements of the keywords' relevance and associations from publications made in complex systems science. Results revealed differences and overlaps between public perception and actual usage of keywords in publications on complex systems. Four topical communities were obtained from the keyword association network, although they were highly intertwined with each other. We hope that the resulting network visualization of complex systems keywords provides a more up-to-date, accurate topic map of the field of complex systems as of today.</description>
      <guid isPermaLink="false">oai:arXiv.org:2509.11997v2</guid>
      <category>cs.DL</category>
      <category>cs.SI</category>
      <category>nlin.AO</category>
      <category>physics.ed-ph</category>
      <pubDate>Tue, 14 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Hiroki Sayama</dc:creator>
    </item>
    <item>
      <title>Physics-Informed High-order Graph Dynamics Identification Learning for Predicting Complex Networks Long-term Dynamics</title>
      <link>https://arxiv.org/abs/2510.09082</link>
      <description>arXiv:2510.09082v2 Announce Type: replace-cross 
Abstract: Learning complex network dynamics is fundamental to understanding, modelling and controlling real-world complex systems. There are two main problems in the task of predicting the dynamic evolution of complex networks: on the one hand, existing methods usually use simple graphs to describe the relationships in complex networks; however, this approach can only capture pairwise relationships, while there may be rich non-pairwise structured relationships in the network. First-order GNNs have difficulty in capturing dynamic non-pairwise relationships. On the other hand, theoretical prediction models lack accuracy and data-driven prediction models lack interpretability. To address the above problems, this paper proposes a higher-order network dynamics identification method for long-term dynamic prediction of complex networks. Firstly, to address the problem that traditional graph machine learning can only deal with pairwise relations, dynamic hypergraph learning is introduced to capture the higher-order non-pairwise relations among complex networks and improve the accuracy of complex network modelling. Then, a dual-driven dynamic prediction module for physical data is proposed. The Koopman operator theory is introduced to transform the nonlinear dynamical differential equations for the dynamic evolution of complex networks into linear systems for solving. Meanwhile, the physical information neural differential equation method is utilised to ensure that the dynamic evolution conforms to the physical laws. The dual-drive dynamic prediction module ensures both accuracy and interpretability of the prediction. Validated on public datasets and self-built industrial chain network datasets, the experimental results show that the method in this paper has good prediction accuracy and long-term prediction performance.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.09082v2</guid>
      <category>cs.AI</category>
      <category>cs.CY</category>
      <category>cs.SI</category>
      <category>physics.soc-ph</category>
      <pubDate>Tue, 14 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Bicheng Wang, Junping Wang, Yibo Xue</dc:creator>
    </item>
    <item>
      <title>The Impact of Sanctions on decentralised Privacy Tools: A Case Study of Tornado Cash</title>
      <link>https://arxiv.org/abs/2510.09443</link>
      <description>arXiv:2510.09443v2 Announce Type: replace-cross 
Abstract: This paper investigates the impact of sanctions on Tornado Cash, a smart contract protocol designed to enhance transaction privacy. Following the U.S. Department of the Treasury's sanctions against Tornado Cash in August 2022, platform activity declined sharply. We document a significant and sustained reduction in transaction volume, user diversity, and overall protocol utilization after the sanctions were imposed. Our analysis draws on transaction data from three major blockchains: Ethereum, BNB Smart Chain, and Polygon. We further examine developments following the partial lifting and eventual removal of sanctions by the U.S. Office of Foreign Assets Control (OFAC) in March 2025. Although activity partially recovered, the rebound remained limited. The Tornado Cash case illustrates how regulatory interventions can affect decentralized protocols, while also highlighting the challenges of fully enforcing such measures in decentralized environments.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.09443v2</guid>
      <category>cs.CR</category>
      <category>cs.SI</category>
      <pubDate>Tue, 14 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Raffaele Cristodaro, Benjamin Kraner, Claudio J. Tessone</dc:creator>
    </item>
  </channel>
</rss>
