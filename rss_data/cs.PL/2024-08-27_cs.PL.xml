<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>cs.PL updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/cs.PL</link>
    <description>cs.PL updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/cs.PL" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Wed, 28 Aug 2024 04:00:12 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Wed, 28 Aug 2024 00:00:00 -0400</pubDate>
    <skipDays>
      <day>Sunday</day>
      <day>Saturday</day>
    </skipDays>
    <item>
      <title>Mica: Automated Differential Testing for OCaml Modules</title>
      <link>https://arxiv.org/abs/2408.14561</link>
      <description>arXiv:2408.14561v1 Announce Type: new 
Abstract: Suppose we are given two OCaml modules implementing the same signature. How do we check that they are observationally equivalent -- that is, that they behave the same on all inputs? One established technique is to use a property-based testing (PBT) tool such as QuickCheck. Currently, however, this can require significant amounts of boilerplate code and ad-hoc test harnesses. To address this issue, we present Mica, an automated tool for testing observational equivalence of OCaml modules. Mica is implemented as a PPX compiler extension, allowing users to supply minimal annotations to a module signature. These annotations guide Mica to automatically derive specialized PBT code that checks observational equivalence. We discuss the design of Mica and demonstrate its efficacy as a testing tool on various modules taken from real-world OCaml libraries.</description>
      <guid isPermaLink="false">oai:arXiv.org:2408.14561v1</guid>
      <category>cs.PL</category>
      <category>cs.SE</category>
      <pubDate>Wed, 28 Aug 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Ernest Ng, Harrison Goldstein, Benjamin C. Pierce</dc:creator>
    </item>
    <item>
      <title>Synthesizing Formal Semantics from Executable Interpreters</title>
      <link>https://arxiv.org/abs/2408.14668</link>
      <description>arXiv:2408.14668v1 Announce Type: new 
Abstract: Program verification and synthesis frameworks that allow one to customize the language in which one is interested typically require the user to provide a formally defined semantics for the language.
  Because writing a formal semantics can be a daunting and error-prone task, this requirement stands in the way of such frameworks being adopted by non-expert users.
  We present an algorithm that can automatically synthesize inductively defined syntax-directed semantics when given (i) a grammar describing the syntax of a language and (ii) an executable (closed-box) interpreter for computing the semantics of programs in the language of the grammar.
  Our algorithm synthesizes the semantics in the form of Constrained-Horn Clauses (CHCs), a natural, extensible, and formal logical framework for specifying inductively defined relations that has recently received widespread adoption in program verification and synthesis.
  The key innovation of our synthesis algorithm is a Counterexample-Guided Synthesis (CEGIS) approach that breaks the hard problem of synthesizing a set of constrained Horn clauses into small, tractable expression-synthesis problems that can be dispatched to existing SyGuS synthesizers.
  Our tool Synantic synthesized inductively-defined formal semantics from 14 interpreters for languages used in program-synthesis applications.
  When synthesizing formal semantics for one of our benchmarks, Synantic unveiled an inconsistency in the semantics computed by the interpreter for a language of regular expressions; fixing the inconsistency resulted in a more efficient semantics and, for some cases, in a 1.2x speedup for a synthesizer solving synthesis problems over such a language.</description>
      <guid isPermaLink="false">oai:arXiv.org:2408.14668v1</guid>
      <category>cs.PL</category>
      <pubDate>Wed, 28 Aug 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-sa/4.0/</dc:rights>
      <dc:creator>Jiangyi Liu, Charlie Murphy, Anvay Grover, Keith J. C. Johnson, Thomas Reps, Loris D'Antoni</dc:creator>
    </item>
    <item>
      <title>Galley: Modern Query Optimization for Sparse Tensor Programs</title>
      <link>https://arxiv.org/abs/2408.14706</link>
      <description>arXiv:2408.14706v1 Announce Type: cross 
Abstract: The tensor programming abstraction has become the key . This framework allows users to write high performance programs for bulk computation via a high-level imperative interface. Recent work has extended this paradigm to sparse tensors (i.e. tensors where most entries are not explicitly represented) with the use of sparse tensor compilers. These systems excel at producing efficient code for computation over sparse tensors, which may be stored in a wide variety of formats. However, they require the user to manually choose the order of operations and the data formats at every step. Unfortunately, these decisions are both highly impactful and complicated, requiring significant effort to manually optimize. In this work, we present Galley, a system for declarative sparse tensor programming. Galley performs cost-based optimization to lower these programs to a logical plan then to a physical plan. It then leverages sparse tensor compilers to execute the physical plan efficiently. We show that Galley achieves high performance on a wide variety of problems including machine learning algorithms, subgraph counting, and iterative graph algorithms.</description>
      <guid isPermaLink="false">oai:arXiv.org:2408.14706v1</guid>
      <category>cs.DB</category>
      <category>cs.PL</category>
      <pubDate>Wed, 28 Aug 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Kyle Deeds, Willow Ahrens, Magda Balazinska, Dan Suciu</dc:creator>
    </item>
    <item>
      <title>Deep R Programming</title>
      <link>https://arxiv.org/abs/2301.01188</link>
      <description>arXiv:2301.01188v4 Announce Type: replace 
Abstract: Deep R Programming is a comprehensive and in-depth introductory course on one of the most popular languages for data science. It equips ambitious students, professionals, and researchers with the knowledge and skills to become independent users of this potent environment so that they can tackle any problem related to data wrangling and analytics, numerical computing, statistics, and machine learning. This textbook is a non-profit project. Its online and PDF versions are freely available at &lt;https://deepr.gagolewski.com/&gt;.</description>
      <guid isPermaLink="false">oai:arXiv.org:2301.01188v4</guid>
      <category>cs.PL</category>
      <category>cs.LG</category>
      <category>stat.AP</category>
      <category>stat.CO</category>
      <pubDate>Wed, 28 Aug 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <arxiv:DOI>10.5281/zenodo.7490464</arxiv:DOI>
      <arxiv:journal_reference>Zenodo, Melbourne, ISBN: 978-0-6455719-2-9 (2024) https://deepr.gagolewski.com/</arxiv:journal_reference>
      <dc:creator>Marek Gagolewski</dc:creator>
    </item>
  </channel>
</rss>
