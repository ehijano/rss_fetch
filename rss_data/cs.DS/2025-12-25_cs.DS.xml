<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>cs.DS updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/cs.DS</link>
    <description>cs.DS updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/cs.DS" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Thu, 25 Dec 2025 05:00:10 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Thu, 25 Dec 2025 00:00:00 -0500</pubDate>
    <skipDays>
      <day>Saturday</day>
      <day>Sunday</day>
    </skipDays>
    <item>
      <title>In-Place BWT and Lyndon Array Construction in Constant Space</title>
      <link>https://arxiv.org/abs/2512.20869</link>
      <description>arXiv:2512.20869v1 Announce Type: new 
Abstract: We present an extension of the in-place BWT algorithm of Crochemore et al. [8] that enables the construction of the Lyndon array using O(1) extra space. Our approach incrementally maintains the lexicographic ranks of the suffixes during the right-to-left BWT construction and then derives the Lyndon array through a simple next-smaller-value procedure. Although not intended for practical use due to its quadratic running time, the method is conceptually simple and works for unbounded alphabets.</description>
      <guid isPermaLink="false">oai:arXiv.org:2512.20869v1</guid>
      <category>cs.DS</category>
      <pubDate>Thu, 25 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Felipe A. Louza, Arnaud Lefebvre</dc:creator>
    </item>
    <item>
      <title>Fairness in the k-Server Problem</title>
      <link>https://arxiv.org/abs/2512.20960</link>
      <description>arXiv:2512.20960v1 Announce Type: new 
Abstract: We initiate a formal study of fairness for the $k$-server problem, where the objective is not only to minimize the total movement cost, but also to distribute the cost equitably among servers. We first define a general notion of $(\alpha,\beta)$-fairness, where, for parameters $\alpha \ge 1$ and $\beta \ge 0$, no server incurs more than an $\alpha/k$-fraction of the total cost plus an additive term $\beta$. We then show that fairness can be achieved without a loss in competitiveness in both the offline and online settings. In the offline setting, we give a deterministic algorithm that, for any $\varepsilon &gt; 0$, transforms any optimal solution into an $(\alpha,\beta)$-fair solution for $\alpha = 1 + \varepsilon$ and $\beta = O(\mathrm{diam} \cdot \log k / \varepsilon)$, while increasing the cost of the solution by just an additive $O(\mathrm{diam} \cdot k \log k / \varepsilon)$ term. Here $\mathrm{diam}$ is the diameter of the underlying metric space. We give a similar result in the online setting, showing that any competitive algorithm can be transformed into a randomized online algorithm that is fair with high probability against an oblivious adversary and still competitive up to a small loss.
  The above results leave open a significant question: can fairness be achieved in the online setting, either with a deterministic algorithm or a randomized algorithm, against a fully adaptive adversary? We make progress towards answering this question, showing that the classic deterministic Double Coverage Algorithm (DCA) is fair on line metrics and on tree metrics when $k = 2$. However, we also show a negative result: DCA fails to be fair for any non-vacuous parameters on general tree metrics.</description>
      <guid isPermaLink="false">oai:arXiv.org:2512.20960v1</guid>
      <category>cs.DS</category>
      <category>cs.DM</category>
      <pubDate>Thu, 25 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Mohammadreza Daneshvaramoli, Helia Karisani, Mohammad Hajiesmaili, Shahin Kamali, Cameron Musco</dc:creator>
    </item>
    <item>
      <title>Time-Bucketed Balance Records: Bounded-Storage Ephemeral Tokens for Resource-Constrained Systems</title>
      <link>https://arxiv.org/abs/2512.20962</link>
      <description>arXiv:2512.20962v1 Announce Type: new 
Abstract: Fungible tokens with time-to-live (TTL) semantics require tracking individual expiration times for each deposited unit. A naive implementation creates a new balance record per deposit, leading to unbounded storage growth and vulnerability to denial-of-service attacks. We present time-bucketed balance records, a data structure that bounds storage to O(k) records per account while guaranteeing that tokens never expire before their configured TTL. Our approach discretizes time into k buckets, coalescing deposits within the same bucket to limit unique expiration timestamps. We prove three key properties: (1) storage is bounded by k+1 records regardless of deposit frequency, (2) actual expiration time is always at least the configured TTL, and (3) adversaries cannot increase a victim's operation cost beyond O(k)[amortized] worst case. We provide a reference implementation in Solidity with measured gas costs demonstrating practical efficiency.</description>
      <guid isPermaLink="false">oai:arXiv.org:2512.20962v1</guid>
      <category>cs.DS</category>
      <pubDate>Thu, 25 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Shaun Scovil, Bhargav Chickmagalur Nanjundappa</dc:creator>
    </item>
    <item>
      <title>Approximation Schemes for Planar Graph Connectivity Problems</title>
      <link>https://arxiv.org/abs/2512.21128</link>
      <description>arXiv:2512.21128v1 Announce Type: new 
Abstract: Finding a smallest subgraph that is k-edge-connected, or augmenting a k-edge-connected graph with a smallest subset of given candidate edges to become (k+1)-edge-connected, are among the most fundamental Network Design problems. They are both APX-hard in general graphs. However, this hardness does not carry over to the planar setting, which is not well understood, except for very small values of k. One main obstacle in using standard decomposition techniques for planar graphs, like Baker's technique and extensions thereof, is that connectivity requirements are global (rather than local) properties that are not captured by existing frameworks.
  We present a novel, and arguably clean, decomposition technique for such classical connectivity problems on planar graphs. This technique immediately implies PTASs for the problems of finding a smallest k-edge-connected or k-vertex-connected spanning subgraph of a planar graph for arbitrary k. By leveraging structural results for minimally k-edge-connected graphs, we further obtain a PTAS for planar k-connectivity augmentation for any constant k. We complement this with an NP-hardness result, showing that our results are essentially optimal.</description>
      <guid isPermaLink="false">oai:arXiv.org:2512.21128v1</guid>
      <category>cs.DS</category>
      <pubDate>Thu, 25 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Meike Neuwohner, Vera Traub, Rico Zenklusen</dc:creator>
    </item>
    <item>
      <title>An O($nlogn$) approximate knapsack algorithm</title>
      <link>https://arxiv.org/abs/2512.21195</link>
      <description>arXiv:2512.21195v1 Announce Type: new 
Abstract: A modified dynamic programming algorithm rapidly and accurately solves large 0/1 knapsack problems. It has computational O($nlogn$), space O($nlogn$) and predictable maximum error. Experimentally it's accuracy increases faster than linearly with the solution size $k$. Problems with $k=10^3$ are solved with an average maximum fractional error of $10^{-4}$ and problems with $k=10^5$ with an average maximum fractional error of $10^{-7}$. The algorithm runs in constant time for all problems with a given $n$. On a common desktop computer the algorithm processes $n=10^3$ problems in $10^{-3}$ seconds and $n=10^6$ problems in 2 seconds.</description>
      <guid isPermaLink="false">oai:arXiv.org:2512.21195v1</guid>
      <category>cs.DS</category>
      <pubDate>Thu, 25 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Nick Dawes</dc:creator>
    </item>
    <item>
      <title>ESCHER: Efficient and Scalable Hypergraph Evolution Representation with Application to Triad Counting</title>
      <link>https://arxiv.org/abs/2512.21009</link>
      <description>arXiv:2512.21009v1 Announce Type: cross 
Abstract: Higher-order interactions beyond pairwise relationships in large complex networks are often modeled as hypergraphs. Analyzing hypergraph properties such as triad counts is essential, as hypergraphs can reveal intricate group interaction patterns that conventional graphs fail to capture. In real-world scenarios, these networks are often large and dynamic, introducing significant computational challenges. Due to the absence of specialized software packages and data structures, the analysis of large dynamic hypergraphs remains largely unexplored. Motivated by this gap, we propose ESCHER, a GPU-centric parallel data structure for Efficient and Scalable Hypergraph Evolution Representation, designed to manage large scale hypergraph dynamics efficiently. We also design a hypergraph triad-count update framework that minimizes redundant computation while fully leveraging the capabilities of ESCHER for dynamic operations. We validate the efficacy of our approach across multiple categories of hypergraph triad counting, including hyperedge-based, incident-vertex-based, and temporal triads. Empirical results on both large real-world and synthetic datasets demonstrate that our proposed method outperforms existing state-of-the-art methods, achieving speedups of up to 104.5x, 473.7x, and 112.5x for hyperedge-based, incident-vertex-based, and temporal triad types, respectively.</description>
      <guid isPermaLink="false">oai:arXiv.org:2512.21009v1</guid>
      <category>cs.DC</category>
      <category>cs.DS</category>
      <pubDate>Thu, 25 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>S. M. Shovan, Arindam Khanda, Sanjukta Bhowmick, Sajal K. Das</dc:creator>
    </item>
    <item>
      <title>An Allele-Centric Pan-Graph-Matrix Representation for Scalable Pangenome Analysis</title>
      <link>https://arxiv.org/abs/2512.21320</link>
      <description>arXiv:2512.21320v1 Announce Type: cross 
Abstract: Population-scale pangenome analysis increasingly requires representations that unify single-nucleotide and structural variation while remaining scalable across large cohorts. Existing formats are typically sequence-centric, path-centric, or sample-centric, and often obscure population structure or fail to exploit carrier sparsity. We introduce the H1 pan-graph-matrix, an allele-centric representation that encodes exact haplotype membership using adaptive per-allele compression. By treating alleles as first-class objects and selecting optimal encodings based on carrier distribution, H1 achieves near-optimal storage across both common and rare variants. We further introduce H2, a path-centric dual representation derived from the same underlying allele-haplotype incidence information that restores explicit haplotype ordering while remaining exactly equivalent in information content. Using real human genome data, we show that this representation yields substantial compression gains, particularly for structural variants, while remaining equivalent in information content to pangenome graphs. H1 provides a unified, population-aware foundation for scalable pangenome analysis and downstream applications such as rare-variant interpretation and drug discovery.</description>
      <guid isPermaLink="false">oai:arXiv.org:2512.21320v1</guid>
      <category>q-bio.GN</category>
      <category>cs.DB</category>
      <category>cs.DS</category>
      <pubDate>Thu, 25 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Roberto Garrone</dc:creator>
    </item>
    <item>
      <title>Algorithmic Universality, Low-Degree Polynomials, and Max-Cut in Sparse Random Graphs</title>
      <link>https://arxiv.org/abs/2412.18014</link>
      <description>arXiv:2412.18014v2 Announce Type: replace 
Abstract: Universality, namely distributional invariance, is a well-known property for many random structures. For example, it is known to hold for a broad range of variational problems with random input. Much less is known about the algorithmic universality of specific methods for solving such variational problems. Namely, whether algorithms tuned to specific variational tasks produce the same asymptotic behavior across different input distributions with matching moments.
  In this paper, we establish algorithmic universality for a class of models, which includes spin glass models and constraint satisfaction problems on sparse graphs, provided that an algorithm can be coded as a low-degree polynomial (LDP). We illustrate this specifically for the case of the Max-Cut problem in sparse Erd\"os-R\'enyi graph $\mathbb{G}(n,d/n)$. We use the fact that the Approximate Message Passing (AMP) algorithm, which is an effective algorithm for finding near-ground states of the Sherrington-Kirkpatrick (SK) model, is well approximated by an LDP. We then establish our main universality result: the performance of the LDP based algorithms exhibiting a certain connectivity property, is the same in the mean-field (SK) and in the random graph $\mathbb{G}(n,d/n)$ setting, up to an appropriate rescaling. The main technical challenge we address in this paper is showing that the output of an LDP algorithm on $\mathbb{G}(n,d/n)$ is truly discrete, namely, that it is close to the set of points in the binary cube. This is achieved by establishing universality of coordinate-wise statistics of the LDP output across disorder ensembles, which implies that proximity to the cube transfers from the Gaussian to the sparse graph setting.</description>
      <guid isPermaLink="false">oai:arXiv.org:2412.18014v2</guid>
      <category>cs.DS</category>
      <category>math.PR</category>
      <pubDate>Thu, 25 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Houssam El Cheairi, David Gamarnik</dc:creator>
    </item>
    <item>
      <title>Optimal Pure Differentially Private Sparse Histograms in Deterministic Linear Time</title>
      <link>https://arxiv.org/abs/2507.17017</link>
      <description>arXiv:2507.17017v2 Announce Type: replace 
Abstract: We present an algorithm that releases a pure differentially private (under the replacement neighboring relation) sparse histogram for $n$ participants over a domain of size $d \gg n$. Our method achieves the optimal $\ell_\infty$-estimation error and runs in strictly $O(n)$ time in the Word-RAM model, improving upon the previous best deterministic-time bound of $\tilde{O}(n^2)$ and resolving the open problem of breaking this quadratic barrier (Balcer and Vadhan, 2019). Moreover, the algorithm admits an efficient circuit implementation, enabling the first near-linear communication and computation cost pure DP histogram MPC protocol with optimal $\ell_\infty$-estimation error. Central to our algorithm is a novel **private item blanket** technique with target-length padding, which hides differences in the supports of neighboring histograms while remaining efficiently implementable.</description>
      <guid isPermaLink="false">oai:arXiv.org:2507.17017v2</guid>
      <category>cs.DS</category>
      <category>cs.CR</category>
      <pubDate>Thu, 25 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-sa/4.0/</dc:rights>
      <dc:creator>Florian Kerschbaum, Steven Lee, Hao Wu</dc:creator>
    </item>
    <item>
      <title>Awesome graph parameters</title>
      <link>https://arxiv.org/abs/2511.05285</link>
      <description>arXiv:2511.05285v2 Announce Type: replace-cross 
Abstract: For a graph $G$, we denote by $\alpha(G)$ the size of a maximum independent set and by $\omega(G)$ the size of a maximum clique in $G$. Our paper lies on the edge of two lines of research, related to $\alpha$ and $\omega$, respectively. One of them studies $\alpha$-variants of graph parameters, such as $\alpha$-treewidth or $\alpha$-degeneracy. The second line deals with graph classes where some parameters are bounded by a function of $\omega(G)$. A famous example of this type is the family of $\chi$-bounded classes, where the chromatic number $\chi(G)$ is bounded by a function of $\omega(G)$.
  A Ramsey-type argument implies that if the $\alpha$-variant of a graph parameter $\rho$ is bounded by a constant in a class $\mathcal{G}$, then $\rho$ is bounded by a function of $\omega$ in $\mathcal{G}$. If the reverse implication also holds, we say that $\rho$ is awesome. Otherwise, we say that $\rho$ is awful. In the present paper, we identify a number of awesome and awful graph parameters, derive some algorithmic applications of awesomeness, and propose a number of open problems related to these notions.</description>
      <guid isPermaLink="false">oai:arXiv.org:2511.05285v2</guid>
      <category>math.CO</category>
      <category>cs.DM</category>
      <category>cs.DS</category>
      <pubDate>Thu, 25 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Kenny Be\v{s}ter \v{S}torgel, Cl\'ement Dallard, Vadim Lozin, Martin Milani\v{c}, Viktor Zamaraev</dc:creator>
    </item>
  </channel>
</rss>
