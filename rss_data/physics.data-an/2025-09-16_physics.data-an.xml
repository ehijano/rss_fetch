<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>physics.data-an updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/physics.data-an</link>
    <description>physics.data-an updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/physics.data-an" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Wed, 17 Sep 2025 01:39:41 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Tue, 16 Sep 2025 00:00:00 -0400</pubDate>
    <skipDays>
      <day>Sunday</day>
      <day>Saturday</day>
    </skipDays>
    <item>
      <title>Calibrating a Finite-strain Phase-field Model of Fracture for Bonded Granular Materials with Uncertainty Quantification</title>
      <link>https://arxiv.org/abs/2509.10484</link>
      <description>arXiv:2509.10484v1 Announce Type: cross 
Abstract: To study the mechanical behavior of mock high explosives, an experimental and simulation program was developed to calibrate, with quantified uncertainty, a material model of the bonded granular material Idoxuridine and nitroplasticized Estane-5703. This paper reports on the efficacy of such a framework as a generalizable methodology for calibrating material models against experimental data with uncertainty quantification. Additionally, this paper studies the effect of two manufacturing temperatures and three initial granular configurations on the unconfined compressive behavior of the resulting bonded granular materials. In each of these cases, the same calibration framework was used; in that, hundreds of high-fidelity direct numerical simulations using a new, GPU-enabled, high-performance finite element method software, Ratel, were run to calibrate a finite-strain phase-field fracture model against experimental data. It was found that manufacturing temperature influenced the elastic response of the mock high explosives, with higher temperatures yielding a stiffer response. By contrast, it was found that the initial configuration of the grains had a negligible impact on the overall behavior of the mock high explosives, though it remains possible that local damage accumulation within the specimens could be altered by the initial configurations. Overall, the calibration framework was successful at creating well-calibrated models, showing its usefulness as an engineering and scientific tool.</description>
      <guid isPermaLink="false">oai:arXiv.org:2509.10484v1</guid>
      <category>physics.comp-ph</category>
      <category>cond-mat.mtrl-sci</category>
      <category>cond-mat.soft</category>
      <category>physics.data-an</category>
      <pubDate>Tue, 16 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Abigail C. Schmid, Erik Jensen, Fabio Di Gioacchino, Pooyan B. Javadzadeh, Nate E. Peterson, C. Gus Becker, Hongbing Lu, Fatemeh Pourahmadian, Amy J. Clarke, Alireza Doostan, Richard A. Regueiro</dc:creator>
    </item>
    <item>
      <title>Exploring Multi-view Symbolic Regression methods in physical sciences</title>
      <link>https://arxiv.org/abs/2509.10500</link>
      <description>arXiv:2509.10500v1 Announce Type: cross 
Abstract: Describing the world behavior through mathematical functions help scientists to achieve a better understanding of the inner mechanisms of different phenomena. Traditionally, this is done by deriving new equations from first principles and careful observations. A modern alternative is to automate part of this process with symbolic regression (SR). The SR algorithms search for a function that adequately fits the observed data while trying to enforce sparsity, in the hopes of generating an interpretable equation. A particularly interesting extension to these algorithms is the Multi-view Symbolic Regression (MvSR). It searches for a parametric function capable of describing multiple datasets generated by the same phenomena, which helps to mitigate the common problems of overfitting and data scarcity. Recently, multiple implementations added support to MvSR with small differences between them. In this paper, we test and compare MvSR as supported in Operon, PySR, phy-SO, and eggp, in different real-world datasets. We show that they all often achieve good accuracy while proposing solutions with only few free parameters. However, we find that certain features enable a more frequent generation of better models. We conclude by providing guidelines for future MvSR developments.</description>
      <guid isPermaLink="false">oai:arXiv.org:2509.10500v1</guid>
      <category>cs.LG</category>
      <category>astro-ph.GA</category>
      <category>astro-ph.IM</category>
      <category>physics.data-an</category>
      <pubDate>Tue, 16 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Etienne Russeil, Fabr\'icio Olivetti de Fran\c{c}a, Konstantin Malanchev, Guillaume Moinard, Maxime Cherrey</dc:creator>
    </item>
    <item>
      <title>Contextuality, Holonomy and Discrete Fiber Bundles in Group-Valued Boltzmann Machines</title>
      <link>https://arxiv.org/abs/2509.10536</link>
      <description>arXiv:2509.10536v1 Announce Type: cross 
Abstract: We propose a geometric extension of restricted Boltzmann machines (RBMs) by allowing weights to take values in abstract groups such as \( \mathrm{GL}_n(\mathbb{R}) \), \( \mathrm{SU}(2) \), or even infinite-dimensional operator groups. This generalization enables the modeling of complex relational structures, including projective transformations, spinor dynamics, and functional symmetries, with direct applications to vision, language, and quantum learning.
  A central contribution of this work is the introduction of a \emph{contextuality index} based on group-valued holonomies computed along cycles in the RBM graph. This index quantifies the global inconsistency or "curvature" induced by local weights, generalizing classical notions of coherence, consistency, and geometric flatness. We establish links with sheaf-theoretic contextuality, gauge theory, and noncommutative geometry, and provide numerical and diagrammatic examples in both finite and infinite dimensions.
  This framework opens novel directions in AI, from curvature-aware learning architectures to topological regularization in uncertain or adversarial environments.</description>
      <guid isPermaLink="false">oai:arXiv.org:2509.10536v1</guid>
      <category>cs.LG</category>
      <category>physics.data-an</category>
      <category>quant-ph</category>
      <pubDate>Tue, 16 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Jean-Pierre Magnot</dc:creator>
    </item>
    <item>
      <title>Enhancing Electromagnetic Calorimeter Signal Reconstruction with Machine Learning-Based Noise Discrimination</title>
      <link>https://arxiv.org/abs/2509.11291</link>
      <description>arXiv:2509.11291v1 Announce Type: cross 
Abstract: Calorimeters operating in high-radiation environments are susceptible to damage, leading to increased noise that can significantly degrade energy resolution. A common way to mitigate noise is to apply a higher energy threshold on the cells, typically set a few standard deviations above the noise level. However, this method risks discarding cells with genuine energy deposits, worsening the energy resolution. In this paper we explore various machine learning (ML) algorithms that can replace a rigid threshold on the reconstructed cell energy and we demonstrate the improvement in calorimetric energy reconstruction and energy resolution that these ML methods can achieve in such challenging conditions.</description>
      <guid isPermaLink="false">oai:arXiv.org:2509.11291v1</guid>
      <category>physics.ins-det</category>
      <category>hep-ex</category>
      <category>physics.data-an</category>
      <pubDate>Tue, 16 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-sa/4.0/</dc:rights>
      <dc:creator>Suman Das Gupta, Shamik Ghosh, Laltu Gazi, Shubham Dutta, Alexander Ledovskoy, Satyaki Bhattacharya, Shilpi Jain</dc:creator>
    </item>
    <item>
      <title>Requirements for Early Quantum Advantage and Quantum Utility in the Capacitated Vehicle Routing Problem</title>
      <link>https://arxiv.org/abs/2509.11469</link>
      <description>arXiv:2509.11469v1 Announce Type: cross 
Abstract: We introduce a transparent, encoding-agnostic framework for determining when the Capacitated Vehicle Routing Problem (CVRP) can achieve early quantum advantage. Our analysis shows this is unlikely on noisy intermediate scale quantum (NISQ) hardware even in best case scenarios that use the most qubit-efficient direct encodings. Closed-form resource counts, combined with recent device benchmarks, yield three decisive go/no-go figures of merit: the quantum feasibility point and the qubit- and gate-feasibility lines, which place any CVRP instance on a single decision diagram. Contrasting a direct QUBO mapping with a space-efficient higher-order (HOBO) encoding reveals a large gap. Applied to early-advantage benchmarks such as Golden-5, our diagram shows that HOBO circuits require only 7,685 qubits, whereas comparable QUBO encodings still exceed 200,000 qubits. In addition to identifying candidate instances for early quantum advantage in CVRP, the framework provides a unifying go/no-go metric that ingests any CVRP encoding together with any hardware profile and highlights when quantum devices could challenge classical heuristics. Quantum advantage in CVRP would likely require innovative problem decomposition techniques.</description>
      <guid isPermaLink="false">oai:arXiv.org:2509.11469v1</guid>
      <category>quant-ph</category>
      <category>cs.CE</category>
      <category>physics.app-ph</category>
      <category>physics.comp-ph</category>
      <category>physics.data-an</category>
      <pubDate>Tue, 16 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Chinonso Onah, Kristel Michielsen</dc:creator>
    </item>
    <item>
      <title>OASIS: A Deep Learning Framework for Universal Spectroscopic Analysis Driven by Novel Loss Functions</title>
      <link>https://arxiv.org/abs/2509.11499</link>
      <description>arXiv:2509.11499v1 Announce Type: cross 
Abstract: The proliferation of spectroscopic data across various scientific and engineering fields necessitates automated processing. We introduce OASIS (Omni-purpose Analysis of Spectra via Intelligent Systems), a machine learning (ML) framework for technique-independent, automated spectral analysis, encompassing denoising, baseline correction, and comprehensive peak parameter (location, intensity, FWHM) retrieval without human intervention. OASIS achieves its versatility through models trained on a strategically designed synthetic dataset incorporating features from numerous spectroscopy techniques. Critically, the development of innovative, task-specific loss functions-such as the vicinity peak response (ViPeR) for peak localization-enabled the creation of compact yet highly accurate models from this dataset, validated with experimental data from Raman, UV-vis, and fluorescence spectroscopy. OASIS demonstrates significant potential for applications including in situ experiments, high-throughput optimization, and online monitoring. This study underscores the optimization of the loss function as a key resource-efficient strategy to develop high-performance ML models.</description>
      <guid isPermaLink="false">oai:arXiv.org:2509.11499v1</guid>
      <category>cs.LG</category>
      <category>physics.data-an</category>
      <pubDate>Tue, 16 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Chris Young, Juejing Liu, Marie L. Mortensen, Yifu Feng, Elizabeth Li, Zheming Wang, Xiaofeng Guo, Kevin M. Rosso, Xin Zhang</dc:creator>
    </item>
    <item>
      <title>Growth Regime Shifts in Empirical Networks: Evidence and Challenges from the Software Heritage and APS Citation Case Studies</title>
      <link>https://arxiv.org/abs/2501.10145</link>
      <description>arXiv:2501.10145v4 Announce Type: replace 
Abstract: We investigate the evolution rules and degree distribution properties of the Software Heritage dataset, a large-scale growing network linking software releases and revisions from open-source communities. The network spans over 40 years and includes about 6 billion nodes and edges. Our analysis relies on natural temporal and topological partitions of nodes and edges.
  A derived temporalized graph reveals a bow-tie-like structure and enables study of edge dynamics -- creation, inheritance, and aging -- together with comparisons to minimal models. In- and out-degree distributions and edge timestamp histograms expose regime shifts linked to changes in developer practices, notably in the average number of edges per new node.
  Without presupposing its validity, we estimate the scaling exponent under the scale-free hypothesis. Results highlight the sensitivity of a widely used estimation method to regime changes and outliers, while showing that partitioning improves regularity and helps disentangle these effects.
  We extend the analysis to the APS citation network, which also exhibits a major regime shift around 1985, though driven by distinct factors. Both cases illustrate how structural and dynamical transitions complicate conclusions about the existence and observability of a scale-free regime. These findings underscore the need for refined tools to study transient growth phases and to enable robust comparisons between empirical growing networks and minimal models.</description>
      <guid isPermaLink="false">oai:arXiv.org:2501.10145v4</guid>
      <category>physics.data-an</category>
      <category>physics.comp-ph</category>
      <category>physics.soc-ph</category>
      <pubDate>Tue, 16 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Guillaume Rousseau</dc:creator>
    </item>
    <item>
      <title>A stochastic approach in physics exercises of mathematics education</title>
      <link>https://arxiv.org/abs/2410.04076</link>
      <description>arXiv:2410.04076v2 Announce Type: replace-cross 
Abstract: We present a method for incorporating a stochastic point of view into physics exercises of mathematics education. The core of our method is the randomization of some inputs, the system model used does not differ from what we would use in the deterministic approach. We consider exercises from the theory of projectile motion and statics. The outputs of stochastic models are random variables, and we usually determine their probability distributions, expected values, variances, and relative standard deviations, and the probabilities of some events related to them are also calculated. Students and teachers familiar with elementary probability theory and mechanics may find these exercises useful for understanding some basic concepts of stochastic mechanics.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.04076v2</guid>
      <category>physics.ed-ph</category>
      <category>math.HO</category>
      <category>physics.data-an</category>
      <pubDate>Tue, 16 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Matyas Barczy, Imre Kocsis, Csaba G\'abor K\'ezi</dc:creator>
    </item>
    <item>
      <title>Dimensionless learning based on information</title>
      <link>https://arxiv.org/abs/2504.03927</link>
      <description>arXiv:2504.03927v2 Announce Type: replace-cross 
Abstract: Dimensional analysis is one of the most fundamental tools for understanding physical systems. However, the construction of dimensionless variables, as guided by the Buckingham-$\pi$ theorem, is not uniquely determined. Here, we introduce IT-$\pi$, a model-free method that combines dimensionless learning with the principles of information theory. Grounded in the irreducible error theorem, IT-$\pi$ identifies dimensionless variables with the highest predictive power by measuring their shared information content. The approach is able to rank variables by predictability, identify distinct physical regimes, uncover self-similar variables, determine the characteristic scales of the problem, and extract its dimensionless parameters. IT-$\pi$ also provides a bound of the minimum predictive error achievable across all possible models, from simple linear regression to advanced deep learning techniques, naturally enabling a definition of model efficiency. We benchmark IT-$\pi$ across different cases and demonstrate that it offers superior performance and capabilities compared to existing tools. The method is also applied to conduct dimensionless learning for supersonic turbulence, aerodynamic drag on both smooth and irregular surfaces, magnetohydrodynamic power generation, and laser-metal interaction.</description>
      <guid isPermaLink="false">oai:arXiv.org:2504.03927v2</guid>
      <category>physics.flu-dyn</category>
      <category>physics.comp-ph</category>
      <category>physics.data-an</category>
      <pubDate>Tue, 16 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Yuan Yuan, Adri\'an Lozano-Dur\'an</dc:creator>
    </item>
    <item>
      <title>Quantifying model prediction sensitivity to model-form uncertainty</title>
      <link>https://arxiv.org/abs/2509.08708</link>
      <description>arXiv:2509.08708v2 Announce Type: replace-cross 
Abstract: Model-form uncertainty (MFU) in assumptions made during physics-based model development is widely considered a significant source of uncertainty; however, there are limited approaches that can quantify MFU in predictions extrapolating beyond available data. As a result, it is challenging to know how important MFU is in practice, especially relative to other sources of uncertainty in a model, making it difficult to prioritize resources and efforts to drive down error in model predictions. To address these challenges, we present a novel method to quantify the importance of uncertainties associated with model assumptions. We combine parameterized modifications to assumptions (called MFU representations) with grouped variance-based sensitivity analysis to measure the importance of assumptions. We demonstrate how, in contrast to existing methods addressing MFU, our approach can be applied without access to calibration data. However, if calibration data is available, we demonstrate how it can be used to inform the MFU representation, and how variance-based sensitivity analysis can be meaningfully applied even in the presence of dependence between parameters (a common byproduct of calibration).</description>
      <guid isPermaLink="false">oai:arXiv.org:2509.08708v2</guid>
      <category>cs.CE</category>
      <category>physics.comp-ph</category>
      <category>physics.data-an</category>
      <category>stat.AP</category>
      <pubDate>Tue, 16 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Teresa Portone, Rebekah D. White, Joseph L. Hart</dc:creator>
    </item>
  </channel>
</rss>
