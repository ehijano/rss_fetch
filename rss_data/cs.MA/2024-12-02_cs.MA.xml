<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>cs.MA updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/cs.MA</link>
    <description>cs.MA updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/cs.MA" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Mon, 02 Dec 2024 05:00:19 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Mon, 02 Dec 2024 00:00:00 -0500</pubDate>
    <skipDays>
      <day>Saturday</day>
      <day>Sunday</day>
    </skipDays>
    <item>
      <title>RMIO: A Model-Based MARL Framework for Scenarios with Observation Loss in Some Agents</title>
      <link>https://arxiv.org/abs/2411.19639</link>
      <description>arXiv:2411.19639v1 Announce Type: new 
Abstract: In recent years, model-based reinforcement learning (MBRL) has emerged as a solution to address sample complexity in multi-agent reinforcement learning (MARL) by modeling agent-environment dynamics to improve sample efficiency. However, most MBRL methods assume complete and continuous observations from each agent during the inference stage, which can be overly idealistic in practical applications. A novel model-based MARL approach called RMIO is introduced to address this limitation, specifically designed for scenarios where observation is lost in some agent. RMIO leverages the world model to reconstruct missing observations, and further reduces reconstruction errors through inter-agent information integration to ensure stable multi-agent decision-making. Secondly, unlike CTCE methods such as MAMBA, RMIO adopts the CTDE paradigm in standard environment, and enabling limited communication only when agents lack observation data, thereby reducing reliance on communication. Additionally, RMIO improves asymptotic performance through strategies such as reward smoothing, a dual-layer experience replay buffer, and an RNN-augmented policy model, surpassing previous work. Our experiments conducted in both the SMAC and MaMuJoCo environments demonstrate that RMIO outperforms current state-of-the-art approaches in terms of asymptotic convergence performance and policy robustness, both in standard mission settings and in scenarios involving observation loss.</description>
      <guid isPermaLink="false">oai:arXiv.org:2411.19639v1</guid>
      <category>cs.MA</category>
      <pubDate>Mon, 02 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Shi Zifeng, Liu Meiqin, Zhang Senlin, Zheng Ronghao, Dong Shanling</dc:creator>
    </item>
    <item>
      <title>SPAgent: Adaptive Task Decomposition and Model Selection for General Video Generation and Editing</title>
      <link>https://arxiv.org/abs/2411.18983</link>
      <description>arXiv:2411.18983v1 Announce Type: cross 
Abstract: While open-source video generation and editing models have made significant progress, individual models are typically limited to specific tasks, failing to meet the diverse needs of users. Effectively coordinating these models can unlock a wide range of video generation and editing capabilities. However, manual coordination is complex and time-consuming, requiring users to deeply understand task requirements and possess comprehensive knowledge of each model's performance, applicability, and limitations, thereby increasing the barrier to entry. To address these challenges, we propose a novel video generation and editing system powered by our Semantic Planning Agent (SPAgent). SPAgent bridges the gap between diverse user intents and the effective utilization of existing generative models, enhancing the adaptability, efficiency, and overall quality of video generation and editing. Specifically, the SPAgent assembles a tool library integrating state-of-the-art open-source image and video generation and editing models as tools. After fine-tuning on our manually annotated dataset, SPAgent can automatically coordinate the tools for video generation and editing, through our novelly designed three-step framework: (1) decoupled intent recognition, (2) principle-guided route planning, and (3) capability-based execution model selection. Additionally, we enhance the SPAgent's video quality evaluation capability, enabling it to autonomously assess and incorporate new video generation and editing models into its tool library without human intervention. Experimental results demonstrate that the SPAgent effectively coordinates models to generate or edit videos, highlighting its versatility and adaptability across various video tasks.</description>
      <guid isPermaLink="false">oai:arXiv.org:2411.18983v1</guid>
      <category>cs.CV</category>
      <category>cs.MA</category>
      <pubDate>Mon, 02 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Rong-Cheng Tu, Wenhao Sun, Zhao Jin, Jingyi Liao, Jiaxing Huang, Dacheng Tao</dc:creator>
    </item>
    <item>
      <title>On the Ethical Considerations of Generative Agents</title>
      <link>https://arxiv.org/abs/2411.19211</link>
      <description>arXiv:2411.19211v1 Announce Type: cross 
Abstract: The Generative Agents framework recently developed by Park et al. has enabled numerous new technical solutions and problem-solving approaches. Academic and industrial interest in generative agents has been explosive as a result of the effectiveness of generative agents toward emulating human behaviour. However, it is necessary to consider the ethical challenges and concerns posed by this technique and its usage. In this position paper, we discuss the extant literature that evaluate the ethical considerations regarding generative agents and similar generative tools, and identify additional concerns of significant importance. We also suggest guidelines and necessary future research on how to mitigate some of the ethical issues and systemic risks associated with generative agents.</description>
      <guid isPermaLink="false">oai:arXiv.org:2411.19211v1</guid>
      <category>cs.CY</category>
      <category>cs.AI</category>
      <category>cs.ET</category>
      <category>cs.MA</category>
      <pubDate>Mon, 02 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>N'yoma Diamond, Soumya Banerjee</dc:creator>
    </item>
    <item>
      <title>Integrating Transit Signal Priority into Multi-Agent Reinforcement Learning based Traffic Signal Control</title>
      <link>https://arxiv.org/abs/2411.19359</link>
      <description>arXiv:2411.19359v1 Announce Type: cross 
Abstract: This study integrates Transit Signal Priority (TSP) into multi-agent reinforcement learning (MARL) based traffic signal control. The first part of the study develops adaptive signal control based on MARL for a pair of coordinated intersections in a microscopic simulation environment. The two agents, one for each intersection, are centrally trained using a value decomposition network (VDN) architecture. The trained agents show slightly better performance compared to coordinated actuated signal control based on overall intersection delay at v/c of 0.95. In the second part of the study the trained signal control agents are used as background signal controllers while developing event-based TSP agents. In one variation, independent TSP agents are formulated and trained under a decentralized training and decentralized execution (DTDE) framework to implement TSP at each intersection. In the second variation, the two TSP agents are centrally trained under a centralized training and decentralized execution (CTDE) framework and VDN architecture to select and implement coordinated TSP strategies across the two intersections. In both cases the agents converge to the same bus delay value, but independent agents show high instability throughout the training process. For the test runs, the two independent agents reduce bus delay across the two intersections by 22% compared to the no TSP case while the coordinated TSP agents achieve 27% delay reduction. In both cases, there is only a slight increase in delay for a majority of the side street movements.</description>
      <guid isPermaLink="false">oai:arXiv.org:2411.19359v1</guid>
      <category>cs.AI</category>
      <category>cs.MA</category>
      <category>cs.SY</category>
      <category>eess.SY</category>
      <pubDate>Mon, 02 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Dickness Kakitahi Kwesiga, Suyash Chandra Vishnoi, Angshuman Guin, Michael Hunter</dc:creator>
    </item>
    <item>
      <title>Leveraging Large Language Models for Institutional Portfolio Management: Persona-Based Ensembles</title>
      <link>https://arxiv.org/abs/2411.19515</link>
      <description>arXiv:2411.19515v1 Announce Type: cross 
Abstract: Large language models (LLMs) have demonstrated promising performance in various financial applications, though their potential in complex investment strategies remains underexplored. To address this gap, we investigate how LLMs can predict price movements in stock and bond portfolios using economic indicators, enabling portfolio adjustments akin to those employed by institutional investors. Additionally, we explore the impact of incorporating different personas within LLMs, using an ensemble approach to leverage their diverse predictions. Our findings show that LLM-based strategies, especially when combined with the mode ensemble, outperform the buy-and-hold strategy in terms of Sharpe ratio during periods of rising consumer price index (CPI). However, traditional strategies are more effective during declining CPI trends or sharp market downturns. These results suggest that while LLMs can enhance portfolio management, they may require complementary strategies to optimize performance across varying market conditions.</description>
      <guid isPermaLink="false">oai:arXiv.org:2411.19515v1</guid>
      <category>cs.CE</category>
      <category>cs.MA</category>
      <pubDate>Mon, 02 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Yoshia Abe, Shuhei Matsuo, Ryoma Kondo, Ryohei Hisano</dc:creator>
    </item>
    <item>
      <title>A Local Information Aggregation based Multi-Agent Reinforcement Learning for Robot Swarm Dynamic Task Allocation</title>
      <link>https://arxiv.org/abs/2411.19526</link>
      <description>arXiv:2411.19526v1 Announce Type: cross 
Abstract: In this paper, we explore how to optimize task allocation for robot swarms in dynamic environments, emphasizing the necessity of formulating robust, flexible, and scalable strategies for robot cooperation. We introduce a novel framework using a decentralized partially observable Markov decision process (Dec_POMDP), specifically designed for distributed robot swarm networks. At the core of our methodology is the Local Information Aggregation Multi-Agent Deep Deterministic Policy Gradient (LIA_MADDPG) algorithm, which merges centralized training with distributed execution (CTDE). During the centralized training phase, a local information aggregation (LIA) module is meticulously designed to gather critical data from neighboring robots, enhancing decision-making efficiency. In the distributed execution phase, a strategy improvement method is proposed to dynamically adjust task allocation based on changing and partially observable environmental conditions. Our empirical evaluations show that the LIA module can be seamlessly integrated into various CTDE-based MARL methods, significantly enhancing their performance. Additionally, by comparing LIA_MADDPG with six conventional reinforcement learning algorithms and a heuristic algorithm, we demonstrate its superior scalability, rapid adaptation to environmental changes, and ability to maintain both stability and convergence speed. These results underscore LIA_MADDPG's outstanding performance and its potential to significantly improve dynamic task allocation in robot swarms through enhanced local collaboration and adaptive strategy execution.</description>
      <guid isPermaLink="false">oai:arXiv.org:2411.19526v1</guid>
      <category>cs.AI</category>
      <category>cs.MA</category>
      <category>cs.RO</category>
      <pubDate>Mon, 02 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Yang Lv, Jinlong Lei, Peng Yi</dc:creator>
    </item>
    <item>
      <title>HVAC-DPT: A Decision Pretrained Transformer for HVAC Control</title>
      <link>https://arxiv.org/abs/2411.19746</link>
      <description>arXiv:2411.19746v1 Announce Type: cross 
Abstract: Building operations consume approximately 40% of global energy, with Heating, Ventilation, and Air Conditioning (HVAC) systems responsible for up to 50% of this consumption. As HVAC energy demands are expected to rise, optimising system efficiency is crucial for reducing future energy use and mitigating climate change. Existing control strategies lack generalisation and require extensive training and data, limiting their rapid deployment across diverse buildings. This paper introduces HVAC-DPT, a Decision-Pretrained Transformer using in-context Reinforcement Learning (RL) for multi-zone HVAC control. HVAC-DPT frames HVAC control as a sequential prediction task, training a causal transformer on interaction histories generated by diverse RL agents. This approach enables HVAC-DPT to refine its policy in-context, without modifying network parameters, allowing for deployment across different buildings without the need for additional training or data collection. HVAC-DPT reduces energy consumption in unseen buildings by 45% compared to the baseline controller, offering a scalable and effective approach to mitigating the increasing environmental impact of HVAC systems.</description>
      <guid isPermaLink="false">oai:arXiv.org:2411.19746v1</guid>
      <category>cs.LG</category>
      <category>cs.AI</category>
      <category>cs.MA</category>
      <pubDate>Mon, 02 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Ana\"is Berkes</dc:creator>
    </item>
    <item>
      <title>A Multi-Loss Strategy for Vehicle Trajectory Prediction: Combining Off-Road, Diversity, and Directional Consistency Losses</title>
      <link>https://arxiv.org/abs/2411.19747</link>
      <description>arXiv:2411.19747v1 Announce Type: cross 
Abstract: Trajectory prediction is essential for the safety and efficiency of planning in autonomous vehicles. However, current models often fail to fully capture complex traffic rules and the complete range of potential vehicle movements. Addressing these limitations, this study introduces three novel loss functions: Offroad Loss, Direction Consistency Error, and Diversity Loss. These functions are designed to keep predicted paths within driving area boundaries, aligned with traffic directions, and cover a wider variety of plausible driving scenarios. As all prediction modes should adhere to road rules and conditions, this work overcomes the shortcomings of traditional "winner takes all" training methods by applying the loss functions to all prediction modes. These loss functions not only improve model training but can also serve as metrics for evaluating the realism and diversity of trajectory predictions. Extensive validation on the nuScenes and Argoverse 2 datasets with leading baseline models demonstrates that our approach not only maintains accuracy but significantly improves safety and robustness, reducing offroad errors on average by 47% on original and by 37% on attacked scenes. This work sets a new benchmark for trajectory prediction in autonomous driving, offering substantial improvements in navigating complex environments. Our code is available at https://github.com/vita-epfl/stay-on-track .</description>
      <guid isPermaLink="false">oai:arXiv.org:2411.19747v1</guid>
      <category>cs.CV</category>
      <category>cs.AI</category>
      <category>cs.LG</category>
      <category>cs.MA</category>
      <category>cs.RO</category>
      <pubDate>Mon, 02 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Ahmad Rahimi, Alexandre Alahi</dc:creator>
    </item>
    <item>
      <title>Misinformation Dissemination: Effects of Network Density in Segregated Communities</title>
      <link>https://arxiv.org/abs/2411.19866</link>
      <description>arXiv:2411.19866v1 Announce Type: cross 
Abstract: Understanding the relationship between network features and misinformation propagation is crucial for mitigating the spread of false information. Here, we investigate how network density and segregation affect the dissemination of misinformation using a susceptible-infectious-recovered framework. We find that a higher density consistently increases the proportion of misinformation believers. In segregated networks, our results reveal that minorities affect the majority: denser minority groups increase the number of believers in the majority, demonstrating how the structure of a segregated minority can influence misinformation dynamics within the majority group.</description>
      <guid isPermaLink="false">oai:arXiv.org:2411.19866v1</guid>
      <category>cs.SI</category>
      <category>cs.CY</category>
      <category>cs.MA</category>
      <category>physics.soc-ph</category>
      <pubDate>Mon, 02 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Soroush Karimi, Marcos Oliveira, Diogo Pacheco</dc:creator>
    </item>
    <item>
      <title>Rational Silence and False Polarization: How Viewpoint Organizations and Recommender Systems Distort the Expression of Public Opinion</title>
      <link>https://arxiv.org/abs/2403.06264</link>
      <description>arXiv:2403.06264v2 Announce Type: replace 
Abstract: AI-based social media platforms has already transformed the nature of economic and social interaction. AI enables the massive scale and highly personalized nature of online information sharing that we now take for granted. Extensive attention has been devoted to the polarization that social media platforms appear to facilitate. However, a key implication of the transformation we are experiencing due to these AI-powered platforms has received much less attention: how platforms impact what observers of online discourse come to believe about community views. These observers include policymakers and legislators, who look to social media to gauge the prospects for policy and legislative change, as well as developers of AI models trained on large-scale internet data, whose outputs may similarly reflect a distorted view of public opinion. In this paper, we present a nested game-theoretic model to show how observed online opinion is produced by the interaction of the decisions made by users about whether and with what rhetorical intensity to share their opinions on a platform, the efforts of organizations (such as traditional media and advocacy organizations) that seek to encourage or discourage opinion-sharing online, and the operation of AI-powered recommender systems controlled by social media platforms. We show that signals from ideological organizations encourage an increase in rhetorical intensity, leading to the 'rational silence' of moderate users. This, in turn, creates a polarized impression of where average opinions lie. We also show that this observed polarization can also be amplified by recommender systems that encourage the formation of communities online that end up seeing a skewed sample of opinion. We also identify practical strategies platforms can implement, such as reducing exposure to signals from ideological organizations and a tailored approach to content moderation.</description>
      <guid isPermaLink="false">oai:arXiv.org:2403.06264v2</guid>
      <category>cs.MA</category>
      <category>cs.CY</category>
      <category>physics.soc-ph</category>
      <pubDate>Mon, 02 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Atrisha Sarkar, Gillian K. Hadfield</dc:creator>
    </item>
    <item>
      <title>Scalable Primal Decomposition Schemes for Large-Scale Infrastructure Networks</title>
      <link>https://arxiv.org/abs/2212.11571</link>
      <description>arXiv:2212.11571v2 Announce Type: replace-cross 
Abstract: The operation of large-scale infrastructure networks requires scalable optimization schemes. To guarantee safe system operation, a high degree of feasibility in a small number of iterations is important. Decomposition schemes can help to achieve scalability. In terms of feasibility, however, classical approaches such as the alternating direction method of multipliers (ADMM) often converge slowly. In this work, we present primal decomposition schemes for hierarchically structured strongly convex QPs. These schemes offer high degrees of feasibility in a small number of iterations in combination with global convergence guarantees. We benchmark their performance against the centralized off-the-shelf interior-point solver Ipopt and ADMM on problems with up to 300,000 decision variables and constraints. We find that the proposed approaches solve problems as fast as Ipopt, but with reduced communication and without requiring a full model exchange. Moreover, the proposed schemes achieve a higher accuracy than ADMM.</description>
      <guid isPermaLink="false">oai:arXiv.org:2212.11571v2</guid>
      <category>eess.SY</category>
      <category>cs.MA</category>
      <category>cs.SY</category>
      <pubDate>Mon, 02 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Alexander Engelmann, Sungho Shin, Fran\c{c}ois Pacaud, Victor M. Zavala</dc:creator>
    </item>
    <item>
      <title>Distributed Optimization Methods for Multi-Robot Systems: Part I -- A Tutorial</title>
      <link>https://arxiv.org/abs/2301.11313</link>
      <description>arXiv:2301.11313v3 Announce Type: replace-cross 
Abstract: Distributed optimization provides a framework for deriving distributed algorithms for a variety of multi-robot problems. This tutorial constitutes the first part of a two-part series on distributed optimization applied to multi-robot problems, which seeks to advance the application of distributed optimization in robotics. In this tutorial, we demonstrate that many canonical multi-robot problems can be cast within the distributed optimization framework, such as multi-robot simultaneous localization and planning (SLAM), multi-robot target tracking, and multi-robot task assignment problems. We identify three broad categories of distributed optimization algorithms: distributed first-order methods, distributed sequential convex programming, and the alternating direction method of multipliers (ADMM). We describe the basic structure of each category and provide representative algorithms within each category. We then work through a simulation case study of multiple drones collaboratively tracking a ground vehicle. We compare solutions to this problem using a number of different distributed optimization algorithms. In addition, we implement a distributed optimization algorithm in hardware on a network of Rasberry Pis communicating with XBee modules to illustrate robustness to the challenges of real-world communication networks.</description>
      <guid isPermaLink="false">oai:arXiv.org:2301.11313v3</guid>
      <category>cs.RO</category>
      <category>cs.MA</category>
      <pubDate>Mon, 02 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Ola Shorinwa, Trevor Halsted, Javier Yu, Mac Schwager</dc:creator>
    </item>
    <item>
      <title>Distributed Optimization Methods for Multi-Robot Systems: Part II -- A Survey</title>
      <link>https://arxiv.org/abs/2301.11361</link>
      <description>arXiv:2301.11361v3 Announce Type: replace-cross 
Abstract: Although the field of distributed optimization is well-developed, relevant literature focused on the application of distributed optimization to multi-robot problems is limited. This survey constitutes the second part of a two-part series on distributed optimization applied to multi-robot problems. In this paper, we survey three main classes of distributed optimization algorithms -- distributed first-order methods, distributed sequential convex programming methods, and alternating direction method of multipliers (ADMM) methods -- focusing on fully-distributed methods that do not require coordination or computation by a central computer. We describe the fundamental structure of each category and note important variations around this structure, designed to address its associated drawbacks. Further, we provide practical implications of noteworthy assumptions made by distributed optimization algorithms, noting the classes of robotics problems suitable for these algorithms. Moreover, we identify important open research challenges in distributed optimization, specifically for robotics problems.</description>
      <guid isPermaLink="false">oai:arXiv.org:2301.11361v3</guid>
      <category>cs.RO</category>
      <category>cs.MA</category>
      <pubDate>Mon, 02 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Ola Shorinwa, Trevor Halsted, Javier Yu, Mac Schwager</dc:creator>
    </item>
  </channel>
</rss>
