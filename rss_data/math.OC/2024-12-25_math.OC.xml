<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>math.OC updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/math.OC</link>
    <description>math.OC updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/math.OC" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Wed, 25 Dec 2024 05:00:36 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Wed, 25 Dec 2024 00:00:00 -0500</pubDate>
    <skipDays>
      <day>Sunday</day>
      <day>Saturday</day>
    </skipDays>
    <item>
      <title>Stability Bounds for the Unfolded Forward-Backward Algorithm</title>
      <link>https://arxiv.org/abs/2412.17888</link>
      <description>arXiv:2412.17888v1 Announce Type: new 
Abstract: We consider a neural network architecture designed to solve inverse problems where the degradation operator is linear and known. This architecture is constructed by unrolling a forward-backward algorithm derived from the minimization of an objective function that combines a data-fidelity term, a Tikhonov-type regularization term, and a potentially nonsmooth convex penalty. The robustness of this inversion method to input perturbations is analyzed theoretically. Ensuring robustness complies with the principles of inverse problem theory, as it ensures both the continuity of the inversion method and the resilience to small noise - a critical property given the known vulnerability of deep neural networks to adversarial perturbations. A key novelty of our work lies in examining the robustness of the proposed network to perturbations in its bias, which represents the observed data in the inverse problem. Additionally, we provide numerical illustrations of the analytical Lipschitz bounds derived in our analysis.</description>
      <guid isPermaLink="false">oai:arXiv.org:2412.17888v1</guid>
      <category>math.OC</category>
      <category>cs.AI</category>
      <pubDate>Wed, 25 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Emilie Chouzenoux, Cecile Della Valle, Jean-Christophe Pesquet</dc:creator>
    </item>
    <item>
      <title>Distributed Priority-Based Load Shedding over Time-Varying Communication Networks</title>
      <link>https://arxiv.org/abs/2412.18033</link>
      <description>arXiv:2412.18033v1 Announce Type: new 
Abstract: We study the problem of distributed optimal resource allocation on networks with actions defined on discrete spaces, with applications to adaptive under-frequency load-shedding in power systems. In this context, the primary objective is to identify an optimal subset of loads (i.e., resources) in the grid to be shed to maintain system stability whenever there is a sudden imbalance in the generation and loads. The selection of loads to be shed must satisfy demand requirements while also incorporating criticality functions that account for socio-technical factors in the optimization process, enabling the algorithms to differentiate between network nodes with greater socio-technical value and those with less critical loads. Given the discrete nature of the state space in the optimization problem, which precludes the use of standard gradient-based approaches commonly employed in resource allocation problems with continuous action spaces, we propose a novel load-shedding algorithm based on distributed root-finding techniques and the novel concept of cumulative criticality function (CCF). For the proposed approach, convergence conditions via Lyapunov-like techniques are established for a broad class of time-varying communication graphs that interconnect the system's regions. The theoretical results are validated through numerical examples on the Quebec 29-bus system, demonstrating the algorithm's effectiveness.</description>
      <guid isPermaLink="false">oai:arXiv.org:2412.18033v1</guid>
      <category>math.OC</category>
      <pubDate>Wed, 25 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Adel Aghajan, Miguel Jimenez-Aparicio, Michael E. Ropp, Jorge I. Poveda</dc:creator>
    </item>
    <item>
      <title>Controllability and Insensitizing Controls for Some Coupled Stochastic Parabolic Systems</title>
      <link>https://arxiv.org/abs/2412.18050</link>
      <description>arXiv:2412.18050v1 Announce Type: new 
Abstract: In this paper, we study the null and approximate controllability, along with the existence of insensitizing controls, for a class of coupled systems described by two linear forward stochastic parabolic equations. The first objective is to identify controls that achieve the null and approximate controllability for these systems at a fixed final control time. The second goal is to find controls such that a functional of the states becomes locally insensitive to perturbations in the initial data. To achieve this, we introduce three controls: one localized in space to affect the drift term of the first equation, and two additional controls that influence the diffusion terms of both equations. Moreover, we reduce the insensitizing control problem to a null controllability problem for a cascade system of coupled forward-backward stochastic parabolic systems. By the classical duality argument, our controllability problem for the forward system (resp., forward-backward systems) is equivalent to an observability problem for the corresponding adjoint backward system (resp., backward-forward systems). The observability problems are then addressed by deriving new global Carleman estimates.</description>
      <guid isPermaLink="false">oai:arXiv.org:2412.18050v1</guid>
      <category>math.OC</category>
      <pubDate>Wed, 25 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/publicdomain/zero/1.0/</dc:rights>
      <dc:creator>Abdellatif Elgrou</dc:creator>
    </item>
    <item>
      <title>A bilevel optiization based algorithm for solving a class of price equilibrium problems</title>
      <link>https://arxiv.org/abs/2412.18114</link>
      <description>arXiv:2412.18114v1 Announce Type: new 
Abstract: We consider class of equilibrium models including the implicit Walras supply-demand and competitive models. Such a model in this class, in general, is ill-posed. We formulate such a model in the form a variational inequality having certain monotonicity property which allow us to describe a regularization algorithm avoiding the ill-posedness based upon the bilevel optimization for fnding a point that is nearest to the given guessed or desired equilibrium price for the model. The obtained computational results with many randomly generated data show that the proposed algorithm works well for this class of the equilibrium models.</description>
      <guid isPermaLink="false">oai:arXiv.org:2412.18114v1</guid>
      <category>math.OC</category>
      <pubDate>Wed, 25 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/publicdomain/zero/1.0/</dc:rights>
      <dc:creator>Nguyen Ngoc Hai, Le Dung Muu, Nguyen Van Quy</dc:creator>
    </item>
    <item>
      <title>Set stabilization of Boolean control networks based on bisimulations: A dimensionality reduction approach</title>
      <link>https://arxiv.org/abs/2412.18137</link>
      <description>arXiv:2412.18137v1 Announce Type: new 
Abstract: This paper exploits bisimulation relations, generated by extracting the concept of morphisms between algebraic structures, to analyze set stabilization of Boolean control networks with lower complexity. First, for two kinds of bisimulation relations, called as weak bisimulation and strong bisimulation relations, a novel verification method is provided by constructing the bisimulation matrices. Then the comparison for set stabilization of BCNs via two kinds of bisimulation methods is presented, which involves the dimensionality of quotient systems and dependency of the control laws on the original system. Moreover, the proposed method is also applied to the analysis of probabilistic Boolean control networks to establish the unified analysis framework of bisimulations. Finally, the validity of the obtained results is verified by the practical example.</description>
      <guid isPermaLink="false">oai:arXiv.org:2412.18137v1</guid>
      <category>math.OC</category>
      <pubDate>Wed, 25 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Tiantian Mu, Jun-e Feng, Biao Wang</dc:creator>
    </item>
    <item>
      <title>Optimal error estimates of the stochastic parabolic optimal control problem with integral state constraint</title>
      <link>https://arxiv.org/abs/2412.18173</link>
      <description>arXiv:2412.18173v1 Announce Type: new 
Abstract: In this paper, the optimal strong error estimates for stochastic parabolic optimal control problem with additive noise and integral state constraint are derived based on time-implicit and finite element discretization. The continuous and discrete first-order optimality conditions are deduced by constructing the Lagrange functional, which contains forward-backward stochastic parabolic equations and a variational equation. The fully discrete version of forward-backward stochastic parabolic equations is introduced as an auxiliary problem and the optimal strong convergence orders are estimated, which further allows the optimal a priori error estimates for control, state, adjoint state and multiplier to be derived. Then, a simple and yet efficient gradient projection algorithm is proposed to solve stochastic parabolic control problem and its convergence rate is proved. Numerical experiments are carried out to illustrate the theoretical findings.</description>
      <guid isPermaLink="false">oai:arXiv.org:2412.18173v1</guid>
      <category>math.OC</category>
      <pubDate>Wed, 25 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Qiming Wang, Wanfang Shen, Wenbin Liu</dc:creator>
    </item>
    <item>
      <title>Indices of quadratic programs over reproducing kernel Hilbert spaces for fun and profit</title>
      <link>https://arxiv.org/abs/2412.18201</link>
      <description>arXiv:2412.18201v1 Announce Type: new 
Abstract: We give an abstract perspective on quadratic programming with an eye toward long portfolio theory geared toward explaining sparsity via maximum principles. Specifically, in optimal allocation problems, we see that support of an optimal distribution lies in a variety intersect a kind of distinguished boundary of a compact subspace to be allocated over. We demonstrate some of its intelligence by using it to solve mazes and interpret such behavior as the underlying space trying to understand some hypothetical platonic index for which the capital asset pricing model holds.</description>
      <guid isPermaLink="false">oai:arXiv.org:2412.18201v1</guid>
      <category>math.OC</category>
      <category>math.CV</category>
      <category>math.FA</category>
      <category>q-fin.PM</category>
      <category>q-fin.PR</category>
      <pubDate>Wed, 25 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Geoffrey Hutinet, J. E. Pascoe</dc:creator>
    </item>
    <item>
      <title>Asymptotically Optimal Appointment Scheduling in the Presence of Patient Unpunctuality</title>
      <link>https://arxiv.org/abs/2412.18215</link>
      <description>arXiv:2412.18215v1 Announce Type: new 
Abstract: We consider the optimal appointment scheduling problem that incorporates patients' unpunctual behavior, where the unpunctuality is assumed to be time dependent, but additive. Our goal is to develop an optimal scheduling method for a large patient system to maximize expected net revenue. Methods for deriving optimal appointment schedules for large-scale systems often run into computational bottlenecks due to mixed-integer programming or robust optimization formulations and computationally complex search methods. In this work, we model the system as a single-server queueing system, where patients arrive unpunctually and follow the FIFO service discipline to see the doctor (i.e., get into service). Using the heavy traffic fluid approximation, we develop a deterministic control problem, referred to as the fluid control problem (FCP), which serves as an asymptotic upper bound for the original queueing control problem (QCP). Using the optimal solution of the FCP, we establish an asymptotically optimal scheduling policy on a fluid scale. We further investigate the convergence rate of the QCP under the proposed policy. The FCP, due to the incorporation of unpunctuality, is difficult to solve analytically. We thus propose a time-discretized numerical scheme to approximately solve the FCP. The discretized FCP takes the form of a quadratic program with linear constraints. We examine the behavior of these schedules under different unpunctuality assumptions and test the performance of the schedules on real data in a simulation study. Interestingly, the optimal schedules can involve block booking of patients, even if the unpunctuality distributions are continuous.</description>
      <guid isPermaLink="false">oai:arXiv.org:2412.18215v1</guid>
      <category>math.OC</category>
      <category>math.PR</category>
      <pubDate>Wed, 25 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-sa/4.0/</dc:rights>
      <dc:creator>Nikolai Lipscomb, Xin Liu, Vidyadhar G. Kulkarni</dc:creator>
    </item>
    <item>
      <title>Optimality Conditions for Model Predictive Control: Rethinking Predictive Model Design</title>
      <link>https://arxiv.org/abs/2412.18268</link>
      <description>arXiv:2412.18268v1 Announce Type: new 
Abstract: Optimality is a critical aspect of Model Predictive Control (MPC), especially in economic MPC. However, achieving optimality in MPC presents significant challenges, and may even be impossible, due to inherent inaccuracies in the predictive models. Predictive models often fail to accurately capture the true system dynamics, such as in the presence of stochasticity, leading to suboptimal MPC policies. In this paper, we establish the necessary and sufficient conditions on the underlying prediction model for an MPC scheme to achieve closed-loop optimality. Interestingly, these conditions are counterintuitive to the traditional approach of building predictive models that best fit the data. These conditions present a mathematical foundation for constructing models that are directly linked to the performance of the resulting MPC scheme.</description>
      <guid isPermaLink="false">oai:arXiv.org:2412.18268v1</guid>
      <category>math.OC</category>
      <pubDate>Wed, 25 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Akhil S Anand, Arash Bahari Kordabad, Mario Zanon, Sebastien Gros</dc:creator>
    </item>
    <item>
      <title>A universal reproducing kernel Hilbert space for learning nonlinear systems operators</title>
      <link>https://arxiv.org/abs/2412.18360</link>
      <description>arXiv:2412.18360v1 Announce Type: new 
Abstract: In this work, we consider the problem of learning nonlinear operators that correspond to discrete-time nonlinear dynamical systems with inputs. Given an initial state and a finite input trajectory, such operators yield a finite output trajectory compatible with the system dynamics. Inspired by the universal approximation theorem of operators tailored to radial basis functions neural networks, we construct a class of kernel functions as the product of kernel functions in the space of input trajectories and initial states, respectively. We prove that for positive definite kernel functions, the resulting product reproducing kernel Hilbert space is dense and even complete in the space of nonlinear systems operators, under suitable assumptions. This provides a universal kernel-functions-based framework for learning nonlinear systems operators, which is intuitive and easy to apply to general nonlinear systems.</description>
      <guid isPermaLink="false">oai:arXiv.org:2412.18360v1</guid>
      <category>math.OC</category>
      <category>cs.SY</category>
      <category>eess.SY</category>
      <category>math.DS</category>
      <pubDate>Wed, 25 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Mircea Lazar</dc:creator>
    </item>
    <item>
      <title>A Stochastic Block-coordinate Proximal Newton Method for Nonconvex Composite Minimization</title>
      <link>https://arxiv.org/abs/2412.18394</link>
      <description>arXiv:2412.18394v1 Announce Type: new 
Abstract: We propose a stochastic block-coordinate proximal Newton method for minimizing the sum of a blockwise Lipschitz-continuously differentiable function and a separable nonsmooth convex function. In each iteration, this method randomly selects a block and approximately solves a strongly convex regularized quadratic subproblem, utilizing second-order information from the smooth component of the objective function. A backtracking line search is employed to ensure the monotonicity of the objective value. We demonstrate that under certain sampling assumption, the fundamental convergence results of our proposed stochastic method are in accordance with the corresponding results for the inexact proximal Newton method. We study the convergence of the sequence of expected objective values and the convergence of the sequence of expected residual mapping norms under various sampling assumptions. Furthermore, we introduce a method that employs the unit step size in conjunction with the Lipschitz constant of the gradient of the smooth component to formulate the strongly convex regularized quadratic subproblem. In addition to establishing the global convergence rate, we also provide a local convergence analysis for this method under certain sampling assumption and the higher-order metric subregularity of the residual mapping. To the best knowledge of the authors, this is the first stochastic second-order algorithm with a superlinear local convergence rate for addressing nonconvex composite optimization problems. Finally, we conduct numerical experiments to demonstrate the effectiveness and convergence of the proposed algorithm.</description>
      <guid isPermaLink="false">oai:arXiv.org:2412.18394v1</guid>
      <category>math.OC</category>
      <pubDate>Wed, 25 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Hong Zhu, Xun Qian</dc:creator>
    </item>
    <item>
      <title>Maximal number of mixed Nash equilibria in generic games where each player has two pure strategies</title>
      <link>https://arxiv.org/abs/2412.17890</link>
      <description>arXiv:2412.17890v1 Announce Type: cross 
Abstract: The number of Nash equilibria of the mixed extension of a generic finite game in normal form is finite and odd. This raises the question how large the number can be, depending on the number of players and the numbers of their pure strategies. Here we present a lower bound for the maximal possible number in the case of m-player games where each player has two pure strategies. It is surprisingly close to a known upper bound.</description>
      <guid isPermaLink="false">oai:arXiv.org:2412.17890v1</guid>
      <category>math.CO</category>
      <category>cs.GT</category>
      <category>math.OC</category>
      <pubDate>Wed, 25 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <dc:creator>Claus Hertling, Matija Vujic</dc:creator>
    </item>
    <item>
      <title>Data-Driven Priors in the Maximum Entropy on the Mean Method for Linear Inverse Problems</title>
      <link>https://arxiv.org/abs/2412.17916</link>
      <description>arXiv:2412.17916v1 Announce Type: cross 
Abstract: We establish the theoretical framework for implementing the maximumn entropy on the mean (MEM) method for linear inverse problems in the setting of approximate (data-driven) priors. We prove a.s. convergence for empirical means and further develop general estimates for the difference between the MEM solutions with different priors $\mu$ and $\nu$ based upon the epigraphical distance between their respective log-moment generating functions. These estimates allow us to establish a rate of convergence in expectation for empirical means. We illustrate our results with denoising on MNIST and Fashion-MNIST data sets.</description>
      <guid isPermaLink="false">oai:arXiv.org:2412.17916v1</guid>
      <category>stat.ML</category>
      <category>cs.LG</category>
      <category>math.OC</category>
      <pubDate>Wed, 25 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Matthew King-Roskamp, Rustum Choksi, Tim Hoheisel</dc:creator>
    </item>
    <item>
      <title>Stochastic Control for Fine-tuning Diffusion Models: Optimality, Regularity, and Convergence</title>
      <link>https://arxiv.org/abs/2412.18164</link>
      <description>arXiv:2412.18164v1 Announce Type: cross 
Abstract: Diffusion models have emerged as powerful tools for generative modeling, demonstrating exceptional capability in capturing target data distributions from large datasets. However, fine-tuning these massive models for specific downstream tasks, constraints, and human preferences remains a critical challenge. While recent advances have leveraged reinforcement learning algorithms to tackle this problem, much of the progress has been empirical, with limited theoretical understanding. To bridge this gap, we propose a stochastic control framework for fine-tuning diffusion models. Building on denoising diffusion probabilistic models as the pre-trained reference dynamics, our approach integrates linear dynamics control with Kullback-Leibler regularization. We establish the well-posedness and regularity of the stochastic control problem and develop a policy iteration algorithm (PI-FT) for numerical solution. We show that PI-FT achieves global convergence at a linear rate. Unlike existing work that assumes regularities throughout training, we prove that the control and value sequences generated by the algorithm maintain the regularity. Additionally, we explore extensions of our framework to parametric settings and continuous-time formulations.</description>
      <guid isPermaLink="false">oai:arXiv.org:2412.18164v1</guid>
      <category>cs.LG</category>
      <category>math.OC</category>
      <pubDate>Wed, 25 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Yinbin Han, Meisam Razaviyayn, Renyuan Xu</dc:creator>
    </item>
    <item>
      <title>Simulation-based Approach for Fast Optimal Control of a Stefan Problem with Application to Cell Therapy</title>
      <link>https://arxiv.org/abs/2412.18272</link>
      <description>arXiv:2412.18272v1 Announce Type: cross 
Abstract: This article describes a new, efficient way of finding control and state trajectories in optimal control problems by transformation into a system of differential-algebraic equations (DAEs). The optimal control and state vectors can be obtained via simulation of the resulting DAE system with the selected DAE solver, eliminating the need for an optimization solver. Our simulation-based framework was demonstrated and benchmarked against various optimization-based approaches via four case studies associated with optimization and control of a Stefan problem with application to cell therapy. The simulation-based approach is faster than every optimization-based method by more than an order of magnitude while giving the same level of accuracy in all cases. The proposed technique offers an efficient and reliable framework for optimal control, serving as a promising alternative to the traditional techniques in applications where speed is crucial, e.g., real-time online model predictive control.</description>
      <guid isPermaLink="false">oai:arXiv.org:2412.18272v1</guid>
      <category>eess.SY</category>
      <category>cs.SY</category>
      <category>math.OC</category>
      <pubDate>Wed, 25 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Prakitr Srisuma, George Barbastathis, Richard D. Braatz</dc:creator>
    </item>
    <item>
      <title>Dynamic Mean-Variance Asset Allocation in General Incomplete Markets A Nonlocal BSDE-based Feedback Control Approach</title>
      <link>https://arxiv.org/abs/2412.18498</link>
      <description>arXiv:2412.18498v1 Announce Type: cross 
Abstract: This paper studies dynamic mean-variance (MV) asset allocation problems in general incomplete markets. Besides of the conventional MV objective on portfolio's terminal wealth, our framework can accommodate running MV objectives with general (non-exponential) discounting factors while in general, any time-dependent preferences. We attempt the problem with a game-theoretic framework while decompose the equilibrium control policies into two parts: the first part is a myopic strategy characterized by a linear Volterra integral equation of the second kind and the second part reveals the hedging demand governed by a system of nonlocal backward stochastic differential equations. We manage to establish the well-posedness of the solutions to the two aforementioned equations in tailored Bananch spaces by the fixed-point theorem. It allows us to devise a numerical scheme for solving for the equilibrium control policy with guarantee and to conclude that the dynamic (equilibrium) mean-variance policy in general settings is well-defined. Our probabilistic approach allows us to consider a board range of stochastic factor models, such as the Chan--Karolyi--Longstaff--Sanders (CKLS) model. For which, we verify all technical assumptions and provide a sound numerical scheme. Numerical examples are provided to illustrate our framework.</description>
      <guid isPermaLink="false">oai:arXiv.org:2412.18498v1</guid>
      <category>q-fin.MF</category>
      <category>math.OC</category>
      <category>math.PR</category>
      <pubDate>Wed, 25 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Qian Lei, Chi Seng Pun, Jingxiang Tang</dc:creator>
    </item>
    <item>
      <title>Bayesian Optimization of Bilevel Problems</title>
      <link>https://arxiv.org/abs/2412.18518</link>
      <description>arXiv:2412.18518v1 Announce Type: cross 
Abstract: Bilevel optimization, a hierarchical mathematical framework where one optimization problem is nested within another, has emerged as a powerful tool for modeling complex decision-making processes in various fields such as economics, engineering, and machine learning. This paper focuses on bilevel optimization where both upper-level and lower-level functions are black boxes and expensive to evaluate. We propose a Bayesian Optimization framework that models the upper and lower-level functions as Gaussian processes over the combined space of upper and lower-level decisions, allowing us to exploit knowledge transfer between different sub-problems. Additionally, we propose a novel acquisition function for this model. Our experimental results demonstrate that the proposed algorithm is highly sample-efficient and outperforms existing methods in finding high-quality solutions.</description>
      <guid isPermaLink="false">oai:arXiv.org:2412.18518v1</guid>
      <category>cs.LG</category>
      <category>math.OC</category>
      <pubDate>Wed, 25 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Omer Ekmekcioglu, Nursen Aydin, Juergen Branke</dc:creator>
    </item>
    <item>
      <title>The behavioral approach for LPV data-driven representations</title>
      <link>https://arxiv.org/abs/2412.18543</link>
      <description>arXiv:2412.18543v1 Announce Type: cross 
Abstract: In this paper, we present data-driven representations of linear parameter-varying (LPV) systems that can be used for direct data-driven analysis and control of LPV systems. Specifically, we use the behavioral approach for LPV systems to develop a data-driven representation of the finite-horizon behavior of an LPV system that can be represented by a kernel representation with shifted-affine scheduling dependence. Moreover, we provide a necessary and sufficient rank-based test on the available data that concludes whether the data-driven representation fully represents the finite-horizon behavior. The results in this paper allow for direct data-driven analysis and control of LPV systems with stability and performance guarantees. We demonstrate this by also solving the LPV data-driven simulation problem. Moreover, through the use of LPV systems as surrogates for nonlinear systems, our results may serve as a stepping stone towards direct data-driven analysis and control of nonlinear systems.</description>
      <guid isPermaLink="false">oai:arXiv.org:2412.18543v1</guid>
      <category>eess.SY</category>
      <category>cs.SY</category>
      <category>math.OC</category>
      <pubDate>Wed, 25 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <dc:creator>Chris Verhoek, Ivan Markovsky, Sofie Haesaert, Roland T\'oth</dc:creator>
    </item>
    <item>
      <title>A Behavioral Model for Exploration vs. Exploitation: Theoretical Framework and Experimental Evidence</title>
      <link>https://arxiv.org/abs/2207.01028</link>
      <description>arXiv:2207.01028v3 Announce Type: replace 
Abstract: How do people navigate the exploration-exploitation (EE) trade-off when making repeated choices with unknown rewards? We study this question through the lens of multi-armed bandit problems and introduce a novel behavioral model, Quantal Choice with Adaptive Reduction of Exploration (QCARE). It generalizes Thompson Sampling, allowing for a principled way to quantify the EE trade-off and reflect human decision-making patterns. The model adaptively reduces exploration as information accumulates, with the reduction rate serving as a parameter to quantify the EE trade-off dynamics. We theoretically analyze how varying reduction rates influence decision quality, shedding light on the effects of ``over-exploration'' and ``under-exploration.'' Empirically, we validate QCARE through experiments collecting behavioral data from human participants. QCARE not only captures critical behavioral patterns in the EE trade-off but also outperforms alternative models in predictive power. Our analysis reveals a behavioral tendency toward over-exploration.</description>
      <guid isPermaLink="false">oai:arXiv.org:2207.01028v3</guid>
      <category>math.OC</category>
      <pubDate>Wed, 25 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Jingying Ding, Yifan Feng, Ying Rong</dc:creator>
    </item>
    <item>
      <title>Approximation Algorithms for Line Planning with Multiple Resource Constraints</title>
      <link>https://arxiv.org/abs/2311.03327</link>
      <description>arXiv:2311.03327v3 Announce Type: replace 
Abstract: We consider the problem of maximizing the total reward in a transportation system with $M$ buses that serve a set of Origin-Destination (OD) pairs. Each bus operates on at most one line selected from a set of candidate lines, where operating a line incurs multiple resource costs. The goal is to efficiently assign the buses to the lines to serve integral portions of given OD demands while respecting bus capacity, resource limits, and demand constraints. This model significantly generalizes line planning models in prior works by integrating candidate line assignments to buses, broader OD demand specifications, and considering multiple resource constraints.
  We propose randomized approximation algorithms addressing various problem scenarios. When line costs are zero, we achieve the optimal approximation ratio of $1 - \frac{1}{e}$, assuming $P \neq NP$. For instances with small line costs, the algorithm attains an approximation ratio of $1 - \frac{1}{e} - \eta$. In the most general case, we obtain an approximation ratio of $\frac{1}{2} - \frac{1}{2e} - \eta$. Additionally, we develop an approach ensuring a ratio of $1 - \frac{1}{e} - \eta$ while limiting resource overuse to at most $\tau$ units, where $\eta$ and $\tau$ are arbitrarily small constants.
  To demonstrate real-world applicability, we modify one of our algorithms to improve practical performance while maintaining a level of theoretical guarantees, and validate it using numerical simulations on real-world data. Results show that our algorithm produces high-quality solutions efficiently, outperforming commercial solvers on challenging instances.</description>
      <guid isPermaLink="false">oai:arXiv.org:2311.03327v3</guid>
      <category>math.OC</category>
      <pubDate>Wed, 25 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Hongyi Jiang, Igor Averbakh, Samitha Samaranayake</dc:creator>
    </item>
    <item>
      <title>About some works of Boris Polyak on convergence of gradient methods and their development</title>
      <link>https://arxiv.org/abs/2311.16743</link>
      <description>arXiv:2311.16743v2 Announce Type: replace 
Abstract: The paper presents a review of the state-of-the-art of subgradient and accelerated methods of convex optimization, including in the presence of disturbances and access to various information about the objective function (function value, gradient, stochastic gradient, higher derivatives). For nonconvex problems, the Polak-Lojasiewicz condition is considered and a review of the main results is given. The behavior of numerical methods in the presence of sharp minima is considered. The purpose of this survey is to show the influence of the works of B.T. Polyak (1935 -- 2023) on gradient optimization methods and their neighborhoods on the modern development of numerical optimization methods.</description>
      <guid isPermaLink="false">oai:arXiv.org:2311.16743v2</guid>
      <category>math.OC</category>
      <pubDate>Wed, 25 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <arxiv:DOI>10.1134/S0965542524700076</arxiv:DOI>
      <dc:creator>Seydamet Ablaev, Aleksandr Beznosikov, Alexander Gasnikov, Darina Dvinskikh, Aleksandr Lobanov, Sergei Puchinin, Fedor Stonyakin</dc:creator>
    </item>
    <item>
      <title>Maximum Principle for Control System driven by Mixed Fractional Brownian Motion</title>
      <link>https://arxiv.org/abs/2312.11893</link>
      <description>arXiv:2312.11893v2 Announce Type: replace 
Abstract: In this paper, we investigate the optimal control problem for systems driven by mixed fractional Brownian motion (including a fractional Brownian motion with Hurst parameter $H&gt;1/2$ and the standard Brownian motion). By using Malliavin calculus and introducing a disturbance control region, we obtain a modified maximum principle. Through martingale representation theorem, we obtain the adjoint backward stochastic differential equation in a natural way. Furthermore, corresponding to [1], a significant result is that the necessary condition is simplified by only containing one equality. As an application, the linear quadratic case is investigated to illustrate the main results.</description>
      <guid isPermaLink="false">oai:arXiv.org:2312.11893v2</guid>
      <category>math.OC</category>
      <category>math.PR</category>
      <pubDate>Wed, 25 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Yuhang Li, Yuecai Han</dc:creator>
    </item>
    <item>
      <title>Bandit Convex Optimisation</title>
      <link>https://arxiv.org/abs/2402.06535</link>
      <description>arXiv:2402.06535v3 Announce Type: replace 
Abstract: Bandit convex optimisation is a fundamental framework for studying zeroth-order convex optimisation. These notes cover the many tools used for this problem, including cutting plane methods, interior point methods, continuous exponential weights, gradient descent and online Newton step. The nuances between the many assumptions and setups are explained. Although there is not much truly new here, some existing tools are applied in novel ways to obtain new algorithms. A few bounds are improved in minor ways.</description>
      <guid isPermaLink="false">oai:arXiv.org:2402.06535v3</guid>
      <category>math.OC</category>
      <category>cs.LG</category>
      <category>stat.ML</category>
      <pubDate>Wed, 25 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Tor Lattimore</dc:creator>
    </item>
    <item>
      <title>Asymptotic Stability and Strict Passivity of Port-Hamiltonian Descriptor Systems via State Feedback</title>
      <link>https://arxiv.org/abs/2406.08994</link>
      <description>arXiv:2406.08994v3 Announce Type: replace 
Abstract: While port-Hamiltonian descriptor systems are known to be stable and passive, they may not be asymptotically stable or strictly passive. Necessary and sufficient conditions are presented when these properties as well as the regularity and the index one property can be achieved via state feedback while preserving the port-Hamiltonian structure.</description>
      <guid isPermaLink="false">oai:arXiv.org:2406.08994v3</guid>
      <category>math.OC</category>
      <category>math.CA</category>
      <pubDate>Wed, 25 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Delin Chu, Volker Mehrmann</dc:creator>
    </item>
    <item>
      <title>Unlocking Global Optimality in Bilevel Optimization: A Pilot Study</title>
      <link>https://arxiv.org/abs/2408.16087</link>
      <description>arXiv:2408.16087v2 Announce Type: replace 
Abstract: Bilevel optimization has witnessed a resurgence of interest, driven by its critical role in trustworthy and efficient AI applications. While many recent works have established convergence to stationary points or local minima, obtaining the global optimum of bilevel optimization remains an important yet open problem. The difficulty lies in the fact that, unlike many prior non-convex single-level problems, bilevel problems often do not admit a benign landscape, and may indeed have multiple spurious local solutions. Nevertheless, attaining global optimality is indispensable for ensuring reliability, safety, and cost-effectiveness, particularly in high-stakes engineering applications that rely on bilevel optimization. In this paper, we first explore the challenges of establishing a global convergence theory for bilevel optimization, and present two sufficient conditions for global convergence. We provide algorithm-dependent proofs to rigorously substantiate these sufficient conditions on two specific bilevel learning scenarios: representation learning and data hypercleaning (a.k.a. reweighting). Experiments corroborate the theoretical findings, demonstrating convergence to the global minimum in both cases.</description>
      <guid isPermaLink="false">oai:arXiv.org:2408.16087v2</guid>
      <category>math.OC</category>
      <category>cs.LG</category>
      <pubDate>Wed, 25 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Quan Xiao, Tianyi Chen</dc:creator>
    </item>
    <item>
      <title>Data-driven decision-making under uncertainty with entropic risk measure</title>
      <link>https://arxiv.org/abs/2409.19926</link>
      <description>arXiv:2409.19926v2 Announce Type: replace 
Abstract: The entropic risk measure is widely used in high-stakes decision making to account for tail risks associated with an uncertain loss. With limited data, the empirical entropic risk estimator, i.e. replacing the expectation in the entropic risk measure with a sample average, underestimates the true risk. To debias the empirical entropic risk estimator, we propose a strongly asymptotically consistent bootstrapping procedure. The first step of the procedure involves fitting a distribution to the data, whereas the second step estimates the bias of the empirical entropic risk estimator using bootstrapping, and corrects for it. We show that naively fitting a Gaussian Mixture Model to the data using the maximum likelihood criterion typically leads to an underestimation of the risk. To mitigate this issue, we consider two alternative methods: a more computationally demanding one that fits the distribution of empirical entropic risk, and a simpler one that fits the extreme value distribution. As an application of the approach, we study a distributionally robust entropic risk minimization problem with type-$\infty$ Wasserstein ambiguity set, where debiasing the validation performance using our techniques significantly improves the calibration of the size of the ambiguity set. Furthermore, we propose a distributionally robust optimization model for a well-studied insurance contract design problem. The model considers multiple (potential) policyholders that have dependent risks and the insurer and policyholders use entropic risk measure. We show that cross validation methods can result in significantly higher out-of-sample risk for the insurer if the bias in validation performance is not corrected for. This improvement can be explained from the observation that our methods suggest a higher (and more accurate) premium to homeowners.</description>
      <guid isPermaLink="false">oai:arXiv.org:2409.19926v2</guid>
      <category>math.OC</category>
      <category>cs.LG</category>
      <category>stat.ML</category>
      <pubDate>Wed, 25 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Utsav Sadana, Erick Delage, Angelos Georghiou</dc:creator>
    </item>
    <item>
      <title>Towards An Unsupervised Learning Scheme for Efficiently Solving Parameterized Mixed-Integer Programs</title>
      <link>https://arxiv.org/abs/2412.17623</link>
      <description>arXiv:2412.17623v2 Announce Type: replace 
Abstract: In this paper, we describe a novel unsupervised learning scheme for accelerating the solution of a family of mixed integer programming (MIP) problems. Distinct substantially from existing learning-to-optimize methods, our proposal seeks to train an autoencoder (AE) for binary variables in an unsupervised learning fashion, using data of optimal solutions to historical instances for a parametric family of MIPs. By a deliberate design of AE architecture and exploitation of its statistical implication, we present a simple and straightforward strategy to construct a class of cutting plane constraints from the decoder parameters of an offline-trained AE. These constraints reliably enclose the optimal binary solutions of new problem instances thanks to the representation strength of the AE. More importantly, their integration into the primal MIP problem leads to a tightened MIP with the reduced feasible region, which can be resolved at decision time using off-the-shelf solvers with much higher efficiency. Our method is applied to a benchmark batch process scheduling problem formulated as a mixed integer linear programming (MILP) problem. Comprehensive results demonstrate that our approach significantly reduces the computational cost of off-the-shelf MILP solvers while retaining a high solution quality. The codes of this work are open-sourced at https://github.com/qushiyuan/AE4BV.</description>
      <guid isPermaLink="false">oai:arXiv.org:2412.17623v2</guid>
      <category>math.OC</category>
      <category>cs.LG</category>
      <pubDate>Wed, 25 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Shiyuan Qu, Fenglian Dong, Zhiwei Wei, Chao Shang</dc:creator>
    </item>
    <item>
      <title>Asymptotic Theory for IV-Based Reinforcement Learning with Potential Endogeneity</title>
      <link>https://arxiv.org/abs/2103.04021</link>
      <description>arXiv:2103.04021v3 Announce Type: replace-cross 
Abstract: In the standard data analysis framework, data is collected (once and for all), and then data analysis is carried out. However, with the advancement of digital technology, decision-makers constantly analyze past data and generate new data through their decisions. We model this as a Markov decision process and show that the dynamic interaction between data generation and data analysis leads to a new type of bias -- reinforcement bias -- that exacerbates the endogeneity problem in standard data analysis. We propose a class of instrument variable (IV)-based reinforcement learning (RL) algorithms to correct for the bias and establish their theoretical properties by incorporating them into a stochastic approximation (SA) framework. Our analysis accommodates iterate-dependent Markovian structures and, therefore, can be used to study RL algorithms with policy improvement. We also provide formulas for inference on optimal policies of the IV-RL algorithms. These formulas highlight how intertemporal dependencies of the Markovian environment affect the inference.</description>
      <guid isPermaLink="false">oai:arXiv.org:2103.04021v3</guid>
      <category>stat.ML</category>
      <category>cs.LG</category>
      <category>econ.EM</category>
      <category>math.OC</category>
      <pubDate>Wed, 25 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Jin Li, Ye Luo, Zigan Wang, Xiaowei Zhang</dc:creator>
    </item>
    <item>
      <title>Generalized Orthogonal Procrustes Problem under Arbitrary Adversaries</title>
      <link>https://arxiv.org/abs/2106.15493</link>
      <description>arXiv:2106.15493v3 Announce Type: replace-cross 
Abstract: The generalized orthogonal Procrustes problem (GOPP) plays a fundamental role in several scientific disciplines including statistics, imaging science and computer vision. Despite its tremendous practical importance, it is generally an NP-hard problem to find the least squares estimator. We study the semidefinite relaxation (SDR) and an iterative method named generalized power method (GPM) to find the least squares estimator, and investigate the performance under a signal-plus-noise model. We show that the SDR recovers the least squares estimator exactly and moreover the generalized power method with a proper initialization converges linearly to the global minimizer to the SDR, provided that the signal-to-noise ratio is large. The main technique follows from showing the nonlinear mapping involved in the GPM is essentially a local contraction mapping and then applying the well-known Banach fixed-point theorem finishes the proof. In addition, we analyze the low-rank factorization algorithm and show the corresponding optimization landscape is free of spurious local minimizers under nearly identical conditions that enables the success of SDR approach. The highlight of our work is that the theoretical guarantees are purely algebraic and do not assume any statistical priors of the additive adversaries, and thus it applies to various interesting settings.</description>
      <guid isPermaLink="false">oai:arXiv.org:2106.15493v3</guid>
      <category>cs.IT</category>
      <category>math.IT</category>
      <category>math.OC</category>
      <category>stat.ML</category>
      <pubDate>Wed, 25 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Shuyang Ling</dc:creator>
    </item>
    <item>
      <title>The Effectiveness of Local Updates for Decentralized Learning under Data Heterogeneity</title>
      <link>https://arxiv.org/abs/2403.15654</link>
      <description>arXiv:2403.15654v3 Announce Type: replace-cross 
Abstract: We revisit two fundamental decentralized optimization methods, Decentralized Gradient Tracking (DGT) and Decentralized Gradient Descent (DGD), with multiple local updates. We consider two settings and demonstrate that incorporating local update steps can reduce communication complexity. Specifically, for $\mu$-strongly convex and $L$-smooth loss functions, we proved that local DGT achieves communication complexity {}{$\tilde{\mathcal{O}} \Big(\frac{L}{\mu(K+1)} + \frac{\delta + {}{\mu}}{\mu (1 - \rho)} + \frac{\rho }{(1 - \rho)^2} \cdot \frac{L+ \delta}{\mu}\Big)$}, %\zhize{seems to be $\tilde{\mathcal{O}}$} {where $K$ is the number of additional local update}, $\rho$ measures the network connectivity and $\delta$ measures the second-order heterogeneity of the local losses. Our results reveal the tradeoff between communication and computation and show increasing $K$ can effectively reduce communication costs when the data heterogeneity is low and the network is well-connected. We then consider the over-parameterization regime where the local losses share the same minimums. We proved that employing local updates in DGD, even without gradient correction, achieves exact linear convergence under the Polyak-{\L}ojasiewicz (PL) condition, which can yield a similar effect as DGT in reducing communication complexity. {}{Customization of the result to linear models is further provided, with improved rate expression. }Numerical experiments validate our theoretical results.</description>
      <guid isPermaLink="false">oai:arXiv.org:2403.15654v3</guid>
      <category>cs.LG</category>
      <category>math.OC</category>
      <pubDate>Wed, 25 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Tongle Wu, Zhize Li, Ying Sun</dc:creator>
    </item>
    <item>
      <title>Solving The Travelling Salesman Problem Using A Single Qubit</title>
      <link>https://arxiv.org/abs/2407.17207</link>
      <description>arXiv:2407.17207v2 Announce Type: replace-cross 
Abstract: The travelling salesman problem (TSP) is a popular NP-hard-combinatorial optimization problem that requires finding the optimal way for a salesman to travel through different cities once and return to the initial city. The existing methods of solving TSPs on quantum systems are either gate-based or binary variable-based encoding. Both approaches are resource-expensive in terms of the number of qubits while performing worse compared to existing classical algorithms even for small-size problems. We present an algorithm that solves an arbitrary TSP using a single qubit by invoking the principle of quantum parallelism. The cities are represented as quantum states on the Bloch sphere while the preparation of superposition states allows us to traverse multiple paths at once. The underlying framework of our algorithm is a quantum version of the classical Brachistochrone approach. Optimal control methods are employed to create a selective superposition of the quantum states to find the shortest route of a given TSP. The numerical simulations solve a sample of four to nine cities for which exact solutions are obtained. The algorithm can be implemented on any quantum platform capable of efficiently rotating a qubit and allowing state tomography measurements. For the TSP problem sizes considered in this work, our algorithm is more resource-efficient and accurate than existing quantum algorithms with the potential for scalability. A potential speed-up of polynomial time over classical algorithms is discussed.</description>
      <guid isPermaLink="false">oai:arXiv.org:2407.17207v2</guid>
      <category>quant-ph</category>
      <category>cs.CC</category>
      <category>math.OC</category>
      <pubDate>Wed, 25 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Kapil Goswami, Gagan Anekonda Veereshi, Peter Schmelcher, Rick Mukherjee</dc:creator>
    </item>
    <item>
      <title>Reduction from the partition problem: Dynamic lot sizing problem with polynomial complexity</title>
      <link>https://arxiv.org/abs/2412.05017</link>
      <description>arXiv:2412.05017v2 Announce Type: replace-cross 
Abstract: In this note, we polynomially reduce an instance of the partition problem to a dynamic lot sizing problem, and show that solving the latter problem solves the former problem. We show that the instance of the partition problem can be solved using polynomial number of addition, multiplication and sort operations in input data using the reduction. Numerical results on solving instances of the partition problem are also provided using an implementation of the algorithm to solve the dynamic lot sizing problem that is reduced from the instance of the partition problem.</description>
      <guid isPermaLink="false">oai:arXiv.org:2412.05017v2</guid>
      <category>cs.CC</category>
      <category>math.OC</category>
      <pubDate>Wed, 25 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Chee-Khian Sim</dc:creator>
    </item>
  </channel>
</rss>
