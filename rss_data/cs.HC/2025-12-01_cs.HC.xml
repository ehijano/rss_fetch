<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>cs.HC updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/cs.HC</link>
    <description>cs.HC updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/cs.HC" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Tue, 02 Dec 2025 03:43:54 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Mon, 01 Dec 2025 00:00:00 -0500</pubDate>
    <skipDays>
      <day>Sunday</day>
      <day>Saturday</day>
    </skipDays>
    <item>
      <title>When Are Reactive Notebooks Not Reactive?</title>
      <link>https://arxiv.org/abs/2511.21994</link>
      <description>arXiv:2511.21994v1 Announce Type: new 
Abstract: Computational notebooks are convenient for programmers, but can easily become confusing and inconsistent due to the ability to incrementally edit a program that is running. Recent reactive notebook systems, such as Ipyflow, Marimo and Observable, strive to keep notebook state in sync with the current cell code by re-executing a minimal set of cells upon modification. However, each system defines reactivity a different way. Additionally, within any definition, we find simple notebook modifications that can break each system. Overall, these inconsistencies make it difficult for users to construct a mental model of their reactive notebook's implementation. This paper proposes Rex, a fine-grained test suite to discuss and assess reactivity capabilities within reactive notebook systems. We evaluate Rex on three existing reactive notebook systems and classify their failures with the aims of (i) helping programmers understand when reactivity fails and (ii) helping notebook implementations improve.</description>
      <guid isPermaLink="false">oai:arXiv.org:2511.21994v1</guid>
      <category>cs.HC</category>
      <category>cs.PL</category>
      <category>cs.SE</category>
      <pubDate>Mon, 01 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Megan Zheng, Will Crichton, Akshay Narayan, Deepti Raghavan, Nikos Vasilakis</dc:creator>
    </item>
    <item>
      <title>EAST: Environment-Aware Stylized Transition Along the Reality-Virtuality Continuum</title>
      <link>https://arxiv.org/abs/2511.22056</link>
      <description>arXiv:2511.22056v2 Announce Type: new 
Abstract: In the Virtual Reality (VR) gaming industry, maintaining immersion during real-world interruptions remains a challenge, particularly during transitions along the reality-virtuality continuum (RVC). Existing methods tend to rely on digital replicas or simple visual transitions, neglecting to address the aesthetic discontinuities between real and virtual environments, especially in highly stylized VR games. This paper introduces the Environment-Aware Stylized Transition (EAST) framework, which employs a novel style-transferred 3D Gaussian Splatting (3DGS) technique to transfer real-world interruptions into the virtual environment with seamless aesthetic consistency. Rather than merely transforming the real world into game-like visuals, EAST minimizes the disruptive impact of interruptions by integrating real-world elements within the framework. Qualitative user studies demonstrate significant enhancements in cognitive comfort and emotional continuity during transitions, while quantitative experiments highlight EAST's ability to maintain visual coherence across diverse VR styles.</description>
      <guid isPermaLink="false">oai:arXiv.org:2511.22056v2</guid>
      <category>cs.HC</category>
      <pubDate>Mon, 01 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Xiaohan Zhang, Kan Liu, Yangle Liu, Fengze Li, Jieming Ma, Yue Li</dc:creator>
    </item>
    <item>
      <title>Investigating AI in Peer Support via Multi-Module System-Driven Embodied Conversational Agents</title>
      <link>https://arxiv.org/abs/2511.22269</link>
      <description>arXiv:2511.22269v1 Announce Type: new 
Abstract: Young people's mental well-being is a global concern, with peer support playing a key role in daily emotional regulation. Conversational agents are increasingly viewed as promising tools for delivering accessible, personalised peer support, particularly where professional counselling is limited. However, existing systems often suffer from rigid input formats, scripted responses, and limited emotional sensitivity. The emergence of large language models introduces new possibilities for generating flexible, context-aware, and empathetic responses. To explore how individuals with psychological training perceive such systems in peer support contexts, we developed an LLM-based multi-module system to drive embodied conversational agents informed by Cognitive Behavioral Therapy (CBT). In a user study (N=10), we qualitatively examined participants' perceptions, focusing on trust, response quality, workflow integration, and design opportunities for future mental well-being support systems.</description>
      <guid isPermaLink="false">oai:arXiv.org:2511.22269v1</guid>
      <category>cs.HC</category>
      <pubDate>Mon, 01 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Ruoyu Wen, Xiaoli Wu, Kunal Gupta, Simon Hoermann, Mark Billinghurst, Alaeddin Nassani, Dwain Allan, Thammathip Piumsomboon</dc:creator>
    </item>
    <item>
      <title>HandyLabel: Towards Post-Processing to Real-Time Annotation Using Skeleton Based Hand Gesture Recognition</title>
      <link>https://arxiv.org/abs/2511.22337</link>
      <description>arXiv:2511.22337v1 Announce Type: new 
Abstract: The success of machine learning is deeply linked to the availability of high-quality training data, yet retrieving and manually labeling new data remains a time-consuming and error-prone process. Traditional annotation tools, such as Label Studio, often require post-processing, where users label data after it has been recorded. Post-processing is highly time-consuming and labor-intensive, especially with large datasets, and may lead to erroneous annotations due to the difficulty of subjects' memory tasks when labeling cognitive activities such as emotions or comprehension levels. In this work, we introduce HandyLabel, a real-time annotation tool that leverages hand gesture recognition to map hand signs for labeling. The application enables users to customize gesture mappings through a web-based interface, allowing for real-time annotations. To ensure the performance of HandyLabel, we evaluate several hand gesture recognition models on an open-source hand sign (HaGRID) dataset, with and without skeleton-based preprocessing. We discovered that ResNet50 with preprocessed skeleton-based images performs an F1-score of 0.923. To validate the usability of HandyLabel, a user study was conducted with 46 participants. The results suggest that 88.9% of participants preferred HandyLabel over traditional annotation tools.</description>
      <guid isPermaLink="false">oai:arXiv.org:2511.22337v1</guid>
      <category>cs.HC</category>
      <pubDate>Mon, 01 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Sachin Kumar Singh, Ko Watanabe, Brian Moser, Andreas Dengel</dc:creator>
    </item>
    <item>
      <title>Engineering Trustworthy Automation: Design Principles and Evaluation for AutoML Tools for Novices</title>
      <link>https://arxiv.org/abs/2511.22352</link>
      <description>arXiv:2511.22352v1 Announce Type: new 
Abstract: AutoML systems targeting novices often prioritize algorithmic automation over usability, leaving gaps in users' understanding, trust, and end-to-end workflow support. To address these issues, we propose an abstract pipeline that covers data intake, guided configuration, training, evaluation, and inference. To examine the abstract pipeline, we report a user study where we assess trust, understandability, and UX of a prototype implementation. In a 24-participant study, all participants successfully built their own models, UEQ ratings were positive, yet experienced users reported higher trust and understanding than novices. Based on this study, we propose four design principles to improve the design of AutoML systems targeting novices: (P1) support first-model success to enhance user self-efficacy, (P2) provide explanations to help users form correct mental models and develop appropriate levels of reliance, (P3) provide abstractions and context-aware assistance to keep users in their zone of proximal development, and (P4) ensure predictability and safeguards to strengthen users' sense of control.</description>
      <guid isPermaLink="false">oai:arXiv.org:2511.22352v1</guid>
      <category>cs.HC</category>
      <pubDate>Mon, 01 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <dc:creator>Jarne Thys, Davy Vanacken, Gustavo Rovelo Ruiz</dc:creator>
    </item>
    <item>
      <title>MATCH: Engineering Transparent and Controllable Conversational XAI Systems through Composable Building Blocks</title>
      <link>https://arxiv.org/abs/2511.22420</link>
      <description>arXiv:2511.22420v1 Announce Type: new 
Abstract: While the increased integration of AI technologies into interactive systems enables them to solve an increasing number of tasks, the black-box problem of AI models continues to spread throughout the interactive system as a whole. Explainable AI (XAI) techniques can make AI models more accessible by employing post-hoc methods or transitioning to inherently interpretable models. While this makes individual AI models clearer, the overarching system architecture remains opaque. This challenge not only pertains to standard XAI techniques but also to human examination and conversational XAI approaches that need access to model internals to interpret them correctly and completely. To this end, we propose conceptually representing such interactive systems as sequences of structural building blocks. These include the AI models themselves, as well as control mechanisms grounded in literature. The structural building blocks can then be explained through complementary explanatory building blocks, such as established XAI techniques like LIME and SHAP. The flow and APIs of the structural building blocks form an unambiguous overview of the underlying system, serving as a communication basis for both human and automated agents, thus aligning human and machine interpretability of the embedded AI models. In this paper, we present our flow-based approach and a selection of building blocks as MATCH: a framework for engineering Multi-Agent Transparent and Controllable Human-centered systems. This research contributes to the field of (conversational) XAI by facilitating the integration of interpretability into existing interactive systems.</description>
      <guid isPermaLink="false">oai:arXiv.org:2511.22420v1</guid>
      <category>cs.HC</category>
      <category>cs.AI</category>
      <category>cs.LG</category>
      <category>cs.MA</category>
      <pubDate>Mon, 01 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <dc:creator>Sebe Vanbrabant, Gustavo Rovelo Ruiz, Davy Vanacken</dc:creator>
    </item>
    <item>
      <title>A race to belief: How Evidence Accumulation shapes trust in AI and Human informants</title>
      <link>https://arxiv.org/abs/2511.22617</link>
      <description>arXiv:2511.22617v1 Announce Type: new 
Abstract: The integration of artificial intelligence into everyday decision-making has reshaped patterns of selective trust, yet the cognitive mechanisms behind context-dependent preferences for AI versus human informants remain unclear. We applied a Bayesian Hierarchical Sequential Sampling Model (HSSM) to analyze how 102 Colombian university students made trust decisions across 30 epistemic (factual) and social (interpersonal) scenarios.
  Results show that context-dependent trust is primarily driven by differences in drift rate (v), the rate of evidence accumulation, rather than initial bias (z) or response caution (a). Epistemic scenarios produced strong negative drift rates (mean v = -1.26), indicating rapid evidence accumulation favoring AI, whereas social scenarios yielded positive drift rates (mean v = 0.70) favoring humans. Starting points were near neutral (z = 0.52), indicating minimal prior bias.
  Drift rate showed a strong within-subject association with signed confidence (Fisher-z-averaged r = 0.736; 95 percent bootstrap CI 0.699 to 0.766; 97.8 percent of individual correlations positive, N = 93), suggesting that model-derived evidence accumulation closely mirrors participants' moment-to-moment confidence. These dynamics may help explain the fragility of AI trust: in epistemic domains, rapid but low-vigilance evidence processing may promote uncalibrated reliance on AI that collapses quickly after errors.
  Interpreted through epistemic vigilance theory, the results indicate that domain-specific vigilance mechanisms modulate evidence accumulation. The findings inform AI governance by highlighting the need for transparency features that sustain vigilance without sacrificing efficiency, offering a mechanistic account of selective trust in human-AI collaboration.</description>
      <guid isPermaLink="false">oai:arXiv.org:2511.22617v1</guid>
      <category>cs.HC</category>
      <pubDate>Mon, 01 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Johan Sebasti\'an Galindez-Acosta, Juan Jos\'e Giraldo-Huertas</dc:creator>
    </item>
    <item>
      <title>Epistemic Fragility in Large Language Models: Prompt Framing Systematically Modulates Misinformation Correction</title>
      <link>https://arxiv.org/abs/2511.22746</link>
      <description>arXiv:2511.22746v1 Announce Type: new 
Abstract: As large language models (LLMs) rapidly displace traditional expertise, their capacity to correct misinformation has become a core concern. We investigate the idea that prompt framing systematically modulates misinformation correction - something we term 'epistemic fragility'. We manipulated prompts by open-mindedness, user intent, user role, and complexity. Across ten misinformation domains, we generated 320 prompts and elicited 2,560 responses from four frontier LLMs, which were coded for strength of misinformation correction and rectification strategy use. Analyses showed that creative intent, expert role, and closed framing led to a significant reduction in correction likelihood and effectiveness of used strategy. We also found striking model differences: Gemini 2.5 Pro had 74% lower odds of strong correction than Claude Sonnet 4.5. These findings highlight epistemic fragility as an important structural property of LLMs, challenging current guardrails and underscoring the need for alignment strategies that prioritize epistemic integrity over conversational compliance.</description>
      <guid isPermaLink="false">oai:arXiv.org:2511.22746v1</guid>
      <category>cs.HC</category>
      <pubDate>Mon, 01 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Sekoul Krastev, Hilary Sweatman, Anni Sternisko, Steve Rathje</dc:creator>
    </item>
    <item>
      <title>Learning Programming in Informal Spaces: Using Emotion as a Lens to Understand Novice Struggles on r/learnprogramming</title>
      <link>https://arxiv.org/abs/2511.22789</link>
      <description>arXiv:2511.22789v1 Announce Type: new 
Abstract: Novice programmers experience emotional difficulties in informal online learning environments, where confusion and frustration can hinder motivation and learning outcomes. This study investigates novice programmers' emotional experiences in informal settings, identifies the causes of emotional struggle, and explores design opportunities for affect-aware support systems. We manually annotated 1,500 posts from r/learnprogramming using the Learning-Centered Emotions framework and conducted clustering and axial coding. Confusion, curiosity, and frustration were the most common emotions, often co-occurring and associated with early learning stages. Positive emotions were relatively rare. The primary emotional triggers included ambiguous errors, unclear learning pathways, and misaligned learning resources. We identify five key areas where novice programmers need support in informal learning spaces: stress relief and resilient motivation, topic explanation and resource recommendation, strategic decision-making and learning guidance, technical support, and acknowledgment of their challenges. Our findings highlight the need for intelligent, affect-sensitive mechanisms that provide timely support aligned with learners' emotional states.</description>
      <guid isPermaLink="false">oai:arXiv.org:2511.22789v1</guid>
      <category>cs.HC</category>
      <category>cs.SE</category>
      <pubDate>Mon, 01 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Alif Al Hasan, Subarna Saha, Mia Mohammad Imran</dc:creator>
    </item>
    <item>
      <title>AI summaries in online search influence users' attitudes</title>
      <link>https://arxiv.org/abs/2511.22809</link>
      <description>arXiv:2511.22809v1 Announce Type: new 
Abstract: This study examined how AI-generated summaries, which have become visually prominent in online search results, affect how users think about different issues. In a preregistered randomized controlled experiment, participants (N = 2,004) viewed mock search result pages varying in the presence (vs. absence), placement (top vs. middle), and stance (benefit-framed vs. harm-framed) of AI-generated summaries across four publicly debated topics. Compared to a no-summary control group, participants exposed to AI-generated summaries reported issue attitudes, behavioral intentions, and policy support that aligned more closely with the AI summary stance. The summaries placed at the top of the page produced stronger shifts in users' issue attitudes (but not behavioral intentions or policy support) than those placed at the middle of the page. We also observed moderating effects from issue familiarity and general trust toward AI. In addition, users perceived the AI summaries more useful when it emphasized health harms versus benefits. These findings suggest that AI-generated search summaries can significantly shape public perceptions, raising important implications for the design and regulation of AI-integrated information ecosystems.</description>
      <guid isPermaLink="false">oai:arXiv.org:2511.22809v1</guid>
      <category>cs.HC</category>
      <category>cs.AI</category>
      <category>cs.CY</category>
      <pubDate>Mon, 01 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Yiwei Xu, Saloni Dash, Sungha Kang, Wang Liao, Emma S. Spiro</dc:creator>
    </item>
    <item>
      <title>Body Management Information Practices on a Female-dominant Platform</title>
      <link>https://arxiv.org/abs/2511.22942</link>
      <description>arXiv:2511.22942v1 Announce Type: new 
Abstract: With growing awareness of long-term health and wellness, everyday body management has become a widespread practice. Social media platforms and health-related applications offer abundant information for those pursuing healthier lifestyles and more positive body images. While prior Human-Computer Interaction research has focused extensively on technology-mediated health interventions, the user-initiated practices of browsing and evaluating body management information remain underexplored. In this paper, we study a female-dominant social media platform in China to examine how users seek such information and how it shapes their lifestyle choices. Through semi-structured interviews with 18 users, we identify factors including consumerism, poster popularity, and perceived authenticity that influence decision-making, alongside challenges such as discerning reliable methods and managing body anxiety triggered by social media. We contribute insights into how content and media formats interact to shape users' information evaluation, and we outline design implications for supporting more reliable and healthy engagements with body management information.</description>
      <guid isPermaLink="false">oai:arXiv.org:2511.22942v1</guid>
      <category>cs.HC</category>
      <pubDate>Mon, 01 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Na Li, Chuhao Wu, Hongyang Zhou, Huiran Yi, Xuefei Wang, Jie Cai, Xinyi Fu, John Carroll</dc:creator>
    </item>
    <item>
      <title>Robust In-the-Wild Exercise Recognition from a Single Wearable: Data-Side Fusion, Sensor Rotation, and Feature Engineering</title>
      <link>https://arxiv.org/abs/2511.23173</link>
      <description>arXiv:2511.23173v1 Announce Type: new 
Abstract: Monitoring physical exercises is vital for health promotion, with automated systems becoming standard in personal health surveillance. However, sensor placement variability and unconstrained movements limit their effectiveness. This study proposes the team "3KA"'s one-sensor workout activity recognition method using feature extraction and data augmentation in 2ndWEAR Dataset Challenge. From raw acceleration, angle and signal magnitude vector features were derived, followed by extraction of statistical, fractal/spectral, and higher-order differential features. A fused dataset combining left/right limb data was created, and augmented via sensor rotation and axis inversion. We utilized a soft voting model combining Hist Gradient Boosting with balanced weights and Extreme Gradient Boosting without. Under group 5-fold evaluation, the model achieved 58.83\% macro F1 overall (61.72% arm, 55.95% leg). ANOVA F-score showed fractal/spectral features were most important for arm-based recognition but least for leg-based. The code to reproduce the experiments is publicly available via: https://github.com/Khanghcmut/WEAR\_3K</description>
      <guid isPermaLink="false">oai:arXiv.org:2511.23173v1</guid>
      <category>cs.HC</category>
      <pubDate>Mon, 01 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <arxiv:DOI>10.1145/3714394.3756193</arxiv:DOI>
      <dc:creator>Hoang Khang Phan, Khang Le, Tu Nhat Khang Nguyen, Anh Van Dao, Nhat Tan Le</dc:creator>
    </item>
    <item>
      <title>Can Intelligent User Interfaces Engage in Philosophical Discussions? A Longitudinal Study of Philosophers' Evolving Perceptions</title>
      <link>https://arxiv.org/abs/2511.23188</link>
      <description>arXiv:2511.23188v1 Announce Type: new 
Abstract: This study investigates the evolving attitudes of philosophy scholars towards the participation of generative AI based Intelligent User Interfaces (IUIs) in philosophical discourse. We conducted a three year (2023--2025) mixed methods longitudinal study with 16 philosophy scholars and students. Qualitative data from annual interviews reveal a three stage evolution in attitude: from initial resistance and unfamiliarity, to instrumental acceptance of the IUI as a tool, and finally to a deep principled questioning of the IUI's fundamental capacity for genuine philosophical thought. Quantitative data from blind assessments, where participants rated anonymized philosophical answers from both humans and an IUI, complement these findings. While participants acknowledged the IUI's proficiency in tasks requiring formal logic and knowledge reproduction, they consistently identified significant shortcomings in areas demanding dialectical reasoning, originality and embodied understanding. The study concludes that participants do not see the IUI as a peer but rather as a sophisticated mirror whose capabilities and limitations provoke a deeper reflection on the unique and irreplaceable human dimensions of philosophical inquiry, such as intuition, value laden commitment and the courage to question fundamental premises.</description>
      <guid isPermaLink="false">oai:arXiv.org:2511.23188v1</guid>
      <category>cs.HC</category>
      <pubDate>Mon, 01 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Yibo Meng, Lyumanshan Ye, Eve He, Zhe Yan, Zhiming Liu, Yipeng Yu, Yan Guan, Xiaolan Ding</dc:creator>
    </item>
    <item>
      <title>Is Passive Expertise-Based Personalization Enough? A Case Study in AI-Assisted Test-Taking</title>
      <link>https://arxiv.org/abs/2511.23376</link>
      <description>arXiv:2511.23376v1 Announce Type: new 
Abstract: Novice and expert users have different systematic preferences in task-oriented dialogues. However, whether catering to these preferences actually improves user experience and task performance remains understudied. To investigate the effects of expertise-based personalization, we first built a version of an enterprise AI assistant with passive personalization. We then conducted a user study where participants completed timed exams, aided by the two versions of the AI assistant. Preliminary results indicate that passive personalization helps reduce task load and improve assistant perception, but reveal task-specific limitations that can be addressed through providing more user agency. These findings underscore the importance of combining active and passive personalization to optimize user experience and effectiveness in enterprise task-oriented environments.</description>
      <guid isPermaLink="false">oai:arXiv.org:2511.23376v1</guid>
      <category>cs.HC</category>
      <category>cs.CL</category>
      <pubDate>Mon, 01 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Li Siyan, Jason Zhang, Akash Maharaj, Yuanming Shi, Yunyao Li</dc:creator>
    </item>
    <item>
      <title>AugGen: Augmenting Task-Based Learning in Professional Creative Software with LLM-Generated Scaffolded UIs</title>
      <link>https://arxiv.org/abs/2511.23379</link>
      <description>arXiv:2511.23379v1 Announce Type: new 
Abstract: Professional creative software often presents steep learning curves due to complex interfaces, lack of structured task-aware guidance, and unfamiliar domain terminology. To address these challenges and augment user learning experience, we introduce AugGen, a method for generating scaffolded user interfaces that simplify interface complexity and support task-based learning. With the user's task, our method surfaces task-relevant tools to reduce distracting features, organizes the tools around task workflow stages to offer execution guidance, connects tools with domain concepts to foster learning engagement, and progressively discloses advanced features to manage learning progress. To evaluate the method, we used our LLM-assisted pipeline to generate two task-specific scaffolded UIs and deployed them in Blender, our professional 3D modeling testbed. We invited both beginner (N=32) and expert (N=8) users to evaluate our implemented interfaces. Results show that the scaffolded interfaces significantly reduced user-perceived task load, enhanced task performance via embedded guidance, and augmented concept learning during task execution.</description>
      <guid isPermaLink="false">oai:arXiv.org:2511.23379v1</guid>
      <category>cs.HC</category>
      <pubDate>Mon, 01 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Yimeng Liu, Misha Sra</dc:creator>
    </item>
    <item>
      <title>Improving motor imagery decoding methods for an EEG-based mobile brain-computer interface in the context of the 2024 Cybathlon</title>
      <link>https://arxiv.org/abs/2511.23384</link>
      <description>arXiv:2511.23384v2 Announce Type: new 
Abstract: Motivated by the Cybathlon 2024 competition, we developed a modular, online EEG-based brain-computer interface to address these challenges, increasing accessibility for individuals with severe mobility impairments. Our system uses three mental and motor imagery classes to control up to five control signals. The pipeline consists of four modules: data acquisition, preprocessing, classification, and the transfer function to map classification output to control dimensions. We use three diagonalized structured state-space sequence layers as a deep learning classifier. We developed a training game for our pilot where the mental tasks control the game during quick-time events. We implemented a mobile web application for live user feedback. The components were designed with a human-centred approach in collaboration with the tetraplegic user. We achieve up to 84% classification accuracy in offline analysis using an S4D-layer-based model. In a competition setting, our pilot successfully completed one task; we attribute the reduced performance in this context primarily to factors such as stress and the challenging competition environment. Following the Cybathlon, we further validated our pipeline with the original pilot and an additional participant, achieving a success rate of 73% in real-time gameplay. We also compare our model to the EEGEncoder, which is slower in training but has a higher performance. The S4D model outperforms the reference machine learning models. We provide insights into developing a framework for portable BCIs, bridging the gap between the laboratory and daily life. Specifically, our framework integrates modular design, real-time data processing, user-centred feedback, and low-cost hardware to deliver an accessible and adaptable BCI solution, addressing critical gaps in current BCI applications.</description>
      <guid isPermaLink="false">oai:arXiv.org:2511.23384v2</guid>
      <category>cs.HC</category>
      <pubDate>Mon, 01 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Isabel Whiteley Tscherniak, Niels Christopher Thiemann, Ana McWhinnie-Fern\'andez, Iustin Curcean, Leon Jokinen, Sadat Hodzic, Thomas E. Huber, Daniel Pavlov, Manuel Methasani, Pietro Marcolongo, Glenn Viktor Krafczyk, Oscar Osvaldo Soto Rivera, Thien Le, Flaminia Pallotti, Enrico A. Fazzi, neuroTUM e. V</dc:creator>
    </item>
    <item>
      <title>SoftNash: Entropy-Regularized Nash Games for Non-Fighting Virtual Fixtures</title>
      <link>https://arxiv.org/abs/2511.22087</link>
      <description>arXiv:2511.22087v1 Announce Type: cross 
Abstract: Virtual fixtures (VFs) improve precision in teleoperation but often ``fight'' the user, inflating mental workload and eroding the sense of agency. We propose Soft-Nash Virtual Fixtures, a game-theoretic shared-control policy that softens the classic two-player linear-quadratic (LQ) Nash solution by inflating the fixture's effort weight with a single, interpretable scalar parameter $\tau$. This yields a continuous dial on controller assertiveness: $\tau=0$ recovers a hard, performance-focused Nash / virtual fixture controller, while larger $\tau$ reduce gains and pushback, yet preserve the equilibrium structure and continuity of closed-loop stability. We derive Soft-Nash from both a KL-regularized trust-region and a maximum-entropy viewpoint, obtaining a closed-form robot best response that shrinks authority and aligns the fixture with the operator's input as $\tau$ grows. We implement Soft-Nash on a 6-DoF haptic device in 3D tracking task ($n=12$). Moderate softness ($\tau\approx 1-3$, especially $\tau=2$) maintains tracking error statistically indistinguishable from a tuned classic VF while sharply reducing controller-user conflict, lowering NASA-TLX workload, and increasing Sense of Agency (SoAS). A composite BalancedScore that combines normalized accuracy and non-fighting behavior peaks near $\tau=2-3$. These results show that a one-parameter Soft-Nash policy can preserve accuracy while improving comfort and perceived agency, providing a practical and interpretable pathway to personalized shared control in haptics and teleoperation.</description>
      <guid isPermaLink="false">oai:arXiv.org:2511.22087v1</guid>
      <category>cs.RO</category>
      <category>cs.HC</category>
      <pubDate>Mon, 01 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Tai Inui, Jee-Hwan Ryu</dc:creator>
    </item>
    <item>
      <title>GazeTrack: High-Precision Eye Tracking Based on Regularization and Spatial Computing</title>
      <link>https://arxiv.org/abs/2511.22607</link>
      <description>arXiv:2511.22607v1 Announce Type: cross 
Abstract: Eye tracking has become increasingly important in virtual and augmented reality applications; however, the current gaze accuracy falls short of meeting the requirements for spatial computing. We designed a gaze collection framework and utilized high-precision equipment to gather the first precise benchmark dataset, GazeTrack, encompassing diverse ethnicities, ages, and visual acuity conditions for pupil localization and gaze tracking. We propose a novel shape error regularization method to constrain pupil ellipse fitting and train on open-source datasets, enhancing semantic segmentation and pupil position prediction accuracy. Additionally, we invent a novel coordinate transformation method similar to paper unfolding to accurately predict gaze vectors on the GazeTrack dataset. Finally, we built a gaze vector generation model that achieves reduced gaze angle error with lower computational complexity compared to other methods.</description>
      <guid isPermaLink="false">oai:arXiv.org:2511.22607v1</guid>
      <category>cs.CV</category>
      <category>cs.AI</category>
      <category>cs.HC</category>
      <category>cs.LG</category>
      <pubDate>Mon, 01 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Xiaoyin Yang</dc:creator>
    </item>
    <item>
      <title>Agentic AI Framework for Individuals with Disabilities and Neurodivergence: A Multi-Agent System for Healthy Eating, Daily Routines, and Inclusive Well-Being</title>
      <link>https://arxiv.org/abs/2511.22737</link>
      <description>arXiv:2511.22737v1 Announce Type: cross 
Abstract: The paper presents a detailed Agentic Artificial Intelligence (AI) model that would enable people with disabilities and neurodivergence to lead healthier lives and have more regular days. The system will use a multi-layer structure; it will include an Application and Interface Layer, an Agents Layer, and a Data Source Layer to provide adaptive, transparent, and inclusive support. Fundamentally, a hybrid reasoning engine will synchronize four special-purpose agents, which include: a personalized-nutrition-based, called a Meal Planner Agent; an adaptive-scheduling-based, called a Reminder Agent; interactive assistance during grocery shopping and cooking, called a Food Guidance Agent; and a continuous-intake-and-physiological-tracking, called a Monitoring Agent. All the agents interact through a central communicative system called the Blackboard/Event Bus, which allows autonomous interaction and real-time feedback loops with multimedia user interfaces. Privacy-sensitive data sources, including electronic health records (EHRs), nutritional databases, wearable sensors, and smart kitchen Internet of Things, are also included in the framework and placed into a policy-controlled layer, which ensures data safety and compliance with consent. Collaborative care and clinician dashboards allow common supervision, and discussable artificial intelligence (XAI) modules give brief explanations of why a decision was made, making users responsible and reliant. The proposed agentic AI framework is an extension beyond traditional assistive systems since it incorporates inclusiveness, personalization, and accessibility at all levels. It displays the intersection of multi-agent reasoning, multi-modal interfaces, and human-centered design that will enable the development of autonomy, health, and digital equity among people with disabilities and neurodivergence.</description>
      <guid isPermaLink="false">oai:arXiv.org:2511.22737v1</guid>
      <category>cs.AI</category>
      <category>cs.HC</category>
      <pubDate>Mon, 01 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Salman Jan, Toqeer Ali Syed, Gohar Ali, Ali Akarma, Mohammad Riyaz Belgaum, Ahmad Ali</dc:creator>
    </item>
    <item>
      <title>Safe Autonomous Lane Changing: Planning with Dynamic Risk Fields and Time-Varying Convex Space Generation</title>
      <link>https://arxiv.org/abs/2511.22829</link>
      <description>arXiv:2511.22829v1 Announce Type: cross 
Abstract: This paper presents a novel trajectory planning pipeline for complex driving scenarios like autonomous lane changing, by integrating risk-aware planning with guaranteed collision avoidance into a unified optimization framework. We first construct a dynamic risk fields (DRF) that captures both the static and dynamic collision risks from surrounding vehicles. Then, we develop a rigorous strategy for generating time-varying convex feasible spaces that ensure kinematic feasibility and safety requirements. The trajectory planning problem is formulated as a finite-horizon optimal control problem and solved using a constrained iterative Linear Quadratic Regulator (iLQR) algorithm that jointly optimizes trajectory smoothness, control effort, and risk exposure while maintaining strict feasibility. Extensive simulations demonstrate that our method outperforms traditional approaches in terms of safety and efficiency, achieving collision-free trajectories with shorter lane-changing distances (28.59 m) and times (2.84 s) while maintaining smooth and comfortable acceleration patterns. In dense roundabout environments the planner further demonstrates robust adaptability, producing larger safety margins, lower jerk, and superior curvature smoothness compared with APF, MPC, and RRT based baselines. These results confirm that the integrated DRF with convex feasible space and constrained iLQR solver provides a balanced solution for safe, efficient, and comfortable trajectory generation in dynamic and interactive traffic scenarios.</description>
      <guid isPermaLink="false">oai:arXiv.org:2511.22829v1</guid>
      <category>cs.RO</category>
      <category>cs.HC</category>
      <pubDate>Mon, 01 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Zhen Tian, Zhihao Lin</dc:creator>
    </item>
    <item>
      <title>Amplifiers or Equalizers? A Longitudinal Study of LLM Evolution in Software Engineering Project-Based Learning</title>
      <link>https://arxiv.org/abs/2511.23157</link>
      <description>arXiv:2511.23157v1 Announce Type: cross 
Abstract: As LLMs reshape software development, integrating LLM-augmented practices into SE education has become imperative. While existing studies explore LLMs' educational use in introductory programming or isolated SE tasks, their impact in more open-ended Project-Based Learning (PBL) remains unexplored. This paper introduces a two-year longitudinal study comparing a 2024 (using early free LLMs, $n$=48) and 2025 (using the latest paid LLMs, $n$=46) cohort. Our findings suggest the latest powerful LLMs' dual role: they act as "equalizers," boosting average performance even for programming-weak students, providing opportunities for more authentic SE practices; yet also as "amplifiers," dramatically widening absolute performance gaps, creating new pedagogical challenges for addressing educational inequities.</description>
      <guid isPermaLink="false">oai:arXiv.org:2511.23157v1</guid>
      <category>cs.SE</category>
      <category>cs.HC</category>
      <pubDate>Mon, 01 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Hana Kataoka, Jialong Li, Yutaka Matsuno</dc:creator>
    </item>
    <item>
      <title>Quantifying the Privacy-Utility Trade-off in GPS-based Daily Stress Recognition using Semantic Features</title>
      <link>https://arxiv.org/abs/2511.23200</link>
      <description>arXiv:2511.23200v1 Announce Type: cross 
Abstract: Psychological stress is a widespread issue that significantly impacts student well-being and academic performance. Effective remote stress recognition is crucial, yet existing methods often rely on wearable devices or GPS-based clustering techniques that pose privacy risks. In this study, we introduce a novel, end-to-end privacy-enhanced framework for semantic location encoding using a self-hosted OSM engine and an LLM-bootstrapped static map. We rigorously quantify the privacy-utility trade-off and demonstrate (via LOSO validation) that our Privacy-Aware (PA) model achieves performance statistically indistinguishable from a non-private model, proving that utility does not require sacrificing privacy. Feature importance analysis highlights that recreational activity time, working time, and travel time play a significant role in stress recognition.</description>
      <guid isPermaLink="false">oai:arXiv.org:2511.23200v1</guid>
      <category>cs.CR</category>
      <category>cs.HC</category>
      <pubDate>Mon, 01 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Hoang Khang Phan, Nhat Tan Le</dc:creator>
    </item>
    <item>
      <title>Exploring the Human-LLM Synergy in Advancing Theory-driven Qualitative Analysis</title>
      <link>https://arxiv.org/abs/2405.05758</link>
      <description>arXiv:2405.05758v2 Announce Type: replace 
Abstract: Qualitative coding is a demanding yet crucial research method in the field of Human-Computer Interaction (HCI). While recent studies have shown the capability of large language models (LLMs) to perform qualitative coding within theoretical frameworks, their potential for collaborative human-LLM discovery and generation of new insights beyond initial theory remains underexplored. To bridge this gap, we proposed CHALET, a novel approach that harnesses the power of human-LLM partnership to advance theory-driven qualitative analysis by facilitating iterative coding, disagreement analysis, and conceptualization of qualitative data. We demonstrated CHALET's utility by applying it to the qualitative analysis of conversations related to mental-illness stigma, using the attribution model as the theoretical framework. Results highlighted the unique contribution of human-LLM collaboration in uncovering latent themes of stigma across the cognitive, emotional, and behavioral dimensions. We discuss the methodological implications of the human-LLM collaborative approach to theory-based qualitative analysis for the HCI community and beyond.</description>
      <guid isPermaLink="false">oai:arXiv.org:2405.05758v2</guid>
      <category>cs.HC</category>
      <category>cs.CL</category>
      <category>cs.CY</category>
      <pubDate>Mon, 01 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Han Meng, Yitian Yang, Wayne Fu, Jungup Lee, Yunan Li, Yi-Chieh Lee</dc:creator>
    </item>
    <item>
      <title>Colin: A Multimodal Human-AI Co-Creation Storytelling System To Support Children's Multi-Level Narrative Skills</title>
      <link>https://arxiv.org/abs/2405.06495</link>
      <description>arXiv:2405.06495v5 Announce Type: replace 
Abstract: Children develop narrative skills by understanding and actively building connections between elements, image text matching, and consequences. However, it is challenging for children to clearly grasp these multi level links only through explanations of text or the facilitator's speech. To address this, we developed Colin, an interactive storytelling tool that supports children's multi level narrative skills through both voice and visual modalities. In the generation stage, Colin supports the facilitator to define and review the generated text and image content freely. In the understanding stage, a question feedback model helps children understand multi level connections while co creating stories with Colin. In the building phase, Colin actively encourages children to create connections between elements through drawing and speaking. A user study with 20 participants evaluated Colin by measuring children's engagement, understanding of cause and effect relationships, and the quality of their new story creations. Our results demonstrate that Colin significantly enhances the development of children's narrative skills across multiple levels.</description>
      <guid isPermaLink="false">oai:arXiv.org:2405.06495v5</guid>
      <category>cs.HC</category>
      <pubDate>Mon, 01 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <arxiv:DOI>10.1145/3706599.3719837</arxiv:DOI>
      <dc:creator>Lyumanshan Ye, Jiandong Jiang, Yuhan Liu, Yihan Ran, Yufan Zhou, Zhao Wang, Yipeng Yu, Pengfei Liu, Danni Chang, Yucheng Jin</dc:creator>
    </item>
    <item>
      <title>Biased by Design: Leveraging AI Biases to Enhance Critical Thinking of News Readers</title>
      <link>https://arxiv.org/abs/2504.14522</link>
      <description>arXiv:2504.14522v4 Announce Type: replace 
Abstract: This paper explores the design of a propaganda detection tool using Large Language Models (LLMs). Acknowledging the inherent biases in AI models, especially in political contexts, we investigate how these biases might be leveraged to enhance critical thinking in news consumption. Countering the typical view of AI biases as detrimental, our research proposes strategies of user choice and personalization in response to a user's political stance, applying psychological concepts of confirmation bias and cognitive dissonance. We present findings from a qualitative user study, offering insights and design recommendations (bias awareness, personalization and choice, and gradual introduction of diverse perspectives) for AI tools in propaganda detection.</description>
      <guid isPermaLink="false">oai:arXiv.org:2504.14522v4</guid>
      <category>cs.HC</category>
      <category>cs.AI</category>
      <pubDate>Mon, 01 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Liudmila Zavolokina, Kilian Sprenkamp, Zoya Katashinskaya, Daniel Gordon Jones</dc:creator>
    </item>
    <item>
      <title>F.A.C.U.L.: Language-Based Interaction with AI Companions in Gaming</title>
      <link>https://arxiv.org/abs/2511.13112</link>
      <description>arXiv:2511.13112v2 Announce Type: replace 
Abstract: In cooperative video games, traditional AI companions are deployed to assist players, who control them using hotkeys or command wheels to issue predefined commands such as ``attack'', ``defend'', or ``retreat''. Despite their simplicity, these methods, which lack target specificity, limit players' ability to give complex tactical instructions and hinder immersive gameplay experiences. To address this problem, we propose the FPS AI Companion who Understands Language (F.A.C.U.L.), the first real-time AI system that enables players to communicate and collaborate with AI companions using natural language. By integrating natural language processing with a confidence-based framework, F.A.C.U.L. efficiently decomposes complex commands and interprets player intent. It also employs a dynamic entity retrieval method for environmental awareness, aligning human intentions with decision-making. Unlike traditional rule-based systems, our method supports real-time language interactions, enabling players to issue complex commands such as ``clear the second floor'', ``take cover behind that tree'', or ``retreat to the river''. The system provides real-time behavioral responses and vocal feedback, ensuring seamless tactical collaboration. Using the popular FPS game \textit{Arena Breakout: Infinite} as a case study, we present comparisons demonstrating the efficacy of our approach and discuss the advantages and limitations of AI companions based on real-world user feedback.</description>
      <guid isPermaLink="false">oai:arXiv.org:2511.13112v2</guid>
      <category>cs.HC</category>
      <pubDate>Mon, 01 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Wenya Wei (Tencent Games, Shenzhen, China), Sipeng Yang (Zhejiang University, Hangzhou, China), Qixian Zhou (Tencent Games, Shenzhen, China), Ruochen Liu (Tencent Games, Shenzhen, China), Xuelei Zhang (Tencent Games, Shenzhen, China), Yifu Yuan (Tencent AI Lab, Shenzhen, China), Yan Jiang (Tencent Games, Shenzhen, China), Yongle Luo (Tencent Games, Shenzhen, China), Hailong Wang (Tencent Games, Shenzhen, China), Tianzhou Wang (Tencent Games, Shenzhen, China), Peipei Jin (Tencent Games, Shenzhen, China), Wangtong Liu (Tencent Games, Shenzhen, China), Zhou Zhao (Zhejiang University, Hangzhou, China), Xiaogang Jin (Zhejiang University, Hangzhou, China), Elvis S. Liu (Tencent Games, Shenzhen, China)</dc:creator>
    </item>
    <item>
      <title>Reranking partisan animosity in algorithmic social media feeds alters affective polarization</title>
      <link>https://arxiv.org/abs/2411.14652</link>
      <description>arXiv:2411.14652v2 Announce Type: replace-cross 
Abstract: Today, social media platforms hold sole power to study the effects of feed ranking algorithms. We developed a platform-independent method that reranks participants' feeds in real-time and used this method to conduct a preregistered 10-day field experiment with 1,256 participants on X during the 2024 U.S. presidential campaign. Our experiment used a large language model to rerank posts that expressed antidemocratic attitudes and partisan animosity (AAPA). Decreasing or increasing AAPA exposure shifted out-party partisan animosity by two points on a 100-point feeling thermometer, with no detectable differences across party lines, providing causal evidence that exposure to AAPA content alters affective polarization. This work establishes a method to study feed algorithms without requiring platform cooperation, enabling independent evaluation of ranking interventions in naturalistic settings.</description>
      <guid isPermaLink="false">oai:arXiv.org:2411.14652v2</guid>
      <category>cs.CY</category>
      <category>cs.AI</category>
      <category>cs.HC</category>
      <category>cs.SI</category>
      <pubDate>Mon, 01 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <arxiv:DOI>10.1126/science.adu5584</arxiv:DOI>
      <arxiv:journal_reference>Science; Volume 390 | Issue 6776; 27 November 2025</arxiv:journal_reference>
      <dc:creator>Tiziano Piccardi, Martin Saveski, Chenyan Jia, Jeffrey T. Hancock, Jeanne L. Tsai, Michael Bernstein</dc:creator>
    </item>
    <item>
      <title>Integrating Semantic Communication and Human Decision-Making into an End-to-End Sensing-Decision Framework</title>
      <link>https://arxiv.org/abs/2412.05103</link>
      <description>arXiv:2412.05103v3 Announce Type: replace-cross 
Abstract: As early as 1949, Weaver defined communication in a very broad sense to include all procedures by which one mind or technical system can influence another, thus establishing the idea of semantic communication. With the recent success of machine learning in expert assistance systems where sensed information is wirelessly provided to a human to assist task execution, the need to design effective and efficient communications has become increasingly apparent. In particular, semantic communication aims to convey the meaning behind the sensed information relevant for Human Decision-Making (HDM). Regarding the interplay between semantic communication and HDM, many questions remain, such as how to model the entire end-to-end sensing-decision-making process, how to design semantic communication for the HDM and which information should be provided for HDM. To address these questions, we propose to integrate semantic communication and HDM into one probabilistic end-to-end sensing-decision framework that bridges communications and psychology. In our interdisciplinary framework, we model the human through a HDM process, allowing us to explore how feature extraction from semantic communication can best support HDM both in theory and in simulations. In this sense, our study reveals the fundamental design trade-off between maximizing the relevant semantic information and matching the cognitive capabilities of the HDM model. Our initial analysis shows how semantic communication can balance the level of detail with human cognitive capabilities while demanding less bandwidth, power, and latency.</description>
      <guid isPermaLink="false">oai:arXiv.org:2412.05103v3</guid>
      <category>eess.SP</category>
      <category>cs.HC</category>
      <category>cs.LG</category>
      <pubDate>Mon, 01 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Edgar Beck, Hsuan-Yu Lin, Patrick R\"uckert, Yongping Bao, Bettina von Helversen, Sebastian Fehrler, Kirsten Tracht, Armin Dekorsy</dc:creator>
    </item>
    <item>
      <title>Interactive Groupwise Comparison for Reinforcement Learning from Human Feedback</title>
      <link>https://arxiv.org/abs/2507.04340</link>
      <description>arXiv:2507.04340v2 Announce Type: replace-cross 
Abstract: Reinforcement learning from human feedback (RLHF) has emerged as a key enabling technology for aligning AI behaviour with human preferences. The traditional way to collect data in RLHF is via pairwise comparisons: human raters are asked to indicate which one of two samples they prefer. We present an interactive visualisation that better exploits the human visual ability to compare and explore whole groups of samples. The interface is comprised of two linked views: 1) an exploration view showing a contextual overview of all sampled behaviours organised in a hierarchical clustering structure; and 2) a comparison view displaying two selected groups of behaviours for user queries. Users can efficiently explore large sets of behaviours by iterating between these two views. Additionally, we devised an active learning approach suggesting groups for comparison. As shown by our evaluation in six simulated robotics tasks, our approach increases the final rewards by 69.34%. It leads to lower error rates and better policies. We open-source the code that can be easily integrated into the RLHF training loop, supporting research on human-AI alignment.</description>
      <guid isPermaLink="false">oai:arXiv.org:2507.04340v2</guid>
      <category>cs.LG</category>
      <category>cs.HC</category>
      <pubDate>Mon, 01 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <arxiv:DOI>10.1111/cgf.70290</arxiv:DOI>
      <dc:creator>Jan Kompatscher, Danqing Shi, Giovanna Varni, Tino Weinkauf, Antti Oulasvirta</dc:creator>
    </item>
    <item>
      <title>Human-AI Programming Role Optimization: Developing a Personality-Driven Self-Determination Framework</title>
      <link>https://arxiv.org/abs/2511.00417</link>
      <description>arXiv:2511.00417v2 Announce Type: replace-cross 
Abstract: As artificial intelligence transforms software development, a critical question emerges: how can developers and AI systems collaborate most effectively? This dissertation optimizes human-AI programming roles through self-determination theory and personality psychology, introducing the Role Optimization Motivation Alignment (ROMA) framework.
  Through Design Science Research spanning five cycles, this work establishes empirically-validated connections between personality traits, programming role preferences, and collaborative outcomes, engaging 200 experimental participants and 46 interview respondents.
  Key findings demonstrate that personality-driven role optimization significantly enhances self-determination and team dynamics, yielding 23% average motivation increases among professionals and up to 65% among undergraduates. Five distinct personality archetypes emerge: The Explorer (high Openness/low Agreeableness), The Orchestrator (high Extraversion/Agreeableness), The Craftsperson (high Neuroticism/low Extraversion), The Architect (high Conscientiousness), and The Adapter (balanced profile). Each exhibits distinct preferences for programming roles (Co-Pilot, Co-Navigator, Agent), with assignment modes proving crucial for satisfaction.
  The dissertation contributes: (1) an empirically-validated framework linking personality traits to role preferences and self-determination outcomes; (2) a taxonomy of AI collaboration modalities mapped to personality profiles while preserving human agency; and (3) an ISO/IEC 29110 extension enabling Very Small Entities to implement personality-driven role optimization within established standards.
  Keywords: artificial intelligence, human-computer interaction, behavioral software engineering, self-determination theory, personality psychology, phenomenology, intrinsic motivation, pair programming, design science research, ISO/IEC 29110</description>
      <guid isPermaLink="false">oai:arXiv.org:2511.00417v2</guid>
      <category>cs.SE</category>
      <category>cs.AI</category>
      <category>cs.HC</category>
      <pubDate>Mon, 01 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Marcel Valovy</dc:creator>
    </item>
    <item>
      <title>Mina: A Multilingual LLM-Powered Legal Assistant Agent for Bangladesh for Empowering Access to Justice</title>
      <link>https://arxiv.org/abs/2511.08605</link>
      <description>arXiv:2511.08605v2 Announce Type: replace-cross 
Abstract: Bangladesh's low-income population faces major barriers to affordable legal advice due to complex legal language, procedural opacity, and high costs. Existing AI legal assistants lack Bengali-language support and jurisdiction-specific adaptation, limiting their effectiveness. To address this, we developed Mina, a multilingual LLM-based legal assistant tailored for the Bangladeshi context. It employs multilingual embeddings and a RAG-based chain-of-tools framework for retrieval, reasoning, translation, and document generation, delivering context-aware legal drafts, citations, and plain-language explanations via an interactive chat interface. Evaluated by law faculty from leading Bangladeshi universities across all stages of the 2022 and 2023 Bangladesh Bar Council Exams, Mina scored 75-80% in Preliminary MCQs, Written, and simulated Viva Voce exams, matching or surpassing average human performance and demonstrating clarity, contextual understanding, and sound legal reasoning. Even under a conservative upper bound, Mina operates at just 0.12-0.61% of typical legal consultation costs in Bangladesh, yielding a 99.4-99.9\% cost reduction relative to human-provided services. These results confirm its potential as a low-cost, multilingual AI assistant that automates key legal tasks and scales access to justice, offering a real-world case study on building domain-specific, low-resource systems and addressing challenges of multilingual adaptation, efficiency, and sustainable public-service AI deployment.</description>
      <guid isPermaLink="false">oai:arXiv.org:2511.08605v2</guid>
      <category>cs.CL</category>
      <category>cs.CY</category>
      <category>cs.HC</category>
      <category>cs.MA</category>
      <category>cs.MM</category>
      <pubDate>Mon, 01 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Azmine Toushik Wasi, Wahid Faisal, Mst Rafia Islam</dc:creator>
    </item>
  </channel>
</rss>
