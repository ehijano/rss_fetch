<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>math.OC updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/math.OC</link>
    <description>math.OC updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/math.OC" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Mon, 01 Jul 2024 04:01:24 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Mon, 01 Jul 2024 00:00:00 -0400</pubDate>
    <skipDays>
      <day>Saturday</day>
      <day>Sunday</day>
    </skipDays>
    <item>
      <title>Inventory Management Under Stochastic Demand: A Simulation-Optimization Approach</title>
      <link>https://arxiv.org/abs/2406.19425</link>
      <description>arXiv:2406.19425v1 Announce Type: new 
Abstract: This study presents a comprehensive approach to optimizing inventory management under stochastic demand by leveraging Monte Carlo Simulation (MCS) with grid search and Bayesian optimization. By using a business case of historical demand data and through the comparison of periodic review (p, Q) and continuous review (r, Q) inventory policies, it demonstrates that the (r, Q) policy significantly increases expected profit by dynamically managing inventory levels based on daily demand and lead time considerations. The integration of random and conditional sampling techniques highlights critical periods of high demand, providing deeper insights into demand patterns. While conditional sampling reduces execution time, it yields slightly lower profits compared to random sampling. Though Bayesian optimization marginally outperforms grid search in identifying optimal reorder quantities and points, however, given the stochastic nature of the algorithm, this can change with multiple runs. This study accentuates the effectiveness of advanced simulation and optimization techniques in addressing complex inventory challenges, ultimately supporting more informed and profitable inventory management decisions. The simulation model and optimization framework are open-source and written in Python, promoting transparency and enabling other researchers and practitioners to replicate and build upon this work. This contributes to the advancement of knowledge and the development of more effective inventory management solutions.</description>
      <guid isPermaLink="false">oai:arXiv.org:2406.19425v1</guid>
      <category>math.OC</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <dc:creator>Sarit Maitra</dc:creator>
    </item>
    <item>
      <title>Stochastic First-Order Methods with Non-smooth and Non-Euclidean Proximal Terms for Nonconvex High-Dimensional Stochastic Optimization</title>
      <link>https://arxiv.org/abs/2406.19475</link>
      <description>arXiv:2406.19475v1 Announce Type: new 
Abstract: When the nonconvex problem is complicated by stochasticity, the sample complexity of stochastic first-order methods may depend linearly on the problem dimension, which is undesirable for large-scale problems. In this work, we propose dimension-insensitive stochastic first-order methods (DISFOMs) to address nonconvex optimization with expected-valued objective function. Our algorithms allow for non-Euclidean and non-smooth distance functions as the proximal terms. Under mild assumptions, we show that DISFOM using minibatches to estimate the gradient enjoys sample complexity of $ \mathcal{O} ( (\log d) / \epsilon^4 ) $ to obtain an $\epsilon$-stationary point. Furthermore, we prove that DISFOM employing variance reduction can sharpen this bound to $\mathcal{O} ( (\log d)^{2/3}/\epsilon^{10/3} )$, which perhaps leads to the best-known sample complexity result in terms of $d$. We provide two choices of the non-smooth distance functions, both of which allow for closed-form solutions to the proximal step. Numerical experiments are conducted to illustrate the dimension insensitive property of the proposed frameworks.</description>
      <guid isPermaLink="false">oai:arXiv.org:2406.19475v1</guid>
      <category>math.OC</category>
      <category>cs.LG</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Yue Xie, Jiawen Bi, Hongcheng Liu</dc:creator>
    </item>
    <item>
      <title>Approximately Gaussian Replicator Flows: Nonconvex Optimization as a Nash-Convergent Evolutionary Game</title>
      <link>https://arxiv.org/abs/2406.19529</link>
      <description>arXiv:2406.19529v1 Announce Type: new 
Abstract: This work leverages tools from evolutionary game theory to solve unconstrained nonconvex optimization problems. Specifically, we lift such a problem to an optimization over probability measures, whose minimizers exactly correspond to the Nash equilibria of a particular population game. To algorithmically solve for such Nash equilibria, we introduce approximately Gaussian replicator flows (AGRFs) as a tractable alternative to simulating the corresponding infinite-dimensional replicator dynamics. Our proposed AGRF dynamics can be integrated using off-the-shelf ODE solvers when considering objectives with closed-form integrals against a Gaussian measure. We theoretically analyze AGRF dynamics by explicitly characterizing their trajectories and stability on quadratic objective functions, in addition to analyzing their descent properties. Our methods are supported by illustrative experiments on a range of canonical nonconvex optimization benchmark functions.</description>
      <guid isPermaLink="false">oai:arXiv.org:2406.19529v1</guid>
      <category>math.OC</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Brendon G. Anderson, Samuel Pfrommer, Somayeh Sojoudi</dc:creator>
    </item>
    <item>
      <title>Efficient Path Planning with Soft Homology Constraints</title>
      <link>https://arxiv.org/abs/2406.19551</link>
      <description>arXiv:2406.19551v1 Announce Type: new 
Abstract: We study the problem of path planning with soft homology constraints on a surface topologically equivalent to a disk with punctures. Specifically, we propose an algorithm, named $\Hstar$, for the efficient computation of a path homologous to a user-provided reference path. We show that the algorithm can generate a suite of paths in distinct homology classes, from the overall shortest path to the shortest path homologous to the reference path, ordered both by path length and similarity to the reference path. Rollout is shown to improve the results produced by the algorithm. Experiments demonstrate that $\Hstar$ can be an efficient alternative to optimal methods, especially for configuration spaces with many obstacles.</description>
      <guid isPermaLink="false">oai:arXiv.org:2406.19551v1</guid>
      <category>math.OC</category>
      <category>cs.CG</category>
      <category>cs.RO</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Carlos A. Taveras, Santiago Segarra, C\'esar A. Uribe</dc:creator>
    </item>
    <item>
      <title>Private Zeroth-Order Nonsmooth Nonconvex Optimization</title>
      <link>https://arxiv.org/abs/2406.19579</link>
      <description>arXiv:2406.19579v1 Announce Type: new 
Abstract: We introduce a new zeroth-order algorithm for private stochastic optimization on nonconvex and nonsmooth objectives. Given a dataset of size $M$, our algorithm ensures $(\alpha,\alpha\rho^2/2)$-R\'enyi differential privacy and finds a $(\delta,\epsilon)$-stationary point so long as $M=\tilde\Omega\left(\frac{d}{\delta\epsilon^3} + \frac{d^{3/2}}{\rho\delta\epsilon^2}\right)$. This matches the optimal complexity of its non-private zeroth-order analog. Notably, although the objective is not smooth, we have privacy ``for free'' whenever $\rho \ge \sqrt{d}\epsilon$.</description>
      <guid isPermaLink="false">oai:arXiv.org:2406.19579v1</guid>
      <category>math.OC</category>
      <category>cs.CR</category>
      <category>cs.LG</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Qinzi Zhang, Hoang Tran, Ashok Cutkosky</dc:creator>
    </item>
    <item>
      <title>Filtration learning in exact multi-parameter persistent homology and classification of time-series data</title>
      <link>https://arxiv.org/abs/2406.19587</link>
      <description>arXiv:2406.19587v1 Announce Type: new 
Abstract: To analyze the topological properties of the given discrete data, one needs to consider a continuous transform called filtration. Persistent homology serves as a tool to track changes of homology in the filtration. The outcome of the topological analysis of data varies depending on the choice of filtration, making the selection of filtration crucial. Filtration learning is an attempt to find an optimal filtration that minimizes the loss function. Exact Multi-parameter Persistent Homology (EMPH) has been recently proposed, particularly for topological time-series analysis, that utilizes the exact formula of rank invariant instead of calculating it. In this paper, we propose a framework for filtration learning of EMPH. We formulate an optimization problem and propose an algorithm for solving the problem. We then apply the proposed algorithm to several classification problems. Particularly, we derive the exact formula of the gradient of the loss function with respect to the filtration parameter, which makes it possible to directly update the filtration without using automatic differentiation, significantly enhancing the learning process.</description>
      <guid isPermaLink="false">oai:arXiv.org:2406.19587v1</guid>
      <category>math.OC</category>
      <category>math.AT</category>
      <category>stat.ML</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Keunsu Kim, Jae-Hun Jung</dc:creator>
    </item>
    <item>
      <title>A Customized Augmented Lagrangian Method for Block-Structured Integer Programming</title>
      <link>https://arxiv.org/abs/2406.19605</link>
      <description>arXiv:2406.19605v1 Announce Type: new 
Abstract: Integer programming with block structures has received considerable attention recently and is widely used in many practical applications such as train timetabling and vehicle routing problems. It is known to be NP-hard due to the presence of integer variables. We define a novel augmented Lagrangian function by directly penalizing the inequality constraints and establish the strong duality between the primal problem and the augmented Lagrangian dual problem. Then, a customized augmented Lagrangian method is proposed to address the block-structures. In particular, the minimization of the augmented Lagrangian function is decomposed into multiple subproblems by decoupling the linking constraints and these subproblems can be efficiently solved using the block coordinate descent method. We also establish the convergence property of the proposed method. To make the algorithm more practical, we further introduce several refinement techniques to identify high-quality feasible solutions. Numerical experiments on a few interesting scenarios show that our proposed algorithm often achieves a satisfactory solution and is quite effective.</description>
      <guid isPermaLink="false">oai:arXiv.org:2406.19605v1</guid>
      <category>math.OC</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Rui Wang, Chuwen Zhang, Shanwen Pu, Jianjun Gao, Zaiwen Wen</dc:creator>
    </item>
    <item>
      <title>Closed-loop equilibria for Stackelberg games: it's all about stochastic targets</title>
      <link>https://arxiv.org/abs/2406.19607</link>
      <description>arXiv:2406.19607v1 Announce Type: new 
Abstract: In this paper, we provide a general approach to reformulating any continuous-time stochastic Stackelberg differential game under closed-loop strategies as a single-level optimisation problem with target constraints. More precisely, we consider a Stackelberg game in which the leader and the follower can both control the drift and the volatility of a stochastic output process, in order to maximise their respective expected utility. The aim is to characterise the Stackelberg equilibrium when the players adopt `closed-loop strategies', i.e. their decisions are based solely on the historical information of the output process, excluding especially any direct dependence on the underlying driving noise, often unobservable in real-world applications. We first show that, by considering the--second-order--backward stochastic differential equation associated with the continuation utility of the follower as a controlled state variable for the leader, the latter's unconventional optimisation problem can be reformulated as a more standard stochastic control problem with stochastic target constraints. Thereafter, adapting the methodology developed by Soner and Touzi [67] or Bouchard, \'Elie, and Imbert [14], the optimal strategies, as well as the corresponding value of the Stackelberg equilibrium, can be characterised through the solution of a well-specified system of Hamilton--Jacobi--Bellman equations. For a more comprehensive insight, we illustrate our approach through a simple example, facilitating both theoretical and numerical detailed comparisons with the solutions under different information structures studied in the literature.</description>
      <guid isPermaLink="false">oai:arXiv.org:2406.19607v1</guid>
      <category>math.OC</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Camilo Hern\'andez, Nicol\'as Hern\'andez Santib\'a\~nez, Emma Hubert, Dylan Possama\"i</dc:creator>
    </item>
    <item>
      <title>LIPO+: Frugal Global Optimization for Lipschitz Functions</title>
      <link>https://arxiv.org/abs/2406.19723</link>
      <description>arXiv:2406.19723v1 Announce Type: new 
Abstract: In this paper, we propose simple yet effective empirical improvements to the algorithms of the LIPO family, introduced in [Malherbe2017], that we call LIPO+ and AdaLIPO+. We compare our methods to the vanilla versions of the algorithms over standard benchmark functions and show that they converge significantly faster. Finally, we show that the LIPO family is very prone to the curse of dimensionality and tends quickly to Pure Random Search when the dimension increases. We give a proof for this, which is also formalized in Lean mathematical language. Source codes and a demo are provided online.</description>
      <guid isPermaLink="false">oai:arXiv.org:2406.19723v1</guid>
      <category>math.OC</category>
      <category>math.PR</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Ga\"etan Serr\'e (ENS Paris Saclay, CB), Perceval Beja-Battais (ENS Paris Saclay, CB), Sophia Chirrane (ENS Paris Saclay, CB), Argyris Kalogeratos (ENS Paris Saclay, CB), Nicolas Vayatis (ENS Paris Saclay, CB)</dc:creator>
    </item>
    <item>
      <title>Funplex: A Modified Simplex Algorithm to Efficiently Explore Near-Optimal Spaces</title>
      <link>https://arxiv.org/abs/2406.19809</link>
      <description>arXiv:2406.19809v1 Announce Type: new 
Abstract: Modeling to generate alternatives (MGA) is an increasingly popular method in energy system optimization. MGA explores the near-optimal space, namely, system alternatives whose costs are within a certain fraction of the globally optimal cost. Real-world stakeholders may prefer these alternatives due to intangible factors. Nonetheless, widespread MGA adoption is hampered by its additional computational burden. Current MGA methods identify boundary points of the near-optimal space through repeated, independent optimization problems. Hundreds of model runs are usually required, and such individual runs are often inefficient because they repeat calculations or retrace previous trajectories. In this study, we transcend such limitations by introducing a novel algorithm called Funplex, which uses methods from multi-objective Simplex to optimize many MGA objectives with minimal computational redundancy. For a simple linear-programming energy hub case study, we show that Funplex is five times faster than existing methods and yields higher-quality near-optimal spaces. Furthermore, sensitivity analyses suggest that Funplex scales well with the number of investment variables, making it promising for capacity planning models. The current proof-of-concept implementation based on a full multi-objective tableau may face memory and stability limitations for large models. Nonetheless, future developments based on more advanced versions of Simplex may overcome such barriers, thereby making MGA more accessible and standard among modeling teams.</description>
      <guid isPermaLink="false">oai:arXiv.org:2406.19809v1</guid>
      <category>math.OC</category>
      <category>cs.SY</category>
      <category>eess.SY</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-sa/4.0/</dc:rights>
      <dc:creator>Christoph S. Funke, Linda Brodnicke, Francesco Lombardi, Giovanni Sansavini</dc:creator>
    </item>
    <item>
      <title>Residuals-Based Contextual Distributionally Robust Optimization with Decision-Dependent Uncertainty</title>
      <link>https://arxiv.org/abs/2406.20004</link>
      <description>arXiv:2406.20004v1 Announce Type: new 
Abstract: We consider a residuals-based distributionally robust optimization model, where the underlying uncertainty depends on both covariate information and our decisions. We adopt regression models to learn the latent decision dependency and construct a nominal distribution (thereby ambiguity sets) around the learned model using empirical residuals from the regressions. Ambiguity sets can be formed via the Wasserstein distance, a sample robust approach, or with the same support as the nominal empirical distribution (e.g., phi-divergences), where both the nominal distribution and the radii of the ambiguity sets could be decision- and covariate-dependent. We provide conditions under which desired statistical properties, such as asymptotic optimality, rates of convergence, and finite sample guarantees, are satisfied. Via cross-validation, we devise data-driven approaches to find the best radii for different ambiguity sets, which can be decision-(in)dependent and covariate-(in)dependent. Through numerical experiments, we illustrate the effectiveness of our approach and the benefits of integrating decision dependency into a residuals-based DRO framework.</description>
      <guid isPermaLink="false">oai:arXiv.org:2406.20004v1</guid>
      <category>math.OC</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Qing Zhu, Xian Yu, Guzin Bayraksan</dc:creator>
    </item>
    <item>
      <title>Almost Orthogonal Arrays: Theory and Search Three Ways</title>
      <link>https://arxiv.org/abs/2406.19516</link>
      <description>arXiv:2406.19516v1 Announce Type: cross 
Abstract: Orthogonal arrays play a fundamental role in many applications. However, constructing orthogonal arrays with the required parameters for an application usually is extremely difficult and, sometimes, even impossible. Hence there is an increasing need for a relaxation of orthogonal arrays to allow a wider flexibility. The latter has lead to various types of arrays under the name of ``nearly-orthogonal arrays'', and less often ``almost orthogonal arrays''. The aim of this paper is twofold. On the one hand, we review all the existing relaxations, comparing and discussing them in depth. On the other hand, we explore how to find almost orthogonal arrays three ways: using integer programming, local search meta-heuristics and algebraic methods. We compare all our search results with the ones existing in the literature, and we show that they are competitive, improving some of the existing arrays for many non-orthogonality measures. All our found almost orthogonal arrays are available at a public repository.</description>
      <guid isPermaLink="false">oai:arXiv.org:2406.19516v1</guid>
      <category>math.CO</category>
      <category>cs.DM</category>
      <category>math.OC</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Luis Mart\'inez, Mar\'ia Merino, Juan Manuel Montoya, Josu\'e Tonelli-Cueto</dc:creator>
    </item>
    <item>
      <title>Stochastic Zeroth-Order Optimization under Strongly Convexity and Lipschitz Hessian: Minimax Sample Complexity</title>
      <link>https://arxiv.org/abs/2406.19617</link>
      <description>arXiv:2406.19617v1 Announce Type: cross 
Abstract: Optimization of convex functions under stochastic zeroth-order feedback has been a major and challenging question in online learning. In this work, we consider the problem of optimizing second-order smooth and strongly convex functions where the algorithm is only accessible to noisy evaluations of the objective function it queries. We provide the first tight characterization for the rate of the minimax simple regret by developing matching upper and lower bounds. We propose an algorithm that features a combination of a bootstrapping stage and a mirror-descent stage. Our main technical innovation consists of a sharp characterization for the spherical-sampling gradient estimator under higher-order smoothness conditions, which allows the algorithm to optimally balance the bias-variance tradeoff, and a new iterative method for the bootstrapping stage, which maintains the performance for unbounded Hessian.</description>
      <guid isPermaLink="false">oai:arXiv.org:2406.19617v1</guid>
      <category>cs.LG</category>
      <category>cs.IT</category>
      <category>math.IT</category>
      <category>math.OC</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Qian Yu, Yining Wang, Baihe Huang, Qi Lei, Jason D. Lee</dc:creator>
    </item>
    <item>
      <title>Meshfree Variational Physics Informed Neural Networks (MF-VPINN): an adaptive training strategy</title>
      <link>https://arxiv.org/abs/2406.19831</link>
      <description>arXiv:2406.19831v1 Announce Type: cross 
Abstract: In this paper we introduce a Meshfree Variational Physics Informed Neural Network. It is a Variational Physics Informed Neural Network that does not require the generation of a triangulation of the entire domain and that can be trained with an adaptive set of test functions. In order to generate the test space we exploit an a posteriori error indicator and add test functions only where the error is higher. Four training strategies are proposed and compared. Numerical results show that the accuracy is higher than the one of a Variational Physics Informed Neural Network trained with the same number of test functions but defined on a quasi-uniform mesh.</description>
      <guid isPermaLink="false">oai:arXiv.org:2406.19831v1</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <category>math.OC</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Stefano Berrone, Moreno Pintore</dc:creator>
    </item>
    <item>
      <title>Operator World Models for Reinforcement Learning</title>
      <link>https://arxiv.org/abs/2406.19861</link>
      <description>arXiv:2406.19861v1 Announce Type: cross 
Abstract: Policy Mirror Descent (PMD) is a powerful and theoretically sound methodology for sequential decision-making. However, it is not directly applicable to Reinforcement Learning (RL) due to the inaccessibility of explicit action-value functions. We address this challenge by introducing a novel approach based on learning a world model of the environment using conditional mean embeddings. We then leverage the operatorial formulation of RL to express the action-value function in terms of this quantity in closed form via matrix operations. Combining these estimators with PMD leads to POWR, a new RL algorithm for which we prove convergence rates to the global optimum. Preliminary experiments in finite and infinite state settings support the effectiveness of our method.</description>
      <guid isPermaLink="false">oai:arXiv.org:2406.19861v1</guid>
      <category>cs.LG</category>
      <category>math.OC</category>
      <category>stat.ML</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Pietro Novelli, Marco Prattic\`o, Massimiliano Pontil, Carlo Ciliberto</dc:creator>
    </item>
    <item>
      <title>On the vanishing of eigenfunctions of the Laplacian on tori</title>
      <link>https://arxiv.org/abs/2406.19925</link>
      <description>arXiv:2406.19925v1 Announce Type: cross 
Abstract: Consider an eigenfunction of the Laplacian on a torus. How small can its $L^2$-norm be on small balls? We provide partial answers to this question by exploiting the distribution of integer points on spheres, basic properties of polynomials, and Nazarov--Tur\'an type estimates for exponential polynomials. Applications to quantum limits and control theory are given.</description>
      <guid isPermaLink="false">oai:arXiv.org:2406.19925v1</guid>
      <category>math.AP</category>
      <category>math.OC</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Pierre Germain, Iv\'an Moyano, Hui Zhu</dc:creator>
    </item>
    <item>
      <title>Alon's transmitting problem and multicolor Beck--Spencer Lemma</title>
      <link>https://arxiv.org/abs/2406.19945</link>
      <description>arXiv:2406.19945v1 Announce Type: cross 
Abstract: The Hamming graph $H(n,q)$ is defined on the vertex set $\{1,2,\ldots,q\}^n$ and two vertices are adjacent if and only if they differ in precisely one coordinate. Alon proved that for any sequence $v_1,\ldots,v_b$ of $b=\lceil\frac n2\rceil$ vertices of $H(n,2)$, there is a vertex whose distance from $v_i$ is at least $b-i+1$ for all $1\leq i\leq b$. In this note, we prove that for any $q\geq 3$ and any sequence $v_1,\ldots,v_b$ of $b=\lfloor(1-\frac1q)n\rfloor$ vertices of $H(n,q)$, there is a vertex whose distance from $v_i$ is at least $b-i+1$ for all $1\leq i\leq b$.
  Alon used the Beck--Spencer Lemma which, in turn, was based on the floating variable method introduced by Beck and Fiala who studied combinatorial discrepancies. For our proof, we extend the Beck--Spencer Lemma by using a multicolor version of the floating variable method due to Doerr and Srivastav.</description>
      <guid isPermaLink="false">oai:arXiv.org:2406.19945v1</guid>
      <category>math.CO</category>
      <category>cs.IT</category>
      <category>math.IT</category>
      <category>math.OC</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Norihide Tokushige</dc:creator>
    </item>
    <item>
      <title>ScaleBiO: Scalable Bilevel Optimization for LLM Data Reweighting</title>
      <link>https://arxiv.org/abs/2406.19976</link>
      <description>arXiv:2406.19976v1 Announce Type: cross 
Abstract: Bilevel optimization has shown its utility across various machine learning settings, yet most algorithms in practice require second-order information, making it challenging to scale them up. Only recently, a paradigm of first-order algorithms emerged, capable of effectively addressing bilevel optimization problems. Nevertheless, the practical efficiency of this paradigm remains unverified, particularly in the context of large language models (LLMs). This paper introduces the first scalable instantiation of this paradigm called ScaleBiO, focusing on bilevel optimization for large-scale LLM data reweighting. By combining with a recently proposed memory-efficient training technique called LISA, our novel algorithm allows the paradigm to scale to 34-billion-parameter LLMs on eight A40 GPUs, marking the first successful application of bilevel optimization under practical scenarios for large-sized LLMs. Empirically, extensive experiments on data reweighting verify the effectiveness of ScaleBiO for different-scaled models, including GPT-2, LLaMA-3-8B, GPT-NeoX-20B, and Yi-34B, where bilevel optimization succeeds in filtering irrelevant data samples and selecting informative samples. Theoretically, ScaleBiO ensures the optimality of the learned data weights, along with a convergence guarantee matching the conventional first-order bilevel optimization paradigm on smooth and strongly convex objectives.</description>
      <guid isPermaLink="false">oai:arXiv.org:2406.19976v1</guid>
      <category>cs.LG</category>
      <category>math.OC</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Rui Pan, Jipeng Zhang, Xingyuan Pan, Renjie Pi, Xiaoyu Wang, Tong Zhang</dc:creator>
    </item>
    <item>
      <title>Modeling and LQR Control of Insect Sized Flapping Wing Robot</title>
      <link>https://arxiv.org/abs/2406.20061</link>
      <description>arXiv:2406.20061v1 Announce Type: cross 
Abstract: Flying insects can perform rapid, sophisticated maneuvers like backflips, sharp banked turns, and in-flight collision recovery. To emulate these in aerial robots weighing less than a gram, known as flying insect robots (FIRs), a fast and responsive control system is essential. To date, these have largely been, at their core, elaborations of proportional-integral-derivative (PID)-type feedback control. Without exception, their gains have been painstakingly tuned by hand. Aggressive maneuvers have further required task-specific tuning. Optimal control has the potential to mitigate these issues, but has to date only been demonstrated using approxiate models and receding horizon controllers (RHC) that are too computationally demanding to be carried out onboard the robot. Here we used a more accurate stroke-averaged model of forces and torques to implement the first demonstration of optimal control on an FIR that is computationally efficient enough to be performed by a microprocessor carried onboard. We took force and torque measurements from a 150 mg FIR, the UW Robofly, using a custom-built sensitive force-torque sensor, and validated them using motion capture data in free flight. We demonstrated stable hovering (RMS error of about 4 cm) and trajectory tracking maneuvers at translational velocities up to 25 cm/s using an optimal linear quadratic regulator (LQR). These results were enabled by a more accurate model and lay the foundation for future work that uses our improved model and optimal controller in conjunction with recent advances in low-power receding horizon control to perform accurate aggressive maneuvers without iterative, task-specific tuning.</description>
      <guid isPermaLink="false">oai:arXiv.org:2406.20061v1</guid>
      <category>cs.RO</category>
      <category>math.OC</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <dc:creator>Daksh Dhingra, Kadierdan Kaheman, Sawyer B. Fuller</dc:creator>
    </item>
    <item>
      <title>Low-rank optimization methods based on projected-projected gradient descent that accumulate at Bouligand stationary points</title>
      <link>https://arxiv.org/abs/2201.03962</link>
      <description>arXiv:2201.03962v2 Announce Type: replace 
Abstract: This paper considers the problem of minimizing a differentiable function with locally Lipschitz continuous gradient on the algebraic variety of real matrices of upper-bounded rank. This problem is known to enable the formulation of several machine learning and signal processing tasks such as collaborative filtering and signal recovery. Several definitions of stationarity exist for this nonconvex problem. Among them, Bouligand stationarity is the strongest first-order necessary condition for local optimality. This paper proposes a first-order algorithm that combines the well-known projected-projected gradient descent map with a rank reduction mechanism and generates a sequence in the variety whose accumulation points are Bouligand stationary. This algorithm compares favorably with the three other algorithms known in the literature to enjoy this stationarity property, regarding both the typical computational cost per iteration and empirically observed numerical performance. A framework to design hybrid algorithms enjoying the same property is proposed and illustrated through an example.</description>
      <guid isPermaLink="false">oai:arXiv.org:2201.03962v2</guid>
      <category>math.OC</category>
      <category>cs.NA</category>
      <category>math.NA</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Guillaume Olikier, Kyle A. Gallivan, P. -A. Absil</dc:creator>
    </item>
    <item>
      <title>Forall-exist statements in pseudopolynomial time</title>
      <link>https://arxiv.org/abs/2311.07214</link>
      <description>arXiv:2311.07214v2 Announce Type: replace 
Abstract: Given a convex set $Q \subseteq R^m$ and an integer matrix $W \in Z^{m \times n}$, we consider statements of the form $ \forall b \in Q \cap Z^m$ $\exists x \in Z^n$ s.t. $Wx \leq b$. Such statements can be verified in polynomial time with the algorithm of Kannan and its improvements if $n$ is fixed and $Q$ is a polyhedron. The running time of the best-known algorithms is doubly exponential in~$n$. In this paper, we provide a pseudopolynomial-time algorithm if $m$ is fixed. Its running time is $(m \Delta)^{O(m^2)}$, where $\Delta = \|W\|_\infty$. Furthermore it applies to general convex sets $Q$.</description>
      <guid isPermaLink="false">oai:arXiv.org:2311.07214v2</guid>
      <category>math.OC</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Eleonore Bach, Friedrich Eisenbrand, Thomas Rothvoss, Robert Weismantel</dc:creator>
    </item>
    <item>
      <title>Fast Sampling for Linear Inverse Problems of Vectors and Tensors using Multilinear Extensions</title>
      <link>https://arxiv.org/abs/2312.01574</link>
      <description>arXiv:2312.01574v2 Announce Type: replace 
Abstract: This paper studies the problem of sampling vector and tensor signals, which is the process of choosing sites in vectors and tensors to place sensors for better recovery. A small core tensor and multiple factor matrices can be used to sparsely represent a dense higher-order tensor within a linear model. Using this linear model, one can effectively recover the whole signals from a limited number of measurements by solving linear inverse problems (LIPs). By providing the closed-form expressions of multilinear extensions for the frame potential of pruned matrices, we develop an algorithm named fast Frank-Wolfe algorithm (FFW) for sampling vectors and tensors with low complexity. We provide the approximation factor of our proposed algorithm for the factor matrices that are non-orthogonal and have elements of the same sign in each row.Moreover, we conduct experiments to verify the higher performance and lower complexity of our proposed algorithm for general factor matrix. Finally, we demonstrate that sampling by FFW and reconstruction by least squares methods yield better results for image data compared to convCNP completion with random sampling.</description>
      <guid isPermaLink="false">oai:arXiv.org:2312.01574v2</guid>
      <category>math.OC</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Hao Li, Dong Liang, Zixi Zhou, Zheng Xie</dc:creator>
    </item>
    <item>
      <title>Future-proof ship pipe routing: navigating the energy transition</title>
      <link>https://arxiv.org/abs/2312.09088</link>
      <description>arXiv:2312.09088v2 Announce Type: replace 
Abstract: The maritime industry must prepare for the energy transition from fossil fuels to sustainable alternatives. Making ships future-proof is necessary given their long lifetime, but it is also complex because the future fuel type is uncertain. Within this uncertainty, one typically overlooks pipe routing, although it is a crucial driver for design time and costs. Therefore, we propose a mathematical approach for modeling uncertainty in pipe routing with deterministic, stochastic, and robust optimization. All three models are based on state-of-the-art integer linear optimization models for the Stochastic Steiner Forest Problem and adjusted to the maritime domain using specific constraints for pipe routing. We compare the models using both artificial and realistic instances and show that considering uncertainty using stochastic optimization and robust optimization leads to cost reductions of up to 22% in our experiments.</description>
      <guid isPermaLink="false">oai:arXiv.org:2312.09088v2</guid>
      <category>math.OC</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Berend Markhorst, Joost Berkhout, Alessandro Zocca, Jeroen Pruyn, Rob van der Mei</dc:creator>
    </item>
    <item>
      <title>Last Iterate Convergence of Incremental Methods and Applications in Continual Learning</title>
      <link>https://arxiv.org/abs/2403.06873</link>
      <description>arXiv:2403.06873v2 Announce Type: replace 
Abstract: Incremental gradient and incremental proximal methods are a fundamental class of optimization algorithms used for solving finite sum problems, broadly studied in the literature. Yet, without strong convexity, their convergence guarantees have primarily been established for the ergodic (average) iterate. Motivated by applications in continual learning, we obtain the first convergence guarantees for the last iterate of both incremental gradient and incremental proximal methods, in general convex smooth (for both) and convex Lipschitz (for the proximal variants) settings. Our oracle complexity bounds for the last iterate nearly match (i.e., match up to a square-root-log or a log factor) the best known oracle complexity bounds for the average iterate, for both classes of methods. We further obtain generalizations of our results to weighted averaging of the iterates with increasing weights and for randomly permuted ordering of updates. We study incremental proximal methods as a model of continual learning with generalization and argue that large amount of regularization is crucial to preventing catastrophic forgetting. Our results generalize last iterate guarantees for incremental methods compared to state of the art, as such results were previously known only for overparameterized linear models, which correspond to convex quadratic problems with infinitely many solutions.</description>
      <guid isPermaLink="false">oai:arXiv.org:2403.06873v2</guid>
      <category>math.OC</category>
      <category>cs.LG</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Xufeng Cai, Jelena Diakonikolas</dc:creator>
    </item>
    <item>
      <title>Direct Approach of Indefinite Linear-Quadratic Mean Field Games</title>
      <link>https://arxiv.org/abs/2404.05166</link>
      <description>arXiv:2404.05166v3 Announce Type: replace 
Abstract: This paper is concerned with an indefinite linear-quadratic mean field games of stochastic large-population system, where the individual diffusion coefficients can depend on both the state and the control of the agents. Moreover, the control weights in the cost functionals could be indefinite. A direct approach is used to derive the $\epsilon$-Nash equilibrium strategy. First, we formally solving an $N$-player game problem within a vast and finite population setting. Subsequently, decoupling or reducing high-dimensional systems by introducing two Riccati equations explicitly yields centralized strategies, contingent on the state of a specific player and the average state of the population. As the population size $N$ goes infinity, the construction of decentralized strategies becomes feasible. Then, we demonstrated they are an $\epsilon$-Nash equilibrium. Numerical examples are provided to demonstrate the effectiveness of the proposed strategies.</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.05166v3</guid>
      <category>math.OC</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/publicdomain/zero/1.0/</dc:rights>
      <dc:creator>Wenyu Cong, Jingtao Shi</dc:creator>
    </item>
    <item>
      <title>General Procedure to Provide High-Probability Guarantees for Stochastic Saddle Point Problems</title>
      <link>https://arxiv.org/abs/2405.03219</link>
      <description>arXiv:2405.03219v3 Announce Type: replace 
Abstract: This paper considers smooth strongly convex and strongly concave (SC-SC) stochastic saddle point (SSP) problems. Suppose there is an arbitrary oracle that in expectation returns an $\epsilon$-solution in the sense of certain gaps, which can be the duality gap or its weaker variants. We propose a general PB-SSP framework to guarantee an $\epsilon$ small duality gap solution with high probability via only $\mathcal{O}\big(\log \frac{1}{p}\cdot\text{poly}(\log \kappa)\big)$ calls of this oracle, where $p\in(0,1)$ is the confidence level and $\kappa$ is the condition number. When applied to the sample average approximation (SAA) oracle, in addition to equipping the solution with high probability, our approach even improves the sample complexity by a factor of $\text{poly}(\kappa)$, since the high-probability argument enables us to circumvent some key difficulties of the uniform stability analysis of SAA.</description>
      <guid isPermaLink="false">oai:arXiv.org:2405.03219v3</guid>
      <category>math.OC</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <arxiv:DOI>10.1007/s10915-024-02567-5</arxiv:DOI>
      <arxiv:journal_reference>Journal of Scientific Computing 100 (2024) 13</arxiv:journal_reference>
      <dc:creator>Dongyang Li, Haobin Li, Junyu Zhang</dc:creator>
    </item>
    <item>
      <title>Prophet Inequalities: Separating Random Order from Order Selection</title>
      <link>https://arxiv.org/abs/2304.04024</link>
      <description>arXiv:2304.04024v5 Announce Type: replace-cross 
Abstract: Prophet inequalities are a central object of study in optimal stopping theory. A gambler is sent values in an online fashion, sampled from an instance of independent distributions, in an adversarial, random or selected order, depending on the model. When observing each value, the gambler either accepts it as a reward or irrevocably rejects it and proceeds to observe the next value. The goal of the gambler, who cannot see the future, is maximising the expected value of the reward while competing against the expectation of a prophet (the offline maximum). In other words, one seeks to maximise the gambler-to-prophet ratio of the expectations.
  The model, in which the gambler selects the arrival order first, and then observes the values, is known as Order Selection. In this model a ratio of $0.7251$ is attainable for any instance. Recently, this has been improved up to $0.7258$ by Bubna and Chiplunkar (2023). If the gambler chooses the arrival order (uniformly) at random, we obtain the Random Order model. The worst case ratio over all possible instances has been extensively studied for at least $40$ years. Through simulations, Bubna and Chiplunkar (2023) also showed that this ratio is at most $0.7254$ for the Random Order model, thus establishing for the first time that carefully choosing the order, instead of simply taking it at random, benefits the gambler. We give an alternative, non-simulation-assisted proof of this fact, by showing mathematically that in the Random Order model, no algorithm can achieve a ratio larger than $0.7235$. This sets a new state-of-the-art hardness for this model, and establishes more formally that there is a real benefit in choosing the order.</description>
      <guid isPermaLink="false">oai:arXiv.org:2304.04024v5</guid>
      <category>cs.DS</category>
      <category>cs.DM</category>
      <category>math.OC</category>
      <category>math.PR</category>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Giordano Giambartolomei, Frederik Mallmann-Trenn, Raimundo Saona</dc:creator>
    </item>
    <item>
      <title>A Simple Mixture Policy Parameterization for Improving Sample Efficiency of CVaR Optimization</title>
      <link>https://arxiv.org/abs/2403.11062</link>
      <description>arXiv:2403.11062v3 Announce Type: replace-cross 
Abstract: Reinforcement learning algorithms utilizing policy gradients (PG) to optimize Conditional Value at Risk (CVaR) face significant challenges with sample inefficiency, hindering their practical applications. This inefficiency stems from two main facts: a focus on tail-end performance that overlooks many sampled trajectories, and the potential of gradient vanishing when the lower tail of the return distribution is overly flat. To address these challenges, we propose a simple mixture policy parameterization. This method integrates a risk-neutral policy with an adjustable policy to form a risk-averse policy. By employing this strategy, all collected trajectories can be utilized for policy updating, and the issue of vanishing gradients is counteracted by stimulating higher returns through the risk-neutral component, thus lifting the tail and preventing flatness. Our empirical study reveals that this mixture parameterization is uniquely effective across a variety of benchmark domains. Specifically, it excels in identifying risk-averse CVaR policies in some Mujoco environments where the traditional CVaR-PG fails to learn a reasonable policy.</description>
      <guid isPermaLink="false">oai:arXiv.org:2403.11062v3</guid>
      <category>cs.LG</category>
      <category>math.OC</category>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Yudong Luo, Yangchen Pan, Han Wang, Philip Torr, Pascal Poupart</dc:creator>
    </item>
    <item>
      <title>Submodular Information Selection for Hypothesis Testing with Misclassification Penalties</title>
      <link>https://arxiv.org/abs/2405.10930</link>
      <description>arXiv:2405.10930v3 Announce Type: replace-cross 
Abstract: We consider the problem of selecting an optimal subset of information sources for a hypothesis testing/classification task where the goal is to identify the true state of the world from a finite set of hypotheses, based on finite observation samples from the sources. In order to characterize the learning performance, we propose a misclassification penalty framework, which enables nonuniform treatment of different misclassification errors. In a centralized Bayesian learning setting, we study two variants of the subset selection problem: (i) selecting a minimum cost information set to ensure that the maximum penalty of misclassifying the true hypothesis is below a desired bound and (ii) selecting an optimal information set under a limited budget to minimize the maximum penalty of misclassifying the true hypothesis. Under certain assumptions, we prove that the objective (or constraints) of these combinatorial optimization problems are weak (or approximate) submodular, and establish high-probability performance guarantees for greedy algorithms. Further, we propose an alternate metric for information set selection which is based on the total penalty of misclassification. We prove that this metric is submodular and establish near-optimal guarantees for the greedy algorithms for both the information set selection problems. Finally, we present numerical simulations to validate our theoretical results over several randomly generated instances.</description>
      <guid isPermaLink="false">oai:arXiv.org:2405.10930v3</guid>
      <category>stat.ML</category>
      <category>cs.CC</category>
      <category>cs.IT</category>
      <category>cs.LG</category>
      <category>math.IT</category>
      <category>math.OC</category>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Jayanth Bhargav, Mahsa Ghasemi, Shreyas Sundaram</dc:creator>
    </item>
    <item>
      <title>Convex Optimization of Initial Perturbations toward Quantitative Weather Control</title>
      <link>https://arxiv.org/abs/2405.19546</link>
      <description>arXiv:2405.19546v3 Announce Type: replace-cross 
Abstract: This study proposes introducing convex optimization to find initial perturbations of atmospheric models for realizing specified changes in subsequent forecasts. In the proposed method, we formulate and solve an inverse problem to find effective perturbations in atmospheric variables so that controlled variables satisfy specified changes at a specified time. The proposed method first constructs a sensitivity matrix of controlled variables, such as accumulated precipitation, to the initial atmospheric variables, such as temperature and humidity, through sensitivity analysis using numerical weather prediction (NWP) models. The sensitivity matrix is used to solve the inverse problem as convex optimization, in which a global optimal solution can be found computationally efficiently. The proposed method was validated through a benchmark warm bubble experiment using an NWP model. The experiments showed that identified perturbation successfully realized specified spatial distributions of accumulated precipitation. These results demonstrated the possibility of controlling the real atmosphere by solving inverse problems and adding small perturbations to atmospheric states.</description>
      <guid isPermaLink="false">oai:arXiv.org:2405.19546v3</guid>
      <category>physics.ao-ph</category>
      <category>cs.SY</category>
      <category>eess.SY</category>
      <category>math.OC</category>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Toshiyuki Ohtsuka, Atsushi Okazaki, Masaki Ogura, Shunji Kotsuki</dc:creator>
    </item>
  </channel>
</rss>
