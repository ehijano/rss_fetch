<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>cs.NI updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/cs.NI</link>
    <description>cs.NI updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/cs.NI" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Thu, 19 Jun 2025 01:29:41 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Wed, 18 Jun 2025 00:00:00 -0400</pubDate>
    <skipDays>
      <day>Sunday</day>
      <day>Saturday</day>
    </skipDays>
    <item>
      <title>The Trip to ZigBee Backscatter across a Decade, a Systematic Review</title>
      <link>https://arxiv.org/abs/2506.13822</link>
      <description>arXiv:2506.13822v1 Announce Type: new 
Abstract: The field of backscatter communication has undergone a profound transformation, evolving from a niche technology for radio-frequency identification (RFID) into a sophisticated paradigm poised to enable a truly battery-free Internet of Things (IoT). This evolution is built upon a deepening understanding of the fundamental principles governing these ultra-low-power links. Modern backscatter systems are no longer simple reflectors of continuous waves but are increasingly designed to interact with complex, data-carrying ambient signals from ubiquitous sources like WiFi, ZigBee, and cellular networks. This review systematically charts the journey of ambient backscatter, particularly focusing on its interaction with ZigBee and other commodity wireless protocols over the last decade. We analyze the progression from foundational proof-of-concept systems that established productive backscatter to modern high-throughput, concurrent, and cross-technology communication architectures. Key advancements in fine-grained modulation, robust synchronization, cross-technology physical layer emulation, and multi-tag coordination are detailed. A comparative analysis of state-of-the-art systems highlights the core trade-offs between performance metrics like data rate and range, power consumption, and compatibility with commodity hardware. Finally, we synthesize the primary challenges, including networking scalability, security vulnerabilities, the near-far problem, and practical deployment hurdles, and outline future research directions, such as integration with Reconfigurable Intelligent Surfaces (RIS) and 6G networks, that promise to further expand the capabilities of this transformative technology.</description>
      <guid isPermaLink="false">oai:arXiv.org:2506.13822v1</guid>
      <category>cs.NI</category>
      <category>eess.SP</category>
      <pubDate>Wed, 18 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Yang Liu</dc:creator>
    </item>
    <item>
      <title>Emerging Networks and Services in Developing Nations -- Barbados Use Case</title>
      <link>https://arxiv.org/abs/2506.13934</link>
      <description>arXiv:2506.13934v1 Announce Type: new 
Abstract: This report aims to conduct an in-depth comparison of DTN (Delay/Disconnection Tolerant Network) performance and characteristics in the developing country of Barbados versus two major UK cities Nottingham and London. We aim to detect any common patterns or deviations between the two region areas and use the results of our network simulations to draw well-founded conclusions on the reasons for these similarities and differences. In the end we hope to be able to assimilate specific portions of the island to these major cities in regard to DTN characteristics. We also want to investigate the viability of DTN use in the transport sector which has struggled from a range of issues related to efficiency and finance, by recording and analysing the same metrics for a DTN that consists of only buses. This work is intended to serve as a bridge for expanding the breadth of research done on developed countries allowing other researchers to be able to make well informed assumptions about how that research may apply to developing nations. It will consist of results that show graphical trends and analysis of why these trends might exist and how they apply to real world scenarios.</description>
      <guid isPermaLink="false">oai:arXiv.org:2506.13934v1</guid>
      <category>cs.NI</category>
      <pubDate>Wed, 18 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Warren Scantlebury, Milena Radenkovic</dc:creator>
    </item>
    <item>
      <title>TraGe: A Generic Packet Representation for Traffic Classification Based on Header-Payload Differences</title>
      <link>https://arxiv.org/abs/2506.14151</link>
      <description>arXiv:2506.14151v1 Announce Type: new 
Abstract: Traffic classification has a significant impact on maintaining the Quality of Service (QoS) of the network. Since traditional methods heavily rely on feature extraction and large scale labeled data, some recent pre-trained models manage to reduce the dependency by utilizing different pre-training tasks to train generic representations for network packets. However, existing pre-trained models typically adopt pre-training tasks developed for image or text data, which are not tailored to traffic data. As a result, the obtained traffic representations fail to fully reflect the information contained in the traffic, and may even disrupt the protocol information. To address this, we propose TraGe, a novel generic packet representation model for traffic classification. Based on the differences between the header and payload-the two fundamental components of a network packet-we perform differentiated pre-training according to the byte sequence variations (continuous in the header vs. discontinuous in the payload). A dynamic masking strategy is further introduced to prevent overfitting to fixed byte positions. Once the generic packet representation is obtained, TraGe can be finetuned for diverse traffic classification tasks using limited labeled data. Experimental results demonstrate that TraGe significantly outperforms state-of-the-art methods on two traffic classification tasks, with up to a 6.97% performance improvement. Moreover, TraGe exhibits superior robustness under parameter fluctuations and variations in sampling configurations.</description>
      <guid isPermaLink="false">oai:arXiv.org:2506.14151v1</guid>
      <category>cs.NI</category>
      <pubDate>Wed, 18 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Chungang Lin, Yilong Jiang, Weiyao Zhang, Xuying Meng, Tianyu Zuo, Yujun Zhang</dc:creator>
    </item>
    <item>
      <title>Optimizing System Latency for Blockchain-Encrypted Edge Computing in Internet of Vehicles</title>
      <link>https://arxiv.org/abs/2506.14208</link>
      <description>arXiv:2506.14208v1 Announce Type: new 
Abstract: As Internet of Vehicles (IoV) technology continues to advance, edge computing has become an important tool for assisting vehicles in handling complex tasks. However, the process of offloading tasks to edge servers may expose vehicles to malicious external attacks, resulting in information loss or even tampering, thereby creating serious security vulnerabilities. Blockchain technology can maintain a shared ledger among servers. In the Raft consensus mechanism, as long as more than half of the nodes remain operational, the system will not collapse, effectively maintaining the system's robustness and security. To protect vehicle information, we propose a security framework that integrates the Raft consensus mechanism from blockchain technology with edge computing. To address the additional latency introduced by blockchain, we derived a theoretical formula for system delay and proposed a convex optimization solution to minimize the system latency, ensuring that the system meets the requirements for low latency and high reliability. Simulation results demonstrate that the optimized data extraction rate significantly reduces system delay, with relatively stable variations in latency. Moreover, the proposed optimization solution based on this model can provide valuable insights for enhancing security and efficiency in future network environments, such as 5G and next-generation smart city systems.</description>
      <guid isPermaLink="false">oai:arXiv.org:2506.14208v1</guid>
      <category>cs.NI</category>
      <pubDate>Wed, 18 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Cui Zhang, Maoxin Ji, Qiong Wu, Pingyi Fan, Qiang Fan</dc:creator>
    </item>
    <item>
      <title>A Novel Dynamic Bandwidth Allocation Design for 100G Coherent Passive Optical Network</title>
      <link>https://arxiv.org/abs/2506.14221</link>
      <description>arXiv:2506.14221v1 Announce Type: new 
Abstract: With the rapid advancements in coherent Passive Optical Network (PON) technologies featuring 100G and higher data rates, this paper addresses the urgent requirement for sophisticated simulation and MAC layer development within the domain of coherent Time Division Multiplexing (TDM) PON and coherent Time and Frequency Division Multiplexing (TFDM) PON networks. The ever-growing demand for latency-sensitive services and expanding user populations in next-generation 100G and beyond coherent PONs, underscores the crucial need for low-latency bandwidth management and efficient Dynamic Bandwidth Allocation (DBA) mechanisms. In this paper, we present a pioneering analysis of two established DBAs from the perspective of temporal misalignments. Subsequently, a novel DBA algorithm tailored for coherent PONs featuring 100 Gbps data rate and up to 512 end-users is introduced, named the Hybrid-Switch DBA. This innovative approach allows for adaptive switching of the DBA scheme in response to real-time traffic conditions. To the best of our knowledge, this paper represents the first attempt to address the misalignment problem of DBA and proposes a novel DBA solution for both TDM- and TFDM-based coherent PON networks. This research significantly contributes to the development of coherent TDM PON and coherent TFDM PON networks by enhancing the efficiency of bandwidth allocation and addressing the challenges associated with misalignments in DBA mechanisms. As optical access networks continue to evolve to meet the ever-increasing demands of modern communication services, the Hybrid-Switch DBA algorithm presented in this paper offers a promising solution for optimizing network performance and accommodating latency-sensitive applications.</description>
      <guid isPermaLink="false">oai:arXiv.org:2506.14221v1</guid>
      <category>cs.NI</category>
      <category>cs.SY</category>
      <category>eess.SY</category>
      <pubDate>Wed, 18 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Rujia Zou, Haipeng Zhang, Karthik Sundaresan, Zhensheng Jia, Suresh Subramaniam</dc:creator>
    </item>
    <item>
      <title>SoK: Advances and Open Problems in Web Tracking</title>
      <link>https://arxiv.org/abs/2506.14057</link>
      <description>arXiv:2506.14057v1 Announce Type: cross 
Abstract: Web tracking is a pervasive and opaque practice that enables personalized advertising, retargeting, and conversion tracking. Over time, it has evolved into a sophisticated and invasive ecosystem, employing increasingly complex techniques to monitor and profile users across the web. The research community has a long track record of analyzing new web tracking techniques, designing and evaluating the effectiveness of countermeasures, and assessing compliance with privacy regulations. Despite a substantial body of work on web tracking, the literature remains fragmented across distinctly scoped studies, making it difficult to identify overarching trends, connect new but related techniques, and identify research gaps in the field. Today, web tracking is undergoing a once-in-a-generation transformation, driven by fundamental shifts in the advertising industry, the adoption of anti-tracking countermeasures by browsers, and the growing enforcement of emerging privacy regulations. This Systematization of Knowledge (SoK) aims to consolidate and synthesize this wide-ranging research, offering a comprehensive overview of the technical mechanisms, countermeasures, and regulations that shape the modern and rapidly evolving web tracking landscape. This SoK also highlights open challenges and outlines directions for future research, aiming to serve as a unified reference and introductory material for researchers, practitioners, and policymakers alike.</description>
      <guid isPermaLink="false">oai:arXiv.org:2506.14057v1</guid>
      <category>cs.CR</category>
      <category>cs.CY</category>
      <category>cs.NI</category>
      <pubDate>Wed, 18 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Yash Vekaria (University of California Davis, USA), Yohan Beugin (University of Wisconsin-Madison, USA), Shaoor Munir (University of California Davis, USA), Gunes Acar (Radboud University, Netherlands), Nataliia Bielova (Inria Centre at Universite Cote d'Azur, France), Steven Englehardt (Independent Researcher, USA), Umar Iqbal (Washington University in St. Louis, USA), Alexandros Kapravelos (North Carolina State University, USA), Pierre Laperdrix (Centre National de la Recherche Scientifique, France), Nick Nikiforakis (Stony Brook University, USA), Jason Polakis (University of Illinois Chicago, USA), Franziska Roesner (University of Washington, USA), Zubair Shafiq (University of California Davis, USA), Sebastian Zimmeck (Wesleyan University, USA)</dc:creator>
    </item>
    <item>
      <title>Vulnerability Disclosure or Notification? Best Practices for Reaching Stakeholders at Scale</title>
      <link>https://arxiv.org/abs/2506.14323</link>
      <description>arXiv:2506.14323v1 Announce Type: cross 
Abstract: Security researchers are interested in security vulnerabilities, but these security vulnerabilities create risks for stakeholders. Coordinated Vulnerability Disclosure has been an accepted best practice for many years in disclosing newly discovered vulnerabilities. This practice has mostly worked, but it can become challenging when there are many different parties involved.
  There has also been research into known vulnerabilities, using datasets or active scans to discover how many machines are still vulnerable. The ethical guidelines suggest that researchers also make an effort to notify the owners of these machines. We posit that this differs from vulnerability disclosure, but rather the practice of vulnerability notification. This practice has some similarities with vulnerability disclosure but should be distinguished from it, providing other challenges and requiring a different approach.
  Based on our earlier disclosure experience and on prior work documenting their disclosure and notification operations, we provide a meta-review on vulnerability disclosure and notification to observe the shifts in strategies in recent years. We assess how researchers initiated their messaging and examine the outcomes. We then compile the best practices for the existing disclosure guidelines and for notification operations.</description>
      <guid isPermaLink="false">oai:arXiv.org:2506.14323v1</guid>
      <category>cs.CR</category>
      <category>cs.NI</category>
      <pubDate>Wed, 18 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Ting-Han Chen, Jeroen van der Ham-de Vos</dc:creator>
    </item>
    <item>
      <title>Strategic Client Selection to Address Non-IIDness in HAPS-enabled FL Networks</title>
      <link>https://arxiv.org/abs/2401.05308</link>
      <description>arXiv:2401.05308v3 Announce Type: replace 
Abstract: The deployment of federated learning (FL) in non-terrestrial networks (NTN) that are supported by high-altitude platform stations (HAPS) offers numerous advantages. Due to its large footprint, it facilitates interaction with a large number of line-of-sight (LoS) ground clients, each possessing diverse datasets along with distinct communication and computational capabilities. The presence of many clients enhances the accuracy of the FL model and speeds up convergence. However, the variety of datasets among these clients poses a significant challenge, as it leads to pervasive non-independent and identically distributed (non-IID) data. The data non-IIDness results in markedly reduced training accuracy and slower convergence rates. To address this issue, we propose a novel weighted attribute-based client selection strategy that leverages multiple user-specific attributes, including historical traffic patterns, instantaneous channel conditions, computational capabilities, and previous-round learning performance. By combining these attributes into a composite score for each user at every FL round and selecting users with higher scores as FL clients, the framework ensures more uniform and representative data distributions, effectively mitigating the adverse effects of non-IID data. Simulation results corroborate the effectiveness of the proposed client selection strategy in enhancing FL model accuracy and convergence rate, as well as reducing training loss, by effectively addressing the critical challenge of data non-IIDness in large-scale FL system implementations.</description>
      <guid isPermaLink="false">oai:arXiv.org:2401.05308v3</guid>
      <category>cs.NI</category>
      <category>cs.CV</category>
      <category>cs.LG</category>
      <pubDate>Wed, 18 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Amin Farajzadeh, Animesh Yadav, Halim Yanikomeroglu</dc:creator>
    </item>
    <item>
      <title>mFabric: An Efficient and Scalable Fabric for Mixture-of-Experts Training</title>
      <link>https://arxiv.org/abs/2501.03905</link>
      <description>arXiv:2501.03905v2 Announce Type: replace 
Abstract: Mixture-of-Expert (MoE) models outperform conventional models by selectively activating different subnets, named \emph{experts}, on a per-token basis. This gated computation generates dynamic communications that cannot be determined beforehand, challenging the existing GPU interconnects that remain \emph{static} during the distributed training process. In this paper, we advocate for a first-of-its-kind system, called mFabric, that unlocks topology reconfiguration \emph{during} distributed MoE training. Towards this vision, we first perform a production measurement study and show that the MoE dynamic communication pattern has \emph{strong locality}, alleviating the requirement of global reconfiguration. Based on this, we design and implement a \emph{regionally reconfigurable high-bandwidth domain} on top of existing electrical interconnects using optical circuit switching (OCS), achieving scalability while maintaining rapid adaptability. We have built a fully functional mFabric prototype with commodity hardware and a customized collective communication runtime that trains state-of-the-art MoE models with \emph{in-training} topology reconfiguration across 32 A100 GPUs. Large-scale packet-level simulations show that mFabric delivers comparable performance as the non-blocking fat-tree fabric while boosting the training cost efficiency (e.g., performance per dollar) of four representative MoE models by 1.2$\times$--1.5$\times$ and 1.9$\times$--2.3$\times$ at 100 Gbps and 400 Gbps link bandwidths, respectively.</description>
      <guid isPermaLink="false">oai:arXiv.org:2501.03905v2</guid>
      <category>cs.NI</category>
      <category>cs.LG</category>
      <pubDate>Wed, 18 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Xudong Liao, Yijun Sun, Han Tian, Xinchen Wan, Yilun Jin, Zilong Wang, Zhenghang Ren, Xinyang Huang, Wenxue Li, Kin Fai Tse, Zhizhen Zhong, Guyue Liu, Ying Zhang, Xiaofeng Ye, Yiming Zhang, Kai Chen</dc:creator>
    </item>
    <item>
      <title>Periodic Chains Scheduling on Dedicated Resources -- A Crucial Problem in Time-Sensitive Networks</title>
      <link>https://arxiv.org/abs/2503.19003</link>
      <description>arXiv:2503.19003v2 Announce Type: replace 
Abstract: Periodic messages transfer data from sensors to actuators in cars, planes, and complex production machines. When considering a given routing, the unicast message starts at its source and goes over several dedicated resources to reach its destination. Such unicast message can be represented as a chain of point-to-point communications. Thus, the scheduling of the periodic chains is a principal problem in time-triggered Ethernet, like IEEE 802.1Qbv Time-Sensitive Networks. This paper studies a strongly NP-hard periodic scheduling problem with harmonic periods, task chains, and dedicated resources. We analyze the problem on several levels of generality and complexity and provide the corresponding proofs. We describe a solution methodology to find a feasible schedule that minimizes the chains' degeneracy related to start-to-end latency normalized in the number of periods. We use the local search with the first fit scheduling heuristic, which we warm-start with a constraint programming model. This notably improves the schedulability of instances with up to 100% utilization and thousands (and more) of tasks, with high-quality solutions found in minutes. An efficient constraint programming matheuristic significantly reduces the degeneracy of the found schedules even further. The method is evaluated on sets of industrial-, avionic-, and automotive-inspired instances.</description>
      <guid isPermaLink="false">oai:arXiv.org:2503.19003v2</guid>
      <category>cs.NI</category>
      <pubDate>Wed, 18 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <arxiv:DOI>10.1016/j.cor.2025.107072</arxiv:DOI>
      <arxiv:journal_reference>Computers &amp; Operations Research (2025), 180, 107072</arxiv:journal_reference>
      <dc:creator>Josef Grus, Claire Hanen, Zden\v{e}k Hanz\'alek</dc:creator>
    </item>
    <item>
      <title>OpsEval: A Comprehensive IT Operations Benchmark Suite for Large Language Models</title>
      <link>https://arxiv.org/abs/2310.07637</link>
      <description>arXiv:2310.07637v5 Announce Type: replace-cross 
Abstract: Information Technology (IT) Operations (Ops), particularly Artificial Intelligence for IT Operations (AIOps), is the guarantee for maintaining the orderly and stable operation of existing information systems. According to Gartner's prediction, the use of AI technology for automated IT operations has become a new trend. Large language models (LLMs) that have exhibited remarkable capabilities in NLP-related tasks, are showing great potential in the field of AIOps, such as in aspects of root cause analysis of failures, generation of operations and maintenance scripts, and summarizing of alert information. Nevertheless, the performance of current LLMs in Ops tasks is yet to be determined. In this paper, we present OpsEval, a comprehensive task-oriented Ops benchmark designed for LLMs. For the first time, OpsEval assesses LLMs' proficiency in various crucial scenarios at different ability levels. The benchmark includes 7184 multi-choice questions and 1736 question-answering (QA) formats in English and Chinese. By conducting a comprehensive performance evaluation of the current leading large language models, we show how various LLM techniques can affect the performance of Ops, and discussed findings related to various topics, including model quantification, QA evaluation, and hallucination issues. To ensure the credibility of our evaluation, we invite dozens of domain experts to manually review our questions. At the same time, we have open-sourced 20% of the test QA to assist current researchers in preliminary evaluations of their OpsLLM models. The remaining 80% of the data, which is not disclosed, is used to eliminate the issue of the test set leakage. Additionally, we have constructed an online leaderboard that is updated in real-time and will continue to be updated, ensuring that any newly emerging LLMs will be evaluated promptly. Both our dataset and leaderboard have been made public.</description>
      <guid isPermaLink="false">oai:arXiv.org:2310.07637v5</guid>
      <category>cs.AI</category>
      <category>cs.NI</category>
      <pubDate>Wed, 18 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Yuhe Liu, Changhua Pei, Longlong Xu, Bohan Chen, Mingze Sun, Zhirui Zhang, Yongqian Sun, Shenglin Zhang, Kun Wang, Haiming Zhang, Jianhui Li, Gaogang Xie, Xidao Wen, Xiaohui Nie, Minghua Ma, Dan Pei</dc:creator>
    </item>
  </channel>
</rss>
