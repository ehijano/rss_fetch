<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>physics.med-ph updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/physics.med-ph</link>
    <description>physics.med-ph updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/physics.med-ph" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Fri, 25 Jul 2025 04:06:24 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Fri, 25 Jul 2025 00:00:00 -0400</pubDate>
    <skipDays>
      <day>Saturday</day>
      <day>Sunday</day>
    </skipDays>
    <item>
      <title>Diffusion-Assisted Frequency Attention Model for Whole-body Low-field MRI Reconstruction</title>
      <link>https://arxiv.org/abs/2507.17764</link>
      <description>arXiv:2507.17764v1 Announce Type: new 
Abstract: By integrating the generative strengths of diffusion models with the representation capabilities of frequency-domain attention, DFAM effectively enhances reconstruction performance under low-SNR condi-tions. Experimental results demonstrate that DFAM consistently outperforms both conventional reconstruction algorithms and recent learning-based approaches. These findings highlight the potential of DFAM as a promising solution to advance low-field MRI reconstruction, particularly in resource-constrained or underdeveloped clinical settings.</description>
      <guid isPermaLink="false">oai:arXiv.org:2507.17764v1</guid>
      <category>physics.med-ph</category>
      <category>cs.CV</category>
      <pubDate>Fri, 25 Jul 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Xin Xie, Yu Guan, Zhuoxu Cui, Dong Liang, Qiegen Liu</dc:creator>
    </item>
    <item>
      <title>Multishot Dual Polarity GRAPPA: Robust Nyquist Ghost Correction for multishot EPI</title>
      <link>https://arxiv.org/abs/2507.18273</link>
      <description>arXiv:2507.18273v1 Announce Type: new 
Abstract: Purpose: This work aims to develop a robust Nyquist ghost correction method for multishot echo-planar imaging (EPI). The method helps correct challenging Nyquist ghosts, particularly on scanners with high-performance gradients or ultra-high fields. Methods: A method for multishot EPI ghost correction, called multishot dual-polarity GRAPPA (msDPG), is developed by extending the DPG concept to multishot readouts. msDPG employs tailored DPG kernels to address high-order phase differences between two EPI readout polarities, which cannot be fully addressed using linear phase correction (LPC). Advanced regularizers can be readily employed with the proposed msDPG for physiologic inter-shot phase variation correction during reconstruction. Additionally, a calibration refinement method is proposed to improve the quality of the DPG calibration data and enhance reconstruction performance. Results: Phantom and in vivo experiments on scanners with high-performance gradients and ultra-high fields demonstrated that msDPG achieved superior ghost correction performance than LPC, reducing the ghost-to-signal ratio (GSR) by over 50%. Compared to conventional DPG, msDPG provided images with lower noise amplification, particularly for acquisitions with large in-plane acceleration. Consequently, high-fidelity, submillimeter diffusion images were obtained using msDPG with regularized reconstruction. Conclusion: The proposed msDPG provides a robust Nyquist ghost correction method for multishot EPI, enabling submillimeter imaging with improved fidelity.</description>
      <guid isPermaLink="false">oai:arXiv.org:2507.18273v1</guid>
      <category>physics.med-ph</category>
      <pubDate>Fri, 25 Jul 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Yuancheng Jiang, Yohan Jun, Qiang Liu, Wen Zhong, Yogesh Rathi, Hua Guo, Berkin Bilgic</dc:creator>
    </item>
    <item>
      <title>Design and fabrication of ultrasound linear array transducer used in ultrasound endoscope</title>
      <link>https://arxiv.org/abs/2507.18628</link>
      <description>arXiv:2507.18628v1 Announce Type: new 
Abstract: This report details the successful construction of an ultrasound imaging platform and the design and fabrication of a novel ultrasound endoscope probe. The projects primary objective was to establish a functional system for acquiring and processing ultrasound signals, specifically targeting minimally invasive endoscopic applications. The ultrasound imaging platform was primarily designed and developed based on Texas Instruments (TI) Evaluation Modules (EVMs). It enables the transmission of 32-channel high-voltage signals and the reception of echo signals, with on-chip signal amplification and acquisition capabilities. Furthermore, the platform integrates a complete Time Gain Control (TGC) imaging path and a ContinuousWave Doppler (CWD) path. In conjunction with host computer software, it supports imaging with linear array, convex array, and phased array probes. Concurrently, a 64-element, 5MHz center frequency, phased array linear ultrasound endoscopic probe was designed, aiming for miniaturization and optimal imaging performance. The fabrication and assembly of its matching layer, backing layer, 2-2 piezoelectric composite material, and electrodes were completed.</description>
      <guid isPermaLink="false">oai:arXiv.org:2507.18628v1</guid>
      <category>physics.med-ph</category>
      <category>cs.SY</category>
      <category>eess.SY</category>
      <pubDate>Fri, 25 Jul 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Yuan Zhang, Mingtong Chen, Zhengbao Yang</dc:creator>
    </item>
    <item>
      <title>Direct Dual-Energy CT Material Decomposition using Model-based Denoising Diffusion Model</title>
      <link>https://arxiv.org/abs/2507.18012</link>
      <description>arXiv:2507.18012v1 Announce Type: cross 
Abstract: Dual-energy X-ray Computed Tomography (DECT) constitutes an advanced technology which enables automatic decomposition of materials in clinical images without manual segmentation using the dependency of the X-ray linear attenuation with energy. However, most methods perform material decomposition in the image domain as a post-processing step after reconstruction but this procedure does not account for the beam-hardening effect and it results in sub-optimal results. In this work, we propose a deep learning procedure called Dual-Energy Decomposition Model-based Diffusion (DEcomp-MoD) for quantitative material decomposition which directly converts the DECT projection data into material images. The algorithm is based on incorporating the knowledge of the spectral DECT model into the deep learning training loss and combining a score-based denoising diffusion learned prior in the material image domain. Importantly the inference optimization loss takes as inputs directly the sinogram and converts to material images through a model-based conditional diffusion model which guarantees consistency of the results. We evaluate the performance with both quantitative and qualitative estimation of the proposed DEcomp-MoD method on synthetic DECT sinograms from the low-dose AAPM dataset. Finally, we show that DEcomp-MoD outperform state-of-the-art unsupervised score-based model and supervised deep learning networks, with the potential to be deployed for clinical diagnosis.</description>
      <guid isPermaLink="false">oai:arXiv.org:2507.18012v1</guid>
      <category>eess.IV</category>
      <category>cs.CV</category>
      <category>physics.med-ph</category>
      <pubDate>Fri, 25 Jul 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Hang Xu, Alexandre Bousse, Alessandro Perelli</dc:creator>
    </item>
  </channel>
</rss>
