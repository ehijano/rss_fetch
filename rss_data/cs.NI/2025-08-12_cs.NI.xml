<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>cs.NI updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/cs.NI</link>
    <description>cs.NI updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/cs.NI" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Tue, 12 Aug 2025 04:00:13 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Tue, 12 Aug 2025 00:00:00 -0400</pubDate>
    <skipDays>
      <day>Sunday</day>
      <day>Saturday</day>
    </skipDays>
    <item>
      <title>Iris RESTful Server and IrisTileSource: An Iris implementation for existing OpenSeaDragon viewers</title>
      <link>https://arxiv.org/abs/2508.06615</link>
      <description>arXiv:2508.06615v1 Announce Type: new 
Abstract: The Iris File Extension (IFE) is a low overhead performance-oriented whole slide image (WSI) file format designed to improve the image rendering experience for pathologists and simplify image management for system administrators. However, static hypertext transfer protocol (HTTP) file servers cannot natively stream subregions of high-resolution image files, such as the IFE. The majority of contemporary WSI viewer systems are designed as browser-based web applications and leverage OpenSeaDragon as the tile-based rendering framework. These systems convert WSI files to Deep Zoom Images (DZI) for compatibility with simple static HTTP file servers. In order to address this limitation, we have developed the Iris RESTful Server, a low-overhead HTTP server with a RESTful API that is natively compatible with the DICOMweb WADO-RS API. Written in C++ with Boost Beast HTTP and Asio networking libraries atop the public IFE libraries, the server offers both security and high performance. Testing shows that a single instance can handle over 5000 tile requests per second with a median latency of 21 ms on a private network. We also developed and merged a new OpenSeaDragon TileSource, compatible with the Iris RESTful API, into the next OpenSeaDragon release, enabling simple and immediate drop-in replacement of DZI images within WSI viewer stacks. Designed as a secure cross-origin resource sharing microservice, this architecture includes detailed deployment instructions for new or existing WSI workflows, and the public examples.restful.irisdigitialpathology.org subdomain is provided as a development tool to accelerate WSI web viewer development.</description>
      <guid isPermaLink="false">oai:arXiv.org:2508.06615v1</guid>
      <category>cs.NI</category>
      <pubDate>Tue, 12 Aug 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Ryan Erik Landvater, Navin Kathawa, Mustafa Yousif MD, Ulysses Balis MD</dc:creator>
    </item>
    <item>
      <title>Generative AI for Intent-Driven Network Management in 6G: A Case Study on Hierarchical Learning Approach</title>
      <link>https://arxiv.org/abs/2508.06616</link>
      <description>arXiv:2508.06616v1 Announce Type: new 
Abstract: With the emergence of 6G, mobile networks are becoming increasingly heterogeneous and dynamic, necessitating advanced automation for efficient management. Intent-Driven Networks (IDNs) address this by translating high-level intents into optimization policies. Large Language Models (LLMs) can enhance this process by understanding complex human instructions to enable adaptive, intelligent automation. Given the rapid advancements in Generative AI (GenAI), a comprehensive survey of LLM-based IDN architectures in disaggregated Radio Access Network (RAN) environments is both timely and critical. This article provides such a survey, along with a case study on a hierarchical learning-enabled IDN architecture that integrates GenAI across three key stages: intent processing, intent validation, and intent execution. Unlike most existing approaches that apply GenAI in the form of LLMs for intent processing only, we propose a hierarchical framework that introduces GenAI across all three stages of IDN. To demonstrate the effectiveness of the proposed IDN management architecture, we present a case study based on the latest GenAI architecture named Mamba. The case study shows how the proposed GenAI-driven architecture enhances network performance through intelligent automation, surpassing the performance of the conventional IDN architectures.</description>
      <guid isPermaLink="false">oai:arXiv.org:2508.06616v1</guid>
      <category>cs.NI</category>
      <category>cs.AI</category>
      <pubDate>Tue, 12 Aug 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Md Arafat Habib, Medhat Elsayed, Yigit Ozcan, Pedro Enrique Iturria-Rivera, Majid Bavand, Melike Erol-Kantarci</dc:creator>
    </item>
    <item>
      <title>THz/RF Multi-Hop Routing Throughput: Performance, Optimization, and Application</title>
      <link>https://arxiv.org/abs/2508.06975</link>
      <description>arXiv:2508.06975v1 Announce Type: new 
Abstract: Terahertz (THz) communication offers a promising solution for high-throughput wireless systems. However, the severe path loss of THz signals raises concerns about its effectiveness compared to radio frequency (RF) communication. In this article, we establish the first stochastic geometry (SG)-based analytical framework for routing in THz systems. We develop a stepwise optimization approach to maximize throughput, including power allocation, relay selection, and number of hops design. Analytical expressions for throughput and coverage probability are derived under the SG framework, enabling low complexity and scalable performance evaluation. Numerical results show that the proposed stepwise-optimal routing strategies not only outperform existing SG-based methods but also approach the ideal upper bound. Moreover, we compare the throughput and coverage performance of THz and RF routing and demonstrate the applications of the proposed analytical framework and routing strategies in system parameter design and unmanned aerial vehicle networks.</description>
      <guid isPermaLink="false">oai:arXiv.org:2508.06975v1</guid>
      <category>cs.NI</category>
      <pubDate>Tue, 12 Aug 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Zhengying Lou, Baha Eddine Youcef Belmekki, Mohamed-Slim Alouini</dc:creator>
    </item>
    <item>
      <title>Consensus-based Decentralized Multi-agent Reinforcement Learning for Random Access Network Optimization</title>
      <link>https://arxiv.org/abs/2508.07001</link>
      <description>arXiv:2508.07001v1 Announce Type: new 
Abstract: With wireless devices increasingly forming a unified smart network for seamless, user-friendly operations, random access (RA) medium access control (MAC) design is considered a key solution for handling unpredictable data traffic from multiple terminals. However, it remains challenging to design an effective RA-based MAC protocol to minimize collisions and ensure transmission fairness across the devices. While existing multi-agent reinforcement learning (MARL) approaches with centralized training and decentralized execution (CTDE) have been proposed to optimize RA performance, their reliance on centralized training and the significant overhead required for information collection can make real-world applications unrealistic. In this work, we adopt a fully decentralized MARL architecture, where policy learning does not rely on centralized tasks but leverages consensus-based information exchanges across devices. We design our MARL algorithm over an actor-critic (AC) network and propose exchanging only local rewards to minimize communication overhead. Furthermore, we provide a theoretical proof of global convergence for our approach. Numerical experiments show that our proposed MARL algorithm can significantly improve RA network performance compared to other baselines.</description>
      <guid isPermaLink="false">oai:arXiv.org:2508.07001v1</guid>
      <category>cs.NI</category>
      <category>cs.AI</category>
      <category>cs.LG</category>
      <pubDate>Tue, 12 Aug 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Myeung Suk Oh, Zhiyao Zhang, FNU Hairi, Alvaro Velasquez, Jia Liu</dc:creator>
    </item>
    <item>
      <title>ProtoScan: Measuring censorship in IPv6</title>
      <link>https://arxiv.org/abs/2508.07194</link>
      <description>arXiv:2508.07194v1 Announce Type: new 
Abstract: Internet censorship continues to impact billions of people worldwide, and measurement of it remains an important focus of research. However, most Internet censorship measurements have focused solely on the IPv4 Internet infrastructure. Yet, more clients and servers are available over IPv6: According to Google, over a third of their users now have native IPv6 access. Given the slow-but-steady rate of IPv6 adoption, it is important to understand its impact on censorship. In this paper, we measure and analyze how censorship differs over IPv6 compared to the well-studied IPv4 censorship systems in use today. We perform a comprehensive global study of censorship across an array of commonly censored protocols, including HTTP, DNS, and TLS, on both IPv4 and IPv6, and compare the results. We find that there are several differences in how countries censor IPv6 traffic, both in terms of IPv6 resources, and in where and what blocklists or technologies are deployed on IPv6 networks. Many of these differences are not all-or-nothing: we find that most censors have some capacity to block in IPv6, but are less comprehensive or less reliable compared to their IPv4 censorship systems. Our results suggest that IPv6 offers new areas for censorship circumvention researchers to explore, providing potentially new ways to evade censors. As more users gain access to IPv6 addresses and networks, there will be a need for tools that take advantage of IPv6 techniques and infrastructure to bypass censorship.</description>
      <guid isPermaLink="false">oai:arXiv.org:2508.07194v1</guid>
      <category>cs.NI</category>
      <pubDate>Tue, 12 Aug 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Jack Wampler, Hammas Bin Tanveer, Rishab Nithyanand, Eric Wustrow</dc:creator>
    </item>
    <item>
      <title>Mind the IP Gap: Measuring the impact of IPv6 on DNS censorship</title>
      <link>https://arxiv.org/abs/2508.07197</link>
      <description>arXiv:2508.07197v1 Announce Type: new 
Abstract: Internet censorship impacts large segments of the Internet, but so far, prior work has focused almost exclusively on performing measurements using IPv4. As the Internet grows, and more users connect, IPv6 is increasingly supported and available to users and servers alike. But despite this steady growth, it remains unclear if the information control systems that implement censorship (firewalls, deep packet inspection, DNS injection, etc) are as effective with IPv6 traffic as they are with IPv4. In this paper, we perform the first global measurement of DNS censorship on the IPv6 Internet. Leveraging a recent technique that allows us to discover IPv6-capable open resolvers (along with their corresponding IPv4 address), we send over 20 million A and AAAA DNS requests to DNS resolvers worldwide, and measure the rate at which they block, at the resolver, network, and country level as well examine the characteristics of blocked domains. We observe that while nearly all censors support blocking IPv6, their policies are inconsistent with and frequently less effective than their IPv4 censorship infrastructure. Our results suggest that supporting IPv6 censorship is not all-or-nothing: many censors support it, but poorly. As a result, these censors may have to expend additional resources to bring IPv6 censorship up to parity with IPv4. In the meantime, this affords censorship circumvention researchers a new opportunity to exploit these differences to evade detection and blocking.</description>
      <guid isPermaLink="false">oai:arXiv.org:2508.07197v1</guid>
      <category>cs.NI</category>
      <pubDate>Tue, 12 Aug 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Ian Martiny, Hammas Bin Tanveer, Jack Wampler, Rishab Nithyanand, Eric Wustrow</dc:creator>
    </item>
    <item>
      <title>The Search for Relevance: A Context-Aware Paradigm Shift in Semantic and Task-Oriented V2X Communications</title>
      <link>https://arxiv.org/abs/2508.07394</link>
      <description>arXiv:2508.07394v1 Announce Type: new 
Abstract: The design of communication systems has traditionally focused on the reliable and timely delivery of data. However, the scalability challenges faced by the evolution to a 6G-driven society demand new communication paradigms that carefully curate the content being transmitted. This paper envisions a joint semantic and task-oriented communication paradigm where Connected and Autonomous Vehicles (CAVs) transmit only the information necessary to convey the desired meaning that is relevant to the intended receivers based on the communication context. The V2X domain offers a unique environment for the development of the envisioned semantic and task-oriented communications paradigm, as CAVs are native semantic devices, and the V2X domain is rich in contextual information. This contextual information can be leveraged to estimate the relevance that information may have for the intended receivers. We illustrate and quantitatively evaluate the potential benefits of semantic and task-oriented V2X communications. Numerical results show that by focusing on the transmission of the most relevant information for the intended receivers, semantic and task-oriented V2X communications can achieve a two-fold improvement in communication efficiency, which will significantly benefit the scalability of V2X networks.</description>
      <guid isPermaLink="false">oai:arXiv.org:2508.07394v1</guid>
      <category>cs.NI</category>
      <pubDate>Tue, 12 Aug 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Luca Lusvarghi, Javier Gozalvez, Baldomero Coll-Perales, Mohammad Irfan Khan, Miguel Sepulcre, Seyhan Ucar, Onur Altintas</dc:creator>
    </item>
    <item>
      <title>Unveiling IPv6 Scanning Dynamics: A Longitudinal Study Using Large Scale Proactive and Passive IPv6 Telescopes</title>
      <link>https://arxiv.org/abs/2508.07506</link>
      <description>arXiv:2508.07506v1 Announce Type: new 
Abstract: We introduce new tools and vantage points to develop and integrate proactive techniques to attract IPv6 scan traffic, thus enabling its analysis. By deploying the largest-ever IPv6 proactive telescope in a production ISP network, we collected over 600M packets of unsolicited traffic from 1.9k Autonomous Systems in 10 months. We characterized the sources of unsolicited traffic, evaluated the effectiveness of five major features across the network stack, and inferred scanners' sources of target addresses and their strategies.</description>
      <guid isPermaLink="false">oai:arXiv.org:2508.07506v1</guid>
      <category>cs.NI</category>
      <pubDate>Tue, 12 Aug 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Hammas Bin Tanveer, Wai Sun Chan, Ricky K. P. Mok, Sebastian Kappes, Philipp Richter, Oliver Gasser, John Ronan, Arthur Berger, kc Claffy</dc:creator>
    </item>
    <item>
      <title>Achieving Fair-Effective Communications and Robustness in Underwater Acoustic Sensor Networks: A Semi-Cooperative Approach</title>
      <link>https://arxiv.org/abs/2508.07578</link>
      <description>arXiv:2508.07578v1 Announce Type: new 
Abstract: This paper investigates the fair-effective communication and robustness in imperfect and energy-constrained underwater acoustic sensor networks (IC-UASNs). Specifically, we investigate the impact of unexpected node malfunctions on the network performance under the time-varying acoustic channels. Each node is expected to satisfy Quality of Service (QoS) requirements. However, achieving individual QoS requirements may interfere with other concurrent communications. Underwater nodes rely excessively on the rationality of other underwater nodes when guided by fully cooperative approaches, making it difficult to seek a trade-off between individual QoS and global fair-effective communications under imperfect conditions. Therefore, this paper presents a SEmi-COoperative Power Allocation approach (SECOPA) that achieves fair-effective communication and robustness in IC-UASNs. The approach is distributed multi-agent reinforcement learning (MARL)-based, and the objectives are twofold. On the one hand, each intelligent node individually decides the transmission power to simultaneously optimize individual and global performance. On the other hand, advanced training algorithms are developed to provide imperfect environments for training robust models that can adapt to the time-varying acoustic channels and handle unexpected node failures in the network. Numerical results are presented to validate our proposed approach.</description>
      <guid isPermaLink="false">oai:arXiv.org:2508.07578v1</guid>
      <category>cs.NI</category>
      <pubDate>Tue, 12 Aug 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <arxiv:DOI>10.1109/TMC.2023.3310476</arxiv:DOI>
      <dc:creator>Yu Gou, Tong Zhang, Jun Liu, Tingting Yang, Shanshan Song, Jun-Hong Cui</dc:creator>
    </item>
    <item>
      <title>Joint Scheduling and Resource Allocation in mmWave IAB Networks Using Deep RL</title>
      <link>https://arxiv.org/abs/2508.07604</link>
      <description>arXiv:2508.07604v1 Announce Type: new 
Abstract: Integrated Access and Backhaul (IAB) is critical for dense 5G and beyond deployments, especially in mmWave bands where fiber backhaul is infeasible. We propose a novel Deep Reinforcement Learning (DRL) framework for joint link scheduling and resource slicing in dynamic, interference-prone IAB networks. Our method integrates a greedy Double Deep Q-Network (DDQN) scheduler to activate access and backhaul links based on traffic and topology, with a multi-agent DDQN allocator for bandwidth and antenna assignment across network slices. This decentralized approach respects strict antenna constraints and supports concurrent scheduling across heterogeneous links. Evaluations across 96 dynamic topologies show 99.84 percent scheduling accuracy and 20.90 percent throughput improvement over baselines. The framework's efficient operation and adaptability make it suitable for dynamic and resource-constrained deployments, where fast link scheduling and autonomous backhaul coordination are vital.</description>
      <guid isPermaLink="false">oai:arXiv.org:2508.07604v1</guid>
      <category>cs.NI</category>
      <pubDate>Tue, 12 Aug 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Maryam Abbasalizadeh, Sashank Narain</dc:creator>
    </item>
    <item>
      <title>Joint link scheduling and power allocation in imperfect and energy-constrained underwater wireless sensor networks</title>
      <link>https://arxiv.org/abs/2508.07679</link>
      <description>arXiv:2508.07679v1 Announce Type: new 
Abstract: Underwater wireless sensor networks (UWSNs) stand as promising technologies facilitating diverse underwater applications. However, the major design issues of the considered system are the severely limited energy supply and unexpected node malfunctions. This paper aims to provide fair, efficient, and reliable (FER) communication to the imperfect and energy-constrained UWSNs (IC-UWSNs). Therefore, we formulate a FER-communication optimization problem (FERCOP) and propose ICRL-JSA to solve the formulated problem. ICRL-JSA is a deep multi-agent reinforcement learning (MARL)-based optimizer for IC-UWSNs through joint link scheduling and power allocation, which automatically learns scheduling algorithms without human intervention. However, conventional RL methods are unable to address the challenges posed by underwater environments and IC-UWSNs. To construct ICRL-JSA, we integrate deep Q-network into IC-UWSNs and propose an advanced training mechanism to deal with complex acoustic channels, limited energy supplies, and unexpected node malfunctions. Simulation results demonstrate the superiority of the proposed ICRL-JSA scheme with an advanced training mechanism compared to various benchmark algorithms.</description>
      <guid isPermaLink="false">oai:arXiv.org:2508.07679v1</guid>
      <category>cs.NI</category>
      <pubDate>Tue, 12 Aug 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <arxiv:DOI>10.1109/TMC.2024.3368425</arxiv:DOI>
      <dc:creator>Tong Zhang, Yu Gou, Jun Liu, Shanshan Song, Tingting Yang, Jun-Hong Cui</dc:creator>
    </item>
    <item>
      <title>An Experimental Reservoir-Augmented Foundation Model: 6G O-RAN Case Study</title>
      <link>https://arxiv.org/abs/2508.07778</link>
      <description>arXiv:2508.07778v1 Announce Type: new 
Abstract: Next-generation open radio access networks (O-RAN) continuously stream tens of key performance indicators (KPIs) together with raw in-phase/quadrature (IQ) samples, yielding ultra-high-dimensional, non-stationary time series that overwhelm conventional transformer architectures. We introduce a reservoir-augmented masked autoencoding transformer (RA-MAT). This time series foundation model employs echo state network (ESN) computing with masked autoencoding to satisfy the stringent latency, energy efficiency, and scalability requirements of 6G O-RAN testing. A fixed, randomly initialized ESN rapidly projects each temporal patch into a rich dynamical embedding without backpropagation through time, converting the quadratic self-attention bottleneck into a lightweight linear operation. These embeddings drive a patch-wise masked autoencoder that reconstructs 30% randomly masked patches, compelling the encoder to capture both local dynamics and long-range structure from unlabeled data. After self-supervised pre-training, RA-MAT is fine-tuned with a shallow task head while keeping the reservoir and most transformer layers frozen, enabling low-footprint adaptation to diverse downstream tasks such as O-RAN KPI forecasting. In a comprehensive O-RAN KPI case study, RA-MAT achieved sub-0.06 mean squared error (MSE) on several continuous and discrete KPIs. This work positions RA-MAT as a practical pathway toward real-time, foundation-level analytics in future 6G networks.</description>
      <guid isPermaLink="false">oai:arXiv.org:2508.07778v1</guid>
      <category>cs.NI</category>
      <pubDate>Tue, 12 Aug 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Farhad Rezazadeh, Raymond Zhao, Jiongyu Dai, Amir Ashtari Gargari, Hatim Chergui, Lingjia Liu</dc:creator>
    </item>
    <item>
      <title>Scalable and Energy-Efficient Predictive Data Collection in Wireless Sensor Networks with Constructive Interference</title>
      <link>https://arxiv.org/abs/2508.07882</link>
      <description>arXiv:2508.07882v1 Announce Type: new 
Abstract: A new class of Wireless Sensor Network has emerged whereby multiple nodes transmit data simultaneously, exploiting constructive interference to enable data collection frameworks with low energy usage and latency. This paper presents STAIR (Spatio-Temporal Activation for Intelligent Relaying), a scalable, resilient framework for Wireless Sensor Networks that leverages constructive interference and operates effectively under stringent resource constraints. Using constructive interference requires all nodes to transmit the same packet at the same time, thus, only one source node can send data per time slot. STAIR uses coarse-grained topology information to flood a selected subset of the network, relaying sensor readings from individual nodes during their allocated time slots. A submodular optimisation algorithm with proven quality bounds determines near-optimal sensor activation locations and times, aiming to minimise the sum of mean squared prediction errors from a multiple multivariate linear regression model, which is used to estimate values at unselected locations and times. This framework has been extensively validated on a real-world testbed deployment.</description>
      <guid isPermaLink="false">oai:arXiv.org:2508.07882v1</guid>
      <category>cs.NI</category>
      <pubDate>Tue, 12 Aug 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Conor Muldoon</dc:creator>
    </item>
    <item>
      <title>Adaptive Multiple Access and Service Placement for Generative Diffusion Models</title>
      <link>https://arxiv.org/abs/2508.07978</link>
      <description>arXiv:2508.07978v1 Announce Type: new 
Abstract: Generative Diffusion Models (GDMs) have emerged as key components of Generative Artificial Intelligence (GenAI), offering unparalleled expressiveness and controllability for complex data generation tasks. However, their deployment in real-time and mobile environments remains challenging due to the iterative and resource-intensive nature of the inference process. Addressing these challenges, this paper introduces a unified optimization framework that jointly tackles service placement and multiple access control for GDMs in mobile edge networks. We propose LEARN-GDM, a Deep Reinforcement Learning-based algorithm that dynamically partitions denoising blocks across heterogeneous edge nodes, while accounting for latent transmission costs and enabling adaptive reduction of inference steps. Our approach integrates a greedy multiple access scheme with a Double and Dueling Deep Q-Learning (D3QL)-based service placement, allowing for scalable, adaptable, and resource-efficient operation under stringent quality of service requirements. Simulations demonstrate the superior performance of the proposed framework in terms of scalability and latency resilience compared to conventional monolithic and fixed chain-length placement strategies. This work advances the state of the art in edge-enabled GenAI by offering an adaptable solution for GDM services orchestration, paving the way for future extensions toward semantic networking and co-inference across distributed environments.</description>
      <guid isPermaLink="false">oai:arXiv.org:2508.07978v1</guid>
      <category>cs.NI</category>
      <pubDate>Tue, 12 Aug 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Hamidreza Mazandarani, Mohammad Farhoudi, Masoud Shokrnezhad, Tarik Taleb</dc:creator>
    </item>
    <item>
      <title>Industrial Viewpoints on RAN Technologies for 6G</title>
      <link>https://arxiv.org/abs/2508.08225</link>
      <description>arXiv:2508.08225v1 Announce Type: new 
Abstract: 6G standardization is to start imminently, with commercial deployments expected before 2030. Its technical components and performance requirements are the focus of this article. Our emphasis is on the 6G radio access, especially MIMO, AI, waveforms, coding, signal constellations and integration with non-terrestrial networks. Whilst standardization has not yet formally started, the scope of the 6G study items has been defined. Our predictions in this paper are speculative as there are no results of the study yet, but our views are guided by implementation and deployment aspects. We expect that the views here will guide researchers and industry practitioners.</description>
      <guid isPermaLink="false">oai:arXiv.org:2508.08225v1</guid>
      <category>cs.NI</category>
      <category>cs.IT</category>
      <category>eess.SP</category>
      <category>math.IT</category>
      <pubDate>Tue, 12 Aug 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Mansoor Shafi, Erik G. Larsson, Xingqin Lin, Dorin Panaitopol, Stefan Parkvall, Flavien Ronteix-Jacquet, Antti Toskala</dc:creator>
    </item>
    <item>
      <title>Multimodal Remote Inference</title>
      <link>https://arxiv.org/abs/2508.07555</link>
      <description>arXiv:2508.07555v1 Announce Type: cross 
Abstract: We consider a remote inference system with multiple modalities, where a multimodal machine learning (ML) model performs real-time inference using features collected from remote sensors. As sensor observations may change dynamically over time, fresh features are critical for inference tasks. However, timely delivering features from all modalities is often infeasible due to limited network resources. To this end, we study a two-modality scheduling problem to minimize the ML model's inference error, which is expressed as a penalty function of AoI for both modalities. We develop an index-based threshold policy and prove its optimality. Specifically, the scheduler switches modalities when the current modality's index function exceeds a threshold. We show that the two modalities share the same threshold, and both the index functions and the threshold can be computed efficiently. The optimality of our policy holds for (i) general AoI functions that are \emph{non-monotonic} and \emph{non-additive} and (ii) \emph{heterogeneous} transmission times. Numerical results show that our policy reduces inference error by up to 55% compared to round-robin and uniform random policies, which are oblivious to the AoI-based inference error function. Our results shed light on how to improve remote inference accuracy by optimizing task-oriented AoI functions.</description>
      <guid isPermaLink="false">oai:arXiv.org:2508.07555v1</guid>
      <category>cs.LG</category>
      <category>cs.IT</category>
      <category>cs.NI</category>
      <category>math.IT</category>
      <pubDate>Tue, 12 Aug 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Keyuan Zhang, Yin Sun, Bo Ji</dc:creator>
    </item>
    <item>
      <title>Optimization of Private Semantic Communication Performance: An Uncooperative Covert Communication Method</title>
      <link>https://arxiv.org/abs/2508.07586</link>
      <description>arXiv:2508.07586v1 Announce Type: cross 
Abstract: In this paper, a novel covert semantic communication framework is investigated. Within this framework, a server extracts and transmits the semantic information, i.e., the meaning of image data, to a user over several time slots. An attacker seeks to detect and eavesdrop the semantic transmission to acquire details of the original image. To avoid data meaning being eavesdropped by an attacker, a friendly jammer is deployed to transmit jamming signals to interfere the attacker so as to hide the transmitted semantic information. Meanwhile, the server will strategically select time slots for semantic information transmission. Due to limited energy, the jammer will not communicate with the server and hence the server does not know the transmit power of the jammer. Therefore, the server must jointly optimize the semantic information transmitted at each time slot and the corresponding transmit power to maximize the privacy and the semantic information transmission quality of the user. To solve this problem, we propose a prioritised sampling assisted twin delayed deep deterministic policy gradient algorithm to jointly determine the transmitted semantic information and the transmit power per time slot without the communications between the server and the jammer. Compared to standard reinforcement learning methods, the propose method uses an additional Q network to estimate Q values such that the agent can select the action with a lower Q value from the two Q networks thus avoiding local optimal action selection and estimation bias of Q values. Simulation results show that the proposed algorithm can improve the privacy and the semantic information transmission quality by up to 77.8% and 14.3% compared to the traditional reinforcement learning methods.</description>
      <guid isPermaLink="false">oai:arXiv.org:2508.07586v1</guid>
      <category>cs.AI</category>
      <category>cs.NI</category>
      <pubDate>Tue, 12 Aug 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Wenjing Zhang, Ye Hu, Tao Luo, Zhilong Zhang, Mingzhe Chen</dc:creator>
    </item>
    <item>
      <title>Over-the-Top Resource Broker System for Split Computing: An Approach to Distribute Cloud Computing Infrastructure</title>
      <link>https://arxiv.org/abs/2508.07744</link>
      <description>arXiv:2508.07744v1 Announce Type: cross 
Abstract: 6G network architectures will usher in a wave of innovative services and capabilities, introducing concepts like split computing and dynamic processing nodes. This implicates a paradigm where accessing resources seamlessly aligns with diverse processing node characteristics, ensuring a uniform interface. In this landscape, the identity of the operator becomes inconsequential, paving the way for a collaborative ecosystem where multiple providers contribute to a shared pool of resources. At the core of this vision is the guarantee of specific performance parameters, precisely tailored to the location and service requirements. A consistent layer, as the abstraction of the complexities of different infrastructure providers, is needed to simplify service deployment. One promising approach is the introduction of an over-the-top broker for resource allocation, which streamlines the integration of these services into the network and cloud infrastructure of the future. This paper explores the role of the broker in two split computing scenarios. By abstracting the complexities of various infrastructures, the broker proves to be a versatile solution applicable not only to cloud environments but also to networks and beyond. Additionally, a detailed discussion of a proof-of-concept implementation provides insights into the broker's actual architectural framework.</description>
      <guid isPermaLink="false">oai:arXiv.org:2508.07744v1</guid>
      <category>cs.DC</category>
      <category>cs.NI</category>
      <category>eess.SP</category>
      <pubDate>Tue, 12 Aug 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Ingo Friese, Jochen Klaffer, Mandy Galkow-Schneider, Sergiy Melnyk, Qiuheng Zhou, Hans Dieter Schotten</dc:creator>
    </item>
    <item>
      <title>Performance Evaluation of Brokerless Messaging Libraries</title>
      <link>https://arxiv.org/abs/2508.07934</link>
      <description>arXiv:2508.07934v1 Announce Type: cross 
Abstract: Messaging systems are essential for efficiently transferring large volumes of data, ensuring rapid response times and high-throughput communication. The state-of-the-art on messaging systems mainly focuses on the performance evaluation of brokered messaging systems, which use an intermediate broker to guarantee reliability and quality of service. However, over the past decade, brokerless messaging systems have emerged, eliminating the single point of failure and trading off reliability guarantees for higher performance. Still, the state-of-the-art on evaluating the performance of brokerless systems is scarce. In this work, we solely focus on brokerless messaging systems. First, we perform a qualitative analysis of several possible candidates, to find the most promising ones. We then design and implement an extensive open-source benchmarking suite to systematically and fairly evaluate the performance of the chosen libraries, namely, ZeroMQ, NanoMsg, and NanoMsg-Next-Generation (NNG). We evaluate these libraries considering different metrics and workload conditions, and provide useful insights into their limitations. Our analysis enables practitioners to select the most suitable library for their requirements.</description>
      <guid isPermaLink="false">oai:arXiv.org:2508.07934v1</guid>
      <category>cs.DC</category>
      <category>cs.NI</category>
      <pubDate>Tue, 12 Aug 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Lorenzo La Corte, Syed Aftab Rashid, Andrei-Marian Dan</dc:creator>
    </item>
    <item>
      <title>A Deep Learning Based Resource Allocator for Communication Networks with Dynamic User Utility Demands</title>
      <link>https://arxiv.org/abs/2311.04600</link>
      <description>arXiv:2311.04600v3 Announce Type: replace-cross 
Abstract: Deep learning (DL) based resource allocation (RA) has recently gained significant attention due to its performance efficiency. However, most related studies assume an ideal case where the number of users and their utility demands, e.g., data rate constraints, are fixed, and the designed DL-based RA scheme exploits a policy trained only for these fixed parameters. Consequently, computationally complex policy retraining is required whenever these parameters change. In this paper, we introduce a DL-based resource allocator (ALCOR) that allows users to adjust their utility demands freely, such as based on their application layer requirements. ALCOR employs deep neural networks (DNNs) as the policy in a time-sharing problem. The underlying optimization algorithm iteratively optimizes the on-off status of users to satisfy their utility demands in expectation. The policy performs unconstrained RA (URA) -- RA without considering user utility demands -- among active users to maximize the sum utility (SU) at each time instant. Depending on the chosen URA scheme, ALCOR can perform RA in either a centralized or distributed scenario. The derived convergence analyses provide theoretical guarantees for ALCOR's convergence, and numerical experiments corroborate its effectiveness compared to meta-learning and reinforcement learning approaches.</description>
      <guid isPermaLink="false">oai:arXiv.org:2311.04600v3</guid>
      <category>eess.SP</category>
      <category>cs.LG</category>
      <category>cs.NI</category>
      <category>math.OC</category>
      <pubDate>Tue, 12 Aug 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <arxiv:DOI>10.1109/TWC.2025.3592774</arxiv:DOI>
      <dc:creator>Pourya Behmandpoor, Mark Eisen, Panagiotis Patrinos, Marc Moonen</dc:creator>
    </item>
    <item>
      <title>Toward Intelligent and Secure Cloud: Large Language Model Empowered Proactive Defense</title>
      <link>https://arxiv.org/abs/2412.21051</link>
      <description>arXiv:2412.21051v3 Announce Type: replace-cross 
Abstract: The rapid evolution of cloud computing technologies and the increasing number of cloud applications have provided numerous benefits in our daily lives. However, the diversity and complexity of different components pose a significant challenge to cloud security, especially when dealing with sophisticated and advanced cyberattacks such as Denial of Service (DoS). Recent advancements in the large language models (LLMs) offer promising solutions for security intelligence. By exploiting the powerful capabilities in language understanding, data analysis, task inference, action planning, and code generation, we present LLM-PD, a novel defense architecture that proactively mitigates various DoS threats in cloud networks. LLM-PD can efficiently make decisions through comprehensive data analysis and sequential reasoning, as well as dynamically create and deploy actionable defense mechanisms. Furthermore, it can flexibly self-evolve based on experience learned from previous interactions and adapt to new attack scenarios without additional training. Our case study on three distinct DoS attacks demonstrates its remarkable ability in terms of defense effectiveness and efficiency when compared with other existing methods.</description>
      <guid isPermaLink="false">oai:arXiv.org:2412.21051v3</guid>
      <category>cs.CR</category>
      <category>cs.AI</category>
      <category>cs.NI</category>
      <pubDate>Tue, 12 Aug 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Yuyang Zhou, Guang Cheng, Kang Du, Zihan Chen, Yuyu Zhao</dc:creator>
    </item>
  </channel>
</rss>
