<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>cs.CC updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/cs.CC</link>
    <description>cs.CC updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/cs.CC" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Tue, 09 Sep 2025 02:26:07 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Mon, 08 Sep 2025 00:00:00 -0400</pubDate>
    <skipDays>
      <day>Saturday</day>
      <day>Sunday</day>
    </skipDays>
    <item>
      <title>Computing the Elementary Symmetric Polynomials in Positive Characteristics</title>
      <link>https://arxiv.org/abs/2509.05009</link>
      <description>arXiv:2509.05009v1 Announce Type: new 
Abstract: We first extend the results of CKSV22 by showing that the degree $d$ elementary symmetric polynomials in $n$ variables have formula lower bounds of $\Omega(d(n-d))$ over fields of positive characteristic. Then, we show that the results of the universality of the symmetric model from Shp02 and the results about border fan-in two $\Sigma\Pi\Sigma$ circuits from Kum20 over zero characteristic fields do not extend to fields of positive characteristic. In particular, we show that 
  1.There are polynomials that cannot be represented as linear projections of the elementary symmetric polynomials (in fact, we show that they cannot be represented as the sum of $k$ such projections for a fixed $k$) and
  2. There are polynomials that cannot be computed by border depth-$3$ circuits of top fan-in $k$, called $\overline{\Sigma^{[k]}\Pi\Sigma}$, for $k = o(n)$. 
  To prove the first result, we consider a geometric property of the elementary symmetric polynomials, namely, the set of all points in which the polynomial and all of its first-order partial derivatives vanish. It was shown in MZ17 and LMP19 that the dimension of this space was exactly $d-2$ for fields of zero characteristic. We extend this to fields of positive characteristic by showing that this dimension must be between $d-2$ and $d-1$. In fact, we show this bound is tight, in the sense that there are (infinitely many) polynomials where each of these bounds is exact.
  Then, to consider the border top fan-in of the symmetric model and depth-$3$ circuits (sometimes called border affine Chow rank), we show that it is sufficient to consider the border top fan-in of the sum of linear projections of the elementary symmetric polynomials. This is done by constructing an explicit metapolynomial to check the condition, meaning that this result also applies in the border setting.</description>
      <guid isPermaLink="false">oai:arXiv.org:2509.05009v1</guid>
      <category>cs.CC</category>
      <pubDate>Mon, 08 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Ian Orzel</dc:creator>
    </item>
    <item>
      <title>Improved Bounds for Twin-Width Parameter Variants with Algorithmic Applications to Counting Graph Colorings</title>
      <link>https://arxiv.org/abs/2509.05122</link>
      <description>arXiv:2509.05122v1 Announce Type: new 
Abstract: The $H$-Coloring problem is a well-known generalization of the classical NP-complete problem $k$-Coloring where the task is to determine whether an input graph admits a homomorphism to the template graph $H$. This problem has been the subject of intense theoretical research and in this article we study the complexity of $H$-Coloring with respect to the parameters clique-width and the more recent component twin-width, which describe desirable computational properties of graphs. We give two surprising linear bounds between these parameters, thus improving the previously known exponential and double exponential bounds. Our constructive proof naturally extends to related parameters and as a showcase we prove that total twin-width and linear clique-width can be related via a tight quadratic bound. These bounds naturally lead to algorithmic applications. The linear bounds between component twin-width and clique-width entail natural approximations of component twin-width, by making use of the results known for clique-width. As for computational aspects of graph coloring, we target the richer problem of counting the number of homomorphisms to $H$ (#$H$-Coloring). The first algorithm that we propose uses a contraction sequence of the input graph $G$ parameterized by the component twin-width of $G$. This leads to a positive FPT result for the counting version. The second uses a contraction sequence of the template graph $H$ and here we instead measure the complexity with respect to the number of vertices in the input graph. Using our linear bounds we show that our algorithms are always at least as fast as the previously best #$H$-Coloring algorithms (based on clique-width) and for several interesting classes of graphs (e.g., cographs, cycles of length $\ge 7$, or distance-hereditary graphs) are in fact strictly faster.</description>
      <guid isPermaLink="false">oai:arXiv.org:2509.05122v1</guid>
      <category>cs.CC</category>
      <category>cs.DS</category>
      <pubDate>Mon, 08 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Ambroise Baril, Miguel Couceiro, Victor Lagerkvist</dc:creator>
    </item>
    <item>
      <title>Algorithmic Information Bounds for Distances and Orthogonal Projections</title>
      <link>https://arxiv.org/abs/2509.05211</link>
      <description>arXiv:2509.05211v1 Announce Type: new 
Abstract: We develop quantitative algorithmic information bounds for orthogonal projections and distances in the plane. Under mild independence conditions, the distance $|x-y|$ and a projection coordinate $p_e x$ each retain at least half the algorithmic information content of $x$ in the sense of finite-precision Kolmogorov complexity, up to lower-order terms. Our bounds support conditioning on coarser approximations, enabling case analyses across precision scales. The proofs introduce a surrogate point selection step. Via the point-to-set principle we derive a new bound on the Hausdorff dimension of pinned distance sets, showing that every analytic set $E\subseteq\mathbb{R}^2$ with $\dim_H(E)\leq 1$ satisfies
  \[\sup_{x\in E}\dim_H(\Delta_x E)\geq \frac{3}{4}\dim_H(E).\]
  We also extend Bourgain's theorem on exceptional sets for orthogonal projections to all sets that admit optimal Hausdorff oracles.</description>
      <guid isPermaLink="false">oai:arXiv.org:2509.05211v1</guid>
      <category>cs.CC</category>
      <category>math.CA</category>
      <pubDate>Mon, 08 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Peter Cholak, Marianna Cs\"ornyei, Neil Lutz, Patrick Lutz, Elvira Mayordomo, D. M. Stull</dc:creator>
    </item>
    <item>
      <title>Can Almost Everybody be Almost Happy? PCP for PPAD and the Inapproximability of Nash</title>
      <link>https://arxiv.org/abs/1504.02411</link>
      <description>arXiv:1504.02411v4 Announce Type: replace 
Abstract: We conjecture that PPAD has a PCP-like complete problem, seeking a near equilibrium in which all but very few players have very little incentive to deviate. We show that, if one assumes that this problem requires exponential time, several open problems in this area are settled. The most important implication, proved via a "birthday repetition" reduction, is that the n^O(log n) approximation scheme of [LMM03] for the Nash equilibrium of two-player games is essentially optimum. Two other open problems in the area are resolved once one assumes this conjecture, establishing that certain approximate equilibria are PPAD-complete: Finding a relative approximation of two-player Nash equilibria (without the well-supported restriction of [Das13]), and an approximate competitive equilibrium with equal incomes [Bud11] with small clearing error and near-optimal Gini coefficient.</description>
      <guid isPermaLink="false">oai:arXiv.org:1504.02411v4</guid>
      <category>cs.CC</category>
      <category>cs.GT</category>
      <pubDate>Mon, 08 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Yakov Babichenko, Christos Papadimitriou, Aviad Rubinstein</dc:creator>
    </item>
    <item>
      <title>Structure of sparse Boolean functions over Abelian groups, and its application to testing</title>
      <link>https://arxiv.org/abs/2406.18700</link>
      <description>arXiv:2406.18700v2 Announce Type: replace 
Abstract: We study Fourier-sparse Boolean functions over general finite Abelian groups. A Boolean function $f : \mathcal{G} \to \{-1,+1\}$ is $s$-sparse if it has at most $s$ non-zero Fourier coefficients. We introduce a general notion of \emph{granularity} of Fourier coefficients and prove that every non-zero coefficient of an $s$-sparse Boolean function has magnitude at least \[ \frac{1}{2^{\varphi(\lcmG)/2} \, s^{\varphi(\lcmG)/2}}, \] where $\Delta$ denotes the exponent of the group $\mathcal{G}$ (that is, the maximum order of an element in $\mathcal{G}$) and $\varphi$ is the Euler's totient function. This generalizes the celebrated result of Gopalan et al. (SICOMP 2011) for $\mathbb{Z}_2^n$, extending it to all finite Abelian groups via new techniques from group theory and algebraic number theory.
  Using our new structural results on the Fourier coefficients of sparse functions, we design an efficient sparsity testing algorithm for Boolean functions. The tester distinguishes whether a given function is $s$-sparse or $\epsilon$-far from every $s$-sparse Boolean function, with query complexity $poly\left((2s)^{\varphi(\lcmG)},1/\epsilon \right)$. In addition, we generalize the classical notion of Boolean degree to arbitrary Abelian groups and establish an $\Omega(\sqrt{s})$ lower bound for adaptive sparsity testing.</description>
      <guid isPermaLink="false">oai:arXiv.org:2406.18700v2</guid>
      <category>cs.CC</category>
      <pubDate>Mon, 08 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Sourav Chakraborty, Swarnalipa Datta, Pranjal Dutta, Arijit Ghosh, Swagato Sanyal</dc:creator>
    </item>
    <item>
      <title>A LOCAL View of the Polynomial Hierarchy</title>
      <link>https://arxiv.org/abs/2305.09538</link>
      <description>arXiv:2305.09538v4 Announce Type: replace-cross 
Abstract: We extend classical methods of computational complexity to the realm of distributed computing, where they sometimes prove more effective than in their original context. Our focus is on decision problems in the LOCAL model, a setting in which networked computers use synchronous message passing to collectively answer questions about their network topology. We impose two time constraints on this model: the number of communication rounds is bounded by a constant, and the number of computation steps of each computer is polynomially bounded in the size of its local input and received messages.
  By letting two players alternately assign certificates to all computers, we obtain a distributed generalization of the polynomial hierarchy (and thus of the complexity classes $\mathbf{P}$ and $\mathbf{NP}$). We then extend key results of complexity theory to this setting, including the Cook-Levin theorem (which identifies Boolean satisfiability as a complete problem for $\mathbf{NP}$) and Fagin's theorem (which characterizes $\mathbf{NP}$ as the class of problems expressible in existential second-order logic). The original results can be recovered as the special case where the network consists of a single computer.
  But perhaps more surprisingly, separating complexity classes becomes easier in the distributed setting: we can show that our hierarchy is infinite, while it remains notoriously open whether the same holds when restricted to a single computer. (By contrast, a collapse of our hierarchy would have implied a collapse of the classical polynomial hierarchy.)
  As an application, we propose quantifier alternation as a new tool for measuring the locality of problems in distributed computing.</description>
      <guid isPermaLink="false">oai:arXiv.org:2305.09538v4</guid>
      <category>cs.DC</category>
      <category>cs.CC</category>
      <category>cs.FL</category>
      <category>cs.LO</category>
      <pubDate>Mon, 08 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Fabian Reiter</dc:creator>
    </item>
    <item>
      <title>Expansion of higher-dimensional cubical complexes with application to quantum locally testable codes</title>
      <link>https://arxiv.org/abs/2402.07476</link>
      <description>arXiv:2402.07476v3 Announce Type: replace-cross 
Abstract: We introduce a high-dimensional cubical complex, for any dimension t&gt;0, and apply it to the design of quantum locally testable codes. Our complex is a natural generalization of the constructions by Panteleev and Kalachev and by Dinur et. al of a square complex (case t=2), which have been applied to the design of classical locally testable codes (LTC) and quantum low-density parity check codes (qLDPC) respectively.
  We turn the geometric (cubical) complex into a chain complex by relying on constant-sized local codes $h_1,\ldots,h_t$ as gadgets. A recent result of Panteleev and Kalachev on existence of tuples of codes that are product expanding enables us to prove lower bounds on the cycle and co-cycle expansion of our chain complex.
  For t=4 our construction gives a new family of "almost-good" quantum LTCs -- with constant relative rate, inverse-polylogarithmic relative distance and soundness, and constant-size parity checks. Both the distance of the quantum code and its local testability are proven directly from the cycle and co-cycle expansion of our chain complex.</description>
      <guid isPermaLink="false">oai:arXiv.org:2402.07476v3</guid>
      <category>quant-ph</category>
      <category>cs.CC</category>
      <category>cs.IT</category>
      <category>math.IT</category>
      <pubDate>Mon, 08 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Irit Dinur, Ting-Chun Lin, Thomas Vidick</dc:creator>
    </item>
    <item>
      <title>When and Why is Persuasion Hard? A Computational Complexity Result</title>
      <link>https://arxiv.org/abs/2408.07923</link>
      <description>arXiv:2408.07923v2 Announce Type: replace-cross 
Abstract: As generative foundation models improve, they also tend to become more persuasive, raising concerns that AI automation will enable governments, firms, and other actors to manipulate beliefs with unprecedented scale and effectiveness at virtually no cost. The full economic and social ramifications of this trend have been difficult to foresee, however, given that we currently lack a complete theoretical understanding of why persuasion is costly for human labor to produce in the first place. This paper places human and AI agents on a common conceptual footing by formalizing informational persuasion as a mathematical decision problem and characterizing its computational complexity. A novel proof establishes that persuasive messages are challenging to discover (NP-Hard) but easy to adopt if supplied by others (NP). This asymmetry helps explain why people are susceptible to persuasion, even in contexts where all relevant information is publicly available. The result also illuminates why litigation, strategic communication, and other persuasion-oriented activities have historically been so human capital intensive, and it provides a new theoretical basis for studying how AI will impact various industries.</description>
      <guid isPermaLink="false">oai:arXiv.org:2408.07923v2</guid>
      <category>cs.CY</category>
      <category>cs.CC</category>
      <category>econ.GN</category>
      <category>q-fin.EC</category>
      <pubDate>Mon, 08 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Zachary Wojtowicz</dc:creator>
    </item>
    <item>
      <title>Multi-Pass Streaming Lower Bounds for Approximating Max-Cut</title>
      <link>https://arxiv.org/abs/2503.23404</link>
      <description>arXiv:2503.23404v2 Announce Type: replace-cross 
Abstract: In the Max-Cut problem in the streaming model, an algorithm is given the edges of an unknown graph $G = (V,E)$ in some fixed order, and its goal is to approximate the size of the largest cut in $G$. Improving upon an earlier result of Kapralov, Khanna and Sudan, it was shown by Kapralov and Krachun that for all $\varepsilon&gt;0$, no $o(n)$ memory streaming algorithm can achieve a $(1/2+\varepsilon)$-approximation for Max-Cut. Their result holds for single-pass streams, i.e.~the setting in which the algorithm only views the stream once, and it was open whether multi-pass access may help. The state-of-the-art result along these lines, due to Assadi and N, rules out arbitrarily good approximation algorithms with constantly many passes and $n^{1-\delta}$ space for any $\delta&gt;0$.
  We improve upon this state-of-the-art result, showing that any non-trivial approximation algorithm for Max-Cut requires either polynomially many passes or polynomially large space. More specifically, we show that for all $\varepsilon&gt;0$, a $k$-pass streaming $(1/2+\varepsilon)$-approximation algorithm for Max-Cut requires $\Omega_{\varepsilon}\left(n^{1/3}/k\right)$ space. This result leads to a similar lower bound for the Maximum Directed Cut problem, showing the near optimality of the algorithm of [Saxena, Singer, Sudan, Velusamy, SODA 2025].
  Our lower bounds proceed by showing a communication complexity lower bound for the Distributional Implicit Hidden Partition (DIHP) Problem, introduced by Kapralov and Krachun. While a naive application of the discrepancy method fails, we identify a property of protocols called ``globalness'', and show that (1) any protocol for DIHP can be turned into a global protocol, (2) the discrepancy of a global protocol must be small. The second step is the more technically involved step in the argument, and therein we use global hypercontractive inequalities.</description>
      <guid isPermaLink="false">oai:arXiv.org:2503.23404v2</guid>
      <category>cs.DS</category>
      <category>cs.CC</category>
      <category>cs.DM</category>
      <pubDate>Mon, 08 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Yumou Fei, Dor Minzer, Shuo Wang</dc:creator>
    </item>
    <item>
      <title>Epistemic Skills: Reasoning about Knowledge and Oblivion</title>
      <link>https://arxiv.org/abs/2504.01733</link>
      <description>arXiv:2504.01733v2 Announce Type: replace-cross 
Abstract: This paper presents a class of epistemic logics that captures the dynamics of acquiring knowledge and descending into oblivion, while incorporating concepts of group knowledge. The approach is grounded in a system of weighted models, introducing an ``epistemic skills'' metric to represent the epistemic capacities tied to knowledge updates. Within this framework, knowledge acquisition is modeled as a process of upskilling, whereas oblivion is represented as a consequence of downskilling. The framework further enables exploration of ``knowability'' and ``forgettability,'' defined as the potential to gain knowledge through upskilling and to lapse into oblivion through downskilling, respectively. Additionally, it supports a detailed analysis of the distinctions between epistemic de re and de dicto expressions. The computational complexity of the model checking and satisfiability problems is examined, offering insights into their theoretical foundations and practical implications.</description>
      <guid isPermaLink="false">oai:arXiv.org:2504.01733v2</guid>
      <category>cs.AI</category>
      <category>cs.CC</category>
      <category>cs.LO</category>
      <pubDate>Mon, 08 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Xiaolong Liang, Y\`i N. W\'ang</dc:creator>
    </item>
  </channel>
</rss>
