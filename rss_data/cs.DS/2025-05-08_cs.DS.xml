<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>cs.DS updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/cs.DS</link>
    <description>cs.DS updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/cs.DS" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Fri, 09 May 2025 01:42:54 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Thu, 08 May 2025 00:00:00 -0400</pubDate>
    <skipDays>
      <day>Saturday</day>
      <day>Sunday</day>
    </skipDays>
    <item>
      <title>Differentially Private Densest-$k$-Subgraph</title>
      <link>https://arxiv.org/abs/2505.03858</link>
      <description>arXiv:2505.03858v1 Announce Type: new 
Abstract: Many graph datasets involve sensitive network data, motivating the need for privacy-preserving graph mining. The Densest-$k$-subgraph (D$k$S) problem is a key primitive in graph mining that aims to extract a subset of $k$ vertices with the maximum internal connectivity. Although non-private algorithms are known for D$k$S, this paper is the first to design algorithms that offer formal differential privacy (DP) guarantees for the problem. We base our general approach on using the principal component (PC) of the graph adjacency matrix to output a subset of $k$ vertices under edge DP. For this task, we first consider output perturbation, which traditionally offer good scalability, but at the expense of utility. Our tight on the local sensitivity indicate a big gap with the global sensitivity, motivating the use of instance specific sensitive methods for private PC. Next, we derive a tight bound on the smooth sensitivity and show that it can be close to the global sensitivity. This leads us to consider the Propose-Test-Release (PTR) framework for private PC. Although computationally expensive in general, we design a novel approach for implementing PTR in the same time as computation of a non-private PC, while offering good utility for \DkS{}. Additionally, we also consider the iterative private power method (PPM) for private PC, albeit it is significantly slower than PTR on large networks. We run our methods on diverse real-world networks, with the largest having 3 million vertices, and show good privacy-utility trade-offs. Although PTR requires a slightly larger privacy budget, on average, it achieves a 180-fold improvement in runtime over PPM.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.03858v1</guid>
      <category>cs.DS</category>
      <category>cs.LG</category>
      <pubDate>Thu, 08 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Alireza Khayatian, Anil Vullikanti, Aritra Konar</dc:creator>
    </item>
    <item>
      <title>Bicluster Editing with Overlaps: A Vertex Splitting Approach</title>
      <link>https://arxiv.org/abs/2505.03959</link>
      <description>arXiv:2505.03959v1 Announce Type: new 
Abstract: The BiCluster Editing problem aims at editing a given bipartite graph into a disjoint union of bicliques via a minimum number of edge deletion or addition operations. As a graph-based model for data clustering, the problem aims at a partition of the input dataset, which cannot always obtain meaningful clusters when some data elements are expected to belong to more than one cluster each. To address this limitation, we introduce the Bicluster Editing with Vertex Splitting problem (BCEVS) which consists of finding a minimum sequence of edge editions and vertex splittings such that the result graph is a disjoint union of bicliques. The vertex splitting operation consists of replacing a vertex $v$ with two vertices whose union of neighborhoods is the neighborhood of $v$. We also introduce the problem of Bicluster Editing with One-Sided Vertex Splitting (BCEOVS) where we restrict the splitting operations to the first set of the bipartition (often corresponding to data elements in the input raw data). We prove the two problems are NP-complete even when restricted to bipartite planar graphs of maximum degree three. Moreover, assuming the Exponential Time Hypothesis holds, there is no $2^{o(n)}n^{O(1)}$-time (resp. $2^{o(\sqrt{n})}n^{O(1)}$-time) algorithm for BCEVS and BCEOVS on bipartite (resp. planar) graphs with maximum degree three where $n$ is the number of vertices of the graph. Furthermore we prove both problems are APX-hard and solvable in polynomial time on trees. On the other hand, we prove that BCEOVS is fixed parameter tractable with respect to solution size and admits a polynomial size kernel.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.03959v1</guid>
      <category>cs.DS</category>
      <pubDate>Thu, 08 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Faisal N. Abu-Khzam, Lucas Isenmann, Zeina Merchad</dc:creator>
    </item>
    <item>
      <title>The Kinetic Hourglass Data Structure for Computing the Bottleneck Distance of Dynamic Data</title>
      <link>https://arxiv.org/abs/2505.04048</link>
      <description>arXiv:2505.04048v1 Announce Type: new 
Abstract: The kinetic data structure (KDS) framework is a powerful tool for maintaining various geometric configurations of continuously moving objects. In this work, we introduce the kinetic hourglass, a novel KDS implementation designed to compute the bottleneck distance for geometric matching problems. We detail the events and updates required for handling general graphs, accompanied by a complexity analysis. Furthermore, we demonstrate the utility of the kinetic hourglass by applying it to compute the bottleneck distance between two persistent homology transforms (PHTs) derived from shapes in $\mathbb{R}^2$, which are topological summaries obtained by computing persistent homology from every direction in $\mathbb{S}^1$.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.04048v1</guid>
      <category>cs.DS</category>
      <pubDate>Thu, 08 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Elizabeth Munch, Elena Xinyi Wang, Carola Wenk</dc:creator>
    </item>
    <item>
      <title>Light Spanners with Small Hop-Diameter</title>
      <link>https://arxiv.org/abs/2505.04536</link>
      <description>arXiv:2505.04536v1 Announce Type: new 
Abstract: Lightness, sparsity, and hop-diameter are the fundamental parameters of geometric spanners. Arya et al. [STOC'95] showed in their seminal work that there exists a construction of Euclidean $(1+\varepsilon)$-spanners with hop-diameter $O(\log n)$ and lightness $O(\log n)$. They also gave a general tradeoff of hop-diameter $k$ and sparsity $O(\alpha_k(n))$, where $\alpha_k$ is a very slowly growing inverse of an Ackermann-style function. The former combination of logarithmic hop-diameter and lightness is optimal due to the lower bound by Dinitz et al. [FOCS'08]. Later, Elkin and Solomon [STOC'13] generalized the light spanner construction to doubling metrics and extended the tradeoff for more values of hop-diameter $k$. In a recent line of work [SoCG'22, SoCG'23], Le et al. proved that the aforementioned tradeoff between the hop-diameter and sparsity is tight for every choice of hop-diameter $k$. A fundamental question remains: What is the optimal tradeoff between the hop-diameter and lightness for every value of $k$?
  In this paper, we present a general framework for constructing light spanners with small hop-diameter. Our framework is based on tree covers. In particular, we show that if a metric admits a tree cover with $\gamma$ trees, stretch $t$, and lightness $L$, then it also admits a $t$-spanner with hop-diameter $k$ and lightness $O(kn^{2/k}\cdot \gamma L)$. Further, we note that the tradeoff for trees is tight due to a construction in uniform line metric, which is perhaps the simplest tree metric. As a direct consequence of this framework, we obtain a tight tradeoff between lightness and hop-diameter for doubling metrics in the entire regime of $k$.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.04536v1</guid>
      <category>cs.DS</category>
      <category>cs.CG</category>
      <pubDate>Thu, 08 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Sujoy Bhore, Lazar Milenkovic</dc:creator>
    </item>
    <item>
      <title>Fast Pattern Matching with Epsilon Transitions</title>
      <link>https://arxiv.org/abs/2505.04549</link>
      <description>arXiv:2505.04549v1 Announce Type: new 
Abstract: In the String Matching in Labeled Graphs (SMLG) problem, we need to determine whether a pattern string appears on a given labeled graph or a given automaton. Under the Orthogonal Vectors hypothesis, the SMLG problem cannot be solved in subquadratic time [ICALP 2019]. In typical bioinformatics applications, pattern matching algorithms should be both fast and space-efficient, so we need to determine useful classes of graphs on which the SLMG problem can be solved efficiently.
  In this paper, we improve on a recent result [STACS 2024] that shows how to solve the SMLG problem in linear time on the compressed representation of Wheeler generalized automata, a class of string-labeled automata that extend de Bruijn graphs. More precisely, we show how to remove the assumption that the automata contain no $ \epsilon $-transitions (namely, edges labeled with the empty string), while retaining the same time and space bounds. This is a significant improvement because $ \epsilon $-transitions add considerable expressive power (making it possible to jump to multiple states for free) and capture the complexity of regular expressions (through Thompson's construction for converting a regular expression into an equivalent automaton). We prove that, to enable $ \epsilon $-transitions, we only need to store two additional bitvectors that can be constructed in linear time.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.04549v1</guid>
      <category>cs.DS</category>
      <pubDate>Thu, 08 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Nicola Cotumaccio</dc:creator>
    </item>
    <item>
      <title>Minimum Congestion Routing of Unsplittable Flows in Data-Center Networks</title>
      <link>https://arxiv.org/abs/2505.03908</link>
      <description>arXiv:2505.03908v1 Announce Type: cross 
Abstract: Millions of flows are routed concurrently through a modern data-center. These networks are often built as Clos topologies, and flow demands are constrained only by the link capacities at the ingress and egress points. The minimum congestion routing problem seeks to route a set of flows through a data center while minimizing the maximum flow demand on any link. This is easily achieved by splitting flow demands along all available paths. However, arbitrary flow splitting is unrealistic. Instead, network operators rely on heuristics for routing unsplittable flows, the best of which results in a worst-case congestion of $2$ (twice the uniform link capacities). But is $2$ the lowest possible congestion? If not, can an efficient routing algorithm attain congestion below $2$?
  Guided by these questions, we investigate the minimum congestion routing problem in Clos networks with unsplittable flows. First, we show that for some sets of flows the minimum congestion is at least $\nicefrac{3}{2}$, and that it is $NP$-hard to approximate a minimum congestion routing by a factor less than $\nicefrac{3}{2}$. Second, addressing the motivating questions directly, we present a polynomial-time algorithm that guarantees a congestion of at most $\nicefrac{9}{5}$ for any set of flows, while also providing a $\nicefrac{9}{5}$ approximation of a minimum congestion routing. Last, shifting to the online setting, we demonstrate that no online algorithm (even randomized) can approximate a minimum congestion routing by a factor less than $2$, providing a strict separation between the online and the offline setting.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.03908v1</guid>
      <category>cs.NI</category>
      <category>cs.DS</category>
      <category>cs.PF</category>
      <pubDate>Thu, 08 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Miguel Ferreira, Nirav Atre, Justine Sherry, Michael Dinitz, Jo\~ao Lu\'is Sobrinho</dc:creator>
    </item>
    <item>
      <title>Improved bounds on the zeros of the chromatic polynomial of graphs and claw-free graphs</title>
      <link>https://arxiv.org/abs/2505.04366</link>
      <description>arXiv:2505.04366v1 Announce Type: cross 
Abstract: We prove that for any graph $G$ the (complex) zeros of its chromatic polynomial, $\chi_G(x)$, lie inside the disk centered at $0$ of radius $4.25 \Delta(G)$, where $\Delta(G)$ denote the maximum degree of $G$. This improves on a recent result of Jenssen, Patel and the second author, who proved a bound of $5.94\Delta(G)$. We moreover show that for graphs of sufficiently large girth we can replace $4.25$ by $3.60$ and for claw-free graphs we can replace $4.25$ by $3.81$.
  Our proofs build on the ideas developed by Jenssen, Patel and the second author, adding some new ideas. A key novel ingredient for claw-free graphs is to use a representation of the coefficients of the chromatic polynomial in terms of the number of certain partial acyclic orientations.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.04366v1</guid>
      <category>math.CO</category>
      <category>cs.DM</category>
      <category>cs.DS</category>
      <pubDate>Thu, 08 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Ferenc Bencs, Guus Regts</dc:creator>
    </item>
    <item>
      <title>Optimal Deterministic Rendezvous in Labeled Lines</title>
      <link>https://arxiv.org/abs/2505.04564</link>
      <description>arXiv:2505.04564v1 Announce Type: cross 
Abstract: In a rendezvous task, a set of mobile agents dispersed in a network have to gather at an arbitrary common site. We consider the rendezvous problem on the infinite labeled line, with $2$ initially asleep agents, without communication, and a synchronous notion of time. Nodes are labeled with unique positive integers. The initial distance between the two agents is denoted by $D$. Time is divided into rounds. We count time from when an agent first wakes up, and denote by $\tau$ the delay between the agents' wake up times. If awake in a given round $T$, an agent has three options: stay at its current node $v$, take port $0$, or take port $1$. If it decides to stay, the agent is still at node $v$ in round $T+1$. Otherwise, it is at one of the two neighbors of $v$ on the line, based on the port it chose. The agents achieve rendezvous in $T$ rounds if they are at the same node in round $T$. We aim for a deterministic algorithm for this task.
  The problem was recently considered by Miller and Pelc [DISC 2023]. With $\ell_{\max}$ the largest label of the two starting nodes, they showed that no algorithm can guarantee rendezvous in $o(D \log^* \ell_{\max})$ rounds. The lower bound follows from a connection with the LOCAL model of distributed computing, and holds even if the agents are guaranteed simultaneous wake-up ($\tau = 0$) and are given $D$ as advice. Miller and Pelc also gave an algorithm of optimal matching complexity $O(D \log^* \ell_{\max})$ when $D$ is known to the agents, but only obtained the higher bound of $O(D^2 (\log^* \ell_{\max})^3)$ when $D$ is unknown.
  We improve this second complexity to a tight $O(D \log^* \ell_{\max})$. In fact, our algorithm achieves rendezvous in $O(D \log^* \ell_{\min})$ rounds, where $\ell_{\min}$ is the smallest label within distance $O(D)$ of the two starting positions.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.04564v1</guid>
      <category>cs.DC</category>
      <category>cs.DS</category>
      <pubDate>Thu, 08 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <arxiv:DOI>10.1145/3732772.3733537</arxiv:DOI>
      <dc:creator>Yann Bourreau, Ananth Narayanan, Alexandre Nolin</dc:creator>
    </item>
    <item>
      <title>Testing Juntas Optimally with Samples</title>
      <link>https://arxiv.org/abs/2505.04604</link>
      <description>arXiv:2505.04604v1 Announce Type: cross 
Abstract: We prove tight upper and lower bounds of $\Theta\left(\tfrac{1}{\epsilon}\left( \sqrt{2^k \log\binom{n}{k} } + \log\binom{n}{k} \right)\right)$ on the number of samples required for distribution-free $k$-junta testing. This is the first tight bound for testing a natural class of Boolean functions in the distribution-free sample-based model. Our bounds also hold for the feature selection problem, showing that a junta tester must learn the set of relevant variables. For tolerant junta testing, we prove a sample lower bound of $\Omega(2^{(1-o(1)) k} + \log\binom{n}{k})$ showing that, unlike standard testing, there is no large gap between tolerant testing and learning.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.04604v1</guid>
      <category>cs.LG</category>
      <category>cs.CC</category>
      <category>cs.DS</category>
      <pubDate>Thu, 08 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Lorenzo Beretta, Nathaniel Harms, Caleb Koch</dc:creator>
    </item>
    <item>
      <title>Universal Optimality of Dijkstra via Beyond-Worst-Case Heaps</title>
      <link>https://arxiv.org/abs/2311.11793</link>
      <description>arXiv:2311.11793v4 Announce Type: replace 
Abstract: In this paper we prove that Dijkstra's shortest-path algorithm, if implemented with a sufficiently efficient heap, is universally optimal in its running time, and with suitable small additions is also universally optimal in its number of comparisons.
  Universal optimality is a powerful beyond-worst-case performance guarantee for graph algorithms that informally states that a single algorithm on a problem involving graphs with arc and/or vertex weights performs as well as possible on every graph, assuming a worst-case choice of weights. We give the first application of this notion to any sequential algorithm.
  We design a new heap data structure with a working-set bound, which guarantees that the heap takes advantage of a certain kind of locality in the heap operations. Our heap has the optimal (amortized) bounds of Fibonacci heaps but also has the beyond-worst-case guarantee that the cost of deleting the minimum item is logarithmic in the number of items inserted after it but before it is deleted, instead of logarithmic in the size of the heap when the item is deleted. That is, deletion of recently inserted items is especially efficient.
  We prove that our working-set bound guarantees universal optimality for the problem of ordering vertices by their distance from the source vertex, which we call the distance order problem. Our result relies on the observation that the sequence of heap operations generated by any run of Dijkstra's algorithm on a fixed graph possesses enough locality that one can couple the number of comparisons performed by any heap with our working-set bound to the minimum number of comparisons required to solve the distance order problem on this graph for a worst-case choice of arc lengths.</description>
      <guid isPermaLink="false">oai:arXiv.org:2311.11793v4</guid>
      <category>cs.DS</category>
      <pubDate>Thu, 08 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Bernhard Haeupler, Richard Hlad\'ik, V\'aclav Rozho\v{n}, Robert E. Tarjan, Jakub T\v{e}tek</dc:creator>
    </item>
    <item>
      <title>Residue Domination in Bounded-Treewidth Graphs</title>
      <link>https://arxiv.org/abs/2403.07524</link>
      <description>arXiv:2403.07524v2 Announce Type: replace 
Abstract: For the vertex selection problem $(\sigma,\rho)$-DomSet one is given two fixed sets $\sigma$ and $\rho$ of integers and the task is to decide whether we can select vertices of the input graph such that, for every selected vertex, the number of selected neighbors is in $\sigma$ and, for every unselected vertex, the number of selected neighbors is in $\rho$ [Telle, Nord. J. Comp. 1994]. This framework covers many fundamental graph problems such as Independent Set and Dominating Set.
  We significantly extend the recent result by Focke et al. [SODA 2023] to investigate the case when $\sigma$ and $\rho$ are two (potentially different) residue classes modulo $m\ge 2$. We study the problem parameterized by treewidth and present an algorithm that solves in time $m^{tw} \cdot n^{O(1)}$ the decision, minimization and maximization version of the problem. This significantly improves upon the known algorithms where for the case $m \ge 3$ not even an explicit running time is known. We complement our algorithm by providing matching lower bounds which state that there is no $(m-\epsilon)^{pw} \cdot n^{O(1)}$-time algorithm parameterized by pathwidth $pw$, unless SETH fails. For $m = 2$, we extend these bounds to the minimization version as the decision version is efficiently solvable.</description>
      <guid isPermaLink="false">oai:arXiv.org:2403.07524v2</guid>
      <category>cs.DS</category>
      <category>cs.CC</category>
      <pubDate>Thu, 08 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Jakob Greilhuber, Philipp Schepper, Philip Wellnitz</dc:creator>
    </item>
    <item>
      <title>Approximation Algorithms for Optimal Hopsets</title>
      <link>https://arxiv.org/abs/2502.06522</link>
      <description>arXiv:2502.06522v2 Announce Type: replace 
Abstract: For a given graph $G$, a "hopset" $H$ with hopbound $\beta$ and stretch $\alpha$ is a set of edges such that between every pair of vertices $u$ and $v$, there is a path with at most $\beta$ hops in $G \cup H$ that approximates the distance between $u$ and $v$ up to a multiplicative stretch of $\alpha$. Hopsets have found a wide range of applications for distance-based problems in various computational models since the 90s. More recently, there has been significant interest in understanding these fundamental objects from an existential and structural perspective. But all of this work takes a worst-case (or existential) point of view: How many edges do we need to add to satisfy a given hopbound and stretch requirement for any input graph?
  We initiate the study of the natural optimization variant of this problem: given a specific graph instance, what is the minimum number of edges that satisfy the hopbound and stretch requirements? We give approximation algorithms for a generalized hopset problem which, when combined with known existential bounds, lead to different approximation guarantees for various regimes depending on hopbound, stretch, and directed vs. undirected inputs. We complement our upper bounds with a lower bound that implies Label Cover hardness for directed hopsets and shortcut sets with hopbound at least $3$.</description>
      <guid isPermaLink="false">oai:arXiv.org:2502.06522v2</guid>
      <category>cs.DS</category>
      <category>cs.DM</category>
      <pubDate>Thu, 08 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Michael Dinitz, Ama Koranteng, Yasamin Nazari</dc:creator>
    </item>
    <item>
      <title>A Space-Efficient Algorithm for Longest Common Almost Increasing Subsequence of Two Sequences</title>
      <link>https://arxiv.org/abs/2503.15442</link>
      <description>arXiv:2503.15442v2 Announce Type: replace 
Abstract: Let $A$ and $B$ be two number sequences of length $n$ and $m$, respectively, where $m\le n$. Given a positive number $\delta$, a common almost increasing sequence $s_1\ldots s_k$ is a common subsequence for both $A$ and $B$ such that for all $2\le i\le k$, $s_i+\delta &gt; \max_{1\le j &lt; i} s_j$. The LCaIS problem seeks to find the longest common almost increasing subsequence (LCaIS) of $A$ and $B$. An LCaIS can be computed in $O(nm\ell)$ time and $O(nm)$ space [Ta, Shieh, Lu (TCS 2021)], where $\ell$ is the length of the LCaIS of $A$ and $B$. In this paper we first give an $O(nm\ell)$-time and $O(n+m\ell)$-space algorithm to find LCaIS, which improves the space complexity. We then design an $O((n+m)\log n +\mathcal{M}\log \mathcal{M} + \mathcal{C}\ell)$-time and $O(\mathcal{M}(\ell+\log \mathcal{M}))$-space algorithm, which is faster when the number of matching pairs $\mathcal{M}$ and the number of compatible matching pairs $\mathcal{C}$ are in $o(nm/\log m)$.</description>
      <guid isPermaLink="false">oai:arXiv.org:2503.15442v2</guid>
      <category>cs.DS</category>
      <pubDate>Thu, 08 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Md Tanzeem Rahat, Md. Manzurul Hasan, Debajyoti Mondal</dc:creator>
    </item>
    <item>
      <title>Maximum Coverage in Turnstile Streams with Applications to Fingerprinting Measures</title>
      <link>https://arxiv.org/abs/2504.18394</link>
      <description>arXiv:2504.18394v2 Announce Type: replace 
Abstract: In the maximum coverage problem we are given $d$ subsets from a universe $[n]$, and the goal is to output $k$ subsets such that their union covers the largest possible number of distinct items. We present the first algorithm for maximum coverage in the turnstile streaming model, where updates which insert or delete an item from a subset come one-by-one. Notably our algorithm only uses $poly\log n$ update time. We also present turnstile streaming algorithms for targeted and general fingerprinting for risk management where the goal is to determine which features pose the greatest re-identification risk in a dataset. As part of our work, we give a result of independent interest: an algorithm to estimate the complement of the $p^{\text{th}}$ frequency moment of a vector for $p \geq 2$. Empirical evaluation confirms the practicality of our fingerprinting algorithms demonstrating a speedup of up to $210$x over prior work.</description>
      <guid isPermaLink="false">oai:arXiv.org:2504.18394v2</guid>
      <category>cs.DS</category>
      <pubDate>Thu, 08 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Alina Ene, Alessandro Epasto, Vahab Mirrokni, Hoai-An Nguyen, Huy L. Nguyen, David P. Woodruff, Peilin Zhong</dc:creator>
    </item>
    <item>
      <title>A practical algorithm for 2-admissibility</title>
      <link>https://arxiv.org/abs/2505.03419</link>
      <description>arXiv:2505.03419v2 Announce Type: replace 
Abstract: The $2$-admissibility of a graph is a promising measure to identify real-world networks which have an algorithmically favourable structure. In contrast to other related measures, like the weak/strong $2$-colouring numbers or the maximum density of graphs that appear as $1$-subdivisions, the $2$-admissibility can be computed in polynomial time. However, so far these results are theoretical only and no practical implementation to compute the $2$-admissibility exists.
  Here we present an algorithm which decides whether the $2$-admissibility of an input graph $G$ is at most $p$ in time $O(p^4 |V(G)|)$ and space $O(|E(G)| + p^2)$. The simple structure of the algorithm makes it easy to implement. We evaluate our implementation on a corpus of 214 real-world networks and find that the algorithm runs efficiently even on networks with millions of edges, that it has a low memory footprint, and that indeed many networks have a small $2$-admissibility.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.03419v2</guid>
      <category>cs.DS</category>
      <category>math.CO</category>
      <pubDate>Thu, 08 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Christine Awofeso, Patrick Greaves, Oded Lachish, Felix Reidl</dc:creator>
    </item>
    <item>
      <title>A characterization of testable hypergraph properties</title>
      <link>https://arxiv.org/abs/1707.03303</link>
      <description>arXiv:1707.03303v3 Announce Type: replace-cross 
Abstract: We provide a combinatorial characterization of all testable properties of $k$-uniform hypergraphs ($k$-graphs for short). Here, a $k$-graph property $P$ is testable if there is a randomized algorithm which makes a bounded number of edge queries and distinguishes with probability $2/3$ between $k$-graphs that satisfy $P$ and those that are far from satisfying $P$. For the $2$-graph case, such a combinatorial characterization was obtained by Alon, Fischer, Newman and Shapira. Our results for the $k$-graph setting are in contrast to those of Austin and Tao, who showed that for the somewhat stronger concept of local repairability, the testability results for graphs do not extend to the $3$-graph setting. Our proof relies on a random subhypergraph sampling result proved in a companion paper.</description>
      <guid isPermaLink="false">oai:arXiv.org:1707.03303v3</guid>
      <category>math.CO</category>
      <category>cs.DM</category>
      <category>cs.DS</category>
      <pubDate>Thu, 08 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <arxiv:DOI>10.1016/j.jctb.2025.04.009</arxiv:DOI>
      <arxiv:journal_reference>Journal of Combinatorial Theory, Series B 174 (2025), 133-189</arxiv:journal_reference>
      <dc:creator>Felix Joos, Jaehoon Kim, Daniela K\"uhn, Deryk Osthus</dc:creator>
    </item>
    <item>
      <title>Provable Accuracy Bounds for Hybrid Dynamical Optimization and Sampling</title>
      <link>https://arxiv.org/abs/2410.06397</link>
      <description>arXiv:2410.06397v2 Announce Type: replace-cross 
Abstract: Analog dynamical accelerators (DXs) are a growing sub-field in computer architecture research, offering order-of-magnitude gains in power efficiency and latency over traditional digital methods in several machine learning, optimization, and sampling tasks. However, limited-capacity accelerators require hybrid analog/digital algorithms to solve real-world problems, commonly using large-neighborhood local search (LNLS) frameworks. Unlike fully digital algorithms, hybrid LNLS has no non-asymptotic convergence guarantees and no principled hyperparameter selection schemes, particularly limiting cross-device training and inference.
  In this work, we provide non-asymptotic convergence guarantees for hybrid LNLS by reducing to block Langevin Diffusion (BLD) algorithms. Adapting tools from classical sampling theory, we prove exponential KL-divergence convergence for randomized and cyclic block selection strategies using ideal DXs. With finite device variation, we provide explicit bounds on the 2-Wasserstein bias in terms of step duration, noise strength, and function parameters. Our BLD model provides a key link between established theory and novel computing platforms, and our theoretical results provide a closed-form expression linking device variation, algorithm hyperparameters, and performance.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.06397v2</guid>
      <category>cs.LG</category>
      <category>cs.DS</category>
      <category>math.ST</category>
      <category>stat.TH</category>
      <pubDate>Thu, 08 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Matthew X. Burns, Qingyuan Hou, Michael C. Huang</dc:creator>
    </item>
  </channel>
</rss>
