<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>cs.LO updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/cs.LO</link>
    <description>cs.LO updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/cs.LO" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Thu, 26 Feb 2026 02:53:12 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Wed, 25 Feb 2026 00:00:00 -0500</pubDate>
    <skipDays>
      <day>Saturday</day>
      <day>Sunday</day>
    </skipDays>
    <item>
      <title>Rethinking Clause Management for CDCL SAT Solvers</title>
      <link>https://arxiv.org/abs/2602.20829</link>
      <description>arXiv:2602.20829v2 Announce Type: new 
Abstract: Boolean Satisfiability (SAT) solving underpins a wide range of applications in Electronic Design Automation (EDA), particularly formal verification. However, this paper observes that the mainstream clause reduction heuristic in modern SAT solvers becomes ineffective in the critical domain of complex arithmetic circuit verification, such as multipliers. On these instances, the dominant Literal Block Distance (LBD) metric for measuring clause quality degrades into a simple value of clause length, without any perception of dynamic clause usage during solving. To address this issue, a novel clause reduction mechanism is proposed, which is entirely independent of LBD. Its core idea is to decouple and handle separately the two most fundamental characteristics of learnt clauses--inherent lineage and dynamic usage patterns--thereby avoiding the efficiency degradation caused by inappropriately mixing these properties. Experiments show that our method consistently improves mainstream solvers and achieves speedups of up to 5.74x on complex arithmetic circuit problems, while maintaining comparable performance on general-purpose benchmarks. These results challenge the prevailing LBD-centric clause quality metric for clause management.</description>
      <guid isPermaLink="false">oai:arXiv.org:2602.20829v2</guid>
      <category>cs.LO</category>
      <pubDate>Wed, 25 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Yalun Cai, Xindi Zhang, Zhengyuan Shi, Mengxia Tao, Qiang Xu</dc:creator>
    </item>
    <item>
      <title>Expregular functions</title>
      <link>https://arxiv.org/abs/2602.21019</link>
      <description>arXiv:2602.21019v1 Announce Type: cross 
Abstract: Polyregular functions form a robust class of string-to-string functions with polynomial growth, as evidenced by Bojanczyk (2018).
  This class admits numerous descriptions and enjoys several closure properties.
  Most notably, polyregular functions are regularity reflecting (\ie the inverse image of a regular language is regular).
  In this work, we propose a robust class of string-to-string functions with exponential growth which we call expregular functions. We consider the following three models for describing them:
  - MSO set interpretations, which extend MSO interpretations (one of the models capturing polyregular functions), by operating on monadic variables instead of tuples of first-order variables;
  - yield-Hennie machines, which are branching one-tape Turing machines with bounded visit; and
  - Ariadne transducers, a new model of 2-way pushdown machines with a bounded visit restriction.
  Our main contribution is a translation from MSO set interpretations to yield-Hennie machines, which are known to be regularity reflecting (Dartois, Nguy\~{\^{e}}n, Peyrat 2026).
  In particular this establishes that MSO set interpretations are regularity reflecting, which in turn settles a major conjecture about automatic structures: every automatic $\omega$-word has a decidable MSO theory.
  Yield-Hennie machine directly translate to Ariadne transducers, and our second contribution is to prove that Ariadne transducers also translate to MSO set interpretations, thus establishing the equivalence of the three models. This is obtained by showing that Ariadne automata -- the automaton model corresponding to Ariadne transducers -- recognise regular languages.</description>
      <guid isPermaLink="false">oai:arXiv.org:2602.21019v1</guid>
      <category>cs.FL</category>
      <category>cs.LO</category>
      <pubDate>Wed, 25 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Thomas Colcombet, Nathan Lhote, Pierre Ohlmann</dc:creator>
    </item>
    <item>
      <title>The Golden Path to Guarded Monotone Strict NP</title>
      <link>https://arxiv.org/abs/2310.01254</link>
      <description>arXiv:2310.01254v5 Announce Type: replace 
Abstract: Guarded Monotone Strict NP (GMSNP) extends Monotone Monadic Strict NP (MMSNP) by guarded existentially quantified predicates of arbitrary arities. We prove that the containment and the FO-rewritability problems for GMSNP are decidable, thereby settling an open question of Bienvenu, ten Cate, Lutz, and Wolter, later restated by Bourhis and Lutz. Our proof also comes with a 2NEXPTIME upper bound on the complexity of the two problems, which matches the lower bounds for MMSNP due to Bourhis and Lutz. To obtain these results, we significantly improve the state of knowledge of the model-theoretic properties of GMSNP. Bodirsky, Kn\"{a}uer, and Starke previously showed that every GMSNP sentence defines a finite union of CSPs of $\omega$-categorical structures. We show that these structures can be used to obtain a reduction from the containment problem for GMSNP to the much simpler problem of testing the existence of a recolouring; a careful analysis of this yields said upper bound for containment. The upper bound for FO-rewritability is subsequently obtained by an application of several standard techniques from the theory of infinite-domain CSPs. As our secondary contribution, we refine the construction of Bodirsky, Kn\"{a}uer, and Starke by adding a restricted form of homogeneity to the properties of these structures, making the logic amenable to future complexity classifications for query evaluation using techniques developed for infinite-domain CSPs.</description>
      <guid isPermaLink="false">oai:arXiv.org:2310.01254v5</guid>
      <category>cs.LO</category>
      <category>cs.DB</category>
      <category>math.LO</category>
      <pubDate>Wed, 25 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Alexey Barsukov, Michael Pinsker, Jakub Rydval</dc:creator>
    </item>
    <item>
      <title>A categorical perspective on constraint satisfaction: The wonderland of adjunctions</title>
      <link>https://arxiv.org/abs/2503.10353</link>
      <description>arXiv:2503.10353v2 Announce Type: replace 
Abstract: The so-called algebraic approach to the constraint satisfaction problem (CSP) has been a prevalent method of the study of complexity of these problems since early 2000's. The core of this approach is the notion of *polymorphisms* which determine the complexity of the problem (up to log-space reductions). In the past few years, a new, more general version of the CSP emerged, the promise constraint satisfaction problem (PCSP), and the notion of polymorphisms and most of the core theses of the algebraic approach were generalised to the promise setting. Nevertheless, recent work also suggests that insights from other fields are immensely useful in the study of PCSPs including algebraic topology.
  In this paper, we provide an entry point for category-theorists into the study of complexity of CSPs and PCSPs. We show that many standard CSP notions have clear and well-known categorical counterparts. For example, the algebraic structure of polymorphisms can be described as a set-functor defined as a right Kan extension. We provide purely categorical proofs of core results of the algebraic approach including a proof that the complexity only depends on the polymorphisms. Our new proofs are substantially shorter and, from the categorical perspective, cleaner than previous proofs of the same results. Moreover, as expected, are applicable more widely. We believe that, in particular in the case of PCSPs, category theory brings insights that can help solve some of the current challenges of the field.</description>
      <guid isPermaLink="false">oai:arXiv.org:2503.10353v2</guid>
      <category>cs.LO</category>
      <category>math.CT</category>
      <pubDate>Wed, 25 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-sa/4.0/</dc:rights>
      <dc:creator>Maximilian Hadek, Tom\'a\v{s} Jakl, Jakub Opr\v{s}al</dc:creator>
    </item>
    <item>
      <title>Towards the Usage of Window Counting Constraints in the Synthesis of Reactive Systems to Reduce State Space Explosion</title>
      <link>https://arxiv.org/abs/2503.21852</link>
      <description>arXiv:2503.21852v4 Announce Type: replace 
Abstract: The synthesis of reactive systems aims for the automated construction of strategies for systems that interact with their environment. Whereas the synthesis approach has the potential to change the development of reactive systems significantly due to the avoidance of manual implementation, it still suffers from a lack of efficient synthesis algorithms for many application scenarios. The translation of the system specification into an automaton that allows for strategy construction (if a winning strategy exists) is nonelementary in the length of the specification in S1S and doubly exponential for LTL, raising the need of highly specialized algorithms. In this article, we present an approach on how to reduce this state space explosion in the construction of this automaton by exploiting a monotonicity property of specifications. For this, we introduce window counting constraints that allow for step-wise refinement or abstraction of specifications. In an iterative synthesis procedure, those window counting constraints are used to construct automata representing over- or under-approximations (depending on the counting constraint) of constraint-compliant behavior. Analysis results on winning regions of previous iterations are used to reduce the size of the next automaton, leading to an overall reduction of the state space explosion extent. We present the implementation results of the iterated synthesis for a zero-sum game setting as proof of concept. Furthermore, we discuss the current limitations of the approach in a zero-sum setting and sketch future work in non-zero-sum settings.</description>
      <guid isPermaLink="false">oai:arXiv.org:2503.21852v4</guid>
      <category>cs.LO</category>
      <pubDate>Wed, 25 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Linda Feeken, Martin Fr\"anzle</dc:creator>
    </item>
    <item>
      <title>Probabilistic Linear Logic Programming with an Application to Bayesian Network Computations (Extended Version)</title>
      <link>https://arxiv.org/abs/2601.13270</link>
      <description>arXiv:2601.13270v2 Announce Type: replace 
Abstract: Bayesian networks are a canonical formalism for representing probabilistic dependencies, yet their integration within logic programming frameworks remains a nontrivial challenge, mainly due to the complex structure of these networks. In this paper, we propose probLO (probabilistic Linear Objects) an extension of Andreoli and Pareschi's LO language which embeds Bayesian network representation and computation within the framework of multiplicative-additive linear logic programming. The key novelty is the use of multi-head Prolog-like methods to reconstruct network structures, which are not necessarily trees, and the operation of slicing, standard in the literature of linear logic, enabling internal numerical probability computations without relying on external semantic interpretation.</description>
      <guid isPermaLink="false">oai:arXiv.org:2601.13270v2</guid>
      <category>cs.LO</category>
      <pubDate>Wed, 25 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Matteo Acclavio, Roberto Maieli</dc:creator>
    </item>
  </channel>
</rss>
