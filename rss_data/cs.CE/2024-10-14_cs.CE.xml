<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>cs.CE updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/cs.CE</link>
    <description>cs.CE updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/cs.CE" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Tue, 15 Oct 2024 03:31:35 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Mon, 14 Oct 2024 00:00:00 -0400</pubDate>
    <skipDays>
      <day>Sunday</day>
      <day>Saturday</day>
    </skipDays>
    <item>
      <title>Cyber-physical and business perspectives using Federated Digital Twins in multinational and multimodal transportation systems</title>
      <link>https://arxiv.org/abs/2410.08479</link>
      <description>arXiv:2410.08479v1 Announce Type: new 
Abstract: Digital Twin (DT) technologies promise to remove cyber-physical barriers in systems and services and provide seamless management of distributed resources effectively. Ideally, full-fledged instantiations of DT offer bi-directional features for physical-virtual representations, tackling data governance, risk assessment, security and privacy protections, resilience, and performance, to name a few characteristics. More broadly, Federated Digital Twins (FDT) are distributed physical-virtual counterparts that collaborate for enacting synchronisation and accurate mapping of multiple DT instances. In this work we focus on understanding and conceptualising the cyber-physical and business perspectives using FDT in multinational and multimodal transportation systems. These settings enforce a plethora of regulations, compliance, standards in the physical counterpart that must be carefully considered in the virtual mirroring. Our aim is to discuss the regulatory and technical underpinnings and, consequently, the existing operational and budgetary overheads to factor in when designing or operating FDT.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.08479v1</guid>
      <category>cs.CE</category>
      <pubDate>Mon, 14 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-sa/4.0/</dc:rights>
      <dc:creator>Ricardo M. Czekster, Alexeis Garcia Perez, Manolya Kavakli-Thorne, Seif Allah El Mesloul Nasri, Siraj Shaikh</dc:creator>
    </item>
    <item>
      <title>Adaptive optimization of wave energy conversion in oscillatory wave surge converters via SPH simulation and deep reinforcement learning</title>
      <link>https://arxiv.org/abs/2410.08871</link>
      <description>arXiv:2410.08871v1 Announce Type: new 
Abstract: The nonlinear damping characteristics of the oscillating wave surge converter (OWSC) significantly impact the performance of the power take-off system. This study presents a framework by integrating deep reinforcement learning (DRL) with numerical simulations of OWSC to identify optimal adaptive damping policy under varying wave conditions, thereby enhancing wave energy harvesting efficiency. Firstly, the open-source multiphysics libraries SPHinXsys and Simbody are employed to establish the numerical environment for wave interaction with OWSCs. Subsequently, a comparative analysis of three DRL algorithms-proximal policy optimization (PPO), twin delayed deep deterministic policy gradient (TD3), and soft actor-critic (SAC)-is conducted using the two-dimensional (2D) numerical study of OWSC interacting with regular waves. The results reveal that artificial neural networks capture the nonlinear characteristics of wave-structure interactions and provide efficient PTO policies. Notably, the SAC algorithm demonstrates exceptional robustness and accuracy, achieving a 10.61% improvement in wave energy harvesting. Furthermore, policies trained in a 2D environment are successfully applied to the three-dimensional (3D) study, with an improvement of 22.54% in energy harvesting. Additionally, the study shows that energy harvesting is improved by 6.42% for complex irregular waves. However, for the complex dual OWSC system, optimizing the damping characteristics alone is insufficient to enhance energy harvesting.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.08871v1</guid>
      <category>cs.CE</category>
      <pubDate>Mon, 14 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Mai Ye, Chi Zhang, Yaru Ren, Ziyuan Liu, Oskar J. Haidn, Xiangyu Hu</dc:creator>
    </item>
    <item>
      <title>Simulating anisotropic diffusion processes with smoothed particle hydrodynamics</title>
      <link>https://arxiv.org/abs/2410.08888</link>
      <description>arXiv:2410.08888v1 Announce Type: new 
Abstract: Diffusion problems with anisotropic features arise in the various areas of science and engineering fields. As a Lagrangian mesh-less method, SPH has a special advantage in addressing the diffusion problems due to the the benefit of dealing with the advection term. But its application to solving anisotropic diffusion is still limited since a robust and general SPH formulation is required to obtain accurate approximations of second derivatives. In this paper, we modify a second derivatives model based on the SPH formulation to obtain a full version of Hessian matrix consisting of the Laplacian operator elements. To verify the proposed SPH scheme, firstly, the diffusion of a scalar which distributes following a pre-function within a thin structure is performed by using anisotropic resolution coupling anisotropic kernel. With various anisotropic ratios, excellent agreements with the theoretical solution are achieved. Then, the anisotropic diffusion of a contaminant in fluid is simulated. The simulation results are very consistent with corresponding analytical solutions, showing that the present algorithm can obtain smooth solution without the spurious oscillations for contaminant transport problems with discontinuities, and achieve second-order accuracy. Subsequently, we utilize this newly developed SPH formulation to tackle the problem of the fluid diffusion through a thin porous membrane and the anisotropic transport of transmembrane potential within the left ventricle, demonstrating the capabilities of the proposed SPH framework in solving the complex anisotropic problems.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.08888v1</guid>
      <category>cs.CE</category>
      <pubDate>Mon, 14 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Xiaojing Tang, Oskar Haidn, Xiangyu Hu</dc:creator>
    </item>
    <item>
      <title>PEAR: A Robust and Flexible Automation Framework for Ptychography Enabled by Multiple Large Language Model Agents</title>
      <link>https://arxiv.org/abs/2410.09034</link>
      <description>arXiv:2410.09034v1 Announce Type: new 
Abstract: Ptychography is an advanced computational imaging technique in X-ray and electron microscopy. It has been widely adopted across scientific research fields, including physics, chemistry, biology, and materials science, as well as in industrial applications such as semiconductor characterization. In practice, obtaining high-quality ptychographic images requires simultaneous optimization of numerous experimental and algorithmic parameters. Traditionally, parameter selection often relies on trial and error, leading to low-throughput workflows and potential human bias. In this work, we develop the "Ptychographic Experiment and Analysis Robot" (PEAR), a framework that leverages large language models (LLMs) to automate data analysis in ptychography. To ensure high robustness and accuracy, PEAR employs multiple LLM agents for tasks including knowledge retrieval, code generation, parameter recommendation, and image reasoning. Our study demonstrates that PEAR's multi-agent design significantly improves the workflow success rate, even with smaller open-weight models such as LLaMA 3.1 8B. PEAR also supports various automation levels and is designed to work with customized local knowledge bases, ensuring flexibility and adaptability across different research environments.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.09034v1</guid>
      <category>cs.CE</category>
      <category>cs.AI</category>
      <category>cs.CL</category>
      <category>cs.MA</category>
      <pubDate>Mon, 14 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Xiangyu Yin, Chuqiao Shi, Yimo Han, Yi Jiang</dc:creator>
    </item>
    <item>
      <title>Embedding an ANN-Based Crystal Plasticity Model into the Finite Element Framework using an ABAQUS User-Material Subroutine</title>
      <link>https://arxiv.org/abs/2410.08214</link>
      <description>arXiv:2410.08214v1 Announce Type: cross 
Abstract: This manuscript presents a practical method for incorporating trained Neural Networks (NNs) into the Finite Element (FE) framework using a user material (UMAT) subroutine. The work exemplifies crystal plasticity, a complex inelastic non-linear path-dependent material response, with a wide range of applications in ABAQUS UMAT. However, this approach can be extended to other material behaviors and FE tools. The use of a UMAT subroutine serves two main purposes: (1) it predicts and updates the stress or other mechanical properties of interest directly from the strain history; (2) it computes the Jacobian matrix either through backpropagation or numerical differentiation, which plays an essential role in the solution convergence. By implementing NNs in a UMAT subroutine, a trained machine learning model can be employed as a data-driven constitutive law within the FEM framework, preserving multiscale information that conventional constitutive laws often neglect or average. The versatility of this method makes it a powerful tool for integrating machine learning into mechanical simulation. While this approach is expected to provide higher accuracy in reproducing realistic material behavior, the reliability of the solution process and the convergence conditions must be paid special attention. While the theory of the model is explained in [Heider et al. 2020], exemplary source code is also made available for interested readers [https://doi.org/10.25835/6n5uu50y]</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.08214v1</guid>
      <category>physics.comp-ph</category>
      <category>cs.AI</category>
      <category>cs.CE</category>
      <category>cs.LG</category>
      <pubDate>Mon, 14 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Yuqing He, Yousef Heider, Bernd Markert</dc:creator>
    </item>
    <item>
      <title>CryoFM: A Flow-based Foundation Model for Cryo-EM Densities</title>
      <link>https://arxiv.org/abs/2410.08631</link>
      <description>arXiv:2410.08631v1 Announce Type: cross 
Abstract: Cryo-electron microscopy (cryo-EM) is a powerful technique in structural biology and drug discovery, enabling the study of biomolecules at high resolution. Significant advancements by structural biologists using cryo-EM have led to the production of over 38,626 protein density maps at various resolutions1. However, cryo-EM data processing algorithms have yet to fully benefit from our knowledge of biomolecular density maps, with only a few recent models being data-driven but limited to specific tasks. In this study, we present CryoFM, a foundation model designed as a generative model, learning the distribution of high-quality density maps and generalizing effectively to downstream tasks. Built on flow matching, CryoFM is trained to accurately capture the prior distribution of biomolecular density maps. Furthermore, we introduce a flow posterior sampling method that leverages CRYOFM as a flexible prior for several downstream tasks in cryo-EM and cryo-electron tomography (cryo-ET) without the need for fine-tuning, achieving state-of-the-art performance on most tasks and demonstrating its potential as a foundational model for broader applications in these fields.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.08631v1</guid>
      <category>q-bio.BM</category>
      <category>cs.AI</category>
      <category>cs.CE</category>
      <category>cs.LG</category>
      <pubDate>Mon, 14 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Yi Zhou, Yilai Li, Jing Yuan, Quanquan Gu</dc:creator>
    </item>
    <item>
      <title>No Tick-Size Too Small: A General Method for Modelling Small Tick Limit Order Books</title>
      <link>https://arxiv.org/abs/2410.08744</link>
      <description>arXiv:2410.08744v1 Announce Type: cross 
Abstract: We investigate the disparity in the microstructural properties of the Limit Order Book (LOB) across different relative tick sizes. Tick sizes not only influence the granularity of the price formation process but also affect market agents' behavior. A key contribution of this study is the identification of several stylized facts, which are used to differentiate between large, medium, and small tick stocks, along with clear metrics for their measurement. We provide cross-asset visualizations to illustrate how these attributes vary with relative tick size. Further, we propose a Hawkes Process model that accounts for sparsity, multi-tick level price moves, and the shape of the book in small-tick stocks. Through simulation studies, we demonstrate the universality of the model and identify key variables that determine whether a simulated LOB resembles a large-tick or small-tick stock. Our tests show that stylized facts like sparsity, shape, and relative returns distribution can be smoothly transitioned from a large-tick to a small-tick asset using our model. We test this model's assumptions, showcase its challenges and propose questions for further directions in this area of research.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.08744v1</guid>
      <category>q-fin.TR</category>
      <category>cs.CE</category>
      <category>q-fin.CP</category>
      <pubDate>Mon, 14 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Konark Jain, Jean-Fran\c{c}ois Muzy, Jonathan Kochems, Emmanuel Bacry</dc:creator>
    </item>
    <item>
      <title>A Diffusion MRI model for axonal damage quantification based on axial diffusivity reduction in axons: a Monte Carlo simulation study</title>
      <link>https://arxiv.org/abs/2403.06140</link>
      <description>arXiv:2403.06140v3 Announce Type: replace 
Abstract: Axonal damage is the primary pathological correlate of long-term impairment in multiple sclerosis (MS). Previous work has demonstrated a strong, quantitative relationship between decrease in axial diffusivity and axonal damage. In the present work, we develop an extension of diffusion basis spectrum imaging (DBSI) which can be used to quantify the fraction of diseased and healthy axons based on reduction in axial diffusivity in axons. In this novel method, we model the MRI signal with the axial diffusion (AD) spectrum for each fiber orientation and use two component restricted anisotropic diffusion spectrum (RADS) to model the anisotropic component of the diffusion-weighted MRI signal. Diffusion coefficients and signal fractions are computed for the optimal model with the lowest Bayesian information criterion (BIC) score. This gives us the fractions of diseased and healthy axons. We test our method using Monte-Carlo (MC) simulations with the MC simulation package developed as part of this work. The simulation geometry for the voxel includes uniformly spaced cylinders to model axons, and uniformly spaced spheres to model extra-axonal cells. First we test and validate our MC simulations for the basic RADS model. It accurately recovers the fiber and cell fractions simulated, as well as the simulated diffusivities. For testing and validating RADS to quantify axonal damage, we simulate different fractions of diseased and healthy axons. Our method produces highly accurate quantification of diseased and healthy axons with Pearson's correlation (predicted vs true proportion) of r = 0.98 (p-value = 0.001); the one Sample t-test for proportion error gives the mean error of 2% (p-value = 0.034). Furthermore, the method recovers the axial diffusivities of the diseased and healthy axons very accurately with mean error of 4% (p-value = 0.001).</description>
      <guid isPermaLink="false">oai:arXiv.org:2403.06140v3</guid>
      <category>cs.CE</category>
      <pubDate>Mon, 14 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Nand Sharma</dc:creator>
    </item>
    <item>
      <title>Reduced-order modeling for second-order computational homogenization with applications to geometrically parameterized elastomeric metamaterials</title>
      <link>https://arxiv.org/abs/2405.00437</link>
      <description>arXiv:2405.00437v2 Announce Type: replace 
Abstract: The structural properties of mechanical metamaterials are typically studied with two-scale methods based on computational homogenization. Because such materials have a complex microstructure, enriched schemes such as second-order computational homogenization are required to fully capture their non-linear behavior, which arises from non-local interactions due to the buckling or patterning of the microstructure. In the two-scale formulation, the effective behavior of the microstructure is captured with a representative volume element (RVE), and a homogenized effective continuum is considered on the macroscale. Although an effective continuum formulation is introduced, solving such two-scale models concurrently is still computationally demanding due to the many repeated solutions for each RVE at the microscale level. In this work, we propose a reduced-order model for the microscopic problem arising in second-order computational homogenization, using proper orthogonal decomposition and a novel hyperreduction method that is specifically tailored for this problem and inspired by the empirical cubature method. Two numerical examples are considered, in which the performance of the reduced-order model is carefully assessed by comparing its solutions with direct numerical simulations (entirely resolving the underlying microstructure) and the full second-order computational homogenization model. The reduced-order model is able to approximate the result of the full computational homogenization well, provided that the training data is representative for the problem at hand. Any remaining errors, when compared with the direct numerical simulation, can be attributed to the inherent approximation errors in the computational homogenization scheme. Regarding run times for one thread, speed-ups on the order of 100 are achieved with the reduced-order model as compared to direct numerical simulations.</description>
      <guid isPermaLink="false">oai:arXiv.org:2405.00437v2</guid>
      <category>cs.CE</category>
      <pubDate>Mon, 14 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <arxiv:DOI>10.1002/nme.7604</arxiv:DOI>
      <dc:creator>T. Guo, V. G. Kouznetsova, M. G. D. Geers, K. Veroy, O. Roko\v{s}</dc:creator>
    </item>
    <item>
      <title>Machine Learning based Prediction of Ditching Loads</title>
      <link>https://arxiv.org/abs/2402.10724</link>
      <description>arXiv:2402.10724v2 Announce Type: replace-cross 
Abstract: We present approaches to predict dynamic ditching loads on aircraft fuselages using machine learning. The employed learning procedure is structured into two parts, the reconstruction of the spatial loads using a convolutional autoencoder (CAE) and the transient evolution of these loads in a subsequent part. Different CAE strategies are assessed and combined with either long short-term memory (LSTM) networks or Koopman-operator based methods to predict the transient behaviour. The training data is compiled by an extension of the momentum method of von-Karman and Wagner and the rationale of the training approach is briefly summarised. The application included refers to a full-scale fuselage of a DLR-D150 aircraft for a range of horizontal and vertical approach velocities at 6{\deg} incidence. Results indicate a satisfactory level of predictive agreement for all four investigated surrogate models examined, with the combination of an LSTM and a deep decoder CAE showing the best performance.</description>
      <guid isPermaLink="false">oai:arXiv.org:2402.10724v2</guid>
      <category>cs.LG</category>
      <category>cs.CE</category>
      <pubDate>Mon, 14 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Henning Schwarz, Micha \"Uberr\"uck, Jens-Peter M. Zemke, Thomas Rung</dc:creator>
    </item>
    <item>
      <title>A Unification Between Deep-Learning Vision, Compartmental Dynamical Thermodynamics, and Robotic Manipulation for a Circular Economy</title>
      <link>https://arxiv.org/abs/2405.14406</link>
      <description>arXiv:2405.14406v2 Announce Type: replace-cross 
Abstract: The shift from a linear to a circular economy has the potential to simultaneously reduce uncertainties of material supplies and waste generation. However, to date, the development of robotic and, more generally, autonomous systems have been rarely integrated into circular economy implementation strategies despite their potential to reduce the operational costs and the contamination risks from handling waste. In addition, the science of circularity still lacks the physical foundations needed to improve the accuracy and the repeatability of the models. Hence, in this paper, we merge deep-learning vision, compartmental dynamical thermodynamics, and robotic manipulation into a theoretically-coherent physics-based research framework to lay the foundations of circular flow designs of materials. The proposed framework tackles circularity by generalizing the design approach of the Rankine cycle enhanced with dynamical systems theory. This differs from state-of-the-art approaches to circular economy, which are mainly based on data analysis, e.g., material flow analysis (MFA). We begin by reviewing the literature of the three abovementioned research areas, then we introduce the proposed unified framework and we report the initial application of the framework to plastics systems along with initial simulation results of reinforcement-learning control of robotic waste sorting. This shows the framework applicability, generality, scalability, and the similarity and difference between the optimization of artificial neural systems and the proposed compartmental networks. Finally, we discuss the still not fully exploited opportunities for robotics in circular economy and the future challenges in the theory and practice of the proposed circularity framework.</description>
      <guid isPermaLink="false">oai:arXiv.org:2405.14406v2</guid>
      <category>cs.RO</category>
      <category>cs.CE</category>
      <pubDate>Mon, 14 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Federico Zocco, Wassim M. Haddad, Andrea Corti, Monica Malvezzi</dc:creator>
    </item>
  </channel>
</rss>
