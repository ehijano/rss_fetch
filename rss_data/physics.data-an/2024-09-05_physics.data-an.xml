<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>physics.data-an updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/physics.data-an</link>
    <description>physics.data-an updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/physics.data-an" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Fri, 06 Sep 2024 01:39:39 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Thu, 05 Sep 2024 00:00:00 -0400</pubDate>
    <skipDays>
      <day>Sunday</day>
      <day>Saturday</day>
    </skipDays>
    <item>
      <title>Fitting an Equation to Data Impartially</title>
      <link>https://arxiv.org/abs/2409.02573</link>
      <description>arXiv:2409.02573v1 Announce Type: cross 
Abstract: We consider the problem of fitting a relationship (e.g. a potential scientific law) to data involving multiple variables. Ordinary (least squares) regression is not suitable for this because the estimated relationship will differ according to which variable is chosen as being dependent, and the dependent variable is unrealistically assumed to be the only variable which has any measurement error (noise). We present a very general method for estimating a linear functional relationship between multiple noisy variables, which are treated impartially, i.e. no distinction between dependent and independent variables. The data are not assumed to follow any distribution, but all variables are treated as being equally reliable. Our approach extends the geometric mean functional relationship to multiple dimensions. This is especially useful with variables measured in different units, as it is naturally scale-invariant, whereas orthogonal regression is not. This is because our approach is not based on minimizing distances, but on the symmetric concept of correlation. The estimated coefficients are easily obtained from the covariances or correlations, and correspond to geometric means of associated least squares coefficients. The ease of calculation will hopefully allow widespread application of impartial fitting to estimate relationships in a neutral way.</description>
      <guid isPermaLink="false">oai:arXiv.org:2409.02573v1</guid>
      <category>stat.ME</category>
      <category>econ.EM</category>
      <category>math.ST</category>
      <category>physics.data-an</category>
      <category>q-fin.ST</category>
      <category>stat.TH</category>
      <pubDate>Thu, 05 Sep 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <arxiv:DOI>10.3390/math11183957</arxiv:DOI>
      <arxiv:journal_reference>Mathematics, 11(18), 3957 (2023)</arxiv:journal_reference>
      <dc:creator>Chris Tofallis</dc:creator>
    </item>
    <item>
      <title>Gaussian Processes enabled model calibration in the context of deep geological disposal</title>
      <link>https://arxiv.org/abs/2409.02576</link>
      <description>arXiv:2409.02576v1 Announce Type: cross 
Abstract: This work introduces a surrogate modeling approach for an emplacement drift of a deep geological repository based on Gaussian Processes (GPs). The surrogate model is used as a substitute for the high-fidelity mechanical model in many-query scenarios, such as time-dependent sensitivity analysis and calibration. Our GP-based approach emulates the behavior of an emplacement drift of a deep geological repository with significantly reduced computational time, enabling faster design iterations and effective incorporation as well as interpretation of monitoring data. Our findings show that only a few key parameters are essential for accurately reflecting in-situ conditions in complex rock salt models, which is critical for ensuring safety in deep geological disposal.</description>
      <guid isPermaLink="false">oai:arXiv.org:2409.02576v1</guid>
      <category>physics.geo-ph</category>
      <category>physics.data-an</category>
      <pubDate>Thu, 05 Sep 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Lennart Paul, Jorge-Humberto Urrea-Quintero, Umer Fiaz, Ali Hussein, Hazem Yaghi, Henning Wessels, Ulrich R\"omer, Joachim Stahlmann</dc:creator>
    </item>
    <item>
      <title>Delay Parameter Selection in Permutation Entropy Using Topological Data Analysis</title>
      <link>https://arxiv.org/abs/1905.04329</link>
      <description>arXiv:1905.04329v3 Announce Type: replace 
Abstract: Permutation Entropy (PE) is a powerful tool for quantifying the complexity of a signal which includes measuring the regularity of a time series. Additionally, outside of entropy and information theory, permutations have recently been leveraged as a graph representation, which opens the door for graph theory tools and analysis. Despite the successful application of permutations in a variety of scientific domains, permutations requires a judicious choice of the delay parameter $\tau$ and dimension $n$. However, $n$ is typically selected within an accepted range giving optimal results for the majority of systems. Therefore, in this work we focus on choosing the delay parameter, while giving some general guidance on the appropriate selection of $n$ based on a statistical analysis of the permutation distribution. Selecting $\tau$ is often accomplished using trial and error guided by the expertise of domain scientists. However, in this paper, we show how persistent homology, a commonly used tool from Topological Data Analysis (TDA), provides methods for the automatic selection of $\tau$. We evaluate the successful identification of a suitable $\tau$ from our TDA-based approach by comparing our results to both expert suggested parameters from published literature and optimized parameters (if possible) for a wide variety of dynamical systems.</description>
      <guid isPermaLink="false">oai:arXiv.org:1905.04329v3</guid>
      <category>physics.data-an</category>
      <category>cs.CG</category>
      <category>cs.IT</category>
      <category>math.IT</category>
      <category>nlin.CD</category>
      <pubDate>Thu, 05 Sep 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <arxiv:DOI>10.1007/s44007-024-00110-4</arxiv:DOI>
      <dc:creator>Audun D. Myers, Max M. Chumley, Firas A. Khasawneh</dc:creator>
    </item>
    <item>
      <title>Ab initio uncertainty quantification in scattering analysis of microscopy</title>
      <link>https://arxiv.org/abs/2309.02468</link>
      <description>arXiv:2309.02468v4 Announce Type: replace-cross 
Abstract: Estimating parameters from data is a fundamental problem, customarily done by minimizing a loss function between a model and observed statistics. In scattering-based analysis, researchers often employ their domain expertise to select a specific range of wave vectors for analysis, a choice that can vary depending on the specific case. We introduce another paradigm that defines a probabilistic generative model from the beginning of data processing and propagates the uncertainty for parameter estimation, termed the ab initio uncertainty quantification (AIUQ). As an illustrative example, we demonstrate this approach with differential dynamic microscopy (DDM) that extracts dynamical information through Fourier analysis at a selected range of wave vectors. We first show that the conventional way of estimation in DDM is equivalent to fitting a temporal variogram in the reciprocal space using a latent factor model. Then we derive the maximum marginal likelihood estimator, which optimally weighs the information at all wave vectors, therefore eliminating the need to select the range of wave vectors. Furthermore, we substantially reduce the computational cost by utilizing the generalized Schur algorithm for Toeplitz covariances without approximation. Simulated studies validate that AIUQ improves estimation accuracy and enables model selection with automated analysis. The utility of AIUQ is also demonstrated by three distinct sets of experiments: first in an isotropic Newtonian fluid, pushing limits of optically dense systems compared to multiple particle tracking; next in a system undergoing a sol-gel transition, automating the determination of gelling points and critical exponent; and lastly, in discerning anisotropic diffusive behavior of colloids in a liquid crystal. These outcomes collectively underscore AIUQ's versatility to capture system dynamics in an efficient and automated manner.</description>
      <guid isPermaLink="false">oai:arXiv.org:2309.02468v4</guid>
      <category>physics.comp-ph</category>
      <category>cond-mat.soft</category>
      <category>physics.data-an</category>
      <category>stat.AP</category>
      <category>stat.ME</category>
      <pubDate>Thu, 05 Sep 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <arxiv:DOI>10.1103/PhysRevE.110.034601</arxiv:DOI>
      <arxiv:journal_reference>Phys. Rev. E 110, 034601 (2024)</arxiv:journal_reference>
      <dc:creator>Mengyang Gu, Yue He, Xubo Liu, Yimin Luo</dc:creator>
    </item>
    <item>
      <title>Simultaneous Dimensionality Reduction: A Data Efficient Approach for Multimodal Representations Learning</title>
      <link>https://arxiv.org/abs/2310.04458</link>
      <description>arXiv:2310.04458v3 Announce Type: replace-cross 
Abstract: We explore two primary classes of approaches to dimensionality reduction (DR): Independent Dimensionality Reduction (IDR) and Simultaneous Dimensionality Reduction (SDR). In IDR methods, of which Principal Components Analysis is a paradigmatic example, each modality is compressed independently, striving to retain as much variation within each modality as possible. In contrast, in SDR, one simultaneously compresses the modalities to maximize the covariation between the reduced descriptions while paying less attention to how much individual variation is preserved. Paradigmatic examples include Partial Least Squares and Canonical Correlations Analysis. Even though these DR methods are a staple of statistics, their relative accuracy and data set size requirements are poorly understood. We introduce a generative linear model to synthesize multimodal data with known variance and covariance structures to examine these questions. We assess the accuracy of the reconstruction of the covariance structures as a function of the number of samples, signal-to-noise ratio, and the number of varying and covarying signals in the data. Using numerical experiments, we demonstrate that linear SDR methods consistently outperform linear IDR methods and yield higher-quality, more succinct reduced-dimensional representations with smaller datasets. Remarkably, regularized CCA can identify low-dimensional weak covarying structures even when the number of samples is much smaller than the dimensionality of the data, which is a regime challenging for all dimensionality reduction methods. Our work corroborates and explains previous observations in the literature that SDR can be more effective in detecting covariation patterns in data. These findings suggest that SDR should be preferred to IDR in real-world data analysis when detecting covariation is more important than preserving variation.</description>
      <guid isPermaLink="false">oai:arXiv.org:2310.04458v3</guid>
      <category>stat.ML</category>
      <category>physics.data-an</category>
      <pubDate>Thu, 05 Sep 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Eslam Abdelaleem, Ahmed Roman, K. Michael Martini, Ilya Nemenman</dc:creator>
    </item>
    <item>
      <title>Convolutional L2LFlows: Generating Accurate Showers in Highly Granular Calorimeters Using Convolutional Normalizing Flows</title>
      <link>https://arxiv.org/abs/2405.20407</link>
      <description>arXiv:2405.20407v3 Announce Type: replace-cross 
Abstract: In the quest to build generative surrogate models as computationally efficient alternatives to rule-based simulations, the quality of the generated samples remains a crucial frontier. So far, normalizing flows have been among the models with the best fidelity. However, as the latent space in such models is required to have the same dimensionality as the data space, scaling up normalizing flows to high dimensional datasets is not straightforward. The prior L2LFlows approach successfully used a series of separate normalizing flows and sequence of conditioning steps to circumvent this problem. In this work, we extend L2LFlows to simulate showers with a 9-times larger profile in the lateral direction. To achieve this, we introduce convolutional layers and U-Net-type connections, move from masked autoregressive flows to coupling layers, and demonstrate the successful modelling of showers in the ILD Electromagnetic Calorimeter as well as Dataset 3 from the public CaloChallenge dataset.</description>
      <guid isPermaLink="false">oai:arXiv.org:2405.20407v3</guid>
      <category>physics.ins-det</category>
      <category>cs.LG</category>
      <category>hep-ex</category>
      <category>hep-ph</category>
      <category>physics.data-an</category>
      <pubDate>Thu, 05 Sep 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <arxiv:DOI>10.1088/1748-0221/19/09/P09003</arxiv:DOI>
      <arxiv:journal_reference>2024 JINST 19 P09003</arxiv:journal_reference>
      <dc:creator>Thorsten Buss, Frank Gaede, Gregor Kasieczka, Claudius Krause, David Shih</dc:creator>
    </item>
  </channel>
</rss>
