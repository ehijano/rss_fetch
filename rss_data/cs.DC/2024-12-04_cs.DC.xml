<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>cs.DC updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/cs.DC</link>
    <description>cs.DC updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/cs.DC" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Wed, 04 Dec 2024 05:00:14 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Wed, 04 Dec 2024 00:00:00 -0500</pubDate>
    <skipDays>
      <day>Sunday</day>
      <day>Saturday</day>
    </skipDays>
    <item>
      <title>AVA: Fault-tolerant Reconfigurable Geo-Replication on Heterogeneous Clusters</title>
      <link>https://arxiv.org/abs/2412.01999</link>
      <description>arXiv:2412.01999v1 Announce Type: new 
Abstract: Fault-tolerant replicated database systems consume less energy than the compute-intensive proof-of-work blockchain. Thus, they are promising technologies for the building blocks that assemble global financial infrastructure. To facilitate global scaling, clustered replication protocols are essential in orchestrating nodes into clusters based on proximity. However, the existing approaches often assume a homogeneous and fixed model in which the number of nodes across clusters is the same and fixed, and often limited to a fail-stop fault model. This paper presents heterogeneous and reconfigurable clustered replication for the general environment with arbitrary failures. In particular, we present AVA, a fault-tolerant reconfigurable geo-replication that allows dynamic membership: replicas are allowed to join and leave clusters. We formally state and prove the safety and liveness properties of the protocol. Furthermore, our replication protocol is consensus-agnostic, meaning each cluster can utilize any local replication mechanism. In our comprehensive evaluation, we instantiate our replication with both HotStuff and BFT-SMaRt. Experiments on geo-distributed deployments on Google Cloud demonstrates that members of clusters can be reconfigured without considerably affecting transaction processing, and that heterogeneity of clusters may significantly improve throughput.</description>
      <guid isPermaLink="false">oai:arXiv.org:2412.01999v1</guid>
      <category>cs.DC</category>
      <pubDate>Wed, 04 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Tejas Mane, Xiao Li, Mohammad Sadoghi, Mohsen Lesani</dc:creator>
    </item>
    <item>
      <title>Stably computable relations and predicates</title>
      <link>https://arxiv.org/abs/2412.02008</link>
      <description>arXiv:2412.02008v1 Announce Type: new 
Abstract: A population protocol stably computes a relation R(x,y) if its output always stabilizes and R(x,y) holds if and only if y is a possible output for input x. Alternatively, a population protocol computes a predicate R(&lt;x,y&gt;) on pairs &lt;x,y&gt; if its output stabilizes on the truth value of the predicate when given &lt;x,y&gt; as input.
  We consider how stably computing R(x,y) and R(&lt;x,y&gt;) relate to each other. We show that for population protocols running on a complete interaction graph with n&gt;=2, if R(&lt;x,y&gt;) is a stably computable predicate such that R(x,y) holds for at least one y for each x, then R(x,y) is a stably computable relation. In contrast, the converse is not necessarily true unless R(x,y) holds for exactly one y for each x.</description>
      <guid isPermaLink="false">oai:arXiv.org:2412.02008v1</guid>
      <category>cs.DC</category>
      <pubDate>Wed, 04 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-sa/4.0/</dc:rights>
      <dc:creator>James Aspnes</dc:creator>
    </item>
    <item>
      <title>Simplifying HPC resource selection: A tool for optimizing execution time and cost on Azure</title>
      <link>https://arxiv.org/abs/2412.02047</link>
      <description>arXiv:2412.02047v1 Announce Type: new 
Abstract: Azure Cloud offers a wide range of resources for running HPC workloads, requiring users to configure their deployment by selecting VM types, number of VMs, and processes per VM. Suboptimal decisions may lead to longer execution times or additional costs for the user. We are developing an open-source tool to assist users in making these decisions by considering application input parameters, as they influence resource consumption. The tool automates the time-consuming process of setting up the cloud environment, executing the benchmarking runs, handling output, and providing users with resource selection recommendations as high level insights on run times and costs across different VM types and number of VMs. In this work, we present initial results and insights on reducing the number of cloud executions needed to provide such guidance, leveraging data analytics and optimization techniques with two well-known HPC applications: OpenFOAM and LAMMPS.</description>
      <guid isPermaLink="false">oai:arXiv.org:2412.02047v1</guid>
      <category>cs.DC</category>
      <pubDate>Wed, 04 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Marco A. S. Netto, Wolfgang De Savador, Davide Vanzo</dc:creator>
    </item>
    <item>
      <title>Thallus: An RDMA-based Columnar Data Transport Protocol</title>
      <link>https://arxiv.org/abs/2412.02192</link>
      <description>arXiv:2412.02192v1 Announce Type: new 
Abstract: The volume of data generated and stored in contemporary global data centers is experiencing exponential growth. This rapid data growth necessitates efficient processing and analysis to extract valuable business insights. In distributed data processing systems, data undergoes exchanges between the compute servers that contribute significantly to the total data processing duration in adequately large clusters, necessitating efficient data transport protocols. Traditionally, data transport frameworks such as JDBC and ODBC have used TCP/IP-over-Ethernet as their underlying network protocol. Such frameworks require serializing the data into a single contiguous buffer before handing it off to the network card, primarily due to the requirement of contiguous data in TCP/IP. In OLAP use cases, this serialization process is costly for columnar data batches as it involves numerous memory copies that hurt data transport duration and overall data processing performance. We study the serialization overhead in the context of a widely-used columnar data format, Apache Arrow, and propose leveraging RDMA to transport Arrow data over Infiniband in a zero-copy manner. We design and implement Thallus, an RDMA-based columnar data transport protocol for Apache Arrow based on the Thallium framework from the Mochi ecosystem, compare it with a purely Thallium RPC-based implementation, and show substantial performance improvements can be achieved by using RDMA for columnar data transport.</description>
      <guid isPermaLink="false">oai:arXiv.org:2412.02192v1</guid>
      <category>cs.DC</category>
      <category>cs.DB</category>
      <category>cs.OS</category>
      <pubDate>Wed, 04 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Jayjeet Chakraborty, Matthieu Dorier, Philip Carns, Robert Ross, Carlos Maltzahn, Heiner Litz</dc:creator>
    </item>
    <item>
      <title>Connecting Large Language Models with Blockchain: Advancing the Evolution of Smart Contracts from Automation to Intelligence</title>
      <link>https://arxiv.org/abs/2412.02263</link>
      <description>arXiv:2412.02263v1 Announce Type: new 
Abstract: Blockchain smart contracts have catalyzed the development of decentralized applications across various domains, including decentralized finance. However, due to constraints in computational resources and the prevalence of data silos, current smart contracts face significant challenges in fully leveraging the powerful capabilities of Large Language Models (LLMs) for tasks such as intelligent analysis and reasoning. To address this gap, this paper proposes and implements a universal framework for integrating LLMs with blockchain data, {\sysname}, effectively overcoming the interoperability barriers between blockchain and LLMs. By combining semantic relatedness with truth discovery methods, we introduce an innovative data aggregation approach, {\funcname}, which significantly enhances the accuracy and trustworthiness of data generated by LLMs. To validate the framework's effectiveness, we construct a dataset consisting of three types of questions, capturing Q\&amp;A interactions between 10 oracle nodes and 5 LLM models. Experimental results demonstrate that, even with 40\% malicious nodes, the proposed solution improves data accuracy by an average of 17.74\% compared to the optimal baseline. This research not only provides an innovative solution for the intelligent enhancement of smart contracts but also highlights the potential for deep integration between LLMs and blockchain technology, paving the way for more intelligent and complex applications of smart contracts in the future.</description>
      <guid isPermaLink="false">oai:arXiv.org:2412.02263v1</guid>
      <category>cs.DC</category>
      <category>cs.AI</category>
      <pubDate>Wed, 04 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Youquan Xian, Xueying Zeng, Duancheng Xuan, Danping Yang, Chunpei Li, Peng Fan, Peng Liu</dc:creator>
    </item>
    <item>
      <title>Scalable Analysis of Urban Scaling Laws: Leveraging Cloud Computing to Analyze 21,280 Global Cities</title>
      <link>https://arxiv.org/abs/2412.02299</link>
      <description>arXiv:2412.02299v1 Announce Type: new 
Abstract: Cities play a pivotal role in human development and sustainability, yet studying them presents significant challenges due to the vast scale and complexity of spatial-temporal data. One such challenge is the need to uncover universal urban patterns, such as the urban scaling law, across thousands of cities worldwide. In this study, we propose a novel large-scale geospatial data processing system that enables city analysis on an unprecedented scale. We demonstrate the system's capabilities by revisiting the urban scaling law across 21,280 cities globally, using a range of open-source datasets including road networks, nighttime light intensity, built-up areas, and population statistics. Analyzing the characteristics of 21,280 cities involves querying over half a billion geospatial data points, a task that traditional Geographic Information Systems (GIS) would take several days to process. In contrast, our cloud-based system accelerates the analysis, reducing processing time to just minutes while significantly lowering resource consumption. Our findings reveal that the urban scaling law varies across cities in under-developed, developing, and developed regions, extending the insights gained from previous studies focused on hundreds of cities. This underscores the critical importance of cloud-based big data processing for efficient, large-scale geospatial analysis. As the availability of satellite imagery and other global datasets continues to grow, the potential for scientific discovery expands exponentially. Our approach not only demonstrates how such large-scale tasks can be executed efficiently but also offers a powerful solution for data scientists and researchers working in the fields of city and geospatial science.</description>
      <guid isPermaLink="false">oai:arXiv.org:2412.02299v1</guid>
      <category>cs.DC</category>
      <pubDate>Wed, 04 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Zhenhui Li, Hongwei Zhang, Kan Wu</dc:creator>
    </item>
    <item>
      <title>MQFL-FHE: Multimodal Quantum Federated Learning Framework with Fully Homomorphic Encryption</title>
      <link>https://arxiv.org/abs/2412.01858</link>
      <description>arXiv:2412.01858v1 Announce Type: cross 
Abstract: The integration of fully homomorphic encryption (FHE) in federated learning (FL) has led to significant advances in data privacy. However, during the aggregation phase, it often results in performance degradation of the aggregated model, hindering the development of robust representational generalization. In this work, we propose a novel multimodal quantum federated learning framework that utilizes quantum computing to counteract the performance drop resulting from FHE. For the first time in FL, our framework combines a multimodal quantum mixture of experts (MQMoE) model with FHE, incorporating multimodal datasets for enriched representation and task-specific learning. Our MQMoE framework enhances performance on multimodal datasets and combined genomics and brain MRI scans, especially for underrepresented categories. Our results also demonstrate that the quantum-enhanced approach mitigates the performance degradation associated with FHE and improves classification accuracy across diverse datasets, validating the potential of quantum interventions in enhancing privacy in FL.</description>
      <guid isPermaLink="false">oai:arXiv.org:2412.01858v1</guid>
      <category>quant-ph</category>
      <category>cs.CR</category>
      <category>cs.DC</category>
      <category>cs.ET</category>
      <category>cs.LG</category>
      <pubDate>Wed, 04 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Siddhant Dutta, Nouhaila Innan, Sadok Ben Yahia, Muhammad Shafique, David Esteban Bernal Neira</dc:creator>
    </item>
    <item>
      <title>Towards the efficacy of federated prediction for epidemics on networks</title>
      <link>https://arxiv.org/abs/2412.02161</link>
      <description>arXiv:2412.02161v1 Announce Type: cross 
Abstract: Epidemic prediction is of practical significance in public health, enabling early intervention, resource allocation, and strategic planning. However, privacy concerns often hinder the sharing of health data among institutions, limiting the development of accurate prediction models. In this paper, we develop a general privacy-preserving framework for node-level epidemic prediction on networks based on federated learning (FL). We frame the spatio-temporal spread of epidemics across multiple data-isolated subnetworks, where each node state represents the aggregate epidemic severity within a community. Then, both the pure temporal LSTM model and the spatio-temporal model i.e., Spatio-Temporal Graph Attention Network (STGAT) are proposed to address the federated epidemic prediction. Extensive experiments are conducted on various epidemic processes using a practical airline network, offering a comprehensive assessment of FL efficacy under diverse scenarios. By introducing the efficacy energy metric to measure system robustness under various client configurations, we systematically explore key factors influencing FL performance, including client numbers, aggregation strategies, graph partitioning, missing infectious reports. Numerical results manifest that STGAT excels in capturing spatio-temporal dependencies in dynamic processes whereas LSTM performs well in simpler pattern. Moreover, our findings highlight the importance of balancing feature consistency and volume uniformity among clients, as well as the prediction dilemma between information richness and intrinsic stochasticity of dynamic processes. This study offers practical insights into the efficacy of FL scenario in epidemic management, demonstrates the potential of FL to address broader collective dynamics.</description>
      <guid isPermaLink="false">oai:arXiv.org:2412.02161v1</guid>
      <category>cs.SI</category>
      <category>cs.DC</category>
      <category>cs.LG</category>
      <pubDate>Wed, 04 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Chengpeng Fu, Tong Li, Hao Chen, Wen Du, Zhidong He</dc:creator>
    </item>
    <item>
      <title>Technical Report on Reinforcement Learning Control on the Lucas-N\"ulle Inverted Pendulum</title>
      <link>https://arxiv.org/abs/2412.02264</link>
      <description>arXiv:2412.02264v1 Announce Type: cross 
Abstract: The discipline of automatic control is making increased use of concepts that originate from the domain of machine learning. Herein, reinforcement learning (RL) takes an elevated role, as it is inherently designed for sequential decision making, and can be applied to optimal control problems without the need for a plant system model. To advance education of control engineers and operators in this field, this contribution targets an RL framework that can be applied to educational hardware provided by the Lucas-N\"ulle company. Specifically, the goal of inverted pendulum control is pursued by means of RL, including both, swing-up and stabilization within a single holistic design approach. Herein, the actual learning is enabled by separating corresponding computations from the real-time control computer and outsourcing them to a different hardware. This distributed architecture, however, necessitates communication of the involved components, which is realized via CAN bus. The experimental proof of concept is presented with an applied safeguarding algorithm that prevents the plant from being operated harmfully during the trial-and-error training phase.</description>
      <guid isPermaLink="false">oai:arXiv.org:2412.02264v1</guid>
      <category>eess.SY</category>
      <category>cs.DC</category>
      <category>cs.LG</category>
      <category>cs.SY</category>
      <pubDate>Wed, 04 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Maximilian Schenke, Shalbus Bukarov</dc:creator>
    </item>
    <item>
      <title>Learn More by Using Less: Distributed Learning with Energy-Constrained Devices</title>
      <link>https://arxiv.org/abs/2412.02289</link>
      <description>arXiv:2412.02289v1 Announce Type: cross 
Abstract: Federated Learning (FL) has emerged as a solution for distributed model training across decentralized, privacy-preserving devices, but the different energy capacities of participating devices (system heterogeneity) constrain real-world implementations. These energy limitations not only reduce model accuracy but also increase dropout rates, impacting on convergence in practical FL deployments. In this work, we propose LeanFed, an energy-aware FL framework designed to optimize client selection and training workloads on battery-constrained devices. LeanFed leverages adaptive data usage by dynamically adjusting the fraction of local data each device utilizes during training, thereby maximizing device participation across communication rounds while ensuring they do not run out of battery during the process. We rigorously evaluate LeanFed against traditional FedAvg on CIFAR-10 and CIFAR-100 datasets, simulating various levels of data heterogeneity and device participation rates. Results show that LeanFed consistently enhances model accuracy and stability, particularly in settings with high data heterogeneity and limited battery life, by mitigating client dropout and extending device availability. This approach demonstrates the potential of energy-efficient, privacy-preserving FL in real-world, large-scale applications, setting a foundation for robust and sustainable pervasive AI on resource-constrained networks.</description>
      <guid isPermaLink="false">oai:arXiv.org:2412.02289v1</guid>
      <category>cs.LG</category>
      <category>cs.DC</category>
      <category>eess.SP</category>
      <pubDate>Wed, 04 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Roberto Pereira, Cristian J. Vaca-Rubio, Luis Blanco</dc:creator>
    </item>
    <item>
      <title>Dispersion on Time-Varying Graphs</title>
      <link>https://arxiv.org/abs/2410.04050</link>
      <description>arXiv:2410.04050v2 Announce Type: replace 
Abstract: Besides being studied over static graphs heavily, the dispersion problem is also studied on dynamic graphs with $n$ nodes where at each discrete time step the graph is a connected sub-graph of the complete graph $K_n$. An optimal algorithm is provided assuming global communication and 1-hop visibility of the agents. How this problem pans out on Time-Varying Graphs (TVG) is kept as an open question in the literature. In this work, we study this problem on TVG considering $k\geq 1$ agents where at each discrete time step the adversary can remove at most one edge keeping the underlying graph connected. We have the following main results considering all agents start from a rooted initial configuration. Global communication and 1-hop visibility are must to solve dispersion for $pn$ ($p\geq 1$) co-located agents on a TVG even if agents have unlimited memory and knowledge of $n$. We provide an algorithm that disperses $n+1$ agents on TVG by dropping both the assumptions of global communication and 1-hop visibility using $O(\log n)$ memory per agent. We extend this algorithm to solve dispersion with $pn+1$ agents with the same model assumptions.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.04050v2</guid>
      <category>cs.DC</category>
      <pubDate>Wed, 04 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Ashish Saxena, Tanvir Kaur, Kaushik Mondal</dc:creator>
    </item>
    <item>
      <title>Restless reachability problems in temporal graphs</title>
      <link>https://arxiv.org/abs/2010.08423</link>
      <description>arXiv:2010.08423v5 Announce Type: replace-cross 
Abstract: We study a family of reachability problems under waiting-time restrictions in temporal and vertex-colored temporal graphs. Given a temporal graph and a set of source vertices, we find the set of vertices that are reachable from a source via a time-respecting path, where the difference in timestamps between consecutive edges is at most a resting time. Given a vertex-colored temporal graph and a multiset query of colors, we find the set of vertices reachable from a source via a time-respecting path such that the vertex colors of the path agree with the multiset query and the difference in timestamps between consecutive edges is at most a resting time. These kind of problems have applications in understanding the spread of a disease in a network, tracing contacts in epidemic outbreaks, finding signaling pathways in the brain network, and recommending tours for tourists, among other.
  We present an algebraic algorithmic framework based on constrained multi\-linear sieving for solving the restless reachability problems we propose. In particular, parameterized by the length $k$ of a path sought, we show that the proposed problems can be solved in $O(2^k k m \Delta)$ time and $O(n \Delta)$ space, where $n$ is the number of vertices, $m$ the number of edges, and $\Delta$ the maximum resting time of an input temporal graph. In addition, we prove that our algorithms for the restless reachability problems in vertex-colored temporal graphs are optimal under plausible complexity-theoretic assumptions. Finally, with an open-source implementation, we demonstrate that our algorithm scales to large graphs with up to one billion temporal edges, despite the problems being NP-hard. Specifically, we present extensive experiments to evaluate our scalability claims both on synthetic and real-world graphs. Our implementation is efficiently engineered and highly optimized.</description>
      <guid isPermaLink="false">oai:arXiv.org:2010.08423v5</guid>
      <category>cs.DS</category>
      <category>cs.DC</category>
      <pubDate>Wed, 04 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <dc:creator>Suhas Thejaswi, Juho Lauri, Aristides Gionis</dc:creator>
    </item>
  </channel>
</rss>
