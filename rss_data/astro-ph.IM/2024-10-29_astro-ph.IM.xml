<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>astro-ph.IM updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/astro-ph.IM</link>
    <description>astro-ph.IM updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/astro-ph.IM" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Tue, 29 Oct 2024 04:00:13 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Tue, 29 Oct 2024 00:00:00 -0400</pubDate>
    <skipDays>
      <day>Saturday</day>
      <day>Sunday</day>
    </skipDays>
    <item>
      <title>wolensing: A Python package for computing the amplification factor for gravitational waves with wave-optics effects</title>
      <link>https://arxiv.org/abs/2410.19804</link>
      <description>arXiv:2410.19804v1 Announce Type: new 
Abstract: The wolensing Python package offers a solution for gravitational wave lensing computations within the full wave-optics regime. This tool is primarily designed to calculate the gravitational lensing amplification factor including diffractive effects, an essential component for generating accurate lensed gravitational wave waveforms. These waveforms are integral to astrophysical and cosmological studies related to gravitational-wave lensing. Integrating with lensingGW (Pagano, Hannuksela, and Li 2020), wolensing provides solutions for image positions in the high-frequency regime where wave and geometrical optics converge. This functionality allows the amplification factor to be applicable across a wider frequency range. Another key feature of wolensing is its ability to plot time delay contours on the lens plane, offering researchers a visual tool to better understand the relationship between the lens system and the amplification factor. wolensing is compatible with various lens models in lenstronomy (Birrer et al. 2021). There are also built-in lens models including point mass, singular isothermal sphere (SIS),and nonsingular isothermal ellipsoid (NIE) with jax (Bradbury et al. 2018) supporting GPU computation. Users can accommodate different lens models in the code with jax. wolensing is available as an open-source package on PyPI and can be installed via pip.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.19804v1</guid>
      <category>astro-ph.IM</category>
      <pubDate>Tue, 29 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Simon M. C. Yeung, Mark H. Y. Cheung, Miguel Zumalacarregui, Otto A. Hannuksela</dc:creator>
    </item>
    <item>
      <title>Gravitational-Wave Parameter Estimation in non-Gaussian noise using Score-Based Likelihood Characterization</title>
      <link>https://arxiv.org/abs/2410.19956</link>
      <description>arXiv:2410.19956v1 Announce Type: new 
Abstract: Gravitational-wave (GW) parameter estimation typically assumes that instrumental noise is Gaussian and stationary. Obvious departures from this idealization are typically handled on a case-by-case basis, e.g., through bespoke procedures to ``clean'' non-Gaussian noise transients (glitches), as was famously the case for the GW170817 neutron-star binary. Although effective, manipulating the data in this way can introduce biases in the inference of key astrophysical properties, like binary precession, and compound in unpredictable ways when combining multiple observations; alternative procedures free of the same biases, like joint inference of noise and signal properties, have so far proved too computationally expensive to execute at scale. Here we take a different approach: rather than explicitly modeling individual non-Gaussianities to then apply the traditional GW likelihood, we seek to learn the true distribution of instrumental noise without presuming Gaussianity and stationarity in the first place. Assuming only noise additivity, we employ score-based diffusion models to learn an empirical noise distribution directly from detector data and then combine it with a deterministic waveform model to provide an unbiased estimate of the likelihood function. We validate the method by performing inference on a subset of GW parameters from 400 mock observations, containing real LIGO noise from either the Livingston or Hanford detectors. We show that the proposed method can recover the true parameters even in the presence of loud glitches, and that the inference is unbiased over a population of signals without applying any cleaning to the data. This work provides a promising avenue for extracting unbiased source properties in future GW observations over the coming decade.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.19956v1</guid>
      <category>astro-ph.IM</category>
      <category>astro-ph.HE</category>
      <category>gr-qc</category>
      <pubDate>Tue, 29 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Ronan Legin, Maximiliano Isi, Kaze W. K. Wong, Yashar Hezaveh, Laurence Perreault-Levasseur</dc:creator>
    </item>
    <item>
      <title>Robust support for semi-automated reductions of Keck/NIRSPEC data using PypeIt</title>
      <link>https://arxiv.org/abs/2410.19991</link>
      <description>arXiv:2410.19991v1 Announce Type: new 
Abstract: We present a data reduction pipeline (DRP) for Keck/NIRSPEC built as an addition to the PypeIt Python package. The DRP is capable of reducing multi-order echelle data taken both before and after the detector upgrade in 2018. As part of developing the pipeline, we implemented major improvements to the capabilities of the PypeIt package, including manual wavelength calibration for multi-order data and new output product that returns a coadded spectrum order-by-order. We also provide a procedure for correcting telluric absorption in NIRSPEC data by using the spectra of telluric standard stars taken near the time of the science spectra. At high resolutions, this is often more accurate than modeling-based approaches.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.19991v1</guid>
      <category>astro-ph.IM</category>
      <pubDate>Tue, 29 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Adolfo S. Carvalho, Greg Doppmann, Kyle B. Westfall, Debora Pelliccia, J. Xavier Prochaska, Joseph Hennawi, Frederick B. Davies, Max Brodheim, Feige Wang, Ryan Cooke</dc:creator>
    </item>
    <item>
      <title>Cross-Survey Image Transformation: Enhancing SDSS and DECaLS Images to Near-HSC Quality for Advanced Astronomical Analysis</title>
      <link>https://arxiv.org/abs/2410.20025</link>
      <description>arXiv:2410.20025v1 Announce Type: new 
Abstract: This study focuses on transforming galaxy images between astronomical surveys, specifically enhancing images from the Sloan Digital Sky Survey (SDSS) and the Dark Energy Camera Legacy Survey (DECaLS) to achieve quality comparable to the Hyper Suprime-Cam survey (HSC). We proposed a hybrid model called Pix2WGAN, which integrates the pix2pix framework with the Wasserstein Generative Adversarial Network with Gradient Penalty (WGAN-GP) to convert low-quality observational images into high-quality counterparts. Our model successfully transformed DECaLS images into pseudo-HSC images, yielding impressive results and significantly enhancing the identification of complex structures, such as galaxy spiral arms and tidal tails, which may have been overlooked in the original DECaLS images. Moreover, Pix2WGAN effectively addresses issues like artifacts, noise, and blurriness in both source and target images. In addition to the basic Pix2WGAN model, we further developed an advanced architecture called Cascaded Pix2WGAN, which incorporates a multi-stage training mechanism designed to bridge the quality gap between SDSS and HSC images, demonstrating similarly promising outcomes. We systematically assessed the similarity between the model-generated pseudo-HSC images and actual HSC images using various metrics, including Mean Squared Error (MSE), Peak Signal-to-Noise Ratio (PSNR), and Structural Similarity Index (SSIM), along with perceptual metrics such as Learned Perceptual Image Patch Similarity (LPIPS) and Fr\'echet Inception Distance (FID). The results indicate that images transformed by our model outperform both the original SDSS and DECaLS images across nearly all evaluation metrics. Our research is expected to provide significant technical support for astronomical data analysis, cross-survey image integration, and high-precision astrometry.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.20025v1</guid>
      <category>astro-ph.IM</category>
      <category>astro-ph.GA</category>
      <pubDate>Tue, 29 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Zhijian Luo, Shaohua Zhang, Jianzhen Chen, Zhu Chen, Liping Fu, Hubing Xiao, Wei Du, Chenggang Shu</dc:creator>
    </item>
    <item>
      <title>Lensing point-spread function of coherent astrophysical sources and non-trivial wave effects</title>
      <link>https://arxiv.org/abs/2410.20049</link>
      <description>arXiv:2410.20049v1 Announce Type: new 
Abstract: Most research on astrophysical lensing has been conducted using the geometric optics framework, where there exists a clear concept of lensing images. However, wave optics effects can be important for coherent sources, e.g. pulsars, fast raio bursts, and gravitational waves observed at long wavelengths. There, the concept of lensing images needs an extension. We introduce the concept of the `lensing point-spread function' (LPSF), the smoothed flux density distribution of a coherent point source after being lensed, as a generalization of the lensing image concept at finite frequencies. The frequency-dependent LPSF captures the gradual change of the flux density distribution of the source from discrete geometric images at high frequencies to a smooth distribution at low frequencies. It complements other generalizations of lensing images, notably the imaginary images and the Lefschetz thimbles. Being a footprint of a lensing system, the LPSF is useful for theoretical studies of lensing. Using the LPSF, we identify a frequency range with non-trivial wave effects, where both geometric optics and perturbative wave optics fail, and determine this range to be $|\kappa|^{-1} \lesssim \nu \lesssim 10$, with $\kappa$ and $\nu$ being the dimensionless lens amplitude and the reduced observing frequency, respectively. Observation of LPSFs with non-trivial wave effects requires either very close-by lenses or very large observing wavelengths. The potential possibilities are the lensing of gravitational waves, the plasma lensing of Milky Way pulsars, and lensing by the solar gravitational lens.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.20049v1</guid>
      <category>astro-ph.IM</category>
      <category>astro-ph.CO</category>
      <category>astro-ph.GA</category>
      <category>physics.optics</category>
      <pubDate>Tue, 29 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <arxiv:DOI>10.3847/1538-4357/ad75fb</arxiv:DOI>
      <arxiv:journal_reference>2024 ApJ 975 79</arxiv:journal_reference>
      <dc:creator>Xun Shi</dc:creator>
    </item>
    <item>
      <title>Postprocessing of tilt-to-length noise with coefficient drifts in TianQin using a null time-delay interferometry channel</title>
      <link>https://arxiv.org/abs/2410.20121</link>
      <description>arXiv:2410.20121v1 Announce Type: new 
Abstract: Tilt-to-length (TTL) coupling is expected to be one of the major noise sources in the interferometric phase readouts in TianQin mission. Arising from the angular motion of spacecraft (SC) and the onboard movable optical subassemblies (MOSAs), TTL noise needs to be removed in postprocessing after suppressing the laser phase noise with time-delay interferometry (TDI) technique. In this article, we show that we can estimate the TTL coupling coefficients using the null TDI channel {\zeta} and remove the TTL noise in the commonly used Michelson variables with the estimated coefficients. We introduce the theoretical model of TTL noise in TDI and consider linear drifts in the linear TTL coefficients for noise estimation and subtraction. The TTL coefficients with drifts are estimated successfully with an accuracy of 10 {\mu}m/rad in our numerical simulation. We discuss the impact of point-ahead angle compensation error and wavefront error, and find it necessary to estimate linear drift coefficients and quadratic TTL coefficients to keep TTL noise residuals below the 0.3 pm noise reference curve. However, the estimation accuracy suffers greatly from the correlation between yaw jitter measurements that contain the same SC jitter. Assuming all angular jitters induced by MOSAs are independent, choosing a frequency range with relatively higher MOSA yaw jitter noise levels is beneficial to the TTL coefficient estimation.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.20121v1</guid>
      <category>astro-ph.IM</category>
      <pubDate>Tue, 29 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Zhizhao Wang, Shuju Yang, Kaihang Wu, Xiaojie Wang, Huizong Duan, Yurong Liang, Xuefeng Zhang, Hsien-Chi Yeh</dc:creator>
    </item>
    <item>
      <title>Orbit Design for the Millimetron Space Observatory</title>
      <link>https://arxiv.org/abs/2410.20847</link>
      <description>arXiv:2410.20847v1 Announce Type: new 
Abstract: Millimetron is a space observatory for millimeter and sub-millimeter observations planned for launch around 2030. The 10-meter diameter space unfolded telescope will be cooled down to 10~K and operated in the vicinity of Lagrange point L2. Mission lifetime is 10 years and it includes astronomical observations in two modes: as a space-ground interferometer and as a single-dish telescope. This paper presents the results of the Millimetron space observatory orbit design that takes into account technical and scientific requirements and constraints. It covers the computation of suitable operational orbits, the selection of an orbit, and the transfer from Earth. Furthermore, scientific objectives are demonstrated through VLBI visibility simulation and image reconstruction. Unlike previous works that used analytical methods, this work employs numerical integration for orbital design. Based on the orbital design methods developed in this work, we calculate the exact dates for departure, halo formation, and trajectory correction. Additionally, we investigate the existence of the short baseline projection and its specific dates for VLBI mode and show the feasibility of scientific objectives through VLBI visibility simulation and image reconstruction.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.20847v1</guid>
      <category>astro-ph.IM</category>
      <pubDate>Tue, 29 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>T. A. Syachina, A. G. Rudnitskiy, P. V. Mzhelskiy, M. A. Shchurov, P. R. Zapevalin</dc:creator>
    </item>
    <item>
      <title>Accelerated Bayesian parameter estimation and model selection for gravitational waves with normalizing flows</title>
      <link>https://arxiv.org/abs/2410.21076</link>
      <description>arXiv:2410.21076v1 Announce Type: new 
Abstract: We present an accelerated pipeline, based on high-performance computing techniques and normalizing flows, for joint Bayesian parameter estimation and model selection and demonstrate its efficiency in gravitational wave astrophysics. We integrate the Jim inference toolkit, a normalizing flow-enhanced Markov chain Monte Carlo (MCMC) sampler, with the learned harmonic mean estimator. Our Bayesian evidence estimates run on $1$ GPU are consistent with traditional nested sampling techniques run on $16$ CPU cores, while reducing the computation time by factors of $5\times$ and $15\times$ for $4$-dimensional and $11$-dimensional gravitational wave inference problems, respectively. Our code is available in well-tested and thoroughly documented open-source packages, ensuring accessibility and reproducibility for the wider research community.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.21076v1</guid>
      <category>astro-ph.IM</category>
      <category>astro-ph.HE</category>
      <category>cs.LG</category>
      <category>gr-qc</category>
      <pubDate>Tue, 29 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Alicja Polanska, Thibeau Wouters, Peter T. H. Pang, Kaze K. W. Wong, Jason D. McEwen</dc:creator>
    </item>
    <item>
      <title>Superluminous supernova search with PineForest</title>
      <link>https://arxiv.org/abs/2410.21077</link>
      <description>arXiv:2410.21077v1 Announce Type: new 
Abstract: The advent of large astronomical surveys has made available large and complex data sets. However, the process of discovery and interpretation of each potentially new astronomical source is, many times, still handcrafted. In this context, machine learning algorithms have emerged as a powerful tool to mine large data sets and lower the burden on the domain expert. Active learning strategies are specially good in this task. In this report, we used the PineForest algorithm to search for superluminous supernova (SLSN) candidates in the Zwicky Transient Facility. We showcase how the use of previously confirmed sources can provide important information to boost the convergence of the active learning algorithm. Starting from a data set of $\sim$14 million objects, and using 8 previously confirmed SLSN light curves as priors, we scrutinized 120 candidates and found 8 SLSN candidates, 2 of which have not been reported before (AT 2018moa and AT 2018mob). These results demonstrate how existing spectroscopic samples can be used to improve the efficiency of active learning strategies in searching for rare astronomical sources.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.21077v1</guid>
      <category>astro-ph.IM</category>
      <category>astro-ph.HE</category>
      <pubDate>Tue, 29 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>T. Majumder, M. V. Pruzhinskaya, E. E. O. Ishida, K. L. Malanchev, T. A. Semenikhin</dc:creator>
    </item>
    <item>
      <title>SIROCCO: A Publicly Available Monte Carlo Ionization and Radiative Transfer Code for Astrophysical Outflows</title>
      <link>https://arxiv.org/abs/2410.19908</link>
      <description>arXiv:2410.19908v1 Announce Type: cross 
Abstract: Outflows are critical components of many astrophysical systems, including accreting compact binaries and active galactic nuclei (AGN). These outflows can significantly affect a system's evolution and alter its observational appearance by reprocessing the radiation produced by the central engine. Sirocco (Simulating Ionization and Radiation in Outflows Created by Compact Objects - or "the code formerly known as Python") is a Sobolev-based Monte Carlo ionization and radiative transfer code. It is designed to simulate the spectra produced by any system with an azimuthally-symmetric outflow, from spherical stellar winds to rotating, biconical accretion disc winds. Wind models can either be parametrized or imported, e.g. from hydrodynamical simulations. The radiation sources include an optically thick accretion disc and various central sources with flexible spectra and geometries. The code tracks the "photon packets" produced by the sources in any given simulation as they traverse and interact with the wind. The code assumes radiative near-equilibrium, so the thermal and ionization state can be determined iteratively from these interactions. Once the physical properties in the wind have converged, Sirocco can be used to generate synthetic spectra at a series of observer sightlines. Here, we describe the physical assumptions, operation, performance and limitations of the code. We validate it against tardis, cmfgen and cloudy, finding good agreement, and present illustrative synthetic spectra from disc winds in cataclysmic variables, tidal disruption events, AGN and X-ray binaries. Sirocco is publicly available on GitHub, alongside its associated data, documentation and sample input files covering a wide range of astrophysical applications.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.19908v1</guid>
      <category>astro-ph.HE</category>
      <category>astro-ph.GA</category>
      <category>astro-ph.IM</category>
      <category>astro-ph.SR</category>
      <pubDate>Tue, 29 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>James H. Matthews, Knox S. Long, Christian Knigge, Stuart A. Sim, Edward J. Parkinson, Nick Higginbottom, Samuel W. Mangham, Nicolas Scepi, Austen Wallis, Henrietta A. Hewitt, Amin Mosallanezhad</dc:creator>
    </item>
    <item>
      <title>Detecting and sizing the Earth with PLATO: A feasibility study based on solar data</title>
      <link>https://arxiv.org/abs/2410.20077</link>
      <description>arXiv:2410.20077v1 Announce Type: cross 
Abstract: Context. The PLAnetary Transits and Oscillations of stars (PLATO) mission will observe the same area of the sky continuously for at least two years in an effort to detect transit signals of an Earth-like planet orbiting a solar-like star.
  Aims. We aim to study how short-term solar-like variability caused by oscillations and granulation would affect PLATO's ability to detect and size Earth if PLATO were to observe the Solar System itself.
  Methods. We injected Earth-like transit signals onto real solar data taken by the Helioseismic and Magnetic Imager (HMI) instrument. We isolated short-term stellar variability by removing any variability with characteristic timescales longer than five hours. We then added a noise model for a variety of different stellar magnitudes computed by PlatoSim assuming an observation by all 24 normal cameras. We first compared four different commonly used treatments of correlated noise in the time domain. We then tried to recover pairs of transit signals. Finally, we performed transit fits using realistic priors on planetary and stellar parameters.
  Results. We find that short-term solar-like variability affects the correct retrieval of Earth-like transit signals in PLATO data. Variability models accounting for variations with typical timescales at the order of one hour are sufficient to mitigate these effects. For bright targets (8.5 - 10.5 mag), the transit signal of an Earth analogue can reliably be detected in PLATO data. For faint targets the results of transit search algorithms have to be verified by transit-fitting algorithms to avoid false positive detections being flagged. For bright targets (V-mag $\leq$ 9.5), the radius of an Earth-like planet orbiting a solar-like star can be correctly determined at a precision of 3% or less, assuming that at least two transit events are observed and the characteristics of the host star are well understood.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.20077v1</guid>
      <category>astro-ph.EP</category>
      <category>astro-ph.IM</category>
      <category>astro-ph.SR</category>
      <pubDate>Tue, 29 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>A. F. Krenn, M. Lendl, S. Sulis, M. Deleuil, S. J. Hofmeister, N. Jannsen, L. Fossati, J. De Ridder, D. Seynaeve, R. Jarolim, A. M. Veronig</dc:creator>
    </item>
    <item>
      <title>Machine Learning based Glitch Veto for inspiral binary merger signals using Linear Chirp Transform</title>
      <link>https://arxiv.org/abs/2410.20269</link>
      <description>arXiv:2410.20269v1 Announce Type: cross 
Abstract: Unphysical templates for inspiral binary merger signals have emerged as an effective way to veto signals (rule out false positives) identified as glitches. These templates help reduce the parameters needed to distinguish glitches from real gravitational wave signals. Glitches are short, transient noise artifacts which often mimic the true signals, complicating gravitational wave detection. In this study, we apply the chirp transform -- a modification of the Fourier transform incorporating a linear chirp rate, denoted as $\gamma$. This method better tracks signals with varying frequencies, essential for analyzing inspiral merger events. By applying the chirp transform to gravitational wave strain time series, we generate 3D spectrograms with time,frequency and chirp axes, providing a richer dataset for analysis.These spectrograms reveal subtle features ideal for classification tasks. We leverage the use of convolutional neural networks (CNNs) to enhance the accuracy. CNNs are well suited for image based data like these, and we have optimized them to differentiate glitches from true merger signals. Our approach achieves high accuracy on both training and validation datasets, demonstrating the efficacy of combining the chirp transform with deep learning for signal classification. Ultimately we offer a refined efficient classification process by overlapping machine learning and Chirp transform, which will enhance accuracy of glitch detection from observations from detectors like LIGO, VIRGO and upcoming observatories.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.20269v1</guid>
      <category>gr-qc</category>
      <category>astro-ph.IM</category>
      <pubDate>Tue, 29 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/publicdomain/zero/1.0/</dc:rights>
      <dc:creator>N. Arutkeerthi, Xiyuan Li, SR Valluri</dc:creator>
    </item>
    <item>
      <title>Modifications of SPH towards three-dimensional simulations of an icy moon with internal ocean</title>
      <link>https://arxiv.org/abs/2410.20433</link>
      <description>arXiv:2410.20433v1 Announce Type: cross 
Abstract: There are some traces of the existence of internal ocean in some icy moons, such as the vapor plumes of Europa and Enceladus. This implies a region of liquid water beneath the surface ice shell. Since liquid water would be essential for the origin of life, it is important to understand the development of these internal oceans, particularly their temperature distribution and evolution. The balance between tidal heating and radiative cooling is believed to sustain liquid water beneath an icy moon's surface. We aim to simulate the tidal heating of an internal ocean in an icy moon using 3-dimensional numerical fluid calculations with the Smoothed Particle Hydrodynamics (SPH) method. We incorporated viscosity and thermal conduction terms into the governing equations of SPH. However, we encountered two issues while calculating rigid body rotation using SPH with a viscous term: (1) conventional viscosity formulations generated unphysical forces that hindered rotation, and (2) there was artificial internal energy partitioning within the layered structure, which was due to the standard SPH formulations. To address the first issue, we modified the viscosity formulation.For the second, we adopted Density Independent SPH (DISPH) developed in previous studies to improve behavior at discontinuous surfaces. Additionally, we implemented radiative cooling using an algorithm to define fluid surfaces via the particle method. We also introduced an equation of state accounting for phase transitions. With these modifications, we have refined the SPH method to encompass all necessary physical processes for simulating the evolution of icy moons with internal oceans.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.20433v1</guid>
      <category>astro-ph.EP</category>
      <category>astro-ph.IM</category>
      <category>physics.comp-ph</category>
      <category>physics.flu-dyn</category>
      <pubDate>Tue, 29 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Keiya Murashima, Natsuki Hosono, Takayuki R. Saitoh, Takanori Sasaki</dc:creator>
    </item>
    <item>
      <title>A Cosmic-Scale Benchmark for Symmetry-Preserving Data Processing</title>
      <link>https://arxiv.org/abs/2410.20516</link>
      <description>arXiv:2410.20516v1 Announce Type: cross 
Abstract: Efficiently processing structured point cloud data while preserving multiscale information is a key challenge across domains, from graphics to atomistic modeling. Using a curated dataset of simulated galaxy positions and properties, represented as point clouds, we benchmark the ability of graph neural networks to simultaneously capture local clustering environments and long-range correlations. Given the homogeneous and isotropic nature of the Universe, the data exhibits a high degree of symmetry. We therefore focus on evaluating the performance of Euclidean symmetry-preserving ($E(3)$-equivariant) graph neural networks, showing that they can outperform non-equivariant counterparts and domain-specific information extraction techniques in downstream performance as well as simulation-efficiency. However, we find that current architectures fail to capture information from long-range correlations as effectively as domain-specific baselines, motivating future work on architectures better suited for extracting long-range information.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.20516v1</guid>
      <category>cs.LG</category>
      <category>astro-ph.IM</category>
      <pubDate>Tue, 29 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Julia Balla, Siddharth Mishra-Sharma, Carolina Cuesta-Lazaro, Tommi Jaakkola, Tess Smidt</dc:creator>
    </item>
    <item>
      <title>Asteroid Mining: ACT&amp;Friends' Results for the GTOC 12 Problem</title>
      <link>https://arxiv.org/abs/2410.20839</link>
      <description>arXiv:2410.20839v1 Announce Type: cross 
Abstract: In 2023, the 12th edition of Global Trajectory Competition was organised around the problem referred to as "Sustainable Asteroid Mining". This paper reports the developments that led to the solution proposed by ESA's Advanced Concepts Team. Beyond the fact that the proposed approach failed to rank higher than fourth in the final competition leader-board, several innovative fundamental methodologies were developed which have a broader application. In particular, new methods based on machine learning as well as on manipulating the fundamental laws of astrodynamics were developed and able to fill with remarkable accuracy the gap between full low-thrust trajectories and their representation as impulsive Lambert transfers. A novel technique was devised to formulate the challenge of optimal subset selection from a repository of pre-existing optimal mining trajectories as an integer linear programming problem. Finally, the fundamental problem of searching for single optimal mining trajectories (mining and collecting all resources), albeit ignoring the possibility of having intra-ship collaboration and thus sub-optimal in the case of the GTOC12 problem, was efficiently solved by means of a novel search based on a look-ahead score and thus making sure to select asteroids that had chances to be re-visited later on.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.20839v1</guid>
      <category>astro-ph.EP</category>
      <category>astro-ph.IM</category>
      <category>cs.LG</category>
      <pubDate>Tue, 29 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Dario Izzo, Marcus M\"artens, Laurent Beauregard, Max Bannach, Giacomo Acciarini, Emmanuel Blazquez, Alexander Hadjiivanov, Jai Grover, Gernot Hei{\ss}el, Yuri Shimane, Chit Hong Yam</dc:creator>
    </item>
    <item>
      <title>Generative Simulations of The Solar Corona Evolution With Denoising Diffusion : Proof of Concept</title>
      <link>https://arxiv.org/abs/2410.20843</link>
      <description>arXiv:2410.20843v1 Announce Type: cross 
Abstract: The solar magnetized corona is responsible for various manifestations with a space weather impact, such as flares, coronal mass ejections (CMEs) and, naturally, the solar wind. Modeling the corona's dynamics and evolution is therefore critical for improving our ability to predict space weather In this work, we demonstrate that generative deep learning methods, such as Denoising Diffusion Probabilistic Models (DDPM), can be successfully applied to simulate future evolutions of the corona as observed in Extreme Ultraviolet (EUV) wavelengths. Our model takes a 12-hour video of an Active Region (AR) as input and simulate the potential evolution of the AR over the subsequent 12 hours, with a time-resolution of two hours. We propose a light UNet backbone architecture adapted to our problem by adding 1D temporal convolutions after each classical 2D spatial ones, and spatio-temporal attention in the bottleneck part. The model not only produce visually realistic outputs but also captures the inherent stochasticity of the system's evolution. Notably, the simulations enable the generation of reliable confidence intervals for key predictive metrics such as the EUV peak flux and fluence of the ARs, paving the way for probabilistic and interpretable space weather forecasting. Future studies will focus on shorter forecasting horizons with increased spatial and temporal resolution, aiming at reducing the uncertainty of the simulations and providing practical applications for space weather forecasting. The code used for this study is available at the following link: https://github.com/gfrancisco20/video_diffusion</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.20843v1</guid>
      <category>astro-ph.SR</category>
      <category>astro-ph.IM</category>
      <category>cs.AI</category>
      <pubDate>Tue, 29 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Gr\'egoire Francisco, Francesco Pio Ramunno, Manolis K. Georgoulis, Jo\~ao Fernandes, Teresa Barata, Dario Del Moro</dc:creator>
    </item>
    <item>
      <title>CODES: Benchmarking Coupled ODE Surrogates</title>
      <link>https://arxiv.org/abs/2410.20886</link>
      <description>arXiv:2410.20886v1 Announce Type: cross 
Abstract: We introduce CODES, a benchmark for comprehensive evaluation of surrogate architectures for coupled ODE systems. Besides standard metrics like mean squared error (MSE) and inference time, CODES provides insights into surrogate behaviour across multiple dimensions like interpolation, extrapolation, sparse data, uncertainty quantification and gradient correlation. The benchmark emphasizes usability through features such as integrated parallel training, a web-based configuration generator, and pre-implemented baseline models and datasets. Extensive documentation ensures sustainability and provides the foundation for collaborative improvement. By offering a fair and multi-faceted comparison, CODES helps researchers select the most suitable surrogate for their specific dataset and application while deepening our understanding of surrogate learning behaviour.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.20886v1</guid>
      <category>cs.LG</category>
      <category>astro-ph.IM</category>
      <category>physics.comp-ph</category>
      <pubDate>Tue, 29 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-sa/4.0/</dc:rights>
      <dc:creator>Robin Janssen, Immanuel Sulzer, Tobias Buck</dc:creator>
    </item>
    <item>
      <title>A novel conjunction filter based on the minimum distance between perturbed trajectories</title>
      <link>https://arxiv.org/abs/2410.20928</link>
      <description>arXiv:2410.20928v1 Announce Type: cross 
Abstract: The increasing congestion in the near-Earth space environment has amplified the need for robust and efficient conjunction analysis techniques including the computation of the minimum distance between orbital paths in the presence of perturbations. After showing that classical Minimum Orbit Intersection Distance (MOID) computation schemes are unsuitable to treat Earth orbiting objects, the article presents an analytical approach to provide a more accurate estimate of the true distance between perturbed trajectories by incorporating the effect of zonal harmonics of arbitrary order. Cook's linear secular theory for the motion of the eccentricity vector is extended to include higher order eccentricity effects and applied to the computation of the minimum and maximum radii attained by two orbits at their mutual nodes, which can be employed to estimate the true distance between the two orbital paths and to establish an efficient algorithm for determining or excluding potential conjunctions. Extensive testing and validation are conducted using a high-fidelity propagator and a comprehensive dataset of resident space objects. The results demonstrate an accuracy below the km level for the orbit distance computation in 99\% of cases, which enables high-efficiency conjunction filtering.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.20928v1</guid>
      <category>astro-ph.EP</category>
      <category>astro-ph.IM</category>
      <pubDate>Tue, 29 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Ana S. Rivero, Giulio Ba\`u, Rafael Vazquez, Claudio Bombardelli</dc:creator>
    </item>
    <item>
      <title>Breccia and basalt classification of thin sections of Apollo rocks with deep learning</title>
      <link>https://arxiv.org/abs/2410.21024</link>
      <description>arXiv:2410.21024v1 Announce Type: cross 
Abstract: Human exploration of the moon is expected to resume in the next decade, following the last such activities in the Apollo programme time. One of the major objectives of returning to the Moon is to continue retrieving geological samples, with a focus on collecting high-quality specimens to maximize scientific return. Tools that assist astronauts in making informed decisions about sample collection activities can maximize the scientific value of future lunar missions. A lunar rock classifier is a tool that can potentially provide the necessary information for astronauts to analyze lunar rock samples, allowing them to augment in-situ value identification of samples. Towards demonstrating the value of such a tool, in this paper, we introduce a framework for classifying rock types in thin sections of lunar rocks. We leverage the vast collection of petrographic thin-section images from the Apollo missions, captured under plane-polarized light (PPL), cross-polarised light (XPL), and reflected light at varying magnifications. Advanced machine learning methods, including contrastive learning, are applied to analyze these images and extract meaningful features. The contrastive learning approach fine-tunes a pre-trained Inception-Resnet-v2 network with the SimCLR loss function. The fine-tuned Inception-Resnet-v2 network can then extract essential features effectively from the thin-section images of Apollo rocks. A simple binary classifier is trained using transfer learning from the fine-tuned Inception-ResNet-v2 to 98.44\% ($\pm$1.47) accuracy in separating breccias from basalts.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.21024v1</guid>
      <category>astro-ph.EP</category>
      <category>astro-ph.IM</category>
      <category>cs.LG</category>
      <pubDate>Tue, 29 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Freja Thoresen, Aidan Cowley, Romeo Haak, Jonas Lewe, Clara Moriceau, Piotr Knapczyk, Victoria S. Engelschi{\o}n</dc:creator>
    </item>
    <item>
      <title>The VSPEC Collection: A suite of utilities to model spectroscopic phase curves of 3D exoplanet atmospheres in the presence of stellar variability</title>
      <link>https://arxiv.org/abs/2410.21190</link>
      <description>arXiv:2410.21190v1 Announce Type: cross 
Abstract: We present the Variable Star PhasE Curve (VSPEC) Collection, a set of Python packages for simulating combined-light spectroscopic observations of 3-dimensional exoplanet atmospheres in the presence of stellar variability and inhomogeneity. VSPEC uses the Planetary Spectrum Generator's Global Emission Spectra (PSG/GlobES) application along with a custom-built multi-component time-variable stellar model based on a user-defined grid of stellar photosphere models to produce spectroscopic light curves of the planet-host system. VSPEC can be a useful tool for modeling observations of exoplanets in transiting geometries (primary transit, secondary eclipse) as well as orbital phase curve measurements, and is built in a modular and flexible configuration for easy adaptability to new stellar and planetary model inputs. We additionally present a set of codes developed alongside the core VSPEC modules, including the stellar surface model generator vspec-vsm, the stellar spectral grid interpolation code GridPolator, and a Python interface for PSG, libpypsg.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.21190v1</guid>
      <category>astro-ph.EP</category>
      <category>astro-ph.IM</category>
      <category>astro-ph.SR</category>
      <pubDate>Tue, 29 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Ted M Johnson, Cameron Kelahan, Avi M. Mandell, Ashraf Dhahbi, Tobi Hammond, Thomas Barclay, Veselin B. Kostov, Geronimo L. Villanueva</dc:creator>
    </item>
    <item>
      <title>Microlensing Discovery and Characterization Efficiency in the Vera C. Rubin Legacy Survey of Space and Time</title>
      <link>https://arxiv.org/abs/2309.15310</link>
      <description>arXiv:2309.15310v2 Announce Type: replace 
Abstract: The Vera C. Rubin Legacy Survey of Space and Time will discover thousands of microlensing events across the Milky Way Galaxy, allowing for the study of populations of exoplanets, stars, and compact objects. We evaluate numerous survey strategies simulated in the Rubin Operation Simulations (OpSims) to assess the discovery and characterization efficiencies of microlensing events. We have implemented three metrics in the Rubin Metric Analysis Framework: a discovery metric and two characterization metrics, where one estimates how well the lightcurve is covered and the other quantifies how precisely event parameters can be determined. We also assess the characterizability of microlensing parallax, critical for detection of free-floating black hole lenses. We find that, given Rubin's baseline cadence, the discovery and characterization efficiency will be higher for longer duration and larger parallax events. Microlensing discovery efficiency is dominated by the observing footprint, where more time spent looking at regions of high stellar density including the Galactic bulge, Galactic plane, and Magellanic clouds, leads to higher discovery and characterization rates. However, if the observations are stretched over too wide an area, including low-priority areas of the Galactic plane with fewer stars and higher extinction, event characterization suffers by &gt; 10%. This could impact exoplanet, binary star, and compact object events alike. We find that some rolling strategies (where Rubin focuses on a fraction of the sky in alternating years) in the Galactic bulge can lead to a 15-20% decrease in microlensing parallax characterization, so rolling strategies should be chosen carefully to minimize losses.</description>
      <guid isPermaLink="false">oai:arXiv.org:2309.15310v2</guid>
      <category>astro-ph.IM</category>
      <category>astro-ph.GA</category>
      <category>astro-ph.SR</category>
      <pubDate>Tue, 29 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Natasha S. Abrams, Markus P. G. Hundertmark, Somayeh Khakpash, Rachel A. Street, R. Lynne Jones, Jessica R. Lu, Etienne Bachelet, Yiannis Tsapras, Marc Moniez, Tristan Blaineauu, Rosanne Di Stefano, Martin Makler, Anibal Varela, Markus Rabus</dc:creator>
    </item>
    <item>
      <title>Machine Learning based Pointing Models for Radio/Sub-millimeter Telescopes</title>
      <link>https://arxiv.org/abs/2402.08589</link>
      <description>arXiv:2402.08589v2 Announce Type: replace 
Abstract: Radio, sub-millimeter and millimeter ground-based telescopes are powerful instruments for studying the gas and dust-rich regions of the Universe that are invisible at optical wavelengths, but the pointing accuracy is crucial for obtaining high-quality data. Pointing errors are small deviations of the telescope's orientation from its desired direction. The telescopes use linear regression pointing models to correct for these errors, taking into account various factors such as weather conditions, telescope mechanical structure, and the target's position in the sky. However, residual pointing errors can still occur due to factors that are hard to model accurately, such as thermal and gravitational deformation and environmental conditions like humidity and wind. Here we present a proof-of-concept for reducing pointing error for the Atacama Pathfinder EXperiment (APEX) telescope in the high-altitude Atacama Desert in Chile based on machine learning. Using historic pointing data from 2022, we trained eXtreme Gradient Boosting (XGBoost) models that reduced the Root Mean Squared Error (RMSE) for azimuth and elevation (horizontal and vertical angle) pointing corrections by 4.3% and 9.5%, respectively, on hold-out test data. Our results will inform operations of current and future facilities such as the next-generation Atacama Large Aperture Submillimeter Telescope (AtLAST).</description>
      <guid isPermaLink="false">oai:arXiv.org:2402.08589v2</guid>
      <category>astro-ph.IM</category>
      <category>physics.data-an</category>
      <pubDate>Tue, 29 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Bendik Nyheim, Signe Riemer-S{\o}rensen, Rodrigo Parra, Claudia Cicone</dc:creator>
    </item>
    <item>
      <title>Variational Inference for Acceleration of SN Ia Photometric Distance Estimation with BayeSN</title>
      <link>https://arxiv.org/abs/2405.06013</link>
      <description>arXiv:2405.06013v2 Announce Type: replace 
Abstract: Type Ia supernovae (SNe Ia) are standarizable candles whose observed light curves can be used to infer their distances, which can in turn be used in cosmological analyses. As the quantity of observed SNe Ia grows with current and upcoming surveys, increasingly scalable analyses are necessary to take full advantage of these new datasets for precise estimation of cosmological parameters. Bayesian inference methods enable fitting SN Ia light curves with robust uncertainty quantification, but traditional posterior sampling using Markov Chain Monte Carlo (MCMC) is computationally expensive. We present an implementation of variational inference (VI) to accelerate the fitting of SN Ia light curves using the BayeSN hierarchical Bayesian model for time-varying SN Ia spectral energy distributions (SEDs). We demonstrate and evaluate its performance on both simulated light curves and data from the Foundation Supernova Survey with two different forms of surrogate posterior -- a multivariate normal and a custom multivariate zero-lower-truncated normal distribution -- and compare them with the Laplace Approximation and full MCMC analysis. To validate of our variational approximation, we calculate the pareto-smoothed importance sampling (PSIS) diagnostic, and perform variational simulation-based calibration (VSBC). The VI approximation achieves similar results to MCMC but with an order-of-magnitude speedup for the inference of the photometric distance moduli. Overall, we show that VI is a promising method for scalable parameter inference that enables analysis of larger datasets for precision cosmology.</description>
      <guid isPermaLink="false">oai:arXiv.org:2405.06013v2</guid>
      <category>astro-ph.IM</category>
      <category>astro-ph.CO</category>
      <category>stat.AP</category>
      <category>stat.ME</category>
      <pubDate>Tue, 29 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Ana Sof\'ia M. Uzsoy, Stephen Thorp, Matthew Grayling, Kaisey S. Mandel</dc:creator>
    </item>
    <item>
      <title>Generative models of astrophysical fields with scattering transforms on the sphere</title>
      <link>https://arxiv.org/abs/2407.07007</link>
      <description>arXiv:2407.07007v2 Announce Type: replace 
Abstract: Scattering transforms are a new type of summary statistics recently developed for the study of highly non-Gaussian processes, which have been shown to be very promising for astrophysical studies. In particular, they allow one to build generative models of complex non-linear fields from a limited amount of data, and have also been used as the basis of new statistical component separation algorithms. In the context of upcoming cosmological surveys, such as LiteBIRD for the cosmic microwave background polarization or Rubin-LSST and Euclid for study of the large scale structures of the Universe, the extension of these tools to spherical data is necessary. We develop scattering transforms on the sphere and focus on the construction of maximum-entropy generative models of several astrophysical fields. We construct, from a single target field, generative models of homogeneous astrophysical and cosmological fields, whose samples are quantitatively compared to the target fields using common statistics (power spectrum, pixel probability density function and Minkowski functionals). Our sampled fields agree well with the target fields, both statistically and visually. These generative models therefore open up a wide range of new applications for future astrophysical and cosmological studies; particularly those for which very little simulated data is available. We make our code available to the community so that this work can be easily reproduced and developed further.</description>
      <guid isPermaLink="false">oai:arXiv.org:2407.07007v2</guid>
      <category>astro-ph.IM</category>
      <pubDate>Tue, 29 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Louise Mousset, Erwan Allys, Matthew A. Price, Jonathan Aumont, Jean-Marc Delouis, Ludovic Montier, Jason D. McEwen</dc:creator>
    </item>
    <item>
      <title>CNNCat: Categorizing high-energy photons in a Compton/Pair Telescope with Convolutional Neural Networks</title>
      <link>https://arxiv.org/abs/2407.10358</link>
      <description>arXiv:2407.10358v2 Announce Type: replace 
Abstract: A Compton/Pair telescope, designed to provide spectral resolved images of cosmic photons from sub-MeV to GeV energies, records a wealth of data in a combination of tracking detector and calorimeter. Onboard event classification can be required to decide on which data to downlink with priority, given limited data-transfer bandwidth. Event classification is also the first and one of the most crucial steps in reconstructing data. Its outcome determines the further handling of the event, i.e., the type of reconstruction (Compton, pair) or, possibly, the decision to discard it. Errors at this stage result in misreconstruction and loss of source information. We present a classification algorithm driven by a Convolutional Neural Network. It provides classification of the type of electromagnetic interaction, based solely on low-level detector data. We introduce the task, describe the architecture and the dataset used, and present the performance of this method in the context of the proposed (e-)ASTROGAM and similar telescopes.</description>
      <guid isPermaLink="false">oai:arXiv.org:2407.10358v2</guid>
      <category>astro-ph.IM</category>
      <pubDate>Tue, 29 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Jan Peter Lommler, Uwe Oberlack</dc:creator>
    </item>
    <item>
      <title>Generative AI for Overall Mission Effectiveness at the Habitable Worlds Observatory</title>
      <link>https://arxiv.org/abs/2410.16609</link>
      <description>arXiv:2410.16609v2 Announce Type: replace 
Abstract: Here we present several use cases for using Generative AI (Gen AI) to improve systems engineering and cognitive knowledge management related to the future of astronomy from a culmination of working meetings and presentations as part of the Gen AI Task Group for the NASA Habitable Worlds Observatory (HWO) Science and Technology Architecture Review Team (START) AI/ML Working Group. Collectively, our group mission statement is "Where is the Human-in-the-loop as Gen AI systems become more powerful and autonomous?" with an emphasis on the ethical applications of Gen AI, guided by using these systems to remove drudgery from human work while simultaneously increasing opportunities for humans to experience more collective creativity and innovation. The HWO mission stands to benefit dramatically from generative models for different data types including text, time series/spectra, and image data. These cover a wide range of applications in science and engineering for HWO, including: mission development acceleration, data analysis and interpretation, enhancing imaging capabilities, anomaly detection, predictive modeling and simulation, data augmentation for machine learning, instrument calibration and optimization, public engagement and education, and assisting in mission planning. As an example, through sensitivity analysis of simulated exoplanet population science data sets of various generative model complexity, we can reverse engineer the measurement uncertainty requirements for HWO instruments to produce data that can constrain population models and thus inform HWO design requirements. This approach to HWO design is one example of a strategy that can ensure that HWO remains AI-ready. Through presenting herein a combination of visionary ideas balanced with grounded validated use case examples, we aim to support the development of a long-term strategy to keep HWO AI-ready as it moves forward.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.16609v2</guid>
      <category>astro-ph.IM</category>
      <pubDate>Tue, 29 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Megan Shabram, Ryan McClelland, John Wu, Hamsa Shwetha Venkataram, Heidi Segars, Bruce Dean, Christine Ye, Aquib Moin, Megan Ansdell, Mark Moussa, Umaa Rebbapragada, Hamed Valizadegan, Dominick Perini, Glenn Ko, Victoria Da Poian, Sam Gharib-Nezhad, Giuseppe Cataldo</dc:creator>
    </item>
    <item>
      <title>General relativistic self-gravitating equilibrium disks around rotating neutron stars</title>
      <link>https://arxiv.org/abs/2406.00945</link>
      <description>arXiv:2406.00945v2 Announce Type: replace-cross 
Abstract: In modeling a relativistic disk around a compact object, the self-gravity of the disk is often neglected while it needs to be incorporated for more accurate descriptions in several circumstances. Extending the Komatsu-Eriguchi-Hachisu self-consistent field method, we present numerical models of a rapidly rotating neutron star with a self-gravitating disk in stationary equilibrium. In particular, our approach allows us to obtain numerical solutions involving a massive disk with the rest mass $O(10^{-1})-O(10^0) M_\odot$ closely attached to a rotating neutron star. We also assess the impact of self-gravity on the internal structure of the disk and the neutron star. These axisymmetric, stationary solutions can be employed for simulations involving the neutron star-disk system in the context of high-energy transients and gravitational wave emissions.</description>
      <guid isPermaLink="false">oai:arXiv.org:2406.00945v2</guid>
      <category>astro-ph.HE</category>
      <category>astro-ph.IM</category>
      <category>gr-qc</category>
      <pubDate>Tue, 29 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <arxiv:DOI>10.1093/mnras/stae2287</arxiv:DOI>
      <arxiv:journal_reference>Monthly Notices of the Royal Astronomical Society, Volume 534, Issue 4, November 2024, Pages 3958-3973</arxiv:journal_reference>
      <dc:creator>Yoonsoo Kim, Jinho Kim, Hee Il Kim, Hyung Mok Lee</dc:creator>
    </item>
    <item>
      <title>Superconducting resonator parametric amplifiers with intrinsic separation of pump and signal tones</title>
      <link>https://arxiv.org/abs/2406.02455</link>
      <description>arXiv:2406.02455v3 Announce Type: replace-cross 
Abstract: Superconducting resonator parametric amplifiers achieve ultra-low-noise amplification through the nonlinear kinetic inductance of thin-film superconductors. One of the main challenges to the operation of these devices is the separation of the strong pump tone from the signal tone after amplification has been achieved. In this paper, we propose and experimentally demonstrate a pump separation method based on operating a half-wave superconducting resonator amplifier behind a cryogenic circulator. Our pump separation scheme does not involve post-amplification interference, and thereby avoids the delicate phase matching of two different pump paths. We demonstrate the scheme using two-port half-wave resonator amplifiers based on superconducting NbN thin-films. We present measurements of gain profiles and degrees of pump separation for amplifiers having different coupling quality factors. On an amplifier having a coupling quality factor of $\sim2000$, we measured a peak signal gain of $15\,\mathrm{dB}$ whilst achieving pump separation of $12\,\mathrm{dB}$. The amplifier was stable for continuous measurements, and the gain drift was measured to be $0.15\,\mathrm{dB}$ over an hour. The same amplifier was operated at $3.2\,\mathrm{K}$ and achieved a peak signal gain of $11\,\mathrm{dB}$ whilst having a pump separation factor of $10.5\,\mathrm{dB}$. The pump separation scheme, and these promising results, will advance the development of superconducting resonator amplifiers as an important technology in quantum sensing.</description>
      <guid isPermaLink="false">oai:arXiv.org:2406.02455v3</guid>
      <category>physics.ins-det</category>
      <category>astro-ph.IM</category>
      <category>cond-mat.supr-con</category>
      <pubDate>Tue, 29 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <arxiv:DOI>10.1088/1361-6463/ad875e</arxiv:DOI>
      <arxiv:journal_reference>J. Phys. D: Appl. Phys. 58 (2025) 035305</arxiv:journal_reference>
      <dc:creator>Songyuan Zhao, Stafford Withington, Christopher Niall Thomas</dc:creator>
    </item>
    <item>
      <title>Exploring pulsar timing precision: A comparative study of polarization calibration methods for NANOGrav data from the Green Bank Telescope</title>
      <link>https://arxiv.org/abs/2406.13463</link>
      <description>arXiv:2406.13463v2 Announce Type: replace-cross 
Abstract: Pulsar timing array experiments have recently uncovered evidence for a nanohertz gravitational wave background by precisely timing an ensemble of millisecond pulsars. The next significant milestones for these experiments include characterizing the detected background with greater precision, identifying its source(s), and detecting continuous gravitational waves from individual supermassive black hole binaries. To achieve these objectives, generating accurate and precise times of arrival of pulses from pulsar observations is crucial. Incorrect polarization calibration of the observed pulsar profiles may introduce errors in the measured times of arrival. Further, previous studies (e.g., van Straten 2013; Manchester et al. 2013) have demonstrated that robust polarization calibration of pulsar profiles can reduce noise in the pulsar timing data and improve timing solutions. In this paper, we investigate and compare the impact of different polarization calibration methods on pulsar timing precision using three distinct calibration techniques: the Ideal Feed Assumption (IFA), Measurement Equation Modeling (MEM), and Measurement Equation Template Matching (METM). Three NANOGrav pulsars-PSRs J1643$-$1224, J1744$-$1134, and J1909$-$3744-observed with the 800 MHz and 1.5 GHz receivers at the Green Bank Telescope (GBT) are utilized for our analysis. Our findings reveal that all three calibration methods enhance timing precision compared to scenarios where no polarization calibration is performed. Additionally, among the three calibration methods, the IFA approach generally provides the best results for timing analysis of pulsars observed with the GBT receiver system. We attribute the comparatively poorer performance of the MEM and METM methods to potential instabilities in the reference noise diode coupled to the receiver and temporal variations in the profile of the reference pulsar, respectively.</description>
      <guid isPermaLink="false">oai:arXiv.org:2406.13463v2</guid>
      <category>astro-ph.HE</category>
      <category>astro-ph.IM</category>
      <pubDate>Tue, 29 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Lankeswar Dey, Maura A. McLaughlin, Haley M. Wahl, Paul B. Demorest, Zaven Arzoumanian, Harsha Blumer, Paul R. Brook, Sarah Burke-Spolaor, H. Thankful Cromartie, Megan E. DeCesar, Timothy Dolch, Justin A. Ellis, Robert D. Ferdman, Elizabeth C. Ferrara, William Fiore, Emmanuel Fonseca, Nate Garver-Daniels, Peter A. Gentile, Joseph Glaser, Deborah C. Good, Ross J. Jennings, Megan L. Jones, Michael T. Lam, Duncan R. Lorimer, Jing Luo, Ryan S. Lynch, Cherry Ng, David J. Nice, Timothy T. Pennucci, Nihan S. Pol, Scott M. Ransom, Ren\'ee Spiewak, Ingrid H. Stairs, Kevin Stovall, Joseph K. Swiggum</dc:creator>
    </item>
    <item>
      <title>Galaxy spectroscopy without spectra: Galaxy properties from photometric images with conditional diffusion models</title>
      <link>https://arxiv.org/abs/2406.18175</link>
      <description>arXiv:2406.18175v2 Announce Type: replace-cross 
Abstract: Modern spectroscopic surveys can only target a small fraction of the vast amount of photometrically cataloged sources in wide-field surveys. Here, we report the development of a generative AI method capable of predicting optical galaxy spectra from photometric broad-band images alone. This method draws from the latest advances in diffusion models in combination with contrastive networks. We pass multi-band galaxy images into the architecture to obtain optical spectra. From these, robust values for galaxy properties can be derived with any methods in the spectroscopic toolbox, such as standard population synthesis techniques and Lick indices. When trained and tested on 64x64-pixel images from the Sloan Digital Sky Survey, the global bimodality of star-forming and quiescent galaxies in photometric space is recovered, as well as a mass-metallicity relation of star-forming galaxies. The comparison between the observed and the artificially created spectra shows good agreement in overall metallicity, age, Dn4000, stellar velocity dispersion, and E(B-V) values. Photometric redshift estimates of our generative algorithm can compete with other current, specialized deep-learning techniques. Moreover, this work is the first attempt in the literature to infer velocity dispersion from photometric images. Additionally, we can predict the presence of an active galactic nucleus up to an accuracy of 82%. With our method, scientifically interesting galaxy properties, normally requiring spectroscopic inputs, can be obtained in future data sets from large-scale photometric surveys alone. The spectra prediction via AI can further assist in creating realistic mock catalogs.</description>
      <guid isPermaLink="false">oai:arXiv.org:2406.18175v2</guid>
      <category>astro-ph.GA</category>
      <category>astro-ph.IM</category>
      <category>cs.AI</category>
      <pubDate>Tue, 29 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Lars Doorenbos, Eva Sextl, Kevin Heng, Stefano Cavuoti, Massimo Brescia, Olena Torbaniuk, Giuseppe Longo, Raphael Sznitman, Pablo M\'arquez-Neila</dc:creator>
    </item>
    <item>
      <title>A generative adversarial network for stellar core-collapse gravitational-waves</title>
      <link>https://arxiv.org/abs/2408.02895</link>
      <description>arXiv:2408.02895v2 Announce Type: replace-cross 
Abstract: We present a rapid stellar core-collapse waveform emulator built using a deep convolutional generative adversarial network (DCGAN). The DCGAN was trained on the Richers \textit{et al.~}\cite{richers:2017} waveform catalogue to learn the structure of rotating stellar core-collapse gravitational-wave signals and generate realistic waveforms. We show that the DCGAN learns the distribution of the training data reasonably well, and that the waveform emulator produces signals that appear to have the key features of core-collapse, bounce, early post-bounce, and ringdown oscillations of the early proto-neutron star. The pre-trained DCGAN can therefore be used as a phenomenological model for rotating stellar core-collapse gravitational-waves.</description>
      <guid isPermaLink="false">oai:arXiv.org:2408.02895v2</guid>
      <category>gr-qc</category>
      <category>astro-ph.IM</category>
      <pubDate>Tue, 29 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Tarin Eccleston, Matthew C. Edwards</dc:creator>
    </item>
  </channel>
</rss>
