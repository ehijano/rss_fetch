<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>cs.CY updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/cs.CY</link>
    <description>cs.CY updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/cs.CY" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Tue, 05 Aug 2025 04:03:45 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Tue, 05 Aug 2025 00:00:00 -0400</pubDate>
    <skipDays>
      <day>Saturday</day>
      <day>Sunday</day>
    </skipDays>
    <item>
      <title>A Modular, Low-Cost IoT System for Environmental and Behavioural Monitoring in Cultural Heritage Sites</title>
      <link>https://arxiv.org/abs/2508.00849</link>
      <description>arXiv:2508.00849v1 Announce Type: new 
Abstract: The preservation of cultural heritage faces growing challenges from climate change, tourism pressure, and limited conservation resources. Existing monitoring solutions are often cost-prohibitive, proprietary, and inflexible, leaving many institutions, particularly in developing regions, without viable tools for proactive management. This study presents a modular, low-cost Internet of Things (IoT) system designed for real-time environmental and behavioural monitoring in heritage sites. Built with off-the-shelf components such as ESP32 microcontrollers and Raspberry Pi, the system integrates a wireless sensor network, edge computing, and cloud services (Microsoft Azure) to measure variables including temperature, humidity, sound, and visitor proximity. It also incorporates computer vision models to classify visitor behaviour, achieving up to 95% accuracy using fine-tuned Vision Transformers. The system's modularity, enabled via JSON configurations, allows for rapid reconfiguration without firmware changes. A simulated deployment demonstrated robust performance, low power consumption, and cost-efficiency (less than 200 GBP per node), validating the system's potential for scalable, sustainable heritage monitoring. This open-source framework offers a practical path forward for institutions seeking to balance accessibility with conservation needs.</description>
      <guid isPermaLink="false">oai:arXiv.org:2508.00849v1</guid>
      <category>cs.CY</category>
      <pubDate>Tue, 05 Aug 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Juan Palomeque-Gonzalez</dc:creator>
    </item>
    <item>
      <title>UrbanScore: A Real-Time Personalised Liveability Analytics Platform</title>
      <link>https://arxiv.org/abs/2508.00857</link>
      <description>arXiv:2508.00857v1 Announce Type: new 
Abstract: This paper introduces UrbanScore - a real-time web platform that computes a personalised liveability score for any urban address. The system fuses five data streams: (i) address geocoding via Nominatim, (ii) facility extraction from OpenStreetMap through Overpass QL, (iii) segment-level traffic metrics from TomTom Flow v10, (iv) hourly air-quality readings from OpenWeatherMap, and (v) user-declared preference profiles, all persisted in an Oracle 19c relational store. Six sub-scores (air, traffic, lifestyle, education, metro access, surface transport) are derived, adaptively weighted and combined; an OpenAI large-language model then converts the numeric results into concise, user-friendly explanations. A pilot deployment covering the 226 km2 metropolitan area of Bucharest evaluated 3,450 unique addresses over four weeks. Median end-to-end latency was 2.1 s (p95 = 2.9s), meeting the &lt;3 non-functional requirement. Aggregate scores ranged from 34 to 92 (mean 68, SD 11), with high-scoring clusters along metro corridors that pair abundant green space with PM2.5 levels below 35 ug m-3. A detailed case study of the Tineretului district produced an overall score of 91/100 and demonstrated how the narrative layer guides users toward comparable neighbourhoods. Limitations include dependence on third-party API uptime, spatial bias toward well-mapped OSM regions and the absence of noise and crime layers, cited by 18% of survey participants as a desired enhancement. Overall, the results show that open geodata, commercial mobility feeds and conversational AI can be integrated into a performant, explainable decision-support tool that places "liveability analytics" in the hands of every house-hunter, commuter and city planner.</description>
      <guid isPermaLink="false">oai:arXiv.org:2508.00857v1</guid>
      <category>cs.CY</category>
      <pubDate>Tue, 05 Aug 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <dc:creator>Vrinceanu Alin Vladut</dc:creator>
    </item>
    <item>
      <title>Toward Responsible And Beneficial Ai: Comparing Regulatory And Guidance-Based Approaches</title>
      <link>https://arxiv.org/abs/2508.00868</link>
      <description>arXiv:2508.00868v1 Announce Type: new 
Abstract: This dissertation presents a comprehensive comparative analysis of artificial intelligence governance frameworks across the European Union, United States, China, and IEEE technical standards, examining how different jurisdictions and organizations approach the challenge of promoting responsible and beneficial AI development. Using a qualitative research design based on systematic content analysis, the study identifies distinctive patterns in regulatory philosophy, implementation mechanisms, and global engagement strategies across these major AI governance ecosystems.</description>
      <guid isPermaLink="false">oai:arXiv.org:2508.00868v1</guid>
      <category>cs.CY</category>
      <pubDate>Tue, 05 Aug 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Jian Du</dc:creator>
    </item>
    <item>
      <title>FairFedMed: Benchmarking Group Fairness in Federated Medical Imaging with FairLoRA</title>
      <link>https://arxiv.org/abs/2508.00873</link>
      <description>arXiv:2508.00873v1 Announce Type: new 
Abstract: Fairness remains a critical concern in healthcare, where unequal access to services and treatment outcomes can adversely affect patient health. While Federated Learning (FL) presents a collaborative and privacy-preserving approach to model training, ensuring fairness is challenging due to heterogeneous data across institutions, and current research primarily addresses non-medical applications. To fill this gap, we establish the first experimental benchmark for fairness in medical FL, evaluating six representative FL methods across diverse demographic attributes and imaging modalities. We introduce FairFedMed, the first medical FL dataset specifically designed to study group fairness (i.e., demographics). It comprises two parts: FairFedMed-Oph, featuring 2D fundus and 3D OCT ophthalmology samples with six demographic attributes; and FairFedMed-Chest, which simulates real cross-institutional FL using subsets of CheXpert and MIMIC-CXR. Together, they support both simulated and real-world FL across diverse medical modalities and demographic groups. Existing FL models often underperform on medical images and overlook fairness across demographic groups. To address this, we propose FairLoRA, a fairness-aware FL framework based on SVD-based low-rank approximation. It customizes singular value matrices per demographic group while sharing singular vectors, ensuring both fairness and efficiency. Experimental results on the FairFedMed dataset demonstrate that FairLoRA not only achieves state-of-the-art performance in medical image classification but also significantly improves fairness across diverse populations. Our code and dataset can be accessible via link: https://wang.hms.harvard.edu/fairfedmed/.</description>
      <guid isPermaLink="false">oai:arXiv.org:2508.00873v1</guid>
      <category>cs.CY</category>
      <category>cs.CV</category>
      <category>cs.LG</category>
      <pubDate>Tue, 05 Aug 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Minghan Li, Congcong Wen, Yu Tian, Min Shi, Yan Luo, Hao Huang, Yi Fang, Mengyu Wang</dc:creator>
    </item>
    <item>
      <title>Preliminary suggestions for rigorous GPAI model evaluations</title>
      <link>https://arxiv.org/abs/2508.00875</link>
      <description>arXiv:2508.00875v1 Announce Type: new 
Abstract: This document presents a preliminary compilation of general-purpose AI (GPAI) evaluation practices that may promote internal validity, external validity and reproducibility. It includes suggestions for human uplift studies and benchmark evaluations, as well as cross-cutting suggestions that may apply to many different evaluation types. Suggestions are organised across four stages in the evaluation life cycle: design, implementation, execution and documentation. Drawing from established practices in machine learning, statistics, psychology, economics, biology and other fields recognised to have important lessons for AI evaluation, these suggestions seek to contribute to the conversation on the nascent and evolving field of the science of GPAI evaluations. The intended audience of this document includes providers of GPAI models presenting systemic risk (GPAISR), for whom the EU AI Act lays out specific evaluation requirements; third-party evaluators; policymakers assessing the rigour of evaluations; and academic researchers developing or conducting GPAI evaluations.</description>
      <guid isPermaLink="false">oai:arXiv.org:2508.00875v1</guid>
      <category>cs.CY</category>
      <pubDate>Tue, 05 Aug 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <arxiv:DOI>10.7249/PEA3971-1</arxiv:DOI>
      <dc:creator>Patricia Paskov, Michael J. Byun, Kevin Wei, Toby Webster</dc:creator>
    </item>
    <item>
      <title>A Relational (Re)Turn: Revisit Interactive Art through Interaction and Aesthetics</title>
      <link>https://arxiv.org/abs/2508.00878</link>
      <description>arXiv:2508.00878v1 Announce Type: new 
Abstract: This paper revisits the concept of interaction in interactive art, tracing its evolution from sociocultural origins to its narrowing within human-computer paradigms. It critiques this reduction and proposes a relational (re)turn through reclaiming interaction as intersubjective and relational. Through a synthesis of aesthetic theories and case studies from Ars Electronica, the paper introduces Techno Relational Aesthetics, a new conceptual lens that emphasizes technologically mediated relationality. This approach expands interactive art beyond audience-artwork interaction and opens the possibility to broader relational practices.</description>
      <guid isPermaLink="false">oai:arXiv.org:2508.00878v1</guid>
      <category>cs.CY</category>
      <pubDate>Tue, 05 Aug 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Aven-Le Zhou</dc:creator>
    </item>
    <item>
      <title>Small Towns, Big Questions: Methodological Insights into Use Case Selection for Digital Twins in Small Towns</title>
      <link>https://arxiv.org/abs/2508.00883</link>
      <description>arXiv:2508.00883v1 Announce Type: new 
Abstract: Selecting appropriate use cases for implementing digital solutions in small towns is a recurring challenge for smart city projects. This paper presents a transdisciplinary methodology for systematically identifying and evaluating such use cases, drawing from diverse academic disciplines and practical expertise. The proposed methodology was developed and implemented in Lower Austria, with a particular focus on the small towns that are characteristic of a region lacking major urban centres. Through semi-structured interviews and collaborative workshops (e.g. a needs requirements workshop) with various relevant stakeholders, fifteen possible use cases were first identified. Then these use cases were categorised and assessed based on criteria such as feasibility, usefulness, the need for biological or human modelling, and overall complexity. Based on these characteristics, three use cases were selected for further development. These will be the basis of digital twin solutions for supporting decision-making and public outreach regarding policy decisions in those fields. Our proposed methodology emphasises stakeholder engagement to ensure robust data collection and alignment with practical requirements and the involved towns' current needs. We thus provide a replicable framework for researchers and practitioners aiming to implement digital twin tools in future smart city initiatives in non-urban and rural contexts.</description>
      <guid isPermaLink="false">oai:arXiv.org:2508.00883v1</guid>
      <category>cs.CY</category>
      <pubDate>Tue, 05 Aug 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <arxiv:DOI>10.1109/ICEDEG65568.2025.11081584</arxiv:DOI>
      <arxiv:journal_reference>Proceedings of the 2025 Eleventh International Conference on eDemocracy and eGovernment (ICEDEG 2025), 2025, 169-178</arxiv:journal_reference>
      <dc:creator>Lucy Temple, Gabriela Viale Pereira, Laura Kaltenbrunner, Lukas Daniel Klausner</dc:creator>
    </item>
    <item>
      <title>Exploring the Role of Gamification in Enhancing Academic Library Services: A Survey of Library Leaders in India</title>
      <link>https://arxiv.org/abs/2508.00906</link>
      <description>arXiv:2508.00906v1 Announce Type: new 
Abstract: This study explores the role of gamification in enhancing academic library services in India by surveying library leaders across various institutions. Using game-like elements in non-game contexts, gamification can boost user engagement and improve services such as information literacy and research consultations. Findings reveal moderate awareness and generally positive perceptions of gamification's effectiveness. However, challenges like insufficient staff expertise, infrastructure, and limited funding hinder implementation. The study emphasises the need for additional resources, including staff training and technological upgrades, to unlock the full potential of gamification in academic libraries.</description>
      <guid isPermaLink="false">oai:arXiv.org:2508.00906v1</guid>
      <category>cs.CY</category>
      <category>cs.DL</category>
      <category>cs.ET</category>
      <pubDate>Tue, 05 Aug 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Subaveerapandiyan A, Pragya Lohia, Dattatraya Kalbande, Naved Ahmad, Kailash Chand Sharma</dc:creator>
    </item>
    <item>
      <title>Mapping Stakeholder Needs to Multi-Sided Fairness in Candidate Recommendation for Algorithmic Hiring</title>
      <link>https://arxiv.org/abs/2508.00908</link>
      <description>arXiv:2508.00908v1 Announce Type: new 
Abstract: Already before the enactment of the EU AI Act, candidate or job recommendation for algorithmic hiring -- semi-automatically matching CVs to job postings -- was used as an example of a high-risk application where unfair treatment could result in serious harms to job seekers. Recommending candidates to jobs or jobs to candidates, however, is also a fitting example of a multi-stakeholder recommendation problem. In such multi-stakeholder systems, the end user is not the only party whose interests should be considered when generating recommendations. In addition to job seekers, other stakeholders -- such as recruiters, organizations behind the job postings, and the recruitment agency itself -- are also stakeholders in this and deserve to have their perspectives included in the design of relevant fairness metrics. Nevertheless, past analyses of fairness in algorithmic hiring have been restricted to single-side fairness, ignoring the perspectives of the other stakeholders. In this paper, we address this gap and present a multi-stakeholder approach to fairness in a candidate recommender system that recommends relevant candidate CVs to human recruiters in a human-in-the-loop algorithmic hiring scenario. We conducted semi-structured interviews with 40 different stakeholders (job seekers, companies, recruiters, and other job portal employees). We used these interviews to explore their lived experiences of unfairness in hiring, co-design definitions of fairness as well as metrics that might capture these experiences. Finally, we attempt to reconcile and map these different (and sometimes conflicting) perspectives and definitions to existing (categories of) fairness metrics that are relevant for our candidate recommendation scenario.</description>
      <guid isPermaLink="false">oai:arXiv.org:2508.00908v1</guid>
      <category>cs.CY</category>
      <pubDate>Tue, 05 Aug 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <arxiv:DOI>10.1145/3705328.3748079</arxiv:DOI>
      <dc:creator>Mesut Kaya, Toine Bogers</dc:creator>
    </item>
    <item>
      <title>Mitigating the Carbon Footprint of Chatbots as Consumers</title>
      <link>https://arxiv.org/abs/2508.00911</link>
      <description>arXiv:2508.00911v1 Announce Type: new 
Abstract: In the context of the high energy demand of large language models (LLMs) and growing concerns about global warming, there is significant demand for actionable recommendations that can help reduce emissions when utilizing such technologies. This paper examines the environmental impact linked to a fundamental function of LLM-based conversational systems that might be less well known to end users: the conversational memory, which enables the system to maintain context throughout the dialog. After analyzing conversation patterns using anonymized token data from a real world system, a recommendation for individuals on how they could use chatbots in a more sustainable way is derived. Based on a simulation, the savings potential resulting from the adoption of such an ecological gesture is estimated.</description>
      <guid isPermaLink="false">oai:arXiv.org:2508.00911v1</guid>
      <category>cs.CY</category>
      <pubDate>Tue, 05 Aug 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <arxiv:DOI>10.1007/978-981-96-1452-3_2</arxiv:DOI>
      <dc:creator>Boris Ruf, Marcin Detyniecki</dc:creator>
    </item>
    <item>
      <title>Translating Machine Learning Interpretability into Clinical Insights for ICU Mortality Prediction</title>
      <link>https://arxiv.org/abs/2508.00919</link>
      <description>arXiv:2508.00919v1 Announce Type: new 
Abstract: Current research efforts largely focus on employing at most one interpretable method to elucidate machine learning (ML) model performance. However, significant barriers remain in translating these interpretability techniques into actionable insights for clinicians, notably due to complexities such as variability across clinical settings and the Rashomon effect. In this study, we developed and rigorously evaluated two ML models along with interpretation mechanisms, utilizing data from 131,051 ICU admissions across 208 hospitals in the United States, sourced from the eICU Collaborative Research Database. We examined two datasets: one with imputed missing values (130,810 patients, 5.58% ICU mortality) and another excluding patients with missing data (5,661 patients, 23.65% ICU mortality). The random forest (RF) model demonstrated an AUROC of 0.912 with the first dataset and 0.839 with the second dataset, while the XGBoost model achieved an AUROC of 0.924 with the first dataset and 0.834 with the second dataset. Consistently identified predictors of ICU mortality across datasets, cross-validation folds, models, and explanation mechanisms included lactate levels, arterial pH, body temperature, and others. By aligning with routinely collected clinical variables, this study aims to enhance ML model interpretability for clinical use, promote greater understanding and adoption among clinicians, and ultimately contribute to improved patient outcomes.</description>
      <guid isPermaLink="false">oai:arXiv.org:2508.00919v1</guid>
      <category>cs.CY</category>
      <pubDate>Tue, 05 Aug 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Ling Liao, Eva Aagaard</dc:creator>
    </item>
    <item>
      <title>Themed Challenges to Solve Data Scarcity in Africa: A Proposition for Increasing Local Data Collection and Integration</title>
      <link>https://arxiv.org/abs/2508.00925</link>
      <description>arXiv:2508.00925v1 Announce Type: new 
Abstract: In Africa, the scarcity of computational resources and medical datasets remains a major hurdle to the development and deployment of artificial intelligence (AI) tools in clinical settings, further contributing to global bias. These limitations hinder the full realization of AI's potential and present serious challenges to advancing healthcare across the region.
  This paper proposes a framework aimed at addressing data scarcity in African healthcare. The framework presents a comprehensive strategy to encourage healthcare providers across the continent to create, curate, and share locally sourced medical imaging datasets. By organizing themed challenges that promote participation, accurate and relevant datasets can be generated within the African healthcare community. This approach seeks to overcome existing dataset limitations, paving the way for a more inclusive and impactful AI ecosystem that is specifically tailored to Africa's healthcare needs.</description>
      <guid isPermaLink="false">oai:arXiv.org:2508.00925v1</guid>
      <category>cs.CY</category>
      <pubDate>Tue, 05 Aug 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Mubaraq Yakubu, Udunna Anazodo, Maruf Adewole, Theodore Barfoot, Tiarna Lee, Tom Vercauteren, Jonathan Shapey, Andrew King, Alexander Hammers</dc:creator>
    </item>
    <item>
      <title>How Sovereign Is Sovereign Compute? A Review of 775 Non-U.S. Data Centers</title>
      <link>https://arxiv.org/abs/2508.00932</link>
      <description>arXiv:2508.00932v1 Announce Type: new 
Abstract: Previous literature has proposed that the companies operating data centers enforce government regulations on AI companies. Using a new dataset of 775 non-U.S. data center projects, this paper estimates how often data centers could be subject to foreign legal authorities due to the nationality of the data center operators. We find that U.S. companies operate 48% of all non-U.S. data center projects in our dataset when weighted by investment value - a proxy for compute capacity. This is an approximation based on public data and should be interpreted as an initial estimate. For the United States, our findings suggest that data center operators offer a lever for internationally governing AI that complements traditional export controls, since operators can be used to regulate computing resources already deployed in non-U.S. data centers. For other countries, our results show that building data centers locally does not guarantee digital sovereignty if those facilities are run by foreign entities.
  To support future research, we release our dataset, which documents over 20 variables relating to each data center, including the year it was announced, the investment value, and its operator's national affiliation. The dataset also includes over 1,000 quotes describing these data centers' strategic motivations, operational challenges, and engagement with U.S. and Chinese entities.</description>
      <guid isPermaLink="false">oai:arXiv.org:2508.00932v1</guid>
      <category>cs.CY</category>
      <pubDate>Tue, 05 Aug 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Aris Richardson, Haley Yi, Michelle Nie, Simon Wisdom, Casey Price, Ruben Weijers, Steven Veld, Mauricio Baker</dc:creator>
    </item>
    <item>
      <title>Stakeholder Perspectives on Digital Twin Implementation Challenges in Healthcare: Insights from a Provider Digital Twin Case Study</title>
      <link>https://arxiv.org/abs/2508.00936</link>
      <description>arXiv:2508.00936v1 Announce Type: new 
Abstract: Digital twin (DT) technology holds immense potential for transforming healthcare systems through real-time monitoring, predictive analysis, and agile interventions to support various decision-making needs. However, its successful implementation depends on addressing a range of complex sociotechnical challenges. Using a case study of provider workload DT, this research investigates DT implementation challenges in healthcare by capturing the perspectives of four distinct stakeholders: family medicine specialists (FMS), organizational psychologists (OP), engineers (EE), and implementation scientists (IS). We conducted semi-structured interviews guided by the updated Consolidated Framework for Implementation Research (CFIR 2.0), a widely used implementation science framework for understanding factors that influence implementation outcomes. We then mapped each stakeholder group's preferences and concerns, revealing a nuanced landscape of converging and diverging perspectives that highlight both shared and group-specific implementation barriers. Through thematic coding, the 66 identified challenges were categorized into seven domains: data-related, financial and economic, operational, organizational, personnel, regulatory and ethical, and technological. Our findings reveal shared concerns such as data privacy and security, interoperability, and regulatory compliance. However, divergences also emerged, reflecting each group's functional focus. These findings emphasize the need for a multidisciplinary, stakeholder-sensitive approach that addresses both functional and practical concerns, highlighting the importance of tailored implementation strategies to support successful DT adoption in healthcare.</description>
      <guid isPermaLink="false">oai:arXiv.org:2508.00936v1</guid>
      <category>cs.CY</category>
      <pubDate>Tue, 05 Aug 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Md Doulotuzzaman Xames, Taylan G. Topcu</dc:creator>
    </item>
    <item>
      <title>Practical Retrofitting for Obsolete Devices -- Bridging the gap with old tech to create alternative interaction paradigms and workflows</title>
      <link>https://arxiv.org/abs/2508.00942</link>
      <description>arXiv:2508.00942v1 Announce Type: new 
Abstract: Over the last twenty years, smartphones gradually replaced many earlier digital tools such as PDAs, cameras and music players. Today these objects are regarded as obsolete: they may hold some esthetic or nostalgic appeal but they do not fit in a modern, zero-friction, cloud-first workflow. Yet these devices still have desirable qualities that smartphones lack: a singular focus on a specific use case; hardware buttons and physical connectors; multi-day battery life. Even their lack of connectivity can be seen as an asset from a resilience, privacy and security standpoint. Actually using decades-old tech today is challenging, in spite of its apparent simplicity, because the friction of physical media-based workflows now feels unacceptable. But much like classic cars can be fitted with an EV motor, it is possible to retrofit older devices in order to make them usable again in a connected world. Long after the manufacturer stops supporting a device, user communities play a crucial role in reverse-engineering file formats and communication protocols, maintaining documentation and software archives, as well as designing and producing spare parts that can even overcome initial design flaws. This paper will explore both software and hardware retrofitting techniques, using various examples: cameras, music players, dedicated writing instruments, video games. The resulting retrofitted devices are neither vintage nor modern, creating their own hybrid interaction paradigm around monotasking on dedicated hardware with intermittent connectivity. The various examples discussed outline some common factors that increase the likelihood that a successful retrofitting path can be found for a device. These factors can also be understood as proven design principles to create resilient hardware.</description>
      <guid isPermaLink="false">oai:arXiv.org:2508.00942v1</guid>
      <category>cs.CY</category>
      <pubDate>Tue, 05 Aug 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Martin Lafr\'echoux</dc:creator>
    </item>
    <item>
      <title>Academic Vibe Coding: Opportunities for Accelerating Research in an Era of Resource Constraint</title>
      <link>https://arxiv.org/abs/2508.00952</link>
      <description>arXiv:2508.00952v1 Announce Type: new 
Abstract: Academic laboratories face mounting resource constraints: budgets are tightening, grant overheads are potentially being capped, and the market rate for data-science talent significantly outstrips university compensation. Vibe coding, which is structured, prompt-driven code generation with large language models (LLMs) embedded in reproducible workflows, offers one pragmatic response. It aims to compress the idea-to-analysis timeline, reduce staffing pressure on specialized data roles, and maintain rigorous, version-controlled outputs. This article defines the vibe coding concept, situates it against the current academic resourcing crisis, details a beginner-friendly toolchain for its implementation, and analyzes inherent limitations that necessitate governance and mindful application.</description>
      <guid isPermaLink="false">oai:arXiv.org:2508.00952v1</guid>
      <category>cs.CY</category>
      <category>cs.AI</category>
      <category>cs.PL</category>
      <category>cs.SE</category>
      <pubDate>Tue, 05 Aug 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Matthew G Crowson, Leo Celi A. Celi</dc:creator>
    </item>
    <item>
      <title>Value of the Teaching Career and Factors in Its Path in Peru</title>
      <link>https://arxiv.org/abs/2508.00966</link>
      <description>arXiv:2508.00966v1 Announce Type: new 
Abstract: The teaching career shares common global characteristics, such as internal promotion, performance evaluation, recruitment of top candidates, continuous training, specialization, and peer learning. This study aims to describe the factors associated with the value placed on the teaching career in Peru. A total of 28217 public school teachers were analyzed using data from the 2020 National Teacher Survey. A variable measuring the "value of the teaching career" was constructed using eight indicators and categorized as low, medium, or high. Another variable, vision of the future, was classified as pessimistic, conformist, or optimistic. This observational, cross-sectional, and analytical study included variables related to in-service training, working conditions, professional recognition, and sociodemographic characteristics. Among the teachers surveyed, 45.8 % expressed an optimistic outlook on the future of the profession, 48 % held a conformist view, and only 6.2 % reported a pessimistic perspective. A generalized linear model revealed that the value placed on the teaching career was significantly associated with male gender (p = 0.002), a professional career (p &lt; 0.001), an optimistic outlook (p = 0.033), and working at the primary level (p &lt; 0.001). It was concluded that Peruvian teachers predominantly hold conformist or optimistic views of their profession. This highlights the need to reinforce merit-based advancement, competency-based training, intrinsic motivation, and ongoing professional development</description>
      <guid isPermaLink="false">oai:arXiv.org:2508.00966v1</guid>
      <category>cs.CY</category>
      <pubDate>Tue, 05 Aug 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Michelle Lozada-Urbano, Delsi Mariela Huaita Acha, Rosa Maria Benavente Ayquipa, Freddy Felipe Luza Castillo, Rosse Mary Falc\'on-Antenucci</dc:creator>
    </item>
    <item>
      <title>AI-Educational Development Loop (AI-EDL): A Conceptual Framework to Bridge AI Capabilities with Classical Educational Theories</title>
      <link>https://arxiv.org/abs/2508.00970</link>
      <description>arXiv:2508.00970v1 Announce Type: new 
Abstract: This study introduces the AI-Educational Development Loop (AI-EDL), a theory-driven framework that integrates classical learning theories with human-in-the-loop artificial intelligence (AI) to support reflective, iterative learning. Implemented in EduAlly, an AI-assisted platform for writing-intensive and feedback-sensitive tasks, the framework emphasizes transparency, self-regulated learning, and pedagogical oversight. A mixed-methods study was piloted at a comprehensive public university to evaluate alignment between AI-generated feedback, instructor evaluations, and student self-assessments; the impact of iterative revision on performance; and student perceptions of AI feedback. Quantitative results demonstrated statistically significant improvement between first and second attempts, with agreement between student self-evaluations and final instructor grades. Qualitative findings indicated students valued immediacy, specificity, and opportunities for growth that AI feedback provided. These findings validate the potential to enhance student learning outcomes through developmentally grounded, ethically aligned, and scalable AI feedback systems. The study concludes with implications for future interdisciplinary applications and refinement of AI-supported educational technologies.</description>
      <guid isPermaLink="false">oai:arXiv.org:2508.00970v1</guid>
      <category>cs.CY</category>
      <category>cs.AI</category>
      <pubDate>Tue, 05 Aug 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Ning Yu, Jie Zhang, Sandeep Mitra, Rebecca Smith, Adam Rich</dc:creator>
    </item>
    <item>
      <title>Generative AI as a Geopolitical Factor in Industry 5.0: Sovereignty, Access, and Control</title>
      <link>https://arxiv.org/abs/2508.00973</link>
      <description>arXiv:2508.00973v1 Announce Type: new 
Abstract: Industry 5.0 marks a new phase in industrial evolution, emphasizing human-centricity, sustainability, and resilience through the integration of advanced technologies. Within this evolving landscape, Generative AI (GenAI) and autonomous systems are not only transforming industrial processes but also emerging as pivotal geopolitical instruments. We examine strategic implications of GenAI in Industry 5.0, arguing that these technologies have become national assets central to sovereignty, access, and global influence. As countries compete for AI supremacy, growing disparities in talent, computational infrastructure, and data access are reshaping global power hierarchies and accelerating the fragmentation of the digital economy. The human-centric ethos of Industry 5.0, anchored in collaboration between humans and intelligent systems, increasingly conflicts with the autonomy and opacity of GenAI, raising urgent governance challenges related to meaningful human control, dual-use risks, and accountability. We analyze how these dynamics influence defense strategies, industrial competitiveness, and supply chain resilience, including the geopolitical weaponization of export controls and the rise of data sovereignty. Our contribution synthesizes technological, economic, and ethical perspectives to propose a comprehensive framework for navigating the intersection of GenAI and geopolitics. We call for governance models that balance national autonomy with international coordination while safeguarding human-centric values in an increasingly AI-driven world.</description>
      <guid isPermaLink="false">oai:arXiv.org:2508.00973v1</guid>
      <category>cs.CY</category>
      <category>cs.AI</category>
      <pubDate>Tue, 05 Aug 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Azmine Toushik Wasi, Enjamamul Haque Eram, Sabrina Afroz Mitu, Md Manjurul Ahsan</dc:creator>
    </item>
    <item>
      <title>Generative AI Adoption in Postsecondary Education, AI Hype, and ChatGPT's Launch</title>
      <link>https://arxiv.org/abs/2508.01003</link>
      <description>arXiv:2508.01003v1 Announce Type: new 
Abstract: The rapid integration of generative artificial intelligence (AI) into postsecondary education and many other sectors resulted in a global reckoning with this new technology. This paper contributes to the study of the multifaceted influence of generative AI, with a particular focus on OpenAI's ChatGPT within academic settings during the first six months after the release in three specific ways. First, it scrutinizes the rise of ChatGPT as a transformative event construed through a study of mainstream discourses exhibiting AI hype. Second, it discusses the perceived implications of generative AI for writing, teaching, and learning through the lens of critical discourse analysis and critical AI studies. Third, it encourages the necessity for best practices in the adoption of generative AI technologies in education.</description>
      <guid isPermaLink="false">oai:arXiv.org:2508.01003v1</guid>
      <category>cs.CY</category>
      <category>cs.AI</category>
      <pubDate>Tue, 05 Aug 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <arxiv:DOI>10.18357/otessaj.2024.4.1.59</arxiv:DOI>
      <arxiv:journal_reference>Open/Technology in Education, Society, and Scholarship Association Journal (2024) v4.1, 1-19</arxiv:journal_reference>
      <dc:creator>Isabel Pedersen</dc:creator>
    </item>
    <item>
      <title>AI-Generated Algorithmic Virality</title>
      <link>https://arxiv.org/abs/2508.01042</link>
      <description>arXiv:2508.01042v1 Announce Type: new 
Abstract: There is a growing discussion about social media feeds being increasingly filled with AI-generated content. Due to its visual plausibility, low cost, and fast production speed, AI-generated content is said to be highly effective in "gaming the algorithm" and going viral. Popularly referred to as "AI slop," this phenomenon arguably leads to the presence of sloppy and potentially deceptive content at a scale unseen before. This investigation offers a systematic analysis of AI-generated content and its labelling in TikTok's and Instagram's search results across 13 hashtags (see Appendix) in three European countries (Spain, Germany, and Poland) over the course of June 2025. We manually annotated and analyzed the 30 top search results on political (#trump, #zelensky, #pope) and broader topics (e.g.,#health, #history) to understand the relation between synthetic (content that is partially or entirely made using generative AI) and non-synthetic content across languages and countries. We then explored the emerging phenomenon of accounts producing generative AI content at scale by analyzing 153 accounts and proposing a new categorization schema of what we termed Agentic AI Accounts. Our main findings are:</description>
      <guid isPermaLink="false">oai:arXiv.org:2508.01042v1</guid>
      <category>cs.CY</category>
      <pubDate>Tue, 05 Aug 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-sa/4.0/</dc:rights>
      <dc:creator>Natalia Stanusch, Martin Degeling, Salvatore Romano, Raziye Buse \c{C}etin, Miazia Sch\"uler, Silvia Semenzin</dc:creator>
    </item>
    <item>
      <title>Disaggregated Health Data in LLMs: Evaluating Data Equity in the Context of Asian American Representation</title>
      <link>https://arxiv.org/abs/2508.01091</link>
      <description>arXiv:2508.01091v1 Announce Type: new 
Abstract: Large language models (LLMs), such as ChatGPT and Claude, have emerged as essential tools for information retrieval, often serving as alternatives to traditional search engines. However, ensuring that these models provide accurate and equitable information tailored to diverse demographic groups remains an important challenge. This study investigates the capability of LLMs to retrieve disaggregated health-related information for sub-ethnic groups within the Asian American population, such as Korean and Chinese communities. Data disaggregation has been a critical practice in health research to address inequities, making it an ideal domain for evaluating representation equity in LLM outputs. We apply a suite of statistical and machine learning tools to assess whether LLMs deliver appropriately disaggregated and equitable information. By focusing on Asian American sub-ethnic groups, a highly diverse population often aggregated in traditional analyses; we highlight how LLMs handle complex disparities in health data. Our findings contribute to ongoing discussions about responsible AI, particularly in ensuring data equity in the outputs of LLM-based systems.</description>
      <guid isPermaLink="false">oai:arXiv.org:2508.01091v1</guid>
      <category>cs.CY</category>
      <pubDate>Tue, 05 Aug 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/publicdomain/zero/1.0/</dc:rights>
      <dc:creator>Uvini Balasuriya Mudiyanselage, Bharat Jayprakash, Kookjin Lee, K. Hazel Kwon</dc:creator>
    </item>
    <item>
      <title>Generative AI-Driven Decision-Making for Disease Control and Pandemic Preparedness Model 4.0 in Rural Communities of Bangladesh: Management Informatics Approach</title>
      <link>https://arxiv.org/abs/2508.01142</link>
      <description>arXiv:2508.01142v1 Announce Type: new 
Abstract: Rural Bangladesh is confronted with substantial healthcare obstacles, such as inadequate infrastructure, inadequate information systems, and restricted access to medical personnel. These obstacles impede effective disease control and pandemic preparedness. This investigation employs a structured methodology to develop and analyze numerous plausible scenarios systematically. A purposive sampling strategy was implemented, which involved the administration of a questionnaire survey to 264 rural residents in the Rangamati district of Bangladesh and the completion of a distinct questionnaire by 103 healthcare and medical personnel. The impact and effectiveness of the study are assessed through logistic regression analysis and a pre-post comparison that employs the Wilcoxon Signed-Rank test and Kendall's coefficient for non-parametric paired and categorical variables. This analysis evaluates the evolution of disease control and preparedness prior to and subsequent to the implementation of the Generative AI-Based Model 4.0. The results indicate that trust in AI (\b{eta} = 1.20, p = 0.020) and confidence in sharing health data (\b{eta} = 9.049, p = 0.020) are the most significant predictors of AI adoption. At the same time, infrastructure limitations and digital access constraints continue to be significant constraints. The study concludes that the health resilience and pandemic preparedness of marginalized rural populations can be improved through AI-driven, localized disease control strategies. The integration of Generative AI into rural healthcare systems offers a transformative opportunity, but it is contingent upon active community engagement, enhanced digital literacy, and strong government involvement.</description>
      <guid isPermaLink="false">oai:arXiv.org:2508.01142v1</guid>
      <category>cs.CY</category>
      <category>econ.GN</category>
      <category>q-fin.EC</category>
      <pubDate>Tue, 05 Aug 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <arxiv:DOI>10.59324/ejmhr.2025.3(2).11</arxiv:DOI>
      <arxiv:journal_reference>Eur J Med Health Res, 2025;3(2):104-21</arxiv:journal_reference>
      <dc:creator>Mohammad Saddam Hosen, MD Shahidul Islam Fakir, Shamal Chandra Hawlader, Farzana Rahman, Tasmim Karim, Muhammed Habil Uddin</dc:creator>
    </item>
    <item>
      <title>WIP: Enhancing Game-Based Learning with AI-Driven Peer Agents</title>
      <link>https://arxiv.org/abs/2508.01169</link>
      <description>arXiv:2508.01169v1 Announce Type: new 
Abstract: This work-in-progress paper presents SPARC (Systematic Problem Solving and Algorithmic Reasoning for Children), a gamified learning platform designed to enhance engagement and knowledge retention in K-12 STEM education. Traditional approaches often struggle to motivate students or facilitate deep understanding, especially for complex scientific concepts. SPARC addresses these challenges by integrating interactive, narrative-driven gameplay with an artificial intelligence peer agent built on large language models. Rather than simply providing answers, the agent engages students in dialogue and inquiry, prompting them to explain concepts and solve problems collaboratively. The platform's design is grounded in educational theory and closely aligned with state learning standards. Initial classroom pilots utilized a multi-method assessment framework combining pre- and post-tests, in-game analytics, and qualitative feedback from students and teachers. Preliminary findings indicate that SPARC significantly increases student engagement, with most participants reporting greater interest in STEM subjects and moderate gains in conceptual understanding observed in post-test results. Ongoing development focuses on refining the AI agent, expanding curriculum integration, and improving accessibility. These early results demonstrate the potential of combining AI-driven peer support with game-based learning to create inclusive, effective, and engaging educational experiences for K-12 learners.</description>
      <guid isPermaLink="false">oai:arXiv.org:2508.01169v1</guid>
      <category>cs.CY</category>
      <pubDate>Tue, 05 Aug 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Chengzhang Zhu, Cecile H. Sam, Yanlai Wu, Ying Tang</dc:creator>
    </item>
    <item>
      <title>Recognising, Anticipating, and Mitigating LLM Pollution of Online Behavioural Research</title>
      <link>https://arxiv.org/abs/2508.01390</link>
      <description>arXiv:2508.01390v1 Announce Type: new 
Abstract: Online behavioural research faces an emerging threat as participants increasingly turn to large language models (LLMs) for advice, translation, or task delegation: LLM Pollution. We identify three interacting variants through which LLM Pollution threatens the validity and integrity of online behavioural research. First, Partial LLM Mediation occurs when participants make selective use of LLMs for specific aspects of a task, such as translation or wording support, leading researchers to (mis)interpret LLM-shaped outputs as human ones. Second, Full LLM Delegation arises when agentic LLMs complete studies with little to no human oversight, undermining the central premise of human-subject research at a more foundational level. Third, LLM Spillover signifies human participants altering their behaviour as they begin to anticipate LLM presence in online studies, even when none are involved. While Partial Mediation and Full Delegation form a continuum of increasing automation, LLM Spillover reflects second-order reactivity effects. Together, these variants interact and generate cascading distortions that compromise sample authenticity, introduce biases that are difficult to detect post hoc, and ultimately undermine the epistemic grounding of online research on human cognition and behaviour. Crucially, the threat of LLM Pollution is already co-evolving with advances in generative AI, creating an escalating methodological arms race. To address this, we propose a multi-layered response spanning researcher practices, platform accountability, and community efforts. As the challenge evolves, coordinated adaptation will be essential to safeguard methodological integrity and preserve the validity of online behavioural research.</description>
      <guid isPermaLink="false">oai:arXiv.org:2508.01390v1</guid>
      <category>cs.CY</category>
      <category>cs.AI</category>
      <pubDate>Tue, 05 Aug 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Raluca Rilla, Tobias Werner, Hiromu Yakura, Iyad Rahwan, Anne-Marie Nussberger</dc:creator>
    </item>
    <item>
      <title>Artificial Intelligence and Misinformation in Art: Can Vision Language Models Judge the Hand or the Machine Behind the Canvas?</title>
      <link>https://arxiv.org/abs/2508.01408</link>
      <description>arXiv:2508.01408v1 Announce Type: new 
Abstract: The attribution of artworks in general and of paintings in particular has always been an issue in art. The advent of powerful artificial intelligence models that can generate and analyze images creates new challenges for painting attribution. On the one hand, AI models can create images that mimic the style of a painter, which can be incorrectly attributed, for example, by other AI models. On the other hand, AI models may not be able to correctly identify the artist for real paintings, inducing users to incorrectly attribute paintings. In this paper, both problems are experimentally studied using state-of-the-art AI models for image generation and analysis on a large dataset with close to 40,000 paintings from 128 artists. The results show that vision language models have limited capabilities to: 1) perform canvas attribution and 2) to identify AI generated images. As users increasingly rely on queries to AI models to get information, these results show the need to improve the capabilities of VLMs to reliably perform artist attribution and detection of AI generated images to prevent the spread of incorrect information.</description>
      <guid isPermaLink="false">oai:arXiv.org:2508.01408v1</guid>
      <category>cs.CY</category>
      <pubDate>Tue, 05 Aug 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Tarian Fu, Javier Conde, Gonzalo Mart\'inez, Pedro Reviriego, Elena Merino-G\'omez, Fernando Moral</dc:creator>
    </item>
    <item>
      <title>Difficulty Generating Factors for Context-free Language Construction Assignments</title>
      <link>https://arxiv.org/abs/2508.01735</link>
      <description>arXiv:2508.01735v1 Announce Type: new 
Abstract: Computer science students often struggle with abstract theoretical concepts, particularly in introductory courses on theoretical computer science. One such challenge is understanding context-free languages and their various representations.
  In this study we investigate factors that influence the difficulty of constructing context-free grammars and pushdown automata for context-free languages. We propose two potential difficulty generating factors targeting how a language is presented to students: representation in natural language and as a verbose set notation. Furthermore, we propose two factors targeting the structure of the given context-free language: nesting of constructs and insertion of multiplicities.
  We conducted a controlled experiment using within-subject randomization in an interactive learning system, testing the proposed difficulty factors for constructing context-free grammars and pushdown automata. Our results suggest that three of the four factors significantly influence students' objective performance in solving exercises for constructing context-free grammars, while students' perceived difficulties only partly align with the objective performance measures. The findings for pushdown automata tasks differed markedly from those for context-free grammar tasks. Our variations either had negligible effects or, in some cases, even reduced difficulty. Thus, no robust statistical conclusions can be made for pushdown automata tasks.
  The results lay foundations for learning systems that adaptively choose appropriate exercises for individual students.</description>
      <guid isPermaLink="false">oai:arXiv.org:2508.01735v1</guid>
      <category>cs.CY</category>
      <category>cs.FL</category>
      <pubDate>Tue, 05 Aug 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <arxiv:DOI>10.1145/3702652.3744201</arxiv:DOI>
      <dc:creator>Florian Schmalstieg, Marko Schmellenkamp, Jakob Schwerter, Thomas Zeume</dc:creator>
    </item>
    <item>
      <title>The AI-Augmented Research Process: A Historian's Perspective</title>
      <link>https://arxiv.org/abs/2508.01779</link>
      <description>arXiv:2508.01779v1 Announce Type: new 
Abstract: This paper presents a detailed case study of how artificial intelligence, especially large language models, can be integrated into historical research workflows. The workflow is divided into nine steps, covering the full research cycle from question formulation to dissemination and reproducibility, and includes two framing phases that address setup and documentation. Each research step is mapped across three operational domains: 1. LLM, referring to tasks delegated to language models; 2. Mind, referring to conceptual and interpretive contributions by the historian; and 3. Computational, referring to conventional programming-based methods like Python, R, Cytoscape, etc. The study emphasizes that LLMs are not replacements for domain expertise but can support and expand capacity of historians to process, verify, and interpret large corpora of texts. At the same time, it highlights the necessity of rigorous quality control, cross-checking outputs, and maintaining scholarly standards. Drawing from an in-depth study of three Shanghai merchants, the paper also proposes a structured workflow based on a real case study hat articulates the cognitive labor of the historian with both computational tools and generative AI. This paper makes both a methodological and epistemological contribution by showing how AI can be responsibly incorporated into historical research through transparent and reproducible workflows. It is intended as a practical guide and critical reflection for historians facing the increasingly complex landscape of AI-enhanced scholarship.</description>
      <guid isPermaLink="false">oai:arXiv.org:2508.01779v1</guid>
      <category>cs.CY</category>
      <pubDate>Tue, 05 Aug 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-sa/4.0/</dc:rights>
      <dc:creator>Christian Henriot</dc:creator>
    </item>
    <item>
      <title>Understanding Student Attitudes and Acceptability of GenAI Tools in Higher Ed: Scale Development and Evaluation</title>
      <link>https://arxiv.org/abs/2508.01926</link>
      <description>arXiv:2508.01926v1 Announce Type: new 
Abstract: As generative AI (GenAI) tools like ChatGPT become more common in higher education, understanding student attitudes is essential for evaluating their educational impact and supporting responsible AI integration. This study introduces a validated survey instrument designed to assess students' perceptions of GenAI, including its acceptability for academic tasks, perceived influence on learning and careers, and broader societal concerns. We administered the survey to 297 undergraduates at a U.S. university. The instrument includes six thematic domains: institutional understanding, fairness and trust, academic and career influence, societal concerns, and GenAI use in writing and coursework. Exploratory factor analysis revealed four attitudinal dimensions: societal concern, policy clarity, fairness and trust, and career impact. Subgroup analyses identified statistically significant differences across student backgrounds. Male students and those speaking a language other than English at home rated GenAI use in writing tasks as more acceptable. First-year students expressed greater societal concern than upper-year peers. Students from multilingual households perceived greater clarity in institutional policy, while first-generation students reported a stronger belief in GenAI's impact on future careers. This work contributes a practical scale for evaluating the student impact of GenAI tools, informing the design of educational AI systems.</description>
      <guid isPermaLink="false">oai:arXiv.org:2508.01926v1</guid>
      <category>cs.CY</category>
      <pubDate>Tue, 05 Aug 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Xiuxiu Tang, Si Chen, Ying Cheng, Nitesh V Chawla, Ronald Metoyer, G. Alex Ambrose</dc:creator>
    </item>
    <item>
      <title>The Actual Usage Of Cryptocurrency By Individuals</title>
      <link>https://arxiv.org/abs/2508.02086</link>
      <description>arXiv:2508.02086v1 Announce Type: new 
Abstract: This study investigates how media influence and educational resources shape individual engagement with cryptocurrencies. As digital assets become increasingly mainstream, social media platforms, influencers, and financial analysts play a central role in driving public interest and investment behavior. Quantitative surveys and qualitative interviews reveal that persuasive narratives and success stories on social media often attract new investors, while accessible educational materials empower individuals to make informed decisions in a volatile market. The findings highlight that media exposure can spark initial adoption, but sustained and responsible participation depends on comprehensive education in cryptocurrency fundamentals, trading strategies, and blockchain technology</description>
      <guid isPermaLink="false">oai:arXiv.org:2508.02086v1</guid>
      <category>cs.CY</category>
      <pubDate>Tue, 05 Aug 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Fahed Quttainah</dc:creator>
    </item>
    <item>
      <title>Assessing the Reliability and Validity of Large Language Models for Automated Assessment of Student Essays in Higher Education</title>
      <link>https://arxiv.org/abs/2508.02442</link>
      <description>arXiv:2508.02442v1 Announce Type: new 
Abstract: This study investigates the reliability and validity of five advanced Large Language Models (LLMs), Claude 3.5, DeepSeek v2, Gemini 2.5, GPT-4, and Mistral 24B, for automated essay scoring in a real world higher education context. A total of 67 Italian-language student essays, written as part of a university psychology course, were evaluated using a four-criterion rubric (Pertinence, Coherence, Originality, Feasibility). Each model scored all essays across three prompt replications to assess intra-model stability. Human-LLM agreement was consistently low and non-significant (Quadratic Weighted Kappa), and within-model reliability across replications was similarly weak (median Kendall's W &lt; 0.30). Systematic scoring divergences emerged, including a tendency to inflate Coherence and inconsistent handling of context-dependent dimensions. Inter-model agreement analysis revealed moderate convergence for Coherence and Originality, but negligible concordance for Pertinence and Feasibility. Although limited in scope, these findings suggest that current LLMs may struggle to replicate human judgment in tasks requiring disciplinary insight and contextual sensitivity. Human oversight remains critical when evaluating open-ended academic work, particularly in interpretive domains.</description>
      <guid isPermaLink="false">oai:arXiv.org:2508.02442v1</guid>
      <category>cs.CY</category>
      <category>cs.AI</category>
      <pubDate>Tue, 05 Aug 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-sa/4.0/</dc:rights>
      <dc:creator>Andrea Gaggioli, Giuseppe Casaburi, Leonardo Ercolani, Francesco Collova', Pietro Torre, Fabrizio Davide</dc:creator>
    </item>
    <item>
      <title>A Schema.org Mapping for Brazilian Legal Norms: Toward Interoperable Legal Graphs and Open Government Data</title>
      <link>https://arxiv.org/abs/2508.00827</link>
      <description>arXiv:2508.00827v1 Announce Type: cross 
Abstract: Open Government Data (OGD) initiatives aim to enhance transparency and public participation by making government data openly accessible. However, structuring legal norms for machine readability remains a critical challenge for advancing Legal Tech applications such as Legal Knowledge Graphs (LKGs). Focusing on the Normas.leg.br portal initiative by the Brazilian National Congress, we propose a unified mapping of Brazilian legislation to the schema.org/Legislation vocabulary via JSON-LD and Linked Data. Our approach covers both the conceptual "Norm" entity (mapped to sdo:Legislation) and its digital publications or manifestations (mapped to sdo:LegislationObject). We detail key properties for each type, providing concrete examples and considering URN identifiers (per the LexML standard), multilingual support, versioning in the Official Journal, and inter-norm relationships (e.g., citations and references). Our structured schema improves the quality and interoperability of Brazilian legal data, fosters integration within the global OGD ecosystem, and facilitates the creation of a wor</description>
      <guid isPermaLink="false">oai:arXiv.org:2508.00827v1</guid>
      <category>cs.DL</category>
      <category>cs.AI</category>
      <category>cs.CY</category>
      <category>cs.IR</category>
      <pubDate>Tue, 05 Aug 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Hudson de Martim</dc:creator>
    </item>
    <item>
      <title>GPT Chatbots for Alleviating Anxiety and Depression: A Pilot Randomized Controlled Trial with Afghan Women</title>
      <link>https://arxiv.org/abs/2508.00847</link>
      <description>arXiv:2508.00847v1 Announce Type: cross 
Abstract: In this study, we investigated the effects of GPT-4, with and without specific conversational instructions, on the mental health of Afghan women. These women face multifaceted challenges, including Taliban-imposed restrictions, societal inequalities, and domestic violence, adversely affecting their well-being. We conducted a randomized controlled trial with 60 participants, dividing them into three groups: GPT-4, a supportive listener (GPT-4 with empathetic engagement instructions), and a waiting list. The Hospital Anxiety and Depression Scale (HADS) was used to measure anxiety and depression before and after the intervention. Linguistic analysis of chat data examined personal pronouns, tones, emotions, and Language Style Matching (LSM). The supportive listener group showed a significant reduction in HADS scores compared to the other groups. Linguistic analysis revealed a more positive tone and higher LSM in the supportive listener group, with a significant negative correlation between LSM and changes in HADS scores, indicating greater linguistic alignment was linked to reductions in anxiety and depression. Perceived empathy ratings were also significantly higher in the supportive listener group. These findings highlight the potential of AI-driven interventions, like GPT-4, in providing accessible mental health support. However, such interventions should complement traditional psychotherapy, ensuring a collaborative approach to optimize therapeutic outcomes.</description>
      <guid isPermaLink="false">oai:arXiv.org:2508.00847v1</guid>
      <category>cs.HC</category>
      <category>cs.CY</category>
      <pubDate>Tue, 05 Aug 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Sofia Sahab, Jawad Haqbeen, Diksha Sapkota, Takayuki Ito</dc:creator>
    </item>
    <item>
      <title>RestAware: Non-Invasive Sleep Monitoring Using FMCW Radar and AI-Generated Summaries</title>
      <link>https://arxiv.org/abs/2508.00848</link>
      <description>arXiv:2508.00848v1 Announce Type: cross 
Abstract: Monitoring sleep posture and behavior is critical for diagnosing sleep disorders and improving overall sleep quality. However, traditional approaches, such as wearable devices, cameras, and pressure sensors, often compromise user comfort, fail under obstructions like blankets, and raise privacy concerns. To overcome these limitations, we present RestAware, a non-invasive, contactless sleep monitoring system based on a 24GHz frequency-modulated continuous wave (FMCW) radar. Our system is evaluated on 25 participants across eight common sleep postures, achieving 92% classification accuracy and an F1-score of 0.91 using a K-Nearest Neighbors (KNN) classifier. In addition, we integrate instruction-tuned large language models (Mistral, Llama, and Falcon) to generate personalized, human-readable sleep summaries from radar-derived posture data. This low-cost ($ 35), privacy-preserving solution offers a practical alternative for real-time deployment in smart homes and clinical environments.</description>
      <guid isPermaLink="false">oai:arXiv.org:2508.00848v1</guid>
      <category>cs.HC</category>
      <category>cs.CY</category>
      <category>eess.SP</category>
      <pubDate>Tue, 05 Aug 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Agniva Banerjee, Bhanu Partap Paregi, Haroon R. Lone</dc:creator>
    </item>
    <item>
      <title>Gearshift Fellowship: A Next-Generation Neurocomputational Game Platform to Model and Train Human-AI Adaptability</title>
      <link>https://arxiv.org/abs/2508.00850</link>
      <description>arXiv:2508.00850v1 Announce Type: cross 
Abstract: How do we learn when to persist, when to let go, and when to shift gears? Gearshift Fellowship (GF) is the prototype of a new Supertask paradigm designed to model how humans and artificial agents adapt to shifting environment demands. Grounded in cognitive neuroscience, computational psychiatry, economics, and artificial intelligence, Supertasks combine computational neurocognitive modeling with serious gaming. This creates a dynamic, multi-mission environment engineered to assess mechanisms of adaptive behavior across cognitive and social contexts. Computational parameters explain behavior and probe mechanisms by controlling the game environment. Unlike traditional tasks, GF enables neurocognitive modeling of individual differences across perceptual decisions, learning, and meta-cognitive levels. This positions GF as a flexible testbed for understanding how cognitive-affective control processes, learning styles, strategy use, and motivational shifts adapt across contexts and over time. It serves as an experimental platform for scientists, a phenotype-to-mechanism intervention for clinicians, and a training tool for players aiming to strengthen self-regulated learning, mood, and stress resilience. Online study (n = 60, ongoing) results show that GF recovers effects from traditional neuropsychological tasks (construct validity), uncovers novel patterns in how learning differs across contexts and how clinical features map onto distinct adaptations. These findings pave the way for developing in-game interventions that foster self-efficacy and agency to cope with real-world stress and uncertainty. GF builds a new adaptive ecosystem designed to accelerate science, transform clinical care, and foster individual growth. It offers a mirror and training ground where humans and machines co-develop together deeper flexibility and awareness.</description>
      <guid isPermaLink="false">oai:arXiv.org:2508.00850v1</guid>
      <category>cs.HC</category>
      <category>cs.AI</category>
      <category>cs.CE</category>
      <category>cs.CY</category>
      <pubDate>Tue, 05 Aug 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Nadja R. Ging-Jehli, Russell K. Childers, Joshua Lu, Robert Gemma, Rachel Zhu</dc:creator>
    </item>
    <item>
      <title>EthicAlly: a Prototype for AI-Powered Research Ethics Support for the Social Sciences and Humanities</title>
      <link>https://arxiv.org/abs/2508.00856</link>
      <description>arXiv:2508.00856v1 Announce Type: cross 
Abstract: In biomedical science, review by a Research Ethics Committee (REC) is an indispensable way of protecting human subjects from harm. However, in social science and the humanities, mandatory ethics compliance has long been met with scepticism as biomedical models of ethics can map poorly onto methodologies involving complex socio-political and cultural considerations. As a result, tailored ethics training and support as well as access to RECs with the necessary expertise is lacking in some areas, including parts of Europe and low- and middle-income countries. This paper suggests that Generative AI can meaningfully contribute to closing these gaps, illustrating this claim by presenting EthicAlly, a proof-of-concept prototype for an AI-powered ethics support system for social science and humanities researchers. Drawing on constitutional AI technology and a collaborative prompt development methodology, EthicAlly provides structured ethics assessment that incorporates both universal ethics principles and contextual and interpretive considerations relevant to most social science research. In supporting researchers in ethical research design and preparation for REC submission, this kind of system can also contribute to easing the burden on institutional RECs, without attempting to automate or replace human ethical oversight.</description>
      <guid isPermaLink="false">oai:arXiv.org:2508.00856v1</guid>
      <category>cs.HC</category>
      <category>cs.AI</category>
      <category>cs.CY</category>
      <pubDate>Tue, 05 Aug 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Steph Grohmann</dc:creator>
    </item>
    <item>
      <title>Patents as Knowledge Artifacts: An Information Science Perspective on Global Innovation</title>
      <link>https://arxiv.org/abs/2508.00871</link>
      <description>arXiv:2508.00871v1 Announce Type: cross 
Abstract: In an age of fast-paced technological change, patents have evolved into not only legal mechanisms of intellectual property, but also structured storage containers of knowledge full of metadata, categories, and formal innovation. This chapter proposes to reframe patents in the context of information science, by focusing on patents as knowledge artifacts, and by seeing patents as fundamentally tied to the global movement of scientific and technological knowledge. With a focus on three areas, the inventions of AIs, biotech patents, and international competition with patents, this work considers how new technologies are challenging traditional notions of inventorship, access, and moral accountability.The chapter provides a critical analysis of AI's implications for patent authorship and prior art searches, ownership issues arising from proprietary claims in biotechnology to ethical dilemmas, and the problem of using patents for strategic advantage in a global context of innovation competition. In this analysis, the chapter identified the importance of organizing information, creating metadata standards about originality, implementing retrieval systems to access previous works, and ethical contemplation about patenting unseen relationships in innovation ecosystems. Ultimately, the chapter called for a collaborative, transparent, and ethically-based approach in managing knowledge in the patenting environment highlighting the role for information professionals and policy to contribute to access equity in innovation.</description>
      <guid isPermaLink="false">oai:arXiv.org:2508.00871v1</guid>
      <category>cs.DL</category>
      <category>cs.AI</category>
      <category>cs.CY</category>
      <pubDate>Tue, 05 Aug 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>M. S. Rajeevan, B. Mini Devi</dc:creator>
    </item>
    <item>
      <title>ff4ERA: A new Fuzzy Framework for Ethical Risk Assessment in AI</title>
      <link>https://arxiv.org/abs/2508.00899</link>
      <description>arXiv:2508.00899v1 Announce Type: cross 
Abstract: The emergence of Symbiotic AI (SAI) introduces new challenges to ethical decision-making as it deepens human-AI collaboration. As symbiosis grows, AI systems pose greater ethical risks, including harm to human rights and trust. Ethical Risk Assessment (ERA) thus becomes crucial for guiding decisions that minimize such risks. However, ERA is hindered by uncertainty, vagueness, and incomplete information, and morality itself is context-dependent and imprecise. This motivates the need for a flexible, transparent, yet robust framework for ERA. Our work supports ethical decision-making by quantitatively assessing and prioritizing multiple ethical risks so that artificial agents can select actions aligned with human values and acceptable risk levels. We introduce ff4ERA, a fuzzy framework that integrates Fuzzy Logic, the Fuzzy Analytic Hierarchy Process (FAHP), and Certainty Factors (CF) to quantify ethical risks via an Ethical Risk Score (ERS) for each risk type. The final ERS combines the FAHP-derived weight, propagated CF, and risk level. The framework offers a robust mathematical approach for collaborative ERA modeling and systematic, step-by-step analysis. A case study confirms that ff4ERA yields context-sensitive, ethically meaningful risk scores reflecting both expert input and sensor-based evidence. Risk scores vary consistently with relevant factors while remaining robust to unrelated inputs. Local sensitivity analysis shows predictable, mostly monotonic behavior across perturbations, and global Sobol analysis highlights the dominant influence of expert-defined weights and certainty factors, validating the model design. Overall, the results demonstrate ff4ERA ability to produce interpretable, traceable, and risk-aware ethical assessments, enabling what-if analyses and guiding designers in calibrating membership functions and expert judgments for reliable ethical decision support.</description>
      <guid isPermaLink="false">oai:arXiv.org:2508.00899v1</guid>
      <category>cs.AI</category>
      <category>cs.CY</category>
      <category>cs.HC</category>
      <category>cs.LG</category>
      <pubDate>Tue, 05 Aug 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <dc:creator>Abeer Dyoub, Ivan Letteri, Francesca A. Lisi</dc:creator>
    </item>
    <item>
      <title>An analysis of AI Decision under Risk: Prospect theory emerges in Large Language Models</title>
      <link>https://arxiv.org/abs/2508.00902</link>
      <description>arXiv:2508.00902v1 Announce Type: cross 
Abstract: Judgment of risk is key to decision-making under uncertainty. As Daniel Kahneman and Amos Tversky famously discovered, humans do so in a distinctive way that departs from mathematical rationalism. Specifically, they demonstrated experimentally that humans accept more risk when they feel themselves at risk of losing something than when they might gain. I report the first tests of Kahneman and Tversky's landmark 'prospect theory' with Large Language Models, including today's state of the art chain-of-thought 'reasoners'.
  In common with humans, I find that prospect theory often anticipates how these models approach risky decisions across a range of scenarios. I also demonstrate that context is key to explaining much of the variance in risk appetite. The 'frame' through which risk is apprehended appears to be embedded within the language of the scenarios tackled by the models. Specifically, I find that military scenarios generate far larger 'framing effects' than do civilian settings, ceteris paribus. My research suggests, therefore, that language models the world, capturing our human heuristics and biases. But also that these biases are uneven - the idea of a 'frame' is richer than simple gains and losses. Wittgenstein's notion of 'language games' explains the contingent, localised biases activated by these scenarios. Finally, I use my findings to reframe the ongoing debate about reasoning and memorisation in LLMs.</description>
      <guid isPermaLink="false">oai:arXiv.org:2508.00902v1</guid>
      <category>cs.AI</category>
      <category>cs.CL</category>
      <category>cs.CY</category>
      <pubDate>Tue, 05 Aug 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Kenneth Payne</dc:creator>
    </item>
    <item>
      <title>Accessibility and Social Inclusivity: A Literature Review of Music Technology for Blind and Low Vision People</title>
      <link>https://arxiv.org/abs/2508.00929</link>
      <description>arXiv:2508.00929v1 Announce Type: cross 
Abstract: This paper presents a systematic literature review of music technology tailored for blind and low vision (BLV) individuals. Music activities can be particularly beneficial for BLV people. However, a systematic approach to organizing knowledge on designing accessible technology for BLV people has yet to be attempted. We categorize the existing studies based on the type of technology and the extent of BLV people's involvement in the research. We identify six main categories of BLV people-oriented music technology and highlight four key trends in design goals. Based on these categories, we propose four general insights focusing on (1) spatial awareness, (2) access to information, (3) (non-verbal) communication, and (4) memory. The identified trends suggest that more empirical studies involving BLV people in real-world scenarios are needed to ensure that technological advancements can enhance musical experiences and social inclusion. This research proposes collaborative music technology and inclusive real-world testing with the target group as two key areas missing in current research. They serve as a foundational step in shifting the focus from ``accessible technology'' to ``inclusive technology'' for BLV individuals within the broader field of accessibility research.</description>
      <guid isPermaLink="false">oai:arXiv.org:2508.00929v1</guid>
      <category>cs.HC</category>
      <category>cs.CY</category>
      <category>cs.SD</category>
      <category>eess.AS</category>
      <pubDate>Tue, 05 Aug 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-sa/4.0/</dc:rights>
      <arxiv:DOI>10.1145/3663547.3746466</arxiv:DOI>
      <dc:creator>Shumeng Zhang, Raul Masu, Mela Bettega, Mingming Fan</dc:creator>
    </item>
    <item>
      <title>How Cybersecurity Behaviors affect the Success of Darknet Drug Vendors: A Quantitative Analysis</title>
      <link>https://arxiv.org/abs/2508.00934</link>
      <description>arXiv:2508.00934v1 Announce Type: cross 
Abstract: Understanding behavioral drivers of success in illicit digital marketplaces is critical for developing effective enforcement strategies and understanding digital commerce evolution, as darknet drug markets represent a growing share of the total drug economy. This study employs quantitative regression analysis of 50,000+ listings from 2,653 vendors in the Agora marketplace (2014-2015), examining relationships between cybersecurity signaling (PGP encryption mentions), product diversification, and commercial success through nested regression specifications controlling for reputation, pricing, and category-specific factors. Product diversification emerges as the dominant predictor of vendor scale, increasing the odds of large vendor status by 169% per additional category, while PGP encryption signaling functions primarily as a professional marker rather than an independent success factor. Vendor success depends on portfolio breadth rather than specialization, with category-specific enforcement creating differential market constraints. Successful vendors operate as diversified enterprises capable of rapid pivoting between product categories, requiring targeted enforcement towards diversified vendors based on coordinated multi-category enforcement approaches rather than traditional substance-specific targeting strategies.</description>
      <guid isPermaLink="false">oai:arXiv.org:2508.00934v1</guid>
      <category>cs.CR</category>
      <category>cs.CY</category>
      <pubDate>Tue, 05 Aug 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Syon Balakrishnan, Aaron Grinberg</dc:creator>
    </item>
    <item>
      <title>Autonomous Penetration Testing: Solving Capture-the-Flag Challenges with LLMs</title>
      <link>https://arxiv.org/abs/2508.01054</link>
      <description>arXiv:2508.01054v1 Announce Type: cross 
Abstract: This study evaluates the ability of GPT-4o to autonomously solve beginner-level offensive security tasks by connecting the model to OverTheWire's Bandit capture-the-flag game. Of the 25 levels that were technically compatible with a single-command SSH framework, GPT-4o solved 18 unaided and another two after minimal prompt hints for an overall 80% success rate. The model excelled at single-step challenges that involved Linux filesystem navigation, data extraction or decoding, and straightforward networking. The approach often produced the correct command in one shot and at a human-surpassing speed. Failures involved multi-command scenarios that required persistent working directories, complex network reconnaissance, daemon creation, or interaction with non-standard shells. These limitations highlight current architectural deficiencies rather than a lack of general exploit knowledge. The results demonstrate that large language models (LLMs) can automate a substantial portion of novice penetration-testing workflow, potentially lowering the expertise barrier for attackers and offering productivity gains for defenders who use LLMs as rapid reconnaissance aides. Further, the unsolved tasks reveal specific areas where secure-by-design environments might frustrate simple LLM-driven attacks, informing future hardening strategies. Beyond offensive cybersecurity applications, results suggest the potential to integrate LLMs into cybersecurity education as practice aids.</description>
      <guid isPermaLink="false">oai:arXiv.org:2508.01054v1</guid>
      <category>cs.CR</category>
      <category>cs.AI</category>
      <category>cs.CY</category>
      <pubDate>Tue, 05 Aug 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Isabelle Bakker, John Hastings</dc:creator>
    </item>
    <item>
      <title>Protecting Student Mental Health with a Context-Aware Machine Learning Framework for Stress Monitoring</title>
      <link>https://arxiv.org/abs/2508.01105</link>
      <description>arXiv:2508.01105v1 Announce Type: cross 
Abstract: Student mental health is an increasing concern in academic institutions, where stress can severely impact well-being and academic performance. Traditional assessment methods rely on subjective surveys and periodic evaluations, offering limited value for timely intervention. This paper introduces a context-aware machine learning framework for classifying student stress using two complementary survey-based datasets covering psychological, academic, environmental, and social factors. The framework follows a six-stage pipeline involving preprocessing, feature selection (SelectKBest, RFECV), dimensionality reduction (PCA), and training with six base classifiers: SVM, Random Forest, Gradient Boosting, XGBoost, AdaBoost, and Bagging. To enhance performance, we implement ensemble strategies, including hard voting, soft voting, weighted voting, and stacking. Our best models achieve 93.09% accuracy with weighted hard voting on the Student Stress Factors dataset and 99.53% with stacking on the Stress and Well-being dataset, surpassing previous benchmarks. These results highlight the potential of context-integrated, data-driven systems for early stress detection and underscore their applicability in real-world academic settings to support student well-being.</description>
      <guid isPermaLink="false">oai:arXiv.org:2508.01105v1</guid>
      <category>cs.LG</category>
      <category>cs.AI</category>
      <category>cs.CY</category>
      <pubDate>Tue, 05 Aug 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Md Sultanul Islam Ovi, Jamal Hossain, Md Raihan Alam Rahi, Fatema Akter</dc:creator>
    </item>
    <item>
      <title>RoboLinker: A Diffusion-model-based Matching Clothing Generator Between Humans and Companion Robots</title>
      <link>https://arxiv.org/abs/2508.01165</link>
      <description>arXiv:2508.01165v1 Announce Type: cross 
Abstract: We present RoboLinker, a generative design system that creates matching outfits for humans and their robots. Using a diffusion-based model, the system takes a robot image and a style prompt from users as input, and outputs a human outfit that visually complements the robot's attire. Through an interactive interface, users can refine the generated designs. We evaluate RoboLinker with both humanoid and pet-like robots, demonstrating its capacity to produce stylistically coherent and emotionally resonant results.</description>
      <guid isPermaLink="false">oai:arXiv.org:2508.01165v1</guid>
      <category>cs.HC</category>
      <category>cs.CY</category>
      <category>cs.RO</category>
      <pubDate>Tue, 05 Aug 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <arxiv:DOI>10.1145/3746058.3758427</arxiv:DOI>
      <dc:creator>Jing Tang, Qing Xiao, Kunxu Du, Zaiqiao Ye</dc:creator>
    </item>
    <item>
      <title>FedCD: A Fairness-aware Federated Cognitive Diagnosis Framework</title>
      <link>https://arxiv.org/abs/2508.01296</link>
      <description>arXiv:2508.01296v1 Announce Type: cross 
Abstract: Online intelligent education platforms have generated a vast amount of distributed student learning data. This influx of data presents opportunities for cognitive diagnosis (CD) to assess students' mastery of knowledge concepts while also raising significant data privacy and security challenges. To cope with this issue, federated learning (FL) becomes a promising solution by jointly training models across multiple local clients without sharing their original data. However, the data quality problem, caused by the ability differences and educational context differences between different groups/schools of students, further poses a challenge to the fairness of models. To address this challenge, this paper proposes a fairness-aware federated cognitive diagnosis framework (FedCD) to jointly train CD models built upon a novel parameter decoupling-based personalization strategy, preserving privacy of data and achieving precise and fair diagnosis of students on each client. As an FL paradigm, FedCD trains a local CD model for the students in each client based on its local student learning data, and each client uploads its partial model parameters to the central server for parameter aggregation according to the devised innovative personalization strategy. The main idea of this strategy is to decouple model parameters into two parts: the first is used as locally personalized parameters, containing diagnostic function-related model parameters, to diagnose each client's students fairly; the second is the globally shared parameters across clients and the server, containing exercise embedding parameters, which are updated via fairness-aware aggregation, to alleviate inter-school unfairness. Experiments on three real-world datasets demonstrate the effectiveness of the proposed FedCD framework and the personalization strategy compared to five FL approaches under three CD models.</description>
      <guid isPermaLink="false">oai:arXiv.org:2508.01296v1</guid>
      <category>cs.LG</category>
      <category>cs.CY</category>
      <pubDate>Tue, 05 Aug 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Shangshang Yang, Jialin Han, Xiaoshan Yu, Ziwen Wang, Hao Jiang, Haiping Ma, Xingyi Zhang, Geyong Min</dc:creator>
    </item>
    <item>
      <title>Idempotent Equilibrium Analysis of Hybrid Workflow Allocation: A Mathematical Schema for Future Work</title>
      <link>https://arxiv.org/abs/2508.01323</link>
      <description>arXiv:2508.01323v1 Announce Type: cross 
Abstract: The rapid advance of large-scale AI systems is reshaping how work is divided between people and machines. We formalise this reallocation as an iterated task-delegation map and show that--under broad, empirically grounded assumptions--the process converges to a stable idempotent equilibrium in which every task is performed by the agent (human or machine) with enduring comparative advantage. Leveraging lattice-theoretic fixed-point tools (Tarski and Banach), we (i) prove existence of at least one such equilibrium and (ii) derive mild monotonicity conditions that guarantee uniqueness. In a stylised continuous model the long-run automated share takes the closed form $x^* = \alpha / (\alpha + \beta)$, where $\alpha$ captures the pace of automation and $\beta$ the rate at which new, human-centric tasks appear; hence full automation is precluded whenever $\beta &gt; 0$. We embed this analytic result in three complementary dynamical benchmarks--a discrete linear update, an evolutionary replicator dynamic, and a continuous Beta-distributed task spectrum--each of which converges to the same mixed equilibrium and is reproducible from the provided code-free formulas. A 2025-to-2045 simulation calibrated to current adoption rates projects automation rising from approximately 10% of work to approximately 65%, leaving a persistent one-third of tasks to humans. We interpret that residual as a new profession of workflow conductor: humans specialise in assigning, supervising and integrating AI modules rather than competing with them. Finally, we discuss implications for skill development, benchmark design and AI governance, arguing that policies which promote "centaur" human-AI teaming can steer the economy toward the welfare-maximising fixed point.</description>
      <guid isPermaLink="false">oai:arXiv.org:2508.01323v1</guid>
      <category>cs.AI</category>
      <category>cs.CY</category>
      <category>econ.GN</category>
      <category>q-fin.EC</category>
      <pubDate>Tue, 05 Aug 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Faruk Alpay, Bugra Kilictas, Taylan Alpay, Hamdi Alakkad</dc:creator>
    </item>
    <item>
      <title>Unlocking Excellence: The Impact of Voucher Incentives on Cybersecurity Education</title>
      <link>https://arxiv.org/abs/2508.01520</link>
      <description>arXiv:2508.01520v1 Announce Type: cross 
Abstract: While voucher incentives have been popular for primary and secondary schools, they are less used in higher education. In this study, we leverage industry voucher incentives to inspire students in cybersecurity education (CSE). We adopt a 100% portfolio-based assessment strategy, where students can freely select their target grades in the investigated unit. We purposely design one of the high distinction (HD) tasks to be obtaining an industry certificate and provide vouchers to those who can accomplish a predefined set of tasks before a midpoint. The voucher recipients will use the voucher to access the industry certificate training materials and sit the certificate exam for free. Passing the certificate exam is one of the conditions for gaining an HD grade. Our survey and interviews reveal a substantial influence of voucher incentives on students' career aspirations. In light of the findings, recommendations on adopting voucher incentives in CSE or broader ICT education are offered for institutions and researchers.</description>
      <guid isPermaLink="false">oai:arXiv.org:2508.01520v1</guid>
      <category>cs.HC</category>
      <category>cs.CY</category>
      <pubDate>Tue, 05 Aug 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <arxiv:DOI>10.1007/978-3-031-82606-1_9</arxiv:DOI>
      <dc:creator>Jianhua Li, Shang Gao, Michelle Harvey, Trina Myers</dc:creator>
    </item>
    <item>
      <title>Authorship Attribution in Multilingual Machine-Generated Texts</title>
      <link>https://arxiv.org/abs/2508.01656</link>
      <description>arXiv:2508.01656v1 Announce Type: cross 
Abstract: As Large Language Models (LLMs) have reached human-like fluency and coherence, distinguishing machine-generated text (MGT) from human-written content becomes increasingly difficult. While early efforts in MGT detection have focused on binary classification, the growing landscape and diversity of LLMs require a more fine-grained yet challenging authorship attribution (AA), i.e., being able to identify the precise generator (LLM or human) behind a text. However, AA remains nowadays confined to a monolingual setting, with English being the most investigated one, overlooking the multilingual nature and usage of modern LLMs. In this work, we introduce the problem of Multilingual Authorship Attribution, which involves attributing texts to human or multiple LLM generators across diverse languages. Focusing on 18 languages -- covering multiple families and writing scripts -- and 8 generators (7 LLMs and the human-authored class), we investigate the multilingual suitability of monolingual AA methods, their cross-lingual transferability, and the impact of generators on attribution performance. Our results reveal that while certain monolingual AA methods can be adapted to multilingual settings, significant limitations and challenges remain, particularly in transferring across diverse language families, underscoring the complexity of multilingual AA and the need for more robust approaches to better match real-world scenarios.</description>
      <guid isPermaLink="false">oai:arXiv.org:2508.01656v1</guid>
      <category>cs.CL</category>
      <category>cs.AI</category>
      <category>cs.CY</category>
      <category>cs.HC</category>
      <category>physics.soc-ph</category>
      <pubDate>Tue, 05 Aug 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Lucio La Cava, Dominik Macko, R\'obert M\'oro, Ivan Srba, Andrea Tagarelli</dc:creator>
    </item>
    <item>
      <title>Complete Evasion, Zero Modification: PDF Attacks on AI Text Detection</title>
      <link>https://arxiv.org/abs/2508.01887</link>
      <description>arXiv:2508.01887v1 Announce Type: cross 
Abstract: AI-generated text detectors have become essential tools for maintaining content authenticity, yet their robustness against evasion attacks remains questionable. We present PDFuzz, a novel attack that exploits the discrepancy between visual text layout and extraction order in PDF documents. Our method preserves exact textual content while manipulating character positioning to scramble extraction sequences. We evaluate this approach against the ArguGPT detector using a dataset of human and AI-generated text. Our results demonstrate complete evasion: detector performance drops from (93.6 $\pm$ 1.4) % accuracy and 0.938 $\pm$ 0.014 F1 score to random-level performance ((50.4 $\pm$ 3.2) % accuracy, 0.0 F1 score) while maintaining perfect visual fidelity. Our work reveals a vulnerability in current detection systems that is inherent to PDF document structures and underscores the need for implementing sturdy safeguards against such attacks. We make our code publicly available at https://github.com/ACMCMC/PDFuzz.</description>
      <guid isPermaLink="false">oai:arXiv.org:2508.01887v1</guid>
      <category>cs.CR</category>
      <category>cs.AI</category>
      <category>cs.CL</category>
      <category>cs.CY</category>
      <pubDate>Tue, 05 Aug 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Aldan Creo</dc:creator>
    </item>
    <item>
      <title>Human Capital Visualization using Speech Amount during Meetings</title>
      <link>https://arxiv.org/abs/2508.02075</link>
      <description>arXiv:2508.02075v1 Announce Type: cross 
Abstract: In recent years, many companies have recognized the importance of human resources and are investing in human capital to revitalize their organizations and enhance internal communication, thereby fostering innovation. However, conventional quantification methods have mainly focused on readily measurable indicators without addressing the fundamental role of conversations in human capital. This study focuses on routine meetings and proposes strategies to visualize human capital by analyzing speech amount during these meetings. We employ conversation visualization technology, which operates effectively, to quantify speech. We then measure differences in speech amount by attributes such as gender and job post, changes in speech amount depending on whether certain participants are present, and correlations between speech amount and continuous attributes. To verify the effectiveness of our proposed methods, we analyzed speech amounts by departmental affiliation during weekly meetings at small to medium enterprises.</description>
      <guid isPermaLink="false">oai:arXiv.org:2508.02075v1</guid>
      <category>cs.HC</category>
      <category>cs.CL</category>
      <category>cs.CY</category>
      <pubDate>Tue, 05 Aug 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Ekai Hashimoto, Takeshi Mizumoto, Kohei Nagira, Shun Shiramatsu</dc:creator>
    </item>
    <item>
      <title>Stakeholder Perspectives on Humanistic Implementation of Computer Perception in Healthcare: A Qualitative Study</title>
      <link>https://arxiv.org/abs/2508.02550</link>
      <description>arXiv:2508.02550v1 Announce Type: cross 
Abstract: Computer perception (CP) technologies (digital phenotyping, affective computing and related passive sensing approaches) offer unprecedented opportunities to personalize healthcare, but provoke concerns about privacy, bias and the erosion of empathic, relationship-centered practice. A comprehensive understanding of perceived risks, benefits, and implementation challenges from those who design, deploy and experience these tools in real-world settings remains elusive. This study provides the first evidence-based account of key stakeholder perspectives on the relational, technical, and governance challenges raised by the integration of CP technologies into patient care. We conducted in-depth, semi-structured interviews with 102 stakeholders: adolescent patients and their caregivers, frontline clinicians, technology developers, and ethics, legal, policy or philosophy scholars. Transcripts underwent thematic analysis by a multidisciplinary team; reliability was enhanced through double coding and consensus adjudication. Stakeholders articulated seven interlocking concern domains: (1) trustworthiness and data integrity; (2) patient-specific relevance; (3) utility and workflow integration; (4) regulation and governance; (5) privacy and data protection; (6) direct and indirect patient harms; and (7) philosophical critiques of reductionism. To operationalize humanistic safeguards, we propose "personalized roadmaps": co-designed plans that predetermine which metrics will be monitored, how and when feedback is shared, thresholds for clinical action, and procedures for reconciling discrepancies between algorithmic inferences and lived experience. By translating these insights into personalized roadmaps, we offer a practical framework for developers, clinicians and policymakers seeking to harness continuous behavioral data while preserving the humanistic core of care.</description>
      <guid isPermaLink="false">oai:arXiv.org:2508.02550v1</guid>
      <category>cs.HC</category>
      <category>cs.AI</category>
      <category>cs.CY</category>
      <pubDate>Tue, 05 Aug 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Kristin M. Kostick-Quenet (Baylor College of Medicine, Houston, TX, 77030, USA), Meghan E. Hurley (Baylor College of Medicine, Houston, TX, 77030, USA), Syed Ayaz (Baylor College of Medicine, Houston, TX, 77030, USA), John Herrington (Children's Hospital of Philadelphia, Philadelphia, PA 19104, USA), Casey Zampella (Children's Hospital of Philadelphia, Philadelphia, PA 19104, USA), Julia Parish-Morris (Children's Hospital of Philadelphia, Philadelphia, PA 19104, USA), Birkan Tun\c{c} (Children's Hospital of Philadelphia, Philadelphia, PA 19104, USA), Gabriel L\'azaro-Mu\~noz (Massachussetts General Hospital, Boston, MA 02114, USA), J. S. Blumenthal-Barby (Baylor College of Medicine, Houston, TX, 77030, USA), Eric A. Storch (Baylor College of Medicine, Houston, TX, 77030, USA)</dc:creator>
    </item>
    <item>
      <title>Noosemia: toward a Cognitive and Phenomenological Account of Intentionality Attribution in Human-Generative AI Interaction</title>
      <link>https://arxiv.org/abs/2508.02622</link>
      <description>arXiv:2508.02622v1 Announce Type: cross 
Abstract: This paper introduces and formalizes Noosemia, a novel cognitive-phenomenological phenomenon emerging from human interaction with generative AI systems, particularly those enabling dialogic or multimodal exchanges. We propose a multidisciplinary framework to explain how, under certain conditions, users attribute intentionality, agency, and even interiority to these systems - a process grounded not in physical resemblance, but in linguistic performance, epistemic opacity, and emergent technological complexity. By linking an LLM declination of meaning holism to our technical notion of the LLM Contextual Cognitive Field, we clarify how LLMs construct meaning relationally and how coherence and a simulacrum of agency arise at the human-AI interface. The analysis situates noosemia alongside pareidolia, animism, the intentional stance and the uncanny valley, distinguishing its unique characteristics. We also introduce a-noosemia to describe the phenomenological withdrawal of such projections. The paper concludes with reflections on the broader philosophical, epistemological, and social implications of noosemic dynamics and directions for future research.</description>
      <guid isPermaLink="false">oai:arXiv.org:2508.02622v1</guid>
      <category>cs.AI</category>
      <category>cs.CL</category>
      <category>cs.CY</category>
      <pubDate>Tue, 05 Aug 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Enrico De Santis, Antonello Rizzi</dc:creator>
    </item>
    <item>
      <title>What Is Your AI Agent Buying? Evaluation, Implications and Emerging Questions for Agentic E-Commerce</title>
      <link>https://arxiv.org/abs/2508.02630</link>
      <description>arXiv:2508.02630v1 Announce Type: cross 
Abstract: Online marketplaces will be transformed by autonomous AI agents acting on behalf of consumers. Rather than humans browsing and clicking, vision-language-model (VLM) agents can parse webpages, evaluate products, and transact. This raises a fundamental question: what do AI agents buy, and why? We develop ACES, a sandbox environment that pairs a platform-agnostic VLM agent with a fully programmable mock marketplace to study this question. We first conduct basic rationality checks in the context of simple tasks, and then, by randomizing product positions, prices, ratings, reviews, sponsored tags, and platform endorsements, we obtain causal estimates of how frontier VLMs actually shop. Models show strong but heterogeneous position effects: all favor the top row, yet different models prefer different columns, undermining the assumption of a universal "top" rank. They penalize sponsored tags and reward endorsements. Sensitivities to price, ratings, and reviews are directionally human-like but vary sharply in magnitude across models. Motivated by scenarios where sellers use AI agents to optimize product listings, we show that a seller-side agent that makes minor tweaks to product descriptions, targeting AI buyer preferences, can deliver substantial market-share gains if AI-mediated shopping dominates. We also find that modal product choices can differ across models and, in some cases, demand may concentrate on a few select products, raising competition questions. Together, our results illuminate how AI agents may behave in e-commerce settings and surface concrete seller strategy, platform design, and regulatory questions in an AI-mediated ecosystem.</description>
      <guid isPermaLink="false">oai:arXiv.org:2508.02630v1</guid>
      <category>cs.AI</category>
      <category>cs.CY</category>
      <category>cs.HC</category>
      <category>cs.MA</category>
      <category>econ.GN</category>
      <category>q-fin.EC</category>
      <pubDate>Tue, 05 Aug 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Amine Allouah, Omar Besbes, Josu\'e D Figueroa, Yash Kanoria, Akshit Kumar</dc:creator>
    </item>
    <item>
      <title>Assessing Social Alignment: Do Personality-Prompted Large Language Models Behave Like Humans?</title>
      <link>https://arxiv.org/abs/2412.16772</link>
      <description>arXiv:2412.16772v3 Announce Type: replace 
Abstract: The ongoing revolution in language modeling has led to various novel applications, some of which rely on the emerging social abilities of large language models (LLMs). Already, many turn to the new cyber friends for advice during the pivotal moments of their lives and trust them with the deepest secrets, implying that accurate shaping of the LLM's personality is paramount. To this end, state-of-the-art approaches exploit a vast variety of training data, and prompt the model to adopt a particular personality. We ask (i) if personality-prompted models behave (i.e., make decisions when presented with a social situation) in line with the ascribed personality (ii) if their behavior can be finely controlled. We use classic psychological experiments, the Milgram experiment and the Ultimatum Game, as social interaction testbeds and apply personality prompting to open- and closed-source LLMs from 4 different vendors. Our experiments reveal failure modes of the prompt-based modulation of the models' behavior that are shared across all models tested and persist under prompt perturbations. These findings challenge the optimistic sentiment toward personality prompting generally held in the community.</description>
      <guid isPermaLink="false">oai:arXiv.org:2412.16772v3</guid>
      <category>cs.CY</category>
      <category>cs.AI</category>
      <category>cs.LG</category>
      <pubDate>Tue, 05 Aug 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Ivan Zakazov, Mikolaj Boronski, Lorenzo Drudi, Robert West</dc:creator>
    </item>
    <item>
      <title>Integrating Generative Artificial Intelligence in ADRD: A Roadmap for Streamlining Diagnosis and Care in Neurodegenerative Diseases</title>
      <link>https://arxiv.org/abs/2502.06842</link>
      <description>arXiv:2502.06842v3 Announce Type: replace 
Abstract: Healthcare systems are struggling to meet the growing demand for neurological care, particularly in Alzheimer's disease and related dementias (ADRD). We propose that LLM-based generative AI systems can enhance clinician capabilities to approach specialist-level assessment and decision-making in ADRD care at scale. This article presents a comprehensive six-phase roadmap for responsible design and integration of such systems into ADRD care: (1) high-quality standardized data collection across modalities; (2) decision support; (3) clinical integration enhancing workflows; (4) rigorous validation and monitoring protocols; (5) continuous learning through clinical feedback; and (6) robust ethics and risk management frameworks. This human centered approach optimizes clinicians' capabilities in comprehensive data collection, interpretation of complex clinical information, and timely application of relevant medical knowledge while prioritizing patient safety, healthcare equity, and transparency. Though focused on ADRD, these principles offer broad applicability across medical specialties facing similar systemic challenges.</description>
      <guid isPermaLink="false">oai:arXiv.org:2502.06842v3</guid>
      <category>cs.CY</category>
      <category>cs.AI</category>
      <pubDate>Tue, 05 Aug 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Andrew G. Breithaupt, Michael Weiner, Alice Tang, Katherine L. Possin, Marina Sirota, James Lah, Allan I. Levey, Pascal Van Hentenryck, Reza Zandehshahvar, Marilu Luisa Gorno-Tempini, Joseph Giorgio, Jingshen Wang, Andreas M. Rauschecker, Howard J. Rosen, Rachel L. Nosheny, Bruce L. Miller, Pedro Pinheiro-Chagas</dc:creator>
    </item>
    <item>
      <title>Three Kinds of AI Ethics</title>
      <link>https://arxiv.org/abs/2503.18842</link>
      <description>arXiv:2503.18842v3 Announce Type: replace 
Abstract: There is an overwhelming abundance of works in AI Ethics. This growth is chaotic because of how sudden it is, its volume, and its multidisciplinary nature. This makes difficult to keep track of debates, and to systematically characterize goals, research questions, methods, and expertise required by AI ethicists. In this article, I show that the relation between AI and ethics can be characterized in at least three ways, which correspond to three well-represented kinds of AI ethics: ethics and AI; ethics in AI; ethics of AI. I elucidate the features of these three kinds of AI Ethics, characterize their research questions, and identify the kind of expertise that each kind needs. I also show how certain criticisms to AI ethics are misplaced, as being done from the point of view of one kind of AI ethics, to another kind with different goals. All in all, this work sheds light on the nature of AI ethics, and sets the groundwork for more informed discussions about the scope, methods, and training of AI ethicists.</description>
      <guid isPermaLink="false">oai:arXiv.org:2503.18842v3</guid>
      <category>cs.CY</category>
      <category>cs.AI</category>
      <pubDate>Tue, 05 Aug 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Emanuele Ratti</dc:creator>
    </item>
    <item>
      <title>Exploring utilization of generative AI for research and education in data-driven materials science</title>
      <link>https://arxiv.org/abs/2504.08817</link>
      <description>arXiv:2504.08817v2 Announce Type: replace 
Abstract: Generative AI has recently had a profound impact on various fields, including daily life, research, and education. To explore its efficient utilization in data-driven materials science, we organized a hackathon -- AIMHack2024 -- in July 2024. In this hackathon, researchers from fields such as materials science, information science, bioinformatics, and condensed matter physics worked together to explore how generative AI can facilitate research and education. Based on the results of the hackathon, this paper presents topics related to (1) conducting AI-assisted software trials, (2) building AI tutors for software, and (3) developing GUI applications for software. While generative AI continues to evolve rapidly, this paper provides an early record of its application in data-driven materials science and highlights strategies for integrating AI into research and education.</description>
      <guid isPermaLink="false">oai:arXiv.org:2504.08817v2</guid>
      <category>cs.CY</category>
      <category>cs.AI</category>
      <category>cs.LG</category>
      <category>physics.ed-ph</category>
      <pubDate>Tue, 05 Aug 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Takahiro Misawa, Ai Koizumi, Ryo Tamura, Kazuyoshi Yoshimi</dc:creator>
    </item>
    <item>
      <title>The Cognitive Foundations of Economic Exchange: A Modular Framework Grounded in Behavioral Evidence</title>
      <link>https://arxiv.org/abs/2505.02945</link>
      <description>arXiv:2505.02945v4 Announce Type: replace 
Abstract: The origins of economic behavior remain unresolved-not only in the social sciences but also in AI, where dominant theories often rely on predefined incentives or institutional assumptions. Contrary to the longstanding myth of barter as the foundation of exchange, converging evidence from early human societies suggests that reciprocity-not barter-was the foundational economic logic, enabling communities to sustain exchange and social cohesion long before formal markets emerged. Yet despite its centrality, reciprocity lacks a simulateable and cognitively grounded account. Here, we introduce a minimal behavioral framework based on three empirically supported cognitive primitives-individual recognition, reciprocal credence, and cost--return sensitivity-that enable agents to participate in and sustain reciprocal exchange, laying the foundation for scalable economic behavior. These mechanisms scaffold the emergence of cooperation, proto-economic exchange, and institutional structure from the bottom up. By bridging insights from primatology, developmental psychology, and economic anthropology, this framework offers a unified substrate for modeling trust, coordination, and economic behavior in both human and artificial systems. For an interactive visualization of the framework, see: https://egil158.github.io/cogfoundations-econ/</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.02945v4</guid>
      <category>cs.CY</category>
      <category>cs.AI</category>
      <category>cs.MA</category>
      <category>econ.GN</category>
      <category>q-bio.NC</category>
      <category>q-fin.EC</category>
      <pubDate>Tue, 05 Aug 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Egil Diau</dc:creator>
    </item>
    <item>
      <title>Catching Dark Signals in Algorithms: Unveiling Audiovisual and Thematic Markers of Unsafe Content Recommended for Children and Teenagers</title>
      <link>https://arxiv.org/abs/2507.12571</link>
      <description>arXiv:2507.12571v2 Announce Type: replace 
Abstract: The prevalence of short form video platforms, combined with the ineffectiveness of age verification mechanisms, raises concerns about the potential harms facing children and teenagers in an algorithm-moderated online environment. We conducted multimodal feature analysis and thematic topic modeling of 4,492 short videos recommended to children and teenagers on Instagram Reels, TikTok, and YouTube Shorts, collected as a part of an algorithm auditing experiment. This feature-level and content-level analysis revealed that unsafe (i.e., problematic, mentally distressing) short videos (a) possess darker visual features and (b) contain explicitly harmful content and implicit harm from anxiety-inducing ordinary content. We introduce a useful framework of online harm (i.e., explicit, implicit, unintended), providing a unique lens for understanding the dynamic, multifaceted online risks facing children and teenagers. The findings highlight the importance of protecting younger audiences in critical developmental stages from both explicit and implicit risks on social media, calling for nuanced content moderation, age verification, and platform regulation.</description>
      <guid isPermaLink="false">oai:arXiv.org:2507.12571v2</guid>
      <category>cs.CY</category>
      <category>cs.MM</category>
      <pubDate>Tue, 05 Aug 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Haoning Xue, Brian Nishimine, Martin Hilbert, Drew Cingel, Samantha Vigil, Jane Shawcroft, Arti Thakur, Zubair Shafiq, Jingwen Zhang</dc:creator>
    </item>
    <item>
      <title>Combining Cost-Constrained Runtime Monitors for AI Safety</title>
      <link>https://arxiv.org/abs/2507.15886</link>
      <description>arXiv:2507.15886v2 Announce Type: replace 
Abstract: Monitoring AIs at runtime can help us detect and stop harmful actions. In this paper, we study how to combine multiple runtime monitors into a single monitoring protocol. The protocol's objective is to maximize the probability of applying a safety intervention on misaligned outputs (i.e., maximize recall). Since running monitors and applying safety interventions are costly, the protocol also needs to adhere to an average-case budget constraint. Taking the monitors' performance and cost as given, we develop an algorithm to find the most efficient protocol. The algorithm exhaustively searches over when and which monitors to call, and allocates safety interventions based on the Neyman-Pearson lemma. By focusing on likelihood ratios and strategically trading off spending on monitors against spending on interventions, we more than double our recall rate compared to a naive baseline in a code review setting. We also show that combining two monitors can Pareto dominate using either monitor alone. Our framework provides a principled methodology for combining existing monitors to detect undesirable behavior in cost-sensitive settings.</description>
      <guid isPermaLink="false">oai:arXiv.org:2507.15886v2</guid>
      <category>cs.CY</category>
      <category>cs.AI</category>
      <pubDate>Tue, 05 Aug 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Tim Tian Hua, James Baskerville, Henri Lemoine, Mia Hopman, Aryan Bhatt, Tyler Tracy</dc:creator>
    </item>
    <item>
      <title>The Xeno Sutra: Can Meaning and Value be Ascribed to an AI-Generated "Sacred" Text?</title>
      <link>https://arxiv.org/abs/2507.20525</link>
      <description>arXiv:2507.20525v3 Announce Type: replace 
Abstract: This paper presents a case study in the use of a large language model to generate a fictional Buddhist "sutra"', and offers a detailed analysis of the resulting text from a philosophical and literary point of view. The conceptual subtlety, rich imagery, and density of allusion found in the text make it hard to causally dismiss on account of its mechanistic origin. This raises questions about how we, as a society, should come to terms with the potentially unsettling possibility of a technology that encroaches on human meaning-making. We suggest that Buddhist philosophy, by its very nature, is well placed to adapt.</description>
      <guid isPermaLink="false">oai:arXiv.org:2507.20525v3</guid>
      <category>cs.CY</category>
      <category>cs.AI</category>
      <pubDate>Tue, 05 Aug 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Murray Shanahan, Tara Das, Robert Thurman</dc:creator>
    </item>
    <item>
      <title>Can Memory-Augmented LLM Agents Aid Journalism in Interpreting and Framing News for Diverse Audiences?</title>
      <link>https://arxiv.org/abs/2507.21055</link>
      <description>arXiv:2507.21055v2 Announce Type: replace 
Abstract: Modern news is often comprehensive, weaving together information from diverse domains, including technology, finance, and agriculture. This very comprehensiveness creates a challenge for interpretation, as audiences typically possess specialized knowledge related to their expertise, age, or standpoint. Consequently, a reader might fully understand the financial implications of a story but fail to grasp or even actively misunderstand its legal or technological dimensions, resulting in critical comprehension gaps. In this work, we investigate how to identify these comprehension gaps and provide solutions to improve audiences' understanding of news content, particularly in the aspects of articles outside their primary domains of knowledge. We propose MADES, an agent-based framework designed to simulate societal communication. The framework utilizes diverse agents, each configured to represent a specific occupation or age group. Each agent is equipped with a memory system. These agents are then simulated to discuss the news. This process enables us to monitor and analyze their behavior and cognitive processes. Our findings indicate that the framework can identify confusions and misunderstandings within news content through its iterative discussion process. Based on these accurate identifications, the framework then designs supplementary material. We validated these outcomes using both statistical analysis and human evaluation, and the results show that agents exhibit significantly improved news understanding after receiving this supplementary material.</description>
      <guid isPermaLink="false">oai:arXiv.org:2507.21055v2</guid>
      <category>cs.CY</category>
      <category>cs.AI</category>
      <category>cs.SI</category>
      <pubDate>Tue, 05 Aug 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Leyi Ouyang</dc:creator>
    </item>
    <item>
      <title>Green Computing: The Ultimate Carbon Destroyer for a Sustainable Future</title>
      <link>https://arxiv.org/abs/2508.00153</link>
      <description>arXiv:2508.00153v2 Announce Type: replace 
Abstract: Green computing represents a critical pathway to decarbonize the digital economy while maintaining technological progress. This article examines how sustainable IT strategies including energy-efficient hardware, AI-optimized data centres, and circular e-waste systems can transform computing into a net carbon sink. Through analysis of industry best practices and emerging technologies like quantum computing and biodegradable electronics, we demonstrate achievable reductions of 40-60% in energy consumption without compromising performance. The study highlights three key findings: (1) current solutions already deliver both environmental and economic benefits, with typical payback periods of 3-5 years; (2) systemic barriers including cost premiums and policy fragmentation require coordinated action; and (3) next-generation innovations promise order-of-magnitude improvements in efficiency. We present a practical framework for stakeholders from corporations adopting renewable-powered cloud services to individuals extending device lifespans to accelerate the transition. The research underscores computing's unique potential as a climate solution through its rapid innovation cycles and measurable impacts, concluding that strategic investments in green IT today can yield disproportionate sustainability dividends across all sectors tomorrow. This work provides both a compelling case for urgent action and a clear roadmap to realize computing's potential as a powerful carbon destruction tool in the climate crisis era.</description>
      <guid isPermaLink="false">oai:arXiv.org:2508.00153v2</guid>
      <category>cs.CY</category>
      <category>cs.SC</category>
      <pubDate>Tue, 05 Aug 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <dc:creator>Sayed Mahbub Hasan Amiri, Prasun Goswami, Md. Mainul Islam, Mohammad Shakhawat Hossen, Marzana Mithila, Naznin Akter</dc:creator>
    </item>
    <item>
      <title>Beyond Images: Adaptive Fusion of Visual and Textual Data for Food Classification</title>
      <link>https://arxiv.org/abs/2308.02562</link>
      <description>arXiv:2308.02562v3 Announce Type: replace-cross 
Abstract: This study introduces a novel multimodal food recognition framework that effectively combines visual and textual modalities to enhance classification accuracy and robustness. The proposed approach employs a dynamic multimodal fusion strategy that adaptively integrates features from unimodal visual inputs and complementary textual metadata. This fusion mechanism is designed to maximize the use of informative content, while mitigating the adverse impact of missing or inconsistent modality data. The framework was rigorously evaluated on the UPMC Food-101 dataset and achieved unimodal classification accuracies of 73.60% for images and 88.84% for text. When both modalities were fused, the model achieved an accuracy of 97.84%, outperforming several state-of-the-art methods. Extensive experimental analysis demonstrated the robustness, adaptability, and computational efficiency of the proposed settings, highlighting its practical applicability to real-world multimodal food-recognition scenarios.</description>
      <guid isPermaLink="false">oai:arXiv.org:2308.02562v3</guid>
      <category>cs.CV</category>
      <category>cs.AI</category>
      <category>cs.CY</category>
      <category>cs.LG</category>
      <pubDate>Tue, 05 Aug 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Prateek Mittal, Puneet Goyal, Joohi Chauhan</dc:creator>
    </item>
    <item>
      <title>AdapFair: Ensuring Adaptive Fairness for Machine Learning Operations</title>
      <link>https://arxiv.org/abs/2409.15088</link>
      <description>arXiv:2409.15088v2 Announce Type: replace-cross 
Abstract: The biases and discrimination of machine learning algorithms have attracted significant attention, leading to the development of various algorithms tailored to specific contexts. However, these solutions often fall short of addressing fairness issues inherent in machine learning operations. In this paper, we present an adaptive debiasing framework designed to find an optimal fair transformation of input data that maximally preserves data predictability under dynamic conditions. A distinctive feature of our approach is its flexibility and efficiency. It can be integrated with pretrained black-box classifiers, providing fairness guarantees with minimal retraining efforts, even in the face of frequent data drifts, evolving fairness requirements, and batches of similar tasks. To achieve this, we leverage the normalizing flows to enable efficient, information-preserving data transformation, ensuring that no critical information is lost during the debiasing process. Additionally, we incorporate the Wasserstein distance as the fairness measure to guide the optimization of data transformations. Finally, we introduce an efficient optimization algorithm with closed-formed gradient computations, making our framework scalable and suitable for dynamic, real-world environments.</description>
      <guid isPermaLink="false">oai:arXiv.org:2409.15088v2</guid>
      <category>cs.LG</category>
      <category>cs.CY</category>
      <pubDate>Tue, 05 Aug 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Yinghui Huang, Zihao Tang, Xiangyu Chang</dc:creator>
    </item>
    <item>
      <title>A Guide to Misinformation Detection Data and Evaluation</title>
      <link>https://arxiv.org/abs/2411.05060</link>
      <description>arXiv:2411.05060v5 Announce Type: replace-cross 
Abstract: Misinformation is a complex societal issue, and mitigating solutions are difficult to create due to data deficiencies. To address this, we have curated the largest collection of (mis)information datasets in the literature, totaling 75. From these, we evaluated the quality of 36 datasets that consist of statements or claims, as well as the 9 datasets that consist of data in purely paragraph form. We assess these datasets to identify those with solid foundations for empirical work and those with flaws that could result in misleading and non-generalizable results, such as spurious correlations, or examples that are ambiguous or otherwise impossible to assess for veracity. We find the latter issue is particularly severe and affects most datasets in the literature. We further provide state-of-the-art baselines on all these datasets, but show that regardless of label quality, categorical labels may no longer give an accurate evaluation of detection model performance. Finally, we propose and highlight Evaluation Quality Assurance (EQA) as a tool to guide the field toward systemic solutions rather than inadvertently propagating issues in evaluation. Overall, this guide aims to provide a roadmap for higher quality data and better grounded evaluations, ultimately improving research in misinformation detection. All datasets and other artifacts are available at https://misinfo-datasets.complexdatalab.com/.</description>
      <guid isPermaLink="false">oai:arXiv.org:2411.05060v5</guid>
      <category>cs.SI</category>
      <category>cs.CL</category>
      <category>cs.CY</category>
      <pubDate>Tue, 05 Aug 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Camille Thibault, Jacob-Junqi Tian, Gabrielle Peloquin-Skulski, Taylor Lynn Curtis, James Zhou, Florence Laflamme, Yuxiang Guan, Reihaneh Rabbany, Jean-Fran\c{c}ois Godbout, Kellin Pelrine</dc:creator>
    </item>
    <item>
      <title>Speak Easy: Eliciting Harmful Jailbreaks from LLMs with Simple Interactions</title>
      <link>https://arxiv.org/abs/2502.04322</link>
      <description>arXiv:2502.04322v3 Announce Type: replace-cross 
Abstract: Despite extensive safety alignment efforts, large language models (LLMs) remain vulnerable to jailbreak attacks that elicit harmful behavior. While existing studies predominantly focus on attack methods that require technical expertise, two critical questions remain underexplored: (1) Are jailbroken responses truly useful in enabling average users to carry out harmful actions? (2) Do safety vulnerabilities exist in more common, simple human-LLM interactions? In this paper, we demonstrate that LLM responses most effectively facilitate harmful actions when they are both actionable and informative--two attributes easily elicited in multi-step, multilingual interactions. Using this insight, we propose HarmScore, a jailbreak metric that measures how effectively an LLM response enables harmful actions, and Speak Easy, a simple multi-step, multilingual attack framework. Notably, by incorporating Speak Easy into direct request and jailbreak baselines, we see an average absolute increase of 0.319 in Attack Success Rate and 0.426 in HarmScore in both open-source and proprietary LLMs across four safety benchmarks. Our work reveals a critical yet often overlooked vulnerability: Malicious users can easily exploit common interaction patterns for harmful intentions.</description>
      <guid isPermaLink="false">oai:arXiv.org:2502.04322v3</guid>
      <category>cs.LG</category>
      <category>cs.AI</category>
      <category>cs.CL</category>
      <category>cs.CY</category>
      <pubDate>Tue, 05 Aug 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Yik Siu Chan, Narutatsu Ri, Yuxin Xiao, Marzyeh Ghassemi</dc:creator>
    </item>
    <item>
      <title>Robustness tests for biomedical foundation models should tailor to specifications</title>
      <link>https://arxiv.org/abs/2502.10374</link>
      <description>arXiv:2502.10374v2 Announce Type: replace-cross 
Abstract: The rise of biomedical foundation models creates new hurdles in model testing and authorization given their broad capabilities and susceptibility to complex distribution shifts. We suggest tailoring robustness tests according to task-dependent priorities and propose to integrate granular notions of robustness in a predefined specification to guide implementation. Our approach facilitates the standardization of robustness assessments in the model lifecycle and connects abstract AI regulatory frameworks with concrete testing procedures.</description>
      <guid isPermaLink="false">oai:arXiv.org:2502.10374v2</guid>
      <category>cs.SE</category>
      <category>cs.CY</category>
      <pubDate>Tue, 05 Aug 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <dc:creator>R. Patrick Xian, Noah R. Baker, Tom David, Qiming Cui, A. Jay Holmgren, Stefan Bauer, Madhumita Sushil, Reza Abbasi-Asl</dc:creator>
    </item>
    <item>
      <title>Thinking Outside the (Gray) Box: A Context-Based Score for Assessing Value and Originality in Neural Text Generation</title>
      <link>https://arxiv.org/abs/2502.13207</link>
      <description>arXiv:2502.13207v2 Announce Type: replace-cross 
Abstract: Despite the increasing use of large language models for creative tasks, their outputs often lack diversity. Common solutions, such as sampling at higher temperatures, can compromise the quality of the results. Dealing with this trade-off is still an open challenge in designing AI systems for creativity. Drawing on information theory, we propose a context-based score to quantitatively evaluate value and originality. This score incentivizes accuracy and adherence to the request while fostering divergence from the learned distribution. We show that our score can be used as a reward in a reinforcement learning framework to fine-tune large language models for maximum performance. We validate our strategy through experiments considering a variety of creative tasks, such as poetry generation and math problem solving, demonstrating that it enhances the value and originality of the generated solutions.</description>
      <guid isPermaLink="false">oai:arXiv.org:2502.13207v2</guid>
      <category>cs.CL</category>
      <category>cs.AI</category>
      <category>cs.CY</category>
      <category>cs.LG</category>
      <pubDate>Tue, 05 Aug 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Giorgio Franceschelli, Mirco Musolesi</dc:creator>
    </item>
    <item>
      <title>MedGNN: Capturing the Links Between Urban Characteristics and Medical Prescriptions</title>
      <link>https://arxiv.org/abs/2504.04739</link>
      <description>arXiv:2504.04739v2 Announce Type: replace-cross 
Abstract: Understanding how urban socio-demographic and environmental factors relate with health is essential for public health and urban planning. However, traditional statistical methods struggle with nonlinear effects, while machine learning models often fail to capture geographical (nearby areas being more similar) and topological (unequal connectivity between places) effects in an interpretable way. To address this, we propose MedGNN, a spatio-topologically explicit framework that constructs a 2-hop spatial graph, integrating positional and locational node embeddings with urban characteristics in a graph neural network. Applied to MEDSAT, a comprehensive dataset covering over 150 environmental and socio-demographic factors and six prescription outcomes (depression, anxiety, diabetes, hypertension, asthma, and opioids) across 4,835 Greater London neighborhoods, MedGNN improved predictions by over 25% on average compared to baseline methods. Using depression prescriptions as a case study, we analyzed graph embeddings via geographical principal component analysis, identifying findings that: align with prior research (e.g., higher antidepressant prescriptions among older and White populations), contribute to ongoing debates (e.g., greenery linked to higher and NO2 to lower prescriptions), and warrant further study (e.g., canopy evaporation correlated with fewer prescriptions). These results demonstrate MedGNN's potential, and more broadly, of carefully applied machine learning, to advance transdisciplinary public health research.</description>
      <guid isPermaLink="false">oai:arXiv.org:2504.04739v2</guid>
      <category>cs.LG</category>
      <category>cs.CY</category>
      <pubDate>Tue, 05 Aug 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Minwei Zhao, Sanja Scepanovic, Stephen Law, Ivica Obadic, Cai Wu, Daniele Quercia</dc:creator>
    </item>
    <item>
      <title>Agree to Disagree? A Meta-Evaluation of LLM Misgendering</title>
      <link>https://arxiv.org/abs/2504.17075</link>
      <description>arXiv:2504.17075v2 Announce Type: replace-cross 
Abstract: Numerous methods have been proposed to measure LLM misgendering, including probability-based evaluations (e.g., automatically with templatic sentences) and generation-based evaluations (e.g., with automatic heuristics or human validation). However, it has gone unexamined whether these evaluation methods have convergent validity, that is, whether their results align. Therefore, we conduct a systematic meta-evaluation of these methods across three existing datasets for LLM misgendering. We propose a method to transform each dataset to enable parallel probability- and generation-based evaluation. Then, by automatically evaluating a suite of 6 models from 3 families, we find that these methods can disagree with each other at the instance, dataset, and model levels, conflicting on 20.2% of evaluation instances. Finally, with a human evaluation of 2400 LLM generations, we show that misgendering behaviour is complex and goes far beyond pronouns, which automatic evaluations are not currently designed to capture, suggesting essential disagreement with human evaluations. Based on our findings, we provide recommendations for future evaluations of LLM misgendering. Our results are also more widely relevant, as they call into question broader methodological conventions in LLM evaluation, which often assume that different evaluation methods agree.</description>
      <guid isPermaLink="false">oai:arXiv.org:2504.17075v2</guid>
      <category>cs.CL</category>
      <category>cs.CY</category>
      <pubDate>Tue, 05 Aug 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Arjun Subramonian, Vagrant Gautam, Preethi Seshadri, Dietrich Klakow, Kai-Wei Chang, Yizhou Sun</dc:creator>
    </item>
  </channel>
</rss>
