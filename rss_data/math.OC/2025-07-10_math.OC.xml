<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>math.OC updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/math.OC</link>
    <description>math.OC updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/math.OC" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Thu, 10 Jul 2025 04:00:45 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Thu, 10 Jul 2025 00:00:00 -0400</pubDate>
    <skipDays>
      <day>Saturday</day>
      <day>Sunday</day>
    </skipDays>
    <item>
      <title>Min-Max Optimization with Dual-Linear Coupling</title>
      <link>https://arxiv.org/abs/2507.06328</link>
      <description>arXiv:2507.06328v1 Announce Type: new 
Abstract: We study a class of convex-concave min-max problems in which the coupled component of the objective is linear in at least one of the two decision vectors. We identify such problem structure as interpolating between the bilinearly and nonbilinearly coupled problems, motivated by key applications in areas such as distributionally robust optimization and convex optimization with functional constraints. Leveraging the considered nonlinear-linear coupling of the primal and the dual decision vectors, we develop a general algorithmic framework leading to fine-grained complexity bounds exploiting separability properties of the problem, whenever present. The obtained complexity bounds offer potential improvements over state-of-the-art scaling with $\sqrt{n}$ or $n$ in some of the considered problem settings, which even include bilinearly coupled problems, where $n$ is the dimension of the dual decision vector. On the algorithmic front, our work provides novel strategies for combining randomization with extrapolation and multi-point anchoring in the mirror descent-style updates in the primal and the dual, which we hope will find further applications in addressing related optimization problems. %</description>
      <guid isPermaLink="false">oai:arXiv.org:2507.06328v1</guid>
      <category>math.OC</category>
      <pubDate>Thu, 10 Jul 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Ronak Mehta, Jelena Diakonikolas, Zaid Harchaoui</dc:creator>
    </item>
    <item>
      <title>Neural Actor-Critic Methods for Hamilton-Jacobi-Bellman PDEs: Asymptotic Analysis and Numerical Studies</title>
      <link>https://arxiv.org/abs/2507.06428</link>
      <description>arXiv:2507.06428v1 Announce Type: new 
Abstract: We mathematically analyze and numerically study an actor-critic machine learning algorithm for solving high-dimensional Hamilton-Jacobi-Bellman (HJB) partial differential equations from stochastic control theory. The architecture of the critic (the estimator for the value function) is structured so that the boundary condition is always perfectly satisfied (rather than being included in the training loss) and utilizes a biased gradient which reduces computational cost. The actor (the estimator for the optimal control) is trained by minimizing the integral of the Hamiltonian over the domain, where the Hamiltonian is estimated using the critic. We show that the training dynamics of the actor and critic neural networks converge in a Sobolev-type space to a certain infinite-dimensional ordinary differential equation (ODE) as the number of hidden units in the actor and critic $\rightarrow \infty$. Further, under a convexity-like assumption on the Hamiltonian, we prove that any fixed point of this limit ODE is a solution of the original stochastic control problem. This provides an important guarantee for the algorithm's performance in light of the fact that finite-width neural networks may only converge to a local minimizers (and not optimal solutions) due to the non-convexity of their loss functions. In our numerical studies, we demonstrate that the algorithm can solve stochastic control problems accurately in up to 200 dimensions. In particular, we construct a series of increasingly complex stochastic control problems with known analytic solutions and study the algorithm's numerical performance on them. These problems range from a linear-quadratic regulator equation to highly challenging equations with non-convex Hamiltonians, allowing us to identify and analyze the strengths and limitations of this neural actor-critic method for solving HJB equations.</description>
      <guid isPermaLink="false">oai:arXiv.org:2507.06428v1</guid>
      <category>math.OC</category>
      <category>cs.LG</category>
      <category>cs.NA</category>
      <category>math.NA</category>
      <category>stat.ML</category>
      <pubDate>Thu, 10 Jul 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Samuel N. Cohen, Jackson Hebner, Deqing Jiang, Justin Sirignano</dc:creator>
    </item>
    <item>
      <title>Distributed Optimization of Finite Condition Number for Laplacian Matrix in Multi-Agent Systems</title>
      <link>https://arxiv.org/abs/2507.06440</link>
      <description>arXiv:2507.06440v1 Announce Type: new 
Abstract: This paper addresses the distributed optimization of the finite condition number of the Laplacian matrix in multi-agent systems. The finite condition number, defined as the ratio of the largest to the second smallest eigenvalue of the Laplacian matrix, plays an important role in determining the convergence rate and performance of consensus algorithms, especially in discrete-time implementations. We propose a fully distributed algorithm by regulating the node weights. The approach leverages max consensus, distributed power iteration, and consensus-based normalization for eigenvalue and eigenvector estimation, requiring only local communication and computation. Simulation results demonstrate that the proposed method achieves performance comparable to centralized LMI-based optimization, significantly improving consensus speed and multi-agent system performance. The framework can be extended to edge weight optimization and the scenarios with non-simple eigenvalues, highlighting its scalability and practical applicability for large-scale networked systems.</description>
      <guid isPermaLink="false">oai:arXiv.org:2507.06440v1</guid>
      <category>math.OC</category>
      <category>cs.SY</category>
      <category>eess.SY</category>
      <pubDate>Thu, 10 Jul 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Yicheng Xu, Faryar Jabbari</dc:creator>
    </item>
    <item>
      <title>Relationship between Maximum Principle and Dynamic Programming Principle for Risk-Sensitive Stochastic Optimal Control Problems with Applications</title>
      <link>https://arxiv.org/abs/2507.06504</link>
      <description>arXiv:2507.06504v1 Announce Type: new 
Abstract: This paper is concerned with the relationship between maximum principle and dynamic programming principle for risk-sensitive stochastic optimal control problems. Under the smooth assumption of the value function, relations among the adjoint processes, the generalized Hamiltonian function, and the value function are given. As an application, a linear-quadratic risk-sensitive portfolio optimization problem in the financial market is discussed.</description>
      <guid isPermaLink="false">oai:arXiv.org:2507.06504v1</guid>
      <category>math.OC</category>
      <pubDate>Thu, 10 Jul 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/publicdomain/zero/1.0/</dc:rights>
      <dc:creator>Huanqing Dong, Jingtao Shi</dc:creator>
    </item>
    <item>
      <title>Real-time Optimization of Transport Chains for Single Wagon Load Railway Transport</title>
      <link>https://arxiv.org/abs/2507.06621</link>
      <description>arXiv:2507.06621v1 Announce Type: new 
Abstract: The freight branch of the Swiss national railways, SBB Cargo, offers customers to ship single or few wagons within its wagon load transportation system (WLV). In this system, wagons travel along a transport chain which is a sequence of consecutive trains. Recently, SBB Cargo redesigned its IT systems and renewed the computation of these transport chains. This paper describes the main design decisions and technical details: data structures, search algorithms, mathematical optimization of throughput in the real-time setting, and some selected details for making the algorithms work in the operational software. We also comment on the employed technology stack and finally demonstrate some performance metrics from running operations.</description>
      <guid isPermaLink="false">oai:arXiv.org:2507.06621v1</guid>
      <category>math.OC</category>
      <category>cs.DM</category>
      <pubDate>Thu, 10 Jul 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <arxiv:journal_reference>11th International Conference on Railway Operations Modelling and Analysis, RailDresden 2025</arxiv:journal_reference>
      <dc:creator>Carsten Moldenhauer, Philipp Germann, Cedric Heimhofer, Caroline Spieckermann, Andreas Andresen</dc:creator>
    </item>
    <item>
      <title>Nestorv's Accelerated Proximal Gradient Method with Backtracking for Multiobjective Optimization</title>
      <link>https://arxiv.org/abs/2507.06737</link>
      <description>arXiv:2507.06737v1 Announce Type: new 
Abstract: In this paper, we propose a novel extrapolation coefficient scheme within the Nesterov framework and develop an accelerated proximal gradient algorithm. We establish that the algorithm achieves a sublinear convergence rate. The proposed scheme only requires the Lipschitz constant estimate sequence to satisfy mild initial conditions, under which a key equality property can be derived to support the convergence analysis. Numerical experiments are provided to demonstrate the effectiveness and practical performance of the proposed method.</description>
      <guid isPermaLink="false">oai:arXiv.org:2507.06737v1</guid>
      <category>math.OC</category>
      <pubDate>Thu, 10 Jul 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Chengzhi Huang</dc:creator>
    </item>
    <item>
      <title>A derivative-free Levenberg-Marquardt method for sparse nonlinear least squares problems</title>
      <link>https://arxiv.org/abs/2507.06772</link>
      <description>arXiv:2507.06772v1 Announce Type: new 
Abstract: This paper studies sparse nonlinear least squares problems, where the Jacobian matrices are unavailable or expensive to compute, yet have some underlying sparse structures. We construct the Jacobian models by the $ \ell_1 $ minimization subject to a small number of interpolation constraints with interpolation points generated from some certain distributions,and propose a derivative-free Levenberg-Marquardt algorithm based on such Jacobian models.It is proved that the Jacobian models are probabilistically first-order accurate and the algorithm converges globally almost surely.Numerical experiments are presented to show the efficiency of the proposed algorithm for sparse nonlinear least squares problems.</description>
      <guid isPermaLink="false">oai:arXiv.org:2507.06772v1</guid>
      <category>math.OC</category>
      <pubDate>Thu, 10 Jul 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Yuchen Feng, Chuanlong Wang, Jinyan Fan</dc:creator>
    </item>
    <item>
      <title>Dynamic Output-Feedback Controller Synthesis for Dissipativity from Noisy Input-State Data</title>
      <link>https://arxiv.org/abs/2507.06788</link>
      <description>arXiv:2507.06788v1 Announce Type: new 
Abstract: In this paper we propose a dynamic output-feedback controller synthesis method for discrete-time linear time-invariant systems. The synthesis goal is to render closed-loop system dissipative with respect to a given generic unstructured quadratic supply rate, while the system dynamics is partially represented by input-state data corrupted by a bounded disturbance. The controller synthesis is performed with respect to all systems which are consistent with the available data, and it is formulated in terms of a linear matrix inequality parametrized by a scalar variable, so that the synthesis can be performed using line search and convex optimization. Within the considered setting, the proposed synthesis procedure is non-conservative in a sense that it is based on conditions which are both necessary and sufficient.</description>
      <guid isPermaLink="false">oai:arXiv.org:2507.06788v1</guid>
      <category>math.OC</category>
      <category>cs.SY</category>
      <category>eess.SY</category>
      <pubDate>Thu, 10 Jul 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Pietro Kristovi\'c, Andrej Joki\'c, Mircea Lazar</dc:creator>
    </item>
    <item>
      <title>Manifolds in Power Systems Optimization</title>
      <link>https://arxiv.org/abs/2507.06883</link>
      <description>arXiv:2507.06883v1 Announce Type: new 
Abstract: Manifold optimization (MO) is a powerful mathematical framework that can be applied to solving complex optimization problems with objective functions (OFs) and constraints on complex geometric structures, which is particularly useful in advanced power systems. We explore the application of MO techniques, which offer a robust framework for solving complex, non-convex optimization problems in electrical power distribution systems (EPDS) and electrical power transmission systems (EPTS), particularly for power flow analysis. This paper introduces the principles of MO and demonstrates its advantages over conventional methods by applying it to power flow optimization. For EPDS, a cost function derived from a backward-forward sweep (BFS) algorithm is optimized using the Manopt toolbox, yielding high accuracy and competitive computational times on 14-bus, 33-bus, and 69-bus systems when compared to established solvers. Similarly, for EPTS, MO applied via Manopt to 3-bus and 4-bus systems effectively solves power flow equations, matching traditional methods such as Newton-Raphson in performance. The study highlights that tools such as Manopt can mitigate implementation complexities, positioning MO as an efficient and accessible tool for power system analysis and potentially broader planning applications. The paper provides a comprehensive tutorial on MO, detailing its theoretical foundations, practical methodologies, and specific applications in power systems, particularly in power flow optimization.</description>
      <guid isPermaLink="false">oai:arXiv.org:2507.06883v1</guid>
      <category>math.OC</category>
      <category>cs.SY</category>
      <category>eess.SY</category>
      <category>stat.AP</category>
      <pubDate>Thu, 10 Jul 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Lucca Rodrigues Pinto, Wilson de Souza Junior, Jaime Laelson Jacob, Luis Alfonso Gallego Pareja, Taufik Abr\~ao</dc:creator>
    </item>
    <item>
      <title>Strength of the Upper Bounds for the Edge-Weighted Maximum Clique Problem</title>
      <link>https://arxiv.org/abs/2507.06898</link>
      <description>arXiv:2507.06898v1 Announce Type: new 
Abstract: We theoretically and computationally compare the strength of the two main upper bounds from the literature on the optimal value of the Edge-Weighted Maximum Clique Problem (EWMCP). We provide a set of instances for which the ratio between either of the two upper bounds and the optimal value of the EWMCP is unbounded. This result shows that neither of the two upper bounds can give a performance guarantee. In addition, we provide two sets of instances for which the ratio between the two upper bounds, and its reciprocal, are unbounded. This result shows that there are EWMCP instances in which one of the upper bounds can be arbitrarily better than the other one and vice versa. Our theoretical analysis is complemented by extensive computational experiments on two benchmark datasets: the standard DIMACS instances and randomly generated instances, providing practical insights into the empirical strength of the upper bounds.</description>
      <guid isPermaLink="false">oai:arXiv.org:2507.06898v1</guid>
      <category>math.OC</category>
      <category>math.CO</category>
      <pubDate>Thu, 10 Jul 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Fabio Ciccarelli, Valerio Dose, Fabio Furini, Marta Monaci</dc:creator>
    </item>
    <item>
      <title>Sample-Based Consistency in Infinite-Dimensional Conic-Constrained Stochastic Optimization</title>
      <link>https://arxiv.org/abs/2507.06982</link>
      <description>arXiv:2507.06982v1 Announce Type: new 
Abstract: This paper is concerned with a class of stochastic optimization problems defined on a Banach space with almost sure conic-type constraints. For this class of problems, we investigate the consistency of optimal values and solutions corresponding to sample average approximation. Consistency is also shown in the case where a Moreau--Yosida-type regularization of the constraint is used. Additionally, the consistency of Karush--Kuhn--Tucker conditions is shown under mild conditions. This work provides theoretical justification for the numerical computation of solutions frequently used in the literature. Several applications are explored showing the flexibility of the framework.</description>
      <guid isPermaLink="false">oai:arXiv.org:2507.06982v1</guid>
      <category>math.OC</category>
      <pubDate>Thu, 10 Jul 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Caroline Geiersbach, Johannes Milz</dc:creator>
    </item>
    <item>
      <title>Robust signal decompositions on the circle</title>
      <link>https://arxiv.org/abs/2507.07007</link>
      <description>arXiv:2507.07007v1 Announce Type: new 
Abstract: We consider the problem of decomposing a piecewise constant function on the circle into a sum of indicator functions of closed circular disks in the plane, whose number and location are not a priori known. This represents a situation where an agent moving on the circle is able to sense its proximity to some landmarks, and the goal is to estimate the number of these landmarks and their possible locations -- which can in turn enable control tasks such as motion planning and obstacle avoidance. Moreover, the exact values of the function at its discontinuities (which correspond to disk boundaries for the individual indicator functions) are not assumed to be known to the agent. We introduce suitable notions of robustness and degrees of freedom to single out those decompositions that are more desirable, or more likely, given this non-precise data collected by the agent. We provide a characterization of robust decompositions and give a procedure for generating all such decompositions. When the given function admits a robust decomposition, we compute the number of possible robust decompositions and derive bounds for the number of decompositions maximizing the degrees of freedom.</description>
      <guid isPermaLink="false">oai:arXiv.org:2507.07007v1</guid>
      <category>math.OC</category>
      <pubDate>Thu, 10 Jul 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Aral Kose, Daniel Liberzon</dc:creator>
    </item>
    <item>
      <title>Portfolio optimization in incomplete markets and price constraints determined by maximum entropy in the mean</title>
      <link>https://arxiv.org/abs/2507.07053</link>
      <description>arXiv:2507.07053v1 Announce Type: new 
Abstract: A solution to a portfolio optimization problem is always conditioned by constraints on the initial capital and the price of the available market assets. If a risk neutral measure is known, then the price of each asset is the discounted expected value of the asset's price under this measure. But if the market is incomplete, the risk neutral measure is not unique, and there is a range of possible prices for each asset, which can be identified with bid-ask ranges. We present in this paper an effective method to determine the current prices of a collection of assets in incomplete markets, and such that these prices comply with the cost constraints for a portfolio optimization problem. Our workhorse is the method of maximum entropy in the mean to adjust a distortion function from bid-ask market data. This distortion function plays the role of a risk neutral measure, which is used to price the assets, and the distorted probability that it determines reproduces bid-ask market values. We carry out numerical examples to study the effect on portfolio returns of the computation of prices of the assets conforming the portfolio with the proposed methodology.</description>
      <guid isPermaLink="false">oai:arXiv.org:2507.07053v1</guid>
      <category>math.OC</category>
      <category>q-fin.CP</category>
      <category>q-fin.PM</category>
      <category>q-fin.RM</category>
      <pubDate>Thu, 10 Jul 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <arxiv:DOI>10.1007/s10614-019-09954-3</arxiv:DOI>
      <arxiv:journal_reference>Computational Economics, 56, 929-952 (2020)</arxiv:journal_reference>
      <dc:creator>Argimiro Arratia, Henryk Gzyl</dc:creator>
    </item>
    <item>
      <title>Mathematical Modelling of Oscillatory Dynamics in Circular Traffic Systems</title>
      <link>https://arxiv.org/abs/2507.06702</link>
      <description>arXiv:2507.06702v1 Announce Type: cross 
Abstract: This paper presents a rigorous analytical model of traffic dynamics on a circular track, demonstrating the emergence of standing oscillations resulting from microscopic driver behaviour, delay responses, and proximity pressure. Without relying on simulation, we derive a series of coupled delay differential equations to model vehicular interactions. By introducing a mnemonic-based symbolic system, we establish a mathematical framework incorporating stochastic initial conditions, non-uniform reaction times, and cognitive lag. A full linear stability analysis is conducted using Fourier decomposition and modal perturbation techniques. Our results identify critical thresholds for harmonic induction, delineate the bounds of safe following distances, and reveal hysteresis in driver overcorrection. The analysis concludes with implications for autonomous vehicle control and potential suppression strategies for oscillatory instability. All derivations are purely symbolic and analytically proven.</description>
      <guid isPermaLink="false">oai:arXiv.org:2507.06702v1</guid>
      <category>nlin.AO</category>
      <category>cs.SY</category>
      <category>eess.SY</category>
      <category>math.DS</category>
      <category>math.OC</category>
      <category>physics.soc-ph</category>
      <pubDate>Thu, 10 Jul 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <dc:creator>Craig S Wright</dc:creator>
    </item>
    <item>
      <title>Fast Equivariant Imaging: Acceleration for Unsupervised Learning via Augmented Lagrangian and Auxiliary PnP Denoisers</title>
      <link>https://arxiv.org/abs/2507.06764</link>
      <description>arXiv:2507.06764v1 Announce Type: cross 
Abstract: We propose Fast Equivariant Imaging (FEI), a novel unsupervised learning framework to efficiently train deep imaging networks without ground-truth data. From the perspective of reformulating the Equivariant Imaging based optimization problem via the method of Lagrange multipliers and utilizing plug-and-play denoisers, this novel unsupervised scheme shows superior efficiency and performance compared to vanilla Equivariant Imaging paradigm. In particular, our PnP-FEI scheme achieves an order-of-magnitude (10x) acceleration over standard EI on training U-Net with CT100 dataset for X-ray CT reconstruction, with improved generalization performance.</description>
      <guid isPermaLink="false">oai:arXiv.org:2507.06764v1</guid>
      <category>eess.IV</category>
      <category>cs.CV</category>
      <category>cs.LG</category>
      <category>math.OC</category>
      <pubDate>Thu, 10 Jul 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Guixian Xu, Jinglai Li, Junqi Tang</dc:creator>
    </item>
    <item>
      <title>Constraint Optimized Multichannel Mixer-limiter Design</title>
      <link>https://arxiv.org/abs/2507.06769</link>
      <description>arXiv:2507.06769v1 Announce Type: cross 
Abstract: Multichannel audio mixer and limiter designs are conventionally decoupled for content reproduction over loudspeaker arrays due to high computational complexity and run-time costs. We propose a coupled mixer-limiter-envelope design formulated as an efficient linear-constrained quadratic program that minimizes a distortion objective over multichannel gain variables subject to sample mixture constraints. Novel methods for asymmetric constant overlap-add window optimization, objective function approximation, variable and constraint reduction are presented. Experiments demonstrate distortion reduction of the coupled design, and computational trade-offs required for efficient real-time processing.</description>
      <guid isPermaLink="false">oai:arXiv.org:2507.06769v1</guid>
      <category>cs.SD</category>
      <category>eess.AS</category>
      <category>eess.SP</category>
      <category>math.OC</category>
      <pubDate>Thu, 10 Jul 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Yuancheng Luo, Dmitriy Yamkovoy, Guillermo Garcia</dc:creator>
    </item>
    <item>
      <title>Designing Robust Software Sensors for Nonlinear Systems via Neural Networks and Adaptive Sliding Mode Control</title>
      <link>https://arxiv.org/abs/2507.06817</link>
      <description>arXiv:2507.06817v1 Announce Type: cross 
Abstract: Accurate knowledge of the state variables in a dynamical system is critical for effective control, diagnosis, and supervision, especially when direct measurements of all states are infeasible. This paper presents a novel approach to designing software sensors for nonlinear dynamical systems expressed in their most general form. Unlike traditional model-based observers that rely on explicit transformations or linearization, the proposed framework integrates neural networks with adaptive Sliding Mode Control (SMC) to design a robust state observer under a less restrictive set of conditions. The learning process is driven by available sensor measurements, which are used to correct the observer's state estimate. The training methodology leverages the system's governing equations as a physics-based constraint, enabling observer synthesis without access to ground-truth state trajectories. By employing a time-varying gain matrix dynamically adjusted by the neural network, the observer adapts in real-time to system changes, ensuring robustness against noise, external disturbances, and variations in system dynamics. Furthermore, we provide sufficient conditions to guarantee estimation error convergence, establishing a theoretical foundation for the observer's reliability. The methodology's effectiveness is validated through simulations on challenging examples, including systems with non-differentiable dynamics and varying observability conditions. These examples, which are often problematic for conventional techniques, serve to demonstrate the robustness and broad applicability of our approach. The results show rapid convergence and high accuracy, underscoring the method's potential for addressing complex state estimation challenges in real-world applications.</description>
      <guid isPermaLink="false">oai:arXiv.org:2507.06817v1</guid>
      <category>math.DS</category>
      <category>cs.LG</category>
      <category>cs.NE</category>
      <category>math.OC</category>
      <pubDate>Thu, 10 Jul 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Ayoub Farkane, Mohamed Boutayeb, Mustapha Oudani, Mounir Ghogho</dc:creator>
    </item>
    <item>
      <title>The Integrality Gap of the Traveling Salesman Problem is $4/3$ if the LP Solution Has at Most $n+6$ Non-zero Components</title>
      <link>https://arxiv.org/abs/2507.07003</link>
      <description>arXiv:2507.07003v1 Announce Type: cross 
Abstract: In this paper, we address the classical Dantzig-Fulkerson-Johnson formulation of the metric Traveling Salesman Problem and study the integrality gap of its linear relaxation, namely the Subtour Elimination Problem (SEP). This integrality gap is conjectured to be $4/3$. We prove that, when solving a problem on $n$ nodes, if the optimal SEP solution has at most $n+6$ non-zero components, then the conjecture is true. To establish this result, we consider, for a given integer $k$, the infinite family $F_k$ which gathers, among all the vertices of all the SEP polytopes for $n \in \mathbb{N}$, the ones with exactly $n+k$ non-zero components. Then, we introduce a procedure that reduces the description of $F_k$ to a finite set, and we present the Gap-Bounding algorithm, which provides provable upper bounds on the integrality gap for entire families $F_k$. The application of the Gap-Bounding algorithm for $k \leq 6$ yields a computer-aided proof that the conjectured bound holds in this case.</description>
      <guid isPermaLink="false">oai:arXiv.org:2507.07003v1</guid>
      <category>cs.DM</category>
      <category>math.OC</category>
      <pubDate>Thu, 10 Jul 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Tullio Villa, Eleonora Vercesi, Janos Barta, Monaldo Mastrolilli</dc:creator>
    </item>
    <item>
      <title>Extremal problems for clamped plates under tension</title>
      <link>https://arxiv.org/abs/2507.07040</link>
      <description>arXiv:2507.07040v1 Announce Type: cross 
Abstract: We address extremum problems for spectral quantities associated with operators of the form $\Delta^2-\tau\Delta$ with Dirichlet boundary conditions, for non-negative values of $\tau$. The focus is on two shape optimisation problems: minimising the first eigenvalue; and maximising the torsional rigidity, both under volume constraint. We establish, on the one hand, a Szeg\H{o}-type inequality, that is, we show that among all domains having a first eigenfunction of fixed sign the ball minimises the corresponding first eigenvalue; on the other hand a Saint--Venant-type inequality, namely, a sharp upper bound on the torsional rigidity, again achieved by the ball. We further present other properties related to these operators and express the optimality condition associated with the minimisation of the first eigenvalue.</description>
      <guid isPermaLink="false">oai:arXiv.org:2507.07040v1</guid>
      <category>math.AP</category>
      <category>math.OC</category>
      <pubDate>Thu, 10 Jul 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Pedro Freitas, Rom\'eo Leylekian</dc:creator>
    </item>
    <item>
      <title>Proximal Oracles for Optimization and Sampling</title>
      <link>https://arxiv.org/abs/2404.02239</link>
      <description>arXiv:2404.02239v2 Announce Type: replace 
Abstract: We consider convex optimization with non-smooth objective function and log-concave sampling with non-smooth potential (negative log density). In particular, we study two specific settings where the convex objective/potential function is either H\"older smooth or in hybrid form as the finite sum of H\"older smooth components. To overcome the challenges caused by non-smoothness, our algorithms employ two powerful proximal frameworks in optimization and sampling: the proximal point framework for optimization and the alternating sampling framework (ASF) that uses Gibbs sampling on an augmented distribution. A key component of both optimization and sampling algorithms is the efficient implementation of the proximal map by the regularized cutting-plane method. We establish its iteration-complexity under both H\"older smoothness and hybrid settings using novel convergence analysis, yielding results that are new to the literature. We further propose an adaptive proximal bundle method for non-smooth optimization that employs an aggressive adaptive stepsize strategy, which adjusts stepsizes only when necessary and never rejects iterates. The proposed method is universal since it does not need any problem parameters as input. Additionally, we provide an exact implementation of a proximal sampling oracle, analogous to the proximal map in optimization, along with simple complexity analyses for both the H\"older smooth and hybrid cases, using a novel technique based on a modified Gaussian integral. Finally, we combine this proximal sampling oracle and ASF to obtain a Markov chain Monte Carlo method with non-asymptotic complexity bounds for sampling in H\"older smooth and hybrid settings.</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.02239v2</guid>
      <category>math.OC</category>
      <category>cs.LG</category>
      <pubDate>Thu, 10 Jul 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Jiaming Liang, Yongxin Chen</dc:creator>
    </item>
    <item>
      <title>Optimizing Multiple-Control Toffoli Quantum Circuit Design with Constraint Programming</title>
      <link>https://arxiv.org/abs/2404.14384</link>
      <description>arXiv:2404.14384v3 Announce Type: replace 
Abstract: As quantum technology advances, the efficient design of quantum circuits has become an important area of research. This paper provides an introduction to the MCT quantum circuit design problem for reversible Boolean functions with the necessary background in quantum computing to comprehend the problem. While this is a well-studied problem, optimization models that minimize the true objective have only been explored recently. This paper introduces a new optimization model and symmetry-breaking constraints that improve solving time by up to two orders of magnitude compared to earlier work when a Constraint Programming solver is used. Experiments with up to seven qubits and using up to 15 quantum gates result in several new best-known circuits, obtained by any method, for well-known benchmarks. Several in-depth analyses are presented to validate the effectiveness of the symmetry-breaking constraints from multiple perspectives. Finally, an extensive comparison with other approaches shows that optimization models may require more time but can provide superior circuits with optimality guarantees.</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.14384v3</guid>
      <category>math.OC</category>
      <category>cs.ET</category>
      <category>quant-ph</category>
      <pubDate>Thu, 10 Jul 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <arxiv:DOI>10.4230/LIPIcs.CP.2024.16</arxiv:DOI>
      <dc:creator>Jihye Jung, Kevin Dalmeijer, Pascal Van Hentenryck</dc:creator>
    </item>
    <item>
      <title>Distributionally Robust Joint Chance-Constrained Optimization for Electricity Imbalance: Integrating Renewables and Storage</title>
      <link>https://arxiv.org/abs/2409.00367</link>
      <description>arXiv:2409.00367v2 Announce Type: replace 
Abstract: Integrating Distributed Energy Resources (DERs) with peer-to-peer (P2P) energy trading offers promising solutions for grid modernization by incentivizing prosumers to participate in mitigating peak demand. However, this integration also introduces operational uncertainties and computational challenges. This paper aims to address these challenges with a novel scalable and tractable distributionally robust joint chance-constrained (DRJCC) optimization framework that effectively facilitates P2P energy trading by enhancing flexibility provision from large-scale DER operations under uncertain supply and demand. Therefore, a practical framework is proposed to solve the core challenges of DRJCC by integrating three key components: (1) a Wasserstein ambiguity set that effectively quantifies uncertainty with sparse data, (2) a CVaR-based approximation of joint chance constraints to balance computational efficiency with risk control, and (3) a privacy-preserving ADMM algorithm that enables distributed implementation through decomposition. To discern patterns in the data that indicate collaboration potential and adjust ambiguity sets for improved efficiency, K-means clustering is applied to historical scenarios. Simulation results show that the proposed framework reduces peak demand by approximately 28% and total community costs by around 31%, underscoring its effectiveness in enhancing grid robustness, operational reliability, and economic optimization in renewable-based energy management.</description>
      <guid isPermaLink="false">oai:arXiv.org:2409.00367v2</guid>
      <category>math.OC</category>
      <category>cs.SY</category>
      <category>eess.SY</category>
      <pubDate>Thu, 10 Jul 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <arxiv:DOI>10.22034/tjee.2025.63090.4884</arxiv:DOI>
      <dc:creator>Amir Noori, Babak Tavassoli, Alireza Fereidunian</dc:creator>
    </item>
    <item>
      <title>From Gradient Clipping to Normalization for Heavy Tailed SGD</title>
      <link>https://arxiv.org/abs/2410.13849</link>
      <description>arXiv:2410.13849v3 Announce Type: replace 
Abstract: Recent empirical evidence indicates that many machine learning applications involve heavy-tailed gradient noise, which challenges the standard assumptions of bounded variance in stochastic optimization. Gradient clipping has emerged as a popular tool to handle this heavy-tailed noise, as it achieves good performance in this setting both theoretically and practically. However, our current theoretical understanding of non-convex gradient clipping has three main shortcomings. First, the theory hinges on large, increasing clipping thresholds, which are in stark contrast to the small constant clipping thresholds employed in practice. Second, clipping thresholds require knowledge of problem-dependent parameters to guarantee convergence. Lastly, even with this knowledge, current sampling complexity upper bounds for the method are sub-optimal in nearly all parameters. To address these issues, we study convergence of Normalized SGD (NSGD). First, we establish a parameter-free sample complexity for NSGD of $\mathcal{O}\left(\varepsilon^{-\frac{2p}{p-1}}\right)$ to find an $\varepsilon$-stationary point. Furthermore, we prove tightness of this result, by providing a matching algorithm-specific lower bound. In the setting where all problem parameters are known, we show this complexity is improved to $\mathcal{O}\left(\varepsilon^{-\frac{3p-2}{p-1}}\right)$, matching the previously known lower bound for all first-order methods in all problem dependent parameters. Finally, we establish high-probability convergence of NSGD with a mild logarithmic dependence on the failure probability. Our work complements the studies of gradient clipping under heavy tailed noise improving the sample complexities of existing algorithms and offering an alternative mechanism to achieve high probability convergence.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.13849v3</guid>
      <category>math.OC</category>
      <category>cs.LG</category>
      <category>stat.ML</category>
      <pubDate>Thu, 10 Jul 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <arxiv:journal_reference>Proceedings of The 28th International Conference on Artificial Intelligence and Statistics, PMLR 258:2413-2421, 2025</arxiv:journal_reference>
      <dc:creator>Florian H\"ubler, Ilyas Fatkhullin, Niao He</dc:creator>
    </item>
    <item>
      <title>Evacuation Planning on Time-Expanded Networks with Integrated Wildfire Information</title>
      <link>https://arxiv.org/abs/2410.14500</link>
      <description>arXiv:2410.14500v2 Announce Type: replace 
Abstract: We study the problem of evacuation planning for natural disasters, focusing on wildfire evacuations. By creating pre-planned evacuation routes that can be updated based on real-time data, we provide an easily adjustable approach to evacuation planning and implementation. Our method uses publicly available data and can be tailored for a particular region or circumstance.
  We formulate large-scale evacuations as maximum flow problems on time-expanded networks, in which we integrate hazard information given in the form of a shapefile. An initial flow and evacuation plan is found based on a predicted fire, and is then updated based on revised fire information received during the evacuation.
  We provide a proof of concept on three locations with historic deadly fires using data available through OpenStreetMaps, a basemap for a geographic information system (GIS), on a NetworkX Python script. The results validate viable running times and quality of information for application in practice. Particular strengths are the scalability and modularity of our approach and accompanying software package.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.14500v2</guid>
      <category>math.OC</category>
      <pubDate>Thu, 10 Jul 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Steffen Borgwardt, Nicholas Crawford, Drew Horton, Angela Morrison, Emily Speakman</dc:creator>
    </item>
    <item>
      <title>Estimating Varying Parameters in Dynamical Systems: A Modular Framework Using Switch Detection, Optimization, and Sparse Regression</title>
      <link>https://arxiv.org/abs/2412.16198</link>
      <description>arXiv:2412.16198v3 Announce Type: replace 
Abstract: The estimation of static parameters in dynamical systems and control theory has been extensively studied, with significant progress made in estimating varying parameters in specific system types. Suppose, in the general case, we have data from a system with parameters that depend on an independent variable such as time or space. Further, suppose the system's model structure is known, but our aim is to identify functions describing parameter-varying elements as they change with respect to time or another variable. Focusing initially on the subclass of problems where parameters are discretely switching piecewise constant functions, we develop an algorithmic framework for detecting discrete parameter switches and fitting a piecewise constant model to data using optimization-based parameter estimation. Our modular framework allows for customization of switch detection, numerical integration, and optimization sub-steps to suit user requirements. Binary segmentation is used for switch detection, with Nelder-Mead and Powell methods employed for optimization. To address broader problems, we extend our framework using dictionary-based sparse regression with trigonometric and polynomial functions to obtain continuously varying parameter functions. Finally, we assess the framework's robustness to measurement noise. We demonstrate its capabilities across several examples, including time-varying promoter-gene expression, a genetic toggle switch, a parameter-switching manifold, the heat equation with a time-varying diffusion coefficient, and the advection-diffusion equation with a continuously varying parameter.</description>
      <guid isPermaLink="false">oai:arXiv.org:2412.16198v3</guid>
      <category>math.OC</category>
      <category>math.DS</category>
      <pubDate>Thu, 10 Jul 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <dc:creator>Jamiree Harrison, Enoch Yeung</dc:creator>
    </item>
    <item>
      <title>On a geometric graph-covering problem related to optimal safety-landing-site location</title>
      <link>https://arxiv.org/abs/2501.10742</link>
      <description>arXiv:2501.10742v2 Announce Type: replace 
Abstract: We propose integer-programming formulations for an optimal safety-landing site (SLS) location problem that arises in the design of urban air-transportation networks. We first develop a set-cover based approach for the case where the candidate location set is finite and composed of points, and we link the problems to solvable cases that have been studied. We then use a mixed-integer second-order cone program to model the situation where the locations of SLSs are restricted to convex sets only. Finally, we introduce strong fixing, which we found to be very effective in reducing the size of integer programs.</description>
      <guid isPermaLink="false">oai:arXiv.org:2501.10742v2</guid>
      <category>math.OC</category>
      <pubDate>Thu, 10 Jul 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Claudia D'Ambrosio, Marcia Fampa, Jon Lee, Felipe Sinnecker</dc:creator>
    </item>
    <item>
      <title>Lagrangian Duality for Mixed-Integer Semidefinite Programming: Theory and Algorithms</title>
      <link>https://arxiv.org/abs/2501.11397</link>
      <description>arXiv:2501.11397v2 Announce Type: replace 
Abstract: This paper presents the Lagrangian duality theory for mixed-integer semidefinite programming (MISDP). We derive the Lagrangian dual problem and prove that the resulting Lagrangian dual bound dominates the bound obtained from the continuous relaxation of the MISDP problem. We present a hierarchy of Lagrangian dual bounds by exploiting the theory of integer positive semidefinite matrices and propose three algorithms for obtaining those bounds. Our algorithms are variants of well-known algorithms for minimizing non-differentiable convex functions. The numerical results on the max-$k$-cut problem show that the Lagrangian dual bounds are substantially stronger than the semidefinite programming bound obtained by relaxing integrality, already for lower levels in the hierarchy.</description>
      <guid isPermaLink="false">oai:arXiv.org:2501.11397v2</guid>
      <category>math.OC</category>
      <pubDate>Thu, 10 Jul 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Frank de Meijer, Renata Sotirov</dc:creator>
    </item>
    <item>
      <title>Optimization techniques for modeling with piecewise-linear functions</title>
      <link>https://arxiv.org/abs/2503.10405</link>
      <description>arXiv:2503.10405v2 Announce Type: replace 
Abstract: In this paper we aim to construct piecewise-linear (PWL) approximations for functions of multiple variables and to build compact mixed-integer linear programming (MILP) formulations to represent the resulting PWL function. On the one hand, we describe a simple heuristic to iteratively construct a triangulation with a small number of triangles, while decreasing the error of the piecewise-linear approximation. On the other hand, we extend known techniques for modeling PWLs in MILPs more efficiently than state-of-the-art methods permit. The crux of our method is that the MILP model is a result of solving some hard combinatorial optimization problems, for which we present heuristic algorithms. The effectiveness of our techniques is demonstrated by a series of computational experiments including a short-term hydropower scheduling problem</description>
      <guid isPermaLink="false">oai:arXiv.org:2503.10405v2</guid>
      <category>math.OC</category>
      <pubDate>Thu, 10 Jul 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>P\'eter Dobrovoczki, Tam\'as Kis</dc:creator>
    </item>
    <item>
      <title>Multilevel Bregman Proximal Gradient Descent</title>
      <link>https://arxiv.org/abs/2506.03950</link>
      <description>arXiv:2506.03950v2 Announce Type: replace 
Abstract: We present the Multilevel Bregman Proximal Gradient Descent (ML BPGD) method, a novel multilevel optimization framework tailored to constrained convex problems with relative Lipschitz smoothness. Our approach extends the classical multilevel optimization framework (MGOPT) to handle Bregman-based geometries and constrained domains. We provide a rigorous analysis of ML BPGD for multiple coarse levels and establish a global linear convergence rate. We demonstrate the effectiveness of ML BPGD in the context of image reconstruction, providing theoretical guarantees for the well-posedness of the multilevel framework and validating its performance through numerical experiments.</description>
      <guid isPermaLink="false">oai:arXiv.org:2506.03950v2</guid>
      <category>math.OC</category>
      <pubDate>Thu, 10 Jul 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Yara Elshiaty, Stefania Petra</dc:creator>
    </item>
    <item>
      <title>Computer-aided analyses of stochastic first-order methods, via interpolation conditions for stochastic optimization</title>
      <link>https://arxiv.org/abs/2507.05466</link>
      <description>arXiv:2507.05466v2 Announce Type: replace 
Abstract: This work proposes a framework, embedded within the Performance Estimation framework (PEP), for obtaining worst-case performance guarantees on stochastic first-order methods. Given a first-order method, a function class, and a noise model with prescribed expectation and variance properties, we present a range of semidefinite programs (SDPs) of increasingly large size, whose solutions yield increasingly strong convergence guarantees on the problem. Eventually, we propose SDPs whose size depends on $2^N$, with $N$ the number of iterations analyzed, that yield tight guarantees, attained by specific functions and noise distributions within these classes. On the other side of the spectrum, we propose SDPs whose size depends linearly on $N$, and numerically show that, on many problems, they already provide tight guarantees.
  The framework accommodates a wide range of stochastic settings, with finite or infinite support, including the unstructured noise model with bounded variance, finite-sum optimization, and block-coordinate methods, in a unified manner, as guarantees apply to any setting consistent with the noise model, i.e., its expectation and variance. It covers both non-variance-reduced and variance-reduced methods. Using the framework, we analyze the stochastic gradient method under several noise models, and illustrate how the resulting numerical and analytical convergence rates connect with existing results. In particular, we provide improved convergence rates on the unstructured noise model with bounded variance and in the block-coordinate setting.</description>
      <guid isPermaLink="false">oai:arXiv.org:2507.05466v2</guid>
      <category>math.OC</category>
      <pubDate>Thu, 10 Jul 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Anne Rubbens, S\'ebastien Colla, Julien M. Hendrickx</dc:creator>
    </item>
    <item>
      <title>On the Inherent Privacy of Zeroth Order Projected Gradient Descent</title>
      <link>https://arxiv.org/abs/2507.05610</link>
      <description>arXiv:2507.05610v2 Announce Type: replace 
Abstract: Differentially private zeroth-order optimization methods have recently gained popularity in private fine tuning of machine learning models due to their reduced memory requirements. Current approaches for privatizing zeroth-order methods rely on adding Gaussian noise to the estimated zeroth-order gradients. However, since the search direction in the zeroth-order methods is inherently random, researchers including Tang et al. (2024) and Zhang et al. (2024a) have raised an important question: is the inherent noise in zeroth-order estimators sufficient to ensure the overall differential privacy of the algorithm? This work settles this question for a class of oracle-based optimization algorithms where the oracle returns zeroth-order gradient estimates. In particular, we show that for a fixed initialization, there exist strongly convex objective functions such that running (Projected) Zeroth-Order Gradient Descent (ZO-GD) is not differentially private. Furthermore, we show that even with random initialization and without revealing (initial and) intermediate iterates, the privacy loss in ZO-GD can grow superlinearly with the number of iterations when minimizing convex objective functions.</description>
      <guid isPermaLink="false">oai:arXiv.org:2507.05610v2</guid>
      <category>math.OC</category>
      <category>cs.LG</category>
      <category>stat.ML</category>
      <pubDate>Thu, 10 Jul 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Devansh Gupta, Meisam Razaviyayn, Vatsal Sharan</dc:creator>
    </item>
    <item>
      <title>The Singular Angle of Nonlinear Systems</title>
      <link>https://arxiv.org/abs/2109.01629</link>
      <description>arXiv:2109.01629v2 Announce Type: replace-cross 
Abstract: In this paper, we introduce an angle notion called the singular angle for nonlinear systems from an input-output perspective. The proposed system singular angle, based on the angle between $L_2$-signals, describes an upper bound for the ''rotating effect'' from system input to output signals. It quantifies passivity and serves as a counterpart to system $L_2$-gain. It also provides an alternative to a recently defined notion of system phase which adopts complexification of real-valued signals via the Hilbert transform. A nonlinear small angle theorem is established for feedback stability analysis, which involves a comparison of the loop system angle with $\pi$. The theorem generalizes the classical passivity theorem via a tradeoff between the singular angles of open-loop systems.</description>
      <guid isPermaLink="false">oai:arXiv.org:2109.01629v2</guid>
      <category>eess.SY</category>
      <category>cs.SY</category>
      <category>math.OC</category>
      <pubDate>Thu, 10 Jul 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Chao Chen, Di Zhao, Sei Zhen Khong</dc:creator>
    </item>
    <item>
      <title>Tropical toric maximum likelihood estimation</title>
      <link>https://arxiv.org/abs/2404.10567</link>
      <description>arXiv:2404.10567v2 Announce Type: replace-cross 
Abstract: We consider toric maximum likelihood estimation over the field of Puiseux series and study critical points of the likelihood function using tropical methods. This problem translates to finding the intersection points of a tropical affine space with a classical linear subspace. We derive new structural results on tropical affine spaces and use these to give a complete and explicit description of the tropical critical points in certain cases. In these cases, we associate tropical critical points to the simplices in a regular triangulation of the polytope giving rise to the toric model.</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.10567v2</guid>
      <category>math.AG</category>
      <category>math.CO</category>
      <category>math.OC</category>
      <pubDate>Thu, 10 Jul 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Emma Boniface, Karel Devriendt, Serkan Ho\c{s}ten</dc:creator>
    </item>
    <item>
      <title>Understanding Fixed Predictions via Confined Regions</title>
      <link>https://arxiv.org/abs/2502.16380</link>
      <description>arXiv:2502.16380v2 Announce Type: replace-cross 
Abstract: Machine learning models can assign fixed predictions that preclude individuals from changing their outcome. Existing approaches to audit fixed predictions do so on a pointwise basis, which requires access to an existing dataset of individuals and may fail to anticipate fixed predictions in out-of-sample data. This work presents a new paradigm to identify fixed predictions by finding confined regions of the feature space in which all individuals receive fixed predictions. This paradigm enables the certification of recourse for out-of-sample data, works in settings without representative datasets, and provides interpretable descriptions of individuals with fixed predictions. We develop a fast method to discover confined regions for linear classifiers using mixed-integer quadratically constrained programming. We conduct a comprehensive empirical study of confined regions across diverse applications. Our results highlight that existing pointwise verification methods fail to anticipate future individuals with fixed predictions, while our method both identifies them and provides an interpretable description.</description>
      <guid isPermaLink="false">oai:arXiv.org:2502.16380v2</guid>
      <category>cs.LG</category>
      <category>cs.AI</category>
      <category>math.OC</category>
      <pubDate>Thu, 10 Jul 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Connor Lawless, Tsui-Wei Weng, Berk Ustun, Madeleine Udell</dc:creator>
    </item>
    <item>
      <title>A localized consensus-based sampling algorithm</title>
      <link>https://arxiv.org/abs/2505.24861</link>
      <description>arXiv:2505.24861v2 Announce Type: replace-cross 
Abstract: We develop a novel interacting-particle method for sampling from non-Gaussian distributions. As a first step, we propose a new way to derive the consensus-based sampling (CBS) algorithm, starting from ensemble-preconditioned Langevin diffusions. We approximate the target potential by its Moreau envelope, such that the gradient in the Langevin equation can be replaced by a proximal operator. We then approximate the proximal operator by a weighted mean, and finally assume that the initial and target distributions are Gaussian, resulting in the CBS dynamics. If we keep only those approximations that can be justified in the non-Gaussian setting, the result is a new interacting-particle method for sampling, which we call localized consensus-based sampling. We prove that our algorithm is affine-invariant and exact for Gaussian distributions in the mean-field setting. Numerical tests illustrate that localized CBS compares favorably to alternative methods in terms of affine-invariance and performance on non-Gaussian distributions.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.24861v2</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <category>math.OC</category>
      <pubDate>Thu, 10 Jul 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Arne Bouillon, Alexander Bodard, Panagiotis Patrinos, Dirk Nuyens, Giovanni Samaey</dc:creator>
    </item>
  </channel>
</rss>
