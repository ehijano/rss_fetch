<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>cs.DS updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/cs.DS</link>
    <description>cs.DS updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/cs.DS" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Thu, 12 Feb 2026 02:49:38 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Wed, 11 Feb 2026 00:00:00 -0500</pubDate>
    <skipDays>
      <day>Saturday</day>
      <day>Sunday</day>
    </skipDays>
    <item>
      <title>The Price of Privacy For Approximating Max-CSP</title>
      <link>https://arxiv.org/abs/2602.09273</link>
      <description>arXiv:2602.09273v1 Announce Type: new 
Abstract: We study approximation algorithms for Maximum Constraint Satisfaction Problems (Max-CSPs) under differential privacy (DP) where the constraints are considered sensitive data. Information-theoretically, we aim to classify the best approximation ratios possible for a given privacy budget $\varepsilon$. In the high-privacy regime ($\varepsilon \ll 1$), we show that any $\varepsilon$-DP algorithm cannot beat a random assignment by more than $O(\varepsilon)$ in the approximation ratio. We devise a polynomial-time algorithm which matches this barrier under the assumptions that the instances are bounded-degree and triangle-free. Finally, we show that one or both of these assumptions can be removed for specific CSPs--such as Max-Cut or Max $k$-XOR--albeit at the cost of computational efficiency.</description>
      <guid isPermaLink="false">oai:arXiv.org:2602.09273v1</guid>
      <category>cs.DS</category>
      <category>cs.CR</category>
      <pubDate>Wed, 11 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Prathamesh Dharangutte, Jingcheng Liu, Pasin Manurangsi, Akbar Rafiey, Phanu Vajanopath, Zongrui Zou</dc:creator>
    </item>
    <item>
      <title>Beyond Vizing Chains: Improved Recourse in Dynamic Edge Coloring</title>
      <link>https://arxiv.org/abs/2602.09497</link>
      <description>arXiv:2602.09497v1 Announce Type: new 
Abstract: We study the maintenance of a $(\Delta+C)$-edge-coloring ($C\ge 1$) in a fully dynamic graph $G$ with maximum degree $\Delta$. We focus on minimizing \emph{recourse} which equals the number of recolored edges per edge updates.
  We present a new technique based on an object which we call a \emph{shift-tree}. This object tracks multiple possible recolorings of $G$ and enables us to maintain a proper coloring with small recourse in polynomial time. We shift colors over a path of edges, but unlike many other algorithms, we do not use \emph{fans} and \emph{alternating bicolored paths}.
  We combine the shift-tree with additional techniques to obtain an algorithm with a \emph{tight} recourse of $O\big( \frac{\log n}{\log \frac{\Delta+C}{\Delta-C}}\big)$ for all $C \ge 0.62\Delta$ where $\Delta-C = O(n^{1-\delta})$. Our algorithm is the first deterministic algorithm to establish tight bounds for large palettes, and the first to do so when $\Delta-C=o(\Delta)$. This result settles the theoretical complexity of the recourse for large palettes. Furthermore, we believe that viewing the possible shifts as a tree can lead to similar tree-based techniques that extend to lower values of $C$, and to improved update times.
  A second application is to graphs with low arboricity $\alpha$. Previous works [BCPS24, CRV24] achieve $O(\epsilon^{-1}\log n)$ recourse per update with $C\ge (4+\epsilon)\alpha$, and we improve by achieving the same recourse while only requiring $C \ge (2+\epsilon)\alpha - 1$. This result is $\Delta$-adaptive, i.e., it uses $\Delta_t+C$ colors where $\Delta_t$ is the current maximum degree.
  Trying to understand the limitations of our technique, and shift-based algorithms in general, we show a separation between the recourse achievable by algorithms that only shift colors along a path, and more general algorithms such as ones using the Nibbling Method [BGW21, BCPS24].</description>
      <guid isPermaLink="false">oai:arXiv.org:2602.09497v1</guid>
      <category>cs.DS</category>
      <pubDate>Wed, 11 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Yaniv Sadeh, Haim Kaplan</dc:creator>
    </item>
    <item>
      <title>Maximizing Diversity in (near-)Median String Selection</title>
      <link>https://arxiv.org/abs/2602.10050</link>
      <description>arXiv:2602.10050v1 Announce Type: new 
Abstract: Given a set of strings over a specified alphabet, identifying a median or consensus string that minimizes the total distance to all input strings is a fundamental data aggregation problem. When the Hamming distance is considered as the underlying metric, this problem has extensive applications, ranging from bioinformatics to pattern recognition. However, modern applications often require the generation of multiple (near-)optimal yet diverse median strings to enhance flexibility and robustness in decision-making.
  In this study, we address this need by focusing on two prominent diversity measures: sum dispersion and min dispersion. We first introduce an exact algorithm for the diameter variant of the problem, which identifies pairs of near-optimal medians that are maximally diverse. Subsequently, we propose a $(1-\epsilon)$-approximation algorithm (for any $\epsilon &gt;0$) for sum dispersion, as well as a bi-criteria approximation algorithm for the more challenging min dispersion case, allowing the generation of multiple (more than two) diverse near-optimal Hamming medians. Our approach primarily leverages structural insights into the Hamming median space and also draws on techniques from error-correcting code construction to establish these results.</description>
      <guid isPermaLink="false">oai:arXiv.org:2602.10050v1</guid>
      <category>cs.DS</category>
      <pubDate>Wed, 11 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Diptarka Chakraborty, Rudrayan Kundu, Nidhi Purohit, Aravinda Kanchana Ruwanpathirana</dc:creator>
    </item>
    <item>
      <title>Beyond a Single Queue: Multi-Level-Multi-Queue as an Effective Design for SSSP problems on GPUs</title>
      <link>https://arxiv.org/abs/2602.10080</link>
      <description>arXiv:2602.10080v1 Announce Type: new 
Abstract: As one of the most fundamental problems in graph processing, the Single-Source Shortest Path (SSSP) problem plays a critical role in numerous application scenarios. However, existing GPU-based solutions remain inefficient, as they typically rely on a single, fixed queue design that incurs severe synchronization overhead, high memory latency, and poor adaptivity to diverse inputs. To address these inefficiencies, we propose MultiLevelMultiQueue (MLMQ), a novel data structure that distributes multiple queues across the GPU's multi-level parallelism and memory hierarchy. To realize MLMQ, we introduce a cache-like collaboration mechanism for efficient inter-queue coordination, and develop a modular queue design based on unified Read and Write primitives. Within this framework, we expand the optimization space by designing a set of GPU-friendly queues, composing them across multiple levels, and further providing an input-adaptive MLMQ configuration scheme. Our MLMQ design achieves average speedups of 1.87x to 17.13x over state-of-the-art implementations. Our code is open-sourced at https://github.com/Leo9660/MLMQ.git.</description>
      <guid isPermaLink="false">oai:arXiv.org:2602.10080v1</guid>
      <category>cs.DS</category>
      <pubDate>Wed, 11 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Zhengding Hu, Jingwen Sun, Le Jiang, Yuhao Wang, Junqing Lin, Yi Zong, Guangzhong Sun</dc:creator>
    </item>
    <item>
      <title>From Average Sensitivity to Small-Loss Regret Bounds under Random-Order Model</title>
      <link>https://arxiv.org/abs/2602.09457</link>
      <description>arXiv:2602.09457v1 Announce Type: cross 
Abstract: We study online learning in the random-order model, where the multiset of loss functions is chosen adversarially but revealed in a uniformly random order. Building on the batch-to-online conversion by Dong and Yoshida (2023), we show that if an offline algorithm admits a $(1+\varepsilon)$-approximation guarantee and the effect of $\varepsilon$ on its average sensitivity is characterized by a function $\varphi(\varepsilon)$, then an adaptive choice of $\varepsilon$ yields a small-loss regret bound of $\tilde O(\varphi^{\star}(\mathrm{OPT}_T))$, where $\varphi^{\star}$ is the concave conjugate of $\varphi$, $\mathrm{OPT}_T$ is the offline optimum over $T$ rounds, and $\tilde O$ hides polylogarithmic factors in $T$. Our method requires no regularity assumptions on loss functions, such as smoothness, and can be viewed as a generalization of the AdaGrad-style tuning applied to the approximation parameter $\varepsilon$. Our result recovers and strengthens the $(1+\varepsilon)$-approximate regret bounds of Dong and Yoshida (2023) and yields small-loss regret bounds for online $k$-means clustering, low-rank approximation, and regression. We further apply our framework to online submodular function minimization using $(1\pm\varepsilon)$-cut sparsifiers of submodular hypergraphs, obtaining a small-loss regret bound of $\tilde O(n^{3/4}(1 + \mathrm{OPT}_T^{3/4}))$, where $n$ is the ground-set size. Our approach sheds light on the power of sparsification and related techniques in establishing small-loss regret bounds in the random-order model.</description>
      <guid isPermaLink="false">oai:arXiv.org:2602.09457v1</guid>
      <category>stat.ML</category>
      <category>cs.DS</category>
      <category>cs.LG</category>
      <pubDate>Wed, 11 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Shinsaku Sakaue, Yuichi Yoshida</dc:creator>
    </item>
    <item>
      <title>Non-Additive Discrepancy: Coverage Functions in a Beck-Fiala Setting</title>
      <link>https://arxiv.org/abs/2602.09948</link>
      <description>arXiv:2602.09948v1 Announce Type: cross 
Abstract: Recent concurrent work by Dupr\'{e} la Tour and Fujii and by Hollender, Manurangsi, Meka, and Suksompong [ITCS'26] introduced a generalization of classical discrepancy theory to non-additive functions, motivated by applications in fair division. As many classical techniques from discrepancy theory seem to fail in this setting, including linear algebraic methods like the Beck-Fiala Theorem [Discrete Appl. Math '81], it remains widely open whether comparable non-additive bounds can be achieved.
  Towards a better understanding of non-additive discrepancy, we study coverage functions in a sparse setting comparable to the classical Beck-Fiala Theorem. Our setting generalizes the additive Beck-Fiala setting, rank functions of partition matroids, and edge coverage in graphs. More precisely, assuming each of the $n$ items covers only $t$ elements across all functions, we prove a constructive discrepancy bound that is polynomial in $t$, the number of colors $k$, and $\log n$.</description>
      <guid isPermaLink="false">oai:arXiv.org:2602.09948v1</guid>
      <category>math.CO</category>
      <category>cs.DM</category>
      <category>cs.DS</category>
      <pubDate>Wed, 11 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>T. R. Avila, Lars Rohwedder, Leo Wennmann</dc:creator>
    </item>
    <item>
      <title>Efficient Online Random Sampling via Randomness Recycling</title>
      <link>https://arxiv.org/abs/2505.18879</link>
      <description>arXiv:2505.18879v4 Announce Type: replace 
Abstract: This article studies the fundamental problem of using i.i.d. coin tosses from an entropy source to efficiently generate random variables $X_i \sim P_i$ $(i \ge 1)$, where $(P_1, P_2, \dots)$ is a random sequence of rational discrete probability distributions subject to an \textit{arbitrary} stochastic process. Our method achieves an amortized expected entropy cost within $\varepsilon &gt; 0$ bits of the information-theoretically optimal Shannon lower bound using $O(\log(1/\varepsilon))$ space. This result holds both pointwise in terms of the Shannon information content conditioned on $X_i$ and $P_i$, and in expectation to obtain a rate of $\mathbb{E}[H(P_1) + \dots + H(P_n)]/n + \varepsilon$ bits per sample as $n \to \infty$ (where $H$ is the Shannon entropy). The combination of space, time, and entropy properties of our method improves upon the Knuth and Yao (1976) entropy-optimal algorithm and Han and Hoshi (1997) interval algorithm for online sampling, which require unbounded space. It also uses exponentially less space than the more specialized methods of Kozen and Soloviev (2022) and Shao and Wang (2025) that generate i.i.d. samples from a fixed distribution. Our online sampling algorithm rests on a powerful algorithmic technique called \textit{randomness recycling}, which reuses a fraction of the random information consumed by a probabilistic algorithm to reduce its amortized entropy cost.
  On the practical side, we develop randomness recycling techniques to accelerate a variety of prominent sampling algorithms. We show that randomness recycling enables state-of-the-art runtime performance on the Fisher-Yates shuffle when using a cryptographically secure pseudorandom number generator, and that it reduces the entropy cost of discrete Gaussian sampling. Accompanying the manuscript is a performant software library in the C programming language.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.18879v4</guid>
      <category>cs.DS</category>
      <category>cs.DM</category>
      <category>cs.IT</category>
      <category>math.IT</category>
      <category>math.PR</category>
      <category>stat.CO</category>
      <pubDate>Wed, 11 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <arxiv:DOI>10.1137/1.9781611978971.89</arxiv:DOI>
      <arxiv:journal_reference>Proceedings of the 2026 Annual ACM-SIAM Symposium on Discrete Algorithms (SODA), pp. 2473-2511. Society for Industrial and Applied Mathematics, 2026</arxiv:journal_reference>
      <dc:creator>Thomas L. Draper, Feras A. Saad</dc:creator>
    </item>
    <item>
      <title>A Simple Algorithm for Trimmed Multipoint Evaluation</title>
      <link>https://arxiv.org/abs/2507.00196</link>
      <description>arXiv:2507.00196v2 Announce Type: replace 
Abstract: Evaluating a polynomial on a set of points is a fundamental task in computer algebra. In this work, we revisit a particular variant called trimmed multipoint evaluation: given an $n$-variate polynomial with bounded individual degree $d$ and total degree $D$, the goal is to evaluate it on a natural class of input points. This problem arises as a key subroutine in recent algorithmic results [Dinur; SODA '21], [Dell, Haak, Kallmayer, Wennmann; SODA '25]. It is known that trimmed multipoint evaluation can be solved in near-linear time [van der Hoeven, Schost; AAECC '13] by a clever yet somewhat involved algorithm. We give a simple recursive algorithm that avoids heavy computer-algebraic machinery, and can be readily understood by researchers without specialized background.</description>
      <guid isPermaLink="false">oai:arXiv.org:2507.00196v2</guid>
      <category>cs.DS</category>
      <pubDate>Wed, 11 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Nick Fischer, Melvin Kallmayer, Leo Wennmann</dc:creator>
    </item>
    <item>
      <title>An $O(n\log n)$ Algorithm for Single-Item Capacitated Lot Sizing with a One-Breakpoint All-Units Discount and Non-Increasing Prices</title>
      <link>https://arxiv.org/abs/2510.11368</link>
      <description>arXiv:2510.11368v3 Announce Type: replace 
Abstract: This paper addresses the single-item capacitated lot sizing problem with a 1-breakpoint all-units quantity discount in a monotonic setting where the purchase prices are non-increasing over the planning horizon. For this case, we establish several novel properties of the optimal solution and develop a hybrid dynamic programming approach that maintains a compact representation of the solution space by storing only essential information about the states and using linear equations for intermediate values. Our algorithm runs in \(O(n\log n)\) time, where \(n\) denotes the number of periods. Our result is an improvement over the previous state-of-the-art algorithm, which has an \(O(n^2)\) time complexity.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.11368v3</guid>
      <category>cs.DS</category>
      <pubDate>Wed, 11 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Kleitos Papadopoulos</dc:creator>
    </item>
    <item>
      <title>A Faster Directed Single-Source Shortest Path Algorithm</title>
      <link>https://arxiv.org/abs/2602.07868</link>
      <description>arXiv:2602.07868v2 Announce Type: replace 
Abstract: This paper presents a new deterministic algorithm for single-source shortest paths (SSSP) on real non-negative edge-weighted directed graphs, with running time $O(m\sqrt{\log n}+\sqrt{mn\log n\log \log n})$, which is $O(m\sqrt{\log n\log \log n})$ for sparse graphs. This improves the recent breakthrough result of $O(m\log^{2/3} n)$ time for directed SSSP algorithm [Duan, Mao, Mao, Shu, Yin 2025].</description>
      <guid isPermaLink="false">oai:arXiv.org:2602.07868v2</guid>
      <category>cs.DS</category>
      <pubDate>Wed, 11 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Ran Duan, Xiao Mao, Xinkai Shu, Longhui Yin</dc:creator>
    </item>
  </channel>
</rss>
