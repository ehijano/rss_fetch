<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>math.IT updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/math.IT</link>
    <description>math.IT updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/math.IT" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Tue, 23 Jul 2024 02:42:51 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Mon, 22 Jul 2024 00:00:00 -0400</pubDate>
    <skipDays>
      <day>Saturday</day>
      <day>Sunday</day>
    </skipDays>
    <item>
      <title>Fundamental Scaling Laws of Covert Communication in the Presence of Block Fading</title>
      <link>https://arxiv.org/abs/2407.13898</link>
      <description>arXiv:2407.13898v1 Announce Type: new 
Abstract: Covert communication is the undetected transmission of sensitive information over a communication channel. In wireless communication systems, channel impairments such as signal fading present challenges in the effective implementation and analysis of covert communication systems. This paper generalizes early work in the covert communication field by considering asymptotic results for the number of bits that can be covertly transmitted in $n$ channel uses on a block fading channel. Critical to the investigation is characterizing the performance of optimal detectors at the adversary. Matching achievable and converse results are presented.</description>
      <guid isPermaLink="false">oai:arXiv.org:2407.13898v1</guid>
      <category>cs.IT</category>
      <category>cs.CR</category>
      <category>math.IT</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Amir Reza Ramtin, Dennis Goeckel, Don Towsley</dc:creator>
    </item>
    <item>
      <title>Integrated Push-and-Pull Update Model for Goal-Oriented Effective Communication</title>
      <link>https://arxiv.org/abs/2407.14092</link>
      <description>arXiv:2407.14092v1 Announce Type: new 
Abstract: This paper studies decision-making for goal-oriented effective communication. We consider an end-to-end status update system where a sensing agent (SA) observes a source, generates and transmits updates to an actuation agent (AA), while the AA takes actions to accomplish a goal at the endpoint. We integrate the push- and pull-based update communication models to obtain a push-and-pull model, which allows the transmission controller at the SA to decide to push an update to the AA and the query controller at the AA to pull updates by raising queries at specific time instances. To gauge effectiveness, we utilize a grade of effectiveness (GoE) metric incorporating updates' freshness, usefulness, and timeliness of actions as qualitative attributes. We then derive effect-aware policies to maximize the expected discounted sum of updates' effectiveness subject to induced costs. The effect-aware policy at the SA considers the potential effectiveness of communicated updates at the endpoint, while at the AA, it accounts for the probabilistic evolution of the source and importance of generated updates. Our results show the proposed push-and-pull model outperforms models solely based on push- or pull-based updates both in terms of efficiency and effectiveness. Additionally, using effect-aware policies at both agents enhances effectiveness compared to periodic and/or probabilistic effect-agnostic policies at either or both agents.</description>
      <guid isPermaLink="false">oai:arXiv.org:2407.14092v1</guid>
      <category>cs.IT</category>
      <category>cs.AI</category>
      <category>cs.MA</category>
      <category>cs.NI</category>
      <category>math.IT</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Pouya Agheli, Nikolaos Pappas, Petar Popovski, Marios Kountouris</dc:creator>
    </item>
    <item>
      <title>MDS Generalized Convertible Code</title>
      <link>https://arxiv.org/abs/2407.14304</link>
      <description>arXiv:2407.14304v1 Announce Type: new 
Abstract: In this paper, we consider the convertible codes with the maximum distance separable (MDS) property, which can adjust the code rate according to the failure rates of devices. We first extend the notion of convertible codes to allow initial and final codes with different parameters. Then, we investigate the relationship between these parameters and thus establish new lower bounds on the access cost in the merge and split regimes. To gain a deeper understanding of access-optimal MDS convertible codes in the merge regime, we characterize them from the perspective of parity check matrices. Consequently, we present a necessary and sufficient condition for the access-optimal MDS convertible code in the merge regime. Finally, as an application of our characterization, we construct MDS convertible codes in the merge regime with optimal access cost based on the extended generalized Reed-Solomon codes.</description>
      <guid isPermaLink="false">oai:arXiv.org:2407.14304v1</guid>
      <category>cs.IT</category>
      <category>math.IT</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Songping Ge, Han Cai, Xiaohu Tang</dc:creator>
    </item>
    <item>
      <title>Performance Analysis and Low-Complexity Beamforming Design for Near-Field Physical Layer Security</title>
      <link>https://arxiv.org/abs/2407.13491</link>
      <description>arXiv:2407.13491v1 Announce Type: cross 
Abstract: Extremely large-scale arrays (XL-arrays) have emerged as a key enabler in achieving the unprecedented performance requirements of future wireless networks, leading to a significant increase in the range of the near-field region. This transition necessitates the spherical wavefront model for characterizing the wireless propagation rather than the far-field planar counterpart, thereby introducing extra degrees of freedom (DoFs) to wireless system design. In this paper, we explore the beam focusing-based physical layer security (PLS) in the near field, where multiple legitimate users and one eavesdropper are situated in the near-field region of the XL-array base station (BS). First, we consider a special case with one legitimate user and one eavesdropper to shed useful insights into near-field PLS. In particular, it is shown that 1) Artificial noise (AN) is crucial to near-field security provisioning, transforming an insecure system to a secure one; 2) AN can yield numerous security gains, which considerably enhances PLS in the near field as compared to the case without AN taken into account. Next, for the general case with multiple legitimate users, we propose an efficient low-complexity approach to design the beamforming with AN to guarantee near-field secure transmission. Specifically, the low-complexity approach is conceived starting by introducing the concept of interference domain to capture the inter-user interference level, followed by a three-step identification framework for designing the beamforming. Finally, numerical results reveal that 1) the PLS enhancement in the near field is pronounced thanks to the additional spatial DoFs; 2) the proposed approach can achieve close performance to that of the computationally-extensive conventional approach yet with a significantly lower computational complexity.</description>
      <guid isPermaLink="false">oai:arXiv.org:2407.13491v1</guid>
      <category>eess.SP</category>
      <category>cs.IT</category>
      <category>math.IT</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Yunpu Zhang, Yuan Fang, Xianghao Yu, Changsheng You, Ying-Jun Angela Zhang</dc:creator>
    </item>
    <item>
      <title>Optimal high-precision shadow estimation</title>
      <link>https://arxiv.org/abs/2407.13874</link>
      <description>arXiv:2407.13874v1 Announce Type: cross 
Abstract: We give the first tight sample complexity bounds for shadow tomography and classical shadows in the regime where the target error is below some sufficiently small inverse polynomial in the dimension of the Hilbert space. Formally we give a protocol that, given any $m\in\mathbb{N}$ and $\epsilon \le O(d^{-12})$, measures $O(\log(m)/\epsilon^2)$ copies of an unknown mixed state $\rho\in\mathbb{C}^{d\times d}$ and outputs a classical description of $\rho$ which can then be used to estimate any collection of $m$ observables to within additive accuracy $\epsilon$. Previously, even for the simpler task of shadow tomography -- where the $m$ observables are known in advance -- the best known rates either scaled benignly but suboptimally in all of $m, d, \epsilon$, or scaled optimally in $\epsilon, m$ but had additional polynomial factors in $d$ for general observables. Intriguingly, we also show via dimensionality reduction, that we can rescale $\epsilon$ and $d$ to reduce to the regime where $\epsilon \le O(d^{-1/2})$. Our algorithm draws upon representation-theoretic tools recently developed in the context of full state tomography.</description>
      <guid isPermaLink="false">oai:arXiv.org:2407.13874v1</guid>
      <category>quant-ph</category>
      <category>cs.DS</category>
      <category>cs.IT</category>
      <category>cs.LG</category>
      <category>math.IT</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Sitan Chen, Jerry Li, Allen Liu</dc:creator>
    </item>
    <item>
      <title>A Purely Entropic Approach to the Rainbow Triangle Problem</title>
      <link>https://arxiv.org/abs/2407.14084</link>
      <description>arXiv:2407.14084v1 Announce Type: cross 
Abstract: In this short note, we present a purely entropic proof that in a $3$-edge-colored simple graph with $R$ red edges, $G$ green edges, and $B$ blue edges, the number of rainbow triangles is at most $\sqrt{2RGB}$.</description>
      <guid isPermaLink="false">oai:arXiv.org:2407.14084v1</guid>
      <category>math.CO</category>
      <category>cs.IT</category>
      <category>math.IT</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <dc:creator>Ting-Wei Chao, Hung-Hsun Hans Yu</dc:creator>
    </item>
    <item>
      <title>A Mirror Descent-Based Algorithm for Corruption-Tolerant Distributed Gradient Descent</title>
      <link>https://arxiv.org/abs/2407.14111</link>
      <description>arXiv:2407.14111v1 Announce Type: cross 
Abstract: Distributed gradient descent algorithms have come to the fore in modern machine learning, especially in parallelizing the handling of large datasets that are distributed across several workers. However, scant attention has been paid to analyzing the behavior of distributed gradient descent algorithms in the presence of adversarial corruptions instead of random noise. In this paper, we formulate a novel problem in which adversarial corruptions are present in a distributed learning system. We show how to use ideas from (lazy) mirror descent to design a corruption-tolerant distributed optimization algorithm. Extensive convergence analysis for (strongly) convex loss functions is provided for different choices of the stepsize. We carefully optimize the stepsize schedule to accelerate the convergence of the algorithm, while at the same time amortizing the effect of the corruption over time. Experiments based on linear regression, support vector classification, and softmax classification on the MNIST dataset corroborate our theoretical findings.</description>
      <guid isPermaLink="false">oai:arXiv.org:2407.14111v1</guid>
      <category>eess.SP</category>
      <category>cs.IT</category>
      <category>cs.LG</category>
      <category>math.IT</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Shuche Wang, Vincent Y. F. Tan</dc:creator>
    </item>
    <item>
      <title>Domain Adaptation for Industrial Time-series Forecasting via Counterfactual Inference</title>
      <link>https://arxiv.org/abs/2407.14214</link>
      <description>arXiv:2407.14214v1 Announce Type: cross 
Abstract: Industrial time-series, as a structural data responds to production process information, can be utilized to perform data-driven decision-making for effective monitoring of industrial production process. However, there are some challenges for time-series forecasting in industry, e.g., predicting few-shot caused by data shortage, and decision-confusing caused by unknown treatment policy. To cope with the problems, we propose a novel causal domain adaptation framework, Causal Domain Adaptation (CDA) forecaster to improve the performance on the interested domain with limited data (target). Firstly, we analyze the causality existing along with treatments, and thus ensure the shared causality over time. Subsequently, we propose an answer-based attention mechanism to achieve domain-invariant representation by the shared causality in both domains. Then, a novel domain-adaptation is built to model treatments and outcomes jointly training on source and target domain. The main insights are that our designed answer-based attention mechanism allows the target domain to leverage the existed causality in source time-series even with different treatments, and our forecaster can predict the counterfactual outcome of industrial time-series, meaning a guidance in production process. Compared with commonly baselines, our method on real-world and synthetic oilfield datasets demonstrates the effectiveness in across-domain prediction and the practicality in guiding production process</description>
      <guid isPermaLink="false">oai:arXiv.org:2407.14214v1</guid>
      <category>cs.LG</category>
      <category>cs.IT</category>
      <category>math.IT</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Chao Min, Guoquan Wen, Jiangru Yuan, Jun Yi, Xing Guo</dc:creator>
    </item>
    <item>
      <title>On the use of Probabilistic Forecasting for Network Analysis in Open RAN</title>
      <link>https://arxiv.org/abs/2407.14375</link>
      <description>arXiv:2407.14375v1 Announce Type: cross 
Abstract: Unlike other single-point Artificial Intelligence (AI)-based prediction techniques, such as Long-Short Term Memory (LSTM), probabilistic forecasting techniques (e.g., DeepAR and Transformer) provide a range of possible outcomes and associated probabilities that enable decision makers to make more informed and robust decisions. At the same time, the architecture of Open RAN has emerged as a revolutionary approach for mobile networks, aiming at openness, interoperability and innovation in the ecosystem of RAN. In this paper, we propose the use of probabilistic forecasting techniques as a radio App (rApp) within the Open RAN architecture. We investigate and compare different probabilistic and single-point forecasting methods and algorithms to estimate the utilization and resource demands of Physical Resource Blocks (PRBs) of cellular base stations. Through our evaluations, we demonstrate the numerical advantages of probabilistic forecasting techniques over traditional single-point forecasting methods and show that they are capable of providing more accurate and reliable estimates. In particular, DeepAR clearly outperforms single-point forecasting techniques such as LSTM and Seasonal-Naive (SN) baselines and other probabilistic forecasting techniques such as Simple-Feed-Forward (SFF) and Transformer neural networks.</description>
      <guid isPermaLink="false">oai:arXiv.org:2407.14375v1</guid>
      <category>cs.NI</category>
      <category>cs.AI</category>
      <category>cs.DC</category>
      <category>cs.IT</category>
      <category>cs.LG</category>
      <category>math.IT</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <arxiv:DOI>10.1109/MeditCom58224.2023.10266607</arxiv:DOI>
      <dc:creator>Vaishnavi Kasuluru, Luis Blanco, Engin Zeydan</dc:creator>
    </item>
    <item>
      <title>Enhancing Cloud-Native Resource Allocation with Probabilistic Forecasting Techniques in O-RAN</title>
      <link>https://arxiv.org/abs/2407.14377</link>
      <description>arXiv:2407.14377v1 Announce Type: cross 
Abstract: The need for intelligent and efficient resource provisioning for the productive management of resources in real-world scenarios is growing with the evolution of telecommunications towards the 6G era. Technologies such as Open Radio Access Network (O-RAN) can help to build interoperable solutions for the management of complex systems. Probabilistic forecasting, in contrast to deterministic single-point estimators, can offer a different approach to resource allocation by quantifying the uncertainty of the generated predictions. This paper examines the cloud-native aspects of O-RAN together with the radio App (rApp) deployment options. The integration of probabilistic forecasting techniques as a rApp in O-RAN is also emphasized, along with case studies of real-world applications. Through a comparative analysis of forecasting models using the error metric, we show the advantages of Deep Autoregressive Recurrent network (DeepAR) over other deterministic probabilistic estimators. Furthermore, the simplicity of Simple-Feed-Forward (SFF) leads to a fast runtime but does not capture the temporal dependencies of the input data. Finally, we present some aspects related to the practical applicability of cloud-native O-RAN with probabilistic forecasting.</description>
      <guid isPermaLink="false">oai:arXiv.org:2407.14377v1</guid>
      <category>cs.NI</category>
      <category>cs.AI</category>
      <category>cs.DC</category>
      <category>cs.IT</category>
      <category>cs.LG</category>
      <category>math.IT</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Vaishnavi Kasuluru, Luis Blanco, Engin Zeydan, Albert Bel, Angelos Antonopoulos</dc:creator>
    </item>
    <item>
      <title>On the Impact of PRB Load Uncertainty Forecasting for Sustainable Open RAN</title>
      <link>https://arxiv.org/abs/2407.14400</link>
      <description>arXiv:2407.14400v1 Announce Type: cross 
Abstract: The transition to sustainable Open Radio Access Network (O-RAN) architectures brings new challenges for resource management, especially in predicting the utilization of Physical Resource Block (PRB)s. In this paper, we propose a novel approach to characterize the PRB load using probabilistic forecasting techniques. First, we provide background information on the O-RAN architecture and components and emphasize the importance of energy/power consumption models for sustainable implementations. The problem statement highlights the need for accurate PRB load prediction to optimize resource allocation and power efficiency. We then investigate probabilistic forecasting techniques, including Simple-Feed-Forward (SFF), DeepAR, and Transformers, and discuss their likelihood model assumptions. The simulation results show that DeepAR estimators predict the PRBs with less uncertainty and effectively capture the temporal dependencies in the dataset compared to SFF- and Transformer-based models, leading to power savings. Different percentile selections can also increase power savings, but at the cost of over-/under provisioning. At the same time, the performance of the Long-Short Term Memory (LSTM) is shown to be inferior to the probabilistic estimators with respect to all error metrics. Finally, we outline the importance of probabilistic, prediction-based characterization for sustainable O-RAN implementations and highlight avenues for future research.</description>
      <guid isPermaLink="false">oai:arXiv.org:2407.14400v1</guid>
      <category>cs.NI</category>
      <category>cs.AI</category>
      <category>cs.DC</category>
      <category>cs.IT</category>
      <category>cs.LG</category>
      <category>math.IT</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Vaishnavi Kasuluru, Luis Blanco, Cristian J. Vaca-Rubio, Engin Zeydan</dc:creator>
    </item>
    <item>
      <title>Extending the Limit Theorem of Barmpalias and Lewis-Pye to all reals</title>
      <link>https://arxiv.org/abs/2407.14445</link>
      <description>arXiv:2407.14445v1 Announce Type: cross 
Abstract: By a celebrated result of Ku\v{c}era and Slaman (DOI:10.1137/S0097539799357441), the Martin-L\"of random left-c.e. reals form the highest left-c.e. Solovay degree. Barmpalias and Lewis-Pye (arXiv:1604.00216) strengthened this result by showing that, for all left-c.e. reals $\alpha$ and $\beta$ such that $\beta$ is Martin-L\"of random and all left-c.e. approximations $a_0,a_1,\dots$ and $b_0,b_1,\dots$ of $\alpha$ and $\beta$, respectively, the limit \begin{equation*}
  \lim\limits_{n\to\infty}\frac{\alpha - a_n}{\beta - b_n} \end{equation*} exists and does not depend on the choice of the left-c.e. approximations to $\alpha$ and $\beta$.
  Here we give an equivalent formulation of the result of Barmpalias and Lewis-Pye in terms of nondecreasing translation functions and generalize their result to the set of all (i.e., not necessarily left-c.e.) reals.</description>
      <guid isPermaLink="false">oai:arXiv.org:2407.14445v1</guid>
      <category>math.LO</category>
      <category>cs.IT</category>
      <category>math.IT</category>
      <category>math.PR</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Ivan Titov</dc:creator>
    </item>
    <item>
      <title>On the matrix code of quadratic relationships for a Goppa code</title>
      <link>https://arxiv.org/abs/2310.20497</link>
      <description>arXiv:2310.20497v2 Announce Type: replace 
Abstract: In this article, we continue the analysis started in \cite{CMT23} for the matrix code of quadratic relationships associated with a Goppa code. We provide new sparse and low-rank elements in the matrix code and categorize them according to their shape. Thanks to this description, we prove that the set of rank 2 matrices in the matrix codes associated with square-free binary Goppa codes, i.e. those used in Classic McEiece, is much larger than what is expected, at least in the case where the Goppa polynomial degree is 2. We build upon the algebraic determinantal modeling introduced in \cite{CMT23} to derive a structural attack on these instances. Our method can break in just a few seconds some recent challenges about key-recovery attacks on the McEliece cryptosystem, consistently reducing their estimated security level. We also provide a general method, valid for any Goppa polynomial degree, to transform a generic pair of support and multiplier into a pair of support and Goppa polynomial.</description>
      <guid isPermaLink="false">oai:arXiv.org:2310.20497v2</guid>
      <category>cs.IT</category>
      <category>cs.CR</category>
      <category>math.IT</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Rocco Mora</dc:creator>
    </item>
    <item>
      <title>Energy-Efficient Channel Decoding for Wireless Federated Learning: Convergence Analysis and Adaptive Design</title>
      <link>https://arxiv.org/abs/2407.13703</link>
      <description>arXiv:2407.13703v2 Announce Type: replace 
Abstract: One of the most critical challenges for deploying distributed learning solutions, such as federated learning (FL), in wireless networks is the limited battery capacity of mobile clients. While it is a common belief that the major energy consumption of mobile clients comes from the uplink data transmission, this paper presents a novel finding, namely the channel decoding operation also contributes significantly to the overall energy consumption of mobile clients in FL. Motivated by this new observation, we propose an energy-efficient adaptive channel decoding scheme that leverages the intrinsic robustness of FL to model errors. In particular, the robustness is exploited to reduce the energy consumption of channel decoders at mobile clients by adaptively adjusting the number of decoding iterations. We theoretically prove that wireless FL with communication errors can converge at the same rate as the case with error-free communication as long as the bit error rate (BER) is properly constrained. An adaptive channel decoding scheme is then proposed to improve the energy efficiency of wireless FL systems. Experimental results demonstrate that the proposed method maintains the same learning accuracy while reducing the channel decoding energy consumption by 20% when compared to existing approaches.</description>
      <guid isPermaLink="false">oai:arXiv.org:2407.13703v2</guid>
      <category>cs.IT</category>
      <category>cs.LG</category>
      <category>eess.SP</category>
      <category>math.IT</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Linping Qu, Yuyi Mao, Shenghui Song, Chi-Ying Tsui</dc:creator>
    </item>
    <item>
      <title>Mapping the Empirical Evidence of the GDPR (In-)Effectiveness: A Systematic Review</title>
      <link>https://arxiv.org/abs/2310.16735</link>
      <description>arXiv:2310.16735v2 Announce Type: replace-cross 
Abstract: In the realm of data protection, a striking disconnect prevails between traditional domains of doctrinal, legal, theoretical, and policy-based inquiries and a burgeoning body of empirical evidence. Much of the scholarly and regulatory discourse remains entrenched in abstract legal principles or normative frameworks, leaving the empirical landscape uncharted or minimally engaged. Since the birth of EU data protection law, a modest body of empirical evidence has been generated but remains widely scattered and unexamined. Such evidence offers vital insights into the perception, impact, clarity, and effects of data protection measures but languishes on the periphery, inadequately integrated into the broader conversation. To make a meaningful connection, we conduct a comprehensive review and synthesis of empirical research spanning nearly three decades (1995- March 2022), advocating for a more robust integration of empirical evidence into the evaluation and review of the GDPR, while laying a methodological foundation for future empirical research.</description>
      <guid isPermaLink="false">oai:arXiv.org:2310.16735v2</guid>
      <category>cs.CY</category>
      <category>cs.AI</category>
      <category>cs.HC</category>
      <category>cs.IT</category>
      <category>math.IT</category>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Wenlong Li, Zihao Li, Wenkai Li, Yueming Zhang, Aolan Li</dc:creator>
    </item>
    <item>
      <title>Private Mean Estimation with Person-Level Differential Privacy</title>
      <link>https://arxiv.org/abs/2405.20405</link>
      <description>arXiv:2405.20405v3 Announce Type: replace-cross 
Abstract: We study person-level differentially private (DP) mean estimation in the case where each person holds multiple samples. DP here requires the usual notion of distributional stability when $\textit{all}$ of a person's datapoints can be modified. Informally, if $n$ people each have $m$ samples from an unknown $d$-dimensional distribution with bounded $k$-th moments, we show that \[n = \tilde \Theta\left(\frac{d}{\alpha^2 m} + \frac{d}{\alpha m^{1/2} \varepsilon} + \frac{d}{\alpha^{k/(k-1)} m \varepsilon} + \frac{d}{\varepsilon}\right)\] people are necessary and sufficient to estimate the mean up to distance $\alpha$ in $\ell_2$-norm under $\varepsilon$-differential privacy (and its common relaxations). In the multivariate setting, we give computationally efficient algorithms under approximate-DP and computationally inefficient algorithms under pure DP, and our nearly matching lower bounds hold for the most permissive case of approximate DP. Our computationally efficient estimators are based on the standard clip-and-noise framework, but the analysis for our setting requires both new algorithmic techniques and new analyses. In particular, our new bounds on the tails of sums of independent, vector-valued, bounded-moments random variables may be of interest.</description>
      <guid isPermaLink="false">oai:arXiv.org:2405.20405v3</guid>
      <category>cs.DS</category>
      <category>cs.CR</category>
      <category>cs.IT</category>
      <category>cs.LG</category>
      <category>math.IT</category>
      <category>stat.ML</category>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Sushant Agarwal, Gautam Kamath, Mahbod Majid, Argyris Mouzakis, Rose Silver, Jonathan Ullman</dc:creator>
    </item>
    <item>
      <title>Tight lower bound on the error exponent of classical-quantum channels</title>
      <link>https://arxiv.org/abs/2407.11118</link>
      <description>arXiv:2407.11118v2 Announce Type: replace-cross 
Abstract: A fundamental quantity of interest in Shannon theory, classical or quantum, is the error exponent of a given channel $W$ and rate $R$: the constant $E(W,R)$ which governs the exponential decay of decoding error when using ever larger optimal codes of fixed rate $R$ to communicate over ever more (memoryless) instances of a given channel $W$. Nearly matching lower and upper bounds are well-known for classical channels. Here I show a lower bound on the error exponent of communication over arbitrary classical-quantum (CQ) channels which matches Dalai's sphere-packing upper bound [IEEE TIT 59, 8027 (2013)] for rates above a critical value, exactly analogous to the case of classical channels. This proves a conjecture made by Holevo in his investigation of the problem [IEEE TIT 46, 2256 (2000)].
  Unlike the classical case, however, the argument does not proceed via a refined analysis of a suitable decoder, but instead by leveraging a bound by Hayashi on the error exponent of the cryptographic task of privacy amplification [CMP 333, 335 (2015)]. This bound is then related to the coding problem via tight entropic uncertainty relations and Gallager's method of constructing capacity-achieving parity-check codes for arbitrary channels. Along the way, I find a lower bound on the error exponent of the task of compression of classical information relative to quantum side information that matches the sphere-packing upper bound of Cheng et al. [IEEE TIT 67, 902 (2021)]. In turn, the polynomial prefactors to the sphere-packing bound found by Cheng et al. may be translated to the privacy amplification problem, sharpening a recent result by Li, Yao, and Hayashi [IEEE TIT 69, 1680 (2023)], at least for linear randomness extractors.</description>
      <guid isPermaLink="false">oai:arXiv.org:2407.11118v2</guid>
      <category>quant-ph</category>
      <category>cs.IT</category>
      <category>math.IT</category>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Joseph M. Renes</dc:creator>
    </item>
  </channel>
</rss>
