<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>stat.CO updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/stat.CO</link>
    <description>stat.CO updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/stat.CO" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Tue, 02 Jul 2024 04:00:44 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Tue, 02 Jul 2024 00:00:00 -0400</pubDate>
    <skipDays>
      <day>Saturday</day>
      <day>Sunday</day>
    </skipDays>
    <item>
      <title>A General Purpose Approximation to the Ferguson-Klass Algorithm for Sampling from L\'evy Processes Without Gaussian Components</title>
      <link>https://arxiv.org/abs/2407.01483</link>
      <description>arXiv:2407.01483v1 Announce Type: new 
Abstract: We propose a general-purpose approximation to the Ferguson-Klass algorithm for generating samples from L\'evy processes without Gaussian components. We show that the proposed method is more than 1000 times faster than the standard Ferguson-Klass algorithm without a significant loss of precision. This method can open an avenue for computationally efficient and scalable Bayesian nonparametric models which go beyond conjugacy assumptions, as demonstrated in the examples section.</description>
      <guid isPermaLink="false">oai:arXiv.org:2407.01483v1</guid>
      <category>stat.CO</category>
      <category>stat.AP</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Dawid Bernaciak, Jim E. Griffin</dc:creator>
    </item>
    <item>
      <title>Multifidelity Cross-validation</title>
      <link>https://arxiv.org/abs/2407.01495</link>
      <description>arXiv:2407.01495v1 Announce Type: new 
Abstract: Emulating the mapping between quantities of interest and their control parameters using surrogate models finds widespread application in engineering design, including in numerical optimization and uncertainty quantification. Gaussian process models can serve as a probabilistic surrogate model of unknown functions, thereby making them highly suitable for engineering design and decision-making in the presence of uncertainty. In this work, we are interested in emulating quantities of interest observed from models of a system at multiple fidelities, which trade accuracy for computational efficiency. Using multifidelity Gaussian process models, to efficiently fuse models at multiple fidelities, we propose a novel method to actively learn the surrogate model via leave-one-out cross-validation (LOO-CV). Our proposed multifidelity cross-validation (\texttt{MFCV}) approach develops an adaptive approach to reduce the LOO-CV error at the target (highest) fidelity, by learning the correlations between the LOO-CV at all fidelities. \texttt{MFCV} develops a two-step lookahead policy to select optimal input-fidelity pairs, both in sequence and in batches, both for continuous and discrete fidelity spaces. We demonstrate the utility of our method on several synthetic test problems as well as on the thermal stress analysis of a gas turbine blade.</description>
      <guid isPermaLink="false">oai:arXiv.org:2407.01495v1</guid>
      <category>stat.CO</category>
      <category>stat.ML</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>S. Ashwin Renganathan, Kade Carlson</dc:creator>
    </item>
    <item>
      <title>Graph Simplification Solutions to the Street Intersection Miscount Problem</title>
      <link>https://arxiv.org/abs/2407.00258</link>
      <description>arXiv:2407.00258v1 Announce Type: cross 
Abstract: Street intersection counts and densities are ubiquitous measures in transport geography and planning. However, typical street network data and typical street network analysis tools can substantially overcount them. This paper explains why this happens and introduces solutions to this problem. It presents the OSMnx package's algorithms to automatically simplify graph models of urban street networks -- via edge simplification and node consolidation -- resulting in faster, parsimonious models and more accurate network measures like intersection counts/densities, street segment lengths, and node degrees. Then it validates these algorithms and conducts a worldwide empirical assessment of count bias to quantify the motivating problem's prevalence. A full accounting of this bias and better methods to attenuate misrepresentations of intersections are necessary for data-driven, evidence-informed transport planning.</description>
      <guid isPermaLink="false">oai:arXiv.org:2407.00258v1</guid>
      <category>physics.soc-ph</category>
      <category>cs.DM</category>
      <category>cs.SY</category>
      <category>eess.SY</category>
      <category>stat.CO</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Geoff Boeing</dc:creator>
    </item>
    <item>
      <title>Deterministic and Stochastic Frank-Wolfe Recursion on Probability Spaces</title>
      <link>https://arxiv.org/abs/2407.00307</link>
      <description>arXiv:2407.00307v1 Announce Type: cross 
Abstract: Motivated by applications in emergency response and experimental design, we consider smooth stochastic optimization problems over probability measures supported on compact subsets of the Euclidean space. With the influence function as the variational object, we construct a deterministic Frank-Wolfe (dFW) recursion for probability spaces, made especially possible by a lemma that identifies a ``closed-form'' solution to the infinite-dimensional Frank-Wolfe sub-problem. Each iterate in dFW is expressed as a convex combination of the incumbent iterate and a Dirac measure concentrating on the minimum of the influence function at the incumbent iterate. To address common application contexts that have access only to Monte Carlo observations of the objective and influence function, we construct a stochastic Frank-Wolfe (sFW) variation that generates a random sequence of probability measures constructed using minima of increasingly accurate estimates of the influence function. We demonstrate that sFW's optimality gap sequence exhibits $O(k^{-1})$ iteration complexity almost surely and in expectation for smooth convex objectives, and $O(k^{-1/2})$ (in Frank-Wolfe gap) for smooth non-convex objectives. Furthermore, we show that an easy-to-implement fixed-step, fixed-sample version of (sFW) exhibits exponential convergence to $\varepsilon$-optimality. We end with a central limit theorem on the observed objective values at the sequence of generated random measures. To further intuition, we include several illustrative examples with exact influence function calculations.</description>
      <guid isPermaLink="false">oai:arXiv.org:2407.00307v1</guid>
      <category>math.OC</category>
      <category>stat.CO</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Di Yu, Shane G. Henderson, Raghu Pasupathy</dc:creator>
    </item>
    <item>
      <title>A note on the relationship between PDE-based precision operators and Mat\'ern covariances</title>
      <link>https://arxiv.org/abs/2407.00471</link>
      <description>arXiv:2407.00471v1 Announce Type: cross 
Abstract: The purpose of this technical note is to summarize the relationship between the marginal variance and correlation length of a Gaussian random field with Mat\'ern covariance and the coefficients of the corresponding partial-differential-equation (PDE)-based precision operator.</description>
      <guid isPermaLink="false">oai:arXiv.org:2407.00471v1</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <category>math.PR</category>
      <category>stat.CO</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Umberto Villa, Thomas O'Leary-Roseberry</dc:creator>
    </item>
    <item>
      <title>Fast Gibbs sampling for the local and global trend Bayesian exponential smoothing model</title>
      <link>https://arxiv.org/abs/2407.00492</link>
      <description>arXiv:2407.00492v1 Announce Type: cross 
Abstract: In Smyl et al. [Local and global trend Bayesian exponential smoothing models. International Journal of Forecasting, 2024.], a generalised exponential smoothing model was proposed that is able to capture strong trends and volatility in time series. This method achieved state-of-the-art performance in many forecasting tasks, but its fitting procedure, which is based on the NUTS sampler, is very computationally expensive. In this work, we propose several modifications to the original model, as well as a bespoke Gibbs sampler for posterior exploration; these changes improve sampling time by an order of magnitude, thus rendering the model much more practically relevant. The new model, and sampler, are evaluated on the M3 dataset and are shown to be competitive, or superior, in terms of accuracy to the original method, while being substantially faster to run.</description>
      <guid isPermaLink="false">oai:arXiv.org:2407.00492v1</guid>
      <category>cs.LG</category>
      <category>stat.CO</category>
      <category>stat.ML</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Xueying Long, Daniel F. Schmidt, Christoph Bergmeir, Slawek Smyl</dc:creator>
    </item>
    <item>
      <title>Hyperparameter Optimization for Randomized Algorithms: A Case Study for Random Features</title>
      <link>https://arxiv.org/abs/2407.00584</link>
      <description>arXiv:2407.00584v1 Announce Type: cross 
Abstract: Randomized algorithms exploit stochasticity to reduce computational complexity. One important example is random feature regression (RFR) that accelerates Gaussian process regression (GPR). RFR approximates an unknown function with a random neural network whose hidden weights and biases are sampled from a probability distribution. Only the final output layer is fit to data. In randomized algorithms like RFR, the hyperparameters that characterize the sampling distribution greatly impact performance, yet are not directly accessible from samples. This makes optimization of hyperparameters via standard (gradient-based) optimization tools inapplicable. Inspired by Bayesian ideas from GPR, this paper introduces a random objective function that is tailored for hyperparameter tuning of vector-valued random features. The objective is minimized with ensemble Kalman inversion (EKI). EKI is a gradient-free particle-based optimizer that is scalable to high-dimensions and robust to randomness in objective functions. A numerical study showcases the new black-box methodology to learn hyperparameter distributions in several problems that are sensitive to the hyperparameter selection: two global sensitivity analyses, integrating a chaotic dynamical system, and solving a Bayesian inverse problem from atmospheric dynamics. The success of the proposed EKI-based algorithm for RFR suggests its potential for automated optimization of hyperparameters arising in other randomized algorithms.</description>
      <guid isPermaLink="false">oai:arXiv.org:2407.00584v1</guid>
      <category>cs.LG</category>
      <category>stat.CO</category>
      <category>stat.ML</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Oliver R. A. Dunbar, Nicholas H. Nelsen, Maya Mutic</dc:creator>
    </item>
    <item>
      <title>Posterior Sampling with Denoising Oracles via Tilted Transport</title>
      <link>https://arxiv.org/abs/2407.00745</link>
      <description>arXiv:2407.00745v1 Announce Type: cross 
Abstract: Score-based diffusion models have significantly advanced high-dimensional data generation across various domains, by learning a denoising oracle (or score) from datasets. From a Bayesian perspective, they offer a realistic modeling of data priors and facilitate solving inverse problems through posterior sampling. Although many heuristic methods have been developed recently for this purpose, they lack the quantitative guarantees needed in many scientific applications.
  In this work, we introduce the \textit{tilted transport} technique, which leverages the quadratic structure of the log-likelihood in linear inverse problems in combination with the prior denoising oracle to transform the original posterior sampling problem into a new `boosted' posterior that is provably easier to sample from. We quantify the conditions under which this boosted posterior is strongly log-concave, highlighting the dependencies on the condition number of the measurement matrix and the signal-to-noise ratio. The resulting posterior sampling scheme is shown to reach the computational threshold predicted for sampling Ising models [Kunisky'23] with a direct analysis, and is further validated on high-dimensional Gaussian mixture models and scalar field $\varphi^4$ models.</description>
      <guid isPermaLink="false">oai:arXiv.org:2407.00745v1</guid>
      <category>cs.LG</category>
      <category>math.PR</category>
      <category>stat.CO</category>
      <category>stat.ML</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Joan Bruna, Jiequn Han</dc:creator>
    </item>
    <item>
      <title>Structured Sketching for Linear Systems</title>
      <link>https://arxiv.org/abs/2407.00746</link>
      <description>arXiv:2407.00746v1 Announce Type: cross 
Abstract: For linear systems $Ax=b$ we develop iterative algorithms based on a sketch-and-project approach. By using judicious choices for the sketch, such as the history of residuals, we develop weighting strategies that enable short recursive formulas. The proposed algorithms have a low memory footprint and iteration complexity compared to regular sketch-and-project methods. In a set of numerical experiments the new methods compare well to GMRES, SYMMLQ and state-of-the-art randomized solvers.</description>
      <guid isPermaLink="false">oai:arXiv.org:2407.00746v1</guid>
      <category>math.NA</category>
      <category>cs.MS</category>
      <category>cs.NA</category>
      <category>stat.CO</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Johannes J Brust, Michael A Saunders</dc:creator>
    </item>
    <item>
      <title>inlabru: software for fitting latent Gaussian models with non-linear predictors</title>
      <link>https://arxiv.org/abs/2407.00791</link>
      <description>arXiv:2407.00791v1 Announce Type: cross 
Abstract: The integrated nested Laplace approximation (INLA) method has become a popular approach for computationally efficient approximate Bayesian computation. In particular, by leveraging sparsity in random effect precision matrices, INLA is commonly used in spatial and spatio-temporal applications. However, the speed of INLA comes at the cost of restricting the user to the family of latent Gaussian models and the likelihoods currently implemented in {INLA}, the main software implementation of the INLA methodology.
  {inlabru} is a software package that extends the types of models that can be fitted using INLA by allowing the latent predictor to be non-linear in its parameters, moving beyond the additive linear predictor framework to allow more complex functional relationships. For inference it uses an approximate iterative method based on the first-order Taylor expansion of the non-linear predictor, fitting the model using INLA for each linearised model configuration.
  {inlabru} automates much of the workflow required to fit models using {R-INLA}, simplifying the process for users to specify, fit and predict from models. There is additional support for fitting joint likelihood models by building each likelihood individually. {inlabru} also supports the direct use of spatial data structures, such as those implemented in the {sf} and {terra} packages.
  In this paper we outline the statistical theory, model structure and basic syntax required for users to understand and develop their own models using {inlabru}. We evaluate the approximate inference method using a Bayesian method checking approach. We provide three examples modelling simulated spatial data that demonstrate the benefits of the additional flexibility provided by {inlabru}.</description>
      <guid isPermaLink="false">oai:arXiv.org:2407.00791v1</guid>
      <category>stat.ME</category>
      <category>stat.CO</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Finn Lindgren, Fabian Bachl, Janine Illian, Man Ho Suen, H{\aa}vard Rue, Andrew E. Seaton</dc:creator>
    </item>
    <item>
      <title>A flexible Bayesian g-formula for causal survival analyses with time-dependent confounding</title>
      <link>https://arxiv.org/abs/2402.02306</link>
      <description>arXiv:2402.02306v2 Announce Type: replace-cross 
Abstract: In longitudinal observational studies with a time-to-event outcome, a common objective in causal analysis is to estimate the causal survival curve under hypothetical intervention scenarios within the study cohort. The g-formula is a particularly useful tool for this analysis. To enhance the traditional parametric g-formula approach, we developed a more adaptable Bayesian g-formula estimator, which incorporates the Bayesian additive regression trees (BART) in the modeling of the time-evolving generative components, aiming to mitigate bias due to model misspecification. Specifically, we introduce a more general class of g-formulas for discrete survival data that can incorporate the longitudinal balancing scores, which serve as an effective method for dimension reduction and are vital when dealing with an expanding array of time-varying confounders. The minimum sufficient formulation of these longitudinal balancing scores is linked to the nature of treatment regimes, whether static or dynamic. For each type of treatment regime, we provide posterior sampling algorithms grounded in the BART framework. We have conducted simulation studies to illustrate the empirical performance of the proposed method and further demonstrate its practical utility using data from the Yale New Haven Health System's (YNHHS) electronic health records.</description>
      <guid isPermaLink="false">oai:arXiv.org:2402.02306v2</guid>
      <category>stat.ME</category>
      <category>stat.CO</category>
      <category>stat.ML</category>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Xinyuan Chen, Liangyuan Hu, Fan Li</dc:creator>
    </item>
  </channel>
</rss>
