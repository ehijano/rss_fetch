<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>q-bio.NC updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/q-bio.NC</link>
    <description>q-bio.NC updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/q-bio.NC" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Fri, 08 Aug 2025 01:28:22 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Thu, 07 Aug 2025 00:00:00 -0400</pubDate>
    <skipDays>
      <day>Sunday</day>
      <day>Saturday</day>
    </skipDays>
    <item>
      <title>Controllable Surface Diffusion Generative Model for Neurodevelopmental Trajectories</title>
      <link>https://arxiv.org/abs/2508.03706</link>
      <description>arXiv:2508.03706v1 Announce Type: new 
Abstract: Preterm birth disrupts the typical trajectory of cortical neurodevelopment, increasing the risk of cognitive and behavioral difficulties. However, outcomes vary widely, posing a significant challenge for early prediction. To address this, individualized simulation offers a promising solution by modeling subject-specific neurodevelopmental trajectories, enabling the identification of subtle deviations from normative patterns that might act as biomarkers of risk. While generative models have shown potential for simulating neurodevelopment, prior approaches often struggle to preserve subject-specific cortical folding patterns or to reproduce region-specific morphological variations. In this paper, we present a novel graph-diffusion network that supports controllable simulation of cortical maturation. Using cortical surface data from the developing Human Connectome Project (dHCP), we demonstrate that the model maintains subject-specific cortical morphology while modeling cortical maturation sufficiently well to fool an independently trained age regression network, achieving a prediction accuracy of $0.85 \pm 0.62$.</description>
      <guid isPermaLink="false">oai:arXiv.org:2508.03706v1</guid>
      <category>q-bio.NC</category>
      <category>cs.AI</category>
      <pubDate>Thu, 07 Aug 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Zhenshan Xie, Levente Baljer, M. Jorge Cardoso, Emma Robinson</dc:creator>
    </item>
    <item>
      <title>Cognitive Effort in the Two-Step Task: An Active Inference Drift-Diffusion Model Approach</title>
      <link>https://arxiv.org/abs/2508.04435</link>
      <description>arXiv:2508.04435v1 Announce Type: new 
Abstract: High-level theories rooted in the Bayesian Brain Hypothesis often frame cognitive effort as the cost of resolving the conflict between habits and optimal policies. In parallel, evidence accumulator models (EAMs) provide a mechanistic account of how effort arises from competition between the subjective values of available options. Although EAMs have been combined with frameworks like Reinforcement Learning to bridge the gap between high-level theories and process-level mechanisms, relatively less attention has been paid to their implications for a unified notion of cognitive effort. Here, we combine Active Inference (AIF) with the Drift-Diffusion Model (DDM) to investigate whether the resulting AIF-DDM can simultaneously account for effort arising from both habit violation and value discriminability. To our knowledge, this is the first time AIF has been combined with an EAM. We tested the AIF-DDM on a behavioral dataset from the two-step task and compared its predictions to an information-theoretic definition of cognitive effort based on AIF. The model's predictions successfully accounted for second-stage reaction times but failed to capture the dynamics of the first stage. We argue the latter discrepancy likely stems from the experimental design rather than a fundamental flaw in the model's assumptions about cognitive effort. Accordingly, we propose several modifications of the two-step task to better measure and isolate cognitive effort. Finally, we found that integrating the DDM significantly improved parameter recovery, which could help future studies to obtain more reliable parameter estimates.</description>
      <guid isPermaLink="false">oai:arXiv.org:2508.04435v1</guid>
      <category>q-bio.NC</category>
      <pubDate>Thu, 07 Aug 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Alvaro Garrido Perez, Viktor Lemoine, Amrapali Pednekar, Yara Khaluf, Pieter Simoens</dc:creator>
    </item>
    <item>
      <title>Relationship between Perceived Maneuverability and Involuntary Eye Movements under Systematically Varied Time Constants of Ride-on Machinery</title>
      <link>https://arxiv.org/abs/2508.03717</link>
      <description>arXiv:2508.03717v1 Announce Type: cross 
Abstract: Studies suggest that involuntary eye movements exhibit greater stability during active motion compared to passive motion, and this effect may also apply to the operation of ride-on machinery. Moreover, a study suggested that experimentally manipulating the sense of agency (SoA) by introducing delays may influence the stability of involuntary eye movements. Although a preliminary investigation examined involuntary eye movements and perceived maneuverability under two distinct machine dynamics with preserved SoA, it remains unclear how systematic variations in motion dynamics influence these factors. Therefore, the purpose of the present research was to investigate whether systematic variations in the dynamic properties of a ride-on machine, where the perceived maneuverability is modulated, influence the accuracy of involuntary eye movements in human operators. Participants rode a yaw-rotational platform whose time constant from joystick input to motor torque of a rotational machine was systematically manipulated. During the operation, eye movements were recorded while participants fixated on a visual target. After each condition, participants provided subjective ratings of maneuverability and cognitive load. As the platform's time constant increased, the perceived maneuverability scores decreased while the cognitive loads increased. Concurrently, involuntary eye movement accuracy decreased. Moderate to weak positive correlations emerged between the perceived maneuverability scores and the eye movement gain and accuracy, while a weak negative correlation was found with cognitive load.</description>
      <guid isPermaLink="false">oai:arXiv.org:2508.03717v1</guid>
      <category>cs.HC</category>
      <category>q-bio.NC</category>
      <pubDate>Thu, 07 Aug 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Muhammad Akmal Bin Mohammed Zaffir, Daisuke Sakai, Yuki Sato, Takahiro Wada</dc:creator>
    </item>
    <item>
      <title>From eye to AI: studying rodent social behavior in the era of machine Learning</title>
      <link>https://arxiv.org/abs/2508.04255</link>
      <description>arXiv:2508.04255v1 Announce Type: cross 
Abstract: The study of rodent social behavior has shifted in the last years from relying on direct human observation to more nuanced approaches integrating computational methods in artificial intelligence (AI) and machine learning. While conventional approaches introduce bias and can fail to capture the complexity of rodent social interactions, modern approaches bridging computer vision, ethology and neuroscience provide more multifaceted insights into behavior which are particularly relevant to social neuroscience. Despite these benefits, the integration of AI into social behavior research also poses several challenges. Here we discuss the main steps involved and the tools available for analyzing rodent social behavior, examining their advantages and limitations. Additionally, we suggest practical solutions to address common hurdles, aiming to guide young researchers in adopting these methods and to stimulate further discussion among experts regarding the evolving requirements of these tools in scientific applications.</description>
      <guid isPermaLink="false">oai:arXiv.org:2508.04255v1</guid>
      <category>cs.CV</category>
      <category>q-bio.NC</category>
      <pubDate>Thu, 07 Aug 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Giuseppe Chindemi, Camilla Bellone, Benoit Girard</dc:creator>
    </item>
    <item>
      <title>Artificial Consciousness as Interface Representation</title>
      <link>https://arxiv.org/abs/2508.04383</link>
      <description>arXiv:2508.04383v1 Announce Type: cross 
Abstract: Whether artificial intelligence (AI) systems can possess consciousness is a contentious question because of the inherent challenges of defining and operationalizing subjective experience. This paper proposes a framework to reframe the question of artificial consciousness into empirically tractable tests. We introduce three evaluative criteria - S (subjective-linguistic), L (latent-emergent), and P (phenomenological-structural) - collectively termed SLP-tests, which assess whether an AI system instantiates interface representations that facilitate consciousness-like properties. Drawing on category theory, we model interface representations as mappings between relational substrates (RS) and observable behaviors, akin to specific types of abstraction layers. The SLP-tests collectively operationalize subjective experience not as an intrinsic property of physical systems but as a functional interface to a relational entity.</description>
      <guid isPermaLink="false">oai:arXiv.org:2508.04383v1</guid>
      <category>cs.AI</category>
      <category>q-bio.NC</category>
      <pubDate>Thu, 07 Aug 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <arxiv:DOI>10.1007/978-3-032-00800-8_12</arxiv:DOI>
      <arxiv:journal_reference>LNAI 16058, 2025</arxiv:journal_reference>
      <dc:creator>Robert Prentner</dc:creator>
    </item>
    <item>
      <title>Ordinal Characterization of Similarity Judgments</title>
      <link>https://arxiv.org/abs/2310.07543</link>
      <description>arXiv:2310.07543v5 Announce Type: replace 
Abstract: Characterizing judgments of similarity within a perceptual or semantic domain, and making inferences about the underlying structure of this domain from these judgments, has an increasingly important role in cognitive and systems neuroscience. We present a new framework for this purpose that makes limited assumptions about how perceptual distances are converted into similarity judgments. The approach starts from a dataset of empirical judgments of relative similarities: the fraction of times that a subject chooses one of two comparison stimuli to be more similar to a reference stimulus. These empirical judgments provide Bayesian estimates of underling choice probabilities. From these estimates, we derive indices that characterize the set of judgments in three ways: compatibility with a symmetric dis-similarity, compatibility with an ultrametric space, and compatibility with an additive tree. Each of the indices is derived from rank-order relationships among the choice probabilities that, as we show, are necessary and sufficient for local consistency with the three respective characteristics. We illustrate this approach with simulations and example psychophysical datasets of dis-similarity judgments in several visual domains and provide code that implements the analyses at https://github.com/jvlab/simrank.</description>
      <guid isPermaLink="false">oai:arXiv.org:2310.07543v5</guid>
      <category>q-bio.NC</category>
      <category>q-bio.QM</category>
      <pubDate>Thu, 07 Aug 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <arxiv:DOI>10.46298/mna.12457</arxiv:DOI>
      <dc:creator>Jonathan D. Victor, Guillermo Aguilar, Suniyya A. Waraich</dc:creator>
    </item>
    <item>
      <title>Brain functions emerge as thermal equilibrium states of the connectome</title>
      <link>https://arxiv.org/abs/2408.14221</link>
      <description>arXiv:2408.14221v3 Announce Type: replace 
Abstract: A fundamental idea in neuroscience is that cognitive functions -- such as perception, learning, memory, and locomotion -- are shaped and constrained by the brain's structural organization. Despite significant progress in mapping and analyzing structural connectomes, the principles linking the brain's physical architecture to its functional capabilities remain elusive. Here, we introduce an algebraic quantum model to bridge this theoretical gap, offering new insights into the relationship between the connectome and emergent brain functions, while connecting structural data to functional predictions. Using the well-mapped C. elegans anatomical and extrasynaptic connectomes, we demonstrate that brain functions, defined as functional networks of a neural system, emerge as thermal equilibrium states of an algebraic quantum system derived from the graph algebra of the underlying directed multigraph. Specifically, these equilibrium states, characterized by the Kubo-Martin-Schwinger (KMS) formalism, reveal how individual neurons contribute to functional network formation. Our model illuminates the structure-function relationship in neural circuits through two key features: (1) a functional connectome that delineates topologically driven neuronal interactions and (2) an Integration Capacity (IC) index that quantifies how effectively neurons coordinate and modulate diverse information flows. Together, these features provide a statistical and mechanistic account of information flow and reveal how the network topology of the connectome predicts cognition and complex behaviors.</description>
      <guid isPermaLink="false">oai:arXiv.org:2408.14221v3</guid>
      <category>q-bio.NC</category>
      <category>cond-mat.dis-nn</category>
      <category>cond-mat.stat-mech</category>
      <category>math.OA</category>
      <category>quant-ph</category>
      <pubDate>Thu, 07 Aug 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <arxiv:DOI>10.1103/jmqh-bqnc</arxiv:DOI>
      <dc:creator>Elka\"ioum M. Moutuou, Habib Benali</dc:creator>
    </item>
    <item>
      <title>The Spatiotemporal Organization of Motor Cortex Activity Supporting Manual Dexterity</title>
      <link>https://arxiv.org/abs/2506.21738</link>
      <description>arXiv:2506.21738v2 Announce Type: replace 
Abstract: Motor cortex (M1) is a crucial brain area for controlling voluntary movements, such as reaching and grasping for a cup of coffee. M1 is organized in a somatotopic manner, such that M1 output driving movement to different parts of the body is organized along the cortical surface. In primates, the arm and hand are represented in M1 as separate but overlapping territories. Unit activity recorded from the M1 forelimb representation comodulates with parameters related to reaching and/or grasping. The overall aim of this dissertation is to understand the spatiotemporal dynamics of M1 activity that produces reach-to-grasp movements. To address this goal, intracortical microstimulation (ICMS) is delivered along the precentral gyrus of two macaque monkeys to define the M1 motor map. Subsequently, cortical activity is recorded from the M1 forelimb representation using intrinsic signal optical imaging (ISOI) while macaques execute an instructed reach-to-grasp task. Results from imaging experiments produce spatial maps that define cortical territories with increased activity during reach-to-grasp movements. Next, unit activity was recorded from the M1 forelimb representation with a laminar multielectrode while macaques completed the same reach-to-grasp task. Recording site locations differed between sessions to comprehensively sample unit responses throughout the M1 forelimb representation. Imaging experiments reveal that activity supporting reach-to-grasp movements was concentrated in patches that comprise less than half of the M1 forelimb representation. Electrophysiology recordings reveal that activity related to reaching is spatially organized within M1 distinctly from activity related to grasping. The results support the idea that spatial organizing principles are inherent in M1 activity that supports reach-to-grasp movements.</description>
      <guid isPermaLink="false">oai:arXiv.org:2506.21738v2</guid>
      <category>q-bio.NC</category>
      <pubDate>Thu, 07 Aug 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Nicholas Chehade</dc:creator>
    </item>
    <item>
      <title>The Multi-biophysical nature of Computation in brain neural networks</title>
      <link>https://arxiv.org/abs/2508.03115</link>
      <description>arXiv:2508.03115v2 Announce Type: replace 
Abstract: Comprehending the nature of action potentials is fundamental to our understanding of the functioning of nervous systems in general. The ionic mechanisms underlying action potentials in the squid giant axon were first described by Hodgkin and Huxley in 1952 and their findings have formed our orthodox view of how the physiological action potential functions. However, substan-tial evidence has now accumulated to show that the action potential is accompanied by a syn-chronized coupled soliton pressure pulse in the cell membrane, the action potential pulse (AP-Pulse) which we have recently shown to have an essential function in computation. Here we ex-plore the interactions between the soliton and the ionic mechanisms known to be associated with the action potential. Computational models of the action potential usually describe it as a binary event, but we have shown that it must be a quantum ternary event known as the computa-tional action potential (CAP), whose temporal fixed point is the threshold of the soliton, rather than the rather plastic action potential peak used in other models to facilitate meaningful compu-tation. We have demonstrated this type of frequency computation for the retina, in detail, and also provided an extensive analysis for computation for other brain neural networks. The CAP ac-companies the APPulse and the Physiological action potential. Therefore, we conclude that nerve impulses appear to be an ensemble of three inseparable, interdependent, concurrent states: the physiological action potential, the APPulse and the CAP. However, while the physio-logical action potential is important in terms of neural connectivity, it is irrelevant to computational processes as this is always facilitated by the soliton part of the APPulse.</description>
      <guid isPermaLink="false">oai:arXiv.org:2508.03115v2</guid>
      <category>q-bio.NC</category>
      <pubDate>Thu, 07 Aug 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <dc:creator>William Winlow, Andrew Simon Johnson</dc:creator>
    </item>
    <item>
      <title>pyhgf: A neural network library for predictive coding</title>
      <link>https://arxiv.org/abs/2410.09206</link>
      <description>arXiv:2410.09206v2 Announce Type: replace-cross 
Abstract: Bayesian models of cognition have gained considerable traction in computational neuroscience and psychiatry. Their scopes are now expected to expand rapidly to artificial intelligence, providing general inference frameworks to support embodied, adaptable, and energy-efficient autonomous agents. A central theory in this domain is predictive coding, which posits that learning and behaviour are driven by hierarchical probabilistic inferences about the causes of sensory inputs. Biological realism constrains these networks to rely on simple local computations in the form of precision-weighted predictions and prediction errors. This can make this framework highly efficient, but its implementation comes with unique challenges on the software development side. Embedding such models in standard neural network libraries often becomes limiting, as these libraries' compilation and differentiation backends can force a conceptual separation between optimization algorithms and the systems being optimized. This critically departs from other biological principles such as self-monitoring, self-organisation, cellular growth and functional plasticity. In this paper, we introduce \texttt{pyhgf}: a Python package backed by JAX and Rust for creating, manipulating and sampling dynamic networks for predictive coding. We improve over other frameworks by enclosing the network components as transparent, modular and malleable variables in the message-passing steps. The resulting graphs can implement arbitrary computational complexities as beliefs propagation. But the transparency of core variables can also translate into inference processes that leverage self-organisation principles, and express structure learning, meta-learning or causal discovery as the consequence of network structural adaptation to surprising inputs. The code, tutorials and documentation are hosted at: https://github.com/ilabcode/pyhgf.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.09206v2</guid>
      <category>cs.NE</category>
      <category>cs.AI</category>
      <category>cs.LG</category>
      <category>q-bio.NC</category>
      <pubDate>Thu, 07 Aug 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Nicolas Legrand, Lilian Weber, Peter Thestrup Waade, Anna Hedvig M{\o}ller Daugaard, Mojtaba Khodadadi, Nace Miku\v{s}, Chris Mathys</dc:creator>
    </item>
    <item>
      <title>Algorithm Development in Neural Networks: Insights from the Streaming Parity Task</title>
      <link>https://arxiv.org/abs/2507.09897</link>
      <description>arXiv:2507.09897v2 Announce Type: replace-cross 
Abstract: Even when massively overparameterized, deep neural networks show a remarkable ability to generalize. Research on this phenomenon has focused on generalization within distribution, via smooth interpolation. Yet in some settings neural networks also learn to extrapolate to data far beyond the bounds of the original training set, sometimes even allowing for infinite generalization, implying that an algorithm capable of solving the task has been learned. Here we undertake a case study of the learning dynamics of recurrent neural networks (RNNs) trained on the streaming parity task in order to develop an effective theory of algorithm development. The streaming parity task is a simple but nonlinear task defined on sequences up to arbitrary length. We show that, with sufficient finite training experience, RNNs exhibit a phase transition to perfect infinite generalization. Using an effective theory for the representational dynamics, we find an implicit representational merger effect which can be interpreted as the construction of a finite automaton that reproduces the task. Overall, our results disclose one mechanism by which neural networks can generalize infinitely from finite training experience.</description>
      <guid isPermaLink="false">oai:arXiv.org:2507.09897v2</guid>
      <category>cs.LG</category>
      <category>q-bio.NC</category>
      <pubDate>Thu, 07 Aug 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Loek van Rossem, Andrew M. Saxe</dc:creator>
    </item>
  </channel>
</rss>
