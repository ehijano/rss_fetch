<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>cs.ET updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/cs.ET</link>
    <description>cs.ET updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/cs.ET" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Wed, 09 Apr 2025 01:53:14 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Tue, 08 Apr 2025 00:00:00 -0400</pubDate>
    <skipDays>
      <day>Sunday</day>
      <day>Saturday</day>
    </skipDays>
    <item>
      <title>Reconfigurable Time-Domain In-Memory Computing Marco using CAM FeFET with Multilevel Delay Calibration in 28 nm CMOS</title>
      <link>https://arxiv.org/abs/2504.03925</link>
      <description>arXiv:2504.03925v1 Announce Type: new 
Abstract: Time-domain nonvolatile in-memory computing (TD-nvIMC) architectures enhance energy efficiency by reducing data movement and data converter power. This work presents a reconfigurable TD-nvIMC accelerator integrating on-die a ferroelectric FET content-addressable memory array, delay element chain, and time-to-digital converter. Fabricated in 28 nm CMOS, it supports binary MAC operations using XOR/AND for multiplication and Boolean logic. FeFET-based nvIMC with 550 ps step size is empirically demonstrated, almost 2000$\times$ improvement from previous works. Write-disturb prevention and multilevel state (MLS) is demonstrated using isolated bulks. Delay element mismatch is compensated through an on-die MLS calibration for robust operation with a high temporal resolution of 100 ps. The proposed architecture can achieve a throughput of 232 GOPS and energy efficiency of 1887 TOPS/W with a 0.85-V supply, making it a promising candidate for efficient in-memory computing.</description>
      <guid isPermaLink="false">oai:arXiv.org:2504.03925v1</guid>
      <category>cs.ET</category>
      <category>cs.AR</category>
      <pubDate>Tue, 08 Apr 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Jeries Mattar, Mor M. Dahan, Stefan Dunkel, Halid Mulaosmanovic, Sven Beyer, Eilam Yalon, Nicol\'as Wainstein</dc:creator>
    </item>
    <item>
      <title>pc-COP: An Efficient and Configurable 2048-p-Bit Fully-Connected Probabilistic Computing Accelerator for Combinatorial Optimization</title>
      <link>https://arxiv.org/abs/2504.04543</link>
      <description>arXiv:2504.04543v1 Announce Type: new 
Abstract: Probabilistic computing is an emerging quantum-inspired computing paradigm capable of solving combinatorial optimization and various other classes of computationally hard problems. In this work, we present pc-COP, an efficient and configurable probabilistic computing hardware accelerator with 2048 fully connected probabilistic bits (p-bits) implemented on Xilinx UltraScale+ FPGA. We propose a pseudo-parallel p-bit update architecture with speculate-and-select logic which improves overall performance by $4 \times$ compared to the traditional sequential p-bit update. Using our FPGA-based accelerator, we demonstrate the standard G-Set graph maximum cut benchmarks with near-99% average accuracy. Compared to state-of-the-art hardware implementations, we achieve similar performance and accuracy with lower FPGA resource utilization.</description>
      <guid isPermaLink="false">oai:arXiv.org:2504.04543v1</guid>
      <category>cs.ET</category>
      <pubDate>Tue, 08 Apr 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <arxiv:DOI>10.1109/HPEC62836.2024.10938509</arxiv:DOI>
      <arxiv:journal_reference>IEEE HPEC (2024) 1-7</arxiv:journal_reference>
      <dc:creator>Kiran Magar, Shreya Bharathan, Utsav Banerjee</dc:creator>
    </item>
    <item>
      <title>Augmenting Anonymized Data with AI: Exploring the Feasibility and Limitations of Large Language Models in Data Enrichment</title>
      <link>https://arxiv.org/abs/2504.03778</link>
      <description>arXiv:2504.03778v1 Announce Type: cross 
Abstract: Large Language Models (LLMs) have demonstrated advanced capabilities in both text generation and comprehension, and their application to data archives might facilitate the privatization of sensitive information about the data subjects. In fact, the information contained in data often includes sensitive and personally identifiable details. This data, if not safeguarded, may bring privacy risks in terms of both disclosure and identification. Furthermore, the application of anonymisation techniques, such as k-anonymity, can lead to a significant reduction in the amount of data within data sources, which may reduce the efficacy of predictive processes. In our study, we investigate the capabilities offered by LLMs to enrich anonymized data sources without affecting their anonymity. To this end, we designed new ad-hoc prompt template engineering strategies to perform anonymized Data Augmentation and assess the effectiveness of LLM-based approaches in providing anonymized data. To validate the anonymization guarantees provided by LLMs, we exploited the pyCanon library, designed to assess the values of the parameters associated with the most common privacy-preserving techniques via anonymization. Our experiments conducted on real-world datasets demonstrate that LLMs yield promising results for this goal.</description>
      <guid isPermaLink="false">oai:arXiv.org:2504.03778v1</guid>
      <category>cs.CR</category>
      <category>cs.ET</category>
      <pubDate>Tue, 08 Apr 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <arxiv:journal_reference>3rd Italian Conference on Big Data and Data Science (ITADATA 2024)</arxiv:journal_reference>
      <dc:creator>Stefano Cirillo, Domenico Desiato, Giuseppe Polese, Monica Maria Lucia Sebillo, Giandomenico Solimando</dc:creator>
    </item>
    <item>
      <title>Secure Federated XGBoost with CUDA-accelerated Homomorphic Encryption via NVIDIA FLARE</title>
      <link>https://arxiv.org/abs/2504.03909</link>
      <description>arXiv:2504.03909v1 Announce Type: cross 
Abstract: Federated learning (FL) enables collaborative model training across decentralized datasets. NVIDIA FLARE's Federated XGBoost extends the popular XGBoost algorithm to both vertical and horizontal federated settings, facilitating joint model development without direct data sharing. However, the initial implementation assumed mutual trust over the sharing of intermediate gradient statistics produced by the XGBoost algorithm, leaving potential vulnerabilities to honest-but-curious adversaries. This work introduces "Secure Federated XGBoost", an efficient solution to mitigate these risks. We implement secure federated algorithms for both vertical and horizontal scenarios, addressing diverse data security patterns. To secure the messages, we leverage homomorphic encryption (HE) to protect sensitive information during training. A novel plugin and processor interface seamlessly integrates HE into the Federated XGBoost pipeline, enabling secure aggregation over ciphertexts. We present both CPU-based and CUDA-accelerated HE plugins, demonstrating significant performance gains. Notably, our CUDA-accelerated HE implementation achieves up to 30x speedups in vertical Federated XGBoost compared to existing third-party solutions. By securing critical computation steps and encrypting sensitive assets, Secure Federated XGBoost provides robust data privacy guarantees, reinforcing the fundamental benefits of federated learning while maintaining high performance.</description>
      <guid isPermaLink="false">oai:arXiv.org:2504.03909v1</guid>
      <category>cs.CR</category>
      <category>cs.DC</category>
      <category>cs.ET</category>
      <pubDate>Tue, 08 Apr 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Ziyue Xu, Yuan-Ting Hsieh, Zhihong Zhang, Holger R. Roth, Chester Chen, Yan Cheng, Andrew Feng</dc:creator>
    </item>
    <item>
      <title>Bridging LMS and Generative AI: Dynamic Course Content Integration (DCCI) for Connecting LLMs to Course Content -- The Ask ME Assistant</title>
      <link>https://arxiv.org/abs/2504.03966</link>
      <description>arXiv:2504.03966v1 Announce Type: cross 
Abstract: The integration of Large Language Models (LLMs) with Learning Management Systems (LMSs) has the potential to enhance task automation and accessibility in education. However, hallucination where LLMs generate inaccurate or misleading information remains a significant challenge. This study introduces the Dynamic Course Content Integration (DCCI) mechanism, which dynamically retrieves and integrates course content and curriculum from Canvas LMS into the LLM-powered assistant, Ask ME. By employing prompt engineering to structure retrieved content within the LLM's context window, DCCI ensures accuracy, relevance, and contextual alignment, mitigating hallucination. To evaluate DCCI's effectiveness, Ask ME's usability, and broader student perceptions of AI in education, a mixed-methods approach was employed, incorporating user satisfaction ratings and a structured survey. Results from a pilot study indicate high user satisfaction (4.614/5), with students recognizing Ask ME's ability to provide timely and contextually relevant responses for both administrative and course-related inquiries. Additionally, a majority of students agreed that Ask ME's integration with course content in Canvas LMS reduced platform-switching, improving usability, engagement, and comprehension. AI's role in reducing classroom hesitation and fostering self-directed learning and intellectual curiosity was also highlighted. Despite these benefits and positive perception of AI tools, concerns emerged regarding over-reliance on AI, accuracy limitations, and ethical issues such as plagiarism and reduced student-teacher interaction. These findings emphasize the need for strategic AI implementation, ethical safeguards, and a pedagogical framework that prioritizes human-AI collaboration over substitution.</description>
      <guid isPermaLink="false">oai:arXiv.org:2504.03966v1</guid>
      <category>cs.CY</category>
      <category>cs.AI</category>
      <category>cs.ET</category>
      <category>cs.HC</category>
      <category>cs.SE</category>
      <pubDate>Tue, 08 Apr 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <arxiv:DOI>10.21203/rs.3.rs-6256444/v1</arxiv:DOI>
      <dc:creator>Kovan Mzwri (Doctoral School of Informatics, E\"otv\"os Lor\'and University, Budapest, Hungary), M\'arta Turcs\'anyi-Szabo (Department of Media &amp; Educational Technology, Faculty of Informatics, E\"otv\"os Lor\'and University, Budapest, Hungary)</dc:creator>
    </item>
    <item>
      <title>Multi-Phase Coupled CMOS Ring Oscillator based Potts Machine</title>
      <link>https://arxiv.org/abs/2504.04223</link>
      <description>arXiv:2504.04223v1 Announce Type: cross 
Abstract: This paper presents a coupled ring oscillator based Potts ma chine to solve NP-hard combinatorial optimization problems
  (COPs). Potts model is a generalization of the Ising model, cap turing multivalued spins in contrast to the binary-valued spins
  allowed in the Ising model. Similar to recent literature on Ising
  machines, the proposed architecture of Potts machines imple ments the Potts model with interacting spins represented by cou pled ring oscillators. Unlike Ising machines which are limited
  to two spin values, Potts machines model COPs that require a
  larger number of spin values. A major novelty of the proposed
  Potts machine is the utilization of the N-SHIL (Sub-Harmonic
  Injection Locking) mechanism, where multiple stable phases are
  obtained from a single (i.e. ring) oscillator. In evaluation, 3 coloring problems from the DIMACS SATBLIB benchmark and
  two randomly generated larger problems are mapped to the pro posed architecture. The proposed architecture is demonstrated
  to solve problems of varying size with 89% to 92% accuracy
  averaged over multiple iterations. The simulation results show
  that there is no degradation in accuracy, no significant increase
  in solution time, and only a linear increase in power dissipation
  with increasing problem sizes up to 2000 nodes.</description>
      <guid isPermaLink="false">oai:arXiv.org:2504.04223v1</guid>
      <category>cs.AR</category>
      <category>cs.ET</category>
      <pubDate>Tue, 08 Apr 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <arxiv:DOI>10.1145/3676536.3676720</arxiv:DOI>
      <dc:creator>Yilmaz Ege Gonul, Baris Taskin</dc:creator>
    </item>
    <item>
      <title>Impact of Error Rate Misreporting on Resource Allocation in Multi-tenant Quantum Computing and Defense</title>
      <link>https://arxiv.org/abs/2504.04285</link>
      <description>arXiv:2504.04285v1 Announce Type: cross 
Abstract: Cloud-based quantum service providers allow multiple users to run programs on shared hardware concurrently to maximize resource utilization and minimize operational costs. This multi-tenant computing (MTC) model relies on the error parameters of the hardware for fair qubit allocation and scheduling, as error-prone qubits can degrade computational accuracy asymmetrically for users sharing the hardware. To maintain low error rates, quantum providers perform periodic hardware calibration, often relying on third-party calibration services. If an adversary within this calibration service misreports error rates, the allocator can be misled into making suboptimal decisions even when the physical hardware remains unchanged. We demonstrate such an attack model in which an adversary strategically misreports qubit error rates to reduce hardware throughput, and probability of successful trial (PST) for two previously proposed allocation frameworks, i.e. Greedy and Community-Based Dynamic Allocation Partitioning (COMDAP). Experimental results show that adversarial misreporting increases execution latency by 24% and reduces PST by 7.8%. We also propose to identify inconsistencies in reported error rates by analyzing statistical deviations in error rates across calibration cycles.</description>
      <guid isPermaLink="false">oai:arXiv.org:2504.04285v1</guid>
      <category>quant-ph</category>
      <category>cs.CR</category>
      <category>cs.ET</category>
      <pubDate>Tue, 08 Apr 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Subrata Das, Swaroop Ghosh</dc:creator>
    </item>
    <item>
      <title>Beyond Answers: How LLMs Can Pursue Strategic Thinking in Education</title>
      <link>https://arxiv.org/abs/2504.04815</link>
      <description>arXiv:2504.04815v1 Announce Type: cross 
Abstract: Artificial Intelligence (AI) holds transformative potential in education, enabling personalized learning, enhancing inclusivity, and encouraging creativity and curiosity. In this paper, we explore how Large Language Models (LLMs) can act as both patient tutors and collaborative partners to enhance education delivery. As tutors, LLMs personalize learning by offering step-by-step explanations and addressing individual needs, making education more inclusive for students with diverse backgrounds or abilities. As collaborators, they expand students' horizons, supporting them in tackling complex, real-world problems and co-creating innovative projects. However, to fully realize these benefits, LLMs must be leveraged not as tools for providing direct solutions but rather to guide students in developing resolving strategies and finding learning paths together. Therefore, a strong emphasis should be placed on educating students and teachers on the successful use of LLMs to ensure their effective integration into classrooms. Through practical examples and real-world case studies, this paper illustrates how LLMs can make education more inclusive and engaging while empowering students to reach their full potential.</description>
      <guid isPermaLink="false">oai:arXiv.org:2504.04815v1</guid>
      <category>cs.CY</category>
      <category>cs.ET</category>
      <category>eess.SP</category>
      <pubDate>Tue, 08 Apr 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-sa/4.0/</dc:rights>
      <dc:creator>Eleonora Grassucci, Gualtiero Grassucci, Aurelio Uncini, Danilo Comminiello</dc:creator>
    </item>
    <item>
      <title>Measuring the right thing: justifying metrics in AI impact assessments</title>
      <link>https://arxiv.org/abs/2504.05007</link>
      <description>arXiv:2504.05007v1 Announce Type: cross 
Abstract: AI Impact Assessments are only as good as the measures used to assess the impact of these systems. It is therefore paramount that we can justify our choice of metrics in these assessments, especially for difficult to quantify ethical and social values. We present a two-step approach to ensure metrics are properly motivated. First, a conception needs to be spelled out (e.g. Rawlsian fairness or fairness as solidarity) and then a metric can be fitted to that conception. Both steps require separate justifications, as conceptions can be judged on how well they fit with the function of, for example, fairness. We argue that conceptual engineering offers helpful tools for this step. Second, metrics need to be fitted to a conception. We illustrate this process through an examination of competing fairness metrics to illustrate that here the additional content that a conception offers helps us justify the choice for a specific metric. We thus advocate that impact assessments are not only clear on their metrics, but also on the conceptions that motivate those metrics.</description>
      <guid isPermaLink="false">oai:arXiv.org:2504.05007v1</guid>
      <category>cs.CY</category>
      <category>cs.AI</category>
      <category>cs.ET</category>
      <pubDate>Tue, 08 Apr 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Stefan Buijsman, Herman Veluwenkamp</dc:creator>
    </item>
    <item>
      <title>A Survey on Deep Learning Hardware Accelerators for Heterogeneous HPC Platforms</title>
      <link>https://arxiv.org/abs/2306.15552</link>
      <description>arXiv:2306.15552v3 Announce Type: replace-cross 
Abstract: Recent trends in deep learning (DL) have made hardware accelerators essential for various high-performance computing (HPC) applications, including image classification, computer vision, and speech recognition. This survey summarizes and classifies the most recent developments in DL accelerators, focusing on their role in meeting the performance demands of HPC applications. We explore cutting-edge approaches to DL acceleration, covering not only GPU- and TPU-based platforms but also specialized hardware such as FPGA- and ASIC-based accelerators, Neural Processing Units, open hardware RISC-V-based accelerators, and co-processors. This survey also describes accelerators leveraging emerging memory technologies and computing paradigms, including 3D-stacked Processor-In-Memory, non-volatile memories like Resistive RAM and Phase Change Memories used for in-memory computing, as well as Neuromorphic Processing Units, and Multi-Chip Module-based accelerators. Furthermore, we provide insights into emerging quantum-based accelerators and photonics. Finally, this survey categorizes the most influential architectures and technologies from recent years, offering readers a comprehensive perspective on the rapidly evolving field of deep learning acceleration.</description>
      <guid isPermaLink="false">oai:arXiv.org:2306.15552v3</guid>
      <category>cs.AR</category>
      <category>cs.ET</category>
      <category>cs.LG</category>
      <pubDate>Tue, 08 Apr 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Cristina Silvano, Daniele Ielmini, Fabrizio Ferrandi, Leandro Fiorin, Serena Curzel, Luca Benini, Francesco Conti, Angelo Garofalo, Cristian Zambelli, Enrico Calore, Sebastiano Fabio Schifano, Maurizio Palesi, Giuseppe Ascia, Davide Patti, Nicola Petra, Davide De Caro, Luciano Lavagno, Teodoro Urso, Valeria Cardellini, Gian Carlo Cardarilli, Robert Birke, Stefania Perri</dc:creator>
    </item>
    <item>
      <title>Quantum Computing: Vision and Challenges</title>
      <link>https://arxiv.org/abs/2403.02240</link>
      <description>arXiv:2403.02240v5 Announce Type: replace-cross 
Abstract: The recent development of quantum computing, which uses entanglement, superposition, and other quantum fundamental concepts, can provide substantial processing advantages over traditional computing. These quantum features help solve many complex problems that cannot be solved otherwise with conventional computing methods. These problems include modeling quantum mechanics, logistics, chemical-based advances, drug design, statistical science, sustainable energy, banking, reliable communication, and quantum chemical engineering. The last few years have witnessed remarkable progress in quantum software and algorithm creation and quantum hardware research, which has significantly advanced the prospect of realizing quantum computers. It would be helpful to have comprehensive literature research on this area to grasp the current status and find outstanding problems that require considerable attention from the research community working in the quantum computing industry. To better understand quantum computing, this paper examines the foundations and vision based on current research in this area. We discuss cutting-edge developments in quantum computer hardware advancement and subsequent advances in quantum cryptography, quantum software, and high-scalability quantum computers. Many potential challenges and exciting new trends for quantum technology research and development are highlighted in this paper for a broader debate.</description>
      <guid isPermaLink="false">oai:arXiv.org:2403.02240v5</guid>
      <category>cs.DC</category>
      <category>cs.ET</category>
      <category>quant-ph</category>
      <pubDate>Tue, 08 Apr 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Sukhpal Singh Gill, Oktay Cetinkaya, Stefano Marrone, Daniel Claudino, David Haunschild, Leon Schlote, Huaming Wu, Carlo Ottaviani, Xiaoyuan Liu, Sree Pragna Machupalli, Kamalpreet Kaur, Priyansh Arora, Ji Liu, Ahmed Farouk, Houbing Herbert Song, Steve Uhlig, Kotagiri Ramamohanarao</dc:creator>
    </item>
    <item>
      <title>A Survey on Federated Analytics: Taxonomy, Enabling Techniques, Applications and Open Issues</title>
      <link>https://arxiv.org/abs/2404.12666</link>
      <description>arXiv:2404.12666v3 Announce Type: replace-cross 
Abstract: The escalating influx of data generated by networked edge devices, coupled with the growing awareness of data privacy, has restricted the traditional data analytics workflow, where the edge data are gathered by a centralized server to be further utilized by data analysts. To continue leveraging vast edge data to support various data-incentive applications, computing paradigms have promoted a transformative shift from centralized data processing to privacy-preserved distributed data processing. The need to perform data analytics on private edge data motivates federated analytics (FA), an emerging technique to support collaborative data analytics among diverse data owners without centralizing the raw data. Despite the wide applications of FA in industry and academia, a comprehensive examination of existing research efforts in FA has been notably absent. This survey aims to bridge this gap by first providing an overview of FA, elucidating key concepts, and discussing its relationship with similar concepts. We then thoroughly examine FA, including its key challenges, taxonomy, and enabling techniques. Diverse FA applications, including statistical metrics, frequency-related applications, database query operations, FL-assisting FA tasks, and other wireless network applications are then carefully reviewed. We complete the survey with several open research issues, future directions, and a comprehensive lessons learned part. This survey intends to provide a holistic understanding of the emerging FA techniques and foster the continued evolution of privacy-preserving distributed data processing in the emerging networked society.</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.12666v3</guid>
      <category>cs.DC</category>
      <category>cs.CR</category>
      <category>cs.ET</category>
      <pubDate>Tue, 08 Apr 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Zibo Wang, Haichao Ji, Yifei Zhu, Dan Wang, Zhu Han</dc:creator>
    </item>
    <item>
      <title>Quantum Kernel Learning for Small Dataset Modeling in Semiconductor Fabrication: Application to Ohmic Contact</title>
      <link>https://arxiv.org/abs/2409.10803</link>
      <description>arXiv:2409.10803v2 Announce Type: replace-cross 
Abstract: Complex semiconductor fabrication processes, such as Ohmic contact formation in unconventional semiconductor devices, pose significant modeling challenges due to a large number of operational variables and the difficulty of collecting large, high-quality datasets. Classical machine learning (CML) models often struggle in such scenarios, where the data is both high-dimensional and limited in quantity, leading to overfitting and reduced predictive accuracy. To address this challenge, we develop the first application of quantum machine learning (QML) to model this semiconductor process, leveraging quantum systems' capacity to efficiently capture complex correlations in high-dimensional spaces and generalize well with small datasets. Using only 159 experimental samples augmented via a variational autoencoder, we report a quantum kernel-based regressor (SQKR) with a static 2-level ZZ feature map. The SQKR consistently outperformed six mainstream CML models across all evaluation metrics, achieving the lowest mean absolute error (MAE), mean squared error (MSE), and root mean squared error (RMSE), with repeated experiments confirming its robustness. Notably, SQKR achieved an MAE of 0.314 Ohm-mm with data from experimental verification, demonstrating its ability to effectively model semiconductor fabrication processes despite limited data availability. These results highlight QML's unique capability to handle small yet high-dimensional datasets in the semiconductor industry, making it a promising alternative to classical approaches for semiconductor process modeling.</description>
      <guid isPermaLink="false">oai:arXiv.org:2409.10803v2</guid>
      <category>cs.LG</category>
      <category>cs.ET</category>
      <category>quant-ph</category>
      <pubDate>Tue, 08 Apr 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Zeheng Wang, Fangzhou Wang, Liang Li, Zirui Wang, Timothy van der Laan, Ross C. C. Leon, Jing-Kai Huang, Muhammad Usman</dc:creator>
    </item>
    <item>
      <title>Pushing the Boundary of Quantum Advantage in Hard Combinatorial Optimization with Probabilistic Computers</title>
      <link>https://arxiv.org/abs/2503.10302</link>
      <description>arXiv:2503.10302v2 Announce Type: replace-cross 
Abstract: Recent demonstrations on specialized benchmarks have reignited excitement for quantum computers, yet whether they can deliver an advantage for practical real-world problems remains an open question. Here, we show that probabilistic computers (p-computers) when co-designed with hardware to implement powerful Monte Carlo algorithms can surpass state-of-the-art quantum annealers &lt;a href="https://www.nature.com/articles/s41586-023-05867-2" target="_blank"&gt;[King et al., Nature (2023)]&lt;/a&gt; in solving certain hard optimization problems. We focus on two key algorithms: discrete-time simulated quantum annealing (DT-SQA) and adaptive parallel tempering (APT), both applied to 3D spin glasses. For DT-SQA, we find that increasing the number of replicas improves residual energy scaling, while parallelizing fewer replicas across independent runs also achieves comparable scaling. Both strategies align with the theoretical expectations from extreme value theory. In addition, APT outperforms DT-SQA when supported by non-local isoenergetic cluster moves. Finite-size scaling analysis suggests a universal behavior that explains the superior performance of APT over both DT-SQA and quantum annealing. We show that these algorithms are readily implementable in modern hardware thanks to the mature semiconductor technology. Unlike software simulations, replicas can be monolithically housed on a single chip and a large number of spins can be updated in parallel and asynchronously, similar to a quantum annealer. We project that custom Field Programmable Gate Arrays (FPGA) or specialized chips leveraging massive parallelism can further accelerate these algorithms by orders of magnitude, while drastically improving energy efficiency. Our results raise the bar for a practical quantum advantage in optimization and present p-computers as scalable, energy-efficient hardware for real-world optimization problems.</description>
      <guid isPermaLink="false">oai:arXiv.org:2503.10302v2</guid>
      <category>quant-ph</category>
      <category>cond-mat.dis-nn</category>
      <category>cs.ET</category>
      <pubDate>Tue, 08 Apr 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Shuvro Chowdhury, Navid Anjum Aadit, Andrea Grimaldi, Eleonora Raimondo, Atharva Raut, P. Aaron Lott, Johan H. Mentink, Marek M. Rams, Federico Ricci-Tersenghi, Massimo Chiappini, Luke S. Theogarajan, Tathagata Srimani, Giovanni Finocchio, Masoud Mohseni, Kerem Y. Camsari</dc:creator>
    </item>
    <item>
      <title>Superhuman Game AI Disclosure: Expertise and Context Moderate Effects on Trust and Fairness</title>
      <link>https://arxiv.org/abs/2503.15514</link>
      <description>arXiv:2503.15514v2 Announce Type: replace-cross 
Abstract: As artificial intelligence surpasses human performance in select tasks, disclosing superhuman capabilities poses distinct challenges for fairness, accountability, and trust. However, the impact of such disclosures on diverse user attitudes and behaviors remains unclear, particularly concerning potential negative reactions like discouragement or overreliance. This paper investigates these effects by utilizing Persona Cards: a validated, standardized set of synthetic personas designed to simulate diverse user reactions and fairness perspectives. We conducted an ethics board-approved study (N=32), utilizing these personas to investigate how capability disclosure influenced behaviors with a superhuman game AI in competitive StarCraft II scenarios. Our results reveal transparency is double-edged: while disclosure could alleviate suspicion, it also provoked frustration and strategic defeatism among novices in cooperative scenarios, as well as overreliance in competitive contexts. Experienced and competitive players interpreted disclosure as confirmation of an unbeatable opponent, shifting to suboptimal goals. We release the Persona Cards Dataset, including profiles, prompts, interaction logs, and protocols, to foster reproducible research into human alignment AI design. This work demonstrates that transparency is not a cure-all; successfully leveraging disclosure to enhance trust and accountability requires careful tailoring to user characteristics, domain norms, and specific fairness objectives.</description>
      <guid isPermaLink="false">oai:arXiv.org:2503.15514v2</guid>
      <category>cs.HC</category>
      <category>cs.AI</category>
      <category>cs.CL</category>
      <category>cs.CY</category>
      <category>cs.ET</category>
      <pubDate>Tue, 08 Apr 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Jaymari Chua, Chen Wang, Lina Yao</dc:creator>
    </item>
    <item>
      <title>GIScience in the Era of Artificial Intelligence: A Research Agenda Towards Autonomous GIS</title>
      <link>https://arxiv.org/abs/2503.23633</link>
      <description>arXiv:2503.23633v3 Announce Type: replace-cross 
Abstract: The advent of generative AI exemplified by large language models (LLMs) opens new ways to represent and compute geographic information and transcends the process of geographic knowledge production, driving geographic information systems (GIS) towards autonomous GIS. Leveraging LLMs as the decision core, autonomous GIS can independently generate and execute geoprocessing workflows to perform spatial analysis. In this vision paper, we further elaborate on the concept of autonomous GIS and present a conceptual framework that defines its five autonomous goals, five autonomous levels, five core functions, and three operational scales. We demonstrate how autonomous GIS could perform geospatial data retrieval, spatial analysis, and map making with four proof-of-concept GIS agents. We conclude by identifying critical challenges and future research directions, including fine-tuning and self-growing decision-cores, autonomous modeling, and examining the societal and practical implications of autonomous GIS. By establishing the groundwork for a paradigm shift in GIScience, this paper envisions a future where GIS moves beyond traditional workflows to autonomously reason, derive, innovate, and advance geospatial solutions to pressing global challenges. As we design and deploy increasingly intelligent geospatial systems, we have a responsibility to ensure they are developed in socially responsible ways, serve the public good, and support the continued value of human geographic insight in an AI-augmented future.</description>
      <guid isPermaLink="false">oai:arXiv.org:2503.23633v3</guid>
      <category>cs.AI</category>
      <category>cs.ET</category>
      <category>cs.SE</category>
      <pubDate>Tue, 08 Apr 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Zhenlong Li, Huan Ning, Song Gao, Krzysztof Janowicz, Wenwen Li, Samantha T. Arundel, Chaowei Yang, Budhendra Bhaduri, Shaowen Wang, A-Xing Zhu, Mark Gahegan, Shashi Shekhar, Xinyue Ye, Grant McKenzie, Guido Cervone, Michael E. Hodgson</dc:creator>
    </item>
  </channel>
</rss>
