<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>stat.TH updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/stat.TH</link>
    <description>stat.TH updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/stat.TH" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Fri, 06 Jun 2025 04:06:13 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Fri, 06 Jun 2025 00:00:00 -0400</pubDate>
    <skipDays>
      <day>Sunday</day>
      <day>Saturday</day>
    </skipDays>
    <item>
      <title>Classification of Extremal Dependence in Financial Markets via Bootstrap Inference</title>
      <link>https://arxiv.org/abs/2506.04656</link>
      <description>arXiv:2506.04656v1 Announce Type: new 
Abstract: Accurately identifying the extremal dependence structure in multivariate heavy-tailed data is a fundamental yet challenging task, particularly in financial applications. Following a recently proposed bootstrap-based testing procedure, we apply the methodology to absolute log returns of U.S. S&amp;P 500 and Chinese A-share stocks over a time period well before the U.S. election in 2024. The procedure reveals more isolated clustering of dependent assets in the U.S. economy compared with China which exhibits different characteristics and a more interconnected pattern of extremal dependence. Cross-market analysis identifies strong extremal linkages in sectors such as materials, consumer staples and consumer discretionary, highlighting the effectiveness of the testing procedure for large-scale empirical applications.</description>
      <guid isPermaLink="false">oai:arXiv.org:2506.04656v1</guid>
      <category>math.ST</category>
      <category>stat.TH</category>
      <pubDate>Fri, 06 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Qian Hui, Sidney I. Resnick, Tiandong Wang</dc:creator>
    </item>
    <item>
      <title>A dimension reduction for extreme types of directed dependence</title>
      <link>https://arxiv.org/abs/2506.04825</link>
      <description>arXiv:2506.04825v1 Announce Type: new 
Abstract: In recent years, a variety of novel measures of dependence have been introduced being capable of characterizing diverse types of directed dependence, hence diverse types of how a number of predictor variables $\mathbf{X} = (X_1, \dots, X_p)$, $p \in \mathbb{N}$, may affect a response variable $Y$. This includes perfect dependence of $Y$ on $\mathbf{X}$ and independence between $\mathbf{X}$ and $Y$, but also less well-known concepts such as zero-explainability, stochastic comparability and complete separation. Certain such measures offer a representation in terms of the Markov product $(Y,Y')$, with $Y'$ being a conditionally independent copy of $Y$ given $\mathbf{X}$. This dimension reduction principle allows these measures to be estimated via the powerful nearest neighbor based estimation principle introduced in [4]. To achieve a deeper insight into the dimension reduction principle, this paper aims at translating the extreme variants of directed dependence, typically formulated in terms of the random vector $(\mathbf{X},Y)$, into the Markov product $(Y,Y')$.</description>
      <guid isPermaLink="false">oai:arXiv.org:2506.04825v1</guid>
      <category>math.ST</category>
      <category>stat.TH</category>
      <pubDate>Fri, 06 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Sebastian Fuchs, Carsten Limbach</dc:creator>
    </item>
    <item>
      <title>kTULA: A Langevin sampling algorithm with improved KL bounds under super-linear log-gradients</title>
      <link>https://arxiv.org/abs/2506.04878</link>
      <description>arXiv:2506.04878v1 Announce Type: new 
Abstract: Motivated by applications in deep learning, where the global Lipschitz continuity condition is often not satisfied, we examine the problem of sampling from distributions with super-linearly growing log-gradients. We propose a novel tamed Langevin dynamics-based algorithm, called kTULA, to solve the aforementioned sampling problem, and provide a theoretical guarantee for its performance. More precisely, we establish a non-asymptotic convergence bound in Kullback-Leibler (KL) divergence with the best-known rate of convergence equal to $2-\overline{\epsilon}$, $\overline{\epsilon}&gt;0$, which significantly improves relevant results in existing literature. This enables us to obtain an improved non-asymptotic error bound in Wasserstein-2 distance, which can be used to further derive a non-asymptotic guarantee for kTULA to solve the associated optimization problems. To illustrate the applicability of kTULA, we apply the proposed algorithm to the problem of sampling from a high-dimensional double-well potential distribution and to an optimization problem involving a neural network. We show that our main results can be used to provide theoretical guarantees for the performance of kTULA.</description>
      <guid isPermaLink="false">oai:arXiv.org:2506.04878v1</guid>
      <category>math.ST</category>
      <category>cs.LG</category>
      <category>math.PR</category>
      <category>stat.ML</category>
      <category>stat.TH</category>
      <pubDate>Fri, 06 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Iosif Lytras, Sotirios Sabanis, Ying Zhang</dc:creator>
    </item>
    <item>
      <title>At the edge of Donsker's Theorem: Asymptotics of multiscale scan statistics</title>
      <link>https://arxiv.org/abs/2506.05112</link>
      <description>arXiv:2506.05112v1 Announce Type: new 
Abstract: For nonparametric inference about a function, multiscale testing procedures resolve the need for bandwidth selection and achieve asymptotically optimal detection performance against a broad range of alternatives. However, critical values strongly depend on the noise distribution, and we argue that existing methods are either statistically infeasible, or asymptotically sub-optimal. To address this methodological challenge, we show how to develop a feasible multiscale test via weak convergence arguments, by replacing the additive multiscale penalty with a multiplicative weighting. This new theoretical foundation preserves the optimal detection properties of multiscale tests and extends their applicability to nonstationary nonlinear time series via a tailored bootstrap scheme. Inference for signal discovery, goodness-of-fit testing of regression functions, and multiple changepoint detection is studied in detail, and we apply the new methodology to analyze the April 2025 power blackout on the Iberian peninsula. Our methodology is enabled by a novel functional central limit in H\"older spaces with critical modulus of continuity, where Donsker's theorem fails to hold due to lack of tightness. Probabilistically, we discover a novel form of thresholded weak convergence that holds only in the upper support of the distribution.</description>
      <guid isPermaLink="false">oai:arXiv.org:2506.05112v1</guid>
      <category>math.ST</category>
      <category>stat.ME</category>
      <category>stat.TH</category>
      <pubDate>Fri, 06 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Johann K\"ohne, Fabian Mies</dc:creator>
    </item>
    <item>
      <title>Statistical microlocal analysis in two-dimensional X-ray CT</title>
      <link>https://arxiv.org/abs/2506.05113</link>
      <description>arXiv:2506.05113v1 Announce Type: new 
Abstract: In many imaging applications it is important to assess how well the edges of the original object, $f$, are resolved in an image, $f^\text{rec}$, reconstructed from the measured data, $g$. In this paper we consider the case of image reconstruction in 2D X-ray Computed Tomography (CT). Let $f$ be a function describing the object being scanned, and $g=Rf + \eta$ be the Radon transform data in $\mathbb{R}^2$ corrupted by noise, $\eta$, and sampled with step size $\sim\epsilon$. Conventional microlocal analysis provides conditions for edge detectability based on the scanner geometry in the case of continuous, noiseless data (when $\eta = 0$), but does not account for noise and finite sampling step size. We develop a novel technique called \emph{Statistical Microlocal Analysis} (SMA), which uses a statistical hypothesis testing framework to determine if an image edge (singularity) of $f$ is detectable from $f^\text{rec}$, and we quantify edge detectability using the statistical power of the test. Our approach is based on the theory we developed in \cite{AKW2024_1}, which provides a characterization of $f^\text{rec}$ in local $O(\epsilon)$-size neighborhoods when $\eta \neq 0$. We derive a statistical test for the presence and direction of an edge microlocally given the magnitude of $\eta$ and data sampling step size. Using the properties of the null distribution of the test, we quantify the uncertainty of the edge magnitude and direction. We validate our theory using simulations, which show strong agreement between our predictions and experimental observations. Our work is not only of practical value, but of theoretical value as well. SMA is a natural extension of classical microlocal analysis theory which accounts for practical measurement imperfections, such as noise and finite step size, at the highest possible resolution compatible with the data.</description>
      <guid isPermaLink="false">oai:arXiv.org:2506.05113v1</guid>
      <category>math.ST</category>
      <category>math.FA</category>
      <category>stat.TH</category>
      <pubDate>Fri, 06 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Anuj Abhishek, Alexander Katsevich, James W. Webber</dc:creator>
    </item>
    <item>
      <title>On the Spherical Dirichlet Distribution: Corrections and Results</title>
      <link>https://arxiv.org/abs/2506.04441</link>
      <description>arXiv:2506.04441v1 Announce Type: cross 
Abstract: This note corrects a technical error in Guardiola (2020, Journal of Statistical Distributions and Applications), presents updated derivations, and offers an extended discussion of the properties of the spherical Dirichlet distribution. Today, data mining and gene expressions are at the forefront of modern data analysis. Here we introduce a novel probability distribution that is applicable in these fields. This paper develops the proposed Spherical-Dirichlet Distribution designed to fit vectors located at the positive orthant of the hypersphere, as it is often the case for data in these fields, avoiding unnecessary probability mass. Basic properties of the proposed distribution, including normalizing constants and moments are developed. Relationships with other distributions are also explored. Estimators based on classical inferential statistics, such as method of moments and maximum likelihood estimators are obtained. Two applications are developed: the first one uses simulated data, and the second uses a real text mining example. Both examples are fitted using the proposed Spherical-Dirichlet Distribution and their results are discussed.</description>
      <guid isPermaLink="false">oai:arXiv.org:2506.04441v1</guid>
      <category>stat.ME</category>
      <category>math.ST</category>
      <category>stat.TH</category>
      <pubDate>Fri, 06 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <arxiv:DOI>10.1186/s40488-020-00106-9</arxiv:DOI>
      <arxiv:journal_reference>J. Stat. Distrib. App. 7, 6 (2020)</arxiv:journal_reference>
      <dc:creator>Jose H Guardiola</dc:creator>
    </item>
    <item>
      <title>Robust Estimation in Step-Stress Experiments under Exponential Lifetime Distributions</title>
      <link>https://arxiv.org/abs/2506.04445</link>
      <description>arXiv:2506.04445v1 Announce Type: cross 
Abstract: Many modern products exhibit high reliability, often resulting in long times to failure. Consequently, conducting experiments under normal operating conditions may require an impractically long duration to obtain sufficient failure data for reliable statistical inference. As an alternative, accelerated life tests (ALTs) are employed to induce earlier failures and thereby reduce testing time. In step-stress experiments a stress factor that accelerates product degradation is identified and systematically increased to provoke early failures. The stress level is increased at predetermined time points and maintained constant between these intervals. Failure data observed under increased levels of stress is statistically analyzed, and results are then extrapolate to normal operating conditions.
  Classical estimation methods such analysis rely on the maximum likelihood estimator (MLE) which is know to be very efficient, but lack robustness in the presence of outlying data. In this work, Minimum Density Power Divergence Estimators (MDPDEs) are proposed as a robust alternative, demonstrating an appealing compromise between efficiency and robustness. The MDPDE based on mixed distributions is developed, and its theoretical properties, including the expression for the asymptotic distribution of the model parameters, are derived under exponential lifetime assumptions. The good performance of the proposed method is evaluated through simulation studies, and its applicability is demonstrated using real data.</description>
      <guid isPermaLink="false">oai:arXiv.org:2506.04445v1</guid>
      <category>stat.ME</category>
      <category>math.ST</category>
      <category>stat.TH</category>
      <pubDate>Fri, 06 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Mar\'ia Jaenada, Juan Manuel Mill\'an, Leandro Pardo</dc:creator>
    </item>
    <item>
      <title>The Spurious Factor Dilemma: Robust Inference in Heavy-Tailed Elliptical Factor Models</title>
      <link>https://arxiv.org/abs/2506.05116</link>
      <description>arXiv:2506.05116v1 Announce Type: cross 
Abstract: Factor models are essential tools for analyzing high-dimensional data, particularly in economics and finance. However, standard methods for determining the number of factors often overestimate the true number when data exhibit heavy-tailed randomness, misinterpreting noise-induced outliers as genuine factors. This paper addresses this challenge within the framework of Elliptical Factor Models (EFM), which accommodate both heavy tails and potential non-linear dependencies common in real-world data. We demonstrate theoretically and empirically that heavy-tailed noise generates spurious eigenvalues that mimic true factor signals. To distinguish these, we propose a novel methodology based on a fluctuation magnification algorithm. We show that under magnifying perturbations, the eigenvalues associated with real factors exhibit significantly less fluctuation (stabilizing asymptotically) compared to spurious eigenvalues arising from heavy-tailed effects. This differential behavior allows the identification and detection of the true and spurious factors. We develop a formal testing procedure based on this principle and apply it to the problem of accurately selecting the number of common factors in heavy-tailed EFMs. Simulation studies and real data analysis confirm the effectiveness of our approach compared to existing methods, particularly in scenarios with pronounced heavy-tailedness.</description>
      <guid isPermaLink="false">oai:arXiv.org:2506.05116v1</guid>
      <category>stat.ME</category>
      <category>econ.EM</category>
      <category>math.ST</category>
      <category>stat.TH</category>
      <pubDate>Fri, 06 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Jiang Hu, Jiahui Xie, Yangchun Zhang, Wang Zhou</dc:creator>
    </item>
    <item>
      <title>Counterfactual reasoning: an analysis of in-context emergence</title>
      <link>https://arxiv.org/abs/2506.05188</link>
      <description>arXiv:2506.05188v1 Announce Type: cross 
Abstract: Large-scale neural language models (LMs) exhibit remarkable performance in in-context learning: the ability to learn and reason the input context on the fly without parameter update. This work studies in-context counterfactual reasoning in language models, that is, to predict the consequences of changes under hypothetical scenarios. We focus on studying a well-defined synthetic setup: a linear regression task that requires noise abduction, where accurate prediction is based on inferring and copying the contextual noise from factual observations. We show that language models are capable of counterfactual reasoning in this controlled setup and provide insights that counterfactual reasoning for a broad class of functions can be reduced to a transformation on in-context observations; we find self-attention, model depth, and data diversity in pre-training drive performance in Transformers. More interestingly, our findings extend beyond regression tasks and show that Transformers can perform noise abduction on sequential data, providing preliminary evidence on the potential for counterfactual story generation. Our code is available under https://github.com/moXmiller/counterfactual-reasoning.git .</description>
      <guid isPermaLink="false">oai:arXiv.org:2506.05188v1</guid>
      <category>cs.CL</category>
      <category>cs.AI</category>
      <category>cs.LG</category>
      <category>math.ST</category>
      <category>stat.TH</category>
      <pubDate>Fri, 06 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Moritz Miller, Bernhard Sch\"olkopf, Siyuan Guo</dc:creator>
    </item>
    <item>
      <title>Transformers Meet In-Context Learning: A Universal Approximation Theory</title>
      <link>https://arxiv.org/abs/2506.05200</link>
      <description>arXiv:2506.05200v1 Announce Type: cross 
Abstract: Modern large language models are capable of in-context learning, the ability to perform new tasks at inference time using only a handful of input-output examples in the prompt, without any fine-tuning or parameter updates. We develop a universal approximation theory to better understand how transformers enable in-context learning. For any class of functions (each representing a distinct task), we demonstrate how to construct a transformer that, without any further weight updates, can perform reliable prediction given only a few in-context examples. In contrast to much of the recent literature that frames transformers as algorithm approximators -- i.e., constructing transformers to emulate the iterations of optimization algorithms as a means to approximate solutions of learning problems -- our work adopts a fundamentally different approach rooted in universal function approximation. This alternative approach offers approximation guarantees that are not constrained by the effectiveness of the optimization algorithms being approximated, thereby extending far beyond convex problems and linear function classes. Our construction sheds light on how transformers can simultaneously learn general-purpose representations and adapt dynamically to in-context examples.</description>
      <guid isPermaLink="false">oai:arXiv.org:2506.05200v1</guid>
      <category>cs.LG</category>
      <category>math.ST</category>
      <category>stat.ML</category>
      <category>stat.TH</category>
      <pubDate>Fri, 06 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Gen Li, Yuchen Jiao, Yu Huang, Yuting Wei, Yuxin Chen</dc:creator>
    </item>
    <item>
      <title>Smoothness Estimation for Whittle-Mat\'ern Processes on Closed Riemannian Manifolds</title>
      <link>https://arxiv.org/abs/2401.00510</link>
      <description>arXiv:2401.00510v3 Announce Type: replace 
Abstract: The family of Mat\'ern kernels are often used in spatial statistics, function approximation and Gaussian process methods in machine learning. One reason for their popularity is the presence of a smoothness parameter that controls, for example, optimal error bounds for kriging and posterior contraction rates in Gaussian process regression. On closed Riemannian manifolds, we show that the smoothness parameter can be consistently estimated from the maximizer(s) of the Gaussian likelihood when the underlying data are from point evaluations of a Gaussian process and, perhaps surprisingly, even when the data comprise evaluations of a non-Gaussian process. The points at which the process is observed need not have any particular spatial structure beyond quasi-uniformity. Our methods are based on results from approximation theory for the Sobolev scale of Hilbert spaces. Moreover, we generalize a well-known equivalence of measures phenomenon related to Mat\'ern kernels to the non-Gaussian case by using Kakutani's theorem.</description>
      <guid isPermaLink="false">oai:arXiv.org:2401.00510v3</guid>
      <category>math.ST</category>
      <category>stat.TH</category>
      <pubDate>Fri, 06 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <arxiv:DOI>10.1016/j.spa.2025.104685</arxiv:DOI>
      <arxiv:journal_reference>Stochastic Processes and their Applications 189:104685, 2025</arxiv:journal_reference>
      <dc:creator>Moritz Korte-Stapff, Toni Karvonen, Eric Moulines</dc:creator>
    </item>
    <item>
      <title>Are all models wrong? Fundamental limits in distribution-free empirical model falsification</title>
      <link>https://arxiv.org/abs/2502.06765</link>
      <description>arXiv:2502.06765v2 Announce Type: replace 
Abstract: In statistics and machine learning, when we train a fitted model on available data, we typically want to ensure that we are searching within a model class that contains at least one accurate model -- that is, we would like to ensure an upper bound on the model class risk (the lowest possible risk that can be attained by any model in the class). However, it is also of interest to establish lower bounds on the model class risk, for instance so that we can determine whether our fitted model is at least approximately optimal within the class, or, so that we can decide whether the model class is unsuitable for the particular task at hand. Particularly in the setting of interpolation learning where machine learning models are trained to reach zero error on the training data, we might ask if, at the very least, a positive lower bound on the model class risk is possible -- or are we unable to detect that "all models are wrong"? In this work, we answer these questions in a distribution-free setting by establishing a model-agnostic, fundamental hardness result for the problem of constructing a lower bound on the best test error achievable over a model class, and examine its implications on specific model classes such as tree-based methods and linear regression.</description>
      <guid isPermaLink="false">oai:arXiv.org:2502.06765v2</guid>
      <category>math.ST</category>
      <category>cs.LG</category>
      <category>stat.ML</category>
      <category>stat.TH</category>
      <pubDate>Fri, 06 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Manuel M. M\"uller, Yuetian Luo, Rina Foygel Barber</dc:creator>
    </item>
    <item>
      <title>Pooling information in likelihood-free inference</title>
      <link>https://arxiv.org/abs/2212.02658</link>
      <description>arXiv:2212.02658v2 Announce Type: replace-cross 
Abstract: Likelihood-free inference (LFI) methods, such as approximate Bayesian computation, have become commonplace for conducting inference in complex models. Many approaches are based on summary statistics or discrepancies derived from synthetic data. However, determining which summary statistics or discrepancies to use for constructing the posterior remains a challenging question, both practically and theoretically. Instead of relying on a single vector of summaries for inference, we propose a new pooled posterior that optimally combines inferences from multiple LFI posteriors. This pooled approach eliminates the need to select a single vector of summaries or even a specific LFI algorithm. Our approach is straightforward to implement and avoids performing a high-dimensional LFI analysis involving all summary statistics. We give theoretical guarantees for the improved performance of the pooled posterior mean in terms of asymptotic frequentist risk and demonstrate the effectiveness of the approach in a number of benchmark examples.</description>
      <guid isPermaLink="false">oai:arXiv.org:2212.02658v2</guid>
      <category>stat.ME</category>
      <category>math.ST</category>
      <category>stat.CO</category>
      <category>stat.TH</category>
      <pubDate>Fri, 06 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>David T. Frazier, Christopher Drovandi, Lucas Kock, David J. Nott</dc:creator>
    </item>
    <item>
      <title>Policy learning "without" overlap: Pessimism and generalized empirical Bernstein's inequality</title>
      <link>https://arxiv.org/abs/2212.09900</link>
      <description>arXiv:2212.09900v4 Announce Type: replace-cross 
Abstract: This paper studies offline policy learning, which aims at utilizing observations collected a priori (from either fixed or adaptively evolving behavior policies) to learn an optimal individualized decision rule that achieves the best overall outcomes for a given population. Existing policy learning methods rely on a uniform overlap assumption, i.e., the propensities of exploring all actions for all individual characteristics must be lower bounded. As one has no control over the data collection process, this assumption can be unrealistic in many situations, especially when the behavior policies are allowed to evolve over time with diminishing propensities for certain actions.
  In this paper, we propose Pessimistic Policy Learning (PPL), a new algorithm that optimizes lower confidence bounds (LCBs) -- instead of point estimates -- of the policy values. The LCBs are constructed using knowledge of the behavior policies for collecting the offline data. Without assuming any uniform overlap condition, we establish a data-dependent upper bound for the suboptimality of our algorithm, which only depends on (i) the overlap for the optimal policy, and (ii) the complexity of the policy class we optimize over. As an implication, for adaptively collected data, we ensure efficient policy learning as long as the propensities for optimal actions are lower bounded over time, while those for suboptimal ones are allowed to diminish arbitrarily fast. In our theoretical analysis, we develop a new self-normalized type concentration inequality for inverse-propensity-weighting estimators, generalizing the well-known empirical Bernstein's inequality to unbounded and non-i.i.d. data. We complement our theory with an efficient optimization algorithm via Majorization-Minimization and policy tree search, as well as extensive simulation studies and real-world applications that demonstrate the efficacy of PPL.</description>
      <guid isPermaLink="false">oai:arXiv.org:2212.09900v4</guid>
      <category>cs.LG</category>
      <category>math.ST</category>
      <category>stat.ME</category>
      <category>stat.ML</category>
      <category>stat.TH</category>
      <pubDate>Fri, 06 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Ying Jin, Zhimei Ren, Zhuoran Yang, Zhaoran Wang</dc:creator>
    </item>
    <item>
      <title>Lattice Rules Meet Kernel Cubature</title>
      <link>https://arxiv.org/abs/2501.09500</link>
      <description>arXiv:2501.09500v2 Announce Type: replace-cross 
Abstract: Rank-1 lattice rules are a class of equally weighted quasi-Monte Carlo methods that achieve essentially linear convergence rates for functions in a reproducing kernel Hilbert space (RKHS) characterized by square-integrable first-order mixed partial derivatives. In this work, we explore the impact of replacing the equal weights in lattice rules with optimized cubature weights derived using the reproducing kernel. We establish a theoretical result demonstrating a doubled convergence rate in the one-dimensional case and provide numerical investigations of convergence rates in higher dimensions. We also present numerical results for an uncertainty quantification problem involving an elliptic partial differential equation with a random coefficient.</description>
      <guid isPermaLink="false">oai:arXiv.org:2501.09500v2</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <category>math.ST</category>
      <category>stat.TH</category>
      <pubDate>Fri, 06 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Vesa Kaarnioja, Ilja Klebanov, Claudia Schillings, Yuya Suzuki</dc:creator>
    </item>
    <item>
      <title>Retrieval-Augmented Generation as Noisy In-Context Learning: A Unified Theory and Risk Bounds</title>
      <link>https://arxiv.org/abs/2506.03100</link>
      <description>arXiv:2506.03100v2 Announce Type: replace-cross 
Abstract: Retrieval-augmented generation (RAG) has seen many empirical successes in recent years by aiding the LLM with external knowledge. However, its theoretical aspect has remained mostly unexplored. In this paper, we propose the first finite-sample generalization bound for RAG in in-context linear regression and derive an exact bias-variance tradeoff. Our framework views the retrieved texts as query-dependent noisy in-context examples and recovers the classical in-context learning (ICL) and standard RAG as the limit cases. Our analysis suggests that an intrinsic ceiling on generalization error exists on RAG as opposed to the ICL. Furthermore, our framework is able to model retrieval both from the training data and from external corpora by introducing uniform and non-uniform RAG noise. In line with our theory, we show the sample efficiency of ICL and RAG empirically with experiments on common QA benchmarks, such as Natural Questions and TriviaQA.</description>
      <guid isPermaLink="false">oai:arXiv.org:2506.03100v2</guid>
      <category>cs.LG</category>
      <category>cs.AI</category>
      <category>cs.CL</category>
      <category>cs.IR</category>
      <category>math.ST</category>
      <category>stat.TH</category>
      <pubDate>Fri, 06 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <dc:creator>Yang Guo, Yutian Tao, Yifei Ming, Robert D. Nowak, Yingyu Liang</dc:creator>
    </item>
  </channel>
</rss>
