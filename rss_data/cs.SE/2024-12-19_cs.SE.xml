<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>cs.SE updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/cs.SE</link>
    <description>cs.SE updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/cs.SE" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Fri, 20 Dec 2024 02:53:58 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Thu, 19 Dec 2024 00:00:00 -0500</pubDate>
    <skipDays>
      <day>Sunday</day>
      <day>Saturday</day>
    </skipDays>
    <item>
      <title>Creating an LLM-based AI-agent: A high-level methodology towards enhancing LLMs with APIs</title>
      <link>https://arxiv.org/abs/2412.13233</link>
      <description>arXiv:2412.13233v1 Announce Type: new 
Abstract: Large Language Models (LLMs) have revolutionized various aspects of engineering and science. Their utility is often bottlenecked by the lack of interaction with the external digital environment. To overcome this limitation and achieve integration of LLMs and Artificial Intelligence (AI) into real-world applications, customized AI agents are being constructed. Based on the technological trends and techniques, we extract a high-level approach for constructing these AI agents, focusing on their underlying architecture. This thesis serves as a comprehensive guide that elucidates a multi-faceted approach for empowering LLMs with the capability to leverage Application Programming Interfaces (APIs). We present a 7-step methodology that begins with the selection of suitable LLMs and the task decomposition that is necessary for complex problem-solving. This methodology includes techniques for generating training data for API interactions and heuristics for selecting the appropriate API among a plethora of options. These steps eventually lead to the generation of API calls that are both syntactically and semantically aligned with the LLM's understanding of a given task. Moreover, we review existing frameworks and tools that facilitate these processes and highlight the gaps in current attempts. In this direction, we propose an on-device architecture that aims to exploit the functionality of carry-on devices by using small models from the Hugging Face community. We examine the effectiveness of these approaches on real-world applications of various domains, including the generation of a piano sheet. Through an extensive analysis of the literature and available technologies, this thesis aims to set a compass for researchers and practitioners to harness the full potential of LLMs augmented with external tool capabilities, thus paving the way for more autonomous, robust, and context-aware AI agents.</description>
      <guid isPermaLink="false">oai:arXiv.org:2412.13233v1</guid>
      <category>cs.SE</category>
      <pubDate>Thu, 19 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Ioannis Tzachristas</dc:creator>
    </item>
    <item>
      <title>What do Computing Interns Discuss Online? An Empirical Analysis of Reddit Posts</title>
      <link>https://arxiv.org/abs/2412.13296</link>
      <description>arXiv:2412.13296v1 Announce Type: new 
Abstract: Computing internships are the most common way for students to gain practical real-world experience. Internships have become a major part of most computing curricula because they help match student abilities or expectations with the demand of the workforce. The internship experience for students vary due to diverse factors such misconceptions about industrial realities, level of preparation, networking opportunities and so on. This papers attempts to provide insights into students discussions and opinions related to internship. We extracted 143,912 online Reddit posts related to computing internships out of 921,845 posts containing the rootword "intern", and then used topic modelling to unravel the common themes in the discussions. Next, we applied sentiment analysis techniques to understand the feelings expressed by the students in the Reddit posts. The results show that computing interns generally express a positive sentiment and the discussions were mostly related to academics, school admissions, professional career, entertainment activities, and social interactions.</description>
      <guid isPermaLink="false">oai:arXiv.org:2412.13296v1</guid>
      <category>cs.SE</category>
      <pubDate>Thu, 19 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Saheed Popoola, Ashwitha Vollem, Kofi Nti</dc:creator>
    </item>
    <item>
      <title>An Exploratory Study of ML Sketches and Visual Code Assistants</title>
      <link>https://arxiv.org/abs/2412.13386</link>
      <description>arXiv:2412.13386v1 Announce Type: new 
Abstract: This paper explores the integration of Visual Code Assistants in Integrated Development Environments (IDEs). In Software Engineering, whiteboard sketching is often the initial step before coding, serving as a crucial collaboration tool for developers. Previous studies have investigated patterns in SE sketches and how they are used in practice, yet methods for directly using these sketches for code generation remain limited. The emergence of visually-equipped large language models presents an opportunity to bridge this gap, which is the focus of our research. In this paper, we built a first prototype of a Visual Code Assistant to get user feedback regarding in-IDE sketch-to-code tools. We conduct an experiment with 19 data scientists, most of whom regularly sketch as part of their job. We investigate developers' mental models by analyzing patterns commonly observed in their sketches when developing an ML workflow. Analysis indicates that diagrams were the preferred organizational component (52.6%), often accompanied by lists (42.1%) and numbered points (36.8%). Our tool converts their sketches into a Python notebook by querying an LLM. We use an LLM-as-judge setup to score the quality of the generated code, finding that even brief sketching can effectively generate useful code outlines. We also find a positive correlation between sketch time and the quality of the generated code. We conclude the study by conducting extensive interviews to assess the tool's usefulness, explore potential use cases, and understand developers' needs. As noted by participants, promising applications for these assistants include education, prototyping, and collaborative settings. Our findings signal promise for the next generation of Code Assistants to integrate visual information, both to improve code generation and to better leverage developers' existing sketching practices.</description>
      <guid isPermaLink="false">oai:arXiv.org:2412.13386v1</guid>
      <category>cs.SE</category>
      <category>cs.AI</category>
      <category>cs.HC</category>
      <pubDate>Thu, 19 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <arxiv:journal_reference>Proceedings of the 2025 IEEE/ACM 47th International Conference on Software Engineering (ICSE)</arxiv:journal_reference>
      <dc:creator>Lu\'is F. Gomes, Vincent J. Hellendoorn, Jonathan Aldrich, Rui Abreu</dc:creator>
    </item>
    <item>
      <title>GenX: Mastering Code and Test Generation with Execution Feedback</title>
      <link>https://arxiv.org/abs/2412.13464</link>
      <description>arXiv:2412.13464v1 Announce Type: new 
Abstract: Recent advancements in language modeling have enabled the translation of natural language into code, and the use of execution feedback to improve code generation. However, these methods often rely heavily on pre-existing test cases, which may not always be available or comprehensive. In this work, we propose a novel approach that concurrently trains a code generation model and a test generation model, utilizing execution feedback to refine and enhance the performance of both. We introduce two strategies for test and code data augmentation and a new scoring function for code and test ranking. We experiment on the APPS dataset and demonstrate that our approach can effectively generate and augment test cases, filter and synthesize correct code solutions, and rank the quality of generated code and tests. The results demonstrate that our models, when iteratively trained with an increasing number of test cases and code solutions, outperform those trained on the original dataset.</description>
      <guid isPermaLink="false">oai:arXiv.org:2412.13464v1</guid>
      <category>cs.SE</category>
      <category>cs.CL</category>
      <pubDate>Thu, 19 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Nan Wang, Yafei Liu, Chen Chen, Haonan Lu</dc:creator>
    </item>
    <item>
      <title>Transducer Tuning: Efficient Model Adaptation for Software Tasks Using Code Property Graphs</title>
      <link>https://arxiv.org/abs/2412.13467</link>
      <description>arXiv:2412.13467v1 Announce Type: new 
Abstract: Large language models have demonstrated promising performance across various software engineering tasks. While fine-tuning is a common practice to adapt these models for downstream tasks, it becomes challenging in resource-constrained environments due to increased memory requirements from growing trainable parameters in increasingly large language models. We introduce \approach, a technique to adapt large models for downstream code tasks using Code Property Graphs (CPGs). Our approach introduces a modular component called \transducer that enriches code embeddings with structural and dependency information from CPGs. The Transducer comprises two key components: Graph Vectorization Engine (GVE) and Attention-Based Fusion Layer (ABFL). GVE extracts CPGs from input source code and transforms them into graph feature vectors. ABFL then fuses those graphs feature vectors with initial code embeddings from a large language model. By optimizing these transducers for different downstream tasks, our approach enhances the models without the need to fine-tune them for specific tasks. We have evaluated \approach on three downstream tasks: code summarization, assert generation, and code translation. Our results demonstrate competitive performance compared to full parameter fine-tuning while reducing up to 99\% trainable parameters to save memory. \approach also remains competitive against other fine-tuning approaches (e.g., LoRA, Prompt-Tuning, Prefix-Tuning) while using only 1.5\%-80\% of their trainable parameters. Our findings show that integrating structural and dependency information through Transducer Tuning enables more efficient model adaptation, making it easier for users to adapt large models in resource-constrained settings.</description>
      <guid isPermaLink="false">oai:arXiv.org:2412.13467v1</guid>
      <category>cs.SE</category>
      <category>cs.AI</category>
      <category>cs.CL</category>
      <pubDate>Thu, 19 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-sa/4.0/</dc:rights>
      <dc:creator>Imam Nur Bani Yusuf, Lingxiao Jiang</dc:creator>
    </item>
    <item>
      <title>CPPJoules: An Energy Measurement Tool for C++</title>
      <link>https://arxiv.org/abs/2412.13555</link>
      <description>arXiv:2412.13555v1 Announce Type: new 
Abstract: With the increasing complexity of modern software and the demand for high performance, energy consumption has become a critical factor for developers and researchers. While much of the research community is focused on evaluating the energy consumption of machine learning and artificial intelligence systems -- often implemented in Python -- there is a gap when it comes to tools and frameworks for measuring energy usage in other programming languages. C++, in particular, remains a foundational language for a wide range of software applications, from game development to parallel programming frameworks, yet lacks dedicated energy measurement solutions. To address this, we have developed CPPJoules, a tool built on top of Intel-RAPL to measure the energy consumption of C++ code snippets. We have evaluated the tool by measuring the energy consumption of the standard computational tasks from the Rosetta Code repository. The demonstration of the tool is available at \url{https://www.youtube.com/watch?v=GZXYF3AKzPk} and related artifacts at \url{https://rishalab.github.io/CPPJoules/}.</description>
      <guid isPermaLink="false">oai:arXiv.org:2412.13555v1</guid>
      <category>cs.SE</category>
      <pubDate>Thu, 19 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Shivadharshan S, Akilesh P, Rajrupa Chattaraj, Sridhar Chimalakonda</dc:creator>
    </item>
    <item>
      <title>Visibility of Domain Elements in the Elicitation Process: A Family of Empirical Studies</title>
      <link>https://arxiv.org/abs/2412.13691</link>
      <description>arXiv:2412.13691v1 Announce Type: new 
Abstract: Background: Various factors determine analyst effectiveness during elicitation. While the literature suggests that elicitation technique and time are influential factors, other attributes could also play a role. Aim: Determine aspects that may have an influence on analysts' ability to identify certain elements of the problem domain. Methodology: We conducted 14 quasi-experiments, inquiring 134 subjects about two problem domains. For each problem domain, we calculated whether the experimental subjects identified the problem domain elements (concepts, processes, and requirements), i.e., the degree to which these domain elements were visible. Results: Domain element visibility does not appear to be related to either analyst experience or analyst-client interaction. Domain element visibility depends on how analysts provide the elicited information: when asked about the knowledge acquired during elicitation, domain element visibility dramatically increases compared to the information they provide using a written report. Conclusions: Further research is required to replicate our results. However, the finding that analysts have difficulty reporting the information they have acquired is useful for identifying alternatives for improving the documentation of elicitation results. We found evidence that other issues, like domain complexity, the relative importance of different elements within the domain, and the interview script, also seem influential.</description>
      <guid isPermaLink="false">oai:arXiv.org:2412.13691v1</guid>
      <category>cs.SE</category>
      <pubDate>Thu, 19 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Alejandrina Aranda, Oscar Dieste, Natalia Juristo</dc:creator>
    </item>
    <item>
      <title>A2H: A UI Converter from Android to HarmonyOS Platform</title>
      <link>https://arxiv.org/abs/2412.13693</link>
      <description>arXiv:2412.13693v2 Announce Type: new 
Abstract: With the growing importance of smartphones, developers face the challenge of creating separate applications for multiple platforms (e.g., Android, iOS, and HarmonyOS), leading to increased development costs and longer iteration cycles. One potential solution is to develop an app on one platform and then automatically convert it to other platforms, reducing the need for separate development efforts. However, migrating user interfaces (UIs) between platforms is particularly challenging due to significant differences in layout structures and development paradigms, such as the disparity between XML layout files in Android and ArkUI framework in HarmonyOS. Manual conversion of UIs is time-consuming, error-prone, and inefficient, necessitating an automated solution to streamline the process and enable seamless migration from Android to HarmonyOS. To address this challenge, we propose the A2H Converter, an automated tool for migrating Android UIs to HarmonyOS. The tool employs an large language model (LLM)-driven multi-agent framework to convert Android XML layouts into HarmonyOS ArkUI layouts. Using the RAG combing with decision rules, the system maps Android UI components to ArkUI equivalents, while a reflective mechanism continuously improves conversion accuracy. A2H Converter handles project-level layouts, ensuring consistency across multiple files and addressing complex UI logic. Experiments on six Android applications collected from GitHub demonstrate that our A2H Converter achieves a migration success rate of over 90.1%, 89.3%, and 89.2% at the component, page, and project levels, respectively. The demo video is available at. The tool is available at http://124.70.54.129:37860/.</description>
      <guid isPermaLink="false">oai:arXiv.org:2412.13693v2</guid>
      <category>cs.SE</category>
      <pubDate>Thu, 19 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Chen Wang, Lina Gong, Yujun Huang, Di Cui, Mingqiang Wei</dc:creator>
    </item>
    <item>
      <title>On the Compression of Language Models for Code: An Empirical Study on CodeBERT</title>
      <link>https://arxiv.org/abs/2412.13737</link>
      <description>arXiv:2412.13737v1 Announce Type: new 
Abstract: Language models have proven successful across a wide range of software engineering tasks, but their significant computational costs often hinder their practical adoption. To address this challenge, researchers have begun applying various compression strategies to improve the efficiency of language models for code. These strategies aim to optimize inference latency and memory usage, though often at the cost of reduced model effectiveness. However, there is still a significant gap in understanding how these strategies influence the efficiency and effectiveness of language models for code. Here, we empirically investigate the impact of three well-known compression strategies -- knowledge distillation, quantization, and pruning -- across three different classes of software engineering tasks: vulnerability detection, code summarization, and code search. Our findings reveal that the impact of these strategies varies greatly depending on the task and the specific compression method employed. Practitioners and researchers can use these insights to make informed decisions when selecting the most appropriate compression strategy, balancing both efficiency and effectiveness based on their specific needs.</description>
      <guid isPermaLink="false">oai:arXiv.org:2412.13737v1</guid>
      <category>cs.SE</category>
      <category>cs.AI</category>
      <category>cs.PF</category>
      <pubDate>Thu, 19 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Giordano d'Aloisio, Luca Traini, Federica Sarro, Antinisca Di Marco</dc:creator>
    </item>
    <item>
      <title>A Comprehensive Evaluation of Parameter-Efficient Fine-Tuning on Method-Level Code Smell Detection</title>
      <link>https://arxiv.org/abs/2412.13801</link>
      <description>arXiv:2412.13801v1 Announce Type: new 
Abstract: Code smells are suboptimal coding practices that negatively impact the quality of software systems. Existing detection methods, relying on heuristics or Machine Learning (ML) and Deep Learning (DL) techniques, often face limitations such as unsatisfactory performance. Parameter-Efficient Fine-Tuning (PEFT) methods have emerged as a resource-efficient approach for adapting LLMs to specific tasks, but their effectiveness for method-level code smell detection remains underexplored. In this regard, this study evaluates state-of-the-art PEFT methods on both small and large Language Models (LMs) for detecting two types of method-level code smells: Complex Conditional and Complex Method. Using high-quality datasets sourced from GitHub, we fine-tuned four small LMs and six LLMs with PEFT techniques, including prompt tuning, prefix tuning, LoRA, and (IA)3. Results show that PEFT methods achieve comparable or better performance than full fine-tuning while consuming less GPU memory. Notably, LLMs did not outperform small LMs, suggesting smaller models' suitability for this task. Additionally, increasing training dataset size significantly boosted performance, while increasing trainable parameters did not. Our findings highlight PEFT methods as effective and scalable solutions, outperforming existing heuristic-based and DL-based detectors.</description>
      <guid isPermaLink="false">oai:arXiv.org:2412.13801v1</guid>
      <category>cs.SE</category>
      <pubDate>Thu, 19 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Beiqi Zhang, Peng Liang, Xin Zhou, Xiyu Zhou, David Lo, Qiong Feng, Zengyang Li, Lin Li</dc:creator>
    </item>
    <item>
      <title>SimADFuzz: Simulation-Feedback Fuzz Testing for Autonomous Driving Systems</title>
      <link>https://arxiv.org/abs/2412.13802</link>
      <description>arXiv:2412.13802v1 Announce Type: new 
Abstract: Autonomous driving systems (ADS) have achieved remarkable progress in recent years. However, ensuring their safety and reliability remains a critical challenge due to the complexity and uncertainty of driving scenarios. In this paper, we focus on simulation testing for ADS, where generating diverse and effective testing scenarios is a central task. Existing fuzz testing methods face limitations, such as overlooking the temporal and spatial dynamics of scenarios and failing to leverage simulation feedback (e.g., speed, acceleration and heading) to guide scenario selection and mutation. To address these issues, we propose SimADFuzz, a novel framework designed to generate high-quality scenarios that reveal violations in ADS behavior. Specifically, SimADFuzz employs violation prediction models, which evaluate the likelihood of ADS violations, to optimize scenario selection. Moreover, SimADFuzz proposes distance-guided mutation strategies to enhance interactions among vehicles in offspring scenarios, thereby triggering more edge-case behaviors of vehicles. Comprehensive experiments demonstrate that SimADFuzz outperforms state-of-the-art fuzzers by identifying 32 more unique violations, including 4 reproducible cases of vehicle-vehicle and vehicle-pedestrian collisions. These results demonstrate SimADFuzz's effectiveness in enhancing the robustness and safety of autonomous driving systems.</description>
      <guid isPermaLink="false">oai:arXiv.org:2412.13802v1</guid>
      <category>cs.SE</category>
      <category>cs.RO</category>
      <pubDate>Thu, 19 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Huiwen Yang, Yu Zhou, Taolue Chen</dc:creator>
    </item>
    <item>
      <title>From Expectation to Habit: Why Do Software Practitioners Adopt Fairness Toolkits?</title>
      <link>https://arxiv.org/abs/2412.13846</link>
      <description>arXiv:2412.13846v2 Announce Type: new 
Abstract: As the adoption of machine learning (ML) systems continues to grow across industries, concerns about fairness and bias in these systems have taken center stage. Fairness toolkits, designed to mitigate bias in ML models, serve as critical tools for addressing these ethical concerns. However, their adoption in the context of software development remains underexplored, especially regarding the cognitive and behavioral factors driving their usage. As a deeper understanding of these factors could be pivotal in refining tool designs and promoting broader adoption, this study investigates the factors influencing the adoption of fairness toolkits from an individual perspective. Guided by the Unified Theory of Acceptance and Use of Technology (UTAUT2), we examined the factors shaping the intention to adopt and actual use of fairness toolkits. Specifically, we employed Partial Least Squares Structural Equation Modeling (PLS-SEM) to analyze data from a survey study involving practitioners in the software industry. Our findings reveal that performance expectancy and habit are the primary drivers of fairness toolkit adoption. These insights suggest that by emphasizing the effectiveness of these tools in mitigating bias and fostering habitual use, organizations can encourage wider adoption. Practical recommendations include improving toolkit usability, integrating bias mitigation processes into routine development workflows, and providing ongoing support to ensure professionals see clear benefits from regular use.</description>
      <guid isPermaLink="false">oai:arXiv.org:2412.13846v2</guid>
      <category>cs.SE</category>
      <category>cs.AI</category>
      <pubDate>Thu, 19 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Gianmario Voria, Stefano Lambiase, Maria Concetta Schiavone, Gemma Catolino, Fabio Palomba</dc:creator>
    </item>
    <item>
      <title>Rango: Adaptive Retrieval-Augmented Proving for Automated Software Verification</title>
      <link>https://arxiv.org/abs/2412.14063</link>
      <description>arXiv:2412.14063v1 Announce Type: new 
Abstract: Formal verification using proof assistants, such as Coq, enables the creation of high-quality software. However, the verification process requires significant expertise and manual effort to write proofs. Recent work has explored automating proof synthesis using machine learning and large language models (LLMs). This work has shown that identifying relevant premises, such as lemmas and definitions, can aid synthesis. We present Rango, a fully automated proof synthesis tool for Coq that automatically identifies relevant premises and also similar proofs from the current project and uses them during synthesis. Rango uses retrieval augmentation at every step of the proof to automatically determine which proofs and premises to include in the context of its fine-tuned LLM. In this way, Rango adapts to the project and to the evolving state of the proof. We create a new dataset, CoqStoq, of 2,226 open-source Coq projects and 196,929 theorems from GitHub, which includes both training data and a curated evaluation benchmark of well-maintained projects. On this benchmark, Rango synthesizes proofs for 32.0% of the theorems, which is 29% more theorems than the prior state-of-the-art tool Tactician. Our evaluation also shows that Rango adding relevant proofs to its context leads to a 47% increase in the number of theorems proven.</description>
      <guid isPermaLink="false">oai:arXiv.org:2412.14063v1</guid>
      <category>cs.SE</category>
      <category>cs.AI</category>
      <pubDate>Thu, 19 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Kyle Thompson, Nuno Saavedra, Pedro Carrott, Kevin Fisher, Alex Sanchez-Stern, Yuriy Brun, Jo\~ao F. Ferreira, Sorin Lerner, Emily First</dc:creator>
    </item>
    <item>
      <title>Design choices made by LLM-based test generators prevent them from finding bugs</title>
      <link>https://arxiv.org/abs/2412.14137</link>
      <description>arXiv:2412.14137v1 Announce Type: new 
Abstract: There is an increasing amount of research and commercial tools for automated test case generation using Large Language Models (LLMs). This paper critically examines whether recent LLM-based test generation tools, such as Codium CoverAgent and CoverUp, can effectively find bugs or unintentionally validate faulty code. Considering bugs are only exposed by failing test cases, we explore the question: can these tools truly achieve the intended objectives of software testing when their test oracles are designed to pass? Using real human-written buggy code as input, we evaluate these tools, showing how LLM-generated tests can fail to detect bugs and, more alarmingly, how their design can worsen the situation by validating bugs in the generated test suite and rejecting bug-revealing tests. These findings raise important questions about the validity of the design behind LLM-based test generation tools and their impact on software quality and test suite reliability.</description>
      <guid isPermaLink="false">oai:arXiv.org:2412.14137v1</guid>
      <category>cs.SE</category>
      <category>cs.AI</category>
      <pubDate>Thu, 19 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <dc:creator>Noble Saji Mathews, Meiyappan Nagappan</dc:creator>
    </item>
    <item>
      <title>4.5 Million (Suspected) Fake Stars in GitHub: A Growing Spiral of Popularity Contests, Scams, and Malware</title>
      <link>https://arxiv.org/abs/2412.13459</link>
      <description>arXiv:2412.13459v1 Announce Type: cross 
Abstract: GitHub, the de-facto platform for open-source software development, provides a set of social-media-like features to signal high-quality repositories. Among them, the star count is the most widely used popularity signal, but it is also at risk of being artificially inflated (i.e., faked), decreasing its value as a decision-making signal and posing a security risk to all GitHub users. In this paper, we present a systematic, global, and longitudinal measurement study of fake stars in GitHub. To this end, we build StarScout, a scalable tool able to detect anomalous starring behaviors (i.e., low activity and lockstep) across the entire GitHub metadata. Analyzing the data collected using StarScout, we find that: (1) fake-star-related activities have rapidly surged since 2024; (2) the user profile characteristics of fake stargazers are not distinct from average GitHub users, but many of them have highly abnormal activity patterns; (3) the majority of fake stars are used to promote short-lived malware repositories masquerading as pirating software, game cheats, or cryptocurrency bots; (4) some repositories may have acquired fake stars for growth hacking, but fake stars only have a promotion effect in the short term (i.e., less than two months) and become a burden in the long term. Our study has implications for platform moderators, open-source practitioners, and supply chain security researchers.</description>
      <guid isPermaLink="false">oai:arXiv.org:2412.13459v1</guid>
      <category>cs.CR</category>
      <category>cs.SE</category>
      <pubDate>Thu, 19 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Hao He, Haoqin Yang, Philipp Burckhardt, Alexandros Kapravelos, Bogdan Vasilescu, Christian K\"astner</dc:creator>
    </item>
    <item>
      <title>Verified invertible lexer using regular expressions and DFAs</title>
      <link>https://arxiv.org/abs/2412.13581</link>
      <description>arXiv:2412.13581v1 Announce Type: cross 
Abstract: In this project, we explore the concept of invertibility applied to serialisation and lexing frameworks. Recall that, on one hand, serialisation is the process of taking a data structure and writing it to a bit array while parsing is the reverse operation, i.e., reading the bit array and constructing the data structure back. While lexing, on the other hand, is the process of reading a stream of characters and splitting them into tokens, by following a list of given rules. While used in different applications, both are similar in their abstract operation: they both take a list of simple characters and extract a more complex structure. Applications in which these two operations are used are different but they share a need for the invertibility of the process. For example, when tokenising a code file that was prettyprinted by a compiler, one would expect to get the same sequence of tokens. Similarly, when a spacecraft sends scientific data to the ground, one would expect the parsed data to be the same as the one serialised by the spacecraft. The idea of this project is to explore the idea of having a framework capable of generating parser/serialiser or lexer/prettyprinter pairs with a formally verified notion of invertibility. We first explore related works and frameworks. After that, we present our verified lexer framework developed in Scala and verified using the Stainless framework1. We explain the implementation choices we make and present the specifications and their proofs. The code of the lexer with the proofs is available on Github2. The main branch contains the regular expression (called regex from now on) matcher version and the verified Computable Languages while the dfa match branch contains the version using the DFA matcher.</description>
      <guid isPermaLink="false">oai:arXiv.org:2412.13581v1</guid>
      <category>cs.PL</category>
      <category>cs.SE</category>
      <pubDate>Thu, 19 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Samuel Chassot, Viktor Kun\v{c}ak</dc:creator>
    </item>
    <item>
      <title>Software Engineering Educational Experience in Building an Intelligent Tutoring System</title>
      <link>https://arxiv.org/abs/2310.05472</link>
      <description>arXiv:2310.05472v3 Announce Type: replace 
Abstract: The growing number of students enrolling in Computer Science (CS) programmes is pushing CS educators to their limits. This poses significant challenges to computing education, particularly the teaching of introductory programming and advanced software engineering (SE) courses. First-year programming courses often face overwhelming enrollments, including interdisciplinary students who are not CS majors. The high teacher-to-student ratio makes it challenging to provide timely and high-quality feedback. Meanwhile, software engineering education comes with inherent difficulties like acquiring industry partners and the dilemma that such software projects are often under or over-specified and one-time efforts within one team or one course. To address these challenges, we designed a novel foundational SE course. This SE course envisions building a full-fledged Intelligent Tutoring System (ITS) of Programming Assignments to provide automated, real-time feedback for novice students in programming courses over multiple years. Each year, SE students contribute to specific short-running SE projects that improve the existing ITS implementation, while at the same time, we can deploy the ITS for usage by students for learning programming. This project setup builds awareness among SE students about their contribution to a "to-be-deployed" software project. In this multi-year teaching effort, we have incrementally built an ITS that is now deployed in various programming courses. This paper discusses the Intelligent Tutoring System architecture, our teaching concept in the SE course, our experience with the built ITS, and our view of future computing education.</description>
      <guid isPermaLink="false">oai:arXiv.org:2310.05472v3</guid>
      <category>cs.SE</category>
      <category>cs.CY</category>
      <pubDate>Thu, 19 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Zhiyu Fan, Yannic Noller, Ashish Dandekar, Abhik Roychoudhury</dc:creator>
    </item>
    <item>
      <title>Training LLMs for Generating IEC 61131-3 Structured Text with Online Feedback</title>
      <link>https://arxiv.org/abs/2410.22159</link>
      <description>arXiv:2410.22159v3 Announce Type: replace 
Abstract: IEC 61131-3 Structured Text (ST) is a widely used programming language for programmable logic controllers (PLCs) in automation systems. However, generating ST code with LLMs poses unique challenges due to limited data in public training datasets and the complexity of ST language syntax. This paper proposes an approach to fine-tune LLMs for the generation of ST code that leverages a preference-based learning method through an online process involving compiler feedback and evaluation from an LLM-based ST expert. In this framework, the model is iteratively refined and generates new training samples, which are subsequently evaluated by a compiler for syntactical correctness and by a specialized LLM that excels at assessing semantic accuracy, though it is not optimized for code generation itself. This approach results in marked improvements for the trained LLM, leading to higher compilation success rates and better semantic precision. As a result, the framework proves highly suitable for industrial automation applications and outperforms state-of-the-art models.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.22159v3</guid>
      <category>cs.SE</category>
      <pubDate>Thu, 19 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Aaron Haag, Bertram Fuchs, Altay Kacan, Oliver Lohse</dc:creator>
    </item>
    <item>
      <title>Guardians of the Ledger: Protecting Decentralized Exchanges from State Derailment Defects</title>
      <link>https://arxiv.org/abs/2411.18935</link>
      <description>arXiv:2411.18935v2 Announce Type: replace 
Abstract: The decentralized exchange (DEX) leverages smart contracts to trade digital assets for users on the blockchain. Developers usually develop several smart contracts into one project, implementing complex logic functions and multiple transaction operations. However, the interaction among these contracts poses challenges for developers analyzing the state logic. Due to the complex state logic in DEX projects, many critical state derailment defects have emerged in recent years. In this paper, we conduct the first systematic study of state derailment defects in DEX. We define five categories of state derailment defects and provide detailed analyses of them. Furthermore, we propose a novel deep learning-based framework StateGuard for detecting state derailment defects in DEX smart contracts. It leverages a smart contract deconstructor to deconstruct the contract into an Abstract Syntax Tree (AST), from which five categories of dependency features are extracted. Next, it implements a graph optimizer to process the structured data. At last, the optimized data is analyzed by Graph Convolutional Networks (GCNs) to identify potential state derailment defects. We evaluated StateGuard through a dataset of 46 DEX projects containing 5,671 smart contracts, and it achieved 94.25% F1-score. In addition, in a comparison experiment with state-of-the-art, StateGuard leads the F1-score by 6.29%. To further verify its practicality, we used StateGuar to audit real-world contracts and successfully authenticated multiple novel CVEs.</description>
      <guid isPermaLink="false">oai:arXiv.org:2411.18935v2</guid>
      <category>cs.SE</category>
      <category>cs.CR</category>
      <pubDate>Thu, 19 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Zongwei Li, Wenkai Li, Xiaoqi Li, Yuqing Zhang</dc:creator>
    </item>
    <item>
      <title>Analyzing Toxicity in Open Source Software Communications Using Psycholinguistics and Moral Foundations Theory</title>
      <link>https://arxiv.org/abs/2412.13133</link>
      <description>arXiv:2412.13133v2 Announce Type: replace 
Abstract: Studies have shown that toxic behavior can cause contributors to leave, and hinder newcomers' (especially from underrepresented communities) participation in Open Source Software (OSS) projects. Thus, detection of toxic language plays a crucial role in OSS collaboration and inclusivity. Off-the-shelf toxicity detectors are ineffective when applied to OSS communications, due to the distinct nature of toxicity observed in these channels (e.g., entitlement and arrogance are more frequently observed on GitHub than on Reddit or Twitter). In this paper, we investigate a machine learning-based approach for the automatic detection of toxic communications in OSS. We leverage psycholinguistic lexicons, and Moral Foundations Theory to analyze toxicity in two types of OSS communication channels; issue comments and code reviews. Our evaluation indicates that our approach can achieve a significant performance improvement (up to 7% increase in F1 score) over the existing domain-specific toxicity detector. We found that using moral values as features is more effective than linguistic cues, resulting in 67.50% F1-measure in identifying toxic instances in code review data and 64.83% in issue comments. While the detection accuracy is far from accurate, this improvement demonstrates the potential of integrating moral and psycholinguistic features in toxicity detection models. These findings highlight the importance of context-specific models that consider the unique communication styles within OSS, where interpersonal and value-driven language dynamics differ markedly from general social media platforms. Future work could focus on refining these models to further enhance detection accuracy, possibly by incorporating community-specific norms and conversational context to better capture the nuanced expressions of toxicity in OSS environments.</description>
      <guid isPermaLink="false">oai:arXiv.org:2412.13133v2</guid>
      <category>cs.SE</category>
      <pubDate>Thu, 19 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Ramtin Ehsani, Shadi Rezapour, Preetha Chatterjee</dc:creator>
    </item>
    <item>
      <title>AwesomeMeta+: Bridging the Technical Barriers to Meta-Learning via A Prototyping and Learning System</title>
      <link>https://arxiv.org/abs/2304.12921</link>
      <description>arXiv:2304.12921v2 Announce Type: replace-cross 
Abstract: Meta-learning, also known as "learning to learn", enables models to acquire great generalization abilities by learning from various tasks. Recent advancements have made these models applicable across various fields without data constraints, offering new opportunities for general artificial intelligence. However, applying these models can be challenging due to their often task-specific, standalone nature and the technical barriers involved. To address this challenge, we develop AwesomeMeta+, a prototyping and learning system that standardizes different components of meta-learning and uses a building block metaphor to assist in model construction. AwesomeMeta+ allows users to assemble compatible algorithm modules to meet the application needs in practice. To optimize AwesomeMeta+, we provide the interface to 50 researchers and refine the design based on their feedback. Through machine-based testing and user studies, we demonstrate that AwesomeMeta+ enhances users' understanding of the related technologies and accelerates their engineering processes by offering guidance for meta-learning deployments.</description>
      <guid isPermaLink="false">oai:arXiv.org:2304.12921v2</guid>
      <category>cs.LG</category>
      <category>cs.CV</category>
      <category>cs.SE</category>
      <pubDate>Thu, 19 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Jingyao Wang, Yuxuan Yang, Wenwen Qiang, Changwen Zheng</dc:creator>
    </item>
  </channel>
</rss>
