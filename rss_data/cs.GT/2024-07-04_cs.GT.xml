<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>cs.GT updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/cs.GT</link>
    <description>cs.GT updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/cs.GT" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Thu, 04 Jul 2024 04:00:39 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Thu, 04 Jul 2024 00:00:00 -0400</pubDate>
    <skipDays>
      <day>Saturday</day>
      <day>Sunday</day>
    </skipDays>
    <item>
      <title>Fair Division of Indivisible Chores via Earning Restricted Equilibria</title>
      <link>https://arxiv.org/abs/2407.03318</link>
      <description>arXiv:2407.03318v1 Announce Type: new 
Abstract: We study fair division of $m$ indivisible chores among $n$ agents with additive preferences. We consider the desirable fairness notions of envy-freeness up to any chore (EFX) and envy-freeness up to $k$ chores (EF$k$), alongside the efficiency notion of Pareto optimality (PO). We present the first constant approximations of these notions, showing the existence of:
  - 5-EFX allocations, which improve the best-known factor of $O(n^2)$-EFX.
  - 3-EFX and PO allocations for the special case of bivalued instances, which improve the best-known factor of $O(n)$-EFX without any efficiency guarantees.
  - 2-EF2 + PO allocations, which improve the best-known factor of EF$m$ + PO.
  A notable contribution of our work is the introduction of the novel concept of earning-restricted (ER) competitive equilibrium for fractional allocations, which limits agents' earnings from each chore. Technically, our work addresses two main challenges: proving the existence of an ER equilibrium and designing algorithms that leverage ER equilibria to achieve the above results. To tackle the first challenge, we formulate a linear complementarity problem (LCP) formulation that captures all ER equilibria and show that the classic complementary pivot algorithm on the LCP must terminate at an ER equilibrium. For the second challenge, we carefully set the earning limits and use properties of ER equilibria to design sophisticated procedures that involve swapping and merging bundles to meet the desired fairness and efficiency criteria. We expect that the concept of ER equilibrium will be instrumental in deriving further results on related problems.</description>
      <guid isPermaLink="false">oai:arXiv.org:2407.03318v1</guid>
      <category>cs.GT</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Jugal Garg, Aniket Murhekar, John Qin</dc:creator>
    </item>
    <item>
      <title>Game-Theoretic Protection Adoption Against Networked SIS Epidemics</title>
      <link>https://arxiv.org/abs/2407.03126</link>
      <description>arXiv:2407.03126v1 Announce Type: cross 
Abstract: In this paper, we investigate game-theoretic strategies for containing spreading processes on large-scale networks. Specifically, we consider the class of networked susceptible-infected-susceptible (SIS) epidemics where a large population of agents strategically choose whether to adopt partially effective protection. We define the utilities of the agents which depends on the degree of the agent, its individual infection status and action, as well as the the overall prevalence of the epidemic and strategy profile of the entire population. We further present the coupled dynamics of epidemic evolution as well as strategy update which is assumed to follow the replicator dynamics. By relying on timescale separation arguments, we first derive the optimal strategy of protection adoption by the agents for a given epidemic state, and then present the reduced epidemic dynamics. The existence and uniqueness of endemic equilibrium is rigorously characterized and forms the main result of this paper. Finally, we present extensive numerical results to highlight the impacts of heterogeneous node degrees, infection rates, cost of protection adoption, and effectiveness of protection on the epidemic prevalence at the equilibrium.</description>
      <guid isPermaLink="false">oai:arXiv.org:2407.03126v1</guid>
      <category>eess.SY</category>
      <category>cs.GT</category>
      <category>cs.SI</category>
      <category>cs.SY</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Abhisek Satapathi, Ashish R. Hota</dc:creator>
    </item>
    <item>
      <title>Enhancing Class Fairness in Classification with A Two-Player Game Approach</title>
      <link>https://arxiv.org/abs/2407.03146</link>
      <description>arXiv:2407.03146v1 Announce Type: cross 
Abstract: Data augmentation is widely applied and has shown its benefits in different machine learning tasks. However, as recently observed in some downstream tasks, data augmentation may introduce an unfair impact on classifications. While it can improve the performance of some classes, it can actually be detrimental for other classes, which can be problematic in some application domains. In this paper, to counteract this phenomenon, we propose a FAir Classification approach with a Two-player game (FACT). We first formulate the training of a classifier with data augmentation as a fair optimization problem, which can be further written as an adversarial two-player game. Following this formulation, we propose a novel multiplicative weight optimization algorithm, for which we theoretically prove that it can converge to a solution that is fair over classes. Interestingly, our formulation also reveals that this fairness issue over classes is not due to data augmentation only, but is in fact a general phenomenon. Our empirical experiments demonstrate that the performance of our learned classifiers is indeed more fairly distributed over classes in five datasets, with only limited impact on the average accuracy.</description>
      <guid isPermaLink="false">oai:arXiv.org:2407.03146v1</guid>
      <category>cs.CY</category>
      <category>cs.AI</category>
      <category>cs.CV</category>
      <category>cs.GT</category>
      <category>cs.LG</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Yunpeng Jiang, Paul Weng, Yutong Ban</dc:creator>
    </item>
    <item>
      <title>Collaborative Decision-Making and the k-Strong Price of Anarchy in Common Interest Games</title>
      <link>https://arxiv.org/abs/2311.01379</link>
      <description>arXiv:2311.01379v2 Announce Type: replace 
Abstract: The control of large-scale, multi-agent systems often entails distributing decision-making across the system components. However, with advances in communication and computation technologies, we can consider new collaborative decision-making paradigms that exist somewhere between centralized and distributed control. In this work, we seek to understand the benefits and costs of increased collaborative communication in multi-agent systems. We specifically study this in the context of common interest games in which groups of up to k agents can coordinate their actions in maximizing the common objective function. The equilibria that emerge in these systems are the k-strong Nash equilibria of the common interest game; studying the properties of these states can provide relevant insights into the efficacy of inter-agent collaboration. Our contributions come threefold: 1) provide bounds on how well k-strong Nash equilibria approximate the optimal system welfare, formalized by the k-strong price of anarchy, 2) study the run-time and transient performance of collaborative agent-based dynamics, and 3) consider the task of redesigning objectives for groups of agents which improve system performance. We study these three facets generally as well as in the context of resource allocation problems, in which we provide tractable linear programs that give tight bounds on the k-strong price of anarchy.</description>
      <guid isPermaLink="false">oai:arXiv.org:2311.01379v2</guid>
      <category>cs.GT</category>
      <category>cs.SY</category>
      <category>eess.SY</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Bryce L. Ferguson, Dario Paccagnan, Bary S. R. Pradelski, Jason R. Marden</dc:creator>
    </item>
    <item>
      <title>On Tractable $\Phi$-Equilibria in Non-Concave Games</title>
      <link>https://arxiv.org/abs/2403.08171</link>
      <description>arXiv:2403.08171v2 Announce Type: replace 
Abstract: While Online Gradient Descent and other no-regret learning procedures are known to efficiently converge to a coarse correlated equilibrium in games where each agent's utility is concave in their own strategy, this is not the case when utilities are non-concave -- a common scenario in machine learning applications involving strategies parameterized by deep neural networks, or when agents' utilities are computed by neural networks, or both. Non-concave games introduce significant game-theoretic and optimization challenges: (i) Nash equilibria may not exist; (ii) local Nash equilibria, though existing, are intractable; and (iii) mixed Nash, correlated, and coarse correlated equilibria generally have infinite support and are intractable. To sidestep these challenges, we revisit the classical solution concept of $\Phi$-equilibria introduced by Greenwald and Jafari [2003], which is guaranteed to exist for an arbitrary set of strategy modifications $\Phi$ even in non-concave games [Stoltz and Lugosi, 2007]. However, the tractability of $\Phi$-equilibria in such games remains elusive. In this paper, we initiate the study of tractable $\Phi$-equilibria in non-concave games and examine several natural families of strategy modifications. We show that when $\Phi$ is finite, there exists an efficient uncoupled learning algorithm that converges to the corresponding $\Phi$-equilibria. Additionally, we explore cases where $\Phi$ is infinite but consists of local modifications, showing that Online Gradient Descent can efficiently approximate $\Phi$-equilibria in non-trivial regimes.</description>
      <guid isPermaLink="false">oai:arXiv.org:2403.08171v2</guid>
      <category>cs.GT</category>
      <category>cs.LG</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Yang Cai, Constantinos Daskalakis, Haipeng Luo, Chen-Yu Wei, Weiqiang Zheng</dc:creator>
    </item>
    <item>
      <title>An extension of May's Theorem to three alternatives: axiomatizing Minimax voting</title>
      <link>https://arxiv.org/abs/2312.14256</link>
      <description>arXiv:2312.14256v2 Announce Type: replace-cross 
Abstract: May's Theorem [K. O. May, Econometrica 20 (1952) 680-684] characterizes majority voting on two alternatives as the unique preferential voting method satisfying several simple axioms. Here we show that by adding some desirable axioms to May's axioms, we can uniquely determine how to vote on three alternatives (setting aside tiebreaking). In particular, we add two axioms stating that the voting method should mitigate spoiler effects and avoid the so-called strong no show paradox. We prove a theorem stating that any preferential voting method satisfying our enlarged set of axioms, which includes some weak homogeneity and preservation axioms, must choose from among the Minimax winners in all three-alternative elections. When applied to more than three alternatives, our axioms also distinguish Minimax from other known voting methods that coincide with or refine Minimax for three alternatives.</description>
      <guid isPermaLink="false">oai:arXiv.org:2312.14256v2</guid>
      <category>econ.TH</category>
      <category>cs.GT</category>
      <category>cs.MA</category>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Wesley H. Holliday, Eric Pacuit</dc:creator>
    </item>
    <item>
      <title>Monitoring with Rich Data</title>
      <link>https://arxiv.org/abs/2312.16789</link>
      <description>arXiv:2312.16789v2 Announce Type: replace-cross 
Abstract: We consider moral hazard problems where a principal has access to rich monitoring data about an agent's action. Rather than focusing on optimal contracts (which are known to in general be complicated), we characterize the optimal rate at which the principal's payoffs can converge to the first-best payoff as the amount of data grows large. Our main result suggests a novel rationale for the widely observed binary wage schemes, by showing that such simple contracts achieve the optimal convergence rate. Notably, in order to attain the optimal convergence rate, the principal must set a lenient cutoff for when the agent receives a high vs. low wage. In contrast, we find that other common contracts where wages vary more finely with observed data (e.g., linear contracts) approximate the first-best at a highly suboptimal rate. Finally, we show that the optimal convergence rate depends only on a simple summary statistic of the monitoring technology. This yields a detail-free ranking over monitoring technologies that quantifies their value for incentive provision in data-rich settings and applies regardless of the agent's specific utility or cost functions.</description>
      <guid isPermaLink="false">oai:arXiv.org:2312.16789v2</guid>
      <category>econ.TH</category>
      <category>cs.GT</category>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Mira Frick, Ryota Iijima, Yuhta Ishii</dc:creator>
    </item>
  </channel>
</rss>
