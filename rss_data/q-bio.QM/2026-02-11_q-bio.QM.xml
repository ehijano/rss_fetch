<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>q-bio.QM updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/q-bio.QM</link>
    <description>q-bio.QM updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/q-bio.QM" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Wed, 11 Feb 2026 05:00:21 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Wed, 11 Feb 2026 00:00:00 -0500</pubDate>
    <skipDays>
      <day>Sunday</day>
      <day>Saturday</day>
    </skipDays>
    <item>
      <title>Importance inversion transfer identifies shared principles for cross-domain learning</title>
      <link>https://arxiv.org/abs/2602.09116</link>
      <description>arXiv:2602.09116v1 Announce Type: cross 
Abstract: The capacity to transfer knowledge across scientific domains relies on shared organizational principles. However, existing transfer-learning methodologies often fail to bridge radically heterogeneous systems, particularly under severe data scarcity or stochastic noise. This study formalizes Explainable Cross-Domain Transfer Learning (X-CDTL), a framework unifying network science and explainable artificial intelligence to identify structural invariants that generalize across biological, linguistic, molecular, and social networks. By introducing the Importance Inversion Transfer (IIT) mechanism, the framework prioritizes domain-invariant structural anchors over idiosyncratic, highly discriminative features. In anomaly detection tasks, models guided by these principles achieve significant performance gains - exhibiting a 56\% relative improvement in decision stability under extreme noise - over traditional baselines. These results provide evidence for a shared organizational signature across heterogeneous domains, establishing a principled paradigm for cross-disciplinary knowledge propagation. By shifting from opaque latent representations to explicit structural laws, this work advances machine learning as a robust engine for scientific discovery.</description>
      <guid isPermaLink="false">oai:arXiv.org:2602.09116v1</guid>
      <category>cs.LG</category>
      <category>physics.soc-ph</category>
      <category>q-bio.QM</category>
      <pubDate>Wed, 11 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Daniele Caligiore</dc:creator>
    </item>
    <item>
      <title>Reward-Guided Discrete Diffusion via Clean-Sample Markov Chain for Molecule and Biological Sequence Design</title>
      <link>https://arxiv.org/abs/2602.09424</link>
      <description>arXiv:2602.09424v1 Announce Type: cross 
Abstract: Discrete diffusion models have recently emerged as a powerful class of generative models for chemistry and biology data. In these fields, the goal is to generate various samples with high rewards (e.g., drug-likeness in molecules), making reward-based guidance crucial. Most existing methods are based on guiding the diffusion model using intermediate rewards but tend to underperform since intermediate rewards are noisy due to the non-smooth nature of reward functions used in scientific domains. To address this, we propose Clean-Sample Markov Chain (CSMC) Sampler, a method that performs effective test-time reward-guided sampling for discrete diffusion models, enabling local search without relying on intermediate rewards. CSMC constructs a Markov chain of clean samples using the Metropolis-Hastings algorithm such that its stationary distribution is the target distribution. We design a proposal distribution by sequentially applying the forward and backward diffusion processes, making the acceptance probability tractable. Experiments on molecule and biological sequence generation with various reward functions demonstrate that our method consistently outperforms prior approaches that rely on intermediate rewards.</description>
      <guid isPermaLink="false">oai:arXiv.org:2602.09424v1</guid>
      <category>cs.LG</category>
      <category>q-bio.QM</category>
      <pubDate>Wed, 11 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Prin Phunyaphibarn, Minhyuk Sung</dc:creator>
    </item>
    <item>
      <title>Fully-automated sleep staging: multicenter validation of a generalizable deep neural network for Parkinson's disease and isolated REM sleep behavior disorder</title>
      <link>https://arxiv.org/abs/2602.09793</link>
      <description>arXiv:2602.09793v1 Announce Type: cross 
Abstract: Isolated REM sleep behavior disorder (iRBD) is a key prodromal marker of Parkinson's disease (PD), and video-polysomnography (vPSG) remains the diagnostic gold standard. However, manual sleep staging is particularly challenging in neurodegenerative diseases due to EEG abnormalities and fragmented sleep, making PSG assessments a bottleneck for deploying new RBD screening technologies at scale. We adapted U-Sleep, a deep neural network, for generalizable sleep staging in PD and iRBD. A pretrained U-Sleep model, based on a large publicly available, multisite non-neurodegenerative dataset (PUB; 19,236 PSGs across 12 sites), was fine-tuned on research datasets from two centers (Lundbeck Foundation Parkinson's Disease Research Center (PACE) and the Cologne-Bonn Cohort (CBC); 112 PD, 138 iRBD, 89 age-matched controls. The resulting model was evaluated on an independent dataset from the Danish Center for Sleep Medicine (DCSM; 81 PD, 36 iRBD, 87 sleep-clinic controls). A subset of PSGs with low agreement between the human rater and the model (\k{appa} &lt; 0.6) was re-scored by a second blinded human rater to identify sources of disagreement. Finally, we applied confidence-based thresholds to optimize REM sleep staging. The pretrained model achieved mean \k{appa} = 0.81 in PUB, but \k{appa} = 0.66 when applied directly to PACE/CBC. By fine-tuning the model, we developed a generalized model with \k{appa} = 0.74 on PACE/CBC (p &lt; 0.001 vs. the pretrained model). In DCSM, mean and median \k{appa} increased from 0.60 to 0.64 (p &lt; 0.001) and 0.64 to 0.69 (p &lt; 0.001), respectively. In the interrater study, PSGs with low agreement between the model and the initial scorer showed similarly low agreement between human scorers. Applying a confidence threshold increased the proportion of correctly identified REM sleep epochs from 85% to 95.5%, while preserving sufficient (&gt; 5 min) REM sleep for 95% of subjects.</description>
      <guid isPermaLink="false">oai:arXiv.org:2602.09793v1</guid>
      <category>cs.LG</category>
      <category>q-bio.QM</category>
      <pubDate>Wed, 11 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Jesper Str{\o}m, Casper Skj{\ae}rb{\ae}k, Natasha Becker Bertelsen, Steffen Torpe Simonsen, Niels Okkels, David Bertram, Sinah R\"ottgen, Konstantin Kufer, Kaare B. Mikkelsen, Marit Otto, Poul J{\o}rgen Jennum, Per Borghammer, Michael Sommerauer, Preben Kidmose</dc:creator>
    </item>
    <item>
      <title>Chargaff's second parity rule and the kinetics of DNA replication</title>
      <link>https://arxiv.org/abs/2601.12101</link>
      <description>arXiv:2601.12101v2 Announce Type: replace 
Abstract: This paper presents the study of a DNA replication model grounded in the biochemical kinetics of DNA polymerases, which copy each DNA strand into a complementary strand, except for rare point-like mutations caused by nucleotide substitution errors. Numerical simulations of many successive replications, starting from an arbitrary initial DNA sequence, show that the fractions of mono- and oligonucleotides converge toward compliance with Chargaff's second parity rule. The theoretical framework developed for this multireplication process demonstrates that the near-equalities of complementary nucleotide fractions arise from two key features: (1) the dominant role of base-pair complementarity in replication kinetics and (2) the low intrinsic error rate of DNA polymerases. Together, these two features yield a robust mechanistic basis for Chargaff's second parity rule. These considerations explain the existence of deviations with respect to the predictions of models assuming no-strand-bias conditions.</description>
      <guid isPermaLink="false">oai:arXiv.org:2601.12101v2</guid>
      <category>q-bio.QM</category>
      <pubDate>Wed, 11 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Pierre Gaspard</dc:creator>
    </item>
    <item>
      <title>Pangenome-guided sequence assembly via binary optimisation</title>
      <link>https://arxiv.org/abs/2508.08200</link>
      <description>arXiv:2508.08200v2 Announce Type: replace-cross 
Abstract: De novo genome assembly is challenging in highly repetitive regions; however, reference-guided assemblers often suffer from bias. We propose a framework for pangenome-guided sequence assembly, which can resolve short-read data in complex regions without bias towards a single reference genome. Our primary contribution is to frame the assembly as a graph traversal optimisation problem, which can be implemented classically or on a quantum computer. The workflow involves first annotating pangenome graphs with estimated copy numbers for each node, then finding a path on the graph that best explains those copy numbers. On simulated data, our approach significantly reduces the number of contigs compared to de novo assemblers. While they introduce a small increase in inaccuracies, such as false joins, our optimisation-based methods are competitive with current exhaustive search techniques. They are also designed to scale more efficiently as the problem size grows and will run effectively on future quantum computers; a small experiment on a real quantum device showcases this behaviour. Moreover, they are more resilient to noise in copy number estimation inherent in short-read-based assembly. We also develop novel tools for creating realistic synthetic pangenomes, aligning reads to pangenomes and for evaluating assembly quality.</description>
      <guid isPermaLink="false">oai:arXiv.org:2508.08200v2</guid>
      <category>quant-ph</category>
      <category>q-bio.QM</category>
      <pubDate>Wed, 11 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <arxiv:DOI>10.1101/2025.08.06.668889</arxiv:DOI>
      <dc:creator>Josh Cudby, James Bonfield, Chenxi Zhou, Richard Durbin, Sergii Strelchuk</dc:creator>
    </item>
  </channel>
</rss>
