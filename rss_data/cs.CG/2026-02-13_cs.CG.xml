<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>cs.CG updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/cs.CG</link>
    <description>cs.CG updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/cs.CG" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Fri, 13 Feb 2026 07:15:08 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Fri, 13 Feb 2026 00:00:00 -0500</pubDate>
    <skipDays>
      <day>Saturday</day>
      <day>Sunday</day>
    </skipDays>
    <item>
      <title>An Improved Upper Bound for the Euclidean TSP Constant Using Band Crossovers</title>
      <link>https://arxiv.org/abs/2602.11250</link>
      <description>arXiv:2602.11250v1 Announce Type: new 
Abstract: Consider $n$ points generated uniformly at random in the unit square, and let $L_n$ be the length of their optimal traveling salesman tour. Beardwood, Halton, and Hammersley (1959) showed $L_n / \sqrt n \to \beta$ almost surely as $n\to \infty$ for some constant $\beta$. The exact value of $\beta$ is unknown but estimated to be approximately $0.71$ (Applegate, Bixby, Chv\'atal, Cook 2011). Beardwood et al. further showed that $0.625 \leq \beta \leq 0.92116.$ Currently, the best known bounds are $0.6277 \leq \beta \leq 0.90380$, due to Gaudio and Jaillet (2019) and Carlsson and Yu (2023), respectively. The upper bound was derived using a computer-aided approach that is amenable to lower bounds with improved computation speed. In this paper, we show via simulation and concentration analysis that future improvement of the $0.90380$ is limited to $\sim0.88$. Moreover, we provide an alternative tour-constructing heuristic that, via simulation, could potentially improve the upper bound to $\sim0.85$. Our approach builds on a prior \emph{band-traversal} strategy, initially proposed by Beardwood et al. (1959) and subsequently refined by Carlsson and Yu (2023): divide the unit square into bands of height $\Theta(1/\sqrt{n})$, construct paths within each band, and then connect the paths to create a TSP tour. Our approach allows paths to cross bands, and takes advantage of pairs of points in adjacent bands which are close to each other. A rigorous numerical analysis improves the upper bound to $0.90367$.</description>
      <guid isPermaLink="false">oai:arXiv.org:2602.11250v1</guid>
      <category>cs.CG</category>
      <category>cs.DS</category>
      <category>math.CO</category>
      <category>math.PR</category>
      <pubDate>Fri, 13 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Julia Gaudio, Charlie K. Guan</dc:creator>
    </item>
    <item>
      <title>An Improved FPT Algorithm for Computing the Interleaving Distance between Merge Trees via Path-Preserving Maps</title>
      <link>https://arxiv.org/abs/2602.12028</link>
      <description>arXiv:2602.12028v1 Announce Type: new 
Abstract: A merge tree is a fundamental topological structure used to capture the sub-level set (and similarly, super-level set) topology in scalar data analysis. The interleaving distance is a theoretically sound, stable metric for comparing merge trees. However, computing this distance exactly is NP-hard. First fixed-parameter tractable (FPT) algorithm for it's exact computation introduces the concept of an $\varepsilon$-good map between two merge trees, where $\varepsilon$ is a candidate value for the interleaving distance. The complexity of their algorithm is $O(2^{2\tau}(2\tau)^{2\tau+2}\cdot n^2\log^3n)$ where $\tau$ is the degree-bound parameter and $n$ is the total number of nodes in both the merge trees. Their algorithm exhibits exponential complexity in $\tau$, which increases with the increasing value of $\varepsilon$. In the current paper, we propose an improved FPT algorithm for computing the $\varepsilon$-good map between two merge trees. Our algorithm introduces two new parameters, $\eta_f$ and $\eta_g$, corresponding to the numbers of leaf nodes in the merge trees $M_f$ and $M_g$, respectively. This parametrization is motivated by the observation that a merge tree can be decomposed into a collection of unique leaf-to-root paths. The proposed algorithm achieves a complexity of $O\!\left(n^2\log n+\eta_g^{\eta_f}(\eta_f+\eta_g)\, n \log n \right)$. To obtain this reduced complexity, we assume that number of possible $\varepsilon$-good maps from $M_f$ to $M_g$ does not exceed that from $M_g$ to $M_f$. Notably, the parameters $\eta_f$ and $\eta_g$ are independent of the choice of $\varepsilon$. Compared to their algorithm, our approach substantially reduces the search space for computing an optimal $\varepsilon$-good map. We also provide a formal proof of correctness for the proposed algorithm.</description>
      <guid isPermaLink="false">oai:arXiv.org:2602.12028v1</guid>
      <category>cs.CG</category>
      <category>cs.DS</category>
      <pubDate>Fri, 13 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <dc:creator>Althaf P V, Amit Chattopadhyay, Osamu Saeki</dc:creator>
    </item>
    <item>
      <title>Data-Driven Trajectory Imputation for Vessel Mobility Analysis</title>
      <link>https://arxiv.org/abs/2602.11890</link>
      <description>arXiv:2602.11890v1 Announce Type: cross 
Abstract: Modeling vessel activity at sea is critical for a wide range of applications, including route planning, transportation logistics, maritime safety, and environmental monitoring. Over the past two decades, the Automatic Identification System (AIS) has enabled real-time monitoring of hundreds of thousands of vessels, generating huge amounts of data daily. One major challenge in using AIS data is the presence of large gaps in vessel trajectories, often caused by coverage limitations or intentional transmission interruptions. These gaps can significantly degrade data quality, resulting in inaccurate or incomplete analysis. State-of-the-art imputation approaches have mainly been devised to tackle gaps in vehicle trajectories, even when the underlying road network is not considered. But the motion patterns of sailing vessels differ substantially, e.g., smooth turns, maneuvering near ports, or navigating in adverse weather conditions. In this application paper, we propose HABIT, a lightweight, configurable H3 Aggregation-Based Imputation framework for vessel Trajectories. This data-driven framework provides a valuable means to impute missing trajectory segments by extracting, analyzing, and indexing motion patterns from historical AIS data. Our empirical study over AIS data across various timeframes, densities, and vessel types reveals that HABIT produces maritime trajectory imputations performing comparably to baseline methods in terms of accuracy, while performing better in terms of latency while accounting for vessel characteristics and their motion patterns.</description>
      <guid isPermaLink="false">oai:arXiv.org:2602.11890v1</guid>
      <category>cs.DB</category>
      <category>cs.CG</category>
      <category>cs.RO</category>
      <category>eess.IV</category>
      <pubDate>Fri, 13 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Giannis Spiliopoulos, Alexandros Troupiotis-Kapeliaris, Kostas Patroumpas, Nikolaos Liapis, Dimitrios Skoutas, Dimitris Zissis, Nikos Bikakis</dc:creator>
    </item>
    <item>
      <title>Optimal Parallel Algorithms for Convex Hulls in 2D and 3D under Noisy Primitive Operations</title>
      <link>https://arxiv.org/abs/2506.17507</link>
      <description>arXiv:2506.17507v2 Announce Type: replace 
Abstract: In the noisy primitives model, each primitive comparison performed by an algorithm, e.g., testing whether one value is greater than another, returns the incorrect answer with random, independent probability p &lt; 1/2 and otherwise returns a correct answer. This model was first applied in the context of sorting and searching, and recent work by Eppstein, Goodrich, and Sridhar extends this model to sequential algorithms involving geometric primitives such as orientation and sidedness tests. However, their approaches appear to be inherently sequential; hence, in this paper, we study parallel computational geometry algorithms for 2D and 3D convex hulls in the noisy primitives model. We give the first optimal parallel algorithms in the noisy primitives model for 2D and 3D convex hulls in the CREW PRAM model. The main technical contribution of our work concerns our ability to detect and fix errors during intermediate steps of our algorithm using a generalization of the failure sweeping technique.</description>
      <guid isPermaLink="false">oai:arXiv.org:2506.17507v2</guid>
      <category>cs.CG</category>
      <category>cs.DC</category>
      <pubDate>Fri, 13 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <arxiv:journal_reference>In Proceedings of the 37th Canadian Conference on Computational Geometry, pages 36-52, 2025</arxiv:journal_reference>
      <dc:creator>Michael T. Goodrich, Vinesh Sridhar</dc:creator>
    </item>
    <item>
      <title>Breaking the Curse of Dimensionality: On the Stability of Modern Vector Retrieval</title>
      <link>https://arxiv.org/abs/2512.12458</link>
      <description>arXiv:2512.12458v2 Announce Type: replace-cross 
Abstract: Modern vector databases enable efficient retrieval over high-dimensional neural embeddings, powering applications from web search to retrieval-augmented generation. However, classical theory predicts such tasks should suffer from the curse of dimensionality, where distances between points become nearly indistinguishable, thereby crippling efficient nearest-neighbor search. We revisit this paradox through the lens of stability, the property that small perturbations to a query do not radically alter its nearest neighbors. Building on foundational results, we extend stability theory to three key retrieval settings widely used in practice: (i) multi-vector search, where we prove that the popular Chamfer distance metric preserves single-vector stability, while average pooling aggregation may destroy it; (ii) filtered vector search, where we show that sufficiently large penalties for mismatched filters can induce stability even when the underlying search is unstable; and (iii) sparse vector search, where we formalize and prove novel sufficient stability conditions. Across synthetic and real datasets, our experimental results match our theoretical predictions, offering concrete guidance for model and system design to avoid the curse of dimensionality.</description>
      <guid isPermaLink="false">oai:arXiv.org:2512.12458v2</guid>
      <category>cs.IR</category>
      <category>cs.CG</category>
      <category>cs.DB</category>
      <category>cs.LG</category>
      <pubDate>Fri, 13 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Vihan Lakshman, Blaise Munyampirwa, Julian Shun, Benjamin Coleman</dc:creator>
    </item>
  </channel>
</rss>
