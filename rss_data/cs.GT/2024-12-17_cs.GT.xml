<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>cs.GT updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/cs.GT</link>
    <description>cs.GT updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/cs.GT" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Tue, 17 Dec 2024 05:00:29 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Tue, 17 Dec 2024 00:00:00 -0500</pubDate>
    <skipDays>
      <day>Sunday</day>
      <day>Saturday</day>
    </skipDays>
    <item>
      <title>Hiring Strategies</title>
      <link>https://arxiv.org/abs/2412.10490</link>
      <description>arXiv:2412.10490v1 Announce Type: new 
Abstract: We investigate the hiring problem where a sequence of applicants is sequentially interviewed, and a decision on whether to hire an applicant is immediately made based on the applicant's score. For the maximal and average improvement strategies, the decision depends on the applicant's score and the scores of all employees, i.e., previous successful applicants. For local improvement strategies, an interviewing committee randomly chosen for each applicant makes the decision depending on the score of the applicant and the scores of the members of the committee. These idealized hiring strategies capture the challenges of decision-making under uncertainty. We probe the average score of the best employee, the probability of hiring all first $N$ applicants, the fraction of superior companies in which, throughout the evolution, every hired applicant has a score above expected, etc.</description>
      <guid isPermaLink="false">oai:arXiv.org:2412.10490v1</guid>
      <category>cs.GT</category>
      <category>math.CO</category>
      <category>math.PR</category>
      <category>physics.soc-ph</category>
      <pubDate>Tue, 17 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>P. L. Krapivsky</dc:creator>
    </item>
    <item>
      <title>Deviate or Not: Learning Coalition Structures with Multiple-bit Observations in Games</title>
      <link>https://arxiv.org/abs/2412.10636</link>
      <description>arXiv:2412.10636v1 Announce Type: new 
Abstract: We consider the Coalition Structure Learning (CSL) problem in multi-agent systems, motivated by the existence of coalitions in many real-world systems, e.g., trading platforms and auction systems. In this problem, there is a hidden coalition structure within a set of $n$ agents, which affects the behavior of the agents in games. Our goal is to actively design a sequence of games for the agents to play, such that observations in these games can be used to learn the hidden coalition structure. In particular, we consider the setting where in each round, we design and present a game together with a strategy profile to the agents, and receive a multiple-bit observation -- for each agent, we observe whether or not they would like to deviate from the specified strategy. We show that we can learn the coalition structure in $O(\log n)$ rounds if we are allowed to design any normal-form game, matching the information-theoretical lower bound. For practicality, we extend the result to settings where we can only choose games of a specific format, and design algorithms to learn the coalition structure in these settings. For most settings, our complexity matches the theoretical lower bound up to a constant factor.</description>
      <guid isPermaLink="false">oai:arXiv.org:2412.10636v1</guid>
      <category>cs.GT</category>
      <pubDate>Tue, 17 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Yixuan Even Xu, Zhe Feng, Fei Fang</dc:creator>
    </item>
    <item>
      <title>Bi-Criteria Metric Distortion</title>
      <link>https://arxiv.org/abs/2412.10671</link>
      <description>arXiv:2412.10671v1 Announce Type: new 
Abstract: Selecting representatives based on voters' preferences is a fundamental problem in social choice theory. While cardinal utility functions offer a detailed representation of preferences, ordinal rankings are often the only available information due to their simplicity and practical constraints. The metric distortion framework addresses this issue by modeling voters and candidates as points in a metric space, with distortion quantifying the efficiency loss from relying solely on ordinal rankings. Existing works define the cost of a voter with respect to a candidate as their distance and set the overall cost as either the sum (utilitarian) or maximum (egalitarian) of these costs across all voters. They show that deterministic algorithms achieve a best-possible distortion of 3 for any metric when considering a single candidate.
  This paper explores whether one can obtain a better approximation compared to an optimal candidate by relying on a committee of $k$ candidates ($k \ge 1$), where the cost of a voter is defined as its distance to the closest candidate in the committee. We answer this affirmatively in the case of line metrics, demonstrating that with $O(1)$ candidates, it is possible to achieve optimal cost. Our results extend to both utilitarian and egalitarian objectives, providing new upper bounds for the problem. We complement our results with lower bounds for both the line and 2-D Euclidean metrics.</description>
      <guid isPermaLink="false">oai:arXiv.org:2412.10671v1</guid>
      <category>cs.GT</category>
      <category>cs.DS</category>
      <pubDate>Tue, 17 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Kiarash Banihashem, Diptarka Chakraborty, Shayan Chashm Jahan, Iman Gholami, MohammadTaghi Hajiaghayi, Mohammad Mahdavi, Max Springer</dc:creator>
    </item>
    <item>
      <title>Improving Community-Participated Patrol for Anti-Poaching</title>
      <link>https://arxiv.org/abs/2412.10799</link>
      <description>arXiv:2412.10799v1 Announce Type: new 
Abstract: Community engagement plays a critical role in anti-poaching efforts, yet existing mathematical models aimed at enhancing this engagement often overlook direct participation by community members as alternative patrollers. Unlike professional rangers, community members typically lack flexibility and experience, resulting in new challenges in optimizing patrol resource allocation. To address this gap, we propose a novel game-theoretic model for community-participated patrol, where a conservation agency strategically deploys both professional rangers and community members to safeguard wildlife against a best-responding poacher. In addition to a mixed-integer linear program formulation, we introduce a Two-Dimensional Binary Search algorithm and a novel Hybrid Waterfilling algorithm to efficiently solve the game in polynomial time. Through extensive experiments and a detailed case study focused on a protected tiger habitat in Northeast China, we demonstrate the effectiveness of our algorithms and the practical applicability of our model.</description>
      <guid isPermaLink="false">oai:arXiv.org:2412.10799v1</guid>
      <category>cs.GT</category>
      <pubDate>Tue, 17 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Yufei Wu, Yixuan Even Xu, Xuming Zhang, Duo Liu, Shibing Zhu, Fei Fang</dc:creator>
    </item>
    <item>
      <title>Distributed Facility Location Games with Candidate Locations</title>
      <link>https://arxiv.org/abs/2412.11049</link>
      <description>arXiv:2412.11049v1 Announce Type: new 
Abstract: We study the distributed facility location games with candidate locations, where agents on a line are partitioned into groups. Both desirable and obnoxious facility location settings are discussed. In distributed location problems, distortion can serve as a standard for quantifying performance, measuring the degree of difference between the actual location plan and the ideal location plan. For the desirable setting, under the max of sum cost objective, we give a strategyproof distributed mechanism with $5$-distortion, and prove that no strategyproof mechanism can have a distortion better than $\sqrt{2}+1$. Under the sum of max cost objective, we give a strategyproof distributed mechanism with $5$-distortion, and prove that no strategyproof mechanism can have a distortion better than $\frac{\sqrt{5}+1}{2}$. Under the max of max cost, we get a strategyproof distributed mechanism with $3$-distortion, and prove that no strategyproof mechanism can have a distortion better than $\frac{\sqrt{5}+1}{2}$. For the obnoxious setting, under three social objectives, we present that there is no strategyproof mechanism with bounded distortion in the case of discrete candidate locations, and no group strategyproof mechanism with bounded distortion in the case of continuous candidate locations.</description>
      <guid isPermaLink="false">oai:arXiv.org:2412.11049v1</guid>
      <category>cs.GT</category>
      <category>math.OC</category>
      <pubDate>Tue, 17 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Feiyue Sun</dc:creator>
    </item>
    <item>
      <title>Optimal Strategy-proof Mechanisms on Single-crossing Domains</title>
      <link>https://arxiv.org/abs/2412.11113</link>
      <description>arXiv:2412.11113v1 Announce Type: new 
Abstract: We consider an economic environment with one buyer and one seller. For a bundle $(t,q)\in [0,\infty[\times [0,1]=\mathbb{Z}$, $q$ refers to the winning probability of an object, and $t$ denotes the payment that the buyer makes. We consider continuous and monotone preferences on $\mathbb{Z}$ as the primitives of the buyer. These preferences can incorporate both quasilinear and non-quasilinear preferences, and multidimensional pay-off relevant parameters. We define rich single-crossing subsets of this class and characterize strategy-proof mechanisms by using monotonicity of the mechanisms and continuity of the indirect preference correspondences. We also provide a computationally tractable optimization program to compute the optimal mechanism for mechanisms with finite range. We do not use revenue equivalence and virtual valuations as tools in our proofs. Our proof techniques bring out the geometric interaction between the single-crossing property and the positions of bundles $(t,q)$s in the space $\mathbb{Z}$. We also provide an extension of our analysis to an $n-$buyer environment, and to the situation where $q$ is a qualitative variable.</description>
      <guid isPermaLink="false">oai:arXiv.org:2412.11113v1</guid>
      <category>cs.GT</category>
      <category>econ.TH</category>
      <pubDate>Tue, 17 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Mridu Prabal Goswami</dc:creator>
    </item>
    <item>
      <title>Neural Double Auction Mechanism</title>
      <link>https://arxiv.org/abs/2412.11465</link>
      <description>arXiv:2412.11465v1 Announce Type: new 
Abstract: Mechanism design, a branch of economics, aims to design rules that can autonomously achieve desired outcomes in resource allocation and public decision making. The research on mechanism design using machine learning is called automated mechanism design or mechanism learning. In our research, we constructed a new network based on the existing method for single auctions and aimed to automatically design a mechanism by applying it to double auctions. In particular, we focused on the following four desirable properties for the mechanism: individual rationality, balanced budget, Pareto efficiency, and incentive compatibility. We conducted experiments assuming a small-scale double auction and clarified how deterministic the trade matching of the obtained mechanism is. We also confirmed how much the learnt mechanism satisfies the four properties compared to two representative protocols. As a result, we verified that the mechanism is more budget-balanced than the VCG protocol and more economically efficient than the MD protocol, with the incentive compatibility mostly guaranteed.</description>
      <guid isPermaLink="false">oai:arXiv.org:2412.11465v1</guid>
      <category>cs.GT</category>
      <pubDate>Tue, 17 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Tsuyoshi Suehara, Koh Takeuchi, Hisashi Kashima, Satoshi Oyama, Yuko Sakurai, Makoto Yokoo</dc:creator>
    </item>
    <item>
      <title>Metric Distortion of Obnoxious Distributed Voting</title>
      <link>https://arxiv.org/abs/2412.11492</link>
      <description>arXiv:2412.11492v1 Announce Type: new 
Abstract: We consider a distributed voting problem with a set of agents that are partitioned into disjoint groups and a set of obnoxious alternatives. Agents and alternatives are represented by points in a metric space. The goal is to compute the alternative that maximizes the total distance from all agents using a two-step mechanism which, given some information about the distances between agents and alternatives, first chooses a representative alternative for each group of agents, and then declares one of them as the overall winner. Due to the restricted nature of the mechanism and the potentially limited information it has to make its decision, it might not be always possible to choose the optimal alternative. We show tight bounds on the distortion of different mechanisms depending on the amount of the information they have access to; in particular, we study full-information and ordinal mechanisms.</description>
      <guid isPermaLink="false">oai:arXiv.org:2412.11492v1</guid>
      <category>cs.GT</category>
      <pubDate>Tue, 17 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Alexandros A. Voudouris</dc:creator>
    </item>
    <item>
      <title>Contextual Generative Auction with Permutation-level Externalities for Online Advertising</title>
      <link>https://arxiv.org/abs/2412.11544</link>
      <description>arXiv:2412.11544v1 Announce Type: new 
Abstract: Online advertising has become a core revenue driver for the internet industry, with ad auctions playing a crucial role in ensuring platform revenue and advertiser incentives. Traditional auction mechanisms, like GSP, rely on the independent CTR assumption and fail to account for the influence of other displayed items, termed externalities. Recent advancements in learning-based auctions have enhanced the encoding of high-dimensional contextual features. However, existing methods are constrained by the "allocation-after-prediction" design paradigm, which models set-level externalities within candidate ads and fails to consider the sequential context of the final allocation, leading to suboptimal results. This paper introduces the Contextual Generative Auction (CGA), a novel framework that incorporates permutation-level externalities in multi-slot ad auctions. Built on the structure of our theoretically derived optimal solution, CGA decouples the optimization of allocation and payment. We construct an autoregressive generative model for allocation and reformulate the incentive compatibility (IC) constraint into minimizing ex-post regret that supports gradient computation, enabling end-to-end learning of the optimal payment rule. Extensive offline and online experiments demonstrate that CGA significantly enhances platform revenue and CTR compared to existing methods, while effectively approximating the optimal auction with nearly maximal revenue and minimal regret.</description>
      <guid isPermaLink="false">oai:arXiv.org:2412.11544v1</guid>
      <category>cs.GT</category>
      <pubDate>Tue, 17 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Ruitao Zhu, Yangsu Liu, Dagui Chen, Zhenjia Ma, Chufeng Shi, Zhenzhe Zheng, Jie Zhang, Jian Xu, Bo Zheng, Fan Wu</dc:creator>
    </item>
    <item>
      <title>Weak Strategyproofness in Randomized Social Choice</title>
      <link>https://arxiv.org/abs/2412.11977</link>
      <description>arXiv:2412.11977v1 Announce Type: new 
Abstract: An important -- but very demanding -- property in collective decision-making is strategyproofness, which requires that voters cannot benefit from submitting insincere preferences. Gibbard (1977) has shown that only rather unattractive rules are strategyproof, even when allowing for randomization. However, Gibbard's theorem is based on a rather strong interpretation of strategyproofness, which deems a manipulation successful if it increases the voter's expected utility for at least one utility function consistent with his ordinal preferences. In this paper, we study weak strategyproofness, which deems a manipulation successful if it increases the voter's expected utility for all utility functions consistent with his ordinal preferences. We show how to systematically design attractive, weakly strategyproof social decision schemes (SDSs) and explore their limitations for both strict and weak preferences. In particular, for strict preferences, we show that there are weakly strategyproof SDSs that are either ex post efficient or Condorcet-consistent, while neither even-chance SDSs nor pairwise SDSs satisfy both properties and weak strategyproofness at the same time. By contrast, for the case of weak preferences, we discuss two sweeping impossibility results that preclude the existence of appealing weakly strategyproof SDSs.</description>
      <guid isPermaLink="false">oai:arXiv.org:2412.11977v1</guid>
      <category>cs.GT</category>
      <category>econ.TH</category>
      <pubDate>Tue, 17 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Felix Brandt, Patrick Lederer</dc:creator>
    </item>
    <item>
      <title>Recommendation and Temptation</title>
      <link>https://arxiv.org/abs/2412.10595</link>
      <description>arXiv:2412.10595v1 Announce Type: cross 
Abstract: Traditional recommender systems based on utility maximization and revealed preferences often fail to capture users' dual-self nature, where consumption choices are driven by both long-term benefits (enrichment) and desire for instant gratification (temptation). Consequently, these systems may generate recommendations that fail to provide long-lasting satisfaction to users. To address this issue, we propose a novel user model that accounts for this dual-self behavior and develop an optimal recommendation strategy to maximize enrichment from consumption. We highlight the limitations of historical consumption data in implementing this strategy and present an estimation framework that makes minimal assumptions and leverages explicit user feedback and implicit choice data to overcome these constraints. We evaluate our approach through both synthetic simulations and simulations based on real-world data from the MovieLens dataset. Results demonstrate that our proposed recommender can deliver superior enrichment compared to several competitive baseline algorithms that assume a single utility type and rely solely on revealed preferences. Our work emphasizes the critical importance of optimizing for enrichment in recommender systems, particularly in temptation-laden consumption contexts. Our findings have significant implications for content platforms, user experience design, and the development of responsible AI systems, paving the way for more nuanced and user-centric recommendation approaches.</description>
      <guid isPermaLink="false">oai:arXiv.org:2412.10595v1</guid>
      <category>cs.IR</category>
      <category>cs.CY</category>
      <category>cs.GT</category>
      <pubDate>Tue, 17 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Md Sanzeed Anwar, Paramveer S. Dhillon, Grant Schoenebeck</dc:creator>
    </item>
    <item>
      <title>p-Mean Regret for Stochastic Bandits</title>
      <link>https://arxiv.org/abs/2412.10751</link>
      <description>arXiv:2412.10751v1 Announce Type: cross 
Abstract: In this work, we extend the concept of the $p$-mean welfare objective from social choice theory (Moulin 2004) to study $p$-mean regret in stochastic multi-armed bandit problems. The $p$-mean regret, defined as the difference between the optimal mean among the arms and the $p$-mean of the expected rewards, offers a flexible framework for evaluating bandit algorithms, enabling algorithm designers to balance fairness and efficiency by adjusting the parameter $p$. Our framework encompasses both average cumulative regret and Nash regret as special cases.
  We introduce a simple, unified UCB-based algorithm (Explore-Then-UCB) that achieves novel $p$-mean regret bounds. Our algorithm consists of two phases: a carefully calibrated uniform exploration phase to initialize sample means, followed by the UCB1 algorithm of Auer, Cesa-Bianchi, and Fischer (2002). Under mild assumptions, we prove that our algorithm achieves a $p$-mean regret bound of $\tilde{O}\left(\sqrt{\frac{k}{T^{\frac{1}{2|p|}}}}\right)$ for all $p \leq -1$, where $k$ represents the number of arms and $T$ the time horizon. When $-1&lt;p&lt;0$, we achieve a regret bound of $\tilde{O}\left(\sqrt{\frac{k^{1.5}}{T^{\frac{1}{2}}}}\right)$. For the range $0&lt; p \leq 1$, we achieve a $p$-mean regret scaling as $\tilde{O}\left(\sqrt{\frac{k}{T}}\right)$, which matches the previously established lower bound up to logarithmic factors (Auer et al. 1995). This result stems from the fact that the $p$-mean regret of any algorithm is at least its average cumulative regret for $p \leq 1$.
  In the case of Nash regret (the limit as $p$ approaches zero), our unified approach differs from prior work (Barman et al. 2023), which requires a new Nash Confidence Bound algorithm. Notably, we achieve the same regret bound up to constant factors using our more general method.</description>
      <guid isPermaLink="false">oai:arXiv.org:2412.10751v1</guid>
      <category>cs.LG</category>
      <category>cs.GT</category>
      <pubDate>Tue, 17 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Anand Krishna, Philips George John, Adarsh Barik, Vincent Y. F. Tan</dc:creator>
    </item>
    <item>
      <title>Paid with Models: Optimal Contract Design for Collaborative Machine Learning</title>
      <link>https://arxiv.org/abs/2412.11122</link>
      <description>arXiv:2412.11122v1 Announce Type: cross 
Abstract: Collaborative machine learning (CML) provides a promising paradigm for democratizing advanced technologies by enabling cost-sharing among participants. However, the potential for rent-seeking behaviors among parties can undermine such collaborations. Contract theory presents a viable solution by rewarding participants with models of varying accuracy based on their contributions. However, unlike monetary compensation, using models as rewards introduces unique challenges, particularly due to the stochastic nature of these rewards when contribution costs are privately held information. This paper formalizes the optimal contracting problem within CML and proposes a transformation that simplifies the non-convex optimization problem into one that can be solved through convex optimization algorithms. We conduct a detailed analysis of the properties that an optimal contract must satisfy when models serve as the rewards, and we explore the potential benefits and welfare implications of these contract-driven CML schemes through numerical experiments.</description>
      <guid isPermaLink="false">oai:arXiv.org:2412.11122v1</guid>
      <category>cs.LG</category>
      <category>cs.AI</category>
      <category>cs.GT</category>
      <category>econ.TH</category>
      <pubDate>Tue, 17 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Bingchen Wang, Zhaoxuan Wu, Fusheng Liu, Bryan Kian Hsiang Low</dc:creator>
    </item>
    <item>
      <title>GAP: Game Theory-Based Approach for Reliability and Power Management in Emerging Fog Computing</title>
      <link>https://arxiv.org/abs/2412.11310</link>
      <description>arXiv:2412.11310v1 Announce Type: cross 
Abstract: Fog computing brings about a transformative shift in data management, presenting unprecedented opportunities for enhanced performance and reduced latency. However, one of the key aspects of fog computing revolves around ensuring efficient power and reliability management. To address this challenge, we have introduced a novel model that proposes a non-cooperative game theory-based strategy to strike a balance between power consumption and reliability in decision-making processes. Our proposed model capitalizes on the Cold Primary/Backup strategy (CPB) to guarantee reliability target by re-executing tasks to different nodes when a fault occurs, while also leveraging Dynamic Voltage and Frequency Scaling (DVFS) to reduce power consumption during task execution and maximizing overall efficiency. Non-cooperative game theory plays a pivotal role in our model, as it facilitates the development of strategies and solutions that uphold reliability while reducing power consumption. By treating the trade-off between power and reliability as a non-cooperative game, our proposed method yields significant energy savings, with up to a 35% reduction in energy consumption, 41% decrease in wait time, and 31% shorter completion time compared to state-of-the-art approaches. Our findings underscore the value of game theory in optimizing power and reliability within fog computing environments, demonstrating its potential for driving substantial improvements</description>
      <guid isPermaLink="false">oai:arXiv.org:2412.11310v1</guid>
      <category>cs.DC</category>
      <category>cs.ET</category>
      <category>cs.GT</category>
      <pubDate>Tue, 17 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Abolfazl Younesi, Mohsen Ansari, Alireza Ejlali, Mohammad Amin Fazli, Muhammad Shafique, J\"org Henkel</dc:creator>
    </item>
    <item>
      <title>Adaptive Manipulation for Coalitions in Knockout Tournaments</title>
      <link>https://arxiv.org/abs/2412.11799</link>
      <description>arXiv:2412.11799v1 Announce Type: cross 
Abstract: Knockout tournaments, also known as single-elimination or cup tournaments, are a popular form of sports competitions. In the standard probabilistic setting, for each pairing of players, one of the players wins the game with a certain (a priori known) probability. Due to their competitive nature, tournaments are prone to manipulation. We investigate the computational problem of determining whether, for a given tournament, a coalition has a manipulation strategy that increases the winning probability of a designated player above a given threshold. More precisely, in every round of the tournament, coalition players can strategically decide which games to throw based on the advancement of other players to the current round. We call this setting adaptive constructive coalition manipulation. To the best of our knowledge, while coalition manipulation has been studied in the literature, this is the first work to introduce adaptiveness to this context.
  We show that the above problem is hard for every complexity class in the polynomial hierarchy. On the algorithmic side, we show that the problem is solvable in polynomial time when the coalition size is a constant. Furthermore, we show that the problem is fixed-parameter tractable when parameterized by the coalition size and the size of a minimum player set that must include at least one player from each non-deterministic game. Lastly, we investigate a generalized setting where the tournament tree can be imbalanced.</description>
      <guid isPermaLink="false">oai:arXiv.org:2412.11799v1</guid>
      <category>cs.DS</category>
      <category>cs.GT</category>
      <category>cs.MA</category>
      <pubDate>Tue, 17 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Juhi Chaudhary, Hendrik Molter, Meirav Zehavi</dc:creator>
    </item>
    <item>
      <title>Quantifying Inefficiency</title>
      <link>https://arxiv.org/abs/2412.11984</link>
      <description>arXiv:2412.11984v1 Announce Type: cross 
Abstract: We axiomatically define a cardinal social inefficiency function, which, given a set of alternatives and individuals' vNM preferences over the alternatives, assigns a unique number -- the social inefficiency -- to each alternative. These numbers -- and not only their order -- are uniquely defined by our axioms despite no exogenously given interpersonal comparison, outside option, or disagreement point. We interpret these numbers as per capita losses in endogenously normalized utility. We apply our social inefficiency function to a setting in which interpersonal comparison is notoriously hard to justify -- object allocation without money -- leveraging techniques from computer science to prove an approximate-efficiency result for the Random Serial Dictatorship mechanism.</description>
      <guid isPermaLink="false">oai:arXiv.org:2412.11984v1</guid>
      <category>econ.TH</category>
      <category>cs.GT</category>
      <pubDate>Tue, 17 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Yannai A. Gonczarowski, Ella Segev</dc:creator>
    </item>
    <item>
      <title>Algorithmic Collusion Without Threats</title>
      <link>https://arxiv.org/abs/2409.03956</link>
      <description>arXiv:2409.03956v2 Announce Type: replace 
Abstract: There has been substantial recent concern that pricing algorithms might learn to ``collude.'' Supra-competitive prices can emerge as a Nash equilibrium of repeated pricing games, in which sellers play strategies which threaten to punish their competitors who refuse to support high prices, and these strategies can be automatically learned. In fact, a standard economic intuition is that supra-competitive prices emerge from either the use of threats, or a failure of one party to optimize their payoff. Is this intuition correct? Would preventing threats in algorithmic decision-making prevent supra-competitive prices when sellers are optimizing for their own revenue? No. We show that supra-competitive prices can emerge even when both players are using algorithms which do not encode threats, and which optimize for their own revenue. We study sequential pricing games in which a first mover deploys an algorithm and then a second mover optimizes within the resulting environment. We show that if the first mover deploys any algorithm with a no-regret guarantee, and then the second mover even approximately optimizes within this now static environment, monopoly-like prices arise. The result holds for any no-regret learning algorithm deployed by the first mover and for any pricing policy of the second mover that obtains them profit at least as high as a random pricing would -- and hence the result applies even when the second mover is optimizing only within a space of non-responsive pricing distributions which are incapable of encoding threats. In fact, there exists a set of strategies, neither of which explicitly encode threats that form a Nash equilibrium of the simultaneous pricing game in algorithm space, and lead to near monopoly prices. This suggests that the definition of ``algorithmic collusion'' may need to be expanded, to include strategies without explicitly encoded threats.</description>
      <guid isPermaLink="false">oai:arXiv.org:2409.03956v2</guid>
      <category>cs.GT</category>
      <category>cs.LG</category>
      <category>econ.TH</category>
      <pubDate>Tue, 17 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Eshwar Ram Arunachaleswaran, Natalie Collina, Sampath Kannan, Aaron Roth, Juba Ziani</dc:creator>
    </item>
    <item>
      <title>Steering Language Models with Game-Theoretic Solvers</title>
      <link>https://arxiv.org/abs/2402.01704</link>
      <description>arXiv:2402.01704v3 Announce Type: replace-cross 
Abstract: Mathematical models of interactions among rational agents have long been studied in game theory. However these interactions are often over a small set of discrete game actions which is very different from how humans communicate in natural language. To bridge this gap, we introduce a framework that allows equilibrium solvers to work over the space of natural language dialogue generated by large language models (LLMs). Specifically, by modelling the players, strategies and payoffs in a "game" of dialogue, we create a binding from natural language interactions to the conventional symbolic logic of game theory. Given this binding, we can ask existing game-theoretic algorithms to provide us with strategic solutions (e.g., what string an LLM should generate to maximize payoff in the face of strategic partners or opponents), giving us predictors of stable, rational conversational strategies. We focus on three domains that require different negotiation strategies: scheduling meetings, trading fruit and debate, and evaluate an LLM's generated language when guided by solvers. We see that LLMs that follow game-theory solvers result in dialogue generations that are less exploitable than the control (no guidance from solvers), and the language generated results in higher rewards, in all negotiation domains. We discuss future implications of this work, and how game-theoretic solvers that can leverage the expressivity of natural language can open up a new avenue of guiding language research.</description>
      <guid isPermaLink="false">oai:arXiv.org:2402.01704v3</guid>
      <category>cs.CL</category>
      <category>cs.AI</category>
      <category>cs.GT</category>
      <pubDate>Tue, 17 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Ian Gemp, Roma Patel, Yoram Bachrach, Marc Lanctot, Vibhavari Dasagi, Luke Marris, Georgios Piliouras, Siqi Liu, Karl Tuyls</dc:creator>
    </item>
    <item>
      <title>Luce contracts</title>
      <link>https://arxiv.org/abs/2402.15890</link>
      <description>arXiv:2402.15890v2 Announce Type: replace-cross 
Abstract: We study a multi-agent contract design problem with moral hazard. In our model, each agent exerts costly effort towards an individual task at which it may either succeed or fail, and the principal, who wishes to encourage effort, has an exclusive-use budget that it can use to reward the agents. We first show that any optimal contract must distribute the entire budget among the successful agents. Moreover, every such contract is optimal for some objective function. Our main contribution is then to introduce a novel class of contracts, which we call Luce contracts, and show that there is always a Luce contract that is optimal. A (generic) Luce contract assigns weights to the agents and distributes the entire budget among the successful agents in proportion to their weights. Lastly, we characterize effort profiles that can be implemented by Luce contracts, and note that Luce contracts offer a desirable alternative for implementation over commonly studied contracts, like piece-rate and bonus-pool contracts, on account of their reward variance-minimizing property.</description>
      <guid isPermaLink="false">oai:arXiv.org:2402.15890v2</guid>
      <category>econ.TH</category>
      <category>cs.GT</category>
      <pubDate>Tue, 17 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Sumit Goel, Wade Hann-Caruthers</dc:creator>
    </item>
    <item>
      <title>Learning to be Indifferent in Complex Decisions: A Coarse Payoff-Assessment Model</title>
      <link>https://arxiv.org/abs/2412.09321</link>
      <description>arXiv:2412.09321v2 Announce Type: replace-cross 
Abstract: We introduce the Coarse Payoff-Assessment Learning (CPAL) model, which captures reinforcement learning by boundedly rational decision-makers who focus on the aggregate outcomes of choosing among exogenously defined clusters of alternatives (similarity classes), rather than evaluating each alternative individually. Analyzing a smooth approximation of the model, we show that the learning dynamics exhibit steady-states corresponding to smooth Valuation Equilibria (Jehiel and Samet, 2007). We demonstrate the existence of multiple equilibria in decision trees with generic payoffs and establish the local asymptotic stability of pure equilibria when they occur. Conversely, when trivial choices featuring alternatives within the same similarity class yield sufficiently high payoffs, a unique mixed equilibrium emerges, characterized by indifferences between similarity classes, even under acute sensitivity to payoff differences. Finally, we prove that this unique mixed equilibrium is globally asymptotically stable under the CPAL dynamics.</description>
      <guid isPermaLink="false">oai:arXiv.org:2412.09321v2</guid>
      <category>econ.TH</category>
      <category>cs.GT</category>
      <pubDate>Tue, 17 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Philippe Jehiel, Aviman Satpathy</dc:creator>
    </item>
  </channel>
</rss>
