<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>physics.data-an updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/physics.data-an</link>
    <description>physics.data-an updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/physics.data-an" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Tue, 22 Jul 2025 04:02:31 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Tue, 22 Jul 2025 00:00:00 -0400</pubDate>
    <skipDays>
      <day>Saturday</day>
      <day>Sunday</day>
    </skipDays>
    <item>
      <title>Eigenvalue Distribution of Empirical Correlation Matrices for Multiscale Complex Systems and Application to Financial Data</title>
      <link>https://arxiv.org/abs/2507.14325</link>
      <description>arXiv:2507.14325v1 Announce Type: cross 
Abstract: We introduce a method for describing eigenvalue distributions of correlation matrices from multidimensional time series. Using our newly developed matrix H theory, we improve the description of eigenvalue spectra for empirical correlation matrices in multivariate financial data by considering an informational cascade modeled as a hierarchical structure akin to the Kolmogorov statistical theory of turbulence. Our approach extends the Marchenko-Pastur distribution to account for distinct characteristic scales, capturing a larger fraction of data variance, and challenging the traditional view of noise-dressed financial markets. We conjecture that the effectiveness of our method stems from the increased complexity in financial markets, reflected by new characteristic scales and the growth of computational trading. These findings not only support the turbulent market hypothesis as a source of noise but also provide a practical framework for noise reduction in empirical correlation matrices, enhancing the inference of true market correlations between assets.</description>
      <guid isPermaLink="false">oai:arXiv.org:2507.14325v1</guid>
      <category>q-fin.ST</category>
      <category>physics.data-an</category>
      <pubDate>Tue, 22 Jul 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Luan M. T. de Moraes, Ant\^onio M. S. Mac\^edo, Giovani L. Vasconcelos, Raydonal Ospina</dc:creator>
    </item>
    <item>
      <title>Accelerating Hamiltonian Monte Carlo for Bayesian Inference in Neural Networks and Neural Operators</title>
      <link>https://arxiv.org/abs/2507.14652</link>
      <description>arXiv:2507.14652v1 Announce Type: cross 
Abstract: Hamiltonian Monte Carlo (HMC) is a powerful and accurate method to sample from the posterior distribution in Bayesian inference. However, HMC techniques are computationally demanding for Bayesian neural networks due to the high dimensionality of the network's parameter space and the non-convexity of their posterior distributions. Therefore, various approximation techniques, such as variational inference (VI) or stochastic gradient MCMC, are often employed to infer the posterior distribution of the network parameters. Such approximations introduce inaccuracies in the inferred distributions, resulting in unreliable uncertainty estimates. In this work, we propose a hybrid approach that combines inexpensive VI and accurate HMC methods to efficiently and accurately quantify uncertainties in neural networks and neural operators. The proposed approach leverages an initial VI training on the full network. We examine the influence of individual parameters on the prediction uncertainty, which shows that a large proportion of the parameters do not contribute substantially to uncertainty in the network predictions. This information is then used to significantly reduce the dimension of the parameter space, and HMC is performed only for the subset of network parameters that strongly influence prediction uncertainties. This yields a framework for accelerating the full batch HMC for posterior inference in neural networks. We demonstrate the efficiency and accuracy of the proposed framework on deep neural networks and operator networks, showing that inference can be performed for large networks with tens to hundreds of thousands of parameters. We show that this method can effectively learn surrogates for complex physical systems by modeling the operator that maps from upstream conditions to wall-pressure data on a cone in hypersonic flow.</description>
      <guid isPermaLink="false">oai:arXiv.org:2507.14652v1</guid>
      <category>stat.ML</category>
      <category>cs.CE</category>
      <category>cs.LG</category>
      <category>physics.data-an</category>
      <pubDate>Tue, 22 Jul 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Ponkrshnan Thiagarajan, Tamer A. Zaki, Michael D. Shields</dc:creator>
    </item>
    <item>
      <title>Impact of Geant4's Electromagnetic Physics Constructors on Accuracy and Performance of Simulations for Rare Event Searches</title>
      <link>https://arxiv.org/abs/2507.14788</link>
      <description>arXiv:2507.14788v1 Announce Type: cross 
Abstract: A primary objective in contemporary low background physics is the search for rare and novel phenomena beyond the Standard Model of particle physics, e.g. the scattering off of a potential Dark Matter particle or the neutrinoless double beta decay. The success of such searches depends on a reliable background prediction via Monte Carlo simulations. A widely used toolkit to construct these simulations is Geant4, which offers the user a wide choice of how to model the physics of particle interactions. For example, for electromagnetic interactions, Geant4 provides pre-defined sets of models: physics constructors. As decay products of radioactive contaminants contribute to the background mainly via electromagnetic interactions, the physics constructor used in a Geant4 simulation may have an impact on the total energy deposition inside the detector target. To facilitate the selection of physics constructors for simulations of experiments that are using CaWO$_\mathrm{4}$ and Ge targets, we quantify their impact on the total energy deposition for several test cases. These cases consist of radioactive contaminants commonly encountered, covering energy depositions via $\alpha$, $\beta$, and $\gamma$ particles, as well as two examples for the target thickness: thin and bulky. We also consider the computing performance of the studied physics constructors.</description>
      <guid isPermaLink="false">oai:arXiv.org:2507.14788v1</guid>
      <category>astro-ph.IM</category>
      <category>physics.comp-ph</category>
      <category>physics.data-an</category>
      <pubDate>Tue, 22 Jul 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-sa/4.0/</dc:rights>
      <dc:creator>H. Kluck (Institut f\"ur Hochenergiephysik der \"Osterreichischen Akademie der Wissenschaften, Wien, Austria, Atominstitut, Technische Universit\"at Wien, Wien, Austria), R. Breier (Faculty of Mathematics, Physics and Informatics, Comenius University, Bratislava, Slovakia), A. Fu{\ss} (Institut f\"ur Hochenergiephysik der \"Osterreichischen Akademie der Wissenschaften, Wien, Austria, Atominstitut, Technische Universit\"at Wien, Wien, Austria), V. Mokina (Institut f\"ur Hochenergiephysik der \"Osterreichischen Akademie der Wissenschaften, Wien, Austria), V. Palu\v{s}ov\'a (Faculty of Mathematics, Physics and Informatics, Comenius University, Bratislava, Slovakia, Present address: Institut f\"ur Physik, Johannes Gutenberg-Universit\"at Mainz, Mainz, Germany), P. Povinec (Faculty of Mathematics, Physics and Informatics, Comenius University, Bratislava, Slovakia)</dc:creator>
    </item>
    <item>
      <title>Harnessing PyStoch potential: detecting continuous gravitational waves from interesting supernova remnant targets</title>
      <link>https://arxiv.org/abs/2507.15027</link>
      <description>arXiv:2507.15027v1 Announce Type: cross 
Abstract: Detecting continuous gravitational waves (CWs) is challenging due to their weak amplitude and high computational demands, especially with poorly constrained source parameters. Stochastic gravitational-wave background (SGWB) searches using cross-correlation techniques can identify unresolved astrophysical sources, including CWs, at lower computational cost, albeit with reduced sensitivity. This motivates a hybrid approach where SGWB algorithms act as a first-pass filter to identify CW candidates for follow-up with dedicated CW pipelines.
  We evaluated the discovery potential of the SGWB analysis tool PyStoch for detecting CWs, using simulated signals from spinning down NSs. We then applied the method to data from the third LIGO-Virgo-KAGRA observing run (O3), covering the (20-1726) Hz frequency band, and targeting four supernova remnants: Vela Jr., G347.3-0.5, Cassiopeia A, and the NS associated with the 1987A supernova remnant. If necessary, significant candidates are followed up using the 5-vector Resampling and Band-Sampled Data Frequency-Hough techniques. However, since no interesting candidates were identified in the real O3 analysis, we set 95\% confidence-level upper limits on the CW strain amplitude $h_0$. The most stringent limit was obtained for Cassiopeia A, and is $h_0 = 1.13 \times 10^{-25}$ at $201.57$ Hz with a frequency resolution of $1/32$ Hz. As for the other targets, the best upper limits have been set with the same frequency resolution, and correspond to $h_0 = 1.20 \times 10^{-25} $ at $202.16$ Hz for G347.3-0.5, $1.20 \times 10^{-25}$ at $217.81$ Hz for Vela Jr., and $1.47 \times 10^{-25}$ at $186.41$ Hz for the NS in the 1987A supernova remnant.</description>
      <guid isPermaLink="false">oai:arXiv.org:2507.15027v1</guid>
      <category>astro-ph.HE</category>
      <category>physics.data-an</category>
      <pubDate>Tue, 22 Jul 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Claudio Salvadore, Iuri La Rosa, Paola Leaci, Francesco Amicucci, Pia Astone, Sabrina D'Antonio, Luca D'Onofrio, Cristiano Palomba, Lorenzo Pierini, Francesco Safai Tehrani</dc:creator>
    </item>
    <item>
      <title>Change point detection in ERA5 ground temperature time series</title>
      <link>https://arxiv.org/abs/2507.15045</link>
      <description>arXiv:2507.15045v1 Announce Type: cross 
Abstract: We analyze the ERA5 reanalysis 2-meter temperature time series
  on all land
  grid points using change point analysis. We fit two linear
  slopes to the data with the constraint that they merge at the point in time
  where the slope changes. We compare such fits to a standard
  linear regression in two ways: We use Akaike's and the
  Bayesian
  information
  criteria for model selection, and we test against the null hypothesis of
  no change of the trend value. For those grid points where the
  dual linear fit is superior, we construct maps of the time when the trend
  changes, and of the warming trends in both time intervals. In doing so, we
  indentify areas where warming speeds up, but find as well areas where
  warming slows down.
  We thereby contribute to the characterization of local effects of climate
  change. We find that many grid points exhibit a
  change to a much stronger warming trend around the 1980s. This raises
  the question of whether the climate system has already passed some
  tipping point.</description>
      <guid isPermaLink="false">oai:arXiv.org:2507.15045v1</guid>
      <category>stat.AP</category>
      <category>physics.data-an</category>
      <pubDate>Tue, 22 Jul 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Fatemeh Aghaei A., Ewan T. Phillips, Holger Kantz</dc:creator>
    </item>
    <item>
      <title>High-Performance Data Format for Scientific Data Storage and Analysis</title>
      <link>https://arxiv.org/abs/2501.07666</link>
      <description>arXiv:2501.07666v3 Announce Type: replace 
Abstract: In this article, we present the High-Performance Output (HiPO) data format developed at Jefferson Laboratory for storing and analyzing data from Nuclear Physics experiments. The format was designed to efficiently store large amounts of experimental data, utilizing modern fast compression algorithms. The purpose of this development was to provide organized data in the output, facilitating access to relevant information within the large data files. The HiPO data format has features that are suited for storing raw detector data, reconstruction data, and the final physics analysis data efficiently, eliminating the need to do data conversions through the lifecycle of experimental data. The HiPO data format is implemented in C++ and JAVA, and provides bindings to FORTRAN, Python, and Julia, providing users with the choice of data analysis frameworks to use. In this paper, we will present the general design and functionalities of the HiPO library and compare the performance of the library with more established data formats used in data analysis in High Energy and Nuclear Physics (such as ROOT and Parquete).</description>
      <guid isPermaLink="false">oai:arXiv.org:2501.07666v3</guid>
      <category>physics.data-an</category>
      <pubDate>Tue, 22 Jul 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Gagik Gavalian</dc:creator>
    </item>
  </channel>
</rss>
