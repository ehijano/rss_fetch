<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>econ.EM updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/econ.EM</link>
    <description>econ.EM updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/econ.EM" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Mon, 17 Jun 2024 04:05:50 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Mon, 17 Jun 2024 00:00:00 -0400</pubDate>
    <skipDays>
      <day>Saturday</day>
      <day>Sunday</day>
    </skipDays>
    <item>
      <title>Multidimensional clustering in judge designs</title>
      <link>https://arxiv.org/abs/2406.09473</link>
      <description>arXiv:2406.09473v1 Announce Type: new 
Abstract: Estimates in judge designs run the risk of being biased due to the many judge identities that are implicitly or explicitly used as instrumental variables. The usual method to analyse judge designs, via a leave-out mean instrument, eliminates this many instrument bias only in case the data are clustered in at most one dimension. What is left out in the mean defines this clustering dimension. How most judge designs cluster their standard errors, however, implies that there are additional clustering dimensions, which makes that a many instrument bias remains. We propose two estimators that are many instrument bias free, also in multidimensional clustered judge designs. The first generalises the one dimensional cluster jackknife instrumental variable estimator, by removing from this estimator the additional bias terms due to the extra dependence in the data. The second models all but one clustering dimensions by fixed effects and we show how these numerous fixed effects can be removed without introducing extra bias. A Monte-Carlo experiment and the revisitation of two judge designs show the empirical relevance of properly accounting for multidimensional clustering in estimation.</description>
      <guid isPermaLink="false">oai:arXiv.org:2406.09473v1</guid>
      <category>econ.EM</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Johannes W. Ligtenberg, Tiemen Woutersen</dc:creator>
    </item>
    <item>
      <title>Randomization Inference: Theory and Applications</title>
      <link>https://arxiv.org/abs/2406.09521</link>
      <description>arXiv:2406.09521v1 Announce Type: new 
Abstract: We review approaches to statistical inference based on randomization. Permutation tests are treated as an important special case. Under a certain group invariance property, referred to as the ``randomization hypothesis,'' randomization tests achieve exact control of the Type I error rate in finite samples. Although this unequivocal precision is very appealing, the range of problems that satisfy the randomization hypothesis is somewhat limited. We show that randomization tests are often asymptotically, or approximately, valid and efficient in settings that deviate from the conditions required for finite-sample error control. When randomization tests fail to offer even asymptotic Type 1 error control, their asymptotic validity may be restored by constructing an asymptotically pivotal test statistic. Randomization tests can then provide exact error control for tests of highly structured hypotheses with good performance in a wider class of problems. We give a detailed overview of several prominent applications of randomization tests, including two-sample permutation tests, regression, and conformal inference.</description>
      <guid isPermaLink="false">oai:arXiv.org:2406.09521v1</guid>
      <category>econ.EM</category>
      <category>stat.ME</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>David M. Ritzwoller, Joseph P. Romano, Azeem M. Shaikh</dc:creator>
    </item>
    <item>
      <title>Identification of Ex ante Returns Using Elicited Choice Probabilities: an Application to Preferences for Public-sector Jobs</title>
      <link>https://arxiv.org/abs/2303.03009</link>
      <description>arXiv:2303.03009v2 Announce Type: replace 
Abstract: Ex ante returns, the net value that agents perceive before they take an investment decision, are understood as the main drivers of individual decisions. Hence, their distribution in a population is an important tool for counterfactual analysis and policy evaluation. This paper studies the identification of the population distribution of ex ante returns using stated choice experiments, in the context of binary investment decisions. The environment is characterised by uncertainty about future outcomes, with some uncertainty being resolved over time. In this context, each individual holds a probability distribution over different levels of returns. The paper provides novel, nonparametric identification results for the population distribution of returns, accounting for uncertainty. It complements these with a nonparametric/semiparametric estimation methodology, which is new to the stated-preference literature. Finally, it uses these results to study the preference of high ability students in Cote d'Ivoire for public-sector jobs and how the competition for talent affects the expansion of the private sector.</description>
      <guid isPermaLink="false">oai:arXiv.org:2303.03009v2</guid>
      <category>econ.EM</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Romuald Meango, Esther Mirjam Girsberger</dc:creator>
    </item>
    <item>
      <title>Estimating Input Coefficients for Regional Input-Output Tables Using Deep Learning with Mixup</title>
      <link>https://arxiv.org/abs/2305.01201</link>
      <description>arXiv:2305.01201v3 Announce Type: replace 
Abstract: An input-output table is an important data for analyzing the economic situation of a region. Generally, the input-output table for each region (regional input-output table) in Japan is not always publicly available, so it is necessary to estimate the table. In particular, various methods have been developed for estimating input coefficients, which are an important part of the input-output table. Currently, non-survey methods are often used to estimate input coefficients because they require less data and computation, but these methods have some problems, such as discarding information and requiring additional data for estimation.
  In this study, the input coefficients are estimated by approximating the generation process with an artificial neural network (ANN) to mitigate the problems of the non-survey methods and to estimate the input coefficients with higher precision. To avoid over-fitting due to the small data used, data augmentation, called mixup, is introduced to increase the data size by generating virtual regions through region composition and scaling.
  By comparing the estimates of the input coefficients with those of Japan as a whole, it is shown that the accuracy of the method of this research is higher and more stable than that of the conventional non-survey methods. In addition, the estimated input coefficients for the three cities in Japan are generally close to the published values for each city.</description>
      <guid isPermaLink="false">oai:arXiv.org:2305.01201v3</guid>
      <category>econ.EM</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <arxiv:DOI>10.1007/s10614-024-10641-1</arxiv:DOI>
      <arxiv:journal_reference>Computational Economics (2004), 26 pages</arxiv:journal_reference>
      <dc:creator>Shogo Fukui</dc:creator>
    </item>
    <item>
      <title>On the Efficiency of Finely Stratified Experiments</title>
      <link>https://arxiv.org/abs/2307.15181</link>
      <description>arXiv:2307.15181v3 Announce Type: replace 
Abstract: This paper examines finely stratified designs for the efficient estimation of treatment effect parameters in randomized experiments. In such designs, units are divided into groups of fixed size, with a proportion within each group randomly assigned to a binary treatment. We focus on parameters defined using moment conditions constructed from known functions of the observed data. We establish that the naive method of moments estimator under a finely stratified design achieves the same asymptotic variance as that obtained using ex post covariate adjustment in i.i.d. designs, and further that this variance achieves the efficiency bound in a large class of designs.</description>
      <guid isPermaLink="false">oai:arXiv.org:2307.15181v3</guid>
      <category>econ.EM</category>
      <category>math.ST</category>
      <category>stat.ME</category>
      <category>stat.TH</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Yuehao Bai, Jizhou Liu, Azeem M. Shaikh, Max Tabord-Meehan</dc:creator>
    </item>
    <item>
      <title>Data-Driven Real-time Coupon Allocation in the Online Platform</title>
      <link>https://arxiv.org/abs/2406.05987</link>
      <description>arXiv:2406.05987v2 Announce Type: replace 
Abstract: Traditionally, firms have offered coupons to customer groups at predetermined discount rates. However, advancements in machine learning and the availability of abundant customer data now enable platforms to provide real-time customized coupons to individuals. In this study, we partner with Meituan, a leading shopping platform, to develop a real-time, end-to-end coupon allocation system that is fast and effective in stimulating demand while adhering to marketing budgets when faced with uncertain traffic from a diverse customer base. Leveraging comprehensive customer and product features, we estimate Conversion Rates (CVR) under various coupon values and employ isotonic regression to ensure the monotonicity of predicted CVRs with respect to coupon value. Using calibrated CVR predictions as input, we propose a Lagrangian Dual-based algorithm that efficiently determines optimal coupon values for each arriving customer within 50 milliseconds. We theoretically and numerically investigate the model performance under parameter misspecifications and apply a control loop to adapt to real-time updated information, thereby better adhering to the marketing budget. Finally, we demonstrate through large-scale field experiments and observational data that our proposed coupon allocation algorithm outperforms traditional approaches in terms of both higher conversion rates and increased revenue. As of May 2024, Meituan has implemented our framework to distribute coupons to over 100 million users across more than 110 major cities in China, resulting in an additional CNY 8 million in annual profit. We demonstrate how to integrate a machine learning prediction model for estimating customer CVR, a Lagrangian Dual-based coupon value optimizer, and a control system to achieve real-time coupon delivery while dynamically adapting to random customer arrival patterns.</description>
      <guid isPermaLink="false">oai:arXiv.org:2406.05987v2</guid>
      <category>econ.EM</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Jinglong Dai, Hanwei Li, Weiming Zhu, Jianfeng Lin, Binqiang Huang</dc:creator>
    </item>
    <item>
      <title>What To Do (and Not to Do) with Causal Panel Analysis under Parallel Trends: Lessons from A Large Reanalysis Study</title>
      <link>https://arxiv.org/abs/2309.15983</link>
      <description>arXiv:2309.15983v3 Announce Type: replace-cross 
Abstract: Two-way fixed effects (TWFE) models are ubiquitous in causal panel analysis in political science. However, recent methodological discussions challenge their validity in the presence of heterogeneous treatment effects (HTE) and violations of the parallel trends assumption (PTA). This burgeoning literature has introduced multiple estimators and diagnostics, leading to confusion among empirical researchers on two fronts: the reliability of existing results based on TWFE models and the current best practices. To address these concerns, we examined, replicated, and reanalyzed 37 articles from three leading political science journals that employed observational panel data with binary treatments. Using six newly introduced HTE-robust estimators, along with diagnostics tests and uncertainty measures that are robust to PTA violations, we find that only a small minority of studies are highly robust. Although HTE-robust estimates tend to be broadly consistent with TWFE estimates, discrepancies in point estimates, increased measures of uncertainty, and potential PTA violations call into question many results that were already on the margins of statistical significance. We offer recommendations for improving practice in empirical research based on these findings.</description>
      <guid isPermaLink="false">oai:arXiv.org:2309.15983v3</guid>
      <category>stat.ME</category>
      <category>econ.EM</category>
      <category>stat.AP</category>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Albert Chiu, Xingchen Lan, Ziyi Liu, Yiqing Xu</dc:creator>
    </item>
  </channel>
</rss>
