<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>q-bio.NC updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/q-bio.NC</link>
    <description>q-bio.NC updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/q-bio.NC" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Wed, 18 Dec 2024 05:00:40 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Wed, 18 Dec 2024 00:00:00 -0500</pubDate>
    <skipDays>
      <day>Sunday</day>
      <day>Saturday</day>
    </skipDays>
    <item>
      <title>The Brain-Mesh Model: A Unified Framework For Neural Synchrony, Plasticity, And Coherence</title>
      <link>https://arxiv.org/abs/2412.12106</link>
      <description>arXiv:2412.12106v1 Announce Type: new 
Abstract: The brain-mesh model introduces a novel three-layered architecture that integrates local and macro-regional connectivity with an underlying, mesh-inspired network layer. This foundational mesh layer, based on metallic mesh structures, spans the entire brain and generates interference patterns, noise, and resonance effects that modulate both local and global neural dynamics. The fused model goes beyond traditional connectivity frameworks by providing a unified explanation for phenomena such as brain-wide phase gradients, stable low-frequency resonance frequencies, and long-range plasticity effects, which are often difficult to explain cohesively within existing models.
  In addition to accounting for classical neurobiological observations, such as phase synchrony, functional connectivity fluctuations, and local Hebbian plasticity, the model offers novel insights into less understood phenomena. Specifically, it predicts connectivity-independent phase gradients across non-synaptic regions, harmonic resonance peaks consistent across individuals, and diffuse plasticity driven by global interference patterns, all of which are challenging to explain under current frameworks.
  These unique predictions align with partial empirical observations, such as traveling wave dynamics, consistent low-frequency oscillations, and task-induced connectivity shifts, underscoring the model's relevance. Additionally, the brain-mesh model generates testable hypotheses that distinguish it from traditional approaches. This provides a promising framework for future experimental validation and opens new avenues for understanding global brain function.</description>
      <guid isPermaLink="false">oai:arXiv.org:2412.12106v1</guid>
      <category>q-bio.NC</category>
      <pubDate>Wed, 18 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Andreu Ball\'us</dc:creator>
    </item>
    <item>
      <title>Generative Modeling of Neural Dynamics via Latent Stochastic Differential Equations</title>
      <link>https://arxiv.org/abs/2412.12112</link>
      <description>arXiv:2412.12112v1 Announce Type: new 
Abstract: We propose a probabilistic framework for developing computational models of biological neural systems. In this framework, physiological recordings are viewed as discrete-time partial observations of an underlying continuous-time stochastic dynamical system which implements computations through its state evolution. To model this dynamical system, we employ a system of coupled stochastic differential equations with differentiable drift and diffusion functions and use variational inference to infer its states and parameters. This formulation enables seamless integration of existing mathematical models in the literature, neural networks, or a hybrid of both to learn and compare different models. We demonstrate this in our framework by developing a generative model that combines coupled oscillators with neural networks to capture latent population dynamics from single-cell recordings. Evaluation across three neuroscience datasets spanning different species, brain regions, and behavioral tasks show that these hybrid models achieve competitive performance in predicting stimulus-evoked neural and behavioral responses compared to sophisticated black-box approaches while requiring an order of magnitude fewer parameters, providing uncertainty estimates, and offering a natural language for interpretation.</description>
      <guid isPermaLink="false">oai:arXiv.org:2412.12112v1</guid>
      <category>q-bio.NC</category>
      <category>cs.LG</category>
      <pubDate>Wed, 18 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Ahmed ElGazzar, Marcel van Gerven</dc:creator>
    </item>
    <item>
      <title>Towards a (meta-)mathematical theory of consciousness: universal (mapping) properties of experience</title>
      <link>https://arxiv.org/abs/2412.12179</link>
      <description>arXiv:2412.12179v1 Announce Type: new 
Abstract: Conscious (subjective) experience permeates our daily lives, yet general consensus on a theory of consciousness remains elusive. Integrated Information Theory (IIT) is a prominent approach that asserts the existence of subjective experience (0th axiom), from an intrinsic system of causally related units, and five essential properties (axioms 1-5): intrinsicality, information, integration, exclusion and composition. However, despite empirical support for some aspects of IIT, the supposed necessity of these axioms is unclear given their informal presentation and operationalized dependence on a specific mathematical instantiation as the so-called postulates. The category theory approach presented here attempts to redress this situation. Category theory is a kind of meta-mathematics invented to make relations between formal structures formally precise and so facilitate doing "ordinary" mathematics. In this way, the five essential properties for consciousness are organized around a smaller number of meta-mathematical principles for comparison with IIT. In particular, category theory characterizes mathematical structures by their "universal mapping properties" -- a unique-existence condition for all instances of the structure. Accordingly, axioms 1-5 pertain to universal mapping properties for experience, whence the slogan, "Consciousness is a universal property."</description>
      <guid isPermaLink="false">oai:arXiv.org:2412.12179v1</guid>
      <category>q-bio.NC</category>
      <pubDate>Wed, 18 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Steven Phillips, Naotsugu Tsuchiya</dc:creator>
    </item>
    <item>
      <title>Pop-out vs. Glue: A Study on the pre-attentive and focused attention stages in Visual Search tasks</title>
      <link>https://arxiv.org/abs/2412.12198</link>
      <description>arXiv:2412.12198v1 Announce Type: new 
Abstract: This study explores visual search asymmetry and the detection process between parallel and serial search strategies, building upon Treisman's Feature Integration Theory [3]. Our experiment examines how easy it is to locate an oblique line among vertical distractors versus a vertical line among oblique distractors, a framework previously validated by Treisman &amp; Gormican (1988) [4] and Gupta et al. (2015) [1]. We hypothesised that an oblique target among vertical lines would produce a perceptual 'pop-out' effect, allowing for faster, parallel search, while the reverse condition would require serial search strategy. Seventy-eight participants from Utrecht University engaged in trials with varied target-distractor orientations and number of items. We measured reaction times and found a significant effect of target type on search speed: oblique targets were identified more quickly, reflecting 'pop-out' behaviour, while vertical targets demanded focused attention ('glue phase'). Our results align with past findings, supporting our hypothesis on search asymmetry and its dependency on distinct visual features. Future research could benefit from eye-tracking and neural network analysis, particularly for identifying the neural processing of visual features in both parallel and serial search conditions.</description>
      <guid isPermaLink="false">oai:arXiv.org:2412.12198v1</guid>
      <category>q-bio.NC</category>
      <category>cs.AI</category>
      <category>stat.ME</category>
      <pubDate>Wed, 18 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Hendrik Beukelman, Wilder C. Rodrigues</dc:creator>
    </item>
    <item>
      <title>Efficacy of Temporal Interference Electrical Stimulation for Spinal Cord Injury Rehabilitation: A Case Series</title>
      <link>https://arxiv.org/abs/2412.12229</link>
      <description>arXiv:2412.12229v1 Announce Type: new 
Abstract: Spinal cord injury (SCI) is a debilitating condition that often results in significant motor and sensory deficits, impacting the quality of life. Current rehabilitation methods, including physical therapy and electrical stimulation, offer variable outcomes and often require invasive procedures. Temporal interference (TI) stimulation has emerged as a novel, non-invasive neuromodulation technique capable of targeting deep neural structures with precision, providing a promising alternative for SCI rehabilitation. This study explores the efficacy of TI stimulation as a non-invasive approach for improving motor and sensory function in patients with incomplete SCI. Three male patients with incomplete cervical SCI (AIS D) participated in a two-week intervention consisting of 14 sessions of TI stimulation targeting their injury sites. TI stimulation was delivered using frequencies of 1000 Hz and 1040 Hz, with assessments conducted pre- and post-intervention, including motor and sensory evaluations, functional scales, and imaging studies.All participants demonstrated significant improvements in neurological function, motor strength, sensory perception, and functional independence. Neurological levels of injury shifted upward in all cases, with one patient improving from C5 to C7. Graded Redefined Assessment of Strength, Sensibility and Prehension (GRASSP) results shows additional strength, prehension and sensory outcomes obtained for the arm and hand functions of participants. Motor scores (UEMS and LEMS) increased, sensory scores for light touch and pin prick improved, and functional assessments, such as the Berg Balance Scale (BBS) and Barthel Index (BI), showed marked gains. Pain scores also decreased in two participants, highlighting additional therapeutic benefits.</description>
      <guid isPermaLink="false">oai:arXiv.org:2412.12229v1</guid>
      <category>q-bio.NC</category>
      <pubDate>Wed, 18 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Ruidong Cheng, Yuling Shao, Xi Li, Li Zhang, Zehao Sheng, Chenyang Li, Xu Xie, Huilin Mou, Weidong Chen, Shaomin Zhang, Yuchen Xu, Minmin Wang</dc:creator>
    </item>
    <item>
      <title>Identification of Epileptic Spasms (ESES) Phases Using EEG Signals: A Vision Transformer Approach</title>
      <link>https://arxiv.org/abs/2412.13028</link>
      <description>arXiv:2412.13028v1 Announce Type: new 
Abstract: This work introduces a new approach to the Epileptic Spasms (ESES) detection based on the EEG signals using Vision Transformers (ViT). Classic ESES detection approaches have usually been performed with manual processing or conventional algorithms, suffering from poor sample sizes, single-channel-based analyses, and low generalization abilities. In contrast, the proposed ViT model overcomes these limitations by using the attention mechanism to focus on the important features in multi-channel EEG data, which is contributing to both better accuracy and efficiency. The model processes frequency-domain representations of EEG signals, such as spectrograms, as image data to capture long-range dependencies and complex patterns in the signal. The model demonstrates high performance with an accuracy of 97% without requiring intensive data preprocessing, thus rendering it suitable for real-time clinical applications on a large scale. The method represents a significant development in the advancement of neurological disorders such as ESES in detection and analysis.</description>
      <guid isPermaLink="false">oai:arXiv.org:2412.13028v1</guid>
      <category>q-bio.NC</category>
      <category>cs.CE</category>
      <pubDate>Wed, 18 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Wei Gong, Yaru Li</dc:creator>
    </item>
    <item>
      <title>Chaotic dynamics and fractal geometry in ring lattice systems of non-chaotic Rulkov neurons</title>
      <link>https://arxiv.org/abs/2412.12134</link>
      <description>arXiv:2412.12134v1 Announce Type: cross 
Abstract: This paper investigates the complex dynamics and fractal attractors that emerge from 60-dimensional ring lattice systems of electrically coupled non-chaotic Rulkov neurons. Although networks of chaotic Rulkov neurons are well-studied, systems of non-chaotic Rulkov neurons have not been extensively explored due to the piecewise complexity of the non-chaotic Rulkov map. We find rich dynamics emerge from the electrical coupling of regular spiking Rulkov neurons, including chaotic spiking, chaotic bursting, and complete chaos. We also discover general trends in the maximal Lyapunov exponent among different ring lattice systems as the electrical coupling strength between neurons is varied. By means of the Kaplan-Yorke conjecture, we also examine the fractal geometry of the chaotic attractors of the ring systems and find various correlations and differences between the fractal dimensions of the attractors and the chaotic dynamics on them.</description>
      <guid isPermaLink="false">oai:arXiv.org:2412.12134v1</guid>
      <category>nlin.CD</category>
      <category>math.DS</category>
      <category>q-bio.NC</category>
      <pubDate>Wed, 18 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Brandon B. Le</dc:creator>
    </item>
    <item>
      <title>Shared Attention-based Autoencoder with Hierarchical Fusion-based Graph Convolution Network for sEEG SOZ Identification</title>
      <link>https://arxiv.org/abs/2412.12651</link>
      <description>arXiv:2412.12651v1 Announce Type: cross 
Abstract: Diagnosing seizure onset zone (SOZ) is a challenge in neurosurgery, where stereoelectroencephalography (sEEG) serves as a critical technique. In sEEG SOZ identification, the existing studies focus solely on the intra-patient representation of epileptic information, overlooking the general features of epilepsy across patients and feature interdependencies between feature elements in each contact site. In order to address the aforementioned challenges, we propose the shared attention-based autoencoder (sATAE). sATAE is trained by sEEG data across all patients, with attention blocks introduced to enhance the representation of interdependencies between feature elements. Considering the spatial diversity of sEEG across patients, we introduce graph-based method for identification SOZ of each patient. However, the current graph-based methods for sEEG SOZ identification rely exclusively on static graphs to model epileptic networks. Inspired by the finding of neuroscience that epileptic network is intricately characterized by the interplay of sophisticated equilibrium between fluctuating and stable states, we design the hierarchical fusion-based graph convolution network (HFGCN) to identify the SOZ. HFGCN integrates the dynamic and static characteristics of epileptic networks through hierarchical weighting across different hierarchies, facilitating a more comprehensive learning of epileptic features and enriching node information for sEEG SOZ identification. Combining sATAE and HFGCN, we perform comprehensive experiments with sATAE-HFGCN on the self-build sEEG dataset, which includes sEEG data from 17 patients with temporal lobe epilepsy. The results show that our method, sATAE-HFGCN, achieves superior performance for identifying the SOZ of each patient, effectively addressing the aforementioned challenges, providing an efficient solution for sEEG-based SOZ identification.</description>
      <guid isPermaLink="false">oai:arXiv.org:2412.12651v1</guid>
      <category>cs.LG</category>
      <category>cs.AI</category>
      <category>eess.SP</category>
      <category>q-bio.NC</category>
      <pubDate>Wed, 18 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Huachao Yan, Kailing Guo, Shiwei Song, Yihai Dai, Xiaoqiang Wei, Xiaofen Xing, Xiangmin Xu</dc:creator>
    </item>
    <item>
      <title>Artificial intelligence for science: The easy and hard problems</title>
      <link>https://arxiv.org/abs/2408.14508</link>
      <description>arXiv:2408.14508v2 Announce Type: replace-cross 
Abstract: A suite of impressive scientific discoveries have been driven by recent advances in artificial intelligence. These almost all result from training flexible algorithms to solve difficult optimization problems specified in advance by teams of domain scientists and engineers with access to large amounts of data. Although extremely useful, this kind of problem solving only corresponds to one part of science - the "easy problem." The other part of scientific research is coming up with the problem itself - the "hard problem." Solving the hard problem is beyond the capacities of current algorithms for scientific discovery because it requires continual conceptual revision based on poorly defined constraints. We can make progress on understanding how humans solve the hard problem by studying the cognitive science of scientists, and then use the results to design new computational agents that automatically infer and update their scientific paradigms.</description>
      <guid isPermaLink="false">oai:arXiv.org:2408.14508v2</guid>
      <category>cs.AI</category>
      <category>cs.LG</category>
      <category>q-bio.NC</category>
      <pubDate>Wed, 18 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Ruairidh M. Battleday, Samuel J. Gershman</dc:creator>
    </item>
    <item>
      <title>Plastic Arbor: a modern simulation framework for synaptic plasticity $\unicode{x2013}$ from single synapses to networks of morphological neurons</title>
      <link>https://arxiv.org/abs/2411.16445</link>
      <description>arXiv:2411.16445v2 Announce Type: replace-cross 
Abstract: Arbor is a software library designed for efficient simulation of large-scale networks of biological neurons with detailed morphological structures. It combines customizable neuronal and synaptic mechanisms with high-performance computing, supporting multi-core CPU and GPU systems.
  In humans and other animals, synaptic plasticity processes play a vital role in cognitive functions, including learning and memory. Recent studies have shown that intracellular molecular processes in dendrites significantly influence single-neuron dynamics. However, for understanding how the complex interplay between dendrites and synaptic processes influences network dynamics, computational modeling is required.
  To enable the modeling of large-scale networks of morphologically detailed neurons with diverse plasticity processes, we have extended the Arbor library to the Plastic Arbor framework, supporting simulations of a large variety of spike-driven plasticity paradigms. To showcase the features of the new framework, we present examples of computational models, beginning with single-synapse dynamics, progressing to multi-synapse rules, and finally scaling up to large recurrent networks. While cross-validating our implementations by comparison with other simulators, we show that Arbor allows simulating plastic networks of multi-compartment neurons at nearly no additional cost in runtime compared to point-neuron simulations. Using the new framework, we have already been able to investigate the impact of dendritic structures on network dynamics across a timescale of several hours, showing a relation between the length of dendritic trees and the ability of the network to efficiently store information.
  By our extension of Arbor, we aim to provide a valuable tool that will support future studies on the impact of synaptic plasticity, especially, in conjunction with neuronal morphology, in large networks.</description>
      <guid isPermaLink="false">oai:arXiv.org:2411.16445v2</guid>
      <category>cs.CE</category>
      <category>cs.NE</category>
      <category>q-bio.NC</category>
      <pubDate>Wed, 18 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Jannik Luboeinski, Sebastian Schmitt, Shirin Shafiee, Thorsten Hater, Fabian B\"osch, Christian Tetzlaff</dc:creator>
    </item>
  </channel>
</rss>
