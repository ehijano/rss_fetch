<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>cs.CE updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/cs.CE</link>
    <description>cs.CE updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/cs.CE" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Thu, 09 May 2024 04:01:13 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Thu, 09 May 2024 00:00:00 -0400</pubDate>
    <skipDays>
      <day>Saturday</day>
      <day>Sunday</day>
    </skipDays>
    <item>
      <title>Neural network based approach for solving problems in plane wave duct acoustics</title>
      <link>https://arxiv.org/abs/2405.04603</link>
      <description>arXiv:2405.04603v1 Announce Type: new 
Abstract: Neural networks have emerged as a tool for solving differential equations in many branches of engineering and science. But their progress in frequency domain acoustics is limited by the vanishing gradient problem that occurs at higher frequencies. This paper discusses a formulation that can address this issue. The problem of solving the governing differential equation along with the boundary conditions is posed as an unconstrained optimization problem. The acoustic field is approximated to the output of a neural network which is constructed in such a way that it always satisfies the boundary conditions. The applicability of the formulation is demonstrated on popular problems in plane wave acoustic theory. The predicted solution from the neural network formulation is compared with those obtained from the analytical solution. A good agreement is observed between the two solutions. The method of transfer learning to calculate the particle velocity from the existing acoustic pressure field is demonstrated with and without mean flow effects. The sensitivity of the training process to the choice of the activation function and the number of collocation points is studied.</description>
      <guid isPermaLink="false">oai:arXiv.org:2405.04603v1</guid>
      <category>cs.CE</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <arxiv:DOI>10.1016/j.jsv.2024.118476</arxiv:DOI>
      <arxiv:journal_reference>Journal of Sound and Vibration, 585, 2024:118476</arxiv:journal_reference>
      <dc:creator>D. Veerababu, Prasanta K. Ghosh</dc:creator>
    </item>
    <item>
      <title>An Artificial Intelligence Approach for Interpreting Creative Combinational Designs</title>
      <link>https://arxiv.org/abs/2405.04985</link>
      <description>arXiv:2405.04985v1 Announce Type: new 
Abstract: Combinational creativity, a form of creativity involving the blending of familiar ideas, is pivotal in design innovation. While most research focuses on how combinational creativity in design is achieved through blending elements, this study focuses on the computational interpretation, specifically identifying the 'base' and 'additive' components that constitute a creative design. To achieve this goal, the authors propose a heuristic algorithm integrating computer vision and natural language processing technologies, and implement multiple approaches based on both discriminative and generative artificial intelligence architectures. A comprehensive evaluation was conducted on a dataset created for studying combinational creativity. Among the implementations of the proposed algorithm, the most effective approach demonstrated a high accuracy in interpretation, achieving 87.5% for identifying 'base' and 80% for 'additive'. We conduct a modular analysis and an ablation experiment to assess the performance of each part in our implementations. Additionally, the study includes an analysis of error cases and bottleneck issues, providing critical insights into the limitations and challenges inherent in the computational interpretation of creative designs.</description>
      <guid isPermaLink="false">oai:arXiv.org:2405.04985v1</guid>
      <category>cs.CE</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Liuqing Chen, Shuhong Xiao, Yunnong Chen, Linyun Sun, Peter R. N. Childs, Ji Han</dc:creator>
    </item>
    <item>
      <title>Multi-fidelity Hamiltonian Monte Carlo</title>
      <link>https://arxiv.org/abs/2405.05033</link>
      <description>arXiv:2405.05033v1 Announce Type: new 
Abstract: Numerous applications in biology, statistics, science, and engineering require generating samples from high-dimensional probability distributions. In recent years, the Hamiltonian Monte Carlo (HMC) method has emerged as a state-of-the-art Markov chain Monte Carlo technique, exploiting the shape of such high-dimensional target distributions to efficiently generate samples. Despite its impressive empirical success and increasing popularity, its wide-scale adoption remains limited due to the high computational cost of gradient calculation. Moreover, applying this method is impossible when the gradient of the posterior cannot be computed (for example, with black-box simulators). To overcome these challenges, we propose a novel two-stage Hamiltonian Monte Carlo algorithm with a surrogate model. In this multi-fidelity algorithm, the acceptance probability is computed in the first stage via a standard HMC proposal using an inexpensive differentiable surrogate model, and if the proposal is accepted, the posterior is evaluated in the second stage using the high-fidelity (HF) numerical solver. Splitting the standard HMC algorithm into these two stages allows for approximating the gradient of the posterior efficiently, while producing accurate posterior samples by using HF numerical solvers in the second stage. We demonstrate the effectiveness of this algorithm for a range of problems, including linear and nonlinear Bayesian inverse problems with in-silico data and experimental data. The proposed algorithm is shown to seamlessly integrate with various low-fidelity and HF models, priors, and datasets. Remarkably, our proposed method outperforms the traditional HMC algorithm in both computational and statistical efficiency by several orders of magnitude, all while retaining or improving the accuracy in computed posterior statistics.</description>
      <guid isPermaLink="false">oai:arXiv.org:2405.05033v1</guid>
      <category>cs.CE</category>
      <category>cs.LG</category>
      <category>stat.ML</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Dhruv V. Patel, Jonghyun Lee, Matthew W. Farthing, Peter K. Kitanidis, Eric F. Darve</dc:creator>
    </item>
    <item>
      <title>Cryptocurrency Risk, Trust, and Acceptance in Thailand: A Comparative Study with Switzerland</title>
      <link>https://arxiv.org/abs/2405.05086</link>
      <description>arXiv:2405.05086v1 Announce Type: new 
Abstract: The adoption of the Pao Tang digital wallet in Thailand, promoted under the Khon la Krueng (50-50 Co-Payment) Scheme, illustrates Thailand's receptiveness to digital financial instruments, amassing over 40 million users in just three years during the COVID-19 social distancing era. Nevertheless, acceptance of this platform does not confirm a broad understanding of cryptocurrencies and Web 3.0 technologies in the region. Through a mix of documentary research, online surveys and a targeted interview with the Pao Tang app's founder, this study evaluates the factors behind the Pao Tang platform's success and contrasts it with digital practices in Switzerland. Preliminary outcomes reveal a pronounced knowledge gap in Thailand regarding decentralized technologies. With regulatory frameworks for Web 3.0 and digital currencies still nascent, this research underscores the need for further exploration, serving as a blueprint for shaping strategies, policies, and awareness campaigns in both countries.</description>
      <guid isPermaLink="false">oai:arXiv.org:2405.05086v1</guid>
      <category>cs.CE</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <arxiv:journal_reference>CVC Research Journal 2023</arxiv:journal_reference>
      <dc:creator>Kanyanut Suriyan, Tim Weingaertner</dc:creator>
    </item>
    <item>
      <title>An efficient truncation scheme for Eulerian and total Lagrangian SPH methods</title>
      <link>https://arxiv.org/abs/2405.05155</link>
      <description>arXiv:2405.05155v1 Announce Type: new 
Abstract: In smoothed particle hydrodynamics (SPH) method, the particle-based approximations are implemented via kernel functions, and the evaluation of performance involves two key criteria: numerical accuracy and computational efficiency. In the SPH community, the Wendland kernel reigns as the prevailing choice due to its commendable accuracy and reasonable computational efficiency. Nevertheless, there exists an urgent need to enhance the computational efficiency of numerical methods while upholding accuracy. In this paper, we employ a truncation approach to limit the compact support of the Wendland kernel to 1.6h. This decision is based on the observation that particles within the range of 1.6h to 2h make negligible contributions, practically approaching zero, to the SPH approximation. To address integration errors stemming from the truncation, we incorporate the Laguerre-Gauss kernel for particle relaxation due to the fact that this kernel has been demonstrated to enable the attainment of particle distributions with reduced residue and integration errors \cite{wang2023fourth}. Furthermore, we introduce the kernel gradient correction to rectify numerical errors from the SPH approximation of kernel gradient and the truncated compact support. A comprehensive set of numerical examples including fluid dynamics in Eulerian formulation and solid dynamics in total Lagrangian formulation are tested and have demonstrated that truncated and standard Wendland kernels enable achieve the same level accuracy but the former significantly increase the computational efficiency.</description>
      <guid isPermaLink="false">oai:arXiv.org:2405.05155v1</guid>
      <category>cs.CE</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Zhentong Wang, Chi Zhang, Oskar J. Haidn, Xiangyu Hu</dc:creator>
    </item>
    <item>
      <title>Some variation of COBRA in sequential learning setup</title>
      <link>https://arxiv.org/abs/2405.04539</link>
      <description>arXiv:2405.04539v1 Announce Type: cross 
Abstract: This research paper introduces innovative approaches for multivariate time series forecasting based on different variations of the combined regression strategy. We use specific data preprocessing techniques which makes a radical change in the behaviour of prediction. We compare the performance of the model based on two types of hyper-parameter tuning Bayesian optimisation (BO) and Usual Grid search. Our proposed methodologies outperform all state-of-the-art comparative models. We illustrate the methodologies through eight time series datasets from three categories: cryptocurrency, stock index, and short-term load forecasting.</description>
      <guid isPermaLink="false">oai:arXiv.org:2405.04539v1</guid>
      <category>stat.ML</category>
      <category>cs.CE</category>
      <category>cs.LG</category>
      <category>eess.SP</category>
      <category>q-fin.CP</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-sa/4.0/</dc:rights>
      <dc:creator>Aryan Bhambu, Arabin Kumar Dey</dc:creator>
    </item>
    <item>
      <title>Exponential time propagators for elastodynamics</title>
      <link>https://arxiv.org/abs/2405.05213</link>
      <description>arXiv:2405.05213v1 Announce Type: cross 
Abstract: We propose a computationally efficient and systematically convergent approach for elastodynamics simulations. We recast the second-order dynamical equation of elastodynamics into an equivalent first-order system of coupled equations, so as to express the solution in the form of a Magnus expansion. With any spatial discretization, it entails computing the exponential of a matrix acting upon a vector. We employ an adaptive Krylov subspace approach to inexpensively and and accurately evaluate the action of the exponential matrix on a vector. In particular, we use an apriori error estimate to predict the optimal Kyrlov subspace size required for each time-step size. We show that the Magnus expansion truncated after its first term provides quadratic and superquadratic convergence in the time-step for nonlinear and linear elastodynamics, respectively. We demonstrate the accuracy and efficiency of the proposed method for one linear (linear cantilever beam) and three nonlinear (nonlinear cantilever beam, soft tissue elastomer, and hyperelastic rubber) benchmark systems. For a desired accuracy in energy, displacement, and velocity, our method allows for $10-100\times$ larger time-steps than conventional time-marching schemes such as Newmark-$\beta$ method. Computationally, it translates to a $\sim$$1000\times$ and $\sim$$10-100\times$ speed-up over conventional time-marching schemes for linear and nonlinear elastodynamics, respectively.</description>
      <guid isPermaLink="false">oai:arXiv.org:2405.05213v1</guid>
      <category>math.NA</category>
      <category>cs.CE</category>
      <category>cs.NA</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Paavai Pari, Bikash Kanungo, Vikram Gavini</dc:creator>
    </item>
  </channel>
</rss>
