<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>q-bio.NC updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/q-bio.NC</link>
    <description>q-bio.NC updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/q-bio.NC" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Fri, 13 Jun 2025 01:41:12 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Thu, 12 Jun 2025 00:00:00 -0400</pubDate>
    <skipDays>
      <day>Sunday</day>
      <day>Saturday</day>
    </skipDays>
    <item>
      <title>How attention simplifies mental representations for planning</title>
      <link>https://arxiv.org/abs/2506.09520</link>
      <description>arXiv:2506.09520v1 Announce Type: new 
Abstract: Human planning is efficient -- it frugally deploys limited cognitive resources to accomplish difficult tasks -- and flexible -- adapting to novel problems and environments. Computational approaches suggest that people construct simplified mental representations of their environment, balancing the complexity of a task representation with its utility. These models imply a nested optimisation in which planning shapes perception, and perception shapes planning -- but the perceptual and attentional mechanisms governing how this interaction unfolds remain unknown. Here, we harness virtual maze navigation to characterise how spatial attention controls which aspects of a task representation enter subjective awareness and are available for planning. We find that spatial proximity governs which aspects of a maze are available for planning, and that when task-relevant information follows natural (lateralised) contours of attention, people can more easily construct simplified and useful maze representations. This influence of attention varies considerably across individuals, explaining differences in people's task representations and behaviour. Inspired by the 'spotlight of attention' analogy, we incorporate the effects of visuospatial attention into existing computational accounts of value-guided construal. Together, our work bridges computational perspectives on perception and decision-making to better understand how individuals represent their environments in aid of planning.</description>
      <guid isPermaLink="false">oai:arXiv.org:2506.09520v1</guid>
      <category>q-bio.NC</category>
      <category>cs.AI</category>
      <category>cs.RO</category>
      <pubDate>Thu, 12 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <dc:creator>Jason da Silva Castanheira, Nicholas Shea, Stephen M. Fleming</dc:creator>
    </item>
    <item>
      <title>Spiking Neural Models for Decision-Making Tasks with Learning</title>
      <link>https://arxiv.org/abs/2506.09087</link>
      <description>arXiv:2506.09087v1 Announce Type: cross 
Abstract: In cognition, response times and choices in decision-making tasks are commonly modeled using Drift Diffusion Models (DDMs), which describe the accumulation of evidence for a decision as a stochastic process, specifically a Brownian motion, with the drift rate reflecting the strength of the evidence. In the same vein, the Poisson counter model describes the accumulation of evidence as discrete events whose counts over time are modeled as Poisson processes, and has a spiking neurons interpretation as these processes are used to model neuronal activities. However, these models lack a learning mechanism and are limited to tasks where participants have prior knowledge of the categories. To bridge the gap between cognitive and biological models, we propose a biologically plausible Spiking Neural Network (SNN) model for decision-making that incorporates a learning mechanism and whose neurons activities are modeled by a multivariate Hawkes process. First, we show a coupling result between the DDM and the Poisson counter model, establishing that these two models provide similar categorizations and reaction times and that the DDM can be approximated by spiking Poisson neurons. To go further, we show that a particular DDM with correlated noise can be derived from a Hawkes network of spiking neurons governed by a local learning rule. In addition, we designed an online categorization task to evaluate the model predictions. This work provides a significant step toward integrating biologically relevant neural mechanisms into cognitive models, fostering a deeper understanding of the relationship between neural activity and behavior.</description>
      <guid isPermaLink="false">oai:arXiv.org:2506.09087v1</guid>
      <category>cs.LG</category>
      <category>math.PR</category>
      <category>q-bio.NC</category>
      <category>stat.ML</category>
      <pubDate>Thu, 12 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Sophie Jaffard (LJAD), Giulia Mezzadri (LJAD, CNRS), Patricia Reynaud-Bouret (LJAD, CNRS), Etienne Tanr\'e (LJAD, CRISAM)</dc:creator>
    </item>
    <item>
      <title>On the Arrow of Inference</title>
      <link>https://arxiv.org/abs/2402.14186</link>
      <description>arXiv:2402.14186v3 Announce Type: replace 
Abstract: Just as the arrow of time structures physics, the arrow of inference organizes cognition, directing the flow of information in perception, action, and memory. The Context-Content Uncertainty Principle (CCUP) formalizes this asymmetry, between high-entropy context and low-entropy content, and frames inference as a cycle that aligns the two through selective, bidirectional interaction. Cycle formation resolves the Information Bottleneck (IB) in Optimal Transport (OT) by coordinating bottom-up contextual disambiguation with top-down content reconstruction, a process neurobiologically mirrored in the cyclical interplay between dorsal (context) and ventral (content) streams. Local inference cycles extend into memory chains that simulate goals, support counterfactual reasoning, and scaffold internal model refinement across time. By operating on delta-seeded goal manifolds, each level of the hierarchy circumvents the curse of dimensionality through structured diffusion guided by priors and context. This mechanism generalizes across timescales, from perception-action loops to the sleep-wake cycle-and scales socially through language, which externalizes inference by transmitting latent content across minds. Thus, CCUP provides a unifying framework for understanding cognition as cycle-consistent inference, anchoring both individual thought and collective intelligence.</description>
      <guid isPermaLink="false">oai:arXiv.org:2402.14186v3</guid>
      <category>q-bio.NC</category>
      <pubDate>Thu, 12 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/publicdomain/zero/1.0/</dc:rights>
      <dc:creator>Xin Li</dc:creator>
    </item>
    <item>
      <title>Markov Blanket Density and Free Energy Minimization</title>
      <link>https://arxiv.org/abs/2506.05794</link>
      <description>arXiv:2506.05794v2 Announce Type: replace 
Abstract: This paper presents a continuous, information-theoretic extension of the Free Energy Principle through the concept of Markov blanket density, i.e., a scalar field that quantifies the degree of conditional independence between internal and external states at each point in space (ranging from 0 for full coupling to 1 for full separation). It demonstrates that active inference dynamics (including the minimization of variational and expected free energy) naturally emerge from spatial gradients in this density, making Markov blanket density a necessary foundation for the definability and coherence of the Free Energy Principle. These ideas are developed through a mathematically framework that links density gradients to precise and testable dynamics, offering a foundation for novel predictions and simulation paradigms.</description>
      <guid isPermaLink="false">oai:arXiv.org:2506.05794v2</guid>
      <category>q-bio.NC</category>
      <category>cs.IT</category>
      <category>math.IT</category>
      <pubDate>Thu, 12 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Luca M. Possati</dc:creator>
    </item>
    <item>
      <title>AI Agent Behavioral Science</title>
      <link>https://arxiv.org/abs/2506.06366</link>
      <description>arXiv:2506.06366v3 Announce Type: replace 
Abstract: Recent advances in large language models (LLMs) have enabled the development of AI agents that exhibit increasingly human-like behaviors, including planning, adaptation, and social dynamics across diverse, interactive, and open-ended scenarios. These behaviors are not solely the product of the internal architectures of the underlying models, but emerge from their integration into agentic systems operating within specific contexts, where environmental factors, social cues, and interaction feedbacks shape behavior over time. This evolution necessitates a new scientific perspective: AI Agent Behavioral Science. Rather than focusing only on internal mechanisms, this perspective emphasizes the systematic observation of behavior, design of interventions to test hypotheses, and theory-guided interpretation of how AI agents act, adapt, and interact over time. We systematize a growing body of research across individual agent, multi-agent, and human-agent interaction settings, and further demonstrate how this perspective informs responsible AI by treating fairness, safety, interpretability, accountability, and privacy as behavioral properties. By unifying recent findings and laying out future directions, we position AI Agent Behavioral Science as a necessary complement to traditional model-centric approaches, providing essential tools for understanding, evaluating, and governing the real-world behavior of increasingly autonomous AI systems.</description>
      <guid isPermaLink="false">oai:arXiv.org:2506.06366v3</guid>
      <category>q-bio.NC</category>
      <category>cs.CY</category>
      <category>cs.MA</category>
      <pubDate>Thu, 12 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Lin Chen, Yunke Zhang, Jie Feng, Haoye Chai, Honglin Zhang, Bingbing Fan, Yibo Ma, Shiyuan Zhang, Nian Li, Tianhui Liu, Nicholas Sukiennik, Keyu Zhao, Yu Li, Ziyi Liu, Fengli Xu, Yong Li</dc:creator>
    </item>
    <item>
      <title>Dataset Properties Shape the Success of Neuroimaging-Based Patient Stratification: A Benchmarking Analysis Across Clustering Algorithms</title>
      <link>https://arxiv.org/abs/2503.12066</link>
      <description>arXiv:2503.12066v2 Announce Type: replace-cross 
Abstract: Background: Data driven stratification of patients into biologically informed subtypes holds promise for precision neuropsychiatry, yet neuroimaging-based clustering methods often fail to generalize across cohorts. While algorithmic innovations have focused on model complexity, the role of underlying dataset characteristics remains underexplored. We hypothesized that cluster separation, size imbalance, noise, and the direction and magnitude of disease-related effects in the input data critically determine both within-algorithm accuracy and reproducibility. Methods: We evaluated 4 widely used stratification algorithms, HYDRA, SuStaIn, SmileGAN, and SurrealGAN, on a suite of synthetic brain-morphometry cohorts derived from the Human Connectome Project Young Adult dataset. Three global transformation patterns were applied to 600 pseudo-patients against 508 controls, followed by 4 within-dataset variations varying cluster count (k=2-6), overlap, and effect magnitude. Algorithm performance was quantified by accuracy in recovering the known ground-truth clusters. Results: Across 122 synthetic scenarios, data complexity consistently outweighed algorithm choice in predicting stratification success. Well-separated clusters yielded high accuracy for all methods, whereas overlapping, unequal-sized, or subtle effects reduced accuracy by up to 50%. SuStaIn could not scale beyond 17 features, HYDRA's accuracy varied unpredictably with data heterogeneity. SmileGAN and SurrealGAN maintained robust pattern detection but did not assign discrete cluster labels to individuals. Conclusions: The study results demonstrate the impact of statistical properties of input data across algorithms and highlight the need for using realistic dataset distributions when new algorithms are being developed and suggest greater focus on data-centric strategies that actively shape and standardize the input distributions.</description>
      <guid isPermaLink="false">oai:arXiv.org:2503.12066v2</guid>
      <category>cs.LG</category>
      <category>q-bio.NC</category>
      <category>q-bio.QM</category>
      <pubDate>Thu, 12 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <dc:creator>Yuetong Yu, Ruiyang Ge, Ilker Hacihaliloglu, Alexander Rauscher, Roger Tam, Sophia Frangou</dc:creator>
    </item>
    <item>
      <title>SpikeSift: A Computationally Efficient and Drift-Resilient Spike Sorting Algorithm</title>
      <link>https://arxiv.org/abs/2504.01604</link>
      <description>arXiv:2504.01604v2 Announce Type: replace-cross 
Abstract: Objective: Spike sorting is a fundamental step in analysing extracellular recordings, enabling the isolation of single-neuron activity. However, it remains a challenging problem because extracellular traces mix overlapping spikes from neighbouring cells and are marred by recording instabilities such as electrode drift. Numerous algorithms have been proposed, yet many struggle to balance accuracy and computational efficiency, limiting their practicality for todays large-scale datasets. Approach: In response, we introduce SpikeSift, a spike-sorting algorithm expressly designed to mitigate drift while running on standard CPUs. SpikeSift (i) partitions long recordings into shorter, relatively stationary segments, (ii) carries out spike detection and clustering simultaneously through an iterative detect-and-subtract scheme within each segment, and (iii) preserves neuronal identity across segments via a fast template alignment stage that dispenses with continuous trajectory estimation. Main results: Extensive validation on paired intracellularly validated datasets and on biophysically realistic MEArec simulations covering elevated noise, diverse drift profiles, ultra short recordings and bursting activity, demonstrates that SpikeSift matches or exceeds the accuracy of state of the art methods while completing sorting an order of magnitude faster on a single desktop core. Significance: The combination of high fidelity, drift resilience, and modest computational demand renders SpikeSift broadly accessible while preserving data quality for downstream neurophysiological analysis</description>
      <guid isPermaLink="false">oai:arXiv.org:2504.01604v2</guid>
      <category>eess.SP</category>
      <category>q-bio.NC</category>
      <pubDate>Thu, 12 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Vasileios Georgiadis, Panagiotis C. Petrantonakis</dc:creator>
    </item>
    <item>
      <title>Unable to Forget: Proactive lnterference Reveals Working Memory Limits in LLMs Beyond Context Length</title>
      <link>https://arxiv.org/abs/2506.08184</link>
      <description>arXiv:2506.08184v2 Announce Type: replace-cross 
Abstract: Information retrieval in Large Language Models (LLMs) is increasingly recognized as intertwined with generation capabilities rather than mere lookup. While longer contexts are often assumed to improve retrieval, the effects of intra-context interference remain understudied. To address this, we adapt the proactive interference (PI) paradigm from cognitive science, where earlier information disrupts recall of newer updates. In humans, susceptibility to such interference is inversely linked to working memory capacity. We introduce PI-LLM, an evaluation that sequentially streams semantically related key-value updates and queries only the final values. Although these final values are clearly positioned just before the query, LLM retrieval accuracy declines log-linearly toward zero as interference accumulates; errors arise from retrieving previously overwritten values. Attempts to mitigate interference via prompt engineering (e.g., instructing models to ignore earlier input) yield limited success. These findings reveal a fundamental constraint on LLMs' ability to disentangle interference and flexibly manipulate information, suggesting a working memory bottleneck beyond mere context access. This calls for approaches that strengthen models' ability to suppress irrelevant content during retrieval.</description>
      <guid isPermaLink="false">oai:arXiv.org:2506.08184v2</guid>
      <category>cs.CL</category>
      <category>cs.AI</category>
      <category>q-bio.NC</category>
      <pubDate>Thu, 12 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Chupei Wang (University of Virginia), Jiaqiu Vince Sun (New York University)</dc:creator>
    </item>
  </channel>
</rss>
