<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>cs.DC updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/cs.DC</link>
    <description>cs.DC updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/cs.DC" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Wed, 02 Apr 2025 09:18:13 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Wed, 02 Apr 2025 00:00:00 -0400</pubDate>
    <skipDays>
      <day>Saturday</day>
      <day>Sunday</day>
    </skipDays>
    <item>
      <title>AMP4EC: Adaptive Model Partitioning Framework for Efficient Deep Learning Inference in Edge Computing Environments</title>
      <link>https://arxiv.org/abs/2504.00407</link>
      <description>arXiv:2504.00407v1 Announce Type: new 
Abstract: Edge computing enables efficient deep learning inference in resource-constrained environments. In this paper, we propose AMP4EC, an adaptive model partitioning framework that optimizes inference by dynamically partitioning deep learning models based on real-time resource availability. Our approach achieves a latency reduction of up to 78% and a throughput improvement of 414% compared to baseline methods.</description>
      <guid isPermaLink="false">oai:arXiv.org:2504.00407v1</guid>
      <category>cs.DC</category>
      <pubDate>Wed, 02 Apr 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Guilin Zhang, Wulan Guo, Ziqi Tan, Hailong Jiang</dc:creator>
    </item>
    <item>
      <title>CFP: Low-overhead Profiling-based Intra-operator Parallelism Generation by Preserving Communication-Free Structures</title>
      <link>https://arxiv.org/abs/2504.00598</link>
      <description>arXiv:2504.00598v1 Announce Type: new 
Abstract: This paper introduces CFP, a system that search intra-operator parallelism configurations by leveraging runtime profiles of actual parallel programs. The key idea is to profile a limited space by identifying a new structure named ParallelBlock, which is a group of operators with the property of communication-free tensor partition propagation: the partition of its input tensor can propagate through all operators to its output tensor without introducing communication or synchronization. Based on this property, an optimal tensor partition of operators within a ParallelBlock should be inferred from the partition of input tensor through partition propagation to prevent the avoidable communication. Thus, the search space can be reduced by only profiling each ParallelBlock with different input tensor partitions at its entry, instead of enumerating all combinations among operators within the ParallelBlock. Moreover, the search space is further reduced by identifying ParallelBlock sequences (segments) with similar parallel behavior. CFP computes the overall performance of the model based on the profiles of all segments. On GPT, LLAMA, and MoE models, CFP achieves up to a 1.51x, 1.31x, and 3.43x speedup over the state-of-the-art framework, Alpa.</description>
      <guid isPermaLink="false">oai:arXiv.org:2504.00598v1</guid>
      <category>cs.DC</category>
      <pubDate>Wed, 02 Apr 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Weifang Hu, Xuanhua Shi, Chang Wu, Yunkai Zhang, Xuan Peng, Jiaqi Zhai, Hai Jin, Yongluan Zhou, Xuehai Qian</dc:creator>
    </item>
    <item>
      <title>Performance bounds for priority-based stochastic coflow scheduling</title>
      <link>https://arxiv.org/abs/2504.00628</link>
      <description>arXiv:2504.00628v1 Announce Type: new 
Abstract: We consider the coflow scheduling problem in the non-clairvoyant setting, assuming that flow sizes are realized on-line according to given probability distributions. The goal is to minimize the weighted average completion time of coflows in expectation. We first obtain inequalities for this problem that are valid for all non-anticipative order-based rate-allocation policies and define a polyhedral relaxation of the performance space of such scheduling policies. This relaxation is used to analyze the performance of a simple priority policy in which the priority order is computed by Sincronia from expected flow sizes instead of their unknown actual values. We establish a bound on the approximation ratio of this priority policy with respect to the optimal priority policy for arbitrary probability distributions of flow sizes (with finite first and second moments). Tighter upper bounds are obtained for some specific distributions. Extensive numerical results suggest that performance of the proposed policy is much better than the upper bound.</description>
      <guid isPermaLink="false">oai:arXiv.org:2504.00628v1</guid>
      <category>cs.DC</category>
      <pubDate>Wed, 02 Apr 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <dc:creator>Olivier Brun, Balakrishna J. Prabhu</dc:creator>
    </item>
    <item>
      <title>Efficient Location-Based Service Discovery for IoT and Edge Computing in the 6G Era</title>
      <link>https://arxiv.org/abs/2504.00743</link>
      <description>arXiv:2504.00743v1 Announce Type: new 
Abstract: Efficient service discovery is a cornerstone of the rapidly expanding Internet of Things (IoT) and edge computing ecosystems, where low latency and localized service provisioning are critical. This paper proposes a novel location-based DNS (Domain Name System) method that leverages Location Resource Records (LOC RRs) to enhance service discovery. By embedding geographic data in DNS responses, the system dynamically allocates services to edge nodes based on user proximity, ensuring reduced latency and improved Quality of Service (QoS). Comprehensive evaluations demonstrate minimal computational overhead, with processing times below 1 ms, making the approach highly suitable for latency-sensitive applications. Furthermore, the proposed methodology aligns with emerging 6G standards, which promise sub-millisecond latency and robust connectivity. Future research will focus on real-world deployment, validating the approach in dynamic IoT environments. This work establishes a scalable, efficient, and practical framework for location-aware service discovery, providing a strong foundation for next-generation IoT and edge-computing solutions.</description>
      <guid isPermaLink="false">oai:arXiv.org:2504.00743v1</guid>
      <category>cs.DC</category>
      <pubDate>Wed, 02 Apr 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Kurt Horvath, Dragi Kimovski</dc:creator>
    </item>
    <item>
      <title>Towards a Decentralised Application-Centric Orchestration Framework in the Cloud-Edge Continuum</title>
      <link>https://arxiv.org/abs/2504.00761</link>
      <description>arXiv:2504.00761v1 Announce Type: new 
Abstract: The efficient management of complex distributed applications in the Cloud-Edge continuum, including their deployment on heterogeneous computing resources and run-time operations, presents significant challenges. Resource management solutions -- also called orchestrators -- play a pivotal role by automating and managing tasks such as resource discovery, optimisation, application deployment, and lifecycle management, whilst ensuring the desired system performance. This paper introduces Swarmchestrate, a decentralised, application-centric orchestration framework inspired by the self-organising principles of Swarms. Swarmchestrate addresses the end-to-end management of distributed applications, from submission to optimal resource allocation across cloud and edge providers, as well as dynamic reconfiguration. Our initial findings include the implementation of the application deployment phase within a Cloud-Edge simulation environment, demonstrating the potential of Swarmchestrate. The results offer valuable insight into the coordination of resource offerings between various providers and optimised resource allocation, providing a foundation for designing scalable and efficient infrastructures.</description>
      <guid isPermaLink="false">oai:arXiv.org:2504.00761v1</guid>
      <category>cs.DC</category>
      <category>cs.NE</category>
      <category>cs.NI</category>
      <pubDate>Wed, 02 Apr 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Amjad Ullah, Andras Markus, Hac{\i} \.Ismail Aslan, Tamas Kiss, Jozsef Kovacs, James Deslauriers, Amy L. Murphy, Yiming Wang Odej Kao</dc:creator>
    </item>
    <item>
      <title>Optimizing Resource Allocation and Energy Efficiency in Federated Fog Computing for IoT</title>
      <link>https://arxiv.org/abs/2504.00791</link>
      <description>arXiv:2504.00791v1 Announce Type: new 
Abstract: Fog computing significantly enhances the efficiency of IoT applications by providing computation, storage, and networking resources at the edge of the network. In this paper, we propose a federated fog computing framework designed to optimize resource management, minimize latency, and reduce energy consumption across distributed IoT environments. Our framework incorporates predictive scheduling, energy-aware resource allocation, and adaptive mobility management strategies. Experimental results obtained from extensive simulations using the OMNeT++ environment demonstrate that our federated approach outperforms traditional non-federated architectures in terms of resource utilization, latency, energy efficiency, task execution time, and scalability. These findings underline the suitability and effectiveness of the proposed framework for supporting sustainable and high-performance IoT services.</description>
      <guid isPermaLink="false">oai:arXiv.org:2504.00791v1</guid>
      <category>cs.DC</category>
      <pubDate>Wed, 02 Apr 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Syed Sarmad Shah, Anas Ali</dc:creator>
    </item>
    <item>
      <title>AutoAppendix: Towards one-click Reproduction of Computational Artifacts</title>
      <link>https://arxiv.org/abs/2504.00876</link>
      <description>arXiv:2504.00876v1 Announce Type: new 
Abstract: This report summarizes the findings of the AutoAppendix project, conducted during the UCSC OSPO Summer of Reproducibility 2024. The project involved a evaluation of reproducibility artifacts submitted to SC24, focusing on their deployability and robustness on the Chameleon Cloud platform. This technical report aims to inform and support the reproducibility community by sharing observed challenges, patterns, and best practices. Furthermore, we share templates developed for Chameleon Cloud's Jupyter interface that are intended to assist future authors and reviewers in streamlining artifact evaluation workflows.</description>
      <guid isPermaLink="false">oai:arXiv.org:2504.00876v1</guid>
      <category>cs.DC</category>
      <pubDate>Wed, 02 Apr 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Klaus Kra{\ss}nitzer</dc:creator>
    </item>
    <item>
      <title>Green computing toward SKA era with RICK</title>
      <link>https://arxiv.org/abs/2504.00959</link>
      <description>arXiv:2504.00959v1 Announce Type: new 
Abstract: Square Kilometer Array is expected to generate hundreds of petabytes of data per year, two orders of magnitude more than current radio interferometers. Data processing at this scale necessitates advanced High Performance Computing (HPC) resources. However, modern HPC platforms consume up to tens of M W , i.e. megawatts, and energy-to-solution in algorithms will become of utmost importance in the next future. In this work we study the trade-off between energy-to-solution and time-to-solution of our RICK code (Radio Imaging Code Kernels), which is a novel approach to implement the w-stacking algorithm designed to run on state-of-the-art HPC systems. The code can run on heterogeneous systems exploiting the accelerators. We did both single-node tests and multi-node tests with both CPU and GPU solutions, in order to study which one is the greenest and which one is the fastest. We then defined the green productivity, i.e. a quantity which relates energy-to-solution and time-to-solution in different code configurations compared to a reference one. Configurations with the highest green productivities are the most efficient ones. The tests have been run on the Setonix machine available at the Pawsey Supercomputing Research Centre (PSC) in Perth (WA), ranked as 28th in Top500 list, updated at June 2024.</description>
      <guid isPermaLink="false">oai:arXiv.org:2504.00959v1</guid>
      <category>cs.DC</category>
      <category>astro-ph.IM</category>
      <pubDate>Wed, 02 Apr 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Giovanni Lacopo, Claudio Gheller, Emanuele De Rubeis, Pascal Jahan Elahi, Maciej Cytowski, Luca Tornatore, Giuliano Taffoni, Ugo Varetto</dc:creator>
    </item>
    <item>
      <title>New Improvements in Solving Large LABS Instances Using Massively Parallelizable Memetic Tabu Search</title>
      <link>https://arxiv.org/abs/2504.00987</link>
      <description>arXiv:2504.00987v1 Announce Type: new 
Abstract: Low Autocorrelation Binary Sequences (LABS) is a particularly challenging binary optimization problem which quickly becomes intractable in finding the global optimum for problem sizes beyond 66. This aspect makes LABS appealing to use as a test-bed for meta-heuristic optimization solvers to target large problem sizes. In this work, we introduce a massively parallelized implementation of the memetic tabu search algorithm to tackle LABS problem for sizes up to 120. By effectively combining the block level and thread level parallelism framework within a single Nvidia-A100 GPU, and creating hyper optimized binary-valued data structures for shared memory among the blocks, we showcase up to 26 fold speedup compared to the analogous 16-core CPU implementation. Our implementation has also enabled us to find new LABS merit factor values for twelve different problem sizes between 92 and 118. Crucially, we also showcase improved values for two odd-sized problems {99, 107} whose previous best known results coincided with the provably optimal skew-symmetric search sequences. Consequently, our result highlights the importance of a focus on general-purpose solver to tackle LABS, since leveraging its skew-symmetry could lead to sub-optimal solutions.</description>
      <guid isPermaLink="false">oai:arXiv.org:2504.00987v1</guid>
      <category>cs.DC</category>
      <pubDate>Wed, 02 Apr 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Zhiwei Zhang, Jiayu Shen, Niraj Kumar, Marco Pistoia</dc:creator>
    </item>
    <item>
      <title>Dynamic hashtag recommendation in social media with trend shift detection and adaptation</title>
      <link>https://arxiv.org/abs/2504.00044</link>
      <description>arXiv:2504.00044v1 Announce Type: cross 
Abstract: The widespread use of social media platforms results in the generation of vast amounts of user-generated content, which requires efficient methods for categorization and search. Hashtag recommendation systems have emerged as a crucial tool for automatically suggesting relevant hashtags and improving content discoverability. However, existing static models struggle to adapt to the highly dynamic and real-time nature of social media conversations, where new hashtags emerge and existing ones undergo semantic shifts. To address these challenges, this paper presents H-ADAPTS (Hashtag recommendAtion by Detecting and adAPting to Trend Shifts), a BERT-based hashtag recommendation methodology that can detect and adapt to shifts in the main trends and topics underlying social media conversation. Our approach introduces a trend-aware detection mechanism to identify changes in hashtag usage, triggering efficient model adaptation on a (small) set of recent posts. The framework leverages Apache Storm for real-time stream processing, enabling scalable and fault-tolerant analysis of high-velocity social data. Experimental results on two real-world case studies, including the COVID-19 pandemic and the 2020 US presidential election, demonstrate the ability to maintain high recommendation accuracy by adapting to emerging trends. Our methodology significantly outperforms existing solutions, ensuring timely and relevant hashtag recommendations in dynamic environments.</description>
      <guid isPermaLink="false">oai:arXiv.org:2504.00044v1</guid>
      <category>cs.SI</category>
      <category>cs.CL</category>
      <category>cs.DC</category>
      <category>cs.NE</category>
      <pubDate>Wed, 02 Apr 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Riccardo Cantini, Fabrizio Marozzo, Alessio Orsino, Domenico Talia, Paolo Trunfio</dc:creator>
    </item>
    <item>
      <title>Rack Position Optimization in Large-Scale Heterogeneous Data Centers</title>
      <link>https://arxiv.org/abs/2504.00277</link>
      <description>arXiv:2504.00277v1 Announce Type: cross 
Abstract: As rapidly growing AI computational demands accelerate the need for new hardware installation and maintenance, this work explores optimal data center resource management by balancing operational efficiency with fault tolerance through strategic rack positioning considering diverse resources and locations. Traditional mixed-integer programming (MIP) approaches often struggle with scalability, while heuristic methods may result in significant sub-optimality. To address these issues, this paper presents a novel two-tier optimization framework using a high-level deep reinforcement learning (DRL) model to guide a low-level gradient-based heuristic for local search. The high-level DRL agent employs Leader Reward for optimal rack type ordering, and the low-level heuristic efficiently maps racks to positions, minimizing movement counts and ensuring fault-tolerant resource distribution. This approach allows scalability to over 100,000 positions and 100 rack types. Our method outperformed the gradient-based heuristic by 7\% on average and the MIP solver by over 30\% in objective value. It achieved a 100\% success rate versus MIP's 97.5\% (within a 20-minute limit), completing in just 2 minutes compared to MIP's 1630 minutes (i.e., almost 4 orders of magnitude improvement). Unlike the MIP solver, which showed performance variability under time constraints and high penalties, our algorithm consistently delivered stable, efficient results - an essential feature for large-scale data center management.</description>
      <guid isPermaLink="false">oai:arXiv.org:2504.00277v1</guid>
      <category>cs.AI</category>
      <category>cs.DC</category>
      <category>cs.LG</category>
      <category>cs.NI</category>
      <category>math.OC</category>
      <pubDate>Wed, 02 Apr 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Chang-Lin Chen, Jiayu Chen, Tian Lan, Zhaoxia Zhao, Hongbo Dong, Vaneet Aggarwal</dc:creator>
    </item>
    <item>
      <title>Carbon and Reliability-Aware Computing for Heterogeneous Data Centers</title>
      <link>https://arxiv.org/abs/2504.00518</link>
      <description>arXiv:2504.00518v1 Announce Type: cross 
Abstract: The rapid expansion of data centers (DCs) has intensified energy and carbon footprint, incurring a massive environmental computing cost. While carbon-aware workload migration strategies have been examined, existing approaches often overlook reliability metrics such as server lifetime degradation, and quality-of-service (QoS) that substantially affects both carbon and operational efficiency of DCs. Hence, this paper proposes a comprehensive optimization framework for spatio-temporal workload migration across distributed DCs that jointly minimizes operational and embodied carbon emissions while complying with service-level agreements (SLA). A key contribution is the development of an embodied carbon emission model based on servers' expected lifetime analysis, which explicitly considers server heterogeneity resulting from aging and utilization conditions. These issues are accommodated using new server dispatch strategies, and backup resource allocation model, accounting hardware, software and workload-induced failure. The overall model is formulated as a mixed-integer optimization problem with multiple linearization techniques to ensure computational tractability. Numerical case studies demonstrate that the proposed method reduces total carbon emissions by up to 21%, offering a pragmatic approach to sustainable DC operations.</description>
      <guid isPermaLink="false">oai:arXiv.org:2504.00518v1</guid>
      <category>eess.SY</category>
      <category>cs.CE</category>
      <category>cs.DC</category>
      <category>cs.PF</category>
      <category>cs.SY</category>
      <pubDate>Wed, 02 Apr 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Yichao Zhang, Yubo Song, Subham Sahoo</dc:creator>
    </item>
    <item>
      <title>EMO: Edge Model Overlays to Scale Model Size in Federated Learning</title>
      <link>https://arxiv.org/abs/2504.00726</link>
      <description>arXiv:2504.00726v1 Announce Type: cross 
Abstract: Federated Learning (FL) trains machine learning models on edge devices with distributed data. However, the computational and memory limitations of these devices restrict the training of large models using FL. Split Federated Learning (SFL) addresses this challenge by distributing the model across the device and server, but it introduces a tightly coupled data flow, leading to computational bottlenecks and high communication costs. We propose EMO as a solution to enable the training of large models in FL while mitigating the challenges of SFL. EMO introduces Edge Model Overlay(s) between the device and server, enabling the creation of a larger ensemble model without modifying the FL workflow. The key innovation in EMO is Augmented Federated Learning (AFL), which builds an ensemble model by connecting the original (smaller) FL model with model(s) trained in the overlay(s) to facilitate horizontal or vertical scaling. This is accomplished through three key modules: a hierarchical activation replay cache to decouple AFL from FL, a convergence-aware communication controller to optimize communication overhead, and an ensemble inference module. Evaluations on a real-world prototype show that EMO improves accuracy by up to 17.77% compared to FL, and reduces communication costs by up to 7.17x and decreases training time by up to 6.9x compared to SFL.</description>
      <guid isPermaLink="false">oai:arXiv.org:2504.00726v1</guid>
      <category>cs.LG</category>
      <category>cs.DC</category>
      <pubDate>Wed, 02 Apr 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Di Wu, Weibo He, Wanglei Feng, Zhenyu Wen, Bin Qian, Blesson Varghese</dc:creator>
    </item>
    <item>
      <title>Design, Implementation and Practical Energy-Efficiency Evaluation of a Blockchain Based Academic Credential Verification System for Low-Power Nodes</title>
      <link>https://arxiv.org/abs/2410.20605</link>
      <description>arXiv:2410.20605v2 Announce Type: replace 
Abstract: The educational system manages extensive documentation and paperwork, which can lead to human errors and sometimes abuse or fraud, such as the falsification of diplomas, certificates or other credentials. In fact, in the last years, multiple cases of fraud have been detected, which have a significant cost to society, since they harm the trustworthiness of certificates and academic institutions. To tackle such an issue, this article proposes a solution aimed at recording and verifying academic records through a decentralized application that is supported by a smart contract deployed in the Ethereum blockchain and by a decentralized storage system based on Inter-Planetary File System (IPFS). The proposed solution is evaluated in terms of performance and energy-efficiency, comparing the results obtained with a traditional Proof-of-Work (PoW) consensus protocol and the new Proof-of-Authority (PoA) protocol. The results shown in this paper indicate that the latter is clearly greener and demands less CPU load. Moreover, this article compares the performance of a traditional computer and two SBCs (a Raspberry Pi 4 and an Orange Pi One), showing that is possible to make use of the latter low-power devices to implement blockchain nodes but at the cost of higher response latency. Furthermore, the impact of Ethereum gas limit is evaluated, demonstrating its significant influence on the blockchain network performance. Thus, this article provides guidelines, useful practical evaluations and key findings that will help the next generation of green blockchain developers and researchers.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.20605v2</guid>
      <category>cs.DC</category>
      <category>cs.CR</category>
      <category>cs.CY</category>
      <category>cs.SY</category>
      <category>eess.SY</category>
      <pubDate>Wed, 02 Apr 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Gabriel Fern\'andez-Blanco, Iv\'an Froiz-M\'iguez, Paula Fraga-Lamas, Tiago M. Fern\'andez-Caram\'es</dc:creator>
    </item>
    <item>
      <title>A Performance Analysis of Task Scheduling for UQ Workflows on HPC Systems</title>
      <link>https://arxiv.org/abs/2503.22645</link>
      <description>arXiv:2503.22645v2 Announce Type: replace 
Abstract: Uncertainty Quantification (UQ) workloads are becoming increasingly common in science and engineering. They involve the submission of thousands or even millions of similar tasks with potentially unpredictable runtimes, where the total number is usually not known a priori. A static one-size-fits-all batch script would likely lead to suboptimal scheduling, and native schedulers installed on High Performance Computing (HPC) systems such as SLURM often struggle to efficiently handle such workloads. In this paper, we introduce a new load balancing approach suitable for UQ workflows. To demonstrate its efficiency in a real-world setting, we focus on the GS2 gyrokinetic plasma turbulence simulator. Individual simulations can be computationally demanding, with runtimes varying significantly-from minutes to hours-depending on the high-dimensional input parameters. Our approach uses UQ and Modelling Bridge, which offers a language-agnostic interface to a simulation model, combined with HyperQueue which works alongside the native scheduler. In particular, deploying this framework on HPC systems does not require system-level changes. We benchmark our proposed framework against a standalone SLURM approach using GS2 and a Gaussian Process surrogate thereof. Our results demonstrate a reduction in scheduling overhead by up to three orders of magnitude and a maximum reduction of 38% in CPU time for long-running simulations compared to the naive SLURM approach, while making no assumptions about the job submission patterns inherent to UQ workflows.</description>
      <guid isPermaLink="false">oai:arXiv.org:2503.22645v2</guid>
      <category>cs.DC</category>
      <pubDate>Wed, 02 Apr 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Chung Ming Loi, Anne Reinarz, Mikkel Lykkegaard, William Hornsby, James Buchanan, Linus Seelinger</dc:creator>
    </item>
    <item>
      <title>FedORGP: Guiding Heterogeneous Federated Learning with Orthogonality Regularization on Global Prototypes</title>
      <link>https://arxiv.org/abs/2502.16119</link>
      <description>arXiv:2502.16119v2 Announce Type: replace-cross 
Abstract: Federated Learning (FL) has emerged as an essential framework for distributed machine learning, especially with its potential for privacy-preserving data processing. However, existing FL frameworks struggle to address statistical and model heterogeneity, which severely impacts model performance. While Heterogeneous Federated Learning (HtFL) introduces prototype-based strategies to address the challenges, current approaches face limitations in achieving optimal separation of prototypes. This paper presents FedORGP, a novel HtFL algorithm designed to improve global prototype separation through orthogonality regularization, which not only encourages intra-class prototype similarity but also significantly expands the inter-class angular separation. With the guidance of the global prototype, each client keeps its embeddings aligned with the corresponding prototype in the feature space, promoting directional independence that integrates seamlessly with the cross-entropy (CE) loss. We provide theoretical proof of FedORGP's convergence under non-convex conditions. Extensive experiments demonstrate that FedORGP outperforms seven state-of-the-art baselines, achieving up to 10.12\% accuracy improvement in scenarios where statistical and model heterogeneity coexist.</description>
      <guid isPermaLink="false">oai:arXiv.org:2502.16119v2</guid>
      <category>cs.LG</category>
      <category>cs.DC</category>
      <pubDate>Wed, 02 Apr 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Fucheng Guo, Zeyu Luan, Qing Li, Dan Zhao, Yong Jiang</dc:creator>
    </item>
  </channel>
</rss>
