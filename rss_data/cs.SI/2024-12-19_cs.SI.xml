<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>cs.SI updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/cs.SI</link>
    <description>cs.SI updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/cs.SI" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Fri, 20 Dec 2024 02:54:21 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Thu, 19 Dec 2024 00:00:00 -0500</pubDate>
    <skipDays>
      <day>Sunday</day>
      <day>Saturday</day>
    </skipDays>
    <item>
      <title>Political Fact-Checking Efforts are Constrained by Deficiencies in Coverage, Speed, and Reach</title>
      <link>https://arxiv.org/abs/2412.13280</link>
      <description>arXiv:2412.13280v1 Announce Type: new 
Abstract: Fact-checking has been promoted as a key method for combating political misinformation. Comparing the spread of election-related misinformation narratives along with their relevant political fact-checks, this study provides the most comprehensive assessment to date of the real-world limitations faced by political fact-checking efforts. To examine barriers to impact, this study extends recent work from laboratory and experimental settings to the wider online information ecosystem present during the 2022 U.S. midterm elections. From analyses conducted within this context, we find that fact-checks as currently developed and distributed are severely inhibited in election contexts by constraints on their i. coverage, ii. speed, and, iii. reach. Specifically, we provide evidence that fewer than half of all prominent election-related misinformation narratives were fact-checked. Within the subset of fact-checked claims, we find that the median fact-check was released a full four days after the initial appearance of a narrative. Using network analysis to estimate user partisanship and dynamics of information spread, we additionally find evidence that fact-checks make up less than 1.2\% of narrative conversations and that even when shared, fact-checks are nearly always shared within,rather than between, partisan communities. Furthermore, we provide empirical evidence which runs contrary to the assumption that misinformation moderation is politically biased against the political right. In full, through this assessment of the real-world influence of political fact-checking efforts, our findings underscore how limitations in coverage, speed, and reach necessitate further examination of the potential use of fact-checks as the primary method for combating the spread of political misinformation.</description>
      <guid isPermaLink="false">oai:arXiv.org:2412.13280v1</guid>
      <category>cs.SI</category>
      <category>cs.CY</category>
      <pubDate>Thu, 19 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Morgan Wack, Kayla Duskin, Damian Hodel</dc:creator>
    </item>
    <item>
      <title>BotSim: LLM-Powered Malicious Social Botnet Simulation</title>
      <link>https://arxiv.org/abs/2412.13420</link>
      <description>arXiv:2412.13420v1 Announce Type: new 
Abstract: Social media platforms like X(Twitter) and Reddit are vital to global communication. However, advancements in Large Language Model (LLM) technology give rise to social media bots with unprecedented intelligence. These bots adeptly simulate human profiles, conversations, and interactions, disseminating large amounts of false information and posing significant challenges to platform regulation. To better understand and counter these threats, we innovatively design BotSim, a malicious social botnet simulation powered by LLM. BotSim mimics the information dissemination patterns of real-world social networks, creating a virtual environment composed of intelligent agent bots and real human users. In the temporal simulation constructed by BotSim, these advanced agent bots autonomously engage in social interactions such as posting and commenting, effectively modeling scenarios of information flow and user interaction. Building on the BotSim framework, we construct a highly human-like, LLM-driven bot dataset called BotSim-24 and benchmark multiple bot detection strategies against it. The experimental results indicate that detection methods effective on traditional bot datasets perform worse on BotSim-24, highlighting the urgent need for new detection strategies to address the cybersecurity threats posed by these advanced bots.</description>
      <guid isPermaLink="false">oai:arXiv.org:2412.13420v1</guid>
      <category>cs.SI</category>
      <pubDate>Thu, 19 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Boyu Qiao, Kun Li, Wei Zhou, Shilong Li, Qianqian Lu, Songlin Hu</dc:creator>
    </item>
    <item>
      <title>Emotional Sequential Influence Modeling on False Information</title>
      <link>https://arxiv.org/abs/2412.13668</link>
      <description>arXiv:2412.13668v1 Announce Type: new 
Abstract: The extensive dissemination of false information in social networks affects netizens social lives, morals, and behaviours. When a neighbour expresses strong emotions (e.g., fear, anger, excitement) based on a false statement, these emotions can be transmitted to others, especially through interactions on social media. Therefore, exploring the mechanism that explains how an individuals emotions change under the influence of a neighbours false statement is a practically important task. In this work, we systematically examining the publics personal, interpersonal, and historical emotional influence based on social context, content, and emotional based features. The contribution of this paper is to build an emotionally infused model called the Emotional based User Sequential Influence Model(EUSIM) to understand users temporal emotional propagation patterns and predict future emotions against false information.</description>
      <guid isPermaLink="false">oai:arXiv.org:2412.13668v1</guid>
      <category>cs.SI</category>
      <pubDate>Thu, 19 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-sa/4.0/</dc:rights>
      <arxiv:DOI>10.1007/978-3-031-77731-8_9</arxiv:DOI>
      <dc:creator>Debashis Naskar, Subhashis Das, Sara Rodriguez Gonzalez</dc:creator>
    </item>
    <item>
      <title>Modality-Independent Graph Neural Networks with Global Transformers for Multimodal Recommendation</title>
      <link>https://arxiv.org/abs/2412.13994</link>
      <description>arXiv:2412.13994v1 Announce Type: new 
Abstract: Multimodal recommendation systems can learn users' preferences from existing user-item interactions as well as the semantics of multimodal data associated with items. Many existing methods model this through a multimodal user-item graph, approaching multimodal recommendation as a graph learning task. Graph Neural Networks (GNNs) have shown promising performance in this domain. Prior research has capitalized on GNNs' capability to capture neighborhood information within certain receptive fields (typically denoted by the number of hops, $K$) to enrich user and item semantics. We observe that the optimal receptive fields for GNNs can vary across different modalities. In this paper, we propose GNNs with Modality-Independent Receptive Fields, which employ separate GNNs with independent receptive fields for different modalities to enhance performance. Our results indicate that the optimal $K$ for certain modalities on specific datasets can be as low as 1 or 2, which may restrict the GNNs' capacity to capture global information. To address this, we introduce a Sampling-based Global Transformer, which utilizes uniform global sampling to effectively integrate global information for GNNs. We conduct comprehensive experiments that demonstrate the superiority of our approach over existing methods. Our code is publicly available at https://github.com/CrawlScript/MIG-GT.</description>
      <guid isPermaLink="false">oai:arXiv.org:2412.13994v1</guid>
      <category>cs.SI</category>
      <category>cs.LG</category>
      <pubDate>Thu, 19 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Jun Hu, Bryan Hooi, Bingsheng He, Yinwei Wei</dc:creator>
    </item>
    <item>
      <title>Evolution of the "long tail" concept for scientific data</title>
      <link>https://arxiv.org/abs/2412.13307</link>
      <description>arXiv:2412.13307v1 Announce Type: cross 
Abstract: This review paper explores the evolution of discussions about "long-tail" scientific data in the scholarly literature. The "long-tail" concept, originally used to explain trends in digital consumer goods, was first applied to scientific data in 2007 to refer to a vast array of smaller, heterogeneous data collections that cumulatively represent a substantial portion of scientific knowledge. However, these datasets, often referred to as "long-tail data," are frequently mismanaged or overlooked due to inadequate data management practices and institutional support. This paper examines the changing landscape of discussions about long-tail data over time, situated within broader ecosystems of research data management and the natural interplay between "big" and "small" data. The review also bridges discussions on data curation in Library &amp; Information Science (LIS) and domain-specific contexts, contributing to a more comprehensive understanding of the long-tail concept's utility for effective data management outcomes. The review aims to provide a more comprehensive understanding of this concept, its terminological diversity in the literature, and its utility for guiding data management, overall informing current and future information science research and practice.</description>
      <guid isPermaLink="false">oai:arXiv.org:2412.13307v1</guid>
      <category>cs.DL</category>
      <category>cs.SI</category>
      <pubDate>Thu, 19 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <arxiv:DOI>10.1002/asi.24967</arxiv:DOI>
      <arxiv:journal_reference>Journal of the Association for Information Science &amp; Technology, 1-20 (2024)</arxiv:journal_reference>
      <dc:creator>Gretchen R. Stahlman, Inna Kouper</dc:creator>
    </item>
    <item>
      <title>Toward an Insider Threat Education Platform: A Theoretical Literature Review</title>
      <link>https://arxiv.org/abs/2412.13446</link>
      <description>arXiv:2412.13446v1 Announce Type: cross 
Abstract: Insider threats (InTs) within organizations are small in number but have a disproportionate ability to damage systems, information, and infrastructure. Existing InT research studies the problem from psychological, technical, and educational perspectives. Proposed theories include research on psychological indicators, machine learning, user behavioral log analysis, and educational methods to teach employees recognition and mitigation techniques. Because InTs are a human problem, training methods that address InT detection from a behavioral perspective are critical. While numerous technological and psychological theories exist on detection, prevention, and mitigation, few training methods prioritize psychological indicators. This literature review studied peer-reviewed, InT research organized by subtopic and extracted critical theories from psychological, technical, and educational disciplines. In doing so, this is the first study to comprehensively organize research across all three approaches in a manner which properly informs the development of an InT education platform.</description>
      <guid isPermaLink="false">oai:arXiv.org:2412.13446v1</guid>
      <category>cs.CR</category>
      <category>cs.AI</category>
      <category>cs.CY</category>
      <category>cs.HC</category>
      <category>cs.SI</category>
      <pubDate>Thu, 19 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Haywood Gelman, John D. Hastings, David Kenley, Eleanor Loiacono</dc:creator>
    </item>
    <item>
      <title>Polaris: Sampling from the Multigraph Configuration Model with Prescribed Color Assortativity</title>
      <link>https://arxiv.org/abs/2409.01363</link>
      <description>arXiv:2409.01363v2 Announce Type: replace 
Abstract: We introduce Polaris, a network null model for colored multi-graphs that preserves the Joint Color Matrix. Polaris is specifically designed for studying network polarization, where vertices belong to a side in a debate or a partisan group, represented by a vertex color, and relations have different strengths, represented by an integer-valued edge multiplicity. The key feature of Polaris is preserving the Joint Color Matrix (JCM) of the multigraph, which specifies the number of edges connecting vertices of any two given colors. The JCM is the basic property that determines color assortativity, a fundamental aspect in studying homophily and segregation in polarized networks. By using Polaris, network scientists can test whether a phenomenon is entirely explained by the JCM of the observed network or whether other phenomena might be at play. Technically, our null model is an extension of the configuration model: an ensemble of colored multigraphs characterized by the same degree sequence and the same JCM. To sample from this ensemble, we develop a suite of Markov Chain Monte Carlo algorithms, collectively named Polaris-*. It includes Polaris-B, an adaptation of a generic Metropolis-Hastings algorithm, and Polaris-C, a faster, specialized algorithm with higher acceptance probabilities. This new null model and the associated algorithms provide a more nuanced toolset for examining polarization in social networks, thus enabling statistically sound conclusions.</description>
      <guid isPermaLink="false">oai:arXiv.org:2409.01363v2</guid>
      <category>cs.SI</category>
      <pubDate>Thu, 19 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <arxiv:DOI>10.1145/3701551.3703560</arxiv:DOI>
      <dc:creator>Giulia Preti, Matteo Riondato, Aristides Gionis, Gianmarco De Francisci Morales</dc:creator>
    </item>
    <item>
      <title>Two Layer Walk: A Community-Aware Graph Embedding</title>
      <link>https://arxiv.org/abs/2412.12933</link>
      <description>arXiv:2412.12933v2 Announce Type: replace 
Abstract: Community structures are critical for understanding the mesoscopic organization of networks, bridging local and global patterns. While methods such as DeepWalk and node2vec capture local positional information through random walks, they fail to preserve community structures. Other approaches like modularized nonnegative matrix factorization and evolutionary algorithms address this gap but are computationally expensive and unsuitable for large-scale networks. To overcome these limitations, we propose Two Layer Walk (TLWalk), a novel graph embedding algorithm that incorporates hierarchical community structures. TLWalk balances intra- and inter-community relationships through a community-aware random walk mechanism without requiring additional parameters. Theoretical analysis demonstrates that TLWalk effectively mitigates locality bias. Experiments on benchmark datasets show that TLWalk outperforms state-of-the-art methods, achieving up to 3.2% accuracy gains for link prediction tasks. By encoding dense local and sparse global structures, TLWalk proves robust and scalable across diverse networks, offering an efficient solution for network analysis.</description>
      <guid isPermaLink="false">oai:arXiv.org:2412.12933v2</guid>
      <category>cs.SI</category>
      <category>cs.AI</category>
      <pubDate>Thu, 19 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>He Yu, Jing Liu</dc:creator>
    </item>
    <item>
      <title>Clique and cycle frequencies in a sparse random graph model with overlapping communities</title>
      <link>https://arxiv.org/abs/1911.12827</link>
      <description>arXiv:1911.12827v4 Announce Type: replace-cross 
Abstract: A statistical network model with overlapping communities can be generated as a superposition of mutually independent random graphs of varying size. The model is parameterized by the number of nodes, the number of communities, and the joint distribution of the community size and the edge probability. This model admits sparse parameter regimes with power-law limiting degree distributions and non-vanishing clustering coefficients. This article presents large-scale approximations of clique and cycle frequencies for graph samples generated by the model, which are valid for regimes with unbounded numbers of overlapping communities. Our results reveal the growth rates of these subgraph frequencies and show that their theoretical densities can be reliably estimated from data.</description>
      <guid isPermaLink="false">oai:arXiv.org:1911.12827v4</guid>
      <category>math.PR</category>
      <category>cs.SI</category>
      <category>math.ST</category>
      <category>stat.TH</category>
      <pubDate>Thu, 19 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <arxiv:DOI>10.1080/15326349.2024.2313987</arxiv:DOI>
      <arxiv:journal_reference>Stochastic Models 40(4): 634-658 (2024)</arxiv:journal_reference>
      <dc:creator>Tommi Gr\"ohn, Joona Karjalainen, Lasse Leskel\"a</dc:creator>
    </item>
    <item>
      <title>Neural Temporal Point Processes for Forecasting Directional Relations in Evolving Hypergraphs</title>
      <link>https://arxiv.org/abs/2301.12210</link>
      <description>arXiv:2301.12210v3 Announce Type: replace-cross 
Abstract: Forecasting relations between entities is paramount in the current era of data and AI. However, it is often overlooked that real-world relationships are inherently directional, involve more than two entities, and can change with time. In this paper, we provide a comprehensive solution to the problem of forecasting directional relations in a general setting, where relations are higher-order, i.e., directed hyperedges in a hypergraph. This problem has not been previously explored in the existing literature. The primary challenge in solving this problem is that the number of possible hyperedges is exponential in the number of nodes at each event time. To overcome this, we propose a sequential generative approach that segments the forecasting process into multiple stages, each contingent upon the preceding stages, thereby reducing the search space involved in predictions of hyperedges. The first stage involves a temporal point process-based node event forecasting module that identifies the subset of nodes involved in an event. The second stage is a candidate generation module that predicts hyperedge sizes and adjacency vectors for nodes observing events. The final stage is a directed hyperedge predictor that identifies the truth by searching over the set of candidate hyperedges. To validate the effectiveness of our model, we compiled five datasets and conducted an extensive empirical study to assess each downstream task. Our proposed method achieves a performance gain of 32\% and 41\% compared to the state-of-the-art pairwise and hyperedge event forecasting models, respectively, for the event type prediction.</description>
      <guid isPermaLink="false">oai:arXiv.org:2301.12210v3</guid>
      <category>cs.LG</category>
      <category>cs.AI</category>
      <category>cs.SI</category>
      <pubDate>Thu, 19 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Tony Gracious, Arman Gupta, Ambedkar Dukkipati</dc:creator>
    </item>
    <item>
      <title>Semiotics Networks Representing Perceptual Inference</title>
      <link>https://arxiv.org/abs/2310.05212</link>
      <description>arXiv:2310.05212v5 Announce Type: replace-cross 
Abstract: Every day, humans perceive objects and communicate these perceptions through various channels. In this paper, we present a computational model designed to track and simulate the perception of objects, as well as their representations as conveyed in communication.
  We delineate two fundamental components of our internal representation, termed "observed" and "seen", which we correlate with established concepts in computer vision, namely encoding and decoding. These components are integrated into semiotic networks, which simulate perceptual inference of object perception and human communication.
  Our model of object perception by a person allows us to define object perception by {\em a network}. We demonstrate this with an example of an image baseline classifier by constructing a new network that includes the baseline classifier and an additional layer. This layer produces the images "perceived" by the entire network, transforming it into a perceptualized image classifier. This facilitates visualization of the acquired network.
  Within our network, the image representations become more efficient for classification tasks when they are assembled and randomized. In our experiments, the perceptualized network outperformed the baseline classifier on MNIST training databases consisting of a restricted number of images.
  Our model is not limited to persons and can be applied to any system featuring a loop involving the processing from "internal" to "external" representations.</description>
      <guid isPermaLink="false">oai:arXiv.org:2310.05212v5</guid>
      <category>cs.AI</category>
      <category>cs.CV</category>
      <category>cs.SI</category>
      <pubDate>Thu, 19 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>David Kupeev, Eyal Nitzany</dc:creator>
    </item>
    <item>
      <title>Deep Representation Learning for Forecasting Recursive and Multi-Relational Events in Temporal Networks</title>
      <link>https://arxiv.org/abs/2404.17943</link>
      <description>arXiv:2404.17943v2 Announce Type: replace-cross 
Abstract: Understanding relations arising out of interactions among entities can be very difficult, and predicting them is even more challenging. This problem has many applications in various fields, such as financial networks and e-commerce. These relations can involve much more complexities than just involving more than two entities. One such scenario is evolving recursive relations between multiple entities, and so far, this is still an open problem. This work addresses the problem of forecasting higher-order interaction events that can be multi-relational and recursive. We pose the problem in the framework of representation learning of temporal hypergraphs that can capture complex relationships involving multiple entities. The proposed model, \textit{Relational Recursive Hyperedge Temporal Point Process} (RRHyperTPP) uses an encoder that learns a dynamic node representation based on the historical interaction patterns and then a hyperedge link prediction-based decoder to model the occurrence of interaction events. These learned representations are then used for downstream tasks involving forecasting the type and time of interactions. The main challenge in learning from hyperedge events is that the number of possible hyperedges grows exponentially with the number of nodes in the network. This will make the computation of negative log-likelihood of the temporal point process expensive, as the calculation of survival function requires a summation over all possible hyperedges. In our work, we develop a noise contrastive estimation method to learn the parameters of our model, and we have experimentally shown that our models perform better than previous state-of-the-art methods for interaction forecasting.</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.17943v2</guid>
      <category>cs.LG</category>
      <category>cs.AI</category>
      <category>cs.SI</category>
      <pubDate>Thu, 19 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Tony Gracious, Ambedkar Dukkipati</dc:creator>
    </item>
  </channel>
</rss>
