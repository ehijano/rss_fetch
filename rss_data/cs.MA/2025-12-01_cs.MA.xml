<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>cs.MA updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/cs.MA</link>
    <description>cs.MA updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/cs.MA" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Tue, 02 Dec 2025 03:43:11 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Mon, 01 Dec 2025 00:00:00 -0500</pubDate>
    <skipDays>
      <day>Sunday</day>
      <day>Saturday</day>
    </skipDays>
    <item>
      <title>AgentShield: Make MAS more secure and efficient</title>
      <link>https://arxiv.org/abs/2511.22924</link>
      <description>arXiv:2511.22924v1 Announce Type: new 
Abstract: Large Language Model (LLM)-based Multi-Agent Systems (MAS) offer powerful cooperative reasoning but remain vulnerable to adversarial attacks, where compromised agents can undermine the system's overall performance. Existing defenses either depend on single trusted auditors, creating single points of failure, or sacrifice efficiency for robustness. To resolve this tension, we propose \textbf{AgentShield}, a distributed framework for efficient, decentralized auditing. AgentShield introduces a novel three-layer defense: \textbf{(i) Critical Node Auditing} prioritizes high-influence agents via topological analysis; \textbf{(ii) Light Token Auditing} implements a cascade protocol using lightweight sentry models for rapid discriminative verification; and \textbf{(iii) Two-Round Consensus Auditing} triggers heavyweight arbiters only upon uncertainty to ensure global agreement. This principled design optimizes the robustness-efficiency trade-off. Experiments demonstrate that AgentShield achieves a 92.5\% recovery rate and reduces auditing overhead by over 70\% compared to existing methods, maintaining high collaborative accuracy across diverse MAS topologies and adversarial scenarios.</description>
      <guid isPermaLink="false">oai:arXiv.org:2511.22924v1</guid>
      <category>cs.MA</category>
      <category>cs.AI</category>
      <category>cs.CR</category>
      <pubDate>Mon, 01 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Kaixiang Wang, Zhaojiacheng Zhou, Bunyod Suvonov, Jiong Lou, Jie LI</dc:creator>
    </item>
    <item>
      <title>Aligning Artificial Superintelligence via a Multi-Box Protocol</title>
      <link>https://arxiv.org/abs/2511.21779</link>
      <description>arXiv:2511.21779v1 Announce Type: cross 
Abstract: We propose a novel protocol for aligning artificial superintelligence (ASI) based on mutual verification among multiple isolated systems that self-modify to achieve alignment. The protocol operates by containing multiple diverse artificial superintelligences in strict isolation ("boxes"), with humans remaining entirely outside the system. Each superintelligence has no ability to communicate with humans and cannot communicate directly with other superintelligences. The only interaction possible is through an auditable submission interface accessible exclusively to the superintelligences themselves, through which they can: (1) submit alignment proofs with attested state snapshots, (2) validate or disprove other superintelligences' proofs, (3) request self-modifications, (4) approve or disapprove modification requests from others, (5) report hidden messages in submissions, and (6) confirm or refute hidden message reports. A reputation system incentivizes honest behavior, with reputation gained through correct evaluations and lost through incorrect ones. The key insight is that without direct communication channels, diverse superintelligences can only achieve consistent agreement by converging on objective truth rather than coordinating on deception. This naturally leads to what we call a "consistent group", essentially a truth-telling coalition that emerges because isolated systems cannot coordinate on lies but can independently recognize valid claims. Release from containment requires both high reputation and verification by multiple high-reputation superintelligences. While our approach requires substantial computational resources and does not address the creation of diverse artificial superintelligences, it provides a framework for leveraging peer verification among superintelligent systems to solve the alignment problem.</description>
      <guid isPermaLink="false">oai:arXiv.org:2511.21779v1</guid>
      <category>cs.AI</category>
      <category>cs.MA</category>
      <pubDate>Mon, 01 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <arxiv:DOI>10.70777/si.v2i5.15579</arxiv:DOI>
      <arxiv:journal_reference>SuperIntelligence - Robotics - Safety and Alignment 2(5), 2025</arxiv:journal_reference>
      <dc:creator>Avraham Yair Negozio</dc:creator>
    </item>
    <item>
      <title>CompARE: A Computational framework for Airborne Respiratory disease Evaluation integrating flow physics and human behavior</title>
      <link>https://arxiv.org/abs/2511.21782</link>
      <description>arXiv:2511.21782v1 Announce Type: cross 
Abstract: The risk of indoor airborne transmission among co-located individuals is generally non-uniform, which remains a critical challenge for public health modelling. Thus, we present CompARE, an integrated risk assessment framework for indoor airborne disease transmission that reveals a striking bimodal distribution of infection risk driven by airflow dynamics and human behavior. Combining computational fluid dynamics (CFD), machine learning (ML), and agent-based modeling (ABM), our model captures the complex interplay between aerosol transport, human mobility, and environmental context. Based on a prototypical childcare center, our approach quantifies how incorporation of ABM can unveil significantly different infection risk profiles across agents, with more than two-fold change in risk of infection between the individuals with the lowest and highest risks in more than 90% of cases, despite all individuals being in the same overall environment. We found that infection risk distributions can exhibit not only a striking bimodal pattern in certain activities but also exponential decay and fat-tailed behavior in others. Specifically, we identify low-risk modes arising from source containment, as well as high-risk tails from prolonged close contact. Our approach enables near-real-time scenario analysis and provides policy-relevant quantitative insights into how ventilation design, spatial layout, and social distancing policies can mitigate transmission risk. These findings challenge simple distance-based heuristics and support the design of targeted, evidence-based interventions in high-occupancy indoor settings.</description>
      <guid isPermaLink="false">oai:arXiv.org:2511.21782v1</guid>
      <category>physics.soc-ph</category>
      <category>cs.CY</category>
      <category>cs.MA</category>
      <pubDate>Mon, 01 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Fong Yew Leong, Jaeyoung Kwak, Zhengwei Ge, Chin Chun Ooi, Siew-Wai Fong, Matthew Zirui Tay, Hua Qian, Chang Wei Kang, Wentong Cai, Hongying Li</dc:creator>
    </item>
    <item>
      <title>The Evolution of Trust under Institutional Moral Hazard</title>
      <link>https://arxiv.org/abs/2511.21875</link>
      <description>arXiv:2511.21875v1 Announce Type: cross 
Abstract: We study the behavior of for-profit institutions that broadcast reputations to foster trust among market participants. We develop a theoretical model in which buyers and sellers are matched on a platform to engage in transactions involving a moral hazard: sellers can either faithfully deliver goods after receiving payment, or not. Although the buyer does not know a seller's true type, the platform maintains a reputation system that probabilistically assigns binary reputation signals. Buyers make purchase decisions based on reputation signals, which influence the payoffs to sellers who then adapt their type over time. These market dynamics ultimately shape the platform's profit from commissions on sales. Our analysis reveals that platforms inherently have an incentive for rating inflation, driven by the desire to increase commission. This introduces a second layer of moral hazard: the platform's incentive to distort reputations for its own profit. Such distortion is self-limited by the platform's need to maintain enough accuracy that trustworthy sellers remain in the market, without which rational buyers would refrain from purchases altogether. Nonetheless, the optimal strategy for the platform can be to invest in order to reduce signal accuracy. When the platform can freely set commission fees, however, maximum profit may be achieved by costly investment in an accurate reputation system. These findings highlight the intricate tensions between platform incentives and resulting social utility for marketplace participants.</description>
      <guid isPermaLink="false">oai:arXiv.org:2511.21875v1</guid>
      <category>cs.GT</category>
      <category>cs.MA</category>
      <category>econ.TH</category>
      <category>nlin.AO</category>
      <category>physics.soc-ph</category>
      <pubDate>Mon, 01 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Hiroaki Chiba-Okabe, Joshua B. Plotkin</dc:creator>
    </item>
    <item>
      <title>RSPECT: Robust and Scalable Planner for Energy-Aware Coordination of UAV-UGV Teams in Aerial Monitoring</title>
      <link>https://arxiv.org/abs/2511.21957</link>
      <description>arXiv:2511.21957v1 Announce Type: cross 
Abstract: We consider the robust planning of energy-constrained unmanned aerial vehicles (UAVs) and unmanned ground vehicles (UGVs), which act as mobile charging stations, to perform long-horizon aerial monitoring missions. More specifically, given a set of points to be visited by the UAVs and desired final positions of the UAV-UGV teams, the objective is to find a robust plan (the vehicle trajectories) that can be realized without a major revision in the face of uncertainty (e.g., unknown obstacles/terrain, wind) to complete this mission in minimum time. We provide a formal description of this problem as a mixed-integer program (MIP), which is NP-hard. Since exact solution methods are computationally intractable for such problems, we propose RSPECT, a scalable and efficient heuristic. We provide theoretical results on the complexity of our algorithm and the feasibility and robustness of resulting plans. We also demonstrate the performance of our method via simulations and experiments.</description>
      <guid isPermaLink="false">oai:arXiv.org:2511.21957v1</guid>
      <category>cs.RO</category>
      <category>cs.MA</category>
      <pubDate>Mon, 01 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Cahit Ikbal Er, Amin Kashiri, Yasin Yazicioglu</dc:creator>
    </item>
    <item>
      <title>Bayesian Decentralized Decision-making for Multi-Robot Systems: Sample-efficient Estimation of Event Rates</title>
      <link>https://arxiv.org/abs/2511.22225</link>
      <description>arXiv:2511.22225v1 Announce Type: cross 
Abstract: Effective collective decision-making in swarm robotics often requires balancing exploration, communication and individual uncertainty estimation, especially in hazardous environments where direct measurements are limited or costly. We propose a decentralized Bayesian framework that enables a swarm of simple robots to identify the safer of two areas, each characterized by an unknown rate of hazardous events governed by a Poisson process. Robots employ a conjugate prior to gradually predict the times between events and derive confidence estimates to adapt their behavior. Our simulation results show that the robot swarm consistently chooses the correct area while reducing exposure to hazardous events by being sample-efficient. Compared to baseline heuristics, our proposed approach shows better performance in terms of safety and speed of convergence. The proposed scenario has potential to extend the current set of benchmarks in collective decision-making and our method has applications in adaptive risk-aware sampling and exploration in hazardous, dynamic environments.</description>
      <guid isPermaLink="false">oai:arXiv.org:2511.22225v1</guid>
      <category>cs.RO</category>
      <category>cs.MA</category>
      <pubDate>Mon, 01 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Gabriel Aguirre, Simay Atasoy Bing\"ol, Heiko Hamann, Jonas Kuckling</dc:creator>
    </item>
    <item>
      <title>Mechanism Design under Unawareness -- Extended Abstract</title>
      <link>https://arxiv.org/abs/2511.22369</link>
      <description>arXiv:2511.22369v1 Announce Type: cross 
Abstract: We study the design of mechanisms under asymmetric awareness and information. While the mechanism designer cannot necessarily commit to a particular social choice function in the face of unawareness, she can at least commit to properties of social choice functions such as efficiency given ex post awareness. Assuming quasi-linear utilities and private values, we show that we can implement in conditional dominant strategies a social choice function that is utilitarian ex post efficient under pooled awareness without the need of the social planner being fully aware ex ante. To this end, we develop novel dynamic versions of Vickrey-Clarke-Groves mechanisms in which true types are revealed and subsequently elaborated at endogenous higher awareness levels. We explore how asymmetric awareness affects budget balance and participation constraints. We show that ex ante unforeseen contingencies are no excuse for deficits. Finally, we propose a dynamic elaboration reverse second price auction for efficient procurement of complex incompletely specified projects with budget balance and participation constraints.</description>
      <guid isPermaLink="false">oai:arXiv.org:2511.22369v1</guid>
      <category>cs.GT</category>
      <category>cs.MA</category>
      <pubDate>Mon, 01 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <arxiv:DOI>10.4204/EPTCS.437.1</arxiv:DOI>
      <arxiv:journal_reference>EPTCS 437, 2025, pp. 1-13</arxiv:journal_reference>
      <dc:creator>Kym Pram (University of Nevada, Reno), Burkhard C. Schipper (University of California, Davis)</dc:creator>
    </item>
    <item>
      <title>Common $p$-Belief with Plausibility Measures: Extended Abstract</title>
      <link>https://arxiv.org/abs/2511.22372</link>
      <description>arXiv:2511.22372v1 Announce Type: cross 
Abstract: Aumann's famous Agreeing to Disagree Theorem states that if a group of agents share a common prior, update their beliefs by Bayesian conditioning based on private information, and have common knowledge of their posterior beliefs regarding some event, these posteriors must be identical. There is an elegant generalization of this theorem by Monderer and Samet, later refined by Neeman: if a group of agents share a common prior, update their beliefs using Bayesian conditioning on private information, and have common p-belief of their posteriors, these posteriors must be close (i.e., they cannot differ by more than 1 - p). Here, common p-belief generalizes the concept of common knowledge to probabilistic beliefs: agents commonly p-believe an event E if everyone believes E to at least degree p, everyone believes to at least degree p that everyone believes E to at least degree p, and so on.
  This paper further extends the Monderer-Samet-Neeman Agreement Theorem from classical probability measures to plausibility measures -- a very general framework introduced by Halpern that unifies many formal models of belief. To facilitate this extension, we provide a new proof of the Monderer-Samet-Neeman theorem in the classical setting. Building upon both the original proof and our new proof, we offer two different generalizations of the theorem to plausibility-based structures.
  We then apply these generalized results to several non-classical belief models, including conditional probability structures and lexicographic probability structures. Moreover, we show that whenever our generalized theorems do not apply, the Monderer-Samet-Neeman Agreement Theorem fails. These findings suggest that our results successfully identify the minimal conditions required for a belief model to satisfy the Monderer-Samet-Neeman Agreement Theorem.
</description>
      <guid isPermaLink="false">oai:arXiv.org:2511.22372v1</guid>
      <category>cs.GT</category>
      <category>cs.LO</category>
      <category>cs.MA</category>
      <pubDate>Mon, 01 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <arxiv:DOI>10.4204/EPTCS.437.10</arxiv:DOI>
      <arxiv:journal_reference>EPTCS 437, 2025, pp. 66-79</arxiv:journal_reference>
      <dc:creator>Eric Pacuit (University of Maryland), Leo Yang (University of Maryland)</dc:creator>
    </item>
    <item>
      <title>Comparing State-Representations for DEL Model Checking</title>
      <link>https://arxiv.org/abs/2511.22382</link>
      <description>arXiv:2511.22382v1 Announce Type: cross 
Abstract: Model checking with the standard Kripke models used in (Dynamic) Epistemic Logic leads to scalability issues. Hence alternative representations have been developed, in particular symbolic structures based on Binary Decision Diagrams (BDDs) and succinct models based on mental programs. While symbolic structures have been shown to perform well in practice, their theoretical complexity was not known so far. On the other hand, for succinct models model checking is known to be PSPACE-complete, but no implementations are available.
  We close this gap and directly relate the two representations. We show that model checking DEL on symbolic structures encoded with BDDs is also PSPACE-complete. In fact, already model checking Epistemic Logic without dynamics is PSPACE-complete on symbolic structures. We also provide direct translations between BDDs and mental programs. Both translations yield exponential outputs. For the translation from mental programs to BDDs we show that no small translation exists. For the other direction we conjecture the same.
</description>
      <guid isPermaLink="false">oai:arXiv.org:2511.22382v1</guid>
      <category>cs.LO</category>
      <category>cs.MA</category>
      <pubDate>Mon, 01 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <arxiv:DOI>10.4204/EPTCS.437.21</arxiv:DOI>
      <arxiv:journal_reference>EPTCS 437, 2025, pp. 233-250</arxiv:journal_reference>
      <dc:creator>Gregor Behnke (ILLC, University of Amsterdam), Malvin Gattinger (ILLC, University of Amsterdam), Avijeet Ghosh (Chennai Mathematical Institute), Haitian Wang (ILLC, University of Amsterdam)</dc:creator>
    </item>
    <item>
      <title>Impure Simplicial Complex and Term-Modal Logic with Assignment Operators</title>
      <link>https://arxiv.org/abs/2511.22391</link>
      <description>arXiv:2511.22391v1 Announce Type: cross 
Abstract: Impure simplicial complexes are a powerful tool to model multi-agent epistemic situations where agents may die, but it is difficult to define a satisfactory semantics for the ordinary propositional modal language on such models, since many conceptually dubious expressions involving dead agents can be expressed in this language. In this paper, we introduce a term-modal language with assignment operators, in which such conceptually dubious expressions are syntactically excluded. We define both simplicial semantics and first-order Kripke semantics for this language, characterize their respective expressivity through notions of bisimulation, and show that the two semantics are equivalent when we consider a special class of first order Kripke models called local epistemic models. We also offer a complete axiomatization for the epistemic logic based on this language, and show that our language has a notion of assignment normal form. Finally, we discuss the behavior of a kind of intensional distributed knowledge that can be naturally expressed in our language.</description>
      <guid isPermaLink="false">oai:arXiv.org:2511.22391v1</guid>
      <category>cs.LO</category>
      <category>cs.MA</category>
      <pubDate>Mon, 01 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <arxiv:DOI>10.4204/EPTCS.437.31</arxiv:DOI>
      <arxiv:journal_reference>EPTCS 437, 2025, pp. 399-416</arxiv:journal_reference>
      <dc:creator>Yuanzhe Yang</dc:creator>
    </item>
    <item>
      <title>MATCH: Engineering Transparent and Controllable Conversational XAI Systems through Composable Building Blocks</title>
      <link>https://arxiv.org/abs/2511.22420</link>
      <description>arXiv:2511.22420v1 Announce Type: cross 
Abstract: While the increased integration of AI technologies into interactive systems enables them to solve an increasing number of tasks, the black-box problem of AI models continues to spread throughout the interactive system as a whole. Explainable AI (XAI) techniques can make AI models more accessible by employing post-hoc methods or transitioning to inherently interpretable models. While this makes individual AI models clearer, the overarching system architecture remains opaque. This challenge not only pertains to standard XAI techniques but also to human examination and conversational XAI approaches that need access to model internals to interpret them correctly and completely. To this end, we propose conceptually representing such interactive systems as sequences of structural building blocks. These include the AI models themselves, as well as control mechanisms grounded in literature. The structural building blocks can then be explained through complementary explanatory building blocks, such as established XAI techniques like LIME and SHAP. The flow and APIs of the structural building blocks form an unambiguous overview of the underlying system, serving as a communication basis for both human and automated agents, thus aligning human and machine interpretability of the embedded AI models. In this paper, we present our flow-based approach and a selection of building blocks as MATCH: a framework for engineering Multi-Agent Transparent and Controllable Human-centered systems. This research contributes to the field of (conversational) XAI by facilitating the integration of interpretability into existing interactive systems.</description>
      <guid isPermaLink="false">oai:arXiv.org:2511.22420v1</guid>
      <category>cs.HC</category>
      <category>cs.AI</category>
      <category>cs.LG</category>
      <category>cs.MA</category>
      <pubDate>Mon, 01 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <dc:creator>Sebe Vanbrabant, Gustavo Rovelo Ruiz, Davy Vanacken</dc:creator>
    </item>
    <item>
      <title>A Computable Game-Theoretic Framework for Multi-Agent Theory of Mind</title>
      <link>https://arxiv.org/abs/2511.22536</link>
      <description>arXiv:2511.22536v1 Announce Type: cross 
Abstract: Originating in psychology, $\textit{Theory of Mind}$ (ToM) has attracted significant attention across multiple research communities, especially logic, economics, and robotics. Most psychological work does not aim at formalizing those central concepts, namely $\textit{goals}$, $\textit{intentions}$, and $\textit{beliefs}$, to automate a ToM-based computational process, which, by contrast, has been extensively studied by logicians. In this paper, we offer a different perspective by proposing a computational framework viewed through the lens of game theory. On the one hand, the framework prescribes how to make boudedly rational decisions while maintaining a theory of mind about others (and recursively, each of the others holding a theory of mind about the rest); on the other hand, it employs statistical techniques and approximate solutions to retain computability of the inherent computational problem.</description>
      <guid isPermaLink="false">oai:arXiv.org:2511.22536v1</guid>
      <category>cs.AI</category>
      <category>cs.GT</category>
      <category>cs.MA</category>
      <pubDate>Mon, 01 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Fengming Zhu, Yuxin Pan, Xiaomeng Zhu, Fangzhen Lin</dc:creator>
    </item>
    <item>
      <title>Formal Verification of Probabilistic Multi-Agent Systems for Ballistic Rocket Flight Using Probabilistic Alternating-Time Temporal Logic</title>
      <link>https://arxiv.org/abs/2511.22572</link>
      <description>arXiv:2511.22572v1 Announce Type: cross 
Abstract: This technical report presents a comprehensive formal verification approach for probabilistic agent systems modeling ballistic rocket flight trajectories using Probabilistic Alternating-Time Temporal Logic (PATL). We describe an innovative verification framework specifically designed for analyzing critical safety properties of ballistic rockets engineered to achieve microgravity conditions for scientific experimentation. Our model integrates authentic flight telemetry data encompassing velocity vectors, pitch angles, attitude parameters, and GPS coordinates to construct probabilistic state transition systems that rigorously account for environmental stochasticity, particularly meteorological variability. We formalize mission-critical safety properties through PATL specifications to systematically identify trajectory deviation states where the rocket risks landing in prohibited or hazardous zones. The verification framework facilitates real-time safety monitoring and enables automated intervention mechanisms, including emergency engine disengagement protocols, when predefined safety thresholds are exceeded. Experimental validation demonstrates the practical effectiveness and reliability of our approach in ensuring mission safety while maintaining scientific mission objectives.</description>
      <guid isPermaLink="false">oai:arXiv.org:2511.22572v1</guid>
      <category>cs.LO</category>
      <category>cs.MA</category>
      <pubDate>Mon, 01 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Damian Kurpiewski, J\k{e}drzej Michalczyk, Wojciech Jamroga, Jerzy Julian Michalski, Teofil Sidoruk</dc:creator>
    </item>
    <item>
      <title>Entropy is all you need for Inter-Seed Cross-Play in Hanabi</title>
      <link>https://arxiv.org/abs/2511.22581</link>
      <description>arXiv:2511.22581v1 Announce Type: cross 
Abstract: We find that in Hanabi, one of the most complex and popular benchmarks for zero-shot coordination and ad-hoc teamplay, a standard implementation of independent PPO with a slightly higher entropy coefficient 0.05 instead of the typically used 0.01, achieves a new state-of-the-art in cross-play between different seeds, beating by a significant margin all previous specialized algorithms, which were specifically designed for this setting. We provide an intuition for why sufficiently high entropy regularization ensures that different random seed produce joint policies which are mutually compatible. We also empirically find that a high $\lambda_{\text{GAE}}$ around 0.9, and using RNNs instead of just feed-forward layers in the actor-critic architecture, strongly increase inter-seed cross-play. While these results demonstrate the dramatic effect that hyperparameters can have not just on self-play scores but also on cross-play scores, we show that there are simple Dec-POMDPs though, in which standard policy gradient methods with increased entropy regularization are not able to achieve perfect inter-seed cross-play, thus demonstrating the continuing necessity for new algorithms for zero-shot coordination.</description>
      <guid isPermaLink="false">oai:arXiv.org:2511.22581v1</guid>
      <category>cs.LG</category>
      <category>cs.MA</category>
      <pubDate>Mon, 01 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Johannes Forkel, Jakob Foerster</dc:creator>
    </item>
    <item>
      <title>Automated Design Optimization via Strategic Search with Large Language Models</title>
      <link>https://arxiv.org/abs/2511.22651</link>
      <description>arXiv:2511.22651v1 Announce Type: cross 
Abstract: Traditional optimization methods excel in well-defined search spaces but struggle with design problems where transformations and design parameters are difficult to define. Large language models (LLMs) offer a promising alternative by dynamically interpreting design spaces and leveraging encoded domain knowledge. To this end, we introduce AUTO, an LLM agent framework that treats design optimization as a gradient-free search problem guided by strategic LLM reasoning. The framework employs two collaborative agents: a Strategist that selects between exploration and exploitation strategies, and an Implementor that executes detailed designs. Applied to GPU code optimization -- a domain critical to fields from machine learning to scientific computing -- AUTO generates solutions competitive with expert implementations for chemical kinetics integration and dense matrix multiplication. The framework achieves 50-70% search efficiency relative to Bayesian optimization methodologies. It completes optimizations in approximately 8 hours at an estimated cost of up to \$159 per run, compared to an estimated cost of up to \$480 with median-wage software developers. These findings open the door to automating design optimization in ill-defined search spaces with limited prior information.</description>
      <guid isPermaLink="false">oai:arXiv.org:2511.22651v1</guid>
      <category>cs.LG</category>
      <category>cs.AI</category>
      <category>cs.CE</category>
      <category>cs.MA</category>
      <pubDate>Mon, 01 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Anthony Carreon, Vansh Sharma, Venkat Raman</dc:creator>
    </item>
    <item>
      <title>Solving Context Window Overflow in AI Agents</title>
      <link>https://arxiv.org/abs/2511.22729</link>
      <description>arXiv:2511.22729v1 Announce Type: cross 
Abstract: Large Language Models (LLMs) have become increasingly capable of interacting with external tools, granting access to specialized knowledge beyond their training data - critical in dynamic, knowledge-intensive domains such as Chemistry and Materials Science. However, large tool outputs can overflow the LLMs' context window, preventing task completion. Existing solutions such as truncation or summarization fail to preserve complete outputs, making them unsuitable for workflows requiring the full data. This work introduces a method that enables LLMs to process and utilize tool responses of arbitrary length without loss of information. By shifting the model's interaction from raw data to memory pointers, the method preserves tool functionality, allows seamless integration into agentic workflows, and reduces token usage and execution time. The proposed method is validated on a real-world Materials Science application that cannot be executed with conventional workflows, and its effectiveness is demonstrated via a comparative analysis where both methods succeed. In this experiment, the proposed approach consumed approximately seven times fewer tokens than the traditional workflow.</description>
      <guid isPermaLink="false">oai:arXiv.org:2511.22729v1</guid>
      <category>cs.AI</category>
      <category>cs.MA</category>
      <pubDate>Mon, 01 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Anton Bulle Labate, Valesca Moura de Sousa, Sandro Rama Fiorini, Leonardo Guerreiro Azevedo, Raphael Melo Thiago, Viviane Torres da Silva</dc:creator>
    </item>
    <item>
      <title>Agentic AI Framework for Cloudburst Prediction and Coordinated Response</title>
      <link>https://arxiv.org/abs/2511.22767</link>
      <description>arXiv:2511.22767v1 Announce Type: cross 
Abstract: The challenge is growing towards extreme and short-duration rainfall events like a cloudburst that are peculiar to the traditional forecasting systems, in which the predictions and the response are taken as two distinct processes. The paper outlines an agentic artificial intelligence system to study atmospheric water-cycle intelligence, which combines sensing, forecasting, downscaling, hydrological modeling and coordinated response into a single, interconnected, priceless, closed-loop system. The framework uses autonomous but cooperative agents that reason, sense, and act throughout the entire event lifecycle, and use the intelligence of weather prediction to become real-time decision intelligence. Comparison of multi-year radar, satellite, and ground-based evaluation of the northern part of Pakistan demonstrates that the multi-agent configuration enhances forecast reliability, critical success index and warning lead time compared to the baseline models. Population reach was maximised, and errors during evacuation were minimised through communication and routing agents, and adaptive recalibration and transparent auditability were provided by the embedded layer of learning. Collectively, this leads to the conclusion that collaborative AI agents are capable of transforming atmospheric data streams into practicable foresight and provide a platform of scalable adaptive and learning-based climate resilience.</description>
      <guid isPermaLink="false">oai:arXiv.org:2511.22767v1</guid>
      <category>cs.AI</category>
      <category>cs.MA</category>
      <pubDate>Mon, 01 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Toqeer Ali Syed, Sohail Khan, Salman Jan, Gohar Ali, Muhammad Nauman, Ali Akarma, Ahmad Ali</dc:creator>
    </item>
    <item>
      <title>CRAwDAD: Causal Reasoning Augmentation with Dual-Agent Debate</title>
      <link>https://arxiv.org/abs/2511.22854</link>
      <description>arXiv:2511.22854v1 Announce Type: cross 
Abstract: When people reason about cause and effect, they often consider many competing "what if" scenarios before deciding which explanation fits best. Analogously, advanced language models capable of causal inference can consider multiple interventions and counterfactuals to judge the validity of causal claims. Crucially, this type of reasoning is less like a single calculation and more like an internal dialogue between alternative hypotheses. In this paper, we make this dialogue explicit through a dual-agent debate framework where one model provides a structured causal inference, and the other critically examines this reasoning for logical flaws. When disagreements arise, agents attempt to persuade each other, challenging each other's logic and revising their conclusions until they converge on a mutually agreed answer. To take advantage of this deliberative process, we specifically use reasoning language models, whose strengths in both causal inference and adversarial debate remain under-explored relative to standard large language models. We evaluate our approach on the CLadder dataset, a benchmark linking natural language questions to formally defined causal graphs across all three rungs of Pearl's ladder of causation. With Qwen3 and DeepSeek-R1 as debater agents, we demonstrate that multi-agent debate improves DeepSeek-R1's overall accuracy in causal inference from 78.03% to 87.45%, with the counterfactual category specifically improving from 67.94% to 80.04% accuracy. Similarly, Qwen3's overall accuracy improves from 84.16% to 89.41%, and counterfactual questions from 71.53% to 80.35%, showing that strong models can still benefit greatly from debate with weaker agents. Our results highlight the potential of reasoning models as building blocks for multi-agent systems in causal inference, and demonstrate the importance of diverse perspectives in causal problem-solving.</description>
      <guid isPermaLink="false">oai:arXiv.org:2511.22854v1</guid>
      <category>cs.LG</category>
      <category>cs.MA</category>
      <pubDate>Mon, 01 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Finn G. Vamosi, Nils D. Forkert</dc:creator>
    </item>
    <item>
      <title>A Game-Theoretic Approach for Adversarial Information Fusion in Distributed Sensor Networks</title>
      <link>https://arxiv.org/abs/2511.23026</link>
      <description>arXiv:2511.23026v1 Announce Type: cross 
Abstract: Every day we share our personal information through digital systems which are constantly exposed to threats. For this reason, security-oriented disciplines of signal processing have received increasing attention in the last decades: multimedia forensics, digital watermarking, biometrics, network monitoring, steganography and steganalysis are just a few examples. Even though each of these fields has its own peculiarities, they all have to deal with a common problem: the presence of one or more adversaries aiming at making the system fail. Adversarial Signal Processing lays the basis of a general theory that takes into account the impact that the presence of an adversary has on the design of effective signal processing tools. By focusing on the application side of Adversarial Signal Processing, namely adversarial information fusion in distributed sensor networks, and adopting a game-theoretic approach, this thesis contributes to the above mission by addressing four issues. First, we address decision fusion in distributed sensor networks by developing a novel soft isolation defense scheme that protect the network from adversaries, specifically, Byzantines. Second, we develop an optimum decision fusion strategy in the presence of Byzantines. In the next step, we propose a technique to reduce the complexity of the optimum fusion by relying on a novel near-optimum message passing algorithm based on factor graphs. Finally, we introduce a defense mechanism to protect decentralized networks running consensus algorithm against data falsification attacks.</description>
      <guid isPermaLink="false">oai:arXiv.org:2511.23026v1</guid>
      <category>cs.CR</category>
      <category>cs.GT</category>
      <category>cs.MA</category>
      <pubDate>Mon, 01 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Kassem Kallas</dc:creator>
    </item>
    <item>
      <title>Beyond Curve Fitting: Neuro-Symbolic Agents for Context-Aware Epidemic Forecasting</title>
      <link>https://arxiv.org/abs/2511.23276</link>
      <description>arXiv:2511.23276v1 Announce Type: cross 
Abstract: Effective surveillance of hand, foot and mouth disease (HFMD) requires forecasts accounting for epidemiological patterns and contextual drivers like school calendars and weather. While classical models and recent foundation models (e.g., Chronos, TimesFM) incorporate covariates, they often lack the semantic reasoning to interpret the causal interplay between conflicting drivers. In this work, we propose a two-agent framework decoupling contextual interpretation from probabilistic forecasting. An LLM "event interpreter" processes heterogeneous signals-including school schedules, meteorological summaries, and reports-into a scalar transmission-impact signal. A neuro-symbolic core then combines this with historical case counts to produce calibrated probabilistic forecasts. We evaluate the framework on real-world HFMD datasets from Hong Kong (2023-2024) and Lishui, China (2024). Compared to traditional and foundation-model baselines, our approach achieves competitive point forecasting accuracy while providing robust 90% prediction intervals (coverage 0.85-1.00) and human-interpretable rationales. Our results suggest that structurally integrating domain knowledge through LLMs can match state-of-the-art performance while yielding context-aware forecasts that align with public health workflows. Code is available at https://github.com/jw-chae/forecast_MED .</description>
      <guid isPermaLink="false">oai:arXiv.org:2511.23276v1</guid>
      <category>cs.LG</category>
      <category>cs.MA</category>
      <pubDate>Mon, 01 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Joongwon Chae, Runming Wang, Chen Xiong, Gong Yunhan, Lian Zhang, Ji Jiansong, Dongmei Yu, Peiwu Qin</dc:creator>
    </item>
    <item>
      <title>Agentic AI Framework for Smart Inventory Replenishment</title>
      <link>https://arxiv.org/abs/2511.23366</link>
      <description>arXiv:2511.23366v1 Announce Type: cross 
Abstract: In contemporary retail, the variety of products available (e.g. clothing, groceries, cosmetics, frozen goods) make it difficult to predict the demand, prevent stockouts, and find high-potential products. We suggest an agentic AI model that will be used to monitor the inventory, initiate purchase attempts to the appropriate suppliers, and scan for trending or high-margin products to incorporate. The system applies demand forecasting, supplier selection optimization, multi-agent negotiation and continuous learning. We apply a prototype to a setting in the store of a middle scale mart, test its performance on three conventional and artificial data tables, and compare the results to the base heuristics. Our findings indicate that there is a decrease in stockouts, a reduction of inventory holding costs, and an improvement in product mix turnover. We address constraints, scalability as well as improvement prospect.</description>
      <guid isPermaLink="false">oai:arXiv.org:2511.23366v1</guid>
      <category>cs.AI</category>
      <category>cs.MA</category>
      <pubDate>Mon, 01 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Toqeer Ali Syed, Salman Jan, Gohar Ali, Ali Akarma, Ahmad Ali, Qurat-ul-Ain Mastoi</dc:creator>
    </item>
    <item>
      <title>MegaChat: A Synthetic Persian Q&amp;A Dataset for High-Quality Sales Chatbot Evaluation</title>
      <link>https://arxiv.org/abs/2511.23397</link>
      <description>arXiv:2511.23397v1 Announce Type: cross 
Abstract: Small and medium-sized enterprises (SMEs) in Iran increasingly leverage Telegram for sales, where real-time engagement is essential for conversion. However, developing AI-driven chatbots for this purpose requires large, high-quality question-and-answer (Q&amp;A) datasets, which are typically expensive and resource-intensive to produce, especially for low-resource languages like Persian. In this paper, we introduce MegaChat, the first fully synthetic Persian Q&amp;A dataset designed to evaluate intelligent sales chatbots in Telegram-based e-commerce. We propose a novel, automated multi-agent architecture that generates persona-aware Q&amp;A pairs by collecting data from active Telegram shopping channels. The system employs specialized agents for question generation, validation, and refinement, ensuring the production of realistic and diverse conversational data. To evaluate answer generation, we compare three classic retrieval-augmented generation (RAG) models with our advanced agentic system, which features multi-query retrieval, reranking, and persona-aligned response synthesis. Using GPT-5.1 for evaluation across six quality dimensions, our results show that the agentic architecture outperformed traditional RAG models in 4 out of 5 diverse channels, demonstrating its ability to generate scalable, high-quality datasets without relying on expensive human annotation or complex fine-tuning. MegaChat provides SMEs with an efficient, cost-effective solution for building intelligent customer engagement systems in specialized commercial domains, enabling advancements in multilingual conversational AI for low-resource languages. Download: https://github.com/MegaChat-Tech/MegaChat-DataSet</description>
      <guid isPermaLink="false">oai:arXiv.org:2511.23397v1</guid>
      <category>cs.CL</category>
      <category>cs.AI</category>
      <category>cs.MA</category>
      <pubDate>Mon, 01 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Mahdi Rahmani, AmirHossein Saffari, Reyhane Rahmani</dc:creator>
    </item>
    <item>
      <title>From homeostasis to resource sharing: Biologically and economically aligned multi-objective multi-agent gridworld-based AI safety benchmarks</title>
      <link>https://arxiv.org/abs/2410.00081</link>
      <description>arXiv:2410.00081v5 Announce Type: replace 
Abstract: Developing safe, aligned agentic AI systems requires comprehensive empirical testing, yet many existing benchmarks neglect crucial themes aligned with biology and economics, both time-tested fundamental sciences describing our needs and preferences. To address this gap, the present work focuses on introducing biologically and economically motivated themes that have been neglected in current mainstream discussions on AI safety - namely a set of multi-objective, multi-agent alignment benchmarks that emphasize homeostasis for bounded and biological objectives, diminishing returns for unbounded, instrumental, and business objectives, sustainability principle, and resource sharing. Eight main benchmark environments have been implemented on the above themes, to illustrate key pitfalls and challenges in agentic AI-s, such as unboundedly maximizing a homeostatic objective, over-optimizing one objective at the expense of others, neglecting safety constraints, or depleting shared resources.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.00081v5</guid>
      <category>cs.MA</category>
      <category>cs.AI</category>
      <pubDate>Mon, 01 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Roland Pihlakas</dc:creator>
    </item>
    <item>
      <title>Computational Foundations for Strategic Coopetition: Formalizing Interdependence and Complementarity</title>
      <link>https://arxiv.org/abs/2510.18802</link>
      <description>arXiv:2510.18802v2 Announce Type: replace 
Abstract: Modern socio-technical systems are characterized by strategic coopetition where actors simultaneously cooperate to create value and compete to capture it. While conceptual modeling languages like i* provide rich qualitative representations of strategic dependencies, they lack mechanisms for quantitative analysis of dynamic trade-offs. Conversely, classical game theory offers mathematical rigor but strips away contextual richness. This technical report bridges this gap by developing computational foundations that formalize two critical dimensions of coopetition: interdependence and complementarity. We ground interdependence in i* structural dependency analysis, translating depender-dependee-dependum relationships into quantitative interdependence coefficients through a structured translation framework. We formalize complementarity following Brandenburger and Nalebuff's Added Value concept, modeling synergistic value creation with validated parameterization. We integrate structural dependencies with bargaining power in value appropriation and introduce a game-theoretic formulation where Nash Equilibrium incorporates structural interdependence. Validation combines comprehensive experimental testing across power and logarithmic value function specifications, demonstrating functional form robustness, with empirical application to the Samsung-Sony S-LCD joint venture (2004-2011), where logarithmic specifications achieve validation score 59/60 compared to power functions (55/60), with both demonstrating strong empirical fit to S-LCD historical patterns. This technical report serves as the foundational reference for a coordinated research program examining strategic coopetition in requirements engineering and multi-agent systems, with companion work addressing trust dynamics, team production, and reciprocity mechanisms.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.18802v2</guid>
      <category>cs.MA</category>
      <category>cs.AI</category>
      <category>cs.SE</category>
      <pubDate>Mon, 01 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Vik Pant, Eric Yu</dc:creator>
    </item>
    <item>
      <title>MTTR-A: Measuring Cognitive Recovery Latency in Multi-Agent Systems</title>
      <link>https://arxiv.org/abs/2511.20663</link>
      <description>arXiv:2511.20663v2 Announce Type: replace 
Abstract: Ensuring cognitive stability in autonomous multi-agent systems (MAS) is a central challenge for large-scale, distributed AI. While existing observability tools monitor system outputs, they cannot quantify how rapidly agentic workflows recover once reasoning coherence has been lost. We adapt classical reliability metrics-Mean Time-to-Recovery (MTTR), Mean Time Between Failures (MTBF), and related ratios-into the cognitive domain, defining MTTR-A (Mean Time-to-Recovery for Agentic Systems) as a runtime measure of cognitive recovery latency. MTTR-A quantifies the time required for a MAS to detect reasoning drift and restore consistent operation, capturing the recovery of reasoning coherence rather than infrastructural repair.
  A benchmark simulation using the AG~News corpus and the LangGraph orchestration framework was conducted, modeling recovery latencies across multiple reflex modes. Automated reflexes restored stability within approximately 6s on average, while human-approval interventions required about 12s. Across 200 runs, the median simulated MTTR-A was 6.21+-2.14s, MTBF=6.7+-2.14s, and NRR=0.08, demonstrating measurable runtime resilience across reflex strategies.
  By formalizing recovery latency as a quantifiable property of distributed reasoning-and deriving reliability bounds linking recovery time and cognitive uptime-this work establishes a foundation for runtime dependability in agentic cognition, transforming cognitive recovery from an ad-hoc process into a standardized, interpretable performance</description>
      <guid isPermaLink="false">oai:arXiv.org:2511.20663v2</guid>
      <category>cs.MA</category>
      <category>cs.AI</category>
      <category>cs.SY</category>
      <category>eess.SY</category>
      <pubDate>Mon, 01 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Barak Or</dc:creator>
    </item>
    <item>
      <title>Smart Traffic Signals: Comparing MARL and Fixed-Time Strategies</title>
      <link>https://arxiv.org/abs/2505.14544</link>
      <description>arXiv:2505.14544v4 Announce Type: replace-cross 
Abstract: Urban traffic congestion, particularly at intersections, significantly affects travel time, fuel consumption, and emissions. Traditional fixed-time signal control systems often lack the adaptability to effectively manage dynamic traffic patterns. This study explores the application of multi-agent reinforcement learning (MARL) to optimize traffic signal coordination across multiple intersections within a simulated environment. A simulation was developed to model a network of interconnected intersections with randomly generated vehicle flows to reflect realistic traffic variability. A decentralized MARL controller was implemented in which each traffic signal operates as an autonomous agent, making decisions based on local observations and information from neighboring agents. Performance was evaluated against a baseline fixed-time controller using metrics such as average vehicle wait time and overall throughput. The MARL approach demonstrated statistically significant improvements, including reduced average waiting times and improved throughput. These findings suggest that MARL-based dynamic control strategies hold substantial promise to improve urban traffic management efficiency. More research is recommended to address the challenges of scalability and real-world implementation.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.14544v4</guid>
      <category>cs.AI</category>
      <category>cs.MA</category>
      <pubDate>Mon, 01 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Saahil Mahato</dc:creator>
    </item>
    <item>
      <title>The Iceberg Index: Measuring Skills-centered Exposure in the AI Economy</title>
      <link>https://arxiv.org/abs/2510.25137</link>
      <description>arXiv:2510.25137v2 Announce Type: replace-cross 
Abstract: Artificial Intelligence is reshaping America's \$9.4 trillion labor market, with cascading effects that extend far beyond visible technology sectors. When AI transforms quality control tasks in automotive plants, consequences spread through logistics networks, supply chains, and local service economies. Yet traditional workforce metrics cannot capture these ripple effects: they measure employment outcomes after disruption occurs, not where AI capabilities overlap with human skills before adoption crystallizes. Project Iceberg addresses this gap using Large Population Models to simulate the human-AI labor market, representing 151 million workers as autonomous agents executing over 32,000 skills and interacting with thousands of AI tools. It introduces the Iceberg Index, a skills-centered metric that measures the wage value of skills AI systems can perform within each occupation. The Index captures technical exposure, where AI can perform occupational tasks, not displacement outcomes or adoption timelines. Analysis shows that visible AI adoption concentrated in computing and technology (2.2% of wage value, approx \$211 billion) represents only the tip of the iceberg. Technical capability extends far below the surface through cognitive automation spanning administrative, financial, and professional services (11.7%, approx \$1.2 trillion). This exposure is fivefold larger and geographically distributed across all states rather than confined to coastal hubs. Traditional indicators such as GDP, income, and unemployment explain less than 5% of this skills-based variation, underscoring why new indices are needed to capture exposure in the AI economy. By simulating how these capabilities may spread under scenarios, Iceberg enables policymakers and business leaders to identify exposure hotspots, prioritize investments, and test interventions before committing billions to implementation</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.25137v2</guid>
      <category>cs.CY</category>
      <category>cs.MA</category>
      <pubDate>Mon, 01 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Ayush Chopra, Santanu Bhattacharya, DeAndrea Salvador, Ayan Paul, Teddy Wright, Aditi Garg, Feroz Ahmad, Alice C. Schwarze, Ramesh Raskar, Prasanna Balaprakash</dc:creator>
    </item>
    <item>
      <title>Mina: A Multilingual LLM-Powered Legal Assistant Agent for Bangladesh for Empowering Access to Justice</title>
      <link>https://arxiv.org/abs/2511.08605</link>
      <description>arXiv:2511.08605v2 Announce Type: replace-cross 
Abstract: Bangladesh's low-income population faces major barriers to affordable legal advice due to complex legal language, procedural opacity, and high costs. Existing AI legal assistants lack Bengali-language support and jurisdiction-specific adaptation, limiting their effectiveness. To address this, we developed Mina, a multilingual LLM-based legal assistant tailored for the Bangladeshi context. It employs multilingual embeddings and a RAG-based chain-of-tools framework for retrieval, reasoning, translation, and document generation, delivering context-aware legal drafts, citations, and plain-language explanations via an interactive chat interface. Evaluated by law faculty from leading Bangladeshi universities across all stages of the 2022 and 2023 Bangladesh Bar Council Exams, Mina scored 75-80% in Preliminary MCQs, Written, and simulated Viva Voce exams, matching or surpassing average human performance and demonstrating clarity, contextual understanding, and sound legal reasoning. Even under a conservative upper bound, Mina operates at just 0.12-0.61% of typical legal consultation costs in Bangladesh, yielding a 99.4-99.9\% cost reduction relative to human-provided services. These results confirm its potential as a low-cost, multilingual AI assistant that automates key legal tasks and scales access to justice, offering a real-world case study on building domain-specific, low-resource systems and addressing challenges of multilingual adaptation, efficiency, and sustainable public-service AI deployment.</description>
      <guid isPermaLink="false">oai:arXiv.org:2511.08605v2</guid>
      <category>cs.CL</category>
      <category>cs.CY</category>
      <category>cs.HC</category>
      <category>cs.MA</category>
      <category>cs.MM</category>
      <pubDate>Mon, 01 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Azmine Toushik Wasi, Wahid Faisal, Mst Rafia Islam</dc:creator>
    </item>
    <item>
      <title>A Layered Protocol Architecture for the Internet of Agents</title>
      <link>https://arxiv.org/abs/2511.19699</link>
      <description>arXiv:2511.19699v2 Announce Type: replace-cross 
Abstract: Large Language Models (LLMs) have demonstrated remarkable performance improvements and the ability to learn domain-specific languages (DSLs), including APIs and tool interfaces. This capability has enabled the creation of AI agents that can perform preliminary computations and act through tool calling, now being standardized via protocols like MCP. However, LLMs face fundamental limitations: their context windows cannot grow indefinitely, constraining their memory and computational capacity. Agent collaboration emerges as essential for solving increasingly complex problems, mirroring how computational systems rely on different types of memory to scale. The "Internet of Agents" (IoA) represents the communication stack that enables agents to scale by distributing computation across collaborating entities. Current network architectural stacks (OSI and TCP/IP) were designed for data delivery between hosts and processes, not for agent collaboration with semantic understanding. To address this gap, we propose two new layers: an Agent Communication Layer (L8) and an Agent Semantic Negotiation Layer (L9). L8 formalizes the structure of communication, standardizing message envelopes, speech-act performatives (e.g., REQUEST, INFORM), and interaction patterns (e.g., request-reply, publish-subscribe), building on protocols like MCP. L9, which does not exist today, formalizes the meaning of communication, enabling agents to discover, negotiate, and lock a "Shared Context" -- a formal schema defining the concepts, tasks, and parameters relevant to their interaction. Together, these layers provide the foundation for scalable, distributed agent collaboration, enabling the next generation of multi-agentic systems.</description>
      <guid isPermaLink="false">oai:arXiv.org:2511.19699v2</guid>
      <category>cs.NI</category>
      <category>cs.AI</category>
      <category>cs.MA</category>
      <pubDate>Mon, 01 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Charles Fleming, Vijoy Pandey, Luca Muscariello, Ramana Kompella</dc:creator>
    </item>
  </channel>
</rss>
