<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>cs.GT updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/cs.GT</link>
    <description>cs.GT updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/cs.GT" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Fri, 29 Aug 2025 04:01:05 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Fri, 29 Aug 2025 00:00:00 -0400</pubDate>
    <skipDays>
      <day>Saturday</day>
      <day>Sunday</day>
    </skipDays>
    <item>
      <title>Collaborating with GenAI: Incentives and Replacements</title>
      <link>https://arxiv.org/abs/2508.20213</link>
      <description>arXiv:2508.20213v1 Announce Type: new 
Abstract: The rise of Generative AI (GenAI) is reshaping how workers contribute to shared projects. While workers can use GenAI to boost productivity or reduce effort, managers may use it to replace some workers entirely. We present a theoretical framework to analyze how GenAI affects collaboration in such settings. In our model, the manager selects a team to work on a shared task, with GenAI substituting for unselected workers. Each worker selects how much effort to exert, and incurs a cost that increases with the level of effort. We show that GenAI can lead workers to exert no effort, even if GenAI is almost ineffective. We further show that the manager's optimization problem is NP-complete, and provide an efficient algorithm for the special class of (almost-) linear instances. Our analysis shows that even workers with low individual value may play a critical role in sustaining overall output, and excluding such workers can trigger a cascade. Finally, we conduct extensive simulations to illustrate our theoretical findings.</description>
      <guid isPermaLink="false">oai:arXiv.org:2508.20213v1</guid>
      <category>cs.GT</category>
      <category>cs.AI</category>
      <pubDate>Fri, 29 Aug 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/publicdomain/zero/1.0/</dc:rights>
      <dc:creator>Boaz Taitler, Omer Ben-Porat</dc:creator>
    </item>
    <item>
      <title>Balancing Profit and Traveller Acceptance in Ride-Pooling Personalised Fares</title>
      <link>https://arxiv.org/abs/2508.20723</link>
      <description>arXiv:2508.20723v1 Announce Type: new 
Abstract: Ride-pooling systems, to succeed, must provide an attractive service, namely compensate perceived costs with an appealing price. However, because of a strong heterogeneity in a value-of-time, each traveller has his own acceptable price, unknown to the operator. Here, we show that individual acceptance levels can be learned by the operator (over $90\%$ accuracy for pooled travellers in $10$ days) to optimise personalised fares. We propose an adaptive pricing policy, where every day the operator constructs an offer that progressively meets travellers' expectations and attracts a growing demand. Our results suggest that operators, by learning behavioural traits of individual travellers, may improve performance not only for travellers (increased utility) but also for themselves (increased profit). Moreover, such knowledge allows the operator to remove inefficient pooled rides and focus on attractive and profitable combinations.</description>
      <guid isPermaLink="false">oai:arXiv.org:2508.20723v1</guid>
      <category>cs.GT</category>
      <category>cs.LG</category>
      <category>cs.SY</category>
      <category>eess.SY</category>
      <pubDate>Fri, 29 Aug 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Michal Bujak, Rafal Kucharski</dc:creator>
    </item>
    <item>
      <title>Guarding Against Malicious Biased Threats (GAMBiT) Experiments: Revealing Cognitive Bias in Human-Subjects Red-Team Cyber Range Operations</title>
      <link>https://arxiv.org/abs/2508.20963</link>
      <description>arXiv:2508.20963v1 Announce Type: cross 
Abstract: We present three large-scale human-subjects red-team cyber range datasets from the Guarding Against Malicious Biased Threats (GAMBiT) project. Across Experiments 1-3 (July 2024-March 2025), 19-20 skilled attackers per experiment conducted two 8-hour days of self-paced operations in a simulated enterprise network (SimSpace Cyber Force Platform) while we captured multi-modal data: self-reports (background, demographics, psychometrics), operational notes, terminal histories, keylogs, network packet captures (PCAP), and NIDS alerts (Suricata). Each participant began from a standardized Kali Linux VM and pursued realistic objectives (e.g., target discovery and data exfiltration) under controlled constraints. Derivative curated logs and labels are included. The combined release supports research on attacker behavior modeling, bias-aware analytics, and method benchmarking. Data are available via IEEE Dataport entries for Experiments 1-3.</description>
      <guid isPermaLink="false">oai:arXiv.org:2508.20963v1</guid>
      <category>cs.CR</category>
      <category>cs.GT</category>
      <pubDate>Fri, 29 Aug 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Brandon Beltz, Jim Doty, Yvonne Fonken, Nikolos Gurney, Brett Israelsen, Nathan Lau, Stacy Marsella, Rachelle Thomas, Stoney Trent, Peggy Wu, Ya-Ting Yang, Quanyan Zhu</dc:creator>
    </item>
  </channel>
</rss>
