<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>cs.GT updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/cs.GT</link>
    <description>cs.GT updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/cs.GT" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Thu, 27 Feb 2025 02:53:19 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Wed, 26 Feb 2025 00:00:00 -0500</pubDate>
    <skipDays>
      <day>Saturday</day>
      <day>Sunday</day>
    </skipDays>
    <item>
      <title>Information Disclosure Makes Simple Mechanisms Competitive</title>
      <link>https://arxiv.org/abs/2502.17809</link>
      <description>arXiv:2502.17809v1 Announce Type: new 
Abstract: In classical mechanism design, the prevailing assumption is that the information structure about agents' types is exogenous. This assumption introduces complexity, especially with multi-dimensional agent types, leading to mechanisms that, while optimal, may appear complex and unnatural. Furthermore, Hart and Nisan (2019) show that the gap between the performance of any simple mechanism and the optimal solution could be potentially unbounded. We challenge this conventional view by showing that simple mechanisms can be highly competitive if the information structure is endogenous and can be influenced by the designer.
  We study a multi-dimensional generalization of a single-dimensional model proposed by Bergemann and Pesendorfer (2007), where the designer can shape the information structure via information disclosure. Specifically, we consider a fundamental multi-dimensional mechanism design problem, where a seller is selling m items to a single unit-demand buyer to maximize her revenue. The buyer's values can be arbitrarily correlated across the items. Our main result shows that, following an appropriately chosen information disclosure scheme, item pricing, i.e., set a take-it-or-leave-it price on each item is highly competitive and guarantees to attain at least 50.1% of the optimal revenue. To our knowledge, this is the first result demonstrating the (approximate) optimality of simple mechanisms in this extensively studied multi-dimensional setting, without making any assumptions about the buyer's value distribution. We believe our result not only demonstrates the power of information disclosure in enhancing the performance of simple mechanisms but also suggests a new framework for reevaluating their efficacy in multi-dimensional settings.</description>
      <guid isPermaLink="false">oai:arXiv.org:2502.17809v1</guid>
      <category>cs.GT</category>
      <pubDate>Wed, 26 Feb 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Yang Cai, Yingkai Li, Jinzhao Wu</dc:creator>
    </item>
    <item>
      <title>Maximum Welfare Allocations under Quantile Valuations</title>
      <link>https://arxiv.org/abs/2502.17869</link>
      <description>arXiv:2502.17869v1 Announce Type: new 
Abstract: We propose a new model for aggregating preferences over a set of indivisible items based on a quantile value. In this model, each agent is endowed with a specific quantile, and the value of a given bundle is defined by the corresponding quantile of the individual values of the items within it. Our model captures the diverse ways in which agents may perceive a bundle, even when they agree on the values of individual items. It enables richer behavioral modeling that cannot be easily captured by additive valuation functions. We study the problem of maximizing utilitarian and egalitarian welfare within the quantile-based valuation setting. For each of the welfare functions, we analyze the complexity of the objectives. Interestingly, our results show that the complexity of both objectives varies significantly depending on whether the allocation is required to be balanced. We provide near-optimal approximation algorithms for utilitarian welfare, and for egalitarian welfare, we present exact algorithms whenever possible.</description>
      <guid isPermaLink="false">oai:arXiv.org:2502.17869v1</guid>
      <category>cs.GT</category>
      <pubDate>Wed, 26 Feb 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Haris Aziz, Shivika Narang, Mashbat Suzuki</dc:creator>
    </item>
    <item>
      <title>A Competitive Posted-Price Mechanism for Online Budget-Feasible Auctions</title>
      <link>https://arxiv.org/abs/2502.18265</link>
      <description>arXiv:2502.18265v1 Announce Type: new 
Abstract: We consider online procurement auctions, where the agents arrive sequentially, in random order, and have private costs for their services. The buyer aims to maximize a monotone submodular value function for the subset of agents whose services are procured, subject to a budget constraint on their payments. We consider a posted-price setting where upon each agent's arrival, the buyer decides on a payment offered to them. The agent accepts or rejects the offer, depending on whether the payment exceeds their cost, without revealing any other information about their private costs whatsoever. We present a randomized online posted-price mechanism with constant competitive ratio, thus resolving the main open question of (Badanidiyuru, Kleinberg and Singer, EC 2012). Posted-price mechanisms for online procurement typically operate by learning an estimation of the optimal value, denoted as OPT, and using it to determine the payments offered to the agents. The main challenge is to learn OPT within a constant factor from the agents' accept / reject responses to the payments offered. Our approach is based on an online test of whether our estimation is too low compared against OPT and a carefully designed adaptive search that gradually refines our estimation.</description>
      <guid isPermaLink="false">oai:arXiv.org:2502.18265v1</guid>
      <category>cs.GT</category>
      <category>cs.DS</category>
      <pubDate>Wed, 26 Feb 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Andreas Charalampopoulos, Dimitris Fotakis, Panagiotis Patsilinakos, Thanos Tolias</dc:creator>
    </item>
    <item>
      <title>Mixing Any Cocktail with Limited Ingredients: On the Structure of Payoff Sets in Multi-Objective MDPs and its Impact on Randomised Strategies</title>
      <link>https://arxiv.org/abs/2502.18296</link>
      <description>arXiv:2502.18296v1 Announce Type: new 
Abstract: We consider multi-dimensional payoff functions in Markov decision processes, and ask whether a given expected payoff vector can be achieved or not. In general, pure strategies (i.e., not resorting to randomisation) do not suffice for this problem.
  We study the structure of the set of expected payoff vectors of all strategies given a multi-dimensional payoff function and its consequences regarding randomisation requirements for strategies. In particular, we prove that for any payoff for which the expectation is well-defined under all strategies, it is sufficient to mix (i.e., randomly select a pure strategy at the start of a play and committing to it for the rest of the play) finitely many pure strategies to approximate any expected payoff vector up to any precision. Furthermore, for any payoff for which the expected payoff is finite under all strategies, any expected payoff can be obtained exactly by mixing finitely many strategies.</description>
      <guid isPermaLink="false">oai:arXiv.org:2502.18296v1</guid>
      <category>cs.GT</category>
      <category>cs.AI</category>
      <category>cs.FL</category>
      <category>cs.LO</category>
      <category>math.PR</category>
      <pubDate>Wed, 26 Feb 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>James C. A. Main, Mickael Randour</dc:creator>
    </item>
    <item>
      <title>FedSV: Byzantine-Robust Federated Learning via Shapley Value</title>
      <link>https://arxiv.org/abs/2502.17526</link>
      <description>arXiv:2502.17526v1 Announce Type: cross 
Abstract: In Federated Learning (FL), several clients jointly learn a machine learning model: each client maintains a local model for its local learning dataset, while a master server maintains a global model by aggregating the local models of the client devices. However, the repetitive communication between server and clients leaves room for attacks aimed at compromising the integrity of the global model, causing errors in its targeted predictions. In response to such threats on FL, various defense measures have been proposed in the literature. In this paper, we present a powerful defense against malicious clients in FL, called FedSV, using the Shapley Value (SV), which has been proposed recently to measure user contribution in FL by computing the marginal increase of average accuracy of the model due to the addition of local data of a user. Our approach makes the identification of malicious clients more robust, since during the learning phase, it estimates the contribution of each client according to the different groups to which the target client belongs. FedSV's effectiveness is demonstrated by extensive experiments on MNIST datasets in a cross-silo context under various attacks.</description>
      <guid isPermaLink="false">oai:arXiv.org:2502.17526v1</guid>
      <category>cs.LG</category>
      <category>cs.CR</category>
      <category>cs.GT</category>
      <pubDate>Wed, 26 Feb 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <arxiv:DOI>10.1109/ICC51166.2024.10622175</arxiv:DOI>
      <arxiv:journal_reference>IEEE International Conference on Communications, Jun 2024, Denver (CO), United States. pp.4620-4625</arxiv:journal_reference>
      <dc:creator>Khaoula Otmani (AU, LIA), Rachid Elazouzi (LIA, CMU), Vincent Labatut (AU, LIA)</dc:creator>
    </item>
    <item>
      <title>Instance-Dependent Regret Bounds for Learning Two-Player Zero-Sum Games with Bandit Feedback</title>
      <link>https://arxiv.org/abs/2502.17625</link>
      <description>arXiv:2502.17625v1 Announce Type: cross 
Abstract: No-regret self-play learning dynamics have become one of the premier ways to solve large-scale games in practice. Accelerating their convergence via improving the regret of the players over the naive $O(\sqrt{T})$ bound after $T$ rounds has been extensively studied in recent years, but almost all studies assume access to exact gradient feedback. We address the question of whether acceleration is possible under bandit feedback only and provide an affirmative answer for two-player zero-sum normal-form games. Specifically, we show that if both players apply the Tsallis-INF algorithm of Zimmert and Seldin (2018, arXiv:1807.07623), then their regret is at most $O(c_1 \log T + \sqrt{c_2 T})$, where $c_1$ and $c_2$ are game-dependent constants that characterize the difficulty of learning -- $c_1$ resembles the complexity of learning a stochastic multi-armed bandit instance and depends inversely on some gap measures, while $c_2$ can be much smaller than the number of actions when the Nash equilibria have a small support or are close to the boundary. In particular, for the case when a pure strategy Nash equilibrium exists, $c_2$ becomes zero, leading to an optimal instance-dependent regret bound as we show. We additionally prove that in this case, our algorithm also enjoys last-iterate convergence and can identify the pure strategy Nash equilibrium with near-optimal sample complexity.</description>
      <guid isPermaLink="false">oai:arXiv.org:2502.17625v1</guid>
      <category>cs.LG</category>
      <category>cs.GT</category>
      <pubDate>Wed, 26 Feb 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Shinji Ito, Haipeng Luo, Taira Tsuchiya, Yue Wu</dc:creator>
    </item>
    <item>
      <title>A Market for Accuracy: Classification under Competition</title>
      <link>https://arxiv.org/abs/2502.18052</link>
      <description>arXiv:2502.18052v1 Announce Type: cross 
Abstract: Machine learning models play a key role for service providers looking to gain market share in consumer markets. However, traditional learning approaches do not take into account the existence of additional providers, who compete with each other for consumers. Our work aims to study learning in this market setting, as it affects providers, consumers, and the market itself. We begin by analyzing such markets through the lens of the learning objective, and show that accuracy cannot be the only consideration. We then propose a method for classification under competition, so that a learner can maximize market share in the presence of competitors. We show that our approach benefits the providers as well as the consumers, and find that the timing of market entry and model updates can be crucial. We display the effectiveness of our approach across a range of domains, from simple distributions to noisy datasets, and show that the market as a whole remains stable by converging quickly to an equilibrium.</description>
      <guid isPermaLink="false">oai:arXiv.org:2502.18052v1</guid>
      <category>cs.LG</category>
      <category>cs.GT</category>
      <pubDate>Wed, 26 Feb 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Ohad Einav, Nir Rosenfeld</dc:creator>
    </item>
    <item>
      <title>FACT or Fiction: Can Truthful Mechanisms Eliminate Federated Free Riding?</title>
      <link>https://arxiv.org/abs/2405.13879</link>
      <description>arXiv:2405.13879v3 Announce Type: replace 
Abstract: Standard federated learning (FL) approaches are vulnerable to the free-rider dilemma: participating agents can contribute little to nothing yet receive a well-trained aggregated model. While prior mechanisms attempt to solve the free-rider dilemma, none have addressed the issue of truthfulness. In practice, adversarial agents can provide false information to the server in order to cheat its way out of contributing to federated training. In an effort to make free-riding-averse federated mechanisms truthful, and consequently less prone to breaking down in practice, we propose FACT. FACT is the first federated mechanism that: (1) eliminates federated free riding by using a penalty system, (2) ensures agents provide truthful information by creating a competitive environment, and (3) encourages agent participation by offering better performance than training alone. Empirically, FACT avoids free-riding when agents are untruthful, and reduces agent loss by over 4x.</description>
      <guid isPermaLink="false">oai:arXiv.org:2405.13879v3</guid>
      <category>cs.GT</category>
      <category>cs.DC</category>
      <category>cs.LG</category>
      <category>econ.TH</category>
      <pubDate>Wed, 26 Feb 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Marco Bornstein, Amrit Singh Bedi, Abdirisak Mohamed, Furong Huang</dc:creator>
    </item>
    <item>
      <title>Method of Equal Shares with Bounded Overspending</title>
      <link>https://arxiv.org/abs/2409.15005</link>
      <description>arXiv:2409.15005v2 Announce Type: replace 
Abstract: In participatory budgeting (PB), voters decide through voting which subset of projects to fund within a given budget. Proportionality in the context of PB is crucial to ensure equal treatment of all groups of voters. However, pure proportional rules can sometimes lead to suboptimal outcomes. We introduce the Method of Equal Shares with Bounded Overspending (BOS Equal Shares), a robust variant of Equal Shares that balances proportionality and efficiency. BOS Equal Shares addresses inefficiencies implied by strict proportionality axioms, yet the rule still provides fairness guarantees, similar to the original Method of Equal Shares. Our extensive empirical analysis on real-world PB instances shows excellent performance of BOS Equal Shares across several metrics. In the course of the analysis, we also present and examine a fractional variant of the Method of Equal Shares which allows for partial funding of projects.</description>
      <guid isPermaLink="false">oai:arXiv.org:2409.15005v2</guid>
      <category>cs.GT</category>
      <category>cs.AI</category>
      <category>cs.MA</category>
      <pubDate>Wed, 26 Feb 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Georgios Papasotiropoulos, Seyedeh Zeinab Pishbin, Oskar Skibski, Piotr Skowron, Tomasz W\k{a}s</dc:creator>
    </item>
    <item>
      <title>Learning Collusion in Episodic, Inventory-Constrained Markets</title>
      <link>https://arxiv.org/abs/2410.18871</link>
      <description>arXiv:2410.18871v2 Announce Type: replace 
Abstract: Pricing algorithms have demonstrated the capability to learn tacit collusion that is largely unaddressed by current regulations. Their increasing use in markets, including oligopolistic industries with a history of collusion, calls for closer examination by competition authorities. In this paper, we extend the study of tacit collusion in learning algorithms from basic pricing games to more complex markets characterized by perishable goods with fixed supply and sell-by dates, such as airline tickets, perishables, and hotel rooms. We formalize collusion within this framework and introduce a metric based on price levels under both the competitive (Nash) equilibrium and collusive (monopolistic) optimum. Since no analytical expressions for these price levels exist, we propose an efficient computational approach to derive them. Through experiments, we demonstrate that deep reinforcement learning agents can learn to collude in this more complex domain. Additionally, we analyze the underlying mechanisms and structures of the collusive strategies these agents adopt.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.18871v2</guid>
      <category>cs.GT</category>
      <category>cs.MA</category>
      <pubDate>Wed, 26 Feb 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Paul Friedrich, Barna P\'asztor, Giorgia Ramponi</dc:creator>
    </item>
    <item>
      <title>The Complexity of Symmetric Equilibria in Min-Max Optimization and Team Zero-Sum Games</title>
      <link>https://arxiv.org/abs/2502.08519</link>
      <description>arXiv:2502.08519v2 Announce Type: replace 
Abstract: We consider the problem of computing stationary points in min-max optimization, with a particular focus on the special case of computing Nash equilibria in (two-)team zero-sum games.
  We first show that computing $\epsilon$-Nash equilibria in $3$-player \emph{adversarial} team games -- wherein a team of $2$ players competes against a \emph{single} adversary -- is \textsf{CLS}-complete, resolving the complexity of Nash equilibria in such settings. Our proof proceeds by reducing from \emph{symmetric} $\epsilon$-Nash equilibria in \emph{symmetric}, identical-payoff, two-player games, by suitably leveraging the adversarial player so as to enforce symmetry -- without disturbing the structure of the game. In particular, the class of instances we construct comprises solely polymatrix games, thereby also settling a question left open by Hollender, Maystre, and Nagarajan (2024). We also provide some further results concerning equilibrium computation in adversarial team games.
  Moreover, we establish that computing \emph{symmetric} (first-order) equilibria in \emph{symmetric} min-max optimization is \textsf{PPAD}-complete, even for quadratic functions. Building on this reduction, we further show that computing symmetric $\epsilon$-Nash equilibria in symmetric, $6$-player ($3$ vs. $3$) team zero-sum games is also \textsf{PPAD}-complete, even for $\epsilon = \text{poly}(1/n)$. As an immediate corollary, this precludes the existence of symmetric dynamics -- which includes many of the algorithms considered in the literature -- converging to stationary points. Finally, we prove that computing a \emph{non-symmetric} $\text{poly}(1/n)$-equilibrium in symmetric min-max optimization is \textsf{FNP}-hard.</description>
      <guid isPermaLink="false">oai:arXiv.org:2502.08519v2</guid>
      <category>cs.GT</category>
      <category>cs.CC</category>
      <pubDate>Wed, 26 Feb 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Ioannis Anagnostides, Ioannis Panageas, Tuomas Sandholm, Jingming Yan</dc:creator>
    </item>
    <item>
      <title>Gnothi Seauton: Empowering Faithful Self-Interpretability in Black-Box Transformers</title>
      <link>https://arxiv.org/abs/2410.21815</link>
      <description>arXiv:2410.21815v2 Announce Type: replace-cross 
Abstract: The debate between self-interpretable models and post-hoc explanations for black-box models is central to Explainable AI (XAI). Self-interpretable models, such as concept-based networks, offer insights by connecting decisions to human-understandable concepts but often struggle with performance and scalability. Conversely, post-hoc methods like Shapley values, while theoretically robust, are computationally expensive and resource-intensive. To bridge the gap between these two lines of research, we propose a novel method that combines their strengths, providing theoretically guaranteed self-interpretability for black-box models without compromising prediction accuracy. Specifically, we introduce a parameter-efficient pipeline, AutoGnothi, which integrates a small side network into the black-box model, allowing it to generate Shapley value explanations without changing the original network parameters. This side-tuning approach significantly reduces memory, training, and inference costs, outperforming traditional parameter-efficient methods, where full fine-tuning serves as the optimal baseline. AutoGnothi enables the black-box model to predict and explain its predictions with minimal overhead. Extensive experiments show that AutoGnothi offers accurate explanations for both vision and language tasks, delivering superior computational efficiency with comparable interpretability.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.21815v2</guid>
      <category>cs.LG</category>
      <category>cs.AI</category>
      <category>cs.CL</category>
      <category>cs.CV</category>
      <category>cs.GT</category>
      <pubDate>Wed, 26 Feb 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <arxiv:journal_reference>International Conference on Learning Representations, 2025</arxiv:journal_reference>
      <dc:creator>Shaobo Wang, Hongxuan Tang, Mingyang Wang, Hongrui Zhang, Xuyang Liu, Weiya Li, Xuming Hu, Linfeng Zhang</dc:creator>
    </item>
    <item>
      <title>An Adversarial Analysis of Thompson Sampling for Full-information Online Learning: from Finite to Infinite Action Spaces</title>
      <link>https://arxiv.org/abs/2502.14790</link>
      <description>arXiv:2502.14790v3 Announce Type: replace-cross 
Abstract: We develop an analysis of Thompson sampling for online learning under full feedback - also known as prediction with expert advice - where the learner's prior is defined over the space of an adversary's future actions, rather than the space of experts. We show regret decomposes into regret the learner expected a priori, plus a prior-robustness-type term we call excess regret. In the classical finite-expert setting, this recovers optimal rates. As an initial step towards practical online learning in settings with a potentially-uncountably-infinite number of experts, we show that Thompson sampling with a certain Gaussian process prior widely-used in the Bayesian optimization literature has a $\mathcal{O}(\beta\sqrt{T\log(1+\lambda)})$ rate against a $\beta$-bounded $\lambda$-Lipschitz adversary.</description>
      <guid isPermaLink="false">oai:arXiv.org:2502.14790v3</guid>
      <category>cs.LG</category>
      <category>cs.GT</category>
      <category>math.ST</category>
      <category>stat.ML</category>
      <category>stat.TH</category>
      <pubDate>Wed, 26 Feb 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Alexander Terenin, Jeffrey Negrea</dc:creator>
    </item>
    <item>
      <title>Polytopal Stochastic Games</title>
      <link>https://arxiv.org/abs/2502.16208</link>
      <description>arXiv:2502.16208v2 Announce Type: replace-cross 
Abstract: In this paper we introduce polytopal stochastic games, an extension of two-player, zero-sum, turn-based stochastic games, in which we may have uncertainty over the transition probabilities. In these games the uncertainty over the probabilities distributions is captured via linear (in)equalities whose space of solutions forms a polytope. We give a formal definition of these games and prove their basic properties: determinacy and existence of optimal memoryless and deterministic strategies. We do this for reachability and different types of reward objectives and show that the solution exists in a finite representation of the game. We also state that the corresponding decision problems are in the intersection of NP and coNP. We motivate the use of polytopal stochastic games via a simple example. Finally, we report some experiments we performed with a prototype tool.</description>
      <guid isPermaLink="false">oai:arXiv.org:2502.16208v2</guid>
      <category>cs.LO</category>
      <category>cs.GT</category>
      <pubDate>Wed, 26 Feb 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Pablo F. Castro, Pedro D'Argenio</dc:creator>
    </item>
    <item>
      <title>Survey on Strategic Mining in Blockchain: A Reinforcement Learning Approach</title>
      <link>https://arxiv.org/abs/2502.17307</link>
      <description>arXiv:2502.17307v2 Announce Type: replace-cross 
Abstract: Strategic mining attacks, such as selfish mining, exploit blockchain consensus protocols by deviating from honest behavior to maximize rewards. Markov Decision Process (MDP) analysis faces scalability challenges in modern digital economics, including blockchain. To address these limitations, reinforcement learning (RL) provides a scalable alternative, enabling adaptive strategy optimization in complex dynamic environments.
  In this survey, we examine RL's role in strategic mining analysis, comparing it to MDP-based approaches. We begin by reviewing foundational MDP models and their limitations, before exploring RL frameworks that can learn near-optimal strategies across various protocols. Building on this analysis, we compare RL techniques and their effectiveness in deriving security thresholds, such as the minimum attacker power required for profitable attacks. Expanding the discussion further, we classify consensus protocols and propose open challenges, such as multi-agent dynamics and real-world validation.
  This survey highlights the potential of reinforcement learning (RL) to address the challenges of selfish mining, including protocol design, threat detection, and security analysis, while offering a strategic roadmap for researchers in decentralized systems and AI-driven analytics.</description>
      <guid isPermaLink="false">oai:arXiv.org:2502.17307v2</guid>
      <category>cs.LG</category>
      <category>cs.GT</category>
      <category>cs.MA</category>
      <pubDate>Wed, 26 Feb 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Jichen Li, Lijia Xie, Hanting Huang, Bo Zhou, Binfeng Song, Wanying Zeng, Xiaotie Deng, Xiao Zhang</dc:creator>
    </item>
  </channel>
</rss>
