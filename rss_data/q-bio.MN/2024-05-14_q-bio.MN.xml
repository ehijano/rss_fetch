<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>q-bio.MN updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/q-bio.MN</link>
    <description>q-bio.MN updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/q-bio.MN" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Tue, 14 May 2024 05:08:48 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Tue, 14 May 2024 00:00:00 -0400</pubDate>
    <skipDays>
      <day>Saturday</day>
      <day>Sunday</day>
    </skipDays>
    <item>
      <title>Boolean matrix logic programming for active learning of gene functions in genome-scale metabolic network models</title>
      <link>https://arxiv.org/abs/2405.06724</link>
      <description>arXiv:2405.06724v1 Announce Type: new 
Abstract: Techniques to autonomously drive research have been prominent in Computational Scientific Discovery, while Synthetic Biology is a field of science that focuses on designing and constructing new biological systems for useful purposes. Here we seek to apply logic-based machine learning techniques to facilitate cellular engineering and drive biological discovery. Comprehensive databases of metabolic processes called genome-scale metabolic network models (GEMs) are often used to evaluate cellular engineering strategies to optimise target compound production. However, predicted host behaviours are not always correctly described by GEMs, often due to errors in the models. The task of learning the intricate genetic interactions within GEMs presents computational and empirical challenges. To address these, we describe a novel approach called Boolean Matrix Logic Programming (BMLP) by leveraging boolean matrices to evaluate large logic programs. We introduce a new system, $BMLP_{active}$, which efficiently explores the genomic hypothesis space by guiding informative experimentation through active learning. In contrast to sub-symbolic methods, $BMLP_{active}$ encodes a state-of-the-art GEM of a widely accepted bacterial host in an interpretable and logical representation using datalog logic programs. Notably, $BMLP_{active}$ can successfully learn the interaction between a gene pair with fewer training examples than random experimentation, overcoming the increase in experimental design space. $BMLP_{active}$ enables rapid optimisation of metabolic models to reliably engineer biological systems for producing useful compounds. It offers a realistic approach to creating a self-driving lab for microbial engineering.</description>
      <guid isPermaLink="false">oai:arXiv.org:2405.06724v1</guid>
      <category>q-bio.MN</category>
      <category>cs.AI</category>
      <category>cs.LG</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Lun Ai, Stephen H. Muggleton, Shi-Shun Liang, Geoff S. Baldwin</dc:creator>
    </item>
    <item>
      <title>CANA v1.0.0 and schematodes: efficient quantification of symmetry in Boolean automata</title>
      <link>https://arxiv.org/abs/2405.07123</link>
      <description>arXiv:2405.07123v1 Announce Type: new 
Abstract: The biomolecular networks underpinning cell function exhibit canalization, or the buffering of fluctuations required to function in a noisy environment. One understudied putative mechanism for canalization is the functional equivalence of a biomolecular entity's regulators (e.g., among the transcription factors for a gene). In these discrete dynamical systems, activation and inhibition of biomolecular entities (e.g., transcription of genes) are modeled as the activity of coupled 2-state automata, and thus the equivalence of regulators can be studied using the theory of symmetry in discrete functions. To this end, we present a new exact algorithm for finding maximal symmetry groups among the inputs to discrete functions. We implement this algorithm in Rust as a Python package, schematodes. We include schematodes in the new CANA v1.0.0 release, an open source Python library for analyzing canalization in Boolean networks, which we also present here. We compare our exact method implemented in schematodes to the previously published inexact method used in earlier releases of CANA and find that schematodes significantly outperforms the prior method both in speed and accuracy. We also apply CANA v1.0.0 to study the symmetry properties of regulatory function from an ensemble of experimentally-supported Boolean networks from the Cell Collective. Using CANA v1.0.0, we find that the distribution of a previously reported symmetry parameter, $k_s/k$, is statistically significantly different in the Cell Collective than in random automata with the same in-degree and activation bias (Kolmogorov-Smirnov test, $p&lt;0.001$). In particular, its spread is much wider than in our null model (IQR 0.31 vs IQR 0.20 with equal medians), demonstrating that the Cell Collective is enriched in functions with extreme symmetry or asymmetry.</description>
      <guid isPermaLink="false">oai:arXiv.org:2405.07123v1</guid>
      <category>q-bio.MN</category>
      <category>q-bio.QM</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Austin M. Marcus, Jordan Rozum, Herbert Sizek, Luis M. Rocha</dc:creator>
    </item>
    <item>
      <title>ProLLM: Protein Chain-of-Thoughts Enhanced LLM for Protein-Protein Interaction Prediction</title>
      <link>https://arxiv.org/abs/2405.06649</link>
      <description>arXiv:2405.06649v1 Announce Type: cross 
Abstract: The prediction of protein-protein interactions (PPIs) is crucial for understanding biological functions and diseases. Previous machine learning approaches to PPI prediction mainly focus on direct physical interactions, ignoring the broader context of nonphysical connections through intermediate proteins, thus limiting their effectiveness. The emergence of Large Language Models (LLMs) provides a new opportunity for addressing this complex biological challenge. By transforming structured data into natural language prompts, we can map the relationships between proteins into texts. This approach allows LLMs to identify indirect connections between proteins, tracing the path from upstream to downstream. Therefore, we propose a novel framework ProLLM that employs an LLM tailored for PPI for the first time. Specifically, we propose Protein Chain of Thought (ProCoT), which replicates the biological mechanism of signaling pathways as natural language prompts. ProCoT considers a signaling pathway as a protein reasoning process, which starts from upstream proteins and passes through several intermediate proteins to transmit biological signals to downstream proteins. Thus, we can use ProCoT to predict the interaction between upstream proteins and downstream proteins. The training of ProLLM employs the ProCoT format, which enhances the model's understanding of complex biological problems. In addition to ProCoT, this paper also contributes to the exploration of embedding replacement of protein sites in natural language prompts, and instruction fine-tuning in protein knowledge datasets. We demonstrate the efficacy of ProLLM through rigorous validation against benchmark datasets, showing significant improvement over existing methods in terms of prediction accuracy and generalizability. The code is available at: https://github.com/MingyuJ666/ProLLM.</description>
      <guid isPermaLink="false">oai:arXiv.org:2405.06649v1</guid>
      <category>q-bio.BM</category>
      <category>cs.LG</category>
      <category>q-bio.MN</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Mingyu Jin, Haochen Xue, Zhenting Wang, Boming Kang, Ruosong Ye, Kaixiong Zhou, Mengnan Du, Yongfeng Zhang</dc:creator>
    </item>
  </channel>
</rss>
