<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>cs.AR updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/cs.AR</link>
    <description>cs.AR updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/cs.AR" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Fri, 06 Feb 2026 05:00:09 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Fri, 06 Feb 2026 00:00:00 -0500</pubDate>
    <skipDays>
      <day>Saturday</day>
      <day>Sunday</day>
    </skipDays>
    <item>
      <title>CVA6-CFI: A First Glance at RISC-V Control-Flow Integrity Extensions</title>
      <link>https://arxiv.org/abs/2602.04991</link>
      <description>arXiv:2602.04991v1 Announce Type: new 
Abstract: This work presents the first design, integration, and evaluation of the standard RISC-V extensions for Control-Flow Integrity (CFI). The Zicfiss and Zicfilp extensions aim at protecting the execution of a vulnerable program from control-flow hijacking attacks through the implementation of security mechanisms based on shadow stack and landing pad primitives. We introduce two independent and configurable hardware units implementing forward-edge and backward-edge control-flow protection, fully integrated into the open-source CVA6 core. Our design incurs in only 1.0% area overhead when synthesized in 22 nm FDX technology, and up to 15.6% performance overhead based on evaluation with the MiBench automotive benchmark subset. We release the complete implementation as open source.</description>
      <guid isPermaLink="false">oai:arXiv.org:2602.04991v1</guid>
      <category>cs.AR</category>
      <category>cs.CR</category>
      <pubDate>Fri, 06 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Simone Manoni, Emanuele Parisi, Riccardo Tedeschi, Davide Rossi, Andrea Acquaviva, Andrea Bartolini</dc:creator>
    </item>
    <item>
      <title>COFFEE: A Carbon-Modeling and Optimization Framework for HZO-based FeFET eNVMs</title>
      <link>https://arxiv.org/abs/2602.05018</link>
      <description>arXiv:2602.05018v1 Announce Type: new 
Abstract: Information and communication technologies account for a growing portion of global environmental impacts. While emerging technologies, such as emerging non-volatile memories (eNVM), offer a promising solution to energy efficient computing, their end-to-end footprint is not well understood. Understanding the environmental impact of hardware systems over their life cycle is the first step to realizing sustainable computing. This work conducts a detailed study of one example eNVM device: hafnium-zirconium-oxide (HZO)-based ferroelectric field-effect transistors (FeFETs). We present COFFEE, the first carbon modeling framework for HZO-based FeFET eNVMs across life cycle, from hardware manufacturing (embodied carbon) to use (operational carbon). COFFEE builds on data gathered from a real semiconductor fab and device fabrication recipes to estimate embodied carbon, and architecture level eNVM design space exploration tools to quantify use-phase performance and energy. Our evaluation shows that, at 2 MB capacity, the embodied carbon per unit area overhead of HZO-FeFETs can be up to 11% higher than the CMOS baseline, while the embodied carbon per MB remains consistently about 4.3x lower than SRAM across different memory capacity. A further case study applies COFFEE to an edge ML accelerator, showing that replacing the SRAM-based weight buffer with HZO-based FeFET eNVMs reduces embodied carbon by 42.3% and operational carbon by up to 70%.</description>
      <guid isPermaLink="false">oai:arXiv.org:2602.05018v1</guid>
      <category>cs.AR</category>
      <pubDate>Fri, 06 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Hongbang Wu, Xuesi Chen, Shubham Jadhav, Amit Lal, Lillian Pentecost, Udit Gupta</dc:creator>
    </item>
    <item>
      <title>Balancing FP8 Computation Accuracy and Efficiency on Digital CIM via Shift-Aware On-the-fly Aligned-Mantissa Bitwidth Prediction</title>
      <link>https://arxiv.org/abs/2602.05743</link>
      <description>arXiv:2602.05743v1 Announce Type: new 
Abstract: FP8 low-precision formats have gained significant adoption in Transformer inference and training. However, existing digital compute-in-memory (DCIM) architectures face challenges in supporting variable FP8 aligned-mantissa bitwidths, as unified alignment strategies and fixed-precision multiply-accumulate (MAC) units struggle to handle input data with diverse distributions. This work presents a flexible FP8 DCIM accelerator with three innovations: (1) a dynamic shift-aware bitwidth prediction (DSBP) with on-the-fly input prediction that adaptively adjusts weight (2/4/6/8b) and input (2$\sim$12b) aligned-mantissa precision; (2) a FIFO-based input alignment unit (FIAU) replacing complex barrel shifters with pointer-based control; and (3) a precision-scalable INT MAC array achieving flexible weight precision with minimal overhead. Implemented in 28nm CMOS with a 64$\times$96 CIM array, the design achieves 20.4 TFLOPS/W for fixed E5M7, demonstrating 2.8$\times$ higher FP8 efficiency than previous work while supporting all FP8 formats. Results on Llama-7b show that the DSBP achieves higher efficiency than fixed bitwidth mode at the same accuracy level on both BoolQ and Winogrande datasets, with configurable parameters enabling flexible accuracy-efficiency trade-offs.</description>
      <guid isPermaLink="false">oai:arXiv.org:2602.05743v1</guid>
      <category>cs.AR</category>
      <pubDate>Fri, 06 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Liang Zhao, Kunming Shao, Zhipeng Liao, Xijie Huang, Tim Kwang-Ting Cheng, Chi-Ying Tsui, Yi Zou</dc:creator>
    </item>
    <item>
      <title>System-Level Isolation for Mixed-Criticality RISC-V SoCs: A "World" Reality Check</title>
      <link>https://arxiv.org/abs/2602.05002</link>
      <description>arXiv:2602.05002v1 Announce Type: cross 
Abstract: As RISC-V adoption accelerates, domains such as automotive, the Internet of Things (IoT), and industrial control are attracting growing attention. These domains are subject to stringent Size, Weight, Power, and Cost (SWaP-C) constraints, which have driven a shift toward heterogeneous Systems-on-Chip (SoCs) integrating general-purpose CPUs, tightly coupled accelerators, and diverse I/O devices with different integrity levels. While such integration improves cost efficiency and performance, it introduces a fundamental safety and security challenge: enforcing system-level isolation in mixed-criticality environments. Although RISC-V International has proposed several hardware isolation primitives, including RISC-V Worlds, IOPMP, and SmMTT, their interoperability, scalability, and suitability for real-time systems remain insufficiently understood. In this paper, we present a comparative analysis of these primitives from the perspective of practical heterogeneous SoC designs. We implement an IOPMP, a World-based checker, and a modified RISC-V World checker that addresses key limitations of the baseline specification, and evaluate their trade-offs in terms of security guarantees and power-performance-area (PPA). Our results show that the World-based checker introduces a fixed, configuration-independent access latency, achieving lower worst-case delay than the evaluated alternatives while scaling predictably with system size. At the macro level, we estimate that the proposed modifications reduce SoC area by up to approximately 5% compared to a baseline design. All artifacts will be released as open source, and we expect these findings to directly contribute to the evolution and ratification of RISC-V specifications, as well as to the design of future RISC-V SoCs.</description>
      <guid isPermaLink="false">oai:arXiv.org:2602.05002v1</guid>
      <category>cs.CR</category>
      <category>cs.AR</category>
      <pubDate>Fri, 06 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Luis Cunha, Jose Martins, Manuel Rodriguez, Tiago Gomes, Sandro Pinto, Uwe Moslehner, Kai Dieffenbach, Glenn Farrall, Kajetan Nuernberger, Thomas Roecker</dc:creator>
    </item>
    <item>
      <title>Quantum Sequential Circuits</title>
      <link>https://arxiv.org/abs/2602.05166</link>
      <description>arXiv:2602.05166v1 Announce Type: cross 
Abstract: This work introduces and characterizes quantum sequential circuits (QSCs) as a hardware-oriented paradigm for quantum computing, built upon a novel foundational element termed the quantum transistor. Unlike conventional qubit-based architectures, QSCs employ symmetry-protected topological junctions where quantum gates are encoded as Choi states via channel-state duality and activated through bulk measurements, utilizing ebits to realize the functional analog of feedback loops in classical sequential circuits. This framework establishes a universal model for quantum computation that inherently incorporates memory and temporal sequencing, complementing existing combinational quantum circuit model. Our work advances the conceptual bridge towards a quantum von Neumann architecture, underscoring the potential of hybrid and modular design principles for the development of large-scale, integrated quantum information processors.</description>
      <guid isPermaLink="false">oai:arXiv.org:2602.05166v1</guid>
      <category>quant-ph</category>
      <category>cond-mat.mtrl-sci</category>
      <category>cs.AR</category>
      <pubDate>Fri, 06 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <dc:creator>D. -S. Wang</dc:creator>
    </item>
    <item>
      <title>CGRA4ML: A Hardware/Software Framework to Implement Neural Networks for Scientific Edge Computing</title>
      <link>https://arxiv.org/abs/2408.15561</link>
      <description>arXiv:2408.15561v3 Announce Type: replace 
Abstract: The scientific community increasingly relies on machine learning (ML) for near-sensor processing, leveraging its strengths in tasks such as pattern recognition, anomaly detection, and real-time decision-making. These deployments demand accelerators that combine extremely high performance with programmability, ease of integration, and straightforward verification. We present cgra4ml, an open-source, modular framework that generates parameterizable CGRA accelerators in synthesizable SystemVerilog RTL, tailored to common ML compute patterns found in scientific applications. The framework supports seamless system integration through AXI-compliant interfaces and open-source DMA components, and it includes automatic firmware generation for programming the accelerator. A comprehensive verification suite and a runtime firmware stack further support deployment across diverse SoC platforms. cgra4ml provides a modular, full-stack infrastructure, including a Python API, SystemVerilog hardware, TCL toolflows, and a C runtime, which facilitates easy integration and experimentation, allowing scientists to focus on innovation rather than dealing with the intricacies of hardware design and optimization. We demonstrate the effectiveness of cgra4ml to implement common scientific edge neural networks using ASIC and FPGA design flows.</description>
      <guid isPermaLink="false">oai:arXiv.org:2408.15561v3</guid>
      <category>cs.AR</category>
      <category>cs.AI</category>
      <pubDate>Fri, 06 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>G Abarajithan, Zhenghua Ma, Ravidu Munasinghe, Francesco Restuccia, Ryan Kastner</dc:creator>
    </item>
    <item>
      <title>STELLAR: Structure-guided LLM Assertion Retrieval and Generation for Formal Verification</title>
      <link>https://arxiv.org/abs/2601.19903</link>
      <description>arXiv:2601.19903v2 Announce Type: replace 
Abstract: Formal Verification (FV) relies on high-quality SystemVerilog Assertions (SVAs), but the manual writing process is slow and error-prone. Existing LLM-based approaches either generate assertions from scratch or ignore structural patterns in hardware designs and expert-crafted assertions. This paper presents STELLAR, the first framework that guides LLM-based SVA generation with structural similarity. STELLAR represents RTL blocks as AST structural fingerprints, retrieves structurally relevant (RTL, SVA) pairs from a knowledge base, and integrates them into structure-guided prompts. Experiments show that STELLAR achieves superior syntax correctness, stylistic alignment, and functional correctness, highlighting structure-aware retrieval as a promising direction for industrial FV.</description>
      <guid isPermaLink="false">oai:arXiv.org:2601.19903v2</guid>
      <category>cs.AR</category>
      <category>cs.AI</category>
      <pubDate>Fri, 06 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-sa/4.0/</dc:rights>
      <dc:creator>Saeid Rajabi, Chengmo Yang, Satwik Patnaik</dc:creator>
    </item>
    <item>
      <title>BioLite U-Net: Edge-Deployable Semantic Segmentation for In Situ Bioprinting Monitoring</title>
      <link>https://arxiv.org/abs/2509.06690</link>
      <description>arXiv:2509.06690v2 Announce Type: replace-cross 
Abstract: Bioprinting is a rapidly advancing field that offers a transformative approach to fabricating tissue and organ models through the precise deposition of cell-laden bioinks. Ensuring the fidelity and consistency of printed structures in real-time remains a core challenge, particularly under constraints imposed by limited imaging data and resource-constrained embedded hardware. Semantic segmentation of the extrusion process, differentiating between nozzle, extruded bioink, and surrounding background, enables in situ monitoring critical to maintaining print quality and biological viability. In this work, we introduce a lightweight semantic segmentation framework tailored for real-time bioprinting applications. We present a novel, manually annotated dataset comprising 787 RGB images captured during the bioprinting process, labeled across three classes: nozzle, bioink, and background. To achieve fast and efficient inference suitable for integration with bioprinting systems, we propose a BioLite U-Net architecture that leverages depthwise separable convolutions to drastically reduce computational load without compromising accuracy. Our model is benchmarked against MobileNetV2 and MobileNetV3-based segmentation baselines using mean Intersection over Union (mIoU), Dice score, and pixel accuracy. All models were evaluated on a Raspberry Pi 4B to assess real-world feasibility. The proposed BioLite U-Net achieves an mIoU of 92.85% and a Dice score of 96.17%, while being over 1300x smaller than MobileNetV2-DeepLabV3+. On-device inference takes 335 ms per frame, demonstrating near real-time capability. Compared to MobileNet baselines, BioLite U-Net offers a superior tradeoff between segmentation accuracy, efficiency, and deployability, making it highly suitable for intelligent, closed-loop bioprinting systems.</description>
      <guid isPermaLink="false">oai:arXiv.org:2509.06690v2</guid>
      <category>cs.CV</category>
      <category>cs.AI</category>
      <category>cs.AR</category>
      <pubDate>Fri, 06 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Usman Haider, Lukasz Szemet, Daniel Kelly, Vasileios Sergis, Andrew C. Daly, Karl Mason</dc:creator>
    </item>
    <item>
      <title>Governance at the Edge of Architecture: Regulating NeuroAI and Neuromorphic Systems</title>
      <link>https://arxiv.org/abs/2602.01503</link>
      <description>arXiv:2602.01503v2 Announce Type: replace-cross 
Abstract: Current AI governance frameworks, including regulatory benchmarks for accuracy, latency, and energy efficiency, are built for static, centrally trained artificial neural networks on von Neumann hardware. NeuroAI systems, embodied in neuromorphic hardware and implemented via spiking neural networks, break these assumptions. This paper examines the limitations of current AI governance frameworks for NeuroAI, arguing that assurance and audit methods must co-evolve with these architectures, aligning traditional regulatory metrics with the physics, learning dynamics, and embodied efficiency of brain-inspired computation to enable technically grounded assurance.</description>
      <guid isPermaLink="false">oai:arXiv.org:2602.01503v2</guid>
      <category>cs.ET</category>
      <category>cs.AI</category>
      <category>cs.AR</category>
      <pubDate>Fri, 06 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Afifah Kashif, Abdul Muhsin Hameed, Asim Iqbal</dc:creator>
    </item>
  </channel>
</rss>
