<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>cs.CC updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/cs.CC</link>
    <description>cs.CC updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/cs.CC" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Thu, 18 Sep 2025 01:35:46 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Wed, 17 Sep 2025 00:00:00 -0400</pubDate>
    <skipDays>
      <day>Sunday</day>
      <day>Saturday</day>
    </skipDays>
    <item>
      <title>An elementary proof that linking problems are hard</title>
      <link>https://arxiv.org/abs/2509.13120</link>
      <description>arXiv:2509.13120v1 Announce Type: new 
Abstract: We give a new, elementary proof of what we believe is the simplest known example of a ``natural'' problem in computational 3-dimensional topology that is $\mathsf{NP}$-hard -- namely, the \emph{Trivial Sublink Problem}: given a diagram $L$ of a link in $S^3$ and a positive integer $k$, decide if $L$ contains a $k$ component sublink that is trivial. This problem was previously shown to be $\mathsf{NP}$-hard in independent works of Koenig-Tsvietkova and de Mesmay-Rieck-Sedgwick-Tancer, both of which used reductions from $\mathsf{3SAT}$. The reduction we describe instead starts with the Independent Set Problem, and allows us to avoid the use of Brunnian links such as the Borromean rings. On the technical level, this entails a new conceptual insight: the Trivial Sublink Problem is hard entirely due to mod 2 pairwise linking, with no need for integral or higher order linking. On the pedagogical level, the reduction we describe is entirely elementary, and thus suitable for introducing undergraduates and non-experts to complexity-theoretic low-dimensional topology. To drive this point home, in this work we assume no familiarity with low-dimensional topology, and -- other than Reidemeister's Theorem and Karp's result that the Clique Problem is $\mathsf{NP}$-hard -- we provide more-or-less complete definitions and proofs. We have also constructed a web app that accompanies this work and allows a user to visualize the new reduction interactively.</description>
      <guid isPermaLink="false">oai:arXiv.org:2509.13120v1</guid>
      <category>cs.CC</category>
      <category>cs.CG</category>
      <category>math.GT</category>
      <pubDate>Wed, 17 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Shannon Cheng, Anna Chlopecki, Saarah Nazar, Eric Samperton</dc:creator>
    </item>
    <item>
      <title>On the Hardness of Order Finding and Equivalence Testing for ROABPs</title>
      <link>https://arxiv.org/abs/2509.13238</link>
      <description>arXiv:2509.13238v1 Announce Type: new 
Abstract: The complexity of representing a polynomial by a Read-Once Oblivious Algebraic Branching Program (ROABP) is highly dependent on the chosen variable ordering. Bhargava et al. prove that finding the optimal ordering is NP-hard, and provide some evidence (based on the Small Set Expansion hypothesis) that it is also hard to approximate the optimal ROABP width. In another work, Baraskar et al. show that it is NP-hard to test whether a polynomial is in the $\mathrm{GL}_n$ orbit of a polynomial of sparsity at most $s$. Building upon these works, we show the following results: first, we prove that approximating the minimum ROABP width up to any constant factor is NP-hard, when the input is presented as a circuit. This removes the reliance on stronger conjectures in the previous work. Second, we show that testing if an input polynomial given in the sparse representation is in the affine $\mathrm{GL}_n$ orbit of a width-$w$ ROABP is NP-hard. Furthermore, we show that over fields of characteristic $0$, the problem is NP-hard even when the input polynomial is homogeneous. This provides the first NP-hardness results for membership testing for a dense subclass of polynomial sized algebraic branching programs (VBP). Finally, we locate the source of hardness for the order finding problem at the lowest possible non-trivial degree, proving that the problem is NP-hard even for quadratic forms.</description>
      <guid isPermaLink="false">oai:arXiv.org:2509.13238v1</guid>
      <category>cs.CC</category>
      <pubDate>Wed, 17 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>C. Ramya, Pratik Shastri</dc:creator>
    </item>
    <item>
      <title>Deterministic polynomial factorisation modulo many primes</title>
      <link>https://arxiv.org/abs/2509.12705</link>
      <description>arXiv:2509.12705v1 Announce Type: cross 
Abstract: Designing a deterministic polynomial time algorithm for factoring univariate polynomials over finite fields remains a notorious open problem. In this paper, we present an unconditional deterministic algorithm that takes as input an irreducible polynomial $f \in \mathbb{Z}[x]$, and computes the factorisation of its reductions modulo $p$ for all primes $p$ up to a prescribed bound $N$. The \emph{average running time per prime} is polynomial in the size of the input and the degree of the splitting field of $f$ over $\mathbb{Q}$. In particular, if $f$ is Galois, we succeed in factoring in (amortised) deterministic polynomial time.</description>
      <guid isPermaLink="false">oai:arXiv.org:2509.12705v1</guid>
      <category>math.NT</category>
      <category>cs.CC</category>
      <pubDate>Wed, 17 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Daniel Altman</dc:creator>
    </item>
    <item>
      <title>Fast quantum algorithm for differential equations</title>
      <link>https://arxiv.org/abs/2306.11802</link>
      <description>arXiv:2306.11802v3 Announce Type: replace-cross 
Abstract: Partial differential equations (PDEs) are ubiquitous in science and engineering. Prior quantum algorithms for solving the system of linear algebraic equations obtained from discretizing a PDE have a computational complexity that scales at least linearly with the condition number $\kappa$ of the matrices involved in the computation. For many practical applications, $\kappa$ scales polynomially with the size $N$ of the matrices, rendering a polynomial complexity in $N$ for these algorithms. Here we present a quantum algorithm with a complexity that is polylogarithmic in $N$ but is independent of $\kappa$ for a large class of PDEs. Our algorithm generates a quantum state from which features of the solution can be extracted. Central to our methodology is using a wavelet basis as an auxiliary system of coordinates in which the condition number of associated matrices becomes independent of $N$ by a simple diagonal preconditioner. We present numerical simulations showing the effect of the wavelet preconditioner for several differential equations. Our work could provide a practical way to boost the performance of quantum simulation algorithms where standard methods are used for discretization.</description>
      <guid isPermaLink="false">oai:arXiv.org:2306.11802v3</guid>
      <category>quant-ph</category>
      <category>cs.CC</category>
      <category>cs.DS</category>
      <pubDate>Wed, 17 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Mohsen Bagherimehrab, Kouhei Nakaji, Nathan Wiebe, Gavin K. Brennen, Barry C. Sanders, Al\'an Aspuru-Guzik</dc:creator>
    </item>
    <item>
      <title>Gibbs state preparation for commuting Hamiltonian: Mapping to classical Gibbs sampling</title>
      <link>https://arxiv.org/abs/2410.04909</link>
      <description>arXiv:2410.04909v4 Announce Type: replace-cross 
Abstract: Gibbs state preparation, or Gibbs sampling, is a key computational technique extensively used in physics, statistics, and other scientific fields. Recent efforts for designing fast mixing Gibbs samplers for quantum Hamiltonians have largely focused on commuting local Hamiltonians (CLHs), a non-trivial subclass of Hamiltonians which include highly entangled systems such as the Toric code and quantum double model. Most previous Gibbs samplers relied on simulating the Davies generator, which is a Lindbladian associated with the thermalization process in nature.
  Instead of using the Davies generator, we design a different Gibbs sampler for various CLHs by giving a reduction to classical Hamiltonians, in the sense that one can efficiently prepare the Gibbs state for some CLH $H$ on a quantum computer as long as one can efficiently do classical Gibbs sampling for the corresponding classical Hamiltonian $H^{(c)}$. We demonstrate that our Gibbs sampler is able to replicate state-of-the-art results as well as prepare the Gibbs state in regimes which were previously unknown, such as the low temperature region, as long as there exists fast mixing Gibbs samplers for the corresponding classical Hamiltonians. Our reductions are as follows.
  - If $H$ is a 2-local qudit CLH, then $H^{(c)}$ is a 2-local qudit classical Hamiltonian.
  - If $H$ is a 4-local qubit CLH on 2D lattice and there are no classical qubits, then $H^{(c)}$ is a 2-local qudit classical Hamiltonian on a planar graph. As an example, our algorithm can prepare the Gibbs state for the (defected) Toric code at any non-zero temperature in $O(n^2 poly(log n))$ time.
  - If $H$ is a 4-local qubit CLH on 2D lattice and there are classical qubits, assuming that quantum terms are uniformly correctable, then $H^{(c)}$ is a constant-local classical Hamiltonian.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.04909v4</guid>
      <category>quant-ph</category>
      <category>cs.CC</category>
      <category>cs.DS</category>
      <pubDate>Wed, 17 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Yeongwoo Hwang, Jiaqing Jiang</dc:creator>
    </item>
    <item>
      <title>On the consistency of stronger lower bounds for NEXP</title>
      <link>https://arxiv.org/abs/2504.03320</link>
      <description>arXiv:2504.03320v2 Announce Type: replace-cross 
Abstract: It was recently shown by Atserias, Buss and Mueller that the standard complexity-theoretic conjecture NEXP not in P / poly is consistent with the relatively strong bounded arithmetic theory V^0_2, which can prove a substantial part of complexity theory. We observe that their approach can be extended to show that the stronger conjectures NEXP not in EXP / poly and NEXP not in coNEXP are consistent with a stronger theory, which includes every true universal number-sort sentence.</description>
      <guid isPermaLink="false">oai:arXiv.org:2504.03320v2</guid>
      <category>cs.LO</category>
      <category>cs.CC</category>
      <category>math.LO</category>
      <pubDate>Wed, 17 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Neil Thapen</dc:creator>
    </item>
    <item>
      <title>Fine-Grained Complexity via Quantum Natural Proofs</title>
      <link>https://arxiv.org/abs/2504.10363</link>
      <description>arXiv:2504.10363v2 Announce Type: replace-cross 
Abstract: Buhrman, Patro, and Speelman presented a framework of conjectures that together form a quantum analogue of the strong exponential-time hypothesis and its variants. They called it the QSETH framework. In this paper, using a notion of quantum natural proofs (built from natural proofs introduced by Razborov and Rudich), we show how part of the QSETH conjecture that requires properties to be `compression oblivious' can in many cases be replaced by assuming the existence of quantum-secure pseudorandom functions, a standard hardness assumption. Combined with techniques from Fourier analysis of Boolean functions, we show that properties such as PARITY and MAJORITY are compression oblivious for certain circuit class $\Lambda$ if subexponentially secure quantum pseudorandom functions exist in $\Lambda$, answering an open question in [Buhrman-Patro-Speelman 2021].</description>
      <guid isPermaLink="false">oai:arXiv.org:2504.10363v2</guid>
      <category>quant-ph</category>
      <category>cs.CC</category>
      <pubDate>Wed, 17 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Yanlin Chen, Yilei Chen, Rajendra Kumar, Subhasree Patro, Florian Speelman</dc:creator>
    </item>
    <item>
      <title>Quantifying The Limits of AI Reasoning: Systematic Neural Network Representations of Algorithms</title>
      <link>https://arxiv.org/abs/2508.18526</link>
      <description>arXiv:2508.18526v2 Announce Type: replace-cross 
Abstract: A main open question in contemporary AI research is quantifying the forms of reasoning neural networks can perform when perfectly trained. This paper answers this by interpreting reasoning tasks as circuit emulation, where the gates define the type of reasoning; e.g. Boolean gates for predicate logic, tropical circuits for dynamic programming, arithmetic and analytic gates for symbolic mathematical representation, and hybrids thereof for deeper reasoning; e.g. higher-order logic.
  We present a systematic meta-algorithm that converts essentially any circuit into a feedforward neural network (NN) with ReLU activations by iteratively replacing each gate with a canonical ReLU MLP emulator. We show that, on any digital computer, our construction emulates the circuit exactly--no approximation, no rounding, modular overflow included--demonstrating that no reasoning task lies beyond the reach of neural networks. The number of neurons in the resulting network (parametric complexity) scales with the circuit's complexity, and the network's computational graph (structure) mirrors that of the emulated circuit. This formalizes the folklore that NNs networks trade algorithmic run-time (circuit runtime) for space complexity (number of neurons).
  We derive a range of applications of our main result, from emulating shortest-path algorithms on graphs with cubic--size NNs, to simulating stopped Turing machines with roughly quadratically--large NNs, and even the emulation of randomized Boolean circuits. Lastly, we demonstrate that our result is strictly more powerful than a classical universal approximation theorem: any universal function approximator can be encoded as a circuit and directly emulated by a NN.</description>
      <guid isPermaLink="false">oai:arXiv.org:2508.18526v2</guid>
      <category>cs.LG</category>
      <category>cs.CC</category>
      <category>cs.LO</category>
      <category>cs.NA</category>
      <category>cs.NE</category>
      <category>math.NA</category>
      <pubDate>Wed, 17 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Anastasis Kratsios, Dennis Zvigelsky, Bradd Hart</dc:creator>
    </item>
  </channel>
</rss>
