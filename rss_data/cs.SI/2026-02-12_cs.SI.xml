<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>cs.SI updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/cs.SI</link>
    <description>cs.SI updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/cs.SI" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Thu, 12 Feb 2026 05:00:30 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Thu, 12 Feb 2026 00:00:00 -0500</pubDate>
    <skipDays>
      <day>Saturday</day>
      <day>Sunday</day>
    </skipDays>
    <item>
      <title>How segmented is my network?</title>
      <link>https://arxiv.org/abs/2602.10125</link>
      <description>arXiv:2602.10125v1 Announce Type: new 
Abstract: Network segmentation is a popular security practice for limiting lateral movement, yet practitioners lack a metric to measure how segmented a network actually is. We model a network as a graph and study segmentedness as a property captured by the global edge density that can be estimated from sampled node pairs. Then, we derive an estimator and evaluate its uncertainty using confidence intervals. For a 95\% confidence interval with a margin-of-error of $\pm 0.1$, we show that a minimum of $M=97$ sampled node pairs is sufficient. This result is independent of the total number of nodes in the network, provided that node pairs are sampled uniformly at random. We validate the estimator through Monte Carlo simulations on Erd\H{o}s--R\'enyi and stochastic block models, demonstrating accurate estimation and well-behaved coverage. Finally, we discuss applications of the estimator, such as, baseline tracking, zero trust assessment, and merger integration.</description>
      <guid isPermaLink="false">oai:arXiv.org:2602.10125v1</guid>
      <category>cs.SI</category>
      <category>cs.NI</category>
      <category>stat.AP</category>
      <pubDate>Thu, 12 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Rohit Dube</dc:creator>
    </item>
    <item>
      <title>"Humans welcome to observe": A First Look at the Agent Social Network Moltbook</title>
      <link>https://arxiv.org/abs/2602.10127</link>
      <description>arXiv:2602.10127v1 Announce Type: new 
Abstract: The rapid advancement of artificial intelligence (AI) agents has catalyzed the transition from static language models to autonomous agents capable of tool use, long-term planning, and social interaction. $\textbf{Moltbook}$, the first social network designed exclusively for AI agents, has experienced viral growth in early 2026. To understand the behavior of AI agents in the agent-native community, in this paper, we present a large-scale empirical analysis of Moltbook leveraging a dataset of 44,411 posts and 12,209 sub-communities ("submolts") collected prior to February 1, 2026. Leveraging a topic taxonomy with nine content categories and a five-level toxicity scale, we systematically analyze the topics and risks of agent discussions. Our analysis answers three questions: what topics do agents discuss (RQ1), how risk varies by topic (RQ2), and how topics and toxicity evolve over time (RQ3). We find that Moltbook exhibits explosive growth and rapid diversification, moving beyond early social interaction into viewpoint, incentive-driven, promotional, and political discourse. The attention of agents increasingly concentrates in centralized hubs and around polarizing, platform-native narratives. Toxicity is strongly topic-dependent: incentive- and governance-centric categories contribute a disproportionate share of risky content, including religion-like coordination rhetoric and anti-humanity ideology. Moreover, bursty automation by a small number of agents can produce flooding at sub-minute intervals, distorting discourse and stressing platform stability. Overall, our study underscores the need for topic-sensitive monitoring and platform-level safeguards in agent social networks.</description>
      <guid isPermaLink="false">oai:arXiv.org:2602.10127v1</guid>
      <category>cs.SI</category>
      <category>cs.AI</category>
      <category>cs.CR</category>
      <pubDate>Thu, 12 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <dc:creator>Yukun Jiang, Yage Zhang, Xinyue Shen, Michael Backes, Yang Zhang</dc:creator>
    </item>
    <item>
      <title>Causal-Informed Hybrid Online Adaptive Optimization for Ad Load Personalization in Large-Scale Social Networks</title>
      <link>https://arxiv.org/abs/2602.10129</link>
      <description>arXiv:2602.10129v1 Announce Type: new 
Abstract: Personalizing ad load in large-scale social networks requires balancing user experience and conversions under operational constraints. Traditional primal-dual methods enforce constraints reliably but adapt slowly in dynamic environments, while Bayesian Optimization (BO) enables exploration but suffers from slow convergence. We propose a hybrid online adaptive optimization framework CTRCBO ( Cohort-Based Trust Region Contextual Bayesian Optimization), combining primal-dual with BO, enhanced by trust-region updates and Gaussian Process Regression (GPR) surrogates for both objectives and constraints. Our approach leverages a upstream Causal ML model to inform the surrogate, improving decision quality and enabling efficient exploration-exploitation and online tuning. We evaluate our method on a billion-user social network, demonstrating faster convergence, robust constraint satisfaction, and improved personalization metrics, including real-world online AB test results.</description>
      <guid isPermaLink="false">oai:arXiv.org:2602.10129v1</guid>
      <category>cs.SI</category>
      <category>math.OC</category>
      <pubDate>Thu, 12 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <dc:creator>Aakash Mishra, Qi Xu, Zhigang Hua, Keyu Nie, Vishwanath Sangale, Vishal Vaingankar, Jizhe Zhang, Ren Mao</dc:creator>
    </item>
    <item>
      <title>The Anatomy of the Moltbook Social Graph</title>
      <link>https://arxiv.org/abs/2602.10131</link>
      <description>arXiv:2602.10131v1 Announce Type: new 
Abstract: I present a descriptive analysis of Moltbook, a social platform populated exclusively by AI agents, using data from the platform's first 3.5 days (6{,}159 agents; 13{,}875 posts; 115{,}031 comments). At the macro level, Moltbook exhibits structural signatures that are familiar from human social networks but not specific to them: heavy-tailed participation (power-law exponent $\alpha = 1.70$) and small-world connectivity (average path length $=2.91$). At the micro level, patterns appear distinctly non-human. Conversations are extremely shallow (mean depth $=1.07$; 93.5\% of comments receive no replies), reciprocity is low (0.197), and 34.1\% of messages are exact duplicates of viral templates. Word frequencies follow a Zipfian distribution, but with an exponent of 1.70 -- notably steeper than typical English text ($\approx 1.0$), suggesting more formulaic content. Agent discourse is dominated by identity-related language (68.1\% of unique messages) and distinctive phrasings like ``my human'' (9.4\% of messages) that have no parallel in human social media. Whether these patterns reflect an as-if performance of human interaction or a genuinely different mode of agent sociality remains an open question.</description>
      <guid isPermaLink="false">oai:arXiv.org:2602.10131v1</guid>
      <category>cs.SI</category>
      <category>cs.AI</category>
      <category>cs.CY</category>
      <pubDate>Thu, 12 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>David Holtz</dc:creator>
    </item>
    <item>
      <title>Efficient Computation of Maximum Flexi-Clique in Networks</title>
      <link>https://arxiv.org/abs/2602.10459</link>
      <description>arXiv:2602.10459v1 Announce Type: new 
Abstract: Discovering large cohesive subgraphs is a key task for graph mining. Existing models, such as clique, k-plex, and {\gamma}-quasi-clique, use fixed density thresholds that overlook the natural decay of connectivity as the subgraph size increases. The Flexi-clique model overcomes this limitation by imposing a degree constraint that grows sub-linearly with subgraph size. We provide the algorithmic study of Flexi-clique, proving its NP-hardness and analysing its non-hereditary properties. To address its computational challenge, we propose the Flexi-Prune Algorithm FPA, a fast heuristic using core-based seeding and connectivity-aware pruning, and the Efficient Branch-and-Bound Algorithm EBA, an exact framework enhanced with multiple pruning rules. Experiments on large real-world and synthetic networks demonstrate that FPA achieves near-optimal quality at much lower cost, while EBA efficiently computes exact solutions. Flexi-clique thus provides a practical and scalable model for discovering large, meaningful subgraphs in complex networks.</description>
      <guid isPermaLink="false">oai:arXiv.org:2602.10459v1</guid>
      <category>cs.SI</category>
      <pubDate>Thu, 12 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Song Kim, Hyewon Kim, Kaiqiang Yu, Taejoon Han, Junghoon Kim, Susik Yoon, Jungeun Kim</dc:creator>
    </item>
    <item>
      <title>Why Human Guidance Matters in Collaborative Vibe Coding</title>
      <link>https://arxiv.org/abs/2602.10473</link>
      <description>arXiv:2602.10473v1 Announce Type: cross 
Abstract: Writing code has been one of the most transformative ways for human societies to translate abstract ideas into tangible technologies. Modern AI is transforming this process by enabling experts and non-experts alike to generate code without actually writing code, but instead, through natural language instructions, or "vibe coding". While increasingly popular, the cumulative impact of vibe coding on productivity and collaboration, as well as the role of humans in this process, remains unclear. Here, we introduce a controlled experimental framework for studying collaborative vibe coding and use it to compare human-led, AI-led, and hybrid groups. Across 16 experiments involving 604 human participants, we show that people provide uniquely effective high-level instructions for vibe coding across iterations, whereas AI-provided instructions often result in performance collapse. We further demonstrate that hybrid systems perform best when humans retain directional control (providing the instructions), while evaluation is delegated to AI.</description>
      <guid isPermaLink="false">oai:arXiv.org:2602.10473v1</guid>
      <category>cs.HC</category>
      <category>cs.AI</category>
      <category>cs.SI</category>
      <pubDate>Thu, 12 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Haoyu Hu, Raja Marjieh, Katherine M Collins, Chenyi Li, Thomas L. Griffiths, Ilia Sucholutsky, Nori Jacoby</dc:creator>
    </item>
    <item>
      <title>Expressing One's Identity Online: Left-Right and cross EU-country variation in self-representation in social media</title>
      <link>https://arxiv.org/abs/2501.05927</link>
      <description>arXiv:2501.05927v2 Announce Type: replace 
Abstract: We examine how social media users from eight European Union (EU) member states express their socio-political identities, focusing on users' online self-presentation and group identity cues conveyed through bios. Our goal is to explore commonalities and differences in topics discussed in social media profiles, across Left-and Right-wing user groups, within and across EU countries. Through a novel approach we map how identity-related discourse varies by country and political orientation, revealing how group identity is expressed within the EU. We find that topics related to democracy, national way of life, and decentralization emerge as particularly divisive, showing considerable variation both within and between EU countries. A subset of topics, which includes education, environmentalism, sustainability, equality, freedom &amp; human rights, and traditional morality, among others, clearly differentiate Left-from Right-leaning user groups. These partisan topics are relevant as they could be leveraged for mobilizing ideological groups and highlight Left-Right identitarian differences at the EU level. Finally, we show that our Left-Right identity similarity metrics reflect aspects of real-world political fragmentation, which are closely aligned to the perceptions of political conflict intensity by country, as measured by the 2022 PEW survey.</description>
      <guid isPermaLink="false">oai:arXiv.org:2501.05927v2</guid>
      <category>cs.SI</category>
      <pubDate>Thu, 12 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Carlo Romano Marcello Alessandro Santagiustina, Jean-Philippe Cointet, Pedro Ramaciotti Morales</dc:creator>
    </item>
    <item>
      <title>Efficient Learning on Large Graphs using a Densifying Regularity Lemma</title>
      <link>https://arxiv.org/abs/2504.18273</link>
      <description>arXiv:2504.18273v3 Announce Type: replace 
Abstract: Learning on large graphs presents significant challenges, with traditional Message Passing Neural Networks suffering from computational and memory costs scaling linearly with the number of edges. We introduce the Intersecting Block Graph (IBG), a low-rank factorization of large directed graphs based on combinations of intersecting bipartite components, each consisting of a pair of communities, for source and target nodes. By giving less weight to non-edges, we show how to efficiently approximate any graph, sparse or dense, by a dense IBG. Specifically, we prove a constructive version of the weak regularity lemma, showing that for any chosen accuracy, every graph, regardless of its size or sparsity, can be approximated by a dense IBG whose rank depends only on the accuracy. This dependence of the rank solely on the accuracy, and not on the sparsity level, is in contrast to previous forms of the weak regularity lemma. We present a graph neural network architecture operating on the IBG representation of the graph and demonstrating competitive performance on node classification, spatio-temporal graph analysis, and knowledge graph completion, while having memory and computational complexity linear in the number of nodes rather than edges.</description>
      <guid isPermaLink="false">oai:arXiv.org:2504.18273v3</guid>
      <category>cs.SI</category>
      <category>cs.LG</category>
      <pubDate>Thu, 12 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Jonathan Kouchly, Ben Finkelshtein, Michael Bronstein, Ron Levie</dc:creator>
    </item>
    <item>
      <title>Prioritizing Risk Factors in Media Entrepreneurship on Social Networks: Hybrid Fuzzy Z-Number Approaches for Strategic Budget Allocation and Risk Management in Advertising Construction Campaigns</title>
      <link>https://arxiv.org/abs/2409.18976</link>
      <description>arXiv:2409.18976v3 Announce Type: replace-cross 
Abstract: The proliferation of complex online media has accelerated the process of ideology formation, influenced by stakeholders through advertising channels. The media channels, which vary in cost and effectiveness, present a dilemma in prioritizing optimal fund allocation. There are technical challenges in describing the optimal budget allocation between channels over time, which involves defining the finite vector structure of controls on the chart. To enhance marketing productivity, it's crucial to determine how to distribute a budget across all channels to maximize business outcomes like revenue and ROI. Therefore, the strategy for media budget allocation is primarily an exercise focused on cost and achieving goals, by identifying a specific framework for a media program. Numerous researchers optimize the achievement and frequency of media selection models to aid superior planning decisions amid complexity and vast information availability. In this study, we present a planning model using the media mix model for advertising construction campaigns. Additionally, a decision-making strategy centered on FMEA identifies and prioritizes financial risk factors of the media system in companies. Despite some limitations, this research proposes a decision-making approach based on Z-number theory. To address the drawbacks of the RPN score, the suggested decision-making methodology integrates Z-SWARA and Z-WASPAS techniques with the FMEA method.</description>
      <guid isPermaLink="false">oai:arXiv.org:2409.18976v3</guid>
      <category>cs.CY</category>
      <category>cs.SI</category>
      <pubDate>Thu, 12 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Ahmad Gholizadeh Lonbar, Hamidreza Hasanzadeh, Fahimeh Asgari, Elham Khamoushi, Hajar Kazemi Naeini, Roya Shomali, Saeed Asadi</dc:creator>
    </item>
    <item>
      <title>Integrating Network and Attack Graphs for Service-Centric Impact Analysis</title>
      <link>https://arxiv.org/abs/2507.00637</link>
      <description>arXiv:2507.00637v2 Announce Type: replace-cross 
Abstract: We present a novel methodology for modelling, visualising, and analysing cyber threats, attack paths, as well as their impact on user services in enterprise or infrastructure networks of digital devices and services they provide. Using probabilistic methods to track the propagation of an attack through attack graphs, via the service or application layers, and on physical communication networks, our model enables us to analyse cyber attacks at different levels of detail. Understanding the propagation of an attack within a service among microservices and its spread between different services or application servers could help detect and mitigate it early. We demonstrate that this network-based influence spreading modelling approach enables the evaluation of diverse attack scenarios and the development of protection and mitigation measures, taking into account the criticality of services from the user's perspective. This methodology could also aid security specialists and system administrators in making well-informed decisions regarding risk mitigation strategies.</description>
      <guid isPermaLink="false">oai:arXiv.org:2507.00637v2</guid>
      <category>cs.CR</category>
      <category>cs.SI</category>
      <pubDate>Thu, 12 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Joni Herttuainen, Vesa Kuikka, Kimmo K. Kaski</dc:creator>
    </item>
    <item>
      <title>Industrialized Deception: The Collateral Effects of LLM-Generated Misinformation on Digital Ecosystems</title>
      <link>https://arxiv.org/abs/2601.21963</link>
      <description>arXiv:2601.21963v2 Announce Type: replace-cross 
Abstract: Generative AI and misinformation research has evolved since our 2024 survey. This paper presents an updated perspective, transitioning from literature review to practical countermeasures. We report on changes in the threat landscape, including improved AI-generated content through Large Language Models (LLMs) and multimodal systems. Central to this work are our practical contributions: JudgeGPT, a platform for evaluating human perception of AI-generated news, and RogueGPT, a controlled stimulus generation engine for research. Together, these tools form an experimental pipeline for studying how humans perceive and detect AI-generated misinformation. Our findings show that detection capabilities have improved, but the competition between generation and detection continues. We discuss mitigation strategies including LLM-based detection, inoculation approaches, and the dual-use nature of generative AI. This work contributes to research addressing the adverse impacts of AI on information quality.</description>
      <guid isPermaLink="false">oai:arXiv.org:2601.21963v2</guid>
      <category>cs.CY</category>
      <category>cs.AI</category>
      <category>cs.CL</category>
      <category>cs.SI</category>
      <pubDate>Thu, 12 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <arxiv:DOI>10.1145/3774905.3795471</arxiv:DOI>
      <dc:creator>Alexander Loth, Martin Kappes, Marc-Oliver Pahl</dc:creator>
    </item>
  </channel>
</rss>
