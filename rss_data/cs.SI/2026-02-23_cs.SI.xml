<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>cs.SI updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/cs.SI</link>
    <description>cs.SI updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/cs.SI" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Mon, 23 Feb 2026 05:00:00 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Mon, 23 Feb 2026 00:00:00 -0500</pubDate>
    <skipDays>
      <day>Saturday</day>
      <day>Sunday</day>
    </skipDays>
    <item>
      <title>Beyond Individual Influence: The Role of Echo Chambers and Community Seeding in the Multilayer three state q-Voter Model</title>
      <link>https://arxiv.org/abs/2602.18088</link>
      <description>arXiv:2602.18088v1 Announce Type: new 
Abstract: The diffusion of complex opinions is severely hindered in multilayer social networks by echo chambers and cognitive consistency mechanisms. We investigate Influence Maximization strategies within the 3-state multilayer q-voter model. Utilizing the mABCD benchmark, we simulate social environments ranging from integrated Open Worlds to segregated Fortress Worlds. Our results reveal a topological paradox that we term the "Fortress Trap". In highly modular networks, strategies maximizing local density such as Clique Influence Maximization (CIM) and k-Shell fail to trigger global cascades, creating isolated bunkers of consensus due to the Overkill Effect. Furthermore, we identify a Redundancy Trap in perfectly aligned Clan topologies, where the structural overlap of layers creates a "Perfect Prison," rendering it the most resistant environment to diffusion. We demonstrate that VoteRank, a strategy that prioritizes diversity of reach over local intensity, consistently outperforms structure-based methods. These findings suggest that, for complex contagion, maximizing topological entropy is more effective than reinforcing local clusters.</description>
      <guid isPermaLink="false">oai:arXiv.org:2602.18088v1</guid>
      <category>cs.SI</category>
      <category>physics.soc-ph</category>
      <pubDate>Mon, 23 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Igor Ho{\l}owacz, Piotr Br\'odka</dc:creator>
    </item>
    <item>
      <title>Identifying the Source of Information Spread in Networks via Markov Chains</title>
      <link>https://arxiv.org/abs/2401.11330</link>
      <description>arXiv:2401.11330v2 Announce Type: replace 
Abstract: Nowadays, the diffusion of information through social networks is a powerful phenomenon. One common way to model diffusions in social networks is the Independent Cascade (IC) model. Given a set of infected nodes according to the IC model, a natural problem is the source detection problem, in which the goal is to identify the unique node that has started the diffusion. Maximum Likelihood Estimation (MLE) is a common approach for tackling the source detection problem, but it is computationally hard.
  In this work, we propose an efficient method for the source detection problem under the MLE approach, which is based on computing the stationary distribution of a Markov chain. Using simulations, we demonstrate the effectiveness of our method compared to other state-of-the-art methods from the literature, both on random and real-world networks.</description>
      <guid isPermaLink="false">oai:arXiv.org:2401.11330v2</guid>
      <category>cs.SI</category>
      <pubDate>Mon, 23 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <arxiv:DOI>10.65109/LLZL6722</arxiv:DOI>
      <arxiv:journal_reference>AAMAS 2026</arxiv:journal_reference>
      <dc:creator>Yael Sabato, Amos Azaria, Noam Hazon</dc:creator>
    </item>
    <item>
      <title>Learning hidden cascades via classification</title>
      <link>https://arxiv.org/abs/2505.11228</link>
      <description>arXiv:2505.11228v4 Announce Type: replace 
Abstract: The spreading dynamics in social networks are often studied under the assumption that individuals' statuses, whether informed or infected, are fully observable. However, in many real-world situations, such statuses remain unobservable, which is crucial for determining an individual's potential to further spread the infection. While final statuses are hidden, intermediate indicators such as symptoms of infection are observable and provide useful representations of the underlying diffusion process. We propose a partial observability-aware Machine Learning framework to learn the characteristics of the spreading model. We term the method Distribution Classification, which utilizes the power of classifiers to infer the underlying transmission dynamics. Through extensive benchmarking against Approximate Bayesian Computation and GNN-based baselines, our framework consistently outperforms these state-of-the-art methods, delivering accurate parameter estimates across diverse diffusion settings while scaling efficiently to large networks. We validate the method on synthetic networks and extend the study to a real-world insider trading network, demonstrating its effectiveness in analyzing spreading phenomena where direct observation of individual statuses is not possible.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.11228v4</guid>
      <category>cs.SI</category>
      <category>cs.LG</category>
      <pubDate>Mon, 23 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Derrick Gilchrist Edward Manoharan, Anubha Goel, Alexandros Iosifidis, Henri Hansen, Juho Kanniainen</dc:creator>
    </item>
    <item>
      <title>Beyond Homophily: Community Search on Heterophilic Graphs</title>
      <link>https://arxiv.org/abs/2601.01703</link>
      <description>arXiv:2601.01703v2 Announce Type: replace 
Abstract: Community search aims to identify a refined set of nodes that are most relevant to a given query, supporting tasks ranging from fraud detection to recommendation. Unlike homophilic graphs, many real-world networks are heterophilic, where edges predominantly connect dissimilar nodes. Therefore, structural signals that once reflected smooth, low-frequency similarity now appear as sharp, high-frequency contrasts. However, both classical algorithms (e.g., k-core, k-truss) and recent ML-based models struggle to achieve effective community search on heterophilic graphs, where edge signs or semantics are generally unknown. Algorithm-based methods often return communities with mixed class labels, while GNNs, built on homophily, smooth away meaningful signals and blur community boundaries. Therefore, we propose Adaptive Community Search (AdaptCS), a lightweight framework featuring three key designs: (i) an AdaptCS Encoder that disentangles multi-hop and multi-frequency signals, enabling the model to capture both smooth (homophilic) and contrastive (heterophilic) relations; (ii) a memory-efficient low-rank optimization that removes the main computational bottleneck and ensures model scalability; and (iii) an Adaptive Community Score (ACS) that guides online search by balancing embedding similarity and topological relations. Extensive experiments on both heterophilic and homophilic benchmarks demonstrate that AdaptCS outperforms the best-performing baseline by an average of 11% in F1-score, retains robustness across heterophily levels, and achieves up to 2 orders of magnitude speedup over the strongest ML-based CS baselines.</description>
      <guid isPermaLink="false">oai:arXiv.org:2601.01703v2</guid>
      <category>cs.SI</category>
      <category>cs.AI</category>
      <category>cs.DB</category>
      <category>cs.IR</category>
      <pubDate>Mon, 23 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Qing Sima, Xiaoyang Wang, Wenjie Zhang</dc:creator>
    </item>
    <item>
      <title>Self-reinforcing cascades: A spreading model for beliefs or products of varying intensity or quality</title>
      <link>https://arxiv.org/abs/2411.00714</link>
      <description>arXiv:2411.00714v3 Announce Type: replace-cross 
Abstract: Models of how things spread often assume that transmission mechanisms are fixed over time. However, social contagions--the spread of ideas, beliefs, innovations--can lose or gain in momentum as they spread: ideas can get reinforced, beliefs strengthened, products refined. We study the impacts of such self-reinforcement mechanisms in cascade dynamics. We use different mathematical modeling techniques to capture the recursive, yet changing nature of the process. We find a critical regime with a range of power-law cascade size distributions with non-universal scaling exponents. This regime clashes with classic models, where criticality requires fine tuning at a precise critical point. Self-reinforced cascades produce critical-like behavior over a wide range of parameters, which may help explain the ubiquity of power-law distributions in empirical social data.</description>
      <guid isPermaLink="false">oai:arXiv.org:2411.00714v3</guid>
      <category>physics.soc-ph</category>
      <category>cs.SI</category>
      <pubDate>Mon, 23 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <arxiv:DOI>10.1103/5mph-sws5</arxiv:DOI>
      <arxiv:journal_reference>Phys. Rev. Lett. 135, 087401 (2025)</arxiv:journal_reference>
      <dc:creator>Laurent H\'ebert-Dufresne, Juniper Lovato, Giulio Burgio, James P. Gleeson, S. Redner, P. L. Krapivsky</dc:creator>
    </item>
    <item>
      <title>Bending the Scaling Law Curve in Large-Scale Recommendation Systems</title>
      <link>https://arxiv.org/abs/2602.16986</link>
      <description>arXiv:2602.16986v2 Announce Type: replace-cross 
Abstract: Learning from user interaction history through sequential models has become a cornerstone of large-scale recommender systems. Recent advances in large language models have revealed promising scaling laws, sparking a surge of research into long-sequence modeling and deeper architectures for recommendation tasks. However, many recent approaches rely heavily on cross-attention mechanisms to address the quadratic computational bottleneck in sequential modeling, which can limit the representational power gained from self-attention. We present ULTRA-HSTU, a novel sequential recommendation model developed through end-to-end model and system co-design. By innovating in the design of input sequences, sparse attention mechanisms, and model topology, ULTRA-HSTU achieves substantial improvements in both model quality and efficiency. Comprehensive benchmarking demonstrates that ULTRA-HSTU achieves remarkable scaling efficiency gains -- over 5x faster training scaling and 21x faster inference scaling compared to conventional models -- while delivering superior recommendation quality. Our solution is fully deployed at scale, serving billions of users daily and driving significant 4% to 8% consumption and engagement improvements in real-world production environments.</description>
      <guid isPermaLink="false">oai:arXiv.org:2602.16986v2</guid>
      <category>cs.IR</category>
      <category>cs.SI</category>
      <pubDate>Mon, 23 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Qin Ding, Kevin Course, Linjian Ma, Jianhui Sun, Ruochen Liu, Zhao Zhu, Chunxing Yin, Wei Li, Dai Li, Yu Shi, Xuan Cao, Ze Yang, Han Li, Xing Liu, Bi Xue, Hongwei Li, Rui Jian, Daisy Shi He, Jing Qian, Matt Ma, Qunshu Zhang, Rui Li</dc:creator>
    </item>
  </channel>
</rss>
