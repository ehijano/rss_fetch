<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>cs.NI updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/cs.NI</link>
    <description>cs.NI updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/cs.NI" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Tue, 14 May 2024 04:00:09 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Tue, 14 May 2024 00:00:00 -0400</pubDate>
    <skipDays>
      <day>Saturday</day>
      <day>Sunday</day>
    </skipDays>
    <item>
      <title>Wall-Street: Smart Surface-Enabled 5G mmWave for Roadside Networking</title>
      <link>https://arxiv.org/abs/2405.06754</link>
      <description>arXiv:2405.06754v1 Announce Type: new 
Abstract: 5G mmWave roadside networks promise high-speed wireless connectivity, but face significant challenges in maintaining reliable connections for users moving at high speed. Frequent handovers, complex beam alignment, and signal attenuation due to obstacles like car bodies lead to service interruptions and degraded performance. We present Wall-Street, a smart surface installed on vehicles to enhance 5G mmWave connectivity for users inside. Wall-Street improves mobility management by (1) steering outdoor mmWave signals into the vehicle, ensuring coverage for all users; (2) enabling simultaneous serving cell data transfer and candidate handover cell measurement, allowing seamless handovers without service interruption; and (3) combining beams from source and target cells during a handover to increase reliability. Through its flexible and diverse signal manipulation capabilities, Wall-Street provides uninterrupted high-speed connectivity for latency-sensitive applications in challenging mobile environments. We have implemented and integrated Wall-Street in the COSMOS testbed and evaluated its real-time performance with four gNBs and a mobile client inside a surface-enabled vehicle, driving on a nearby road. Wall-Street achieves a 2.5-3.4x TCP throughput improvement and a 0.4-0.8x reduction in delay over a baseline 5G Standalone handover protocol.</description>
      <guid isPermaLink="false">oai:arXiv.org:2405.06754v1</guid>
      <category>cs.NI</category>
      <category>eess.SP</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Kun Woo Cho, Prasanthi Maddala, Ivan Seskar, Kyle Jamieson</dc:creator>
    </item>
    <item>
      <title>LEO Satellite Network Access in the Wild: Potentials, Experiences, and Challenges</title>
      <link>https://arxiv.org/abs/2405.06801</link>
      <description>arXiv:2405.06801v1 Announce Type: new 
Abstract: In the past three years, working with the Pacific Salmon Foundation and various First Nations groups, we have established Starlink-empowered wild salmon monitoring sites in remote Northern British Columbia, Canada. We report our experiences with the network services in these challenging environments, including deep woods and deep valleys, that lack infrastructural support with some close to Starlink's service boundary at the far north. We assess the portability and mobility of the satellite dishes and the quality of existing network access in underdeveloped countries that Starlink expects to cover. Our experiences suggest that network access based on LEO satellite constellations holds promise but faces hurdles such as energy supply constraints and environmental factors like temperature, precipitation, and solar storms. The presence of wildlife and respecting local residents' culture and heritage pose further complications. We envision several technical solutions addressing the challenges and believe that further regulations will be necessary.</description>
      <guid isPermaLink="false">oai:arXiv.org:2405.06801v1</guid>
      <category>cs.NI</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <arxiv:DOI>10.1109/MNET.2024.3391271</arxiv:DOI>
      <dc:creator>Sami Ma (Simon Fraser University), Yi Ching Chou (Simon Fraser University), Miao Zhang (Simon Fraser University), Hao Fang (Simon Fraser University), Haoyuan Zhao (Simon Fraser University), Jiangchuan Liu (Simon Fraser University), William I. Atlas (Pacific Salmon Foundation)</dc:creator>
    </item>
    <item>
      <title>ISAC-Assisted Wireless Rechargeable Sensor Networks with Multiple Mobile Charging Vehicles</title>
      <link>https://arxiv.org/abs/2405.06983</link>
      <description>arXiv:2405.06983v1 Announce Type: new 
Abstract: As IoT-based wireless sensor networks (WSNs) become more prevalent, the issue of energy shortages becomes more pressing. One potential solution is the use of wireless power transfer (WPT) technology, which is the key to building a new shape of wireless rechargeable sensor networks (WRSNs). However, efficient charging and scheduling are critical for WRSNs to function properly. Motivated by the fact that probabilistic techniques can help enhance the effectiveness of charging scheduling for WRSNs, this article addresses the aforementioned issue and proposes a novel ISAC-assisted WRSN protocol. In particular, our proposed protocol considers several factors to balance the charging load on each mobile charging vehicle (MCV), uses an efficient charging factor strategy to partially charge network devices, and employs the ISAC concept to reduce the traveling cost of each MCV and prevent charging conflicts. Simulation results demonstrate that this protocol outperforms other classic, cutting-edge protocols in multiple areas.</description>
      <guid isPermaLink="false">oai:arXiv.org:2405.06983v1</guid>
      <category>cs.NI</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Muhammad Umar Farooq Qaisar, Weijie Yuan, Paolo Bellavista, Guangjie Han, Adeel Ahmed</dc:creator>
    </item>
    <item>
      <title>A Performance Analysis Modeling Framework for Extended Reality Applications in Edge-Assisted Wireless Networks</title>
      <link>https://arxiv.org/abs/2405.07033</link>
      <description>arXiv:2405.07033v1 Announce Type: new 
Abstract: Extended reality (XR) is at the center of attraction in the research community due to the emergence of augmented, mixed, and virtual reality applications. The performance of such applications needs to be uptight to maintain the requirements of latency, energy consumption, and freshness of data. Therefore, a comprehensive performance analysis model is required to assess the effectiveness of an XR application but is challenging to design due to the dependence of the performance metrics on several difficult-to-model parameters, such as computing resources and hardware utilization of XR and edge devices, which are controlled by both their operating systems and the application itself. Moreover, the heterogeneity in devices and wireless access networks brings additional challenges in modeling. In this paper, we propose a novel modeling framework for performance analysis of XR applications considering edge-assisted wireless networks and validate the model with experimental data collected from testbeds designed specifically for XR applications. In addition, we present the challenges associated with performance analysis modeling and present methods to overcome them in detail. Finally, the performance evaluation shows that the proposed analytical model can analyze XR applications' performance with high accuracy compared to the state-of-the-art analytical models.</description>
      <guid isPermaLink="false">oai:arXiv.org:2405.07033v1</guid>
      <category>cs.NI</category>
      <category>cs.CV</category>
      <category>cs.DC</category>
      <category>eess.IV</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Anik Mallik, Jiang Xie, Zhu Han</dc:creator>
    </item>
    <item>
      <title>A hybrid meta-heuristic approach for channel estimation in OFDM MIMO</title>
      <link>https://arxiv.org/abs/2405.07189</link>
      <description>arXiv:2405.07189v1 Announce Type: new 
Abstract: In wireless communication Multiple Input Multiple Output (MIMO) technology has brought significant improvement in service by adopting Orthogonal Frequency Division Multiplexing (OFDM), a digital modulation technique. To achieve great performance with MIMO efficiently gathering channel state information (CSI) plays a vital role. Among different approach of channel estimation techniques data-aided channel estimation is more reliable. The existing methods of data-aided channel estimation are Least Square (LS) and Minimum Mean Square Error (MMSE) methods which do not achieve a great performance. Moreover, MMSE is little complex and has higher computational cost. That is why many attempts have been done previously to optimize the methods with help of meta heuristics and also other ways. In this paper we have tried to optimize LS estimation with a combined algorithm of Genetic Algorithm (GA) and Particle Swarm Optimization (PSO). The proposed algorithm has outperformed LS and MMSE. And it gives similar result if we optimize LS with standard PSO but in less numbers of iteration.</description>
      <guid isPermaLink="false">oai:arXiv.org:2405.07189v1</guid>
      <category>cs.NI</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <arxiv:journal_reference>Journal of Gono Bishwabidyalay, Vol. 4, Issue. 1, PP. 224-236, 2023</arxiv:journal_reference>
      <dc:creator>Shahriar Hassan, Umme Farhana, Md Karam Newaz</dc:creator>
    </item>
    <item>
      <title>QACM: QoS-Aware xApp Conflict Mitigation in Open RAN</title>
      <link>https://arxiv.org/abs/2405.07324</link>
      <description>arXiv:2405.07324v1 Announce Type: new 
Abstract: The advent of Open Radio Access Network (RAN) has revolutionized the field of RAN by introducing elements of native support of intelligence and openness into the next generation of mobile network infrastructure. Open RAN paves the way for standardized interfaces and enables the integration of network applications from diverse vendors, thereby enhancing network management flexibility. However, control decision conflicts occur when components from different vendors are deployed together. This article provides an overview of various types of conflicts that may occur in Open RAN, with a particular focus on intra-component conflict mitigation among Extended Applications (xApps) in the Near Real Time RAN Intelligent Controller (Near-RT-RIC). A QoS-Aware Conflict Mitigation (QACM) method is proposed that finds the optimal configuration of conflicting parameters while maximizing the number of xApps that have their Quality of Service (QoS) requirements met. We compare the performance of the proposed QACM method with two benchmark methods for priority and non-priority cases. The results indicate that our proposed method is the most effective in maintaining QoS requirements for conflicting xApps.</description>
      <guid isPermaLink="false">oai:arXiv.org:2405.07324v1</guid>
      <category>cs.NI</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Abdul Wadud, Fatemeh Golpayegani, Nima Afraz</dc:creator>
    </item>
    <item>
      <title>Power Evaluation of IOT Application Layer Protocols</title>
      <link>https://arxiv.org/abs/2405.07326</link>
      <description>arXiv:2405.07326v1 Announce Type: new 
Abstract: The Internet of Things has affected all aspects of daily life, and the number of IoT devices is increasing day by day. According to forecasts, the number of Internet of Things devices will reach one trillion devices by 2035. The increase in the number of devices connected to the Internet will cause various concerns. One of the most important concerns is the energy and power consumption of these devices. Although Internet of Things modules are low in energy consumption, their widespread and large-scale use has made the issue of power consumption become the most important challenge in this field. For this reason, it is necessary to use communication protocols that, in addition to establishing efficient communication, impose minimal power consumption on the network. In this paper, application layer protocols such as MQTT, MQTT-SN, CoAP, and HTTP are simulated using the tools available in the Contiki operating system, including COOJA and Powertrace, and they { are evaluated} and compared with each other in terms of power consumption. According to the simulations performed by the mentioned tools, the MQTT-SN protocol was the least consuming protocol in terms of power consumption. After that, the CoAP protocol is placed, and with a slight difference, the MQTT protocol, which consumes more than MQTT-SN. Finally, the HTTP protocol consumes the most power, which makes it unsuitable for communication in the Internet of Things</description>
      <guid isPermaLink="false">oai:arXiv.org:2405.07326v1</guid>
      <category>cs.NI</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-sa/4.0/</dc:rights>
      <dc:creator>Amirhossein Shahrokhi, Mahmood Ahmadi</dc:creator>
    </item>
    <item>
      <title>ZBanner: Fast Stateless Scanning Capable of Obtaining Responses over TCP</title>
      <link>https://arxiv.org/abs/2405.07409</link>
      <description>arXiv:2405.07409v1 Announce Type: new 
Abstract: Fast large-scale network scanning is an important way to understand internet service configurations and security in real time, among which stateless scan is representative. Existing stateless scanners can perform single-packet scans for internet-wide network measurements but are limited to host discovery or port scanning. To obtain further information over TCP, slower stateful scanners must be used in conjunction which spend more time and memory because of connection state maintenance. Through simplifying TCP finite state machine, this paper proposes a novel stateless scanning model, which can establish TCP connections and obtain further responses in a completely stateless manner. Based on this model, we implement ZBanner, an improved modular stateless scanner that utilizes user-defined probes for identifying services and versions, fingerprinting TLS servers, etc. We present unique design of ZBanner and experimentally characterize its feasibility and performance. Experiments show that ZBanner performs better than current state-of-the-art solutions in terms of scan rate and memory usage. ZBanner achieves at least three times faster than current tools for generic ports and over 90 times faster for open ports while keeping a minimum and stable memory usage.</description>
      <guid isPermaLink="false">oai:arXiv.org:2405.07409v1</guid>
      <category>cs.NI</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Chiyu Chen, Yuliang Lu, Guozheng Yang, Yi Xie, Shasha Guo</dc:creator>
    </item>
    <item>
      <title>La ROUTOURNE va tourner</title>
      <link>https://arxiv.org/abs/2405.07584</link>
      <description>arXiv:2405.07584v1 Announce Type: new 
Abstract: Segment routing (SR) offers precise control over the paths taken: it specifies a list of detours, called segments, in IP packets. However, the number of detours that can be specified is limited by the hardware. When calculating segment lists, it is therefore necessary to limit their size. Although solutions have been proposed for calculating these lists, they lack generality and are not always optimal or efficient. We present ROUTOURNE, a method for diverting routing algorithms so that they calculate, not simply an optimal physical path to be translated into a list of segments a posteriori (with no guarantee of its size), but directly the optimal lists of segments deployable by the underlying hardware. ROUTOURNE thus facilitates the deployment of advanced traffic engineering strategies and policies, notably for load balancing from sources. Despite a route fraught with surprising challenges - in particular, the loss of isotonicity induced by SR - ROUTOURNE proves efficient, inducing at worst a linear overhead. Its accuracy and optimality have been proven, and its effectiveness evaluated by generalizing it to several more or less complex path calculation algorithms.</description>
      <guid isPermaLink="false">oai:arXiv.org:2405.07584v1</guid>
      <category>cs.NI</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Quentin Bramas (ICube, UNISTRA), Jean-Romain Luttringer (ICube, UNISTRA), Pascal M\'erindol (ICube, UNISTRA)</dc:creator>
    </item>
    <item>
      <title>Empirical Application Insights on Industrial Data and Service Aspects of Digital Twin Networks</title>
      <link>https://arxiv.org/abs/2405.07605</link>
      <description>arXiv:2405.07605v1 Announce Type: new 
Abstract: Digital twin networks (DTNs) serve as an emerging facilitator in the industrial networking sector, enabling the management of new classes of services, which require tailored support for improved resource utilization, low latencies and accurate data fidelity. In this paper, we explore the intersection between theoretical recommendations and practical implications of applying DTNs to industrial networked environments, sharing empirical findings and lessons learned from our ongoing work. To this end, we first provide experimental examples from selected aspects of data representations and fidelity, mixed-criticality workload support, and application-driven services. Then, we introduce an architectural framework for DTNs, exposing a more practical extension of existing standards; notably the ITU-T Y.3090 (2022) recommendation. Specifically, we explore and discuss the dual nature of DTNs, meant as a digital twin of the network and a network of digital twins, allowing the co-existence of both paradigms.</description>
      <guid isPermaLink="false">oai:arXiv.org:2405.07605v1</guid>
      <category>cs.NI</category>
      <category>cs.ET</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <arxiv:journal_reference>IEEE MeditCom 2024</arxiv:journal_reference>
      <dc:creator>Marco Becattini, Davide Borsatti, Armir Bujari, Laura Carnevali, Andrea Garbugli, Hrant Khachatrian, Theofanis P. Raptis, Daniele Tarchi</dc:creator>
    </item>
    <item>
      <title>FNCC: Fast Notification Congestion Control in Data Center Networks</title>
      <link>https://arxiv.org/abs/2405.07608</link>
      <description>arXiv:2405.07608v1 Announce Type: new 
Abstract: Congestion control plays a pivotal role in large-scale data centers, facilitating ultra-low latency, high bandwidth, and optimal utilization. Even with the deployment of data center congestion control mechanisms such as DCQCN and HPCC, these algorithms often respond to congestion sluggishly. This sluggishness is primarily due to the slow notification of congestion. It takes almost one round-trip time (RTT) for the congestion information to reach the sender. In this paper, we introduce the Fast Notification Congestion Control (FNCC) mechanism, which achieves sub-RTT notification. FNCC leverages the acknowledgment packet (ACK) from the return path to carry in-network telemetry (INT) information of the request path, offering the sender more timely and accurate INT. To further accelerate the responsiveness of last-hop congestion control, we propose that the receiver notifies the sender of the number of concurrent congested flows, which can be used to adjust the congested flows to a fair rate quickly. Our experimental results demonstrate that FNCC reduces flow completion time by 27.4% and 88.9% compared to HPCC and DCQCN, respectively. Moreover, FNCC triggers minimal pause frames and maintains high utilization even at 400Gbps.</description>
      <guid isPermaLink="false">oai:arXiv.org:2405.07608v1</guid>
      <category>cs.NI</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Jing Xu, Zhan Wang, Fan Yang, Ning Kang, Zhenlong Ma, Xiaoyi Lu, Rui Miao, Guojun Yuan, Guangming Tan, Ninghui Sun</dc:creator>
    </item>
    <item>
      <title>End-to-End Delivery in LEO Mega-constellations and the Reordering Problem</title>
      <link>https://arxiv.org/abs/2405.07627</link>
      <description>arXiv:2405.07627v1 Announce Type: new 
Abstract: Low Earth orbit (LEO) satellite mega-constellations with hundreds or thousands of satellites and inter-satellite links (ISLs) have the potential to provide global end-to-end connectivity. Furthermore, if the physical distance between source and destination is sufficiently long, end-to-end routing over the LEO constellation can provide lower latency when compared to the terrestrial infrastructure due to the faster propagation of electromagnetic waves in space than in optic fiber. However, the frequent route changes due to the movement of the satellites result in the out-of-order delivery of packets, causing sudden changes to the Round-Trip Time (RTT) that can be misinterpreted as congestion by congestion control algorithms. In this paper, the performance of three widely used congestion control algorithms, Cubic, Reno, and BBR, is evaluated in an emulated LEO satellite constellation with Free-Space Optical (FSO) ISLs. Furthermore, we perform a sensitivity analysis for Cubic by changing the satellite constellation parameters, length of the routes, and the positions of the source and destination to identify problematic routing scenarios. The results show that route changes can have profound transient effects on the goodput of the connection, posing problems for typical broadband applications.</description>
      <guid isPermaLink="false">oai:arXiv.org:2405.07627v1</guid>
      <category>cs.NI</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Rasmus Sibbern Frederiksen, Thomas Gundgaard Mulvad, Israel Leyva-Mayorga, Tatiana Kozlova Madsen, Federico Chiariotti</dc:creator>
    </item>
    <item>
      <title>DoLLM: How Large Language Models Understanding Network Flow Data to Detect Carpet Bombing DDoS</title>
      <link>https://arxiv.org/abs/2405.07638</link>
      <description>arXiv:2405.07638v1 Announce Type: new 
Abstract: It is an interesting question Can and How Large Language Models (LLMs) understand non-language network data, and help us detect unknown malicious flows. This paper takes Carpet Bombing as a case study and shows how to exploit LLMs' powerful capability in the networking area. Carpet Bombing is a new DDoS attack that has dramatically increased in recent years, significantly threatening network infrastructures. It targets multiple victim IPs within subnets, causing congestion on access links and disrupting network services for a vast number of users. Characterized by low-rates, multi-vectors, these attacks challenge traditional DDoS defenses. We propose DoLLM, a DDoS detection model utilizes open-source LLMs as backbone. By reorganizing non-contextual network flows into Flow-Sequences and projecting them into LLMs semantic space as token embeddings, DoLLM leverages LLMs' contextual understanding to extract flow representations in overall network context. The representations are used to improve the DDoS detection performance. We evaluate DoLLM with public datasets CIC-DDoS2019 and real NetFlow trace from Top-3 countrywide ISP. The tests have proven that DoLLM possesses strong detection capabilities. Its F1 score increased by up to 33.3% in zero-shot scenarios and by at least 20.6% in real ISP traces.</description>
      <guid isPermaLink="false">oai:arXiv.org:2405.07638v1</guid>
      <category>cs.NI</category>
      <category>cs.AI</category>
      <category>cs.CR</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Qingyang Li, Yihang Zhang, Zhidong Jia, Yannan Hu, Lei Zhang, Jianrong Zhang, Yongming Xu, Yong Cui, Zongming Guo, Xinggong Zhang</dc:creator>
    </item>
    <item>
      <title>Waste Factor and Waste Figure: A Unified Theory for Modeling and Analyzing Wasted Power in Radio Access Networks for Improved Sustainability</title>
      <link>https://arxiv.org/abs/2405.07710</link>
      <description>arXiv:2405.07710v1 Announce Type: new 
Abstract: This paper introduces Waste Factor (W), also denoted as Waste Figure (WF) in dB, a promising new metric for quantifying energy efficiency in a wide range of circuits and systems applications, including data centers and RANs. Also, the networks used to connect data centers and AI computing engines with users for ML applications must become more power efficient. This paper illustrates the limitations of existing energy efficiency metrics that inadequately capture the intricate energy dynamics of RAN components. We delineate the methodology for applying W across various network configurations, including MISO, SIMO, and MIMO systems, and demonstrate the effectiveness of W in identifying energy optimization opportunities. Our findings reveal that W not only offers nuanced insights into the energy performance of RANs but also facilitates informed decision-making for network design and operational efficiency. Furthermore, we show how W can be integrated with other KPIs to guide the development of optimal strategies for enhancing network energy efficiency under different operational conditions. Additionally, we present simulation results for a distributed multi-user MIMO system at 3.5, 17, and 28 GHz, demonstrating overall network power efficiency on a per square kilometer basis, and show how overall W decreases with an increasing number of base stations and increasing carrier frequency. This paper shows that adopting W as a figure of merit can significantly contribute to the sustainability and energy optimization of next-generation wireless communication networks, paving the way for greener and more sustainable, energy-efficient 5G and 6G technologies.</description>
      <guid isPermaLink="false">oai:arXiv.org:2405.07710v1</guid>
      <category>cs.NI</category>
      <category>eess.SP</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Theodore S. Rappaport, Mingjun Ying, Nicola Piovesan, Antonio De Domenico, Dipankar Shakya</dc:creator>
    </item>
    <item>
      <title>Joint Robotic Aerial Base Station Deployment and Wireless Backhauling in 6G Multi-hop Networks</title>
      <link>https://arxiv.org/abs/2405.07714</link>
      <description>arXiv:2405.07714v1 Announce Type: new 
Abstract: Due to their ability to anchor into tall urban landforms, such as lampposts or street lights, robotic aerial base stations (RABSs) can create a hyper-flexible wireless multi-hop heterogeneous network to meet the forthcoming green, densified, and dynamic network deployment to support, inter alia, high data rates. In this work, we propose a network infrastructure that can concurrently support the wireless backhaul link capacity and access link traffic demand in the millimeter-wave (mmWave) frequency band. The RABSs grasping locations, resource blocks (RBs) assignment, and route flow control are simultaneously optimized to maximize the served traffic demands. Robotic base stations capitalize on the fact that traffic distribution varies considerably across both time and space within a given geographical area. Hence, they are able to relocate to suitable locations, i.e., 'follow' the traffic demand as it unfolds to increase the overall network efficiency. To tackle the curse of dimensionality of the proposed mixed-integer linear problem, we propose a greedy algorithm to obtain a competitive solution with low computational complexity. Compared to baseline models, which are heterogeneous networks with randomly deployed fixed small cells and pre-allocated RBs for wireless access and backhaul links, a wide set of numerical investigations reveals that robotic base stations could improve the served traffic demand. Specifically, the proposed mode serves at most 65\% more traffic demand compared to an equal number of deployed fixed small cells.</description>
      <guid isPermaLink="false">oai:arXiv.org:2405.07714v1</guid>
      <category>cs.NI</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Wen Shang, Yuan Liao, Vasilis Friderikos, Halim Yanikomeroglu</dc:creator>
    </item>
    <item>
      <title>Knowledge Graph Embedding in Intent-Based Networking</title>
      <link>https://arxiv.org/abs/2405.07850</link>
      <description>arXiv:2405.07850v1 Announce Type: new 
Abstract: This paper presents a novel approach to network management by integrating intent-based networking (IBN) with knowledge graphs (KGs), creating a more intuitive and efficient pipeline for service orchestration. By mapping high-level business intents onto network configurations using KGs, the system dynamically adapts to network changes and service demands, ensuring optimal performance and resource allocation. We utilize knowledge graph embedding (KGE) to acquire context information from the network and service providers. The KGE model is trained using a custom KG and Gaussian embedding model and maps intents to services via service prediction and intent validation processes. The proposed intent lifecycle enables intent translation and assurance by only deploying validated intents according to network and resource availability. We evaluate the trained model for its efficiency in service mapping and intent validation tasks using simulated environments and extensive experiments. The service prediction and intent verification accuracy greater than 80 percent is achieved for the trained KGE model on a custom service orchestration intent knowledge graph (IKG) based on TMForum's intent common model.</description>
      <guid isPermaLink="false">oai:arXiv.org:2405.07850v1</guid>
      <category>cs.NI</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Kashif Mehmood, Katina Kralevska, David Palma</dc:creator>
    </item>
    <item>
      <title>On User Association in Large-Scale Heterogeneous LEO Satellite Network</title>
      <link>https://arxiv.org/abs/2405.06978</link>
      <description>arXiv:2405.06978v1 Announce Type: cross 
Abstract: In this paper, we investigate the performance of large-scale heterogeneous low Earth orbit (LEO) satellite networks in the context of three association schemes. In contrast to existing studies, where single-tier LEO satellite-based network deployments are considered, the developed framework captures the heterogeneous nature of real-world satellite network deployments. More specifically, we propose an analytical framework to evaluate the performance of multi-tier LEO satellite-based networks, where the locations of LEO satellites are approximated as points of independent Poisson point processes, with different density, transmit power, and altitude. We propose three association schemes for the considered network topology based on: 1) the Euclidean distance, 2) the average received power, and 3) a random selection. By using stochastic geometry tools, analytical expressions for the association probability, the downlink coverage probability, as well as the spectral efficiency are derived for each association scheme, where the interference is considered. Moreover, we assess the achieved network performance under several different fading environments, including low, typical, and severe fading conditions, namely non-fading, shadowed-Rician and Rayleigh fading channels, respectively. Our results reveal the impact of fading channels on the coverage probability, and illustrate that the average power-based association scheme outperforms in terms of achieved coverage and spectral efficiency performance against the other two association policies. Furthermore, we highlight the impact of the proposed association schemes and the network topology on the optimal number of LEO satellites, providing guidance for the planning of multi-tier LEO satellite-based networks in order to enhance network performance.</description>
      <guid isPermaLink="false">oai:arXiv.org:2405.06978v1</guid>
      <category>cs.ET</category>
      <category>cs.NI</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/publicdomain/zero/1.0/</dc:rights>
      <dc:creator>Yuan Guo, Christodoulos Skouroumounis, Symeon Chatzinotas, Ioannis Krikidis</dc:creator>
    </item>
    <item>
      <title>Edge Intelligence Optimization for Large Language Model Inference with Batching and Quantization</title>
      <link>https://arxiv.org/abs/2405.07140</link>
      <description>arXiv:2405.07140v1 Announce Type: cross 
Abstract: Generative Artificial Intelligence (GAI) is taking the world by storm with its unparalleled content creation ability. Large Language Models (LLMs) are at the forefront of this movement. However, the significant resource demands of LLMs often require cloud hosting, which raises issues regarding privacy, latency, and usage limitations. Although edge intelligence has long been utilized to solve these challenges by enabling real-time AI computation on ubiquitous edge resources close to data sources, most research has focused on traditional AI models and has left a gap in addressing the unique characteristics of LLM inference, such as considerable model size, auto-regressive processes, and self-attention mechanisms. In this paper, we present an edge intelligence optimization problem tailored for LLM inference. Specifically, with the deployment of the batching technique and model quantization on resource-limited edge devices, we formulate an inference model for transformer decoder-based LLMs. Furthermore, our approach aims to maximize the inference throughput via batch scheduling and joint allocation of communication and computation resources, while also considering edge resource constraints and varying user requirements of latency and accuracy. To address this NP-hard problem, we develop an optimal Depth-First Tree-Searching algorithm with online tree-Pruning (DFTSP) that operates within a feasible time complexity. Simulation results indicate that DFTSP surpasses other batching benchmarks in throughput across diverse user settings and quantization techniques, and it reduces time complexity by over 45% compared to the brute-force searching method.</description>
      <guid isPermaLink="false">oai:arXiv.org:2405.07140v1</guid>
      <category>cs.LG</category>
      <category>cs.AI</category>
      <category>cs.NI</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Xinyuan Zhang, Jiang Liu, Zehui Xiong, Yudong Huang, Gaochang Xie, Ran Zhang</dc:creator>
    </item>
    <item>
      <title>DID Connect: Authentication in TLS with Decentralized Identifiers and Verifiable Credentials</title>
      <link>https://arxiv.org/abs/2405.07533</link>
      <description>arXiv:2405.07533v1 Announce Type: cross 
Abstract: Authentication in TLS is predominately carried out with X.509 digital certificates issued by certificate authorities (CA). The centralized nature of current public key infrastructures, however, comes along with severe risks, such as single points of failure and susceptibility to cyber-attacks, potentially undermining the security and trustworthiness of the entire system. With Decentralized Identifiers (DID) alongside distributed ledger technology, it becomes technically feasible to prove ownership of a unique identifier without requiring an attestation of the proof's public key by a centralized and therefore vulnerable CA. This article presents DID Connect, a novel authentication scheme for TLS 1.3 that empowers entities to authenticate in a TLS-compliant way with self-issued X.509 certificates that are equipped with ledger-anchored DIDs instead of CA-issued identifiers. It facilitates the exchange of tamper-proof and 3rd-party attested claims in the form of DID-bound Verifiable Credentials after the TLS handshake to complete the authentication with a full identification of the communication partner. A prototypical implementation shows comparable TLS handshake durations of DID Connect if verification material is cached and reasonable prolongations if it is obtained from a ledger. The significant speed improvement of the resulting TLS channel over a widely used, DID-based alternative transport protocol on the application layer demonstrates the potential of DID Connect to become a viable solution for the establishment of secure and trustful end-to-end communication links with decentrally managed digital identities.</description>
      <guid isPermaLink="false">oai:arXiv.org:2405.07533v1</guid>
      <category>cs.CR</category>
      <category>cs.NI</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Sandro Rodriguez Garzon, Dennis Natusch, Artur Philipp, Axel K\"upper, Hans Joachim Einsiedler, Daniela Schneider</dc:creator>
    </item>
    <item>
      <title>Entanglement Swapping in Orbit: a Satellite Quantum Link Case Study</title>
      <link>https://arxiv.org/abs/2405.07589</link>
      <description>arXiv:2405.07589v1 Announce Type: cross 
Abstract: Satellite quantum communication is a promising way to build long distance quantum links, making it an essential complement to optical fiber for quantum internetworking beyond metropolitan scales. A satellite point to point optical link differs from the more common fiber links in many ways, both quantitative (higher latency, strong losses) and qualitative (nonconstant parameter values during satellite passage, intermittency of the link, impossibility to set repeaters between the satellite and the ground station). We study here the performance of a quantum link between two ground stations, using a quantum-memory-equipped satellite as a quantum repeater. In contrast with quantum key distribution satellite links, the number of available quantum memory slots m, together with the unavoidable round-trip communication latency t of at least a few milliseconds, severely reduces the effective average repetition rate to m/t -- at most a few kilohertz for foreseeable quantum memories. Our study uses two approaches, which validate each other: 1) a simple analytical model of the effective rate of the quantum link; 2) an event-based simulation using the open source Quantum Internet Simulation Package (QuISP). The important differences between satellite and fiber links led us to modify QuISP itself. This work paves the way to the study of hybrid satellite- and fiber-based quantum repeater networks interconnecting different metropolitan areas.</description>
      <guid isPermaLink="false">oai:arXiv.org:2405.07589v1</guid>
      <category>quant-ph</category>
      <category>cs.NI</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Paolo Fittipaldi, Kentaro Teramoto, Naphan Benchasattabuse, Michal Hajdu\v{s}ek, Rodney Van Meter, Fr\'ed\'eric Grosshans</dc:creator>
    </item>
    <item>
      <title>Quality of Experience Optimization for Real-time XR Video Transmission with Energy Constraints</title>
      <link>https://arxiv.org/abs/2405.07689</link>
      <description>arXiv:2405.07689v1 Announce Type: cross 
Abstract: Extended Reality (XR) is an important service in the 5G network and in future 6G networks. In contrast to traditional video on demand services, real-time XR video is transmitted frame-by-frame, requiring low latency and being highly sensitive to network fluctuations. In this paper, we model the quality of experience (QoE) for real-time XR video transmission on a frame-by-frame basis. Based on the proposed QoE model, we formulate an optimization problem that maximizes QoE with constraints on wireless resources and long-term energy consumption. We utilize Lyapunov optimization to transform the original problem into a single-frame optimization problem and then allocate wireless subchannels. We propose an adaptive XR video bitrate algorithm that employs a Long Short Term Memory (LSTM) based Deep Q-Network (DQN) algorithm for video bitrate selection. Through numerical results, we show that our proposed algorithm outperforms the baseline algorithms, with the average QoE improvements of 0.04 to 0.46. Specifically, compared to baseline algorithms, the proposed algorithm reduces average video quality variations by 29% to 50% and improves the frame transmission success rate by 5% to 48%.</description>
      <guid isPermaLink="false">oai:arXiv.org:2405.07689v1</guid>
      <category>cs.MM</category>
      <category>cs.NI</category>
      <category>cs.SY</category>
      <category>eess.SY</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Guangjin Pan, Shugong Xu, Shunqing Zhang, Xiaojing Chen, Yanzan Sun</dc:creator>
    </item>
    <item>
      <title>MADRL-Based Rate Adaptation for 360$\degree$ Video Streaming with Multi-Viewpoint Prediction</title>
      <link>https://arxiv.org/abs/2405.07759</link>
      <description>arXiv:2405.07759v1 Announce Type: cross 
Abstract: Over the last few years, 360$\degree$ video traffic on the network has grown significantly. A key challenge of 360$\degree$ video playback is ensuring a high quality of experience (QoE) with limited network bandwidth. Currently, most studies focus on tile-based adaptive bitrate (ABR) streaming based on single viewport prediction to reduce bandwidth consumption. However, the performance of models for single-viewpoint prediction is severely limited by the inherent uncertainty in head movement, which can not cope with the sudden movement of users very well. This paper first presents a multimodal spatial-temporal attention transformer to generate multiple viewpoint trajectories with their probabilities given a historical trajectory. The proposed method models viewpoint prediction as a classification problem and uses attention mechanisms to capture the spatial and temporal characteristics of input video frames and viewpoint trajectories for multi-viewpoint prediction. After that, a multi-agent deep reinforcement learning (MADRL)-based ABR algorithm utilizing multi-viewpoint prediction for 360$\degree$ video streaming is proposed for maximizing different QoE objectives under various network conditions. We formulate the ABR problem as a decentralized partially observable Markov decision process (Dec-POMDP) problem and present a MAPPO algorithm based on centralized training and decentralized execution (CTDE) framework to solve the problem. The experimental results show that our proposed method improves the defined QoE metric by up to 85.5\% compared to existing ABR methods.</description>
      <guid isPermaLink="false">oai:arXiv.org:2405.07759v1</guid>
      <category>cs.MM</category>
      <category>cs.AI</category>
      <category>cs.NI</category>
      <category>eess.IV</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <arxiv:DOI>10.1109/JIOT.2024.3398548</arxiv:DOI>
      <dc:creator>Haopeng Wang, Zijian Long, Haiwei Dong, Abdulmotaleb El Saddik</dc:creator>
    </item>
    <item>
      <title>A Decentralized and Self-Adaptive Approach for Monitoring Volatile Edge Environments</title>
      <link>https://arxiv.org/abs/2405.07806</link>
      <description>arXiv:2405.07806v1 Announce Type: cross 
Abstract: Edge computing provides resources for IoT workloads at the network edge. Monitoring systems are vital for efficiently managing resources and application workloads by collecting, storing, and providing relevant information about the state of the resources. However, traditional monitoring systems have a centralized architecture for both data plane and control plane, which increases latency, creates a failure bottleneck, and faces challenges in providing quick and trustworthy data in volatile edge environments, especially where infrastructures are often built upon failure-prone, unsophisticated computing and network resources. Thus, we propose DEMon, a decentralized, self-adaptive monitoring system for edge. DEMon leverages the stochastic gossip communication protocol at its core. It develops efficient protocols for information dissemination, communication, and retrieval, avoiding a single point of failure and ensuring fast and trustworthy data access. Its decentralized control enables self-adaptive management of monitoring parameters, addressing the trade-offs between the quality of service of monitoring and resource consumption. We implement the proposed system as a lightweight and portable container-based system and evaluate it through experiments. We also present a use case demonstrating its feasibility. The results show that DEMon efficiently disseminates and retrieves the monitoring information, addressing the challenges of edge monitoring.</description>
      <guid isPermaLink="false">oai:arXiv.org:2405.07806v1</guid>
      <category>cs.DC</category>
      <category>cs.IR</category>
      <category>cs.NI</category>
      <category>cs.SY</category>
      <category>eess.SY</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Shashikant Ilager, Jakob Fahringer, Alessandro Tundo, Ivona Brandi\'c</dc:creator>
    </item>
    <item>
      <title>Efficient Direct-Connect Topologies for Collective Communications</title>
      <link>https://arxiv.org/abs/2202.03356</link>
      <description>arXiv:2202.03356v5 Announce Type: replace 
Abstract: We consider the problem of distilling efficient network topologies for collective communications. We provide an algorithmic framework for constructing direct-connect topologies optimized for the latency vs. bandwidth trade-off associated with the workload. Our approach synthesizes many different topologies and schedules for a given cluster size and degree and then identifies the appropriate topology and schedule for a given workload. Our algorithms start from small, optimal base topologies and associated communication schedules and use techniques that can be iteratively applied to derive much larger topologies and schedules. Additionally, we incorporate well-studied large-scale graph topologies into our algorithmic framework by producing efficient collective schedules for them using a novel polynomial-time algorithm. Our evaluation uses multiple testbeds and large-scale simulations to demonstrate significant performance benefits from our derived topologies and schedules.</description>
      <guid isPermaLink="false">oai:arXiv.org:2202.03356v5</guid>
      <category>cs.NI</category>
      <category>cs.DC</category>
      <category>cs.LG</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Liangyu Zhao, Siddharth Pal, Tapan Chugh, Weiyang Wang, Jason Fantl, Prithwish Basu, Joud Khoury, Arvind Krishnamurthy</dc:creator>
    </item>
    <item>
      <title>Survey on Near-Space Information Networks: Channel Modeling, Networking, and Transmission Perspectives</title>
      <link>https://arxiv.org/abs/2310.09025</link>
      <description>arXiv:2310.09025v4 Announce Type: replace 
Abstract: Near-space information networks (NSINs) composed of high-altitude platforms (HAPs) and high- and low-altitude unmanned aerial vehicles (UAVs) are a new regime for providing quick, robust, and cost-efficient sensing and communication services. Precipitated by innovations and breakthroughs in manufacturing, materials, communications, electronics, and control techniques, NSINs have been envisioned as an essential component of the emerging sixth-generation of mobile communication systems. This article reveals some critical issues needing to be tackled in NSINs through conducting experiments and discusses the latest advances in NSINs in the research areas of channel modeling, networking, and transmission from a forward-looking, comparative, and technical evolutionary perspective. In this article, we highlight the characteristics of NSINs and present the promising use cases of NSINs. The impact of airborne platforms' unstable movements on the phase delays of onboard antenna arrays with diverse structures is mathematically analyzed. The recent advances in HAP channel modeling are elaborated on, along with the significant differences between HAP and UAV channel modeling. A comprehensive review of the networking techniques of NSINs in network deployment, handoff management, and network management aspects is provided. Besides, the promising techniques and communication protocols of the physical (PHY) layer, medium access control (MAC) layer, network layer, and transport layer of NSINs for achieving efficient transmission over NSINs are reviewed, and we have conducted experiments with practical NSINs to verify the performance of some techniques. Finally, we outline some open issues and promising directions for NSINs deserved for future study and discuss the corresponding challenges.</description>
      <guid isPermaLink="false">oai:arXiv.org:2310.09025v4</guid>
      <category>cs.NI</category>
      <category>eess.SP</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Xianbin Cao, Peng Yang, Xiaoning Su</dc:creator>
    </item>
    <item>
      <title>HRL-TSCH: A Hierarchical Reinforcement Learning-based TSCH Scheduler for IIoT</title>
      <link>https://arxiv.org/abs/2401.10368</link>
      <description>arXiv:2401.10368v2 Announce Type: replace 
Abstract: The Industrial Internet of Things (IIoT) demands adaptable Networked Embedded Systems (NES) for optimal performance. Combined with recent advances in Artificial Intelligence (AI), tailored solutions can be developed to meet specific application requirements. This study introduces HRL-TSCH, an approach rooted in Hierarchical Reinforcement Learning (HRL), to devise Time Slotted Channel Hopping (TSCH) schedules provisioning IIoT demand. HRL-TSCH employs dual policies: one at a higher level for TSCH schedule link management, and another at a lower level for timeslot and channel assignments. The proposed RL agents address a multi-objective problem, optimizing throughput, power efficiency, and network delay based on predefined application requirements. Simulation experiments demonstrate HRL-TSCH superiority over existing state-of-art approaches, effectively achieving an optimal balance between throughput, power consumption, and delay, thereby enhancing IIoT network performance.</description>
      <guid isPermaLink="false">oai:arXiv.org:2401.10368v2</guid>
      <category>cs.NI</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>F. Fernando Jurado-Lasso, Charalampos Orfanidis, J. F. Jurado, Xenofon Fafoutis</dc:creator>
    </item>
    <item>
      <title>Joint AP-UE Association and Power Factor Optimization for Distributed Massive MIMO</title>
      <link>https://arxiv.org/abs/2402.14693</link>
      <description>arXiv:2402.14693v5 Announce Type: replace 
Abstract: The uplink sum-throughput of distributed massive multiple-input-multiple-output (mMIMO) networks depends majorly on Access point (AP)-User Equipment (UE) association and power control. The AP-UE association and power control both are important problems in their own right in distributed mMIMO networks to improve scalability and reduce front-haul load of the network, and to enhance the system performance by mitigating the interference and boosting the desired signals, respectively. Unlike previous studies, which focused primarily on addressing these two problems separately, this work addresses the uplink sum-throughput maximization problem in distributed mMIMO networks by solving the joint AP-UE association and power control problem, while maintaining Quality-of-Service (QoS) requirements for each UE. To improve scalability, we present an l1-penalty function that delicately balances the trade-off between spectral efficiency (SE) and front-haul signaling load. Our proposed methodology leverages fractional programming, Lagrangian dual formation, and penalty functions to provide an elegant and effective iterative solution with guaranteed convergence. Extensive numerical simulations validate the efficacy of the proposed technique for maximizing sum-throughput while considering the joint AP-UE association and power control problem, demonstrating its superiority over approaches that address these problems individually. Furthermore, the results show that the introduced penalty function can help us effectively control the maximum front-haul load.</description>
      <guid isPermaLink="false">oai:arXiv.org:2402.14693v5</guid>
      <category>cs.NI</category>
      <category>cs.IT</category>
      <category>math.IT</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Mohd Saif Ali Khan, Samar Agnihotri, Karthik R. M</dc:creator>
    </item>
    <item>
      <title>Non-Primary Channel Access in IEEE 802.11 UHR: Comprehensive Analysis and Evaluation</title>
      <link>https://arxiv.org/abs/2403.11300</link>
      <description>arXiv:2403.11300v2 Announce Type: replace 
Abstract: The evolution of the IEEE 802.11 standards marks a significant throughput advancement in wireless access technologies, progressively increasing bandwidth capacities from 20 MHz in the IEEE 802.11a to up to 320 MHz in the latest IEEE 802.11be (Wi-Fi 7). However, the increased bandwidth capacities may not be well exploited due to inefficient bandwidth utilization on multiple channels. This issue typically occurs when the primary channel is busy, secondary channels (also known as non-primary channels) are prevented from being utilized even if they are idle, thereby wasting the available bandwidth. This paper investigates the fundamentals of the Non-Primary Channel Access (NPCA) protocol that was defined in IEEE 802.11 Ultra-High Reliability (UHR) group to cope with the above issue. We develop a novel analytical model to assess NPCA protocol performance in terms of the average throughput and delay. Via simulation, we verify that the NPCA network outperforms the legacy network by increasing at least 50% average throughput while reducing at least 40% average delay.</description>
      <guid isPermaLink="false">oai:arXiv.org:2403.11300v2</guid>
      <category>cs.NI</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Dongyu Wei, Liu Cao, Lyutianyang Zhang, Xiangyu Gao, Hao Yin</dc:creator>
    </item>
    <item>
      <title>Accelerating Time-to-Science by Streaming Detector Data Directly into Perlmutter Compute Nodes</title>
      <link>https://arxiv.org/abs/2403.14352</link>
      <description>arXiv:2403.14352v2 Announce Type: replace 
Abstract: Recent advancements in detector technology have significantly increased the size and complexity of experimental data, and high-performance computing (HPC) provides a path towards more efficient and timely data processing. However, movement of large data sets from acquisition systems to HPC centers introduces bottlenecks owing to storage I/O at both ends. This manuscript introduces a streaming workflow designed for an high data rate electron detector that streams data directly to compute node memory at the National Energy Research Scientific Computing Center (NERSC), thereby avoiding storage I/O. The new workflow deploys ZeroMQ-based services for data production, aggregation, and distribution for on-the-fly processing, all coordinated through a distributed key-value store. The system is integrated with the detector's science gateway and utilizes the NERSC Superfacility API to initiate streaming jobs through a web-based frontend. Our approach achieves up to a 14-fold increase in data throughput and enhances predictability and reliability compared to a I/O-heavy file-based transfer workflow. Our work highlights the transformative potential of streaming workflows to expedite data analysis for time-sensitive experiments.</description>
      <guid isPermaLink="false">oai:arXiv.org:2403.14352v2</guid>
      <category>cs.NI</category>
      <category>cs.DC</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Samuel S. Welborn, Bjoern Enders, Chris Harris, Peter Ercius, Deborah J. Bard</dc:creator>
    </item>
    <item>
      <title>TrimCaching: Parameter-sharing Edge Caching for AI Model Downloading</title>
      <link>https://arxiv.org/abs/2404.14204</link>
      <description>arXiv:2404.14204v2 Announce Type: replace 
Abstract: Next-generation mobile networks are expected to facilitate fast AI model downloading to end users. By caching models on edge servers, mobile networks can deliver models to end users with low latency, resulting in a paradigm called edge model caching. In this paper, we develop a novel model placement scheme, called parameter-sharing model caching (TrimCaching). TrimCaching exploits the key observation that a wide range of AI models, such as convolutional neural networks or large language models, can share a significant proportion of parameter blocks containing reusable knowledge, thereby improving storage efficiency. To this end, we formulate a parameter-sharing model placement problem to maximize the cache hit ratio in multi-edge wireless networks by balancing the fundamental tradeoff between storage efficiency and service latency. We show that the formulated problem is a submodular maximization problem with submodular constraints, for which no polynomial-time approximation algorithm exists. To overcome this challenge, we study an important special case, where a small fixed number of parameter blocks are shared across models, which often holds in practice. In such a case, a polynomial-time algorithm with $\left(1-\epsilon\right)/2$-approximation guarantee is developed. Subsequently, we address the original problem for the general case by developing a greedy algorithm. Simulation results demonstrate that the proposed TrimCaching framework significantly improves the cache hit ratio compared with state-of-the-art content caching without exploiting shared parameters in AI models.</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.14204v2</guid>
      <category>cs.NI</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Guanqiao Qu, Zheng Lin, Qian Chen, Jian Li, Fangming Liu, Xianhao Chen, Kaibin Huang</dc:creator>
    </item>
  </channel>
</rss>
