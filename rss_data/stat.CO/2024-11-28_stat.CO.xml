<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>stat.CO updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/stat.CO</link>
    <description>stat.CO updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/stat.CO" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Thu, 28 Nov 2024 05:01:12 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Thu, 28 Nov 2024 00:00:00 -0500</pubDate>
    <skipDays>
      <day>Saturday</day>
      <day>Sunday</day>
    </skipDays>
    <item>
      <title>spar: Sparse Projected Averaged Regression in R</title>
      <link>https://arxiv.org/abs/2411.17808</link>
      <description>arXiv:2411.17808v1 Announce Type: new 
Abstract: Package spar for R builds ensembles of predictive generalized linear models with high-dimensional predictors. It employs an algorithm utilizing variable screening and random projection tools to efficiently handle the computational challenges associated with large sets of predictors. The package is designed with a strong focus on extensibility. Screening and random projection techniques are implemented as S3 classes with user-friendly constructor functions, enabling users to easily integrate and develop new procedures. This design enhances the package's adaptability and makes it a powerful tool for a variety of high-dimensional applications.</description>
      <guid isPermaLink="false">oai:arXiv.org:2411.17808v1</guid>
      <category>stat.CO</category>
      <category>stat.ME</category>
      <pubDate>Thu, 28 Nov 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Roman Parzer, Laura Vana-G\"ur, Peter Filzmoser</dc:creator>
    </item>
    <item>
      <title>Sparse twoblock dimension reduction for simultaneous compression and variable selection in two blocks of variables</title>
      <link>https://arxiv.org/abs/2411.17859</link>
      <description>arXiv:2411.17859v1 Announce Type: cross 
Abstract: A method is introduced to perform simultaneous sparse dimension reduction on two blocks of variables. Beyond dimension reduction, it also yields an estimator for multivariate regression with the capability to intrinsically deselect uninformative variables in both independent and dependent blocks. An algorithm is provided that leads to a straightforward implementation of the method. The benefits of simultaneous sparse dimension reduction are shown to carry through to enhanced capability to predict a set of multivariate dependent variables jointly. Both in a simulation study and in two chemometric applications, the new method outperforms its dense counterpart, as well as multivariate partial least squares.</description>
      <guid isPermaLink="false">oai:arXiv.org:2411.17859v1</guid>
      <category>stat.ME</category>
      <category>stat.CO</category>
      <pubDate>Thu, 28 Nov 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <dc:creator>Sven Serneels</dc:creator>
    </item>
    <item>
      <title>Exponential speed up in Monte Carlo sampling through Radial Updates</title>
      <link>https://arxiv.org/abs/2411.18218</link>
      <description>arXiv:2411.18218v1 Announce Type: cross 
Abstract: Very recently it has been shown that the hybrid Monte Carlo (HMC) algorithm is guaranteed to converge exponentially to a given target probability distribution $p(x)\propto e^{-V(x)}$ on non-compact spaces if augmented by an appropriate radial update. In this work we present a simple way to derive efficient radial updates meeting the necessary requirements for any potential $V$. We reduce the task to finding a substitution of the radial direction $||x||=f(z)$ so that the effective potential $V(f(z))$ grows exponentially with $z\rightarrow\pm\infty$. Any additive update of $z$ then leads to the desired convergence. We show that choosing this update from a normal distribution with standard deviation $\sigma\approx 1/\sqrt{d}$ in $d$ dimensions yields very good results. We further generalise the previous results on radial updates to a wide class of Markov chain Monte Carlo (MCMC) algorithms beyond the HMC and we quantify the convergence behaviour of MCMC algorithms with badly chosen radial update. Finally, we apply the radial update to the sampling of heavy-tailed distributions and achieve a speed up of many orders of magnitude.</description>
      <guid isPermaLink="false">oai:arXiv.org:2411.18218v1</guid>
      <category>physics.comp-ph</category>
      <category>cs.NA</category>
      <category>hep-lat</category>
      <category>math.NA</category>
      <category>stat.CO</category>
      <pubDate>Thu, 28 Nov 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Johann Ostmeyer</dc:creator>
    </item>
    <item>
      <title>On an EM-based closed-form solution for 2 parameter IRT models</title>
      <link>https://arxiv.org/abs/2411.18351</link>
      <description>arXiv:2411.18351v1 Announce Type: cross 
Abstract: It is a well-known issue that in Item Response Theory models there is no closed-form for the maximum likelihood estimators of the item parameters. Parameter estimation is therefore typically achieved by means of numerical methods like gradient search. The present work has a two-fold aim: On the one hand, we revise the fundamental notions associated to the item parameter estimation in 2 parameter Item Response Theory models from the perspective of the complete-data likelihood. On the other hand, we argue that, within an Expectation-Maximization approach, a closed-form for discrimination and difficulty parameters can actually be obtained that simply corresponds to the Ordinary Least Square solution.</description>
      <guid isPermaLink="false">oai:arXiv.org:2411.18351v1</guid>
      <category>stat.ME</category>
      <category>stat.CO</category>
      <pubDate>Thu, 28 Nov 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Stefano Noventa (Methods Center, University of Tuebingen), Roberto Faleh (Methods Center, University of Tuebingen), Augustin Kelava (Methods Center, University of Tuebingen)</dc:creator>
    </item>
    <item>
      <title>Probabilistic size-and-shape functional mixed models</title>
      <link>https://arxiv.org/abs/2411.18416</link>
      <description>arXiv:2411.18416v1 Announce Type: cross 
Abstract: The reliable recovery and uncertainty quantification of a fixed effect function $\mu$ in a functional mixed model, for modelling population- and object-level variability in noisily observed functional data, is a notoriously challenging task: variations along the $x$ and $y$ axes are confounded with additive measurement error, and cannot in general be disentangled. The question then as to what properties of $\mu$ may be reliably recovered becomes important. We demonstrate that it is possible to recover the size-and-shape of a square-integrable $\mu$ under a Bayesian functional mixed model. The size-and-shape of $\mu$ is a geometric property invariant to a family of space-time unitary transformations, viewed as rotations of the Hilbert space, that jointly transform the $x$ and $y$ axes. A random object-level unitary transformation then captures size-and-shape \emph{preserving} deviations of $\mu$ from an individual function, while a random linear term and measurement error capture size-and-shape \emph{altering} deviations. The model is regularized by appropriate priors on the unitary transformations, posterior summaries of which may then be suitably interpreted as optimal data-driven rotations of a fixed orthonormal basis for the Hilbert space. Our numerical experiments demonstrate utility of the proposed model, and superiority over the current state-of-the-art.</description>
      <guid isPermaLink="false">oai:arXiv.org:2411.18416v1</guid>
      <category>stat.ME</category>
      <category>stat.CO</category>
      <category>stat.ML</category>
      <pubDate>Thu, 28 Nov 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Fangyi Wang, Karthik Bharath, Oksana Chkrebtii, Sebastian Kurtek</dc:creator>
    </item>
    <item>
      <title>Bhirkuti's Test of Bias Acceptance: Examining in Psychometric Simulations</title>
      <link>https://arxiv.org/abs/2411.18481</link>
      <description>arXiv:2411.18481v1 Announce Type: cross 
Abstract: This study introduces Bhirkuti's Test of Bias Acceptance, a systematic graphical framework for evaluating bias and determining its acceptability under varying experimental conditions. Absolute Relative Bias (ARB), while useful for understanding bias, is sensitive to outliers and population parameter magnitudes, often overstating bias for small values and understating it for larger ones. Similarly, Relative Efficiency (RE) can be influenced by variance differences and outliers, occasionally producing counterintuitive values exceeding 100%, which complicates interpretation. By addressing the limitations of traditional metrics such as Absolute Relative Bias (ARB) and Relative Efficiency (RE), the proposed graphical methodology framework leverages ridgeline plots and standardized estimate to provide a comprehensive visualization of parameter estimate distributions. Ridgeline plots done this way offer a robust alternative by visualizing full distributions, highlighting variability, trends, outliers, descriptive and facilitating more informed decision-making. This study employs multivariate Latent Growth Models (LGM) and Monte Carlo simulations to examine the performance of growth curve modeling under planned missing data designs, focusing on parameter estimate recovery and efficiency. By combining innovative visualization techniques with rigorous simulation methods, Bhirkuti's Test of Bias Acceptance provides a versatile and interpretable toolset for advancing quantitative research in bias evaluation and efficiency assessment.</description>
      <guid isPermaLink="false">oai:arXiv.org:2411.18481v1</guid>
      <category>stat.ME</category>
      <category>stat.AP</category>
      <category>stat.CO</category>
      <category>stat.OT</category>
      <pubDate>Thu, 28 Nov 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Aneel Bhusal, Todd D. Little</dc:creator>
    </item>
  </channel>
</rss>
