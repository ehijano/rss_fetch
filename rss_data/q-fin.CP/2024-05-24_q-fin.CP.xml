<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>q-fin.CP updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/q-fin.CP</link>
    <description>q-fin.CP updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/q-fin.CP" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Fri, 24 May 2024 04:00:10 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Fri, 24 May 2024 00:00:00 -0400</pubDate>
    <skipDays>
      <day>Saturday</day>
      <day>Sunday</day>
    </skipDays>
    <item>
      <title>Trading Volume Maximization with Online Learning</title>
      <link>https://arxiv.org/abs/2405.13102</link>
      <description>arXiv:2405.13102v1 Announce Type: cross 
Abstract: We explore brokerage between traders in an online learning framework. At any round $t$, two traders meet to exchange an asset, provided the exchange is mutually beneficial. The broker proposes a trading price, and each trader tries to sell their asset or buy the asset from the other party, depending on whether the price is higher or lower than their private valuations. A trade happens if one trader is willing to sell and the other is willing to buy at the proposed price. Previous work provided guidance to a broker aiming at enhancing traders' total earnings by maximizing the gain from trade, defined as the sum of the traders' net utilities after each interaction. In contrast, we investigate how the broker should behave to maximize the trading volume, i.e., the total number of trades. We model the traders' valuations as an i.i.d. process with an unknown distribution. If the traders' valuations are revealed after each interaction (full-feedback), and the traders' valuations cumulative distribution function (cdf) is continuous, we provide an algorithm achieving logarithmic regret and show its optimality up to constant factors. If only their willingness to sell or buy at the proposed price is revealed after each interaction ($2$-bit feedback), we provide an algorithm achieving poly-logarithmic regret when the traders' valuations cdf is Lipschitz and show that this rate is near-optimal. We complement our results by analyzing the implications of dropping the regularity assumptions on the unknown traders' valuations cdf. If we drop the continuous cdf assumption, the regret rate degrades to $\Theta(\sqrt{T})$ in the full-feedback case, where $T$ is the time horizon. If we drop the Lipschitz cdf assumption, learning becomes impossible in the $2$-bit feedback case.</description>
      <guid isPermaLink="false">oai:arXiv.org:2405.13102v1</guid>
      <category>cs.GT</category>
      <category>cs.LG</category>
      <category>q-fin.CP</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Tommaso Cesari, Roberto Colomboni</dc:creator>
    </item>
    <item>
      <title>An Asymptotic CVaR Measure of Risk for Markov Chains</title>
      <link>https://arxiv.org/abs/2405.13513</link>
      <description>arXiv:2405.13513v1 Announce Type: cross 
Abstract: Risk sensitive decision making finds important applications in current day use cases. Existing risk measures consider a single or finite collection of random variables, which do not account for the asymptotic behaviour of underlying systems. Conditional Value at Risk (CVaR) is the most commonly used risk measure, and has been extensively utilized for modelling rare events in finite horizon scenarios. Naive extension of existing risk criteria to asymptotic regimes faces fundamental challenges, where basic assumptions of existing risk measures fail. We present a complete simulation based approach for sequentially computing Asymptotic CVaR (ACVaR), a risk measure we define on limiting empirical averages of markovian rewards. Large deviations theory, density estimation, and two-time scale stochastic approximation are utilized to define a 'tilted' probability kernel on the underlying state space to facilitate ACVaR simulation. Our algorithm enjoys theoretical guarantees, and we numerically evaluate its performance over a variety of test cases.</description>
      <guid isPermaLink="false">oai:arXiv.org:2405.13513v1</guid>
      <category>q-fin.RM</category>
      <category>q-fin.CP</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Shivam Patel, Vivek Borkar</dc:creator>
    </item>
    <item>
      <title>Tackling Decision Processes with Non-Cumulative Objectives using Reinforcement Learning</title>
      <link>https://arxiv.org/abs/2405.13609</link>
      <description>arXiv:2405.13609v1 Announce Type: cross 
Abstract: Markov decision processes (MDPs) are used to model a wide variety of applications ranging from game playing over robotics to finance. Their optimal policy typically maximizes the expected sum of rewards given at each step of the decision process. However, a large class of problems does not fit straightforwardly into this framework: Non-cumulative Markov decision processes (NCMDPs), where instead of the expected sum of rewards, the expected value of an arbitrary function of the rewards is maximized. Example functions include the maximum of the rewards or their mean divided by their standard deviation. In this work, we introduce a general mapping of NCMDPs to standard MDPs. This allows all techniques developed to find optimal policies for MDPs, such as reinforcement learning or dynamic programming, to be directly applied to the larger class of NCMDPs. Focusing on reinforcement learning, we show applications in a diverse set of tasks, including classical control, portfolio optimization in finance, and discrete optimization problems. Given our approach, we can improve both final performance and training time compared to relying on standard MDPs.</description>
      <guid isPermaLink="false">oai:arXiv.org:2405.13609v1</guid>
      <category>cs.LG</category>
      <category>q-fin.CP</category>
      <category>quant-ph</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Maximilian N\"agele, Jan Olle, Thomas F\"osel, Remmy Zen, Florian Marquardt</dc:creator>
    </item>
    <item>
      <title>Stochastic arbitrage with market index options</title>
      <link>https://arxiv.org/abs/2207.00949</link>
      <description>arXiv:2207.00949v3 Announce Type: replace 
Abstract: Opportunities for stochastic arbitrage in an options market arise when it is possible to construct a portfolio of options which provides a positive option premium and which, when combined with a direct investment in the underlying asset, generates a payoff which stochastically dominates the payoff from the direct investment in the underlying asset. We provide linear and mixed-integer linear programs for computing the stochastic arbitrage opportunity providing the maximum option premium to an investor. We apply our programs to 18 years of data on monthly put and call options on the Standard &amp; Poors 500 index, confining attention to options with moderate moneyness, and using two specifications of the underlying asset return distribution, one symmetric and one skewed. The pricing of market index options with moderate moneyness appears to be broadly consistent with our skewed specification of market returns.</description>
      <guid isPermaLink="false">oai:arXiv.org:2207.00949v3</guid>
      <category>q-fin.CP</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Brendan K. Beare, Juwon Seo, Zhongxi Zheng</dc:creator>
    </item>
    <item>
      <title>Efficient Risk Estimation for the Credit Valuation Adjustment</title>
      <link>https://arxiv.org/abs/2301.05886</link>
      <description>arXiv:2301.05886v2 Announce Type: replace 
Abstract: The valuation of over-the-counter derivatives is subject to a series of valuation adjustments known as xVA, which pose additional risks for financial institutions. Associated risk measures, such as the value-at-risk of an underlying valuation adjustment, play an important role in managing these risks. Monte Carlo methods are often regarded as inefficient for computing such measures. As an example, we consider the value-at-risk of the Credit Valuation Adjustment (CVA-VaR), which can be expressed using a triple nested expectation. Traditional Monte Carlo methods are often inefficient at handling several nested expectations. Utilising recent developments in multilevel nested simulation for probabilities, we construct a hierarchical estimator of the CVA-VaR which reduces the computational complexity by 3 orders of magnitude compared to standard Monte Carlo.</description>
      <guid isPermaLink="false">oai:arXiv.org:2301.05886v2</guid>
      <category>q-fin.CP</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Michael B. Giles, Abdul-Lateef Haji-Ali, Jonathan Spence</dc:creator>
    </item>
    <item>
      <title>Convergence of the deep BSDE method for stochastic control problems formulated through the stochastic maximum principle</title>
      <link>https://arxiv.org/abs/2401.17472</link>
      <description>arXiv:2401.17472v2 Announce Type: replace-cross 
Abstract: It is well-known that decision-making problems from stochastic control can be formulated by means of a forward-backward stochastic differential equation (FBSDE). Recently, the authors of Ji et al. 2022 proposed an efficient deep learning algorithm based on the stochastic maximum principle (SMP). In this paper, we provide a convergence result for this deep SMP-BSDE algorithm and compare its performance with other existing methods. In particular, by adopting a strategy as in Han and Long 2020, we derive a-posteriori estimate, and show that the total approximation error can be bounded by the value of the loss functional and the discretization error. We present numerical examples for high-dimensional stochastic control problems, both in case of drift- and diffusion control, which showcase superior performance compared to existing algorithms.</description>
      <guid isPermaLink="false">oai:arXiv.org:2401.17472v2</guid>
      <category>math.OC</category>
      <category>cs.NA</category>
      <category>math.NA</category>
      <category>q-fin.CP</category>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Zhipeng Huang, Balint Negyesi, Cornelis W. Oosterlee</dc:creator>
    </item>
  </channel>
</rss>
