<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>cs.CY updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/cs.CY</link>
    <description>cs.CY updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/cs.CY" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Wed, 11 Dec 2024 02:51:55 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Tue, 10 Dec 2024 00:00:00 -0500</pubDate>
    <skipDays>
      <day>Sunday</day>
      <day>Saturday</day>
    </skipDays>
    <item>
      <title>International Scientific Report on the Safety of Advanced AI (Interim Report)</title>
      <link>https://arxiv.org/abs/2412.05282</link>
      <description>arXiv:2412.05282v1 Announce Type: new 
Abstract: This is the interim publication of the first International Scientific Report on the Safety of Advanced AI. The report synthesises the scientific understanding of general-purpose AI -- AI that can perform a wide variety of tasks -- with a focus on understanding and managing its risks. A diverse group of 75 AI experts contributed to this report, including an international Expert Advisory Panel nominated by 30 countries, the EU, and the UN. Led by the Chair, these independent experts collectively had full discretion over the report's content.</description>
      <guid isPermaLink="false">oai:arXiv.org:2412.05282v1</guid>
      <category>cs.CY</category>
      <category>cs.AI</category>
      <pubDate>Tue, 10 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Yoshua Bengio, S\"oren Mindermann, Daniel Privitera, Tamay Besiroglu, Rishi Bommasani, Stephen Casper, Yejin Choi, Danielle Goldfarb, Hoda Heidari, Leila Khalatbari, Shayne Longpre, Vasilios Mavroudis, Mantas Mazeika, Kwan Yee Ng, Chinasa T. Okolo, Deborah Raji, Theodora Skeadas, Florian Tram\`er, Bayo Adekanmbi, Paul Christiano, David Dalrymple, Thomas G. Dietterich, Edward Felten, Pascale Fung, Pierre-Olivier Gourinchas, Nick Jennings, Andreas Krause, Percy Liang, Teresa Ludermir, Vidushi Marda, Helen Margetts, John A. McDermid, Arvind Narayanan, Alondra Nelson, Alice Oh, Gopal Ramchurn, Stuart Russell, Marietje Schaake, Dawn Song, Alvaro Soto, Lee Tiedrich, Ga\"el Varoquaux, Andrew Yao, Ya-Qin Zhang</dc:creator>
    </item>
    <item>
      <title>Can OpenAI o1 outperform humans in higher-order cognitive thinking?</title>
      <link>https://arxiv.org/abs/2412.05753</link>
      <description>arXiv:2412.05753v1 Announce Type: new 
Abstract: This study evaluates the performance of OpenAI's o1-preview model in higher-order cognitive domains, including critical thinking, systematic thinking, computational thinking, data literacy, creative thinking, logical reasoning, and scientific reasoning. Using established benchmarks, we compared the o1-preview models's performance to human participants from diverse educational levels. o1-preview achieved a mean score of 24.33 on the Ennis-Weir Critical Thinking Essay Test (EWCTET), surpassing undergraduate (13.8) and postgraduate (18.39) participants (z = 1.60 and 0.90, respectively). In systematic thinking, it scored 46.1, SD = 4.12 on the Lake Urmia Vignette, significantly outperforming the human mean (20.08, SD = 8.13, z = 3.20). For data literacy, o1-preview scored 8.60, SD = 0.70 on Merk et al.'s "Use Data" dimension, compared to the human post-test mean of 4.17, SD = 2.02 (z = 2.19). On creative thinking tasks, the model achieved originality scores of 2.98, SD = 0.73, higher than the human mean of 1.74 (z = 0.71). In logical reasoning (LogiQA), it outperformed humans with average 90%, SD = 10% accuracy versus 86%, SD = 6.5% (z = 0.62). For scientific reasoning, it achieved near-perfect performance (mean = 0.99, SD = 0.12) on the TOSLS,, exceeding the highest human scores of 0.85, SD = 0.13 (z = 1.78). While o1-preview excelled in structured tasks, it showed limitations in problem-solving and adaptive reasoning. These results demonstrate the potential of AI to complement education in structured assessments but highlight the need for ethical oversight and refinement for broader applications.</description>
      <guid isPermaLink="false">oai:arXiv.org:2412.05753v1</guid>
      <category>cs.CY</category>
      <category>cs.AI</category>
      <pubDate>Tue, 10 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Ehsan Latif, Yifan Zhou, Shuchen Guo, Lehong Shi, Yizhu Gao, Matthew Nyaaba, Arne Bewerdorff, Xiantong Yang, Xiaoming Zhai</dc:creator>
    </item>
    <item>
      <title>Interactions Between Artificial Intelligence and Digital Public Infrastructure: Concepts, Benefits, and Challenges</title>
      <link>https://arxiv.org/abs/2412.05761</link>
      <description>arXiv:2412.05761v1 Announce Type: new 
Abstract: Artificial intelligence (AI) and digital public infrastructure (DPI) are two technological developments that have taken center stage in global policy discourse. Yet, to date, there has been relatively little discussion about how AI and DPI can mutually enhance the public value provided by each other. Therefore, in this paper, we describe both the opportunities and challenges under which AI and DPI can interact for mutual benefit. First, we define both AI and DPI to provide clarity and help policymakers distinguish between these two technological developments. Second, we provide empirical evidence for how AI, a general-purpose technology, can integrate into many DPI systems, aiding DPI function in use cases like language localization via machine translation (MT), personalized service delivery via recommender systems, and more. Third, we catalog how DPI can act as a foundation for creating more advanced AI systems by improving both the quantity and quality of training data available. Fourth, we discuss the challenges of integrating AI and DPI, including high inference costs for advanced AI models, interoperability challenges with legacy software, concerns about induced bias in AI systems, and privacy challenges related to DPI. We conclude with key takeaways for how policymakers can work to enhance the positive interactions of AI and DPI.</description>
      <guid isPermaLink="false">oai:arXiv.org:2412.05761v1</guid>
      <category>cs.CY</category>
      <pubDate>Tue, 10 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Sarosh Nagar, David Eaves</dc:creator>
    </item>
    <item>
      <title>Fairness in Computational Innovations: Identifying Bias in Substance Use Treatment Length of Stay Prediction Models with Policy Implications</title>
      <link>https://arxiv.org/abs/2412.05832</link>
      <description>arXiv:2412.05832v1 Announce Type: new 
Abstract: Predictive machine learning (ML) models are computational innovations that can enhance medical decision-making, including aiding in determining optimal timing for discharging patients. However, societal biases can be encoded into such models, raising concerns about inadvertently affecting health outcomes for disadvantaged groups. This issue is particularly pressing in the context of substance use disorder (SUD) treatment, where biases in predictive models could significantly impact the recovery of highly vulnerable patients. In this study, we focus on the development and assessment of ML models designed to predict the length of stay (LOS) for both inpatients (i.e., residential) and outpatients undergoing SUD treatment. We utilize the Treatment Episode Data Set for Discharges (TEDS-D) from the Substance Abuse and Mental Health Services Administration (SAMHSA). Through the lenses of distributive justice and socio-relational fairness, we assess our models for bias across variables related to demographics (e.g., race) as well as medical (e.g., diagnosis) and financial conditions (e.g., insurance). We find that race, US geographic region, type of substance used, diagnosis, and payment source for treatment are primary indicators of unfairness. From a policy perspective, we provide bias mitigation strategies to achieve fair outcomes. We discuss the implications of these findings for medical decision-making and health equity. We ultimately seek to contribute to the innovation and policy-making literature by seeking to advance the broader objectives of social justice when applying computational innovations in health care.</description>
      <guid isPermaLink="false">oai:arXiv.org:2412.05832v1</guid>
      <category>cs.CY</category>
      <category>cs.HC</category>
      <pubDate>Tue, 10 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <dc:creator>Ugur Kursuncu, Aaron Baird, Yusen Xia</dc:creator>
    </item>
    <item>
      <title>Optimizing Location Allocation in Urban Management: A Brief Review</title>
      <link>https://arxiv.org/abs/2412.06032</link>
      <description>arXiv:2412.06032v1 Announce Type: new 
Abstract: Regarding the concepts of urban management, digital transformation, and smart cities, various issues are presented. Currently, we like to attend to location allocation problems that can be a new part of digital transformation in urban management (such as locating and placing facilities, locating and arranging centers such as aid and rescue centers, or even postal hubs, telecommunications, electronic equipment, and data centers, and routing in transportation optimization). These issues, which are seemingly simple but in practice complex, are important in urban environments, and the issue of accurate location allocation based on existing criteria directly impacts cost management, profit, efficiency, and citizen satisfaction. In recent years, researchers have used or presented various models and methods for location allocation problems, some of which will be mentioned in this article. Given the nature of these problems, which are optimization problems, this article will also examine existing research from an optimization perspective in summary. Finally, a brief conclusion will be made of the existing methods and their weaknesses, and suggestions will be made for continuing the path and improving scientific and practical research in this field.</description>
      <guid isPermaLink="false">oai:arXiv.org:2412.06032v1</guid>
      <category>cs.CY</category>
      <pubDate>Tue, 10 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <dc:creator>Aref Ayati, Mohammad Mahdi Hashemi, Mohsen Saffar, Hamid Reza Naji</dc:creator>
    </item>
    <item>
      <title>The Unpaid Toll: Quantifying the Public Health Impact of AI</title>
      <link>https://arxiv.org/abs/2412.06288</link>
      <description>arXiv:2412.06288v1 Announce Type: new 
Abstract: The surging demand for AI has led to a rapid expansion of energy-intensive data centers, impacting the environment through escalating carbon emissions and water consumption. While significant attention has been paid to AI's growing environmental footprint, the public health burden, a hidden toll of AI, has been largely overlooked. Specifically, AI's lifecycle, from chip manufacturing to data center operation, significantly degrades air quality through emissions of criteria air pollutants such as fine particulate matter, substantially impacting public health. This paper introduces a methodology to model pollutant emissions across AI's lifecycle, quantifying the public health impacts. Our findings reveal that training an AI model of the Llama3.1 scale can produce air pollutants equivalent to more than 10,000 round trips by car between Los Angeles and New York City. The total public health burden of U.S. data centers in 2030 is valued at up to more than $20 billion per year, double that of U.S. coal-based steelmaking and comparable to that of on-road emissions of California. Further, the public health costs unevenly impact economically disadvantaged communities, where the per-household health burden could be 200x more than that in less-impacted communities. We recommend adopting a standard reporting protocol for criteria air pollutants and the public health costs of AI, paying attention to all impacted communities, and implementing health-informed AI to mitigate adverse effects while promoting public health equity.</description>
      <guid isPermaLink="false">oai:arXiv.org:2412.06288v1</guid>
      <category>cs.CY</category>
      <pubDate>Tue, 10 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Yuelin Han, Zhifeng Wu, Pengfei Li, Adam Wierman, Shaolei Ren</dc:creator>
    </item>
    <item>
      <title>Towards Civic Digital Twins: Co-Design the Citizen-Centric Future of Bologna</title>
      <link>https://arxiv.org/abs/2412.06328</link>
      <description>arXiv:2412.06328v1 Announce Type: new 
Abstract: We introduce Civic Digital Twin (CDT), an evolution of Urban Digital Twins designed to support a citizen-centric transformative approach to urban planning and governance. CDT is being developed in the scope of the Bologna Digital Twin initiative, launched one year ago by the city of Bologna, to fulfill the city's political and strategic goal of adopting innovative digital tools to support decision-making and civic engagement. The CDT, in addition to its capability of sensing the city through spatial, temporal, and social data, must be able to model and simulate social dynamics in a city: the behavior, attitude, and preference of citizens and collectives and how they impact city life and transform transformation processes. Another distinctive feature of CDT is that it must be able to engage citizens (individuals, collectives, and organized civil society) and other civic stakeholders (utilities, economic actors, third sector) interested in co-designing the future of the city. In this paper, we discuss the motivations that led to the definition of the CDT, define its modeling aspects and key research challenges, and illustrate its intended use with two use cases in urban mobility and urban development.</description>
      <guid isPermaLink="false">oai:arXiv.org:2412.06328v1</guid>
      <category>cs.CY</category>
      <pubDate>Tue, 10 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Massimiliano Luca, Bruno Lepri, Riccardo Gallotti, Stefania Paolazzi, Mauro Bigi, Marco Pistore</dc:creator>
    </item>
    <item>
      <title>Reputation Management in the ChatGPT Era</title>
      <link>https://arxiv.org/abs/2412.06356</link>
      <description>arXiv:2412.06356v1 Announce Type: new 
Abstract: Generative AI systems often generate outputs about real people, even when not explicitly prompted to do so. This can lead to significant reputational and privacy harms, especially when sensitive, misleading, and outright false. This paper considers what legal tools currently exist to protect such individuals, with a particular focus on defamation and data protection law. We explore the potential of libel law, arguing that it is a potential but not an ideal remedy, due to lack of harmonization, and the focus on damages rather than systematic prevention of future libel. We then turn to data protection law, arguing that the data subject rights to erasure and rectification may offer some more meaningful protection, although the technical feasibility of compliance is a matter of ongoing research. We conclude by noting the limitations of these individualistic remedies and hint at the need for a more systemic, environmental approach to protecting the infosphere against generative AI.</description>
      <guid isPermaLink="false">oai:arXiv.org:2412.06356v1</guid>
      <category>cs.CY</category>
      <pubDate>Tue, 10 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <arxiv:journal_reference>ACM Symposium on Computer Science and Law 2025</arxiv:journal_reference>
      <dc:creator>Lilian Edwards, Reuben Binns</dc:creator>
    </item>
    <item>
      <title>Chatbots im Schulunterricht: Wir testen das Fobizz-Tool zur automatischen Bewertung von Hausaufgaben</title>
      <link>https://arxiv.org/abs/2412.06651</link>
      <description>arXiv:2412.06651v2 Announce Type: new 
Abstract: [Study in German language.] This study examines the AI-powered grading tool "AI Grading Assistant" by the German company Fobizz, designed to support teachers in evaluating and providing feedback on student assignments. Against the societal backdrop of an overburdened education system and rising expectations for artificial intelligence as a solution to these challenges, the investigation evaluates the tool's functional suitability through two test series. The results reveal significant shortcomings: The tool's numerical grades and qualitative feedback are often random and do not improve even when its suggestions are incorporated. The highest ratings are achievable only with texts generated by ChatGPT. False claims and nonsensical submissions frequently go undetected, while the implementation of some grading criteria is unreliable and opaque. Since these deficiencies stem from the inherent limitations of large language models (LLMs), fundamental improvements to this or similar tools are not immediately foreseeable. The study critiques the broader trend of adopting AI as a quick fix for systemic problems in education, concluding that Fobizz's marketing of the tool as an objective and time-saving solution is misleading and irresponsible. Finally, the study calls for systematic evaluation and subject-specific pedagogical scrutiny of the use of AI tools in educational contexts.</description>
      <guid isPermaLink="false">oai:arXiv.org:2412.06651v2</guid>
      <category>cs.CY</category>
      <pubDate>Tue, 10 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Rainer Muehlhoff, Marte Henningsen</dc:creator>
    </item>
    <item>
      <title>Digital Transformation in the Water Distribution System based on the Digital Twins Concept</title>
      <link>https://arxiv.org/abs/2412.06694</link>
      <description>arXiv:2412.06694v1 Announce Type: new 
Abstract: Digital Twins have emerged as a disruptive technology with great potential; they can enhance WDS by offering real-time monitoring, predictive maintenance, and optimization capabilities. This paper describes the development of a state-of-the-art DT platform for WDS, introducing advanced technologies such as the Internet of Things, Artificial Intelligence, and Machine Learning models. This paper provides insight into the architecture of the proposed platform-CAUCCES-that, informed by both historical and meteorological data, effectively deploys AI/ML models like LSTM networks, Prophet, LightGBM, and XGBoost in trying to predict water consumption patterns. Furthermore, we delve into how optimization in the maintenance of WDS can be achieved by formulating a Constraint Programming problem for scheduling, hence minimizing the operational cost efficiently with reduced environmental impacts. It also focuses on cybersecurity and protection to ensure the integrity and reliability of the DT platform. In this view, the system will contribute to improvements in decision-making capabilities, operational efficiency, and system reliability, with reassurance being drawn from the important role it can play toward sustainable management of water resources.</description>
      <guid isPermaLink="false">oai:arXiv.org:2412.06694v1</guid>
      <category>cs.CY</category>
      <category>cs.AI</category>
      <pubDate>Tue, 10 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-sa/4.0/</dc:rights>
      <dc:creator>MohammadHossein Homaei, Agust\'in Javier Di Bartolo, Mar \'Avila, \'Oscar Mogoll\'on-Guti\'errez, Andr\'es Caro</dc:creator>
    </item>
    <item>
      <title>Text Is Not All You Need: Multimodal Prompting Helps LLMs Understand Humor</title>
      <link>https://arxiv.org/abs/2412.05315</link>
      <description>arXiv:2412.05315v1 Announce Type: cross 
Abstract: While Large Language Models (LLMs) have demonstrated impressive natural language understanding capabilities across various text-based tasks, understanding humor has remained a persistent challenge. Humor is frequently multimodal, relying on phonetic ambiguity, rhythm and timing to convey meaning. In this study, we explore a simple multimodal prompting approach to humor understanding and explanation. We present an LLM with both the text and the spoken form of a joke, generated using an off-the-shelf text-to-speech (TTS) system. Using multimodal cues improves the explanations of humor compared to textual prompts across all tested datasets.</description>
      <guid isPermaLink="false">oai:arXiv.org:2412.05315v1</guid>
      <category>cs.CL</category>
      <category>cs.CY</category>
      <pubDate>Tue, 10 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Ashwin Baluja</dc:creator>
    </item>
    <item>
      <title>Collaborative and parametric insurance on the Ethereum blockchain</title>
      <link>https://arxiv.org/abs/2412.05321</link>
      <description>arXiv:2412.05321v1 Announce Type: cross 
Abstract: This paper introduces a blockchain-based insurance scheme that integrates parametric and collaborative elements. A pool of investors, referred to as surplus providers, locks funds in a smart contract, enabling blockchain users to underwrite parametric insurance contracts. These contracts automatically trigger compensation when predefined conditions are met. The collaborative aspect is embodied in the generation of tokens, which are distributed to both surplus providers and policyholders. These tokens represent each participant's share of the surplus and grant voting rights for management decisions. The smart contract is developed in Solidity, a high-level programming language for the Ethereum blockchain, and deployed on the Sepolia testnet, with data processing and analysis conducted using Python. In addition, open-source code is provided and main research challenges are identified, so that further research can be carried out to overcome limitations of this first proof of concept.</description>
      <guid isPermaLink="false">oai:arXiv.org:2412.05321v1</guid>
      <category>cs.CR</category>
      <category>cs.CE</category>
      <category>cs.CY</category>
      <category>cs.GT</category>
      <category>math.PR</category>
      <pubDate>Tue, 10 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <dc:creator>Pierre-Olivier Goffard, St\'ephane Loisel</dc:creator>
    </item>
    <item>
      <title>Toxic behavior silences online political conversations</title>
      <link>https://arxiv.org/abs/2412.05741</link>
      <description>arXiv:2412.05741v1 Announce Type: cross 
Abstract: Quantifying how individuals react to social influence is crucial for tackling collective political behavior online. While many studies of opinion in public forums focus on social feedback, they often overlook the potential for human interactions to result in self-censorship. Here, we investigate political deliberation in online spaces by exploring the hypothesis that individuals may refrain from expressing minority opinions publicly due to being exposed to toxic behavior. Analyzing conversations under YouTube videos from six prominent US news outlets around the 2020 US presidential elections, we observe patterns of self-censorship signaling the influence of peer toxicity on users' behavior. Using hidden Markov models, we identify a latent state consistent with toxicity-driven silence. Such state is characterized by reduced user activity and a higher likelihood of posting toxic content, indicating an environment where extreme and antisocial behaviors thrive. Our findings offer insights into the intricacies of online political deliberation and emphasize the importance of considering self-censorship dynamics to properly characterize ideological polarization in digital spheres.</description>
      <guid isPermaLink="false">oai:arXiv.org:2412.05741v1</guid>
      <category>cs.SI</category>
      <category>cs.CY</category>
      <pubDate>Tue, 10 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Gabriela Juncosa, Taha Yasseri, Julia Koltai, Gerardo Iniguez</dc:creator>
    </item>
    <item>
      <title>Strategizing Equitable Transit Evacuations: A Data-Driven Reinforcement Learning Approach</title>
      <link>https://arxiv.org/abs/2412.05777</link>
      <description>arXiv:2412.05777v1 Announce Type: cross 
Abstract: As natural disasters become increasingly frequent, the need for efficient and equitable evacuation planning has become more critical. This paper proposes a data-driven, reinforcement learning-based framework to optimize bus-based evacuations with an emphasis on improving both efficiency and equity. We model the evacuation problem as a Markov Decision Process solved by reinforcement learning, using real-time transit data from General Transit Feed Specification and transportation networks extracted from OpenStreetMap. The reinforcement learning agent dynamically reroutes buses from their scheduled location to minimize total passengers' evacuation time while prioritizing equity-priority communities. Simulations on the San Francisco Bay Area transportation network indicate that the proposed framework achieves significant improvements in both evacuation efficiency and equitable service distribution compared to traditional rule-based and random strategies. These results highlight the potential of reinforcement learning to enhance system performance and urban resilience during emergency evacuations, offering a scalable solution for real-world applications in intelligent transportation systems.</description>
      <guid isPermaLink="false">oai:arXiv.org:2412.05777v1</guid>
      <category>cs.LG</category>
      <category>cs.AI</category>
      <category>cs.CY</category>
      <category>cs.SY</category>
      <category>eess.SY</category>
      <pubDate>Tue, 10 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Fang Tang, Han Wang, Maria Laura Delle Monache</dc:creator>
    </item>
    <item>
      <title>An Overview of Cyber Security Funding for Open Source Software</title>
      <link>https://arxiv.org/abs/2412.05887</link>
      <description>arXiv:2412.05887v1 Announce Type: cross 
Abstract: Many open source software (OSS) projects need more human resources for maintenance, improvements, and sometimes even their survival. This need allegedly applies even to vital OSS projects that can be seen as being a part of the world's critical infrastructures. To address this resourcing problem, new funding instruments for OSS projects have been established in recent years. The paper examines two such funding bodies for OSS and the projects they have funded. The focus of both funding bodies is on software security and cyber security in general. Based on a qualitative analysis, particularly OSS supply chains, network and cryptography libraries, programming languages, and operating systems and their low-level components have been funded and thus seen as critical in terms of cyber security by the two funding bodies. In addition to this and other results, the paper makes a contribution by connecting the research branches of critical infrastructure and sustainability of OSS projects. A further contribution is made by connecting the topic examined to recent cyber security regulations. Furthermore, an important argument is raised that neither cyber security nor sustainability alone can entirely explain the rationales behind the funding decisions made by the two bodies.</description>
      <guid isPermaLink="false">oai:arXiv.org:2412.05887v1</guid>
      <category>cs.CR</category>
      <category>cs.CY</category>
      <category>cs.SE</category>
      <pubDate>Tue, 10 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Jukka Ruohonen, Gaurav Choudhary, Adam Alami</dc:creator>
    </item>
    <item>
      <title>Accurate Multi-Category Student Performance Forecasting at Early Stages of Online Education Using Neural Networks</title>
      <link>https://arxiv.org/abs/2412.05938</link>
      <description>arXiv:2412.05938v1 Announce Type: cross 
Abstract: The ability to accurately predict and analyze student performance in online education, both at the outset and throughout the semester, is vital. Most of the published studies focus on binary classification (Fail or Pass) but there is still a significant research gap in predicting students' performance across multiple categories. This study introduces a novel neural network-based approach capable of accurately predicting student performance and identifying vulnerable students at early stages of the online courses. The Open University Learning Analytics (OULA) dataset is employed to develop and test the proposed model, which predicts outcomes in Distinction, Fail, Pass, and Withdrawn categories. The OULA dataset is preprocessed to extract features from demographic data, assessment data, and clickstream interactions within a Virtual Learning Environment (VLE). Comparative simulations indicate that the proposed model significantly outperforms existing baseline models including Artificial Neural Network Long Short Term Memory (ANN-LSTM), Random Forest (RF) 'gini', RF 'entropy' and Deep Feed Forward Neural Network (DFFNN) in terms of accuracy, precision, recall, and F1-score. The results indicate that the prediction accuracy of the proposed method is about 25% more than the existing state-of-the-art. Furthermore, compared to existing methodologies, the model demonstrates superior predictive capability across temporal course progression, achieving superior accuracy even at the initial 20% phase of course completion.</description>
      <guid isPermaLink="false">oai:arXiv.org:2412.05938v1</guid>
      <category>cs.LG</category>
      <category>cs.CY</category>
      <pubDate>Tue, 10 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <dc:creator>Naveed Ur Rehman Junejo, Muhammad Wasim Nawaz, Qingsheng Huang, Xiaoqing Dong, Chang Wang, Gengzhong Zheng</dc:creator>
    </item>
    <item>
      <title>A Dynamic Tree Structure for Hierarchical On-Chain Asset Management</title>
      <link>https://arxiv.org/abs/2412.06026</link>
      <description>arXiv:2412.06026v1 Announce Type: cross 
Abstract: In this paper, we introduce the Sarv, a novel non-monolithic blockchain-based data structure designed to represent hierarchical relationships between digitally representable components. Sarv serves as an underlying infrastructure for a wide range of applications requiring hierarchical data management, such as supply chain tracking, asset management, and circular economy implementations. Our approach leverages a tree-based data structure to accurately reflect products and their sub-components, enabling functionalities such as modification, disassembly, borrowing, and refurbishment, mirroring real-world operations. The hierarchy within Sarv is embedded in the on-chain data structure through a smart contract-based design, utilizing Algorand Standard Assets (ASAs). The uniqueness of Sarv lies in its compact and non-monolithic architecture, its mutability, and a two-layer action authorization scheme that enhances security and delegation of asset management. We demonstrate that Sarv addresses real-world requirements by providing a scalable, mutable, and secure solution for managing hierarchical data on the blockchain.</description>
      <guid isPermaLink="false">oai:arXiv.org:2412.06026v1</guid>
      <category>cs.CR</category>
      <category>cs.CY</category>
      <category>cs.DS</category>
      <category>cs.ET</category>
      <pubDate>Tue, 10 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Mojtaba Eshghie, Gustav Andersson Kasche</dc:creator>
    </item>
    <item>
      <title>The AI Double Standard: Humans Judge All AIs for the Actions of One</title>
      <link>https://arxiv.org/abs/2412.06040</link>
      <description>arXiv:2412.06040v1 Announce Type: cross 
Abstract: Robots and other artificial intelligence (AI) systems are widely perceived as moral agents responsible for their actions. As AI proliferates, these perceptions may become entangled via the moral spillover of attitudes towards one AI to attitudes towards other AIs. We tested how the seemingly harmful and immoral actions of an AI or human agent spill over to attitudes towards other AIs or humans in two preregistered experiments. In Study 1 (N = 720), we established the moral spillover effect in human-AI interaction by showing that immoral actions increased attributions of negative moral agency (i.e., acting immorally) and decreased attributions of positive moral agency (i.e., acting morally) and moral patiency (i.e., deserving moral concern) to both the agent (a chatbot or human assistant) and the group to which they belong (all chatbot or human assistants). There was no significant difference in the spillover effects between the AI and human contexts. In Study 2 (N = 684), we tested whether spillover persisted when the agent was individuated with a name and described as an AI or human, rather than specifically as a chatbot or personal assistant. We found that spillover persisted in the AI context but not in the human context, possibly because AIs were perceived as more homogeneous due to their outgroup status relative to humans. This asymmetry suggests a double standard whereby AIs are judged more harshly than humans when one agent morally transgresses. With the proliferation of diverse, autonomous AI systems, HCI research and design should account for the fact that experiences with one AI could easily generalize to perceptions of all AIs and negative HCI outcomes, such as reduced trust.</description>
      <guid isPermaLink="false">oai:arXiv.org:2412.06040v1</guid>
      <category>cs.AI</category>
      <category>cs.CY</category>
      <category>cs.ET</category>
      <category>cs.HC</category>
      <pubDate>Tue, 10 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Aikaterina Manoli, Janet V. T. Pauketat, Jacy Reese Anthis</dc:creator>
    </item>
    <item>
      <title>Cloud Platforms for Developing Generative AI Solutions: A Scoping Review of Tools and Services</title>
      <link>https://arxiv.org/abs/2412.06044</link>
      <description>arXiv:2412.06044v1 Announce Type: cross 
Abstract: Generative AI is transforming enterprise application development by enabling machines to create content, code, and designs. These models, however, demand substantial computational power and data management. Cloud computing addresses these needs by offering infrastructure to train, deploy, and scale generative AI models. This review examines cloud services for generative AI, focusing on key providers like Amazon Web Services (AWS), Microsoft Azure, Google Cloud, IBM Cloud, Oracle Cloud, and Alibaba Cloud. It compares their strengths, weaknesses, and impact on enterprise growth. We explore the role of high-performance computing (HPC), serverless architectures, edge computing, and storage in supporting generative AI. We also highlight the significance of data management, networking, and AI-specific tools in building and deploying these models. Additionally, the review addresses security concerns, including data privacy, compliance, and AI model protection. It assesses the performance and cost efficiency of various cloud providers and presents case studies from healthcare, finance, and entertainment. We conclude by discussing challenges and future directions, such as technical hurdles, vendor lock-in, sustainability, and regulatory issues. Put together, this work can serve as a guide for practitioners and researchers looking to adopt cloud-based generative AI solutions, serving as a valuable guide to navigating the intricacies of this evolving field.</description>
      <guid isPermaLink="false">oai:arXiv.org:2412.06044v1</guid>
      <category>cs.DC</category>
      <category>cs.AI</category>
      <category>cs.CY</category>
      <pubDate>Tue, 10 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Dhavalkumar Patel, Ganesh Raut, Satya Narayan Cheetirala, Girish N Nadkarni, Robert Freeman, Benjamin S. Glicksberg, Eyal Klang, Prem Timsina</dc:creator>
    </item>
    <item>
      <title>Network analysis of the Danish bicycle infrastructure: Bikeability across urban-rural divides</title>
      <link>https://arxiv.org/abs/2412.06083</link>
      <description>arXiv:2412.06083v1 Announce Type: cross 
Abstract: Research on cycling conditions focuses on cities, because cycling is commonly considered an urban phenomenon. People outside of cities should, however, also have access to the benefits of active mobility. To bridge the gap between urban and rural cycling research, we analyze the bicycle network of Denmark, covering around 43,000 km2 and nearly 6 mio. inhabitants. We divide the network into four levels of traffic stress and quantify the spatial patterns of bikeability based on network density, fragmentation, and reach. We find that the country has a high share of low-stress infrastructure, but with a very uneven distribution. The widespread fragmentation of low-stress infrastructure results in low mobility for cyclists who do not tolerate high traffic stress. Finally, we partition the network into bikeability clusters and conclude that both high and low bikeability are strongly spatially clustered. Our research confirms that in Denmark, bikeability tends to be high in urban areas. The latent potential for cycling in rural areas is mostly unmet, although some rural areas benefit from previous infrastructure investments. To mitigate the lack of low-stress cycling infrastructure outside of urban centers, we suggest prioritizing investments in urban-rural cycling connections and encourage further research in improving rural cycling conditions.</description>
      <guid isPermaLink="false">oai:arXiv.org:2412.06083v1</guid>
      <category>physics.soc-ph</category>
      <category>cs.CY</category>
      <pubDate>Tue, 10 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Ane Rahbek Vier{\o}, Michael Szell</dc:creator>
    </item>
    <item>
      <title>Ethnography and Machine Learning: Synergies and New Directions</title>
      <link>https://arxiv.org/abs/2412.06087</link>
      <description>arXiv:2412.06087v1 Announce Type: cross 
Abstract: Ethnography (social scientific methods that illuminate how people understand, navigate and shape the real world contexts in which they live their lives) and machine learning (computational techniques that use big data and statistical learning models to perform quantifiable tasks) are each core to contemporary social science. Yet these tools have remained largely separate in practice. This chapter draws on a growing body of scholarship that argues that ethnography and machine learning can be usefully combined, particularly for large comparative studies. Specifically, this paper (a) explains the value (and challenges) of using machine learning alongside qualitative field research for certain types of projects, (b) discusses recent methodological trends to this effect, (c) provides examples that illustrate workflow drawn from several large projects, and (d) concludes with a roadmap for enabling productive coevolution of field methods and machine learning.</description>
      <guid isPermaLink="false">oai:arXiv.org:2412.06087v1</guid>
      <category>cs.LG</category>
      <category>cs.AI</category>
      <category>cs.CY</category>
      <category>stat.ME</category>
      <pubDate>Tue, 10 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <arxiv:DOI>10.1093/oxfordhb/9780197653609.013.36</arxiv:DOI>
      <arxiv:journal_reference>Borch, and Pardo-Guerra (eds), The Oxford Handbook of the Sociology of Machine Learning (2024)</arxiv:journal_reference>
      <dc:creator>Zhuofan Li, Corey M. Abramson</dc:creator>
    </item>
    <item>
      <title>LLMs as Debate Partners: Utilizing Genetic Algorithms and Adversarial Search for Adaptive Arguments</title>
      <link>https://arxiv.org/abs/2412.06229</link>
      <description>arXiv:2412.06229v1 Announce Type: cross 
Abstract: This paper introduces DebateBrawl, an innovative AI-powered debate platform that integrates Large Language Models (LLMs), Genetic Algorithms (GA), and Adversarial Search (AS) to create an adaptive and engaging debating experience. DebateBrawl addresses the limitations of traditional LLMs in strategic planning by incorporating evolutionary optimization and game-theoretic techniques. The system demonstrates remarkable performance in generating coherent, contextually relevant arguments while adapting its strategy in real-time. Experimental results involving 23 debates show balanced outcomes between AI and human participants, with the AI system achieving an average score of 2.72 compared to the human average of 2.67 out of 10. User feedback indicates significant improvements in debating skills and a highly satisfactory learning experience, with 85% of users reporting improved debating abilities and 78% finding the AI opponent appropriately challenging. The system's ability to maintain high factual accuracy (92% compared to 78% in human-only debates) while generating diverse arguments addresses critical concerns in AI-assisted discourse. DebateBrawl not only serves as an effective educational tool but also contributes to the broader goal of improving public discourse through AI-assisted argumentation. The paper discusses the ethical implications of AI in persuasive contexts and outlines the measures implemented to ensure responsible development and deployment of the system, including robust fact-checking mechanisms and transparency in decision-making processes.</description>
      <guid isPermaLink="false">oai:arXiv.org:2412.06229v1</guid>
      <category>cs.AI</category>
      <category>cs.CL</category>
      <category>cs.CY</category>
      <category>cs.NE</category>
      <pubDate>Tue, 10 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Prakash Aryan</dc:creator>
    </item>
    <item>
      <title>Vulnerability Coordination Under the Cyber Resilience Act</title>
      <link>https://arxiv.org/abs/2412.06261</link>
      <description>arXiv:2412.06261v1 Announce Type: cross 
Abstract: A new Cyber Resilience Act (CRA) was recently agreed upon in the European Union (EU). It imposes many new cyber security requirements practically to all information technology products, whether hardware or software. The paper examines and elaborates the CRA's new requirements for vulnerability coordination, including vulnerability disclosure. Although these requirements are only a part of the CRA's obligations for vendors, also some new vulnerability coordination mandates are present, including particularly with respect to so-called actively exploited vulnerabilities. The CRA further alters the coordination practices on the side of public administrations. With the examination, elaboration, and associated discussion, the paper contributes to the study of cyber security regulations, providing also a few practical takeaways.</description>
      <guid isPermaLink="false">oai:arXiv.org:2412.06261v1</guid>
      <category>cs.CR</category>
      <category>cs.CY</category>
      <category>cs.SE</category>
      <pubDate>Tue, 10 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Jukka Ruohonen, Paul Timmers</dc:creator>
    </item>
    <item>
      <title>Advancing Music Therapy: Integrating Eastern Five-Element Music Theory and Western Techniques with AI in the Novel Five-Element Harmony System</title>
      <link>https://arxiv.org/abs/2412.06600</link>
      <description>arXiv:2412.06600v1 Announce Type: cross 
Abstract: In traditional medical practices, music therapy has proven effective in treating various psychological and physiological ailments. Particularly in Eastern traditions, the Five Elements Music Therapy (FEMT), rooted in traditional Chinese medicine, possesses profound cultural significance and unique therapeutic philosophies. With the rapid advancement of Information Technology and Artificial Intelligence, applying these modern technologies to FEMT could enhance the personalization and cultural relevance of the therapy and potentially improve therapeutic outcomes. In this article, we developed a music therapy system for the first time by applying the theory of the five elements in music therapy to practice. This innovative approach integrates advanced Information Technology and Artificial Intelligence with Five-Element Music Therapy (FEMT) to enhance personalized music therapy practices. As traditional music therapy predominantly follows Western methodologies, the unique aspects of Eastern practices, specifically the Five-Element theory from traditional Chinese medicine, should be considered. This system aims to bridge this gap by utilizing computational technologies to provide a more personalized, culturally relevant, and therapeutically effective music therapy experience.</description>
      <guid isPermaLink="false">oai:arXiv.org:2412.06600v1</guid>
      <category>cs.HC</category>
      <category>cs.AI</category>
      <category>cs.CY</category>
      <pubDate>Tue, 10 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <dc:creator>Yubo Zhou, Weizhen Bian, Kaitai Zhang, Xiaohan Gu</dc:creator>
    </item>
    <item>
      <title>A Comparative Study of Online Disinformation and Offline Protests</title>
      <link>https://arxiv.org/abs/2106.11000</link>
      <description>arXiv:2106.11000v4 Announce Type: replace 
Abstract: In early 2021 the United States Capitol in Washington was stormed during a riot and violent attack. A similar storming occurred in Brazil in
  2023. Although both attacks were instances in longer sequences of events, these have provided a testimony for many observers who had claimed that online actions, including the propagation of disinformation, have offline consequences. Soon after, a number of papers have been published about the relation between online disinformation and offline violence, among other related relations. Hitherto, the effects upon political protests have been unexplored. This paper thus evaluates such effects with a time series cross-sectional sample of 125 countries in a period between 2000 and 2019. The results are mixed. Based on Bayesian multi-level regression modeling, (i) there indeed is an effect between online disinformation and offline protests, but the effect is partially meditated by political polarization. The results are clearer in a sample of countries belonging to the European Economic Area. With this sample, (ii) offline protest counts increase from online disinformation disseminated by domestic governments, political parties, and politicians as well as by foreign governments. Furthermore, (iii) Internet shutdowns tend to decrease the counts, although, paradoxically, the absence of governmental online monitoring of social media tends to also decrease these. With these results, the paper contributes to the blossoming disinformation research by modeling the impact of disinformation upon offline phenomenon. The contribution is important due to the various policy measures planned or already enacted.</description>
      <guid isPermaLink="false">oai:arXiv.org:2106.11000v4</guid>
      <category>cs.CY</category>
      <pubDate>Tue, 10 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <arxiv:DOI>10.1007/s43545-024-01029-x</arxiv:DOI>
      <arxiv:journal_reference>SN Social Sciences, 2024, vol. 4, pp. 1-18</arxiv:journal_reference>
      <dc:creator>Jukka Ruohonen</dc:creator>
    </item>
    <item>
      <title>Synthesizing Proteins on the Graphics Card. Protein Folding and the Limits of Critical AI Studies</title>
      <link>https://arxiv.org/abs/2405.09788</link>
      <description>arXiv:2405.09788v2 Announce Type: replace 
Abstract: This paper investigates the application of the transformer architecture in protein folding, as exemplified by DeepMind's AlphaFold project, and its implications for the understanding of so-called large language models. The prevailing discourse often assumes a ready-made analogy between proteins, encoded as sequences of amino acids, and natural language, which we term the language paradigm of computational (structural) biology. Instead of assuming this analogy as given, we critically evaluate it to assess the kind of knowledge-making afforded by the transformer architecture. We first trace the analogy's emergence and historical development, carving out the influence of structural linguistics on structural biology beginning in the mid-20th century. We then examine three often overlooked preprocessing steps essential to the transformer architecture, including subword tokenization, word embedding, and positional encoding, to demonstrate its regime of representation based on continuous, high-dimensional vector spaces, which departs from the discrete nature of language. The successful deployment of transformers in protein folding, we argue, discloses what we consider a non-linguistic approach to token processing intrinsic to the architecture. We contend that through this non-linguistic processing, the transformer architecture carves out unique epistemological territory and produces a new class of knowledge, distinct from established domains. We contend that our search for intelligent machines has to begin with the shape, rather than the place, of intelligence. Consequently, the emerging field of critical AI studies should take methodological inspiration from the history of science in its quest to conceptualize the contributions of artificial intelligence to knowledge-making, within and beyond the domain-specific sciences.</description>
      <guid isPermaLink="false">oai:arXiv.org:2405.09788v2</guid>
      <category>cs.CY</category>
      <pubDate>Tue, 10 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Fabian Offert, Paul Kim, Qiaoyu Cai</dc:creator>
    </item>
    <item>
      <title>Why Algorithms Remain Unjust: Power Structures Surrounding Algorithmic Activity</title>
      <link>https://arxiv.org/abs/2405.18461</link>
      <description>arXiv:2405.18461v2 Announce Type: replace 
Abstract: Algorithms are unavoidable in our social lives, yet often perpetuate social injustices. The popular means of addressing this is through algorithmic reformism: fine-tuning algorithms themselves to be more fair, accountable, and transparent. However, reformism fails to curtail algorithmic injustice because it ignores the power structure surrounding algorithms. Heeding calls from critical algorithm studies, I employ a framework developed by Erik Olin Wright to examine the configuration of power surrounding algorithmic systems in society (Algorithmic Activity). Algorithmic Activity is unjust because it is dominated by economic power. To create socially just Algorithmic Activity, the power configuration must instead empower end users. I explore Wright's symbiotic, interstitial, and raptural transformations in the context of just Algorithmic Activity. My vision for social justice in algorithmic systems requires a continuous (re)evaluation of how power can be transformed in light of current structure, social theories, evolving methodologies, and one's relationship to power itself.</description>
      <guid isPermaLink="false">oai:arXiv.org:2405.18461v2</guid>
      <category>cs.CY</category>
      <category>cs.LG</category>
      <pubDate>Tue, 10 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Andrew Balch</dc:creator>
    </item>
    <item>
      <title>Information Seeking and Communication among International Students on Reddit</title>
      <link>https://arxiv.org/abs/2407.06506</link>
      <description>arXiv:2407.06506v2 Announce Type: replace 
Abstract: This study examines the impact of the COVID-19 pandemic on information-seeking behaviors among international students, with a focus on the r/f1visa subreddit. Our study indicates a considerable rise in the number of users posting more than one question during the pandemic. Those asking recurring questions demonstrate more active involvement in communication, suggesting a continuous pursuit of knowledge. Furthermore, the thematic focus has shifted from questions about jobs before COVID-19 to concerns about finances, school preparations, and taxes during COVID-19. These findings carry implications for support policymaking, highlighting the importance of delivering timely and relevant information to meet the evolving needs of international students. To enhance international students' understanding and navigation of this dynamic environment, future research in this field is necessary.</description>
      <guid isPermaLink="false">oai:arXiv.org:2407.06506v2</guid>
      <category>cs.CY</category>
      <pubDate>Tue, 10 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Chaeeun Han, Sangpil Youm, Hojeong Yoo, Sou Hyun Jang</dc:creator>
    </item>
    <item>
      <title>Future and AI-Ready Data Strategies: Response to DOC RFI on AI and Open Government Data Assets</title>
      <link>https://arxiv.org/abs/2408.01457</link>
      <description>arXiv:2408.01457v2 Announce Type: replace 
Abstract: The following is a response to the US Department of Commerce's Request for Information (RFI) regarding AI and Open Government Data Assets. First, we commend the Department for its initiative in seeking public insights on the organization and sharing of data. To facilitate scientific discovery and advance AI development, it is crucial for all data producers, including the Department of Commerce and other governmental entities, to prioritize the quality of their data corpora. Ensuring data is accessible, scalable, and secure is essential for harnessing its full potential. In our response, we outline best practices and key considerations for AI and the Department of Commerce's Open Government Data Assets.</description>
      <guid isPermaLink="false">oai:arXiv.org:2408.01457v2</guid>
      <category>cs.CY</category>
      <pubDate>Tue, 10 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Hamidah Oderinwale, Shayne Longpre</dc:creator>
    </item>
    <item>
      <title>To Be or Not to Be (in the EU): Measurement of Discrepancies Presented in Cookie Paywalls (LONG)</title>
      <link>https://arxiv.org/abs/2410.06920</link>
      <description>arXiv:2410.06920v3 Announce Type: replace 
Abstract: Cookie paywalls allow visitors to access the content of a website only after making a choice between paying a fee (paying option) or accepting tracking (cookie option). The practice has been studied in previous research in regard to its prevalence and legal standing, but the effects of the clients' device and geographic location remain unexplored. To address these questions, this study explores the effects of three factors: 1) the clients' browser, 2) the device type (desktop or mobile), and 3) the geographic location on the presence and behavior of cookie paywalls and the handling of users' data.
  Using an automatic crawler on our dataset composed of 804 websites that present a cookie paywall, we observed that the presence of a cookie paywall was most affected by the geographic location of the user. We further showed that both the behavior of a cookie paywall and the processing of user data are impacted by all three factors, but no patterns of significance could be found. Finally, an additional type of paywall was discovered to be used on approximately 11% of the studied websites, coined the "double paywall", which consists of a cookie paywall complemented by another paywall once tracking is accepted.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.06920v3</guid>
      <category>cs.CY</category>
      <category>cs.ET</category>
      <pubDate>Tue, 10 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Andreas Stenwreth, Simon T\"ang, Victor Morel</dc:creator>
    </item>
    <item>
      <title>Bridging Today and the Future of Humanity: AI Safety in 2024 and Beyond</title>
      <link>https://arxiv.org/abs/2410.18114</link>
      <description>arXiv:2410.18114v3 Announce Type: replace 
Abstract: The advancements in generative AI inevitably raise concerns about the associated risks and safety implications, which, in return, catalyzes significant progress in AI safety. However, as this field continues to evolve, a critical question arises: are our current efforts aligned with the long-term goal of human history and civilization? This paper presents a blueprint for an advanced human society and leverages this vision to guide contemporary AI safety efforts. It outlines a future where the Internet of Everything becomes reality, and creates a roadmap of significant technological advancements towards this envisioned future. For each stage of the advancements, this paper forecasts potential AI safety issues that humanity may face. By projecting current efforts against this blueprint, we examine the alignment between the present efforts and the long-term needs. We also identify gaps in current approaches and highlight unique challenges and missions that demand increasing attention from AI safety practitioners in the 2020s, addressing critical areas that must not be overlooked in shaping a responsible and promising future of AI. This vision paper aims to offer a broader perspective on AI safety, emphasizing that our current efforts should not only address immediate concerns but also anticipate potential risks in the expanding AI landscape, thereby promoting a more secure and sustainable future in human civilization.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.18114v3</guid>
      <category>cs.CY</category>
      <category>cs.AI</category>
      <pubDate>Tue, 10 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Shanshan Han</dc:creator>
    </item>
    <item>
      <title>Toward Democracy Levels for AI</title>
      <link>https://arxiv.org/abs/2411.09222</link>
      <description>arXiv:2411.09222v2 Announce Type: replace 
Abstract: There is increasing concern about the unilateral power of the organizations involved in the development, alignment, and governance of AI. Recent pilots - such as Meta's Community Forums and Anthropic's Collective Constitutional AI - have illustrated a promising direction, where democratic processes might be used to meaningfully improve public involvement and trust in critical decisions. However, there is no standard framework for evaluating such processes. In this paper, building on insights from the theory and practice of deliberative democracy, we provide a "Democracy Levels" framework for evaluating the degree to which decisions in a given domain are made democratically. The framework can be used (i) to define milestones in a roadmap for the democratic AI, pluralistic AI, and public AI ecosystems, (ii) to guide organizations that need to increase the legitimacy of their decisions on difficult AI governance questions, and (iii) as a rubric by those aiming to evaluate AI organizations and keep them accountable.</description>
      <guid isPermaLink="false">oai:arXiv.org:2411.09222v2</guid>
      <category>cs.CY</category>
      <pubDate>Tue, 10 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Aviv Ovadya, Luke Thorburn, Kyle Redman, Flynn Devine, Smitha Milli, Manon Revel, Andrew Konya, Atoosa Kasirzadeh</dc:creator>
    </item>
    <item>
      <title>Implications of Distance over Redistricting Maps: Central and Outlier Maps</title>
      <link>https://arxiv.org/abs/2203.00872</link>
      <description>arXiv:2203.00872v5 Announce Type: replace-cross 
Abstract: In representative democracy, a redistricting map is chosen to partition an electorate into districts which each elects a representative. A valid redistricting map must satisfy a collection of constraints such as being compact, contiguous, and of almost-equal population. However, these constraints are loose enough to enable an enormous ensemble of valid redistricting maps. This enables a partisan legislature to gerrymander by choosing a map which unfairly favors it. In this paper, we introduce an interpretable and tractable distance measure over redistricting maps which does not use election results and study its implications over the ensemble of redistricting maps. Specifically, we define a central map which may be considered "most typical" and give a rigorous justification for it by showing that it mirrors the Kemeny ranking in a scenario where we have a committee voting over a collection of redistricting maps to be drawn. We include running time and sample complexity analysis for our algorithms, including some negative results which hold using any algorithm. We further study outlier detection based on this distance measure and show that our framework can detect some gerrymandered maps. More precisely, we show some maps that are widely considered to be gerrymandered that lie very far away from our central maps in comparison to a large ensemble of valid redistricting maps. Since our distance measure does not rely on election results, this gives a significant advantage in gerrymandering detection which is lacking in all previous methods.</description>
      <guid isPermaLink="false">oai:arXiv.org:2203.00872v5</guid>
      <category>cs.GT</category>
      <category>cs.AI</category>
      <category>cs.CY</category>
      <category>cs.DS</category>
      <pubDate>Tue, 10 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Seyed A. Esmaeili, Darshan Chakrabarti, Hayley Grape, Brian Brubach</dc:creator>
    </item>
    <item>
      <title>Auditing Fairness under Unobserved Confounding</title>
      <link>https://arxiv.org/abs/2403.14713</link>
      <description>arXiv:2403.14713v3 Announce Type: replace-cross 
Abstract: Many definitions of fairness or inequity involve unobservable causal quantities that cannot be directly estimated without strong assumptions. For instance, it is particularly difficult to estimate notions of fairness that rely on hard-to-measure concepts such as risk (e.g., quantifying whether patients at the same risk level have equal probability of treatment, regardless of group membership). Such measurements of risk can be accurately obtained when no unobserved confounders have jointly influenced past decisions and outcomes. However, in the real world, this assumption rarely holds. In this paper, we show that, surprisingly, one can still compute meaningful bounds on treatment rates for high-risk individuals (i.e., conditional on their true, \textit{unobserved} negative outcome), even when entirely eliminating or relaxing the assumption that we observe all relevant risk factors used by decision makers. We use the fact that in many real-world settings (e.g., the release of a new treatment) we have data from prior to any allocation to derive unbiased estimates of risk. This result enables us to audit unfair outcomes of existing decision-making systems in a principled manner. We demonstrate the effectiveness of our framework with a real-world study of Paxlovid allocation, provably identifying that observed racial inequity cannot be explained by unobserved confounders of the same strength as important observed covariates.</description>
      <guid isPermaLink="false">oai:arXiv.org:2403.14713v3</guid>
      <category>cs.LG</category>
      <category>cs.CY</category>
      <category>stat.ME</category>
      <category>stat.ML</category>
      <pubDate>Tue, 10 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Yewon Byun, Dylan Sam, Michael Oberst, Zachary C. Lipton, Bryan Wilder</dc:creator>
    </item>
    <item>
      <title>Past, Present, and Future of Citation Practices in HCI</title>
      <link>https://arxiv.org/abs/2405.16526</link>
      <description>arXiv:2405.16526v5 Announce Type: replace-cross 
Abstract: Science is a complex system comprised of many scientists who individually make decisions that, due to the size and nature of the academic system, largely do not affect the system as a whole. However, certain decisions at the meso-level of research communities, such as the Human-Computer Interaction (HCI) community, may result in deep and long-lasting behavioral changes in scientists. In this article, we provide empirical evidence on how a change in editorial policies introduced at the ACM CHI Conference in 2016 destabilized the CHI research community and launched it on an expansive path, denoted by a year-by-year increase in the mean number of references included in CHI articles. If this near-linear trend continues undisrupted, an article at CHI 2030 will include on average almost 130 references. The trend towards more citations reflects a citation culture where quantity is prioritized over quality, contributing to both author and peer reviewer fatigue. Our exploratory analysis underscores the profound impact of meso-level policy adjustments on the evolution of scientific fields and disciplines, urging all stakeholders to carefully consider the broader implications of such changes.</description>
      <guid isPermaLink="false">oai:arXiv.org:2405.16526v5</guid>
      <category>cs.HC</category>
      <category>cs.CY</category>
      <category>cs.DL</category>
      <pubDate>Tue, 10 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Jonas Oppenlaender</dc:creator>
    </item>
    <item>
      <title>Dataset Distribution Impacts Model Fairness: Single vs. Multi-Task Learning</title>
      <link>https://arxiv.org/abs/2407.17543</link>
      <description>arXiv:2407.17543v2 Announce Type: replace-cross 
Abstract: The influence of bias in datasets on the fairness of model predictions is a topic of ongoing research in various fields. We evaluate the performance of skin lesion classification using ResNet-based CNNs, focusing on patient sex variations in training data and three different learning strategies. We present a linear programming method for generating datasets with varying patient sex and class labels, taking into account the correlations between these variables. We evaluated the model performance using three different learning strategies: a single-task model, a reinforcing multi-task model, and an adversarial learning scheme. Our observations include: 1) sex-specific training data yields better results, 2) single-task models exhibit sex bias, 3) the reinforcement approach does not remove sex bias, 4) the adversarial model eliminates sex bias in cases involving only female patients, and 5) datasets that include male patients enhance model performance for the male subgroup, even when female patients are the majority. To generalise these findings, in future research, we will examine more demographic attributes, like age, and other possibly confounding factors, such as skin colour and artefacts in the skin lesions. We make all data and models available on GitHub.</description>
      <guid isPermaLink="false">oai:arXiv.org:2407.17543v2</guid>
      <category>cs.LG</category>
      <category>cs.AI</category>
      <category>cs.CY</category>
      <pubDate>Tue, 10 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-sa/4.0/</dc:rights>
      <arxiv:DOI>10.1007/978-3-031-72787-0_2</arxiv:DOI>
      <arxiv:journal_reference>Ethics and Fairness in Medical Imaging. FAIMI EPIMI 2024 2024. Lecture Notes in Computer Science, vol 15198</arxiv:journal_reference>
      <dc:creator>Ralf Raumanns, Gerard Schouten, Josien P. W. Pluim, Veronika Cheplygina</dc:creator>
    </item>
    <item>
      <title>From Pixels to Words: Leveraging Explainability in Face Recognition through Interactive Natural Language Processing</title>
      <link>https://arxiv.org/abs/2409.16089</link>
      <description>arXiv:2409.16089v2 Announce Type: replace-cross 
Abstract: Face Recognition (FR) has advanced significantly with the development of deep learning, achieving high accuracy in several applications. However, the lack of interpretability of these systems raises concerns about their accountability, fairness, and reliability. In the present study, we propose an interactive framework to enhance the explainability of FR models by combining model-agnostic Explainable Artificial Intelligence (XAI) and Natural Language Processing (NLP) techniques. The proposed framework is able to accurately answer various questions of the user through an interactive chatbot. In particular, the explanations generated by our proposed method are in the form of natural language text and visual representations, which for example can describe how different facial regions contribute to the similarity measure between two faces. This is achieved through the automatic analysis of the output's saliency heatmaps of the face images and a BERT question-answering model, providing users with an interface that facilitates a comprehensive understanding of the FR decisions. The proposed approach is interactive, allowing the users to ask questions to get more precise information based on the user's background knowledge. More importantly, in contrast to previous studies, our solution does not decrease the face recognition performance. We demonstrate the effectiveness of the method through different experiments, highlighting its potential to make FR systems more interpretable and user-friendly, especially in sensitive applications where decision-making transparency is crucial.</description>
      <guid isPermaLink="false">oai:arXiv.org:2409.16089v2</guid>
      <category>cs.CV</category>
      <category>cs.AI</category>
      <category>cs.CY</category>
      <category>cs.LG</category>
      <pubDate>Tue, 10 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <arxiv:journal_reference>27th International Conference on Pattern Recognition Workshops (ICPRw 2024)</arxiv:journal_reference>
      <dc:creator>Ivan DeAndres-Tame, Muhammad Faisal, Ruben Tolosana, Rouqaiah Al-Refai, Ruben Vera-Rodriguez, Philipp Terh\"orst</dc:creator>
    </item>
    <item>
      <title>Learning With Multi-Group Guarantees For Clusterable Subpopulations</title>
      <link>https://arxiv.org/abs/2410.14588</link>
      <description>arXiv:2410.14588v2 Announce Type: replace-cross 
Abstract: A canonical desideratum for prediction problems is that performance guarantees should hold not just on average over the population, but also for meaningful subpopulations within the overall population. But what constitutes a meaningful subpopulation? In this work, we take the perspective that relevant subpopulations should be defined with respect to the clusters that naturally emerge from the distribution of individuals for which predictions are being made. In this view, a population refers to a mixture model whose components constitute the relevant subpopulations. We suggest two formalisms for capturing per-subgroup guarantees: first, by attributing each individual to the component from which they were most likely drawn, given their features; and second, by attributing each individual to all components in proportion to their relative likelihood of having been drawn from each component. Using online calibration as a case study, we study a multi-objective algorithm that provides guarantees for each of these formalisms by handling all plausible underlying subpopulation structures simultaneously, and achieve an $O(T^{1/2})$ rate even when the subpopulations are not well-separated. In comparison, the more natural cluster-then-predict approach that first recovers the structure of the subpopulations and then makes predictions suffers from a $O(T^{2/3})$ rate and requires the subpopulations to be separable. Along the way, we prove that providing per-subgroup calibration guarantees for underlying clusters can be easier than learning the clusters: separation between median subgroup features is required for the latter but not the former.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.14588v2</guid>
      <category>cs.LG</category>
      <category>cs.CY</category>
      <pubDate>Tue, 10 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Jessica Dai, Nika Haghtalab, Eric Zhao</dc:creator>
    </item>
    <item>
      <title>On the Unknowable Limits to Prediction</title>
      <link>https://arxiv.org/abs/2411.19223</link>
      <description>arXiv:2411.19223v3 Announce Type: replace-cross 
Abstract: This short Correspondence critiques the classic dichotomization of prediction error into reducible and irreducible components, noting that certain types of error can be eliminated at differential speeds. We propose an improved analytical framework that better distinguishes epistemic from aleatoric uncertainty, emphasizing that predictability depends on information sets and cautioning against premature claims of unpredictability.</description>
      <guid isPermaLink="false">oai:arXiv.org:2411.19223v3</guid>
      <category>cs.LG</category>
      <category>cs.AI</category>
      <category>cs.CY</category>
      <category>stat.ME</category>
      <pubDate>Tue, 10 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Jiani Yan, Charles Rahal</dc:creator>
    </item>
  </channel>
</rss>
