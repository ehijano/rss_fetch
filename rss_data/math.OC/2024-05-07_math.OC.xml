<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>math.OC updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/math.OC</link>
    <description>math.OC updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/math.OC" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Tue, 07 May 2024 04:00:48 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Tue, 07 May 2024 00:00:00 -0400</pubDate>
    <skipDays>
      <day>Saturday</day>
      <day>Sunday</day>
    </skipDays>
    <item>
      <title>Exponentially Weighted Algorithm for Online Network Resource Allocation with Long-Term Constraints</title>
      <link>https://arxiv.org/abs/2405.02373</link>
      <description>arXiv:2405.02373v1 Announce Type: new 
Abstract: This paper studies an online optimal resource reservation problem in communication networks with job transfers where the goal is to minimize the reservation cost while maintaining the blocking cost under a certain budget limit. To tackle this problem, we propose a novel algorithm based on a randomized exponentially weighted method that encompasses long-term constraints. We then analyze the performance of our algorithm by establishing an upper bound for the associated regret and the cumulative constraint violations. Finally, we present numerical experiments where we compare the performance of our algorithm with those of reinforcement learning where we show that our algorithm surpasses it.</description>
      <guid isPermaLink="false">oai:arXiv.org:2405.02373v1</guid>
      <category>math.OC</category>
      <category>cs.LG</category>
      <category>stat.ML</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Ahmed Sid-Ali, Ioannis Lambadaris, Yiqiang Q. Zhao, Gennady Shaikhet, Amirhossein Asgharnia</dc:creator>
    </item>
    <item>
      <title>Dynamic Single Facility Location under Cumulative Customer Demand</title>
      <link>https://arxiv.org/abs/2405.02439</link>
      <description>arXiv:2405.02439v1 Announce Type: new 
Abstract: Dynamic facility location problems aim at placing one or more valuable resources over a planning horizon to meet customer demand. Existing literature commonly assumes that customer demand quantities are defined independently for each time period. In many planning contexts, however, unmet demand carries over to future time periods. Unmet demand at some time periods may therefore affect decisions of subsequent time periods. This work studies a novel location problem, where the decision maker relocates a single temporary facility over time to capture cumulative customer demand. We propose two mixed-integer programming models for this problem, and show that one of them has a tighter continuous relaxation and allows the representation of more general customer demand behaviour. We characterize the computational complexity for this problem, and analyze which problem characteristics result in NP-hardness. We then propose an exact branch-and-Benders-cut method, and show how optimality cuts can be computed efficiently through an analytical procedure. Computational experiments show that our method is approximately 30 times faster than solving the tighter formulation directly. Our results also quantify the benefit of accounting for cumulative customer demand within the optimization framework, since the corresponding planning solutions perform much better than those obtained by ignoring cumulative demand or employing myopic heuristics.</description>
      <guid isPermaLink="false">oai:arXiv.org:2405.02439v1</guid>
      <category>math.OC</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Warley Almeida Silva, Margarida Carvalho, Sanjay Dominik Jena</dc:creator>
    </item>
    <item>
      <title>Natural Policy Gradient and Actor Critic Methods for Constrained Multi-Task Reinforcement Learning</title>
      <link>https://arxiv.org/abs/2405.02456</link>
      <description>arXiv:2405.02456v1 Announce Type: new 
Abstract: Multi-task reinforcement learning (RL) aims to find a single policy that effectively solves multiple tasks at the same time. This paper presents a constrained formulation for multi-task RL where the goal is to maximize the average performance of the policy across tasks subject to bounds on the performance in each task. We consider solving this problem both in the centralized setting, where information for all tasks is accessible to a single server, and in the decentralized setting, where a network of agents, each given one task and observing local information, cooperate to find the solution of the globally constrained objective using local communication.
  We first propose a primal-dual algorithm that provably converges to the globally optimal solution of this constrained formulation under exact gradient evaluations. When the gradient is unknown, we further develop a sampled-based actor-critic algorithm that finds the optimal policy using online samples of state, action, and reward. Finally, we study the extension of the algorithm to the linear function approximation setting.</description>
      <guid isPermaLink="false">oai:arXiv.org:2405.02456v1</guid>
      <category>math.OC</category>
      <category>cs.LG</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Sihan Zeng, Thinh T. Doan, Justin Romberg</dc:creator>
    </item>
    <item>
      <title>Prediction techniques for dynamic imaging with online primal-dual methods</title>
      <link>https://arxiv.org/abs/2405.02497</link>
      <description>arXiv:2405.02497v1 Announce Type: new 
Abstract: Online optimisation facilitates the solution of dynamic inverse problems, such as image stabilisation, fluid flow monitoring, and dynamic medical imaging. In this paper, we improve upon previous work on predictive online primal-dual methods on two fronts. Firstly, we provide a more concise analysis that symmetrises previously unsymmetric regret bounds, and relaxes previous restrictive conditions on the dual predictor. Secondly, based on the latter, we develop several improved dual predictors. We numerically demonstrate their efficacy in image stabilisation and dynamic positron emission tomography.</description>
      <guid isPermaLink="false">oai:arXiv.org:2405.02497v1</guid>
      <category>math.OC</category>
      <category>cs.CV</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Neil Dizon, Jyrki Jauhiainen, Tuomo Valkonen</dc:creator>
    </item>
    <item>
      <title>A computational study of cutting-plane methods for multi-stage stochastic integer programs</title>
      <link>https://arxiv.org/abs/2405.02533</link>
      <description>arXiv:2405.02533v1 Announce Type: new 
Abstract: We report a computational study of cutting plane algorithms for multi-stage stochastic mixed-integer programming models with the following cuts: (i) Benders', (ii) Integer L-shaped, and (iii) Lagrangian cuts. We first show that Integer L-shaped cuts correspond to one of the optimal solutions of the Lagrangian dual problem, and, therefore, belong to the class of Lagrangian cuts. To efficiently generate these cuts, we present an enhancement strategy to reduce time-consuming exact evaluations of integer subproblems by alternating between cuts derived from the relaxed and exact computation. Exact evaluations are only employed when Benders' cut from the relaxation fails to cut off the incumbent solution. Our preliminary computational results show the merit of this approach on multiple classes of real-world problems.</description>
      <guid isPermaLink="false">oai:arXiv.org:2405.02533v1</guid>
      <category>math.OC</category>
      <category>math.CO</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Akul Bansal, Simge K\"u\c{c}\"ukyavuz</dc:creator>
    </item>
    <item>
      <title>An integer programming approach for quick-commerce assortment planning</title>
      <link>https://arxiv.org/abs/2405.02553</link>
      <description>arXiv:2405.02553v1 Announce Type: new 
Abstract: In this paper, we explore the challenge of assortment planning in the context of quick-commerce, a rapidly-growing business model that aims to deliver time-sensitive products. In order to achieve quick delivery to satisfy the immediate demands of online customers in close proximity, personalized online assortments need to be included in brick-and-mortar store offerings. With the presence of this physical linkage requirement and distinct multinomial logit (MNL) choice models for online consumer segments, the firm seeks to maximize overall revenue by selecting an optimal assortment of products for local stores and by tailoring a personalized assortment for each online consumer segment. We refer to this problem as quick-commerce assortment planning (QAP). We employ an integer programming approach to solve this NP-hard problem to global optimality. Specifically, we propose convexification techniques to handle its combinatorial and nonconvex nature. We capture the consumer choice of each online segment using a convex hull representation. By exploiting the geometry behind Luce's choice axiom, we provide a compact polyhedral characterization of the convex hull under various operational constraints that are not totally-unimodular. Furthermore, we conduct a polyhedral study on the relation between assortment decisions for products to offer and choice probabilities of products under the MNL model.Our methodology, coupled with a modified choice probability ordered separation algorithm, yields formulations that provide a significant computational advantage over existing methods. Through comprehensive numerical studies, we emphasize the significance of aligning offline and online assortment decisions and underscore the perils associated with inaccurately specifying customer behavior models.</description>
      <guid isPermaLink="false">oai:arXiv.org:2405.02553v1</guid>
      <category>math.OC</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <dc:creator>Yajing Chen, Taotao He, Ying Rong, Yunlong Wang</dc:creator>
    </item>
    <item>
      <title>Inexact Adaptive Cubic Regularization Algorithms on Riemannian Manifolds and Application</title>
      <link>https://arxiv.org/abs/2405.02588</link>
      <description>arXiv:2405.02588v1 Announce Type: new 
Abstract: The adaptive cubic regularization algorithm employing the inexact gradient and Hessian is proposed on general Riemannian manifolds, together with the iteration complexity to get an approximate second-order optimality under certain assumptions on accuracies about the inexact gradient and Hessian. The algorithm extends the inexact adaptive cubic regularization algorithm under true gradient in [Math. Program., 184(1-2): 35-70, 2020] to more general cases even in Euclidean settings. As an application, the algorithm is applied to solve the joint diagonalization problem on the Stiefel manifold. Numerical experiments illustrate that the algorithm performs better than the inexact trust-region algorithm in [Advances of the neural information processing systems, 31, 2018].</description>
      <guid isPermaLink="false">oai:arXiv.org:2405.02588v1</guid>
      <category>math.OC</category>
      <category>cs.NA</category>
      <category>math.NA</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Z. Y. Li, X. M. Wang</dc:creator>
    </item>
    <item>
      <title>Unscented Trajectory Optimization</title>
      <link>https://arxiv.org/abs/2405.02753</link>
      <description>arXiv:2405.02753v1 Announce Type: new 
Abstract: In a nutshell, unscented trajectory optimization is the generation of optimal trajectories through the use of an unscented transform. Although unscented trajectory optimization was introduced by the authors about a decade ago, it is reintroduced in this paper as a special instantiation of tychastic optimal control theory. Tychastic optimal control theory (from \textit{Tyche}, the Greek goddess of chance) avoids the use of a Brownian motion and the resulting It\^{o} calculus even though it uses random variables across the entire spectrum of a problem formulation. This approach circumvents the enormous technical and numerical challenges associated with stochastic trajectory optimization. Furthermore, it is shown how a tychastic optimal control problem that involves nonlinear transformations of the expectation operator can be quickly instantiated using an unscented transform. These nonlinear transformations are particularly useful in managing trajectory dispersions be it associated with path constraints or targeted values of final-time conditions. This paper also presents a systematic and rapid process for formulating and computing the most desirable tychastic trajectory using an unscented transform. Numerical examples are used to illustrate how unscented trajectory optimization may be used for risk reduction and mission recovery caused by uncertainties and failures.</description>
      <guid isPermaLink="false">oai:arXiv.org:2405.02753v1</guid>
      <category>math.OC</category>
      <category>cs.SY</category>
      <category>eess.SY</category>
      <category>math.ST</category>
      <category>stat.CO</category>
      <category>stat.TH</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>I. M. Ross, R. J. Proulx, M. Karpenko</dc:creator>
    </item>
    <item>
      <title>Real-time solution of quadratic optimization problems with banded matrices and indicator variables</title>
      <link>https://arxiv.org/abs/2405.03051</link>
      <description>arXiv:2405.03051v1 Announce Type: new 
Abstract: We consider mixed-integer quadratic optimization problems with banded matrices and indicator variables. These problems arise pervasively in statistical inference problems with time-series data, where the banded matrix captures the temporal relationship of the underlying process. In particular, the problem studied arises in monitoring problems, where the decision-maker wants to detect changes or anomalies. We propose to solve these problems using decision diagrams. In particular we show how to exploit the temporal dependencies to construct diagrams with size polynomial in the number of decision variables. We also describe how to construct the convex hull of the set under study from the decision diagrams, and how to deploy the method online to solve the problems in milliseconds via a shortest path algorithm.</description>
      <guid isPermaLink="false">oai:arXiv.org:2405.03051v1</guid>
      <category>math.OC</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Andres Gomez, Shaoning Han, Leonardo Lozano</dc:creator>
    </item>
    <item>
      <title>Convergence and Complexity Guarantee for Inexact First-order Riemannian Optimization Algorithms</title>
      <link>https://arxiv.org/abs/2405.03073</link>
      <description>arXiv:2405.03073v1 Announce Type: new 
Abstract: We analyze inexact Riemannian gradient descent (RGD) where Riemannian gradients and retractions are inexactly (and cheaply) computed. Our focus is on understanding when inexact RGD converges and what is the complexity in the general nonconvex and constrained setting. We answer these questions in a general framework of tangential Block Majorization-Minimization (tBMM). We establish that tBMM converges to an $\epsilon$-stationary point within $O(\epsilon^{-2})$ iterations. Under a mild assumption, the results still hold when the subproblem is solved inexactly in each iteration provided the total optimality gap is bounded. Our general analysis applies to a wide range of classical algorithms with Riemannian constraints including inexact RGD and proximal gradient method on Stiefel manifolds. We numerically validate that tBMM shows improved performance over existing methods when applied to various problems, including nonnegative tensor decomposition with Riemannian constraints, regularized nonnegative matrix factorization, and low-rank matrix recovery problems.</description>
      <guid isPermaLink="false">oai:arXiv.org:2405.03073v1</guid>
      <category>math.OC</category>
      <category>stat.ML</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Yuchen Li, Laura Balzano, Deanna Needell, Hanbaek Lyu</dc:creator>
    </item>
    <item>
      <title>Linear-Quadratic Mean Field Stackelberg Stochastic Differential Game with Partial Information and Common Noise</title>
      <link>https://arxiv.org/abs/2405.03102</link>
      <description>arXiv:2405.03102v1 Announce Type: new 
Abstract: This paper is concerned with a linear-quadratic mean field Stackelberg stochastic differential game with partial information and common noise, which contains a leader and a large number of followers. To be specific, the followers face a large population Nash game after the leader first announces his strategy, while the leader will then optimize his own cost functional on consideration of the followers' reactions. The state equation of the leader and followers are both general stochastic differential equations, where the diffusion terms contain both the control and state variables. However, the followers' average state terms enter into the drift term of the leader's state equation, reflecting that the leader's state is influenced by the followers' states. By virtue of stochastic maximum principle with partial information and optimal filter technique, we deduce the open-loop adapted decentralized strategies and feedback decentralized strategies of this leader-followers system, and demonstrate that the decentralized strategies are the corresponding $\varepsilon$-Stackelberg-Nash equilibrium.</description>
      <guid isPermaLink="false">oai:arXiv.org:2405.03102v1</guid>
      <category>math.OC</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/publicdomain/zero/1.0/</dc:rights>
      <dc:creator>Yu Si, Jingtao Shi</dc:creator>
    </item>
    <item>
      <title>Revealing Decision Conservativeness Through Inverse Distributionally Robust Optimization</title>
      <link>https://arxiv.org/abs/2405.03123</link>
      <description>arXiv:2405.03123v1 Announce Type: new 
Abstract: This paper introduces Inverse Distributionally Robust Optimization (I-DRO) as a method to infer the conservativeness level of a decision-maker, represented by the size of a Wasserstein metric-based ambiguity set, from the optimal decisions made using Forward Distributionally Robust Optimization (F-DRO). By leveraging the Karush-Kuhn-Tucker (KKT) conditions of the convex F-DRO model, we formulate I-DRO as a bi-linear program, which can be solved using off-the-shelf optimization solvers. Additionally, this formulation exhibits several advantageous properties. We demonstrate that I-DRO not only guarantees the existence and uniqueness of an optimal solution but also establishes the necessary and sufficient conditions for this optimal solution to accurately match the actual conservativeness level in F-DRO. Furthermore, we identify three extreme scenarios that may impact I-DRO effectiveness. Our case study applies F-DRO for power system scheduling under uncertainty and employs I-DRO to recover the conservativeness level of system operators. Numerical experiments based on an IEEE 5-bus system and a realistic NYISO 11-zone system demonstrate I-DRO performance in both normal and extreme scenarios.</description>
      <guid isPermaLink="false">oai:arXiv.org:2405.03123v1</guid>
      <category>math.OC</category>
      <category>cs.SY</category>
      <category>eess.SY</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Qi Li, Zhirui Liang, Andrey Bernstein, Yury Dvorkin</dc:creator>
    </item>
    <item>
      <title>General Procedure to Provide High-Probability Guarantees for Stochastic Saddle Point Problems</title>
      <link>https://arxiv.org/abs/2405.03219</link>
      <description>arXiv:2405.03219v1 Announce Type: new 
Abstract: This paper considers smooth strongly convex and strongly concave (SC-SC) stochastic saddle point (SSP) problems. Suppose there is an arbitrary oracle that in expectation returns an $\epsilon$-solution in the sense of certain gaps, which can be the duality gap or its weaker variants. We propose a general PB-SSP framework to guarantee an $\epsilon$ small duality gap solution with high probability via only $\mathcal{O}\big(\log \frac{1}{p}\cdot\text{poly}(\log \kappa)\big)$ calls of this oracle, where $p\in(0,1)$ is the confidence level and $\kappa$ is the condition number. When applied to the sample average approximation (SAA) oracle, in addition to equipping the solution with high probability, our approach even improves the sample complexity by a factor of $\text{poly}(\kappa)$, since the high-probability argument enables us to circumvent some key difficulties of the uniform stability analysis of SAA.</description>
      <guid isPermaLink="false">oai:arXiv.org:2405.03219v1</guid>
      <category>math.OC</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Dongyang Li, Haobin Li, Junyu Zhang</dc:creator>
    </item>
    <item>
      <title>Inertial Relaxed Proximal Linearized ADMM for Nonconvex Optimization under Minimal Continuity Assumption</title>
      <link>https://arxiv.org/abs/2405.03233</link>
      <description>arXiv:2405.03233v1 Announce Type: new 
Abstract: This paper proposes an Inertial Relaxed Proximal Linearized Alternating Direction Method of Multipliers (IRPL-ADMM) for solving general multi-block nonconvex composite optimization problems. Distinguishing itself from existing ADMM-style algorithms, our approach imposes a less stringent condition, specifically requiring continuity in only one block of the objective function. It incorporates an inertial strategy for primal variable updates, and a relaxed strategy for dual variable updates. The fundamental concept underlying our algorithm is based on novel \textit{regular penalty update rules}, ensuring that the penalty increases but not excessively fast. We devise a novel potential function to facilitate our convergence analysis and extend our methods from deterministic optimization problems to finite-sum stochastic settings. We establish the iteration complexity for both scenarios for achieving an approximate stationary solution. Under the Kurdyka-Lojasiewicz (KL) inequality, we establish strong limit-point convergence results for the IRPL-ADMM algorithm. Finally, some experiments have been conducted on two machine learning tasks to show the effectiveness of our approaches.</description>
      <guid isPermaLink="false">oai:arXiv.org:2405.03233v1</guid>
      <category>math.OC</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Ganzhao Yuan</dc:creator>
    </item>
    <item>
      <title>Null controllability for stochastic fourth order semi-discrete parabolic equations</title>
      <link>https://arxiv.org/abs/2405.03257</link>
      <description>arXiv:2405.03257v1 Announce Type: new 
Abstract: This paper is devoted to studying null controllability for a class of stochastic fourth order semi-discrete parabolic equations, where the spatial variable is discretized with finite difference scheme and the time is kept as a continuous variable. For this purpose, we establish a new global Carleman estimate for a backward stochastic fourth order semi-discrete parabolic operators, in which the large parameter is connected to the mesh size. A relaxed observability estimate is established for backward stochastic fourth order semi-discrete parabolic equations by this new Carleman estimate, with an explicit observability constant that depends on the discretization parameter and coefficients of lower order terms. Then, the $\phi$-null controllability of the stochastic fourth order semi-discrete parabolic equations is proved using the standard duality technique.</description>
      <guid isPermaLink="false">oai:arXiv.org:2405.03257v1</guid>
      <category>math.OC</category>
      <category>math.PR</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Yu Wang, Qingmei Zhao</dc:creator>
    </item>
    <item>
      <title>Adaptive Accelerated Composite Minimization</title>
      <link>https://arxiv.org/abs/2405.03414</link>
      <description>arXiv:2405.03414v1 Announce Type: new 
Abstract: The choice of the stepsize in first-order convex optimization is typically based on the smoothness constant and plays a crucial role in the performance of algorithms. Recently, there has been a resurgent interest in introducing adaptive stepsizes that do not explicitly depend on smooth constant. In this paper, we propose a novel adaptive stepsize rule based on function evaluations (i.e., zero-order information) that enjoys provable convergence guarantees for both accelerated and non-accelerated gradient descent. We further discuss the similarities and differences between the proposed stepsize regimes and the existing stepsize rules (including Polyak and Armijo). Numerically, we benchmark the performance of our proposed algorithms with the state-of-the-art literature in three different classes of smooth minimization (logistic regression, quadratic programming, log-sum-exponential, and approximate semidefinite programming), composite minimization ($\ell_1$ constrained and regularized problems), and non-convex minimization (cubic problem).</description>
      <guid isPermaLink="false">oai:arXiv.org:2405.03414v1</guid>
      <category>math.OC</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Reza Rahimi Baghbadorani, Sergio Grammatico, Peyman Mohajerin Esfahani</dc:creator>
    </item>
    <item>
      <title>A Symplectic Analysis of Alternating Mirror Descent</title>
      <link>https://arxiv.org/abs/2405.03472</link>
      <description>arXiv:2405.03472v1 Announce Type: new 
Abstract: Motivated by understanding the behavior of the Alternating Mirror Descent (AMD) algorithm for bilinear zero-sum games, we study the discretization of continuous-time Hamiltonian flow via the symplectic Euler method. We provide a framework for analysis using results from Hamiltonian dynamics, Lie algebra, and symplectic numerical integrators, with an emphasis on the existence and properties of a conserved quantity, the modified Hamiltonian (MH), for the symplectic Euler method. We compute the MH in closed-form when the original Hamiltonian is a quadratic function, and show that it generally differs from the other conserved quantity known previously in that case. We derive new error bounds on the MH when truncated at orders in the stepsize in terms of the number of iterations, $K$, and utilize this bound to show an improved $\mathcal{O}(K^{1/5})$ total regret bound and an $\mathcal{O}(K^{-4/5})$ duality gap of the average iterates for AMD. Finally, we propose a conjecture which, if true, would imply that the total regret for AMD goes as $\mathcal{O}\left(K^{\varepsilon}\right)$ and the duality gap of the average iterates as $\mathcal{O}\left(K^{-1+\varepsilon}\right)$ for any $\varepsilon&gt;0$, and we can take $\varepsilon=0$ upon certain convergence conditions for the MH.</description>
      <guid isPermaLink="false">oai:arXiv.org:2405.03472v1</guid>
      <category>math.OC</category>
      <category>cs.GT</category>
      <category>cs.LG</category>
      <category>cs.NA</category>
      <category>math.DS</category>
      <category>math.NA</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Jonas Katona, Xiuyuan Wang, Andre Wibisono</dc:creator>
    </item>
    <item>
      <title>Converse Lyapunov Results for Stability of Switched Systems with Average Dwell-Time</title>
      <link>https://arxiv.org/abs/2405.03560</link>
      <description>arXiv:2405.03560v1 Announce Type: new 
Abstract: This article provides a characterization of stability for switched nonlinear systems under average dwell-time constraints, in terms of necessary and sufficient conditions involving multiple Lyapunov functions. Earlier converse results focus on switched systems with dwell-time constraints only, and the resulting inequalities depend on the flow of individual subsystems. With the help of a counterexample, we show that a lower bound that guarantees stability for dwell-time switching signals may not necessarily imply stability for switching signals with same lower bound on the average dwell-time. Based on these two observations, we provide a converse result for the average dwell-time constrained systems in terms of inequalities which do not depend on the flow of individual subsystems and are easier to check. The particular case of linear switched systems is studied as a corollary to our main result.</description>
      <guid isPermaLink="false">oai:arXiv.org:2405.03560v1</guid>
      <category>math.OC</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Matteo Della Rossa, Aneel Tanwani</dc:creator>
    </item>
    <item>
      <title>A GPU-Accelerated Interior Point Method for Radiation Therapy Optimization</title>
      <link>https://arxiv.org/abs/2405.03584</link>
      <description>arXiv:2405.03584v1 Announce Type: new 
Abstract: Optimization plays a central role in modern radiation therapy, where it is used to determine optimal treatment machine parameters in order to deliver precise doses adapted to each patient case. In general, solving the optimization problems that arise can present a computational bottleneck in the treatment planning process, as they can be large in terms of both variables and constraints. In this paper, we develop a GPU accelerated optimization solver for radiation therapy applications, based on an interior point method (IPM) utilizing iterative linear algebra to find search directions. The use of iterative linear algebra makes the solver suitable for porting to GPUs, as the core computational kernels become standard matrix-vector or vector-vector operations. Our solver is implemented in C++20 and uses CUDA for GPU acceleration.
  The problems we solve are from the commercial treatment planning system RayStation, developed by RaySearch Laboratories (Stockholm, Sweden), which is used clinically in hundreds of cancer clinics around the world. RayStation solves (in general) nonlinear optimization problems using a sequential quadratic programming (SQP) method, where the main computation lies in solving quadratic programming (QP) sub-problems in each iteration. GPU acceleration for the solution of such QP sub-problems is the focus of the interior point method of this work. We benchmark our solver against the existing QP-solver in RayStation and show that our GPU accelerated IPM can accelerate the aggregated time-to-solution for all QP sub-problems in one SQP solve by 1.4 and 4.4 times, respectively, for two real patient cases.</description>
      <guid isPermaLink="false">oai:arXiv.org:2405.03584v1</guid>
      <category>math.OC</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Felix Liu, Albin Fredriksson, Stefano Markidis</dc:creator>
    </item>
    <item>
      <title>Linear Convergence of Independent Natural Policy Gradient in Games with Entropy Regularization</title>
      <link>https://arxiv.org/abs/2405.02769</link>
      <description>arXiv:2405.02769v1 Announce Type: cross 
Abstract: This work focuses on the entropy-regularized independent natural policy gradient (NPG) algorithm in multi-agent reinforcement learning. In this work, agents are assumed to have access to an oracle with exact policy evaluation and seek to maximize their respective independent rewards. Each individual's reward is assumed to depend on the actions of all the agents in the multi-agent system, leading to a game between agents. We assume all agents make decisions under a policy with bounded rationality, which is enforced by the introduction of entropy regularization. In practice, a smaller regularization implies the agents are more rational and behave closer to Nash policies. On the other hand, agents with larger regularization acts more randomly, which ensures more exploration. We show that, under sufficient entropy regularization, the dynamics of this system converge at a linear rate to the quantal response equilibrium (QRE). Although regularization assumptions prevent the QRE from approximating a Nash equilibrium, our findings apply to a wide range of games, including cooperative, potential, and two-player matrix games. We also provide extensive empirical results on multiple games (including Markov games) as a verification of our theoretical analysis.</description>
      <guid isPermaLink="false">oai:arXiv.org:2405.02769v1</guid>
      <category>cs.LG</category>
      <category>cs.MA</category>
      <category>math.OC</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Youbang Sun, Tao Liu, P. R. Kumar, Shahin Shahrampour</dc:creator>
    </item>
    <item>
      <title>Model Predictive Control for Joint Ramping and Regulation-Type Service from Distributed Energy Resource Aggregations</title>
      <link>https://arxiv.org/abs/2405.02813</link>
      <description>arXiv:2405.02813v1 Announce Type: cross 
Abstract: Distributed energy resources (DERs) such as grid-responsive loads and batteries can be harnessed to provide ramping and regulation services across the grid. This paper concerns the problem of optimal allocation of different classes of DERs, where each class is an aggregation of similar DERs, to balance net-demand forecasts. The resulting resource allocation problem is solved using model-predictive control (MPC) that utilizes a rolling sequence of finite time-horizon constrained optimizations. This is based on the concept that we have more accurate estimates of the load forecast in the short term, so each optimization in the rolling sequence of optimization problems uses more accurate short term load forecasts while ensuring satisfaction of capacity and dynamical constraints. Simulations demonstrate that the MPC solution can indeed reduce the ramping required from bulk generation, while mitigating near-real time grid disturbances.</description>
      <guid isPermaLink="false">oai:arXiv.org:2405.02813v1</guid>
      <category>eess.SY</category>
      <category>cs.SY</category>
      <category>math.OC</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Joel Mathias, Rajasekhar Anguluri, Oliver Kosut, Lalitha Sankar</dc:creator>
    </item>
    <item>
      <title>Halfway Escape Optimization: A Quantum-Inspired Solution for Complex Optimization Problems</title>
      <link>https://arxiv.org/abs/2405.02850</link>
      <description>arXiv:2405.02850v1 Announce Type: cross 
Abstract: This paper first proposes the Halfway Escape Optimization (HEO) algorithm, a novel quantum-inspired metaheuristic designed to address complex optimization problems characterized by rugged landscapes and high-dimensionality with an efficient convergence rate. The study presents a comprehensive comparative evaluation of HEO's performance against established optimization algorithms, including Particle Swarm Optimization (PSO), Genetic Algorithm (GA), Artificial Fish Swarm Algorithm (AFSA), Grey Wolf Optimizer (GWO), and Quantum behaved Particle Swarm Optimization (QPSO). The primary analysis encompasses 14 benchmark functions with dimension 30, demonstrating HEO's effectiveness and adaptability in navigating complex optimization landscapes and providing valuable insights into its performance. The simple test of HEO in Traveling Salesman Problem (TSP) also infers its feasibility in real-time applications.</description>
      <guid isPermaLink="false">oai:arXiv.org:2405.02850v1</guid>
      <category>cs.NE</category>
      <category>cs.AI</category>
      <category>math.OC</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Jiawen Li, Anwar PP Abdul Majeed, Pascal Lefevre</dc:creator>
    </item>
    <item>
      <title>Projected gradient descent algorithm for $\textit{ab initio}$ crystal structure relaxation under a fixed unit cell volume</title>
      <link>https://arxiv.org/abs/2405.02934</link>
      <description>arXiv:2405.02934v1 Announce Type: cross 
Abstract: This paper is concerned with $\textit{ab initio}$ crystal structure relaxation under a fixed unit cell volume, which is a step in calculating the static equations of state and forms the basis of thermodynamic property calculations for materials. The task can be formulated as an energy minimization with a determinant constraint. Widely used line minimization-based methods (e.g., conjugate gradient method) lack both efficiency and convergence guarantees due to the nonconvex nature of the feasible region as well as the significant differences in the curvatures of the potential energy surface with respect to atomic and lattice components. To this end, we propose a projected gradient descent algorithm named PANBB. It is equipped with (i) search direction projections onto the tangent spaces of the nonconvex feasible region for lattice vectors, (ii) distinct curvature-aware initial trial step sizes for atomic and lattice updates, and (iii) a nonrestrictive line minimization criterion as the stopping rule for the inner loop. It can be proved that PANBB favors theoretical convergence to equilibrium states. Across a benchmark set containing 223 structures from various categories, PANBB achieves average speedup factors of approximately 1.41 and 1.45 over the conjugate gradient method and direct inversion in the iterative subspace implemented in off-the-shelf simulation software, respectively. Moreover, it normally converges on all the systems, manifesting its unparalleled robustness. As an application, we calculate the static equations of state for the high-entropy alloy AlCoCrFeNi, which remains elusive owing to 160 atoms representing both chemical and magnetic disorder and the strong local lattice distortion. The results are consistent with the previous calculations and are further validated by experimental thermodynamic data.</description>
      <guid isPermaLink="false">oai:arXiv.org:2405.02934v1</guid>
      <category>physics.comp-ph</category>
      <category>cond-mat.mtrl-sci</category>
      <category>math.OC</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Yukuan Hu, Junlei Yin, Xingyu Gao, Xin Liu, Haifeng Song</dc:creator>
    </item>
    <item>
      <title>Bayesian optimization for stable properties amid processing fluctuations in sputter deposition</title>
      <link>https://arxiv.org/abs/2405.03092</link>
      <description>arXiv:2405.03092v1 Announce Type: cross 
Abstract: We introduce a Bayesian optimization approach to guide the sputter deposition of molybdenum thin films, aiming to achieve desired residual stress and sheet resistance while minimizing susceptibility to stochastic fluctuations during deposition. Thin films are pivotal in numerous technologies, including semiconductors and optical devices, where their properties are critical. Sputter deposition parameters, such as deposition power, vacuum chamber pressure, and working distance, influence physical properties like residual stress and resistance. Excessive stress and high resistance can impair device performance, necessitating the selection of optimal process parameters. Furthermore, these parameters should ensure the consistency and reliability of thin film properties, assisting in the reproducibility of the devices. However, exploring the multidimensional design space for process optimization is expensive. Bayesian optimization is ideal for optimizing inputs/parameters of general black-box functions without reliance on gradient information. We utilize Bayesian optimization to optimize deposition power and pressure using a custom-built objective function incorporating observed stress and resistance data. Additionally, we integrate prior knowledge of stress variation with pressure into the objective function to prioritize films least affected by stochastic variations. Our findings demonstrate that Bayesian optimization effectively explores the design space and identifies optimal parameter combinations meeting desired stress and resistance specifications.</description>
      <guid isPermaLink="false">oai:arXiv.org:2405.03092v1</guid>
      <category>cond-mat.mtrl-sci</category>
      <category>cs.LG</category>
      <category>math.OC</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <arxiv:DOI>10.1116/6.0003418</arxiv:DOI>
      <arxiv:journal_reference>J. Vac. Sci. Technol. A 1 May 2024; 42 (3): 033408</arxiv:journal_reference>
      <dc:creator>Ankit Shrivastava, Matias Kalaswad, Joyce O. Custer, David P. Adams, Habib N. Najm</dc:creator>
    </item>
    <item>
      <title>Stability Evaluation via Distributional Perturbation Analysis</title>
      <link>https://arxiv.org/abs/2405.03198</link>
      <description>arXiv:2405.03198v1 Announce Type: cross 
Abstract: The performance of learning models often deteriorates when deployed in out-of-sample environments. To ensure reliable deployment, we propose a stability evaluation criterion based on distributional perturbations. Conceptually, our stability evaluation criterion is defined as the minimal perturbation required on our observed dataset to induce a prescribed deterioration in risk evaluation. In this paper, we utilize the optimal transport (OT) discrepancy with moment constraints on the \textit{(sample, density)} space to quantify this perturbation. Therefore, our stability evaluation criterion can address both \emph{data corruptions} and \emph{sub-population shifts} -- the two most common types of distribution shifts in real-world scenarios. To further realize practical benefits, we present a series of tractable convex formulations and computational methods tailored to different classes of loss functions. The key technical tool to achieve this is the strong duality theorem provided in this paper. Empirically, we validate the practical utility of our stability evaluation criterion across a host of real-world applications. These empirical studies showcase the criterion's ability not only to compare the stability of different learning models and features but also to provide valuable guidelines and strategies to further improve models.</description>
      <guid isPermaLink="false">oai:arXiv.org:2405.03198v1</guid>
      <category>stat.ML</category>
      <category>cs.LG</category>
      <category>math.OC</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Jose Blanchet, Peng Cui, Jiajin Li, Jiashuo Liu</dc:creator>
    </item>
    <item>
      <title>Swarm intelligence for full Stokes dynamic imaging reconstruction of interferometric data</title>
      <link>https://arxiv.org/abs/2405.03330</link>
      <description>arXiv:2405.03330v1 Announce Type: cross 
Abstract: In very long baseline interferometry (VLBI) the combination of multiple antennas permits the synthesis of a virtual telescope with a larger diameter and consequently higher resolution than the individual antennae. Yet, due to the sparse nature of the array, recovering an image from the observed data is a challenging ill-posed inverse problem. The VLBI community is interested in not only recovering an image in total intensity from interferometric data, but also to obtain results in the polarimetric and the temporal domain. Only a few algorithms are able to work in all these domains simultaneously. In particular, the algorithms based on optimization that consider various penalty terms specific to static total intensity imaging, time-variability and polarimetry are restricted to grids the domain of the objective function. In this work we present a novel algorithm, multiobjective particle swarm optimization, that is able to recover the optimal weights without any space-gridding, and to obtain the marginal contribution of each the playing terms. To this end, we utilize multiobjective optimization together with particle swarm metaheuristics. We let the swarm of weights to converge together to the best position. We evaluate our algorithm with representative synthetic data sets focused on the instrumental configuration of the Event Horizon Telescope Collaboration and its planned successors. We successfully recover the polarimetric, static and time-dynamic signature of the ground truth movie, even with relative sparsity, and a set of realistic data corruptions. This is a novel, fast, weighting space gridding-free algorithm that successfully recovers static and dynamic polarimetric reconstructions. Compared to Regularized Maximum Likelihood methods, it avoids the need for parameter surveys, and it is not limited to the number of pixels such as recently proposed multiobjective imaging algorithms.</description>
      <guid isPermaLink="false">oai:arXiv.org:2405.03330v1</guid>
      <category>astro-ph.IM</category>
      <category>astro-ph.GA</category>
      <category>math.OC</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Alejandro Mus, Hendrik M\"uller, Andrei Lobanov</dc:creator>
    </item>
    <item>
      <title>$\epsilon$-Policy Gradient for Online Pricing</title>
      <link>https://arxiv.org/abs/2405.03624</link>
      <description>arXiv:2405.03624v1 Announce Type: cross 
Abstract: Combining model-based and model-free reinforcement learning approaches, this paper proposes and analyzes an $\epsilon$-policy gradient algorithm for the online pricing learning task. The algorithm extends $\epsilon$-greedy algorithm by replacing greedy exploitation with gradient descent step and facilitates learning via model inference. We optimize the regret of the proposed algorithm by quantifying the exploration cost in terms of the exploration probability $\epsilon$ and the exploitation cost in terms of the gradient descent optimization and gradient estimation errors. The algorithm achieves an expected regret of order $\mathcal{O}(\sqrt{T})$ (up to a logarithmic factor) over $T$ trials.</description>
      <guid isPermaLink="false">oai:arXiv.org:2405.03624v1</guid>
      <category>cs.LG</category>
      <category>math.OC</category>
      <category>q-fin.ST</category>
      <category>stat.ML</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Lukasz Szpruch, Tanut Treetanthiploet, Yufei Zhang</dc:creator>
    </item>
    <item>
      <title>Configuration-Constrained Tube MPC for Tracking</title>
      <link>https://arxiv.org/abs/2405.03629</link>
      <description>arXiv:2405.03629v1 Announce Type: cross 
Abstract: This paper proposes a novel tube-based Model Predictive Control (MPC) framework for tracking varying setpoint references with linear systems subject to additive and multiplicative uncertainties. The MPC controllers designed using this framework exhibit recursively feasible for changing references, and robust asymptotic stability for piecewise constant references. The framework leverages configuration-constrained polytopes to parameterize the tubes, offering flexibility to optimize their shape. The efficacy of the approach is demonstrated through two numerical examples. The first example illustrates the theoretical results, and the second uses the framework to design a lane-change controller for an autonomous vehicle.</description>
      <guid isPermaLink="false">oai:arXiv.org:2405.03629v1</guid>
      <category>eess.SY</category>
      <category>cs.SY</category>
      <category>math.OC</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Filippo Badalamenti, Sampath Kumar Mulagaleti, Alberto Bemporad, Boris Houska, Mario Eduardo Villanueva</dc:creator>
    </item>
    <item>
      <title>Multiarmed Bandits Problem Under the Mean-Variance Setting</title>
      <link>https://arxiv.org/abs/2212.09192</link>
      <description>arXiv:2212.09192v4 Announce Type: replace 
Abstract: The classical multi-armed bandit (MAB) problem involves a learner and a collection of K independent arms, each with its own ex ante unknown independent reward distribution. At each one of a finite number of rounds, the learner selects one arm and receives new information. The learner often faces an exploration-exploitation dilemma: exploiting the current information by playing the arm with the highest estimated reward versus exploring all arms to gather more reward information. The design objective aims to maximize the expected cumulative reward over all rounds. However, such an objective does not account for a risk-reward tradeoff, which is often a fundamental precept in many areas of applications, most notably in finance and economics. In this paper, we build upon Sani et al. (2012) and extend the classical MAB problem to a mean-variance setting. Specifically, we relax the assumptions of independent arms and bounded rewards made in Sani et al. (2012) by considering sub-Gaussian arms. We introduce the Risk Aware Lower Confidence Bound (RALCB) algorithm to solve the problem, and study some of its properties. Finally, we perform a number of numerical simulations to demonstrate that, in both independent and dependent scenarios, our suggested approach performs better than the algorithm suggested by Sani et al. (2012).</description>
      <guid isPermaLink="false">oai:arXiv.org:2212.09192v4</guid>
      <category>math.OC</category>
      <category>q-fin.CP</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Hongda Hu, Arthur Charpentier, Mario Ghossoub, Alexander Schied</dc:creator>
    </item>
    <item>
      <title>Convergence of the Preconditioned Proximal Point Method and Douglas-Rachford Splitting in the Absence of Monotonicity</title>
      <link>https://arxiv.org/abs/2305.03605</link>
      <description>arXiv:2305.03605v2 Announce Type: replace 
Abstract: The proximal point algorithm (PPA) is the most widely recognized method for solving inclusion problems and serves as the foundation for many numerical algorithms. Despite this popularity, its convergence results have been largely limited to the monotone setting. In this work, we study the convergence of (relaxed) preconditioned PPA for a class of nonmonotone problems that satisfy an oblique weak Minty condition. Additionally, we study the (relaxed) Douglas-Rachford splitting (DRS) method in the nonmonotone setting by establishing a connection between DRS and the preconditioned PPA with a positive semidefinite preconditioner. To better characterize the class of problems covered by our analysis, we introduce the class of semimonotone operators, offering a natural extension to (hypo)monotone and co(hypo)monotone operators, and describe some of their properties. Sufficient conditions for global convergence of DRS involving the sum of two semimonotone operators are provided. Notably, it is shown that DRS converges even when the sum of the involved operators (or of their inverses) is nonmonotone. Various example problems are provided, demonstrating the tightness of our convergence results and highlighting the wide range of applications our theory is able to cover.</description>
      <guid isPermaLink="false">oai:arXiv.org:2305.03605v2</guid>
      <category>math.OC</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Brecht Evens, Pieter Pas, Puya Latafat, Panagiotis Patrinos</dc:creator>
    </item>
    <item>
      <title>Homogeneous Second-Order Descent Framework: A Fast Alternative to Newton-Type Methods</title>
      <link>https://arxiv.org/abs/2306.17516</link>
      <description>arXiv:2306.17516v3 Announce Type: replace 
Abstract: This paper proposes a homogeneous second-order descent framework (HSODF) for nonconvex and convex optimization based on the generalized homogeneous model (GHM). In comparison to the Newton steps, the GHM can be solved by extremal symmetric eigenvalue procedures and thus grant an advantage in ill-conditioned problems. Moreover, GHM extends the ordinary homogeneous model (OHM) (Zhang et al. 2022) to allow adaptiveness in the construction of the aggregated matrix. Consequently, HSODF is able to recover some well-known second-order methods, such as trust-region methods and gradient regularized methods, while maintaining comparable iteration complexity bounds. We also study two specific realizations of HSODF. One is adaptive HSODM, which has a parameter-free $O(\epsilon^{-3/2})$ global complexity bound for nonconvex second-order Lipschitz continuous objective functions. The other one is homotopy HSODM, which is proven to have a global linear rate of convergence without strong convexity. The efficiency of our approach to ill-conditioned and high-dimensional problems is justified by some preliminary numerical results.</description>
      <guid isPermaLink="false">oai:arXiv.org:2306.17516v3</guid>
      <category>math.OC</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Chang He, Yuntian Jiang, Chuwen Zhang, Dongdong Ge, Bo Jiang, Yinyu Ye</dc:creator>
    </item>
    <item>
      <title>Finite Elements with Switch Detection for Numerical Optimal Control of Nonsmooth Dynamical Systems with Set-Valued Heaviside Step Functions</title>
      <link>https://arxiv.org/abs/2307.03482</link>
      <description>arXiv:2307.03482v2 Announce Type: replace 
Abstract: This paper develops high-accuracy methods for numerically solving optimal control problems subject to nonsmooth differential equations with set-valued step functions. A notable subclass of these systems are Filippov systems. The set-valued step functions are here written as the solution map of a linear program. Using the optimality conditions of this problem we rewrite the initial nonsmooth system into a equivalent dynamic complementarity systems (DCS). We extend the Finite Elements with Switch Detection (FESD) method [Nurkanovi\'c et al., 2024], initially developed for Filippov systems transformed via Stewart's reformulation into DCS [Stewart, 1990], to the class of nonsmooth systems with set-valued step functions. The key ideas are to start with a standard Runge-Kutta method for the obtained DCS and to let the integration step sizes to be degrees of freedom. Next, we introduce additional conditions to enable implicit but exact switch detection and to remove possible spurious degrees of freedom if no switches occur. The theoretical properties of the method are studied. Its favorable properties are illustrated on numerical simulation and optimal control examples. All methods introduced in this paper are implemented in the open-source software package NOSNOC.</description>
      <guid isPermaLink="false">oai:arXiv.org:2307.03482v2</guid>
      <category>math.OC</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Armin Nurkanovi\'c, Anton Pozharskiy, Jonathan Frey, Moritz Diehl</dc:creator>
    </item>
    <item>
      <title>Bounding the Difference between the Values of Robust and Non-Robust Markov Decision Problems</title>
      <link>https://arxiv.org/abs/2308.05520</link>
      <description>arXiv:2308.05520v2 Announce Type: replace 
Abstract: In this note we provide an upper bound for the difference between the value function of a distributionally robust Markov decision problem and the value function of a non-robust Markov decision problem, where the ambiguity set of probability kernels of the distributionally robust Markov decision process is described by a Wasserstein-ball around some reference kernel whereas the non-robust Markov decision process behaves according to a fixed probability kernel contained in the ambiguity set. Our derived upper bound for the difference between the value functions is dimension-free and depends linearly on the radius of the Wasserstein-ball.</description>
      <guid isPermaLink="false">oai:arXiv.org:2308.05520v2</guid>
      <category>math.OC</category>
      <category>math.PR</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Ariel Neufeld, Julian Sester</dc:creator>
    </item>
    <item>
      <title>Rectangularity and duality of distributionally robust Markov Decision Processes</title>
      <link>https://arxiv.org/abs/2308.11139</link>
      <description>arXiv:2308.11139v5 Announce Type: replace 
Abstract: The main goal of this paper is to discuss several approaches to formulation of distributionally robust counterparts of Markov Decision Processes, where the transition kernels are not specified exactly but rather are assumed to be elements of the corresponding ambiguity sets. The intent is to clarify some connections between the game and static formulations of distributionally robust MDPs, and delineate the role of rectangularity associated with ambiguity sets in determining these connections.</description>
      <guid isPermaLink="false">oai:arXiv.org:2308.11139v5</guid>
      <category>math.OC</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <dc:creator>Yan Li, Alexander Shapiro</dc:creator>
    </item>
    <item>
      <title>Mean-field games of speedy information access with observation costs</title>
      <link>https://arxiv.org/abs/2309.07877</link>
      <description>arXiv:2309.07877v2 Announce Type: replace 
Abstract: We investigate mean-field games (MFG) in which agents can actively control their speed of access to information. Specifically, the agents can dynamically decide to obtain observations with reduced delay by accepting higher observation costs. Agents seek to exploit their active information acquisition by making further decisions to influence their state dynamics so as to maximise rewards. In a mean-field equilibrium, each generic agent solves individually a partially observed Markov decision problem in which the way partial observations are obtained is itself subject to dynamic control actions, while no agent can improve unilaterally given the actions of all others. Based on a finite characterisation of belief states, we show how the mean-field game with controlled costly information access can be formulated as an equivalent standard mean-field game on an augmented but finite state space. With sufficient entropy regularisation, a fixed point iteration converges to the unique MFG equilibrium. Moreover, we derive an approximate $\varepsilon$-Nash equilibrium for a large but finite population size and small regularisation parameter. We illustrate our (extended) MFG of information access and of controls by an example from epidemiology, where medical testing results can be procured at different speeds and costs.</description>
      <guid isPermaLink="false">oai:arXiv.org:2309.07877v2</guid>
      <category>math.OC</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Dirk Becherer, Christoph Reisinger, Jonathan Tam</dc:creator>
    </item>
    <item>
      <title>Beyond Stationarity: Convergence Analysis of Stochastic Softmax Policy Gradient Methods</title>
      <link>https://arxiv.org/abs/2310.02671</link>
      <description>arXiv:2310.02671v2 Announce Type: replace 
Abstract: Markov Decision Processes (MDPs) are a formal framework for modeling and solving sequential decision-making problems. In finite-time horizons such problems are relevant for instance for optimal stopping or specific supply chain problems, but also in the training of large language models. In contrast to infinite horizon MDPs optimal policies are not stationary, policies must be learned for every single epoch. In practice all parameters are often trained simultaneously, ignoring the inherent structure suggested by dynamic programming. This paper introduces a combination of dynamic programming and policy gradient called dynamic policy gradient, where the parameters are trained backwards in time. For the tabular softmax parametrisation we carry out the convergence analysis for simultaneous and dynamic policy gradient towards global optima, both in the exact and sampled gradient settings without regularisation. It turns out that the use of dynamic policy gradient training much better exploits the structure of finite- time problems which is reflected in improved convergence bounds.</description>
      <guid isPermaLink="false">oai:arXiv.org:2310.02671v2</guid>
      <category>math.OC</category>
      <category>cs.LG</category>
      <category>stat.ML</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-sa/4.0/</dc:rights>
      <dc:creator>Sara Klein, Simon Weissmann, Leif D\"oring</dc:creator>
    </item>
    <item>
      <title>Deep Policy Iteration for High-Dimensional Mean Field Games</title>
      <link>https://arxiv.org/abs/2310.10827</link>
      <description>arXiv:2310.10827v3 Announce Type: replace 
Abstract: This paper presents Deep Policy Iteration (DPI), a novel approach that integrates the power of Neural Networks with the stability and convergence advantages of the Policy Iteration (PI). DPI is specifically designed to address the computational complexities arising in high-dimensional stochastic Mean Field Games (MFG). Utilizing three neural networks trained iteratively, DPI adeptly approximates MFG solutions by solving PI equations and satisfying forward-backwards conditions. In contrast to PI, which is limited to low-dimensional problems due to the curse of dimensionality, DPI significantly expands the possibilities of PI, allowing it to be applied in high-dimensional cases for both separable and non-separable Hamiltonian. We illustrate the performance of our proposed approach with numerical examples.</description>
      <guid isPermaLink="false">oai:arXiv.org:2310.10827v3</guid>
      <category>math.OC</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Mouhcine Assouli, Badr Missaoui</dc:creator>
    </item>
    <item>
      <title>Solving mathematical programs with complementarity constraints arising in nonsmooth optimal control</title>
      <link>https://arxiv.org/abs/2312.11022</link>
      <description>arXiv:2312.11022v2 Announce Type: replace 
Abstract: This paper examines solution methods for mathematical programs with complementarity constraints (MPCC) obtained from the time-discretization of optimal control problems (OCPs) subject to nonsmooth dynamical systems. The MPCC theory and stationarity concepts are reviewed and summarized. The focus is on relaxation-based methods for MPCCs, which solve a (finite) sequence of more regular nonlinear programs (NLP), where a regularization/homotopy parameter is driven to zero. Such methods perform reasonably well on currently available benchmarks. However, these results do not always generalize to MPCCs obtained from nonsmooth OCPs. To provide a more complete picture, this paper introduces a novel benchmark collection of such problems, which we call nosbench. The problem set includes 603 different MPCCs and we split it into a few representative subsets to accelerate the testing. We compare different relaxation-based methods, NLP solvers, homotopy parameter update and relaxation parameter steering strategies. Moreover, we check whether the obtained stationary points allow first-order descent directions, which may be the case for some of the weaker MPCC stationarity concepts. In the best case, the Scholtes' relaxation [Scholtes, 2002] with IPOPT [W\"achter and Biegler, 2006] as NLP solver manages to solve 73.8 % of the problems. This highlights the need for further improvements in algorithms and software for MPCCs.</description>
      <guid isPermaLink="false">oai:arXiv.org:2312.11022v2</guid>
      <category>math.OC</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Armin Nurkanovi\'c, Anton Pozharskiy, Moritz Diehl</dc:creator>
    </item>
    <item>
      <title>On the convergence of Block Majorization-Minimization algorithms on the Grassmann Manifold</title>
      <link>https://arxiv.org/abs/2402.09907</link>
      <description>arXiv:2402.09907v2 Announce Type: replace 
Abstract: The Majorization-Minimization (MM) framework is widely used to derive efficient algorithms for specific problems that require the optimization of a cost function (which can be convex or not). It is based on a sequential optimization of a surrogate function over closed convex sets. A natural extension of this framework incorporates ideas of Block Coordinate Descent (BCD) algorithms into the MM framework, also known as block MM. The rationale behind the block extension is to partition the optimization variables into several independent blocks, to obtain a surrogate for each block, and to optimize the surrogate of each block cyclically. The advantage of the block MM is that the construction and successive optimization of the surrogate functions is potentially easier than with the non-block alternative. The purpose of this letter is to exploit the geometrical properties of the Grassmann manifold (a non-convex set) for the purpose of extending classical convergence proofs of the block MM when at least one of the blocks is constrained in this manifold.</description>
      <guid isPermaLink="false">oai:arXiv.org:2402.09907v2</guid>
      <category>math.OC</category>
      <category>eess.SP</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-sa/4.0/</dc:rights>
      <arxiv:journal_reference>10.1109/LSP.2024.3396660</arxiv:journal_reference>
      <dc:creator>Carlos Alejandro Lopez, Jaume Riba</dc:creator>
    </item>
    <item>
      <title>A robust optimization approach model for a multi-vaccine multi-echelon supply chain</title>
      <link>https://arxiv.org/abs/2403.16173</link>
      <description>arXiv:2403.16173v4 Announce Type: replace 
Abstract: This research investigates a multi-product, multi-echelon, and multi-period vaccine supply chain network model under uncertainty and quality inspection errors. The objective function seeks optimizing the total cost of the supply chain. Moreover, the proposed model is formulated as a mixed integer linear programming problem under multiple sources of uncertain parameters including demand, inspection errors, vaccine waste generated in healthcare centers, and defective treatment rate of vaccine waste. To provide meaningful solutions that are robust against future fluctuation of parameters, the robust optimization approach is utilized to incorporate the decision maker risk attitude under different type of uncertainty sets. Namely, box, polyhedral and combination of interval polyhedral. The performance of the proposed model is demonstrated through an illustrative example. The results show the effect of different types of uncertainties on the overall objective function. Managerial insights and research implications in terms of vaccine supply chain is advised and future research directions are proposed.</description>
      <guid isPermaLink="false">oai:arXiv.org:2403.16173v4</guid>
      <category>math.OC</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <dc:creator>Bouchenine Abderrahmen, Almaraj Ismail</dc:creator>
    </item>
    <item>
      <title>Technical Report: Pose Graph Optimization over Planar Unit Dual Quaternions: Improved Accuracy with Provably Convergent Riemannian Optimization</title>
      <link>https://arxiv.org/abs/2404.00010</link>
      <description>arXiv:2404.00010v2 Announce Type: replace 
Abstract: It is common in pose graph optimization (PGO) algorithms to assume that noise in the translations and rotations of relative pose measurements is uncorrelated. However, existing work shows that in practice these measurements can be highly correlated, which leads to degradation in the accuracy of PGO solutions that rely on this assumption. Therefore, in this paper we develop a novel algorithm derived from a realistic, correlated model of relative pose uncertainty, and we quantify the resulting improvement in the accuracy of the solutions we obtain relative to state-of-the-art PGO algorithms. Our approach utilizes Riemannian optimization on the planar unit dual quaternion (PUDQ) manifold, and we prove that it converges to first-order stationary points of a Lie-theoretic maximum likelihood objective. Then we show experimentally that, compared to state-of-the-art PGO algorithms, this algorithm produces estimation errors that are lower by 10% to 25% across several orders of magnitude of noise levels and graph sizes.</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.00010v2</guid>
      <category>math.OC</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>William D. Warke, J. Humberto Ramos, Prashant Ganesh, Kevin M. Brink, Matthew T. Hale</dc:creator>
    </item>
    <item>
      <title>A Scoping Review on Simulation-based Design Optimization in Marine Engineering: Trends, Best Practices, and Gaps</title>
      <link>https://arxiv.org/abs/2404.18654</link>
      <description>arXiv:2404.18654v2 Announce Type: replace 
Abstract: This scoping review assesses the current use of simulation-based design optimization (SBDO) in marine engineering, focusing on identifying research trends, methodologies, and application areas. Analyzing 277 studies from Scopus and Web of Science, the review finds that SBDO is predominantly applied to optimizing marine vessel hulls, including both surface and underwater types, and extends to key components like bows, sterns, propellers, and fins. It also covers marine structures and renewable energy systems. A notable trend is the preference for deterministic single-objective optimization methods, indicating potential growth areas in multi-objective and stochastic approaches. The review points out the necessity of integrating more comprehensive multidisciplinary optimization methods to address the complex challenges in marine environments. Despite the extensive application of SBDO in marine engineering, there remains a need for enhancing the methodologies' efficiency and robustness. This review offers a critical overview of SBDO's role in marine engineering and highlights opportunities for future research to advance the field.</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.18654v2</guid>
      <category>math.OC</category>
      <category>cs.CE</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <arxiv:DOI>10.1007/s11831-024-10127-1</arxiv:DOI>
      <dc:creator>Andrea Serani, Thomas Scholcz, Valentina Vanzi</dc:creator>
    </item>
    <item>
      <title>Accelerated Fully First-Order Methods for Bilevel and Minimax Optimization</title>
      <link>https://arxiv.org/abs/2405.00914</link>
      <description>arXiv:2405.00914v2 Announce Type: replace 
Abstract: This paper presents a new algorithm member for accelerating first-order methods for bilevel optimization, namely the \emph{(Perturbed) Restarted Accelerated Fully First-order methods for Bilevel Approximation}, abbreviated as \texttt{(P)RAF${}^2$BA}. The algorithm leverages \emph{fully} first-order oracles and seeks approximate stationary points in nonconvex-strongly-convex bilevel optimization, enhancing oracle complexity for efficient optimization. Theoretical guarantees for finding approximate first-order stationary points and second-order stationary points at the state-of-the-art query complexities are established, showcasing their effectiveness in solving complex optimization tasks. Empirical studies for real-world problems are provided to further validate the outperformance of our proposed algorithms. The significance of \texttt{(P)RAF${}^2$BA} in optimizing nonconvex-strongly-convex bilevel optimization problems is underscored by its state-of-the-art convergence rates and computational efficiency.</description>
      <guid isPermaLink="false">oai:arXiv.org:2405.00914v2</guid>
      <category>math.OC</category>
      <category>cs.LG</category>
      <category>stat.ML</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Chris Junchi Li</dc:creator>
    </item>
    <item>
      <title>QuACK: Accelerating Gradient-Based Quantum Optimization with Koopman Operator Learning</title>
      <link>https://arxiv.org/abs/2211.01365</link>
      <description>arXiv:2211.01365v3 Announce Type: replace-cross 
Abstract: Quantum optimization, a key application of quantum computing, has traditionally been stymied by the linearly increasing complexity of gradient calculations with an increasing number of parameters. This work bridges the gap between Koopman operator theory, which has found utility in applications because it allows for a linear representation of nonlinear dynamical systems, and natural gradient methods in quantum optimization, leading to a significant acceleration of gradient-based quantum optimization. We present Quantum-circuit Alternating Controlled Koopman learning (QuACK), a novel framework that leverages an alternating algorithm for efficient prediction of gradient dynamics on quantum computers. We demonstrate QuACK's remarkable ability to accelerate gradient-based optimization across a range of applications in quantum optimization and machine learning. In fact, our empirical studies, spanning quantum chemistry, quantum condensed matter, quantum machine learning, and noisy environments, have shown accelerations of more than 200x speedup in the overparameterized regime, 10x speedup in the smooth regime, and 3x speedup in the non-smooth regime. With QuACK, we offer a robust advancement that harnesses the advantage of gradient-based quantum optimization for practical benefits.</description>
      <guid isPermaLink="false">oai:arXiv.org:2211.01365v3</guid>
      <category>quant-ph</category>
      <category>cs.AI</category>
      <category>cs.LG</category>
      <category>math.OC</category>
      <category>physics.comp-ph</category>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Di Luo, Jiayu Shen, Rumen Dangovski, Marin Solja\v{c}i\'c</dc:creator>
    </item>
    <item>
      <title>Infection-induced Cascading Failures -- Impact and Mitigation</title>
      <link>https://arxiv.org/abs/2307.16767</link>
      <description>arXiv:2307.16767v4 Announce Type: replace-cross 
Abstract: In the context of epidemic spreading, many intricate dynamical patterns can emerge due to the cooperation of different types of pathogens or the interaction between the disease spread and other failure propagation mechanism. To unravel such patterns, simulation frameworks are usually adopted, but they are computationally demanding on big networks and subject to large statistical uncertainty. Here, we study the two-layer spreading processes on unidirectionally dependent networks, where the spreading infection of diseases or malware in one layer can trigger cascading failures in another layer and lead to secondary disasters, e.g., disrupting public services, supply chains, or power distribution. We utilize a dynamic message-passing method to devise efficient algorithms for inferring the system states, which allows one to investigate systematically the nature of complex intertwined spreading processes and evaluate their impact. Based on such dynamic message-passing framework and optimal control, we further develop an effective optimization algorithm for mitigating network failures.</description>
      <guid isPermaLink="false">oai:arXiv.org:2307.16767v4</guid>
      <category>physics.soc-ph</category>
      <category>cond-mat.dis-nn</category>
      <category>math.OC</category>
      <category>q-bio.PE</category>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <arxiv:DOI>10.1038/s42005-024-01638-1</arxiv:DOI>
      <arxiv:journal_reference>Communications Physics 7, 144 (2024)</arxiv:journal_reference>
      <dc:creator>Bo Li, David Saad</dc:creator>
    </item>
    <item>
      <title>Reinforcement Learning for Near-Optimal Design of Zero-Delay Codes for Markov Sources</title>
      <link>https://arxiv.org/abs/2311.12609</link>
      <description>arXiv:2311.12609v3 Announce Type: replace-cross 
Abstract: In the classical lossy source coding problem, one encodes long blocks of source symbols that enables the distortion to approach the ultimate Shannon limit. Such a block-coding approach introduces large delays, which is undesirable in many delay-sensitive applications. We consider the zero-delay case, where the goal is to encode and decode a finite-alphabet Markov source without any delay. It has been shown that this problem lends itself to stochastic control techniques, which lead to existence, structural, and general structural approximation results. However, these techniques so far have resulted only in computationally prohibitive algorithmic implementations for code design. To address this problem, we present a reinforcement learning design algorithm and rigorously prove its asymptotic optimality. In particular, we show that a quantized Q-learning algorithm can be used to obtain a near-optimal coding policy for this problem. The proof builds on recent results on quantized Q-learning for weakly Feller controlled Markov chains whose application necessitates the development of supporting technical results on regularity and stability properties, and relating the optimal solutions for discounted and average cost infinite horizon criteria problems. These theoretical results are supported by simulations.</description>
      <guid isPermaLink="false">oai:arXiv.org:2311.12609v3</guid>
      <category>cs.IT</category>
      <category>math.IT</category>
      <category>math.OC</category>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-sa/4.0/</dc:rights>
      <dc:creator>Liam Cregg, Tamas Linder, Serdar Yuksel</dc:creator>
    </item>
    <item>
      <title>A study on various generalizations of Generalized centers $\bm{(GC)}$ in Banach spaces</title>
      <link>https://arxiv.org/abs/2311.15818</link>
      <description>arXiv:2311.15818v2 Announce Type: replace-cross 
Abstract: In [{\em Generalized centers of finite sets in Banach spaces}, Acta Math. Univ. Comenian. (N.S.) {\bf 66}(1) (1997), 83--115], Vesel\'{y} developed the idea of generalized centers for finite sets in Banach spaces. In this work, we explore the concept of {\it restricted $\mr{F}$-center property} for a triplet $(X,Y,\mc{F}(X))$, where $Y$ is a subspace of a Banach space $X$ and $\mc{F}(X)$ is the family of finite subsets of $X$. In addition, we generalize the analysis to include all closed, bounded subsets of $X$. Similar to how Lindenstrauss characterized $n.2.I.P.$, we characterize $n.X.I.P.$. So, it is possible to figure out that $Y$ has $n.X.I.P.$ in $X$ for all natural numbers $n$ if and only if $\tr{rad}_Y(F)=\tr{rad}_X(F)$ for all finite subsets $F$ of $Y$. It then turns out that, for all continuous, monotone functions $f$, the $f$-radii viz. $\tr{rad}_Y^f(F),\tr{rad}_X^f(F)$ are same whenever the generalized radii viz. $\tr{rad}_Y(F), \tr{rad}_X(F)$ are also same, for all finite subsets $F$ of $Y$. We establish a variety of characterizations of central subspaces of Banach spaces. With reference to an appropriate subfamily of closed and bounded subsets, it appears that a number of function spaces and subspaces exhibit the restricted weighted Chebyshev center property.</description>
      <guid isPermaLink="false">oai:arXiv.org:2311.15818v2</guid>
      <category>math.FA</category>
      <category>math.OC</category>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Syamantak Das, Tanmoy Paul</dc:creator>
    </item>
    <item>
      <title>A Survey on Optimization Studies of Group Centrality Metrics</title>
      <link>https://arxiv.org/abs/2401.05235</link>
      <description>arXiv:2401.05235v3 Announce Type: replace-cross 
Abstract: Centrality metrics have become a popular concept in network science and optimization. Over the years, centrality has been used to assign importance and identify influential elements in various settings, including transportation, infrastructure, biological, and social networks, among others. That said, most of the literature has focused on nodal versions of centrality. Recently, group counterparts of centrality have started attracting scientific and practitioner interest. The identification of sets of nodes that are influential within a network is becoming increasingly more important. This is even more pronounced when these sets of nodes are required to induce a certain motif or structure. In this study, we review group centrality metrics from an operations research and optimization perspective for the first time. This is particularly interesting due to the rapid evolution and development of this area in the operations research community over the last decade. We first present a historical overview of how we have reached this point in the study of group centrality. We then discuss the different structures and motifs that appear prominently in the literature, alongside the techniques and methodologies that are popular. We finally present possible avenues and directions for future work, mainly in three areas: (i) probabilistic metrics to account for randomness along with stochastic optimization techniques; (ii) structures and relaxations that have not been yet studied; and (iii) new emerging applications that can take advantage of group centrality. Our survey offers a concise review of group centrality and its intersection with network analysis and optimization.</description>
      <guid isPermaLink="false">oai:arXiv.org:2401.05235v3</guid>
      <category>cs.SI</category>
      <category>math.OC</category>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Mustafa Can Camur, Chrysafis Vogiatzis</dc:creator>
    </item>
    <item>
      <title>Centrality of shortest paths: Algorithms and complexity results</title>
      <link>https://arxiv.org/abs/2401.08019</link>
      <description>arXiv:2401.08019v3 Announce Type: replace-cross 
Abstract: The degree centrality of a node, defined as the number of nodes adjacent to it, is often used as a measure of importance of a node to the structure of a network. This metric can be extended to paths in a network, where the degree centrality of a path is defined as the number of nodes adjacent to it. In this paper, we reconsider the problem of finding the most degree-central shortest path in an unweighted network. We propose a polynomial algorithm with the worst-case running time of $O(|E||V|^2\Delta(G))$, where $|V|$ is the number of vertices in the network, $|E|$ is the number of edges in the network, and $\Delta(G)$ is the maximum degree of the graph. We conduct a numerical study of our algorithm on synthetic and real-world networks and compare our results to the existing literature. In addition, we show that the same problem is NP-hard when a weighted graph is considered. Furthermore, we consider other centrality measures, such as the betweenness and closeness centrality, showing that the problem of finding the most betweenness-central shortest path is solvable in polynomial time and finding the most closeness-central shortest path is NP-hard, regardless of whether the graph is weighted or not.</description>
      <guid isPermaLink="false">oai:arXiv.org:2401.08019v3</guid>
      <category>cs.DS</category>
      <category>cs.CC</category>
      <category>math.OC</category>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Johnson Phosavanh, Dmytro Matsypura</dc:creator>
    </item>
    <item>
      <title>Epsilon-Greedy Thompson Sampling to Bayesian Optimization</title>
      <link>https://arxiv.org/abs/2403.00540</link>
      <description>arXiv:2403.00540v2 Announce Type: replace-cross 
Abstract: Bayesian optimization (BO) has become a powerful tool for solving simulation-based engineering optimization problems thanks to its ability to integrate physical and mathematical understandings, consider uncertainty, and address the exploitation--exploration dilemma. Thompson sampling (TS) is a preferred solution for BO to handle the exploitation--exploration trade-off. While it prioritizes exploration by generating and minimizing random sample paths from probabilistic models -- a fundamental ingredient of BO -- TS weakly manages exploitation by gathering information about the true objective function after it obtains new observations. In this work, we improve the exploitation of TS by incorporating the $\varepsilon$-greedy policy, a well-established selection strategy in reinforcement learning. We first delineate two extremes of TS, namely the generic TS and the sample-average TS. The former promotes exploration, while the latter favors exploitation. We then adopt the $\varepsilon$-greedy policy to randomly switch between these two extremes. Small and large values of $\varepsilon$ govern exploitation and exploration, respectively. By minimizing two benchmark functions and solving an inverse problem of a steel cantilever beam,we empirically show that $\varepsilon$-greedy TS equipped with an appropriate $\varepsilon$ is more robust than its two extremes,matching or outperforming the better of the generic TS and the sample-average TS.</description>
      <guid isPermaLink="false">oai:arXiv.org:2403.00540v2</guid>
      <category>cs.LG</category>
      <category>math.OC</category>
      <category>stat.ML</category>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Bach Do, Taiwo Adebiyi, Ruda Zhang</dc:creator>
    </item>
    <item>
      <title>Early years of Biased Random-Key Genetic Algorithms: A systematic review</title>
      <link>https://arxiv.org/abs/2405.01765</link>
      <description>arXiv:2405.01765v2 Announce Type: replace-cross 
Abstract: This paper presents a systematic literature review and bibliometric analysis focusing on Biased Random-Key Genetic Algorithms (BRKGA). BRKGA is a metaheuristic framework that uses random-key-based chromosomes with biased, uniform, and elitist mating strategies alongside a genetic algorithm. This review encompasses around~250 papers, covering a diverse array of applications ranging from classical combinatorial optimization problems to real-world industrial scenarios, and even non-traditional applications like hyperparameter tuning in machine learning and scenario generation for two-stage problems. In summary, this study offers a comprehensive examination of the BRKGA metaheuristic and its various applications, shedding light on key areas for future research.</description>
      <guid isPermaLink="false">oai:arXiv.org:2405.01765v2</guid>
      <category>cs.NE</category>
      <category>math.OC</category>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Mariana A. Londe, Luciana S. Pessoa, Cartlos E. Andrade, Mauricio G. C. Resende</dc:creator>
    </item>
  </channel>
</rss>
