<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>cs.FL updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/cs.FL</link>
    <description>cs.FL updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/cs.FL" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Thu, 08 Aug 2024 01:31:33 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Wed, 07 Aug 2024 00:00:00 -0400</pubDate>
    <skipDays>
      <day>Saturday</day>
      <day>Sunday</day>
    </skipDays>
    <item>
      <title>LLMs as Probabilistic Minimally Adequate Teachers for DFA Learning</title>
      <link>https://arxiv.org/abs/2408.02999</link>
      <description>arXiv:2408.02999v1 Announce Type: new 
Abstract: The emergence of intelligence in large language models (LLMs) has inspired investigations into their integration into automata learning. This paper introduces the probabilistic Minimally Adequate Teacher (pMAT) formulation, which leverages a probabilistic oracle that could give persistent errors randomly during answering the membership queries for deterministic finite automata (DFA) learning. Given the tendency of LLMs to produce hallucinatory content, we have developed techniques to improve answer accuracy and ensure the correctness of the learned automata. We propose the $\mathtt{Discrimination}$ prompt as well as the $\mathtt{Verification}$ prompt and explore their advantages over common prompts. Additionally, we compare DFA learning performance between the TTT algorithm and common active learning algorithms. To address the exponential number of persistent errors, we implement a dynamic query cache refinement algorithm that identifies and corrects conflicting queries by combining the active and passive learning algorithms. The empirical results demonstrate the robustness and efficiency of our approach, providing a theoretical foundation for automata learning with LLMs in the loop.</description>
      <guid isPermaLink="false">oai:arXiv.org:2408.02999v1</guid>
      <category>cs.FL</category>
      <category>cs.AI</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <dc:creator>Lekai Chen, Ashutosh Trivedi, Alvaro Velasquez</dc:creator>
    </item>
    <item>
      <title>Quantum automata and languages of finite index</title>
      <link>https://arxiv.org/abs/2406.13797</link>
      <description>arXiv:2406.13797v2 Announce Type: replace 
Abstract: This paper is a continuation of a previous study on the so-called measure once finite quantum automata model introduced by Moore and Crutchfield in 2000. We investigate conditions assuring that, given a language recognized by such a device and a language generated by a context-free grammar of finite index or by a matrix context-free grammar, it is recursively decidable whether or not they have a nonempty intersection.</description>
      <guid isPermaLink="false">oai:arXiv.org:2406.13797v2</guid>
      <category>cs.FL</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Andrea Benso, Flavio D'Alessandro, Paolo Papi</dc:creator>
    </item>
    <item>
      <title>Regular Grammars for Graph Sets of Tree-Width $\leq2$</title>
      <link>https://arxiv.org/abs/2408.01226</link>
      <description>arXiv:2408.01226v2 Announce Type: replace 
Abstract: Regular and context-free languages form a central pillar of formal language theory. This is because a variety of formalisms are known that define these classes of languages. For example, we have that finite automata, monoids, algebraic recognizability, regular expressions, regular grammars, monadic-second order logic, etc., can be used to represent regular word languages. However, the situation is less clear for formal languages over graphs, and open problems persist. This is because generalizing notions from words to graphs has been more successful for some of the cited formalisms than for the other ones. Bruno Courcelle has introduced hyper-edge replacement (\hr) algebras for generalizing the notion of context-free languages from words to graphs. At the same time, \hr-algebras support the generalization of algebraic recognizability from words to graphs, a notion that has been proven to be equivalent to definability in (counting) monadic-second order logic (\cmso) over graphs of bounded tree-width. In this paper, we deal with generalizing regular word grammars to graphs. We propose regular grammars for (unordered and unranked) trees, series-parallel graphs, and graphs of tree-width $\le 2$, where the qualifier regular is justified because these grammars define exactly the recognizable resp. \cmso-definable subsets of the respective graph classes.</description>
      <guid isPermaLink="false">oai:arXiv.org:2408.01226v2</guid>
      <category>cs.FL</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Marius Bozga, Radu Iosif, Florian Zuleger</dc:creator>
    </item>
    <item>
      <title>On shortest products for nonnegative matrix mortality</title>
      <link>https://arxiv.org/abs/2405.19622</link>
      <description>arXiv:2405.19622v2 Announce Type: replace-cross 
Abstract: Given a finite set of matrices with integer entries, the matrix mortality problem asks if there exists a product of these matrices equal to the zero matrix. We consider a special case of this problem where all entries of the matrices are nonnegative. This case is equivalent to the NFA mortality problem, which, given an NFA, asks for a word $w$ such that the image of every state under $w$ is the empty set. The size of the alphabet of the NFA is then equal to the number of matrices in the set. We study the length of shortest such words depending on the size of the alphabet. We show that for an NFA with $n$ states this length can be at least $2^n - 1$ for an alphabet of size $n$, $2^{(n - 4)/2}$ for an alphabet of size $3$ and $2^{(n - 2)/3}$ for an alphabet of size $2$. We also discuss further open problems related to mortality of NFAs and DFAs.</description>
      <guid isPermaLink="false">oai:arXiv.org:2405.19622v2</guid>
      <category>cs.DM</category>
      <category>cs.FL</category>
      <category>math.CO</category>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Andrew Ryzhikov</dc:creator>
    </item>
  </channel>
</rss>
