<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>stat.ME updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/stat.ME</link>
    <description>stat.ME updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/stat.ME" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Thu, 16 Jan 2025 05:00:08 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Thu, 16 Jan 2025 00:00:00 -0500</pubDate>
    <skipDays>
      <day>Saturday</day>
      <day>Sunday</day>
    </skipDays>
    <item>
      <title>A Comparative Evaluation of Bayesian Model-Assisted Two-Stage Designs for Phase I/II Clinical Trials</title>
      <link>https://arxiv.org/abs/2501.08410</link>
      <description>arXiv:2501.08410v1 Announce Type: new 
Abstract: The primary goal of a two-stage Phase I/II trial is to identify the optimal dose for the following large-scale Phase III trial. Recently, Phase I dose-finding designs have shifted from identifying the maximum tolerated dose (MTD) to the optimal biological dose (OBD). Typically, several doses are selected as recommended Phase II doses (RP2D) for further evaluation. In Phase II dose optimization trials, each RP2D is evaluated independently to determine its "go/no-go" decision. The optimal RP2D is then chosen from the remaining RP2Ds as the recommended Phase III dose (RP3D). The effectiveness of both dose-finding and dose optimization designs at two stages impacts RP3D selection. This paper reviews and compares fifteen Bayesian model-assisted two-stage designs, combining five Phase I dose-finding designs (BOIN, TITE-BOIN, BF-BOIN, BOIN12, and TITE-BOIN12) with three Phase II dose optimization designs (TS, BOP2, and TOP). We conduct extensive simulation studies to evaluate their performance under different dose-response scenarios, with and without the existence of the OBD. Based on our results, we recommend the TITE-BOIN12 + TOP combination as the optimal two-stage design for Phase I/II trials.</description>
      <guid isPermaLink="false">oai:arXiv.org:2501.08410v1</guid>
      <category>stat.ME</category>
      <pubDate>Thu, 16 Jan 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Hao Sun, Jerry Li</dc:creator>
    </item>
    <item>
      <title>A note on the construction of augmented designs in square arrays</title>
      <link>https://arxiv.org/abs/2501.08448</link>
      <description>arXiv:2501.08448v1 Announce Type: new 
Abstract: An augmented design in a square array can be derived from a smaller row-column design (the contraction). Such a contraction has also previously been used to generate a two-replicate resolvable incomplete block design. We demonstrate a parallel between these two uses of the contraction and thereby establish a recently proposed conjecture by linking the average efficiency factor of the augmented design with that of its contraction.</description>
      <guid isPermaLink="false">oai:arXiv.org:2501.08448v1</guid>
      <category>stat.ME</category>
      <pubDate>Thu, 16 Jan 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>E. R. Williams, H-P. Piepho</dc:creator>
    </item>
    <item>
      <title>Convergence guarantees for response prediction for latent structure network time series</title>
      <link>https://arxiv.org/abs/2501.08456</link>
      <description>arXiv:2501.08456v1 Announce Type: new 
Abstract: In this article, we propose a technique to predict the response associated with an unlabeled time series of networks in a semisupervised setting. Our model involves a collection of time series of random networks of growing size, where some of the time series are associated with responses. Assuming that the collection of time series admits an unknown lower dimensional structure, our method exploits the underlying structure to consistently predict responses at the unlabeled time series of networks. Each time series represents a multilayer network on a common set of nodes, and raw stress embedding, a popular dimensionality reduction tool, is used for capturing the unknown latent low dimensional structure. Apart from establishing theoretical convergence guarantees and supporting them with numerical results, we demonstrate the use of our method in the analysis of real-world biological learning circuits of larval Drosophila.</description>
      <guid isPermaLink="false">oai:arXiv.org:2501.08456v1</guid>
      <category>stat.ME</category>
      <pubDate>Thu, 16 Jan 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Aranyak Acharyya, Francesco Sanna Passino, Michael W. Trosset, Carey E. Priebe</dc:creator>
    </item>
    <item>
      <title>Simultaneous Estimation of Multiple Treatment Effects from Observational Studies</title>
      <link>https://arxiv.org/abs/2501.08467</link>
      <description>arXiv:2501.08467v1 Announce Type: new 
Abstract: Unmeasured confounding presents a significant challenge in causal inference from observational studies. Classical approaches often rely on collecting proxy variables, such as instrumental variables. However, in applications where the effects of multiple treatments are of simultaneous interest, finding a sufficient number of proxy variables for consistent estimation of treatment effects can be challenging. Various methods in the literature exploit the structure of multiple treatments to address unmeasured confounding. In this paper, we introduce a novel approach to causal inference with multiple treatments, assuming sparsity in the causal effects. Our procedure autonomously selects treatments with non-zero causal effects, thereby providing a sparse causal estimation. Comprehensive evaluations using both simulated and Genome-Wide Association Study (GWAS) datasets demonstrate the effectiveness and robustness of our method compared to alternative approaches.</description>
      <guid isPermaLink="false">oai:arXiv.org:2501.08467v1</guid>
      <category>stat.ME</category>
      <pubDate>Thu, 16 Jan 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <arxiv:DOI>10.1080/10618600.2024.2449074</arxiv:DOI>
      <arxiv:journal_reference>Journal of Computational and Graphical Statistics, 1-16 (2025)</arxiv:journal_reference>
      <dc:creator>Xiaochuan Shi, Dehan Kong, Linbo Wang</dc:creator>
    </item>
    <item>
      <title>Bayesian Sphere-on-Sphere Regression with Optimal Transport Maps</title>
      <link>https://arxiv.org/abs/2501.08492</link>
      <description>arXiv:2501.08492v1 Announce Type: new 
Abstract: Spherical regression, where both covariate and response variables are defined on the sphere, is a required form of data analysis in several scientific disciplines, and has been the subject of substantial methodological development in recent years. Yet, it remains a challenging problem due to the complexities involved in constructing valid and expressive regression models between spherical domains, and the difficulties involved in quantifying uncertainty of estimated regression maps. To address these challenges, we propose casting spherical regression as a problem of optimal transport within a Bayesian framework. Through this approach, we obviate the need for directly parameterizing a spherical regression map, and are able to quantify uncertainty on the inferred map. We derive posterior contraction rates for the proposed model under two different prior specifications and, in doing so, obtain a result on the quantitative stability of optimal transport maps on the sphere, one that may be useful in other contexts. The utility of our approach is demonstrated empirically through a simulation study and through its application to real data.</description>
      <guid isPermaLink="false">oai:arXiv.org:2501.08492v1</guid>
      <category>stat.ME</category>
      <category>math.ST</category>
      <category>stat.TH</category>
      <pubDate>Thu, 16 Jan 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Tin Lok James Ng, Kwok-Kun Kwong, Jiakun Liu, Andrew Zammit-Mangion</dc:creator>
    </item>
    <item>
      <title>Designing and evaluating advanced adaptive randomised clinical trials: a practical guide</title>
      <link>https://arxiv.org/abs/2501.08765</link>
      <description>arXiv:2501.08765v1 Announce Type: new 
Abstract: Background
  Advanced adaptive randomised clinical trials are increasingly used. Compared to their conventional counterparts, their flexibility may make them more efficient, increase the probability of obtaining conclusive results without larger samples than necessary, and increase the probability that individual participants are allocated to more promising interventions. However, limited guidance is available on designing and evaluating the performance of advanced adaptive trials.
  Methods
  We summarise the methodological considerations and provide practical guidance on the entire workflow of planning and evaluating advanced adaptive trials using adaptive stopping, adaptive arm dropping, and response-adaptive randomisation within a Bayesian statistical framework.
  Results
  This comprehensive practical guide covers the key methodological decisions for advanced adaptive trials and their specification and evaluation using statistical simulation. These considerations include interventions and common control use; outcome type and generation; analysis timing and outcome-data lag; allocation rules; analysis model; adaptation rules for stopping and arm dropping; clinical scenarios assessed; performance metrics; calibration; sensitivity analyses; and reporting. The considerations are covered in the context of realistic examples, along with simulation code using the adaptr R package.
  Conclusions
  This practical guide will help clinical trialists, methodologists, and biostatisticians design and evaluate advanced adaptive trials.</description>
      <guid isPermaLink="false">oai:arXiv.org:2501.08765v1</guid>
      <category>stat.ME</category>
      <pubDate>Thu, 16 Jan 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Anders Granholm, Aksel Karl Georg Jensen, Theis Lange, Anders Perner, Morten Hylander M{\o}ller, Benjamin Skov Kaas-Hansen</dc:creator>
    </item>
    <item>
      <title>COADVISE: Covariate Adjustment with Variable Selection and Missing Data Imputation in Randomized Controlled Trials</title>
      <link>https://arxiv.org/abs/2501.08945</link>
      <description>arXiv:2501.08945v1 Announce Type: new 
Abstract: Adjusting for covariates in randomized controlled trials can enhance the credibility and efficiency of average treatment effect estimation. However, managing numerous covariates and their non-linear transformations is challenging, particularly when outcomes and covariates have missing data. In this tutorial, we propose a principled covariate adjustment framework, "COADVISE," that enables (i) variable selection for covariates most relevant to the outcome, (ii) nonlinear adjustments, and (iii) robust imputation of missing data for both outcomes and covariates. This framework ensures consistent estimates with improved efficiency over unadjusted estimators and provides robust variance estimation, even under outcome model misspecification. We demonstrate efficiency gains through theoretical analysis and conduct extensive simulations to compare alternative variable selection strategies, offering cautionary recommendations. We showcase the framework's practical utility by applying it to the Best Apnea Interventions for Research trial data from the National Sleep Research Resource. A user-friendly R package, Coadvise, facilitates implementation.</description>
      <guid isPermaLink="false">oai:arXiv.org:2501.08945v1</guid>
      <category>stat.ME</category>
      <pubDate>Thu, 16 Jan 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Yi Liu, Ke Zhu, Larry Han, Shu Yang</dc:creator>
    </item>
    <item>
      <title>A joint spatiotemporal model for multiple longitudinal markers and competing events</title>
      <link>https://arxiv.org/abs/2501.08960</link>
      <description>arXiv:2501.08960v1 Announce Type: new 
Abstract: Non-terminal events can represent a meaningful change in a patient's life. Thus, better understanding and predicting their occurrence can bring valuable information to individuals. In a context where longitudinal markers could inform these events, joint models with competing risks have been developed. Their precision relies on a reference time for which disease onset is often used. Nevertheless, chronic diseases have no clear onset, making it difficult to define a precise reference time. We propose a Joint cause-specific Spatiotemporal model to overcome this limitation and to capture a shared latent process, a latent age (temporal aspect), associated with the ordering of the longitudinal outcomes (spatial aspect). First, we validated our model on simulated real-like data. Then, we benchmarked our model with a shared-random-effect joint model on real ALS data using the PRO-ACT dataset. Finally, to show how the model could be used for description tasks, we analysed the impact of sex and onset site on the progression of ALS as well as the initiation of Non-Invasive Ventilation. The Joint cause-specific spatiotemporal model achieved similar performance to the shared random effect joint model while capturing the latent disease age and the impact of the ordering of longitudinal outcomes on the occurrence of the events with fewer parameters. The application study confirmed existing results for the Longitudinal outcomes and showed how to interpret the model. The proposed approach by disentangling a temporal and a spatial aspect of the disease opens the perspective to capture meaningful change in future clinical trials.</description>
      <guid isPermaLink="false">oai:arXiv.org:2501.08960v1</guid>
      <category>stat.ME</category>
      <pubDate>Thu, 16 Jan 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Juliette Ortholand, Stanley Durrleman, Sophie Tezenas du Montcel</dc:creator>
    </item>
    <item>
      <title>Family-wise Error Rate Control with E-values</title>
      <link>https://arxiv.org/abs/2501.09015</link>
      <description>arXiv:2501.09015v1 Announce Type: new 
Abstract: The closure principle is a standard tool for achieving family-wise error rate (FWER) control in multiple testing problems. In general, the computational cost for closed testing can be exponential in the number of hypotheses. The celebrated graphical approach of FWER control overcomes the computational hurdle by using weighted Bonferroni local tests on p-values with appropriately chosen weights. In this study, we extend the graphical approach to e-values. With valid e-values -- common in settings of sequential hypothesis testing or universal inference for irregular parametric models -- we can derive strictly more powerful local tests based on weighted averages of e-values. Consequently, this e-value-based closed test is more powerful than the corresponding graphical approach with inverse e-values as p-values. Although the computational shortcuts for the p-value-based graphical approach are not applicable, we develop efficient polynomial-time algorithms using dynamic programming for e-value-based graphical approaches with any directed acyclic graph. For special graphs, such as those used in the Holm's procedure and fallback procedure, we develop tailored algorithms with computation cost linear in the number of hypotheses, up to logarithmic factors.</description>
      <guid isPermaLink="false">oai:arXiv.org:2501.09015v1</guid>
      <category>stat.ME</category>
      <pubDate>Thu, 16 Jan 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Will Hartog, Lihua Lei</dc:creator>
    </item>
    <item>
      <title>An Ensemble Information Filter: Retrieving Markov-information from the SPDE discretisation</title>
      <link>https://arxiv.org/abs/2501.09016</link>
      <description>arXiv:2501.09016v1 Announce Type: new 
Abstract: Ensemble-based Data Assimilation faces significant challenges in high-dimensional systems due to spurious correlations and ensemble collapse. These issues arise from estimating dense dependencies with limited ensemble sizes. This paper introduces the Ensemble Information Filter, which encodes Markov properties directly into the statistical model's precision matrix, leveraging structure from SPDE dynamics to constrain information to propagate locally. EnIF eliminates the need for ad-hoc localisation, improving statistical consistency and scalability. Numerical experiments demonstrate its advantages in filtering, smoothing, and parameter estimation, making EnIF a robust and efficient solution for large-scale data assimilation problems.</description>
      <guid isPermaLink="false">oai:arXiv.org:2501.09016v1</guid>
      <category>stat.ME</category>
      <category>math.DS</category>
      <pubDate>Thu, 16 Jan 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Berent {\AA}nund Str{\o}mnes Lunde</dc:creator>
    </item>
    <item>
      <title>Causal vs. Anticausal merging of predictors</title>
      <link>https://arxiv.org/abs/2501.08426</link>
      <description>arXiv:2501.08426v1 Announce Type: cross 
Abstract: We study the differences arising from merging predictors in the causal and anticausal directions using the same data. In particular we study the asymmetries that arise in a simple model where we merge the predictors using one binary variable as target and two continuous variables as predictors. We use Causal Maximum Entropy (CMAXENT) as inductive bias to merge the predictors, however, we expect similar differences to hold also when we use other merging methods that take into account asymmetries between cause and effect. We show that if we observe all bivariate distributions, the CMAXENT solution reduces to a logistic regression in the causal direction and Linear Discriminant Analysis (LDA) in the anticausal direction. Furthermore, we study how the decision boundaries of these two solutions differ whenever we observe only some of the bivariate distributions implications for Out-Of-Variable (OOV) generalisation.</description>
      <guid isPermaLink="false">oai:arXiv.org:2501.08426v1</guid>
      <category>cs.LG</category>
      <category>cs.AI</category>
      <category>stat.ME</category>
      <category>stat.ML</category>
      <pubDate>Thu, 16 Jan 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <dc:creator>Sergio Hernan Garrido Mejia, Patrick Bl\"obaum, Bernhard Sch\"olkopf, Dominik Janzing</dc:creator>
    </item>
    <item>
      <title>A Refreshment Stirred, Not Shaken (II): Invariant-Preserving Deployments of Differential Privacy for the US Decennial Census</title>
      <link>https://arxiv.org/abs/2501.08449</link>
      <description>arXiv:2501.08449v1 Announce Type: cross 
Abstract: Through the lens of the system of differential privacy specifications developed in Part I of a trio of articles, this second paper examines two statistical disclosure control (SDC) methods for the United States Decennial Census: the Permutation Swapping Algorithm (PSA), which is similar to the 2010 Census's disclosure avoidance system (DAS), and the TopDown Algorithm (TDA), which was used in the 2020 DAS. To varying degrees, both methods leave unaltered some statistics of the confidential data $\unicode{x2013}$ which are called the method's invariants $\unicode{x2013}$ and hence neither can be readily reconciled with differential privacy (DP), at least as it was originally conceived. Nevertheless, we establish that the PSA satisfies $\varepsilon$-DP subject to the invariants it necessarily induces, thereby showing that this traditional SDC method can in fact still be understood within our more-general system of DP specifications. By a similar modification to $\rho$-zero concentrated DP, we also provide a DP specification for the TDA. Finally, as a point of comparison, we consider the counterfactual scenario in which the PSA was adopted for the 2020 Census, resulting in a reduction in the nominal privacy loss, but at the cost of releasing many more invariants. Therefore, while our results explicate the mathematical guarantees of SDC provided by the PSA, the TDA and the 2020 DAS in general, care must be taken in their translation to actual privacy protection $\unicode{x2013}$ just as is the case for any DP deployment.</description>
      <guid isPermaLink="false">oai:arXiv.org:2501.08449v1</guid>
      <category>cs.CR</category>
      <category>cs.CY</category>
      <category>cs.DS</category>
      <category>stat.ME</category>
      <pubDate>Thu, 16 Jan 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>James Bailie, Ruobin Gong, Xiao-Li Meng</dc:creator>
    </item>
    <item>
      <title>A Semi-Parametric Bayesian Spatial Model for Rainfall Events in Geographically Complex Domains</title>
      <link>https://arxiv.org/abs/2501.08748</link>
      <description>arXiv:2501.08748v1 Announce Type: cross 
Abstract: Environmental phenomena are influenced by complex interactions among various factors. For instance, the amount of rainfall measured at different stations within a given area is shaped by atmospheric conditions, orography, and physics of water processes. Motivated by the need to analyze rainfall across complex spatial locations, we propose a flexible Bayesian semi-parametric model for spatially distributed data. This method effectively accounts for spatial correlation while incorporating dependencies on geographical characteristics in a highly flexible manner. Indeed, using latent Gaussian processes, indexed by spatial coordinates and topographical features, the model integrates spatial dependencies and environmental characteristics within a nonparametric framework. Posterior inference is conducted using an efficient rejection-free Markov Chain Monte Carlo algorithm, which eliminates the need for tuning parameter calibration, ensuring smoother and more reliable estimation. The model's flexibility is evaluated through a series of simulation studies, involving different rainfall and spatial correlation scenarios, to demonstrate its robustness across various conditions. We then apply the model to a large dataset of rainfall events collected from the Italian regions of Veneto and Trentino-Alto Adige, these areas are known for their complex orography and diverse meteorological drivers. By analyzing this data, we generate detailed maps that illustrate the mean and variance of rainfall and rainy days. The method is implemented in a new R package available on GitHub.</description>
      <guid isPermaLink="false">oai:arXiv.org:2501.08748v1</guid>
      <category>stat.AP</category>
      <category>stat.CO</category>
      <category>stat.ME</category>
      <pubDate>Thu, 16 Jan 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Paolo Onorati, Antonio Canale</dc:creator>
    </item>
    <item>
      <title>Nonparametric inference for Poisson-Laguerre tessellations</title>
      <link>https://arxiv.org/abs/2501.08810</link>
      <description>arXiv:2501.08810v1 Announce Type: cross 
Abstract: In this paper, we consider statistical inference for Poisson-Laguerre tessellations in $\mathbb{R}^d$. The object of interest is a distribution function $F$ which uniquely determines the intensity measure of the underlying Poisson process. Two nonparametric estimators for $F$ are introduced which depend only on the points of the Poisson process which generate non-empty cells and the actual cells corresponding to these points. The proposed estimators are proven to be strongly consistent, as the observation window expands unboundedly to the whole space. We also consider a stereological setting, where one is interested in estimating the distribution function associated with the Poisson process of a higher dimensional Poisson-Laguerre tessellation, given that a corresponding sectional Poisson-Laguerre tessellation is observed.</description>
      <guid isPermaLink="false">oai:arXiv.org:2501.08810v1</guid>
      <category>math.ST</category>
      <category>stat.ME</category>
      <category>stat.TH</category>
      <pubDate>Thu, 16 Jan 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Thomas van der Jagt, Geurt Jongbloed, Martina Vittorietti</dc:creator>
    </item>
    <item>
      <title>Quantification and cross-fitting inference of asymmetric relations under generative exposure mapping models</title>
      <link>https://arxiv.org/abs/2311.04696</link>
      <description>arXiv:2311.04696v5 Announce Type: replace 
Abstract: In many practical studies, learning directionality between a pair of variables is of great interest while notoriously hard, especially for mechanistic relationships. This paper presents a method that examines directionality in exposure-outcome pairs when a priori assumptions about their relative ordering are unavailable. We propose a coefficient of asymmetry to quantify directional asymmetry using Shannon's entropy and propose a statistical estimation and inference framework for said estimand. Large-sample theoretical guarantees are established through data-splitting and cross-fitting techniques. The proposed methodology is extended to allow both measured confounders and contamination in outcome measurements. The methodology is extensively evaluated through extensive simulation studies, a benchmark dataset, and a real data application.</description>
      <guid isPermaLink="false">oai:arXiv.org:2311.04696v5</guid>
      <category>stat.ME</category>
      <category>math.ST</category>
      <category>stat.TH</category>
      <pubDate>Thu, 16 Jan 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Soumik Purkayastha, Peter X. -K. Song</dc:creator>
    </item>
    <item>
      <title>Outcomes truncated by death in RCTs: a simulation study on the survivor average causal effect</title>
      <link>https://arxiv.org/abs/2312.11991</link>
      <description>arXiv:2312.11991v3 Announce Type: replace 
Abstract: Continuous outcome measurements truncated by death present a challenge for the estimation of unbiased treatment effects in randomized controlled trials (RCTs). One way to deal with such situations is to estimate the survivor average causal effect (SACE), but this requires making non-testable assumptions. Motivated by an ongoing RCT in very preterm infants with intraventricular hemorrhage, we performed a simulation study to compare a SACE estimator with complete case analysis (CCA) and an analysis after multiple imputation of missing outcomes. We set up 9 scenarios combining positive, negative and no treatment effect on the outcome (cognitive development) and on survival at 2 years of age. Treatment effect estimates from all methods were compared in terms of bias, mean squared error and coverage with regard to two true treatment effects: the treatment effect on the outcome used in the simulation and the SACE, which was derived by simulation of both potential outcomes per patient. Despite targeting different estimands (principal stratum estimand, hypothetical estimand), the SACE-estimator and multiple imputation gave similar estimates of the treatment effect and efficiently reduced the bias compared to CCA. Also, both methods were relatively robust to omission of one covariate in the analysis, and thus violation of relevant assumptions. Although the SACE is not without controversy, we find it useful if mortality is inherent to the study population. Some degree of violation of the required assumptions is almost certain, but may be acceptable in practice.</description>
      <guid isPermaLink="false">oai:arXiv.org:2312.11991v3</guid>
      <category>stat.ME</category>
      <pubDate>Thu, 16 Jan 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Stefanie von Felten, Chiara Vanetta, Christoph M. R\"uegger, Sven Wellmann, Leonhard Held</dc:creator>
    </item>
    <item>
      <title>Between- and Within-Cluster Spearman Rank Correlations</title>
      <link>https://arxiv.org/abs/2402.11341</link>
      <description>arXiv:2402.11341v2 Announce Type: replace 
Abstract: Clustered data are common in practice. Clustering arises when subjects are measured repeatedly, or subjects are nested in groups (e.g., households, schools). It is often of interest to evaluate the correlation between two variables with clustered data. There are three commonly used Pearson correlation coefficients (total, between-, and within-cluster), which together provide an enriched perspective of the correlation. However, these Pearson correlation coefficients are sensitive to extreme values and skewed distributions. They also vary with data transformation, which is arbitrary and often difficult to choose, and they are not applicable to ordered categorical data. Current nonparametric correlation measures for clustered data are only for the total correlation. Here we define population parameters for the between- and within-cluster Spearman rank correlations. The definitions are natural extensions of the Pearson between- and within-cluster correlations to the rank scale. We show that the total Spearman rank correlation approximates a linear combination of the between- and within-cluster Spearman rank correlations, where the weights are functions of rank intraclass correlations of the two random variables. We also discuss the equivalence between the within-cluster Spearman rank correlation and the covariate-adjusted partial Spearman rank correlation. Furthermore, we describe estimation and inference for the three Spearman rank correlations, conduct simulations to evaluate the performance of our estimators, and illustrate their use with data from a longitudinal biomarker study and a clustered randomized trial.</description>
      <guid isPermaLink="false">oai:arXiv.org:2402.11341v2</guid>
      <category>stat.ME</category>
      <pubDate>Thu, 16 Jan 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Shengxin Tu, Chun Li, Bryan E. Shepherd</dc:creator>
    </item>
    <item>
      <title>Modeling Neural Switching via Drift-Diffusion Models</title>
      <link>https://arxiv.org/abs/2410.00781</link>
      <description>arXiv:2410.00781v2 Announce Type: replace 
Abstract: Neural encoding, or neural representation, is a field in neuroscience that focuses on characterizing how information from stimuli is encoded in the spiking activity of neurons. When more than one stimulus is present, a theory known as multiplexing posits that neurons temporally switch between encoding various stimuli, creating a fluctuating firing pattern. Here, we propose a new statistical framework to analyze rate fluctuations and discern whether neurons employ multiplexing as a means of encoding multiple stimuli. We propose a mechanistic approach to modeling multiplexing by constructing a non-Markovian endogenous state-space model. Specifically, we propose that multiplexing arises from competition between the stimuli, which are modeled as latent drift-diffusion processes. We propose a new MCMC algorithm for conducting posterior inference on similar types of state-space models, where typical state-space MCMC methods fail due to strong dependence between the parameters. In addition to a multiplexing-specific model, we develop alternative models that represent a wide class of alternative encoding theories and perform model comparison using WAIC to determine whether the data suggest the occurrence multiplexing over alternative theories of neural encoding. We show that WAIC is highly informative in model selection and discuss different considerations when using WAIC for general point process data and state-space models. Using the proposed framework, we provide evidence of multiplexing within the inferior colliculus and novel insight into the switching dynamics.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.00781v2</guid>
      <category>stat.ME</category>
      <pubDate>Thu, 16 Jan 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Nicholas Marco, Jennifer M. Groh, Surya T. Tokdar</dc:creator>
    </item>
    <item>
      <title>Nonparametric estimation on the circle based on Fej\'er polynomials</title>
      <link>https://arxiv.org/abs/2411.19138</link>
      <description>arXiv:2411.19138v2 Announce Type: replace 
Abstract: This paper presents a comprehensive study of nonparametric estimation techniques on the circle using Fej\'er polynomials, which are analogues of Bernstein polynomials for periodic functions. Building upon Fej\'er's uniform approximation theorem, the paper introduces circular density and distribution function estimators based on Fej\'er kernels. It establishes their theoretical properties, including uniform strong consistency and asymptotic expansions. Since the estimation of the distribution function on the circle depends on the choice of the origin, we propose a data-dependent method to address this issue.
  The proposed methods are extended to account for measurement errors by incorporating classical and Berkson error models, adjusting the Fej\'er estimator to mitigate their effects. Simulation studies analyze the finite-sample performance of these estimators under various scenarios, including mixtures of circular distributions and measurement error models. An application to rainfall data demonstrates the practical application of the proposed estimators, demonstrating their robustness and effectiveness in the presence of rounding-induced Berkson errors.</description>
      <guid isPermaLink="false">oai:arXiv.org:2411.19138v2</guid>
      <category>stat.ME</category>
      <pubDate>Thu, 16 Jan 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Bernhard Klar, Bojana Milo\v{s}evi\'c, Marko Obradovi\'c</dc:creator>
    </item>
    <item>
      <title>Rate accelerated inference for integrals of multivariate random functions</title>
      <link>https://arxiv.org/abs/2412.08533</link>
      <description>arXiv:2412.08533v2 Announce Type: replace 
Abstract: The computation of integrals is a fundamental task in the analysis of functional data, which are typically considered as random elements in a space of squared integrable functions. Borrowing ideas from recent advances in the Monte Carlo integration literature, we propose effective unbiased estimation and inference procedures for integrals of uni- and multivariate random functions. Several applications to key problems in functional data analysis involving random design points are studied and illustrated. In the absence of noise, the proposed estimates converge faster than the sample mean and the usual algorithms for numerical integration. Moreover, the proposed estimator facilitates effective inference by generally providing better coverage with shorter confidence and prediction intervals, in both noisy and noiseless setups.</description>
      <guid isPermaLink="false">oai:arXiv.org:2412.08533v2</guid>
      <category>stat.ME</category>
      <pubDate>Thu, 16 Jan 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <dc:creator>Valentin Patilea, Sunny G. W. Wang</dc:creator>
    </item>
    <item>
      <title>Augmentation Invariant Manifold Learning</title>
      <link>https://arxiv.org/abs/2211.00460</link>
      <description>arXiv:2211.00460v3 Announce Type: replace-cross 
Abstract: Data augmentation is a widely used technique and an essential ingredient in the recent advance in self-supervised representation learning. By preserving the similarity between augmented data, the resulting data representation can improve various downstream analyses and achieve state-of-the-art performance in many applications. Despite the empirical effectiveness, most existing methods lack theoretical understanding under a general nonlinear setting. To fill this gap, we develop a statistical framework on a low-dimension product manifold to model the data augmentation transformation. Under this framework, we introduce a new representation learning method called augmentation invariant manifold learning and design a computationally efficient algorithm by reformulating it as a stochastic optimization problem. Compared with existing self-supervised methods, the new method simultaneously exploits the manifold's geometric structure and invariant property of augmented data and has an explicit theoretical guarantee. Our theoretical investigation characterizes the role of data augmentation in the proposed method and reveals why and how the data representation learned from augmented data can improve the $k$-nearest neighbor classifier in the downstream analysis, showing that a more complex data augmentation leads to more improvement in downstream analysis. Finally, numerical experiments on simulated and real data sets are presented to demonstrate the merit of the proposed method.</description>
      <guid isPermaLink="false">oai:arXiv.org:2211.00460v3</guid>
      <category>stat.ML</category>
      <category>cs.LG</category>
      <category>math.ST</category>
      <category>stat.ME</category>
      <category>stat.TH</category>
      <pubDate>Thu, 16 Jan 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Shulei Wang</dc:creator>
    </item>
    <item>
      <title>Heterogeneous Treatment Effects and Causal Mechanisms</title>
      <link>https://arxiv.org/abs/2404.01566</link>
      <description>arXiv:2404.01566v3 Announce Type: replace-cross 
Abstract: The credibility revolution advances the use of research designs that permit identification and estimation of causal effects. However, understanding which mechanisms produce measured causal effects remains a challenge. A dominant current approach to the quantitative evaluation of mechanisms relies on the detection of heterogeneous treatment effects with respect to pre-treatment covariates. This paper develops a framework to understand when the existence of such heterogeneous treatment effects can support inferences about the activation of a mechanism. We show first that this design cannot provide evidence of mechanism activation without an additional, generally implicit, assumption. Further, even when this assumption is satisfied, if a measured outcome is produced by a non-linear transformation of a directly-affected outcome of theoretical interest, heterogeneous treatment effects are not informative of mechanism activation. We provide novel guidance for interpretation and research design in light of these findings.</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.01566v3</guid>
      <category>econ.EM</category>
      <category>stat.ME</category>
      <pubDate>Thu, 16 Jan 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Jiawei Fu, Tara Slough</dc:creator>
    </item>
  </channel>
</rss>
