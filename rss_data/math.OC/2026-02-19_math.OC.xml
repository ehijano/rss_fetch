<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>math.OC updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/math.OC</link>
    <description>math.OC updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/math.OC" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Thu, 19 Feb 2026 05:00:15 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Thu, 19 Feb 2026 00:00:00 -0500</pubDate>
    <skipDays>
      <day>Saturday</day>
      <day>Sunday</day>
    </skipDays>
    <item>
      <title>Exploring New Frontiers in Vertical Federated Learning: the Role of Saddle Point Reformulation</title>
      <link>https://arxiv.org/abs/2602.15996</link>
      <description>arXiv:2602.15996v1 Announce Type: new 
Abstract: The objective of Vertical Federated Learning (VFL) is to collectively train a model using features available on different devices while sharing the same users. This paper focuses on the saddle point reformulation of the VFL problem via the classical Lagrangian function. We first demonstrate how this formulation can be solved using deterministic methods. More importantly, we explore various stochastic modifications to adapt to practical scenarios, such as employing compression techniques for efficient information transmission, enabling partial participation for asynchronous communication, and utilizing coordinate selection for faster local computation. We show that the saddle point reformulation plays a key role and opens up possibilities to use mentioned extension that seem to be impossible in the standard minimization formulation. Convergence estimates are provided for each algorithm, demonstrating their effectiveness in addressing the VFL problem. Additionally, alternative reformulations are investigated, and numerical experiments are conducted to validate performance and effectiveness of the proposed approach.</description>
      <guid isPermaLink="false">oai:arXiv.org:2602.15996v1</guid>
      <category>math.OC</category>
      <category>cs.LG</category>
      <pubDate>Thu, 19 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Aleksandr Beznosikov, Georgiy Kormakov, Alexander Grigorievskiy, Mikhail Rudakov, Ruslan Nazykov, Alexander Rogozin, Anton Vakhrushev, Andrey Savchenko, Martin Tak\'a\v{c}, Alexander Gasnikov</dc:creator>
    </item>
    <item>
      <title>Exponential Conic Optimization for Multi-Regime Service System Design under Congestion and Tail-Risk Control</title>
      <link>https://arxiv.org/abs/2602.16021</link>
      <description>arXiv:2602.16021v1 Announce Type: new 
Abstract: We study the design of single-facility service systems operating under multiple recurring regimes with service-level constraints on response times. Regime-dependent arrival and service rates induce hyperexponential response-time distributions, and the design problem selects regime-specific capacities to balance cost, congestion, fairness, and reliability. We propose a mixed-integer exponential conic optimization framework integrating SLA chance constraints, conflict-graph design restrictions, and CVaR-based tail-risk control. Although NP-hard, the problem admits an efficient decomposition scheme and tractable special cases. Computational experiments and a large-scale urban case study show substantial improvements over the current system, quantifying explicit trade-offs between efficiency, congestion control, fairness, and robustness. The framework provides a practical tool for congestion-aware and tail-control service system design.</description>
      <guid isPermaLink="false">oai:arXiv.org:2602.16021v1</guid>
      <category>math.OC</category>
      <pubDate>Thu, 19 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>V\'ictor Blanco, Miguel Mart\'inez-Ant\'on, Justo Puerto</dc:creator>
    </item>
    <item>
      <title>Local adapt-then-combine algorithms for distributed nonsmooth optimization: Achieving provable communication acceleration</title>
      <link>https://arxiv.org/abs/2602.16148</link>
      <description>arXiv:2602.16148v1 Announce Type: new 
Abstract: This paper is concerned with the distributed composite optimization problem over networks, where agents aim to minimize a sum of local smooth components and a common nonsmooth term. Leveraging the probabilistic local updates mechanism, we propose a communication-efficient Adapt-Then-Combine (ATC) framework, FlexATC, unifying numerous ATC-based distributed algorithms. Under stepsizes independent of the network topology and the number of local updates, we establish sublinear and linear convergence rates for FlexATC in convex and strongly convex settings, respectively. Remarkably, in the strong convex setting, the linear rate is decoupled from the objective functions and network topology, and FlexATC permits communication to be skipped in most iterations without any deterioration of the linear rate. In addition, the proposed unified theory demonstrates for the first time that local updates provably lead to communication acceleration for ATC-based distributed algorithms. Numerical experiments further validate the efficacy of the proposed framework and corroborate the theoretical results.</description>
      <guid isPermaLink="false">oai:arXiv.org:2602.16148v1</guid>
      <category>math.OC</category>
      <category>cs.LG</category>
      <pubDate>Thu, 19 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Luyao Guo, Xinli Shi, Wenying Xu, Jinde Cao</dc:creator>
    </item>
    <item>
      <title>Null controllability of one-dimensional quasilinear parabolic equations via multiplicative controls</title>
      <link>https://arxiv.org/abs/2602.16150</link>
      <description>arXiv:2602.16150v1 Announce Type: new 
Abstract: This paper is concerned with the null controllability problem for a class of quasilinear parabolic equations under multiplicative control, locally supported in space. For the purpose of proving the existence of a multiplicative control forcing the solution rest at a time $T&gt;0$, we need to establish the decay property of solutions for the system without control first. We have obtained decay estimates for the $L^\infty$-norm and the $H^1$-norm of solutions to the homogenous quasilinear parabolic equations. Notably, the decay of the $L^\infty$-norm requires no smallness condition on the initial data, whereas the decay of the $H^1$-norm requires that the $L^\infty$-norm remains small. Based on the decay estimates and maximum modulus estimate of solutions to quasilinear parabolic equations, together with the local null controllability of quasilinear parabolic equations under additive controls, we prove the null controllability of the quasilinear parabolic equations via multiplicative controls. As a byproduct, we also obtain the global null controllability for large time to the quasilinear parabolic equations via additive controls. Given that the controllability under multiplicative control is achieved over a long time horizon, we finally investigate the existence of time optimal control.</description>
      <guid isPermaLink="false">oai:arXiv.org:2602.16150v1</guid>
      <category>math.OC</category>
      <pubDate>Thu, 19 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Jilei Huang, Peidong Lei, Yansheng Ma, Jingxue Yin</dc:creator>
    </item>
    <item>
      <title>Metaheuristic algorithms for the induced P-median problem with upgrades</title>
      <link>https://arxiv.org/abs/2602.16170</link>
      <description>arXiv:2602.16170v1 Announce Type: new 
Abstract: Facility location problems (FLPs) are a family of optimisation problems with significant social impact. This class of problems has been the subject of study since the 1960s, with classical approaches including the Weber problem and the p-Median problem. Currently, more complex variations of these problems are being investigated. In particular, the Induced p-Median Problem with Upgrades (IpMU) represents a variation of the classical p-Median problem, where the concepts of transport cost and time are separated as distinct metrics in the input graph of the problem. Furthermore, the problem includes a budget which allows one to relax the graph costs, reducing the cost of the edges, thus improving the associated routes between the designated medians and the customers. In this study, a metaheuristic algorithm, based on the Greedy Randomized Adaptive Search Procedure (GRASP), is proposed. A two-phase resolution scheme is defined, studying the median problem and the upgrading problem independently. In this approach, a larger set of state-of-the-art instances was analysed to ensure a fair comparison with previous proposals. In addition, the characteristics of the instances were studied to assess their complexity. The results obtained are promising when compared to the state-of-the-art, which is based entirely on mathematical programming models. The execution time was improved on average by two orders of magnitude for the harder instances, and the best known result was obtained in more than 99% of the tested instances.</description>
      <guid isPermaLink="false">oai:arXiv.org:2602.16170v1</guid>
      <category>math.OC</category>
      <pubDate>Thu, 19 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Sergio Salazar, Abraham Duarte, Mauricio G. C. Resende, J. Manuel Colmenar</dc:creator>
    </item>
    <item>
      <title>Optimal driving strategies for a fleet of trains</title>
      <link>https://arxiv.org/abs/2602.16205</link>
      <description>arXiv:2602.16205v1 Announce Type: new 
Abstract: In order to manage electricity transmission and distribution it is now common practice for system operators to offer financial incentives that encourage large consumers to reduce energy usage during designated peak demand periods. For train operators on large rail networks it may be profitable -- with selected individual journeys -- to reduce energy usage during peak times and increase energy usage at other times rather than simply minimizing overall energy consumption. We will use classical methods of constrained optimization to find optimal driving strategies for a fleet of trains subject to limits on total energy consumption during specified intermediate time intervals but with no change to individual journey times. The proposed strategies can be used by a large rail organisation to reduce overall operating costs with only minimal disruption to existing schedules and with no changes to important departure and arrival times.</description>
      <guid isPermaLink="false">oai:arXiv.org:2602.16205v1</guid>
      <category>math.OC</category>
      <pubDate>Thu, 19 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Phil Howlett, Maria Kapsis, Peter Pudney</dc:creator>
    </item>
    <item>
      <title>Partially observed controlled Markov chains and optimal control of the Wonham filter</title>
      <link>https://arxiv.org/abs/2602.16392</link>
      <description>arXiv:2602.16392v1 Announce Type: new 
Abstract: We consider a class of optimal control problems, with finite or infinite horizon, for a continuous-time Markov chain with finite state space. In this case, the control process affects the transition rates. We suppose that the controlled process can not be observed, and at any time the control actions are chosen based on the observation of a related stochastic process perturbed by an exogenous Brownian motion. We describe a construction of the controlled Markov chain, having stochastic transition rates adapted to the observation filtration. By a change of probability measure of Girsanov type, we introduce the so-called separated optimal control problem, where the state is the conditional (unnormalized) distribution of the controlled Markov chain and the observation process becomes a driving Brownian motion, and we prove the equivalence with the original control problem. The controlled equations for the separated problem are an instance of the Wonham filtering equations. Next we present an analysis of the separated problem: we characterize the value function as the unique viscosity solution to the dynamic programming equations (both in the parabolic and the elliptic case) we prove verifications theorems and a version of the stochastic maximum principle in the form of a necessary conditions for optimality.</description>
      <guid isPermaLink="false">oai:arXiv.org:2602.16392v1</guid>
      <category>math.OC</category>
      <category>math.PR</category>
      <pubDate>Thu, 19 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Fulvia Confortola, Marco Fuhrman</dc:creator>
    </item>
    <item>
      <title>Primal-dual dynamical systems with closed-loop control for convex optimization in continuous and discrete time</title>
      <link>https://arxiv.org/abs/2602.16402</link>
      <description>arXiv:2602.16402v1 Announce Type: new 
Abstract: This paper develops a primal-dual dynamical system where the coefficients are designed in closed-loop way for solving a convex optimization problem with linear equality constraints. We first introduce a ``second-order primal" + ``first-order dual'' continuous-time dynamical system, in which both the time scaling and Hessian-driven damping are governed by a feedback control of the gradient for the Lagrangian function. This system achieves the fast convergence rates for the primal-dual gap, the feasibility violation, and the objective residual along its trajectory. Subsequently, by time discretization of this system, we develop an accelerated primal-dual algorithm with a gradient-defined adaptive step size. We also obtain convergence rates for the primal-dual gap, the feasibility violation, and the objective residual. Furthermore, we provide numerical results to demonstrate the practical efficacy and superior performance of the proposed algorithm.</description>
      <guid isPermaLink="false">oai:arXiv.org:2602.16402v1</guid>
      <category>math.OC</category>
      <pubDate>Thu, 19 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Huan Zhang, Xiangkai Sun, Shengjie Li, Kok Lay Teo</dc:creator>
    </item>
    <item>
      <title>The Complexity Landscape of Two-Stage Robust Selection Problems with Budgeted Uncertainty</title>
      <link>https://arxiv.org/abs/2602.16465</link>
      <description>arXiv:2602.16465v1 Announce Type: new 
Abstract: A standard type of uncertainty set in robust optimization is budgeted uncertainty, where an interval of possible values for each parameter is given and the total deviation from their lower bounds is bounded. In the two-stage setting, discrete and continuous budgeted uncertainty have to be distinguished. The complexity of such problems is largely unexplored, in particular if the underlying nominal optimization problem is simple, such as for selection problems. In this paper, we give a comprehensive answer to long-standing open complexity questions for three types of selection problems and three types of budgeted uncertainty sets. In particular, we demonstrate that the two-stage selection problem with continuous budgeted uncertainty is NP-hard, while the corresponding two-stage representative selection problem is solvable in polynomial time. Our hardness result implies that also the two-stage assignment problem with continuous budgeted uncertainty is NP-hard.</description>
      <guid isPermaLink="false">oai:arXiv.org:2602.16465v1</guid>
      <category>math.OC</category>
      <category>cs.DS</category>
      <pubDate>Thu, 19 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Marc Goerigk, Dorothee Henke, Lasse Wulf</dc:creator>
    </item>
    <item>
      <title>PL conditions do not guarantee convergence of gradient descent-ascent dynamics</title>
      <link>https://arxiv.org/abs/2602.16517</link>
      <description>arXiv:2602.16517v1 Announce Type: new 
Abstract: We give an example of a function satisfying a two-sided Polyak-Lojasiewicz condition but for which a gradient descent-ascent flow line fails to converge to the saddle point, circling around it instead.</description>
      <guid isPermaLink="false">oai:arXiv.org:2602.16517v1</guid>
      <category>math.OC</category>
      <pubDate>Thu, 19 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Jean-Christophe Mourrat</dc:creator>
    </item>
    <item>
      <title>Learning Distributed Equilibria in Linear-Quadratic Stochastic Differential Games: An $\alpha$-Potential Approach</title>
      <link>https://arxiv.org/abs/2602.16555</link>
      <description>arXiv:2602.16555v1 Announce Type: new 
Abstract: We analyze independent policy-gradient (PG) learning in $N$-player linear-quadratic (LQ) stochastic differential games. Each player employs a distributed policy that depends only on its own state and updates the policy independently using the gradient of its own objective. We establish global linear convergence of these methods to an equilibrium by showing that the LQ game admits an $\alpha$-potential structure, with $\alpha$ determined by the degree of pairwise interaction asymmetry. For pairwise-symmetric interactions, we construct an affine distributed equilibrium by minimizing the potential function and show that independent PG methods converge globally to this equilibrium, with complexity scaling linearly in the population size and logarithmically in the desired accuracy. For asymmetric interactions, we prove that independent projected PG algorithms converge linearly to an approximate equilibrium, with suboptimality proportional to the degree of asymmetry. Numerical experiments confirm the theoretical results across both symmetric and asymmetric interaction networks.</description>
      <guid isPermaLink="false">oai:arXiv.org:2602.16555v1</guid>
      <category>math.OC</category>
      <category>cs.LG</category>
      <category>math.PR</category>
      <pubDate>Thu, 19 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Philipp Plank, Yufei Zhang</dc:creator>
    </item>
    <item>
      <title>Optimal bounds for numerical approximations of finite horizon problems based on dynamic programming approach</title>
      <link>https://arxiv.org/abs/2602.16574</link>
      <description>arXiv:2602.16574v1 Announce Type: new 
Abstract: In this paper we provide optimal bounds for fully discrete approximations to finite horizon problems via dynamic programming. We adapt the error analysis in \cite{nos} for the infinite horizon case to the
  finite horizon case. We prove an a priori bound of size $O(h+k)$ for the method, $h$ being the time discretization step and $k$ the spatial mesh size. Arguing with piecewise constants controls we are able to obtain first order of convergence in time and space under standard regularity assumptions, avoiding the more restrictive regularity assumptions on the controls required in \cite{nos}.
  We show that the loss in the rate of convergence in time of the
  infinite case (obtained arguing with piece-wise controls)
  can be avoided in the finite horizon case</description>
      <guid isPermaLink="false">oai:arXiv.org:2602.16574v1</guid>
      <category>math.OC</category>
      <pubDate>Thu, 19 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Javier de Frutos, Julia Novo</dc:creator>
    </item>
    <item>
      <title>Nonparametric Kernel Regression for Coordinated Energy Storage Peak Shaving with Stacked Services</title>
      <link>https://arxiv.org/abs/2602.16586</link>
      <description>arXiv:2602.16586v1 Announce Type: new 
Abstract: Developing effective control strategies for behind-the-meter energy storage to coordinate peak shaving and stacked services is essential for reducing electricity costs and extending battery lifetime in commercial buildings. This work proposes an end-to-end, two-stage framework for coordinating peak shaving and energy arbitrage with a theoretical decomposition guarantee. In the first stage, a non-parametric kernel regression model constructs state-of-charge trajectory bounds from historical data that satisfy peak-shaving requirements. The second stage utilizes the remaining capacity for energy arbitrage via a transfer learning method. Case studies using New York City commercial building demand data show that our method achieves a 1.3 times improvement in performance over the state-of-the-art forecast-based method, achieving cost savings and effective peak management without relying on predictions.</description>
      <guid isPermaLink="false">oai:arXiv.org:2602.16586v1</guid>
      <category>math.OC</category>
      <category>cs.SY</category>
      <category>eess.SY</category>
      <pubDate>Thu, 19 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <arxiv:journal_reference>IEEE PES GM 2026</arxiv:journal_reference>
      <dc:creator>Emily Logan, Ning Qi, Bolun Xu</dc:creator>
    </item>
    <item>
      <title>Hybrid Optimization Techniques for Multi-State Optimal Design Problems</title>
      <link>https://arxiv.org/abs/2602.16592</link>
      <description>arXiv:2602.16592v1 Announce Type: new 
Abstract: This paper addresses optimal design problems governed by multi-state stationary diffusion equations, aiming at the simultaneous optimization of the domain shape and the distribution of two isotropic materials in prescribed proportions. Existence of generalized solutions is established via a hybrid approach combining homogenization-based relaxation in the interior with suitable restrictions on admissible domains.
  Based on this framework, we propose a numerical method that integrates homogenization and shape optimization. The domain boundary is evolved using a level set method driven by the shape derivative, while the interior material distribution is updated via an optimality criteria algorithm. The approach is demonstrated on a representative example.</description>
      <guid isPermaLink="false">oai:arXiv.org:2602.16592v1</guid>
      <category>math.OC</category>
      <category>math.AP</category>
      <pubDate>Thu, 19 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Marko Erceg, Petar Kun\v{s}tek, Marko Vrdoljak</dc:creator>
    </item>
    <item>
      <title>Close-enough general routing problem for multiple unmanned aerial vehicles in monitoring missions</title>
      <link>https://arxiv.org/abs/2602.15841</link>
      <description>arXiv:2602.15841v1 Announce Type: cross 
Abstract: In this paper, we introduce a close-enough multi-UAV general routing problem (CEMUAVGRP) where a fleet of homogeneous UAVs conduct monitoring tasks containing nodes, each of which has its disk neighborhood, and edges, aiming to minimize the total distance. A two-phase iterative method is proposed, partitioning the CEMUAVGRP into a general routing phase where a satisfactory route including required nodes and edges for each UAV is obtained without considering the disk neighborhoods of required nodes, and a close-enough routing phase where representative points are optimized for each required node in the determined route. To be specific, a variable neighborhood descent (VND) heuristic is proposed for the general routing phase, while a second-order cone programming (SOCP) procedure is applied in the close-enough routing phase. These two phases are performed in an iterative fashion under the framework of an adaptive iterated local search (AILS) algorithm until the predefined termination criteria are satisfied. Extensive experiments and comparative studies are conducted, demonstrating the efficiency of the proposed AILS-VND-SOCP algorithm and the superiority of disk neighborhoods.</description>
      <guid isPermaLink="false">oai:arXiv.org:2602.15841v1</guid>
      <category>eess.SY</category>
      <category>cs.NI</category>
      <category>cs.SY</category>
      <category>math.OC</category>
      <pubDate>Thu, 19 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Huan Liu, Michel Gendreau, Binjie Xu, Guohua Wu, Yi Gu</dc:creator>
    </item>
    <item>
      <title>ReLoop: Structured Modeling and Behavioral Verification for Reliable LLM-Based Optimization</title>
      <link>https://arxiv.org/abs/2602.15983</link>
      <description>arXiv:2602.15983v1 Announce Type: cross 
Abstract: Large language models (LLMs) can translate natural language into optimization code, but silent failures pose a critical risk: code that executes and returns solver-feasible solutions may encode semantically incorrect formulations, creating a feasibility-correctness gap of up to 90 percentage points on compositional problems. We introduce ReLoop, addressing silent failures from two complementary directions. Structured generation decomposes code production into a four-stage reasoning chain (understand, formalize, synthesize, verify) that mirrors expert modeling practice, with explicit variable-type reasoning and self-verification to prevent formulation errors at their source. Behavioral verification detects errors that survive generation by testing whether the formulation responds correctly to solver-based parameter perturbation, without requiring ground truth -- an external semantic signal that bypasses the self-consistency problem inherent in LLM-based code review. The two mechanisms are complementary: structured generation dominates on complex compositional problems, while behavioral verification becomes the largest single contributor on problems with localized formulation defects. Together with execution recovery via IIS-enhanced diagnostics, ReLoop raises correctness from 22.6% to 31.1% and execution from 72.1% to 100.0% on the strongest model, with consistent gains across five models spanning three paradigms (foundation, SFT, RL) and three benchmarks. We additionally release RetailOpt-190, 190 compositional retail optimization scenarios targeting the multi-constraint interactions where LLMs most frequently fail.</description>
      <guid isPermaLink="false">oai:arXiv.org:2602.15983v1</guid>
      <category>cs.SE</category>
      <category>cs.AI</category>
      <category>cs.LG</category>
      <category>math.OC</category>
      <pubDate>Thu, 19 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <dc:creator>Junbo Jacob Lian, Yujun Sun, Huiling Chen, Chaoyu Zhang, Chung-Piaw Teo</dc:creator>
    </item>
    <item>
      <title>Towards Efficient Constraint Handling in Neural Solvers for Routing Problems</title>
      <link>https://arxiv.org/abs/2602.16012</link>
      <description>arXiv:2602.16012v1 Announce Type: cross 
Abstract: Neural solvers have achieved impressive progress in addressing simple routing problems, particularly excelling in computational efficiency. However, their advantages under complex constraints remain nascent, for which current constraint-handling schemes via feasibility masking or implicit feasibility awareness can be inefficient or inapplicable for hard constraints. In this paper, we present Construct-and-Refine (CaR), the first general and efficient constraint-handling framework for neural routing solvers based on explicit learning-based feasibility refinement. Unlike prior construction-search hybrids that target reducing optimality gaps through heavy improvements yet still struggle with hard constraints, CaR achieves efficient constraint handling by designing a joint training framework that guides the construction module to generate diverse and high-quality solutions well-suited for a lightweight improvement process, e.g., 10 steps versus 5k steps in prior work. Moreover, CaR presents the first use of construction-improvement-shared representation, enabling potential knowledge sharing across paradigms by unifying the encoder, especially in more complex constrained scenarios. We evaluate CaR on typical hard routing constraints to showcase its broader applicability. Results demonstrate that CaR achieves superior feasibility, solution quality, and efficiency compared to both classical and neural state-of-the-art solvers.</description>
      <guid isPermaLink="false">oai:arXiv.org:2602.16012v1</guid>
      <category>cs.AI</category>
      <category>cs.LG</category>
      <category>math.OC</category>
      <pubDate>Thu, 19 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Jieyi Bi, Zhiguang Cao, Jianan Zhou, Wen Song, Yaoxin Wu, Jie Zhang, Yining Ma, Cathy Wu</dc:creator>
    </item>
    <item>
      <title>Autonomous and non-autonomous fixed-time leader-follower consensus for second-order multi-agent systems</title>
      <link>https://arxiv.org/abs/2602.16260</link>
      <description>arXiv:2602.16260v1 Announce Type: cross 
Abstract: This paper addresses the problem of consensus tracking with fixed-time convergence, for leader-follower multi-agent systems with double-integrator dynamics, where only a subset of followers has access to the state of the leader. The control scheme is divided into two steps. The first one is dedicated to the estimation of the leader state by each follower in a distributed way and in a fixed-time. Then, based on the estimate of the leader state, each follower computes its control law to track the leader in a fixed-time. In this paper, two control strategies are investigated and compared to solve the two mentioned steps. The first one is an autonomous protocol which ensures a fixed-time convergence for the observer and for the controller parts where the Upper Bound of the Settling-Time (UBST) is set a priory by the user. Then, the previous strategy is redesigned using time-varying gains to obtain a non-autonomous protocol. This enables to obtain less conservative estimates of the UBST while guaranteeing that the time-varying gains remain bounded. Some numerical examples show the effectiveness of the proposed consensus protocols.</description>
      <guid isPermaLink="false">oai:arXiv.org:2602.16260v1</guid>
      <category>eess.SY</category>
      <category>cs.SY</category>
      <category>math.DS</category>
      <category>math.OC</category>
      <pubDate>Thu, 19 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <arxiv:DOI>10.1007/s11071-020-06075-7</arxiv:DOI>
      <arxiv:journal_reference>Nonlinear Dynamics, Volume 102, Pages 2669 to 2686, 2020</arxiv:journal_reference>
      <dc:creator>Miguel A. Trujillo, Rodrigo Aldana-L\'opez, David Gomez Gutierrez, Michael Defoort, Javier Ruiz Leon, Hector M. Becerra</dc:creator>
    </item>
    <item>
      <title>Separating Oblivious and Adaptive Models of Variable Selection</title>
      <link>https://arxiv.org/abs/2602.16568</link>
      <description>arXiv:2602.16568v1 Announce Type: cross 
Abstract: Sparse recovery is among the most well-studied problems in learning theory and high-dimensional statistics. In this work, we investigate the statistical and computational landscapes of sparse recovery with $\ell_\infty$ error guarantees. This variant of the problem is motivated by \emph{variable selection} tasks, where the goal is to estimate the support of a $k$-sparse signal in $\mathbb{R}^d$. Our main contribution is a provable separation between the \emph{oblivious} (``for each'') and \emph{adaptive} (``for all'') models of $\ell_\infty$ sparse recovery. We show that under an oblivious model, the optimal $\ell_\infty$ error is attainable in near-linear time with $\approx k\log d$ samples, whereas in an adaptive model, $\gtrsim k^2$ samples are necessary for any algorithm to achieve this bound. This establishes a surprising contrast with the standard $\ell_2$ setting, where $\approx k \log d$ samples suffice even for adaptive sparse recovery. We conclude with a preliminary examination of a \emph{partially-adaptive} model, where we show nontrivial variable selection guarantees are possible with $\approx k\log d$ measurements.</description>
      <guid isPermaLink="false">oai:arXiv.org:2602.16568v1</guid>
      <category>math.ST</category>
      <category>cs.DS</category>
      <category>cs.LG</category>
      <category>math.OC</category>
      <category>stat.ML</category>
      <category>stat.TH</category>
      <pubDate>Thu, 19 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Ziyun Chen, Jerry Li, Kevin Tian, Yusong Zhu</dc:creator>
    </item>
    <item>
      <title>Tractable downfall of basis pursuit in structured sparse optimization</title>
      <link>https://arxiv.org/abs/2503.19126</link>
      <description>arXiv:2503.19126v4 Announce Type: replace 
Abstract: The problem of finding the sparsest solution to a linear underdetermined system of equations, often appearing, e.g., in data analysis, optimal control, system identification, or sensor selection problems, is considered. This non-convex problem is commonly solved by convexification via $\ell_1$-norm minimization, known as basis pursuit (BP). In this work, a class of structured matrices, representing the system of equations, is introduced for which (BP) tractably fails to recover the sparsest solution. In particular, this enables efficient identification of matrix columns corresponding to unrecoverable non-zero entries of the sparsest solution and determination of the uniqueness of such a solution. These deterministic guarantees complement popular probabilistic ones and provide insights into the a priori design of sparse optimization problems. As our matrix structures appear naturally in optimal control problems, we exemplify our findings based on a fuel-optimal control problem for a class of discrete-time linear time-invariant systems. Finally, we draw connections of our results to compressed sensing and common basis functions in geometric modeling.</description>
      <guid isPermaLink="false">oai:arXiv.org:2503.19126v4</guid>
      <category>math.OC</category>
      <category>stat.ML</category>
      <pubDate>Thu, 19 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/publicdomain/zero/1.0/</dc:rights>
      <dc:creator>Maya V. Marmary, Christian Grussler</dc:creator>
    </item>
    <item>
      <title>Fast Frank--Wolfe Algorithms with Adaptive Bregman Step-Size for Weakly Convex Functions</title>
      <link>https://arxiv.org/abs/2504.04330</link>
      <description>arXiv:2504.04330v4 Announce Type: replace 
Abstract: We propose Frank--Wolfe (FW) algorithms with an adaptive Bregman step-size strategy for smooth adaptable (also called: relatively smooth) (weakly-) convex functions. This means that the gradient of the objective function is not necessarily Lipschitz continuous, and we only require the smooth adaptable property. Compared with existing FW algorithms, our assumptions are less restrictive. We establish convergence guarantees in various settings, including convergence rates ranging from sublinear to linear, depending on the assumptions for convex and nonconvex objective functions. Assuming that the objective function is weakly convex and satisfies the local quadratic growth condition, we provide both local sublinear and local linear convergence with respect to the primal gap. We also propose a variant of the away-step FW algorithm using Bregman distances over polytopes. We establish faster global convergence (up to a linear rate) for convex optimization under the H\"{o}lder error bound condition and local linear convergence for nonconvex optimization under the local quadratic growth condition. Numerical experiments demonstrate that our proposed FW algorithms outperform existing methods.</description>
      <guid isPermaLink="false">oai:arXiv.org:2504.04330v4</guid>
      <category>math.OC</category>
      <pubDate>Thu, 19 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Shota Takahashi, Sebastian Pokutta, Akiko Takeda</dc:creator>
    </item>
    <item>
      <title>Advancing Averaged Primer Vector Theory with Bang-Bang Control and Eclipsing</title>
      <link>https://arxiv.org/abs/2505.11660</link>
      <description>arXiv:2505.11660v3 Announce Type: replace 
Abstract: Primer vector theory using averaged dynamics is well suited for optimizing low-thrust, many-revolution spacecraft trajectories, but is difficult to implement in a way that maintains both optimality and computational efficiency. An improved model is presented that combines advances from several past works into a general and practical formulation for minimum-fuel, perturbed Keplerian dynamics. The model maintains computational efficiency of dynamics averaging with optimal handling of the eclipsing constraint and bang-bang control through the use of the Leibniz integral rule for multi-arc averaging. A subtle, but important singularity arising from the averaged eclipsing constraint is identified and fixed. A maximum number of six switching function roots per revolution is established within the averaged dynamics. This new theoretical insight provides a practical upper-bound on the number of thrusting arcs required for any low-thrust optimization problem. Variational equations are provided for fast and accurate calculation of the state transition matrix for use in targeting and optimization. The dynamics include generic two-body perturbations and an expanded state to allow for sensitivity calculations with respect to launch date and flight time. The new model is illustrated on a GTO to GEO transfer, including up to 486 revolutions.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.11660v3</guid>
      <category>math.OC</category>
      <pubDate>Thu, 19 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <arxiv:DOI>10.2514/1.G009348</arxiv:DOI>
      <dc:creator>Noah Lifset</dc:creator>
    </item>
    <item>
      <title>Optimal Control and Neural Porkchop Analysis for Low-Thrust Asteroid Rendezvous Mission</title>
      <link>https://arxiv.org/abs/2508.02920</link>
      <description>arXiv:2508.02920v2 Announce Type: replace 
Abstract: This paper presents a comparative study of the applicability and accuracy of optimal control methods and neural network-based estimators in the context of porkchop plots for preliminary asteroid rendezvous mission design. The scenario considered involves a deep-space CubeSat equipped with a low-thrust engine, departing from Earth and rendezvousing with a near-Earth asteroid within a three-year launch window. A low-thrust trajectory optimization model is formulated, incorporating variable specific impulse, maximum thrust, and path constraints. The optimal control problem is efficiently solved using Sequential Convex Programming (SCP) combined with a solution continuation strategy. The neural network framework consists of two models: one predicts the minimum fuel consumption ($\Delta v$), while the other estimates the minimum flight time ($\Delta t$) which is used to assess transfer feasibility. Case results demonstrate that, in simplified scenarios without path constraints, the neural network approach achieves low relative errors across most of the design space and successfully captures the main structural features of the porkchop plots. In cases where the SCP-based continuation method fails due to the presence of multiple local optima, the neural network still provides smooth and globally consistent predictions, significantly improving the efficiency of early-stage asteroid candidate screening. However, the deformation of the feasible region caused by path constraints leads to noticeable discrepancies in certain boundary regions, thereby limiting the applicability of the network in detailed mission design phases. Overall, the integration of neural networks with porkchop plot analysis offers an effective decision-making tool for mission designers and planetary scientists, with significant potential for engineering applications.</description>
      <guid isPermaLink="false">oai:arXiv.org:2508.02920v2</guid>
      <category>math.OC</category>
      <category>cs.SY</category>
      <category>eess.SY</category>
      <pubDate>Thu, 19 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <arxiv:DOI>10.3390/astronautics1010006</arxiv:DOI>
      <arxiv:journal_reference>Astronautics, 2026</arxiv:journal_reference>
      <dc:creator>Zhong Zhang, Niccol\`o Michelotti, Gon\c{c}alo Oliveira Pinho, Yilin Zou, Francesco Topputo</dc:creator>
    </item>
    <item>
      <title>On Zermelo's planar navigation problem for convex bodies, and implications for non-convex optimal routing</title>
      <link>https://arxiv.org/abs/2510.13458</link>
      <description>arXiv:2510.13458v2 Announce Type: replace 
Abstract: We study a generalized version of Zermelo navigation problem where the set of admissible velocities is a general compact convex set, replacing the classical Euclidean ball. After establishing existence results under the natural assumption of weak currents, we derive necessary optimality conditions via Pontryagin maximum principle and convex analysis. Consequently, in the planar case, the domain of any optimal control is shown to be partitioned into regular and singular regimes. In the former, the optimal control is smooth and satisfies a Zermelo-like navigation equation while in the latter it is largely undetermined. A necessary condition that can exclude singular regimes is stated and proved, providing a useful tool in applications. In regular regimes our results extend the classical Zermelo navigation equation to general convex control sets within a non-parametric setting. Furthermore, we discuss direct applications to the case of a non-convex control set. As an application, we develop the relevant case of an affine current. The results are illustrated with examples relevant to sailing and ship routing with asymmetric or sail-assisted propulsion, including the presence of waves.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.13458v2</guid>
      <category>math.OC</category>
      <pubDate>Thu, 19 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Matteo Della Rossa, Lorenzo Freddi, Mattia Pinatto</dc:creator>
    </item>
    <item>
      <title>Lyapunov Functions can Exactly Quantify Rate Performance of Nonlinear Differential Equations</title>
      <link>https://arxiv.org/abs/2601.01538</link>
      <description>arXiv:2601.01538v2 Announce Type: replace 
Abstract: Pointwise-in-time stability notions for Ordinary Differential Equations (ODEs) provide quantitative metrics for system performance by establishing bounds on the rate of decay of the system state in terms of initial condition -- allowing stability to be quantified by e.g. the maximum provable decay rate. Such bounds may be obtained by finding suitable Lyapunov functions using, e.g. Sum-of-Squares (SOS) optimization. While Lyapunov tests have been proposed for numerous pointwise-in-time stability notions, including exponential, rational, and finite-time stability, it is unclear whether these characterizations are able to provide accurate bounds on system performance.
  In this paper, we start by proposing a generalized notion of rate performance -- with exponential, rational, and finite-time decay rates being special cases. Then, for any such notion and rate, we associate a Lyapunov condition which is shown to be necessary and sufficient for a system to achieve that rate. Finally, we show how the proposed conditions can be enforced using SOS programming in the case of exponential, rational, and finite-time stability. Numerical examples in each case demonstrate that the corresponding SOS test can achieve tight bounds on the rate performance with accurate inner bounds on the associated regions of performance.</description>
      <guid isPermaLink="false">oai:arXiv.org:2601.01538v2</guid>
      <category>math.OC</category>
      <category>cs.SY</category>
      <category>eess.SY</category>
      <category>math.CA</category>
      <pubDate>Thu, 19 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Declan S. Jagt, Matthew M. Peet</dc:creator>
    </item>
    <item>
      <title>Composite Optimization using Local Models and Global Approximations</title>
      <link>https://arxiv.org/abs/2602.11594</link>
      <description>arXiv:2602.11594v2 Announce Type: replace 
Abstract: This work presents a unified framework that combines global approximations with locally built models to handle challenging nonconvex and nonsmooth composite optimization problems, including cases involving extended real-valued functions. We show that near-stationary points of the approximating problems converge to stationary points of the original problem under suitable conditions. Building on this, we develop practical algorithms that use tractable convex master programs derived from local models of the approximating problems. The resulting double-loop structure improves global approximations while adapting local models, providing a flexible and implementable approach for a wide class of composite optimization problems. It also lays the groundwork for new algorithmic developments in this domain.</description>
      <guid isPermaLink="false">oai:arXiv.org:2602.11594v2</guid>
      <category>math.OC</category>
      <pubDate>Thu, 19 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Welington de Oliveira, Johannes O. Royset</dc:creator>
    </item>
    <item>
      <title>Learning Gradient Flow: Using Equation Discovery to Accelerate Engineering Optimization</title>
      <link>https://arxiv.org/abs/2602.13513</link>
      <description>arXiv:2602.13513v2 Announce Type: replace 
Abstract: In this work, we investigate the use of data-driven equation discovery for dynamical systems to model and forecast continuous-time dynamics of unconstrained optimization problems. To avoid expensive evaluations of the objective function and its gradient, we leverage trajectory data on the optimization variables to learn the continuous-time dynamics associated with gradient descent, Newton's method, and ADAM optimization. The discovered gradient flows are then solved as a surrogate for the original optimization problem. To this end, we introduce the Learned Gradient Flow (LGF) optimizer, which is equipped to build surrogate models of variable polynomial order in full- or reduced-dimensional spaces at user-defined intervals in the optimization process. We demonstrate the efficacy of this approach on several standard problems from engineering mechanics and scientific machine learning, including two inverse problems, structural topology optimization, and two forward solves with different discretizations. Our results suggest that the learned gradient flows can significantly expedite convergence by capturing critical features of the optimization trajectory while avoiding expensive evaluations of the objective and its gradient.</description>
      <guid isPermaLink="false">oai:arXiv.org:2602.13513v2</guid>
      <category>math.OC</category>
      <category>cs.CE</category>
      <category>cs.LG</category>
      <category>cs.NA</category>
      <category>math.DS</category>
      <category>math.NA</category>
      <pubDate>Thu, 19 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Grant Norman, Conor Rowan, Kurt Maute, Alireza Doostan</dc:creator>
    </item>
    <item>
      <title>Solving Fredholm Integral Equations of the Second Kind via Wasserstein Gradient Flows</title>
      <link>https://arxiv.org/abs/2409.19642</link>
      <description>arXiv:2409.19642v3 Announce Type: replace-cross 
Abstract: Motivated by a recent method for approximate solution of Fredholm equations of the first kind, we develop a corresponding method for a class of Fredholm equations of the \emph{second kind}. In particular, we consider the class of equations for which the solution is a probability measure. The approach centres around specifying a functional whose gradient flow admits a minimizer corresponding to a regularized version of the solution of the underlying equation and using a mean-field particle system to approximately simulate that flow. Theoretical support for the method is presented, along with some illustrative numerical results.</description>
      <guid isPermaLink="false">oai:arXiv.org:2409.19642v3</guid>
      <category>stat.CO</category>
      <category>cs.NA</category>
      <category>math.NA</category>
      <category>math.OC</category>
      <category>stat.ME</category>
      <pubDate>Thu, 19 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Francesca R. Crucinio, Adam M. Johansen</dc:creator>
    </item>
    <item>
      <title>Data-driven geometric parameter optimization for PD-GMRES</title>
      <link>https://arxiv.org/abs/2503.09728</link>
      <description>arXiv:2503.09728v2 Announce Type: replace-cross 
Abstract: Restarted GMRES is a robust and widely used iterative solver for linear systems. The control of the restart parameter is a key task to accelerate convergence and to prevent the well-known stagnation phenomenon. We focus on the Proportional-Derivative GMRES (PD-GMRES), which has been derived using control-theoretic ideas in [Cuevas N\'u\~nez, Schaerer, and Bhaya (2018)] as a versatile method for modifying the restart parameter. Several variants of a quadtree-based geometric optimization approach are proposed to find a best choice of PD-GMRES parameters. We show that the optimized PD-GMRES performs well across a large number of matrix types and we observe superior performance as compared to major other GMRES-based iterative solvers. Moreover, we propose an extension of the PD-GMRES algorithm to further improve performance by controlling the range of values for the restart parameter.</description>
      <guid isPermaLink="false">oai:arXiv.org:2503.09728v2</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <category>math.OC</category>
      <pubDate>Thu, 19 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <arxiv:DOI>10.1016/j.cam.2026.117453</arxiv:DOI>
      <dc:creator>Lennart Duvenbeck, Cedric Riethm\"uller, Christian Rohde</dc:creator>
    </item>
    <item>
      <title>Availability is all you need: achieving optimal regret with minimal information for dynamic matching</title>
      <link>https://arxiv.org/abs/2503.09762</link>
      <description>arXiv:2503.09762v3 Announce Type: replace-cross 
Abstract: We study a centralized discrete-time dynamic two-way matching model with finitely many agent types. Agents arrive stochastically over time and join their type-dedicated queues waiting to be matched. We focus on availability-based policies that make matching decisions based solely on agent availability across types (i.e., whether queues are empty or not), rather than relying on complete queue-length information (e.g., the longest-queue policy). We aim to achieve constant regret at all times with optimal scaling in terms of the general position gap, $\epsilon$, which measures the distance of the fluid relaxation from degeneracy.
  We classify availability-based policies into global and local policies based on the scope of information they utilize. First, for general networks (possibly cyclic), we propose a global availability-based policy, probabilistic matching, and prove that it achieves the optimal all-time regret scaling of $O(\epsilon^{-1})$, matching the known lower bound established by [KAG24]. Second, for acyclic networks, we focus on the class of local availability-based policies, specifically static priority policies that prioritize matches based on a fixed order. Within this class, we derive the first explicit regret bound for the previously proposed tree priority policy, showing all-time regret scaling of $O(\epsilon^{-(d+1)/2})$, where $d$ is the network depth. Next, we introduce a new truncated tree priority policy and prove that it is the first static priority policy to achieve the optimal all-time regret scaling of $O(\epsilon^{-1})$. These policies are appealing for matching systems such as queueing and load balancing; they reduce operational costs by using minimal information while effectively balancing the trade-off between immediate and future rewards.</description>
      <guid isPermaLink="false">oai:arXiv.org:2503.09762v3</guid>
      <category>cs.DS</category>
      <category>math.OC</category>
      <category>math.PR</category>
      <pubDate>Thu, 19 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>S\"uleyman Kerimov, Pengyu Qian, Mingwei Yang, Sophie H. Yu</dc:creator>
    </item>
    <item>
      <title>Benchmarking Stochastic Approximation Algorithms for Fairness-Constrained Training of Deep Neural Networks</title>
      <link>https://arxiv.org/abs/2507.04033</link>
      <description>arXiv:2507.04033v2 Announce Type: replace-cross 
Abstract: The ability to train Deep Neural Networks (DNNs) with constraints is instrumental in improving the fairness of modern machine-learning models. Many algorithms have been analysed in recent years, and yet there is no standard, widely accepted method for the constrained training of DNNs. In this paper, we provide a challenging benchmark of real-world large-scale fairness-constrained learning tasks, built on top of the US Census (Folktables). We point out the theoretical challenges of such tasks and review the main approaches in stochastic approximation algorithms. Finally, we demonstrate the use of the benchmark by implementing and comparing three recently proposed, but as-of-yet unimplemented, algorithms both in terms of optimization performance, and fairness improvement. We release the code of the benchmark as a Python package at https://github.com/humancompatible/train.</description>
      <guid isPermaLink="false">oai:arXiv.org:2507.04033v2</guid>
      <category>cs.LG</category>
      <category>cs.CY</category>
      <category>math.OC</category>
      <category>stat.ML</category>
      <pubDate>Thu, 19 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <arxiv:journal_reference>14th International Conference on Learning Representations, 2026</arxiv:journal_reference>
      <dc:creator>Andrii Kliachkin, Jana Lep\v{s}ov\'a, Gilles Bareilles, Jakub Mare\v{c}ek</dc:creator>
    </item>
    <item>
      <title>Pinet: Optimizing hard-constrained neural networks with orthogonal projection layers</title>
      <link>https://arxiv.org/abs/2508.10480</link>
      <description>arXiv:2508.10480v2 Announce Type: replace-cross 
Abstract: We introduce an output layer for neural networks that ensures satisfaction of convex constraints. Our approach, $\Pi$net, leverages operator splitting for rapid and reliable projections in the forward pass, and the implicit function theorem for backpropagation. We deploy $\Pi$net as a feasible-by-design optimization proxy for parametric constrained optimization problems and obtain modest-accuracy solutions faster than traditional solvers when solving a single problem, and significantly faster for a batch of problems. We surpass state-of-the-art learning approaches by orders of magnitude in terms of training time, solution quality, and robustness to hyperparameter tuning, while maintaining similar inference times. Finally, we tackle multi-vehicle motion planning with non-convex trajectory preferences and provide $\Pi$net as a GPU-ready package implemented in JAX.</description>
      <guid isPermaLink="false">oai:arXiv.org:2508.10480v2</guid>
      <category>cs.LG</category>
      <category>cs.AI</category>
      <category>math.OC</category>
      <pubDate>Thu, 19 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Panagiotis D. Grontas, Antonio Terpin, Efe C. Balta, Raffaello D'Andrea, John Lygeros</dc:creator>
    </item>
    <item>
      <title>Q3R: Quadratic Reweighted Rank Regularizer for Effective Low-Rank Training</title>
      <link>https://arxiv.org/abs/2511.04485</link>
      <description>arXiv:2511.04485v2 Announce Type: replace-cross 
Abstract: Parameter-efficient training based on low-rank optimization has become a highly successful tool for fine-tuning large deep learning models. However, these methods often fail for low-rank pre-training, where simultaneously maintaining low-rank weight structure and optimizing the task objective remains challenging. We propose the $\textit{Quadratic Reweighted Rank Regularizer}$ ($\texttt{Q3R}$), which leads to a novel low-rank-inducing training strategy inspired by the Iteratively Reweighted Least Squares (IRLS) framework. $\texttt{Q3R}$ is based on a quadratic regularizer term that majorizes a smoothed log-determinant rank surrogate. Unlike other low-rank training techniques, $\texttt{Q3R}$ can train weight matrices to prescribed low target ranks while achieving predictive performance comparable to dense models, with small computational overhead and full compatibility with existing architectures. For example, we demonstrate a $\texttt{Q3R}$-regularized ViT-Tiny experiment where truncating the model to $60\%$ and $80\%$ of its parameters results in only minor absolute accuracy drops of $1.3\%$ and $4\%$, respectively, on CIFAR-10. We confirm the efficacy of $\texttt{Q3R}$ on Transformers across both vision and language tasks, including low-rank fine-tuning.</description>
      <guid isPermaLink="false">oai:arXiv.org:2511.04485v2</guid>
      <category>cs.LG</category>
      <category>cs.AI</category>
      <category>math.OC</category>
      <pubDate>Thu, 19 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-sa/4.0/</dc:rights>
      <arxiv:journal_reference>39th Conference on Neural Information Processing Systems (NeurIPS 2025)</arxiv:journal_reference>
      <dc:creator>Ipsita Ghosh, Ethan Nguyen, Christian K\"ummerle</dc:creator>
    </item>
    <item>
      <title>Communication Compression for Distributed Learning with Aggregate and Server-Guided Feedback</title>
      <link>https://arxiv.org/abs/2512.22623</link>
      <description>arXiv:2512.22623v2 Announce Type: replace-cross 
Abstract: Distributed learning, particularly Federated Learning (FL), faces a significant bottleneck in the communication cost, particularly the uplink transmission of client-to-server updates, which is often constrained by asymmetric bandwidth limits at the edge. Biased compression techniques are effective in practice, but require error feedback mechanisms to provide theoretical guarantees and to ensure convergence when compression is aggressive. Standard error feedback, however, relies on client-specific control variates, which violates user privacy and is incompatible with stateless clients common in large-scale FL. This paper proposes two novel frameworks that enable biased compression without client-side state or control variates. The first, Compressed Aggregate Feedback (CAFe), uses the globally aggregated update from the previous round as a shared control variate for all clients. The second, Server-Guided Compressed Aggregate Feedback (CAFe-S), extends this idea to scenarios where the server possesses a small private dataset; it generates a server-guided candidate update to be used as a more accurate predictor. We consider Distributed Gradient Descent (DGD) as a representative algorithm and analytically prove CAFe's superiority to Distributed Compressed Gradient Descent (DCGD) with biased compression in the non-convex regime with bounded gradient dissimilarity. We further prove that CAFe-S converges to a stationary point, with a rate that improves as the server's data become more representative. Experimental results in FL scenarios validate the superiority of our approaches over existing compression schemes.</description>
      <guid isPermaLink="false">oai:arXiv.org:2512.22623v2</guid>
      <category>cs.LG</category>
      <category>eess.SP</category>
      <category>math.OC</category>
      <pubDate>Thu, 19 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Tomas Ortega, Chun-Yin Huang, Xiaoxiao Li, Hamid Jafarkhani</dc:creator>
    </item>
    <item>
      <title>Imitation Learning for Combinatorial Optimisation under Uncertainty</title>
      <link>https://arxiv.org/abs/2601.05383</link>
      <description>arXiv:2601.05383v3 Announce Type: replace-cross 
Abstract: Imitation learning (IL) provides a data-driven framework for approximating policies for large-scale combinatorial optimisation problems formulated as sequential decision problems (SDPs), where exact solution methods are computationally intractable. A central but underexplored aspect of IL in this context is the role of the \emph{expert} that generates training demonstrations. Existing studies employ a wide range of expert constructions, yet lack a unifying framework to characterise their modelling assumptions, computational properties, and impact on learning performance. This paper introduces a systematic taxonomy of experts for imitation learning in combinatorial optimisation under uncertainty. The literature is classified along three principal dimensions: (i) treatment of uncertainty; (ii) level of optimality, distinguishing task-optimal and approximate experts; and (iii) interaction mode with the learner, ranging from one-shot supervision to iterative, interactive schemes. We further identify additional categories capturing other relevant expert characteristics. Building on this taxonomy, we propose a generalised Dataset Aggregation (DAgger) framework that accommodates multiple expert queries, expert aggregation, and flexible interaction strategies.
  The proposed framework is evaluated on a dynamic physician-to-patient assignment problem with stochastic arrivals and capacity constraints. Computational experiments compare learning outcomes across expert types and interaction regimes. The results show that policies learned from stochastic experts consistently outperform those learned from deterministic or full-information experts, while interactive learning improves solution quality using fewer expert demonstrations. Aggregated deterministic experts provide an effective alternative when stochastic optimisation becomes computationally challenging.</description>
      <guid isPermaLink="false">oai:arXiv.org:2601.05383v3</guid>
      <category>cs.LG</category>
      <category>math.OC</category>
      <pubDate>Thu, 19 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Prakash Gawas, Antoine Legrain, Louis-Martin Rousseau</dc:creator>
    </item>
    <item>
      <title>Quantitative convergence rates for extended mean field games with volatility control</title>
      <link>https://arxiv.org/abs/2601.07028</link>
      <description>arXiv:2601.07028v2 Announce Type: replace-cross 
Abstract: We investigate the convergence of symmetric stochastic differential games with interactions via control, where the volatility terms of both idiosyncratic and common noises are controlled. We apply the stochastic maximum principle, following the approach of Lauri\`{e}re and Tangpi, to reduce the convergence analysis to the study of forward-backward propagation of chaos. Under the standard monotonicity conditions, we derive quantitative convergence rates for open-loop Nash equilibria of $N$-player stochastic differential games toward the corresponding mean field equilibrium. As a prerequisite, we also establish the well-posedness of the conditional McKean--Vlasov forward-backward stochastic differential equations by the method of continuation. Moreover, we analyze a specific class of linear-quadratic settings to demonstrate the applicability of our main result.</description>
      <guid isPermaLink="false">oai:arXiv.org:2601.07028v2</guid>
      <category>math.PR</category>
      <category>math.OC</category>
      <pubDate>Thu, 19 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Erhan Bayraktar, Hiroaki Horikawa</dc:creator>
    </item>
    <item>
      <title>A uniformity principle for spatial matching</title>
      <link>https://arxiv.org/abs/2601.13426</link>
      <description>arXiv:2601.13426v3 Announce Type: replace-cross 
Abstract: Platforms matching spatially distributed supply to demand face a fundamental design choice: given a fixed total budget of service range, how should it be allocated across supply nodes ex ante, i.e. before supply and demand locations are realized, to maximize fulfilled demand? We model this problem using bipartite random geometric graphs where $n$ supply and $m$ demand nodes are uniformly distributed on $[0,1]^k$ ($k \ge 1$), and edges form when demand falls within a supply node's service region, the volume of which is determined by its service range. Since each supply node serves at most one demand, platform performance is determined by the expected size of a maximum matching. We establish a uniformity principle: whenever one service range allocation is more uniform than the other, the more uniform allocation yields a larger expected matching. This principle emerges from diminishing marginal returns to range expanding service range, and limited interference between supply nodes due to bounded ranges naturally fragmenting the graph. For $k=1$, we further characterize the expected matching size through a Markov chain embedding and derive closed-form expressions for special cases. Our results provide theoretical guidance for service-range allocation and incentive design in ride-hailing, on-demand labor markets, and drone delivery platforms, highlighting the benefits of reducing disparities in supply-side flexibility.</description>
      <guid isPermaLink="false">oai:arXiv.org:2601.13426v3</guid>
      <category>math.PR</category>
      <category>cs.DS</category>
      <category>econ.GN</category>
      <category>math.OC</category>
      <category>q-fin.EC</category>
      <pubDate>Thu, 19 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Taha Ameen, Flore Sentenac, Sophie H. Yu</dc:creator>
    </item>
    <item>
      <title>High-dimensional learning dynamics of multi-pass Stochastic Gradient Descent in multi-index models</title>
      <link>https://arxiv.org/abs/2601.21093</link>
      <description>arXiv:2601.21093v2 Announce Type: replace-cross 
Abstract: We study the learning dynamics of a multi-pass, mini-batch Stochastic Gradient Descent (SGD) procedure for empirical risk minimization in high-dimensional multi-index models with isotropic random data. In an asymptotic regime where the sample size $n$ and data dimension $d$ increase proportionally, for any sub-linear batch size $\kappa \asymp n^\alpha$ where $\alpha \in [0,1)$, and for a commensurate ``critical'' scaling of the learning rate, we provide an asymptotically exact characterization of the coordinate-wise dynamics of SGD. This characterization takes the form of a system of dynamical mean-field equations, driven by a scalar Poisson jump process that represents the asymptotic limit of SGD sampling noise. We develop an analogous characterization of the Stochastic Modified Equation (SME) which provides a Gaussian diffusion approximation to SGD.
  Our analyses imply that the limiting dynamics for SGD are the same for any batch size scaling $\alpha \in [0,1)$, and that under a commensurate scaling of the learning rate, dynamics of SGD, SME, and gradient flow are mutually distinct, with those of SGD and SME coinciding in the special case of a linear model. We recover a known dynamical mean-field characterization of gradient flow in a limit of small learning rate, and of one-pass/online SGD in a limit of increasing sample size $n/d \to \infty$.</description>
      <guid isPermaLink="false">oai:arXiv.org:2601.21093v2</guid>
      <category>stat.ML</category>
      <category>cs.LG</category>
      <category>math.OC</category>
      <category>math.PR</category>
      <category>math.ST</category>
      <category>stat.TH</category>
      <pubDate>Thu, 19 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Zhou Fan, Leda Wang</dc:creator>
    </item>
    <item>
      <title>The matrix-vector complexity of $Ax=b$</title>
      <link>https://arxiv.org/abs/2602.04842</link>
      <description>arXiv:2602.04842v2 Announce Type: replace-cross 
Abstract: Matrix--vector algorithms, particularly Krylov subspace methods, are widely viewed as the most effective algorithms for solving large systems of linear equations. This paper establishes lower bounds on the worst-case number of matrix--vector products needed by such an algorithm to approximately solve a general linear system. The first main result is that, for any matrix--vector algorithm which is allowed the use of randomization and can perform products with both a matrix and its transpose, $\Omega(\kappa \log(1/\varepsilon))$ matrix--vector products are necessary to solve a linear system with condition number $\kappa$ to accuracy $\varepsilon$, matching an upper bound for conjugate gradient on the normal equations. The second main result is that one-sided algorithms, which lack access to the transpose, must use $n$ matrix--vector products to solve an $n \times n$ linear system, even when the problem is perfectly conditioned. Both main results include explicit constants that match known upper bounds up to a factor of four. These results rigorously demonstrate the limitations of matrix--vector algorithms and confirm the optimality of widely used Krylov subspace algorithms.</description>
      <guid isPermaLink="false">oai:arXiv.org:2602.04842v2</guid>
      <category>cs.DS</category>
      <category>cs.NA</category>
      <category>math.NA</category>
      <category>math.OC</category>
      <pubDate>Thu, 19 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Micha{\l} Derezi\'nski, Ethan N. Epperly, Raphael A. Meyer</dc:creator>
    </item>
    <item>
      <title>Logarithmic-time Schedules for Scaling Language Models with Momentum</title>
      <link>https://arxiv.org/abs/2602.05298</link>
      <description>arXiv:2602.05298v2 Announce Type: replace-cross 
Abstract: In practice, the hyperparameters $(\beta_1, \beta_2)$ and weight-decay $\lambda$ in AdamW are typically kept at fixed values. Is there any reason to do otherwise? We show that for large-scale language model training, the answer is yes: by exploiting the power-law structure of language data, one can design time-varying schedules for $(\beta_1, \beta_2, \lambda)$ that deliver substantial performance gains.
  We study logarithmic-time scheduling, in which the optimizer's gradient memory horizon grows with training time. Although naive variants of this are unstable, we show that suitable damping mechanisms restore stability while preserving the benefits of longer memory. Based on this, we present ADANA, an AdamW-like optimizer that couples log-time schedules with explicit damping to balance stability and performance. We empirically evaluate ADANA across transformer scalings (45M to 2.6B parameters), comparing against AdamW, Muon, and AdEMAMix.
  When properly tuned, ADANA achieves up to 40% compute efficiency relative to a tuned AdamW, with gains that persist--and even improve--as model scale increases. We further show that similar benefits arise when applying logarithmic-time scheduling to AdEMAMix, and that logarithmic-time weight-decay alone can yield significant improvements. Finally, we present variants of ADANA that mitigate potential failure modes and improve robustness.</description>
      <guid isPermaLink="false">oai:arXiv.org:2602.05298v2</guid>
      <category>stat.ML</category>
      <category>cs.LG</category>
      <category>math.OC</category>
      <pubDate>Thu, 19 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Damien Ferbach, Courtney Paquette, Gauthier Gidel, Katie Everett, Elliot Paquette</dc:creator>
    </item>
  </channel>
</rss>
