<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>cs.DM updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/cs.DM</link>
    <description>cs.DM updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/cs.DM" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Wed, 19 Jun 2024 04:05:39 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Wed, 19 Jun 2024 00:00:00 -0400</pubDate>
    <skipDays>
      <day>Sunday</day>
      <day>Saturday</day>
    </skipDays>
    <item>
      <title>Pushing the Frontier on Approximate EFX Allocations</title>
      <link>https://arxiv.org/abs/2406.12413</link>
      <description>arXiv:2406.12413v1 Announce Type: cross 
Abstract: We study the problem of allocating a set of indivisible goods to a set of agents with additive valuation functions, aiming to achieve approximate envy-freeness up to any good ($\alpha$-EFX). The state-of-the-art results on the problem include that (exact) EFX allocations exist when (a) there are at most three agents, or (b) the agents' valuation functions can take at most two values, or (c) the agents' valuation functions can be represented via a graph. For $\alpha$-EFX, it is known that a $0.618$-EFX allocation exists for any number of agents with additive valuation functions. In this paper, we show that $2/3$-EFX allocations exist when (a) there are at most \emph{seven agents}, (b) the agents' valuation functions can take at most \emph{three values}, or (c) the agents' valuation functions can be represented via a \emph{multigraph}. Our results can be interpreted in two ways. First, by relaxing the notion of EFX to $2/3$-EFX, we obtain existence results for strict generalizations of the settings for which exact EFX allocations are known to exist. Secondly, by imposing restrictions on the setting, we manage to beat the barrier of $0.618$ and achieve an approximation guarantee of $2/3$. Therefore, our results push the \emph{frontier} of existence and computation of approximate EFX allocations, and provide insights into the challenges of settling the existence of exact EFX allocations.</description>
      <guid isPermaLink="false">oai:arXiv.org:2406.12413v1</guid>
      <category>cs.GT</category>
      <category>cs.AI</category>
      <category>cs.DM</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Georgios Amanatidis, Aris Filos-Ratsikas, Alkmini Sgouritsa</dc:creator>
    </item>
    <item>
      <title>Small maximal clusters are very unlikely in critical random graphs</title>
      <link>https://arxiv.org/abs/2406.12451</link>
      <description>arXiv:2406.12451v1 Announce Type: cross 
Abstract: We describe a probabilistic methodology, based on random walk estimates, to obtain exponential upper bounds for the probability of observing unusually small maximal components in two classical (near-)critical random graph models. More specifically, we analyse the near-critical Erd\H{o}s-R\'enyi model $\mathbb{G}(n,p)$ and the random graph $\mathbb{G}(n,d,p)$ obtained by performing near-critical $p$-bond percolation on a simple random $d$-regular graph and show that, for each one of these models, the probability that the size of a largest component is smaller than $n^{2/3}/A$ is at most of order $\exp(-A^{3/2})$. The exponent $3/2$ is known to be optimal for the near-critical $\mathbb{G}(n,p)$ random graph, whereas for the near-critical $\mathbb{G}(n,d,p)$ model the best known upper bound for the above probability was of order $A^{-3/5}$. As a secondary result we show, by means of an optimized version of the martingale method of Nachmias and Peres, that the above probability of observing an unusually small maximal component is at most of order $\exp(-A^{3/5})$ in other two critical models, namely a random intersection graph and the quantum random graph; this stretched-exponential bounds also improve upon the known (polynomial) bounds available for these other two critical models.</description>
      <guid isPermaLink="false">oai:arXiv.org:2406.12451v1</guid>
      <category>math.PR</category>
      <category>cs.DM</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Umberto De Ambroggio</dc:creator>
    </item>
    <item>
      <title>Axioms for Distanceless Graph Partitioning</title>
      <link>https://arxiv.org/abs/2309.09386</link>
      <description>arXiv:2309.09386v2 Announce Type: replace 
Abstract: In 2002, Kleinberg proposed three axioms for distance-based clustering, and proved that it was impossible for a clustering method to satisfy all three. While there has been much subsequent work examining and modifying these axioms for distance-based clustering, little work has been done to explore axioms relevant to the graph partitioning problem when the graph is unweighted and given without a distance matrix. Here, we propose and explore axioms for graph partitioning for this case, including modifications of Kleinberg's axioms and three others: two axioms relevant to the ``Resolution Limit'' and one addressing well-connectedness. We prove that clustering under the Constant Potts Model satisfies all the axioms, while Modularity clustering and iterative k-core both fail many axioms we pose. These theoretical properties of the clustering methods are relevant both for theoretical investigation as well as to practitioners considering which methods to use for their domain science studies.</description>
      <guid isPermaLink="false">oai:arXiv.org:2309.09386v2</guid>
      <category>cs.DM</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>James Willson, Tandy Warnow</dc:creator>
    </item>
    <item>
      <title>Integrated Planning in Hospitals: A Review</title>
      <link>https://arxiv.org/abs/2307.05258</link>
      <description>arXiv:2307.05258v2 Announce Type: replace-cross 
Abstract: Efficient planning of scarce resources in hospitals is a challenging task for which a large variety of Operations Research and Management Science approaches have been developed since the 1950s. While efficient planning of single resources such as operating rooms, beds, or specific types of staff can already lead to enormous efficiency gains, integrated planning of several resources has been shown to hold even greater potential, and a large number of integrated planning approaches have been presented in the literature over the past decades. This paper provides the first literature review that focuses specifically on the Operations Research and Management Science literature related to integrated planning of different resources in hospitals. We collect the relevant literature and analyze it regarding different aspects such as uncertainty modeling and the use of real-life data. Several cross comparisons reveal interesting insights concerning, e.g., relations between the modeling and solution methods used and the practical implementation of the approaches developed. Moreover, we provide a high-level taxonomy for classifying different resource-focused integration approaches and point out gaps in the literature as well as promising directions for future research.</description>
      <guid isPermaLink="false">oai:arXiv.org:2307.05258v2</guid>
      <category>cs.AI</category>
      <category>cs.DM</category>
      <category>math.OC</category>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Sebastian Rachuba, Melanie Reuter-Oppermann, Clemens Thielen</dc:creator>
    </item>
    <item>
      <title>Completeness in the Polynomial Hierarchy for many natural Problems in Bilevel and Robust Optimization</title>
      <link>https://arxiv.org/abs/2311.10540</link>
      <description>arXiv:2311.10540v2 Announce Type: replace-cross 
Abstract: Because $\Sigma^p_2$- and $\Sigma^p_3$-hardness proofs are usually tedious and difficult, not so many complete problems for these classes are known. This is especially true in the areas of min-max regret robust optimization, network interdiction, most vital vertex problems, blocker problems, and two-stage adjustable robust optimization problems. Even though these areas are well-researched for over two decades and one would naturally expect many (if not most) of the problems occurring in these areas to be complete for the above classes, almost no completeness results exist in the literature. We address this lack of knowledge by introducing over 70 new $\Sigma^p_2$-complete and $\Sigma^p_3$-complete problems. We achieve this result by proving a new meta-theorem, which shows $\Sigma^p_2$- and $\Sigma^p_3$-completeness simultaneously for a huge class of problems. The majority of all earlier publications on $\Sigma^p_2$- and $\Sigma^p_3$-completeness in said areas are special cases of our meta-theorem. Our precise result is the following: We introduce a large list of problems for which the meta-theorem is applicable (including clique, vertex cover, knapsack, TSP, facility location and many more). For every problem on this list, we show: The interdiction/minimum cost blocker/most vital nodes problem (with element costs) is $\Sigma^p_2$-complete. The min-max-regret problem with interval uncertainty is $\Sigma^p_2$-complete. The two-stage adjustable robust optimization problem with discrete budgeted uncertainty is $\Sigma^p_3$-complete. In summary, our work reveals the interesting insight that a large amount of NP-complete problems have the property that their min-max versions are 'automatically' $\Sigma^p_2$-complete.</description>
      <guid isPermaLink="false">oai:arXiv.org:2311.10540v2</guid>
      <category>cs.CC</category>
      <category>cs.DM</category>
      <category>math.OC</category>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Christoph Gr\"une, Lasse Wulf</dc:creator>
    </item>
    <item>
      <title>Isomorphism for Tournaments of Small Twin Width</title>
      <link>https://arxiv.org/abs/2312.02048</link>
      <description>arXiv:2312.02048v2 Announce Type: replace-cross 
Abstract: We prove that isomorphism of tournaments of twin width at most $k$ can be decided in time $k^{O(\log k)}n^{O(1)}$. This implies that the isomorphism problem for classes of tournaments of bounded or moderately growing twin width is in polynomial time. By comparison, there are classes of undirected graphs of bounded twin width that are isomorphism complete, that is, the isomorphism problem for the classes is as hard as the general graph isomorphism problem. Twin width is a graph parameter that has been introduced only recently (Bonnet et al., FOCS 2020), but has received a lot of attention in structural graph theory since then. On directed graphs, it is functionally smaller than clique width. We prove that on tournaments (but not on general directed graphs) it is also functionally smaller than directed tree width (and thus, the same also holds for cut width and directed path width). Hence, our result implies that tournament isomorphism testing is also fixed-parameter tractable when parameterized by any of these parameters.
  Our isomorphism algorithm heavily employs group-theoretic techniques. This seems to be necessary: as a second main result, we show that the combinatorial Weisfeiler-Leman algorithm does not decide isomorphism of tournaments of twin width at most 35 if its dimension is $o(n)$. (Throughout this abstract, $n$ is the order of the input graphs.)</description>
      <guid isPermaLink="false">oai:arXiv.org:2312.02048v2</guid>
      <category>cs.DS</category>
      <category>cs.DM</category>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Martin Grohe, Daniel Neuen</dc:creator>
    </item>
    <item>
      <title>Partitioning a Planar Graph into two Triangle-Forests</title>
      <link>https://arxiv.org/abs/2401.15394</link>
      <description>arXiv:2401.15394v2 Announce Type: replace-cross 
Abstract: We show that the vertices of every planar graph can be partitioned into two sets, each inducing a so-called triangle-forest, i.e., a graph with no cycles of length more than three. We further discuss extensions to locally planar graphs.</description>
      <guid isPermaLink="false">oai:arXiv.org:2401.15394v2</guid>
      <category>math.CO</category>
      <category>cs.DM</category>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Kolja Knauer, Cl\'ement Rambaud, Torsten Ueckerdt</dc:creator>
    </item>
    <item>
      <title>Fast Adaptive Meta-Heuristic for Large-Scale Facility Location Problem</title>
      <link>https://arxiv.org/abs/2406.07382</link>
      <description>arXiv:2406.07382v2 Announce Type: replace-cross 
Abstract: Facility location problems have been a major research area of interest in the last several decades. In particular, uncapacitated location problems (ULP) have enormous applications. Variations of ULP often appear, especially as large-scale subproblems in more complex combinatorial optimization problems. Although many researchers have studied different versions of ULP (e.g., uncapacitated facility location problem (UCFLP) and p-Median problem), most of these authors have considered small to moderately sized problems. In this paper, we address the ULP and provide a fast adaptive meta-heuristic for large-scale problems. The approach is based on critical event memory tabu search. For the diversification component of the algorithm, we have chosen a procedure based on a sequencing problem commonly used for traveling salesman-type problems. The efficacy of this approach is evaluated across a diverse range of benchmark problems sourced from the Internet, with a comprehensive comparison against four prominent algorithms in the literature. The proposed adaptive critical event tabu search (ACETS) demonstrates remarkable effectiveness for large-scale problems. The algorithm successfully solved all problems optimally within a short computing time. Notably, ACETS discovered three best new solutions for benchmark problems, specifically for Asymmetric 500A-1, Asymmetric 750A-1, and Symmetric 750B-4, underscoring its innovative and robust nature.</description>
      <guid isPermaLink="false">oai:arXiv.org:2406.07382v2</guid>
      <category>math.OC</category>
      <category>cs.DM</category>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Bahram Alidaee, Haibo Wang</dc:creator>
    </item>
  </channel>
</rss>
