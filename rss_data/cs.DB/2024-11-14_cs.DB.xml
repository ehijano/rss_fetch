<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>cs.DB updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/cs.DB</link>
    <description>cs.DB updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/cs.DB" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Thu, 14 Nov 2024 05:00:20 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Thu, 14 Nov 2024 00:00:00 -0500</pubDate>
    <skipDays>
      <day>Sunday</day>
      <day>Saturday</day>
    </skipDays>
    <item>
      <title>GraphAide: Advanced Graph-Assisted Query and Reasoning System</title>
      <link>https://arxiv.org/abs/2411.08041</link>
      <description>arXiv:2411.08041v1 Announce Type: new 
Abstract: Curating knowledge from multiple siloed sources that contain both structured and unstructured data is a major challenge in many real-world applications. Pattern matching and querying represent fundamental tasks in modern data analytics that leverage this curated knowledge. The development of such applications necessitates overcoming several research challenges, including data extraction, named entity recognition, data modeling, and designing query interfaces. Moreover, the explainability of these functionalities is critical for their broader adoption.
  The emergence of Large Language Models (LLMs) has accelerated the development lifecycle of new capabilities. Nonetheless, there is an ongoing need for domain-specific tools tailored to user activities. The creation of digital assistants has gained considerable traction in recent years, with LLMs offering a promising avenue to develop such assistants utilizing domain-specific knowledge and assumptions.
  In this context, we introduce an advanced query and reasoning system, GraphAide, which constructs a knowledge graph (KG) from diverse sources and allows to query and reason over the resulting KG. GraphAide harnesses both the KG and LLMs to rapidly develop domain-specific digital assistants. It integrates design patterns from retrieval augmented generation (RAG) and the semantic web to create an agentic LLM application. GraphAide underscores the potential for streamlined and efficient development of specialized digital assistants, thereby enhancing their applicability across various domains.</description>
      <guid isPermaLink="false">oai:arXiv.org:2411.08041v1</guid>
      <category>cs.DB</category>
      <category>cs.AI</category>
      <pubDate>Thu, 14 Nov 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Sumit Purohit, George Chin, Patrick S Mackey, Joseph A Cottam</dc:creator>
    </item>
    <item>
      <title>FaaS and Furious: abstractions and differential caching for efficient data pre-processing</title>
      <link>https://arxiv.org/abs/2411.08203</link>
      <description>arXiv:2411.08203v1 Announce Type: new 
Abstract: Data pre-processing pipelines are the bread and butter of any successful AI project. We introduce a novel programming model for pipelines in a data lakehouse, allowing users to interact declaratively with assets in object storage. Motivated by real-world industry usage patterns, we exploit these new abstractions with a columnar and differential cache to maximize iteration speed for data scientists, who spent most of their time in pre-processing - adding or removing features, restricting or relaxing time windows, wrangling current or older datasets. We show how the new cache works transparently across programming languages, schemas and time windows, and provide preliminary evidence on its efficiency on standard data workloads.</description>
      <guid isPermaLink="false">oai:arXiv.org:2411.08203v1</guid>
      <category>cs.DB</category>
      <pubDate>Thu, 14 Nov 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Jacopo Tagliabue, Ryan Curtin, Ciro Greco</dc:creator>
    </item>
    <item>
      <title>Lua API and benchmark design using 3n+1 sequences: Comparing API elegance and raw speed in Redis and YottaDB databases</title>
      <link>https://arxiv.org/abs/2411.08206</link>
      <description>arXiv:2411.08206v1 Announce Type: new 
Abstract: Elegance of a database API matters to the programmer. Frequently, database APIs provide rudimentary functionality without thinking about the programmer's desire for elegant yet efficient syntax. This article discusses API design that is both elegant and efficient. It does so, firstly, by comparing the Lua APIs for two separate databases, Redis and YottaDB. Secondly, it benchmarks both databases using each API to implement a 3n+1 sequence generator (of Collatz Conjecture fame) against both databases. It will cover the eccentricities of the Lua APIs, the databases, and the nifty choice of benchmark tool. Finally, the benchmark results are presented showing the respective speed benefits of each database's unique design.</description>
      <guid isPermaLink="false">oai:arXiv.org:2411.08206v1</guid>
      <category>cs.DB</category>
      <category>cs.PL</category>
      <pubDate>Thu, 14 Nov 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-sa/4.0/</dc:rights>
      <dc:creator>Berwyn Hoyt</dc:creator>
    </item>
    <item>
      <title>A Decidable Case of Query Determinacy: Project-Select Views</title>
      <link>https://arxiv.org/abs/2411.08874</link>
      <description>arXiv:2411.08874v1 Announce Type: new 
Abstract: Query determinacy is decidable for project-select views and a project-select-join query with no self joins, as long as the selection predicates are in a first-order theory for which satisfiability is decidable.</description>
      <guid isPermaLink="false">oai:arXiv.org:2411.08874v1</guid>
      <category>cs.DB</category>
      <pubDate>Thu, 14 Nov 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Wen Zhang, Aurojit Panda, Mooly Sagiv, Scott Shenker</dc:creator>
    </item>
    <item>
      <title>DBgDel: Database-Enhanced Gene Deletion Framework for Growth-Coupled Production in Genome-Scale Metabolic Models</title>
      <link>https://arxiv.org/abs/2411.08077</link>
      <description>arXiv:2411.08077v1 Announce Type: cross 
Abstract: When simulating metabolite productions with genome-scale constraint-based metabolic models, gene deletion strategies are necessary to achieve growth-coupled production, which means cell growth and target metabolite production occur simultaneously. Since obtaining gene deletion strategies for large genome-scale models suffers from significant computational time, it is necessary to develop methods to mitigate this computational burden. In this study, we introduce a novel framework for computing gene deletion strategies. The proposed framework first mines related databases to extract prior information about gene deletions for growth-coupled production. It then integrates the extracted information with downstream algorithms to narrow down the algorithmic search space, resulting in highly efficient calculations on genome-scale models. Computational experiment results demonstrated that our framework can compute stoichiometrically feasible gene deletion strategies for numerous target metabolites, showcasing a noteworthy improvement in computational efficiency. Specifically, our framework achieves an average 6.1-fold acceleration in computational speed compared to existing methods while maintaining a respectable success rate. The source code of DBgDel with examples are available on https://github.com/MetNetComp/DBgDel.</description>
      <guid isPermaLink="false">oai:arXiv.org:2411.08077v1</guid>
      <category>q-bio.QM</category>
      <category>cs.DB</category>
      <pubDate>Thu, 14 Nov 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Ziwei Yang, Takeyuki Tamura</dc:creator>
    </item>
    <item>
      <title>XiYan-SQL: A Multi-Generator Ensemble Framework for Text-to-SQL</title>
      <link>https://arxiv.org/abs/2411.08599</link>
      <description>arXiv:2411.08599v1 Announce Type: cross 
Abstract: To tackle the challenges of large language model performance in natural language to SQL tasks, we introduce XiYan-SQL, an innovative framework that employs a multi-generator ensemble strategy to improve candidate generation. We introduce M-Schema, a semi-structured schema representation method designed to enhance the understanding of database structures. To enhance the quality and diversity of generated candidate SQL queries, XiYan-SQL integrates the significant potential of in-context learning (ICL) with the precise control of supervised fine-tuning. On one hand, we propose a series of training strategies to fine-tune models to generate high-quality candidates with diverse preferences. On the other hand, we implement the ICL approach with an example selection method based on named entity recognition to prevent overemphasis on entities. The refiner optimizes each candidate by correcting logical or syntactical errors. To address the challenge of identifying the best candidate, we fine-tune a selection model to distinguish nuances of candidate SQL queries. The experimental results on multiple dialect datasets demonstrate the robustness of XiYan-SQL in addressing challenges across different scenarios. Overall, our proposed XiYan-SQL achieves the state-of-the-art execution accuracy of 89.65% on the Spider test set, 69.86% on SQL-Eval, 41.20% on NL2GQL, and a competitive score of 72.23% on the Bird development benchmark. The proposed framework not only enhances the quality and diversity of SQL queries but also outperforms previous methods.</description>
      <guid isPermaLink="false">oai:arXiv.org:2411.08599v1</guid>
      <category>cs.AI</category>
      <category>cs.CL</category>
      <category>cs.DB</category>
      <category>cs.LG</category>
      <pubDate>Thu, 14 Nov 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Yingqi Gao, Yifu Liu, Xiaoxia Li, Xiaorong Shi, Yin Zhu, Yiming Wang, Shiqi Li, Wei Li, Yuntao Hong, Zhiling Luo, Jinyang Gao, Liyu Mou, Yu Li</dc:creator>
    </item>
    <item>
      <title>The Galactica database: an open, generic and versatile tool for the dissemination of simulation data in astrophysics</title>
      <link>https://arxiv.org/abs/2411.08647</link>
      <description>arXiv:2411.08647v1 Announce Type: cross 
Abstract: The Galactica simulation database is a platform designed to assist computational astrophysicists with their open science approach based on FAIR (Findable, Accessible, Interoperable, Reusable) principles. It offers the means to publish their numerical simulation projects, whatever their field of application or research theme and provides access to reduced datasets and object catalogs online. The application implements the Simulation Datamodel IVOA standard. To provide the scientific community indirect access to raw simulation data, Galactica can generate, on an "on-demand" basis, custom high-level data products to meet specific user requirements. These data products, accessible through online WebServices, are produced remotely from the raw simulation datasets. To that end, the Galactica central web application communicates with a high-scalability ecosystem of data-processing servers called Terminus by means of an industry-proven asynchronous task management system. Each Terminus node, hosted in a research institute, a regional or national supercomputing facility, contributes to the ecosystem by providing both the storage and the computational resources required to store the massive simulation datasets and post-process them to create the data products requested on Galactica, hence guaranteeing fine-grained sovereignty over data and resources. This distributed architecture is very versatile, it can be interfaced with any kind of data-processing software, written in any language, handling raw data produced by every type of simulation code used in the field of computational astrophysics. Its generality and versatility, together with its excellent scalability makes it a powerful tool for the scientific community to disseminate numerical models in astrophysics in the exascale era.</description>
      <guid isPermaLink="false">oai:arXiv.org:2411.08647v1</guid>
      <category>astro-ph.IM</category>
      <category>cs.CE</category>
      <category>cs.DB</category>
      <pubDate>Thu, 14 Nov 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <dc:creator>Damien Chapon, Patrick Hennebelle</dc:creator>
    </item>
  </channel>
</rss>
