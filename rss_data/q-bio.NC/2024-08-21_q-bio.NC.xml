<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>q-bio.NC updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/q-bio.NC</link>
    <description>q-bio.NC updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/q-bio.NC" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Wed, 21 Aug 2024 04:00:18 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Wed, 21 Aug 2024 00:00:00 -0400</pubDate>
    <skipDays>
      <day>Sunday</day>
      <day>Saturday</day>
    </skipDays>
    <item>
      <title>The Unbearable Slowness of Being</title>
      <link>https://arxiv.org/abs/2408.10234</link>
      <description>arXiv:2408.10234v1 Announce Type: new 
Abstract: This article is about the neural conundrum behind the slowness of human behavior. The information throughput of a human being is about 10 bits/s. In comparison, our sensory systems gather data at an enormous rate, no less than 1 gigabits/s. The stark contrast between these numbers remains unexplained. Resolving this paradox should teach us something fundamental about brain function: What neural substrate sets this low speed limit on the pace of our existence? Why does the brain need billions of neurons to deal with 10 bits/s? Why can we only think about one thing at a time? We consider plausible explanations for the conundrum and propose new research directions to address the paradox between fast neurons and slow behavior.</description>
      <guid isPermaLink="false">oai:arXiv.org:2408.10234v1</guid>
      <category>q-bio.NC</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Jieyu Zheng, Markus Meister</dc:creator>
    </item>
    <item>
      <title>On the alternatives to the ideal mathematical points-like separatedness</title>
      <link>https://arxiv.org/abs/2408.10253</link>
      <description>arXiv:2408.10253v1 Announce Type: new 
Abstract: In a recent paper as an alternative to models based on the notion of ideal mathematical point, characterized by a property of separatedness, we considered a viewpoint based on the notion of continuous change, making use of elements of a non-classical logic, in particular the fuzzy sets theory, with events represented as spatiotemporally blurred blobs. Here we point out and discuss a number of aspects of this imperfect symbolic description that might potentially be misleading. Besides that, we analyze its relation to various concepts used commonly to model physical systems, denoted by terms like: point, set, continuous, discrete, infinite, or local, clarifying further how our viewpoint is different and asking whether, in light of our main postulate, any of these notions, or their opposites, if exist, are in their usual meanings suitable to accurately describe the natural phenomena.</description>
      <guid isPermaLink="false">oai:arXiv.org:2408.10253v1</guid>
      <category>q-bio.NC</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Bartosz Jura</dc:creator>
    </item>
    <item>
      <title>Prompt Your Brain: Scaffold Prompt Tuning for Efficient Adaptation of fMRI Pre-trained Model</title>
      <link>https://arxiv.org/abs/2408.10567</link>
      <description>arXiv:2408.10567v1 Announce Type: new 
Abstract: We introduce Scaffold Prompt Tuning (ScaPT), a novel prompt-based framework for adapting large-scale functional magnetic resonance imaging (fMRI) pre-trained models to downstream tasks, with high parameter efficiency and improved performance compared to fine-tuning and baselines for prompt tuning. The full fine-tuning updates all pre-trained parameters, which may distort the learned feature space and lead to overfitting with limited training data which is common in fMRI fields. In contrast, we design a hierarchical prompt structure that transfers the knowledge learned from high-resource tasks to low-resource ones. This structure, equipped with a Deeply-conditioned Input-Prompt (DIP) mapping module, allows for efficient adaptation by updating only 2% of the trainable parameters. The framework enhances semantic interpretability through attention mechanisms between inputs and prompts, and it clusters prompts in the latent space in alignment with prior knowledge. Experiments on public resting state fMRI datasets reveal ScaPT outperforms fine-tuning and multitask-based prompt tuning in neurodegenerative diseases diagnosis/prognosis and personality trait prediction, even with fewer than 20 participants. It highlights ScaPT's efficiency in adapting pre-trained fMRI models to low-resource tasks.</description>
      <guid isPermaLink="false">oai:arXiv.org:2408.10567v1</guid>
      <category>q-bio.NC</category>
      <category>cs.AI</category>
      <category>cs.CV</category>
      <category>cs.LG</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <dc:creator>Zijian Dong, Yilei Wu, Zijiao Chen, Yichi Zhang, Yueming Jin, Juan Helen Zhou</dc:creator>
    </item>
    <item>
      <title>Manifold Transform by Recurrent Cortical Circuit Enhances Robust Encoding of Familiar Stimuli</title>
      <link>https://arxiv.org/abs/2408.10873</link>
      <description>arXiv:2408.10873v1 Announce Type: new 
Abstract: A ubiquitous phenomenon observed throughout the primate hierarchical visual system is the sparsification of the neural representation of visual stimuli as a result of familiarization by repeated exposure, manifested as the sharpening of the population tuning curves and suppression of neural responses at the population level. In this work, we investigated the computational implications and circuit mechanisms underlying these neurophysiological observations in an early visual cortical circuit model. We found that such a recurrent neural circuit, shaped by BCM Hebbian learning, can also reproduce these phenomena. The resulting circuit became more robust against noises in encoding the familiar stimuli. Analysis of the geometry of the neural response manifold revealed that recurrent computation and familiar learning transform the response manifold and the neural dynamics, resulting in enhanced robustness against noise and better stimulus discrimination. This prediction is supported by preliminary physiological evidence. Familiarity training increases the alignment of the slow modes of network dynamics with the invariant features of the learned images. These findings revealed how these rapid plasticity mechanisms can improve contextual visual processing in even the early visual areas in the hierarchical visual system.</description>
      <guid isPermaLink="false">oai:arXiv.org:2408.10873v1</guid>
      <category>q-bio.NC</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Weifan Wang, Xueyan Niu, Tai-Sing Lee</dc:creator>
    </item>
    <item>
      <title>An Overlooked Role of Context-Sensitive Dendrites</title>
      <link>https://arxiv.org/abs/2408.11019</link>
      <description>arXiv:2408.11019v1 Announce Type: new 
Abstract: To date, most dendritic studies have predominantly focused on the apical zone of pyramidal two-point neurons (TPNs) receiving only feedback (FB) connections from higher perceptual layers and using them for learning. Recent cellular neurophysiology and computational neuroscience studies suggests that the apical input (context), coming from feedback and lateral connections, is multifaceted and far more diverse, with greater implications for ongoing learning and processing in the brain than previously realized. In addition to the FB, the apical tuft receives signals from neighboring cells of the same network as proximal (P) context, other parts of the brain as distal (D) context, and overall coherent information across the network as universal (U) context. The integrated context (C) amplifies and suppresses the transmission of coherent and conflicting feedforward (FF) signals, respectively. Specifically, we show that complex context-sensitive (CS)-TPNs flexibly integrate C moment-by-moment with the FF somatic current at the soma such that the somatic current is amplified when both feedforward (FF) and C are coherent; otherwise, it is attenuated. This generates the event only when the FF and C currents are coherent, which is then translated into a singlet or a burst based on the FB information. Spiking simulation results show that this flexible integration of somatic and contextual currents enables the propagation of more coherent signals (bursts), making learning faster with fewer neurons. Similar behavior is observed when this functioning is used in conventional artificial networks, where orders of magnitude fewer neurons are required to process vast amounts of heterogeneous real-world audio-visual (AV) data trained using backpropagation (BP). The computational findings presented here demonstrate the universality of CS-TPNs, suggesting a dendritic narrative that was previously overlooked.</description>
      <guid isPermaLink="false">oai:arXiv.org:2408.11019v1</guid>
      <category>q-bio.NC</category>
      <category>cs.AI</category>
      <category>cs.LG</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Mohsin Raza, Ahsan Adeel</dc:creator>
    </item>
    <item>
      <title>Reliability of energy landscape analysis of resting-state functional MRI data</title>
      <link>https://arxiv.org/abs/2305.19573</link>
      <description>arXiv:2305.19573v2 Announce Type: replace 
Abstract: Energy landscape analysis is a data-driven method to analyze multidimensional time series, including functional magnetic resonance imaging (fMRI) data. It has been shown to be a useful characterization of fMRI data in health and disease. It fits an Ising model to the data and captures the dynamics of the data as movement of a noisy ball constrained on the energy landscape derived from the estimated Ising model. In the present study, we examine test-retest reliability of the energy landscape analysis. To this end, we construct a permutation test that assesses whether or not indices characterizing the energy landscape are more consistent across different sets of scanning sessions from the same participant (i.e., within-participant reliability) than across different sets of sessions from different participants (i.e., between-participant reliability). We show that the energy landscape analysis has significantly higher within-participant than between-participant test-retest reliability with respect to four commonly used indices. We also show that a variational Bayesian method, which enables us to estimate energy landscapes tailored to each participant, displays comparable test-retest reliability to that using the conventional likelihood maximization method. The proposed methodology paves the way to perform individual-level energy landscape analysis for given data sets with a statistically controlled reliability.</description>
      <guid isPermaLink="false">oai:arXiv.org:2305.19573v2</guid>
      <category>q-bio.NC</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <arxiv:DOI>10.1111/ejn.16390</arxiv:DOI>
      <arxiv:journal_reference>European Journal of Neuroscience 60 (2024) 4265</arxiv:journal_reference>
      <dc:creator>Pitambar Khanra, Johan Nakuci, Sarah Muldoon, Takamitsu Watanabe, Naoki Masuda</dc:creator>
    </item>
    <item>
      <title>Perceptual learning in contour detection transfer across changes in contour path and orientation</title>
      <link>https://arxiv.org/abs/2403.11516</link>
      <description>arXiv:2403.11516v2 Announce Type: replace 
Abstract: The integration of local elements into shape contours is critical for target detection and identification in cluttered scenes. Previous studies have shown that observers can learn to use image regularities for contour integration and target identification. However, we still know little about the generalization of perceptual learning in contour integration. Specifically, whether training in contour detection task could transfer to untrained contour type, path or orientation is still unclear. In a series of four experiments, human perceptual learning in contour detection was studied using psychophysical methods. We trained participants to detect contours in cluttered scenes over several days, which resulted in a significant improvement in sensitivity to trained contour type. This improved sensitivity was highly specific to contour type, but transfer across changes in contour path and contour orientation. These results suggest that short-term training improves the ability to integrate specific types of contours by optimizing the ability of the visual system to extract specific image regularities. The differential specificity and generalization across different stimulus features may support the involvement of both low-level and higher-level visual areas in perceptual learning in contour detection. These findings provide further insights into understanding the nature and the brain plasticity mechanism of contour integration learning.</description>
      <guid isPermaLink="false">oai:arXiv.org:2403.11516v2</guid>
      <category>q-bio.NC</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Yue Ding, Hongqiao Shi, Shuang Song, Yonghui Wang, Ya Li</dc:creator>
    </item>
    <item>
      <title>Tangent space functional reconfigurations in individuals at risk for alcohol use disorder</title>
      <link>https://arxiv.org/abs/2405.15905</link>
      <description>arXiv:2405.15905v2 Announce Type: replace 
Abstract: Human brain function dynamically adjusts to ever-changing stimuli from the external environment. Studies characterizing brain functional reconfiguration are nevertheless scarce. Here we present a principled mathematical framework to quantify brain functional reconfiguration when engaging and disengaging from a stop signal task (SST). We apply tangent space projection (a Riemannian geometry mapping technique) to transform functional connectomes (FCs) of 54 participants and quantify functional reconfiguration using the correlation distance of the resulting tangent-FCs. Our goal was to compare functional reconfigurations in individuals at risk for alcohol use disorder (AUD). We hypothesized that functional reconfigurations when transitioning to/from a task would be influenced by family history of alcohol use disorder (FHA) and other AUD risk factors. Multilinear regression models showed that engaging and disengaging functional reconfiguration were associated with FHA and recent drinking. When engaging in the SST after a rest condition, functional reconfiguration was negatively associated with recent drinking, while functional reconfiguration when disengaging from the SST was negatively associated with FHA. In both models, several other factors contributed to the functional reconfiguration. This study 1demonstrates that tangent-FCs can characterize task-induced functional reconfiguration, and that it is related to AUD risk.</description>
      <guid isPermaLink="false">oai:arXiv.org:2405.15905v2</guid>
      <category>q-bio.NC</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Mahdi Moghaddam, Mario Dzemidzic, Daniel Guerrero, Mintao Liu, Jonathan Alessi, Martin H. Plawecki, Jaroslaw Harezlak, David Kareken, Joaqu\'in Go\~ni</dc:creator>
    </item>
    <item>
      <title>A Comparison of Large Language Model and Human Performance on Random Number Generation Tasks</title>
      <link>https://arxiv.org/abs/2408.09656</link>
      <description>arXiv:2408.09656v2 Announce Type: replace-cross 
Abstract: Random Number Generation Tasks (RNGTs) are used in psychology for examining how humans generate sequences devoid of predictable patterns. By adapting an existing human RNGT for an LLM-compatible environment, this preliminary study tests whether ChatGPT-3.5, a large language model (LLM) trained on human-generated text, exhibits human-like cognitive biases when generating random number sequences. Initial findings indicate that ChatGPT-3.5 more effectively avoids repetitive and sequential patterns compared to humans, with notably lower repeat frequencies and adjacent number frequencies. Continued research into different models, parameters, and prompting methodologies will deepen our understanding of how LLMs can more closely mimic human random generation behaviors, while also broadening their applications in cognitive and behavioral science research.</description>
      <guid isPermaLink="false">oai:arXiv.org:2408.09656v2</guid>
      <category>cs.AI</category>
      <category>cs.CL</category>
      <category>q-bio.NC</category>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Rachel M. Harrison</dc:creator>
    </item>
  </channel>
</rss>
