<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>econ.EM updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/econ.EM</link>
    <description>econ.EM updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/econ.EM" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Wed, 18 Jun 2025 04:02:09 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Wed, 18 Jun 2025 00:00:00 -0400</pubDate>
    <skipDays>
      <day>Saturday</day>
      <day>Sunday</day>
    </skipDays>
    <item>
      <title>High-Dimensional Spatial-Plus-Vertical Price Relationships and Price Transmission: A Machine Learning Approach</title>
      <link>https://arxiv.org/abs/2506.13967</link>
      <description>arXiv:2506.13967v1 Announce Type: new 
Abstract: Price transmission has been studied extensively in agricultural economics through the lens of spatial and vertical price relationships. Classical time series econometric techniques suffer from the "curse of dimensionality" and are applied almost exclusively to small sets of price series, either prices of one commodity in a few regions or prices of a few commodities in one region. However, an agrifood supply chain usually contains several commodities (e.g., cattle and beef) and spans numerous regions. Failing to jointly examine multi-region, multi-commodity price relationships limits researchers' ability to derive insights from increasingly high-dimensional price datasets of agrifood supply chains. We apply a machine-learning method - specifically, regularized regression - to augment the classical vector error correction model (VECM) and study large spatial-plus-vertical price systems. Leveraging weekly provincial-level data on the piglet-hog-pork supply chain in China, we uncover economically interesting changes in price relationships in the system before and after the outbreak of a major hog disease. To quantify price transmission in the large system, we rely on the spatial-plus-vertical price relationships identified by the regularized VECM to visualize comprehensive spatial and vertical price transmission of hypothetical shocks through joint impulse response functions. Price transmission shows considerable heterogeneity across regions and commodities as the VECM outcomes imply and display different dynamics over time.</description>
      <guid isPermaLink="false">oai:arXiv.org:2506.13967v1</guid>
      <category>econ.EM</category>
      <pubDate>Wed, 18 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Mindy L. Mallory, Rundong Peng, Meilin Ma, H. Holly Wang</dc:creator>
    </item>
    <item>
      <title>Machine Learning-Based Estimation of Monthly GDP</title>
      <link>https://arxiv.org/abs/2506.14078</link>
      <description>arXiv:2506.14078v1 Announce Type: new 
Abstract: This paper proposes a scalable framework to estimate monthly GDP using machine learning methods. We apply Multi-Layer Perceptron (MLP), Long Short-Term Memory networks (LSTM), Extreme Gradient Boosting (XGBoost), and Elastic Net regression to map monthly indicators to quarterly GDP growth, and reconcile the outputs with actual aggregates. Using data from China, Germany, the UK, and the US, our method delivers robust performance across varied data environments. Benchmark comparisons with prior US studies and UK official statistics validate its accuracy. The approach offers a flexible and data-driven tool for high-frequency macroeconomic monitoring and policy analysis.</description>
      <guid isPermaLink="false">oai:arXiv.org:2506.14078v1</guid>
      <category>econ.EM</category>
      <pubDate>Wed, 18 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Yonggeun Jung</dc:creator>
    </item>
    <item>
      <title>A break from the norm? Parametric representations of preference heterogeneity for discrete choice models in health</title>
      <link>https://arxiv.org/abs/2506.14099</link>
      <description>arXiv:2506.14099v1 Announce Type: new 
Abstract: Background: Any sample of individuals has its own, unique distribution of preferences for choices that they make. Discrete choice models try to capture these distributions. Mixed logits are by far the most commonly used choice model in health. A raft of parametric model specifications for these models are available. We test a range of alternatives assumptions, and model averaging, to test if or how model outputs are impacted. Design: Scoping review of current modelling practices. Seven alternative distributions, and model averaging over all distributional assumptions, were compared on four datasets: two were stated preference, one was revealed preference, and one was simulated. Analyses examined model fit, preference distributions, willingness-to-pay, and forecasting. Results: Almost universally, using normal distributions is the standard practice in health. Alternative distributional assumptions outperformed standard practice. Preference distributions and the mean willingness-to-pay varied significantly across specifications, and were seldom comparable to those derived from normal distributions. Model averaging offered distributions allowed for greater flexibility, further gains in fit, reproduced underlying distributions in simulations, and mitigated against analyst bias arising from distribution selection. There was no evidence that distributional assumptions impacted predictions from models. Limitations: Our focus was on mixed logit models since these models are the most common in health, though latent class models are also used. Conclusions: The standard practice of using all normal distributions appears to be an inferior approach for capturing random preference heterogeneity. Implications: Researchers should test alternative assumptions to normal distributions in their models.</description>
      <guid isPermaLink="false">oai:arXiv.org:2506.14099v1</guid>
      <category>econ.EM</category>
      <pubDate>Wed, 18 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <dc:creator>John Buckell, Alice Wreford, Matthew Quaife, Thomas O. Hancock</dc:creator>
    </item>
    <item>
      <title>Heterogeneous economic growth vulnerability across Euro Area countries under stressed scenarios</title>
      <link>https://arxiv.org/abs/2506.14321</link>
      <description>arXiv:2506.14321v1 Announce Type: new 
Abstract: We analyse economic growth vulnerability of the four largest Euro Area (EA) countries under stressed macroeconomic and financial conditions. Vulnerability, measured as a lower quantile of the growth distribution conditional on EA-wide and country-specific underlying factors, is found to be higher in Germany, which is more exposed to EA-wide economic conditions, and in Spain, which has large country-specific sectoral dynamics. We show that, under stress, financial factors amplify adverse macroeconomic conditions. Furthermore, even severe sectoral (financial or macro) shocks, whether common or country-specific, fail to fully explain the vulnerability observed under overall stress. Our results underscore the importance of monitoring both local and EA-wide macro-financial conditions to design effective policies for mitigating growth vulnerability.</description>
      <guid isPermaLink="false">oai:arXiv.org:2506.14321v1</guid>
      <category>econ.EM</category>
      <pubDate>Wed, 18 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Claudio Lissona, Esther Ruiz</dc:creator>
    </item>
    <item>
      <title>Causal Mediation Analysis with Multiple Mediators: A Simulation Approach</title>
      <link>https://arxiv.org/abs/2506.14019</link>
      <description>arXiv:2506.14019v1 Announce Type: cross 
Abstract: Analyses of causal mediation often involve exposure-induced confounders or, relatedly, multiple mediators. In such applications, researchers aim to estimate a variety of different quantities, including interventional direct and indirect effects, multivariate natural direct and indirect effects, and/or path-specific effects. This study introduces a general approach to estimating all these quantities by simulating potential outcomes from a series of distribution models for each mediator and the outcome. Building on similar methods developed for analyses with only a single mediator (Imai et al. 2010), we first outline how to implement this approach with parametric models. The parametric implementation can accommodate linear and nonlinear relationships, both continuous and discrete mediators, and many different types of outcomes. However, it depends on correct specification of each model used to simulate the potential outcomes. To address the risk of misspecification, we also introduce an alternative implementation using a novel class of nonparametric models, which leverage deep neural networks to approximate the relevant distributions without relying on strict assumptions about functional form. We illustrate both methods by reanalyzing the effects of media framing on attitudes toward immigration (Brader et al. 2008) and the effects of prenatal care on preterm birth (VanderWeele et al. 2014).</description>
      <guid isPermaLink="false">oai:arXiv.org:2506.14019v1</guid>
      <category>stat.ME</category>
      <category>econ.EM</category>
      <category>stat.AP</category>
      <category>stat.ML</category>
      <pubDate>Wed, 18 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Jesse Zhou, Geoffrey T. Wodtke</dc:creator>
    </item>
    <item>
      <title>Testing Goodness-of-Fit for Conditional Distributions: A New Perspective based on Principal Component Analysis</title>
      <link>https://arxiv.org/abs/2403.10352</link>
      <description>arXiv:2403.10352v2 Announce Type: replace 
Abstract: This paper introduces a novel goodness-of-fit test technique for parametric conditional distributions. The proposed tests are based on a residual marked empirical process, for which we develop a conditional Principal Component Analysis. The obtained components provide a basis for various types of new tests in addition to the omnibus one. Component tests that based on each component serve as experts in detecting certain directions. Smooth tests that assemble a few components are also of great use in practice. To further improve testing performance, we introduce a component selection approach, aiming to identify the most contributory components. The finite sample performance of the proposed tests is illustrated through Monte Carlo experiments.</description>
      <guid isPermaLink="false">oai:arXiv.org:2403.10352v2</guid>
      <category>econ.EM</category>
      <category>math.ST</category>
      <category>stat.TH</category>
      <pubDate>Wed, 18 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Cui Rui, Li Yuhao</dc:creator>
    </item>
    <item>
      <title>Identification of dynamic treatment effects when treatment histories are partially observed</title>
      <link>https://arxiv.org/abs/2501.04853</link>
      <description>arXiv:2501.04853v2 Announce Type: replace 
Abstract: This paper presents a general difference-in-differences framework for identifying path-dependent treatment effects when treatment histories are partially observed. We introduce a novel robust estimator that adjusts for missing histories using a combination of outcome, propensity score, and missing treatment models. We show that this approach identifies the target parameter as long as \textit{any two} of the three models are correctly specified. The method delivers improved robustness against competing alternatives under the same set of identifying assumptions. Theoretical results and numerical experiments demonstrate how the proposed method yields more accurate inference compared to conventional and doubly robust estimators, particularly under nontrivial missingness and misspecification scenarios. Two applications demonstrate that the robust method can produce substantively different estimates of path-dependent treatment effects relative to conventional approaches.</description>
      <guid isPermaLink="false">oai:arXiv.org:2501.04853v2</guid>
      <category>econ.EM</category>
      <pubDate>Wed, 18 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Akanksha Negi, Didier Nibbering</dc:creator>
    </item>
    <item>
      <title>Constructing an Instrument as a Function of Covariates</title>
      <link>https://arxiv.org/abs/2503.10929</link>
      <description>arXiv:2503.10929v2 Announce Type: replace 
Abstract: Researchers often use instrumental variables (IV) models to investigate the causal relationship between an endogenous variable and an outcome while controlling for covariates. When an exogenous variable is unavailable to serve as the instrument for an endogenous treatment, a recurring empirical practice is to construct one from a nonlinear transformation of the covariates. We investigate how reliable these estimates are under mild forms of misspecification. Our main result shows that for instruments constructed from covariates, the IV estimand can be arbitrarily biased under mild forms of misspecification, even when imposing constant linear treatment effects. We perform a semi-synthetic exercise by calibrating data to alternative models proposed in the literature and estimating the average treatment effect. Our results show that IV specifications that use instruments constructed from covariates are non-robust to nonlinearity in the true structural function.</description>
      <guid isPermaLink="false">oai:arXiv.org:2503.10929v2</guid>
      <category>econ.EM</category>
      <pubDate>Wed, 18 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Moses Stewart</dc:creator>
    </item>
    <item>
      <title>Difference-in-Differences Designs: A Practitioner's Guide</title>
      <link>https://arxiv.org/abs/2503.13323</link>
      <description>arXiv:2503.13323v3 Announce Type: replace 
Abstract: Difference-in-differences (DiD) is arguably the most popular quasi-experimental research design. Its canonical form, with two groups and two periods, is well-understood. However, empirical practices can be ad hoc when researchers go beyond that simple case. This article provides an organizing framework for discussing different types of DiD designs and their associated DiD estimators. It discusses covariates, weights, handling multiple periods, and staggered treatments. The organizational framework, however, applies to other extensions of DiD methods as well.</description>
      <guid isPermaLink="false">oai:arXiv.org:2503.13323v3</guid>
      <category>econ.EM</category>
      <category>stat.ME</category>
      <pubDate>Wed, 18 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Andrew Baker, Brantly Callaway, Scott Cunningham, Andrew Goodman-Bacon, Pedro H. C. Sant'Anna</dc:creator>
    </item>
    <item>
      <title>Revealed Information</title>
      <link>https://arxiv.org/abs/2411.13293</link>
      <description>arXiv:2411.13293v2 Announce Type: replace-cross 
Abstract: An analyst observes the frequency with which a decision maker (DM) takes actions, but not the frequency conditional on payoff-relevant states. We ask when the analyst can rationalize the DM's choices as if the DM first learns something about the state before acting. We provide a support-function characterization of the triples of utility functions, prior beliefs, and (marginal) distributions over actions such that the DM's action distribution is consistent with information given the DM's prior and utility function. Assumptions on the cardinality of the state space and the utility function allow us to refine this characterization, obtaining a sharp system of finitely many inequalities the utility function, prior, and action distribution must satisfy. We apply our characterization to study comparative statics and to identify conditions under which a single information structure rationalizes choices across multiple decision problems. We characterize the set of distributions over posterior beliefs that are consistent with the DM's choices. We extend our results to settings with a continuum of actions and states assuming the first-order approach applies, and to simple multi-agent settings.</description>
      <guid isPermaLink="false">oai:arXiv.org:2411.13293v2</guid>
      <category>econ.TH</category>
      <category>econ.EM</category>
      <category>math.OC</category>
      <pubDate>Wed, 18 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Laura Doval, Ran Eilat, Tianhao Liu, Yangfan Zhou</dc:creator>
    </item>
  </channel>
</rss>
