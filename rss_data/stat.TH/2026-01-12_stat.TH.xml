<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>stat.TH updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/stat.TH</link>
    <description>stat.TH updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/stat.TH" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Mon, 12 Jan 2026 05:00:20 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Mon, 12 Jan 2026 00:00:00 -0500</pubDate>
    <skipDays>
      <day>Saturday</day>
      <day>Sunday</day>
    </skipDays>
    <item>
      <title>What Functions Does XGBoost Learn?</title>
      <link>https://arxiv.org/abs/2601.05444</link>
      <description>arXiv:2601.05444v1 Announce Type: new 
Abstract: This paper establishes a rigorous theoretical foundation for the function class implicitly learned by XGBoost, bridging the gap between its empirical success and our theoretical understanding. We introduce an infinite-dimensional function class $\mathcal{F}^{d, s}_{\infty-\text{ST}}$ that extends finite ensembles of bounded-depth regression trees, together with a complexity measure $V^{d, s}_{\infty-\text{XGB}}(\cdot)$ that generalizes the $L^1$ regularization penalty used in XGBoost. We show that every optimizer of the XGBoost objective is also an optimizer of an equivalent penalized regression problem over $\mathcal{F}^{d, s}_{\infty-\text{ST}}$ with penalty $V^{d, s}_{\infty-\text{XGB}}(\cdot)$, providing an interpretation of XGBoost as implicitly targeting a broader function class. We also develop a smoothness-based interpretation of $\mathcal{F}^{d, s}_{\infty-\text{ST}}$ and $V^{d, s}_{\infty-\text{XGB}}(\cdot)$ in terms of Hardy--Krause variation. We prove that the least squares estimator over $\{f \in \mathcal{F}^{d, s}_{\infty-\text{ST}}: V^{d, s}_{\infty-\text{XGB}}(f) \le V\}$ achieves a nearly minimax-optimal rate of convergence $n^{-2/3} (\log n)^{4(\min(s, d) - 1)/3}$, thereby avoiding the curse of dimensionality. Our results provide the first rigorous characterization of the function space underlying XGBoost, clarify its connection to classical notions of variation, and identify an important open problem: whether the XGBoost algorithm itself achieves minimax optimality over this class.</description>
      <guid isPermaLink="false">oai:arXiv.org:2601.05444v1</guid>
      <category>math.ST</category>
      <category>cs.LG</category>
      <category>stat.ML</category>
      <category>stat.TH</category>
      <pubDate>Mon, 12 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Dohyeong Ki, Adityanand Guntuboyina</dc:creator>
    </item>
    <item>
      <title>Detecting Planted Structure in Circular Data</title>
      <link>https://arxiv.org/abs/2601.05993</link>
      <description>arXiv:2601.05993v1 Announce Type: new 
Abstract: Hypothesis testing problems for circular data are formulated, where observations take values on the unit circle and may contain a hidden, phase-coherent structure. Under the null, the data are independent uniform on the unit circle; under the alternative, either (i) a planted subset of size K concentrates around an unknown phase (the flat setting), or (ii) a planted community of size k induces coherence among the edges of a complete graph (the community setting). In each of the two settings, two circular signal distributions are considered: a hard-cluster distribution, where correlated planted observations lie in an arc of known length and unknown location, and a von Mises distribution, where correlated planted observations follow a von Mises distribution with a common unknown location parameter. For each of the four resulting models, nearly matching necessary and sufficient conditions are derived (up to constants and occasional logarithmic factors) for detectability, thereby establishing information-theoretic phase transitions.</description>
      <guid isPermaLink="false">oai:arXiv.org:2601.05993v1</guid>
      <category>math.ST</category>
      <category>cs.IT</category>
      <category>math.IT</category>
      <category>stat.TH</category>
      <pubDate>Mon, 12 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Taha Ameen, Bruce Hajek</dc:creator>
    </item>
    <item>
      <title>On the Effect of Misspecifying the Embedding Dimension in Low-rank Network Models</title>
      <link>https://arxiv.org/abs/2601.06014</link>
      <description>arXiv:2601.06014v1 Announce Type: new 
Abstract: As network data has become ubiquitous in the sciences, there has been growing interest in network models whose structure is driven by latent node-level variables in a (typically low-dimensional) latent geometric space. These "latent positions" are often estimated via embeddings, whereby the nodes of a network are mapped to points in Euclidean space so that "similar" nodes are mapped to nearby points. Under certain model assumptions, these embeddings are consistent estimates of the latent positions, but most such results require that the embedding dimension be chosen correctly, typically equal to the dimension of the latent space. Methods for estimating this correct embedding dimension have been studied extensive in recent years, but there has been little work to date characterizing the behavior of embeddings when this embedding dimension is misspecified. In this work, we provide theoretical descriptions of the effects of misspecifying the embedding dimension of the adjacency spectral embedding under the random dot product graph, a class of latent space network models that includes a number of widely-used network models as special cases, including the stochastic blockmodel. We consider both the case in which the dimension is chosen too small, where we prove estimation error lower-bounds, and the case where the dimension is chosen too large, where we show that consistency still holds, albeit at a slower rate than when the embedding dimension is chosen correctly.A range of synthetic data experiments support our theoretical results. Our main technical result, which may be of independent interest, is a generalization of earlier work in random matrix theory, showing that all non-signal eigenvectors of a low-rank matrix subject to additive noise are delocalized.</description>
      <guid isPermaLink="false">oai:arXiv.org:2601.06014v1</guid>
      <category>math.ST</category>
      <category>stat.TH</category>
      <pubDate>Mon, 12 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Roddy Taing, Keith Levin</dc:creator>
    </item>
    <item>
      <title>Precise Asymptotics for Spectral Methods in Mixed Generalized Linear Models</title>
      <link>https://arxiv.org/abs/2211.11368</link>
      <description>arXiv:2211.11368v5 Announce Type: replace 
Abstract: In a mixed generalized linear model, the goal is to learn multiple signals from unlabeled observations: each sample comes from exactly one signal, but it is not known which one. We consider the prototypical problem of estimating two statistically independent signals in a mixed generalized linear model with Gaussian covariates. Spectral methods are a popular class of estimators which output the top two eigenvectors of a suitable data-dependent matrix. However, despite the wide applicability, their design is still obtained via heuristic considerations, and the number of samples $n$ needed to guarantee recovery is super-linear in the signal dimension $d$. In this paper, we develop exact asymptotics on spectral methods in the challenging proportional regime in which $n, d$ grow large and their ratio converges to a finite constant. This allows us optimize the design of the spectral method, and combine it with a simple linear estimator, to minimize the estimation error. Our characterization exploits a mix of tools from random matrices, free probability and the theory of approximate message passing algorithms. Numerical simulations for mixed linear regression and phase retrieval demonstrate the advantage enabled by our analysis over existing designs of spectral methods.</description>
      <guid isPermaLink="false">oai:arXiv.org:2211.11368v5</guid>
      <category>math.ST</category>
      <category>cs.IT</category>
      <category>cs.LG</category>
      <category>math.IT</category>
      <category>stat.ML</category>
      <category>stat.TH</category>
      <pubDate>Mon, 12 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Yihan Zhang, Marco Mondelli, Ramji Venkataramanan</dc:creator>
    </item>
    <item>
      <title>Probabilistic Analysis of Scalogram Ridges in Signal Processing</title>
      <link>https://arxiv.org/abs/2501.00270</link>
      <description>arXiv:2501.00270v3 Announce Type: replace 
Abstract: While ridges in the scalogram, determined by the squared modulus of analytic wavelet transform (AWT), is a widely accepted concept and utilized in nonstationary time series analysis, their behavior in noisy environments remains underexplored. Our object is to provide a theoretical foundation for scalogram ridges by defining ridges as a potentially set-valued random process connecting local maxima of the scalogram along the scale axis and analyzing their properties when the signal fulfills the adaptive harmonic model and is contaminated by stationary Gaussian noise. In addition to establishing several key properties of the AWT for random processes, we investigate the probabilistic characteristics of the resulting random ridge points in the scalogram. Specifically, we establish the uniqueness property of the ridge point at individual time instances and prove the upper hemicontinuity of the ridge random process. Furthermore, we derive bounds on the probability that the deviation between the ridges of noisy and clean signals exceeds a specified threshold, and these bounds depend on the signal-to-noise ratio. To achieve these ridge deviation results, we derive maximal inequalities for the complex modulus of nonstationary Gaussian processes, leveraging classical tools such as the Borell-TIS inequality and Dudley's theorem, which might be of independent interest.</description>
      <guid isPermaLink="false">oai:arXiv.org:2501.00270v3</guid>
      <category>math.ST</category>
      <category>math.PR</category>
      <category>stat.TH</category>
      <pubDate>Mon, 12 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Gi-Ren Liu, Yuan-Chung Sheu, Hau-Tieng Wu</dc:creator>
    </item>
    <item>
      <title>Matching Criterion for Identifiability in Sparse Factor Analysis</title>
      <link>https://arxiv.org/abs/2502.02986</link>
      <description>arXiv:2502.02986v2 Announce Type: replace 
Abstract: Factor analysis models explain dependence among observed variables by a smaller number of unobserved factors. A main challenge in confirmatory factor analysis is determining whether the factor loading matrix is identifiable from the observed covariance matrix. The factor loading matrix captures the linear effects of the factors and, if unrestricted, can only be identified up to an orthogonal transformation of the factors. However, in many applications the factor loadings exhibit an interesting sparsity pattern that may lead to identifiability up to column signs. We study this phenomenon by connecting sparse confirmatory factor analysis models to bipartite graphs and providing sufficient graphical conditions for identifiability of the factor loading matrix up to column signs. In contrast to previous work, our main contribution, the matching criterion, exploits sparsity by operating locally on the graph structure, thereby improving existing conditions. Our criterion is efficiently decidable in time that is polynomial in the size of the graph, when restricting the search steps to sets of bounded size.</description>
      <guid isPermaLink="false">oai:arXiv.org:2502.02986v2</guid>
      <category>math.ST</category>
      <category>stat.TH</category>
      <pubDate>Mon, 12 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Nils Sturma, Miriam Kranzlmueller, Irem Portakal, Mathias Drton</dc:creator>
    </item>
    <item>
      <title>The resource theory of causal influence and knowledge of causal influence</title>
      <link>https://arxiv.org/abs/2512.11209</link>
      <description>arXiv:2512.11209v2 Announce Type: replace 
Abstract: Understanding and quantifying causal relationships between variables is essential for reasoning about the physical world. In this work, we develop a resource-theoretic framework to do so. Here, we focus on the simplest nontrivial setting -- two variables that are causally ordered, meaning that the first has the potential to influence the second, without hidden confounding. First, we introduce the resource theory that directly quantifies causal influence of a functional dependence in this setting and show that the problem of deciding convertibility of resources and identifying a complete set of monotones has a relatively straightforward solution. Following this, we introduce the resource theory that arises naturally when one has uncertainty about the functional dependence. We describe a linear program for deciding the question of whether one resource (i.e., state of knowledge about the functional dependence) can be converted to another. Then, we focus on the case where the variables are binary. In this case, we identify a triple of monotones that are complete in the sense that they capture the partial order over the set of all resources, and we provide an interpretation of each.</description>
      <guid isPermaLink="false">oai:arXiv.org:2512.11209v2</guid>
      <category>math.ST</category>
      <category>stat.TH</category>
      <pubDate>Mon, 12 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <dc:creator>Marina Maciel Ansanelli, Beata Zjawin, David Schmid, Y\`il\`e Y\=ing, John H. Selby, Ciar\'an M. Gilligan-Lee, Ana Bel\'en Sainz, Robert W. Spekkens</dc:creator>
    </item>
    <item>
      <title>Drift estimation for a partially observed mixed fractional Ornstein--Uhlenbeck process</title>
      <link>https://arxiv.org/abs/2512.15362</link>
      <description>arXiv:2512.15362v2 Announce Type: replace 
Abstract: We consider estimation of the drift parameter $\vartheta&gt;0$ in a \emph{partially observed} Ornstein--Uhlenbeck type model driven by a mixed fractional Brownian noise. Our framework extends the partially observed model of \cite{BrousteKleptsyna2010} to the \emph{mixed} case. We construct the canonical innovation representation, derive the associated Kalman filter and Riccati equations, and analyse the asymptotic behaviour of the filtering error covariance.
  Within the Ibragimov--Khasminskii LAN framework we prove that the MLE of $\vartheta$, based on continuous observation of the partially observed system on $[0,T]$, is consistent and asymptotically normal with rate $\sqrt{T}$ and the Fisher Information is the same as in \cite{BrousteKleptsyna2010} or the standard Brownian motion case.</description>
      <guid isPermaLink="false">oai:arXiv.org:2512.15362v2</guid>
      <category>math.ST</category>
      <category>stat.TH</category>
      <pubDate>Mon, 12 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Chunhao Cai</dc:creator>
    </item>
    <item>
      <title>Minimum Variance Designs With Constrained Maximum Bias</title>
      <link>https://arxiv.org/abs/2512.21806</link>
      <description>arXiv:2512.21806v3 Announce Type: replace 
Abstract: Designs which are minimax in the presence of model misspecifications have been constructed so as to minimize the maximum, over classes of alternate response models, of the integrated mean squared error of the predicted values. This mean squared error decomposes into a term arising solely from variation, and a bias term arising from the model errors. Here we consider the problem of designing so as to minimize the variance of the predictors, subject to a bound on the maximum (over model misspecifications) bias. We consider as well designing so as to minimize the maximum bias, subject to a bound on the variance. We show that solutions to both problems are given by the minimax designs, with appropriately chosen values of their tuning constants. Conversely, any minimax design solves each problem for an appropriate choice of the bound on the maximum bias or variance.</description>
      <guid isPermaLink="false">oai:arXiv.org:2512.21806v3</guid>
      <category>math.ST</category>
      <category>stat.TH</category>
      <pubDate>Mon, 12 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Douglas P. Wiens</dc:creator>
    </item>
    <item>
      <title>Scalability of Metropolis-within-Gibbs schemes for high-dimensional Bayesian models</title>
      <link>https://arxiv.org/abs/2403.09416</link>
      <description>arXiv:2403.09416v2 Announce Type: replace-cross 
Abstract: We study general coordinate-wise MCMC schemes (such as Metropolis-within-Gibbs samplers), which are commonly used to fit Bayesian non-conjugate hierarchical models. We relate their convergence properties to the ones of the corresponding (potentially not implementable) Gibbs sampler through the notion of conditional conductance. This allows us to study the performances of popular Metropolis-within-Gibbs schemes for non-conjugate hierarchical models, in high-dimensional regimes where both number of datapoints and parameters increase. Given random data-generating assumptions, we establish dimension-free convergence results, which are in close accordance with numerical evidences. Applications to Bayesian models for binary regression with unknown hyperparameters and discretely observed diffusions are also discussed. Motivated by such statistical applications, auxiliary results of independent interest on approximate conductances and perturbation of Markov operators are provided.</description>
      <guid isPermaLink="false">oai:arXiv.org:2403.09416v2</guid>
      <category>stat.CO</category>
      <category>math.ST</category>
      <category>stat.ML</category>
      <category>stat.TH</category>
      <pubDate>Mon, 12 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Filippo Ascolani, Gareth O. Roberts, Giacomo Zanella</dc:creator>
    </item>
  </channel>
</rss>
