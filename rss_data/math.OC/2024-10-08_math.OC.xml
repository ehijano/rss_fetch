<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>math.OC updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/math.OC</link>
    <description>math.OC updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/math.OC" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Tue, 08 Oct 2024 04:00:35 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Tue, 08 Oct 2024 00:00:00 -0400</pubDate>
    <skipDays>
      <day>Saturday</day>
      <day>Sunday</day>
    </skipDays>
    <item>
      <title>Perturbation Analysis of Error Bounds for Convex Functions on Banach Spaces</title>
      <link>https://arxiv.org/abs/2410.03687</link>
      <description>arXiv:2410.03687v1 Announce Type: new 
Abstract: This paper focuses on the stability of both local and global error bounds for a proper lower semicontinuous convex function defined on a Banach space. Without relying on any dual space information, we first provide precise estimates of error bound moduli using directional derivatives. For a given proper lower semicontinuous convex function on a Banach space, we prove that the stability of local error bounds under small perturbations is equivalent to the directional derivative at a reference point having a non-zero minimum over the unit sphere. Additionally, the stability of global error bounds is shown to be equivalent to the infimum of the directional derivatives, at all points on the boundary of the solution set, being bounded away from zero over some neighborhood of the unit sphere.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.03687v1</guid>
      <category>math.OC</category>
      <pubDate>Tue, 08 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/publicdomain/zero/1.0/</dc:rights>
      <dc:creator>Zhou Wei, Michel Th\'era, Jen-Chih Yao</dc:creator>
    </item>
    <item>
      <title>Multi-objective optimization for a composite pressure vessel with unequal polar openings</title>
      <link>https://arxiv.org/abs/2410.03708</link>
      <description>arXiv:2410.03708v1 Announce Type: new 
Abstract: Multi-objective parametric optimization problem is presented for overwrapped composite pressure vessels under internal pressure for storage and heating water. It is solved using the developed iterative optimization algorithm. Optimal values of design parameters for the vessel are obtained by varying the set of parameters for composite layers, such as the thickness of layers and radii of polar openings, which influence the distribution of fiber angles along the vessel. The suggested optimization methodology is based on the mechanical solution for composite vessels and the satisfaction of the main failure criteria. An innovative approach lies in the possibility of using the developed optimization methodology for designing vessels with non-symmetrical filament winding, which have unequal polar openings on the domes. This became possible due to the development of a special numerical mechanical finite element model of a composite vessel. A specific Python program provides the creation of a model and controls the exchange of data between the modules of the iterative optimization process. The numerical model includes the determination of the distribution of fiber angles on the domes and cylindrical part of the vessel as well as changes in layer thicknesses. The optimization problem solution is provided using a Multi-Island Genetic Algorithm, this type of method showed its efficiency for such applications, by allowing to avoid local solutions. Thus, optimal parameters of a composite vessel were found by minimizing composite mass and thickness and maximizing the strain energy. Test solutions using the developed methodology are presented for three types of composite materials to evaluate their possibility for integration into the vessel design model.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.03708v1</guid>
      <category>math.OC</category>
      <pubDate>Tue, 08 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <arxiv:DOI>10.1016/j.compstruct.2024.118594</arxiv:DOI>
      <arxiv:journal_reference>Composite Structures, 2025, 351, pp.118594</arxiv:journal_reference>
      <dc:creator>Lyudmyla Rozova (CERI MP - IMT Nord Europe), Bilal Meemary (CERI MP - IMT Nord Europe), Salim Chaki (CERI MP - IMT Nord Europe, TPCIM, IMT Lille Douai), Myl\`ene Del\'eglise-Lagard\`ere (IMT Lille Douai, CERI MP - IMT Nord Europe), Dmytro Vasiukov (CERI MP - IMT Nord Europe, TPCIM, IMT Nord Europe)</dc:creator>
    </item>
    <item>
      <title>NeuralQP: A General Hypergraph-based Optimization Framework for Large-scale QCQPs</title>
      <link>https://arxiv.org/abs/2410.03720</link>
      <description>arXiv:2410.03720v1 Announce Type: new 
Abstract: Machine Learning (ML) optimization frameworks have gained attention for their ability to accelerate the optimization of large-scale Quadratically Constrained Quadratic Programs (QCQPs) by learning shared problem structures. However, existing ML frameworks often rely heavily on strong problem assumptions and large-scale solvers. This paper introduces NeuralQP, a general hypergraph-based framework for large-scale QCQPs. NeuralQP features two main components: Hypergraph-based Neural Prediction, which generates embeddings and predicted solutions for QCQPs without problem assumptions, and Parallel Neighborhood Optimization, which employs a McCormick relaxation-based repair strategy to identify and correct illegal variables, iteratively improving the solution with a small-scale solver. We further prove that our framework UniEGNN with our hypergraph representation is equivalent to the Interior-Point Method (IPM) for quadratic programming. Experiments on two benchmark problems and large-scale real-world instances from QPLIB demonstrate that NeuralQP outperforms state-of-the-art solvers (e.g., Gurobi and SCIP) in both solution quality and time efficiency, further validating the efficiency of ML optimization frameworks for QCQPs.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.03720v1</guid>
      <category>math.OC</category>
      <category>cs.LG</category>
      <pubDate>Tue, 08 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Zhixiao Xiong, Fangyu Zong, Huigen Ye, Hua Xu</dc:creator>
    </item>
    <item>
      <title>A Brief Tutorial on Consensus ADMM for Distributed Optimization with Applications in Robotics</title>
      <link>https://arxiv.org/abs/2410.03753</link>
      <description>arXiv:2410.03753v1 Announce Type: new 
Abstract: This paper presents a tutorial on the Consensus Alternating Direction Method of Multipliers (Consensus ADMM) for distributed optimization, with a specific focus on applications in multi-robot systems. In this tutorial, we derive the consensus ADMM algorithm, highlighting its connections to the augmented Lagrangian and primal-dual methods. Finally, we apply Consensus ADMM to an example problem for trajectory optimization of a multi-agent system.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.03753v1</guid>
      <category>math.OC</category>
      <category>cs.SY</category>
      <category>eess.SY</category>
      <pubDate>Tue, 08 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Jushan Chen</dc:creator>
    </item>
    <item>
      <title>Framing global structural identifiability in terms of parameter symmetries</title>
      <link>https://arxiv.org/abs/2410.03757</link>
      <description>arXiv:2410.03757v1 Announce Type: new 
Abstract: A key initial step in mechanistic modelling of dynamical systems using first-order ordinary differential equations is to conduct a global structural identifiability analysis. This entails deducing which parameter combinations can be estimated from certain observed outputs. The standard differential algebra approach answers this question by re-writing the model as a system of ordinary differential equations solely depending on the observed outputs. Over the last decades, alternative approaches for analysing global structural identifiability based on so-called full symmetries, which are Lie symmetries acting on independent and dependent variables as well as parameters, have been proposed. However, the link between the standard differential algebra approach and that using full symmetries remains elusive. In this work, we establish this link by introducing the notion of parameter symmetries, which are a special type of full symmetry that alter parameters while preserving the observed outputs. Our main result states that a parameter combination is structurally identifiable if and only if it is a differential invariant of all parameter symmetries of a given model. We show that the standard differential algebra approach is consistent with the concept of considering structural identifiability in terms of parameter symmetries. We present an alternative symmetry-based approach, referred to as the CaLinInv-recipe, for analysing structural identifiability using parameter symmetries. Lastly, we demonstrate our approach on a glucose-insulin model and an epidemiological model of tuberculosis.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.03757v1</guid>
      <category>math.OC</category>
      <category>math-ph</category>
      <category>math.CA</category>
      <category>math.MP</category>
      <category>q-bio.QM</category>
      <pubDate>Tue, 08 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Johannes G Borgqvist, Alexander P Browning, Fredrik Ohlsson, Ruth E Baker</dc:creator>
    </item>
    <item>
      <title>On the SAGA algorithm with decreasing step</title>
      <link>https://arxiv.org/abs/2410.03760</link>
      <description>arXiv:2410.03760v1 Announce Type: new 
Abstract: Stochastic optimization naturally appear in many application areas, including machine learning. Our goal is to go further in the analysis of the Stochastic Average Gradient Accelerated (SAGA) algorithm. To achieve this, we introduce a new  $\lambda$-SAGA algorithm which interpolates between the Stochastic Gradient Descent ($\lambda=0$) and the SAGA algorithm ($\lambda=1$). Firstly, we investigate the almost sure convergence of this new algorithm with decreasing step which allows us to avoid the restrictive strong convexity and Lipschitz gradient hypotheses associated to the objective function. Secondly, we establish a central limit theorem for the $\lambda$-SAGA algorithm. Finally, we provide the non-asymptotic $\mathbb{L}^p$ rates of convergence.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.03760v1</guid>
      <category>math.OC</category>
      <category>cs.LG</category>
      <category>math.PR</category>
      <category>stat.ML</category>
      <pubDate>Tue, 08 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Luis Fredes (IMB), Bernard Bercu (IMB), Em\'eric Gbaguidi (IMB)</dc:creator>
    </item>
    <item>
      <title>Electrification of Transportation: A Hybrid Benders/SDDP Algorithm for Optimal Charging Station Trading</title>
      <link>https://arxiv.org/abs/2410.03763</link>
      <description>arXiv:2410.03763v1 Announce Type: new 
Abstract: This paper examines the electrification of transportation as a response to environmental challenges caused by fossil fuels, exploring the potential of battery electric vehicles and hydrogen fuel cell vehicles as alternative solutions. However, a significant barrier to their widespread adoption is the limited availability of charging infrastructure. Therefore, this study proposes the development of comprehensive charging stations capable of accommodating both battery and hydrogen vehicles to address this challenge. The energy is purchased from the day-ahead and intraday auction-based electricity markets, where the electricity price is subject to uncertainty. Therefore, a two-stage stochastic programming model is formulated while the price scenarios are generated utilizing a k-means clustering algorithm. Given the complexity of the proposed model, an efficient solution approach is developed through the hybridization of the Benders decomposition algorithm and stochastic dual dynamic programming. In the Benders master problem, day-ahead bidding variables are determined, whereas the Benders sub-problem addresses intraday bidding and charging station scheduling variables, employing stochastic dual dynamic programming to tackle its intractability. Additionally, we transform the mixed integer linear program model of the second stage problem into a linear program, confirming its validity through KKT conditions. Our model provides practical insights for making informed decisions in electricity markets based on sequential auctions. While the bidding curves submitted to the day-ahead market remain unaffected by scenarios, those submitted to the intra-day market show dependence on fluctuations in day-ahead market prices.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.03763v1</guid>
      <category>math.OC</category>
      <category>cs.OH</category>
      <pubDate>Tue, 08 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <arxiv:DOI>10.1016/j.ijhydene.2024.09.345</arxiv:DOI>
      <arxiv:journal_reference>International Journal of Hydrogen Energy, 89 (2024):1060-1074</arxiv:journal_reference>
      <dc:creator>Farnaz Sohrabi, Mohammad Rohaninejad, J\'ulius Bem\v{s}, Zden\v{e}k Hanz\'alek</dc:creator>
    </item>
    <item>
      <title>Online Control-Informed Learning</title>
      <link>https://arxiv.org/abs/2410.03924</link>
      <description>arXiv:2410.03924v1 Announce Type: new 
Abstract: This paper proposes an Online Control-Informed Learning (OCIL) framework, which synthesizes the well-established control theories to solve a broad class of learning and control tasks in real time. This novel integration effectively handles practical issues in machine learning such as noisy measurement data, online learning, and data efficiency. By considering any robot as a tunable optimal control system, we propose an online parameter estimator based on extended Kalman filter (EKF) to incrementally tune the system in real time, enabling it to complete designated learning or control tasks. The proposed method also improves robustness in learning by effectively managing noise in the data. Theoretical analysis is provided to demonstrate the convergence and regret of OCIL. Three learning modes of OCIL, i.e. Online Imitation Learning, Online System Identification, and Policy Tuning On-the-fly, are investigated via experiments, which validate their effectiveness.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.03924v1</guid>
      <category>math.OC</category>
      <category>cs.LG</category>
      <category>cs.RO</category>
      <category>cs.SY</category>
      <category>eess.SY</category>
      <pubDate>Tue, 08 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Zihao Liang, Tianyu Zhou, Zehui Lu, Shaoshuai Mou</dc:creator>
    </item>
    <item>
      <title>Insights into Weighted Sum Sampling Approaches for Multi-Criteria Decision Making Problems</title>
      <link>https://arxiv.org/abs/2410.03931</link>
      <description>arXiv:2410.03931v1 Announce Type: new 
Abstract: In this paper we explore several approaches for sampling weight vectors in the context of weighted sum scalarisation approaches for solving multi-criteria decision making (MCDM) problems. This established method converts a multi-objective problem into a (single) scalar optimisation problem by assigning weights to each objective. We outline various methods to select these weights, with a focus on ensuring computational efficiency and avoiding redundancy. The challenges and computational complexity of these approaches are explored and numerical examples are provided. The theoretical results demonstrate the trade-offs between systematic and randomised weight generation techniques, highlighting their performance for different problem settings. These sampling approaches will be tested and compared computationally in an upcoming paper.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.03931v1</guid>
      <category>math.OC</category>
      <pubDate>Tue, 08 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Aled Williams, Yilun Cai</dc:creator>
    </item>
    <item>
      <title>Computing Competitive Equilibrium for Chores: Linear Convergence and Lightweight Iteration</title>
      <link>https://arxiv.org/abs/2410.04036</link>
      <description>arXiv:2410.04036v1 Announce Type: new 
Abstract: Competitive equilibrium (CE) for chores has recently attracted significant attention, with many algorithms proposed to approximately compute it. However, existing algorithms either lack iterate convergence guarantees to an exact CE or require solving high-dimensional linear or quadratic programming subproblems. This paper overcomes these issues by proposing a novel unconstrained difference-of-convex formulation, whose stationary points correspond precisely to the CE for chores. We show that the new formulation possesses the local error bound property and the Kurdyka-{\L}ojasiewicz property with an exponent of $1/2$. Consequently, we present the first algorithm whose iterates provably converge linearly to an exact CE for chores. Furthermore, by exploiting the max structure within our formulation and applying smoothing techniques, we develop a subproblem-free algorithm that finds an approximate CE in polynomial time. Numerical experiments demonstrate that the proposed algorithms outperform the state-of-the-art method.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.04036v1</guid>
      <category>math.OC</category>
      <pubDate>Tue, 08 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>He Chen, Chonghe Jiang, Anthony Man-Cho So</dc:creator>
    </item>
    <item>
      <title>Accessible Theoretical Complexity of the Restarted Primal-Dual Hybrid Gradient Method for Linear Programs with Unique Optima</title>
      <link>https://arxiv.org/abs/2410.04043</link>
      <description>arXiv:2410.04043v1 Announce Type: new 
Abstract: The restarted primal-dual hybrid gradient method (rPDHG) has recently emerged as an important tool for solving large-scale linear programs (LPs). For LPs with unique optima, we present an iteration bound of $\widetilde{O}\left(\kappa\Phi\cdot\ln\left(\frac{\|w^*\|}{\varepsilon}\right)\right)$, where $\varepsilon$ is the target tolerance, $\kappa$ is the standard matrix condition number, $\|w^*\|$ is the norm of the optimal solution, and $\Phi$ is a geometric condition number of the LP sublevel sets. This iteration bound is "accessible" in the sense that computing it is no more difficult than computing the optimal solution itself. Indeed, we present a closed-form and tractably computable expression for $\Phi$. This enables an analysis of the "two-stage performance" of rPDHG: we show that the first stage identifies the optimal basis in $\widetilde{O}\left(\kappa\Phi\right)$ iterations, and the second stage computes an $\varepsilon$-optimal solution in $O\left(\|B^{-1}\|\|A\|\cdot\ln\left(\frac{\xi}{\varepsilon}\right)\right)$ additional iterations, where $A$ is the constraint matrix, $B$ is the optimal basis and $\xi$ is the smallest nonzero in the optimal solution. Furthermore, computational tests mostly confirm the tightness of our iterations bounds. We also show a reciprocal relation between the iteration bound and three equivalent types of condition measures: (i) stability under data perturbation, (ii) proximity to multiple optima, and (iii) the LP sharpness of the instance. Finally, we analyze an "optimized" primal-dual reweighting which offers some intuition concerning the step-size heuristics used in practice.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.04043v1</guid>
      <category>math.OC</category>
      <pubDate>Tue, 08 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Zikai Xiong</dc:creator>
    </item>
    <item>
      <title>OPTAMI: Global Superlinear Convergence of High-order Methods</title>
      <link>https://arxiv.org/abs/2410.04083</link>
      <description>arXiv:2410.04083v1 Announce Type: new 
Abstract: Second-order methods for convex optimization outperform first-order methods in terms of theoretical iteration convergence, achieving rates up to $O(k^{-5})$ for highly-smooth functions. However, their practical performance and applications are limited due to their multi-level structure and implementation complexity. In this paper, we present new results on high-order optimization methods, supported by their practical performance. First, we show that the basic high-order methods, such as the Cubic Regularized Newton Method, exhibit global superlinear convergence for $\mu$-strongly star-convex functions, a class that includes $\mu$-strongly convex functions and some non-convex functions. Theoretical convergence results are both inspired and supported by the practical performance of these methods. Secondly, we propose a practical version of the Nesterov Accelerated Tensor method, called NATA. It significantly outperforms the classical variant and other high-order acceleration techniques in practice. The convergence of NATA is also supported by theoretical results. Finally, we introduce an open-source computational library for high-order methods, called OPTAMI. This library includes various methods, acceleration techniques, and subproblem solvers, all implemented as PyTorch optimizers, thereby facilitating the practical application of high-order methods to a wide range of optimization problems. We hope this library will simplify research and practical comparison of methods beyond first-order.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.04083v1</guid>
      <category>math.OC</category>
      <pubDate>Tue, 08 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Dmitry Kamzolov, Dmitry Pasechnyuk, Artem Agafonov, Alexander Gasnikov, Martin Tak\'a\v{c}</dc:creator>
    </item>
    <item>
      <title>Efficient parameter-free restarted accelerated gradient methods for convex and strongly convex optimization</title>
      <link>https://arxiv.org/abs/2410.04248</link>
      <description>arXiv:2410.04248v1 Announce Type: new 
Abstract: This paper develops a new parameter-free restarted method, namely RPF-SFISTA, and a new parameter-free aggressive regularization method, namely A-REG, for solving strongly convex and convex composite optimization problems, respectively. RPF-SFISTA has the major advantage that it requires no knowledge of both the strong convexity parameter of the entire composite objective and the Lipschitz constant of the gradient. Unlike several other restarted first-order methods which restart an accelerated composite gradient (ACG) method after a predetermined number of ACG iterations have been performed, RPF-SFISTA checks a key inequality at each of iterations to determine when to restart. Extensive computational experiments show that RPF-SFISTA is roughly 3 to 15 times faster than other state-of-the-art restarted methods on four important classes of problems. The A-REG method, developed for convex composite optimization, solves each of its strongly convex regularized subproblems according to a stationarity criterion by using the RPF-SFISTA method with a possibly aggressive choice of initial strong convexity estimate. This scheme is thus more aggressive than several other regularization methods which solve their subproblems by running a standard ACG method for a predetermined number of iterations.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.04248v1</guid>
      <category>math.OC</category>
      <pubDate>Tue, 08 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Arnesh Sujanani, Renato D. C. Monteiro</dc:creator>
    </item>
    <item>
      <title>Pareto Control Barrier Function for Inner Safe Set Maximization Under Input Constraints</title>
      <link>https://arxiv.org/abs/2410.04260</link>
      <description>arXiv:2410.04260v1 Announce Type: new 
Abstract: This article introduces the Pareto Control Barrier Function (PCBF) algorithm to maximize the inner safe set of dynamical systems under input constraints. Traditional Control Barrier Functions (CBFs) ensure safety by maintaining system trajectories within a safe set but often fail to account for realistic input constraints. To address this problem, we leverage the Pareto multi-task learning framework to balance competing objectives of safety and safe set volume. The PCBF algorithm is applicable to high-dimensional systems and is computationally efficient. We validate its effectiveness through comparison with Hamilton-Jacobi reachability for an inverted pendulum and through simulations on a 12-dimensional quadrotor system. Results show that the PCBF consistently outperforms existing methods, yielding larger safe sets and ensuring safety under input constraints.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.04260v1</guid>
      <category>math.OC</category>
      <category>cs.AI</category>
      <category>cs.RO</category>
      <pubDate>Tue, 08 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Xiaoyang Cao, Zhe Fu, Alexandre M. Bayen</dc:creator>
    </item>
    <item>
      <title>MindFlayer: Efficient Asynchronous Parallel SGD in the Presence of Heterogeneous and Random Worker Compute Times</title>
      <link>https://arxiv.org/abs/2410.04285</link>
      <description>arXiv:2410.04285v1 Announce Type: new 
Abstract: We study the problem of minimizing the expectation of smooth nonconvex functions with the help of several parallel workers whose role is to compute stochastic gradients. In particular, we focus on the challenging situation where the workers' compute times are arbitrarily heterogeneous and random. In the simpler regime characterized by arbitrarily heterogeneous but deterministic compute times, Tyurin and Richt\'arik (NeurIPS 2023) recently designed the first theoretically optimal asynchronous SGD method, called Rennala SGD, in terms of a novel complexity notion called time complexity. The starting point of our work is the observation that Rennala SGD can have arbitrarily bad performance in the presence of random compute times -- a setting it was not designed to handle. To advance our understanding of stochastic optimization in this challenging regime, we propose a new asynchronous SGD method, for which we coin the name MindFlayer SGD. Our theory and empirical results demonstrate the superiority of MindFlayer SGD over existing baselines, including Rennala SGD, in cases when the noise is heavy tailed.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.04285v1</guid>
      <category>math.OC</category>
      <category>cs.DC</category>
      <category>cs.LG</category>
      <category>stat.ML</category>
      <pubDate>Tue, 08 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Artavazd Maranjyan, Omar Shaikh Omar, Peter Richt\'arik</dc:creator>
    </item>
    <item>
      <title>Time-reversal solution of BSDEs in stochastic optimal control: a linear quadratic study</title>
      <link>https://arxiv.org/abs/2410.04615</link>
      <description>arXiv:2410.04615v1 Announce Type: new 
Abstract: This paper addresses the numerical solution of backward stochastic differential equations (BSDEs) arising in stochastic optimal control. Specifically, we investigate two BSDEs: one derived from the Hamilton-Jacobi-Bellman equation and the other from the stochastic maximum principle. For both formulations, we analyze and compare two numerical methods. The first utilizes the least-squares Monte-Carlo (LSMC) approach for approximating conditional expectations, while the second leverages a time-reversal (TR) of diffusion processes. Although both methods extend to nonlinear settings, our focus is on the linear-quadratic case, where analytical solutions provide a benchmark. Numerical results demonstrate the superior accuracy and efficiency of the TR approach across both BSDE representations, highlighting its potential for broader applications in stochastic control.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.04615v1</guid>
      <category>math.OC</category>
      <pubDate>Tue, 08 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Yuhang Mei, Amirhossein Taghvaei</dc:creator>
    </item>
    <item>
      <title>New Error Estimates for An Elliptic Distributed Optimal Control Problem with Pointwise Control Constraints</title>
      <link>https://arxiv.org/abs/2410.04643</link>
      <description>arXiv:2410.04643v1 Announce Type: new 
Abstract: We derive error estimates for a linear-quadratic elliptic distributed optimal control problem with pointwise control constraints that can be applied to standard finite element methods and multiscale finite element methods.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.04643v1</guid>
      <category>math.OC</category>
      <category>cs.NA</category>
      <category>math.NA</category>
      <pubDate>Tue, 08 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Susanne C. Brenner, Li-yeng Sung</dc:creator>
    </item>
    <item>
      <title>Nonuniform complete observability; preservation by output feedback and duality results</title>
      <link>https://arxiv.org/abs/2410.04656</link>
      <description>arXiv:2410.04656v1 Announce Type: new 
Abstract: In this paper we propose a new observability property for nonautonomous linear control systems in finite dimension; the nonuniform complete observability, which is more general than the uniform complete observability. The main result of this work will prove that nonuniform complete observability is preserved via output feedback. In addition, the duality between this concept and the recently introduced concept of nonuniform complete controllability will be proved, leading to the result of preservation of nonuniform complete controllability via input feedback.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.04656v1</guid>
      <category>math.OC</category>
      <category>math.CA</category>
      <pubDate>Tue, 08 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Ignacio Huerta</dc:creator>
    </item>
    <item>
      <title>Weak sharp minima at infinity and solution stability in mathematical programming via asymptotic analysis</title>
      <link>https://arxiv.org/abs/2410.04695</link>
      <description>arXiv:2410.04695v1 Announce Type: new 
Abstract: We develop sufficient conditions for the existence of the weak sharp minima at infinity property for nonsmooth optimization problems via asymptotic cones and generalized asymptotic functions. Next, we show that these conditions are also useful for studying the solution stability of nonconvex optimization problems under linear perturbations. Finally, we provide applications for a subclass of quasiconvex functions which is stable under linear additivity and includes the convex ones.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.04695v1</guid>
      <category>math.OC</category>
      <pubDate>Tue, 08 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Felipe Lara, Nguyen Van Tuyen, Tran Van Nghi</dc:creator>
    </item>
    <item>
      <title>Approximate optimality conditions and sensitivity analysis in nearly convex optimization</title>
      <link>https://arxiv.org/abs/2410.04710</link>
      <description>arXiv:2410.04710v1 Announce Type: new 
Abstract: In this paper, approximate optimality conditions and sensitivity analysis in nearly convex optimization are discussed. More precisely, as in the spirit of convex analysis, we introduce the concept of $\varepsilon$-subdifferential for nearly convex functions. Then, we examine some significant properties and rules for the $\varepsilon$-subdifferential. These rules are applied to study optimality conditions as well as sensitivity analysis for parametric nearly convex optimization problems, which are two important topics in optimization theory.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.04710v1</guid>
      <category>math.OC</category>
      <pubDate>Tue, 08 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Nguyen Van Tuyen, Liguo Jiao, Vu Hong Quan, Duong Thi Viet An</dc:creator>
    </item>
    <item>
      <title>Shuffling Gradient Descent-Ascent with Variance Reduction for Nonconvex-Strongly Concave Smooth Minimax Problems</title>
      <link>https://arxiv.org/abs/2410.04761</link>
      <description>arXiv:2410.04761v1 Announce Type: new 
Abstract: In recent years, there has been considerable interest in designing stochastic first-order algorithms to tackle finite-sum smooth minimax problems. To obtain the gradient estimates, one typically relies on the uniform sampling-with-replacement scheme or various sampling-without-replacement (also known as shuffling) schemes. While the former is easier to analyze, the latter often have better empirical performance. In this paper, we propose a novel single-loop stochastic gradient descent-ascent (GDA) algorithm that employs both shuffling schemes and variance reduction to solve nonconvex-strongly concave smooth minimax problems. We show that the proposed algorithm achieves $\epsilon$-stationarity in expectation in $\mathcal{O}(\kappa^2 \epsilon^{-2})$ iterations, where $\kappa$ is the condition number of the problem. This outperforms existing shuffling schemes and matches the complexity of the best-known sampling-with-replacement algorithms. Our proposed algorithm also achieves the same complexity as that of its deterministic counterpart, the two-timescale GDA algorithm. Our numerical experiments demonstrate the superior performance of the proposed algorithm.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.04761v1</guid>
      <category>math.OC</category>
      <category>cs.GT</category>
      <pubDate>Tue, 08 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Xia Jiang, Linglingzhi Zhu, Anthony Man-Cho So, Shisheng Cui, Jian Sun</dc:creator>
    </item>
    <item>
      <title>On the Local Controllability of a Class of Quadratic Systems</title>
      <link>https://arxiv.org/abs/2410.04770</link>
      <description>arXiv:2410.04770v1 Announce Type: new 
Abstract: The local controllability of a rich class of affine nonlinear control systems with nonhomogeneous quadratic drift and constant control vector fields is analyzed. The interest in this particular class of systems stems from the ubiquity in science and engineering of some of its notable representatives, namely the Sprott system, the Lorenz system and the rigid body among others. A necessary and sufficient condition for strong accessibility reminiscent of the Kalman rank condition is derived, and it generalizes Crouch's condition for the rigid body. This condition is in general not sufficient to infer small-time local controllability. However, under some additional mild assumptions local controllability is established. In particular for the Sprott and Lorenz systems, sharp conditions for small-time local controllability are obtained in the single-input case.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.04770v1</guid>
      <category>math.OC</category>
      <pubDate>Tue, 08 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Moise R. Mouyebe, Anthony M. Bloch</dc:creator>
    </item>
    <item>
      <title>Optimal execution with deterministically time varying liquidity: well posedness and price manipulation</title>
      <link>https://arxiv.org/abs/2410.04867</link>
      <description>arXiv:2410.04867v1 Announce Type: new 
Abstract: We investigate the well-posedness in the Hadamard sense and the absence of price manipulation in the optimal execution problem within the Almgren-Chriss framework, where the temporary and permanent impact parameters vary deterministically over time. We present sufficient conditions for the existence of a unique solution and provide second-order conditions for the problem, with a particular focus on scenarios where impact parameters change monotonically over time. Additionally, we establish conditions to prevent transaction-triggered price manipulation in the optimal solution, i.e. the occurence of buying and selling in the same trading program. Our findings are supported by numerical analyses that explore various regimes in simple parametric settings for the dynamics of impact parameters.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.04867v1</guid>
      <category>math.OC</category>
      <category>q-fin.TR</category>
      <pubDate>Tue, 08 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Gianluca Palmari, Fabrizio Lillo, Zoltan Eisler</dc:creator>
    </item>
    <item>
      <title>Extensions of $\mathcal{KL}$ and Lyapunov Functions for Discrete-time Dynamical System Peaks Analysis</title>
      <link>https://arxiv.org/abs/2410.04896</link>
      <description>arXiv:2410.04896v1 Announce Type: new 
Abstract: In this paper, we extend two classes of functions classically involved in asymptotic stability analyses for studying a maximization problem on the reachable values of a discrete-time dynamical system. This maximization problem is called a peaks computation problem. The problem is to find a couple composed of an initial state and a time which maximizes a given function over states. The paper focuses on the time component of the optimal solution which is an integer as the time is discrete. We develop a method to provide an upper bound of this integer from a formula which requires a pair of a strictly increasing and continuous function on [0,1] and a scalar in (0,1). A first result proves that the formula provides, in theory, the optimal integer. However, in practice, the computation cannot be so precise. Then, we develop two alternative methods. The first is based on discontinuous and non strictly increasing/decreasing $\mathcal{KL}$-like functions named $\klgen$ functions. We prove that the existence of a $mathcal{KL}_{\rm gen}$ upper bound is equivalent to the existence of a pair of a strictly increasing and continuous function on [0,1] and a scalar in (0,1). The construction of the strictly increasing continuous function from a $mathcal{KL}_{\rm gen}$ function needs an extension of the famous Sontag's lemma. Finally, we construct a new type of Lyapunov functions, called Opt-Lyapunov functions, well designed for our peaks computation problem. Opt-Lyapunov functions are well designed as we establish an equivalence theorem between the existence of an Opt-Lyapunov function and of a pair of a strictly increasing and continuous function on $[0,1]$ and a scalar in (0,1). The construction of a Opt-Lyapunov function from a pair of a strictly increasing and continuous function on [0,1] and a convergent geometric sequence is insipred by the Yoshizawa construction of Lyapunov functions.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.04896v1</guid>
      <category>math.OC</category>
      <category>math.DS</category>
      <pubDate>Tue, 08 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Assal\'e Adj\'e</dc:creator>
    </item>
    <item>
      <title>Spanning and Splitting: Integer Semidefinite Programming for the Quadratic Minimum Spanning Tree Problem</title>
      <link>https://arxiv.org/abs/2410.04997</link>
      <description>arXiv:2410.04997v1 Announce Type: new 
Abstract: In the quadratic minimum spanning tree problem (QMSTP) one wants to find the minimizer of a quadratic function over all possible spanning trees of a graph. We give two formulations of the QMSTP as mixed-integer semidefinite programs exploiting the algebraic connectivity of a graph. Based on these formulations, we derive a doubly nonnegative relaxation for the QMSTP and investigate classes of valid inequalities to strengthen the relaxation using the Chv\'atal-Gomory procedure for mixed-integer conic programming.
  Solving the resulting relaxations is out of reach for off-the-shelf software. We therefore develop and implement a version of the Peaceman-Rachford splitting method that allows to compute the new bounds for graphs from the literature. The numerical results demonstrate that our bounds significantly improve over existing bounds from the literature in both quality and computation time, in particular for graphs with more than 30 vertices.
  This work is further evidence that semidefinite programming is a valuable tool to obtain high-quality bounds for problems in combinatorial optimization, in particular for those that can be modelled as a quadratic problem.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.04997v1</guid>
      <category>math.OC</category>
      <pubDate>Tue, 08 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Frank de Meijer, Melanie Siebenhofer, Renata Sotirov, Angelika Wiegele</dc:creator>
    </item>
    <item>
      <title>On subdifferential chain rule of matrix factorization and beyond</title>
      <link>https://arxiv.org/abs/2410.05022</link>
      <description>arXiv:2410.05022v1 Announce Type: new 
Abstract: In this paper, we study equality-type Clarke subdifferential chain rules of matrix factorization and factorization machine. Specifically, we show for these problems that provided the latent dimension is larger than some multiple of the problem size (i.e., slightly overparameterized) and the loss function is locally Lipschitz, the subdifferential chain rules hold everywhere. In addition, we examine the tightness of the analysis through some interesting constructions and make some important observations from the perspective of optimization; e.g., we show that for all this type of problems, computing a stationary point is trivial. Some tensor generalizations and neural extensions are also discussed, albeit they remain mostly open.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.05022v1</guid>
      <category>math.OC</category>
      <category>stat.ML</category>
      <pubDate>Tue, 08 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Jiewen Guan, Anthony Man-Cho So</dc:creator>
    </item>
    <item>
      <title>$\ell_1$-norm rank-one symmetric matrix factorization has no spurious second-order stationary points</title>
      <link>https://arxiv.org/abs/2410.05025</link>
      <description>arXiv:2410.05025v1 Announce Type: new 
Abstract: This paper studies the nonsmooth optimization landscape of the $\ell_1$-norm rank-one symmetric matrix factorization problem using tools from second-order variational analysis. Specifically, as the main finding of this paper, we show that any second-order stationary point (and thus local minimizer) of the problem is actually globally optimal. Besides, some other results concerning the landscape of the problem, such as a complete characterization of the set of stationary points, are also developed, which should be interesting in their own rights. Furthermore, with the above theories, we revisit existing results on the generic minimizing behavior of simple algorithms for nonsmooth optimization and showcase the potential risk of their applications to our problem through several examples. Our techniques can potentially be applied to analyze the optimization landscapes of a variety of other more sophisticated nonsmooth learning problems, such as robust low-rank matrix recovery.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.05025v1</guid>
      <category>math.OC</category>
      <category>stat.ML</category>
      <pubDate>Tue, 08 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Jiewen Guan, Anthony Man-Cho So</dc:creator>
    </item>
    <item>
      <title>Nonasymptotic Analysis of Stochastic Gradient Descent with the Richardson-Romberg Extrapolation</title>
      <link>https://arxiv.org/abs/2410.05106</link>
      <description>arXiv:2410.05106v1 Announce Type: new 
Abstract: We address the problem of solving strongly convex and smooth minimization problems using stochastic gradient descent (SGD) algorithm with a constant step size. Previous works suggested to combine the Polyak-Ruppert averaging procedure with the Richardson-Romberg extrapolation technique to reduce the asymptotic bias of SGD at the expense of a mild increase of the variance. We significantly extend previous results by providing an expansion of the mean-squared error of the resulting estimator with respect to the number of iterations $n$. More precisely, we show that the mean-squared error can be decomposed into the sum of two terms: a leading one of order $\mathcal{O}(n^{-1/2})$ with explicit dependence on a minimax-optimal asymptotic covariance matrix, and a second-order term of order $\mathcal{O}(n^{-3/4})$ where the power $3/4$ can not be improved in general. We also extend this result to the $p$-th moment bound keeping optimal scaling of the remainders with respect to $n$. Our analysis relies on the properties of the SGD iterates viewed as a time-homogeneous Markov chain. In particular, we establish that this chain is geometrically ergodic with respect to a suitably defined weighted Wasserstein semimetric.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.05106v1</guid>
      <category>math.OC</category>
      <category>cs.LG</category>
      <category>stat.ML</category>
      <pubDate>Tue, 08 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Marina Sheshukova, Denis Belomestny, Alain Durmus, Eric Moulines, Alexey Naumov, Sergey Samsonov</dc:creator>
    </item>
    <item>
      <title>Decentralized Online Riemannian Optimization with Dynamic Environments</title>
      <link>https://arxiv.org/abs/2410.05128</link>
      <description>arXiv:2410.05128v1 Announce Type: new 
Abstract: This paper develops the first decentralized online Riemannian optimization algorithm on Hadamard manifolds. Our algorithm, the decentralized projected Riemannian gradient descent, iteratively performs local updates using projected Riemannian gradient descent and a consensus step via weighted Frechet mean. Theoretically, we establish linear variance reduction for the consensus step. Building on this, we prove a dynamic regret bound of order ${\cal O}(\sqrt{T(1+P_T)}/\sqrt{(1-\sigma_2(W))})$, where $T$ is the time horizon, $P_T$ represents the path variation measuring nonstationarity, and $\sigma_2(W)$ measures the network connectivity. The weighted Frechet mean in our algorithm incurs a minimization problem, which can be computationally expensive. To further alleviate this cost, we propose a simplified consensus step with a closed-form, replacing the weighted Frechet mean. We then establish linear variance reduction for this alternative and prove that the decentralized algorithm, even with this simple consensus step, achieves the same dynamic regret bound. Finally, we validate our approach with experiments on nonstationary decentralized Frechet mean computation over hyperbolic spaces and the space of symmetric positive definite matrices, demonstrating the effectiveness of our methods.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.05128v1</guid>
      <category>math.OC</category>
      <category>math.DG</category>
      <pubDate>Tue, 08 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Hengchao Chen, Qiang Sun</dc:creator>
    </item>
    <item>
      <title>Avoiding Deadlocks via Weak Deadlock Sets</title>
      <link>https://arxiv.org/abs/2410.05175</link>
      <description>arXiv:2410.05175v1 Announce Type: new 
Abstract: A deadlock occurs in a network when two or more items prevent each other from moving and are stalled. In a general model, items are stored at vertices and each vertex $v$ has a buffer with $b(v)$ slots. Given a route for each item toward its destination, the Deadlock Safety Problem asks whether the current state is safe, i.e., it is possible to deliver each item at its destination, or is bound to deadlock, i.e., any sequence of moves will end up with a set of items stalled. While when $b \geq 2$ the problem is solvable in polynomial time building upon a nice characterization of YES/NO-instances, it is NP-hard on quite simple graphs as grids when $b=1$ and on trees when $b\leq 3$. We improve on these results by means of two new tools, weak deadlock sets and wise states. We show that for general networks and $b$ a state that is wise and without weak deadlock sets -- this can be recognized in polynomial time -- is safe: this is indeed a strengthening of the result for $b\geq 2$. We sharpen this result for trees, where we show that a wise state is safe if and only if it has no weak deadlock set. That is interesting in particular in the context of rail transportation where networks are often single-tracked and deadlock detection and avoidance focuses on local sub-networks, mostly with a tree-like structure. We pose some research questions for future investigations.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.05175v1</guid>
      <category>math.OC</category>
      <category>cs.CC</category>
      <pubDate>Tue, 08 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Gianpaolo Oriolo, Anna Russo Russo</dc:creator>
    </item>
    <item>
      <title>Collaborative Safety-Critical Formation Control with Obstacle Avoidance</title>
      <link>https://arxiv.org/abs/2410.03885</link>
      <description>arXiv:2410.03885v1 Announce Type: cross 
Abstract: This work explores a collaborative method for ensuring safety in multi-agent formation control problems. We formulate a control barrier function (CBF) based safety filter control law for a generic distributed formation controller and extend our previously developed collaborative safety framework to an obstacle avoidance problem for agents with acceleration control inputs. We then incorporate multi-obstacle collision avoidance into the collaborative safety framework. This framework includes a method for computing the maximum capability of agents to satisfy their individual safety requirements. We analyze the convergence rate of our collaborative safety algorithm, and prove the linear-time convergence of cooperating agents to a jointly feasible safe action for all agents under the special case of a tree-structured communication network with a single obstacle for each agent. We illustrate the analytical results via simulation on a mass-spring kinematics-based formation controller and demonstrate the finite-time convergence of the collaborative safety algorithm in the simple proven case, the more general case of a fully-connected system with multiple static obstacles, and with dynamic obstacles.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.03885v1</guid>
      <category>cs.RO</category>
      <category>cs.SY</category>
      <category>eess.SY</category>
      <category>math.OC</category>
      <pubDate>Tue, 08 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Brooks A. Butler, Chi Ho Leung, Philip E. Par\'e</dc:creator>
    </item>
    <item>
      <title>Model Developmental Safety: A Safety-Centric Method and Applications in Vision-Language Models</title>
      <link>https://arxiv.org/abs/2410.03955</link>
      <description>arXiv:2410.03955v1 Announce Type: cross 
Abstract: In the real world, a learning-enabled system usually undergoes multiple cycles of model development to enhance the system's ability to handle difficult or emerging tasks. This continual model development process raises a significant issue that the model development for acquiring new or improving existing capabilities may inadvertently lose capabilities of the old model, also known as catastrophic forgetting. Existing continual learning studies focus on mitigating catastrophic forgetting by trading off performance on previous tasks and new tasks to ensure good average performance. However, they are inadequate for many applications especially in safety-critical domains, as failure to strictly preserve the performance of the old model not only introduces safety risks and uncertainties but also imposes substantial expenses in the re-improving and re-validation of existing properties. To address this issue, we introduce model developmental safety as a guarantee of a learning system such that in the model development process the new model should strictly preserve the existing protected capabilities of the old model while improving its performance on target tasks. To ensure the model developmental safety, we present a safety-centric framework by formulating the model developmental safety as data-dependent constraints. Under this framework, we study how to develop a pretrained vision-language model (aka the CLIP model) for acquiring new capabilities or improving existing capabilities of image classification. We propose an efficient constrained optimization algorithm with theoretical guarantee and use its insights to finetune a CLIP model with task-dependent heads for promoting the model developmental safety. Our experiments on improving vision perception capabilities on autonomous driving and scene recognition datasets demonstrate the efficacy of the proposed approach.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.03955v1</guid>
      <category>cs.LG</category>
      <category>cs.AI</category>
      <category>math.OC</category>
      <category>stat.ML</category>
      <pubDate>Tue, 08 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Gang Li, Wendi Yu, Yao Yao, Wei Tong, Yingbin Liang, Qihang Lin, Tianbao Yang</dc:creator>
    </item>
    <item>
      <title>Decoding Game: On Minimax Optimality of Heuristic Text Generation Strategies</title>
      <link>https://arxiv.org/abs/2410.03968</link>
      <description>arXiv:2410.03968v1 Announce Type: cross 
Abstract: Decoding strategies play a pivotal role in text generation for modern language models, yet a puzzling gap divides theory and practice. Surprisingly, strategies that should intuitively be optimal, such as Maximum a Posteriori (MAP), often perform poorly in practice. Meanwhile, popular heuristic approaches like Top-$k$ and Nucleus sampling, which employ truncation and normalization of the conditional next-token probabilities, have achieved great empirical success but lack theoretical justifications. In this paper, we propose Decoding Game, a comprehensive theoretical framework which reimagines text generation as a two-player zero-sum game between Strategist, who seeks to produce text credible in the true distribution, and Nature, who distorts the true distribution adversarially. After discussing the decomposibility of multi-step generation, we derive the optimal strategy in closed form for one-step Decoding Game. It is shown that the adversarial Nature imposes an implicit regularization on likelihood maximization, and truncation-normalization methods are first-order approximations to the optimal strategy under this regularization. Additionally, by generalizing the objective and parameters of Decoding Game, near-optimal strategies encompass diverse methods such as greedy search, temperature scaling, and hybrids thereof. Numerical experiments are conducted to complement our theoretical analysis.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.03968v1</guid>
      <category>cs.LG</category>
      <category>cs.AI</category>
      <category>cs.GT</category>
      <category>math.OC</category>
      <pubDate>Tue, 08 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Sijin Chen, Omar Hagrass, Jason M. Klusowski</dc:creator>
    </item>
    <item>
      <title>Optimizing Sparse Generalized Singular Vectors for Feature Selection in Proximal Support Vector Machines with Application to Breast and Ovarian Cancer Detection</title>
      <link>https://arxiv.org/abs/2410.03978</link>
      <description>arXiv:2410.03978v1 Announce Type: cross 
Abstract: This paper presents approaches to compute sparse solutions of Generalized Singular Value Problem (GSVP). The GSVP is regularized by $\ell_1$-norm and $\ell_q$-penalty for $0&lt;q&lt;1$, resulting in the $\ell_1$-GSVP and $\ell_q$-GSVP formulations. The solutions of these problems are determined by applying the proximal gradient descent algorithm with a fixed step size. The inherent sparsity levels within the computed solutions are exploited for feature selection, and subsequently, binary classification with non-parallel Support Vector Machines (SVM). For our feature selection task, SVM is integrated into the $\ell_1$-GSVP and $\ell_q$-GSVP frameworks to derive the $\ell_1$-GSVPSVM and $\ell_q$-GSVPSVM variants. Machine learning applications to cancer detection are considered. We remarkably report near-to-perfect balanced accuracy across breast and ovarian cancer datasets using a few selected features.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.03978v1</guid>
      <category>cs.LG</category>
      <category>cs.NA</category>
      <category>math.NA</category>
      <category>math.OC</category>
      <category>q-bio.QM</category>
      <category>stat.ML</category>
      <pubDate>Tue, 08 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Ugochukwu O. Ugwu, Michael Kirby</dc:creator>
    </item>
    <item>
      <title>Riemann Sum Optimization for Accurate Integrated Gradients Computation</title>
      <link>https://arxiv.org/abs/2410.04118</link>
      <description>arXiv:2410.04118v1 Announce Type: cross 
Abstract: Integrated Gradients (IG) is a widely used algorithm for attributing the outputs of a deep neural network to its input features. Due to the absence of closed-form integrals for deep learning models, inaccurate Riemann Sum approximations are used to calculate IG. This often introduces undesirable errors in the form of high levels of noise, leading to false insights in the model's decision-making process. We introduce a framework, RiemannOpt, that minimizes these errors by optimizing the sample point selection for the Riemann Sum. Our algorithm is highly versatile and applicable to IG as well as its derivatives like Blur IG and Guided IG. RiemannOpt achieves up to 20% improvement in Insertion Scores. Additionally, it enables its users to curtail computational costs by up to four folds, thereby making it highly functional for constrained environments.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.04118v1</guid>
      <category>cs.LG</category>
      <category>cs.AI</category>
      <category>math.OC</category>
      <pubDate>Tue, 08 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-sa/4.0/</dc:rights>
      <dc:creator>Swadesh Swain, Shree Singhi</dc:creator>
    </item>
    <item>
      <title>A branch-&amp;-price approach to the unrooted maximum agreement forest problem</title>
      <link>https://arxiv.org/abs/2410.04122</link>
      <description>arXiv:2410.04122v1 Announce Type: cross 
Abstract: We propose the first branch-&amp;-price algorithm for the maximum agreement forest problem on unrooted binary trees: given two unrooted X-labelled binary trees we seek to partition X into a minimum number of blocks such that the induced subtrees are disjoint and have the same topologies in both trees. We provide a dynamic programming algorithm for the weighted maximum agreement subtree problem to solve the pricing problem. When combined with rigorous polynomial-time pre-processing our branch-&amp;-price algorithm exhibits (beyond) state-of-the-art performance.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.04122v1</guid>
      <category>cs.DS</category>
      <category>math.OC</category>
      <category>q-bio.PE</category>
      <pubDate>Tue, 08 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Martin Frohn, Steven Kelk, Simona Vychytilova</dc:creator>
    </item>
    <item>
      <title>Trajectory elongation strategies with minimum curvature discontinuities for a Dubins vehicle</title>
      <link>https://arxiv.org/abs/2410.04129</link>
      <description>arXiv:2410.04129v1 Announce Type: cross 
Abstract: In this paper, we present strategies for designing curvature-bounded trajectories of any desired length between any two given oriented points. The proposed trajectory is constructed by the concatenation of three circular arcs of varying radii. Such a trajectory guarantees a complete coverage of the maximum set of reachable lengths while minimising the number of changeover points in the trajectory to a maximum of two under all scenarios. Additionally, by using the notion of internally tangent circles, we expand the set of Circle-Circle-Circle trajectories to eight kinds, consisting of {LLL, LLR, LRR, LRL, RRL, RLL, RLR, RRR} paths. The paper presents a mathematical formulation of the proposed trajectory and the conditions for the existence and classification of each kind of trajectory. We also analyse the variation of the length of the trajectory using suitable elongation strategies and derive the set of reachable lengths for all pairs of oriented points. Finally, the results of this paper are illustrated using numerical simulations.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.04129v1</guid>
      <category>eess.SY</category>
      <category>cs.RO</category>
      <category>cs.SY</category>
      <category>math.OC</category>
      <pubDate>Tue, 08 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Aditya K. Rao, Twinkle Tripathy</dc:creator>
    </item>
    <item>
      <title>SGD with memory: fundamental properties and stochastic acceleration</title>
      <link>https://arxiv.org/abs/2410.04228</link>
      <description>arXiv:2410.04228v1 Announce Type: cross 
Abstract: An important open problem is the theoretically feasible acceleration of mini-batch SGD-type algorithms on quadratic problems with power-law spectrum. In the non-stochastic setting, the optimal exponent $\xi$ in the loss convergence $L_t\sim C_Lt^{-\xi}$ is double that in plain GD and is achievable using Heavy Ball (HB) with a suitable schedule; this no longer works in the presence of mini-batch noise. We address this challenge by considering first-order methods with an arbitrary fixed number $M$ of auxiliary velocity vectors (*memory-$M$ algorithms*). We first prove an equivalence between two forms of such algorithms and describe them in terms of suitable characteristic polynomials. Then we develop a general expansion of the loss in terms of signal and noise propagators. Using it, we show that losses of stationary stable memory-$M$ algorithms always retain the exponent $\xi$ of plain GD, but can have different constants $C_L$ depending on their effective learning rate that generalizes that of HB. We prove that in memory-1 algorithms we can make $C_L$ arbitrarily small while maintaining stability. As a consequence, we propose a memory-1 algorithm with a time-dependent schedule that we show heuristically and experimentally to improve the exponent $\xi$ of plain SGD.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.04228v1</guid>
      <category>cs.LG</category>
      <category>math.OC</category>
      <pubDate>Tue, 08 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Dmitry Yarotsky, Maksim Velikanov</dc:creator>
    </item>
    <item>
      <title>Compositional Diffusion Models for Powered Descent Trajectory Generation with Flexible Constraints</title>
      <link>https://arxiv.org/abs/2410.04261</link>
      <description>arXiv:2410.04261v1 Announce Type: cross 
Abstract: This work introduces TrajDiffuser, a compositional diffusion-based flexible and concurrent trajectory generator for 6 degrees of freedom powered descent guidance. TrajDiffuser is a statistical model that learns the multi-modal distributions of a dataset of simulated optimal trajectories, each subject to only one or few constraints that may vary for different trajectories. During inference, the trajectory is generated simultaneously over time, providing stable long-horizon planning, and constraints can be composed together, increasing the model's generalizability and decreasing the training data required. The generated trajectory is then used to initialize an optimizer, increasing its robustness and speed.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.04261v1</guid>
      <category>cs.RO</category>
      <category>cs.LG</category>
      <category>cs.SY</category>
      <category>eess.SY</category>
      <category>math.OC</category>
      <pubDate>Tue, 08 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Julia Briden, Yilun Du, Enrico M. Zucchelli, Richard Linares</dc:creator>
    </item>
    <item>
      <title>Thermal Bootstrap of Matrix Quantum Mechanics</title>
      <link>https://arxiv.org/abs/2410.04262</link>
      <description>arXiv:2410.04262v1 Announce Type: cross 
Abstract: We implement a bootstrap method that combines Schwinger-Dyson equations, thermal inequalities, and semidefinite relaxations of matrix logarithm in the ungauged one-matrix quantum mechanics, at finite rank N as well as in the large N limit, and determine finite temperature observables that interpolate between available analytic results in the low and high temperature limits respectively. We also obtain bootstrap bounds on thermal phase transition as well as preliminary results in the ungauged two-matrix quantum mechanics.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.04262v1</guid>
      <category>hep-th</category>
      <category>cond-mat.str-el</category>
      <category>math.OC</category>
      <pubDate>Tue, 08 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Minjae Cho, Barak Gabai, Joshua Sandor, Xi Yin</dc:creator>
    </item>
    <item>
      <title>Coalescing Force of Group Pressure: Consensus in Nonlinear Opinion Dynamics</title>
      <link>https://arxiv.org/abs/2410.04301</link>
      <description>arXiv:2410.04301v1 Announce Type: cross 
Abstract: This work extends the recent opinion dynamics model from Cheng et al., emphasizing the role of group pressure in consensus formation. We generalize the findings to incorporate social influence algorithms with general time-varying, opinion-dependent weights and multidimensional opinions, beyond bounded confidence dynamics. We demonstrate that, with uniformly positive conformity levels, group pressure consistently drives consensus and provide a tighter estimate for the convergence rate. Unlike previous models, the common public opinion in our framework can assume arbitrary forms within the convex hull of current opinions, offering flexibility applicable to real-world scenarios such as opinion polls with random participant selection. This analysis provides deeper insights into how group pressure mechanisms foster consensus under diverse conditions.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.04301v1</guid>
      <category>physics.soc-ph</category>
      <category>cs.MA</category>
      <category>cs.SY</category>
      <category>eess.SY</category>
      <category>math.DS</category>
      <category>math.OC</category>
      <pubDate>Tue, 08 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Iryna Zabarianska, Anton V. Proskurnikov</dc:creator>
    </item>
    <item>
      <title>Quantum Approximate Optimization Algorithms for Maxmimum Cut on Low-Girth Graphs</title>
      <link>https://arxiv.org/abs/2410.04409</link>
      <description>arXiv:2410.04409v1 Announce Type: cross 
Abstract: Maximum cut (MaxCut) on graphs is a classic NP-hard problem. In quantum computing, Farhi, Gutmann, and Goldstone proposed the Quantum Approximate Optimization Algorithm (QAOA) for solving the MaxCut problem. Its guarantee on cut fraction (the fraction of edges in the output cut over all edges) was mainly studied for high-girth graphs, i.e., graphs with only long cycles. On the other hand, low-girth graphs are ubiquitous in theoretical computer science, including expander graphs being outstanding examples with wide applications in theory and beyond. In this paper, we apply QAOA to MaxCut on a set of expander graphs proposed by Mohanty and O'Donnell known as additive product graphs. Additionally, we apply multi-angle QAOA (ma-QAOA) to better utilize the graph structure of additive product graphs in ansatz design. In theory, we derive an iterative formula to calculate the expected cut fraction of such graphs. On the other hand, we conduct numerical experiments to compare between best-known classical local algorithms and QAOA with constant depth. Our results demonstrate that QAOA outperforms the best-known classical algorithms by 0.3% to 5.2% on several additive product graphs, while ma-QAOA further enhances this advantage by an additional 0.6% to 2.5%. In particular, we observe cases that ma-QAOA exhibits superiority over best-known classical algorithms but QAOA does not. Furthermore, we extend our experiments to planar graphs such as tiling grid graphs, where QAOA also demonstrates an advantage.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.04409v1</guid>
      <category>quant-ph</category>
      <category>cs.DS</category>
      <category>math.OC</category>
      <pubDate>Tue, 08 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Tongyang Li, Yuexin Su, Ziyi Yang, Shengyu Zhang</dc:creator>
    </item>
    <item>
      <title>A Comprehensive Framework for Analyzing the Convergence of Adam: Bridging the Gap with SGD</title>
      <link>https://arxiv.org/abs/2410.04458</link>
      <description>arXiv:2410.04458v1 Announce Type: cross 
Abstract: Adaptive Moment Estimation (Adam) is a cornerstone optimization algorithm in deep learning, widely recognized for its flexibility with adaptive learning rates and efficiency in handling large-scale data. However, despite its practical success, the theoretical understanding of Adam's convergence has been constrained by stringent assumptions, such as almost surely bounded stochastic gradients or uniformly bounded gradients, which are more restrictive than those typically required for analyzing stochastic gradient descent (SGD).
  In this paper, we introduce a novel and comprehensive framework for analyzing the convergence properties of Adam. This framework offers a versatile approach to establishing Adam's convergence. Specifically, we prove that Adam achieves asymptotic (last iterate sense) convergence in both the almost sure sense and the \(L_1\) sense under the relaxed assumptions typically used for SGD, namely \(L\)-smoothness and the ABC inequality. Meanwhile, under the same assumptions, we show that Adam attains non-asymptotic sample complexity bounds similar to those of SGD.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.04458v1</guid>
      <category>cs.LG</category>
      <category>math.OC</category>
      <pubDate>Tue, 08 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Ruinan Jin, Xiao Li, Yaoliang Yu, Baoxiang Wang</dc:creator>
    </item>
    <item>
      <title>Numerical Solution for Nonlinear 4D Variational Data Assimilation (4D-Var) via ADMM</title>
      <link>https://arxiv.org/abs/2410.04471</link>
      <description>arXiv:2410.04471v1 Announce Type: cross 
Abstract: The four-dimensional variational data assimilation (4D-Var) has emerged as an important methodology, widely used in numerical weather prediction, oceanographic modeling, and climate forecasting. Classical unconstrained gradient-based algorithms often struggle with local minima, making their numerical performance highly sensitive to the initial guess. In this study, we exploit the separable structure of the 4D-Var problem to propose a practical variant of the alternating direction method of multipliers (ADMM), referred to as the linearized multi-block ADMM with regularization. Unlike classical first-order optimization methods that primarily focus on initial conditions, our approach derives the Euler-Lagrange equation for the entire dynamical system, enabling more comprehensive and effective utilization of observational data. When the initial condition is poorly chosen, the arg min operation steers the iteration towards the observational data, thereby reducing sensitivity to the initial guess. The quadratic subproblems further simplify the solution process, while the parallel structure enhances computational efficiency, especially when utilizing modern hardware. To validate our approach, we demonstrate its superior performance using the Lorenz system, even in the presence of noisy observational data. Furthermore, we showcase the effectiveness of the linearized multi-block ADMM with regularization in solving the 4D-Var problems for the viscous Burgers' equation, across various numerical schemes, including finite difference, finite element, and spectral methods. Finally, we illustrate the recovery of dynamics under noisy observational data in a 2D turbulence scenario, particularly focusing on vorticity concentration, highlighting the robustness of our algorithm in handling complex physical phenomena.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.04471v1</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <category>math.OC</category>
      <category>physics.flu-dyn</category>
      <pubDate>Tue, 08 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Bowen Li, Bin Shi</dc:creator>
    </item>
    <item>
      <title>Fast algorithm for sparse least trimmed squares via trimmed-regularized reformulation</title>
      <link>https://arxiv.org/abs/2410.04554</link>
      <description>arXiv:2410.04554v1 Announce Type: cross 
Abstract: The least trimmed squares (LTS) is a reasonable formulation of robust regression whereas it suffers from high computational cost due to the nonconvexity and nonsmoothness of its objective function. The most frequently used FAST-LTS algorithm is particularly slow when a sparsity-inducing penalty such as the $\ell_1$ norm is added. This paper proposes a computationally inexpensive algorithm for the sparse LTS, which is based on the proximal gradient method with a reformulation technique. Proposed method is equipped with theoretical convergence preferred over existing methods. Numerical experiments show that our method efficiently yields small objective value.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.04554v1</guid>
      <category>stat.CO</category>
      <category>math.OC</category>
      <category>stat.ME</category>
      <pubDate>Tue, 08 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Shotaro Yagishita</dc:creator>
    </item>
    <item>
      <title>Tight Stability, Convergence, and Robustness Bounds for Predictive Coding Networks</title>
      <link>https://arxiv.org/abs/2410.04708</link>
      <description>arXiv:2410.04708v1 Announce Type: cross 
Abstract: Energy-based learning algorithms, such as predictive coding (PC), have garnered significant attention in the machine learning community due to their theoretical properties, such as local operations and biologically plausible mechanisms for error correction. In this work, we rigorously analyze the stability, robustness, and convergence of PC through the lens of dynamical systems theory. We show that, first, PC is Lyapunov stable under mild assumptions on its loss and residual energy functions, which implies intrinsic robustness to small random perturbations due to its well-defined energy-minimizing dynamics. Second, we formally establish that the PC updates approximate quasi-Newton methods by incorporating higher-order curvature information, which makes them more stable and able to converge with fewer iterations compared to models trained via backpropagation (BP). Furthermore, using this dynamical framework, we provide new theoretical bounds on the similarity between PC and other algorithms, i.e., BP and target propagation (TP), by precisely characterizing the role of higher-order derivatives. These bounds, derived through detailed analysis of the Hessian structures, show that PC is significantly closer to quasi-Newton updates than TP, providing a deeper understanding of the stability and efficiency of PC compared to conventional learning methods.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.04708v1</guid>
      <category>cs.LG</category>
      <category>cs.AI</category>
      <category>cs.NE</category>
      <category>math.OC</category>
      <category>stat.ML</category>
      <pubDate>Tue, 08 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Ankur Mali, Tommaso Salvatori, Alexander Ororbia</dc:creator>
    </item>
    <item>
      <title>Smart energy management: process structure-based hybrid neural networks for optimal scheduling and economic predictive control in integrated systems</title>
      <link>https://arxiv.org/abs/2410.04743</link>
      <description>arXiv:2410.04743v1 Announce Type: cross 
Abstract: Integrated energy systems (IESs) are complex systems consisting of diverse operating units spanning multiple domains. To address its operational challenges, we propose a physics-informed hybrid time-series neural network (NN) surrogate to predict the dynamic performance of IESs across multiple time scales. This neural network-based modeling approach develops time-series multi-layer perceptrons (MLPs) for the operating units and integrates them with prior process knowledge about system structure and fundamental dynamics. This integration forms three hybrid NNs (long-term, slow, and fast MLPs) that predict the entire system dynamics across multiple time scales. Leveraging these MLPs, we design an NN-based scheduler and an NN-based economic model predictive control (NEMPC) framework to meet global operational requirements: rapid electrical power responsiveness to operators requests, adequate cooling supply to customers, and increased system profitability, while addressing the dynamic time-scale multiplicity present in IESs. The proposed day-ahead scheduler is formulated using the ReLU network-based MLP, which effectively represents IES performance under a broad range of conditions from a long-term perspective. The scheduler is then exactly recast into a mixed-integer linear programming problem for efficient evaluation. The real-time NEMPC, based on slow and fast MLPs, comprises two sequential distributed control agents: a slow NEMPC for the cooling-dominant subsystem with slower transient responses and a fast NEMPC for the power-dominant subsystem with faster responses. Extensive simulations demonstrate that the developed scheduler and NEMPC schemes outperform their respective benchmark scheduler and controller by about 25% and 40%. Together, they enhance overall system performance by over 70% compared to benchmark approaches.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.04743v1</guid>
      <category>eess.SY</category>
      <category>cs.LG</category>
      <category>cs.SY</category>
      <category>math.OC</category>
      <pubDate>Tue, 08 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Long Wu (University of Alberta), Xunyuan Yin (University of Alberta), Lei Pan (University of Alberta), Jinfeng Liu (University of Alberta)</dc:creator>
    </item>
    <item>
      <title>A Differentially Private Energy Trading Mechanism Approaching Social Optimum</title>
      <link>https://arxiv.org/abs/2410.04787</link>
      <description>arXiv:2410.04787v1 Announce Type: cross 
Abstract: This paper proposes a differentially private energy trading mechanism for prosumers in peer-to-peer (P2P) markets, offering provable privacy guarantees while approaching the Nash equilibrium with nearly socially optimal efficiency. We first model the P2P energy trading as a (generalized) Nash game and prove the vulnerability of traditional distributed algorithms to privacy attacks through an adversarial inference model. To address this challenge, we develop a privacy-preserving Nash equilibrium seeking algorithm incorporating carefully calibrated Laplacian noise. We prove that the proposed algorithm achieves $\epsilon$-differential privacy while converging in expectation to the Nash equilibrium with a suitable stepsize. Numerical experiments are conducted to evaluate the algorithm's robustness against privacy attacks, convergence behavior, and optimality compared to the non-private solution. Results demonstrate that our mechanism effectively protects prosumers' sensitive information while maintaining near-optimal market outcomes, offering a practical approach for privacy-preserving coordination in P2P markets.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.04787v1</guid>
      <category>cs.GT</category>
      <category>math.OC</category>
      <pubDate>Tue, 08 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Yuji Cao, Yue Chen</dc:creator>
    </item>
    <item>
      <title>An Effective Positivstellensatz over the Rational Numbers for Finite Semialgebraic Sets</title>
      <link>https://arxiv.org/abs/2410.04845</link>
      <description>arXiv:2410.04845v1 Announce Type: cross 
Abstract: We study the problem of representing multivariate polynomials with rational coefficients, which are nonnegative and strictly positive on finite semialgebraic sets, using rational sums of squares.
  We focus on the case of finite semialgebraic sets S defined by equality constraints, generating a zero-dimensional ideal I, and by nonnegative sign constraints.
  First, we obtain existential results. We prove that a strictly positive polynomial f with coefficients in a subfield K of R has a representation in terms of weighted Sums-of-Squares with coefficients in this field, even if the ideal I is not radical. We generalize this result to the case where f is nonnegative on S and (f ) + (I : f ) = 1. We deduce that nonnegative polynomials with coefficients in K can be represented in terms of Sum-of-Squares of polynomials with coefficients in K, when the ideal is radical.
  Second, we obtain degree bounds for such Sums-of-Squares representations, which depend linearly on the regularity of the ideal and the degree of the defining equations, when they form a graded basis.
  Finally, we analyze the bit complexity of the Sums-of-Squares representations for polynomials with coefficients in Q, in the case the ideal is radical. The bitsize bounds are quadratic or cubic in the Bezout bound, and linear in the regularity, generalizing and improving previous results obtained for special zero dimensional ideals.
  As an application in the context of polynomial optimization, we retrieve and improve results on the finite convergence and exactness of the moment/Sums-of-Squares hierarchy.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.04845v1</guid>
      <category>math.AG</category>
      <category>math.AC</category>
      <category>math.OC</category>
      <pubDate>Tue, 08 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Lorenzo Baldi, Teresa Krick, Bernard Mourrain</dc:creator>
    </item>
    <item>
      <title>Wide Neural Networks Trained with Weight Decay Provably Exhibit Neural Collapse</title>
      <link>https://arxiv.org/abs/2410.04887</link>
      <description>arXiv:2410.04887v1 Announce Type: cross 
Abstract: Deep neural networks (DNNs) at convergence consistently represent the training data in the last layer via a highly symmetric geometric structure referred to as neural collapse. This empirical evidence has spurred a line of theoretical research aimed at proving the emergence of neural collapse, mostly focusing on the unconstrained features model. Here, the features of the penultimate layer are free variables, which makes the model data-agnostic and, hence, puts into question its ability to capture DNN training. Our work addresses the issue, moving away from unconstrained features and studying DNNs that end with at least two linear layers. We first prove generic guarantees on neural collapse that assume (i) low training error and balancedness of the linear layers (for within-class variability collapse), and (ii) bounded conditioning of the features before the linear part (for orthogonality of class-means, as well as their alignment with weight matrices). We then show that such assumptions hold for gradient descent training with weight decay: (i) for networks with a wide first layer, we prove low training error and balancedness, and (ii) for solutions that are either nearly optimal or stable under large learning rates, we additionally prove the bounded conditioning. Taken together, our results are the first to show neural collapse in the end-to-end training of DNNs.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.04887v1</guid>
      <category>cs.LG</category>
      <category>math.OC</category>
      <category>stat.ML</category>
      <pubDate>Tue, 08 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Arthur Jacot, Peter S\'uken\'ik, Zihan Wang, Marco Mondelli</dc:creator>
    </item>
    <item>
      <title>Decomposition Polyhedra of Piecewise Linear Functions</title>
      <link>https://arxiv.org/abs/2410.04907</link>
      <description>arXiv:2410.04907v1 Announce Type: cross 
Abstract: In this paper we contribute to the frequently studied question of how to decompose a continuous piecewise linear (CPWL) function into a difference of two convex CPWL functions. Every CPWL function has infinitely many such decompositions, but for applications in optimization and neural network theory, it is crucial to find decompositions with as few linear pieces as possible. This is a highly challenging problem, as we further demonstrate by disproving a recently proposed approach by Tran and Wang [Minimal representations of tropical rational functions. Algebraic Statistics, 15(1):27-59, 2024]. To make the problem more tractable, we propose to fix an underlying polyhedral complex determining the possible locus of nonlinearity. Under this assumption, we prove that the set of decompositions forms a polyhedron that arises as intersection of two translated cones. We prove that irreducible decompositions correspond to the bounded faces of this polyhedron and minimal solutions must be vertices. We then identify cases with a unique minimal decomposition, and illustrate how our insights have consequences in the theory of submodular functions. Finally, we improve upon previous constructions of neural networks for a given convex CPWL function and apply our framework to obtain results in the nonconvex case.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.04907v1</guid>
      <category>math.CO</category>
      <category>cs.DM</category>
      <category>cs.LG</category>
      <category>cs.NE</category>
      <category>math.OC</category>
      <pubDate>Tue, 08 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Marie-Charlotte Brandenburg, Moritz Grillo, Christoph Hertrich</dc:creator>
    </item>
    <item>
      <title>Function Gradient Approximation with Random Shallow ReLU Networks with Control Applications</title>
      <link>https://arxiv.org/abs/2410.05071</link>
      <description>arXiv:2410.05071v1 Announce Type: cross 
Abstract: Neural networks are widely used to approximate unknown functions in control. A common neural network architecture uses a single hidden layer (i.e. a shallow network), in which the input parameters are fixed in advance and only the output parameters are trained. The typical formal analysis asserts that if output parameters exist to approximate the unknown function with sufficient accuracy, then desired control performance can be achieved. A long-standing theoretical gap was that no conditions existed to guarantee that, for the fixed input parameters, required accuracy could be obtained by training the output parameters. Our recent work has partially closed this gap by demonstrating that if input parameters are chosen randomly, then for any sufficiently smooth function, with high-probability there are output parameters resulting in $O((1/m)^{1/2})$ approximation errors, where $m$ is the number of neurons. However, some applications, notably continuous-time value function approximation, require that the network approximates the both the unknown function and its gradient with sufficient accuracy. In this paper, we show that randomly generated input parameters and trained output parameters result in gradient errors of $O((\log(m)/m)^{1/2})$, and additionally, improve the constants from our prior work. We show how to apply the result to policy evaluation problems.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.05071v1</guid>
      <category>cs.LG</category>
      <category>cs.SY</category>
      <category>eess.SY</category>
      <category>math.OC</category>
      <category>math.ST</category>
      <category>stat.TH</category>
      <pubDate>Tue, 08 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Andrew Lamperski, Siddharth Salapaka</dc:creator>
    </item>
    <item>
      <title>A Simulation-Free Deep Learning Approach to Stochastic Optimal Control</title>
      <link>https://arxiv.org/abs/2410.05163</link>
      <description>arXiv:2410.05163v1 Announce Type: cross 
Abstract: We propose a simulation-free algorithm for the solution of generic problems in stochastic optimal control (SOC). Unlike existing methods, our approach does not require the solution of an adjoint problem, but rather leverages Girsanov theorem to directly calculate the gradient of the SOC objective on-policy. This allows us to speed up the optimization of control policies parameterized by neural networks since it completely avoids the expensive back-propagation step through stochastic differential equations (SDEs) used in the Neural SDE framework. In particular, it enables us to solve SOC problems in high dimension and on long time horizons. We demonstrate the efficiency of our approach in various domains of applications, including standard stochastic optimal control problems, sampling from unnormalized distributions via construction of a Schr\"odinger-F\"ollmer process, and fine-tuning of pre-trained diffusion models. In all cases our method is shown to outperform the existing methods in both the computing time and memory efficiency.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.05163v1</guid>
      <category>cs.LG</category>
      <category>math.OC</category>
      <pubDate>Tue, 08 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Mengjian Hua, Matthieu Lauri\`ere, Eric Vanden-Eijnden</dc:creator>
    </item>
    <item>
      <title>Singular stochastic control problems motivated by the optimal sustainable exploitation of an ecosystem</title>
      <link>https://arxiv.org/abs/2008.05576</link>
      <description>arXiv:2008.05576v2 Announce Type: replace 
Abstract: We derive the explicit solutions to singular stochastic control problems of the monotone follower type with (a) an expected discounted criterion, (b) an expected ergodic criterion and (c) a pathwise ergodic criterion. These problems have been motivated by the optimal sustainable exploitation of an ecosystem, such as a natural fishery. Under general assumptions on the diffusion coefficients, the discounting rate function, the running payoff function and the marginal profit of control action, we show that the optimal strategies are of a threshold type. We solve the three problems by first constructing suitable solutions to their associated HJB equations, which take the form of quasi-variational inequalities with gradient constraints. In the cases of the ergodic control problems, we also use a suitable new variational argument. Furthermore, we establish the convergence of the solution of the discounted control problem to the one of the ergodic control problems as the discounting rate function tends to 0 in an Abelian sense.</description>
      <guid isPermaLink="false">oai:arXiv.org:2008.05576v2</guid>
      <category>math.OC</category>
      <category>math.PR</category>
      <pubDate>Tue, 08 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Gechun Liang, Zhesheng Liu, Mihail Zervos</dc:creator>
    </item>
    <item>
      <title>A Validation Approach to Over-parameterized Matrix and Image Recovery</title>
      <link>https://arxiv.org/abs/2209.10675</link>
      <description>arXiv:2209.10675v2 Announce Type: replace 
Abstract: This paper studies the problem of recovering a low-rank matrix from several noisy random linear measurements. We consider the setting where the rank of the ground-truth matrix is unknown a priori and use an objective function built from a rank-overspecified factored representation of the matrix variable, where the global optimal solutions overfit and do not correspond to the underlying ground truth. We then solve the associated nonconvex problem using gradient descent with small random initialization. We show that as long as the measurement operators satisfy the restricted isometry property (RIP) with its rank parameter scaling with the rank of the ground-truth matrix rather than scaling with the overspecified matrix rank, gradient descent iterations are on a particular trajectory towards the ground-truth matrix and achieve nearly information-theoretically optimal recovery when it is stopped appropriately. We then propose an efficient stopping strategy based on the common hold-out method and show that it detects a nearly optimal estimator provably. Moreover, experiments show that the proposed validation approach can also be efficiently used for image restoration with deep image prior, which over-parameterizes an image with a deep network.</description>
      <guid isPermaLink="false">oai:arXiv.org:2209.10675v2</guid>
      <category>math.OC</category>
      <category>cs.LG</category>
      <category>eess.IV</category>
      <category>stat.ML</category>
      <pubDate>Tue, 08 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Lijun Ding, Zhen Qin, Liwei Jiang, Jinxin Zhou, Zhihui Zhu</dc:creator>
    </item>
    <item>
      <title>A Sequential Quadratic Programming Method with High Probability Complexity Bounds for Nonlinear Equality Constrained Stochastic Optimization</title>
      <link>https://arxiv.org/abs/2301.00477</link>
      <description>arXiv:2301.00477v2 Announce Type: replace 
Abstract: A step-search sequential quadratic programming method is proposed for solving nonlinear equality constrained stochastic optimization problems. It is assumed that constraint function values and derivatives are available, but only stochastic approximations of the objective function and its associated derivatives can be computed via inexact probabilistic zeroth- and first-order oracles. Under reasonable assumptions, a high-probability bound on the iteration complexity of the algorithm to approximate first-order stationarity is derived. Numerical results on standard nonlinear optimization test problems illustrate the advantages and limitations of our proposed method.</description>
      <guid isPermaLink="false">oai:arXiv.org:2301.00477v2</guid>
      <category>math.OC</category>
      <category>stat.ML</category>
      <pubDate>Tue, 08 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Albert S. Berahas, Miaolan Xie, Baoyu Zhou</dc:creator>
    </item>
    <item>
      <title>Optimal control of port-Hamiltonian systems: energy, entropy, and exergy</title>
      <link>https://arxiv.org/abs/2306.08914</link>
      <description>arXiv:2306.08914v2 Announce Type: replace 
Abstract: We consider irreversible and coupled reversible-irreversible nonlinear port-Hamiltonian systems and the respective sets of thermodynamic equilibria. In particular, we are concerned with optimal state transitions and output stabilization on finite-time horizons. We analyze a class of optimal control problems, where the performance functional can be interpreted as a linear combination of energy supply, entropy generation, or exergy supply. Our results establish the integral turnpike property towards the set of thermodynamic equilibria providing a rigorous connection of optimal system trajectories to optimal steady states. Throughout the paper, we illustrate our findings by means of two examples: a network of heat exchangers and a gas-piston system.</description>
      <guid isPermaLink="false">oai:arXiv.org:2306.08914v2</guid>
      <category>math.OC</category>
      <category>cs.SY</category>
      <category>eess.SY</category>
      <category>math.DS</category>
      <pubDate>Tue, 08 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Friedrich Philipp, Manuel Schaller, Karl Worthmann, Timm Faulwasser, Bernhard Maschke</dc:creator>
    </item>
    <item>
      <title>Stability-Adjusted Cross-Validation for Sparse Linear Regression</title>
      <link>https://arxiv.org/abs/2306.14851</link>
      <description>arXiv:2306.14851v2 Announce Type: replace 
Abstract: Given a high-dimensional covariate matrix and a response vector, ridge-regularized sparse linear regression selects a subset of features that explains the relationship between covariates and the response in an interpretable manner. To select the sparsity and robustness of linear regressors, techniques like k-fold cross-validation are commonly used for hyperparameter tuning. However, cross-validation substantially increases the computational cost of sparse regression as it requires solving many mixed-integer optimization problems (MIOs). Additionally, validation metrics often serve as noisy estimators of test set errors, with different hyperparameter combinations leading to models with different noise levels. Therefore, optimizing over these metrics is vulnerable to out-of-sample disappointment, especially in underdetermined settings. To improve upon this state of affairs, we make two key contributions. First, motivated by the generalization theory literature, we propose selecting hyperparameters that minimize a weighted sum of a cross-validation metric and a model's output stability, thus reducing the risk of poor out-of-sample performance. Second, we leverage ideas from the mixed-integer optimization literature to obtain computationally tractable relaxations of k-fold cross-validation metrics and the output stability of regressors, facilitating hyperparameter selection after solving fewer MIOs. These relaxations result in an efficient cyclic coordinate descent scheme, achieving lower validation errors than via traditional methods such as grid search. On synthetic datasets, our confidence adjustment procedure improves out-of-sample performance by 2%-5% compared to minimizing the k-fold error alone. On 13 real-world datasets, our confidence adjustment procedure reduces test set error by 2%, on average.</description>
      <guid isPermaLink="false">oai:arXiv.org:2306.14851v2</guid>
      <category>math.OC</category>
      <category>cs.LG</category>
      <category>stat.ME</category>
      <pubDate>Tue, 08 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Ryan Cory-Wright, Andr\'es G\'omez</dc:creator>
    </item>
    <item>
      <title>Tracking controllability for the heat equation</title>
      <link>https://arxiv.org/abs/2310.00314</link>
      <description>arXiv:2310.00314v3 Announce Type: replace 
Abstract: We study the tracking or sidewise controllability of the heat equation. More precisely, we seek for controls that, acting on part of the boundary of the domain where the heat process evolves, aim to assure that the normal trace or flux on the complementary set tracks a given trajectory. The dual equivalent observability problem is identified. It consists on estimating the boundary sources, localized on a given subset of the boundary, out of boundary measurements on the complementary subset. Classical unique continuation and smoothing properties of the heat equation allow us proving approximate tracking controllability properties and the smoothness of the class of trackable trajectories. We also develop a new transmutation method which allows to transfer known results on the sidewise controllability of the wave equation to the tracking controllability of the heat one. Using the flatness approach we also give explicit estimates on the cost of approximate tracking control. The analysis is complemented with a discussion of some possible variants of these results and a list of open problems.</description>
      <guid isPermaLink="false">oai:arXiv.org:2310.00314v3</guid>
      <category>math.OC</category>
      <pubDate>Tue, 08 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Jon Asier B\'arcena Petiso, Enrique Zuazua</dc:creator>
    </item>
    <item>
      <title>A-Priori Reduction of Scenario Approximation for Automated Generation Control in High-Voltage Power Grids with Renewable Energy</title>
      <link>https://arxiv.org/abs/2310.02509</link>
      <description>arXiv:2310.02509v2 Announce Type: replace 
Abstract: Renewable energy sources (RES) are increasingly integrated into power systems to support the United Nations' Sustainable Development Goals of decarbonization and energy security. However, their low inertia and high uncertainty pose challenges to grid stability and increase the risk of blackouts. Stochastic chance-constrained optimization, particularly data-driven methods, offers solutions but can be time-consuming, especially when handling multiple system snapshots. This paper addresses a dynamic joint chance-constrained Direct Current Optimal Power Flow (DC-OPF) problem with Automated Generation Control (AGC) to facilitate cost-effective power generation while ensuring that balance and security constraints are met. We propose an approach for a data-driven approximation that includes a priori sample reduction, maintaining solution reliability while reducing the size of the data-driven approximation. Both theoretical analysis and empirical results demonstrate the superiority of this approach in handling generation uncertainty, requiring up to twice less data while preserving solution reliability.</description>
      <guid isPermaLink="false">oai:arXiv.org:2310.02509v2</guid>
      <category>math.OC</category>
      <category>stat.CO</category>
      <pubDate>Tue, 08 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <arxiv:DOI>10.1109/LCSYS.2024.3413367</arxiv:DOI>
      <arxiv:journal_reference>in IEEE Control Systems Letters, vol. 8, pp. 1613-1618, 2024</arxiv:journal_reference>
      <dc:creator>Aleksander Lukashevich, Aleksander Bulkin, Yury Maximov</dc:creator>
    </item>
    <item>
      <title>Solving Optimization Problems Using Reinforcement Learning, with Applications to Inverse Problems</title>
      <link>https://arxiv.org/abs/2310.06711</link>
      <description>arXiv:2310.06711v3 Announce Type: replace 
Abstract: We design a new iterative algorithm, called REINFORCE-OPT, for solving a general type of optimization problems. This algorithm parameterizes the solution-searching rule and iteratively improve the parameter using a reinforcement learning (RL) algorithm that resembles REINFORCE. To provide a deeper understanding of the RL-based methods, we prove that the goal of REINFORCE-OPT is equivalent to solving a stochastic-version of the given optimization problem, and that under standard assumptions, the searching-rule parameter almost surely converges to a locally optimal value. Experiments show that REINFORCE-OPT outperforms other optimization methods, such as gradient descent, genetic algorithm, and particle swarm optimization, by its ability to escape form locally optimal solutions and its robustness to the choice of initial values. Then, we formally introduce, with rigorous derivations, the use of reinforcement learning to the field of inverse problems. By choosing specific probability models for the action-selection rule, we connect our approach to the conventional regularization methods of Tikhonov regularization and iterative regularization. Our work provides two typical examples (non-linear integral equations and parameter-identification problems in partial differential equations) on how reinforcement learning can be applied in solving non-linear inverse problems. The numerical experiments highlight the strong performance of REINFORCE-OPT, along with its ability to quantify uncertainty in error estimates and identify multiple solutions for ill-posed inverse problems without stability and uniqueness.</description>
      <guid isPermaLink="false">oai:arXiv.org:2310.06711v3</guid>
      <category>math.OC</category>
      <pubDate>Tue, 08 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Chen Xu, Zhipeng Lu, Ye Zhang</dc:creator>
    </item>
    <item>
      <title>Mixed-integer linearity in nonlinear optimization: a trust region approach</title>
      <link>https://arxiv.org/abs/2310.17285</link>
      <description>arXiv:2310.17285v3 Announce Type: replace 
Abstract: Bringing together nonlinear optimization with polyhedral and integrality constraints enables versatile modeling, but poses significant computational challenges. We investigate a method to address these problems based on sequential mixed-integer linearization with trust region safeguard, computing feasible iterates via calls to a generic mixed-integer linear solver. Convergence to critical, possibly suboptimal, feasible points is established for arbitrary starting points. Finally, we present numerical applications in nonsmooth optimal control and optimal network design and operation.</description>
      <guid isPermaLink="false">oai:arXiv.org:2310.17285v3</guid>
      <category>math.OC</category>
      <pubDate>Tue, 08 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Alberto De Marchi</dc:creator>
    </item>
    <item>
      <title>Shape optimization of harmonic helicity in toroidal domains</title>
      <link>https://arxiv.org/abs/2401.14824</link>
      <description>arXiv:2401.14824v2 Announce Type: replace 
Abstract: In this paper, we introduce a new shape functional defined for toroidal domains that we call harmonic helicity, and study its shape optimization. Given a toroidal domain, we consider its associated harmonic field. The latter is the magnetic field obtained uniquely up to normalization when imposing zero normal trace and zero electrical current inside the domain. We then study the helicity of this field, which is a quantity of interest in magneto-hydrodynamics corresponding to the L2 product of the field with its image by the Biot--Savart operator. To do so, we begin by discussing the appropriate functional framework and an equivalent PDE characterization. We then focus on shape optimization, and we identify the shape gradient of the harmonic helicity. Finally, we study and implement an efficient numerical scheme to compute harmonic helicity and its shape gradient using finite elements exterior calculus.</description>
      <guid isPermaLink="false">oai:arXiv.org:2401.14824v2</guid>
      <category>math.OC</category>
      <category>cs.NA</category>
      <category>math.NA</category>
      <pubDate>Tue, 08 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Remi Robin, Robin Roussel</dc:creator>
    </item>
    <item>
      <title>Decentralized Robust Data-driven Predictive Control for Smoothing Mixed Traffic Flow</title>
      <link>https://arxiv.org/abs/2401.15826</link>
      <description>arXiv:2401.15826v2 Announce Type: replace 
Abstract: In a mixed traffic with connected automated vehicles (CAVs) and human-driven vehicles (HDVs) coexisting, data-driven predictive control of CAVs promises system-wide traffic performance improvements. Yet, most existing approaches focus on a centralized setup, which is not computationally scalable while failing to protect data privacy. The robustness against unknown disturbances has not been well addressed either, causing safety concerns. In this paper, we propose a decentralized robust DeeP-LCC (Data-EnablEd Predictive Leading Cruise Control) approach for CAVs to smooth mixed traffic flow. In particular, each CAV computes its control input based on locally available data from its involved subsystem. Meanwhile, the interaction between neighboring subsystems is modeled as a bounded disturbance, for which appropriate estimation methods are proposed. Then, we formulate a robust optimization problem and present its tractable computational solutions. Compared with the centralized formulation, our method greatly reduces computation burden with better safety performance, while naturally preserving data privacy. Extensive traffic simulations validate its wave-dampening ability, safety performance, and computational benefits.</description>
      <guid isPermaLink="false">oai:arXiv.org:2401.15826v2</guid>
      <category>math.OC</category>
      <category>cs.SY</category>
      <category>eess.SY</category>
      <pubDate>Tue, 08 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Xu Shang, Jiawei Wang, Yang Zheng</dc:creator>
    </item>
    <item>
      <title>Controllability and feedback stabilizability in a nonuniform framework</title>
      <link>https://arxiv.org/abs/2402.08870</link>
      <description>arXiv:2402.08870v2 Announce Type: replace 
Abstract: We propose a new controllability property for linear time varying control systems in finite dimension: the nonuniform complete controllability, which is halfway between the classical Kalman's properties of complete controllability and uniform complete controllability. This new concept is described in terms of two gramian inequalities, which have a strong relation; as we prove in our first result; with the property of nonuniform bounded growth for the corresponding plant, also called uncontrolled part. On the other hand, the second result proves that if a control system is nonuniformly completely controllable and its plant has the property of nonuniform bounded growth, then there exist a linear feedback control leading to a nonuniformly exponentially stable closed--loop system.</description>
      <guid isPermaLink="false">oai:arXiv.org:2402.08870v2</guid>
      <category>math.OC</category>
      <category>math.DS</category>
      <category>math.SP</category>
      <pubDate>Tue, 08 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Ignacio Huerta, Pablo Monz\'on, Gonzalo Robledo</dc:creator>
    </item>
    <item>
      <title>Path constrained unbalanced optimal transport</title>
      <link>https://arxiv.org/abs/2402.15860</link>
      <description>arXiv:2402.15860v2 Announce Type: replace 
Abstract: Dynamical formulations of optimal transport (OT) frame the task of comparing distributions as a variational problem which searches for a path between distributions minimizing a kinetic energy functional. In applications, it is frequently natural to require paths of distributions to satisfy additional conditions. Inspired by this, we introduce a model for dynamical OT which incorporates constraints on the space of admissible paths into the framework of unbalanced OT, where the source and target measures are allowed to have a different total mass. Our main results establish, for several general families of constraints, the existence of solutions to the variational problem which defines this path constrained unbalanced optimal transport framework. These results are primarily concerned with distributions defined on a Euclidean space, but we extend them to distributions defined over parallelizable Riemannian manifolds as well. We also consider metric properties of our framework, showing that, for certain types of constraints, our model defines a metric on the relevant space of distributions. This metric is shown to arise as a geodesic distance of a Riemannian metric, obtained through an analogue of Otto's submersion in the classical OT setting.</description>
      <guid isPermaLink="false">oai:arXiv.org:2402.15860v2</guid>
      <category>math.OC</category>
      <category>math.DG</category>
      <pubDate>Tue, 08 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Martin Bauer, Nicolas Charon, Tom Needham, Mao Nishino</dc:creator>
    </item>
    <item>
      <title>Perturbations in PDE-constrained optimal control decay exponentially in space</title>
      <link>https://arxiv.org/abs/2403.15056</link>
      <description>arXiv:2403.15056v2 Announce Type: replace 
Abstract: For linear-quadratic optimal control problems (OCPs) governed by elliptic and parabolic partial differential equations (PDEs), we investigate the impact of perturbations on optimal solutions. Local perturbations may occur, e.g., due to discretization of the optimality system or {disturbed} problem data. Whereas these perturbations may exhibit global effects in the uncontrolled case, we prove that the ramifications are exponentially damped in space under stabilizability and detectability conditions. To this end, we prove a bound on the optimality condition's solution operator that is uniform in the domain size. Then, this uniformity is used in a scaling argument to show the exponential decay of perturbations in space. We numerically validate and illustrate our results by solving OCPs involving Helmholtz, Poisson, and advection-diffusion-reaction equations.</description>
      <guid isPermaLink="false">oai:arXiv.org:2403.15056v2</guid>
      <category>math.OC</category>
      <category>math.AP</category>
      <pubDate>Tue, 08 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Simone G\"ottlich, Manuel Schaller, Karl Worthmann</dc:creator>
    </item>
    <item>
      <title>A Moreau Envelope Approach for LQR Meta-Policy Estimation</title>
      <link>https://arxiv.org/abs/2403.17364</link>
      <description>arXiv:2403.17364v2 Announce Type: replace 
Abstract: We study the problem of policy estimation for the Linear Quadratic Regulator (LQR) in discrete-time linear time-invariant uncertain dynamical systems. We propose a Moreau Envelope-based surrogate LQR cost, built from a finite set of realizations of the uncertain system, to define a meta-policy efficiently adjustable to new realizations. Moreover, we design an algorithm to find an approximate first-order stationary point of the meta-LQR cost function. Numerical results show that the proposed approach outperforms naive averaging of controllers on new realizations of the linear system. We also provide empirical evidence that our method has better sample complexity than Model-Agnostic Meta-Learning (MAML) approaches.</description>
      <guid isPermaLink="false">oai:arXiv.org:2403.17364v2</guid>
      <category>math.OC</category>
      <category>cs.LG</category>
      <category>cs.SY</category>
      <category>eess.SY</category>
      <pubDate>Tue, 08 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Ashwin Aravind, Mohammad Taha Toghani, C\'esar A. Uribe</dc:creator>
    </item>
    <item>
      <title>State Discretization for Continuous-State MDPs in Infectious Disease Control</title>
      <link>https://arxiv.org/abs/2404.12540</link>
      <description>arXiv:2404.12540v3 Announce Type: replace 
Abstract: Repeated decision-making problems under uncertainty may arise in the health policy context, such as infectious disease control for COVID-19 and other epidemics. These problems may sometimes be effectively solved using Markov decision processes (MDPs). However, the continuous or large state space of such problems for capturing infectious disease prevalence renders it difficult to implement tractable MDPs to identify the optimal disease control policy over time. We therefore develop an algorithm for discretizing continuous states for approximate MDP solutions in this context. We benchmark performance against a uniform discretization using both a synthetic example and an example of COVID-19 in Los Angeles County.</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.12540v3</guid>
      <category>math.OC</category>
      <category>physics.soc-ph</category>
      <pubDate>Tue, 08 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Suyanpeng Zhang, Sze-chuan Suen</dc:creator>
    </item>
    <item>
      <title>Restarted Primal-Dual Hybrid Conjugate Gradient Method for Large-Scale Quadratic Programming</title>
      <link>https://arxiv.org/abs/2405.16160</link>
      <description>arXiv:2405.16160v2 Announce Type: replace 
Abstract: Convex quadratic programming (QP) is an essential class of optimization problems with broad applications across various fields. Traditional QP solvers, typically based on simplex or barrier methods, face significant scalability challenges. In response to these limitations, recent research has shifted towards matrix-free first-order methods to enhance scalability in QP. Among these, the restarted accelerated primal-dual hybrid gradient (rAPDHG) method, proposed by Lu, has gained notable attention due to its linear convergence rate to an optimal solution and its straightforward implementation on Graphics Processing Units (GPUs). Building on this framework, this paper introduces a restarted primal-dual hybrid conjugate gradient (PDHCG) method, which incorporates conjugate gradient (CG) techniques to address the primal subproblems inexactly. We demonstrate that PDHCG maintains a linear convergence rate with an improved convergence constant and is also straightforward to implement on GPUs. Extensive numerical experiments on both synthetic and real-world datasets demonstrate that our method significantly reduces the number of iterations required to achieve the desired accuracy compared to rAPDHG. Additionally, the GPU implementation of our method achieves state-of-the-art performance on large-scale problems. In most large-scale scenarios, our method is approximately 5 times faster than rAPDHG and about 100 times faster than other existing methods. These results highlight the substantial potential of the proposed PDHCG method to greatly improve both the efficiency and scalability of solving complex quadratic programming challenges.</description>
      <guid isPermaLink="false">oai:arXiv.org:2405.16160v2</guid>
      <category>math.OC</category>
      <pubDate>Tue, 08 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Yicheng Huang, Wanyu Zhang, Hongpei Li, Dongdong Ge, Huikang Liu, Yinyu Ye</dc:creator>
    </item>
    <item>
      <title>Filtration learning in exact multi-parameter persistent homology and classification of time-series data</title>
      <link>https://arxiv.org/abs/2406.19587</link>
      <description>arXiv:2406.19587v2 Announce Type: replace 
Abstract: To analyze the topological properties of the given discrete data, one needs to consider a continuous transform called filtration. Persistent homology serves as a tool to track changes of homology in the filtration. The outcome of the topological analysis of data varies depending on the choice of filtration, making the selection of filtration crucial. Filtration learning is an attempt to find an optimal filtration that minimizes the loss function. Exact Multi-parameter Persistent Homology (EMPH) has been recently proposed, particularly for topological time-series analysis, that utilizes the exact formula of rank invariant instead of calculating it. In this paper, we propose a framework for filtration learning of EMPH. We formulate an optimization problem and propose an algorithm for solving the problem. We then apply the proposed algorithm to several classification problems. Particularly, we derive the exact formula of the gradient of the loss function with respect to the filtration parameters, which makes it possible to directly update the filtration without using automatic differentiation, significantly enhancing the learning process.</description>
      <guid isPermaLink="false">oai:arXiv.org:2406.19587v2</guid>
      <category>math.OC</category>
      <category>math.AT</category>
      <category>stat.ML</category>
      <pubDate>Tue, 08 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Keunsu Kim, Jae-Hun Jung</dc:creator>
    </item>
    <item>
      <title>DP-SCC-PL:Differentially Private Decentralized Byzantine-Resilient Stochastic Optimization via Self-Centered Clipping Under Polyak-{\L}ojasiewicz Condition</title>
      <link>https://arxiv.org/abs/2409.18632</link>
      <description>arXiv:2409.18632v3 Announce Type: replace 
Abstract: Privacy leakage and Byzantine failures are two critical issues presenting great challenges to the intelligent decision-making process of multi-agent systems (MASs). Considering the presence of these two issues, this paper targets the resolution of a class of nonconvex optimization problems under the Polyak-{\L}ojasiewicz (P-{\L}) condition. To address this problem, we mask the local gradients with Gaussian noises and adopt a resilient aggregation method self-centered clipping (SCC) to design a differentially private (DP) decentralized Byzantine-resilient algorithm, namely DP-SCC-PL, which simultaneously achieves differential privacy and Byzantine resilience. The convergence analysis of DP-SCC-PL is challenging since the convergence error can be contributed jointly by privacy-preserving and Byzantine-resilient mechanisms, as well as the nonconvex relaxation, which is addressed via seeking the contraction relationships among the disagreement measure of reliable agents before and after aggregation, together with the optimal gap. Theoretical results demonstrate that DP-SCC-PL achieves the consensus among all reliable agents with a decaying step-size and sublinear (inexact) convergence with a constant step-size, where the asymptotic convergence error is characterized in both cases. It has also been proved that if there are no privacy issues and Byzantine agents, then the asymptotic exact convergence can be recovered when adopting a well-designed decaying step-size. Numerical experiments verify the differential privacy, resilience, and effectiveness of DP-SCC-PL via tackling a nonconvex optimization problem satisfying the P-{\L} condition under various Byzantine attacks.</description>
      <guid isPermaLink="false">oai:arXiv.org:2409.18632v3</guid>
      <category>math.OC</category>
      <pubDate>Tue, 08 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Jinhui Hu, Xiaoyu Guo, Huaqing Li, Huqiang Cheng, Guo Chen</dc:creator>
    </item>
    <item>
      <title>UVIP: Model-Free Approach to Evaluate Reinforcement Learning Algorithms</title>
      <link>https://arxiv.org/abs/2105.02135</link>
      <description>arXiv:2105.02135v4 Announce Type: replace-cross 
Abstract: Policy evaluation is an important instrument for the comparison of different algorithms in Reinforcement Learning (RL). Yet even a precise knowledge of the value function $V^{\pi}$ corresponding to a policy $\pi$ does not provide reliable information on how far is the policy $\pi$ from the optimal one. We present a novel model-free upper value iteration procedure $({\sf UVIP})$ that allows us to estimate the suboptimality gap $V^{\star}(x) - V^{\pi}(x)$ from above and to construct confidence intervals for $V^\star$. Our approach relies on upper bounds to the solution of the Bellman optimality equation via martingale approach. We provide theoretical guarantees for ${\sf UVIP}$ under general assumptions and illustrate its performance on a number of benchmark RL problems.</description>
      <guid isPermaLink="false">oai:arXiv.org:2105.02135v4</guid>
      <category>cs.LG</category>
      <category>math.OC</category>
      <pubDate>Tue, 08 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Ilya Levin, Denis Belomestny, Alexey Naumov, Sergey Samsonov</dc:creator>
    </item>
    <item>
      <title>Callable convertible bonds under liquidity constraints and hybrid priorities</title>
      <link>https://arxiv.org/abs/2111.02554</link>
      <description>arXiv:2111.02554v3 Announce Type: replace-cross 
Abstract: This paper investigates the callable convertible bond problem in the presence of a liquidity constraint modelled by Poisson signals. We assume that neither the bondholder nor the firm has absolute priority when they stop the game simultaneously, but instead, a proportion $m\in[0,1]$ of the bond is converted to the firm's stock and the rest is called by the firm. The paper thus generalizes the special case studied in [Liang and Sun, Dynkin games with Poisson random intervention times, SIAM Journal on Control and Optimization, 57 (2019), 2962-2991] where the bondholder has priority ($m=1$), and presents a complete solution to the callable convertible bond problem with liquidity constraint. The callable convertible bond is an example of a Dynkin game, but falls outside the standard paradigm since the payoffs do not depend in an ordered way upon which agent stops the game. We show how to deal with this non-ordered situation by introducing a new technique which may be of interest in its own right, and then apply it to the bond problem.</description>
      <guid isPermaLink="false">oai:arXiv.org:2111.02554v3</guid>
      <category>q-fin.MF</category>
      <category>math.OC</category>
      <pubDate>Tue, 08 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>David Hobson, Gechun Liang, Edward Wang</dc:creator>
    </item>
    <item>
      <title>An active learning method for solving competitive multi-agent decision-making and control problems</title>
      <link>https://arxiv.org/abs/2212.12561</link>
      <description>arXiv:2212.12561v5 Announce Type: replace-cross 
Abstract: To identify a stationary action profile for a population of competitive agents, each executing private strategies, we introduce a novel active-learning scheme where a centralized external observer (or entity) can probe the agents' reactions and recursively update simple local parametric estimates of the action-reaction mappings. Under very general working assumptions (not even assuming that a stationary profile exists), sufficient conditions are established to assess the asymptotic properties of the proposed active learning methodology so that, if the parameters characterizing the action-reaction mappings converge, a stationary action profile is achieved. Such conditions hence act also as certificates for the existence of such a profile. Extensive numerical simulations involving typical competitive multi-agent control and decision-making problems illustrate the practical effectiveness of the proposed learning-based approach.</description>
      <guid isPermaLink="false">oai:arXiv.org:2212.12561v5</guid>
      <category>eess.SY</category>
      <category>cs.LG</category>
      <category>cs.MA</category>
      <category>cs.SY</category>
      <category>math.OC</category>
      <pubDate>Tue, 08 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Filippo Fabiani, Alberto Bemporad</dc:creator>
    </item>
    <item>
      <title>Homotopy Relaxation Training Algorithms for Infinite-Width Two-Layer ReLU Neural Networks</title>
      <link>https://arxiv.org/abs/2309.15244</link>
      <description>arXiv:2309.15244v3 Announce Type: replace-cross 
Abstract: In this paper, we present a novel training approach called the Homotopy Relaxation Training Algorithm (HRTA), aimed at accelerating the training process in contrast to traditional methods. Our algorithm incorporates two key mechanisms: one involves building a homotopy activation function that seamlessly connects the linear activation function with the ReLU activation function; the other technique entails relaxing the homotopy parameter to enhance the training refinement process. We have conducted an in-depth analysis of this novel method within the context of the neural tangent kernel (NTK), revealing significantly improved convergence rates. Our experimental results, especially when considering networks with larger widths, validate the theoretical conclusions. This proposed HRTA exhibits the potential for other activation functions and deep neural networks.</description>
      <guid isPermaLink="false">oai:arXiv.org:2309.15244v3</guid>
      <category>cs.LG</category>
      <category>math.OC</category>
      <pubDate>Tue, 08 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Yahong Yang, Qipin Chen, Wenrui Hao</dc:creator>
    </item>
    <item>
      <title>Signature Methods in Stochastic Portfolio Theory</title>
      <link>https://arxiv.org/abs/2310.02322</link>
      <description>arXiv:2310.02322v3 Announce Type: replace-cross 
Abstract: In the context of stochastic portfolio theory we introduce a novel class of portfolios which we call linear path-functional portfolios. These are portfolios which are determined by certain transformations of linear functions of a collections of feature maps that are non-anticipative path functionals of an underlying semimartingale. As main example for such feature maps we consider the signature of the (ranked) market weights. We prove that these portfolios are universal in the sense that every continuous, possibly path-dependent, portfolio function of the market weights can be uniformly approximated by signature portfolios. We also show that signature portfolios can approximate the growth-optimal portfolio in several classes of non-Markovian market models arbitrarily well and illustrate numerically that the trained signature portfolios are remarkably close to the theoretical growth-optimal portfolios. Besides these universality features, the main numerical advantage lies in the fact that several optimization tasks like maximizing (expected) logarithmic wealth or mean-variance optimization within the class of linear path-functional portfolios reduce to a convex quadratic optimization problem, thus making it computationally highly tractable. We apply our method also to real market data based on several indices. Our results point towards out-performance on the considered out-of-sample data, also in the presence of transaction costs.</description>
      <guid isPermaLink="false">oai:arXiv.org:2310.02322v3</guid>
      <category>q-fin.MF</category>
      <category>math.OC</category>
      <category>math.PR</category>
      <category>q-fin.PM</category>
      <pubDate>Tue, 08 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Christa Cuchiero, Janka M\"oller</dc:creator>
    </item>
    <item>
      <title>Queues with service resetting</title>
      <link>https://arxiv.org/abs/2311.07770</link>
      <description>arXiv:2311.07770v2 Announce Type: replace-cross 
Abstract: Service time fluctuations heavily affect the performance of queueing systems, causing long waiting times and backlogs. Recently, it was shown that when service times are solely determined by the server, service resetting can mitigate the deleterious effects of service time fluctuations and drastically improve queue performance (Bonomo et al.,2022). Yet, in many queueing systems, service times have two independent sources: the intrinsic server slowdown ($S$) and the jobs' inherent size ($X$). In these, so-called $S\&amp;X$ queues (Gardner et al., 2017), service resetting results in a newly drawn server slowdown while the inherent job size remains unchanged. Remarkably, resetting can be useful even then. To show this, we develop a comprehensive theory of $S\&amp;X$ queues with service resetting. We consider cases where the total service time is either a product or a sum of the service slowdown and the jobs' inherent size. For both cases, we derive expressions for the total service time distribution and its mean under a generic service resetting policy. Two prevalent resetting policies are discussed in more detail. We first analyze the constant-rate (Poissonian) resetting policy and derive explicit conditions under which resetting reduces the mean service time and improves queue performance. Next, we consider the sharp (deterministic) resetting policy. While results hold regardless of the arrival process, we dedicate special attention to the $S\&amp;X$-M/G/1 queue with service resetting, and obtain the distribution of the number of jobs in the system and their sojourn time. Our analysis highlights situations where service resetting can be used as an effective tool to improve the performance of $S\&amp;X$ queueing systems. Several examples are given to illustrate our analytical results, which are corroborated using numerical simulations.</description>
      <guid isPermaLink="false">oai:arXiv.org:2311.07770v2</guid>
      <category>math.PR</category>
      <category>cond-mat.stat-mech</category>
      <category>math.OC</category>
      <pubDate>Tue, 08 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Ofek Lauber Bonomo, Uri Yechiali, Shlomi Reuveni</dc:creator>
    </item>
    <item>
      <title>Sum-of-Squares &amp; Gaussian Processes I: Certification</title>
      <link>https://arxiv.org/abs/2401.14383</link>
      <description>arXiv:2401.14383v3 Announce Type: replace-cross 
Abstract: We introduce a class of distributions which may be considered as a smoothed probabilistic version of the ultrametric property that famously characterizes the Gibbs distributions of various spin glass models. This class of \emph{high-entropy step} (HES) distributions is expressive enough to capture a distribution achieving near-optimal average energy on spin glass models in the so-called full Replica-Symmetry Breaking (fRSB) regime.
  Simultaneously, with high probability, there are polynomial-size certificates on the average energy achievable by \emph{any} HES distribution which are tight within a constant factor. These certificates can be found in polynomial time by a semidefinite program corresponding to a sum-of-squares (SoS) hierarchy we introduce, termed the HES SoS hierarchy. This improves over classical sum-of-squares certificates which are loose by a factor of $n^{\lfloor p/2 - 1\rfloor/2}$.</description>
      <guid isPermaLink="false">oai:arXiv.org:2401.14383v3</guid>
      <category>cs.CC</category>
      <category>math-ph</category>
      <category>math.CA</category>
      <category>math.MP</category>
      <category>math.OC</category>
      <category>math.PR</category>
      <pubDate>Tue, 08 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Juspreet Singh Sandhu, Jonathan Shi</dc:creator>
    </item>
    <item>
      <title>Integrated Optimal Fast Charging and Active Thermal Management of Lithium-Ion Batteries in Extreme Ambient Temperatures</title>
      <link>https://arxiv.org/abs/2404.04358</link>
      <description>arXiv:2404.04358v3 Announce Type: replace-cross 
Abstract: This paper presents an integrated control strategy for optimal fast charging and active thermal management of Lithium-ion batteries in extreme ambient temperatures, striking a balance between charging speed and battery health. A control-oriented thermal-NDC (nonlinear double-capacitor) battery model is proposed to describe the electrical and thermal dynamics, incorporating the effects of both an active thermal source and ambient temperature. A state-feedback model predictive control algorithm is then developed for optimal fast charging and active thermal management. Numerical experiments validate the algorithm under extreme temperatures, showing that the proposed algorithm can energy-efficiently adjust the battery temperature, thereby balancing charging speed and battery health. Additionally, an output-feedback model predictive control algorithm with an extended Kalman filter is proposed for battery charging when states are partially measurable. Numerical experiments validate the effectiveness under extreme temperatures.</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.04358v3</guid>
      <category>eess.SY</category>
      <category>cs.SY</category>
      <category>math.OC</category>
      <pubDate>Tue, 08 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Zehui Lu, Hao Tu, Huazhen Fang, Yebin Wang, Shaoshuai Mou</dc:creator>
    </item>
    <item>
      <title>OptiBench Meets ReSocratic: Measure and Improve LLMs for Optimization Modeling</title>
      <link>https://arxiv.org/abs/2407.09887</link>
      <description>arXiv:2407.09887v2 Announce Type: replace-cross 
Abstract: Large language models (LLMs) have exhibited their problem-solving abilities in mathematical reasoning. Solving realistic optimization (OPT) problems in application scenarios requires advanced and applied mathematics ability. However, current OPT benchmarks that merely solve linear programming are far from complex realistic situations. In this work, we propose OptiBench, a benchmark for End-to-end optimization problem-solving with human-readable inputs and outputs. OptiBench contains rich optimization problems, including linear and nonlinear programming with or without tabular data, which can comprehensively evaluate LLMs' solving ability. In our benchmark, LLMs are required to call a code solver to provide precise numerical answers. Furthermore, to alleviate the data scarcity for optimization problems, and to bridge the gap between open-source LLMs on a small scale (e.g., Llama-3-8b) and closed-source LLMs (e.g., GPT-4), we further propose a data synthesis method namely ReSocratic. Unlike general data synthesis methods that proceed from questions to answers, \ReSocratic first incrementally synthesizes formatted optimization demonstration with mathematical formulations step by step and then back-translates the generated demonstrations into questions. Based on this, we synthesize the ReSocratic-29k dataset. We further conduct supervised fine-tuning with ReSocratic-29k on multiple open-source models. Experimental results show that ReSocratic-29k significantly improves the performance of open-source models.</description>
      <guid isPermaLink="false">oai:arXiv.org:2407.09887v2</guid>
      <category>cs.LG</category>
      <category>math.OC</category>
      <pubDate>Tue, 08 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <dc:creator>Zhicheng Yang, Yiwei Wang, Yinya Huang, Zhijiang Guo, Wei Shi, Xiongwei Han, Liang Feng, Linqi Song, Xiaodan Liang, Jing Tang</dc:creator>
    </item>
    <item>
      <title>Online Convex Optimization with a Separation Oracle</title>
      <link>https://arxiv.org/abs/2410.02476</link>
      <description>arXiv:2410.02476v2 Announce Type: replace-cross 
Abstract: In this paper, we introduce a new projection-free algorithm for Online Convex Optimization (OCO) with a state-of-the-art regret guarantee among separation-based algorithms. Existing projection-free methods based on the classical Frank-Wolfe algorithm achieve a suboptimal regret bound of $O(T^{3/4})$, while more recent separation-based approaches guarantee a regret bound of $O(\kappa \sqrt{T})$, where $\kappa$ denotes the asphericity of the feasible set, defined as the ratio of the radii of the containing and contained balls. However, for ill-conditioned sets, $\kappa$ can be arbitrarily large, potentially leading to poor performance. Our algorithm achieves a regret bound of $\widetilde{O}(\sqrt{dT} + \kappa d)$, while requiring only $\widetilde{O}(1)$ calls to a separation oracle per round. Crucially, the main term in the bound, $\widetilde{O}(\sqrt{d T})$, is independent of $\kappa$, addressing the limitations of previous methods. Additionally, as a by-product of our analysis, we recover the $O(\kappa \sqrt{T})$ regret bound of existing OCO algorithms with a more straightforward analysis and improve the regret bound for projection-free online exp-concave optimization. Finally, for constrained stochastic convex optimization, we achieve a state-of-the-art convergence rate of $\widetilde{O}(\sigma/\sqrt{T} + \kappa d/T)$, where $\sigma$ represents the noise in the stochastic gradients, while requiring only $\widetilde{O}(1)$ calls to a separation oracle per iteration.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.02476v2</guid>
      <category>cs.LG</category>
      <category>math.OC</category>
      <pubDate>Tue, 08 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <dc:creator>Zakaria Mhammedi</dc:creator>
    </item>
  </channel>
</rss>
