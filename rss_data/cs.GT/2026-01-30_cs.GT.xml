<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>cs.GT updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/cs.GT</link>
    <description>cs.GT updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/cs.GT" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Fri, 30 Jan 2026 05:00:32 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Fri, 30 Jan 2026 00:00:00 -0500</pubDate>
    <skipDays>
      <day>Saturday</day>
      <day>Sunday</day>
    </skipDays>
    <item>
      <title>On Approximate Nash Equilibria in Mean Field Games</title>
      <link>https://arxiv.org/abs/2601.20910</link>
      <description>arXiv:2601.20910v1 Announce Type: new 
Abstract: In the context of large population symmetric games, approximate Nash equilibria are introduced through equilibrium solutions of the corresponding mean field game in the sense that the individual gain from optimal unilateral deviation under such strategies converges to zero in the large population size asymptotic. We show that these strategies satisfy an $\L^\infty$ notion of approximate Nash equilibrium which guarantees that the individual gain from optimal unilateral deviation is small uniformly among players and uniformly on their initial characteristics. We establish these results in the context of static models and in the dynamic continuous time setting, and we cover situations where the agents' criteria depend on the conditional law of the controlled state process.</description>
      <guid isPermaLink="false">oai:arXiv.org:2601.20910v1</guid>
      <category>cs.GT</category>
      <category>math.OC</category>
      <category>math.PR</category>
      <pubDate>Fri, 30 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Mao Fabrice Djete, Nizar Touzi</dc:creator>
    </item>
    <item>
      <title>Shortlisting: a Principled Approach</title>
      <link>https://arxiv.org/abs/2601.21277</link>
      <description>arXiv:2601.21277v1 Announce Type: new 
Abstract: Shortlisting is the process of selecting a subset of alternatives from a larger pool for further consideration or final decision-making. It is widely applied in social choice and multi-agent system scenarios. The growing demand for participatory decision-making and the continuously expanding space of candidates create an urgent need for efficient and fair shortlisting procedures. However, little principled study has been done on this problem. This blue-sky paper aims to highlight the overlooked significance of shortlisting, distinguish it from related problems, provide initial thoughts, and, more importantly, serve as a call to arms. We envision that principled shortlisting can reduce cognitive burden, enable fair collective decisions, encourage broader participation, and ultimately build trust in democratic systems.</description>
      <guid isPermaLink="false">oai:arXiv.org:2601.21277v1</guid>
      <category>cs.GT</category>
      <pubDate>Fri, 30 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Edith Elkind, Qishen Han, Lirong Xia</dc:creator>
    </item>
    <item>
      <title>Alliance Mechanisms in General Lotto Games</title>
      <link>https://arxiv.org/abs/2601.21319</link>
      <description>arXiv:2601.21319v1 Announce Type: new 
Abstract: How do different alliance mechanisms compare? In this work, we analyze various methods of forming an alliance in the Coalitional General Lotto game, a simple model of competitive resource allocation. In the game, Players 1 and 2 independently compete against a common Adversary by allocating their limited resource budgets towards separate sets of contests; an agent wins a contest by allocating more resources towards it than their opponent. In this setting, we study three alliance mechanisms: budget transfers (resource donation), contest transfers (contest redistribution), and joint transfers (both simultaneously). For all three mechanisms, we study when they present opportunities for collective improvement (the sum of the Players' payoffs increases) or mutual improvement (both Players' individual payoffs increase). In our first result, we show that all three are fundamentally different with regards to mutual improvement; in particular, mutually beneficial budget and contest transfers exist in distinct, limited subsets of games, whereas mutually beneficial joint transfers exist in almost all games. However, in our second result, we demonstrate that all three mechanisms are equivalent when it comes to collective improvement; that is, collectively beneficial budget, contest, and joint transfers exist in almost all game instances, and all three mechanisms achieve the same maximum collective payoff. Together, these results demonstrate that differences between mechanisms depend fundamentally on the objective of the alliance.</description>
      <guid isPermaLink="false">oai:arXiv.org:2601.21319v1</guid>
      <category>cs.GT</category>
      <pubDate>Fri, 30 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Vade Shah, Jason R. Marden</dc:creator>
    </item>
    <item>
      <title>Test-Time Compute Games</title>
      <link>https://arxiv.org/abs/2601.21839</link>
      <description>arXiv:2601.21839v1 Announce Type: cross 
Abstract: Test-time compute has emerged as a promising strategy to enhance the reasoning abilities of large language models (LLMs). However, this strategy has in turn increased how much users pay cloud-based providers offering LLM-as-a-service, since providers charge users for the amount of test-time compute they use to generate an output. In our work, we show that the market of LLM-as-a-service is socially inefficient: providers have a financial incentive to increase the amount of test-time compute, even if this increase contributes little to the quality of the outputs. To address this inefficiency, we introduce a reverse second-price auction mechanism where providers bid their offered price and (expected) quality for the opportunity to serve a user, and users pay proportionally to the marginal value generated by the winning provider relative to the second-highest bidder. To illustrate and complement our theoretical results, we conduct experiments with multiple instruct models from the $\texttt{Llama}$ and $\texttt{Qwen}$ families, as well as reasoning models distilled from $\texttt{DeepSeek-R1}$, on math and science benchmark datasets.</description>
      <guid isPermaLink="false">oai:arXiv.org:2601.21839v1</guid>
      <category>cs.CY</category>
      <category>cs.AI</category>
      <category>cs.GT</category>
      <category>cs.LG</category>
      <pubDate>Fri, 30 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Ander Artola Velasco, Dimitrios Rontogiannis, Stratis Tsirtsis, Manuel Gomez-Rodriguez</dc:creator>
    </item>
    <item>
      <title>Optimal Energy-Aware Service Management in Future Networks with a Gamified Incentives Mechanism</title>
      <link>https://arxiv.org/abs/2601.21846</link>
      <description>arXiv:2601.21846v1 Announce Type: cross 
Abstract: As energy demands surge across ICT infrastructures, service providers must engage users in sustainable practices while maintaining the Quality of Experience (QoE) at acceptable levels. In this paper, we introduce such an approach, leveraging gamified incentives and a model for user's acceptance on incentives, thus encouraging energy-efficient behaviors such as adaptive bitrate streaming. Each user is characterized by an environmental sensitivity factor and a private incentive threshold, shaping probabilistic responses to energy-saving offers. A serious-game mechanism based on positive behavioral reinforcement and rewards of the users, due to their inclusion in top-K and bottom-M rankings, fosters peer comparison and competition, thus transforming passive acceptance into active engagement. Moreover, within a Stackelberg game formulation, the video streaming service provider--acting as the strategic leader--optimizes both incentive levels and game parameters to achieve network-wide energy and traffic reductions, while adhering to budgetary constraints. This structured approach empowers providers with proactive, application-level control over energy consumption, offering them measurable benefits such as reduced high-bitrate traffic and increased participation in energy-saving behaviors, while also considering user satisfaction. The results of our simulations show that indeed gamification boosts significantly user participation and energy savings provided that the incentive and game parameters are chosen optimally.</description>
      <guid isPermaLink="false">oai:arXiv.org:2601.21846v1</guid>
      <category>cs.ET</category>
      <category>cs.GT</category>
      <pubDate>Fri, 30 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Konstantinos Varsos, Adamantia Stamou, George D. Stamoulis, Vasillios A. Siris</dc:creator>
    </item>
    <item>
      <title>Post-Disaster Resource Redistribution and Cooperation Evolution Based on Two-Layer Network Evolutionary Games</title>
      <link>https://arxiv.org/abs/2601.22021</link>
      <description>arXiv:2601.22021v1 Announce Type: cross 
Abstract: In the aftermath of large-scale disasters, the scarcity of resources and the paralysis of infrastructure raise severe challenges to effective post-disaster recovery. Efficient coordination between shelters and victims plays a crucial role in building community resilience, yet the evolution of two-layer behavioral feedback between these two groups through network coupling remains insufficiently understood. Here, this study develops a two-layer network to capture the cross-layer coupling between shelters and victims. The upper layer uses a post-disaster emergency resource redistribution model within the framework of the public goods game, while the lower layer adopts a cooperative evolutionary game to describe internal victim interactions. Monte Carlo simulations on scale-free networks reveal threshold effects of incentives: moderate public goods enhancement and subsidies promote cooperation, whereas excessive incentives induce free-riding. In contrast, credible and well-executed punishment effectively suppresses defection. Targeted punishment of highly connected shelters significantly enhances cooperation under resource constraints. A comparative analysis using a network generated from the actual coordinates of Beijing shelters confirms the model's generality and practical applicability. The findings highlight the importance of calibrated incentives, enforceable sanctions, and structural targeting in fostering robust cooperation across organizational and individual levels in post-disaster environments.</description>
      <guid isPermaLink="false">oai:arXiv.org:2601.22021v1</guid>
      <category>physics.soc-ph</category>
      <category>cs.GT</category>
      <pubDate>Fri, 30 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/publicdomain/zero/1.0/</dc:rights>
      <dc:creator>Yu Chen, Genjiu Xu, Sinan Feng, Chaoqian Wang</dc:creator>
    </item>
    <item>
      <title>The Economics of No-regret Learning Algorithms</title>
      <link>https://arxiv.org/abs/2601.22079</link>
      <description>arXiv:2601.22079v1 Announce Type: cross 
Abstract: A fundamental challenge for modern economics is to understand what happens when actors in an economy are replaced with algorithms. Like rationality has enabled understanding of outcomes of classical economic actors, no-regret can enable the understanding of outcomes of algorithmic actors. This review article covers the classical computer science literature on no-regret algorithms to provide a foundation for an overview of the latest economics research on no-regret algorithms, focusing on the emerging topics of manipulation, statistical inference, and algorithmic collusion.</description>
      <guid isPermaLink="false">oai:arXiv.org:2601.22079v1</guid>
      <category>econ.TH</category>
      <category>cs.GT</category>
      <pubDate>Fri, 30 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Jason Hartline</dc:creator>
    </item>
    <item>
      <title>A Generalization of von Neumann's Reduction from the Assignment Problem to Zero-Sum Games</title>
      <link>https://arxiv.org/abs/2410.10767</link>
      <description>arXiv:2410.10767v3 Announce Type: replace 
Abstract: The equivalence between von Neumann's Minimax Theorem for zero-sum games and the LP Duality Theorem connects cornerstone problems of the two fields of game theory and optimization, respectively, and has been the subject of intense scrutiny for seven decades. Yet, as observed in this paper, the proof of the difficult direction of this equivalence is unsatisfactory: It does not assign distinct roles to the two players of the game, as is natural from the definition of a zero-sum game.
  In retrospect, a partial resolution to this predicament was provided in another brilliant paper of von Neumann, which reduced the assignment problem to zero-sum games. However, the underlying LP is highly specialized; all entries of its objective function vector are strictly positive, the constraint vector is all ones, and the constraint matrix is 0/1.
  We generalize von Neumann's result along two directions, each allowing negative entries in certain parts of the LP. Our reductions make explicit the roles of the two players of the reduced game, namely their maximin strategies are to play optimal solutions to the primal and dual LPs. Furthermore, unlike previous reductions, the value of the reduced game reveals the value of the given LP. Our generalizations encompass several basic economic scenarios.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.10767v3</guid>
      <category>cs.GT</category>
      <category>cs.DS</category>
      <category>econ.TH</category>
      <pubDate>Fri, 30 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Ilan Adler, Martin Bullinger, Vijay V. Vazirani</dc:creator>
    </item>
    <item>
      <title>Is Your LLM Overcharging You? Tokenization, Transparency, and Incentives</title>
      <link>https://arxiv.org/abs/2505.21627</link>
      <description>arXiv:2505.21627v3 Announce Type: replace 
Abstract: State-of-the-art large language models require specialized hardware and substantial energy to operate. As a consequence, cloud-based services that provide access to large language models have become very popular. In these services, the price users pay for an output provided by a model depends on the number of tokens the model uses to generate it: they pay a fixed price per token. In this work, we show that this pricing mechanism creates a financial incentive for providers to strategize and misreport the (number of) tokens a model used to generate an output, and users cannot prove, or even know, whether a provider is overcharging them. However, we also show that, if an unfaithful provider is obliged to be transparent about the generative process used by the model, misreporting optimally without raising suspicion is hard. Nevertheless, as a proof-of-concept, we develop an efficient heuristic algorithm that allows providers to significantly overcharge users without raising suspicion. Crucially, we demonstrate that the cost of running the algorithm is lower than the additional revenue from overcharging users, highlighting the vulnerability of users under the current pay-per-token pricing mechanism. Further, we show that, to eliminate the financial incentive to strategize, a pricing mechanism must price tokens linearly on their character count. While this makes a provider's profit margin vary across tokens, we introduce a simple prescription under which the provider who adopts such an incentive-compatible pricing mechanism can maintain the average profit margin they had under the pay-per-token pricing mechanism. Along the way, to illustrate and complement our theoretical results, we conduct experiments with several large language models from the $\texttt{Llama}$, $\texttt{Gemma}$ and $\texttt{Ministral}$ families, and input prompts from the LMSYS Chatbot Arena platform.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.21627v3</guid>
      <category>cs.GT</category>
      <category>cs.AI</category>
      <category>cs.CY</category>
      <category>cs.LG</category>
      <pubDate>Fri, 30 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Ander Artola Velasco, Stratis Tsirtsis, Nastaran Okati, Manuel Gomez-Rodriguez</dc:creator>
    </item>
    <item>
      <title>The Price of Uncertainty for Social Consensus</title>
      <link>https://arxiv.org/abs/2508.17557</link>
      <description>arXiv:2508.17557v3 Announce Type: replace 
Abstract: How hard is it to achieve consensus in a social network under uncertainty? In this paper we model this problem as a social graph of agents where each vertex is initially colored red or blue. The goal of the agents is to achieve consensus, which is when the colors of all agents align. Agents attempt to do this locally through steps in which an agent changes their color to the color of the majority of their neighbors. In real life, agents may not know exactly how many of their neighbors are red or blue, which introduces uncertainty into this process. Modeling uncertainty as perturbations of relative magnitude $1+\varepsilon$ to these color neighbor counts, we show that even small values of $\varepsilon$ greatly hinder the ability to achieve consensus in a social network. We prove theoretically tight upper and lower bounds on the \emph{price of uncertainty}, a metric defined in previous work by Balcan et al. to quantify the effect of uncertainty in network games.</description>
      <guid isPermaLink="false">oai:arXiv.org:2508.17557v3</guid>
      <category>cs.GT</category>
      <category>cs.MA</category>
      <category>cs.SI</category>
      <pubDate>Fri, 30 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Yunzhe Bai, Alec Sun</dc:creator>
    </item>
    <item>
      <title>Online Price Competition under Generalized Linear Demands</title>
      <link>https://arxiv.org/abs/2511.10718</link>
      <description>arXiv:2511.10718v4 Announce Type: replace 
Abstract: We study sequential price competition among $N$ sellers, each influenced by the pricing decisions of their rivals. Specifically, the demand function for each seller $i$ follows the single index model $\lambda_i(\mathbf{p}) = \mu_i(\langle \boldsymbol{\theta}_{i,0}, \mathbf{p} \rangle)$, with known increasing link $\mu_i$ and unknown parameter $\boldsymbol{\theta}_{i,0}$, where the vector $\mathbf{p}$ denotes the vector of prices offered by all the sellers simultaneously at a given instant. Each seller observes only their own realized demand -- unobservable to competitors -- and the prices set by rivals. Our framework generalizes existing approaches that focus solely on linear demand models. We propose a novel decentralized policy, PML-GLUCB, that combines penalized MLE with an upper-confidence pricing rule, removing the need for coordinated exploration phases across sellers -- which is integral to previous linear models -- and accommodating both binary and real-valued demand observations. Relative to a dynamic benchmark policy, each seller achieves $O(N^{2}\sqrt{T}\log(T))$ regret, which essentially matches the optimal rate known in the linear setting. A significant technical contribution of our work is the development of a variant of the elliptical potential lemma -- typically applied in single-agent systems -- adapted to our competitive multi-agent environment.</description>
      <guid isPermaLink="false">oai:arXiv.org:2511.10718v4</guid>
      <category>cs.GT</category>
      <category>math.ST</category>
      <category>stat.ME</category>
      <category>stat.TH</category>
      <pubDate>Fri, 30 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Daniele Bracale, Moulinath Banerjee, Cong Shi, Yuekai Sun</dc:creator>
    </item>
    <item>
      <title>Dynamic Debt Swapping in Financial Networks</title>
      <link>https://arxiv.org/abs/2302.11250</link>
      <description>arXiv:2302.11250v2 Announce Type: replace-cross 
Abstract: A debt swap is an elementary edge swap in a directed, weighted graph, where two edges with the same weight swap their targets. Debt swaps are a natural and appealing operation in financial networks, in which nodes are banks and edges represent debt contracts. They can improve the clearing payments and the stability of these networks. However, their algorithmic properties are not well-understood.
  We analyze the computational complexity of debt swapping. Our main interest lies in semi-positive swaps, in which no creditor strictly suffers and at least one strictly profits. These swaps lead to a Pareto-improvement in the entire network. We consider network optimization via sequences of v-improving debt swaps from which a given bank v strictly profits. For ranking-based clearing, we show that every sequence of semi-positive v-improving swaps has polynomial length. In contrast, for arbitrary v-improving swaps, the problem of reaching a network configuration that allows no further swaps is PLS-complete.
  In global optimization, the goal is to maximize the utility of a given bank $v$ by performing a sequence of debt swaps in the network. This problem is NP-hard to approximate for multiple types of swaps.
  Moreover, we study reachability problems -- deciding if a sequence of swaps exists between given initial and final networks. We design a polynomial-time algorithm to decide this question for arbitrary swaps and derive hardness results for several other types of swaps.
  Many of our results can be extended to networks with arbitrary monotone clearing.</description>
      <guid isPermaLink="false">oai:arXiv.org:2302.11250v2</guid>
      <category>cs.DS</category>
      <category>cs.CC</category>
      <category>cs.GT</category>
      <category>q-fin.RM</category>
      <pubDate>Fri, 30 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <arxiv:DOI>10.1016/j.tcs.2026.115788</arxiv:DOI>
      <dc:creator>Henri Froese, Martin Hoefer, Lisa Wilhelmi</dc:creator>
    </item>
    <item>
      <title>The incompatibility of the Condorcet winner and loser criteria with positive or negative involvement and resolvability</title>
      <link>https://arxiv.org/abs/2601.10506</link>
      <description>arXiv:2601.10506v4 Announce Type: replace-cross 
Abstract: We prove that there is no preferential voting method satisfying the Condorcet winner and loser criteria, positive involvement (if a candidate $x$ wins in an initial preference profile, then adding a voter who ranks $x$ uniquely first cannot cause $x$ to lose), and $n$-voter resolvability (if $x$ initially ties for winning, then $x$ can be made the unique winner by adding some set of up to $n$ voters). This impossibility theorem holds for any positive integer $n$. In addition, positive involvement can be replaced by negative involvement (if a candidate $x$ loses in an initial preference profile, then adding a voter who ranks $x$ uniquely last cannot cause $x$ to win). In a previous note, we proved an analogous result assuming an additional axiom of ordinal margin invariance, which we now show is unnecessary for an impossibility theorem, at least if the desired voting method is defined for five-candidate elections.</description>
      <guid isPermaLink="false">oai:arXiv.org:2601.10506v4</guid>
      <category>econ.TH</category>
      <category>cs.GT</category>
      <category>cs.MA</category>
      <pubDate>Fri, 30 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Wesley H. Holliday</dc:creator>
    </item>
    <item>
      <title>C2:Cross learning module enhanced decision transformer with Constraint-aware loss for auto-bidding</title>
      <link>https://arxiv.org/abs/2601.20257</link>
      <description>arXiv:2601.20257v2 Announce Type: replace-cross 
Abstract: Decision Transformer (DT) shows promise for generative auto-bidding by capturing temporal dependencies, but suffers from two critical limitations: insufficient cross-correlation modeling among state, action, and return-to-go (RTG) sequences, and indiscriminate learning of optimal/suboptimal behaviors. To address these, we propose C2, a novel framework enhancing DT with two core innovations: (1) a Cross Learning Block (CLB) via cross-attention to strengthen inter-sequence correlation modeling; (2) a Constraint-aware Loss (CL) incorporating budget and Cost-Per-Acquisition (CPA) constraints for selective learning of optimal trajectories. Extensive offline evaluations on the AuctionNet dataset demonstrate consistent performance gains (up to 3.2% over state-of-the-art method) across diverse budget settings; ablation studies verify the complementary synergy of CLB and CL, confirming C2's superiority in auto-bidding. The code for reproducing our results is available at: https://github.com/Dingjinren/C2.</description>
      <guid isPermaLink="false">oai:arXiv.org:2601.20257v2</guid>
      <category>cs.LG</category>
      <category>cs.GT</category>
      <pubDate>Fri, 30 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Jinren Ding, Xuejian Xu, Shen Jiang, Zhitong Hao, Jinhui Yang, Peng Jiang</dc:creator>
    </item>
    <item>
      <title>Normative Equivalence in Human-AI Cooperation: Behaviour, Not Identity, Drives Cooperation in Mixed-Agent Groups</title>
      <link>https://arxiv.org/abs/2601.20487</link>
      <description>arXiv:2601.20487v2 Announce Type: replace-cross 
Abstract: The introduction of artificial intelligence (AI) agents into human group settings raises essential questions about how these novel participants influence cooperative social norms. While previous studies on human-AI cooperation have primarily focused on dyadic interactions, little is known about how integrating AI agents affects the emergence and maintenance of cooperative norms in small groups. This study addresses this gap through an online experiment using a repeated four-player Public Goods Game (PGG). Each group consisted of three human participants and one bot, which was framed either as human or AI and followed one of three predefined decision strategies: unconditional cooperation, conditional cooperation, or free-riding. In our sample of 236 participants, we found that reciprocal group dynamics and behavioural inertia primarily drove cooperation. These normative mechanisms operated identically across conditions, resulting in cooperation levels that did not differ significantly between human and AI labels. Furthermore, we found no evidence of differences in norm persistence in a follow-up Prisoner's Dilemma, or in participants' normative perceptions. Participants' behaviour followed the same normative logic across human and AI conditions, indicating that cooperation depended on group behaviour rather than partner identity. This supports a pattern of normative equivalence, in which the mechanisms that sustain cooperation function similarly in mixed human-AI and all human groups. These findings suggest that cooperative norms are flexible enough to extend to artificial agents, blurring the boundary between humans and AI in collective decision-making.</description>
      <guid isPermaLink="false">oai:arXiv.org:2601.20487v2</guid>
      <category>cs.AI</category>
      <category>cs.GT</category>
      <category>cs.HC</category>
      <category>econ.GN</category>
      <category>q-fin.EC</category>
      <pubDate>Fri, 30 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Nico Mutzner, Taha Yasseri, Heiko Rauhut</dc:creator>
    </item>
  </channel>
</rss>
