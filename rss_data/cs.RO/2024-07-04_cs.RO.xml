<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>cs.RO updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/cs.RO</link>
    <description>cs.RO updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/cs.RO" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Thu, 04 Jul 2024 04:00:19 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Thu, 04 Jul 2024 00:00:00 -0400</pubDate>
    <skipDays>
      <day>Saturday</day>
      <day>Sunday</day>
    </skipDays>
    <item>
      <title>Coupling Machine Learning with Ontology for Robotics Applications</title>
      <link>https://arxiv.org/abs/2407.02500</link>
      <description>arXiv:2407.02500v1 Announce Type: new 
Abstract: In this paper I present a practical approach for coupling machine learning (ML) algorithms with knowledge bases (KB) ontology formalism. The lack of availability of prior knowledge in dynamic scenarios is without doubt a major barrier for scalable machine intelligence. My view of the interaction between the two tiers intelligence is based on the idea that when knowledge is not readily available at the knowledge base tier, more knowledge can be extracted from the other tier, which has access to trained models from machine learning algorithms. To analyse this hypothesis, I create two experiments based on different datasets, which are related directly to risk-awareness of autonomous systems, analysed by different machine learning algorithms (namely; multi-layer feedforward backpropagation, Naive Bayes, and J48 decision tree). My analysis shows that the two-tiers intelligence approach for coupling ML and KB is computationally valid and the time complexity of the algorithms during the robot mission is linear with the size of the data and knowledge.</description>
      <guid isPermaLink="false">oai:arXiv.org:2407.02500v1</guid>
      <category>cs.RO</category>
      <category>cs.AI</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Osama F. Zaki</dc:creator>
    </item>
    <item>
      <title>Impact of an Autonomous Shuttle Service on Urban Road Capacity: Experiments by Microscopic Traffic Simulation</title>
      <link>https://arxiv.org/abs/2407.02502</link>
      <description>arXiv:2407.02502v1 Announce Type: new 
Abstract: Autonomous vehicles are expected to transform transportation systems with rapid technological advancement. Human mobility would become more accessible and safer with the emergence of driverless vehicles. To this end, autonomous shuttle services are currently introduced in different urban conditions throughout the world. As a result, studies are needed to assess the safety and mobility performance of such autonomous shuttle services. However, calibrating the movement of autonomous shuttles in a simulation environment has been a difficult task due to the absence of any real-world data. This study aims to calibrate autonomous shuttles in a microscopic traffic simulation model and consequently assess the impact of the shuttle service on urban road capacity through simulation experiments. For this analysis, a prototype of an operational shuttle system at Lake Nona, Orlando, Florida is emulated in a microscopic traffic simulator during different times of the day. The movements of autonomous vehicles are calibrated using real-world trajectory data which help replicate the driving behavior of the shuttle in the simulation. The analysis reveals that with increasing frequency of the shuttle service the delay time percentage of the shared road sections increases and traveling speed decreases. It is also found that increasing the speed of shuttles up to 5 mph during off-peak hours and 10 mph during peak hours will improve traffic conditions. The findings from this study will assist policymakers and transportation agencies to revise policies for deploying autonomous shuttles and for planning road infrastructures for shared road-use of autonomous shuttles and human driven vehicles.</description>
      <guid isPermaLink="false">oai:arXiv.org:2407.02502v1</guid>
      <category>cs.RO</category>
      <category>cs.SY</category>
      <category>eess.SY</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Sudipta Roy, Bat-hen Nahmias-Biran, Samiul Hasan</dc:creator>
    </item>
    <item>
      <title>Optimizing Deep Reinforcement Learning for Adaptive Robotic Arm Control</title>
      <link>https://arxiv.org/abs/2407.02503</link>
      <description>arXiv:2407.02503v1 Announce Type: new 
Abstract: In this paper, we explore the optimization of hyperparameters for the Soft Actor-Critic (SAC) and Proximal Policy Optimization (PPO) algorithms using the Tree-structured Parzen Estimator (TPE) in the context of robotic arm control with seven Degrees of Freedom (DOF). Our results demonstrate a significant enhancement in algorithm performance, TPE improves the success rate of SAC by 10.48 percentage points and PPO by 34.28 percentage points, where models trained for 50K episodes. Furthermore, TPE enables PPO to converge to a reward within 95% of the maximum reward 76% faster than without TPE, which translates to about 40K fewer episodes of training required for optimal performance. Also, this improvement for SAC is 80% faster than without TPE. This study underscores the impact of advanced hyperparameter optimization on the efficiency and success of deep reinforcement learning algorithms in complex robotic tasks.</description>
      <guid isPermaLink="false">oai:arXiv.org:2407.02503v1</guid>
      <category>cs.RO</category>
      <category>cs.AI</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <dc:creator>Jonaid Shianifar, Michael Schukat, Karl Mason</dc:creator>
    </item>
    <item>
      <title>An Embedded Decision Support System for Runway Safety and Excursion Avoidance</title>
      <link>https://arxiv.org/abs/2407.02504</link>
      <description>arXiv:2407.02504v1 Announce Type: new 
Abstract: Runway Safety Assistant Foreseeing Excursions (RUN.S.A.F.E.) is a complete embedded system solution that predicts a potential runway overrun during the takeoff and landing of a civil aviation aircraft. The system executes both static and dynamic calculations, the former being completely dependent, while the latter completely independent to the user's inputs. The solution is adapted to a Boeing 737-800 aircraft, with CFM56-7B engines. However, the calculations also apply for similar aicrafts, equipped with a tricycle landing gear and turbofan engines. The system is aligned with current regulations and certification specifications, where applicable.</description>
      <guid isPermaLink="false">oai:arXiv.org:2407.02504v1</guid>
      <category>cs.RO</category>
      <category>cs.ET</category>
      <category>cs.SY</category>
      <category>eess.SY</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Georgios Alogdianakis, Ioannis Katsidimas, Athanasios Kotzakolios, Anastasios Plioutsias, Vassilis Kostopoulos</dc:creator>
    </item>
    <item>
      <title>Sample-efficient Imitative Multi-token Decision Transformer for Generalizable Real World Driving</title>
      <link>https://arxiv.org/abs/2407.02508</link>
      <description>arXiv:2407.02508v1 Announce Type: new 
Abstract: Reinforcement learning via sequence modeling has shown remarkable promise in autonomous systems, harnessing the power of offline datasets to make informed decisions in simulated environments. However, the full potential of such methods in complex dynamic environments remain to be discovered. In autonomous driving domain, learning-based agents face significant challenges when transferring knowledge from simulated to real-world settings and the performance is also significantly impacted by data distribution shift. To address these issue, we propose Sample-efficient Imitative Multi-token Decision Transformer (SimDT). SimDT introduces multi-token prediction, imitative online learning and prioritized experience replay to Decision Transformer. The performance is evaluated through empirical experiments and results exceed popular imitation and reinforcement learning algorithms on Waymax benchmark.</description>
      <guid isPermaLink="false">oai:arXiv.org:2407.02508v1</guid>
      <category>cs.RO</category>
      <category>cs.AI</category>
      <category>cs.LG</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Hang Zhou, Dan Xu, Yiding Ji</dc:creator>
    </item>
    <item>
      <title>LLM-A*: Large Language Model Enhanced Incremental Heuristic Search on Path Planning</title>
      <link>https://arxiv.org/abs/2407.02511</link>
      <description>arXiv:2407.02511v1 Announce Type: new 
Abstract: Path planning is a fundamental scientific problem in robotics and autonomous navigation, requiring the derivation of efficient routes from starting to destination points while avoiding obstacles. Traditional algorithms like A* and its variants are capable of ensuring path validity but suffer from significant computational and memory inefficiencies as the state space grows. Conversely, large language models (LLMs) excel in broader environmental analysis through contextual understanding, providing global insights into environments. However, they fall short in detailed spatial and temporal reasoning, often leading to invalid or inefficient routes. In this work, we propose LLM-A*, an new LLM based route planning method that synergistically combines the precise pathfinding capabilities of A* with the global reasoning capability of LLMs. This hybrid approach aims to enhance pathfinding efficiency in terms of time and space complexity while maintaining the integrity of path validity, especially in large-scale scenarios. By integrating the strengths of both methodologies, LLM-A* addresses the computational and memory limitations of conventional algorithms without compromising on the validity required for effective pathfinding.</description>
      <guid isPermaLink="false">oai:arXiv.org:2407.02511v1</guid>
      <category>cs.RO</category>
      <category>cs.AI</category>
      <category>cs.CL</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Silin Meng, Yiwei Wang, Cheng-Fu Yang, Nanyun Peng, Kai-Wei Chang</dc:creator>
    </item>
    <item>
      <title>EditFollower: Tunable Car Following Models for Customizable Adaptive Cruise Control Systems</title>
      <link>https://arxiv.org/abs/2407.02516</link>
      <description>arXiv:2407.02516v1 Announce Type: new 
Abstract: In the realm of driving technologies, fully autonomous vehicles have not been widely adopted yet, making advanced driver assistance systems (ADAS) crucial for enhancing driving experiences. Adaptive Cruise Control (ACC) emerges as a pivotal component of ADAS. However, current ACC systems often employ fixed settings, failing to intuitively capture drivers' social preferences and leading to potential function disengagement. To overcome these limitations, we propose the Editable Behavior Generation (EBG) model, a data-driven car-following model that allows for adjusting driving discourtesy levels. The framework integrates diverse courtesy calculation methods into long short-term memory (LSTM) and Transformer architectures, offering a comprehensive approach to capture nuanced driving dynamics. By integrating various discourtesy values during the training process, our model generates realistic agent trajectories with different levels of courtesy in car-following behavior. Experimental results on the HighD and Waymo datasets showcase a reduction in Mean Squared Error (MSE) of spacing and MSE of speed compared to baselines, establishing style controllability. To the best of our knowledge, this work represents the first data-driven car-following model capable of dynamically adjusting discourtesy levels. Our model provides valuable insights for the development of ACC systems that take into account drivers' social preferences.</description>
      <guid isPermaLink="false">oai:arXiv.org:2407.02516v1</guid>
      <category>cs.RO</category>
      <category>cs.AI</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Xianda Chen, Xu Han, Meixin Zhu, Xiaowen Chu, PakHin Tiu, Xinhu Zheng, Yinhai Wang</dc:creator>
    </item>
    <item>
      <title>CAV-AHDV-CAV: Mitigating Traffic Oscillations for CAVs through a Novel Car-Following Structure and Reinforcement Learning</title>
      <link>https://arxiv.org/abs/2407.02517</link>
      <description>arXiv:2407.02517v1 Announce Type: new 
Abstract: Connected and Automated Vehicles (CAVs) offer a promising solution to the challenges of mixed traffic with both CAVs and Human-Driven Vehicles (HDVs). A significant hurdle in such scenarios is traffic oscillation, or the "stop-and-go" pattern, during car-following situations. While HDVs rely on limited information, CAVs can leverage data from other CAVs for better decision-making. This allows CAVs to anticipate and mitigate the spread of deceleration waves that worsen traffic flow. We propose a novel "CAV-AHDV-CAV" car-following framework that treats the sequence of HDVs between two CAVs as a single entity, eliminating noise from individual driver behaviors. This deep reinforcement learning approach analyzes vehicle equilibrium states and employs a state fusion strategy. Trained and tested on diverse datasets (HighD, NGSIM, SPMD, Waymo, Lyft) encompassing over 70,000 car-following instances, our model outperforms baselines in collision avoidance, maintaining equilibrium with both preceding and leading vehicles and achieving the lowest standard deviation of time headway. These results demonstrate the effectiveness of our approach in developing robust CAV control strategies for mixed traffic. Our model has the potential to mitigate traffic oscillation, improve traffic flow efficiency, and enhance overall safety.</description>
      <guid isPermaLink="false">oai:arXiv.org:2407.02517v1</guid>
      <category>cs.RO</category>
      <category>cs.AI</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Xianda Chen, PakHin Tiu, Yihuai Zhang, Xinhu Zheng, Meixin Zhu</dc:creator>
    </item>
    <item>
      <title>RaCIL: Ray Tracing based Multi-UAV Obstacle Avoidance through Composite Imitation Learning</title>
      <link>https://arxiv.org/abs/2407.02520</link>
      <description>arXiv:2407.02520v1 Announce Type: new 
Abstract: In this study, we address the challenge of obstacle avoidance for Unmanned Aerial Vehicles (UAVs) through an innovative composite imitation learning approach that combines Proximal Policy Optimization (PPO) with Behavior Cloning (BC) and Generative Adversarial Imitation Learning (GAIL), enriched by the integration of ray-tracing techniques. Our research underscores the significant role of ray-tracing in enhancing obstacle detection and avoidance capabilities. Moreover, we demonstrate the effectiveness of incorporating GAIL in coordinating the flight paths of two UAVs, showcasing improved collision avoidance capabilities. Extending our methodology, we apply our combined PPO, BC, GAIL, and ray-tracing framework to scenarios involving four UAVs, illustrating its scalability and adaptability to more complex scenarios. The findings indicate that our approach not only improves the reliability of basic PPO based obstacle avoidance but also paves the way for advanced autonomous UAV operations in crowded or dynamic environments.</description>
      <guid isPermaLink="false">oai:arXiv.org:2407.02520v1</guid>
      <category>cs.RO</category>
      <category>cs.AI</category>
      <category>cs.LG</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Harsh Bansal, Vyom Goyal, Bhaskar Joshi, Akhil Gupta, Harikumar Kandath</dc:creator>
    </item>
    <item>
      <title>Performance Comparison of Deep RL Algorithms for Mixed Traffic Cooperative Lane-Changing</title>
      <link>https://arxiv.org/abs/2407.02521</link>
      <description>arXiv:2407.02521v1 Announce Type: new 
Abstract: Lane-changing (LC) is a challenging scenario for connected and automated vehicles (CAVs) because of the complex dynamics and high uncertainty of the traffic environment. This challenge can be handled by deep reinforcement learning (DRL) approaches, leveraging their data-driven and model-free nature. Our previous work proposed a cooperative lane-changing in mixed traffic (CLCMT) mechanism based on TD3 to facilitate an optimal lane-changing strategy. This study enhances the current CLCMT mechanism by considering both the uncertainty of the human-driven vehicles (HVs) and the microscopic interactions between HVs and CAVs. The state-of-the-art (SOTA) DRL algorithms including DDPG, TD3, SAC, and PPO are utilized to deal with the formulated MDP with continuous actions. Performance comparison among the four DRL algorithms demonstrates that DDPG, TD3, and PPO algorithms can deal with uncertainty in traffic environments and learn well-performed LC strategies in terms of safety, efficiency, comfort, and ecology. The PPO algorithm outperforms the other three algorithms, regarding a higher reward, fewer exploration mistakes and crashes, and a more comfortable and ecology LC strategy. The improvements promise CLCMT mechanism greater advantages in the LC motion planning of CAVs.</description>
      <guid isPermaLink="false">oai:arXiv.org:2407.02521v1</guid>
      <category>cs.RO</category>
      <category>cs.AI</category>
      <category>cs.LG</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Xue Yao, Shengren Hou, Serge P. Hoogendoorn, Simeon C. Calvert</dc:creator>
    </item>
    <item>
      <title>Research on Autonomous Robots Navigation based on Reinforcement Learning</title>
      <link>https://arxiv.org/abs/2407.02539</link>
      <description>arXiv:2407.02539v1 Announce Type: new 
Abstract: Reinforcement learning continuously optimizes decision-making based on real-time feedback reward signals through continuous interaction with the environment, demonstrating strong adaptive and self-learning capabilities. In recent years, it has become one of the key methods to achieve autonomous navigation of robots. In this work, an autonomous robot navigation method based on reinforcement learning is introduced. We use the Deep Q Network (DQN) and Proximal Policy Optimization (PPO) models to optimize the path planning and decision-making process through the continuous interaction between the robot and the environment, and the reward signals with real-time feedback. By combining the Q-value function with the deep neural network, deep Q network can handle high-dimensional state space, so as to realize path planning in complex environments. Proximal policy optimization is a strategy gradient-based method, which enables robots to explore and utilize environmental information more efficiently by optimizing policy functions. These methods not only improve the robot's navigation ability in the unknown environment, but also enhance its adaptive and self-learning capabilities. Through multiple training and simulation experiments, we have verified the effectiveness and robustness of these models in various complex scenarios.</description>
      <guid isPermaLink="false">oai:arXiv.org:2407.02539v1</guid>
      <category>cs.RO</category>
      <category>cs.AI</category>
      <category>cs.LG</category>
      <category>stat.ML</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Zixiang Wang, Hao Yan, Yining Wang, Zhengjia Xu, Zhuoyue Wang, Zhizhong Wu</dc:creator>
    </item>
    <item>
      <title>Adaptive Autopilot: Constrained DRL for Diverse Driving Behaviors</title>
      <link>https://arxiv.org/abs/2407.02546</link>
      <description>arXiv:2407.02546v1 Announce Type: new 
Abstract: In pursuit of autonomous vehicles, achieving human-like driving behavior is vital. This study introduces adaptive autopilot (AA), a unique framework utilizing constrained-deep reinforcement learning (C-DRL). AA aims to safely emulate human driving to reduce the necessity for driver intervention. Focusing on the car-following scenario, the process involves (i) extracting data from the highD natural driving study and categorizing it into three driving styles using a rule-based classifier; (ii) employing deep neural network (DNN) regressors to predict human-like acceleration across styles; and (iii) using C-DRL, specifically the soft actor-critic Lagrangian technique, to learn human-like safe driving policies. Results indicate effectiveness in each step, with the rule-based classifier distinguishing driving styles, the regressor model accurately predicting acceleration, outperforming traditional car-following models, and C-DRL agents learning optimal policies for humanlike driving across styles.</description>
      <guid isPermaLink="false">oai:arXiv.org:2407.02546v1</guid>
      <category>cs.RO</category>
      <category>cs.LG</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Dinesh Cyril Selvaraj, Christian Vitale, Tania Panayiotou, Panayiotis Kolios, Carla Fabiana Chiasserini, Georgios Ellinas</dc:creator>
    </item>
    <item>
      <title>STRIDE: An Open-Source, Low-Cost, and Versatile Bipedal Robot Platform for Research and Education</title>
      <link>https://arxiv.org/abs/2407.02648</link>
      <description>arXiv:2407.02648v1 Announce Type: new 
Abstract: In this paper, we present STRIDE, a Simple, Terrestrial, Reconfigurable, Intelligent, Dynamic, and Educational bipedal platform. STRIDE aims to propel bipedal robotics research and education by providing a cost-effective implementation with step-by-step instructions for building a bipedal robotic platform while providing flexible customizations via a modular and durable design. Moreover, a versatile terrain setup and a quantitative disturbance injection system are augmented to the robot platform to replicate natural terrains and push forces that can be used to evaluate legged locomotion in practical and adversarial scenarios. We demonstrate the functionalities of this platform by realizing an adaptive step-to-step dynamics based walking controller to achieve dynamic walking. Our work with the open-soured implementation shows that STRIDE is a highly versatile and durable platform that can be used in research and education to evaluate locomotion algorithms, mechanical designs, and robust and adaptative controls.</description>
      <guid isPermaLink="false">oai:arXiv.org:2407.02648v1</guid>
      <category>cs.RO</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Yuhao Huang, Yicheng Zeng, Xiaobin Xiong</dc:creator>
    </item>
    <item>
      <title>The path towards contact-based physical human-robot interaction</title>
      <link>https://arxiv.org/abs/2407.02664</link>
      <description>arXiv:2407.02664v1 Announce Type: new 
Abstract: With the advancements in human-robot interaction (HRI), robots are now capable of operating in close proximity and engaging in physical interactions with humans (pHRI). Likewise, contact-based pHRI is becoming increasingly common as robots are equipped with a range of sensors to perceive human motions. Despite the presence of surveys exploring various aspects of HRI and pHRI, there is presently a gap in comprehensive studies that collect, organize and relate developments across all aspects of contact-based pHRI. It has become challenging to gain a comprehensive understanding of the current state of the field, thoroughly analyze the aspects that have been covered, and identify areas needing further attention. Hence, the present survey. While it includes key developments in pHRI, a particular focus is placed on contact-based interaction, which has numerous applications in industrial, rehabilitation and medical robotics. Across the literature, a common denominator is the importance to establish a safe, compliant and human intention-oriented interaction. This endeavour encompasses aspects of perception, planning and control, and how they work together to enhance safety and reliability. Notably, the survey highlights the application of data-driven techniques: backed by a growing body of literature demonstrating their effectiveness, approaches like reinforcement learning and learning from demonstration have become key to improving robot perception and decision-making within complex and uncertain pHRI scenarios. As the field is yet in its early stage, these observations may help guide future developments and steer research towards the responsible integration of physically interactive robots into workplaces, public spaces, and elements of private life.</description>
      <guid isPermaLink="false">oai:arXiv.org:2407.02664v1</guid>
      <category>cs.RO</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Mohammad Farajtabar, Marie Charbonneau</dc:creator>
    </item>
    <item>
      <title>Commonsense Reasoning for Legged Robot Adaptation with Vision-Language Models</title>
      <link>https://arxiv.org/abs/2407.02666</link>
      <description>arXiv:2407.02666v1 Announce Type: new 
Abstract: Legged robots are physically capable of navigating a diverse variety of environments and overcoming a wide range of obstructions. For example, in a search and rescue mission, a legged robot could climb over debris, crawl through gaps, and navigate out of dead ends. However, the robot's controller needs to respond intelligently to such varied obstacles, and this requires handling unexpected and unusual scenarios successfully. This presents an open challenge to current learning methods, which often struggle with generalization to the long tail of unexpected situations without heavy human supervision. To address this issue, we investigate how to leverage the broad knowledge about the structure of the world and commonsense reasoning capabilities of vision-language models (VLMs) to aid legged robots in handling difficult, ambiguous situations. We propose a system, VLM-Predictive Control (VLM-PC), combining two key components that we find to be crucial for eliciting on-the-fly, adaptive behavior selection with VLMs: (1) in-context adaptation over previous robot interactions and (2) planning multiple skills into the future and replanning. We evaluate VLM-PC on several challenging real-world obstacle courses, involving dead ends and climbing and crawling, on a Go1 quadruped robot. Our experiments show that by reasoning over the history of interactions and future plans, VLMs enable the robot to autonomously perceive, navigate, and act in a wide range of complex scenarios that would otherwise require environment-specific engineering or human guidance.</description>
      <guid isPermaLink="false">oai:arXiv.org:2407.02666v1</guid>
      <category>cs.RO</category>
      <category>cs.AI</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Annie S. Chen, Alec M. Lessing, Andy Tang, Govind Chada, Laura Smith, Sergey Levine, Chelsea Finn</dc:creator>
    </item>
    <item>
      <title>PWTO: A Heuristic Approach for Trajectory Optimization in Complex Terrains</title>
      <link>https://arxiv.org/abs/2407.02745</link>
      <description>arXiv:2407.02745v1 Announce Type: new 
Abstract: This paper considers a trajectory planning problem for a robot navigating complex terrains, which arises in applications ranging from autonomous mining vehicles to planetary rovers. The problem seeks to find a low-cost dynamically feasible trajectory for the robot. The problem is challenging as it requires solving a non-linear optimization problem that often has many local minima due to the complex terrain. To address the challenge, we propose a method called Pareto-optimal Warm-started Trajectory Optimization (PWTO) that attempts to combine the benefits of graph search and trajectory optimization, two very different approaches to planning. PWTO first creates a state lattice using simplified dynamics of the robot and leverages a multi-objective graph search method to obtain a set of paths. Each of the paths is then used to warm-start a local trajectory optimization process, so that different local minima are explored to find a globally low-cost solution. In our tests, the solution cost computed by PWTO is often less than half of the costs computed by the baselines. In addition, we verify the trajectories generated by PWTO in Gazebo simulation in complex terrains with both wheeled and quadruped robots. The code of this paper is open sourced and can be found at https://github.com/rap-lab-org/public_pwto.</description>
      <guid isPermaLink="false">oai:arXiv.org:2407.02745v1</guid>
      <category>cs.RO</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Yilin Cai, Zhongqiang Ren</dc:creator>
    </item>
    <item>
      <title>Motion Comparator: Visual Comparison of Robot Motions</title>
      <link>https://arxiv.org/abs/2407.02746</link>
      <description>arXiv:2407.02746v1 Announce Type: new 
Abstract: Roboticists compare robot motions for tasks such as parameter tuning, troubleshooting, and deciding between possible motions. However, most existing visualization tools are designed for individual motions and lack the features necessary to facilitate robot motion comparison. In this paper, we utilize a rigorous design framework to develop Motion Comparator, a web-based tool that facilitates the comprehension, comparison, and communication of robot motions. Our design process identified roboticists' needs, articulated design challenges, and provided corresponding strategies. Motion Comparator includes several key features such as multi-view coordination, quaternion visualization, time warping, and comparative designs. To demonstrate the applications of Motion Comparator, we discuss four case studies in which our tool is used for motion selection, troubleshooting, parameter tuning, and motion review.</description>
      <guid isPermaLink="false">oai:arXiv.org:2407.02746v1</guid>
      <category>cs.RO</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Yeping Wang, Alexander Peseckis, Zelong Jiang, Michael Gleicher</dc:creator>
    </item>
    <item>
      <title>Hierarchical Large Scale Multirobot Path (Re)Planning</title>
      <link>https://arxiv.org/abs/2407.02777</link>
      <description>arXiv:2407.02777v1 Announce Type: new 
Abstract: We consider a large-scale multi-robot path planning problem in a cluttered environment. Our approach achieves real-time replanning by dividing the workspace into cells and utilizing a hierarchical planner. Specifically, multi-commodity flow-based high-level planners route robots through the cells to reduce congestion, while an anytime low-level planner computes collision-free paths for robots within each cell in parallel. Despite resulting in longer paths compared to the baseline multi-agent pathfinding algorithm, our method produces a solution with significant improvement in computation time. Specifically, we show empirical results of a 500-times speedup in computation time compared to the baseline multi-agent pathfinding approach on the environments we study. We account for the robot's embodiment and support non-stop execution when replanning continuously. We demonstrate the real-time performance of our algorithm with up to 142 robots in simulation, and a representative 32 physical Crazyflie nano-quadrotor experiment.</description>
      <guid isPermaLink="false">oai:arXiv.org:2407.02777v1</guid>
      <category>cs.RO</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Lishuo Pan, Kevin Hsu, Nora Ayanian</dc:creator>
    </item>
    <item>
      <title>LiDAR-Inertial Odometry Based on Extended Kalman Filter</title>
      <link>https://arxiv.org/abs/2407.02786</link>
      <description>arXiv:2407.02786v1 Announce Type: new 
Abstract: LiDAR-Inertial Odometry (LIO) is typically implemented using an optimization-based approach, with the factor graph often being employed due to its capability to seamlessly integrate residuals from both LiDAR and IMU measurements. Conversely, a recent study has demonstrated that accurate LIO can also be achieved using a loosely-coupled method. Inspired by this advancements, we present a novel LIO method that leverages the recursive Bayes filter, solved via the Extended Kalman Filter (EKF) - herein referred to as LIO-EKF. Within LIO-EKF, prior and likelihood distributions are computed using IMU preintegration and scan matching between LiDAR and local map point clouds, and the pose, velocity, and IMU biases are updated through the EKF process. Through experiments with the Newer College dataset, we demonstrate that LIO-EKF achieves precise trajectory tracking and mapping. Its accuracy is comparable to that of the state-of-the-art methods in both tightly- and loosely-coupled methods.</description>
      <guid isPermaLink="false">oai:arXiv.org:2407.02786v1</guid>
      <category>cs.RO</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Naoki Akai, Takumi Nakao</dc:creator>
    </item>
    <item>
      <title>Solving Motion Planning Tasks with a Scalable Generative Model</title>
      <link>https://arxiv.org/abs/2407.02797</link>
      <description>arXiv:2407.02797v1 Announce Type: new 
Abstract: As autonomous driving systems being deployed to millions of vehicles, there is a pressing need of improving the system's scalability, safety and reducing the engineering cost. A realistic, scalable, and practical simulator of the driving world is highly desired. In this paper, we present an efficient solution based on generative models which learns the dynamics of the driving scenes. With this model, we can not only simulate the diverse futures of a given driving scenario but also generate a variety of driving scenarios conditioned on various prompts. Our innovative design allows the model to operate in both full-Autoregressive and partial-Autoregressive modes, significantly improving inference and training speed without sacrificing generative capability. This efficiency makes it ideal for being used as an online reactive environment for reinforcement learning, an evaluator for planning policies, and a high-fidelity simulator for testing. We evaluated our model against two real-world datasets: the Waymo motion dataset and the nuPlan dataset. On the simulation realism and scene generation benchmark, our model achieves the state-of-the-art performance. And in the planning benchmarks, our planner outperforms the prior arts. We conclude that the proposed generative model may serve as a foundation for a variety of motion planning tasks, including data generation, simulation, planning, and online training. Source code is public at https://github.com/HorizonRobotics/GUMP/</description>
      <guid isPermaLink="false">oai:arXiv.org:2407.02797v1</guid>
      <category>cs.RO</category>
      <category>cs.CV</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Yihan Hu, Siqi Chai, Zhening Yang, Jingyu Qian, Kun Li, Wenxin Shao, Haichao Zhang, Wei Xu, Qiang Liu</dc:creator>
    </item>
    <item>
      <title>Robot Shape and Location Retention in Video Generation Using Diffusion Models</title>
      <link>https://arxiv.org/abs/2407.02873</link>
      <description>arXiv:2407.02873v1 Announce Type: new 
Abstract: Diffusion models have marked a significant milestone in the enhancement of image and video generation technologies. However, generating videos that precisely retain the shape and location of moving objects such as robots remains a challenge. This paper presents diffusion models specifically tailored to generate videos that accurately maintain the shape and location of mobile robots. This development offers substantial benefits to those working on detecting dangerous interactions between humans and robots by facilitating the creation of training data for collision detection models, circumventing the need for collecting data from the real world, which often involves legal and ethical issues. Our models incorporate techniques such as embedding accessible robot pose information and applying semantic mask regulation within the ConvNext backbone network. These techniques are designed to refine intermediate outputs, therefore improving the retention performance of shape and location. Through extensive experimentation, our models have demonstrated notable improvements in maintaining the shape and location of different robots, as well as enhancing overall video generation quality, compared to the benchmark diffusion model. Codes will be opensourced at \href{https://github.com/PengPaulWang/diffusion-robots}{Github}.</description>
      <guid isPermaLink="false">oai:arXiv.org:2407.02873v1</guid>
      <category>cs.RO</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Peng Wang, Zhihao Guo, Abdul Latheef Sait, Minh Huy Pham</dc:creator>
    </item>
    <item>
      <title>Pr\"avention und Beseitigung von Fehlerursachen im Kontext von unbemannten Fahrzeugen</title>
      <link>https://arxiv.org/abs/2407.02876</link>
      <description>arXiv:2407.02876v1 Announce Type: new 
Abstract: Mobile robots, becoming increasingly autonomous, are capable of operating in diverse and unknown environments. This flexibility allows them to fulfill goals independently and adapting their actions dynamically without rigidly predefined control codes. However, their autonomous behavior complicates guaranteeing safety and reliability due to the limited influence of a human operator to accurately supervise and verify each robot's actions. To ensure autonomous mobile robot's safety and reliability, which are aspects of dependability, methods are needed both in the planning and execution of missions for autonomous mobile robots. In this article, a twofold approach is presented that ensures fault removal in the context of mission planning and fault prevention during mission execution for autonomous mobile robots. First, the approach consists of a concept based on formal verification applied during the planning phase of missions. Second, the approach consists of a rule-based concept applied during mission execution. A use case applying the approach is presented, discussing how the two concepts complement each other and what contribution they make to certain aspects of dependability.
 Unbemannte Fahrzeuge sind durch zunehmende Autonomie in der Lage in unterschiedlichen unbekannten Umgebungen zu operieren. Diese Flexibilit\"at erm\"oglicht es ihnen Ziele eigenst\"andig zu erf\"ullen und ihre Handlungen dynamisch anzupassen ohne starr vorgegebenen Steuerungscode. Allerdings erschwert ihr autonomes Verhalten die Gew\"ahrleistung von Sicherheit und Zuverl\"assigkeit, bzw. der Verl\"asslichkeit, da der Einfluss eines menschlichen Bedieners zur genauen \"Uberwachung und Verifizierung der Aktionen jedes Roboters begrenzt ist. Daher werden Methoden sowohl in der Planung als auch in der Ausf\"uhrung von Missionen f\"ur unbemannte Fahrzeuge ben\"otigt, um die Sicherheit und Zuverl\"assigkeit dieser Fahrzeuge zu gew\"ahrleisten. In diesem Artikel wird ein zweistufiger Ansatz vorgestellt, der eine Fehlerbeseitigung w\"ahrend der Missionsplanung und eine Fehlerpr\"avention w\"ahrend der Missionsausf\"uhrung f\"ur unbemannte Fahrzeuge sicherstellt. Die Fehlerbeseitigung basiert auf formaler Verifikation, die w\"ahrend der Planungsphase der Missionen angewendet wird. Die Fehlerpr\"avention basiert auf einem regelbasierten Konzept, das w\"ahrend der Missionsausf\"uhrung angewendet wird. Der Ansatz wird an einem Beispiel angewendet und es wird diskutiert, wie die beiden Konzepte sich erg\"anzen und welchen Beitrag sie zu verschiedenen Aspekten der Verl\"asslichkeit leisten.</description>
      <guid isPermaLink="false">oai:arXiv.org:2407.02876v1</guid>
      <category>cs.RO</category>
      <category>cs.SY</category>
      <category>eess.SY</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Aron Schnakenbeck, Christoph Sieber, Luis Miguel Vieira da Silva, Felix Gehlhoff, Alexander Fay</dc:creator>
    </item>
    <item>
      <title>Efficient Fusion and Task Guided Embedding for End-to-end Autonomous Driving</title>
      <link>https://arxiv.org/abs/2407.02878</link>
      <description>arXiv:2407.02878v1 Announce Type: new 
Abstract: To address the challenges of sensor fusion and safety risk prediction, contemporary closed-loop autonomous driving neural networks leveraging imitation learning typically require a substantial volume of parameters and computational resources to run neural networks. Given the constrained computational capacities of onboard vehicular computers, we introduce a compact yet potent solution named EfficientFuser. This approach employs EfficientViT for visual information extraction and integrates feature maps via cross attention. Subsequently, it utilizes a decoder-only transformer for the amalgamation of multiple features. For prediction purposes, learnable vectors are embedded as tokens to probe the association between the task and sensor features through attention. Evaluated on the CARLA simulation platform, EfficientFuser demonstrates remarkable efficiency, utilizing merely 37.6% of the parameters and 8.7% of the computations compared to the state-of-the-art lightweight method with only 0.4% lower driving score, and the safety score neared that of the leading safety-enhanced method, showcasing its efficacy and potential for practical deployment in autonomous driving systems.</description>
      <guid isPermaLink="false">oai:arXiv.org:2407.02878v1</guid>
      <category>cs.RO</category>
      <category>cs.AI</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Yipin Guo, Yilin Lang, Qinyuan Ren</dc:creator>
    </item>
    <item>
      <title>The Shortcomings of Force-from-Motion in Robot Learning</title>
      <link>https://arxiv.org/abs/2407.02904</link>
      <description>arXiv:2407.02904v1 Announce Type: new 
Abstract: Robotic manipulation requires accurate motion and physical interaction control. However, current robot learning approaches focus on motion-centric action spaces that do not explicitly give the policy control over the interaction. In this paper, we discuss the repercussions of this choice and argue for more interaction-explicit action spaces in robot learning.</description>
      <guid isPermaLink="false">oai:arXiv.org:2407.02904v1</guid>
      <category>cs.RO</category>
      <category>cs.AI</category>
      <category>cs.LG</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Elie Aljalbout, Felix Frank, Patrick van der Smagt, Alexandros Paraschos</dc:creator>
    </item>
    <item>
      <title>Online Time-Informed Kinodynamic Motion Planning of Nonlinear Systems</title>
      <link>https://arxiv.org/abs/2407.02933</link>
      <description>arXiv:2407.02933v1 Announce Type: new 
Abstract: Sampling-based kinodynamic motion planners (SKMPs) are powerful in finding collision-free trajectories for high-dimensional systems under differential constraints. Time-informed set (TIS) can provide the heuristic search domain to accelerate their convergence to the time-optimal solution. However, existing TIS approximation methods suffer from the curse of dimensionality, computational burden, and limited system applicable scope, e.g., linear and polynomial nonlinear systems. To overcome these problems, we propose a method by leveraging deep learning technology, Koopman operator theory, and random set theory. Specifically, we propose a Deep Invertible Koopman operator with control U model named DIKU to predict states forward and backward over a long horizon by modifying the auxiliary network with an invertible neural network. A sampling-based approach, ASKU, performing reachability analysis for the DIKU is developed to approximate the TIS of nonlinear control systems online. Furthermore, we design an online time-informed SKMP using a direct sampling technique to draw uniform random samples in the TIS. Simulation experiment results demonstrate that our method outperforms other existing works, approximating TIS in near real-time and achieving superior planning performance in several time-optimal kinodynamic motion planning problems.</description>
      <guid isPermaLink="false">oai:arXiv.org:2407.02933v1</guid>
      <category>cs.RO</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Fei Meng, Jianbang Liu, Haojie Shi, Han Ma, Hongliang Ren, Max Q. -H. Meng</dc:creator>
    </item>
    <item>
      <title>Past, Present, and Future: A Survey of The Evolution of Affective Robotics For Well-being</title>
      <link>https://arxiv.org/abs/2407.02957</link>
      <description>arXiv:2407.02957v1 Announce Type: new 
Abstract: Recent research in affective robots has recognized their potential in supporting human well-being. Due to rapidly developing affective and artificial intelligence technologies, this field of research has undergone explosive expansion and advancement in recent years. In order to develop a deeper understanding of recent advancements, we present a systematic review of the past 10 years of research in affective robotics for wellbeing. In this review, we identify the domains of well-being that have been studied, the methods used to investigate affective robots for well-being, and how these have evolved over time. We also examine the evolution of the multifaceted research topic from three lenses: technical, design, and ethical. Finally, we discuss future opportunities for research based on the gaps we have identified in our review -- proposing pathways to take affective robotics from the past and present to the future. The results of our review are of interest to human-robot interaction and affective computing researchers, as well as clinicians and well-being professionals who may wish to examine and incorporate affective robotics in their practices.</description>
      <guid isPermaLink="false">oai:arXiv.org:2407.02957v1</guid>
      <category>cs.RO</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Micol Spitale, Minja Axelsson, Sooyeon Jeong, Paige Tuttos{\i}, Caitlin A. Stamatis, Guy Laban, Angelica Lim, Hatice Gune</dc:creator>
    </item>
    <item>
      <title>Development of a semi-autonomous framework for NDT inspection with a tilting aerial platform</title>
      <link>https://arxiv.org/abs/2407.03003</link>
      <description>arXiv:2407.03003v1 Announce Type: new 
Abstract: This letter investigates the problem of controlling an aerial manipulator, composed of an omnidirectional tilting drone equipped with a five-degrees-of-freedom robotic arm. The robot has to interact with the environment to inspect structures and perform non-destructive measurements. A parallel force-impedance control technique is developed to establish contact with the designed surface with a desired force profile. During the interaction, a pushing phase is required to create a vacuum between the surface and the echometer sensor mounted at the end-effector, to measure the thickness of the interaction surface. Repetitive measures are performed to show the repeatability of the algorithm.</description>
      <guid isPermaLink="false">oai:arXiv.org:2407.03003v1</guid>
      <category>cs.RO</category>
      <category>cs.SY</category>
      <category>eess.SY</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Salvatore Marcellini, Simone D'Angelo, Alessandro De Crescenzo, Michele Marolla, Vincenzo Lippiello, Bruno Siciliano</dc:creator>
    </item>
    <item>
      <title>NLP Sampling: Combining MCMC and NLP Methods for Diverse Constrained Sampling</title>
      <link>https://arxiv.org/abs/2407.03035</link>
      <description>arXiv:2407.03035v1 Announce Type: new 
Abstract: Generating diverse samples under hard constraints is a core challenge in many areas. With this work we aim to provide an integrative view and framework to combine methods from the fields of MCMC, constrained optimization, as well as robotics, and gain insights in their strengths from empirical evaluations. We propose NLP Sampling as a general problem formulation, propose a family of restarting two-phase methods as a framework to integrated methods from across the fields, and evaluate them on analytical and robotic manipulation planning problems. Complementary to this, we provide several conceptual discussions, e.g. on the role of Lagrange parameters, global sampling, and the idea of a Diffused NLP and a corresponding model-based denoising sampler.</description>
      <guid isPermaLink="false">oai:arXiv.org:2407.03035v1</guid>
      <category>cs.RO</category>
      <category>cs.AI</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Marc Toussaint, Cornelius V. Braun, Joaquim Ortiz-Haro</dc:creator>
    </item>
    <item>
      <title>Position and Altitude of the Nao Camera Head from Two Points on the Soccer Field plus the Gravitational Direction</title>
      <link>https://arxiv.org/abs/2407.03041</link>
      <description>arXiv:2407.03041v1 Announce Type: new 
Abstract: To be able to play soccer, a robot needs a good estimate of its current position on the field. Ideally, multiple features are visible that have known locations. By applying trigonometry we can estimate the viewpoint from where this observation was actually made. Given that the Nao robots of the Standard Platform League have quite a limited field of view, a given camera frame typically only allows for one or two points to be recognized.
  In this paper we propose a method for determining the (x, y) coordinates on the field and the height h of the camera from the geometry of a simplified tetrahedron. This configuration is formed by two observed points on the ground plane plus the gravitational direction. When the distance between the two points is known, and the directions to the points plus the gravitational direction are measured, all dimensions of the tetrahedron can be determined.
  By performing these calculations with rational trigonometry instead of classical trigonometry, the computations turn out to be 28.7% faster, with equal numerical accuracy. The position of the head of the Nao can also be externally measured with the OptiTrack system. The difference between externally measured and internally predicted position from sensor data gives us mean absolute errors in the 3-6 centimeters range, when we estimated the gravitational direction from the vanishing point of the outer edges of the goal posts.</description>
      <guid isPermaLink="false">oai:arXiv.org:2407.03041v1</guid>
      <category>cs.RO</category>
      <category>cs.CV</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Stijn Oomes, Arnoud Visser</dc:creator>
    </item>
    <item>
      <title>Applying Extended Object Tracking for Self-Localization of Roadside Radar Sensors</title>
      <link>https://arxiv.org/abs/2407.03084</link>
      <description>arXiv:2407.03084v1 Announce Type: new 
Abstract: Intelligent Transportation Systems (ITS) can benefit from roadside 4D mmWave radar sensors for large-scale traffic monitoring due to their weatherproof functionality, long sensing range and low manufacturing cost. However, the localization method using external measurement devices has limitations in urban environments. Furthermore, if the sensor mount exhibits changes due to environmental influences, they cannot be corrected when the measurement is performed only during the installation. In this paper, we propose self-localization of roadside radar data using Extended Object Tracking (EOT). The method analyses both the tracked trajectories of the vehicles observed by the sensor and the aerial laser scan of city streets, assigns labels of driving behaviors such as "straight ahead", "left turn", "right turn" to trajectory sections and road segments, and performs Semantic Iterative Closest Points (SICP) algorithm to register the point cloud. The method exploits the result from a down stream task -- object tracking -- for localization. We demonstrate high accuracy in the sub-meter range along with very low orientation error. The method also shows good data efficiency. The evaluation is done in both simulation and real-world tests.</description>
      <guid isPermaLink="false">oai:arXiv.org:2407.03084v1</guid>
      <category>cs.RO</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <dc:creator>Longfei Han, Qiuyu Xu, Klaus Kefferp\"utz, Gordon Elger, J\"urgen Beyerer</dc:creator>
    </item>
    <item>
      <title>Performance Comparison of ROS2 Middlewares for Multi-robot Mesh Networks in Planetary Exploration</title>
      <link>https://arxiv.org/abs/2407.03091</link>
      <description>arXiv:2407.03091v1 Announce Type: new 
Abstract: Recent advancements in Multi-Robot Systems (MRS) and mesh network technologies pave the way for innovative approaches to explore extreme environments. The Artemis Accords, a series of international agreements, have further catalyzed this progress by fostering cooperation in space exploration, emphasizing the use of cutting-edge technologies. In parallel, the widespread adoption of the Robot Operating System 2 (ROS 2) by companies across various sectors underscores its robustness and versatility. This paper evaluates the performances of available ROS 2 MiddleWare (RMW), such as FastRTPS, CycloneDDS and Zenoh, over a mesh network with a dynamic topology. The final choice of RMW is determined by the one that would fit the most the scenario: an exploration of the extreme extra-terrestrial environment using a MRS. The conducted study in a real environment highlights Zenoh as a potential solution for future applications, showing a reduced delay, reachability, and CPU usage while being competitive on data overhead and RAM usage over a dynamic mesh topology</description>
      <guid isPermaLink="false">oai:arXiv.org:2407.03091v1</guid>
      <category>cs.RO</category>
      <category>cs.NI</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Lo\"ick Pierre Chovet, Gabriel Manuel Garcia, Abhishek Bera, Antoine Richard, Kazuya Yoshida, Miguel Angel Olivares-Mendez</dc:creator>
    </item>
    <item>
      <title>IntentionNet: Map-Lite Visual Navigation at the Kilometre Scale</title>
      <link>https://arxiv.org/abs/2407.03122</link>
      <description>arXiv:2407.03122v1 Announce Type: new 
Abstract: This work explores the challenges of creating a scalable and robust robot navigation system that can traverse both indoor and outdoor environments to reach distant goals. We propose a navigation system architecture called IntentionNet that employs a monolithic neural network as the low-level planner/controller, and uses a general interface that we call intentions to steer the controller. The paper proposes two types of intentions, Local Path and Environment (LPE) and Discretised Local Move (DLM), and shows that DLM is robust to significant metric positioning and mapping errors. The paper also presents Kilo-IntentionNet, an instance of the IntentionNet system using the DLM intention that is deployed on a Boston Dynamics Spot robot, and which successfully navigates through complex indoor and outdoor environments over distances of up to a kilometre with only noisy odometry.</description>
      <guid isPermaLink="false">oai:arXiv.org:2407.03122v1</guid>
      <category>cs.RO</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <dc:creator>Wei Gao, Bo Ai, Joel Loo,  Vinay, David Hsu</dc:creator>
    </item>
    <item>
      <title>Ultra-Lightweight Collaborative Mapping for Robot Swarms</title>
      <link>https://arxiv.org/abs/2407.03136</link>
      <description>arXiv:2407.03136v1 Announce Type: new 
Abstract: A key requirement in robotics is the ability to simultaneously self-localize and map a previously unknown environment, relying primarily on onboard sensing and computation. Achieving fully onboard accurate simultaneous localization and mapping (SLAM) is feasible for high-end robotic platforms, whereas small and inexpensive robots face challenges due to constrained hardware, therefore frequently resorting to external infrastructure for sensing and computation. The challenge is further exacerbated in swarms of robots, where coordination, scalability, and latency are crucial concerns. This work introduces a decentralized and lightweight collaborative SLAM approach that enables mapping on virtually any robot, even those equipped with low-cost hardware, including miniaturized insect-size devices. Moreover, the proposed solution supports large swarm formations with the capability to coordinate hundreds of agents. To substantiate our claims, we have successfully implemented collaborative SLAM on centimeter-size drones weighing only 46 grams. Remarkably, we achieve results comparable to high-end state-of-the-art solutions while reducing the cost, memory, and computation requirements by two orders of magnitude. Our approach is innovative in three main aspects. First, it enables onboard infrastructure-less collaborative mapping with a lightweight and cost-effective solution in terms of sensing and computation. Second, we optimize the data traffic within the swarm to support hundreds of cooperative agents using standard wireless protocols such as ultra-wideband (UWB), Bluetooth, or WiFi. Last, we implement a distributed swarm coordination policy to decrease mapping latency and enhance accuracy.</description>
      <guid isPermaLink="false">oai:arXiv.org:2407.03136v1</guid>
      <category>cs.RO</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Vlad Niculescu, Tommaso Polonelli, Michele Magno, Luca Benini</dc:creator>
    </item>
    <item>
      <title>Bunny-VisionPro: Real-Time Bimanual Dexterous Teleoperation for Imitation Learning</title>
      <link>https://arxiv.org/abs/2407.03162</link>
      <description>arXiv:2407.03162v1 Announce Type: new 
Abstract: Teleoperation is a crucial tool for collecting human demonstrations, but controlling robots with bimanual dexterous hands remains a challenge. Existing teleoperation systems struggle to handle the complexity of coordinating two hands for intricate manipulations. We introduce Bunny-VisionPro, a real-time bimanual dexterous teleoperation system that leverages a VR headset. Unlike previous vision-based teleoperation systems, we design novel low-cost devices to provide haptic feedback to the operator, enhancing immersion. Our system prioritizes safety by incorporating collision and singularity avoidance while maintaining real-time performance through innovative designs. Bunny-VisionPro outperforms prior systems on a standard task suite, achieving higher success rates and reduced task completion times. Moreover, the high-quality teleoperation demonstrations improve downstream imitation learning performance, leading to better generalizability. Notably, Bunny-VisionPro enables imitation learning with challenging multi-stage, long-horizon dexterous manipulation tasks, which have rarely been addressed in previous work. Our system's ability to handle bimanual manipulations while prioritizing safety and real-time performance makes it a powerful tool for advancing dexterous manipulation and imitation learning.</description>
      <guid isPermaLink="false">oai:arXiv.org:2407.03162v1</guid>
      <category>cs.RO</category>
      <category>cs.CV</category>
      <category>cs.LG</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Runyu Ding, Yuzhe Qin, Jiyue Zhu, Chengzhe Jia, Shiqi Yang, Ruihan Yang, Xiaojuan Qi, Xiaolong Wang</dc:creator>
    </item>
    <item>
      <title>Localization in Dynamic Planar Environments Using Few Distance Measurements</title>
      <link>https://arxiv.org/abs/2407.03219</link>
      <description>arXiv:2407.03219v1 Announce Type: new 
Abstract: We present a method for determining the unknown location of a sensor placed in a known 2D environment in the presence of unknown dynamic obstacles, using only few distance measurements. We present guarantees on the quality of the localization, which are robust under mild assumptions on the density of the unknown/dynamic obstacles in the known environment. We demonstrate the effectiveness of our method in simulated experiments for different environments and varying dynamic-obstacle density. Our open source software is available at https://github.com/TAU-CGL/vb-fdml2-public.</description>
      <guid isPermaLink="false">oai:arXiv.org:2407.03219v1</guid>
      <category>cs.RO</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Michael M. Bilevich, Shahar Guini Menashe, Dan Halperin</dc:creator>
    </item>
    <item>
      <title>PPO-based Dynamic Control of Uncertain Floating Platforms in the Zero-G Environment</title>
      <link>https://arxiv.org/abs/2407.03224</link>
      <description>arXiv:2407.03224v1 Announce Type: new 
Abstract: In the field of space exploration, floating platforms play a crucial role in scientific investigations and technological advancements. However, controlling these platforms in zero-gravity environments presents unique challenges, including uncertainties and disturbances. This paper introduces an innovative approach that combines Proximal Policy Optimization (PPO) with Model Predictive Control (MPC) in the zero-gravity laboratory (Zero-G Lab) at the University of Luxembourg. This approach leverages PPO's reinforcement learning power and MPC's precision to navigate the complex control dynamics of floating platforms. Unlike traditional control methods, this PPO-MPC approach learns from MPC predictions, adapting to unmodeled dynamics and disturbances, resulting in a resilient control framework tailored to the zero-gravity environment. Simulations and experiments in the Zero-G Lab validate this approach, showcasing the adaptability of the PPO agent. This research opens new possibilities for controlling floating platforms in zero-gravity settings, promising advancements in space exploration.</description>
      <guid isPermaLink="false">oai:arXiv.org:2407.03224v1</guid>
      <category>cs.RO</category>
      <category>cs.AI</category>
      <category>cs.SY</category>
      <category>eess.SY</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Mahya Ramezani, M. Amin Alandihallaj, Andreas M. Hein</dc:creator>
    </item>
    <item>
      <title>Terrain Classification Enhanced with Uncertainty for Space Exploration Robots from Proprioceptive Data</title>
      <link>https://arxiv.org/abs/2407.03241</link>
      <description>arXiv:2407.03241v1 Announce Type: new 
Abstract: Terrain Classification is an essential task in space exploration, where unpredictable environments are difficult to observe using only exteroceptive sensors such as vision. Implementing Neural Network classifiers can have high performance but can be deemed untrustworthy as they lack transparency, which makes them unreliable for taking high-stakes decisions during mission planning. We address this by proposing Neural Networks with Uncertainty Quantification in Terrain Classification. We enable our Neural Networks with Monte Carlo Dropout, DropConnect, and Flipout in time series-capable architectures using only proprioceptive data as input. We use Bayesian Optimization with Hyperband for efficient hyperparameter optimization to find optimal models for trustworthy terrain classification.</description>
      <guid isPermaLink="false">oai:arXiv.org:2407.03241v1</guid>
      <category>cs.RO</category>
      <category>cs.LG</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Mariela De Lucas \'Alvarez, Jichen Guo, Raul Dom\'inguez, Matias Valdenegro-Toro</dc:creator>
    </item>
    <item>
      <title>TieBot: Learning to Knot a Tie from Visual Demonstration through a Real-to-Sim-to-Real Approach</title>
      <link>https://arxiv.org/abs/2407.03245</link>
      <description>arXiv:2407.03245v1 Announce Type: new 
Abstract: The tie-knotting task is highly challenging due to the tie's high deformation and long-horizon manipulation actions. This work presents TieBot, a Real-to-Sim-to-Real learning from visual demonstration system for the robots to learn to knot a tie. We introduce the Hierarchical Feature Matching approach to estimate a sequence of tie's meshes from the demonstration video. With these estimated meshes used as subgoals, we first learn a teacher policy using privileged information. Then, we learn a student policy with point cloud observation by imitating teacher policy. Lastly, our pipeline learns a residual policy when the learned policy is applied to real-world execution, mitigating the Sim2Real gap. We demonstrate the effectiveness of TieBot in simulation and the real world. In the real-world experiment, a dual-arm robot successfully knots a tie, achieving 50% success rate among 10 trials. Videos can be found on our $\href{https://tiebots.github.io/}{\text{website}}$.</description>
      <guid isPermaLink="false">oai:arXiv.org:2407.03245v1</guid>
      <category>cs.RO</category>
      <category>cs.AI</category>
      <category>cs.SY</category>
      <category>eess.SY</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Weikun Peng, Jun Lv, Yuwei Zeng, Haonan Chen, Siheng Zhao, Jicheng Sun, Cewu Lu, Lin Shao</dc:creator>
    </item>
    <item>
      <title>Value-Penalized Auxiliary Control from Examples for Learning without Rewards or Demonstrations</title>
      <link>https://arxiv.org/abs/2407.03311</link>
      <description>arXiv:2407.03311v1 Announce Type: new 
Abstract: Learning from examples of success is an appealing approach to reinforcement learning that eliminates many of the disadvantages of using hand-crafted reward functions or full expert-demonstration trajectories, both of which can be difficult to acquire, biased, or suboptimal. However, learning from examples alone dramatically increases the exploration challenge, especially for complex tasks. This work introduces value-penalized auxiliary control from examples (VPACE); we significantly improve exploration in example-based control by adding scheduled auxiliary control and examples of auxiliary tasks. Furthermore, we identify a value-calibration problem, where policy value estimates can exceed their theoretical limits based on successful data. We resolve this problem, which is exacerbated by learning auxiliary tasks, through the addition of an above-success-level value penalty. Across three simulated and one real robotic manipulation environment, and 21 different main tasks, we show that our approach substantially improves learning efficiency. Videos, code, and datasets are available at https://papers.starslab.ca/vpace.</description>
      <guid isPermaLink="false">oai:arXiv.org:2407.03311v1</guid>
      <category>cs.RO</category>
      <category>cs.AI</category>
      <category>cs.LG</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Trevor Ablett, Bryan Chan, Jayce Haoran Wang, Jonathan Kelly</dc:creator>
    </item>
    <item>
      <title>Wildfire Autonomous Response and Prediction Using Cellular Automata (WARP-CA)</title>
      <link>https://arxiv.org/abs/2407.02613</link>
      <description>arXiv:2407.02613v1 Announce Type: cross 
Abstract: Wildfires pose a severe challenge to ecosystems and human settlements, exacerbated by climate change and environmental factors. Traditional wildfire modeling, while useful, often fails to adapt to the rapid dynamics of such events. This report introduces the (Wildfire Autonomous Response and Prediction Using Cellular Automata) WARP-CA model, a novel approach that integrates terrain generation using Perlin noise with the dynamism of Cellular Automata (CA) to simulate wildfire spread. We explore the potential of Multi-Agent Reinforcement Learning (MARL) to manage wildfires by simulating autonomous agents, such as UAVs and UGVs, within a collaborative framework. Our methodology combines world simulation techniques and investigates emergent behaviors in MARL, focusing on efficient wildfire suppression and considering critical environmental factors like wind patterns and terrain features.</description>
      <guid isPermaLink="false">oai:arXiv.org:2407.02613v1</guid>
      <category>cs.AI</category>
      <category>cs.MA</category>
      <category>cs.NE</category>
      <category>cs.RO</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <dc:creator>Abdelrahman Ramadan</dc:creator>
    </item>
    <item>
      <title>A Self-Supervised Task for Fault Detection in Satellite Multivariate Time Series</title>
      <link>https://arxiv.org/abs/2407.02861</link>
      <description>arXiv:2407.02861v1 Announce Type: cross 
Abstract: In the space sector, due to environmental conditions and restricted accessibility, robust fault detection methods are imperative for ensuring mission success and safeguarding valuable assets. This work proposes a novel approach leveraging Physics-Informed Real NVP neural networks, renowned for their ability to model complex and high-dimensional distributions, augmented with a self-supervised task based on sensors' data permutation. It focuses on enhancing fault detection within the satellite multivariate time series. The experiments involve various configurations, including pre-training with self-supervision, multi-task learning, and standalone self-supervised training. Results indicate significant performance improvements across all settings. In particular, employing only the self-supervised loss yields the best overall results, suggesting its efficacy in guiding the network to extract relevant features for fault detection. This study presents a promising direction for improving fault detection in space systems and warrants further exploration in other datasets and applications.</description>
      <guid isPermaLink="false">oai:arXiv.org:2407.02861v1</guid>
      <category>cs.LG</category>
      <category>cs.RO</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Carlo Cena, Silvia Bucci, Alessandro Balossino, Marcello Chiaberge</dc:creator>
    </item>
    <item>
      <title>Fast maneuver recovery from aerial observation: trajectory clustering and outliers rejection</title>
      <link>https://arxiv.org/abs/2407.02863</link>
      <description>arXiv:2407.02863v1 Announce Type: cross 
Abstract: The implementation of road user models that realistically reproduce a credible behavior in a multi-agentsimulation is still an open problem. A data-driven approach consists on to deduce behaviors that may exist in real situation to obtain different types of trajectories from a large set of observations. The data, and its classification, could then be used to train models capable to extrapolate such behavior. Cars and two different types of Vulnerable Road Users (VRU) will be considered by the trajectory clustering methods proposed: pedestrians and cyclists. The results reported here evaluate methods to extract well-defined trajectory classes from raw data without the use of map information while also separating ''eccentric'' or incomplete trajectories from the ones that are complete and representative in any scenario. Two environments will serve as test for the methods develop, three different intersections and one roundabout. The resulting clusters of trajectories can then be used for prediction or learning tasks or discarded if it is composed by outliers.</description>
      <guid isPermaLink="false">oai:arXiv.org:2407.02863v1</guid>
      <category>cs.AI</category>
      <category>cs.CV</category>
      <category>cs.RO</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <arxiv:journal_reference>2024 IEEE Intelligent Vehicles Symposium (IV), ITS-IEEE, Jun 2024, Jeju, South Korea</arxiv:journal_reference>
      <dc:creator>Nelson de Moura (ASTRA), Augustin Gervreau-Mercier (ASTRA), Fernando Garrido (ASTRA), Fawzi Nashashibi (ASTRA)</dc:creator>
    </item>
    <item>
      <title>Magnetic Hysteresis Modeling with Neural Operators</title>
      <link>https://arxiv.org/abs/2407.03261</link>
      <description>arXiv:2407.03261v1 Announce Type: cross 
Abstract: Hysteresis modeling is crucial to comprehend the behavior of magnetic devices, facilitating optimal designs. Hitherto, deep learning-based methods employed to model hysteresis, face challenges in generalizing to novel input magnetic fields. This paper addresses the generalization challenge by proposing neural operators for modeling constitutive laws that exhibit magnetic hysteresis by learning a mapping between magnetic fields. In particular, two prominent neural operators -- deep operator network and Fourier neural operator -- are employed to predict novel first-order reversal curves and minor loops, where novel means they are not used to train the model. In addition, a rate-independent Fourier neural operator is proposed to predict material responses at sampling rates different from those used during training to incorporate the rate-independent characteristics of magnetic hysteresis. The presented numerical experiments demonstrate that neural operators efficiently model magnetic hysteresis, outperforming the traditional neural recurrent methods on various metrics and generalizing to novel magnetic fields. The findings emphasize the advantages of using neural operators for modeling hysteresis under varying magnetic conditions, underscoring their importance in characterizing magnetic material based devices.</description>
      <guid isPermaLink="false">oai:arXiv.org:2407.03261v1</guid>
      <category>cs.LG</category>
      <category>cs.RO</category>
      <category>cs.SY</category>
      <category>eess.SP</category>
      <category>eess.SY</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Abhishek Chandra, Bram Daniels, Mitrofan Curti, Koen Tiels, Elena A. Lomonova</dc:creator>
    </item>
    <item>
      <title>CATNIPS: Collision Avoidance Through Neural Implicit Probabilistic Scenes</title>
      <link>https://arxiv.org/abs/2302.12931</link>
      <description>arXiv:2302.12931v3 Announce Type: replace 
Abstract: We introduce a transformation of a Neural Radiance Field (NeRF) to an equivalent Poisson Point Process (PPP). This PPP transformation allows for rigorous quantification of uncertainty in NeRFs, in particular, for computing collision probabilities for a robot navigating through a NeRF environment. The PPP is a generalization of a probabilistic occupancy grid to the continuous volume and is fundamental to the volumetric ray-tracing model underlying radiance fields. Building upon this PPP representation, we present a chance-constrained trajectory optimization method for safe robot navigation in NeRFs. Our method relies on a voxel representation called the Probabilistic Unsafe Robot Region (PURR) that spatially fuses the chance constraint with the NeRF model to facilitate fast trajectory optimization. We then combine a graph-based search with a spline-based trajectory optimization to yield robot trajectories through the NeRF that are guaranteed to satisfy a user-specific collision probability. We validate our chance constrained planning method through simulations and hardware experiments, showing superior performance compared to prior works on trajectory planning in NeRF environments. Our codebase can be found at https://github.com/chengine/catnips, and videos can be found on our project page (https://chengine.github.io/catnips).</description>
      <guid isPermaLink="false">oai:arXiv.org:2302.12931v3</guid>
      <category>cs.RO</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <arxiv:DOI>10.1109/TRO.2024.3386394</arxiv:DOI>
      <arxiv:journal_reference>IEEE Transactions on Robotics, vol. 40, pp. 2712-2728, 2024</arxiv:journal_reference>
      <dc:creator>Timothy Chen, Preston Culbertson, Mac Schwager</dc:creator>
    </item>
    <item>
      <title>Using Buckingham's $\pi$ Theorem for Multi-System Learning Transfer: a Case-study with 3 Vehicles Sharing a Database</title>
      <link>https://arxiv.org/abs/2310.17545</link>
      <description>arXiv:2310.17545v2 Announce Type: replace 
Abstract: Many advanced driver assistance schemes or autonomous vehicle controllers are based on a motion model of the vehicle behavior, i.e., a function predicting how the vehicle will react to a given control input. Data-driven models, based on experimental or simulated data, are very useful, especially for vehicles difficult to model analytically, for instance, ground vehicles for which the ground-tire interaction is hard to model from first principles. However, learning schemes are limited by the difficulty of collecting large amounts of experimental data or having to rely on high-fidelity simulations. This paper explores the potential of an approach that uses dimensionless numbers based on Buckingham's $\pi$ theorem to improve the efficiency of data for learning models, with the goal of facilitating knowledge sharing between similar systems. A case study using car-like vehicles compares traditional and dimensionless models on simulated and experimental data to validate the benefits of the new dimensionless learning approach. Prediction accuracy improvements with the dimensionless scheme when using a shared database, that is, predicting the motion of a vehicle based on data from various different vehicles was found to be 480\% more accurate for predicting a simple no-slip maneuver based on simulated data and 11\% more accurate to predict a highly dynamic braking maneuver based on experimental data. A modified physics-informed learning scheme with hand-crafted dimensionless features was also shown to increase the improvement to precision gains of 917\% and 28\% respectively. A comparative study also shows that using Buckingham's $\pi$ theorem is a much more effective preprocessing step for this task than principal component analysis (PCA) or simply normalizing the data.</description>
      <guid isPermaLink="false">oai:arXiv.org:2310.17545v2</guid>
      <category>cs.RO</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <arxiv:DOI>10.3390/electronics13112041</arxiv:DOI>
      <arxiv:journal_reference>Electronics 2024, 13(11), 2041</arxiv:journal_reference>
      <dc:creator>William Therrien, Olivier Lecompte, Alexandre Girard</dc:creator>
    </item>
    <item>
      <title>Efficient, Responsive, and Robust Hopping on Deformable Terrain</title>
      <link>https://arxiv.org/abs/2311.18685</link>
      <description>arXiv:2311.18685v2 Announce Type: replace 
Abstract: Legged robot locomotion is hindered by a mismatch between applications where legs can outperform wheels or treads, most of which feature deformable substrates, and existing tools for planning and control, most of which assume flat, rigid substrates. In this study we focus on the ramifications of plastic terrain deformation on the hop-to-hop energy dynamics of a spring-legged monopedal hopping robot animated by a switched-compliance energy injection controller. From this deliberately simple robot-terrain template, we derive a hop-to-hop energy return map, and we use physical experiments and simulations to validate the hop-to-hop energy map for a real robot hopping on a real deformable substrate. The dynamical properties (fixed points, eigenvalues, basins of attraction) of this map provide insights into efficient, responsive, and robust locomotion on deformable terrain. Specifically, we identify constant-fixed-point surfaces in a controller parameter space that suggest it is possible to tune control parameters for efficiency or responsiveness while targeting a desired gait energy level. We also identify conditions under which fixed points of the energy map are globally stable, and we further characterize the basins of attraction of fixed points when these conditions are not satisfied. We conclude by discussing the implications of this hop-to-hop energy map for planning, control, and estimation for efficient, agile, and robust legged locomotion on deformable terrain.</description>
      <guid isPermaLink="false">oai:arXiv.org:2311.18685v2</guid>
      <category>cs.RO</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Daniel J. Lynch, Jason L. Pusey, Sean W. Gart, Paul B. Umbanhowar, Kevin M. Lynch</dc:creator>
    </item>
    <item>
      <title>Multi-Agent Probabilistic Ensembles with Trajectory Sampling for Connected Autonomous Vehicles</title>
      <link>https://arxiv.org/abs/2312.13910</link>
      <description>arXiv:2312.13910v2 Announce Type: replace 
Abstract: Autonomous Vehicles (AVs) have attracted significant attention in recent years and Reinforcement Learning (RL) has shown remarkable performance in improving the autonomy of vehicles. In that regard, the widely adopted Model-Free RL (MFRL) promises to solve decision-making tasks in connected AVs (CAVs), contingent on the readiness of a significant amount of data samples for training. Nevertheless, it might be infeasible in practice and possibly lead to learning instability. In contrast, Model-Based RL (MBRL) manifests itself in sample-efficient learning, but the asymptotic performance of MBRL might lag behind the state-of-the-art MFRL algorithms. Furthermore, most studies for CAVs are limited to the decision-making of a single AV only, thus underscoring the performance due to the absence of communications. In this study, we try to address the decision-making problem of multiple CAVs with limited communications and propose a decentralized Multi-Agent Probabilistic Ensembles with Trajectory Sampling algorithm MA-PETS. In particular, in order to better capture the uncertainty of the unknown environment, MA-PETS leverages Probabilistic Ensemble (PE) neural networks to learn from communicated samples among neighboring CAVs. Afterwards, MA-PETS capably develops Trajectory Sampling (TS)-based model-predictive control for decision-making. On this basis, we derive the multi-agent group regret bound affected by the number of agents within the communication range and mathematically validate that incorporating effective information exchange among agents into the multi-agent learning scheme contributes to reducing the group regret bound in the worst case. Finally, we empirically demonstrate the superiority of MA-PETS in terms of the sample efficiency comparable to MFBL.</description>
      <guid isPermaLink="false">oai:arXiv.org:2312.13910v2</guid>
      <category>cs.RO</category>
      <category>cs.LG</category>
      <category>cs.MA</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Ruoqi Wen, Jiahao Huang, Rongpeng Li, Guoru Ding, Zhifeng Zhao</dc:creator>
    </item>
    <item>
      <title>Explainable AI for Safe and Trustworthy Autonomous Driving: A Systematic Review</title>
      <link>https://arxiv.org/abs/2402.10086</link>
      <description>arXiv:2402.10086v2 Announce Type: replace 
Abstract: Artificial Intelligence (AI) shows promising applications for the perception and planning tasks in autonomous driving (AD) due to its superior performance compared to conventional methods. However, inscrutable AI systems exacerbate the existing challenge of safety assurance of AD. One way to mitigate this challenge is to utilize explainable AI (XAI) techniques. To this end, we present the first comprehensive systematic literature review of explainable methods for safe and trustworthy AD. We begin by analyzing the requirements for AI in the context of AD, focusing on three key aspects: data, model, and agency. We find that XAI is fundamental to meeting these requirements. Based on this, we explain the sources of explanations in AI and describe a taxonomy of XAI. We then identify five key contributions of XAI for safe and trustworthy AI in AD, which are interpretable design, interpretable surrogate models, interpretable monitoring, auxiliary explanations, and interpretable validation. Finally, we propose a modular framework called SafeX to integrate these contributions, enabling explanation delivery to users while simultaneously ensuring the safety of AI models.</description>
      <guid isPermaLink="false">oai:arXiv.org:2402.10086v2</guid>
      <category>cs.RO</category>
      <category>cs.AI</category>
      <category>cs.CV</category>
      <category>cs.HC</category>
      <category>cs.LG</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Anton Kuznietsov, Balint Gyevnar, Cheng Wang, Steven Peters, Stefano V. Albrecht</dc:creator>
    </item>
    <item>
      <title>Reinforcement Learning with Elastic Time Steps</title>
      <link>https://arxiv.org/abs/2402.14961</link>
      <description>arXiv:2402.14961v3 Announce Type: replace 
Abstract: Traditional Reinforcement Learning (RL) policies are typically implemented with fixed control rates, often disregarding the impact of control rate selection. This can lead to inefficiencies as the optimal control rate varies with task requirements. We propose the Multi-Objective Soft Elastic Actor-Critic (MOSEAC), an off-policy actor-critic algorithm that uses elastic time steps to dynamically adjust the control frequency. This approach minimizes computational resources by selecting the lowest viable frequency. We show that MOSEAC converges and produces stable policies at the theoretical level, and validate our findings in a real-time 3D racing game. MOSEAC significantly outperformed other variable time step approaches in terms of energy efficiency and task effectiveness. Additionally, MOSEAC demonstrated faster and more stable training, showcasing its potential for real-world RL applications in robotics.</description>
      <guid isPermaLink="false">oai:arXiv.org:2402.14961v3</guid>
      <category>cs.RO</category>
      <category>cs.LG</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Dong Wang, Giovanni Beltrame</dc:creator>
    </item>
    <item>
      <title>SlideSLAM: Sparse, Lightweight, Decentralized Metric-Semantic SLAM for Multi-Robot Navigation</title>
      <link>https://arxiv.org/abs/2406.17249</link>
      <description>arXiv:2406.17249v2 Announce Type: replace 
Abstract: This paper develops a real-time decentralized metric-semantic Simultaneous Localization and Mapping (SLAM) approach that leverages a sparse and lightweight object-based representation to enable a heterogeneous robot team to autonomously explore 3D environments featuring indoor, urban, and forested areas without relying on GPS. We use a hierarchical metric-semantic representation of the environment, including high-level sparse semantic maps of object models and low-level voxel maps. We leverage the informativeness and viewpoint invariance of the high-level semantic map to obtain an effective semantics-driven place-recognition algorithm for inter-robot loop closure detection across aerial and ground robots with different sensing modalities. A communication module is designed to track each robot's own observations and those of other robots whenever communication links are available. Such observations are then used to construct a merged map. Our framework enables real-time decentralized operations onboard robots, allowing them to opportunistically leverage communication. We integrate and deploy our proposed framework on three types of aerial and ground robots. Extensive experimental results show an average inter-robot localization error of approximately 20 cm in position and 0.2 degrees in orientation, an object mapping F1 score consistently over 0.9, and a communication packet size of merely 2-3 megabytes per kilometer trajectory with as many as 1,000 landmarks. The project website can be found at https://xurobotics.github.io/slideslam/.</description>
      <guid isPermaLink="false">oai:arXiv.org:2406.17249v2</guid>
      <category>cs.RO</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Xu Liu, Jiuzhou Lei, Ankit Prabhu, Yuezhan Tao, Igor Spasojevic, Pratik Chaudhari, Nikolay Atanasov, Vijay Kumar</dc:creator>
    </item>
    <item>
      <title>Residual-MPPI: Online Policy Customization for Continuous Control</title>
      <link>https://arxiv.org/abs/2407.00898</link>
      <description>arXiv:2407.00898v3 Announce Type: replace 
Abstract: Policies learned through Reinforcement Learning (RL) and Imitation Learning (IL) have demonstrated significant potential in achieving advanced performance in continuous control tasks. However, in real-world environments, it is often necessary to further customize a trained policy when there are additional requirements that were unforeseen during the original training phase. It is possible to fine-tune the policy to meet the new requirements, but this often requires collecting new data with the added requirements and access to the original training metric and policy parameters. In contrast, an online planning algorithm, if capable of meeting the additional requirements, can eliminate the necessity for extensive training phases and customize the policy without knowledge of the original training scheme or task. In this work, we propose a generic online planning algorithm for customizing continuous-control policies at the execution time which we call Residual-MPPI. It is able to customize a given prior policy on new performance metrics in few-shot and even zero-shot online settings. Also, Residual-MPPI only requires access to the action distribution produced by the prior policy, without additional knowledge regarding the original task. Through our experiments, we demonstrate that the proposed Residual-MPPI algorithm can accomplish the few-shot/zero-shot online policy customization task effectively, including customizing the champion-level racing agent, Gran Turismo Sophy (GT Sophy) 1.0, in the challenging car racing scenario, Gran Turismo Sport (GTS) environment. Demo videos are available on our website: https://sites.google.com/view/residual-mppi</description>
      <guid isPermaLink="false">oai:arXiv.org:2407.00898v3</guid>
      <category>cs.RO</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Pengcheng Wang, Chenran Li, Catherine Weaver, Kenta Kawamoto, Masayoshi Tomizuka, Chen Tang, Wei Zhan</dc:creator>
    </item>
    <item>
      <title>Labeling Sentences with Symbolic and Deictic Gestures via Semantic Similarity</title>
      <link>https://arxiv.org/abs/2407.02151</link>
      <description>arXiv:2407.02151v2 Announce Type: replace 
Abstract: Co-speech gesture generation on artificial agents has gained attention recently, mainly when it is based on data-driven models. However, end-to-end methods often fail to generate co-speech gestures related to semantics with specific forms, i.e., Symbolic and Deictic gestures. In this work, we identify which words in a sentence are contextually related to Symbolic and Deictic gestures. Firstly, we appropriately chose 12 gestures recognized by people from the Italian culture, which different humanoid robots can reproduce. Then, we implemented two rule-based algorithms to label sentences with Symbolic and Deictic gestures. The rules depend on the semantic similarity scores computed with the RoBerta model between sentences that heuristically represent gestures and sub-sentences inside an objective sentence that artificial agents have to pronounce. We also implemented a baseline algorithm that assigns gestures without computing similarity scores. Finally, to validate the results, we asked 30 persons to label a set of sentences with Deictic and Symbolic gestures through a Graphical User Interface (GUI), and we compared the labels with the ones produced by our algorithms. For this scope, we computed Average Precision (AP) and Intersection Over Union (IOU) scores, and we evaluated the Average Computational Time (ACT). Our results show that semantic similarity scores are useful for finding Symbolic and Deictic gestures in utterances.</description>
      <guid isPermaLink="false">oai:arXiv.org:2407.02151v2</guid>
      <category>cs.RO</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Ariel Gjaci, Carmine Tommaso Recchiuto, Antonio Sgorbissa</dc:creator>
    </item>
    <item>
      <title>PWM: Policy Learning with Large World Models</title>
      <link>https://arxiv.org/abs/2407.02466</link>
      <description>arXiv:2407.02466v2 Announce Type: replace-cross 
Abstract: Reinforcement Learning (RL) has achieved impressive results on complex tasks but struggles in multi-task settings with different embodiments. World models offer scalability by learning a simulation of the environment, yet they often rely on inefficient gradient-free optimization methods. We introduce Policy learning with large World Models (PWM), a novel model-based RL algorithm that learns continuous control policies from large multi-task world models. By pre-training the world model on offline data and using it for first-order gradient policy learning, PWM effectively solves tasks with up to 152 action dimensions and outperforms methods using ground-truth dynamics. Additionally, PWM scales to an 80-task setting, achieving up to 27% higher rewards than existing baselines without the need for expensive online planning. Visualizations and code available at https://www.imgeorgiev.com/pwm</description>
      <guid isPermaLink="false">oai:arXiv.org:2407.02466v2</guid>
      <category>cs.LG</category>
      <category>cs.AI</category>
      <category>cs.RO</category>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Ignat Georgiev, Varun Giridhar, Nicklas Hansen, Animesh Garg</dc:creator>
    </item>
  </channel>
</rss>
